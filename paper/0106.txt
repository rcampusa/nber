                        NBER WORKING PAPER SERIES



                     Parametric Integer Programming:
                        The Right—Hand—Side Case


                            Roy E. Marsten*
                           Thomas L. Morin**


                         Working Paper No. 106




      COMPUTER RESEARCH CENTER FOR ECONOMICS AND MANAGEMENT SCIENCE
               National Bureau of Economic Research, Inc.
                         575 Technology Square
                     Cambridge, Massachusetts 02139




                               October 1975


                     Preliminary: not for quotation

  NBER working papers are distributed informally and in limited numbers for
  comments only. They should not be quoted without written permission.

  This report has not undergone the review accorded official NBER publications;
  in particular, it has not yet been submitted for approval by the Board of
  Directors.

 *NBER Computer Research Center and Sloan School of Management, Massachusetts
  Institute of Technology. Research supported in part by NSF Grant GJ—1154X3
  to the National Bureau of Economic Research, Inc.

**School of Industrial Engineering, Purdue University.
                                 Abstract



       A family of integer programs is considered whose right—hand—sides lie

on a given line segment L. This family is called a parametric integer

program(PIP). Solving a (PIP) means finding an optimal solution for every

program in the family. It is shown how a simple generalization of the

conventional branch—and—bound approach to integer programming makes

it possible to solve such a (PIP). The usual bounding test is extended

from a comparison of two point values to a comparison of two functions

defined on the line segment L. The method is illustrated on a small example

and   computational   results for some larger problems are reported.




                             Acknowledgement


      The computer implementation of the algorithm reported here was done

by Lee Aurich and Nancy Kaplan.
                              Table of Contents



1. Introduction                                                         1

2. A Prototype Branch—and—Bound Algorithm                               2

3. The Optimal Return and Lower Bound Functions                         5

    Figure 1. Typical g(O) and LB(O) functions                          6a
    Figure 2. Typical B(Q) and uB(0;*) functions                        6a

LI. The Upper Bound Functions                                           7

5. A Branch—and—Bound Algorithm for (PIP)                               9

6. Example                                                   .   .   . 13
    Figure 3.   The optimal return function f(b)..           •   •   . 17
    Figure 4.   The parametric function g(O)       .    .             17
    Figure 5.   Branch—and—bound tree for the example                 18
    Figure 6.   Bounding test for node 1                              19
    Figure 7.   Bounding test for node 2                              19
    Figure 8.   Bounding test for node 3                              20
    Figure 9.   Bounding test for node 6      .                       20
    Figure 10. Bounding test for node 10 .                            21
    Figure 11. Bounding test for node 11 .                   •   .   . 21
7. Computational Results                                              22

    Table 1. Computational Results for Three Test Problems            23
    Table 2. The 5x30 Test Problem                           •   .   . 24
    Table 3. The g(O) function for a 10% Increase in b;
              5x30 problem                                            25

REFERENCES                                                            26
                                     1. Introduction



      The purpose of this paper is to show how a simple generalization of

the conventional branch—and—bound approach to integer programming makes

it possible to solve a parametric integer program. Following Nauss [6]

we shall call the family of programs


       (P0) max           r.x.
                    j=l


               subject to


                          a.           b.+Od.
                                        1   1


                               x,J     {O,l}

for         a single parametric integer program (PIP). By "solving" (PIP)

we shall mean obtaining an optimal solution of (P0) for every           for   which

(P) is feasible. We assume that (P0) is feasible for at least one value of 0.

      Parametric integer programming has only recently emerged as a topic

of research. The pioneering papers include Noltemeier [7], Roodman [9,10],

Piper and Zoltners [8], and Bowman [1]. Nauss [6] has reviewed this earlier

work and   contributed   many new results for parameterizations of the objective

function. The present paper, which has grown out of the authors' work on

synthesizing dynamic programming with branch—and—bound [3,4,5], is devoted

to the right—hand—side case.
                                         —2—



           In parametric linear programming, the first step is to solve (P0),

i.e. (P®) for 0=0. Then the direction vector d=(d1, •••         d)   is specified

and    the   analysis is performed by driving 0   from 0 to 1. Critical values of
0 and new optimal solutions are identified one at a time as 0 increases.

In the procedure for parametric integer programming to be presented here,

the direction d must be specified in advance. The (PIP) is solved in one

branch—and—bound      search. The usual bounding test is modified so that a
partial      solution is eliminated only if none of its descendants is optimal

for any (P®),              This means   that some partial solutions must be
retained that could otherwise be eliminated if only (P0) were of interest.
The severity of the resulting computational burden depends on the magnitude
of    d.


           The organization of the paper is as follows. A prototype branch—

and—bound algorithm for (P0) is presented in Section 2.

The lower bound and upper bound functions are developed in Sections 3 and

4, respectively. The modified branch—and—bound algorithm for (PIP) is

given in Section 5 and applied to a sample problem in Section 6. Computational

experience with the algorithm is reported in Section 7.




                  2. A prototype branch—and—bound algorithm



           We shall draw upon the framework and terminology of Geoffrion and

Marsten [2] to describe a simple linear programming based branch—and—bound

algorithm for (P0). Problem (P0) is separated, by fixing variables at zero
                                          —3—




and one, into smaller candidate problems (CP)• Each candidate problem
has an associated set of fixed variables                 c   J{l,   ...,   n}   and partial

solution          That is, (CP') is defined by the conditions x =                    for   j


The current set of candidate problems is called the candidate list. If
any feasible solutions of (P0) are known, the best of these                 is called the

incumbent      and its value denoted by LB. If we let J'= _q be the set of
"free" variables and

                     q= A.x
where   A is the jth      column of A, then a typical candidate problem may be

written   as

               (P)           r.x + max            rx.

                      subject to
                                                   ij j b.—
                                                  a.
                                                         1i
                                                       x•J (O,1}

An upper bound on the value of (CP) is obtained by solving its LP
relaxation (CP ). It is also helpful to compute a lower bound on the value of
(CP)•     This can   be   done by using   a   heuristic to find a feasible solution

of (CP)• This feasible solution, if it is better than the incumbent,

becomes the new incumbent. A prototype branch—and—bound algorithm may now

be described as follows.
                                  —4—
                                                                                                  .
                                                                    —
    Step 1. Place (P0) in the candidate list and set LB

    Step 2. If the candidate list is empty, stop. If there is an
              incumbent, it is optimal for (P0). Otherwise (P0) is            infeasible.
    Step   3. Select a candidate problem and remove it from the candidate
              list. Call it (P)
    Step 4.   Solve    the linear program (CP ). Let            denote its optimal
              value.
    Step 5. If           LB, go to Step 2.
    Step 6. If the optimal solution of (CP )         is   all integer, make this
              solution the new incumbent, set LB                and go to iep 2

    Step 7. Use a heuristic to find a feasible solution of              (P)• Let
                  denote its value. If        >   LB, then make this solution
               the new incumbent and set LB =


    Step 8. Separate (P) into two new candidate problems (P ) and                      (P )
                                                            =     u{p},           0,        =1.
              by choosing        and setting

              Place (P ) and     (P ) in the candidate list and return to
               Step 2.



     A great many variations on this pattern are described in [2], but this

prototype will suffice for our purposes. Step 5 is the bounding test.                  If

this test is satisfied, then no descendant of          is better than the incumbent.

Notice that the bounding test includes the case where (CP ), and hence

(P), is infeasible since then           =   — . If   (cP') does not have to be

separated at Step 8, then we say that it has been fathomed. This occurs

if (P) passes the bounding test or if (CP ) has an all integer solution.

Step 7, the heuristic, is optional. Its purpose is to strengthen the bounding

test by improving the incumbent and increasing LB.
                                            —5—



      The modifications that must be made to this prototype algorithm to

solve (PIP) are confined to Steps 5, 6, and 7. The notion of the incumbent

must be generalized from a single value LB to a function LB(6) defined on

o          The upper bound must also be expressed as a function of e:

The bounding test then becomes a comparison of two functions on the

interval         rather than just a point comparison for 00.




             3. The optimal return and             lower   bound functions.



      In this section we shall investigate the behavior of the optimal

value of an integer program as a function of its right—hand—side. Let

the optimal return function


            f(b.a) = max          rx    subject to Ax      b'

                        x     {0,l}
be defined for b            Rm.    It is apparent that f(b) is nondecreasing in each

component of b. Let {Xk                k E K} be the set of all feasible solutions of

(PIP), i.e. of all (F0) for                       For each k K, define the step function
                                                     k
                irnr.x kif b                c'n
                                            L     A.x.
     fk(b_) =       j=l                     j=l
                I   —       otherwise
for all V Rm.

The optimal return function f(b') is the pointwise maximum of this finite

collection of nondecreasing step functions


     f(b) = max {fk(b.) I k c K}
                                      —6—


                                                                                    S
and is therefore itself a nondecreasing step function.

        Now suppose that the solutions            k K) are known, where K C K.

A lower approximation of f(b') may be constructed from these known solutions,

namely


                = max   {fk(b) k

Clearly f(b) is also a nondecreasing step function and is a lower bound

function for f(b), i.e. (b)          f(b) for all b_€Rm. The approximation

can be improved as new feasible solutions are discovered.

        We are interested in a particular "slice" of f(b) and f(b): the

line segment                         b is the right—hand—side of (P0) and d is

the given direction vector. Define g(O)f(b+Od) and LB(O)=f(b+Od) for

           Then g(e) and LB(e) are both step functions and LB(O)     g(O) for all

           If dO, then g(O) and LB(O) are both nondecreasing. (See Figure 1).

There is at least one optimal solution of (PIP) associated with each step

of g(O). Solving (PIP) is equivalent to constructing g(e) by finding at

least one x solution for each of its steps.

         The procedure for constructing LB(O) from the known feasible solutions

is as follows. For each k E K define


            mm {O                b + Od}                              (3.1)



          = max {O I       A.x   b + Od}                              (3.2)
                        j=l


where       =      =+      if the indicated set is empty. Then


        LBk(O)           rx1                 if                        (3.3)

                 ={,
                   — _                       otherwise
                                —6 a—




0                   0



    Figure 1. Typical g(O) and LB(O) functions.




                            / TJB1(O;*)




0                       0                    1




      Figure 2. Typical UB(e) and UB(0;*) functions.
                                            —7—



and


       LB(0) = max{LBk(0)        k    i}.                                           (3.4)
The solutions which determine LB(0) will be called the incumbents. Each one

is incumbent for a particular interval of 0.

•                        4. The upper bound functions.



            Consider a given partial solution                 In order to demonstrate

that no descendant of            could be optimal for any                   we need an upper bound
                                                                (P0),
on the return achieved by any descendant and this upper bound must depend

on 0. Such an upper bound can be obtained by introducing (Od) into the

relaxed candidate problem (CP ).            Define

              =          rx + max           r•x.

          subject   to

                         a. •x    b.+
                                   1
                                      Od.—?
                                        11
                         1J J

                                                                        j    E


                                  J

so that UB(Q) =             It    is well known    that   UB(0) is concave and         piecewise
linear on           The function UB(0) could be obtained explicitly by

ordinary parametric linear programming. The computational burden involved

in   doing this for every candidate problem Could be quite substantial, however.
Fortunately any dual      feasible solution of (CP )           can be used to construct
a linear upper bound function for UB(B)                   An optimal dual solution of
(CP ), barring degeneracy, yields the first linear segment of UB(0)•
                                                 —8—



By linear programming duality we know                  that;

                =         rx + mm
                                           1=111           11
                                                 u.(b.+Od.—?) +
                                                                            1
                                                                            v.




              subject to                         u.a. + v.
                                                               J
                                                                   r.  .1
                                           i=l
                                                           U.      0
                                                               1

                                                           V.      0



For notational convenience we have included all of the v. variables,

even though v0 for                      in any optimal solution. Let             denote the

dual feasible region


          =   (u,v)0                   ua1. +           for



Since the primal variables are all bounded and at least one (P0) is

feasible, we may conclude that                   is non—empty. Let {(ut,                      and

{(y5, 8)55} denote the sets of extreme points and extreme rays,

respectively, of             Taking e(l, ..., 1) we have

                          rx1 +                        + vte
                                 J



for all t€T, with equality if (Ut, Vt) is optimal for the objective

function u(b+Od—) + ye. As a function of 0 then, the return achieved by

any descendant of            is bounded above by:


                    =   (utd)0       + [     r.x + ut(b_) + vte]
                                                 J J


for any              This is a linear function of U and,since uO, it is

nondecreasing if d0.
                                      —9—



            In the modified branch—and—bound algorithm for (PIP), linear

programming is applied to (CP ) as usual. The functions UB(@;t)        are
obtained at no extra cost. The function obtained from an optimal dual

solution will be denoted UBC1(S;*). Barring degeneracy, UB(;*) coincides

with the first linear segment of UB(0)• (See Figure 2). As in conventional

branch—and--bound, if the dual simplex method is used, then suboptimal dual

solutions can be used to perform additional weaker tests.




            If (CP )   is   infeasible, then the simplex method will terminate

with an extreme point (ut, vt)       0 and an extreme ray (S z5)      0,
such that

      S    q
     y (b—s )   + zs e < 0.


If y5dO, then we may conclude that IJB(0) =      —   for   all       If ySd>O

then UB'(O) =   —    for 0O<O* and B(e) UB'(O;t)       for         where

              5    q     5
     0*     —y (b—s ) — z e
                 S
                yd




                5. A branch—and—bound algorithm for (PIP).



            Now that the upper and lower bound functions have been derived,

the generalized bounding test may be stated. The partial solution            does

not have a descendant that is batter than an incumbent jf
                                          —10—



                  LB(8)                                 for all

or if


                    LB(O)                               for all


for some            This test is the basis for a modified branch—and—bound

algorithm that can solve (PIP).



     Step 1. Place (P0) in the candidate list and set LB(O) =                       —   for
     Step 2. If the candidate list is empty, stop.
              LB(0) = g(O) for

     Step 3. Select a candidate problem and remove it from the candidate
                  list. Call it

     Step 4. Solve (CP ).          If
                                    it is infeasible, obtain the appropriate
                  dual extreme point (u*, v*) and extreme ray (y*, z*).
                  Otherwise obtain an optimal dual solution (u*, v*).

        Step 5. I. (CP )      infeasible.
                     (a) y*d      0.    Go to Step 2.

                     (b)    y*d > 0.    Set 0* =    [_y*(b_1)_z*e]       /   y*d.
                            If TJB(®;*)     LB(O)    for all                 go to Step 2.

                  II. (CP ) feasible.
                      If (Q;*)          LB(0)    for all          go to Step 2.
     Step    6. If the optimal primal solution of (CP )             is       all integer,
                 use it to update LB(0).

        Step 7. Use a heuristic to find feasible solutions of (CP) with
                 right—hand—side (b+Od) for several values of 0. Use these
                 feasible solutions to update LB(0).

        Step 8.   Separate (CP) into two new candidate problems (P ) and
                  (P) by choosing         and setting q =      =    u p}

                      =0, x'     =1. Place (P) and (P) in the candidate

                  list and return to Step 2.
                                           —11—



         The validity of the generalized bounding test insures that art

optimal solution for every (P®),                  will be found by the search. At

worst, an optimal solution may not be discovered until the bottom of the

branch—and—bound    tree is reached (F=J)• This guarantees that 12(0) will
coincide   with g(0) by the time the algorithm is finished. It remains only

to show how the optimal solutions are identified.

         Let {x'kc} be the set of incumbents whenthe algorithm

terminates. Let 0E[O,l] and suppose that (P®) is feasible, g(e) >               —


From the construction of LB(0), (3.1) —           (3.4),   we know that there is some

kd such that


             g(0) = LB(0)

                  =LBk(O)



                  =j=l rx>—     k



Furthermore, LBk(O) >       —
                                     means that 0 0 0 ,       or   equivalently that



                  A.x    b+Od.
            j=l


Since      is feasible for (P®) and its return is equal to g(0), it follows

that      is optimal for (P®). To summarize, if k€ and 0€[O,1], then

optimal for (P®)    if   and only if


            i)          A.x'        b+Od
                  j=l


   and     ii)                  = g(0)
                  j=l
                                   —12—



       At Step 6, in contrast to the prototype algotithm,      is not fathomed

when the optimal primal solution of (CP )   is   all integer. This is because

   may have other descendants which are optimal for 0>0. The use of heuristics

at Step 7, while in principle optional, is an important part of the algorithm

since integer solutions of (CP ) can only yield LB(0) = LB(0) for

The heuristics are needed to produce stronger values of LB(0) for 0 >    0.

       As with the prototype algorithm, the above procedure will admit

considerable variation and refinement. If the dual simplex method is

used, then suboptimal dual solutions can be used to perform additional

bounding tests. Cutting planes can be generated for any candidate

problem to give stronger upper bound functions0 Parametric linear programming

can be used to generate more than the first segment of            If a

candidate problem with an all —integer LP solution has to be separated at

Step 8, then the same LP solution is optimal for one of the two new

candidates and does not have to be recomputed. Extensive experimentation

will be required to determine the most effective computational tactics.
                                              —13—




                                      6.      Example



       In this section the algorithm will be applied to a simple example.

In order to illustrate all of the different cases that can       arise,   the

parameterization will be done over a relatively large interval. The test

problem is


           max lOx1 + 15x2 + lOx3 + 5x4

        subject to

                2x1 + 3x2 + 5x3 + 1x4                 4 + 04



                4x1
                      +
                          2x2
                                + 1x3 + lx4           4   + 04


                                      E    {O,l}

Thus b(4,4), d=(4,4) and increasing 0 from zero to one amounts to doubling

the right—hand—side. A picture of the optimal return function f(b) is

given in Figure 3. The dashed line indicates the line segment of interest:

b+Od                It is clear from this picture that three optimal solutions

must be found, with values of 20, 25, and 30. These solutions are (0,1,0,1),

(1,1,0,0), and (1,1,0,1) respectively. The g(0) function, shown in Figure 4, is


                     2O   for0        0<1/2
           g(0) =     25 for 1/2          0 <   3/4
                     130 for    3/4       0     1.


       The optimal LP solution of (F0) is x=(l/2,l,O,0), u=(5,O), v=(O)

with value UB°=20. The rounded down solution has value 15 and is feasible

for e0; the rounded up solution has value 25 and is feasible for 01/2.
                                        —14—




This provides an initial lower bound              function:

          LB(O) =       for 0   0 <         1/2
                    ç15
                    125 for 1/2   0           1.

The complete branch—and—bound tree is displayed in Figure 5. The nodes

will be discussed in the order in which they were created.



Node 1. LP solution: x(O,l,O,l), u(5,O), 'v(0), UB20. 1B1(0;*)=208+20.

The LP solution is all integer and is feasible for 00. Therefore the lower

bound function may be improved:


          LB(0) =         for 0       0 <   1/2
                    120
                    125   for   1/2     0     1.


The bounding test for node 1 is shown in Figure 6. Node 1 is not fathomed.



Node 2. LP solution: x(l,0,O,O), u(0,lO), v(O),                13B2(0;*)400+lO.

The bounding test, shown in Figure 7, is not successful. Notice that if we

were only interested in solving (P0) we would be finished. Node 1 has an

all integer solution with value 20 and node 2 has upper bound UB2=lO<20L3(0).



Node 3. LP solution: x=(0,0,315,l), u=(2,O), (0,0,0,3),       =ll.
IJB3(0;*)80+1l. The bounding test, shown in Figure 8, is successful and

node 3 is fathomed.



Node 4. Same as node 1, since optimal LP solution at node 1 has x2 = 1.



flex, Same as node 2, since optimal LP solution at node 2 has         =   0.
                                            —15—



Node 6. LP is infeasible.. The dual extreme point is u=(0,lO), v=(0) and

the   extreme ray is y=(O,l), z(0). The critical value of U is (—y(b—6)—ze.)/yd=l/2.

Thus 6(U). —           for   0O<l/2 and UB6(e;*)=400+5 for              The bounding

test is shown in Figure 9.



Node 7. Same as nodes 1 and 4, since optimal LP solution for node 4 has x30.



Node 8. LP is infeasible. The dual extreme point is u=(5,0), v='(O) and

the extreme ray is y(l,0), z=(0). The critical value of U is (—y(b—8)—ze)/yd=l,

so TJB8(U) =   —       on            and node 8 is fathomed.



Node 9. Same as nodes 2 and 5, since optimal LP solution for node 5 has x3=O.



Node 10. LP is infeasible. The dual extreme point is u(5,0), v=(0) and

the extreme ray is y(l,O), z=(0). The critical value of U is (—y(b—°)—ze)/yd=3/4.

Thus UB10(U) —          for     0U<3/4 and UB(U;*)=20U+5 for             Node 10 is

therefore fathomed. See Figure 10.



Node 11. LP is infeasible. The dual extreme point is u(0,5), v(0) and

the extreme ray is y(O,l), z(0). The critical value of U is (y(b_L)—ze)/ydl/2.

Thus UB11(U) =     —        for   0U<l/2 and 1JB11(U;*)=20U+15 for         Node 11 is

not fathomed. See Figure 11.



Node 12. LP is infeasible. The dual extreme point is u=(5,0), v=(0) and

the extreme ray is y(1,0), z=(0). The critical value of U is (—y(b-2)—ze)/yd1

Therefore 12(U) =           —      for       and node 12 is fathomed.
                               —16—


                                                                              S
      Nodes 13—18 are all at the bottom level of the search tree. The

solution for node 18, (1,1,0,1), has value 30 and is feasible for O3/4.

The lower bound function may be improved by redefining LB(O)30 for

LB(O) now coincides with g(O) on         The algorithm terminates since the

candidate list is empty.




      The amount of extra computation required to solve (PIP), as compared

to (P0), depends on the length of the interval of parameterization. When

this interval is small, the burden imposed by parameterization may be

slight or even negligible. When it is large, however, as illustrated in

this example, the burden can be quite substantial.
                           —17—


 8


 7



 6

 5


 4



 3

 2



 1



 0
         1     2       3          4   5    6    7     8   b1


         Figure 3.    The optimal return function f(b).



30


25

20

15


10

 5




     0        1/4             1/2         3/4         1


          Figure 4.   The parametric function g(O).
                                  —18—




                                          =1




                                                           x21




                                         x3= 1         x3= 0           x3= 1
       x30




                                                 x40           x4= 1
x4=O                  x4O




             Figure 5. Branch—and--bound tree for the example.
                   —19—




30

25

20


15


10


5

0
     1/4          1/2         3/4             1



      Figure 6.   Bounding test for node 1.




     1/4          1/2        3/4           1




     Figure 7. Bounding test for node 2.
                  —20—




30

                           LB (6)
25

20


15


10


 5

 0
     1/4          1/2         3/4


      Figure 8. Bounding test for node 3.




30          406+5, 01/2

25

20


15


10


 5



0
     1/4        1/2         3/4            1


     Figure 9. Bounding test for node 6.
                   —21—




30

25

20

15

10

5


0
     1/4         1/2           3/4       1


     Figure 10. Bounding test for node 10.




                200+15, 01/2




0
     1/4        1/2            3/4       1


     Figure 11. Bounding test for node 11.
                                 —22--




                       7. Computational Results


      The ideas presented above were tested by incorporating them into a

branch—and—bound computer code [3J. The results for three test problems are

presented in Table 1. In each run the direction vector d was taken as some

percentage of the right—hand—side b. For example, if d5%b, then (PIP) has

right—hand—sides b+O(.05)b for           The column headed "solutions" gives

the number of optimal solutions found, or equivalently the number of steps

of the g(O) function. "Heuristic" is the number of (evenly spaced) e values

for which the heuristic is applied at Step 7. The problems are of the capital

budgeting type and the heuristic employed is that of Toyoda [11]. "Pivots"

is the total number of linear programming pivots and "time" is the total

solution time in seconds on an IBM 370/168.

      These results illustrate quite clearly how the computational burden

increases as the interval of parameterization is lengthened. In order to

facilitate comparison with our results by other researchers we have included

the data for the 5x30 problem as Table 2 and the corresponding g(O) function

for a 10% increase in b as Table 3.
                                 —23—



     Table 1. Computational Results for three test problems.




 m     n        d       solutions       heuristic   pivots      time

 5    15            0        1               1        39         .239


                .05b         4              10        62         .541


               .lOb          5              10        91         .815


               .15b          7              10       124        1.044

               .20b          8              10       130        1.170

               .25b         10              10       171        1.534

               .50b         16             20        315        3.162

 5    30            0        1              1        153        1.605


               .05b         10             10        479        7.280


               .lOb         26             10       1958       24.040

10    28            0        1              1         67        1.073

               .05b         16             10        181        4.192

               .lOb         29             20        637       11.970

               .15b         42             20       1586       29.204
                               —24—




            Table 2. The 5x30 test problem.

     a.
      ij       a
               zj
                        a.            a.4J    a.5J   c.
                                                      3

     188        91       20            86     164     936
      92       179       99            97      98     695
       6       146       95            42       2     390
      80       155       95            90     165    1152
      91       102       84           101     140     980
      44       112      136              3    106    1000
     108       126      166           101      88     815
     166        21       13            34      68     109
     171        39       20            25      84     807
      64        67      124            72     131     156
      97        29       42            96      55     548
      35        55       58            36      11     335
      51           72    43              3     17     316
      98           17    43            88        4    528
      36            0    44            97      47      36
      70           42      2            77     45    573
      27        15       88            50      11      38
      94           64    55            14      77         3
      68           53    68             77     36     800
      13           30    22             88     49     392
     13.2      2.8      6.8           11.3    2.9      92
     15.1     15.0       8.3          13.8    11.7        4
      3.3      2.6       8.9           4.5    19.2     29
      7.4      3.5       3.1          17.1    18.1     81
      7.0     17.0      16.5          11.8     3.8        2
      1.2      3.5       2.2          17.1    18.0     40
      7.0      5.1       9.7          19.1     8.8     17
     17.0     16.2       4.7           5.0     3.9     16
     13.8     13.2       1.8          10.2    16.9     30
     9.4      13.9      11.0           3.6    13.8    118

b=    800      800       700           700     800
                          —25—




Table 3. The g(O) function for a 10% increase in b; 5x30 problem.




   0      g)          0          g(0)        8        g(0)
  0.0     7515      .44166       7806     .74142      7947
.02750    7578      .52499       7822     .74714      7957
.09666    7607      .59000       7839     .78499      7987
.15428    7612      .64250       7849     .81285      8009
.16875    7633      .64285       7850     .84428      8049
.17125    7696      .65571       7891     .89124      8060
.20374    7725      .68500       7913     .93832      8079
.33625    7726      .70833       7931     .96666      8112
.36666    7777      .71750       7942
                                   —26—


                                REFERENCES



 -i..   BOWMAN,V.J., "The Structure of Integer Programs under the Hermitian
          Normal Form," Operations Research, Vol. 22 No.5 (Sept-Oct), 1974,
          pp.   1067-1080.


 2      GEOFFRION, A.M. and MARSTEN, R.E., "Integer Programming Algorithms: A
          Framework and State—of-the-Art-Survey," Management Science,
          Vol. 18 (1972), pp. 465—491.

                                    "
 3. MARSTEN, R.E. and MORIN, T.L.,    A Hybrid Approach to Discrete Mathematical
       Programming," Sloan School of Management, MIT, Cambridge, Mass. July, 1975.



 4. MORIN, T.L. and MARSTEN, R.E., "An Algorithm for Nonlinear Knapsack
       Problems," Technical Report No. 95, Operations Research Center,
      Massachusetts Institute of Technology, Cambridge, Mass., May, 1974.



 5. MORIN, T.L. and MARSTEN, R.E., "Branch and Bound Strategies for
       Dynamic Programming," WP75O-74, Sloan School of Management,
       MIT, Cambridge, Mass., November, 1974.



 6. NAUSS, R.M., "Parametric Integer PrograniTling," Ph.D Dissertation,
       University of California, Los Angeles, January, 1975.


 7. NOLTEMEIER, H., "Sensitivitalsanalyse bei disketen linèaren
       Optimierungsporblemen," in M. Beckman and H.P. Kunzi (eds),
       Lecture Notes in Operations Research and Mathematical Systems, #30,
       Springer-Verlag, New York, 1970.


8. PIPER, C.J. and ZOLTNERS, A.A., "Implicit Enumeration Based Algorithms
      for Postoptiniizing Zero-One Programs," Management Sciences Research
      Report, No. 313, Graduate School of Industrial Administration, Carnegie-
      Mellon University, March, 1973.


9. ROODMAN, G.M., "Postoptimality Analysis in Zero—One Programming by
      Implicit Enumeration," Naval Research Logistics Quarterly, Vol. 19,
      1972, pp.435—447.


10. ROODMAN, G.M., "Postoptimality Analysis in Integer Programming by Implicit
       Enumeration: The Mixed Integer Case," The Amos Tuck School of
       Business Administration, Dartmouth College, October, 1973.

11. TOYODA, Y., "A Simplified Algorithm for Obtaining Approximate Solutions to
       Zero—One Programming Problems," Management Science, Vol.21, 1975,
       pp. 1417—1427.
