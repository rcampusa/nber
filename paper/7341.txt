                                 NBER WORKING PAPER SERIES




                               CAViaR: CONDITIONAL VALUE AT
                               RISK BY QUANTILE REGRESSION

                                            Robert F. Engle
                                           Simone Manganelli

                                           Working Paper 7341
                                   http://www.nber.org/papers/w7341


                       NATIONAL BUREAU OF ECONOMIC RESEARCH
                                1050 Massachusetts Avenue
                                  Cambridge, MA 02138
                                     September 1999




The views expressed herein are those of the authors and not necessarily those of the National Bureau of
Economic Research.

© 1999 by Robert F. Engle and Simone Manganelli. All rights reserved. Short sections of text, not to exceed
two paragraphs, may be quoted without explicit permission provided that full credit, including © notice, is given
to the source.
CAViaR: Conditional Value at Risk By Quantile Regression
Robert F. Engle and Simone Manganelli
NBER Working Paper No. 7341
September 1999
JEL No. C14

                                                ABSTRACT

        Value at Risk has become the standard measure of market risk employed by financial institutions
for both internal and regulatory purposes. Despite its conceptual simplicity, its measurement is a very
challenging statistical problem and none of the methodologies developed so far give satisfactory solutions.
Interpreting Value at Risk as a quantile of future portfolio values conditional on current information, we
propose a new approach to quantile estimation which does not require any of the extreme assumptions
invoked by existing methodologies (such as normality or i.i.d. returns). The Conditional Value at Risk or
CAViaR model moves the focus of attention from the distribution of returns directly to the behavior of the
quantile. We postulate a variety of dynamic processes for updating the quantile and use regression quantile
estimation to determine the parameters of the updating process. Tests of model adequacy utilize the
criterion that each period the probability of exceeding the VaR must be independent of all the past
information. We use a differential evolutionary genetic algorithm to optimize an objective function which is
non-differentiable and hence cannot be optimized using traditional algorithms. Applications to simulated and
real data provide empirical support to our methodology and illustrate the ability of these algorithms to adapt
to new risk environments.


Robert F. Engle                                          Simone Manganelli
Department of Economics                                  Department of Economics
University of California, San Diego                      University of California, San Diego
San Diego, Ca. 92093                        San Diego, Ca. 92093
and NBER
rengle@weber.ucsd.edu
         CAViaR: CONDITIONAL AUTOREGRESSIVE VALUE AT RISK BY

                              REGRESSION QUANTILES



                           Robert F. Engle and Simone Manganelli

                             University of California, San Diego

                                          July 1999



1. INTRODUCTION

   Recent financial disasters have emphasized the importance of effective risk
management for financial institutions. The use of quantitative risk measures has become

an essential management tool to be placed in parallel with the models of returns. These

measures are used for investment decisions, supervisory decisions, risk capital allocation

and external regulation. In the fast paced financial world, effective risk measures must be

as responsive to news as are other forecasts and must be easy to grasp even in complex

situations. Many financial institutions have switched from management based on accrual

accounting (a practice according to which transactions are booked at historical costs plus

or minus accruals) to management based on daily marking-to-market. This switch has

caused an increase in the volatility of the apparent value of overall positions held by

financial institutions, which now reflects the volatility of the underlying markets and the

effectiveness of hedging strategies.

       Value at Risk (VaR) has become the standard measure of risk employed by

financial institutions and their regulators. VaR is an estimate of how much a certain

portfolio can lose within a given time period and at a given confidence level. More
precisely VaR is defined so that the probability that a portfolio will lose more than its

VaR over a particular time horizon is equal to 0, a prespecified number. The great

popularity that this instrument has achieved among financial practitioners is essentially

due to its conceptual simplicity: VaR reduces the (market) risk associated with any

portfolio to just one dollar amountThe summary of many complex bad outcomes in a

single number, naturally represents a compromise between the needs of different users.

This compromise has received the blessing of a wide range of users and regulators.

      Despite its conceptual simplicity, the measurement of VaR is a very challenging

statistical problem and none of the methodologies developed so far gives satisfactory

solutions. Since VaR can be computed as the quantile of future portfolio returns,

conditional on current information, and since the distribution of portfolio returns typically

changes over time, the challenge is to find a suitable model for time varying order

statistics.

      The problem is to forecast a value each period that will be exceeded with probability

(1-0) by the current portfolio. That is, for {y, }, find VaR1 such that

(1)              Pr[y <—VaR1 c,_11= 0,

where Q11 denotes the information set at time t-1. Any reasonable model should solve

the following three issues:

1) provide a formula for calculating VaR1 as a function of variables known at time t-1

      and a set of parameters that need to be estimated;

2) provide a procedure (namely, a loss function and a suitable optimization algorithm) to

      estimate the set of unknown parameters;

3) provide a test to establish the quality of the estimate.


                                                                                           2
   In this paper we address each of these issues. We propose a conditional
autoregressive specification for VaR1, which we call Conditional Autoregressive Value at

Risk (CAViaR). The unknown parameters of the CAViaR models are estimated using

Koenker and Bassett's (1978) regression quantile framework. Building on White (1994)

and Weiss (1991), we extend the results of the linear regression quantile to the nonlinear

dynamic case, providing the asymptotic distribution of the estimator and a procedure to

estimate the variance-covariancc matrix. We also show how to construct the Wald and

LM statistics to test for significance of the coefficients of the CAViaR process. Since the

regression quantile objective function is not differentiable and has many local optima (in

the nonlinear case), we use a genetic algorithm for the numerical optimization. Finally,

we propose a new test, based on an artificial regression, to evaluate the quality of the

estimated CAViaR processes.

   The paper is structured as follows. In section 2, we quickly review the current

approaches to Value at Risk estimation. Section 3 introduces the CAViaR models. In

section 4 we discuss the issue of how to evaluate a quantile estimate. In sections 5 and 6

we review the literature on regression quantiles and hypothesis testing. Section 7 contains

a brief description of the genetic algorithm we use for the numerical optimization.

Sections 8 and 9 present a Monte Carlo simulation and some empirical applications to

real data of our methodology. Section 10 concludes the paper.



2. VALUE AT RISK MODELS

    VaR estimates can be used for many purposes. The natural first field of application is

risk management. Setting position limits in terms of VaR can help management estimate




                                                                                         3
the cost of positions in term of risk. This allows managers to allocate risk in a more

efficient way. Second, VaR can be applied to evaluate the performance of the risk takers

on a risk/return basis. Rewarding risk takers only on a return basis can bias their behavior

toward taking excessive risk. Hence, if the performance (in terms of returns) of the risk

takers is not properly adjusted for the amount of risk effectively taken, the overall risk of

the firm may exceed its optimal level. Third, the European Community and the Basel

Committee on Banking Supervision at the Bank for International Settlements require

financial institutions such as banks and investment firms to meet capital requirements to

cover the market risks that they incur as a result of their normal operations. However, if

the underlying risk is not properly estimated, these requirements may lead financial

institutions to overestimate (or underestimate) their market risks and consequently to

maintain excessively high (low) capital levels. The result is an inefficient allocation of

financial resources that ultimately could induce firms to move their activities into

jurisdictions with more liberal financial regulations.

    The existing models for calculating VaR differ in the methodology they use, the

assumptions they make and the way they are implemented. However, all the existing

models follow a common general structure, which can be summarized in three points: 1)

the portfolio is marked-to-market daily, 2) the distribution of the portfolio's returns is

estimated, 3) the VaR of the portfolio is computed.

    The main differences among VaR models are related to the second point, namely the

way they address the problem of the portfolio distribution estimation. Existing models

can be classified initially into two broad categories: a) factor models such as RiskMetrics,

b) portfolio models such as historical quantiles. In the first case, the universe of assets is




                                                                                           4
projected onto a limited number of factors whose volatilites and correlations have been

forecast. Thus time variation in the risk of a portfolio is associated with time variation in

the volatility or correlation of the factors. The VaR is assumed to be proportional to the

computed standard deviation of the portfolio, often assuming normality.

    The portfolio models construct historical returns that mimic the past performance of

the current portfolio. From these historical returns, the current VaR is constructed based

on a statistical model. Thus changes in the risk of a particular portfolio are associated

with the historical experience of this portfolio. Although there may be issues in the

construction of the historical returns, the interesting modeling question is how to forecast

the quantiles. Several different approaches have been employed. Some first estimate the

volatility of the portfolio, perhaps by GARCH or exponential smoothing, and then

compute VaR from this, often assuming normality. Others use rolling historical quantiles

under the assumption that any return in a particular period is equally likely. A third

appeals to extreme value theory.

        It is easy to criticize each of these methods. The volatility approach assumes that

the negative extremes follow the same process as the rest of the returns and that the

distribution of the returns divided by standard deviations will be independent and

identically distributed if not normal. The rolling historical quantile method assumes that

for a certain window, such as a year, any return is equally likely, but a return more than a

year old has zero probability of occurring. It is easy to see that the VaR of a portfolio will

drop dramatically just one year after a very bad day. Implicit in this methodology is the

assumption that the distribution of returns does not vary over time at least within a year.




                                                                                              5
   An interesting variation of the historical simulation method is the hybrid approach

proposed by Boudoukh, Richardson and Whitelaw (1998). The hybrid approach

combines volatility and historical simulation methodologies, by applying exponentially

declining weights to past returns of the portfolio. This approach constitutes a significant

improvement over the existing methodologies, since it drastically simplifies the
assumptions needed in the traditional VaR methodology and solves part of the
contradictions implicit in the historical estimation. However, both the choice of the

parameters of interest and the procedure behind the computation of the VaR seem to be

ad hoc and based on empirical justifications rather than on a sound statistical theory.

   Applications of extreme quantile estimation methods to VaR have been recently

proposed by Danielsson and de Vries (1998) and Gourieroux and Jasiak (1998). The

intuition here is to exploit results from statistical extreme value theory and to concentrate

the attention on the asymptotic form of the tail, rather than modeling the whole
distribution. There are two problems with this approach. First it works only for very low

probability quantiles. As shown by Danielsson and de Vries (1998), the approximation

may be very poor at very common probability levels (such as 5%), because they are not

"extreme" enough. Second, and most importantly, these models are nested in a

framework of i.i.d. variables, which is not consistent with the characteristics of most

financial datasets and consequently, the risk of a portfolio may not vary with the

conditioning information set.

    Beder (1995) applies eight common VaR methodologies to three hypothetical

portfolios. The results show that the differences among these methods can be very large,




                                                                                           6
with VaR estimates varying by more that 14 times for the same portfolio! Clearly, there is

a need for a statistical approach to estimation and model selection.



3. CAVIAR

      We propose another approach to quantile estimation. Instead of modeling the whole

distribution, we model directly the quantile. The choice of the best functional form is

mainly an empirical problem and will be determined by the data set under study. The first

thing to keep in mind is the empirical fact that volatilities of stock market returns tend to

cluster over time. This fact may be translated in statistical words by saying that the

distribution of stock market returns tends to be autocorrelated. Consequently, the VaR,

which is tightly linked to the standard deviation of the distribution, must exhibit a similar

behavior. A natural way to formalize this characteristic is to use some type of

autoregressive specification. We propose a conditional autoregressive quantile
specification, which we call Conditional Autoregressive Value at Risk (CAViaR).

      A very general specification for the CAViaR might be the following:

                 VaR1 =f(x1,/ig)
(2)                    =    + /31VaR1_1 + l(fl+1,..., flp+q ;   c1)
where Q11 is the information set available at time t and we suppressed the 9 subscript for

notational convenience.

      In most practical cases the above formulation might reduce to a first order model:

(3)              VaR1 =fl0+fl1VaR,1+1(fl2,y1_1,VaR11)

      The autoregressive term /31VaR11 ensures that the VaR changes "smoothly" over




                                                                                           7
time. The role of l(/32,y_i,VaR1_i), instead, is that of linking the level of VaR, to the

level of        That is, it measures how much the VaR should change based on the new

information in y. This term thus has much the same role as the News Impact Curve for

GARCH models introduced by Engle and Ng(1993). Indeed, we would expect VaR, to

increase as y,.j becomes very negative, as one bad day makes the probability of the next

somewhat greater. It might be that very good days also increase VaR as would be the

case for volatility models. Hence VaR could depend symmetrically upon

      Note that in order for the process in (2) not to be explosive, the roots of

(4)               1—f31z—/32z2—...—/3z"=O

must lie outside the unit circle.

      Here are some examples of CAViaR processes which will be estimated. Obviously

these      merely    scratch    the    surface.    Throughout we use            the   notation

(x) = max(x,O), (x) = min(x,O).

      1. ADAPTIVE:        VaR, — VaR,1   +/3[I(y, —VaR,1)—O]

In terms of the general specification, we set

       fl0 =0, ,8 =1, l(/32,y,_1,VaR1_1)=/32[I(y,_i —VaR,_i)—8]

This model incorporates the very simple rule: whenever you exceed your VaR you should

immediately increase it, but when you don't exceed it, you should decrease it very

slightly. This strategy will obviously reduce the probability of sequences of hits and will

also make it unlikely that there will never be hits. It however learns nothing from returns

which are close to the VaR or which are extremely positive.

      2. PROPORTIONAL SYMMETRIC ADAPTIVE:




                                                                                            8
                    VaR, = VaR     + /(I y,     —VaR,_1)
                                                           —
                                                               /12(1 y,   I
                                                                              —VaR


   3. SYMMETRIC ABSOLUTE VALUE:                VaR, = /1 + /31VaR, + /11 Y,-i        I




   4.   ASYMMETRIC ABSOLUTE VALUE:             VaR, = /3 + /3LVaR, I +        fl I Y,-   —
                                                                                             /33   I



   5.   ASYMMETRIC SLOPE:


        VaR, = /0 + fi1VaR,1 + fl2(Y-1)   —fl3(Yf1)



   6.   INDIRECT GARCH(1,1):          VaR, =   (j + fi2VaR,1 +
   The INDIRECT GARCH model would be correctly specified if the underlying data

were truly a GARCH(1,1) with an i.i.d. error distribution. It is therefore a useful model

for simulations. However if this model is correctly specified, then it would be more

efficient to estimate the GARCH model directly by Maximum Likelihood and then infer

the VaR from the distribution of the standardized residuals.



4. TESTING VALUE AT RISK MODELS

   If a model is correctly specified, then Pr(y, <—VaR,) = 0                      Vt,    at        the true

parameter. This is equivalent to requiring that the sequence of indicator functions

{i(y, <—VaR, )}i be independent and identically distributed. Hence, a property that any

VaR estimate should satisfy is that of providing a filter to transform a (possibly) serially

correlated and heteroskedastic time series into a serially independent sequence of

indicator functions. A natural way to test the validity of the forecast model is to check

whether the sequence {I(y, <—VaR,)}i1 {I,}1 is i.i.d.




                                                                                                         9
      Several statistical procedures are available to check the i.i.d. assumption. At least

three possibilities have been discussed in the literature for general dynamic Bernoulli

random variables: Cowles and Jones (1937), the runs test by Mood (1940) and

straightforward application of Ljung and Box (1978).

      All these tests can detect the presence of serial correlation in the sequence of indicator

functions {i}. However, this is not enough to assess the performance of a VaR

estimate. Indeed, it is not difficult to generate a sequence of independent {i }i from a

given sequence of            }. It   suffices to define a sequence of independent random

variables {z,       such that


                        Ii              with probability 0
(5)                zt=1
                        —1              with probability (1 -0)

Then, setting VaR = Kz,, for K large, will do the job. Notice however, that once
                                                                               is z

observed, the probability of exceeding the Value at Risk is known to be almost zero or

one. Thus the unconditional probabilities are correct and serially uncorrelated, but the

conditional probabilities given VaR are not. This example is an extreme case of

measurement error in VaR. Any noise introduced into the Value at Risk will change the

conditional probability of a hit given VaR.

      Therefore, none of these tests has power against conditional bias and none can be

simply extended to examine other explanatory variables. We propose a new test which

can be easily extended to incorporate a variety of alternatives.

      Define:

(6)               Hit(y1,x,,0)Hit I(y1 <—VaR1)—O.


                                                                                             10
The Hit function assumes value (1-0) every time y is less than VaR, (i.e., every time a

"hit" is realized) and (-0) otherwise. Clearly the expected value of Hit is zero.

Furthermore, from the definition of the quantile function, the conditional expectation of

Hit given any information known at t-1 must also be zero. A simple application of the

law of iterated expectations shows that Hit must be uncorrelated with anything that

belongs to the information set £2:

(7)            E(Hit1   a) =co E(Hit, oj) = 0                     Vw,j Ef2,j.

       In particular, Hit1 must be uncorrelated with any lagged Hjt,k, with the forecasted

VaR, and with a constant. If Hit1 satisfies these moment conditions, then it is sure that

there will be no autocorrelation in the hits, there will be no measurement error as in (5),

and there will be the correct fraction of exceedences. If it is desired to check whether

there are the right proportion of hits in each calendar year, then this can be measured by

checking the correlation of Hit with annual dummy variables. If other functions of the

past information set are suspected of being informative such as rolling standard

deviations or a GARCH volatility estimate, these can be incorporated. A very convenient

way to construct a test is to regress Hit on these independent variables':

                Hit, = 8 + 8,Hit,_1 + ... + b'Hit,_ + 5÷,VaR, +
(8)
                         8p-t-2'yearl,t + + 8p+2+n'yearn,l + Ut

Rewriting this artificial regression in matrix form, we get:

                                                        prob(1—0)
(9)             Hit =X8+u              u =1—0
                                            (1—0)      prob0
A good model should produce a sequence of unbiased and uncorrelated hits, so that the

explanatory power of this artificial regression should be zero. Hence, what we want to




                                                                                        11
test is the null hypothesis H0. 5=0. Noticing that the terms in X are measurable-Q i-i, the

asymptotic distribution of the OLS estimator under the null can be easily established,

invoking an appropriate central limit theorem:


(10)              5OLS =(X'X)'X'Hit - N(0,8(l—9XX'X))
It is now straightforward to derive the Dynamic Quantile test statistic:
                  8OLSXXSOLS
(11)                                  z(p+n+2)
       While this measure of performance is quite useful, its distribution in-sample is

affected by the fact that the Hits are functions of estimated parameters. We will discuss

this problem in section 6.



5. REGRESSION QUANTILES

    Regression quantiles models were introduced by Koenker and Bassett (1978). They

show how a simple minimization problem yielding the ordinary sample quantiles in the

location model can be generalized to the linear regression model. Consider a sample of

independent observations on random variables yj, .. . ,y. distributed according to

(12)              Pr(y <rjx,)=F(rx1)               t i,...,T

where x, is a (k,1) vector of regressors. Let x,/30 be the 0-quantile. Then the model can

be rewritten as

                      x /3
(13)              0= Jf,,(sx1)ds

or, following the convention established by the literature, as

(14)            y, = xi'/i +   u           Quant6('ygxc) = x1'/Jo


 An analogous procedure to evaluate interval forecasts was proposed by Christoffersen (1998).


                                                                                                12
where Quantd'y1Ix) = x1'/J0 is the O-quantile ofy conditional on Xt.

   When x1=1, t= 1, ..., T, we get as a special case the location model, in which fl simply

represents the sample O-quantile. It is straightforward to show that the sample &-quantile

of a random sample {y, t = 1, ...,T) on a random variabley is defined as any solution to


(15)           mm'               OIy1-b+ (l-9)Iy-bI
                        t:y, b          t:y <b


   Koenker    and Bassett (1978) show that a direct generalization of this objective

function extends the notion of sample quantile to the linear model. The 6h regression

quantile is defined as any fi9 that solves:


(16)            mm'               Oy-x'fiI+        (1—O)y1—x,'flI
                                                 t:y,<x,13


    Rewriting this expression in terms of the indicator function yields the equivalent

objective function:


(17)            min{_ >[J(y <x,'/3)- 0] [y - x/fl]}

    Regression quantiles include as a special case the least absolute deviation (LAD)

model. The properties of LAD have been discussed for many years and it is very well

known that they are more robust than OLS estimators whenever the errors have a long

tailed distribution. Koenker and Bassett (1978) ran a simple Monte Carlo experiment and

show how the empirical variance of the median, compared to the variance of the mean, is

slightly higher under the normal distribution, but it is much lower under all the other




                                                                                           13
distributions taken into consideration.2 The result is particularly striking in the Cauchy

case.

     A very important generalization of the basic linear model is the one proposed by

Powell (1986), who introduced the censored regression quantiles model. Newey and

Powell (1990) show that a slight modification of the quantile regression objective

function is able to deliver efficient estimates. They address the issue of attainable

asymptotic efficiency for a linear regression model with error term restricted to have a

zero quantile, conditional on the regressors. They prove that weighting the terms of the

typical objective function with the conditional density at zero of the errors produces

estimators whose variance covariance matrix attains (asymptotically) the theoretical

lower bound.

      In the nonlinear case, in the context of time series, the most important contributions

are those by White (1991, 1994 p. 75) who proves the consistenéy of the nonlinear

regression quantile, both in the i.i.d. and stationary mixing or ergodic cases. Weiss (1991)

shows consistency, asymptotic normality and asymptotic equivalence of LM and Wald

tests for LAD estimators for nonlinear dynamic models. Using the consistency results

provided by White, Weiss's proofs of asymptotic normality and asymptotic equivalence

of the LM and Wald tests can be easily modified to accommodate the more general case

of nonlinear regression quantiles. In the rest of the paper, we rely heavily on Weiss's

assumptions and results. For convenience, we report here White's consistency result and

the quantile generalization of Weiss's asymptotic normality result.

      Consider the model



2
    They consider Gaussian mixture, Laplace and Cauchy distributions.


                                                                                         14
(18)      y, = f(x,/30)+ e               Quant0(e I -i)= 0

   The following assumptions are needed to guarantee the consistency of the regression

quantile estimator:



   Consistency Assumptions

   CO. (Q, F,     P) is a complete probability space and               t = 1, 2,..., are random

vectors on this space.

    Cl. The function f(x1,fl9):          xB — 9? is such that for each /3o in B, a compact

subset of ¶R°, f(x,fl0) is measurable with respect to the Borel set B" and f(x,,.) is

continuous in B, a.s.-P, t=1,2, ... for a given choice of explanatory variables X={x,}.

    C2. (a) E([I(y1 <f(x, /3)) —0] [y1 — f(x1 , fl9 ) exists and is finite for each /io in B.

          (b) E([I(y,. <f(x, , /39)) —0] [y — f(x1 , fl )I1 is continuous in /

          (c) ffI(y, <f(x1 , /30)) —01 [, — f(x1   /   )]} obeys the strong (weak) law of large

numbers. For example, we could assume that {c1,x,} are a-mixing. That is, a(m) satisfies

a(m)— 0 as m—x. See, for example, Andrews (1988) or White and Domowitz (1984)

for further details.

       C3. {n'E{{I(y1                       —f(x1,/39)J} has identifiably unique maximizers.



       Theorem 1 (Consistency, White (1994) page 75) - In model (18), under CO, C], C2

and C3, /3,, —> /3 as n—.,'cca.s.-Po, where fi is the solution to:


       maxn{[I(y, <f(x1,/39))—0] [y1 —f(x,,/39)]}.


                                                                                                15
   To prove the asymptotic normality of ,8, we need to introduce some extra notation.

Following Weiss, let v, be a (rxl) vector of variables that determine the shape of the

conditional distribution of s. Associated with v is a set of parameters •3 Denote the

density of 6, conditional on all the past information, as h (s; q5, v,), e E fiR. Whenever the

dependence on v, and q$ is not relevant, we'll denote the conditional density of simply

by h1(s). Let u,(Ø, fl    s)   be an unconditional density of s, = (St, x,, v). Finally, define the

operators V'a'ôfl, V9'Ô/3,, where fi,            is    the th   element    of j?, f(/3)Vf(x1,fl)          and


Vf(/Vf(xj,fl).



    Asymptotic Normality Assumptions

    AN1. V1J(fi9) is A-smooth with variables A, and functions p,, i=1,...,p. In addition,

max,p,(d)d for d>O small enough.4

    AN2. (i) h,(e) is Lipschitz continuous in 6 uniformly in t.

            (ii) For each t and ( v), h,(e;, v) is continuous in q5.

    AN3. For each (and s, u,(' ,8 s) is continuous in (q flu).

    AN4. {e,,x,} are a-mixing, with parameter a(m), and there exist zl<x and r > 2 such

that a(m)Am2 for some ,%<-2r/(r-2).



' For example, v, might include the conditional variance and q5 might be the vector of parameters that define
a GARCH model.
4f(x,,fl) is A-smooth with variables A0, and function p if, for each /3EB, there is a constant r>O such that
IIfl*_8Ur implies that                                      for all t, a.s.-P, where A0, and pare nonrandom
functions such that A01(xJ is a random variable, lim sup         E{A0, (x1 )] <   x, p(v) >0 for v>O, p(v) — as
                                                       n—
v—0 and r, A0,, p and the null set may depend on fi.


                                                                                                            16
   AN5. For some r>2, Vt(/l) is uniformly r-dominated by functions alt.

   AN6. For all t and i, Es            j<c/.   There exist measurable functions a21 such that

Iu.a2f and for all r, fa24v<and f(aj)3a24v<ci.

                                                      a+n
   AN7. There exists a matrix A such that n1 EIVj(fl9)V'j(fl0)]—÷ A,               as   n—,
                                                     t=a+l



uniformly in a.



   Theorem 2 (Asymptotic Normality) - In the model (18), fAN1-AN7 hold and f the

estimator is   consistent, then.




                           - /39)-÷N(o,l)


where A = n1E[Vj(fle)V'f,(fle)], D = nE[h,(O)Vj(fl9)V'J(fl0)] and /3 is

computed as in Theorem 1.




    Proof - Substituting    iji(x)=sign(x)=2[J(x<O)-1/2] with Hit(x)[I(x<O)-9J in theorem

3 of Weiss (1991) doesn't affect the validity of the argument.



    Note that the Adaptive model does not satisfy White's assumptions for consistency,

since the quantile function, VaR,(fi,), is not continuous in /3. Note also that the only two

models for which the gradient of the quantile function is defined for all /3 are the

Symmetric Absolute Value and the Indirect GARCH models. Hence, strictly speaking,

the asymptotic normality results apply only to these models. However, each of the six

models we take into consideration (including the Adaptive) can be approximated


                                                                                           17
arbitrarily well by continuous and differentiable functions. Since taking these
approximations don't affect the nature of the models (in the sense that the autoregressive

mechanism still applies), we can treat them as if they satisfy all the necessary

assumptions to give consistency and asymptotic normality results.



6. HYPOTHESIS TESTING

   Weiss (1991) proves the asymptotic equivalence of the Wald and LM test, in the case

of nonlinear dynamic LAD models. As for the asymptotic normality theorem, his proofs

can be easily modified to get the analogous tests in the more general case of regression

quantile models.

   The problem with these tests is related to the estimation of the variance-covariance

matrix of the estimator j, and more precisely to the fact that we need an estimate of the

density function of the distribution of the errors, h,(s), at zero. Under the homogeneity

assumption, i. e. assuming that h1(O)= h(O) for all t, Powell (1984) and Weiss (1991)

propose to estimate the density function with kernel estimation techniques:

(19)           h(O)=

where k() is a kernel, ê,, is the tth residual and   is the bandwidth. The most common

and simplest kernel is k(u) = I(1uJ)/2. The idea is that if c—O as n—x, then

    p
h(O)—÷h(O).

    The homogeneity assumption is clearly too much restrictive for our setting, since as

the quantile is changing over time it seems highly implausible that the density function of




                                                                                        18
the returns at the quantile stays fixed. We propose, instead, a less restrictive and, in our

opinion, more realistic assumption to estimate h,(0).

     The strategy we adopt is the following. We estimate the CAViaR model to obtain an

estimate of the quantile f(x,,       and   then construct the series of standardized quantile

residuals:

(20)                             y/f(x1,fl0)_1.
Let g,() be the density function of the standardized quantile residuals. To get an estimate

of           we impose the following assumptions.



Variance-Covariance Estimation Assumptions

VC1 -                     = g6l%/f(fl)J , for all t, provided that f(xt,fle)        0 for all t.



VC2 -   ê /c       where the nonstochastic sequence c,1 satisfies c=o(I)   and c = o(n').
VC3 - The elements of Vj(fl9) are uniformly 4-dominated.




     The crucial assumption is VC 1. This assumption states that the density function of the

standardized quantile residuals at zero is not time varying.

     To understand the implications of this assumption, consider the following. Assume

that the underlying model is y, =     = o-,s where s,     (0,1). By setting the mean of s=0

we   ensure that y, is a Martingale difference sequence. Even if assuming that E(st)=0 is

not necessary to get the desired result, imposing this assumption clarifies the plausibility

of our setting.



                                                                                            19
     Clearly, f(x,/38) = oK1, where K is the 8-quantile of St. If s, is i.i.d., then ,c1 is

constant and our assumption trivially holds. However, when St is not iid, ,c may change

over time and our assumption has force. The assumption can be reformulated in the

following way:



VC1' - Let q be the density function of s, /ic. Then q('])=q(1) for all t.




     Using the jacobian of the transformation, we can get the estimate of the density

function of the errors at zero:

                           g(O)
(21)             h,(O)=

     There is a third way to evaluate this assumption. Assume that model (18) is locally

correctly specified, where by this we mean that there is a neighborhood of 8 in which

model (18) holds. Consider Oj, 0 in this neighborhood and let f(x,,fl9) and f(x,,/30)

be   the corresponding quantile estimates. An estimator of the density function at the 8-

quantile (0 = (0 + 02)12) is:

                                  01—02!
( )               ()
                          f(x,/39 )— f(x1,,80 )i

As the difference between 0 and 02 goes to zero, this should give a consistent estimate

of the density function. The problem of this approach is that we need to estimate

 f(x1, f3) and f(x,, p0) together with f(x,          However, with an extra assumption we




                                                                                        20
can avoid the problem of re-estimation. Rewrite f(x1,         /i), f(x , fl0) and f(x, e)   as


         (7,K and (7tK. Then:


(23)              f(xj,fl0)=f(x,fl9)-           i1,2

If we assume that        0 2       r, for 8 and O' in a neighborhood of 0, then:
                          IC:



                                                        V
24                hO-s          101—021         —

                                                    If(x1,fl)I
                          If(xt,floKtJl
which is exactly the same result we got previously.

      With assumption VC1 and using the Jacobian of the transformation as in (21), it is

possible to rewrite the D matrix that enters the variance-covariance matrix in Theorem 2

as:

          =
              nE[h,(O)Vf,(fl0)Vf1(J30)J

         fllE[ f(fl)1Vft(flo)V(flo)]

       = nlg(O)E[W(flo)J(fl0)
                     [     f(x1,fl0)I

       A natural estimate of this matrix is:



(25)
                    ' = ( )_1ff(x1,po)    .fl

                                                ")          f(x,,fl0)




                                                                                            21
where k(u)=I(luI1)/2 is the kernel for g,            (O)                      and
                                                            1k[f(t.)/eflJ
        -         fx,,/30)
   We can now state the theorem.



   Theorem 3 (Estimation of the Asymptotic Variance-Covariance Matrix) - Under

VCI-VC3 and the same conditions of Theorem 2,

              p
    D —D—.O,

where D is defined as in (25).




                                  p
    Proof - The proof that C,, — C,, is standard and will be omitted. To prove that

       p
 (O)   —* g(O),   we show that


    ,, (cnn)[i[O                  ()cnJ ()cnJ]o
 Then, the Lebesgue Dominated Convergence Theorem implies that



    (cnn)i[O                     c)(O).
    By a simple application of the absolute value inequality, we have:




                                                                                 22
          A cnn)[i[O                            -   i[o
(26)
          +                             c] -
              (cn)-[I[O                         I[O

   Arguing as in Powell (1984), equation A.27, it is possible to show that the two terms

on the right hand side of(26) are o(I). The first term can be rewritten as:


       (cn) I' -                   ten - cn


    For any 77>0,



       Pr{(cfln)I[f() -Cn jC CntJ> }

       Pr{(cnn)
                                   - Cn z] >        + Pr C - c>

         ,[' (cn)                  - Cn         + Pr e - c> }
                      Pra(M)              z]
                    + Pr{c'tC c> }
                              —




by Markov's inequality and the Lipschitz continuity of hQ. Since c'jC —       = o(l) and

       = o(n), it is possible to choose z sufficiently small to make the last term of the

above expression arbitrarily small for large n.

       For the second term in (26), note that




                                                                                      23
                             —i1o                      <
            f(x,f39)        fl)           f(x1,J30)

   -     _________   <       et,n            Etn     ' jI     e1,           < ________   61,n

        f(x1,fl0)        f(x1,0) f(x,fl)J f(x,,fl9)                           f(x,fl0)f(x,,fle)
       11
            e1                           _________
    - f(x,,fl9)< f(x1,o)f(xt,flo)
                     + 11         6tn    —            —j+       t,n — 61,n
                                             'I
                                                             f(x,,fl9) f(x1,J30)


   Since    c1              —
                                             = o,,(l), we can apply the same reasoning as before to
                 fx,/30) f(x,,fl9)
show that also this term is o(I).

                                                                                                Q.E.D




    It is now possible to perform hypothesis testing on CAViaR models. We will
concentrate our attention only on Wald and LM test, since the Likelihood Ratio test has

different asymptotic distribution when the homogeneity assumption is not satisfied (see

Weiss). As usual, let R denote the matrix of restrictions with rank q. We want to test the

null hypothesis H0: RJ3=r.



    Theorem 4 (Wald and LM Test) -                Ifthe same conditions as Theorem 3 hold, under H0
    Wfl =                               —r) [Re ê;'R'](Rj3 _r)
            (1    0)[(O)F(Rflo
                                                                    a
                                                                        2
     LM



                                                                                                   24
where      =n'VJflg)V'J/3e),


        en =

        d(/3)=

(O) is computed as in Theorem 3 and denotes that the variables are evaluated at the

restricted estimates.



    Proof - The proof is again a straightforward extension of Weiss's proofs of theorems

6 and 8. It suffices to replace yi(x)=sign(x)2[I(x<O)-l/2] with Hit(x)=—[J(x<O)-OJ.



    Note that to compute the LM test under assumption VC, we don't need to estimate the

density of the standardized quantile residuals, since the g(O) term drops out of the

expression.

    The LM and Wald tests are appropriate if we want to test the null hypothesis R/3=O,

where flare the parameters of the CAViaR model. For example, these tests can be used to

evaluate whether more terms should be included in the CAViaR specification, such as

extra lagged VaR or y.

    If we adopt the point of view that any model is necessarily misspecified, given the

 complexity of the real world, then the Dynamic Quantile test should be regarded as

 complementary to the LM test. What we want to check is whether the chosen model

 satisfies some basic requirements a good quantile estimate must have, such as
 unbiasedeness, independent hits and independence of the quantile estimate. With the DQ

 test, we are testing the null 8=0, where 5 are the coefficient of the artificial regression



                                                                                         25
(8). If we cannot reject the null that the estimated hits are distributed as a bernoulli(O),

then we have "some" evidence that the model under study provides a satisfactory

description of the real world.

    The main problem with the DQ test is that we don't know its correct distribution when

fi is estimated with the same data being used for the test. However, if all we care about is
whether the hits are uncorrelated and unbiased, this can be tested by constructing the chi

square statistic proposed in expression (11). That is, we can interpret the DQ test as

testing the hit sequence conditional on the estimated betas. Hence, the DQ test can be

used as a model diagnostic or preliminary screening device to distinguish between good

and bad models. For example, the DQ test could be used to evaluate the performance of

the different VaR methodologies. If, for a given time series of (in sample) VaR estimates,

the DQ statistic falls into the rejection region, then we must conclude that the data

provide evidence against the model that produced those estimates. If the DQ statistic falls

into the rejection region for an out of sample test, then this is fhrther evidence against the

model and its stability over time.



 7. DIFFERENTIAL EVOLUTIONARY GENETIC ALGORITHM

    The main problem of nonlinear regression quantiles estimation is that the objective

 function is not differentiable. Consequently, traditional algorithms based on
 differentiation will not work. We use, instead, a genetic algorithm that in theory is able to

 locate the global optimum, even for very complicated problems.

     Genetic algorithms have been the subject of increasing interest in the past few years,

 since they provide a robust search procedure to solve very difficult problems. For large



                                                                                           26
problems, random search or stochastic algorithms may be the only feasible alternative.

Randomization gives a search algorithm the ability to break the curse of dimensionality

that makes nonrandom and exhaustive search methods increasingly inefficient for

functions with many parameters.

   The idea behind this optimization routine is based on the process of natural selection

and on some principles of genetics. The genetic algorithm starts with a population of

initial trials for the parameter vector to be optimized, and interprets the value of the

objective function at each of these trials as a measure of these points' "fitness" as an

optimum. To develop a new population from this initial trial values there are three steps

to follow:

        1.     Reproduction based on fitness - The members of the population are chosen

    for reproduction on the basis of their fitness, defined according to some specific

    criterion. At this stage some sort of "survival of the fittest" principle applies, so that

    the fittest members of the old population are given a higher probability of survival

    and/or reproduction.

        2.     Crossover - Crossover (or recombination) resembles the actual process of

    mating and establishes the rules of the reproduction. In this step, new parameter

    combinations are built from the components of existing vectors. Many different

    recombination methods exist and each combines parameter values from two or more

    parents in its own peculiar way.

        3.      Mutation - Some genes are given the chance of randomly changing, so that

    there is a possibility of improving the characteristics of the population (in the case the




                                                                                           27
    mutation increases the fitness of the members of the population). Mutation is crucial

    for maintaining diversity in a population, even if excessive mutation may be harmful.

These thee features make genetic algorithms radically different from the traditional

search procedures. They allow the algorithm to develop generations that explore the

region of interest and avoid getting stuck at a particular local optimum. This
characteristic is useful for difficult optimization problems and in particular for those with

multiple local minima and maxima. While traditional minimization routines tend to find

only a local optimum, genetic algorithms are generally able to locate the global

optimum.5

    The type of genetic algorithm we use, Differential Evolutionary Genetic Algorithm

(DEGA) is based on Price and Storn (1997).6 This kind of algorithm has been proved to

be much faster than traditional genetic algorithm, when applied to numerical optimization

problems, and more robust at finding global optima. There are thee factors that

determine the evolutionary process of DEGA: the population size (NP), the crossover

parameter (CR) and the mutation parameter (F). Suppose we want to maximize a real-

valued function, with D parameters. DEGA starts by randomly generating NP, D-

dimensional, real-valued vectors within the user-given intervals and evaluating the

objective function at each of these initial trials. These values are stored in an (NP, D+1)

array, called the target vector population. There are three steps to follow to develop a

new generation.

     1) An (NP, D+ 1) array of trial vectors is created.



   For a broad overview of the argument, see Goldberg (1989). Among the results stated in this book, there
 is the fundamental theorem of genetic algorithms, which provides a scientific justification of the ability of
 this class of algorithms to find global optima.
 6
   The Matlab code was provided by Rick Baker, from the MathWorks, Inc.


                                                                                                          28
   2) The fitness of each trial vector is compared with the fitness of the corresponding

       target vector.

   3) The fittest vectors survive and are stored in a new (NP, D+1) array that becomes

       the target vector population for the next generation.

   The peculiarity of DEGA is related to the construction of the trial vector population.

Each trial vector has two parents. The first parent is the target vector with which it has to

compete in point 2) above. The second parent is constructed from three other randomly

chosen target vectors. If we denote the second parent as P2 and the three randomly chosen

target vectors as T1, T2, T3, then DEGA imposes P2=T,+F(T2-T3), where F is the given

mutation parameter. Note that this feature allows the trial vector to assume values outside

the initial parameter range. Finally, the crossover parameter (CR) determines which

genes of the trial vector are taken from which parent, by a series of D binomial
experiments. D uniform random numbers are generated from the interval [0,1). If the dth

random number (d= 1, ..., D) is greater than CR, the trial vector gets the dth parameter

from the target vector parent, otherwise the parameter is inherited from P2. For more

details and sample codes, see Price and Storn (1997).



8. MONTE CARLO SIMULATJON

    To check the ability of the nonlinear regression quantile function and genetic
algorithm to produce consistent parameter estimates, we ran a few Monte Carlo

simulations. First we generated 1000 samples of 3,000 observations using a GARCH(1,1)

process with parameters (0.3, 0.05, 0.90). Then we estimated the GARCH parameters

indirectly, by minimizing the nonlinear regression quantile objective function using the



                                                                                          29
Indirect GARCH CAViaR process as quantile specification. The probability levels of the

quantile were set at 0.1%, 1%, 5% and 25%.

   To implement DEGA, we generated 5000 random vectors, uniformly distributed in

the interval [0, 2] for the 1%, 5% and 25% quantiles and in the interval [0,5] for the 0.1%

quantile. We computed the value of the regression quantile criterion for each of these

vectors. The best 50 vectors, that is the 50 vectors that yielded the lowest criterion value,

were used as the starting population in DEGA. This selection process of the starting

population reduces the number of necessary generations to achieve convergence and

should make the final results more reliable. We set the population size (NP) equal to 50,

the crossover parameter (CR) at 0.5, the mutation parameter (F) at 0.8 and the number of

generations equal to 200. It is possible to increase the accuracy of the minimizing

parameters by choosing a higher number of generations. We believe that the number we

chose represents an acceptable trade off between precision of the estimate and computing

time. Note that DEGA is able to locate a global optimum even if it lies outside the initial

parameter range.7 This is due to the way the trial vector population is generated, as

explained in the previous section.

    The results are shown in table 1. For each quantile, we report the value of the

parameters of the true DGP, and the mean, the median and the variance-covariance

matrix of the 1000 vectors of estimated parameters. For the mean, we computed also the

 t-statistic, using the empirical variance-covariance matrix. Note how in all the cases the

 median is a much better measure of location than the mean.

    As we could expect, the worst results were those for the 0.1% quantile. In a sample of

 3,000 observations, the 0.1% quantile is expected to be exceeded only three times and it



                                                                                           30
may be hard, if not impossible, to get precise estimates. The mean of the estimated

parameters is significantly different from their true values in most of the cases. The high

variances confirm that estimation at such low confidence levels is very noisy. Perhaps,

introducing extreme value theory in the CAViaR framework might be a better strategy to

accomplish such a task.

   The estimates at the other confidence levels are more reliable, as shown by the big

drop in the variance of the first parameter. However, for some samples, the resulting

estimated processes showed very little persistence (the coefficient of the autoregressive

term of the GARCH process was close to zero), with the estimated quantile tending to the

unconditional quantile. This result would arise naturally if the extremes are not clustered

in the sample. With low probability events, there is the possibility that the timing would

not reflect the predictability of extremes even though the DGP incorporated this feature.

Under these circumstances, the lack of precision of the estimate might have no practical

consequences, since the relevant properties of the quantile (unbiasedness and
independence of lagged hits) are preserved. Moreover, this problem is very likely to be

related to the sample size and should disappear as the number of observations in the

 sample becomes larger.

    In table 2 we compute the mean, the median and the variance-covariance matrix, after

 excluding the estimates with GAMMA2 (the coefficient of the autoregressive lag) less

 than 0.5. The sample size after the trimming was 906 for the 0.1% quantile estimate, 986

 for the 1%, 996 for the 5% and 953 for the 25%. The accuracy of the estimates improves

 dramatically, as shown by the reduction in their variances.




  The initial parameter range was [0,2], but some of the optimal parameters were greater than 3.

                                                                                                   31
9. EMPIRICAL RESULTS

   To implement our methodology on real data, the researcher needs to construct the

historical series of portfolio returns and to choose a specification of the functional form

of the quantile. We took a sample of 3392 daily prices from Datastream for General

Motors, IBM and S&P 500, and we computed the daily returns as the difference of the

log of the prices. The samples range from April 7 1986 to April 7 1999. Note that our

samples include the crash of the 1987. We used the first 2892 observations to estimate the

model and the last 500 for out of sample testing. Figure 1 reports the plot of the returns of

the three assets for the full sample.

   We estimated 0.1%, 1%, 5% and 25% one day VaR, using the six CAViaR
specifications described above. The estimated 5% VaR for the three assets are plotted in

Figures 2, 3 and 4.

    The results of the estimates are reported in tables 3 to 8. In each table, we report the

value of the estimated parameters, the corresponding standard errors and (one-sided) p-

values, the value of the regression quantile objective function at the optimum, the

percentage of the times the VaR is exceeded, and the p-value of the Dynamic Quantile

test, both in and out-of-sample. The standard errors were computed using the kernel

described in theorem 3, with a bandwidth of 0.1 for all the assets and for all the

confidence levels. A data dependent choice of the bandwidth would be preferable, since it

would probably increase the precision of the estimate. We didn't report any standard error

 and any DQ test for the 0.1% VaR because the sample we have is not large enough to

 provide reliable estimates.




                                                                                          32
   To identif' the causes of a rejection in the DQ test, we used four different sets of

regressors in the Dynamic Quantile artificial regression (8): 1) the constant and the first

five lagged hits, 2) the VaR estimate, 3) the constant, the first lagged hit and the VaR

estimate, 4) the constant, the first five lagged hits and the VaR estimate. Note that the last

test encompasses all the previous ones.

    Finally, the genetic algorithm was implemented by generating 5,000 random vectors

within a given interval8 and then selecting the fittest ones as starting population in

DEGA. The size of the population was set at 20 times the number of parameters to be

estimated and the VaR was initialized at the (in-sample) empirical VaR.

    In figure 5 we report a plot of the CAViaR news impact curve for the 5% VaR

estimate of S&P 500. Notice how the Adaptive and the Asymmetric Slope news impact

curves differ from the others. In particular, the sharp difference between the impact of

positive and negative returns in the Asymmetric Slope model suggests that there are

relevant asymmetries in the behavior of the 5% quantile of this asset. As we discuss

below, other tests confirm this finding also at the 1% quantile for GM and S&P 500.

    Our results show that all the models but the Adaptive and the Proportional Symmetric

Adaptive perform well according to the number of hits and to the DQ test for all the three

assets and at all confidence levels, both in and out-of-sample. The Proportional

 Symmetric Adaptive model is consistently rejected at the 1% and 5% confidence levels.

 The graphs reported in figures 2 and 3 give a visual confirmation of the clearly different

 pattern generated by this model. This seems to us enough evidence to discard the model.

     The performance of the Adaptive model is more controversial. This model performs

 very well if we just look at the number of hits it produces, both in and out-of-sample.



                                                                                            33
However, the DQ test reveals that these hits tend to be autocorrelated. In other words, the

unconditional performance of the Adaptive model is good, but the conditional one might

be seriously biased. By eyeballing the graphs of figures 2, 3 and 4, we can infer that the

main drawback of the Adaptive model is that it is not flexible enough to adapt to sudden

changes in volatility, like the one that occurred in the fall 1987. This defect must be

attributed to the simplicity of the model, which depends on only one parameter.

      The other four models under study do extremely well for all assets and at all

confidence levels. The only exception is the 5% VaR for S&P 500, whose out-of-sample

performance is rejected in all the cases. The DQ test reveals that there is some
unexplained autocorrelation among the hits. It may be the case that we need to look for

other CAViaR specifications that can provide a better fit for the 5% quantile of this asset,

or it may simply be a feature of this set of data.

       To fully appreciate the performance of the CAViaR models, recall that the samples

over which the models are estimated include the crash of October 1987 and that the out-

of-sample period includes the days of high volatility of the summer 1998. Moreover, the

length of the out of sample period is 500 trading days. This roughly corresponds to two

calendar years! It is likely that financial institutions will re-estimate their models on a

more frequent basis (monthly, weekly, or even daily) and that this procedure of re-

estimation will improve the performance of CAViaR models.

       The issue of model selection is a critical one. Ideally, a good model should have

 stable parameters over time, so that it doesn't need to be re-estimated very often. A model

 with this feature would very likely have a good performance out-of-sample, which is

 what practitioners are interested in.


     The intervals were [0,2] for the 1%, 5% and 25% VaR confidence levels, and [0,4] for the 0.1%.
 8



                                                                                                      34
   One possible strategy to choose among the models is to discard all the models

rejected by the DQ test, either in-sample or out-of-sample. Among the surviving models,

we choose the one with the lowest out-of-sample RQ criterion. We can think of the model

with the minimum RQ criterion as the specification closest to the true quantile process.

Clearly, using in-sample results would bias the choice towards the largest model.

Looking at the out-of-sample values avoids this problem.

   An alternative strategy could be to compute an Akaike Information Criterion for

CAViaR models and choose the model with the lowest AIC. Clearly, the topic of model

selection deserves a more rigorous and systematic treatment, which we leave for future

research.

    According to the RQ criterion, the Asymmetric Slope model is the best CAViaR

specification for GM and S&P 500. Note that the coefficient of the positive slope term is

never significantly different from zero for S&P 500, suggesting that there might be no

impact news from positive returns.

    The best model for IBM, instead, was GARCH at 1% and 25% confidence levels, and

the Asymmetric Absolute Value at 5%. This finding can be taken as a further indication

that different confidence levels might require different models.

    Finally, based on the results of our Monte Carlo simulation, we believe that the

 estimates for the 0.1% quantile must be taken with extreme caution. Even if the

 performance in terms of number of hits is acceptable (both in and out-of-sample), it is

 very challenging to get a reliable estimate of events that should happen only once every 4

 years. Such an estimate will be, to say the least, very noisy. We believe that a better




                                                                                        35
strategy to estimate these extreme quantiles might be to incorporate the extreme value

theory into the CAViaR modeling approach.

   To have a preliminary comparison of the performance of CAViaR models relative to

the existing methodologies, we computed the four quantiles of the three assets by

estimating a plain GARCH (1,1) using the in-sample daily returns. The quantile was then

computed by finding the empirical quantile of the standardized residuals and multiplying

it by the square root of the estimated variance. The results are reported in table 9. The

overall performance of this approach seems good. The difficulty of getting a good out-of-

sample performance of the 5% VaR for S&P 500 is confirmed. The out-of-sample

estimates of the 1% VaR for S&P 500 are also rejected at a confidence level of 5%. Note

how the overall performance of this procedure is similar to the performance of the

Indirect GARCH CAViaR. It is important however to stress that the assumptions of the

CAViaR are much weaker, since there is no need to assume that the standardized

residuals are i.i.d. like in the GARCH framework.



10. CONCLUSION

    We propose a new approach to Value at Risk estimation. All the existing models try

to estimate the distribution of the returns and then recover its quantile in an indirect way.

On the contrary we try to model directly the quantile. To do this we introduce a new class

of models, the Conditional Autoregressive Value at Risk or CAViaR models, which

specify the evolution of the quantile over time using a special type of autoregressive

process. The parameters of the CAViaR model are estimated by minimizing the

regression quantiles objective function. Since this function is not differentiable, we use a




                                                                                          36
genetic algorithm for the numerical optimization. A Monte Carlo experiment shows how

both regression quantiles and genetic algorithm are able to produce unbiased estimates.

We also introduce a new test based on an artificial regression to evaluate the performance

of the CAViaR models. Applications to real data provide empirical support to our

methodology and illustrate the ability of CAViaR models to adapt to new risk

environments.




                                                                                        37
   REFERENCES

Andrews, D.W.K. (1988), Laws of large numbers for dependent non-identically

distributed random variables, Econometric Theory, 4: 458-467.

Beder, T. S. (1995), VaR: seductive but dangerous, Financial Analyst Journal, Sep-Oct,

12-24.

Boudoukh, J., M. Richardson and R.F. Whitelaw (1998), The best of both worlds,

Risk, 11:64-67.

Cowles, A. and H. Jones (1937), 'Some a posteriori probabilities in stock market action',

Econometrica, 5: 280-294.

Christoffersen, P. F. (1998), Evaluating interval forecasts, International Economic

Review, 39: 841-862.

Danielsson, J. and C.G. de Vries (1998), Beyond the sample: extreme quantile and

probability estimation, London School of Economics, Discussion Paper 298.

Engle, R. F. and V. Ng (1993), Measuring and Testing the Impact of News On

Volatility, Journal of Finance, 48: 1749-1778.

Foresi, S. and F. Peracchi (1995), The conditional distribution of excess returns: and

empirical Analysis, Journal of the American Statistical Association, 90: 451-466.

Goldberg, D.E. (1989), Genetic algorithms in search, optimization, and machine

learning, Reading: Addison-Wesley Publishing Corporation, Inc.

Gourieroux, C. and J. Jasiak (1998), Truncated maximum likelihood, goodness of fit

tests and tail analysis, Unpublished manuscript.

Granger, C.W.J., H. White and M. Kamstra (1989), Interval forecasting. An analysis

based upon ARCH-quantile estimators, Journal of Econometrics, 40: 87-96.



                                                                                      38
Koenker, R. and G. Bassett (1978), Regression quantiles, Econometrica, 46: 33-50.

Ljung, G. and G. Box (1979), 'On a measure of lack of fit in time series models,

Biometrica, 66: 265-270.

Mood, A. (1940), 'The distribution theory of runs', Annals of Mathematical Statistics, 11:

367-392.

Newey, W. and J. Powell (1990), Efficient estimation of linear and type I censored

regression models under conditional quantile restrictions, Econometric Theory, 6: 295-

317.

Powell, J. (1984), Least absolute deviations estimation for the censored regression

model, Journal of Econometrics, 25: 303-325.

Powell, J. (1986), Censored regression quantiles, Journal of Econometrics, 32: 143-155.

Price, K. and R. Storn (1997), Differential Evolution, Dr. Dobb's Journal, April, 18-24.

Weiss, A. (1991), Estimating nonlinear dynamic models using least absolute error

estimation, Econometric Theory, 7: 46-68.

White, H. (1991), Nonparametric estimation of conditional quantiles using neural

networks, Unpublished paper.

White, H. (1994), Estimation, Inference and Specflcation Analysis, Cambridge

Universty Press.

White, H. and I. Domowitz (1984), Nonlinear regression with dependent observations,

Econometrica, 52: 143-161.




                                                                                        39
</ref_section>
Figure 1 - Returns for GM, IBM and S&P 500 form April 1986 to April 1999

20                                                  20


 10                                                 10



  0                                                   0


-10                                                 -10


-20                                                 -20


-30                                                 -30


                                                                         I—v IBM       I




                          20


                          10


                            0

                          -10
                                ,
                          -20


                          -30
                                                          thd'dób'
                                            j—vsP I



Figure 2 - 5% CAViaR plots for General Motors


  13                            IC

  &                             S

  S                             S

  4                             4

  2                             2.




       •5b
                                     --   -;-
             I—M                           I—mM                                    — IBM5SA




                                                                 10

                                                                     8

                                                                     8



                                                                     2

                                                                           5bó -   -       -   .

             I — mMs.a1                    [,BM5A                                  I—mM5'1




                                                                                                   40
Figure 3 - 5% CAViaR plots for IBM


                            S


                            S


                            4


 2-                         2

      -   I——
                 ob" do'                  dcb th•
                                     I— OMPSA
                                                        ""a.
                                                                 I — GUSSAVI




                                                    S


                                                    8




                                                               • • ,. •, ';2•'
          I — GU5MVI                 IGMSASI                      I——



Figure 4 - 5% CAViaR plots for S&P 500




                                                                                 41
Figure 5 - 5% CAViaR news impact curves for S&P 500


 4                           4

 3                           3


 2                           2



 I                           I



           a                                              I — SAy   I




                             S

 4                           4                        4


 3.                          3.                       3


 2                                                    2


 I                            I,




          1W1                          a
                                   okkbck3bo3k




                                                                        42
Table I - Summary statistics of the Monte Carlo experiment

       0.1%          GAMMAI GAMMA2 GAMMA3
     True mean         4.15     0.90      0.69
       Mean            7.16     0.80      0.67
      i-statIstic      8.54     -13.60    -0.95
        Median         2.90      0.89     0.53
                      125.16     -2.45    2.60
   Var-Coy matrix      -2.45     0.05     -0.07
                       2.60     -0.07     0.32


          1%         GAMMA 1   GAMMA2 GAMMA3
     True mean         1.62      0.90     0.27
       Mean            2.28      0.87     0.30
      I-stat Istic     7.59     -7.91     6.01
       Median          1.57     0.90      0.27
                       7.79     -0.28     0.19
   Var-Coy matrix      -0.28     0.01     -0.01
                       0.19     -0.01     0.02


          5%         GAMMA 1   GAMMA2 GAMMA3
      True mean        0.81      0.90     0.14
        Mean           1.02      0.88     0.14
      I-statistic      7.59      -7.59    4.74
       Median          0.81      0.90     0. I 4
                       0.79      -0.06    0.02
    Var-Coy matrix     -0.06     0.00     0.00
                       0.02      0.00     0.00


         25%         GAMMAI GAMMA2 GAMMA3
      True mean        0.13       0.90    0.03
        Mean           0.26       0.84    0.03
       I-statistic     9.80     -10.12    1.58
        Median         0.13       0.90    0.02
                       0.17      -0.07    0.00
    Var-Coy matrix     -0.07      0.03    0.00
                       0.00       0.00    0.00




                                                             43
Table 2 - Monte Carlo summary statistics after excluding the samples with GAMMA2<O.5

        0.1%             GAMMA! GAMMA2 GAMMA3
      True mean           4.15      0.90     0.69
    Trimmed Mean          4.04      0.87     0.60
   Trimmed Median         2.49      0.90     0.50
                          18.36     -0.40    0.81
Trimmed Var-Coy matrix    -0.40     0.01     -0.03
                          0.81      -0.03    0.23


         1%              GAMMAI GAMMA2      GAMMA3
      True mean            1.62     0.90      0.27
    Trimmed Mean           2.02     0.88     0.29
   Trimmed Median          1.55     0.90     0.27
                           272      -0.11    0.12
Trimmed Var-Coy matrix    -0.11     0.00     -0.01
                           012      -0.0!    0.02


         5%              GAMMA! GAMMA2 GAMMA3
      True mean            0.8!     0.90     0.135
    Trimmed Mean           0.99     0.89      0.14
   Trimmed Median         0.81      0.90      0.14
                           0.49     -0.04     0.02
Trimmed Var-Coy matrix    -0.04     0.00      0.00
                           0.02     0.00      0.00


         25%             GAMMA I   GAMMA2 GAMMA3
      True mean            0.13     0.90     0.027
    Trimmed Mean           0.18     0.88      0.03
   Trimmed Median          0.13     0.90      0.02
                           0.03     -0.01     0.00
Trimmed Var-Coy matrix     -0.0!     0.01     0.00
                           0.00      0.00     0.00




                                                                                 44
Table 3 - Parameter estimates and relevant statistics for the Adaptive model

    ADAPTIVE '" 0.1%          GM           IBM         S&P 500            ADAPTIVE           1%    GM       IBM      S&1'SOC
Gamma 1                       0.0000       0.0000       2.7409       Gamma 1                        0.26     0.00      2.11
Standard Errors                       -            -                 Standard Errors                0.11     0.08      0.22
P-values                              -            -            -    P-values                       0.01      0.50     0.00
                               3940         46,84        33.99       RQ in sample                  179.66   191.79    114.9
RQ in sample
RQ out of sample                4.21         5.33         7,01       RQ out of sample              29.56    42.11     29.10
Hits in sample (%)            0.0692       0.1037       0.0692       Hits in sample (%)             0.90      1.00     1.00
Hits out of sample (%)        0.0000       0.0000       0.4000       Hitsoutofsantple(%)             1.80     2.00     1.20

DO in sample (p-values)                                              DQ in sample (p-values)
I) [c, hit(-1 to -5)]                 -            .                 I) [c, hit(-1 to -5)]           0.00     0.00     0.82

2) [VaR]
                                      -            .                 2) [VaR]                        0.53     0.98     0.07

3) [c, hit(-l), VaR]
                                                                .    3) [c, hit(-1), VaR)            0.68     0.02     0.00
4) [c, hit(-I to -5), VaR]            -            -            ..   4) [c, hit(-l to .5), VaR]      0.00     0.00     0.01

DQ Out of sample (p-values)                                          DQ Out of sample (p-values)
1) Ic, hit(-l to -5)]                 -            -            -    1) [C. hit(-1 to -5)]           0.00     0.00     0.01
2)[VaR]                               -            -                 2) [VaR]                        0.06     0.02     0.79
3) [c, hit(.l), VaR]                   -           -                 3) [c, hit(-l), VaR]            0.22     0.30     0.37
4) [c, hit(-1 to -5), VaR]             -           -             -   4) [c, hit(-l to -5), VaR]      0.00     0.00     0.01


   ADAPTIVE***5%               GM           IBM        S&P500             ADAPTIVE *** 25%         GM       IBM      S&P 50(
Gamma I                        &22          0.44         0.23        Gamma I                        0.021    0.012     0.017
Standard Errors                0.03         0.05         0.02        Standard Errors                0.004    0.003     0.003
P-values                       0.00         0.00         0.00        P-values                       0.000    0.000     0.000
RQ in sample                  553.26       527.45       312.65       RQ in sample                    1507     1368       752
                              100.84       120.20        72.41       RQoutofsample                 291.62   312.44      184
RQoutofsample
Hits in sample (%)             4.91         5.01         5.08        Hits in sample (%)             24.86    25.31     25.07
Hits out of sample (%)         6.40         5.20         5.00        Hits Out of sample (%)         27.00    24.80     27.40

DO in sample (p-values)                                              DO in sample (p-values)
                               0.31         0.47         0.46        1) [c, hit(-l to -5)1           0.94     0.25      0.59
I) [c, hit(-1 to -5)]
                               0.52         0.34         0.48        2) [VaR]                        0.73     0.80      0.68
2) [VaR]
                               0.12         0.01         0.10        3) (C. hit(-l), VaR]            0.58     0.64      0.30
3) Ic,hit(.1), VaR]
                               0.06         0.01         0.07        4) [c, hit(-l to -5), VaR]      0.81     0.23      0.32
4) [C, hit(-1 to -5), VaR)
DO out of sample (p-values)                                          DO out of sample (p-values)
                               0.40         0.98         0.01        1) [c, hit(-l to -5)]           0.57     0.67      0.45
1) [c, hit(-1 10-5)]
                               0.26         0.90         0.80        2) [VaR]                        0.43     0.97      0.29
2) [VaR]
                               0.40         0.21         0.55        3) Ic. hit(-l), VaR]            0.23     0.28      0.39
3) [C, hit(-l), VaR]
                               0.45         0.56         0.01        4) [c, hit(-1 to -5), VaR]      0.64     0.30      0.41
4) [c, hit(-l 10-5), VaR]




                                                                                                                        45
Table 4 - Parameter estimates and relevant statistics for the Proportional Symmetric
          Adaptive model

PROP SYM ADAPT *** 0.1%         GM        IBM        S&P 500      PROP SYM ADAPT           1%         GM        IBM       S&P50(
Gamma I                        13.3772    0.0000     15.6603     Gamma!                               0.0594    0.0023    0.0116
Standard Errors                      -           -          -    Standard Errors                      0.0365    0.0275    0.00 74
P-values                             -           -          -    P-values                             0.0519    0.4674
Gamma 2                         0.0049    0.0001      0.0017     Gamma 2                              0.0004    0.0000    0.0002
Standard Errors                      -           -          -    Standard Errors                      0.0002    0.0003    0.0001
P-values                             -           -          -    P-values                             0.0326    0.5000
                                 24.77     4652        21.43     RQ in sample                         180.21    191.67     123.27
RQ in sample
RQ out of sample                  6.63      4.78        4.08     RQ out of sample                                40.86     34.43
                                  0.07      0.10        0.10     Hits in sample (%)                     1.00      0.93       1.28
Hits in sample (%)
Hits out of sample (%)            0.40      0.20        020      Hits out of sample (%)                           1.80       5.20

DQ in sample (p-values)                                          DQ in sample (p-values)
                                     —           —          —
                                                                 1) [c, hit(-l to -5)]                                       0.00
I) Ic, hit(—1 to —5)]
2)IVaRJ
                                     -           -          .    2) IVaR]                               0.98      0.73       0.12
                                     -           -          -    3) Ic. hil(-l), VaR]                                        0.03
3) [c, hit(-l), VaR]
                                     -           -          -    4) Ic, hit(-1 to -5), VaR]             0.03      0.00       0.00
4) Ic, hit(-1 to -5), VaR]
DQ out of sample (p-values)                                      DQ Out of sample (p-values)
                                     —           —          —
                                                                 I) [C, hit(-l to -5)]                            0.01       0.00
1) Ic, hit(-l to —5)]
2)[VaR]
                                     -           .          -    2) IVaR]                               0.00      0.07       0.00
                                     -           -          -    3) Ic, hit(-1), VaR]                             0.24       0.00
3) [c, hit(-1), VaR]
                                     -           -          -    4) [c, hit(-l 10-5), VaR]                        0.01       0.00
4) Ic, hit(-1 to -5), VaR]


  PROPSYM ADAPT *** 5%           GM        IBM       S&P 500      PROP SYM ADAPT          ' 25%        GM        IBM    S&P 50(
                                0.0261    0.0007      0.2868     Gamma 1                              0.0148    0.0001   0.001!
Gamma 1
Standard Errors                 0.0086    0.0047      0.0504     Standard Errors                      0.0043    0.0006 0.0004
P-values                        0.0013    0.4413      0.0000     P-values                             0.0003    0.4301
Gamma 2                         0.0012    0.0000      0.0108     Gamma 2                              0.01 10   0.0000 0.0009
                                0.0004    0.0002       0.0016    Standard Errors                  .   0.0030    0.0003
Standard Errors
P-values                        0.000 7   0.5000       0.0000    P-values                             0.0001    0.5000
                                559.88    542.11       322.33    RQ in sample                          1507.1    1369.8   753.5
 RQ in sample
                                102.62    118.52        77.25    RQ out of sample                      292.63              189.2
 RQ out of sample
                                  4.94       4.60         6.98   Hits in sample (%)                     25.52     24.24
 Hits in sample (%)
                                  6.80       6.60         5.60   Hits out of sample (%)                 25.20     25,40   34.20
 Hits out of sample (%)
 DQ in sample (p-values)                                         DQ in sample (p-values)
                                   0.01      0.00        0.00     I) [c, hit(-l to -5)]                            0.43      0.64
 I) Ic, hit(-1 10-5)]
                                   0.85      0.35        0.21    2) IVaRI                                0.95      0.37      0.93
 2) [VaR]
                                   0.41      0.21        0.00    3) Ic. hit(-l), VaR]                    0.03      0.35      0.85
 3) [c, hit(-1), VaR]
                                   0.02      0.00        0.00    4) [c, hit(-l to -5), VaR]              0.06      0.33      0.68
 4) Ic, hit(-l to -5), VaR]
 DQ out of sample (p-values)                                     DQ out of sample (p-values)
                                   0.03      0.49        0.01    I) Ic, hil(-l 10-5)]                    0.91      0.63      0.00
 I) Ic, hit(-1 to -5)]
                                   0.10      0.09        0.66    2) [VaR]                                0.62                0.00
 2) [VaR]
                                   0.04      0.26        0.01    3) [c, hit(-1), VaR]                    0.30                0.00
 3) Ic, hit(-l), VaR]
                                   0.05      0.59        0.00    4) [c, hit(-t to -5), VaR]              0.62                0.00
 4) [c, hit(-l 10-5), VaR]




                                                                                                                              46
Table 5 - Parameter estimates and relevant statistics for the Symmetric Absolute Value
          model

 SYMABSVALUE***O.1%           GM           IBM        S&P500       SYM ABS VALUE *** 1%         GM         IBM       S&P50(
Gamma 1                       6.7241       1.2797      13240     Gamma 1                       0.4784     0.1260     0.2040
Standard Errors                     -            -          -    Standard Errors               0.2/99     0.0930     0.1490
P-values                            -            -          -    P-values                      0.0/48     0.0876     0.0856
Gamma 2                       0.0000       0.7139      0.6360    Gamma 2                       0.8168     0.9477     0.8733
Standard Errors                     -            -          -    Standard Errors               0.0690     0.0332     0.0869
P-values                            -            -          -    P-values                      0.0000     0.0000     0.0000
Gamma 3                       2.4084       30075       2.5713    Camma3                        03503      0.1130     03817
Standard Errors                     -            -               Standard Errors               0.1216     0.0665     0.2711
P-values                            -             -         -    P-values                      0.0020     0.0145     0.0796
                               2863         3571        1817     RQ in sample                  172.12     182.46     109.66
RQ in sample
                                4.64         7.95        3.78    RQoutofsample                 28.99      40,81       26.23
RQ Out of sample
                                0.10         0.07        0.10    Hits in sample (%)             1.00       0.97       0.97
l-Iitsinsample(%)
                                0.00         0.00        0.20    Hits out of sample (%)         1.20       1.60       1.80
Hits out of sample (%)
DQ in sample (p-values)                                          DQ in sample (p-values)
1) Ic, hit(—l to —5)1
                                    —             .         —
                                                                 I) Ic, liit(-1 10-5)]          0.60       0.25
                                       -          -         -    2) [VaR]                       0.97       0.88
2)[VaR]
                                       -          -         -    3) Ic, hit(-l), VaR]           0.96       0.58
3) Ic, hit(-1), VaR]
                                       -          .         -    4) Ic, hit(-l to -5), VaRJ     0.71       0.33       0.88
4) Ic, hit(-1 to -5), VaR]
DQ out of sample (p-values)                                      DQ out of sample (p-values)
                                       -          -         -    I) [C, hit(-1 to -5)]          1.00       0.05
I) Ic, hit(-l to -5)]
                                       -          -         -    2) IVaR]                       0.88       0.22       0.18
2) [VaR]
                                       -          -         -    3) Ic, hit(-l), VaR]           0.48       0.42
3) Ic, hit(-1), VaR]
4) [c, hit(-1 to -5), VaR]
                                       -          .              4) Ic, hit(-1 10-5), VaR]      0.92       0.05       0.03

LM test for VaR(t-2)                   -          -         -    LM test for VaR(t-2)           0.92       0.94       0.97



  SYMABSVALUE***5%             GM           IBM       S&P500      SYMABSVALUE***25%              GM         IBM      S&P50C
                              0.1865       0.1192      0.0512    Gamma I            .           0.0440      0.0235    0.0111
Gamma 1
Standard Errors               0.0897       0.0462      0.0217    Standard Errors                0.0250      0.0/38    0.0056
                              0.0/88       0.0050      0.0092    P-values                       0.0393      0.0445    0.0234
P-values
Gamma 2                       0.8936       0.9053      0.9369    Gamma 2                        0.9272      0.9587    0.9469
Standard Errors               0.044/       0.0294      0.0250    Standard Errors                0.0350      0.0211    0.0247
P-values                      0.0000       0.0000      0.0000    P-values                        0.0000     0.0000    0.0000
Gamma 3                       0.1135       0.1481      0.1339    Gamma 3                        0.0318      0.0197    0.0338
Standard Errors               0.0428       0.0437      0.0549    Standard Errors                 0.0139     0.0093    0.0163
P-values                      0.0040       0.0004      0.0074    P-values                        0.0112     0.0/66    0.0193
                              551.02       522.58      306.51    RQ in sample                   1500.61    1363.02    746.90
RQ in sample
                               99.23       120.47       73.85    RQ out of sample                289.58     311.80
RQ out of sample
                                4.98         4.98        4.98    Hits in sample (%)               25.03      25.03     24.97
Hits in sample (%)
Hits out of sample (%)           4.60         6.00        5.60   Hits Out of sample (%)           26.00      23.20

DQ in sample (p-values)                                          DQ in sample (p-values)
                                 0.45         0.10        0.45   I) Ic, hit(-1 to -5)]             0.65       0.74
I) IC, hit(-l to -5)]
                                 1.00         1.00        0.95   2) IVaR]                          0.92       0.95
2)IVaRI
                                 0.85         0.65        0.99   3) [C, hit(-l), VaR]              0.98       0.88
3) Ic, hit(-1), VaR]
                                 0.56         0.15        0.55   4) [C, hit(-1 to -5), VaR]        0.75       0.83      0.64
4) [c, hit(-1 to -5), VaR]
DQ out of sample (p-values)                                      DQ out of sample (p-values)
                                 0.89         0.23        0.00   I) [c, hit(-1 to -5)]             0.85       0.59
 I) Ic, hit(-l to -5)]
                                 0.55         0.55        0.88   2) [VaR]                          0.72       0.41      0.33
 2) [VaR]
                                 0.95         0.05        0.29   3) Ic, hit(-l), VaR]              0.66       0.82
 3) [c, hit(-l), VaRI
                                 0.94         0.09        0.00   4) [c, hit(-l to -5), VaR]        0.91       0.70       0.39
 4) Ic, hit(.l to -5), VaR]
 LM test for VaR(t-2)            0.90         0.93        0.95   LM test for VaR(t-2)              0.80       0.89       0.48




                                                                                                                        47
Table 6 - Parameter estimates and relevant statistics for the Asymmetric Absolute Value
          model

ASYMABSVALUE***0.I%            GM        IBM        S&PS00      ASVMABSVALUE***1%              GM        IBM       S&P50(
Gamma 1                        0.9233    1.0330      0.5634    Gamma I                        0.4304     0.2746     0.1776
Standard Errors                      -         -          -    Standard Errors                0.1340     0.1421     0.1033
P-values                             .          -         -    P-values                       0.0007     0.0266    0.0428
Gamma 2                        0.7078    0.6884      0.7888    Gamma 2                        0.8271     0.8942    0.8631
Standard Errors                      -          -         -    Standard Errors                0.0428     0.0475    0.0537
P-values                             -          -         -    P-values                       0.0000     0.0000    0.0000
Gamma 3                        1.4313    2.4417      1.9190    Gamma 3                        0.3597     0.2191    03766
Standard Errors                      -          -         -    Standard Errors                0.0826     0.0931    0.1402
P-values                             -          -         -    P-values                       0.0000     0.0093    0.0036
Gamma 4                        0.8916    0.8468      0.6005    Gamma 4                        0.1877     0.0855    0.6402
Standard Errors                      -          -              Standard Errors                0.1738     0.3 125    0.1530
P-values                             -          -         -    P-values                       0.1401     0.3922     0.0000
                                25.26     31.40       17.91    RQ in sample                   170.01     181.63     105.63
RQ in sample
                                 5.19      6.33        3.86    RQ out of sample                28.83      40.20      23.75
RQoutofsample
                                 0.10      0.10        0.14    Flits in sample (%)               1.04      0.86       1.07
Hitsinsample(%)
Hits Out of sample (%)           0.20      0.00        0.00    Hits Out of sample (%)            1.20      1.60       1.80

DQ in sample (p-values)                                        DQ in sample (p-values)
l)[c,hit(-l to-5)1                   -          -              1) Ic, hit(-l to .5)]            0.62       0.23       0.64
                                     -          -         -    2) [VaR]                         0.86       0.49       0.65
2)(VaR]
                                     -          -         -    3) Ic, hit(-l), VaR]             0.95       0.38       0.89
3) [c, hit(-1), VaR]
                                     -          -              4) [c, hit(-1 to -5), VaR]       0.73       0.30       0.74
4) Ic, hit(-1 to -5), VaR]
DQ out of sample (p-values)                                    DQ out of sample (p-values)
                                     —          —         —
                                                                I) [c, hit(-l 10-5)]            1.00       0.05       0.05
1) [c, hit(—l to .5)]
                                     -          -         -    2) [VaR]                         0.83       0.20       0.11
2)(VaR)
3) [C, hit(-l), VaR]
                                     -          -         -    3) Ic, hit(-l), VaR]             0.66       0.52       0.29
4) Ic, hit(-I to -5), VaR]
                                     -          -         -    4) Ic, hit(-I to-5), VaR]         0.97      0.07       0.07


 ASYMABSVALUE***5%              GM        IBM       S&P500      ASyMABSVA1U**25%               GM         IBM      S&P50(
Gamma 1                        0.0908    0.1800      00582     Gamma 1                        0.0500     0.0193     0.0121
Standard Errors                0.0542    0.0628      0.029/    Standard Errors                0.0291     0.0127 0.0064
P-values                       0.04 70   0.0021      0.0228    P-values                       0.042 7    0.0648 0.0303
Gamma 2                        0.9275    0.8591      0.9059    Gamma 2                        09196      0.9566     0.9433
Standard Errors                0.0284    0.0358      0.027!    Standard Errors                0.0399     0.0189 0.0279
P-values                       0.0000    0.0000      0.0000    P-values                       0.0000     0.0000 0.0000
Gamma 3                        0.1031    0.1763      0.2105    Gamma 3                        0.0345     0.0237 0.0366
Standard Errors                0.0366    0.0413      0.0581    Standard Errors                0.0/56     0.0092 0.0188
 P-values                      0.0024    0.0000      0.0001    P-values                       0.0/35     0.0052 0.0260
 Gamma 4                       0.7512    0.6940      0.5681    Gamma 4                        0.0274     0.6532     0.0490
 Standard Errors               0.3121    0.1754      0.1002    Standard Errors                 0.44/7    0.3670     0.1592
 P-values                      0.0080    0.0000      0.0000    P-values                        0.4 753   0.03 75    03790
                               547.52    518.24      300.95    RQ in sample                   1500.30    1361.60    746.19
 RQ in sample
                                99.26    118.80       72.84    RQ out ofsan,Ie                 289.50    310.92     183.51
 RQ out ofsaniple
                                 4.94       5.05        4.94    Hits in sample (%)              24.86     25.21      24.93
 Hits in sample (%)
 Flits out of sample (%)         5.00       7.00        6.20    Flits out of sample (%)         26.00     23.60      26.80
 DQ in sample (p-values)                                        DQ in sample (p-values)
                                  0.97      0.47        0,68    1) Ic, hit(-1 10-5)]             0.66       0.89      0.55
 1) Ic, hit(-l to -5)1
                                  0.93      0.85        0.89    2) IVaR]                         0.93       0.79      0.98
 2) [VaR]
                                  0.98      0.93        0.96    3) Ic, hit(-1), VaR]             0.98       0.92       0.95
 3) [c, hit(-1), VaR]
                                  0.99      0.58        0.76    4) Ic, hit(-1 to -5), VaR]       0.75       0.94       0.66
 4) Ic, hit(-1 to -5), VaR]
 DQ out of sample (p-values)                                    DQ out of sample (p-values)
                                  0.92      0.16        0.00    1) Ic, hit(-I to -5)]            0.85       0.56       0.30
 1) Ic, hit(-1 to -5)]
                                  0.82      0.08        0.65    2) [VaR]                         0.72       0.57       0.54
 2) [VaR]
                                  0.96      0.06        0.02    3) Ic, hit(-1), VaR]             0.66       0.94       0.49
 3) [c, hit(-1), VaR]
                                  0.95      0.16        0.00    4) Ic, hit(-1 to -5), VaR]       0.91       0.68       0.31
 4) Ic, hit(-l to -5), VaR]




                                                                                                                      48
Table 7 - Parameter estimates and relevant statistics for the Asymmetric Slope model

  ASYMSLOPE***0.1%             GM        IBM            S&P500           ASYM SLOPE *** 1%           GM         IBM        S&P50(
Gamma 1                        2.7753    1.0863          0.4325       Gamma 1                        0.3928     0.0572     0.1473
Standard Errors                      -         -              -       Standard Errors                0.22/6     0.0580     0.0833
P-values                                                              P-values                       0.0381     0.1 623    0.0385
Gamma 2                        0.4342    0.6587          0.6871       Gamma 2                        0.7983     0.9427     0.8699
Standard Errors                      -         -              -       Standard Errors                0.06 76    0.022 7    0.0484
P-values                             -         -              -       P-values                       0.0000     0.0000     0.0000
Gamma 3                        0.6130    1.1402          1.8655       Gamma 3                        0.2725     0.0512     0.0001
Standard Errors                      -          -             -       Standard Errors                0.1148     0.0616 0.1168
P-values                             -          -             -       P-values                       0.0088     0.2 029    0.4997
Gamma 4                        2.0416    2.8743          2.2849       Gamma 4                        0.4437     0.2474     0.5045
Standard Errors                      -          -             -       Standard Errors                0.1589     0.1006      0.2403
P-values                             -          -             -       P-values                       0.0026     0.0070      0.0/79
                                25.01     29.27           18.15       RQ in sample                   169.30     179.54      105.84
RQ in sample
                                 4.15      5.93            3.65       RQ Out of sample                28.48      40.54       22.69
RQoutofsample
Hits in sample (%)               0.10      0.10            0.14       Hits in sample (%)                1.00      0.97        0.97
Hits Out of sample (%)           0.00      0.00            0.00       Hits outofsample (%)              1.40       1.60

DQ in sample (p-values)                                               DQ in sample (p-values)
                                                                                                       0.60       0.81
1) [C, hit(.1 to —5)]                                                 I) [c, hit(-l to -5)]
                                     —          —                 —




                                     -          -                 -
                                                                      2) [VaR]                         0.98       0.89
2)[VaR]
                                     -          -                 -   3) Ic, hit(-1), VaR]             0.96                   0.94
3) [c, hit(-l), VaR]
                                     -          -                 -   4) Ic, hit(-l to .5), VaR]       0.71       0.88
4) [c, hit(.l to -5), VaR]
DQ Out of sample (p-values)                                           DQ out of sample (p-values)
                                     —          —                 —
                                                                      I) [C, hit(-l to -5)]             0.96       0.05
I) [C, hit(—1 to —5)]
                                     -          -                 -   2) [VaR]                          0.46       0.21
2) [VaR]
                                     -          -                 -   3) Ic. hit(-l), VaR]              0.67
3) [c, hit(-1), VaR]
                                     -              -             -   4) Ic, hit(-1 to -5), VaR]        0.97       0.07
4) Ic, hit(-l to -5), VaR]
LM test for VaR(t-2)                 -              -             -   LM test for VaR(t-2)              0.92       0.92       0.96


    ASYMSLOPE***5%              GM        IBM           S&P500           AsYMSLOPE***25%              CM         IBM       S&P50(
Gamma 1                        0.0704    0.0951          0.0410       Gamma 1                        0.0404     0.0125      0.0014
                               0.0425    0.0444          0.0221       Standard Errors                0.02 98    0.0104      0.0047
Standard Errors
P-values                       0.0488    0.016/          0.03/6       P-values                       0.0877     0.113 1     0.3820
                               0.9353    0.8916          0.9026       Gamma 2                        0.9132     0.9605      0.9481
Gamma 2
Standard Errors                0.0222    0.02 72         0.0239       Standard Errors                 0.0393     0.0169     0.02/2
                               0.0000    0.0000          0.0000       P-values                        0,0000     0.0000     0.0000
 P-values
Gamma 3                        0.0411    0.0597          0.0307       Gamma 3                         0.0415     0.0108     0.0288
Standard Errors                0.0285    0.0335          0.0469       Standard Errors                 0.0/93     0.0098     0.0192
                                t10745   0.03 72         0.2565       P-values                        0.0157     0.1349     0.0664
 P-values
                                0.1182   0.2110          0.2841       Gamma 4                         0.0290     0.0297     0.0288
 Gamma4
 Standard Errors                0.0399   0.0558          0.0895       Standard Errors                 0.0/70     0.0127     0.0175
                                0.0015   0.0001           0.0008      P-values                        0.044/     0.0097     0.0302
 P-values
                                548.63    515.72          300.76       RQ in sample                  1500.88    1360.53     746.90
 RQ in sample
                                 99.20    121.05           72.05       RQ out of sample               289.41     311.51
 RQoutofsanle
 Hits in sample (%)               4.98      4.91            4.98       Hits in sample (%)              25.00      25.14      24.93
                                  5.20      7.40            6.80       Hits out of sample (%)          25.60                 25.80
 Hits out of sample (%)
 DQ in sample (p-values)                                               DQ in sample (p-values)
                                  0.83      0.74            0.69       I) [c, hit(.l 10-5)]             0.69       0.83        0.49
 1) Ic, hit(-1 to -5)J
                                  0.98      0.87            0.94       2) [VaR]                         0.97                   0.93
 2) [VaR]
                                  0.97      0.97            0.64       3) Ic, hit(-1), VaR]             0.97                   0.99
 3) [c, hit(-1), VaR]
                                  0.89      0.82            0.74       4) [c, hit(-1 to .5), VaR]       0.79       0.90
 4) [c, hit(-1 to -5), VaR]
 DQ out of sample (p-values)                                           DQ out of sample (p-values)
                                  0.92      0.03            0.00       I) [C, hit(-l to .5)]            0.88       0.64
 1) [c, hit(-1 to -5)]
                                  0.97      0.06            0.20       2) [VaR]                         0.88       0.45        0.77
 2) [VaR]
                                  0.96      0.00            0.13       3) Ic, hit(-l), VaR]             0.67       0.79
 3) [C, hit(-l), VaR]
                                  0.95      0.01            0.00       4) [C, hit(-1 to -5), VaR]        0.94      0.70
 4) [c, hit(-l to -5), VaR]
                                  0.96      0.77            0.94       LM test for VaR(t-2)              0.99       0.89       0.60
 LM test for VaR(t-2)




                                                                                                                               49
Table 8 - Parameter estimates and relevant statistics for the Indirect GARCH model

                                 GM           IBM S&P500                       GARCH***1%                GM          IBM S&P500
   GARCH***0.1%
                               36.8548        2.7007 3.6423               Gamma I                        1.4965      13288 0.2329
Gamma I                                                                                                              0.8869 0.1552
                                     -              -            -        Standard Errors                0.7/52
Standard Errors
                                     -              -            -        P-values                       0.0182      0.0670 0.0668
P-values                                                                                                             0.8740 0.8350
                                0.0000         0.4997       0.5719        Gamma 2                        0.7803
Gamma 2                                                                                                              0.0728 0.0651
                                     -              -             -       Standard Errors                0.0630
Standard Errors
                                      -             -             -       P-values                       0.0000      0.0000 0.0000
P-values
                               10.2205        30.3776       14.6629       Gamma 3                        0.9363      0.3374 1.0575
Gamma 3                                                                                                              0.2238 0.4964
                                    -               -             -       Standard Errors                0.2906
Standard Errors
                                    -               -                     P-values                       0.0006      0.0659 0.0166
P-values
                                 2620           33.80         18.22                                      171.04      183.49 108.33
RQ in sample                                                              RQ in sample
                                                               3.59                                       29.36       40.17   24.99
RQoutofsaxnple                    4.14                                    RQoutofsample
                                                               0.10                                        0.97        1.04     1.04
Hits in sample (%)                0.10           0.07                     Hits in sample (%)
                                                               0.00       Hits out of sample (%)            1.20       1.60     1,80
Hits out of sample (%)            0.00
DQ in sample (p-values)                                                   DQ in sample (p-values)
                                         -                           -        hit(-1 to -5)]               0.56        0.28     0.82
1) Ic, hit(-l to -5))                                                                                      0.87        0.77     0.76
                                         -            -
2) [VaR]                                              -                                                    0.96        0.64     0.92
                                         -                                    hit(-l), VaR)
3) Ic, hit(-l), VaR]                                                 -                                     0.67        0.36     0.87
                                         -                                4) hit(-l to -5), VaR]
4) Ic, hit(-l to -5), VaR]
DO out of sample (p-values)                                               DQ out of sample (p-values)
                                          -                          -                                      0.99       0.05     0.05
 I) [c, hit(-l to -5)]                                                    1) (C, hit(-1 to -5)1
                                          -             -                                                   0.87       0.21     0.16
2) [VaR]                                                                  2) IVaRI
                                          -             -             -                                     0.61       0.51     0.24
3) Ic, hit(-l), VaR]                                                            hit(-l), VaR]
                                          -             -                                                   0.96       0.06     0.05
4) [c, hit(-I to -5), VaR]                                                      hit(-1 to -5), VaR]


      GARCH***5%                 GM             IBM         S&P500
                                 0.3336         0.6529       0.0262        Gamma I                        0.0505     0.0203 0.0019
 Gamma I                                                                                                  0.0316     0.0123 0.0014
 Standard Errors                 0.1788         0.2184        0.0153       Standard Errors
                                 0.0310         0.00/4        0.0428       P-values                       0.0549     0.050! 0.0890
 P-values
                                 0.9042         0.7930        0.9287       Gamma 2                        0.8921      0.9570 0.9429
 Gamma 2                                                                                                              0.0225 0.0296
                                 0.0390         0.0582        0.0250       Standard Errors                0,05/I
 Standard Errors                                                                                          0.0000      0.0000 0.0000
 P-values                        0.0000         0.0000        0.0000       P-values
                                 0.1220         0.1784        0.1407       Gamma 3                        0.0183      0.0056 0.0077
 Gamma 3                                                                                                              0.0031   0.0049
                                 0.0530         0.0594        0.0591       Standard Errors                0.0093
 Standard Errors                                                                                          0.0241      0.0363 0.0576
 P-values                        0.0/07         0.0013        0.0086       P-values
                                                              305.83                                     1500.42     1365.02 747.31
                                 552.31         524.86                     RQ in sample
 RQ in sample                                                                                             289.59      310.51   183.65
                                  99.79         119.66         74.08       RQ Out of sample
 RQoutofsa'Tçle                                                                                            25.03       25.03    25.03
 Hits in sample (%)                4.98           5.01          5.05       Hits in sample (%)
                                                  7.60          5.80       Hits out of sample (%)          26.20       24.20    28.00
 Hits out of sampe (%)             4.60
 DQ in sample (p-values)                                                   DQ in sample (p-values)
                                                                0.39                                        0.56        0.58     0.31
 I) Ic, hit(-l to -5)1              0.31          0.34                     1) Ic, hit(-1 to -5)1
                                                                0.88                                        0.94        0.96     0.93
                                    0.93          0.98                     2) [VaRI
 2) [VaRI                                                                                                    0.94       0.92     0.97
                                    0.98          0.84           1.00      3) Ic, hit(-l), VaRI
 3) [c, hit(-l), VaR]                                                                                        0.68       0.70     0.40
                                    0.32          0.39          0,50       4) [c, hit(-1 to -5), VaR]
 4) [c, hit(-l to -5), VaR)
 DQ out of sample (p-values)                                               DO Out Of sample (p-values)
                                                                 0.00                                        0.81       0.75     0.15
 I) Ic, hit(-l to -5)1              0.89           0.03                     I) [C, hit(-1 to -5)1
                                                                 0.77                                        0.64       0.86     0.18
                                    0.55           0.02                    2) [VaR]
  2) [VaR]                                                                                                    0.70      0.78     0.37
                                    0.94           0.01          0.11      3) Ic, hit(-1), VaR]
  3) [c, hit(-l), VaR]                                                                                        0.88      0.77     0.20
                                    0.93           0.04          0.00      4) [c, hit(-1 to -5), VaR]
  4) Ic, hit(-1 to -5), VaR)




                                                                                                                                  50
Table 9 - Plain GARCH( 1,1) estimates
                                                                                                       -
                                                      IBM                              S&P 500
                 GM
                                     0.10%     1%           5%     25%     0.10%     1%       5%           25%
0.10%     1%          5%     25%
                                              Hit in Sample                         Hit in Sample
         Hit in Sample                                                                                     24.97
                                     0.07     0.97          4.98   24.97   0.07      0.97      4.98
0.07     0.97         4.98   24.97
                                             Hit out of Sample                     Hit out of Sample
        Hit out of Sample                                                           1.40      600   28.00
                      4.40   26.20   0.00      1.60         5.80   23.00   0.20
0.00      1.20
                                              DQ in Sample                          DQ in Sample
         DQ in Sample                                                                                0.45
                                                                   0.98     1.00    0.8!      0.32
 1.00     03          0.88   0.54     1.00
                                     0.76
                                              0.81
                                              0.60
                                                            0.46
                                                            0.62   0.31     0.88    0.83      0.60   0.67
0.86      0.92        0.76   0.78
                                              0.71          0.24   0.03     0.59    0.96      0.77   0.84
0.55      0.94        0.64   0.66    0.90
                                              0.77          0.32   0.20     0.94    0.88      0.27   0.47
0.91     0.05      0.78      0.53     1.00
                                             DQ out of Sample                      DQ out of Sample
        DQ out of Sample                                                                                    0.13
                                      1.00    0.05      0.16        0.52    1.00     0.03     0.00
 1.00     0.99        0.96    0.73
                                              0.23      0.78        0.31    0.57     0.5!     0.68          0.23
 0.49     0.82        0.40    0.72    0.50
                                      1.00    0.52      0.07        0.78    0.89     0.71     0.09          0.31
 1.00     0.60        0.84    0.40
                                              0.06      0.06        0.6!    1.00     0.04     0.00          0.16
 1.00     Q.96        0.98    0.81    1.00




                                                                                                                   51
