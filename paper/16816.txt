                                NBER WORKING PAPER SERIES




                   LEARNING, LARGE DEVIATIONS AND RARE EVENTS

                                            Jess Benhabib
                                             Chetan Dave

                                        Working Paper 16816
                                http://www.nber.org/papers/w16816


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                     February 2011




ˆWe thank Chryssi Giannitsarou, In-Koo Cho, John Duffy, George Evans, Boyan Jovanovic, Tomasz
Sadzik, Benoite de Saporta, Tom Sargent and two anonymous referees for helpful comments and suggestions.
The usual disclaimer applies. The views expressed herein are those of the author and do not necessarily
reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2011 by Jess Benhabib and Chetan Dave. All rights reserved. Short sections of text, not to exceed
two paragraphs, may be quoted without explicit permission provided that full credit, including © notice,
is given to the source.
Learning, Large Deviations and Rare Events
Jess Benhabib and Chetan Dave
NBER Working Paper No. 16816
February 2011, Revised Semptmber 2012
JEL No. D83,D84

                                              ABSTRACT

We examine the role of generalized constant gain stochastic gradient (SGCG) learning in generating
large deviations of an endogenous variable from its rational expectations value. We show analytically
that these large deviations can occur with a frequency associated with a fat tailed distribution even
though the model is driven by thin tailed exogenous stochastic processes. We characterize these large
deviations that are driven by sequences of consistently low or consistently high shocks. We then apply
our model to the canonical asset-pricing model. We demonstrate that the tails of the stationary distribution
of the price-dividend ratio will follow a power law.


Jess Benhabib
Department of Economics
New York University
19 West 4th Street, 6th Floor
New York, NY 10012
and NBER
jess.benhabib@nyu.edu

Chetan Dave
New York University
Department of Economics
19 W. 4th Street, 6FL
New York, NY, 10012
cdave@nyu.edu
1.      Introduction

     Dynamic stochastic models have at times di¢ culty matching some features of macro-

economic data.1 One route to reconcile di¤erences between data and theory has been to

replace the assumption of rational expectations with that of adaptive learning, where agents

are assumed to estimate the underlying parameters of a model via recursive least squares.

For example, if the monetary authority adaptively learns the underlying Phillips curve via

decreasing gain least squares regressions, then the Nash outcome is the one that is selected

(see Evans and Honkapohja (2001)). Still, the U.S. economy escaped the high in‡ation of the

1970’s predicted by the standard model with decreasing gains. To provide an explanation

Sargent (1999) and Cho et al. (2002) assumed instead that a monetary authority estimates a

misspeci…ed Phillips curve using constant gain algorithms that place more weight on recent

observations. This assumption allowed the possibility of escape from a Nash outcome to a low

in‡ation (Ramsey) outcome. In particular, within the context of their endogenous tracking

model, a sequence of otherwise rare shocks can cause frequent large deviations from a high

in‡ation self-con…rming equilibrium. Indeed Sargent et al. (2006) take these endogenous

tracking models to the data and account for the behavior of in‡ation in the U.S.

     Our analysis also focuses on the role of large deviations theory and its interplay with

constant gain learning dynamics. Speci…cally, working within the adaptive learning tradition

set out by Sargent and Williams (2005), Evans et al. (2010) and others, we examine the role

of generalized constant gain stochastic gradient (SGCG) learning algorithms in generating

   1
     For example, empirical evaluations of consumption based asset pricing models lead to numerous asset
pricing puzzles, and evaluations of real business cycle models cannot typically account for the pattern of
hours worked without appealing to labor supply elasticities that are often at odds with microeconometric
evidence.


                                                    1
large deviations of an endogenous variable from its rational expectations value. We show

analytically that these large deviations can occur with a frequency associated with a fat tailed

distribution even though the model is driven by thin tailed exogenous stochastic processes.

Using some new techniques in the analysis of stochastic processes and linear recursions with

multiplicative noise2 , we characterize these large deviations occurring under adaptive learning

that are driven by sequences of consistently low or consistently high shocks. Such sequences

are rare in that the average of realizations in the sequences can signi…cantly diverge from

the population mean of the shocks. We then apply our model to the single asset version of

the canonical model of Lucas (1978) that has been studied extensively by Carceles-Poveda

and Giannitsarou (2007, 2008) who look at the ability of learning models to approximate

the behavior of aggregate stock market data.

      A particular issue in the modi…cation of standard rational expectations models to better

account for features of the data by introducing adaptive learning is the choice of the learning

algorithm itself. Typically, in replacing the rational expectations assumption with that of

adaptive learning, agents are assumed to estimate parameters of processes to be forecasted

using recursive (adaptive) methods.3 A particular strain of this literature demonstrates the

consistency of this approach with Bayes’ Law. In a stationary model with optimal learn-

ing, estimated parameters ultimately converge to their rational expectations equilibrium. In

recent work however, Sargent and Williams (2005) introduce a model where agents expect

a random walk drift in estimated parameters. They then show that the SGCG algorithm,

  2
   See Kesten (1973), Saporta (2005) and Roiterstein (2007).
  3
   In asset pricing contexts, see for example: Adam et al. (2008), Adam and Marcet (2011), Branch and
Evans (2010), Brennan and Xia (2001), Bullard and Du¤y (2001), Carceles-Poveda and Giannitsarou (2008),
Cogley and Sargent (2008), and Timmermann (1993, 1996).




                                                  2
that assigns more weight to recent observations on account of the underlying drift in the es-

timated parameters, is asymptotically the optimal Bayesian estimator. Evans et al. (2010)

follow Sargent and Williams (2005) and show how a SGCG learning algorithm approximates

an optimal (in a Bayesian sense) Kalman …lter. Under such adaptive SGCG learning, un-

certainty about estimated parameters persists over time and can fuel escape dynamics in

which a sequence of consistently high or consistently low shocks propel agents away from

the REE of a model.4 In an asset-pricing context Weitzman (2007) also shows that if recent

observations are given more weight under Bayesian learning of the variance of the consump-

tion growth rate, agents will forecast returns and asset prices using thick-tailed distributions

for consumption growth.5 It is for this reason that we focus on an asset pricing context to

analytically demonstrate how SGCG learning, consistent with optimal Bayesian learning,

can account for the data features and fat tailed distributions of the price-dividend ratio.

       Theoretically, we demonstrate that under adaptive learning of the asset prices, the tails

of the stationary distribution of the price-dividend ratio will follow a power law, even though

the dividend process has thin tails and is speci…ed as a stationary AR(1) process. The tail

index or power-law coe¢ cient of the price-dividend ratio can be expressed as a function of

model parameters, and in particular of the optimal gain parameter that assigns decaying

weights to older observations. In fact, as demonstrated by Sargent and Williams (2005)

   4
     See also Holmstrom (1999) for an application to managerial incentives of learning with an underlying
drift in parameters.
   5
     See also Koulovatianos and Wieland (2011). They adopt the notion of rare disasters studied by Barro
(2009) in a Bayesian learning environment. They …nd that volatility issues are well addressed. Similarly
Chevillon and Mavroeidis (2011) …nd that giving more weight to recent observations under learning can
generate low frequency variability observed in the data. See also Gabaix (2009) who provides an excellent
summary of instances in which economic data follow power laws and suggests a number of causes of such laws
for …nancial returns. In particular, Gabaix et al. (2006) suggest that large trades in illiquid asset markets
on the part of institutional investors could generate extreme behavior in trading volumes (usually predicted
to be zero in Lucas-type environments) and returns.


                                                     3
and more recently by Evans et al. (2010), the optimal gain depends on the variance of the

underlying drift in the estimated parameters: the higher the variance of the drift parameter,

the higher the gain, and the thicker the tail of the distribution of the price-dividend ratio.

We characterize how the power law tail index of the of the long-run stationary distribution

of the price-dividend ratio varies as a function of the gain parameter and of the other deep

parameters of the model. Under our adaptive learning scheme that approximates optimal

Bayesian learning, stationary dividend processes generate distributions for the price-dividend

ratio that are not Normal. Thus, large deviations of the price-dividends ratio from the

rational expectations equilibrium are possible with a frequency higher than that associated

with a Normal distribution even though the dividend process is thin-tailed.

   Our analysis and simulations indicate that under standard parameter calibrations, to

match either the empirical tail index or the variance of the annual “fat-tailed”price dividend

ratio, we require a gain parameter around 0:4-0:55, signi…cantly higher than what is typically

used in the adaptive learning literature (0:01-0:04). Carceles-Poveda and Giannitsarou (2008)

also employ large parameter values for the gain in asset pricing contexts, as do Branch and

Evans (2010). The latter implicitly assumes slowly decaying weights on past observations,

and therefore very little underlying drift in the parameters estimated by agents. In order

to get an empirical handle on the gain parameter we estimate the parameters of our model,

including the gain parameter, by two separate methods. The …rst is a structural minimum

distance estimation method for the tail index. This method puts higher weight on the

empirically observed tail of the price-dividend ratio, and produces a gain estimate in the

range of 0:35-0:53. The second method computes the gain as Bayesian agents expecting

drifting parameters would, using a Kalman …lter on the data. This yields a gain parameter

                                              4
in the range of 0:49-0:55, assigning decaying weights on past observations that take the

parameter drift into account. Therefore agents who use this gain parameter would indeed

have their expectations con…rmed by the data.

     The paper is structured as follows. We …rst describe the general dynamic stochastic

equation under learning, and also brie‡y illustrate its application to the single asset pricing

version of Lucas (1978). Then in Section 3 we prove that our learning model, written as a

random linear recursion with multiplicative noise, predicts that the tails of the stationary

distribution of the endogenous variable of interest, in our application the price-dividends

ratio, will follow a power law with coe¢ cient       that is a function of model parameters. In

Section 4 we use simulations to study how        varies with the deep parameters. In Section 5

we provide estimates of the deep parameters of the model for our asset pricing application,

and of the gain parameter in particular, that are consistent with the        estimated directly

from the price-dividends ratio. Section 6 concludes.




2.      Model Environment

     We focus on models of the type



                                      pt = Et (pt+1 ) + dt                                  (1)



in which the exogenous driving process dt follows



                                   dt = dt   1   + "t ; j j < 1                             (2)



                                                 5
                        2                                          2
where "t is an iid(0;       ) random variable (such that               < +1) with compact support

[ a; a], a > 0. Evans and Honkapohja (1999, 2001) consider di¤erent economic environ-

ments that also give rise to such speci…cations.

   The assumption that the exogenous process for dt has compact support is not very re-

strictive and clearly highlights our result: while the stationary distribution of an exogenous

driving process has thin tails, the stationary distribution of the related endogenous variable

may have fat tails, a result also characterized as “thin tails in, thick tails out”. Furthermore,

the assumption of compact support for "t makes it easy to show that the autoregressive

exogenous process is uniformly recurrent over its stationary distribution. The assumption of

uniform recurrence simpli…es proofs and is further discussed in detail in the next section.

   Anticipating our empirical application, we brie‡y provide an asset pricing interpretation

for the model in (1)-(2). Following Lucas (1978), a single asset endowment economy with

utility over consumption given by


                                                    Ct1
                                         u(Ct ) =         ;   >0                              (3)
                                                    1


yields, under a no-bubbles condition, the nonlinear pricing equation

                                         (                                 )
                                              Dt+1
                              Pt = E t                    (Pt+1 + Dt+1 )                      (4)
                                               Dt


where    2 (0; 1) is the usual exponential discount factor and (real) dividends (Dt ) follow




                                                     6
some exogenous stochastic process. Log-linearizing the above equation yields



                               pt = Et (pt+1 ) + (1                       )Et (dt+1 ) + dt                (5)



where all lowercase variables denote log-deviations from the steady state (P ; D) =                   1
                                                                                                          ;1 .

The exogenous process for dt follows the same speci…cation as above and since Et (dt+1 ) = dt ,



                               pt = Et (pt+1 ) + dt ;                  (1                 ) +             (6)



is the fundamental expectational di¤erence equation for prices.6

       Returning to our linear model of learning, we follow Evans and Honkapohja (1999, 2001)

and assume that the perceived law of motion (PLM) of the representative agent is



                                                                                 2        2
                             pt =   t 1 dt 1   + t;      t         i:i:d:(0;         );       < +1;       (8)



which in turn implies

                                                 Et (pt+1 ) =         t 1 dt ;                            (9)


where       t 1   is the coe¢ cient that agents estimate from the data to forecast pt . Inserting the

   6
       The rational expectations solution to (6) is

                                                  REE          REE
                                          pt =          dt ;           =                                   (7)
                                                                            1

for all     6= 1.




                                                               7
above into (6) yields the actual law of motion (ALM) under learning:7



                               pt =            t 1 dt   + dt = (         t 1   + )dt                       (10)

                                       = (      t 1   + ) dt    1   +(         t 1   + )"t :               (11)



In contrast the ALM under rational expectations is



                                             pt = dt =         dt   1   + "t :                             (12)



Under SGCG learning,          t    evolves as8



                               t   =   t 1   + gdt 1 (pt       t 1 dt 1 );      g 2 (0; 1):                (13)



At this point we take the gain parameter g as given, but in section 5. we will estimate its

value under our learning model with Bayesian agents who expect a random walk drift in .

Following the usual practice in the literature for analyzing learning asymptotics, we insert

   7
     We note that in the asset pricing context, the ALM is linear in the ‘belief’ parameter ( t ). In other
contexts the ALM might be nonlinear in beliefs. However, the linear forces generating large deviations in
the adaptive learning model may drive the dynamics in nonlinear contexts. For example in Cho et al. (2002)
adaptive learning leads to non-neglible probablities for large deviations even in the prescence of nonlinearities
for the true data generating process.
   8
     See Carceles-Poveda and Giannitsarou (2007, 2008) for details and derivations under a variety of learning
algorithms.




                                                           8
the ALM under learning in place of pt in the recursion for                          t   in (13) to obtain



                        t   =     t t 1   +     t                                                                    (14)

                        t   = 1      (1             )gd2t   1   + gdt 1 "t = 1     gd2t   1   + g dt dt   1          (15)

                        t   =      gd2t   1   + gdt 1 "t = gdt dt 1 :                                                (16)



The equation in (14) takes the form of a linear recursion with both multiplicative (                          t   in (15))

and additive (      t   in (16)) noise. We show in the next Section that the stationary distribution

of    t   can be fat-tailed and indeed follows a power law even though the forcing variable (dt ) is

a thin tailed process. Under the asset pricing application this implies that the price-dividend

ratio ( t ) can exhibit large deviations from its rational expectations equilibrium value with

non-negligible probabilities.




3.         Large Deviations and Rare Events

      As noted,     t   is a random variable generating multiplicative noise, and our main result is

that it can be the source of large deviations and fat tails for the stationary distribution of

 t.   There are two elements that are absolutely critical for this result. First, the distribution

of the random variable            must have Ej j < 1 or a stationary distribution fails to exist (see

Brandt (1986)). Second, for               t   to have a fat tail even if the exogenous driving process, the

dividends, are thin tailed, we need the distribution of                        to have some support above the unit

circle: P (j j > 1) > 0. Since the distribution of                     t   is governed by the exogenous process for

dt we will need some restrictions on fdt gt2N as discussed below. In particular in section 5.


                                                                   9
where we will apply our results to the asset pricing model and characterize the price-dividend

ratio, these restrictions will apply to the stationary distribution of dividends.

       We use results from large deviation theory (see Hollander (2000)) together with the work

of Saporta (2005), Roitershtein (2007) and Collamore (2009) to characterize the tail of the

                       9
distribution of      t. Let N = 0; 1; 2:::, and note that the stationary AR(1) Markov process
                                                                               h       i
                                                                                  a  a
fdt gt2N    given by (2) is uniformly recurrent, and has compact support D = 1 ; 1       (see

Nummelin (1984), p. 93).10 We use the uniform recurrence of fdt gt2N in step (ii) of the

proof of 1 below to show that j j > 1 with positive probability, or P! (j j > 1) > 0, which is

essential to obtain fat tails for f t g.11

       Next we seek restrictions on the support of the iid noise "t 2 [ a; a] to ensure that

Ej     1j   < 1 where, from equation (15),       1   is the random variable associated with the sta-

tionary distribution of dt . For simplicity, in order to derive restrictions on a that assures

Ej     1j   < 1 we assume that "t is uniformly distributed. We could just as easily have assumed

another distribution, for example a triangular distribution, or even another skewed distribu-

tion over [ a; a], and sought restrictions on its support, or a; to ensure that E j            1j   < 1. The

uniform distribution leads to easy computations, and makes it quite clear that it is not the

skewness or the tails of the distribution of "t that drive our results on the tails of distribution

   9
      For an application of these techniques to the distribution of wealth see Benhabib et al. (2011) and to
regime switching, Benhabib (2010).
   10
      To de…ne uniformly recurrent let (X; X ) be a measurable space and de…ne B P m (x; A) =
P (Xn 2 A; Xi 2  = B; m = 1; :::m 1) : A chain fXn g is uniformly '-recurrent if for all A 2 X with ' (A) > 0;
if limn nm=1 A P m (x; A) = 1 holds uniformly in x. That is, for all " > 0 there exists N such that for
all x 2 X and n        N; nm=1 A P m (x; A) = 1 " (see Petritis (2012, Chapter 11)). To assure that the
AR (1) process fdt gt2Z is uniformly recurrent we also assume that the distribution of "t is not a singular
(see Nummelin (1984, p. 92)). This is a very weak requirement: a probability distribution is singular on Rn
if it is concentrated on a set of Lebesgue measure zero and gives probability zero to every one-point set. An
example on R1 would be the Cantor distribution, a probability distribution over a Cantor set.
   11
      This requirement of uniform recurrence can be weakened, as discussed in Collamore (2009) in more
detail, but proofs would become more cumbersome.



                                                     10
of the price dividend ratio. However a restriction on a that assures E j                                                 1j   < 1, no matter

what the underlying distribution, is critical. If E j                             1j             1, then           t   does not even have a

limiting stationary distribution, so our results about fat tails cannot hold.

       We assume for simplicity therefore that "t 2 [ a; a] and is uniform, and that12


                                                                      2           0:5
                                                      6 (1                )
                                               a<                                        :                                                   (17)
                                                      g (1                )


Note that



                          E( t ) = E 1              g (dt 1 )2 + g (dt                       1   ( dt      1   + "t ))

                          E( t ) = 1           gE (dt 1 )2 +               gE (dt 1 )2

                         E(   1)   =      1     gE (dt 1 )2 (1                       )       t!1
                                                                                                      :



                                                             2
Since "t is iid and is uniform with variance                     ,


                                                                      2
                                   E(     1) = 1           g               2
                                                                                (1                )                                          (18)
                                                               1
                                                                 1
                                                                 12
                                                                      (2a)2
                                   E(     1)    = 1        g                  2
                                                                                   (1                 ):                                     (19)
                                                                 1


From equation (19) it follows that E(               1)   < 1, and solving for a such that E(                                    1)   >   1, we

obtain the restriction (17) to guarantee that E j                      1j         < 1, which is the only reason that we

  12
       We can express this condition as
                                                                       2
                                                          6(1              )
                                                    g<
                                                         a2 (1              )
which implies that given a, if g is too high, the condition E j                   1j     < 1 may fail and the dynamics of                t   may
explode. We thank a referee for pointing this out.




                                                           11
impose the restriction on a.

   We denote the stationary distribution of fdt gt2N by . Since fdt gt2N 2 D and ["t ]t2N 2

[ a; a] are bounded, so are f t gt2N and f t gt2N , and we de…ne ( t ;                           t )t2N   2 B. In fact, fol-

lowing the de…nition of Roitershtein (2007), fdt ; ( t ;                    t )gt2N   constitutes a Markov Modulated

Process (MMP) de…ned on the product space (D; B): conditional on dt , the evolution of the

random variables     t+1   (dt ; dt 1 ) and       t+1   (dt ; dt 1 ) are given by


                                                         Z
               P (dt 2 A; ( t ;     t)   2 B) =                K (d; dy) G (d; y; B) jd=dt 1 ;                           (20)
                                                           A

                                  G (d; y; ) = P (( t ;                t)   2 ) j dt    1   = d; dt = y) ;               (21)



where A 2 D, B 2 B, K (d; dy) is the transition kernel of the Markov process fdt gt2N and

dy represents the di¤erential. In other words an MMP does not require                                t   and   t   to be fully

independent but allows a form of dependence where both can be driven by the process for

fdt gt2N . In addition, since either or both can also be subject to iid shocks, they do not have

to be perfectly correlated. Thus the probability that dt will belong to a set A and ( t ;                                   t)


will belong to a set B depends on dt          1   and on the the transition kernel of the Markov process

fdt gt2N . This will in fact be the case when we apply our results to asset prices in section 5.

where dividends drive both the multiplicative and the additive parts of the process for                                   t.

                                                                  Pn
   To set the stage for Proposition 1 let Sn =                     t=1      log j t j. Following Roitershtein (2007)




                                                             12
and Collamore (2009)13 the tail of the stationary distribution of f t gt depends on the limit14


                              1      Yn
                                                        1
                 ( ) = lim sup log E     j t j = lim sup log E[exp( Sn )] 8                                         2 R:       (22)
                       n!1    n      t=1
                                                 n!1    n


Using results in Roitershtein (2007), we can now prove the following about the tails of the

stationary distribution of f t gt2N :


Proposition 1 For -almost every d0 2 [ a; a], there is a unique positive                                        < 1 that solves

 ( ) = 0, such that



                K1 (d0 ) = lim            P ( > jd0 ) and K               1   (d0 ) = lim        P( <               jd0 )      (23)
                                !1                                                       !1




and K1 (d0 ) and K         1   (d0 ) are not both zero.15

  13
       For results on processes driven by …nite state Markov chains see Saporta (2005).
  14
        lim sup n1 log E[exp( Sn )] is the Gartner Ellis limit that also appears in large deviations theory. For an
       n!1
exposition see Hollander (2000).
  15
     We can also show that (K1 (d0 ) = K 1 (d0 )) = 1 if a is large enough. This follows from Condition
G given
     n by Roitershteino (2007): Conditon G holds if there does not exist a partition of the irreducible set
               a    a
D= d         1   ;1     into two disjoint sets D 1 and D1 such that:

                                   P (d    2 D 1 ; d + " 2 D1 ; < 0)
                                           = P (d 2 D 1 ; d + " 2 D 1 ;               > 0) = 0

where "    [ a; a] and       (0; 1). (See Roitershtein’s De…nition 1.7 and subsequent discussion, and his
Proposition 4.1.) Suppose in fact that P (d 2 D 1 ; d + " 2 D1 ; > 0) = 0 for D 1 with minimal element
d0 and maximal element d1 . Then P (d 2 D 1 ; d + " 2 D 1 ; > 0) = 1. Then it must be true, since d1 is
the maximum element of D 1 , that d1 + a d1 and so 1 a         d1 , implying d1 = 1 a . Similarly, it must be
true that d0 a d0 so that 1 a         d0 , implying 1 a  d0 . Thus D 1 = D, that is the whole set. Now we
can show that for a large enough, P (d 2 D; d + " 2 D; > 0) = 1 cannot hold. Since
                                           2
                            =1       g (d0 ) + g d0 ( d0 + ") = 1             g d20 (1        ) + g d0 ";
                                                            a                                                   a
we attain the smallest possible        if we set d0 =   1         and " =       a, or equivalently d0 =     1        and " = a. Then
                                                                     (1 )
      0 with probability 1 if and only if a        a =          (g(1+ (1 2 )))0:5
                                                                                  . If a > a with positive probability, then
P ( < 0) > 0, which contradicts P (d 2 D         1; d + " 2 D            1;    > 0) = 1. Note also that = 1 for d0 = 0 so
it also follows that the P ( > 0) > 0.



                                                                  13
   Proof. The results follow directly from Roitershtein (2007), Theorem 1.6 if we show the

following:

   (i) There exists a         0   such that ( 0 ) < 0. First we note that (0) = 0 for all n. Note also

that

                                                          Y
                                                          n
                                                d log E         j tj
                   0               1                      t=1
                     (0) = lim sup                                       j   =0
                           n!1     n                    d
                                                                   !     1                                    !
                                    1                 Y
                                                      n                           Y
                                                                                  n                 Y
                                                                                                    n
                          = lim sup               E         j tj             E          j t j log          j tj j   =0
                            n!1     n                 t=1                         t=1               t=1

                                         1             Yn
                          =       lim sup E log     j tj
                                  n!1    n      t=1



For large n, as f t gt converges to its stationary distribution !, we have


                                                   1      Yn
                                  0
                                      (0) = lim sup log E     j t j = E! (log j                     1 j)
                                            n!1    n      t=1



                                                                                            0
From equations (17)-(19) we have E! j                  1j     < 1. Therefore                    (0) = E! log (j        1 j)   < 0, and

there exists   0   > 0 such that ( 0 ) < 0.

   (ii) There exists a        1   such that ( 1 ) > 0. As in (i) above, we can evaluate, using Jensen’s

inequality,


                            1      Yn
                                                      1
               ( ) = lim sup log E     j t j = lim sup log E[exp( Sn )]                                                           (24)
                     n!1    n      t=1
                                               n!1    n
                                                                     1                                         Sn
                      =       lim sup log (E[exp( Sn )]) n                       lim sup log E[exp(               )]              (25)
                              n!1                                             n!1                              n




                                                                14
so that at the stationary distribution of f t gt2N


                                                                       Z
                     ( )       log E! [exp( log j      1 j)]   = log         [exp( log j          1 j)]d!   ( ):                  (26)



As       ! 1 for log j j < 0 we have [exp( log j t j)] ! 0, but if P! (log j j > 0) > 0 at
                                                                                          R
the stationary distribution of f t gt , then lim               !1        ( ) = log            [exp( log j t j)]d! ( ) ! 1.

Therefore if we can show that P! (log j t j > 0) > 0, it follows that there exists a                                   1   for which

 ( 1 ) > 0. Since ( ) is convex16 , it follows that there exists a unique for which ( ) = 0.
                                              n               o
                                                          a
To show that P! (j j > 1) > 0, de…ne A = d 2 0; 1               , 2 (0; 1) so that 1 a < 1 a .
                                                                       h       i
At its stationary distribution fdt gt2N is uniformly recurrent over 1 a ; 1 a which implies
                                                                         1
that P (dt     1   2 A) > 0. We have          t   =1     gdt    1            (1       )dt         1   "t , so for dt       1   2 A and

"t 2 ( a; a], it follows that         t   > 1. Thus P! (j t j > 1) = P (dt                    1   2 At ) P ("t 2 ( a; a]) > 0.

       (iii) The non-arithmeticity assumption required by Roitershtein (2007) (p. 574, (A7))

holds17 : There does not exist an                 > 0 and a function G : R                    f 1; 1g ! R such that



                       P (log j t j 2 G (dt 1 ; )         G (dt ;          sign ( t )) + N) = 1:                                  (27)



We have



log j t j = log (1      gd2t   1   + g dt dt 1 ) = log 1            (1            )gd2t   1   + gdt 1 "t           = F (dt 1 ; "t ) ;

                                                                                                                                  (28)

  16
     This follows since the moments of nonnegative random variables are log convex (in ); see Loeve (1977,
p. 158).
  17
     See also Alsmeyer (1997). In other settings f t gt may contain additional iid noise independent of the
Markov Process fdt gt , in which case the non-aritmeticity is much more easily satis…ed.



                                                           15
which contains the cross-partial term dt dt 1 . Therefore in general F (dt 1 ; "t ) cannot be

represented in separable form as R (dt 1 ; )               R (dt ; ) + N 8 (dt 1 ; dt ) where dt = dt                 1   +

"t . Suppose to the contrary that there is a small rectangle [D; D ]                             [E; E ] in the space

of (d; "), over which          remains of constant sign, say positive, such that F (d; ") = R(d)

R( d + "), d is in the interior of [D; D ], and " is in the interior of [E; E ], up to a constant

from the discrete set N, which we can ignore for variations in [D; D ]                                   [E; E ] that are

small enough. Now …x d, d0 close to one another in the interior of [D; D ]. We must have,

for " 2 [E + jd       d0 j; E        jd    d0 j], that



                    F (d; ")     R(d) =          R( d + ") =       R( d0 + " + (d                d0 ))               (29)

                                          = F (d0 ; " + (d       d0 ))        R(d0 );                                (30)



or F (d; ")     F (d0 ; " + (d     d0 )) = R(d)          R(d0 ). However the latter cannot hold since the

cross-partial term dt 1 "t in F (dt 1 ; "t ) = 1          (1      )gd2t   1   + gdt 1 "t is non-zero except for

a set of zero measure where d or " are zero.18,19

       (iv) To show that K1 (d0 ) = lim          !1      P ( > jd0 ) and K              1   (d0 ) = lim       !1   P( <

  18
    We thank Tomasz Sadzik for suggesting this proof for (iii).
  19
    We can avoid possible degeneracies that may occur if t and            t   have a speci…c form of dependence so
that
                                        P ( j t + t = ) = 1:
Note

                                             t            gd2t + gdt "t+1
                                     =            =
                                          1   t   1 (1         )gd2t + gdt "t+1
                                                   2
                                                 gdt + g gdt "t+1
                                     =
                                            1 (1     )gd2t + gdt "t+1

Di¤erentiating with respect to "t , the right side is zero only if gd2t = 1 (1      )gd2t , or                g = 1 g+g .
This holds only if g = 1. So in general, for any dt , there exists a constant such that P ( j             t     + t= )=1
only if g = 1, which we ruled out by assumption.



                                                          16
     jd0 ) are not both zero, we have to assure, since                          t   and    t   are not assumed to be inde-

pendent, that            is not a deterministic function of the initial d 1 . We invoke (a) and (c) of

Proposition 8.1 in Roitershtein (2007): Condition 1.6,    (K1 (d0 ) + K 1 (d0 ) = 0) = 1, holds
                                                                  h        i
if and only if there exists there exists a measurable function : 1 a ; 1 a ! R such that



                                  P(          0   +    0   ( d   1   + "0 ) =       (d 1 )) = 1:



However



 0   +    0   ( d   1   + "0 ) = gd   1   d       1   + gd 1 "0 + 1          gd2 1 + g d        1   ( d   1   + "0 )   ( d   1   + "0 )



is a random variable that depends on "0 while                             (d 1 ) is a constant, so



                                  P(          0   +    0   ( d   1   + "0 ) =       (d 1 )) < 1



and Condition 1.6 in Roitershtein (2007) cannot hold. Then from Roitershtein (2007) Propo-

sition 1.8 (c), K1 (d0 ) and K            1   (d0 ) are not both zero.20

       The Proposition above characterizes the tail of the stationary distribution of                                             as a

power tail with exponent . It follows that the distribution of                                      has moments only up to

the highest integer less than , and is a ‘fat tailed’distribution rather than a Normal. The

results are driven by the fact that the stationary distribution of f t gt2N has a mean less

  20
     In models where the driving stochastic process is iid or is a …nite stationary Markov chain, the exponent
  can be analytically derived using the results of Kesten (1973) and Saporta (2005 ). In the case where is
iid in equation (14), solves E ( ) = 1. In the …nite Markov chain case, under appropriate assumptions,
  solves & (P A ) = 1 where P is the transition matrix, A is a diagonal matrix of the states of the Markov
chain assumed to be non-negative, and & (P A ) is the dominant root of P A .


                                                                     17
than one, which tends to induce a contraction towards zero, but also has support above 1

with positive probability, which tends to generate divergence towards in…nity. The stationary

distribution arises out of a balance between these two forces. Then large deviations as strings

of realizations of    t   above one, even though they may be rare events, can produce fat tails.

       In the asset price model    relates the dividends to asset prices. Under adaptive learning,

the results above show how the probability distribution of large deviations, or ‘escapes’of

from its REE value is characterized by a fat tailed distribution, and will occur with higher

likelihood than under a Normal.21

       We now brie‡y discuss the case where fdt gt is an M A(1) process. Proposition 1 still

applies and we obtain similar results to the AR(1) case. Let



                                  dt = "t + "t 1 ; j j < 1; t = 1; 2:::                               (31)



Then at its stationary distribution dt 2 [ a (1 + ) ; a (1 + )]. Under the PLM



                                             pt =      0t "t   +   1t "t 1 ;                          (32)



after observing "t at time t but not          1t+1 ,   the agents expect



                              Et (pt+1 ) =    0t Et ("t+1 )    +     1t Et ("t )   =   1t "t :        (33)

  21
    In the model of Cho et al. (2002), the monetary authority has a misspeci…ed Philips curve and sets
in‡ation policy to optimize a quadratic target. The learning algorithm using a constant gain however is not
linear in the recursively estimated parameters (the natural rate and the slope of the Philips curve).




                                                          18
Then the ALM is



                         pt =    1t "t   + ("t + "t 1 ) = [              1t    + ] "t +       "t   1




and the REE is given by



                                               0   =        (1 +         );                                         (34)

                                               1   =         :                                                      (35)



Under the learning algorithm in equation (13) we obtain



                                  1t     =     1t 1   + gdt 1 (pt              1t 1 dt 1 );                         (36)

                                1t+1     =     t+1 1t   +        t+1 ;                                              (37)

                                 t+1     = 1       gd2t + g "t+1 dt ;                                               (38)

                                 t+1     = g "t+1 dt +              gdt "t :                                        (39)



It is straightforward to show that at the stationary distribution of f t gt , E ( t ) < 1, and
                                                                                                            0:5
that P (   t   > 1) > 0. It is also easy to check that             t   > 0 if a < ((1 + )(1 +          ))         . With

the latter restriction, it is easy to check that the other conditions in the proof of Proposition

1 are satis…ed.




                                                        19
4.        Model Simulations and Comparative Statics

       The theoretical results above indicate that, in the context of a simple asset pricing model,

rare but large shocks to the exogenous dividend process can throw o¤ forecasts for the price-

dividend ratio away from its rational expectation value. Of course escapes are more likely

if the variance of the shocks to dividends are high. More critically, escapes in the long-run

are possible if agents put a large weight on recent observations and discount older ones.

The decay of the weights on past observations depends on the gain parameter g.22 The

size of the Bayesian optimal g will in turn depend on the drift that agents expect in the

estimated parameter . We will estimate g in the next section, both directly, and also from

the perspective of Bayesian agents expecting a random walk drift in .

       In this section we explore how    is related to the underlying parameters of our model. We

can simulate the learning algorithm that updates , and then estimate           from the simulated

data using a maximum likelihood procedure following Clauset et al. (2009). We can then

explore how          varies as we vary model parameters. We simulate 1000 series, each of length

5000, for      t   under the AR(1) assumption for dividends with iid uniform shocks. We then

feed the simulated series into the model to produce fPt g and fPt =Dt g. We estimate             for

each simulation and produce an average .

       Escapes or large deviations in prices will take place when sequences of consistently large

shocks to dividends (in absolute value) throw o¤ the learning process away from the rational

expectations equilibrium. Such escapes will be more likely if dividend shocks can produce

  22
    Under constant gains the decay in weights on past observations dating i periods back is given by
      i 1
(1 g) . Note of course that the value of g computed with annual data would be larger than the corre-
sponding g if the data were converted to quarterly.




                                                  20
values of       t   above 1, as we can see from equations (14-16). We expect lower , or fatter tails,

as the support of          t   that lies above 1 gets larger.

       In the AR(1) case for dividends we have              t+1   =1    (1     )gd2t + gdt "t+1 . Given the

stationary distribution of fdt gt and that of f"t gt , the support of             t   above 1 unambiguously

increases if          increases. In principle increasing          can have an ambiguous e¤ect: while the

term (1             ) declines and tends to raise    t   for realizations of dt and "t+1 , the support of the

stationary distribution of fdt gt gets bigger with higher . While this can increase (1                  )gd2t

and reduce the support of             that is above 1 for large realizations of d2t , in our simulations the

former e¤ect seems to dominate. Finally we expect that decreasing g will shrink the support

of     t   that is above 1 so that       increases with g: as the gain parameter decreases, the tails of

the stationary distribution of f t g get thinner.23

       We use a baseline parameterization, ( ; g; ; ) = (0:80; 0:4; 0:95; 2:5) based on estimates

that we obtain in the next section. The estimated parameters, except for g, are in line with

standard calibrations. The discount factor of                  = 0:95 is consistent with annual data and an

annual discount rate of about 5%. While empirical estimates of g are hard to come by, the

usual values of g used in theoretical models are much smaller, in the order of 0:01 or 0:04,

suggesting a very slow decay in the weights attached to past observations. Values of g in the

range of 0:3-0:5 indicate a high decay rate, suggesting a propensity for the agents to think

that “this time it’s di¤erent”. As noted above, we attempt to estimate g in the context of

  23
     This of course is in accord with the Theorem 7.9 in Evans and Honkapohja (2001). As the gain parameter
g ! 0 and tg ! 1, f gt {g =g 0:5 converges to a Gaussian variable where { is the globally stable point of
the associated ODE describing the mean dynamics. More generally, as g ! 0, the estimated coe¢ cient under
learning with gain parameter g, gt , converges in probability (but not uniformly) to { for t ! 1. However,
there will always exist arbitrarily large values of t with gt taking values remote from { (see Benveniste et
al. (1980), pp. 42-45). Note however that our characterization of the tail of the stationary distribution of
f t gt and of is obtained for …xed g > 0.



                                                          21
our model by two separate methods in the next section. However, as the comparative statics

in Figure 2 below demonstrate, for the learning model to explain the fat tails and the high

variance of the P=D ratio, the gain parameter has to be large enough. This also implies, as

discussed further in the next section, that the expected drift in the estimated parameters

should have a large variance.

       For a parametrization based on the asset pricing model, we set the value of a = 0:33

to match the standard deviation of linearly detrended dividends in the data. We …nd that

the average      is 5:0210, the average price-dividend ratio (Pt =Dt ) is 20:6274 and the average

standard deviation of (Pt =Dt ) is 9:8934. We then vary each element of ( ; g; ; ; ) while

keeping the others at their baseline values. The results of varying each parameter around

the baseline values are plotted in Figures 1 and 2 below.24




                                   Figure 1. Simulation Results.

  24
    The restriction given by equation (17) implies a maximum value of a = a  ^ = 4:2733, the corresponding
value for quarterly data would be 3:9933 (see the Quarterly Frequency Results Appendix). For all parameter
values used to produce Figures 1 and 2, the restriction is easily satis…ed.



                                                   22
                           Figure 2. Simulation Results (cont’d.).


     The simulation results con…rm the notion that the average ’s should decline with ,

and a. Figure 2 plots the results of the critical learning parameter g; it clearly demonstrates

that as the learning gain falls, that is, the horizon for learning increases, the average

rises. In summary, SGCG learning leads to large deviations of (Pt =Dt ) from its rational

expectations value even though the exogenous driving process for dividends is thin-tailed.




5.      An Empirical Application

     Figures 3-4 plot aggregate annual stock prices and dividends in the U.S. as measured by

the S&P 500 and CRSP datasets. The plots show that, as predicted by standard theory,

prices and dividends do move in tandem. However the price-dividend ratio, shown in the

third panel of each Figure, exhibits large ‡uctuations, especially in the latter parts of the




                                              23
sample.25 These large ‡uctuations in the price-dividend ratio are di¢ cult to explain with

the standard rational expectations asset pricing model, for example that of Lucas (1978).26




                              Figure 3. Annual S & P 500 (1871-2010).




                                Figure 4. Annual CRSP (1926-1998).

      We …rst check whether real world data on price-dividend ratios have fat tails. We use

the maximum likelihood procedure following Clauset et al. (2009) to estimate        associ-
 25
      Details on the data employed are presented in the Data Appendix.
 26
      See for example Carceles-Poveda and Giannitsarou (2008).

                                                    24
ated with Pt =Dt for both S&P 500 and CRSP dividend series plotted in Figures 3 and 4

above. The results provided in Table 1 below show fairly small values of              for both series,

suggesting that only the …rst few moments of Pt =Dt exist irrespective of the data source.

Table 1 also reports the estimated persistence            under an AR(1) speci…cation for the two

linearly detrended dividends series, alongside the average price-dividends ratio (Pt =Dt ) and

its standard deviation.27


                                        Table 1. Data Characteristics

                                                     S & P 500     CRSP

                                                     1871-2010   1926-1998

                           b                           3.6914      5.5214

                           s:e:(b)                     0.3828      2.6046

                           b                           0.7891      0.7519

                           s:e:(b)                     0.0523      0.0777

                           Mean (Pt =Dt )             25.5211      26.1805

                           Std. Dev. (Pt =Dt )        13.1758      9.3298

                           Corr (Pt =Dt )              0.9438      0.7872

                                   Dt
                           r=      Pt
                                                       0.0336      0.0360

                                               1
                               = (1 + r=4)             0.9917      0.9911

                               d                       0.1892      0.1649

  27
    Whenever we employ actual dividends series, we linearly detrend (see DeJong and Dave (2011)). Note
also that the dividends data have a higher standard deviation than that which is obtained only with post
WWII data. This is because our data series also capture the Great Depression, and in the case of the S&P
500, the higher volatility in stock prices subsequent to the U.S. Civil War.




                                                     25
       We use two separate approaches to get estimates for the gain parameter g. First we

feed the actual S&P and CRSP dividend series into our learning model and estimate the

parameters, # = [g           ] by minimizing the squared di¤erence between the empirical ’s

reported in Table 1 and those generated by our model. That is, we implement a simulated

minimum distance method to estimate # as28



                                         min [        (#)]2 :                                   (40)
                                           #




       This estimation process necessarily puts a great deal of emphasis on the tail of the

empirical data given by . Since the puzzle lies in the fat tail and high variance of P=D,

emphasizing the tail in the estimation method may be justi…ed. The parameter estimates

other than g are certainly in line with basic calibrations in the literature, but the value of

g, as expected from our model, is higher than the usual values of 0:01-0:04 that we …nd in

the literature.

       The minimization procedure is as follows. For candidate parametrizations of # we employ

the S&P 500 or CRSP series dividends dt to calculate            t   as per (14)-(16). The ALM (10)

then produces a corresponding pt series which in turn delivers a price-dividend ratio Pt =Dt .

We then estimate the       associated with the ‘simulated’Pt =Dt , using the methods of Clauset

et al. (2009) to produce the (#). The minimization procedure searches over the parameter

space of # to implement (40). Table 2 below reports the estimates and associated standard

errors for each of the S&P 500 or CRSP dividend series. We also report associated             values

  28
    Minimization was conducted using a simplex method and standard errors were computed using a stan-
dard inverse Hessian method.




                                                 26
obtained by simulating prices using the estimated parameters and the actual dividend data.29


                                     Table 2. Parameter Estimates

                                            S & P 500                   CRSP

                     Parameter        Estimate Std. Err. Estimate Std. Err.

                     g                 0.3468       2.7158       0.5257       0.4722

                                       2.6503       1.7481       2.4598       0.6259

                                       0.9615       0.3870       0.8984       0.4576

                                       0.8729       0.0552       0.7959       0.1355

                     Associated               2.4128                    5.5214

      The point estimates of g, ranging from 0:35 to 0:53 are high, although the standard

errors are quite large, especially in the case of the S & P 500 dataset. The high estimates

for the gain parameter g, which imply a fat tail for the price dividend ratio, re‡ect the fat

tail (or low ) that we observe in the data in Table 1, as expected. Standard errors are

signi…cantly smaller when we construct and use longer quarterly data.30 Carceles-Poveda

and Giannitsarou (2008) discuss possible values of g. Looking at standard deviations of

the price-dividend ratios for the Lucas asset pricing model, they report that the standard

deviations generated by the rational expectations or the learning models are smaller than the

standard deviations in the actual data by factors of about 20 to 50. Note that our estimates

of the parameter values, including g, are very close to those used by Carceles-Poveda and

Giannitsarou (2008) in their simulations except for , the CRRA parameter: they set

= 1 while we have it at           = 2:5. Note also that for our simulations in Figure 1            drops

 29
      Starting values for the minimization procedure were #0 = [0:5 2:5 0:95 0:75].
 30
      Table 5 in the Quarterly Frequency Results Appendix provides estimates for quarterly data.

                                                     27
dramatically with .

       For our second approach to pin down the gain parameter we let the agent optimally

determine g by estimating the standard deviations of the parameter drift, the noise in the

P=D ratio, and the shock to the dividend process.31 Recall that under SGCG learning                                             t


evolves as

                               t   =    t 1   + gdt 1 (pt             t 1 dt 1 );        g 2 (0; 1)                          (41)


Consider the case in which the agents assume that the PLM is



                                                                                2            2
                             pt =      t 1 dt 1   + t;       t        iid(0;        );           < +1                        (42)



with the coe¢ cient        drifting according to a random walk:



                                                                           2             2
                               t   =    t 1   +   t;     t       iid(0;        );            < +1:                           (43)



In this case, the Bayesian agent would use (41) to estimate                                      ,   d   and   and set an optimal

estimate of the gain in the limit as
                                                                       d
                                                       g=                                                                    (44)


where      d   denotes the standard deviation of dt (see Evans et al (2010)). Under this approach,

the long-run value of g that generates fpg and f g under adaptive learning would be self-

con…rming, in the sense that agents would in fact estimate g using (44).

  31
   See Sargent et al. (2006) and others for a more complex version of this approach for models requiring
dynamic tracking estimation.




                                                                 28
       To compute (44) an estimate of       d   is of course readily obtained from the dividend data.

However we need to specify a method for the agents to compute estimates of                       and     . If

we recognize the system above as being analogous to a time varying parameter formulation,

then employing the methods laid out in Kim and Nelson (1999) we can obtain estimates of

       and   .32 We report these results in Table 3 below.


                         Table 3. Drifting Beliefs Model Parameter Estimates

                                           S & P 500                     CRSP

                    Parameter        Estimate Std. Err. Estimate Std. Err.

                                       0.8122        0.7718       0.8588       0.2963

                                       0.3157        0.0230       0.2596       0.0291

                    log L                   -61.4102                    -17.5256

                     d                          0.1892                   0.1649

                    Associated g                0.4866                   0.5455

       These estimates suggest values of the gain signi…cantly larger than those usually assumed

in the literature.33 Looking at Figure 2, a value of g = 0:4866 yields a tail estimate             of about

4:9 while a value of g = 0:5455 yields a           of about 4:75, compared to        in the data ranging

from 3:7 to 5:5 in Table 1. We also simulated the model with baseline parameter values but

with gains of 0:4866 and 0:5455. These simulations resulted in average price-dividend ratios

of 20:6324 and 20:6965 respectively with corresponding standard deviation values of 10:0051

and 10:5870.
  32
     Given our estimate of = 0:95 we convert the CRSP data to annual, summing dividends quarterly
dividends for each year. For the S&P 500 we use the annual data reported by Shiller (1999), pp.439-441.
  33
     We also apply block bootstrap methods to this estimation, detailed at the end of the Quarterly Frequency
Results appendix. These methods allow us to construct average associated g’s with attendant standard
deviations, instead of the associated g in the last row of Table 3.

                                                     29
       Finally, instead of using actual P and D data series, we generate data by simulating

our model with our benchmark values ( ; g; ; ) = (0:80; 0:4; 0:95; 2:5), and then compute

g from (44) using the methods in Kim and Nelson (1999) to check that we recover a value

close to 0:4.34 The average g is 0:3826, which is quite close to and con…rms the benchmark

value of g = 0:4 that we used in generating the simulated data. In fact we conducted these

simulations for a range of values of the gain parameter and then computed the associated

average g value. Our prior was that the resulting plot would intersect near a gain value

which was near g = 0:4; we provide the plot in Figure 5 below and note that our prior was

con…rmed.




                                   Figure 5. Fixed Point Plot.

  34
    We run 1000 simulations each with 5000 periods, and obtain the average g from (44) across the 1000
simulations.




                                                 30
     Given these results, we o¤er a caveat with respect to interpretation of the large gain

parameter estimates that we …nd. One approach is to say that the model with SGCG

learning does very well in matching features of the data given the gain parameter estimates.

Alternatively one could argue that absent large estimates for the gain, the model does not

do well in matching asset pricing facts. We prefer the former interpretation given that it is

entirely reasonable to interpret our empirical exercise as suggesting that heavily discounting

past observations is consistent with market participants’ behavior. With annual data the

estimates suggest market participants’horizon for learning is about 2-3 years which is not

entirely unreasonable given the frequent swings in the data.




6.      Conclusion

     An important and growing literature replaces expectations in dynamic stochastic models

not with realizations and unforecastable errors, but with regressions where agents ‘learn’

the rational expectations equilibria (REE). In these adaptive learning models when agents

employ constant gain algorithms that put heavier emphasis on recent observations and shown

to be optimal when there is drift in estimated parameters, escape dynamics can propel

estimated coe¢ cients away from the REE values. We show that in a constant gain adaptive

learning model, the stationary distribution of the variables that agents are learning can be

fat tailed, and that the tail index of this distribution can be characterized in terms of the

parameters of the model.

     We then analyze, in an asset pricing context, the stationary distribution of the price-

dividend ratio in a canonical model with constant gain adaptive learning. We reinterpret


                                             31
the learning algorithm as a linear recursion with multiplicative noise and use techniques

from large deviations theory to characterize the tail of the stationary distribution of the

price-dividend ratio.

      In an asset pricing context ‘bubbles’, or asset price to dividend ratios that exhibit large

deviations from their REE values (even though our model has presumed a no-bubble con-

dition) can occur with a frequency associated with a fat tailed power law, as observed in

the data. The techniques used in our paper can be generalized to higher dimensions, to

…nite state Markov chains, to continuous time,35 and can be applied more generally to other

economic models that use constant gain learning.




 35
      See for example Saporta (2005), Saporta and Yao (2005), and Ghosh et al. (2010).


                                                    32
References

[1] Adam, K., Marcet, A., and J. P. Nicolini, 2008. “Stock Market Volatility and Learning,”

   European Central Bank Working Paper Series, No. 862.


[2] Adam, K. and Marcet, A., 2011. “Internal Rationality, Imperfect Market Knowledge

   and Asset Prices,”Journal of Economic Theory, 146, 1224-1256.


[3] Alsmeyer, G, 1997. “The Markov Renewal Theorem and Related Results,” Markov

   Process Related Fields 3 103–127.


[4] Barro, R. J, 2009. “Rare Disasters, Asset Prices, and Welfare Costs,” American Eco-

   nomic Review, 99:1, 243–264.


[5] Benhabib, J. Bisin, A. and S. Zhu, 2011. “The Distribution of Wealth and Fiscal Policy

   in Economies with Finitely Lived Agents,”Econometrica 79, 123-158.


[6] Benhabib, J., 2010. “A Note Regime Switching, Monetary Policy and Multiple Equilib-

   ria,”NBER Working Paper No. 14770.


[7] Benveniste, A., Métivier, M. and P. Priouret, 1980. Adaptive Algorithms and Stochastic

   Approximations, Springer-Verlag, New York.


[8] Branch, W., and Evans, G. W., 2010, “Asset Return Dynamics and Learning,”Review

   of Financial Studies, 1651-1680.


[9] Brandt, A., 1986. “The Stochastic Equation Yn+1 = An Yn + Bn With Stationary Coef-

   …cients,”Advances in Applied Probability, 18, 211–220.



                                           33
[10] Brennan, M. J., Xia, 2001. “Stock Price Volatility and Equity Premium,” Journal of

    Monetary Economics, 47, 249-283.


[11] Bullard, J., Du¤y, J., 2001. “Learning and Excess Volatility,”Macroeconomic Dynamics

    5, 272-302.


[12] Campbell, J. Y., 2003. “Consumption-Based Asset Pricing,”Handbook of the Economics

    of Finance, George Constantinides, Milton Harris, and Rene Stulz eds., North-Holland,

    Amsterdam.


[13] Carceles-Poveda, E., Giannitsarou, C., 2007. “Adaptive Learning in Practice,”Journal

    of Economic Dynamics and Control 31, 2659-2697.


[14] Carceles-Poveda, E., Giannitsarou, C., 2008. “Asset Pricing with Adaptive Learning,”

    Review of Economic Dynamics 11 629–651.


[15] Chevillon,   G.,   Mavroeidis,    S.,        “Learning   Generates   Long   Memory,”

    http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1969602


[16] Cho, I-K., Sargent, T. J., Williams, N., 2002. “Escaping Nash In‡ation,” Review of

    Economic Studies 69, 1-40.


[17] Clauset, A., Shalizi, C. R. and M. E. J. Newman, 2009. “Power-law Distributions in

    Empirical Data,”SIAM Review 51(4), 661-703


[18] Collamore, J. F. , 2009. “Random Recurrence Equations and Ruin in a Markov-

    Dependent Stochastic Economic Environment,”Annals of Applied Probability 19, 1404–

    1458.


                                             34
[19] Cogley, T. and Sargent, T. J., 2008. “The Market Price of Risk and the Equity Premium:

    A Legacy of the Great Depression?,”Journal of Monetary Economics, 55, 454–476.


[20] DeJong, D. N. and C. Dave, 2011. Structural Macroeconometrics, 2nd Ed., Princeton

    University Press.


[21] Evans, G., Honkapohja, S., 1999. “Learning Dynamics,”Handbook of Macroeconomics,

    Vol.1, eds. J. Taylor and M. Woodford, 1999, North-Holland, pp.449-542.


[22] Evans, G., Honkapohja, S., 2001. Learning and Expectations in Macroeconomics. Prince-

    ton University Press.


[23] Evans, G., Honkapohja, S., and N. Williams, 2010. “Generalized Stochastic Gradient

    Learning,”International Economic Review, 51, 237-262.


[24] Gabaix, X., Gopikrishnan, P., Plerou, V. and Stanley, H. E., 2006. “Institutional In-

    vestors and Stock Market Volatility,”Quarterly Journal of Economics, 121 (2), p. 461-

    504.


[25] Gabaix, X., 2009. “Power Laws in Economics and Finance,” Annual Review of Eco-

    nomics, 1, p. 255-93.


[26] Ghosh, A. P, Haya, D., Hirpara, H., Rastegar, R., Roitershtein, A.,Schulteis, A., and

    Suhe, J, 2010. “Random Linear Recursions with Dependent Coe¢ cients,”Statistics and

    Probability Letters 80, 1597 1605.


[27] Holmstrom, B., 1999. “Managerial Incentive Problems: A Dynamic Perspective,” The

    Review of Economic Studies, 66, 169-182.


                                            35
[28] Hollander, F. den, (2000), Large Deviations, Fields Institute monographs,American

    Mathematical Society, Providence, Rhode Island.


[29] Kesten, H., 1973. “Random Di¤erence Equations and Renewal Theory for Products of

    Random Matrices,”Acta Mathematica. 131 207–248.


[30] Koulovatianos, C. and V. Wieland, 2011. “Asset Pricing under Rational Learning about

    Rare Disasters,”Manuscript.


[31] Loeve, M. 1977. Probability Theory, 4th Ed., Springer, New York.


[32] Lucas, R. E. Jr., 1978. “Asset Prices in an Exchange Economy,”Econometrica, Vol. 46,

    No. 6. (Nov., 1978), pp. 1429-1445.


[33] Nummelin, E., 1984. General irreducible Markov chains and non-negative operators.

    Cambridge Tracts in Mathematics 83, Cambridge University Press.


[34] Petritis, D., Markov Chains on Measurable Spaces. Université de Rennes, UFR Mathé-

    matiques. perso.univ-rennes1.fr/dimitri.petritis/.../markov/markov.pdf.


[35] Roitershtein, A., 2007. “One-Dimensional Linear Recursions with Markov-Dependent

    Coe¢ cients,”The Annals of Applied Probability, 17(2), 572-608.


[36] Saporta, B., 2005. “Tail of the Stationary solution of the Stochastic equation Yn+1 =

    an Y n +   n   with Markovian Coe¢ cients,” Stochastic Processes and their Applications,

    115(12), 1954-1978.


[37] Saporta, B. and Yao, J-F, 2005, “Tail of a Linear Di¤usion with Markov Switching,”

    The Annals of Applied Probability, 992–1018.

                                              36
[38] Sargent, T. J., 1999. The Conquest of American In‡ation. Princeton University Press.


[39] Sargent, T. J. and Williams, N., 2005. “Impacts of Priors on Convergence and Escape

    from Nash In‡ation,”Review of Economic Dynamics, 8(2), 360-391.


[40] Shiller, R. J., 1999, Market Volatility, 6th printing, MIT Press, Cambridge.


[41] Shiller, R. J., 2005. Irrational Exuberance, 2nd edition, Broadway Books.


[42] Timmermann, A. 1993, “How Learning in Financial markets Generates Excess Volatility

    and Predictability in Stock Prices,”Quarterly Journal Economics,108,1135–1145.


[43] Timmermann, A. 1996, “Excess Volatility and Predictability of Stock Prices in Autore-

    gressive Dividend Models with Learning,”Review of Economic Studies, 63, 523–557.


[44] Weitzman, M. L. 2007. “Subjective Expectations and Asset-Return Puzzles,”American

    Economic Review, 97, 1102–1130.




                                             37
7.   Data Appendix

 1. Annual S&P 500 Dataset from Professor Shiller’s website (see Shiller (2005))


     (a) The following time series are extracted/constructed for 1871 through 2009 (note

         that t = 1; : : : T where T = 2009:12):

           i. Extract S & P Comp (Pe(t)).

                                e
          ii. Extract Dividend (D(t)).

         iii. Extract Consumer Price Index (CP I(t)).

         iv. Construct Real Price (P (t)) as P (t) = [Pe(t)    CP I(T )]=CP I(t).

                                                       e
          v. Construct Real Dividend (D(t)) as D(t) = [D(t)        CP I(T )]=CP I(t).

     (b) Construct the Price to Dividends Ratio (ratio) as P (t)=D(t).


 2. Quarterly CRSP Dataset


     (a) Download the quarterly data from http://scholar.harvard.edu/campbell/data ac-

         cessed from Professor Campbell’s website, where the particular data being used is

         associated with “Replication Data for: Consumption Based Asset Pricing”. The

         relevant …le is titled USAQE.ASC, note that this is e¤ectively a CRSP dataset

         with the relevant variables being VWRETD and VWRETX. The text below is

         an extract from the explanations for this dataset on the above website.

     (b) The following quarterly time series are extracted/constructed for 1926.1 through

         1998.4 from the above dataset (note that t = 1; : : : T where T = 1998:4):

           i. Extract Col. 2: Pe(t). For each month, the price index is calculated as

             Pe(t) = (V W RET X(t) + 1)      Pe(t   1). (Note that time t in this equation is

                                            38
   in months.) The price index for a quarter, as reported in this column, is the

   price index for the last month of the quarter. The original data, which goes

   up to 1996.4 was not altered. The new data, which goes up to 1998.4, was

   created as described here starting from 1997.1.

                    e
ii. Extract Col. 3: D(t). Dividend in local currency, calculated as follows. The

                                                  g (t) = [1+V W RET D(t)]=[1+
   dividend yield for each month is calculated as DY

   V W RET X(t)] 1. Note that if the return index is calculated from V W RET D

   as above, then this formula agrees with the formula for the dividend yield

                                                                          e =
   given earlier. As before, the dividend for each month is calculated as D(t)

   g (t)
   DY         Pe(t). The dividend for a quarter, as reported in this column, is the

   sum of the dividends for the three months comprising the quarter.

iii. Extract the Consumer Price Index from Shiller’s Monthly Data (CP I(t))

   which is monthly and associate the last month of a quarter as a quarterly

   CP I(t).

iv. Construct Real Price (P (t)) as P (t) = [Pe(t)    CP I(T )]=CP I(t). Take the

   last price of a quarter as the annual price.

                                      e
v. Construct Real Dividend (D(t)) as [D(t)        CP I(T )]=CP I(t) and then take

   quarterly sums to get D(t) at an annual frequency.

vi. Construct the Price to Dividends Ratio (ratio) as P (t)=D(t).




                                  39
8.      Quarterly Frequency Results

     We also considered quarterly versions of the data. Quarterly data for the S&P 500 were

constructed from the monthly series reported by Professor Shiller on his website. Quarterly

data for the CRSP series were directly available from the data website maintained by Pro-

fessor Campbell (Campbell (2003)). The plots, analogous to Figures 3 and 4 in the text but

for quarterly data are as follows.




                        Figure 6. Quarterly S & P 500 (1871-2010).




                                             40
                          Figure 7. Quarterly CRSP (1926-1998).

   Both datasets indicate that at the quarterly frequency the price-dividends ratio is quite

volatile, just as in the case with annual data discussed in the text. Next, we employed a

baseline parameterization of ( ; g; ; ) = (0:98; 0:5; 0:99; 2:5) consistent with quarterly data

(e.g. a   = 0:98) and conducted the same simulations as reported in the text above, the

plots, analogous to Figures 1 and 2 in the text, are as follows.




                                Figure 8. Simulation Results.




                                              41
                             Figure 9. Simulation Results (cont’d.).


   Next, our minimum distance estimates analogous to those Tables 1-3 in the text, except

employing quarterly data, are as follows.


                         Table 4. Data Characteristics (Quarterly Data)

                                           S & P 500             CRSP

                                       1871QI-2010QIV 1926QIV-1998QIV

                b                            3.5800              6.9894

                s:e:(b)                      0.2695              1.3133

                b                            0.9826              0.9749

                s:e:(b)                      0.0078              0.0126

                Mean (Pt =Dt )              26.5882             26.0243

                Std. Dev. (Pt =Dt )         13.7369              8.7640

                Corr (Pt =Dt )               0.9882              0.9456

                        Dt
                r=      Pt
                                             0.0322              0.0363

                                  1
                    = (1 + r=4)              0.9920              0.9910

                    d                        0.1836              0.1627

                        Table 5. Parameter Estimates (Quarterly Data)




                                               42
                                        S & P 500               CRSP

                                     1871QI-2010QIV       1926QIV-1998QIV

                Parameter           Estimate Std. Err. Estimate Std. Err.

                g                    0.1585     0.0249     0.3746     0.1737

                                     9.1957     0.1194     1.3088     0.1738

                                     0.9975     0.0008     0.9974     0.0001

                                     0.9895     0.0015     0.9592     0.0002

                Associated                3.5800                6.7959

                        Table 6. Drifting Beliefs Model Parameter Estimates

                                        S & P 500               CRSP

                                     1871QI-2010QIV       1926QIV-1998QIV

                Parameter           Estimate Std. Err. Estimate Std. Err.

                                     0.3603     0.1550     1.0114    0.3432

                                     0.3655     0.0431     0.3032    0.0819

                log L                    -142.2726             -38.9385

                    d                     0.1836                0.1627

                Associated g              0.1810                0.5427

   The main results from employing data at a quarterly frequency are twofold. First, while

the gain estimates reported in Table 5 fall, it still remains the case that the data exhibit

fat tails. This is expected since the data are now at a quarterly frequency. A higher gain

or shorter memory with annual data does indeed correspond to a lower gain and longer

memory with quarterly data since the de…nition of the learning horizon (the inverse of the


                                                43
gain) changes from years to quarters. Second, employing data at a quarterly frequency leads

to the structural estimates (as reported in Table 5) being estimated with greater precision.

In fact with more data the surface over which a minimum is sought in the minimum distance

estimation procedure is sharply de…ned, leading to the increased precision of the estimates.

In contrast to Table 5 however, for Table 6 the CRSP data employed in the drifting beliefs

speci…cation lead to a larger than expected gain. This is driven by a much higher estimate

for      relative to the annual data.

      Finally, we also implemented a block bootstrap in estimating the drifting beliefs model.

That is, we used a block bootstrap to generate 1000 samples from the data, each of which was

used to estimate the parameters of a drifting beliefs model with an attendant computation of

g from equation (44), for example, as reported in the last row of Table 6. This yielded 1000

estimates of g for which we then computed the mean and standard deviation. Such estimates

yielded a mean (standard deviation) of g of 0.5080 (0.1777) using quarterly CRSP data and

a mean (standard deviation) of g of 0.6114 (0.1362) when using S&P 500 data. With annual

data the estimates of g were 0.2095 (0.1788) using CRSP data and 0.2196 (0.1788) using

S&P 500 data. Thus, with quarterly data using the minimum distance method or, using

bootstraps with either quarterly or annual data, the estimates of g were sharper and the

standard errors fell.




                                               44
