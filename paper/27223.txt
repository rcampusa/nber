                               NBER WORKING PAPER SERIES




                            VOLUNTARY REGULATION:
                    EVIDENCE FROM MEDICARE PAYMENT REFORM

                                          Liran Einav
                                         Amy Finkelstein
                                           Yunan Ji
                                         Neale Mahoney

                                       Working Paper 27223
                               http://www.nber.org/papers/w27223


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                                     May 2020




We thank Parag Pathak, Jonathan Skinner, and participants in many seminars for helpful
comments, and Sophia Mo and Xuyang Xia for outstanding research assistance. We gratefully
acknowledge support from J-PAL North America’s Health Care Delivery Initiative (Finkelstein
and Mahoney), the National Institute of Aging grant P01AG019783-15, the Laura and John
Arnold Foundation (Einav, Finkelstein and Mahoney), the Becker Friedman Institute at the
University of Chicago (Mahoney) and the National Science Foundation SES-1730466
(Mahoney). The views expressed herein are those of the authors and do not necessarily reflect the
views of the National Bureau of Economic Research.

At least one co-author has disclosed a financial relationship of potential relevance for this
research. Further information is available online at http://www.nber.org/papers/w27223.ack

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2020 by Liran Einav, Amy Finkelstein, Yunan Ji, and Neale Mahoney. All rights reserved.
Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including © notice, is given to the source.
Voluntary Regulation: Evidence from Medicare Payment Reform
Liran Einav, Amy Finkelstein, Yunan Ji, and Neale Mahoney
NBER Working Paper No. 27223
May 2020
JEL No. H51,I13,I18

                                          ABSTRACT

Government programs are often offered on an optional basis to market participants. We explore
the economics of such voluntary regulation in the context of a Medicare payment reform, in
which one medical provider receives a single, predetermined payment for a sequence of related
healthcare services, instead of separate service-specific payments. This ``bundled payment''
program was originally implemented as a 5-year randomized trial, with mandatory participation
by hospitals assigned to the new payment model, but after two years participation was
unexpectedly made voluntary for half of these hospitals. Using detailed claim-level data, we
document that voluntary participation is more likely for hospitals who can increase revenue
without changing behavior (“selection on levels”) and for hospitals that had large changes in
behavior when participation was mandatory (“selection on slopes”). To assess outcomes under
counterfactual regimes, we estimate a simple model of responsiveness to and selection into the
program. We find that the current voluntary regime generates inefficient transfers to hospitals and
reduces social welfare compared to the status quo, but that alternative (feasible) designs could
substantially reduce these inefficient transfers. Our analysis highlights key design elements to
consider under voluntary regulation.

Liran Einav                                      Yunan Ji
Stanford University                              Harvard University
Department of Economics                          ji@g.harvard.edu
579 Serra Mall
Stanford, CA 94305-6072                          Neale Mahoney
and NBER                                         Booth School of Business
leinav@stanford.edu                              University of Chicago
                                                 5807 South Woodlawn Avenue
Amy Finkelstein                                  Chicago, IL 60637
Department of Economics, E52-442                 and NBER
MIT                                              Neale.Mahoney@chicagobooth.edu
50 Memorial Drive
Cambridge, MA 02142
and NBER
afink@mit.edu
1   Introduction
Government intervention is designed to move market actors away from market equilibrium. Yet

some government programs allow these actors to voluntarily decide whether they would like to

participate in the program. There are a number of reasons why voluntary programs are popu-

lar. From a political perspective, voluntary programs may face less opposition from industry or

consumer lobbies, since their members need only sign up if they benefit. Voluntary programs

may also be more palatable to those with an ideological aversion to government mandates and a

preference for regulatory “nudges” (Thaler and Sunstein, 2003).

    The key economic benefit of voluntary programs – i.e., “choose your own incentives” – is that

they might generate favorable selection. If actors have private information about their net benefits

from changing behavior, then the resulting “selection on slopes” – also known as selection on gains

or Roy selection (Heckman and Honore, 1990) – might result in selection into the program by those

with the highest net social benefits. However, if voluntary programs attract participants who,

without changing their behavior, can simply receive a higher government transfer, the resulting

“selection on levels” could lead to higher government spending without the desired behavior

change. Thus, the extent to which a voluntary program is more or less socially desirable depends

critically on the nature and extent of selection into the program.

    We explore these tradeoffs in the context of the U.S. Medicare program, the public health

insurance program for the elderly and the disabled. Over the last decade, Medicare has rapidly

expanded the use of alternative models for reimbursing healthcare providers, such as Accountable

Care Organizations, bundled payments, and primary care coordination models. By 2016, over

30% of Traditional Medicare spending was based on alternative payments models (Shatto, 2016).

With the partial exception of the payment model we study, provider participation in all of these

payment models has been voluntary (GAO, 2018). However, there is an ongoing and active debate

over whether these programs should be made mandatory (e.g., Gronniger et al., 2017; King, 2019;

Frakt, 2019b; Levy, Bagley and Rajkumar, 2018; Liao, Pauly and Navathe, 2020).

    We analyze the Medicare bundled payments program for hip and knee replacement, known

as Comprehensive Care for Joint Replacement (CJR). Hip and knee replacement is a large cate-

gory, with almost half a million procedures and $10.7 billion in Medicare spending in 2014. Under


                                                 1
bundled payments, Medicare makes a single payment (known as the target price) to the hospital

for all services related to the episode of care, including the initial hospital stay and physician fees,

as well as any subsequent care by other medical providers during the recovery period. By con-

trast, under the status quo Fee-for-Service (FFS) system, Medicare makes separate payments to

different providers based on the care provided. The idea behind the bundled payments reform is

that by making the hospital the residual claimant on the costs related to the entire episode of care,

it will internalize the incentives to provide care efficiently, including coordination with down-

stream providers. In practice, this was implemented by providing financial bonuses or penalties

– known as “reconciliation payments” – to hospitals when the submitted Medicare FFS claims for

the episode deviated from the target price.

    CJR was initially designed by Medicare administrators as a mandatory participation, 5-year

randomized trial. Randomization was conducted at the Metropolitan Statistical Area (MSA) level.

In the 67 treatment MSAs, hospitals were paid under the bundled payments program. In the

104 control MSAs, hospitals were paid under the status quo FFS system. The program was im-

plemented as designed in April 2016. However, toward the end of the second year of the pro-

gram, Medicare unexpectedly announced that participation would be made voluntary in half the

treated MSAs (CMS, 2017), and about three-quarters of the affected hospitals subsequently opted

out. This unusual set of circumstances provides a rare opportunity to assess a voluntary program

while observing behavior under the program even for participants who eventually choose not to

participate.

    We begin by providing descriptive evidence on the mandatory and voluntary regimes. In

the mandatory regime, we closely follow prior analyses and find that bundled payments caused,

on average, a modest reduction in submitted Medicare claims, driven predominantly by reduced

discharges to post-acute care (PAC) facilities (Finkelstein et al., 2018; Dummit et al., 2018; Barnett

et al., 2019; Haas et al., 2019). Once reconciliation payments were taken into account, however, the

mandatory bundled payment regime had no effective impact on government expenditures. We

then examine the nature of selection into the program once it became voluntary. Consistent with

selection on levels, we find that hospitals with lower claims under FFS – who, holding behavior

constant, would benefit more from bundled payments – are more likely to opt in. Consistent with

selection on slopes, we also find that hospitals that achieved larger reductions in claims under

                                                   2
mandatory bundled payments are more likely to opt in when it becomes voluntary.

    Motivated by these patterns, we specify and estimate a stylized model of responsiveness to

and selection into the bundled payment program. In the model, hospitals are characterized by a

hospital-specific “level” (average claims per episode under FFS incentives) and a hospital-specific

“slope” (the reduction in claims under bundled payments). Under a voluntary regime, the selec-

tion decision depends on the hospital-specific “target price” – the bundled payment the hospital

receives from the government under the program – as well as on the hospital’s level and slope

parameters. The random assignment in years 1-2 of the program, when participation was manda-

tory, identifies the levels and slopes, and the voluntary decision in year 3 identifies the selection

equation.

    We estimate that average episode claims under the status quo FFS incentives would be about

$24,000 and that bundled payments reduced claims, on average, by about $400 per episode. These

averages, however, mask substantial heterogeneity across hospitals in both levels and slopes. Het-

erogeneity is particularly large in levels, where the standard deviation across hospitals in claims

under FFS incentives is about $4,000. Observed target prices do not come close to capturing this

heterogeneity, thus making selection on levels the key driver of the participation decision, once

participation becomes voluntary.

    We use the estimated model to compare outcomes and social welfare under the observed

voluntary and mandatory programs, as well as to assess behavior and social welfare under alter-

native bundled payments designs. We define social welfare as the sum of consumer surplus and

producer (hospital) profits, minus the social cost of public spending. We assume that consumer

surplus is not affected by the payment regime; this is consistent with evidence from the random-

ized trial that healthcare quality, patient mix, and patient volume did not change with bundled

payments (Finkelstein et al., 2018; Dummit et al., 2018; Barnett et al., 2019; Haas et al., 2019). We

define the social cost of public spending as government (i.e., Medicare) spending multiplied by

the shadow cost of public funds, which we assume (conservatively) to be 0.15. This “cost of pub-

lic funds” generates the key tradeoff in designing a voluntary bundled payment model: higher

target prices will induce more hospitals to participate and increase productive efficiency, but will

involve higher government spending, which is socially costly. Producer surplus and government

spending can be calculated directly from the data and estimated model parameters.

                                                 3
    The model estimates, like the reduced form descriptive work, indicate substantial selection on

levels: hospitals that opt into the voluntary bundled payment regime would have had (counter-

factual) average claims per episode under the FFS status quo that were substantially lower than

hospitals which do not opt in. Moreover, the magnitude of the favorable selection (on “slopes”) is

too small to offset it. As a result, we estimate that the voluntary bundled payments regime lowers

social surplus relative to the FFS status quo, due to inefficient transfers from the government to

hospitals.

    We also show that better targeting could improve the net social welfare impact of the volun-

tary regime, by reducing the transfers and aligning better participation incentives. For example,

we estimate that a perfectly targeted voluntary bundled payments regime would raise social sur-

plus relative to the status quo. While perfect targeting may be difficult to achieve in practice, we

show that compared to the observed targeting, other feasible designs – based on better exploiting

existing information or defining the bundle more narrowly – can come close to generating the

social gains from perfect targeting, generating up to three-fifths of the social welfare gains from

perfect targeting.

    Our paper relates to several distinct literatures. Most narrowly, it contributes to the literature

on the impact of Medicare bundled payment programs. This includes several recent evaluations

of the first two years of the program we study, when participation was randomly assigned and

mandatory (Finkelstein et al., 2018; Dummit et al., 2018; Barnett et al., 2019; Haas et al., 2019). It

also includes evaluations of the much larger number of voluntary participation bundled payment

programs for a host of conditions, including coronary bypass, prenatal care, cancer, and hip and

knee replacement.1 It is well understood that non-random selection into voluntary models can

bias the evaluation of these program (e.g., Gronniger et al., 2017; Levy, Bagley and Rajkumar,

2018). Our focus here is on how voluntary participation affects the actual impact of the program,

rather than the estimated impact.

    Within health economics more generally, our work contributes to the growing literature on

the impact and optimal design of financial incentives for healthcare providers (e.g., Cutler, 1995;

Clemens and Gottlieb, 2014; Ho and Pakes, 2014; Einav, Finkelstein and Mahoney, 2018; Eliason
   1 See Cromwell, Dayhoff and Thoumaian (1997), Carroll et al. (2018), Newcomer et al. (2014), Doran and Zabinski

(2015), Dummit et al. (2016), Froemke et al. (2015), Navathe et al. (2017).



                                                        4
et al., 2018). It also relates to work on so-called “selection on moral hazard” – i.e., consumer

selection of health insurance plans based not only on levels but on slopes (Einav et al., 2013, 2016;

Shepard, 2016; Marone and Sabety, 2019); here, we examine selection on moral hazard from the

provider side rather than the consumer side.

      More broadly, our emphasis of the potential for selection not only on levels but also on slopes

relates to work in labor economics on selection on gains (Heckman and Honore, 1990), as well

as to work on selection into voluntary regulation in other sectors. For example, recent work has

analyzed selection by landowners into voluntary incentive programs for providing environmen-

tal services (Jack and Jayachandran, 2019), by polluting firms into whether to pay taxes based on

their disclosed and verifiable emissions or the average emission rate among non-disclosers (Ci-

cala, Hémous and Olsen, 2020), by private schools into whether or not to accept public vouchers

(DeAngelis, Burke and Wolf, 2019), and by residential electricity consumers into whether to face a

constant or time-varying regulated electricity price schedule (Ida, Ito and Tanaka, 2020).

      The rest of the paper proceeds as follows. Section 2 provides background on our setting.

Section 3 describes the data and presents reduced form, descriptive evidence of the impact of

bundled payments under mandatory participation as well as the nature of hospital selection once

the program became voluntary. Section 4 presents a stylized model of selection into a voluntary

bundled payment program. Section 5 presents the econometric specification of the model and

describes its identification and estimation. Section 6 presents our main results. The last section

concludes.


2     Setting

2.1    Medicare Bundled Payment Programs

Medicare is the public health insurance program for the elderly and the disabled in the United

States. We focus on the Traditional Medicare program, which provides coverage to about two-

thirds of enrollees. In 2017, Traditional Medicare (hereafter "Medicare") had 38.7 million enrollees

and annual expenditures of $377 billion (CMS, 2019).

      Throughout most of its history, Medicare has paid providers on a cost-plus basis referred to as

Fee-for-Service (FFS), in which providers are reimbursed based on claims submitted for services.



                                                  5
For instance, for a patient undergoing hip replacement, Medicare might make separate payments

to the hospital for the initial hospital stay, the surgeon for performing the procedure, and the

skilled nursing facility for post-acute care, as well as additional payments for each post-operative

visit by the surgeon, or for renting a wheelchair during the recovery period. Moreover, within

most of these categories, the payment would depend on the specific services provided.2

    Over the last decade, Medicare has responded to concerns that the FFS system may encour-

age excessive healthcare use by attempting to shift providers towards alternative payment models,

such as Accountable Care Organizations (ACOs), bundled payments, and primary care coordina-

tion models. By 2016, over 30% of Traditional Medicare spending was based on these alternative

models (Shatto, 2016).

    Our focus is on bundled payments, which represent a middle ground between FFS and fully

capitated models, such as ACOs, in which providers are paid a fixed per capita amount per

annum. Under bundled payments, Medicare makes a predetermined, single payment to one

provider for all services related to a clearly-defined episode of care. Episodes typically start with

an acute-care hospital stay (e.g., for hip replacement surgery) and include most subsequent care

during the recovery period. The payments are sometimes adjusted to reflect predictable variation

in patient health or in costs in the local medical market. The contracts may also be structured to

limit risk exposure for the hospital.

    Proponents of bundled payments argue that by providing a single, fixed reimbursement, bun-

dled payments will improve coordination of care and reduce unnecessary healthcare utilization.

Yet, some are concerned that because providers do not receive marginal payments, they may cut

back on necessary care or cherry-pick patients who have a lower cost of provision (Cutler and

Ghosh, 2012; Fisher, 2016).

    Most prior studies of bundled payments have been observational, focusing on the experi-

ence of a small number of hospitals that voluntarily participated. Many of these studies have

found large government savings associated with bundled payments (e.g., Cromwell, Dayhoff and

Thoumaian, 1997; Carroll et al., 2018; Newcomer et al., 2014; Doran and Zabinski, 2015; Dum-

mit et al., 2016; Froemke et al., 2015; Navathe et al., 2017). However, voluntary participation
   2 One exception to this system is hospital reimbursements. Starting in 1982, Medicare adopted the Prospective Pay-

ment System (PPS) in which it makes a fixed payment for the hospital stay based on the patient’s diagnosis-related
group (DRG) (Cutler, 1995).


                                                         6
makes separating treatment from selection difficult, and the small number of participating hos-

pitals raises concerns about generalizability (e.g., Gronniger et al., 2017; King, 2019).

2.2       Comprehensive Care for Joint Replacement (CJR)

We focus on the Medicare bundled payment program for hip and knee replacement, known as

Comprehensive Care for Joint Replacement (CJR). Hip and knee replacement (also referred in the

medical literature as lower extremity joint replacement, or LEJR) is a large Medicare category; in

2014, the year before CJR was announced, Medicare had almost half a million LEJR procedures,

accounting for about 5% of Medicare admissions and inpatient spending (Finkelstein et al., 2018).

      Under CJR, an episode begins with a hospital stay in a qualifying diagnosis-related group

(DRG) and ends 90 days after hospital discharge. Medicare pays the hospital a predetermined

target price for the episode. The hospital is then financially responsible for medical claims over

the entire episode (except for care that is deemed as obviously unrelated). By contrast, under

the status quo FFS regime, Medicare pays the hospital a fixed amount for the hospital stay, and

reimburses the surgical procedure and post-discharge care separately based on those providers’

submitted claims.

      The level and targeting of the target price are key design elements in a bundled payment pro-

gram. Let th denote the average per episode target price at hospital h in a given year, and let yh

denote average per-episode claims submitted that year. Under FFS, Medicare pays yh on average.

Under bundled payments, Medicare pays th on average. More specifically, under bundled pay-

ments, providers continue to submit claims and receive reimbursement of yh on average as if they

were under FFS, allowing us to observe yh even under bundled payments. At the end of the year,

hospitals under bundled payments receive a “reconciliation payment” of th − yh per episode, so

that the gross Medicare payment is th .

      Under CJR, Medicare tried to set the target price before each program year to be slightly lower

than expected per-episode claims under FFS.3 To do so, the target price included a small discount

off a weighted average of historical hospital and regional (defined by the 9 census divisions) per-

episode claims from three prior reference years, with the weight on the regional component in-

creased over time from one-third in the first two years of the program to 100% in the last two
   3 Inparticular, Medicare set hospital-specific target prices for four severity groups determined by the 2-by-2 interac-
tion of the patient’s DRG (469 or 470) and whether the patient had a hip fracture.


                                                            7
years.4 The ‘’discount factor” was designed to reflect Medicare’s portion of expected savings

from CJR.5

     We abstract in our analyses from two other features of CJR. First, to mitigate concerns that

bundled payments would create incentives to shirk on quality, hospitals were only eligible for

positive reconciliation payments if they met a minimum quality standard.6 However, in practice

the quality standard was not binding for the vast majority of the hospitals.7 In addition, prior

research has not detected effects on either incentivized or non-incentivized measures of quality

(Finkelstein et al., 2018).

     Second, like most bundled payment programs, CJR is not a “pure" bundled payment model

that exposes hospitals and Medicare to unbounded risk. Rather, to limit risk exposure by both

hospitals and Medicare, the reconciliation payment was subject to stop-loss and stop-gain provi-

sions. In particular, if th − yh was less than (the negative of) the stop-loss amount, the hospital

“only” has to pay Medicare the stop-loss amount. Similarly, if th − yh is greater than the stop-

gain amount, Medicare “only” has to pay the hospital the stop-gain amount. The stop-loss and

stop-gain amounts increased over time.8 These provisions complicate the model and its estima-

tion presented later, but do not affect the qualitative economic analysis and do not seem to be

quantitatively important (see Appendix C and Appendix Table A3), so we abstract from them

throughout the main text.
    4 The three reference years of historical claims are updated every other year. In 2016 and 2017 (the first two years

of the program) historical claims from 2012 to 2014 were used, in 2018 and 2019 (the third and fourth program years),
historical claims from 2014-2016 were used, and the final year of the program uses claims from 2016-2018 (CMS, 2015b).
    5 The discount factor ranged from 1.5% to 3% depending on hospital quality (based on a composite quality score

defined below), with smaller discounts for higher quality hospitals (CMS, 2015b). This “discount factor” was intended
to ensure that if claims remained at past levels, Medicare expenditures would decrease under mandatory participation.
In practice, however, there was a steady secular decline in per-episode claims, which offset the built-in “discount.”
    6 The quality standard is based on a composite quality score, which ranges from 0 to 20 points, and hospitals must

score at least 5 points to be eligible for bonus payments. Up to 10 points are given based on a hospital’s quality perfor-
mance percentile on a complication measure for total hip arthroplasty and total knee arthroplasty; up to 8 points are
given based on a standardized national patient experience survey; up to 2 points are given for submitting the patient-
reported outcomes and risk variable data. Finally, up to 1.8 points can be added to the final score for improvement in
either of the first two measures relative to the previous performance year, as long as the final score does not exceed 20.
See https://innovation.cms.gov/Files/x/cjr-qualsup.pdf for details
    7 For example, based on our calculation from the CJR reconciliation data, in the first year of the program fewer than

9% of treatment hospitals failed to meet the minimum quality standard for receiving a bonus.
    8 In the first year, the stop-gain amount was set as 5% of t and the stop-loss was zero (meaning that hospitals would
                                                                h
never need to make payments to Medicare). By years 4 and 5, the stop-gain and stop-loss amounts were each scheduled
to be set at 20% of th .




                                                            8
2.3    Experimental Design

CJR was initially designed by CMS as a 5-year, mandatory participation, randomized trial. Year 1

was defined as April 1 to December 31 of 2016, and years 2-5 were defined as the 2017-2020 cal-

endar years. CMS randomized 196 eligible MSAs into treatment (bundled payments) or control

(status quo FFS). Specifically, MSAs were divided into 8 strata based on the interaction of histor-

ical LEJR spending quartile and above- versus below-median MSA population. MSA treatment

probabilities varied by strata (ranging from 30% to 45%), with higher treatment probabilities for

strata with higher historical LEJR payments. CMS announced assignment to treatment and con-

trol in the July 2015 Federal Register (CMS, 2015b). Treatment and control MSAs are balanced on

outcome variables and MSA characteristics (Finkelstein et al., 2018). After exclusions, the program

covered 67 treatment MSAs and 104 control MSAs.9 Within the 171 MSAs assigned to treatment or

control, a small number of hospital types and episode types were further excluded from eligibility

(see Section 3 for more details).

      Participation was mandatory in treatment MSAs: eligible hospitals had no choice but to be

reimbursed under the new bundled payment model. This mandatory participation feature was

immediately controversial, with then-US representative Tom Price spearheading a letter in 2016,

signed by 179 members of Congress, complaining that mandatory participation was unethical

and unauthorized.10 Subsequently, as the new Secretary of Health and Human Services – the

federal agency charged with overseeing Medicare – Price lead the effort to roll back mandatory

participation bundled payment models. As a result, in a rule finalized in December 2017, Medicare

unexpectedly decided to cancel two previously scheduled mandatory bundled payment models

(Advancing Care Coordination Through Episode Payment and Cardiac Rehabilitation Incentive

Payment Models) and modified CJR to be voluntary in half of the treated MSAs for the remaining

three program years (CMS, 2017).

      Specifically, hospital participation in CJR was made voluntary in 33 of the 67 treatment MSAs
   9 Afterthe initial assignment, Medicare realized that they did not exclude some hospitals that were already (prior
to assignment) signed up for BPCI (a different Medicare program), and subsequently excluded an additional 8 MSAs
from the treatment group. Medicare later identified the 17 MSAs in the control group that would have been excluded
based on these criteria. Since these exclusions were based on hospital decisions made prior to assignment we simply
drop these 25 MSAs from the study.
  10 See https://thehill.com/policy/healthcare/298769-lawmakers-call-for-end-to-medicare-

experiments.



                                                         9
with the lowest historical episode claims under FFS.11 In these “voluntary treatment” MSAs, hos-

pitals had to make a one-time decision at the beginning of program-year 3 of whether to opt in,

and continue to be paid under bundled payments for the remaining 3 program years. If they

did not opt in, reimbursement would revert to FFS for the remaining 3 years. Slightly more than

one-quarter of the hospitals in the voluntary bundled payment MSAs (73 out of 279) chose to re-

main under bundled payments. In the 34 mandatory bundled payment MSAs, hospitals did not

face a choice and continued to be paid under bundled payments. Control group hospitals were

unaffected by this change, and continued to be paid under FFS.

       In the analysis that follows, we define three time periods. Period 1 is the period prior to

bundled payments, when all providers were reimbursed under FFS. Period 2 covers the approxi-

mately two years when the mandatory participation regime was in effect and expected to remain

so. Period 3 is defined as the final 3 years of the program, when the program was voluntary for

some hospitals.

       Figure 1 shows a flow chart of the experimental design. The top part of the figure shows the

initial assignment to treatment and control for period 2, when the program was mandatory, and

the bottom part shows period 3, where treatment MSAs were further divided into mandatory and

voluntary treatment groups. Because this division was based on predetermined historical MSA

spending, we can analogously divide the control MSAs into mandatory and voluntary control

MSAs based on this variable. For some of the subsequent analysis, we will compare mandatory

treatment to mandatory control, and voluntary treatment to voluntary control.


3      Data and Descriptive Evidence
In this section, we describe the data and sample, and reproduce prior findings of the average

impacts of bundled payments during the mandatory participation period. We then present evi-

dence on selection on levels and slopes during the voluntary period. These patterns motivate our

subsequent modeling decisions.
    11 Specifically,
               this determination was made using spending over July 1, 2011 through June 30, 2014, which was the
same period used to determine MSA eligibility in CJR, and occurred entirely before random assignment was announced
(CMS, 2017).




                                                       10
3.1    Data and Sample

Our main data are the 100% Medicare enrollment and claims files. These contain basic demo-

graphic information (age, race, sex, and Medicaid enrollment) and claims for inpatient, outpa-

tient, and post-acute care.12 The claims data include information on Medicare payments made to

providers and out-of-pocket payments owed, dates of admission and discharge, diagnoses, and

discharge destinations.

      We supplement these data with several additional data sources. First, we obtained data from

the CJR website on the eligibility and treatment status of each hospital in each year, the hospital’s

annual target price (for 2016 and 2017), annual reconciliation payment (for 2016 and 2017), and

whether the hospital opted into bundled payments when it became voluntary in 2018.13 Second,

we use data from the 2016 American Hospital Association (AHA) annual survey on the number

of beds, ownership type (for-profit, non-profit, or government-owned), and the teaching status of

the hospital. Third, we obtained data from Hospital Compare on each hospital’s official quality

measures (for 2016 and 2017).

      We limit our analysis sample to the 171 eligible MSAs and, within these MSAs, to hospitals

and episodes that were eligible for CJR. MSAs were excluded primarily due to a low volume of hip

and knee replacements. Within both treatment and control MSAs, hospitals were excluded from

CJR if they were already participating in a pre-existing Medicare voluntary bundled payment

model for LEJR.14 Episodes were excluded if the patient did not have Medicare as the primary

payer, was readmitted during the episode for LEJR, or died during the episode.15,16

      We define period 2 (the period of mandatory participation bundled payments) to include all

episodes with an index admission between April 1, 2016 and September 15, 2017. The start date

corresponds to the program start date, and the end date was chosen so that nearly all 90-day
   12 Specifically, we use the following claims files: Inpatient, Outpatient, Carrier, Skilled Nursing Facility, Home Health

Agency, Durable Medical Equipment, and Hospice.
   13 Source: https://innovation.cms.gov/initiatives/CJR. Target prices and reconciliation payments for

2018 were not available at the time of writing.
   14 Model 1 or Phase 2 (Models 2 or 4) of the Bundled Payments for Care Improvement Initiative (BPCI).
   15 In Table 1, we conduct analysis that expands the sample to include readmitted patients and show there is no effect

on readmissions.
   16 Finkelstein et al. (2018) provides more detail on these eligibility criteria. They estimate that the eligible MSAs

represented about 70 % of all Medicare LEJR patients, and that within eligible MSAs, about 70 % of LEJR patients
were eligible for CJR. About 20 % of LEJR patients within eligible MSAs were excluded because their hospital was not
eligible, and another approximately 10 % due to patient eligibility.



                                                            11
episodes would finish by December 31, 2017, the close of the second year.17 The end date also

ensures that all admissions (and most discharges) occurred prior to the December 2017 announce-

ment that participation would become voluntary for some MSAs starting on January 1, 2018 (CMS,

2017). Following prior work (Finkelstein et al., 2018), we define period 1 (the period when all hos-

pitals are under FFS) to include all episodes admitted between April 1, 2013 and September 15,

2014, and omit 2015 from the analysis to avoid contamination from potential anticipatory effects;

treatment and control MSAs were announced in July 2015 (CMS, 2015a).

      To construct our baseline sample, we start with the universe of 1,570 hospitals in the 171

treatment and control MSAs that had a CJR episode during period 2; these hospitals had a total of

395,938 CJR episodes during period 2. So that we can observe outcomes in the years prior to the

intervention, we restrict the sample to the 1,455 hospitals that have at least one episode in both

years of period 1. These 1,455 hospitals constitute our baseline sample, out of which 664 hospitals

are located in a treatment MSA and 791 hospitals are in a control MSA. A total of 379,843 CJR

episodes in period 2 fall into these 1,455 hospitals.

3.2    Average Treatment Effects

Average effects of CJR in the two-year mandatory participation period (period 2) have been well-

studied (Finkelstein et al., 2018; Dummit et al., 2018; Barnett et al., 2019; Haas et al., 2019); we

reproduce some key results here. Since the program was mandatory and assignment was random

at the MSA level, we follow Finkelstein et al. (2018) and estimate:


                 outcome j2 = β 0 + β 1 BPj + β 2 outcome j,2014 + β 3 outcome j,2013 + δs( j) + ǫ j             (1)


where outcome j2 is the average per-episode outcome in MSA j and period 2, BPj is an indicator for

being randomly assigned to bundled payments, and β 1 is the average treatment effect of bundled

payments. We include lagged outcomes from 2013 and 2014 (i.e., period 1) as controls to improve

statistical power. Because the probability of random assignment to treatment varied across strata,

we include strata fixed effects, δs( j) , to isolate the experimental variation. In all tables, we report

heteroskedasticity robust standard errors.
  17 Recall that the episode of care ends 90 days after hospital discharge.
                                                                        The mean length of stay for an LEJR admission
is 3.1 days for DRG 470 and 7 days for DRG 469, so truncating the sample on September 15, 2017 guarantees that
virtually all claims associated with the episode would be included in the 2017 claim files (CMS, 2016).


                                                            12
    Table 1 shows the average treatment effects. To provide a baseline, the first two columns

show the mean and the standard deviation of the outcome from the control group in period 2. The

remaining columns show the average treatment effect, standard error, and p-value of the estimate.


Healthcare Claims, Use and Government Spending. Panel A of Table 1 examines effects on

healthcare claims, healthcare use, and government spending per episode. “Claims” consist of

Medicare claims paid and patient cost sharing owed over the entire episode of care, but do not

account for any reconciliation payment associated with a bundled payment; they thus correspond

to yh in the notation from Section 2.2, and are measured as average per episode claims. Average

per-episode claims in the control group were about $25,300, with roughly half of this spending

on the index admission, which is already reimbursed with a DRG-based, prospective payment

under the status quo. Of the remaining $11,800, about $4,100 comes from post-discharge claims for

institutional Post Acute Care (PAC) – predominantly skilled nursing facilities – $1,800 represents

post-discharge claims for Home Health Care, and the remaining $5,800 includes categories such as

claims for the surgeon and other physicians (both inpatient and outpatient), hospice, and durable

medical equipment, such as wheelchair rental.

    We estimate that bundled payments reduced average episode claims by about $800, or about

3 %, a statistically significant but economically modest result. This reduction is primarily driven

by a statistically significant $500 decline in claims for institutional PAC (12 % of the control mean),

with no statistically or economically significant effects on other categories of claims. The impacts

on claims are reflected in the impacts on utilization. Bundled payments did not impact average

length of stay for the index admission, but decreased the unconditional average number of days

spent in institutional PAC by about 0.6 days (8 % of the control mean).

    The decline in use of institutional PAC in turn reflects at least in part an extensive margin re-

sponse in where patients are discharged to following their index admission. In the control group,

patients are discharged to institutional PACs, home with home health care, and home without

home health care in equal proportion. Bundled payments reduced discharges to institutional PAC

by a statistically significant 3.4 percentage points (11 %). The decline in discharges to institutional

PAC is accompanied by a similarly sized increase in discharges to home without home health.18
 18 This   can be either because the patients who would have been sent to institutional PAC are being sent home without



                                                           13
These experimental estimates are consistent with qualitative evidence on how hospitals respond

to CJR. In a survey of hospital executives and administers, Zhu et al. (2018) find that hospitals re-

port responding by reducing SNF discharges using risk-stratification and home care support, and

by forming networks of preferred SNFs to influence quality and costs, conditional on discharge.

     Although bundled payments reduced episode claims as they would be paid under FFS, actual

government spending (claims, yh , under FFS and the target price, th , under bundled payments)

does not change. The point estimate indicates a statistically insignificant increase in average gov-

ernment spending per episode of $33 (standard error of $208). The lack of a reduction in gov-

ernment spending – despite modest reductions in submitted claims – reflects the design feature

of bundled payments, according to which target prices were set to approximate counterfactual

claims under FFS.


(Lack of) Quality Shirking and Cream Skimming. The primary concern with bundled pay-

ments is that because providers are no longer paid on the margin, they will cut back on medically

necessary care, cherry-pick patients who have lower costs of provision, or both. The quality incen-

tives provided by the program, as well as physician ethics, reputational concerns, and the threat

of malpractice lawsuits may limit any quality response. Indeed, to the extent that low quality care

increases downstream costs, hospitals may have incentives to improve quality.

     Consistent with prior work on CJR, the bottom two panels of Table 1 show no evidence of

an impact of CJR on quality of care or patient composition. Panel B examines three measures of

quality: a clinically-defined complication rate, whether the patient had an emergency room visit

during the episode, and 90-day all-cause readmission. We estimate a fairly precise zero effect on

all of these measures. Panel C examines patient volume and composition. We estimate a pre-

cise zero effect on the number of LEJR admissions per 1,000 Medicare enrollees and the number

of CJR-eligible admissions.19 We examine patient composition by estimating effects on the Elix-

hauser Comorbidity Index of the patient pool, which is constructed as the sum of indicators for 31
home health, or because there is a cascading effect where the patients who would have been sent to institutional PAC
are being sent home with home health, and patients who would have been sent home with home health are now being
sent home without home health supports. A cascading effect seems more likely (to us), but we cannot differentiate
between these two mechanisms.
  19 Specifically, while our analysis of LEJR admissions includes non-CJR eligible admissions in the sample of 171 eligi-

bles MSAs, our analysis of CJR-eligible admissions excludes hospitals and episodes in these MSAs that are not eligible
for CJR.



                                                           14
comorbidities (Elixhauser et al., 1998; Quan et al., 2005). We estimate a precise zero effect on this

measure as well.

      The lack of a patient volume response is consistent with LEJR as a non-discretionary proce-

dure, or at least a procedure where the change in financial incentives from bundled payments is

small relative to other determining factors. The lack of cream skimming may also reflect the fact

that assignment to bundled payments in period 2 is determined at the MSA level, so that the clos-

est substitutes for a given hospital are likely to be paid under the same regime. Cream skimming

responses could potentially be different in period 3 once participation is voluntary, as there may

now be hospitals paid under bundled payments and under FFS in the same MSA. Indeed, in a dif-

ferent voluntary payment model, Alexander (2017) documents that physicians strategically direct

patients across hospitals within a local area to maximize revenue.

      Since our paper focuses on selection – which is a hospital-level choice – all of our remaining

analyses are conducted at the hospital level, with hospitals weighted by the number of episodes

in period 2 so that the results are representative for the average episode. Appendix Table A1 shows

that the main results from Table 1 are largely similar when estimated at the MSA level weighted

by the number of episodes, or at the hospital level weighted by the number of episodes, although

some of the point estimates shrink in magnitude. In addition, one of our three quality measures

(the complication rate) shows a statistically significant increase of 0.2 percentage points (off a base

of 1.1 %) in one of the three specifications in Appendix Table A1.

      In interpreting this evidence, it is important to point out that the quality measures are limited.

We cannot, for example, measure outcomes such as morbidity, mobility, or activities of daily living

consistently across locations. We therefore cannot definitively rule out any impact of bundled

payments on quality of care. However, given the lack of compelling evidence of a quality response

on the margins we can observe, in our subsequent model and counterfactual exercises we will

assume that quality remains fixed and that patients’ utility is unaffected by the hospital’s response

to incentives.

3.3    Selection on Levels and Slopes

As we formalize in the next section, hospitals have incentives to select into CJR on both levels

and slopes. By selection on levels, we mean that hospitals have a larger incentive to select in if


                                                   15
their average claims, holding behavior fixed at what it would be under FFS, would be below their

target price. By selection on slopes, we mean that hospitals have a larger incentive to select in if

they can more easily reduce their average claims below the target price. We present descriptive

evidence on both margins, examining how the decision among voluntary treatment hospitals to

select in or out of bundled payments in period 3 correlates with episode claim levels in period 1

and behavioral responses to bundled payments in period 2. Table 2 presents the results.


Selection on Levels. In principle, we would want to examine selection on slopes by estimating

the correlation between the selection decision and period 3 spending in the absence of the incen-

tives from bundled payments. Because treated hospitals change behavior in response to bundled

payments (see Table 1), we do not observe unaffected spending levels. The model developed in the

following sections will allow us to formally recover these counterfactual spending levels. To pro-

vide model free evidence, for now we simply look at how selection correlates with the hospital’s

average episode claims in period 1, when all hospitals were paid under FFS. Since spending levels

are strongly auto-correlated within hospitals over time, we expect hospitals with lower average

episode claims in period 1 to be more likely to select in (on levels) in period 3.20

     Panel A of Table 2 shows how the selection decision varies with period 1 levels. Specifically,

we show mean outcomes and their standard deviation for three groups of hospitals. Column

1 shows hospitals in the voluntary control group, which we define as control group hospitals

that would have been assigned to voluntary based on their prior spending levels (see Figure 1).

Columns 2 and 3 show period 1 outcomes for hospitals in the voluntary treatment group, split by

those who in period 3 selected into bundled payments (column 2) or out of bundled payments

(column 3). The first three rows report results for the three outcomes where we observed a statis-

tically significant impact of bundled payments in Table 1: episode claims, claims for institutional

PAC, and share of patients discharged to institutional PAC.

     The results are consistent with selection on levels. Column 1 shows substantial heterogeneity

across hospitals in the voluntary control group, indicating potential scope for selection. For ex-

ample, average episode claims are $26,523, with a standard deviation of $5,368. Columns 2 and

3 show that, as expected, hospitals who select into bundled payments have, on average, about
  20 Specifically,
                 for control group hospitals, the correlation coefficient between period 1 and period 2 is 0.77 for total
episode claims, 0.65 for institutional PAC claims, and 0.71 for the share discharged to institutional PACs.


                                                           16
$1,600 lower average episode claims than those who select out, a statistically significant differ-

ence that is about 6 % of the control mean. The patterns are similar for claims at and the share

discharged to institutional PAC.


Selection on Slopes. To assess selection on slopes, we estimate hospital-specific slopes (i.e., be-

havioral changes in response to bundled payments in period 2) and then examine how selection

into bundled payments in period 3 varies with this measure. Letting outcomeh2 denote the aver-

age episode outcome for hospital h in period 2, we estimate a modified version of Equation 1 that

allows the treatment effect of bundled payments to vary by hospital. Specifically, we estimate:


            outcomeh2 = β 0 + β 1h BPh + β 2 outcomeh,2014 + β 3 outcomeh,2013 + δs(h) + ǫh ,       (2)


where BPh is an indicator for being randomly assigned to bundled payments and β 1h is the hospital-

specific treatment effect. As in Equation 1, we include lagged outcomes as covariates to improve

statistical power, although in this specification the lags are defined at the hospital level. As be-

fore, we also include strata fixed effects because randomization was conducted within strata. We

estimate this specification on the set of voluntary treatment and control hospitals (see Figure 1).

    Panel B of Table 2 shows the results. Specifically, we show the average estimated hospital-

specific treatment effects (β 1h ) and their standard deviation separately across hospitals that select

into bundled payments (column 2) and those that select out (column 3). The results once again

show selection in the expected direction: for hospitals that selected into bundled payments in pe-

riod 3, bundled payments in period 2 reduces average claims per episode by $796, compared to

a lower reduction ($669) for hospitals that revert to FFS in period 3. However, these differences

in average slopes are not statistically distinguishable (column 4). Selection is also in the expected

direction for the other two outcomes in Panel B: hospitals that experienced greater declines in in-

stitutional PAC claims and in the share of patients discharged to institutional PAC due to bundled

payments are more likely to remain under bundled payments. The differences in the impact on

institutional PAC claims in period 2 between those who remain in bundled payments ($519) and

those who select out ($177) in period 3 is statistically distinguishable (p=0.05).

    The random assignment of payment regime in period 2 is not particularly important when



                                                   17
estimating heterogeneity in treatment effects across hospitals (i.e., the β 1h ’s from Equation 2); the

control hospitals simply identify the secular time trend β 0 . Rather, estimation requires the (ad-

mittedly strong) identifying assumption that, conditional on the covariates, there are no hospital-

specific time trends. Any heterogeneity in the change in outcomes across hospitals is interpreted

as reflecting heterogeneous treatment effects. To probe the sensitivity to this assumption, we esti-

mate an alternative specification in which we include hospital-specific linear time trends as con-

trols. Theses time trends are identified off the hospital specific outcomes in 2013 and 2014. In this

specification, the (weaker) identifying assumption is that, conditional on covariates, there are no

hospital specific deviations from the time trend. Appendix Table A2 shows that the qualitative

pattern is robust to this alternative specification: hospitals that select into bundled payments in

period 3 experienced larger changes in outcomes in period 2 than those who opt out, although

none of these differences are statistically distinguishable.


Selection on Hospital Characteristics. Panel C of Table 2 briefly examines other characteristics

of hospitals that select in and select out of bundled payments. Hospitals that select into bundled

payments in period 3 have a somewhat higher volume of CJR episodes in period 1, suggesting

there may be fixed costs to remaining in the program, a point we return to with our model speci-

fication in Section 5.21 Hospitals that select in are less likely to be teaching hospitals, more likely

to be for-profit, and less likely to be government-owned; they are also associated with higher

measured quality.


4      Model of Voluntary Selection

4.1     Setting

We consider a pool of CJR episodes, indexed by i, which are admitted to hospital h. We assume

throughout that this pool is taken as given, and is known to the hospital.

      Under FFS, providers are reimbursed based on claims. Let λi denote the claims generated

under FFS incentives by a given episode. The preceding sections’ description of the institutional

environment and the estimates of the average effects of bundled payments suggest that it is useful

to decompose λi = f iHOSP + f iOTH , where f iHOSP are the fixed, DRG-based claims submitted for the
    21 We   use period 1 volume since it is necessarily unaffected by period 2 treatment assignment.


                                                              18
index hospitalization and f iOTH are the claims submitted by post-acute care and other downstream

providers. Let ciHOSP denote the costs incurred by the hospital and cOTH
                                                                     i   the costs incurred by the

other providers . For tractability, we assume that other providers are reimbursed at cost, so that

f iOTH = cOTH
          i   .22 In what follows, for each variable xi , we focus on hospital-level averages, defined
            1     nh
as xh =     nh   ∑n= 1 xi , where n h is the number of episodes at the hospital.



Hospital Profits and Participation Incentive. Under FFS, average government spending (i.e.,

Medicare reimbursement) per episode is λh = f hHOSP + f hOTH . Hospitals only incur costs and

receive Medicare payment for costs within the hospital, so they earn profits πhFFS = f hHOSP −

chHOSP . Under bundled payment, Medicare reimburses the admitting hospital the fixed target

price th for the entire episode, so average government spending per episode is th . Hospitals are,

effectively, required to incur not only hospital costs chHOSP but also downstream providers’ claims

f hOTH , which would have been reimbursed by Medicare under FFS. We assume that the hospital

can reduce claims outside of the hospital by e through the exertion of “effort” φh (e), where φh (0) =

0, φh′ > 0, and φh′′ > 0.23 Hospitals, thus, choose effort to maximize

                                            h                      i        
                              πhBP = max th − (chHOSP + f hOTH ) − e − φh (e) ,                                       (3)
                                        e



and optimal effort is pinned down by φh′ (eh∗ ) = 1. Since the hospital internalizes both the social

marginal cost and benefit of effort, bundled payments results in the first-best level of effort.
                                                                                                             e2
     For tractability, we assume that the cost of effort is quadratic of the form φh (e) =                  2ωh ,   where

ωh > 0 is a hospital specific parameter. With this assumption, under bundled payments the

hospital’s optimal choice of effort is eh∗ = ωh , average claims are f hHOSP + f hOTH − ωh = λh − ωh ,
                                                                  ωh
and hospital profits are πhBP = th − (chHOSP + f hOTH −           2 ).

     Hospitals select into a voluntary bundled payment program, denoted by the indicator BPh =
  22 This assumption is primarily made to simplify notation. It is straightforward in the context of the model to al-
low other providers to obtain a fixed markup, but reasonable levels of such markups would only slightly affect the
quantitative results and would have no impact on the qualitative conclusions.
  23 For simplicity, we assume that c HOSP remains the same under bundled payments and is not affected by e. This is
                                      h
not essential, and can be viewed as a normalization, although it is a natural assumption. If the effort to reduce hospital
cost and the effort to reduce post-acute care cost are separable, the hospital cost level was already optimized under FFS
given that hospitals were already paid (under FFS) a fixed amount for the hospital portion of the episode.




                                                           19
1, if and only if πhBP > πhFFS . Substituting in yields the criteria

                                                                    ωh
                                       BPh = 1 ⇔ (th − λh ) +          > 0,                                      (4)
                                                                    2

where the right hand side is the sum of a “level” effect (th − λh ) and a “slope” effect ( ω2h ). The

level effect (th − λh ) represents the transfer payment hospitals would receive from the government

under bundled payments relative to under FFS if they did not change their behavior from what it

was under FFS. The slope effect ( ω2h ) denotes the net savings that hospitals get from any change in

behavior under bundled payments, which is the reduced provider costs eh∗ = ωh net of the effort

cost that reduction entails ( ω2h ). These incentives are well understood by the hospital industry. For

example, Arbormetrix, a healthcare consulting firm, advises their client hospitals to consider the

following questions when deciding whether to participate in a bundled payments program: “One:

‘How good is my target price?’ Two ‘What has changed [since the target prices were set]?’ And

three: What is my opportunity to improve?”.24


Social Welfare. The distinction between selection on levels and slopes has important implica-

tions for the social welfare consequences of voluntary programs. We define social welfare W as the

sum of consumer surplus (S) and producer profits (π), minus government spending (G) weighted

by the marginal cost of public funds Λ > 0:


                                            W = S + π − (1 + Λ) G.                                               (5)


The multiplier Λ > 0 captures the deadweight loss associated with raising government revenue

through distortionary taxation. Alternatively, it can be thought of as capturing a societal prefer-

ence for money in the hands of government (or consumers) rather than in the hands of hospitals.25

Consistent with the descriptive results in Section 3, we assume that the hospital’s effort does not

affect patient welfare (S).
  24 See   https://www.arbormetrix.com/press-releases/new-report-significant-variation-in-
expected-savings-per-hospital-in-bpci-advanced.
  25 Recall that y in practice measures claims paid by Medicare or owed out of pocket by consumers. Under this
                   h
interpretation, it would be natural to multiply S by (1 + Λ), so that Λ represents the wedge between hospitals on the
one hand and consumers and government on the other. Since we net S out of the calculations below, this can be done
without loss of generality.



                                                         20
      Government spending per episode (G) is th under bundled payments and λh under FFS. Plug-

ging in for these and for hospital profits implies that hospital participation in the bundled pay-

ments improves social welfare if and only if

                                                                  ωh
                               WBP > WFFS ⇔ −Λ(th − λh ) +           > 0.                                (6)
                                                                  2

      Equation 6 illustrates the key social welfare tradeoff. On one hand, bundled payments incen-
                                                                                                         ωh
tivizes hospitals to exert the first best level of effort eh∗ = ωh , which increases social welfare by   2 .

On the other hand, enticing hospitals to participate in bundled payments increases government

spending by th − λh . Selection on levels (th − λh ) is thus socially costly: it creates a transfer from

the government to hospitals that is associated with a social cost of Λ. By contrast, selection on

slopes increases social welfare due to the reduction in real resource utilization net of effort costs

( ω2h ). In other words, because of the cost of public funds Λ, and the need to ensure that hospitals

are willing to participate in bundled payments, hospital participation is not always social-welfare

enhancing.

4.2    Graphical Intuition

We illustrate the setting graphically in Figure 2, which depicts the participation incentives for hos-

pitals and the corresponding social welfare implications. Hospitals are represented by a {λh , ωh }

pair. If one could mandate participation without any additional government costs, the social wel-

fare maximizing outcome would be to mandate that all hospitals join the BP program (given that

ωh is positive, by design, for all hospitals). However, if participation is voluntary and Medicare’s

ability to encourage participation rests on the financial incentive, th , the tradeoff is represented in

Figure 2.

      To draw the figure, we hold the target price t fixed across hospitals. At this payment, the solid

line represents the set of hospitals that are indifferent between participation in bundled payments

and FFS. Hospitals to the left prefer bundled payments, because the sum of the transfer holding

their behavior constant (t − λ) and the savings they get under bundled payments ( ω2 ) is positive.

Hospitals to the right of the solid line prefer to remain under FFS. Thus, hospitals have both a

simple “level” incentive to participate (if th − λh > 0), as well as an additional “slope” incentive,



                                                   21
which explains why the solid line slopes up. All else equal, a higher ωh provides an additional

incentive for the hospital to join the bundled payment program as it captures some of the savings

it can generate.

      The dashed line in Figure 2 represents the set of hospitals for which social welfare is the same

whether they participate in bundled payments or FFS. While the “slope” effect ( ω2 ) enters identi-

cally (and positively) into the private participation condition (Equation 4) and the social welfare

condition (Equation 6), the “level” effect t − λ enters positively into the hospital’s participation

decision (Equation 4) but negatively in the social welfare calculus (Equation 6). This explains why

the dashed line is downward sloping, and illustrates the central social welfare tension in designing

a voluntary regime: enticing providers to participate can be socially costly.

      Taken together, Figure 2 partitions hospitals to three groups: hospitals that choose the FFS

regime, hospitals that efficiently select into bundled payments, and hospitals that select into bun-

dled payments inefficiently because they get paid much more than they “should” but do not gen-

erate significant efficiency gains (due to low ωh ).

4.3    Targeting

The bundled payment program aligns effort incentives. If Medicare could generate participation

without any additional public expenditure, it would be social-welfare improving to do so (since

we assume ωh > 0). However, in a voluntary regime Medicare must respect the hospitals’ partic-

ipation constraint. If Medicare has perfect information about {λh , ωh }, it could maximize social
                                ωh
welfare by setting th = λh −    2    for each hospital. Under these target prices, all hospitals would

voluntarily participate and government spending would be lower.

      Once information about the joint distribution of {λh , ωh } is incomplete, setting the payment

amount involves a tradeoff, similar to the one in the classic optimal regulation design problem

of Laffont and Tirole (1993). Figure 3 illustrates this tradeoff in our setting. In Panel A we start

with Figure 2 and super-impose on it the participation and social welfare indifference sets that are

associated with a higher target price t′ > t. The black (solid and dashed) indifference lines that

correspond to t′ are analogous to the gray lines, which correspond to t. Naturally, the higher pay-

ment amount increases the share of hospitals that select into bundled payments. For many of the

marginal hospitals that opt in, participation increases social welfare. At the same time, however,


                                                   22
the greater payment increases the social welfare cost associated with infra-marginal participants,

by a fixed amount of Λ(t′ − t), and in doing so makes participation social-welfare reducing for

some of these hospitals (those that lie in between the two dashed lines).

    The ability to effectively target depends on the underlying joint distribution of {λh , ωh } as well

as any information about this joint distribution that the social planner can condition on in setting

target prices. This is shown in the remaining panels of Figure 3, which use ovals to illustrate three

examples of underlying joint distributions, conditional on (priced) observables.

    Comparing Panels B and C shows the importance of the overall level of ωh . When ωh is high

(i.e., the cost of effort associated with reducing claims is lower and therefore optimal effort under

bundled payments is higher), as in Panel B, the participation incentives of the hospital and the

social planner are more closely aligned. In this case, even if λh is heterogenous after conditioning

on available information, it is easier to generate social welfare enhancing participation in bun-

dled payments. However, when ωh is low (i.e., the cost of effort is higher and optimal effort is

lower), as in Panel C, selection is primarily driven by levels, and it is difficult to generate social

welfare enhancing participation by hospitals. In this case, it requires much less heterogeneity in

λh , or more precise information, to be able to generate social welfare gains through the voluntary

bundled payment program.

    Comparing Panels C and D shows the importance of the relative heterogeneity in λh and ωh .

Because the primary policy instrument is a fixed payment, large heterogeneity in λh , as in Panel

C, leads to more inefficient selection into bundled payments. In contrast, if the primary source of

heterogeneity is the “slope” ωh , as in Panel D, voluntary participation is more likely to generate

social welfare gains.

    The joint distribution of λh and ωh , conditional on (priced) observables, is therefore key in

assessing the potential social welfare gains from alternative payment models. It is therefore the

key object of interest in our econometric exercise in the next section.




                                                  23
5   Specification and Results

5.1 Econometric Specification

We now turn to econometrically estimating the economic model presented in the last section.

Recall the way we defined the “periods” associated with the experimental setting. In period 1,

all hospitals are still under FFS, and assignment to bundled payments has not been announced.

In period 2, a subset of the hospitals are randomly assigned to bundled payments. In period 3,

a subset of these latter hospitals endogenously choose to remain under bundled payments while

the rest switch back to FFS.

    For each hospital in the sample, we observe two periods of claims data (yh1 , yh2 ) and three

periods of bundled payments participation indicators (BPh1 , BPh2 , BPh3 ). For hospitals randomly

assigned to bundled payments in period 2, we also observe the hospital-specific target price, th , in

period 2 (even if they select out of the program).

    As discussed in the end of Section 4, our key object of interest is the joint distribution of

{λh , ωh }, where λh is the average per-episode claims under FFS and ωh is the reduction in claims
that is caused by bundled payments. The model implies the following relationships between the

latent objects of interest and the variables we observe. First, the claims equation (for t = 1, 2) is

given by

                                   yht = λh − BPht ωh    for   t = 1, 2,

and second, the hospital’s participation equation (which is relevant only for period 3, when par-

ticipation in bundled payments is voluntary) is given by

                                                                   ωh
                                  BPh3 = 1 ⇐⇒ (th − λh3 ) +           > 0.
                                                                   2

    To help fit the model to the data, we introduce two additional econometric components. First,

we allow λh to vary over time according to


                               ln λht = ln λh + g(t) + ǫht   for    t = 1, 2, 3.


where g(t) = γ (t − 2) is a linear time trend, normalized to be zero in period 2, and ǫht is drawn


                                                    24
(iid) from N (0, σǫ2 ).26

     Second, we introduce a hospital-level choice shifter into the participation equation. Survey

evidence on how hospitals respond to bundled payments suggest that participation may be influ-

enced by both hospital-level fixed costs and marginal per-episode costs (Zhu et al., 2018). To allow
                                                            ν
for both of these forces, we add the term νh =              nκh   to the hospital-level selection equation, where

nh is the number of episodes at the hospital, and ν and κ ∈ [0, 1] are parameters to be estimated.
                                                                    ν
For κ = 1, the hospital-level choice shifter becomes                nh ,   which is equivalent to a choice shifter of

ν in an episode-level specification. For κ = 0, the hospital-level choice shifter becomes ν, imply-

ing no episode-level component. Intermediate values of κ capture intermediate cases. For now,

we remain agnostic as to what these additional forces represent and, in particular, whether they

only affect hospital choice or are also relevant for social welfare. In our counterfactual analyses in

Section 6 we will consider both possibilities.

     Putting everything together, the econometric model is given by the following relationships:


                                  yh1 = λh1 ,

                                  yh2 = λh2 − BPh2 ωh ,
                                                                      ωh   ν
                                BPh3 = 1 ⇐⇒ (th − λh3 ) +                + κ > 0,
                                                                      2   nh

                               ln λht = ln λh + γ (t − 2) + ǫht             for   t = 1, 2, 3.


Finally, we assume that ln ωh and ln λh are joint normally distributed, so that

                                                                
                          ln λ            µ          σ 2    ρ    σ  σ
                              h       λ,s        λ      λω λ ω  
                                 ∼ N      ,                      .
                          ln ωh           µω      ρλω σλ σω     σω2


where the s subscript on µλ,s indicates that we allow the mean of ln λh to vary across strata.27

Because the DRG portion of spending is fixed, we restrict ωh from being infeasibly large by trun-

cating it from above at 0.71 λh .28
  26 Our use of the term “linear” is slightly imprecise, because the trend is in periods, which do not perfectly correspond

to calendar time (e.g., we exclude 2015 due to potential anticipatory effects).
  27 Since assignment to bundled payments in period 2 was random conditional on strata, allowing the mean to vary

by strata isolates the experimental variation and is the analogue to controlling for strata fixed effects in Equation 1.
  28 The institutions and empirical evidence indicate that virtually all of the savings from bundled payments arise from




                                                           25
5.2    Identification

The conceptual identification of the model is fairly straightforward given random assignment to

bundled payments in period 2. The model has a set of parameters that correspond to the “level”

of claims under FFS incentives and its evolution over time: µλs , σλ , γ, σǫ ; a set of parameters that

correspond to the reduction in claims under bundled payments: µω , σω ; a correlation parameter

that relates the levels and slopes: ρλω ; and choice shifter parameters: ν, κ. The intuition for the

identification argument follows in three steps.

      First, using data from the control group alone, in which we observe λh1 and λh2 for the same

set of hospitals, we can identify µλs , γ, σλ , and σǫ . Intuitively, these would be identified from a

random effects model estimated on the control group. We can use the control group alone to es-

timate these parameters because random assignment guarantees that parameters estimated from

the control group are valid for the entire sample.

      Second, using data from the treatment group as well as the control group, we can identify µω ,

σω , and ρλω . We observe λh1 and λh2 for all hospitals in the control group, and λh1 and λh2 − ωh

for all hospitals in the treatment group. The average change between λh1 and λh2 for control

hospitals identifies γ, the time trend in λht . Again, because of random assignment we know that

γ estimated from the control group is valid for the whole sample. For treatment hospitals, the

average difference in λh1 and λh2 − ωh in excess of γ identifies µω .

      The dispersion within the treatment hospitals in the change in episode claims between period

1 and period 2 is driven by a combination of the stochastic evolution of λht and the dispersion

in ωh . Since the stochastic evolution of λht is already identified from the control group, we can

(loosely) net it out, and the residual dispersion for treatment hospitals identifies σω . The intuition

for identifying ρλω is similar: we observe the reduction in claims for each hospital in the treatment

group, and can correlate it with the hospital’s period-1 claims, and adjust it appropriately for the

additional independent noise that is driven by the stochastic evolution of λht , which is already

identified by the control group.

      Finally, the bundled payment participation equation identifies the distribution of the remain-
“other” claims that are not associated with fixed, DRG-based payment for the index admission. The value of 0.71
represents the 99th percentile in the data for the ratio of these other claims to total episode claims. By truncating the
distribution of ωh at the 99th percentile of other claims, we are essentially making the assumption that savings cannot
exceed the 99th percentile of “other” spending.


                                                           26
ing choice shifter parameters ν and κ. This equation resembles a probit equation, but the error

term has an economic interpretation as reflecting hospitals’ profit maximizing choices. The joint

distribution of λh3 and ωh , which is identified from the previous two steps, together with our

model, generates predictions for the overall participation rate in a voluntary bundled payment

program. Any deviation from this “predicted” participation rate identifies ν, with κ identified by

the extent to which hospitals with greater numbers of episodes are, all else equal, more likely to

select into bundled payments.

5.3    Estimation

We estimate the model in two steps using maximum likelihood, following the identification ar-

gument quite closely. We summarize the estimation procedure here, and provide more details in

Appendix A.

      In the first step we follow the first part of the identification argument, by estimating µλs , γ,

σλ , and σǫ using data from the control group alone. An observation is a pair of average episode

claims for a control group hospital in period 1 and period 2 {yh1 , yh2 }.

      We could continue along the identification argument, and estimate the remaining parameters

in two additional steps, but in order to increase efficiency we combine them into one. Specifically,

we now use observations on the treatment group hospitals, where each independent observation

is given by {yh1 , yh2 , BPh3 }. The likelihood is given by


           Lh = Pr ( BPh3 = 1) · f (yh1 , yh2 | BPh3 = 1) + Pr ( BPh3 = 0) · f (yh1 , yh2 | BPh3 = 0),


and can be evaluated numerically. As a way to speed up computation (with some small loss

in efficiency), we can use the parameters estimated in the first step and the observed value of

yh1 to generate a “posterior distribution” for ln λh2 and (identically) ln λh3 for each hospital. This

simplifies the second step of the estimation. When we estimate the model, we weight each hospital

by the number of episodes in period 2, so that the resulting parameters are representative at the

episode level.

      Standard errors are calculated using the bootstrap method. Specifically, we construct boot-

strap samples by drawing the observed number of hospitals with replacement from cells defined



                                                       27
by the full interaction of treatment assignment and strata. When estimate the parameters of the

model on each bootstrap sample and calculate the standard errors as the standard deviation of

these bootstrap parameter estimates.

5.4    Results

Table 3 presents the estimation results. Panel A reports the parameter estimates and Panel B

presents some of the key summary statistics that are implied by these estimates, first for all hos-

pitals (Panel B.1) and then, in Panel B.2, limited to the hospitals in the voluntary treatment group

only (see Figure 1).

      Panel A indicates a negative time trend in episode spending (γ = −0.07), which is consistent

with the time series pattern in the control group, and a relatively small standard deviation for

the idiosyncratic disturbances in λht (σǫ = 0.07 versus σλ = 0.17), which yields a λh3 with an

expected value of $24,200. We estimate that ωh has an expected value of $386, which is smaller

than the average effect estimated in Table 1 (and closer to the hospital-level estimates in Appendix

Table A1). The distributions of λh and ωh have a modest positive correlation (ρλ,ω = 0.30). The

estimate of κ is 0.40, implying that the choice shifter scales up with the number of episodes but

less than proportionally, and can thought of as representing some combination of hospital-level

and episode-level costs. With the exception of the choice-shifter parameter ν, the parameters are

precisely estimated.

      The model emphasizes the importance of heterogeneity in levels and heterogeneity in slopes

in determining the nature of selection, government spending, and social welfare under a volun-

tary bundled payments regime. The results in Panel B.1 indicate that the heterogeneity in levels is

substantially greater than either the level or the heterogeneity in the slopes – the standard devia-

tion of λh3 is $4,400 compared to a standard deviation of ωh of $1,100, and an even lower average

of ωh . This raises concerns that the voluntary system may primarily produce inefficient transfers

to hospitals through selection on levels. However, the potential for selection on levels may be

limited by the design of target prices. We explore this in Panel B.2, which is restricted to the sub-

sample of hospitals in the voluntary treatment regime, where we can also observe target prices

and which will be the focus of our counterfactuals in the next section. Panel B.2 indicates that

netting out target prices does not noticeably reduce heterogeneity in levels: the $4,900 standard


                                                 28
deviation of λh3 − th for voluntary treatment hospitals is only slightly less than the $5,700 standard

deviation of λh3 for these hospitals.29

     To further examine the role of target prices, Figure 4 produces empirical analogues of the

selection figures we used to illustrate the model in Section 4, incrementally accounting for target

prices and the choice-shifter νh . Once again we restrict analysis to the subsample of hospitals in the

voluntary treatment group. To provide a baseline, Panel (a) of Figure 4 plots simulated hospitals

from the joint distribution of ωh (vertical axis) and λh3 (horizontal axis), without netting out the

target price. As would be expected from the results in Panel B.2 of Table 3, the plot suggests

that selection on levels is a primary concern, with a large mass of hospitals selecting bundled

payments inefficiently or selecting FFS. In Panel (b) of Figure 4 we examine the role of targeting by

plotting λh3 − th on the horizontal axis, instead of λh3 . Netting out target prices does not noticeably

shrink the heterogeneity along the horizontal axis, with large masses of hospitals continuing to

select bundled payments inefficiently. In Panel (c), we further add the choice-shifter by plotting

λh3 − th + νh on the horizontal axis, thus capturing all the components of the selection decision.


6 Counterfactuals
We use the estimated model to perform a set of counterfactual exercises. Throughout, we focus

on the sample of hospitals in the voluntary treatment group – i.e., treatment group hospitals that

were given a choice in period 3 of whether to remain under bundled payments or revert back to

FFS (see Figure 1). We perform two main sets of exercises. First, we compare social welfare under

mandatory FFS, mandatory bundled payment, and voluntary bundled payment. Second, within

the voluntary bundled payment regime, we consider how alternative target prices affect social

welfare.30
  29 From a mathematical perspective, this should not be surprising. Since Var ( λ − t ) = Var ( λ ) + Var ( t ) −
                                                                                        h3    h          h3         h
2Cov(λh3 , th ), the distributions of λh3 and th can have a modest positive covariance and still yield a case where
Var (λh3 − th ) ≈ Var (λh3 ).
  30 The current bundled payment option offers the choice of only one target price, paired with incentives that make

the hospital the full residual claimant on effort. It would be natural to explore social welfare under menus of contracts
which trade off higher target prices in return for shallower incentives, as in the classic optimal regulation problem
in Laffont and Tirole (1993). However, given that, as shown in Figure 4, selection on levels rather than slopes is the
primary concern, and that the average slope is relatively modest, better targeting of the price level rather than better
design of the screening contracts seems a more fruitful avenue to explore.




                                                           29
6.1    Voluntary vs. Mandatory

We first compare outcomes under the observed period 3 voluntary bundled payment program to

two period 3 counterfactuals: all hospitals mandated to be under the status quo FFS regime (as

they were in period 1), or all hospitals mandated to participate in the bundled payment program

(as they were in period 2). These counterfactuals can be thought of as measuring the impact of the

government’s decision to make the bundled payment program voluntary, relative to cancelling

the program entirely or keeping it mandatory.

      To operationalize this counterfactual exercise, we use our model, together with the parameter

estimates in Table 3 to simulate hospital-specific values for {λh3 , ωh } in period 3 conditional on

the hospital’s period 3 selection decision BPh3 , their target price th , and number of CJR episodes

nh2 from period 2. We assume a social cost of funds of Λ = 0.15.

      Panel A of Table 4 shows the results. The first row reports the results that would occur if

there were no bundled payment program and all hospitals were paid under FFS. Government

spending (i.e., G in the definition of social welfare from Equation 5) averages $24,443 per episode

in this counterfactual (which corresponds to the average λh3 reported in Panel B.2 of Table 3). The

remainder of the entries are normalized to zero; the mandatory FFS counterfactual will serve as a

benchmark to which we compare other regimes.

      The second row of Panel A considers a counterfactual in which all hospitals are mandated to

enroll in bundled payments in period 3, as was intended under the initial design. Under manda-

tory bundled payment, hospitals receive a transfer of (th − λh ) and are residual claimants on the

ω-related savings they generate ( ω2h ). If target prices had been calibrated to equal counterfactual

claims under FFS incentives (E h th = E h λh3 ), government spending would have been unaffected

relative to the baseline. However, as seen in Panel B.2 of Table 3, target prices th were on average

$85 lower than FFS claims, so government spending is $85 lower and (multiplied by 1 + Λ = 1.15)

social costs decrease by $98 (column 3).

      In columns (4) through (7) we consider two different versions of the welfare analysis, depend-

ing on whether we treat the choice shifter νh term as non-welfare relevant or welfare-relevant.

The choice shifter would be welfare-relevant if it represents a real hospital cost - such as fixed

or variable costs of changing behavior, or perhaps uncertainty about λh , which might be greater



                                                 30
for smaller hospitals. The choice shifter might not be welfare relevant, however, if it represents a

choice friction such as status quo bias. In columns (4) and (5), where we assume νh is not welfare

relevant, hospital profits relative to FFS rise by $116 (column 4). This rise reflects the difference

between the ω-related savings of $201 (half of the expected value of ωh from Panel B.2 of Table 3)

and the $85 reduction in government payments. Social surplus rises by $214 (column 5). In other
                                                                     ωh
words, the incentive effects of bundled payment (which generate      2    = $201 in social savings on
average) represent most of the social gain, with the remainder coming from the reduction in gov-

ernment spending. Naturally, if νh is taken into account (as in columns 6 and 7), both hospital

profits and relative social surplus are lowered by its average of $1,419 (see Panel B.2 of Table 3).

    The third row of Panel A considers the voluntary selection scenario that actually took place.

To be consistent with the other counterfactuals, outcomes for voluntary selection are simulated

based on the model parameters. In particular, for each hospital we simulate a binary participation

decision and the resulting government spending, hospital profits, and social surplus. We find that

38.8% of episode-weighted hospitals select into bundled payments, which is almost identical to

the actual selection percentage (37.2% in Table 2), providing assurances about the in-sample fit of
                                                                                                   ωh
our model. As we discussed in Section 5, the much greater heterogeneity in th − λh , relative to   2 ,

suggests that selection into bundled payment is primarily on “levels.” Consequently, voluntary

participation raises government spending relative to the other counterfactuals; specifically, we

estimate that voluntary participation raises government spending per episode by $1,682 relative

to the mandatory FFS benchmark, and by $1,767 relative to the mandatory bundled payment

regime.

    Since hospitals are given a choice, their profits must be weakly higher under the voluntary

regime relative to a mandatory regime. When we treat the νh term as non-welfare relevant, hospi-

tal profits rise to $1,754 above the mandatory FFS benchmark, which is $1,638 higher than under

mandatory bundled payments. Ignoring νh , social surplus under voluntary bundled payments

is lower than under either the mandatory FFS benchmark (-$179, column 5) or the mandatory

bundled payment regime (-$393); lower social surplus reflects both the larger transfers to hospi-

tals and the smaller share of hospitals generating ω-related efficiency gains. When we treat νh

as welfare relevant, hospital profits rise by a smaller amount of $1,248 (instead of $1,754) above

the mandatory FFS benchmark, and social surplus is correspondingly lower. It is worth noting

                                                 31
however that, while negative, social surplus in the voluntary bundled payment counterfactual is

less negative than under the mandatory bundled payment counterfactual (see column 7). Intu-

itively, if we think that the νh -related costs are real, it is important to let hospitals avoid them if the

offsetting ω-related benefits are not large enough.

      Whether or not we treat the νh term as welfare relevant, the results indicate that the volun-

tary bundled payment model reduces social surplus relative to the mandatory FFS status quo.

However, the results do not imply that a voluntary program is necessarily ineffective. Voluntary

bundled payments generates positive ω-related efficiency gains. The reason overall social welfare

is reduced is because these ω-related gains are small relative to the social welfare losses asso-

ciated with “overpaying” participating hospitals relative to their counterfactual FFS claims. We

therefore turn now to exploring whether and how the voluntary program performance could im-

prove if Medicare were able to set target prices to better reflect underlying hospital-specific costs

and thus capture more of the potential $100 million dollars of potential annual ω-related gains in
                                                                                               ωh
social surplus (from approximately 500,000 CJR episodes per year, with an average              2    of about

200).

6.2     Targeting

In order to explore price targeting under voluntary participation in a systematic fashion, we ap-

proximate the observed target prices using a parametric distribution, and then examine the im-

pacts of shifting its parameters. Specifically, we assume that hospital-level target prices, th , are

log-normally distributed and are correlated with hospital costs. We then explore voluntary partic-

ipation under different parameter values. Appendix B provides more details.

      Figure 5 summarizes the outcomes from this exercise, plotting social surplus relative to the

mandatory FFS benchmark (y-axis) against government spending (x-axis) for different target price

counterfactuals. In the plot, we focus on the social surplus values that do not consider νh (column 5

of Table 4). Panel B of Table 4 reports additional outcomes associated with each exercise, including

analyses where νh is considered welfare-relevant. The black dot in Figure 5 corresponds to the

observed distribution of th , and serves as a baseline. The observed target prices are parameterized

by means µts that vary by strata, a standard deviation of σt = 0.17, and a correlation of ρλ3 ,t = 0.81




                                                    32
with claims under FFS (λh3 ).31 Because of the log-normal parameterization, the outcomes for

observed targeting in Panel B of Table 4 are slightly different to those in the voluntary bundled

payments row of Panel A.

     We consider three counterfactual targeting policies. The first, indicated by the point labeled

“perfect targeting,” sets target prices exactly equal to realized claims under FFS (th = λh3 ). Under

this contract, there is no transfer to hospitals (no selection on levels) and hospitals are the full

residual claimants on the ω-related savings they generate. Because there are no transfers to offset

the νh , only 19.9% of hospitals select into bundled payments. These 19.9% generate non-trivial ω-

related surplus gains, but because there are few of them, average total surplus only increases by

$39 per episode (i.e. about one-fifth of the increase that would be achieved if all hospitals selected

in with no transfers).

     “Perfect targeting” is a useful benchmark, but not feasible in the context of our model. To

see this, recall that we model λh3 = λh + g(t) + ǫh3 , where ǫh3 is an iid random variable that

is not predictable in advance. To gauge the benefits of a more feasible contract, we consider a

second scenario (labelled “feasible targeting”) in which Medicare sets a target price of th = λh +

g(t), which is based on the hospital’s underlying type and the time trend.32 The correlation with

realized claims under FFS is reduced to √ σ2λ                = 0.93, which is two-thirds of the way between the
                                                   σλ +σǫ2
correlation for observed target prices (ρλ3 ,t = 0.81) and perfect targeting (ρλ3 ,t = 1). We estimate

that relative to the observed targeting, feasible targeting generates approximately three-fifths of

the social welfare gains that could be achieved with perfect targeting; as a result, under feasible

targeting, social surplus is virtually identical to the FFS benchmark (-$5).

     The above analysis asks how well observed targeting does compared to its potential; the

mirror-image of this is to ask how well it does relative to no targeting. We therefore undertake

a third exercise, labeled “no targeting,” which considers a case in which target prices are uniform

across hospitals at a value equal to the average of λh3 . Relative to the observed targeting, the no

targeting case leads to higher levels of participation in bundled payment, greater (inefficient) se-

lection on levels, greater government spending and higher social costs. Relative to no targeting,
  31 The  values of µt,s for the 8 strata are [10.00, 10.04, 10.04, 10.11, 10.23, 10.05, 10.14, 10.26]
  32 Given
          q our stochastic assumptions, the mean of this contract is unchanged, and the standard deviation is reduced
to σt =      2 − σ2 = 0.17, from σ = σ = 0.18 under perfect targeting.
            σλ,3  ǫ               t   h3




                                                             33
feasible targeting has the potential to generate $189 per episode in social surplus; the observed

targeting in turn generates approximately two-thirds of these feasible gains ($128 = (-66)- (-194)

out of $189).

     While improved information is a natural way for Medicare to achieve better targeting, it is not

the only way to do so. Medicare could also achieve better targeting through a narrower definition

of the bundle. To illustrate, suppose that we can decompose average per-episode claims into two

additive separable components: hospital claims and other claims, which includes post-acute care.

Because hospitals were already paid a predetermined, DRG-based amount under FFS, we do not

expect hospital claims to respond to the incentives from bundled payments. Indeed, the empirical

evidence shows that most of the ω-related savings come from other claims, and post-acute claims

in particular. However, while hospital claims are not a source of ω-related savings, they are het-

erogenous across hospitals, and thus a source of selection on levels. Eliminating hospital claims

from the bundle thus effectively increases the degree of targeting.

     We simulate the effects of two such narrower bundles. In the first, labelled “narrow bundling,

no targeting”, we remove hospital claims from the bundle but assume that we cannot target prices

for other claims. Within our framework, this is equivalent to setting the target price as the sum of

ex post, realized hospital claims and a predetermined, fixed payment for other costs.33 This target

price has correlation coefficient of ρλ3 ,t = 0.76 and reduces social welfare relative to the observed

target prices.

     In the second, called “narrow bundling, observed targeting”, we continue to assume that

hospitals are paid their ex post realized claims, however, we now assume that Medicare can obtain

the same degree of targeting for other claims as the actual target price achieved for total claims.34

Doing so increases the correlation coefficient to ρλ3 ,t = 0.87. This contract generates social gains

relative to the observed voluntary bundled payment program and brings overall social welfare

(-$39) closer to the level from feasible targeting.

     Overall, our findings suggest that while the observed voluntary program is socially costly,
  33 That is, the target price is set to be f hHOSP + E h [ f hOTH ]. We calculate {µt , σt2 , ρλ3 ,t } for this target price using the
empirical distributions of th = f hHOSP + E h [ f hOTH ] and λh .
  34 Specifically, the target price is set to t = f HOSP + tOTH , where tOTH is the other component of the target prices.
                                               h     h           h             h
We set the mean of tOTH h   equal  to  the mean  of  f OTH , the standard deviation to have the same ratio with f OTH as the
                                                       h                                                                    h
observed target price does with λh , and correlation of tOTH    h     and f hOTH equal to the correlation between the observed
target price and λh .



                                                                 34
there are feasible improvements in targeting which could create a voluntary program that would

mostly eliminate social losses (or perhaps even generate small social gains). These could arise

through tailoring target prices better to reflect claims under FFS of each hospital, or focusing the

bundle on a narrower set of services in which cost-savings can be realized.


7   Conclusion
Government regulations are sometimes based on voluntary participation, allowing market ac-

tors to “choose their own incentives.” These voluntary regimes may be socially beneficial if they

induce selection of actors with private information about the net benefits from changing their

behavior, but they may be socially costly if they primarily attract actors who can receive higher

government payments with no behavior change. We explored this tradeoff between “selection on

slopes” and “selection on levels” in the context of Medicare payment reform.

    Our analysis takes advantage of a unique setting in which Medicare introduced an alterna-

tive payment model – called bundled payments – as a randomized trial and then modified the

experimental design in midstream. Bundled payments was originally imposed as a mandatory

participation model for hospitals in 67 randomly selected markets, with hospitals in 104 other

randomly selected markets paid under the status quo. Two years into this five-year experiment,

however, hospitals in half of the 67 randomly selected markets were unexpectedly allowed to

choose whether to remain under bundled payments or revert back to the status quo payment

model. This provided a rare opportunity to observe all hospitals’ behavior under the alternative

model and then to observe which hospitals voluntarily choose to continue under it.

    Both the descriptive evidence and the model estimates indicate that selection was primarily

based on levels rather than on slopes. The main driver of participation in the voluntary bundled

payment model was whether the hospital would benefit financially from the alternative regime

without any change in behavior. We also found selection on slopes – hospitals who changed their

behavior more in response to bundled payments were also more likely to opt in – but selection on

this margin was much less quantitatively important.

    As a result, we estimated that the voluntary bundled payment model generated inefficient

transfers to hospitals and reduced social welfare relative to imposing the status quo fee-for-service

(FFS) payment regime on all hospitals. However, we also estimated that alternative (feasible) vol-


                                                 35
untary designs that targeted reimbursement more closely to hospitals’ claims level under FFS

could reduce these inefficient transfers substantially. Of course, any design with less generous re-

imbursements to "better-performing" actors may raise concerns about fairness, as well as concerns

about ratchet effects (Freixas, Guesnerie and Tirole, 1985).

    Our quantitative results are, of course, specific to our setting. The impact of alternative pay-

ment models in Medicare have tended to be modest – “singles not home runs” in the words of

Frakt (2019a); in our setting, this limits the scope for social-welfare improving selection on slopes.

In other contexts, this scope could be greater. In addition, the design feature that is so helpful

for our empirical work – that we observe hospital behavior under the alternative regime and then

their choices of whether to continue in it – may also affect the selection dynamics relative to a more

typical setting in which actors are given a choice of opting into a new regime without any prior

experience with that regime. For example, hospitals’ prior experience under bundled payments

may have increased hospitals’ information about their levels and/or slopes, thus creating more

selection on one or both of these dimensions. In addition, the expectation that they would have

to participate in bundled payments for five years may have induced hospitals to undertake sunk

investments, which may in turn have affected their participation decisions when it unexpectedly

became optional.

    Beyond the specific quantitative results, our analysis suggests the importance of considering

– and ideally estimating – selection on both slopes and levels in settings in which the regulator

is considering a voluntary regime. While there is an active and ongoing debate over the merits

of voluntary versus mandatory payment reforms, voluntary participation is currently the norm

across Medicare’s alternative payment models. With the partial exception of the program we

study, all other bundled payment models, Accountable Care Organizations, and primary care co-

ordination models have been implemented in a voluntary manner. Moreover, as we noted in the

introduction, voluntary regulation is widespread outside of healthcare, in sectors such as edu-

cation, environmental regulation, and electricity regulation. Exploring the impact and optimal

design of such voluntary programs in these other settings is an important and fruitful direction

for further work.




                                                 36
References
Alexander, Diane. 2017. “How Do Doctors Respond to Incentives? Unintended Consequences
  of Paying Doctors to Reduce Costs.” Working Paper. https://www.chicagofed.org/
  publications/working-papers/2017/wp2017-09.

Barnett, Michael L, Andrew Wilcock, J Michael McWilliams, Arnold M Epstein, Karen E
  Joynt Maddox, E John Orav, David C Grabowski, and Ateev Mehrotra. 2019. “Two-Year Evalu-
  ation of Mandatory Bundled Payments for Joint Replacement.” New England Journal of Medicine,
  380(3): 252–262.

Carroll, Caitlin, Michael Chernew, A Mark Fendrick, Joe Thompson, and Sherri Rose. 2018.
  “Effects of Episode-Based Payment on Health Care Spending and Utilization: Evidence From
  Perinatal Care in Arkansas.” Journal of Health Economics, 61: 47–62.

Cicala, Steve, David Hémous, and Morten Olsen. 2020. “Adverse Selection as a Policy In-
  strument: Unraveling Climate Change.” Working Paper. https://home.uchicago.edu/
  ~scicala/papers/unraveling/unraveling_climate_change_draft.pdf.

Clemens, Jeffrey, and Joshua D Gottlieb. 2014. “Do Physicians’ Financial Incentives Affect Med-
  ical Treatment and Patient Health?” American Economic Review, 104(4): 1320–49.

CMS. 2015a. “Medicare Program; Comprehensive Care for Joint Replacement Payment Model
 for Acute Care Hospitals Furnishing Lower Extremity Joint Replacement Services. Final Rule.”
 Federal Register, 80(226): 73273–73554.

CMS. 2015b. “Medicare Program; Hospital Inpatient Prospective Payment Systems for Acute Care
 Hospitals and the Long-Term Care Hospital Prospective Payment System Policy Changes and
 Fiscal Year 2016 Rates; Revisions of Quality Reporting Requirements for Specific Providers,
 Including Changes Related to the Electronic Health Record Incentive Program; Extensions of
 the Medicare-Dependent, Small Rural Hospital Program and the Low-Volume Payment Ad-
 justment for Hospitals. Final Rule; Interim Final Rule with Comment Period.” Federal Register,
 80(158): 49325–49886.

CMS. 2016. “Medicare Program; Hospital Inpatient Prospective Payment Systems for Acute Care
 Hospitals and the Long-Term Care Hospital Prospective Payment System and Policy Changes
 and Fiscal Year 2017 Rates; Quality Reporting Requirements for Specific Providers; Graduate
 Medical Education; Hospital Notification Procedures Applicable to Beneficiaries Receiving Ob-
 servation Services; Technical Changes Relating to Costs to Organizations and Medicare Cost
 Reports; Finalization of Interim Final Rules With Comment Period on LTCH PPS Payments
 for Severe Wounds, Modifications of Limitations on Redesignation by the Medicare Geographic
 Classification Review Board, and Extensions of Payments to MDHs and Low-Volume Hospitals.
 Final Rule.” Federal Register, 81(162): 56761–57345.

CMS. 2017. “Medicare Program; Cancellation of Advancing Care Coordination Through Episode
 Payment and Cardiac Rehabilitation Incentive Payment Models; Changes to Comprehensive
 Care for Joint Replacement Payment Model: Extreme and Uncontrollable Circumstances Policy
 for the Comprehensive Care for Joint Replacement Payment Model.” Federal Register, 82: 57066–
 57104.

CMS. 2019. “CMS Fast Facts.” Centers for Medicare & Medicaid Services.


                                              37
Cromwell, Jerry, Debra A Dayhoff, and Armen H Thoumaian. 1997. “Cost Savings and Physi-
  cian Responses to Global Bundled Payments for Medicare Heart Bypass Surgery.” Health Care
  Financing Review, 19(1): 41.

Cutler, David M. 1995. “The Incidence of Adverse Medical Outcomes under Prospective Pay-
 ment.” Econometrica, 63(1): 29–50.

Cutler, David M, and Kaushik Ghosh. 2012. “The Potential for Cost Savings through Bundled
 Episode Payments.” New England Journal of Medicine, 366(12): 1075–1077.

DeAngelis, Corey A, Lindsey M Burke, and Patrick J Wolf. 2019. “The Effects of Regulations
 on Private School Choice Program Participation: Experimental Evidence from Florida.” Social
 Science Quarterly, 100(6): 2316–2336.

Doran, James P, and Stephen J Zabinski. 2015. “Bundled Payment Initiatives for Medicare and
 Non-Medicare Total Joint Arthroplasty Patients at a Community Hospital: Bundles in the Real
 World.” The Journal of Arthroplasty, 30(3): 353–355.

Dummit, Laura A, Daver Kahvecioglu, Grecia Marrufo, Rahul Rajkumar, Jaclyn Marshall,
 Eleonora Tan, Matthew J Press, Shannon Flood, L Daniel Muldoon, Qian Gu, et al. 2016.
 “Association between Hospital Participation in a Medicare Bundled Payment Initiative and
 Payments and Quality Outcomes for Lower Extremity Joint Replacement Episodes.” JAMA,
 316(12): 1267–1278.

Dummit, Laura A, Kimberly Smathers, OJ Bright, Rebecca Cherry, McCulloch Cline, Amy
 Cowell, et al. 2018. “CMS Comprehensive Care for Joint Replacement Model: Performance Year
 1 Evaluation Report.” The Lewin Group.

Einav, Liran, Amy Finkelstein, and Neale Mahoney. 2018. “Provider Incentives and Healthcare
  Costs: Evidence From Long-Term Care Hospitals.” Econometrica, 86(6): 2161–2219.

Einav, Liran, Amy Finkelstein, Raymond Kluender, and Paul Schrimpf. 2016. “Beyond Statistics:
  the Economic Content of Risk Scores.” American Economic Journal: Applied Economics, 8(2): 195–
  224.

Einav, Liran, Amy Finkelstein, Stephen P Ryan, Paul Schrimpf, and Mark R Cullen. 2013. “Se-
  lection on Moral Hazard in Health Insurance.” American Economic Review, 103(1): 178–219.

Eliason, Paul J, Paul LE Grieco, Ryan C McDevitt, and James W Roberts. 2018. “Strategic Patient
  Discharge: The Case of Long-Term Care Hospitals.” American Economic Review, 108(11): 3232–65.

Elixhauser, Anne, Claudia Steiner, D Robert Harris, and Rosanna M Coffey. 1998. “Comorbidity
  Measures for Use with Administrative Data.” Medical Care, 8–27.

Finkelstein, Amy, Yunan Ji, Neale Mahoney, and Jonathan Skinner. 2018. “Mandatory Medicare
  Bundled Payment Program for Lower Extremity Joint Replacement and Discharge to Institu-
  tional Postacute Care: Interim Analysis of the First Year of a 5-Year Randomized Trial.” JAMA,
  320(9): 892–900.

Fisher, Elliott S. 2016. “Medicare’s Bundled Payment Program for Joint Replacement: Promise
  and Peril?” JAMA, 316(12): 1262–1264.



                                              38
Frakt, Austin. 2019a. “‘Value’ of Care Was a Big Goal. How Did It Work Out?” The New York Times,
  September 23.

Frakt, Austin. 2019b. “Which Health Policies Actually Work? We Rarely Find Out.” The New York
  Times, September 9.

Freixas, Xavier, Roger Guesnerie, and Jean Tirole. 1985. “Planning Under Incomplete Informa-
  tion and the Ratchet Effect.” The Review of Economic Studies, 52(2): 173–191.

Froemke, Cecily C, Lian Wang, Matthew L DeHart, Ronda K Williamson, Laura Matsen Ko, and
  Paul J Duwelius. 2015. “Standardizing Care and Improving Quality under a Bundled Payment
  Initiative for Total Joint Arthroplasty.” The Journal of Arthroplasty, 30(10): 1676–1682.

GAO. 2018. “Voluntary and Mandatory EpisodeBased Payment Models and Their Participants.”
 United States Government Accountability Office GAO-19-156.

Gronniger, T, M Fiedler, K Patel, L Adler, and P Ginsberg. 2017. “How Should the Trump Ad-
 ministration Handle Medicare’s New Bundled Payment Programs.” Health Affairs Blog, April.

Haas, Derek A, Xiaoran Zhang, Robert S Kaplan, and Zirui Song. 2019. “Evaluation of Economic
 and Clinical Outcomes Under Centers for Medicare & Medicaid Services Mandatory Bundled
 Payments for Joint Replacements.” JAMA Internal Medicine, 179(7): 924–931.

Heckman, James J, and Bo E Honore. 1990. “The Empirical Content of the Roy Mode.” Economet-
 rica, 58(5): 1121–1149.

Ho, Kate, and Ariel Pakes. 2014. “Hospital Choices, Hospital Prices, and Financial Incentives to
 Physicians.” American Economic Review, 104(12): 3841–84.

Ida, Takanori, Koichiro Ito, and Makoto Tanaka. 2020. “Selection on Welfare Gains and Policy
  Design: Experimental Evidence from Electricity Plan Choice.” Working Paper.

Jack, B Kelsey, and Seema Jayachandran. 2019. “Self-Selection Into Payments for Ecosystem Ser-
  vices Programs.” Proceedings of the National Academy of Sciences, 116(12): 5326–5333.

King, Robert. 2019. “CMS to Use Mandatory Models ‘Very Judiciously,’ Official Says.” Modern
  Healthcare, April 26.

Laffont, Jean-Jacques, and Jean Tirole. 1993. A Theory of Incentives in Procurement and Regulation.
  MIT press.

Levy, S, N Bagley, and R Rajkumar. 2018. “Reform at Risk-Mandating Participation in Alternative
  Payment Plans.” New England Journal of Medicine, 378(18): 1663–1665.

Liao, Joshua M, Mark V Pauly, and Amol S Navathe. 2020. “When Should Medicare Mandate
  Participation In Alternative Payment Models?” Health Affairs, 39(2): 305–309.

Marone, Victoria R, and Adrienne Sabety. 2019. “Should There be Vertical Choice in Health In-
 surance Markets?” Working Paper. https://victoriamarone.github.io/jobmarket/
 Marone_JMP_Vertical_Choice.pdf.

Navathe, Amol S, Andrea B Troxel, Joshua M Liao, Nan Nan, Jingsan Zhu, Wenjun Zhong, and
 Ezekiel J Emanuel. 2017. “Cost of Joint Replacement Using Bundled Payment Models.” JAMA
 Internal Medicine, 177(2): 214–222.

                                                39
Newcomer, Lee N, Bruce Gould, Ray D Page, Sheila A Donelan, and Monica Perkins. 2014.
 “Changing Physician Incentives for Affordable, Quality Cancer Care: Results of an Episode
 Payment Model.” Journal of Oncology Practice, 10(5): 322–326.

Quan, Hude, Vijaya Sundararajan, Patricia Halfon, Andrew Fong, Bernard Burnand, Jean-
 Christophe Luthi, L Duncan Saunders, Cynthia A Beck, Thomas E Feasby, and William A
 Ghali. 2005. “Coding Algorithms for Defining Comorbidities in ICD-9-CM and ICD-10 Admin-
 istrative Data.” Medical Care, 1130–1139.

Shatto, John D. 2016. “Center for Medicare and Medicaid Innovation’s Methodology and Cal-
  culations for the 2016 Estimate of Fee-for-Service Payments to Alternative Payment Models.”
  Centers for Medicare and Medicaid Services.

Shepard, Mark. 2016. “Hospital Network Competition and Adverse Selection: Evidence From
  the Massachusetts Health Insurance Exchange.” Working Paper. https://www.nber.org/
  papers/w22600.

Thaler, Richard H, and Cass R Sunstein. 2003. “Libertarian Paternalism.” American Economic Re-
  view, 93(2): 175–179.

Zhu, Jane M, Viren Patel, Judy A Shea, Mark D Neuman, and Rachel M Werner. 2018. “Hospitals
  Using Bundled Payment Report Reducing Skilled Nursing Facility Use and Improving Care
  Integration.” Health Affairs, 37(8): 1282–1289.




                                             40
                                        Figure 1: Experimental Design


                                                     Eligible MSAs
                                               (MSAs=171, Hospitals=1,455,
                                                   Episodes = 100%)


                          Treatment                                                    Control
                   (MSAs=67, Hospitals = 664,                                 (MSAs=104, Hospitals = 791,
                       Episodes = 42%)                                             Episodes = 58%)
                                                                                                            Year 1-2
                                                                                                             Year 3+



    Mandatory Treatment               Voluntary Treatment           Mandatory* Controls            Voluntary* Controls
    (MSAs=34, Hospitals =            (MSAs=33, Hospitals =         (MSAs=52, Hospitals =         (MSAs=52, Hospitals =
     405, Episodes = 23%)             259, Episodes = 19%)          460, Episodes = 33%)          331, Episodes = 25%)



Note: Figure shows the design of the bundled payments experiment. The top half shows the initial mandatory design in
program years 1-2, and the bottom half shows the partially voluntary design in program years 3-5. Episode shares are based
on data from program years 1-2.

∗ Control   group MSAs are assigned to mandatory vs. voluntary by authors using historical spending.




                                                          41
  Figure 2: Hospital Selection Into Bundled Payment and Social Welfare Implications



            ;                                                          !#17"'8'9

                                               !"#"$%&')*
                                               :--.$.",%#/


                      !#17"'8'=9'>

                                                                              !"#"$%&'((!

                     !"#"$%&')*
                    +,"--.$.",%#/

                                                             %                                    <

Note: Figure shows, for a given target price t, the hospital participation decision and social welfare implications as a
function of the hospital’s λ and ω.




                                                          42
                                                 Figure 3: Model Illustration

            (a) Impact of Raising Target Prices                                              (b) Larger ω, More Variable λ


@                                                     !#2<"'='7              1                                        !#4<"'='9

                        !"#"$%&')*                                                                  !"#"$%&')*
                        ;--.$.",%#/                                                                 0--.$.",%#/


       !#2<"'='>7'?                                                                !#4<"'='>9'?

                                                                                                                            !"#"$%&'((!
                                                      !"#"$%&'((!
      !"#"$%&')*                                                                  !"#"$%&')*
     +,"--.$.",%#/                                                               +,"--.$.",%#/

                                      %   %0                        A                                             %                       2



                (c) Smaller ω, More Variable λ                                         (d) More Variable ω, Less Variable λ


;                                         !#1="'>'6                          ;                                        !#1="'>'6
                        !"#"$%&')*                                                                  !"#"$%&')*
                        :--.$.",%#/                                                                 :--.$.",%#/


       !#1="'>'?6'@                                                                !#1="'>'?6'@

                                                !"#"$%&'((!                                                                 !"#"$%&'((!

      !"#"$%&')*                                                                  !"#"$%&')*
     +,"--.$.",%#/                                                               +,"--.$.",%#/

                                      %                             <                                             %                       <



Note: Figure illustrates some of the key analytics in voluntary bundled payment design. Panel A illustrates the
tradeoffs involved in setting higher target payments t′ > t; Panels B through D consider the impact of different
primitives and targeting, with Panel B vs. C comparing outcomes with higher vs. lower ω and Panel C vs. D
comparing outcomes with more vs less unobserved heterogeneity in λ.




                                                                        43
                                         Figure 4: Model Estimates

         (a) No Target Price or Choice Shifter                        (b) Target Price, Ignoring Choice Shifter




                                          (c) Target Price and Choice Shifter




Note: Figure reports the empirical analogues of Figures 2 and 3. Specifically, it reports simulated hospitals based
on our estimates for the 259 hospitals in the voluntary treatment group (see Figure 1), with circles proportional
to the number of episodes. Panel (a) reports results assuming there are no target prices and the choice shifter νh
in the hospital selection equation is not decision-relevant. Panel (b) considers the role of target prices by plotting
λh3 − th − t on the horizontal axis. In addition to adding th , we subtract the average target price t, so that the axis
remains on the same scale as in Panel (a). In Panel (c), we not only net out target prices but also allow the choice
shifter νh to be decision-relevant.




                                                          44
      Figure 5: Medicare Costs and Social Surplus Under Alternative Target Prices




Note: Figure plots social surplus per episode (relative to the FFS counterfactual) against government spending, and
correspond to the values in columns (5) and (2) of Table 4. See that table note for more details.




                                                        45
                                          Table 1: Experimental Estimates

                                                                                               -.)%*/)'
                                                                      !"#$%"&'                             +$*#5*%5'
                                                                                 !"#$%"&'+,   0%)*$1)#$'                 67.*&8)
                                                                       ()*#'                                 2%%"%
                                                                                                233)4$
!"#$%&'(&)%"*+,-&./*%*0"/*1#-&"#2&3145/&67$#2*#8&97$:&;7*,12$<
    !&*91:                                                            ;<=>?@       >=A?B        7CDC         ;?@          ?E??B
         !&*91:'3"%'F#5)G'-519::9"#                                   B>=<@A       ;=>HC        7BC<         HD            ?E?A
         !&*91:'3"%'F#:$9$8$9"#*&'6-!                                  @=B;;       B=>H?        7@DH         B;H          ?E??B
         !&*91:'3"%'I"1)'I)*&$J                                        B=H?B        DBH          7HD         <D            ?EB@
         K$J)%'!&*91:                                                  <=H><        <>B           ;A         <<            ?EA@
    L$9&9M*$9"#
          N81O)%'"3',*P:'9#'F#5)G'-519::9"#                             ;EA         ?E@          7?EB        ?E?           ?E;B
          N81O)%'"3',*P:'9#'F#:$9$8$9"#*&'6-!                           CEC         ;E>          7?EA        ?E;           ?E?;
    ,9:4J*%/)',):$9#*$9"#
         F#:$9$8$9"#*&'6":$'-48$)'!*%)                                ?E>B>        ?EB?@        7?E?>@      ?E??D         ?E??B
         I"1)'I)*&$J'-/)#4P                                           ?E>>D        ?EBDA         ?E??@      ?E?BH          ?EHB
         I"1)'QRS"'I"1)'I)*&$J'-/)#4PT                                ?E>;D        ?E;>;         ?E?@;      ?E?BH          ?E?;
         K$J)%                                                        ?E?;?        ?E?>;        7?E??@      ?E??;          ?E?<
    U".)%#1)#$'+V)#59#/                                               ;<=>?@       >=A?B         >>          ;?H           ?EHH
!"#$%&=(&>?"%*/@&A$",?:$,
    !"1V&94*$9"#'W*$)                                                 ?E?BB        ?E??<         ?E??B      ?E??B          ?E;A
    2W'X9:9$',8%9#/'2V9:"5)                                           ?EBDD        ?E?;C         ?E??>      ?E??>          ?E@B
    D?75*P'-&&'!*8:)'W)*519::9"#'W*$)                                 ?EB?;        ?E?B<        7?E??B      ?E??;          ?EAD
!"#$%&)(&'2+*,,*1#,&"#2&!"/*$#/&)1+71,*/*1#
    Y2ZW'-519::9"#:'QV)%'B=???')#%"&&)):T                              ;DED         B<EH         7?EH        ?E<           ?EB?
    !ZW7)&9/9O&)'Y2ZW'-519::9"#:'QV)%'B=???')#%"&&)):T                 ;>EA         BBE>          ?EB        ?E<           ?EHD
    2&9GJ*8:)%'!"1"%O959$P'+4"%)                                       ;E@          ?E>           ?E?        ?E?           ?EDH

Note: Table shows results from estimating equation (1) by OLS on period 2 data; the regression includes strata fixed effects
and lagged outcomes from period 1. Standard errors are heteroskedasticity robust. Control means and standard deviations
are from period 2. “Claims” include patient cost-sharing. Complication rate is defined, as in Finkelstein et al. (2018), as the
share of CJR-eligible patients who have at least one of eight underlying complications that go into the total hip arthroplasty
/ total knee arthroplasty 90-day complication measure used in the targeted quality score.




                                                                 46
                                                        Table 2: Selection

                                                                                                                    ! .S'#$,4"54+,#,-&.
                                                                    !"#$%&'()      !"#$%&'()         !"#$%&'()
                                                                                                                     /%4S7G4+,#,-&.0$&4
                                                                     *"%&("#       +,#,-&./%         +,#,-&.0$&
                                                                                                                        N955,(,%-,

1$23,(4"546"789&'#7                                                   ::;              <:               ;=>
1$23,(4"54?897"@,749%4A,(9"@4;                                       B;CBDD          ;EC>>E            FEC<=D
A,(-,%&4"54?897"@,749%4A,(9"@4;                                                      :<GFH             >FG=H
!"#$%&'(&)$%$*+,-#&-#&.$/$%0&1!$2,-3&4&56+*-7$0&8$2&98,0-3$:
    *#'927                                                           F>CBF:          F>C;E>            F<C<<<             IGI:
                                                                     JBC:>=K         JEC;<>K           JBCED=K
    *#'92745"(4/%7&9&$&9"%'#4A"7&4L-$&,4*'(,                          EC=;F           EC>=;             BCBBF             IGIF
                                                                     JFCEI:K         JFCIBEK           JFCEE=K
    +M'(,4N97-M'(O,@4&"4/%7&9&$&9"%'#4A"7&4L-$&,4*'(,                :>GDH           :<G:H             E;G>H              IG;I
                                                                    J;>GIHK         J;>GFHK           J;EGBHK
!"#$%&;(&)$%$*+,-#&-#&)%-8$0
    /28'-&4"%4,897"@,4-#'927                                                           .<D>              .>>D             IG<:
                                                                                    J;CD:FK            JFC=:;K
    /28'-&4"%4/%7&9&$&9"%'#4AL*4-#'927                                                 .B;D              .;<<             IGIB
                                                                                      JD<:K            J;CE<EK
    /28'-&4"%4+M'(,4N97-M'(O,@4&"4/%7&9&$&9"%'#4AL*                                   .:G:H             .;GFH             IG;:
                                                                                     J<G=HK            JDGFHK
!"#$%&<(&)$%$*+,-#&-#&=-08,+"%&<>"2"*+$2,0+,*0
    P,'%41$23,(4"54*QR4?897"@,7                                       :I>             :FI               FB;               IG;E
    L3"S,4P,@9'%4T,@7                                                >IG>H           >FGIH             >IG;H              IG=F
    U,'-M9%O                                                         ;=G<H            EG:H             ;>G;H              IGIF
    V"(.8("59&                                                       ;<GBH           F>G>H             ;FGBH              IGI>
    1"%.8("59&                                                       <=GBH           >:GEH             >=G>H              IGB<
    W"S,(%2,%&."X%,@                                                  EGIH           ;IGIH             ;=GDH              IGFI
    +M'(,4X9&M4L3"S,4P,@9'%4Y$'#9&)                                  >IGIH           <DGFH             BDG:H              IGI;
    1"(&M,'7&                                                         =GEH            BG:H              IG>H              IGI=
    P9@X,7&                                                          ::GEH           ::G;H             BFGFH              IGI:
    +"$&M                                                            FFGEH           ;EGBH             FFGEH              IG:;
    Z,7&                                                             :BG:H           E<G;H             FEG=H              IGIF

Note: Table reports means (and standard deviations in parentheses). In Panel A, all outcomes are defined in period 1 (al-
though the target price is defined in period 2). Panel B reports the average (and standard deviation) over different hospitals
of β 1,h from estimating equation (2) by OLS. In Panel C, the ‘’above median CJR episodes” comes from period 1 data, and
“Above Median Beds”, “Teaching”, “For-profit”, “Non-profit”, and “Government-owned” variables are all based on data
from the 2016 American Hospital Association annual survey; we are unable to match 3 hospitals to these survey. For these
outcomes, the number of hospitals in control, select-in, select-out are 329, 73, and 185, respectively. Finally, “Share with Above
Median Quality” is based on a modified version of the hospitals’ composite quality scores from period 2, which is based on
the first 18 points of the score (see footnote 6). p-values of differences are computed based on a simple t-test of equality of the
means.




                                                               47
                                         Table 3: Parameter Estimates

!"#$%&'(&!")"*$+$)&,-+.*"+$-
                       !"#$%&#'             (#)*+!,,*
!" #                      -.*-/              .*.-0
$"                        .*-12              .*../
%&                       3.*.12              .*../
$ '&                      .*.11              .*..4
µω                        /*055              .*2.0
σω                        -*4..              .*645
ρ λ ,ω                    .*5..              .*.26
ν                       3-47...              -57112
!                         .*/..              .*-.-
!"#$%&/(&0*1%.$2&3.-+).45+.6#-
                           !89:               (;89:               <4        <64            <4.            <24             <=4
/787&'%%&96-1.+"%-
λh                        6470.6              /7555          -=75/-       667250         647//4          607/24         557/22
λ h3                      6/7-0=              /752/          -2726-       6-7.=.         6570.5          617014         5-7=25
ωh                          501               -7-6/            --           /1            -64             5//           -7/21
/7:7&;6-1.+"%-&.#&+9$&<6%5#+")=&>)$"+*$#+&?)651&@#%=
λh                        647=20       47/-6       -07/64                 6-7=02         647521          6=7.2=         547241
λ h3                      6/7//5       47146       -170.4                 6.76..         65720=          6271.4         5/712.
t h - λ h3                  304        /70=4       307650                 367=46          -04            672--          27416
ωh                          /.5        -7.00         --                     /2            -60              541          -7/06
(t h - λ h3 ) + ω/2         --1        /70/2       327=/1                 367254           500            6702-         27126
ν/n hᴷ                    3-7/-=        4-5        367510                 3-7425         3-76=2          3-7-6/          30/4

Note: Panel A reports parameter estimates from the model and Panel B.1 reports some key summary statistics implied by
these estimates for all 1,455 hospitals. Standard errors are calculated using the bootstrap method, based on 20 samples of
hospitals drawn with replacement from cells defined by the full interaction of treatment assignment and strata. Panel B.2
reports these implied statistics separately for the 259 hospitals in the voluntary treatment group (see Figure 1). The model is
estimated weighting each hospital by the number of episodes. The summary statistics in panels B.1 and B.2 are computed
from hospital-level simulated data, weighted by the number of episodes per hospital.

⋆   Episode-weighted average of strata-specific estimates.




                                                             48
                                                                       Table 4: Counterfactuals

                                                                                                  RM=*.&=M(SB*&1"(0B&/%".            R=1*.,*.$%&=M(SB*&1"(0B&/%".
                                                0B$."(       T*'".=C"=%(      !"#$%&'"(
                                                                                           !"#$%&'"()*+,&%$#( !"#$%&'"(0*1&$#(   !"#$%&'"()*+,&%$#( !"#$%&'"(0*1&$#(
                                             0"#"1%&=M(R=(    0,"=>&=M      0*1&$#(S*+%+
                                                                                                 -.*/&%            02.,#2+             -.*/&%           02.,#2+
                                                 345             365            375                385                395               3:5                3;5

     !"#$%&'(&)"#*"+,-.&/01&2,%3#+"-.
     <$=>$%*.?(@@0((3A"=1BC$.D5                 EFEG           68H887            E                E                   E                  E                  E
     <$=>$%*.?(A2=>#">(-$?C"=%                 4EEFEG          68H79I           JKI              44:                648               J4H7E6             J4H6E8
     L*#2=%$.?(A2=>#">(-$?C"=%(                7IFIG           6:H469          4HK77            4H;98               J4;K               4H68I              J:I9
     !"#$%&4(&'%+$-#"+5/$&2,%3#+"-.&6$758$0&95+:&;5<<$-$#+&="-7$+&!-5>$0
     -"./"1%(%$.M"%&=M                         4KFKG          68H;8K            796              7K4                 7K                 49:               J4K:
     @"$+&N#"(%$.M"%&=M                        6KF8G          69HE;7            ;67              ;4I                  J9                79;               J7::
     ON+".'">(%$.M"%&=M                        79FIG          69H8IE           4H4K4            4H46:                J::                :;E               J964
     P*(%$.M"%&=M                              84F8G          6:H68;           6HE;8            4HIIE               J4K8               4H794              J;67
     P$..*Q(N2=>#"H(=*(%$.M"%&=M               7IF:G          69H:88           4H7I4            4H6;K               J4E6                ;K:               J9I9
     P$..*Q(N2=>#"H(*N+".'">(%$.M"%&=M         77F:G          69H6;7            K97              K48                 J7K                8K;               J89:




49
     Note: All counterfactuals are conducted on the 259 hospitals in the voluntary treatment group (See Figure 1). We weight the hospital-level simulated data by
     the number of episodes per hospital, so that the statistics are representative of the average episode. In Panel A, row 1 reports results from the counterfactual
     in which BP does not exist and all hospitals are paid FFS, row 2 reports results from a mandatory participation bundled payment counterfactual, and row
     3 reports results from the observed voluntary participation bundled payment regime. Panel B reports results from counterfactual voluntary participation
     regimes that vary in their target prices. Column 2 reports Medicare spending (G from Equation 5). All other columns report results relative to the FFS
     counterfactual. Column 3 reports relative social costs (i.e. (1 + Λ)((th − λh ). Columns 4 and 5 report hospital profits and social surplus relative to the
     FFS counterfactual, under the assumption that νh is not welfare relevant; therefore hospital profits relative to FFS are given by (th − λh ) + ω2h , and social
     surplus relative to FFS is given by ( ω2h − Λ)(th − λh ). Columns 6 and 7 report relative hospital profits and social surplus when νh is welfare relevant and
     therefore subtracted from both.
                       Voluntary Regulation:
             Evidence from Medicare Bundled Payments
                                            Online Appendix
                Liran Einav         Amy Finkelstein                Yunan Ji           Neale Mahoney

A    Maximum Likelihood Estimation
We estimate the parameters of the model using two-step simulated maximum likelihood. For
notational convenience, let HC = { h : BPh2 = 0} be the set of control group hospitals, and let
HCs be the subset of control group hospitals in stratum s. Similarly, let HT = { h : BPh2 = 1}
be the set of treatment group hospitals. Finally, let HV be the set of treatment group hospitals
who were given the decision whether to voluntarily select into the BP program in period 3 and
HM := HT \ HV be the set of treatment group hospitals who were mandated to remain in the
program.
    We weight hospitals according to the average number of CJR episodes at that hospital so
that our estimates are representative of the average episode in our sample. Let wh denote these
hospital importance weights and let WC = ∑h∈ HC wh denote the sum of control hospital weights
and WCs = ∑h∈ HCs wh be the sum of hospital weights in stratum s.
    In the first step, we estimate the parameters θ1 = {µλ , σλ , γ, σǫ } that determine the evolution
of λ using data from the control group alone. The first step log likelihood is

                                          ln L =    ∑      wh ln f (yh1 , yh2 |θ1 )                    (7)
                                                   h∈ Hc


where {yh1 , yh2 } are data and f is their joint density function.
    Our distributional assumptions imply that ln yh1 and ln yh2 are jointly normally distributed,
allowing us to derive the maximum likelihood estimators in closed form. The first step maximum
likelihood estimators are:

                      1
                b=
                γ
                     WC    ∑      wh [ln yh2 − ln yh1 ]                                                (8)
                          h∈ HC
                         1
                       2WCs h∈∑
                d
                µ λ,s =                         b + ln yh2 ] for s = 1 . . . 8
                                   wh [ln yh1 + γ                                                      (9)
                               HCs
                      s
                         1
                        WC h∈∑
                σbλ =            wh (ln yh1 − µd      b)(ln yh2 − µ
                                                λ,s + γ           d λ,s )                             (10)
                              HC
                      v      "                                                     #
                      u
                      u 1
                σbǫ = t                                                                   2
                        2WC h∈∑
                                    wh [(ln yh1 − µd      b)2 + (ln yh2 − µ
                                                    λ,s + γ               d      2
                                                                            λ,s ) ] − σbλ             (11)
                                 H    C



    In the second step, we estimate the remaining parameters θ2 = {µω , σω , ρλω , ν} of the joint
distribution of {λ, ω } and choice shifter ν, conditional on the first step estimates θb1 . Because the

                                                              50
control-group hospitals provide no information about these second-step parameters, the entire
second step relies only on the hospitals in the treatment group. The second-step log likelihood is
thus given by

                 ln L =     ∑      wh ln g1 ( BPh3 , yh2 |θb1 , θ2 , yh1 ) +    ∑      wh ln g2 (yh2 |θb1 , θ2 , yh1 )        (12)
                           h∈ HV                                               h∈ HM


where g1 is the joint distribution of { BPh3 , yh2 } and g2 is the marginal distribution of yh2 .
    Operationally, we estimate the joint distribution by decomposing it into the conditional choice
probability and marginal distribution

          ln g1 ( BPh3 , yh2 |θb1 , θ2 , yh1 ) = ln Pr( BP = BPh3 |θb1 , θ2 , yh1 , yh2 ) + ln g2 (yh2 |θb1 , θ2 , yh1 ),     (13)

so that

             ln L =     ∑      wh ln Pr( BP = BPh3 |θb1 , θ2 , yh1 , yh2 ) +        ∑      wh ln g2 (yh2 |θb1 , θ2 , yh1 ).   (14)
                       h∈ HV                                                      h ∈ HT


Since neither the choice probability nor the marginal distribution of yh2 has a closed-form solution
(because they depend on yh2 = λh2 − ωh , which is the difference of two log normally distributed
variables), we need to use simulation to construct the likelihood function. For a given set of pa-
rameters θ2 , we simulate many values for λh2 and ωh . We then estimate the marginal density using
a kernel estimator and multiple it by the choice probability to construct the simulated likelihood.
    We tested our estimator by simulating data based on known parameters and then estimat-
ing the model on these simulated data. We found that the estimator performed well when we
draw 50,000 values for each set of candidate parameter values, and estimate the marginal density
function g2 using a Epanechnikov kernel with a bandwidth of 400. We maximize the likelihood
by conducting a grid search over θ2 , which in testing we found worked more reliably than other
methods.

B    Target Price Distribution
For the estimation of the model we use the observed target prices. However, in order to explore the
impact of better targeting in a systematic fashion in our counterfactual exercises, we approximate
the observed target prices using a parametric distribution, and then change these parameters. In
this appendix we provide more details about this exercise.
    We model target prices as log normally distributed, such that they are correlated with hos-
pitals costs λh (but only correlated with ωh via the correlation between λh and ωh ). Since target
prices are partially based on lagged hospital spending, and we allow mean hospital spending to
vary by strata, we also allow the mean of the target price distribution to vary by strata.
    Following the notation in Appendix A, let HT = { h : BPh2 = 1} be the set of treatment
group hospitals. We weight hospitals according to the average number of CJR episodes at a given
hospital. Let wh denote these hospital importance weights and let WT = ∑h∈ HT wh denote the sum

                                                                51
of treatment hospital weights and WTs = ∑h∈ HTs wh be the sum of hospital weights in strata s.
     We only observe target prices for treatment group hospitals in period 2. Using these data,
the maximum likelihood estimators for the mean and standard deviation of the log target price
distribution are given by:

                                         1
                                       WTs h∈∑
                                 µcts =          wh ln th2 for s = 1 . . . 8                                 (15)
                                             HTs
                                       s
                                           1
                                 σbt =       ∑   wh (ln th2 − µcts )2 .                                      (16)
                                         WT h∈ H
                                                             T



     We estimate ρλt using the covariance between log spending in period 1 (ln yh1 ) and the period
2 log target price (ln th2 ). The covariance is given by

           Cov(ln yh1 , ln th2 ) = Cov(ln λh − γ + ǫh1 , ln th2 ) = Cov(ln λh , ln th2 ) = ρλt σλ σt         (17)

where the ǫh1 drops out because it is assumed to be independently drawn and thus Cov(ǫh1 , ln th2 ) =
0.
     It follows that the maximum likelihood estimator of the correlation is

                                   1 1
                        ρc
                         λt =
                                 σbλ σbt WT         ∑       wh (ln yh1 − µc    b)(ln th2 − µcts ).
                                                                          λs + γ                             (18)
                                                   h ∈ HT


where σbλ , µc        b are the estimates described in Appendix A. For our counterfactuals, it will be
             λs , and γ
more natural to adjust the correlation between λh3 and ln th (than the correlation between λh and
                                              σbλ
                                  λ3 t = q
ln th ). This object is given by ρd                      ρc
                                                          λt .
                                           σbλ 2 + σbǫ 2
      To examine the impact of better targeting, we simulate data using different parameters for the
target price distribution, and then examine how these alternative target prices impact selection,
Medicare costs, hospital profits, and social surplus. We simulate data in two steps. First we
draw values for {λh3 , ωh } conditional on the observed th and nh . To do so, we draw from the
unconditional distribution of {λh3 , ωh } and then keep the draws that imply an optimal selection
decision such that BP = BPh3 at these values.
     Second, we draw target prices for a given set of parameters, conditional on the simulated
                                                                                                     j   j
values of λh3 from step 1. Let j be a counterfactual associated with the triplet {µt , σ j , ρλ3 t } for the
                                 j                 j                                                            j
distribution of target prices th . Since th and λh3 are jointly log normal, the conditional values of th
can be simulated as
                                               j
                                              ρλ3 t σt
                                                       j                   q
                             j        j                                               j       j
                            th   =   µt   +                (λh3 − µλ ) +       1 − (ρλ3 t )2 σt ǫh           (19)
                                               σλ3

where ǫh ∼ N (0, 1) is an independent, normally distributed random variable. Importantly, we
keep the draws of ǫh for each hospital fixed throughout the set of counterfactual exercises, so that


                                                                  52
differences in outcomes across exercises are not driven by simulation variation.

C    Stop-Loss and Stop-Gain
As we discussed in Section 2, CJR was not implemented as a “pure” bundled payment program.
Instead, like most bundled payment programs, it limited risk exposure to both hospitals and Medi-
care. In particular, the reconciliation payments for the difference between target prices and real-
ized FFS claims were capped on either side by stop-gain and stop-loss amounts. These amounts
increased from a stop-gain of 5 percent of th and a stop-loss of zero (meaning that hospitals would
never need to make payments to Medicare) in year 1, to stop-gain and stop-loss amounts of ± 20
percent of th in years 4 and 5 of the program.
    Qualitatively, we do not see these provisions as affecting the basic economics of the envi-
ronment. For instance, while some hospitals receive smaller reconciliation payments when the
stop-gain binds, because this provision targets the tail of the distribution, the affected hospitals
are unlikely to be marginal in their selection decision. The same logic holds for the cap on losses.
    To quantitively assess the importance of the stop-gain and stop-loss provisions, we estimate
an alternative version of the model that caps reconciliation payments at ± 20 percent and we redo
our counterfactuals with these estimates. In testing, we found that we required a larger number of
draws for reliable estimation of the model, and this was not feasible on the computer server with
the research identifiable claims data. To estimate this alternative model, we therefore removed
hospital-level data for the 1,326 of 1,455 hospitals where we had adequate sample size to preserve
anonymity (11 or more episodes in periods 1 and 2) and estimated the model on a more powerful
computer server. The hospitals we dropped are those with the smallest number of episodes, and
we confirmed that the estimates of the baseline model (without stop-gain or stop-loss) were very
similar when they were excluded. Appendix Table A3 reproduces Table 4 using the stop-loss and
stop-gain version of the model. While the exact numbers are slightly different, the qualitative
patterns in the tables are identical and the quantitive estimates are very similar.




                                                 53
                                                  Figure A1: Selection on Hospital Characteristics

                                   (a) Pre-Period CJR Episodes                                                                (b) Composite Quality Score
              .005




                                                                                                          .1
                        .004




                                                                                                                    .08
  Selection Into Treatment




                                                                                               Selection Into Treatment
                 .003




                                                                                                              .06
        .002




                                                                                                     .04
.001




                                                                                             .02
              0




                                                                                                          0
                               0     200            400             600           800                                     0       5               10             15                 20
                                      Number of CJR Episodes in Pre Period                                                                   Official CQS

                                    Hospital Selected In        Hospital Selected Out                                          Hospital Selected In         Hospital Selected Out




 Note: Figure shows kernel densities of hospital characteristics by whether the hospital selected in or out of the
 CJR program in period 3.




                                                                                        54
                 Table A1: Experimental Estimates: Alternative Specifications

                                                   (4+?X),)&;'M#S)7-K$)F     (4+?X),)&;'Z)7-K$)F     J"8U7$*&?X),)&;'Z)7-K$)F
                                                                +,)%*-)'                 +,)%*-)'                   +,)%*-)'
                                                   !"#$%"&'                 !"#$%"&'                 !"#$%"&'
                                                               .%)*$/)#$'               .%)*$/)#$'                 .%)*$/)#$'
                                                    ()*#'''                  ()*#'''                  ()*#'''
                                                                 011)2$'                  011)2$'                    011)2$'
                                                    3456          3406''     3456          3406''      3456           3406''
                                                                !"#$%&'                  !"#$%&'                    !"#$%&'
!"#$%&'(&)$"%*+,"-$&./$&"#0&12$#03#4
   !&*7/8                                          9:;<=>         ?@A@      9:;BAA         ?:A<       9:;BAA          ?>=@
                                                   3<;C=D6       39=>6      3<;<>>6       39D<6       3:;D>96        39BC6
                                                                 ()((*                    ()((+                      ()*,-
     !&*7/8'1"%'E#F)G'+F/7887"#                    D<;:>C         ?D@:      D<;@:>         ?DD@       D<;@:>           ?>@
                                                   39;<B@6        3BA6      39;=@A6        3AD6       39;C@=6        3D<<6
                                                                  ()(.                     ()/(                       ()+0
     !&*7/8'1"%'E#8$7$H$7"#*&'I+!'                  >;D99         ?>AB       >;DD@         ?<<<        >;DD@          ?<9<
                                                   3D;<B=6       3D9B6      3D;99=6       3D9D6       39;>DD6        3D9<6
                                                                 ()((*                    ()((+                      ()(*(
     !&*7/8'1"%'J"/)'J)*&$K                         D;B=D          ?BA       D;AA@          D@        D;AA@             9C
                                                    3ADB6         3:A6       3B@96         3B@6       3AAC6           3BA6
                                                                  ()*1                     ()-,                       ()+-
     L$K)%'!&*7/8                                   :;B<:           9C       C;=<9          D=         C;=<9            BA
                                                    3:<D6         3::6       3:<B6         3>>6       3D=>A6          3BC6
                                                                  ().1                     ()-/                       ()0(
   M$7&7N*$7"#'()*8H%)8
     OH/P)%'"1'5*Q8'7#'E#F)G'+F/7887"#               9RC           ?=RD       9RC          ?=R=D        9RC            =R=
                                                    3=R>6         3=R=>6     3=R<6         3=R=>6      3=RC6         3=R=>6
                                                                   ()/*                     ()+0                      ()-+
     OH/P)%'"1'5*Q8'7#'E#8$7$H$7"#*&'I+!             @R@           ?=RC       @RC           ?=R<        @RC           ?=R>
                                                    39R<6         3=R9<6     3DRA6         3=R9D6      3>R96         3=R9D6
                                                                   ()(/                     ()*1                      ()(-
   5782K*%-)'5)8$7#*$7"#
     'E#8$7$H$7"#*&'I"8$'+2H$)'!*%)                 =R<D<        ?=R=<>      =R<9=        ?=R=9D      =R<9=           ?=R=9D
                                                   3=RD=>6       3=R==A6    3=R=A<6       3=R==A6    3=RD:D6         3=R==A6
                                                                  ()((*                    ()(/(                      ()(/(
     'J"/)'J)*&$K'+-)#2Q                            =R<<A          =R==>     =R<@B          =R=9:     =R<@B            =R=9C
                                                   3=RDAC6       3=R=DB6    3=RD@<6       3=R=DA6    3=R9996         3=R=DB6
                                                                   ()-*                     ()*2                       ()*.
     'J"/)'3ST"'J"/)'J)*&$K'+-)#2Q6                 =R<9A          =R=>9     =R9BA          =R=D<     =R9BA           =R==:
                                                   3=R9<96       3=R=DB6    3=R9D96       3=R=DB6    3=R9C:6         3=R=9=6
                                                                   ()(/                     ()1,                       ()-/
     'L$K)%                                         =R=9=         ?=R==>     =R=D<         ?=R==>     =R=D<           ?=R==>
                                                   3=R=<96       3=R=DB6    3=R=9<6       3=R==96    3=R=<=6         3=R==96
                                                                   ()(,                     ()(-                       ()(,
!"#$%&5(&67"%3*8&9$"/7-$/
   !"/U&72*$7"#'V*$)                                =R=DD         =R==D      =R=DD         =R==D      =R=DD           =R==9
                                                   3=R==:6       3=R==D6    3=R==>6      3=R===:6    3=R=D=6        3=R===:6
                                                                  ()/.                     ()(/                        ()(*
   0V'W787$'5H%7#-'0U78"F)                          =RDAA         =R==<      =RDA>         =R==9      =RDA>           =R==9
                                                   3=R=9@6       3=R==<6    3=R=9D6       3=R==96    3=R=>@6         3=R==<6
                                                                  ()1*                     ()1/                        (),*
   A=?F*Q'+&&'!*H8)'V)*F/7887"#'V*$)                =RD=9        ?=R==D      =RD=<        ?=R==9      =RD=<           ?=R==D
                                                   3=R=D:6       3=R==96    3=R==>6       3=R==96    3=R=<D6         3=R==96
                                                                  ().2                     ()//                        ()1(
!"#$%&:(&'0;3//3<#/&"#0&!"*3$#*&:<;2</3*3<#
   X0YV'+F/7887"#8'3U)%'D;===')#%"&&))86            9ARA           ?=RB      9@R<           ?=R:       @RA              ?=R:
                                                   3D:RB6         3=R:6     3D<RC6         3=R<6      3D9R>6           3=R96
                                                                  ()*(                     ()*.                        ()(/
   !YV?)&7-7P&)'+F/7887"#8'3U)%'D;===')#%"&&))86    9<RC           =RD       9DRD            =RD        CR@             ?=R>
                                                   3DDR<6         3=R:6      3AR@6         3=R:6       3AR:6           3=R96
                                                                  ()-2                     ()-+                        ()(/
   0&7GK*H8)%'!"/"%P7F7$Q'42"%)                      9R>         ?=R==D       9R<         ?=R==C        9R<          ?=R===D
                                                    3=R<6        3=R=9A6     3=R96        3=R=9B6      3=R>6         3=R=9@6
                                                                  ()2-                     ()-,                          *

Note: Table compares regression estimates in Table 1 with estimates from two alternative specifications:
an MSA-level specification, where observations are weighted based on number of episodes in the MSA
in period 2, and a hospital-level specification where observations are weighted based on the number of
episodes at the hospital in period 2. See Table 1 note for more details.


                                                               55
                          Table A2: Selection on Slopes with Hospital-Specific Trends

  !"#$%&%$'(%)*+                                                       N'7#-%*#                                      O%(K1P)7"%('-2!"#$%&%$1Q/#*;
                                                                                  52,'-.#1)&1!#-#$(23*1                                     52,'-.#1)&1!#-#$(2
                                                    ,)-.*('/011 ,)-.*('/01!#-#$(2                         ,)-.*('/01111     ,)-.*('/01111
                                                                                     6781!#-#$(24.(1                                         3*16781!#-#$(24.(1
                                                    !#-#$(23*         4.(                                 !#-#$(23*        !#-#$(24.(
                                                                                       9%&&#/#*$#                                                9%&&#/#*$#


  3:"'$(1)*1#"%7);#1$-'%:7                             2<=>            2>>=               ?8<@               2@>A              @BC                 ?8DA
                                                     EFG=@AH         EAGB@FH                               EDG@@CH          EF?G?FBH
  3:"'$(1)*13*7(%(.(%)*'-15IJ1$-'%:7                   2CF=            2F<<               ?8?C               2@?C               D>                 ?8D=
                                                       E=<@H         EFGD<DH                               EAGB=>H           EDGB<>H
  3:"'$(1)*1!K'/#19%7$K'/L#;1()13*7(%(.(%)*'-15IJ     2@8@M           2F8AM               ?8F@              2@8?M             2?8<M                ?8D>
                                                      E<8BMH         E=8AMH                               EF>8?MH           EAA8CMH




Note: The panel titled “Baseline” replicates Table 2 Panel B from the paper, and reports the average (and standard
deviation) over different hospitals of b1,h from estimating equation (2) by OLS. The panel titled “With Hospital-
Specific Trend” reports the analogous results from estimating and augmented version of equation (2), which addi-
tionally controls for hospital-specific linear time trends. Specifically, we report estimates of β 4,h from the regression
yh = β 0 + β 1,h + β 2,t + β 3,h × t + β 4,h × BPh + ǫh,t , where β 1,h are hospital fixed effects, β 2,t are calendar year fixed
effects, β 3,h × t are hospital fixed effects interacted with a linear time trend, and β 4,h × BPh are hospital fixed effects
interacted with an indicator for treatment hospitals in period 2 (when bundled payment was in effect); we estimate
this equation using data from 2013, 2014, 2016 and 2017. All estimates are weighted by the number of episodes in the
hospital in period 2. The p-values in columns (3) and (6) are based on robust standard errors.




                                                                         56
                Table A3: Counterfactuals from Alternative Specification with Stop-Loss and Stop-Gain Provisions

                                                                                                          RM=*.&=M(TB*&1"(0B&/%".               R=1*.,*.$%&=M(TB*&1"(0B&/%".
                                                0B$."(0"#"1%&=M( S*'".=C"=%(   !"#$%&'"(0*1&$#(
                                                                                                  !"#$%&'"()*+,&%$#(    !"#$%&'"(0*1&$#(   !"#$%&'"()*+,&%$#(    !"#$%&'"(0*1&$#(
                                                       R=(        0,"=>&=M         T*+%+
                                                                                                        -.*/&%              02.,#2+              -.*/&%             02.,#2+
                                                      345              365           375                 385                   395                3:5                  3;5

     !"#$%&'(&)"#*"+,-.&/01&2,%3#+"-.
     <$=>$%*.?(@@0((3A"=1BC$.D5                      EFEG            68H7;E          E                    E                    E                   E                    E
     <$=>$%*.?(A2=>#">(-$?C"=%                      4EEFEG           68H79I         J47                  44;                 47E                J4H766               J4H7EI
     K*#2=%$.?(A2=>#">(-$?C"=%(                     7IFLG            6:HE9;        4HL84                4H;6I                J647                4H67:                J;E8
     !"#$%&4(&'%+$-#"+5/$&2,%3#+"-.&6$758$0&95+:&;5<<$-$#+&="-7$+&!-5>$0
     -"./"1%(%$.M"%&=M                               4LFIG            68H:;7        78L                  79I                   L                  494                 J4LI
     @"$+&N#"(%$.M"%&=M                              6IFIG            68HL;I        ;EE                  ::7                  J7;                 787                 J79;
     ON+".'">(%$.M"%&=M                              79FEG            69H7::       4H48:                4HE9E                 JL:                 :7I                 J9EL
     P*(%$.M"%&=M                                    84F4G            6:H4:7       6HE:6                4HI78                J66L                4H779                J;6I
     P$..*Q(N2=>#"H(=*(%$.M"%&=M                     7IF4G            69H99E       4H79;                4H667                J478                 ;;L                 J9;I
     P$..*Q(N2=>#"H(*N+".'">(%$.M"%&=M               77FEG            69H4IE        L76                  I:E                  J;6                 8I9                 J88;



     Note: Table reports analogue outcomes to Table 4 based on an alternative specification of the model with stop-loss and stop-gain provisions for reconcilia-




57
     tion payments. See Appendix Section C for more details.
