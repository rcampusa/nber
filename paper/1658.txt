                    NBER WORKING PAPER SERIES




                   OPTIMAL DYNAMIC R&D PROGRAMS


                         (flg   M


                           Carl Shapiro



                      Working Paper No. 1658




              NATIONAL BUREAU OF ECONOMIC RESEARCH
                    1050 Massachusetts Avenue
                       Cambridge, MA 02138
                            July 1985




We are greatly indebted to Avinash Dixit for his invaluab'e input
into Sections II and III, and to Robert Willig for his suggestions
that allowed us to extend our earlier results in Section IV. We
thank Michael Katz, David Newbery, and seminar participants at the
University of Pennsy'vania for their coments, and the National
Science Foundation under Grant #SES—8408622 for financial support.
Grossman also acknowledges the support of the Alfred P. Sloan
Foundation. The research reported here is part of the NBER's
research program in Productivity. Any opinions expressed are those
of the authors and not those of the National Bureau of Economic
Research.
                                               NBER Working Paper 111658
                                               July 1985




                     Optimal Dynamic R&D Programs



                                 ABSTRACT




     We study the optimal pattern of outlays for a single firm pursuing an R&D
program over time. In the deterministic case, (a) the amount of progress
required to complete the project is known, and (b) the relationship between
outlays and progress is known. In this case, it is optimal to increase effort
over time as the project nears completion.

     Relaxing (a), we find in general a simple, positive relationship between
the optimal expenditure rate at any point in time and the (expected) value at
that time of the research program. We also show that, for a given level of
expected difficulty, a riskier project is always preferred to a safe project.
Relaxing (b), we find again that research outlays increase as further progress
is made.




Gene N. Grossman                                 Carl Shapiro
Woodrow Wilson School                            Woodrow Wilson School
Princeton University                             Princeton Univers ity
Princeton, NJ 08544                              Princeton, NJ 08544
(609) 452—4823                                   (609) 452—4847
I.   Introduction



     Many research projects, as well as some types of investment programs for

the installation of physical capital, can be described as follows: measurable

progress is achieved over a period of time, but the investment yields no

returns until the entire project is completed. Examples of this include

laboratory development of a new product or process, the construction of a new

building, and the writing of a scholarly journal article. When confronted with

investment opportunities of this sort, individuals and firms must decide how

many resources to devote to the project at each point in time. Implicitly,

this also determines the (expected) duration of the project.

     In this paper we characterize the optimal time path of R&D outlays when a

"prize" is earned only after some discrete amount of progress is achieved. We

study both deterministic R&D ventures, where the amount of progress necessary

for success is known at the outset, and uncertain or "risky" projects, where

the difficulty of the endeavor is initially unknown. In the latter case

advancement will imply not only the completion of more stages of the research,

but also an updating of beliefs about the distance still to be covered. Our

characterization will include a comparison of the dynamics of safe and risky

research endeavors.

     In the analysis that follows we treat the determination of a dynamic R&D

investment profile as an optimal control problem facing a single firm. This

can be thought of as an uncontested pursuit of a patent for a new product, or a

project to improve the technology for producing output in a competitive

industry. (The dynamics of oligopolistic interaction in a multi-phase patent

race are the topic of our current research efforts.) We present the solution

to the deterministic program in Section II. In Section III, we analyze a model
                                      -2—




of risky R&D in which the relationship between expenditures and progress is

known, but the amount of progress necessary to complete the project is unknown.

We discuss the effects of this type of uncertainty on both the value of the

program and the optimal expenditure pattern in Section IV. Then, in Section V,

we study a rather different formulation of riskiness: the amount of progress

required for completion is known, but the relationship between effort and

progress is stochastic. A final section summarizes our findings.

    The remainder of this introduction places our work in context in relation

to the existing R&D literature. In the game-theoretic literature, research and

development is most often modelled either as a static allocation problem (e.g.,

Dasgupta and Stiglitz (1980)), or as a dynamic problem only in the limited

sense that there is a flow probability of success at any point in time that

depends on the current level of effort (e.g., Lee and Wilde (1980)). In the

latter case the decision environment is static until an innovation is made, so

there is no reason for a firm to alter its behavior over time. Thus, in the

most common theoretical formulations of the determinants of R&D outlays, the

question of the dynamic program of spending does not arise.

    More recent contributions to this literature have emphasized the

investment-like qualities of expenditures on R&D. Fudenberg, et.al. captured

the notion of "progress's in their model of a two-firm patent race. However,

throughout most of their paper they did not allow firms to vary the intensity

of research effort, which of course precluded study of the profile of R&D

spending.1 Harris and Vickers (1985) also modelled progress in their recent




     11n a final section of their paper, Fudenberg, et.al. (1983) do allow
firms to choose among two levels of effort, but they are concerned with a
different set of issues than we address here, namely how the presence of
information lags regarding a rival's actions affects competitive racing
strategy.
                                           -3-.




paper on patent races. They specified a (deterministic) research project

facing each of two firms that is quite similar to the one that we posit for our

single firm   in   Section II. Furthermore, they found that in a perfect

equilibrium only one firm    actually   engages in research, and it "almost always"

acts as it would if it faced no rivalry. However, they did not investigate the

investment behavior of this single firm,          as   they concentrated instead on the

determinants of the identity of the winning firm. Finally, Judd (1985) has

studied a patent-race model that bears some similarity to the stochastic

version of our control problem in Section III, but he was able to provide

results only under the restrictive assumption that the prize for success is

negligibly different from zero.2

     Our work is most closely related to two earlier papers in the

decision-theoretic R&D literature. Lucas (1971) studied the same deterministic

R&D problem that we analyze in Section II. We extend his characterization of

the optimal research program and provide an analysis of its comparative

dynamics. Kamien and Schwartz (1971) have studied one case of the risky R&D

investment program that we analyze in Section III. We use different techniques

which allow us both to characterize more clearly and fully the solution to the

control problem and to give an economic interpretation of the first-order

conditions. Our approach then permits us to study the effects of riskiness on

R&D outlays in Section IV.




     2The model in Reinganum (1981) shares some of the features of our
formulation, but as we discuss below, the dynamics there are generated entirely
by the artifact of an assumed terminal date before which time all research
projects must be completed.
                                                   -4-




II. Optimal R&D Programs for Projects of Known Difficulty



         A firm seeks a prize of size W.3 To obtain this prize it must "travelt1 a

distance L. We denote by x the distance that has been covered by date t with

     =   0.   Progress is achieved via the expenditure of resources. Let the rate

                                    =
of advance be given by
                                        f(c),   where c is the R&D outlay at time t. We

assume that there exists a c > 0 such that f(c) = 0 for all c < c            ,   and f' (c) >

O   and f"(c) < 0 for all c >           . In other words, we posit decreasing returns to
effort at any point in time given that some progress is being made, but we

allow for the possibility of a fixed start-up cost c at every moment.

         The firm discounts future receipts and expenditures at rate r. Its

problem is to choose expenditures at every point in time up to some terminal

date, as well as the date of termination, T, to maximize the presented

discounted value of the stream of net profits, subject to the constraint that

the total progress attained by the termination date be sufficient to complete

the project. We write this control problem as follows:



                                T
                        -rT
               max We         -f ce-rtdt
                                0
              {c},T


                                        T
                      subject to f f(c)dt > L
                                        0




     3The amount W can represent the present discounted value at the time of
completion of the project of a stream of profits from then into the future. If
the firm is risk neutral (which we will assume to be the case below when we
introduce uncertainty about the difficulty of the project), then it can also be
the expected value of a prize of unknown size.
                                                  -5-




Let n(W, L) be the solution, i.e., the present discounted value of maximal

profit when a prize W is at a distance L.

        The program is solved in two stages. First we consider the sub-problem

for a given terminal date T, the maximized value of which we denote U(T; W,L).

The Lagrangian for this sub-problem is




            H =      eT      -
                                 f    ctertdt +    X[f f(c)dt   -   LI.


The first-order condition for c is4



                     =   _ert + Xf'(c)   = 0




i.e.,

            f'(c) =         et/X                                          (1)



or




                 =   ft   1(e rt/X)                                       (1)


Substituting (1') into the first-order condition for X gives



             T
            5 f(f?i(ert/X))dt L                                           (2)
             0




     4The second-order condition is ftt(c) < 0, which is satisfied at any
(interior) solution. If it is optimal to undertake the research program, then
it cannot ever be optimal to choose c = 0. Doing so would simply delay the
entire program, reducing its value.
                                             -6-




Let the value of A that satisfies (2) be written as X(T, L) and note for later

reference that XL > 0 and AT < 0, where subscripts denote partial derivatives.

     Equation (1) describes a set of paths of R&D expenditures (indexed by A)

that increase over time in such a way that the marginal product of effort falls

exponentially at rate r. Lucas (1971) noted this Hotelling-like property for a

general fCc) and explicitly solved the problem for the special case f(c) =   c.
Only one of the paths satisfying equation (1) reaches L at time T; higher

values of A imply greater effort at each date. The path that does reach L at

time T is optimal for the

sub—problem; it has initial effort given by f'(c0) =         l/X(T,   L).

     Now the solution to the full problem is found by substituting for the

arbitrary T above the date of termination that maximizes U(T; W,L).

The first-order condition is




           UT(T; W,L)
                         _reT -        cTe
                                              +
                                                   X(T,L)f(cT)
                                                                 =    0


or



            rW =                   -
                   X(T,L)f(cT)eT       CT



where we have omitted terms involving ace/aT and X/3T by application of the

envelope theorem.5 The optimal path,{c}, completion time, T(W,L), and

corresponding multiplier, X(W,L), simultaneously satisfy conditions (1), (2)

and (3).




     5The second-order condition, UTT(T; W,L) < 0, is satisfied at any interior
point where U = 0.   If the project is not worth undertaking, then we will have
UT > 0 for all T.
                                         —7—




     The qualitative properties of the optimally-designed research program can

be understood intuitively as follows. If the discount rate is strictly

positive, it cannot be optimal to apply effort to a project evenly throughout.

Relative to this allocation, the discounted development costs could be

decreased for i given duration of the project by shifting expenditures from

the early stages to those later on. Only if the discount rate is zero will it

be optimal to spend at a constant rate, that rate being the one that maximizes

the rate of progress per dollar spent, f(c)/c.6

     Given that the intertemporal pattern of expenditures maintains a constant

discounted marginal product of research outlays, the initial intensity of

effort is chosen so that the marginal benefit of completing the project a

moment sooner is equal to the marginal cost of doing so. The marginal benefit

is rW +         the instantaneous return on holding the prize plus the expenses
          CT,
that would no longer need to be borne at T if the project were to be completed

before then. The marginal cost is f(cT)/f'(cT), the extra outlay that would be

required to travel a distance f(cT) farther at the moment before time T so as

to ensure completion of the project. Note that rW +CT =
                                                             cT)/f'(cT)   is

implied by equation (3), after substitution of the first-order condition for CT

from equation (1).

     It is straightforward to see how the optimal path varies with the parame-

ters of the problem. In Figure 1, we have plotted R&D intensity as a function

of the stage of the project. Relative to some base path, an increase in the




Substituting f'(cT) =    l/
         is clear from (1) that when r = 0, expenditures are time invariant.
                          into (3) gives f'(cT) = f(cT)/CT, which is the first
order condition for maximizing f(cT)/c . With no fixed costs of R&D, _c - 0
as r   0. When fixed costs are presen (c > 0) there will be some c > C that
maximizes f(cT)/cT. Effort is constant at this level when there is no
discounting, and always greater than this level otherwise.
                                                       -8-




prize implies that the project should be completed sooner and that initial

effort should be greater. This is because



              T/aW =                        re_T/UTT < 0
                             -U/1J,

and



              ac
                         -
              aw             2ff,()         3T    aw



Substituting       A =
                      erT/ft(cT) from equation               (1) into equation (3), the terminal

R&D      intensity, CT, is given implicitly by

                   f(cT)               —.
              rW =              -
                       f'(cT)       CT = J(cT).                                   (4)




An increase in the prize, W, causes terminal intensity to increase, since t(c)

>   0.    Indeed, R&D    outlays     are higher at every stage of the project and at every

point in time when the prize is bigger. Note finally that profits are a convex

function of the size of the prize, i.e.,
                                                         fl = _rerT,(aT/aW)        >    0.   We

shall use this fact in our analysis of riskiness below.

         An increase in the difficulty of the research project, L, raises the time

to completion. This can be seen by using UL = -A and AT < 0 to give



                   =   -U =                 >
              3L
                       UTT U 3T

Terminal effort is given by (4) and therefore is unaffected by changes in L.
                                            -9-




       Host important for our purposes is the fact that the value of the research

program is convex in its difficulty, L. In other words, LL(W,L) =                          >
                                                                                —A1(W,L)
0, i.e., A.L < 0. To establish this point, note that n(W,L1 + L2) =

       i.e., a prize of W at distance        +     is equivalent to a prize of n(W,L2)
L1),
at   distance L1. Differentiating this identity with respect to L1 gives

                  nL(7t(W,L2),Ll). Differentiating next with respect to L2 gives

7TLL,Ll + L2) = TrLW(7t(W,L2),Ll)ltL(W,L2).       Since       < 0, all that remains to

be shown is that 1TLW K 0. But ltLW =     - Aw(W,L)   and 1.(W,L) =   X(T(W,L),L), SO LW
=   - X(aT/aW).
       I           Finally, X,.,.
                              j.
                                  < 0 and T/3W < 0, which implies rc., < 0 as claimed.
                                                                       LW

       We   have established that, as the difficulty of the project increases, the

marginal cost of having to travel yet farther, X(W,L), falls. In view of

equation (1), this implies that when the project is more difficult research is

undertaken less vigorously at every stage (and at every moment) up to the last.

       As a final comparative dynamics point, the effects of an increase in the

discount rate are found by differentiating equations (2) and (4) and again

noting the relationship between c0 and A from (1). An increase in r reduces

initial outlays but increases terminal effort. The net effect on the duration

of the research project is ambiguous.



III. Optimal R & D Programs for Projects of Unknown Difficulty



       Suppose that the progress required to complete the project initially is

unknown, but that effort, c, still leads to progress according to the

deterministic function x =      f(c).   The amount of progress needed to attain the

prize is assumed to be a random variable L with probability density function

p(L) on the support (L, ), and corresponding cumulative distribution function

P(L). We define the hazard rate, (x), so that 4(x)dx is the probability that
                                     -10-




success will be achieved between x and x+dx, conditional on the project

already having progressed (unsuccessfully) to a distance x. Then 4(x)

p(x)/(l—P(x)).

     We assume that the firm is risk neutral. Its problem, which is to

maximize expected discounted profits, can be written as




          max          [Wet)_ 5t(x) etdt)p(x)dx
                                    I
          {c} x=L

where t(x) is defined implicitly by ft(X)f(c )dt =   x.7   Kamien and Schwartz

(1971) have analyzed this problem using Pontryagin methods under the assumption

that all R&D activity must end by some exogenously given time.

     This control problem is solved most easily and transparently using the

techniques of dynamic programming. Define V(x) to be the maximum value

function, i.e., the maximal expected discounted profits earned by a firm that

has progressed to x and behaves optimally thereafter. The firm's expenditure

rate when at x, c(x), will be chosen such that, during the time interval from t

to t+t,



          V(x) = max   [-c& ÷ We t)fflt + (l(x)f(c)t)V(x+x)etht]




     7An alternative formulation of an R&D project of unknown difficulty is one
where "success" requires a "breakthrough," the probability of which is an
increasing function of current effort and cumulative past progress, say p(c,x).
If p(c,x) is assumed to be separable and of the form f(c)4(x), where f(c) is
a1s the measure of advancement that enters into the definition of x (i.e., x
 5   f(c1)dt), then this formulation is equivalent to ours.
                                            —11—



where we have used ix =   f(c)t.        The first term in the brackets is the direct

cost of the research program. The second term is the discounted value of the

prize times the probability of completion of the project during the interval

under consideration. This latter probability is the product of the hazard

rate, 4(x), and the amount of ground covered, x. The final term is the

probability that success is not attained during the interval multiplied by the

discounted value of the program at the end of the interval in the event that

this is the case.

     For small time intervals, we have V(x+&)             V(x) + V'(x)ix and etht

1-rAt. Also, terms in (At)2 and (At)3 vanish in the limit as At - 0.

Substituting, and taking this limit, we have



     V(x) = max [—c + •(x)f(c)W -       V(x)(x)f(c)   -   rV(x)   + f(c)Vt(x)]At + V(x)
             C



or



          rV(x) = max [-c + f(c){(x)(W-V(x)) ÷ V'(x)}J                      (5)
                   C


From this we compute the first-order condition for c(x),



          ft(c(x)) =                                                        (6)
                       $(x)(W-V(x))     ÷ Vt(x)


We assume for the moment that equation (6) has a solution, and that it is

optimal to continue the research program when at x. Finally, we insert the

optimized R&D outlay from equation (6) into the Bellman equation (5), to obtain




         rV(x) =
                    f'(())   -   c(x)     s(c(x))                           (7)
                                            -12-


Note the parallel between equations (7) and (4).

        Equation (7) gives the optimal research expenditure at x (assuming that it

is non-zero) as a function of the value of the program; that is, c(x) =

                 Since i'(c) > 0, (7) implies that effort is greater when the

current position is highly valued.8 We now can substitute for c(x) in (6), to

arrive at the following differential equation describing V(x):



              V'(x)   g(V(x)) +    x)(V(x)-W)                             (8)

where



              g(V)
                      f'(, (rV))


If the value function found by solving (8) subject to the boundary          condition
V(L) =   W   remains everywhere    non-negative,   then this gives the solution to the

dynamic program. Alternatively, if no such path exists, then it will be

optimal either to never begin doing research or to abort the research program

if success is not achieved by some critical stage.

     In the following two subsections we distinguish two alternative situations

for purposes of describing the qualitative properties of the optimal program.

These are (A) when the hazard rate (x) is everywhere non-decreasing, and (B)

when the hazard rate declines for some        range   of values of x. Subsequently, we

discuss the optimal program under two sets of conditions that are excluded by

the assumptions maintained in the analysis thus far. These extensions are to




     8Note that if r = 0 the optimal program again involves a constant level of
effort, c*, so as to maximize f(c)/c. Henceforth, we shall assume that the
discount     rate is positive.
                                             —13-




(C) the case of a constant hazard rate over an unbounded support for x and (D)

the case of a discrete distribution of potential prize locations.



     A. Hazard Rate Everywhere Non-Decreasing



     Suppose that '(x) > 0 for all x c[L,L]. This situation arises if whenever

a success not realized, researchers become more optimistic that a breakthrough

is imminent. This case is the one that Kamien and Schwartz have studied using

different methods. Our results in this subsection parallel theirs.

     In Figure 2 we plot the set of points in (x,V) space such that V'(x) =          0.
These points satisfy x) g(V)/(W-V). Note that g'(V) > 0, which implies

that the curve is flat whenever 4 (x) = 0 (including all x < L) and slopes

upward elsewhere. The curve terminates at the point (L,W), since as x +         L,
x) -     and we must have V -*      W   for V'(x) = 0 to hold.

     We use the V'(x) = 0 schedule to aid us in drawing the set of paths that

satisfy (8). Above this curve V is rising, while below it V is falling. Two

situations are possible. First, there may not exist any path that has V(x) > 0

for all x and V(x) -*   W as x -+   f.9 In    this case, it is not worthwhile to begin

the research project at all. Alternatively, there may exist a unique

saddlepath that has V(x) everywhere non-negative and that satisfies the

boundary condition (as depicted in the figure). Then the saddlepath gives the

maximum value function for the dynamic program.

    The qualitative properties of the optimal R&D program can now be de-

scribed. First, note that if it is optimal to begin the research project, then




     9A necessary condition for this to occur is that for some x c[L,L] the
solution to V'(x) = 0 from equation (8) would require V < 0. At this x it must
be the case that 4(x) < l/Wf'(c*), where we recall that c* maximizes f(c)/c.
                                               -14-


it will be optimal to follow it through to fruition in all contingencies. This
is because at each moment the prospects for success are at least as bright as

they were the moment before. Next, notice that along the saddlepath V(x) is

monotonically increasing. But with r >            0,   research effort varies directly with

the value of the program, by equation (7). Thus, if the hazard rate is

non-decreasing and the discount rate is positive, the optimal dynamic program

involves rising R&D outlays over time.



     D
     L). U.-....-1
         L1LOLUD.-..4-..      1.,4... L1JL G
                   JAQI.. 1JLLLLL.LLL                  'J.&. I.



     The hazard rate may decline for a range of x before rising again as x - L.

In the range where ' (x) < 0, the Vt (x) = 0 schedule is downward sloping.

Three types of outcomes can characterize the optimal program. We illustrate

these in the three panels of Figure 3.

     In Figure 3a, the optimal program is qualitatively the same as when the

hazard rate is everywhere non-decreasing. Although the prospects for success

decline for a range of x, the period is not so prolonged nor is the news so

negative that it causes the value of the program to fall. Research effort is

increasing throughout. This is not the case in Figure 3b. Here, effort is

increasing over the stages of research prior to L. Somewhere before the hazard

rate begins to decline it is optimal to begin to reduce R & D expenditures in

the event of no success. The process is reversed at a later stage, again prior

to the time that the hazard rate begins to increase. If there are several

non-contiguous ranges of declining hazard rates, then research intensity may

(but need not) change directions several times, with each reversal leading the

changes in the sign of 4'(x).
                                            -15-




     Finally, Figure 3c depicts a case where it is worthwhile to begin the

research program and proceed as far as x. If success is not achieved by then,

it is optimal to abandon the effort. The relevant path for V(x) in this case is

the one that has V(x) = 0 at exactly the point where the V'(x) = 0 schedule

meets the horizontal axis. Thus, the shutdown point is given by ft(c*)W =

1J(x).   This can be seen as follows. Any path above this one ultimately

violates the constraint that V(x) <     W.     (Note that we are assuming    as a
precondition   for this case that there does not exist a path with V(x) > 0 for

all x and V(x)     W as x      L.) A path that starts below this one

can be shown to lead to a contradiction. Consider for example the path that

has V() = 0 at      <   x.   With V'() < 0, direct reasoning would suggest that it

is not worthwhile to carry on the program beyond ,         since the value of the
program would turn negative. However,          <   x and $'() <   0   together imply

4(x)f'(c*)W > 1.   Using the definition of c*, we have )f(c*)W >            c*.   But then

it cannot be optimal to cease operations at , because the flow (expected)

benefit of proceeding for another instant at intensity c exceeds the flow

cost. Thus, the path under consideration is not internally consistent.

     If a research program has alternating stages where the hazard rate is

increasing and decreasing, then it may be optimal for research intensity to

change directions several times before a shutdown point ultimately is reached.

In any event, research will never cease during a range of increasing hazard

rates, and any shutdown point x must satisfy f'(c*)W          1/4(x).



    C. Constant Hazard Rate



    For any probability density function with a finite support, the hazard

rate eventually must increase as L     is   approached. However, if the support on
                                         -16-




p(L) is unbounded, it is possible for the hazard rate to be everywhere

constant. This occurs if the density function is exponential, i.e., it has the

form p(L) =     qeL.    Reinganuin (1981) has investigated a model of R&D activity

where this assumption is adopted explicitly. Furthermore, the familiar

specification of Lee and Wilde (1980), which posits a flow probability of a

breakthrough that depends only on current expenditures, has an alternative

interpretation in which effort contributes to "progresstt, but with a hazard

rate on successful completion of the project that is constant (see footnote 7

above).

         It is straightforward to extend the analysis of this section to the case

of a constant hazard rate. Equation (8), describing the movement of the

maximum value function as progress is achIeved, continues to apply, but V(L) =

W   must be replaced by an economically-meaningful boundary condition. It is

clear that V(x) is bounded above by W and below by zero. Any path that has V(x)

>   W   is logically inconsistent, while V(x)   0 with V'(x) < 0 implies that

shutdown is optimal. In Figure 4 we show the V'(x) = 0 schedule for the case

of a constant hazard rate; it is given by g(V)       4(W-V), a horizontal line in

(x,V) space. Any path that begins above or below this line eventually must

violate one of the inequality constraints. Thus, the only consistent path for

V(x) has V'(x) = 0 everywhere, i.e., the value of the program is constant. It

follows that R&D effort is constant as well).0 This makes intuitive sense, of

course, since with a constant hazard rate the problem is completely stationary:

failure at any stage does not alter the decision calculus for the future.




     10The optimal level of effort is given implicitly by the solution to
(rW ÷ c)f'(c) = f(c) + r/4.     It
                                is increasing in both 4 and r.
                                       —17—




     Reinganum (1981) specifies a constant hazard rate and finds as the outcome

for a collusive industry that R&D outlays are increasing over time. Kamien and

Schwartz (1971) also allow for this possibility, and draw a similar conclusion.

There is no contradiction with our result, however, because they assume, unlike

here, that all research projects must be completed before an exogenous time T,

or else the prize vanishes. Reinganum interprets T as the time that the

innovation becomes "obsolete". However, this interpretation is not entirely

consistent with another of her assumptions, namely that the (current) value of

the prize is independent of the time   of   discovery.



     D. Discrete Distributions



     The techniques we have employed thus far in this section are most suitable

for control problems where the probability of success of a research project is

a Continuous function of the extent of progress. The case where p(L) is a

discrete distribution is also of some interest, because many research endeavors

involve a sequence of discrete experiments, any one of which may yield a

discovery. Then the prize can be located only at those points corresponding to

the completion of one of these experiments.

     We analyze the optimal R&D program for the case of a two-point

distribution.11 Let p and 1-p be the probabilities that the prize is located

at distances    and L2, respectively. When point L1 is reached, all

uncertainty will be resolved. If it turns out that the news at L1 is

unfavorable, the firm will then follow the optimal path associated with a

deterministic problem for a prize of W at distance L2-L1. Doing so requires




     111t will become clear that the method extends easily to the n-point case.
                                      -18-




that the same level of effort be applied as a function of the stage of the

project    as would have been optimal between L1 and L2 if the firm had known

that the prize was located at L2 from the outset. We illustrate this in Figure

5.

     At the instant before L1, the firm realizes that the (expected) value of

the program there is pW +                      the probability weighted average of
                            (1-p)n(W,L2-L1),
the profits it will earn for each of the two possible outcomes of the initial

experiment. Since the firm is risk neutral, it will behave during the stages

prior to reaching L1 exactly as it would under a deterministic regime with a

prize of pW +
                (1-p)n(W,L2-L1) at a distance L1. This involves less intensive
research at every point than if the prize had been at       with certainty, but

greater outlays than if the prize were at      for sure. Research effort is

increasing over time within each of the two phases of the project (i.e., during

each experiment), but evidently a "disappointment effect" causes a discrete

drop in intensity if the initial experiment fails to achieve results.

     Finally, we have drawn in Figure 5 for purposes of comparison the path of

R&D effort for a deterministic program with a prize W at a distance pL1 +

(l-p)L2.   As we shall prove in the next section when we compare the research

programs under safe and risky conditions, R&D outlays are everywhere greater

during the initial phases of the uncertain regime than they would be if the

same prize had been at the mean distance with certainity.



IV. The Effects of Uncertainty on R&D Outlays



     In this section we show that a risk neutral firm always prefers a risky

research project to a safe project requiring on average the same amount of

progress for success. Since research effort is an increasing function of the
                                      —19-




current value of any program, this will imply immediately that R&D outlays

during the stages before the lower support of the distribution of an uncertain

regime is reached will exceed those expended at these same stages under a

mean-equivalent certain regime. Furthermore, we will show that the effort

paths for these alternative programs must have a single crossing, as depicted

in Figure 6.

     The key to validating these claims is the fact, demonstrated in Section II

above, that, for a deterministic research program, profits are a convex

function of the distance to be covered: ThTT(W,L) > 0.     The convexity of rr(W,L)

in L tells us immediately that if the firm were choosing between a

deterministic project of difficulty L and a risky project with expected

difficulty L and if the actual difficulty of the risky project were to be

revealed before the program had begun (but after the risky project had been

selected), then the firm would select the risky option.

     Since the actual difficulty of the risky project is learned only over time

and after resources have been expended, we cannot conclude from 7tLL > 0 that a

mean-preserving spread in the p(x) distribution raises V(0). Indeed, we shall

present an example below where a mean-preserving spread decreases the value of

the program. Nonetheless, any risky regime with expected difficulty p is

always preferred to a safe project with known difficulty p.

     To prove this fact, we begin by comparing the program for a two-point

distribution with that for a mean-equivalent safe regime. When the first point

is reached where the the prize might be located under the risky option (L1),

the value of this program is VR(Ll)   pW +                       At this same point
                                             (1-p)71(W,L2-L1).
the value of the program for the safe project is Vs(Li) =                          It
                                                             ir(W,(1-p)(L2-L1)).
follows immediately from W = it(W,0) and nLL(W,L) > 0 that VR(Ll) >
                                                                      Vs(Li).
Since optimal paths are followed in each case at all stages prior to        and no
                                              —20-




learning   takes place under either regime during this period, it must be the

case that the risky project also is preferred at the outset, i.e., VR(U) >

Vs(O).
      The proof extends to distributions with more than two points by backward

induction. At the second-to-last point where the prize might be located,12 say

L1, the risky project under consideration is preferred to another

hypothetical project which is otherwise the same except that, rather than

having positive probabilities of discovery of n-1 at                          and p at L, it has

a probability (p_1 ÷ p) of success at (p_1L1 ÷ pL)/(p1 +                                p..    This

latter project in turn has greater value at Ln_2 than a project with no

probability weight there (or at Ln_i or La), but instead a probability n-2 ÷

n-1 +     p)   of success at (Pn..2Ln...2 +
                                              Pn_iLn_i
                                                          +
                                                              pflLn)/(pfl_2
                                                                              +
                                                                                  n-1   +
                                                                                            ps).   And

so, by a chain of inequalities, we have that the initial risky project has

higher value at        than a project with the prize located for sure at L                     p.L..
It must, therefore, have a higher value at the start of the program as well.

      We can also show that the paths of optimal effort (as functions of

distance travelled) for the safe and risky projects, cR(x) and c(x), cross

exactly once. First note, using equation (7), that at any intersection point

VR(x) =   Vs(x).    The equations of motion for the respective value functions are



                      g(V(x)) ÷ (x)(VR(x) -          W)
            VR(x)



and




         continuous probability density function is attained as a limiting case
of the n-point discrete distribution as n + C.
                                              -21-


                 =
          V(x)       g(V(x))

so that at any point where the values are equal, Vs(x) >                                Thus, once
                                                                         VR(x).
the paths intersect for the first time we must have                Vs(x) >     V(x)     ever after.

Such a first crossing must occur, because VR(L) >                        but Vs(1) =         W   >
                                                                Vs(L),                               VR(p).
     What is the effect on profits of further increases in risk? We

demonstrate by means of an example that a mean preserving spread in p(L) may

actually lower the value of the optimal R&D program, despite                   7tLL >   0.       That is,

although some risk is always better than none, more risk is not necessarily

beneficial to the firm. The reason is that some information is obtained earlier

under the less risky regime (as well as some later) and in certain

circumstances this may allow the firm to readjust its program so as to conserve

substantially on (discounted) expenditures.



    Example: Let r = 0 and c* minimize c/fCc), and call a =                     c*/f(c*).            In all

    circumstances it is optimal to set c equal to c* (see equation (7)).

    Therefore n(W,L) =        -
                          W       aL, so long as W >     crL.

         Now consider two risky regimes. Under the riskier regime, A, the

    prize is at x      0 with probability ¼,         at x = L    with probability ¼, and at
    x = N with probability          where N is very large. Under the relatively

    safe regime, B, the prize is at x =          L/2   with probability            otherwise           it

    is at x = N.      Regime A is a mean preserving spread of regime B.

         Consider first regime A. Assuming that W <                a(H-L),     it will be

    optimal to quit if the prize is not at x = L.                Therefore, the value of

    project A is W/4 ÷ 3(W/3 -       aL)/4,   where we assume that W > 3aL. The first

    term represents the ¼ chance that the prize is at x =                 0;   the second term

    represents the 1/3 chance that it is at L, given that it is not at 0,
                                        -22-




     which happens with probability 3/4.       So, the value of project A is W/2 -

     3uL/4.
          Project B has value n(W/2, L/2) = W/2 -      JL/2, since   the expected

     prize at distance L/2 is W/2. Note that if the prize is not found at L/2

     the firm will abandon its efforts there, and again not proceed on to N.

          Clearly Project B, the less risky project, is more valuable. The

     reason is that, if the prize is at the distant point N the firm learns

     this unfortunate news earlier, and thus can save resources by aborting the

     project at L/2 rather than at L.



     While more risk is not always beneficial for the reason just outlined, it

will be so in any situation where initially c'(x) > 0 for all x in the range of

possible prize locations affected by the mean preserving spread.13 This

proposition is proven as follows.14

     Let (t) be the program (now expressed as a function of time) that is

optimal for p(L) before it is subjected to a mean preserving spread. Define



          G(L) e1T -       J (t)etdt
where T is given by Jf('(t))dt = L. Thus G(L) is the profit that is realized

if (t) is followed and it happens that the prize is located at L. We proceed

to show that '(T(L)) > 0 is sufficient for G(L) to be convex at L.




     13Any mean preserving spread of p(L) that raises   (the upper support of
the distribution) is not_covered by the conditions of this proposition, since
effort falls to zero at L in the initial program.

     14We are grateful to Robert Willig for suggesting this result and its
proof to us.
                                               -23-




     Differentiating G(L) twice gives




          erTGt(L) =   - [rW   +                  + [rW ÷      r(T) -



where dT/dL =   l/f((T))   and d2T/dL2 =        f'"/f3.   After substituting, we have




          f2erTG(L) =              [rW +   -          ] + rW   +   r.
But c(t) is optimal for the initial program, so f/V -                   (T)   =   rV(x(T))   which is

less than rW, and the bracketed expression is positive. Thus, c'(T) >                    0    implies

that G"(L) >   0. This in turn implies that an increase in risk in a range where

effort is initially non-decreasing would raise profits, even if the plan of

expenditures were to remain unaltered. It follows a fortiori that profits must

increase if a new optimal path is chosen.

     Evidently, the adverse effect of increased risk, namely the delay in the

revelation of some information, cannot be so severe in cases where R&D expenses

are increasing in the relevant range so as to offset the benefit stemming from

the fact that the prize y come sooner (which is valuable, since 7tLL >                       0).   The

early arrival of unfavorable information under a less risky regime has

relatively greatest value to the firm when it plans to reduce its efforts as a

consequence.



V. R&D Programs with Stochastic Progress



     So far we have assumed that the relationship between current effort and

progress is deterministic: x =        f(c).     In this section we study a model of
                                                 -24-




stochastic progress that is a natural generalization of the formulations used

in the patent race literature (e.g., Lee and Wilde (1980) and Reinganum

(1981)).

     Suppose that n distinct tasks i =             1,2,... ,n,   must be completed in sequence

to receive the prize, W. The firm's progress is measured by the number of

tasks, i, that it has successfully completed. Progress is achieved only by

completing the current task; there is no learning while work is underway on a

given task. When the firm is engaged in task i, it can achieve a flow

probability q of completing that task if it spends resources at a rate c(q);

c(0) = 0, c' > 0 and c" > 0.          Call V. the value of having completed i-i tasks,

i.e., of being in a position to undertake research on the 1th task, i = 1,

n.

     We work backwards beginning with i =               n.   Using dynamic programming

techniques, if the firm chooses to achieve a completion probability of q, then

we have



               rV = -c(q) ÷ q(W_V).                                             (9)




     This equation states that the rate of return r on the asset V equals the

follow of "dividends," -c(q), plus the expected capital gain, q(W-V). Solving

for V and optimizing the choice of q gives



                 qW -    c(q)             qW -   c(q)
           V =                    = max
           n
                   r+q                q r+q

So long as W >               c(q)/q, it is optimal to select q > 0. A similiar line of
                   ffllflq
reasoning implies that
                                                      -25-

                                 -
                          qV.1       c(q)
              Vmax
               1 q               r+q         ,        i=1,2,        ...,n.



and



                              qV.÷1
                                1
                                    -     c(q)
              q.    arginax                            i = 1, 2, ...,          n,                 (10)
                                     +q


where we have adopted the labelling convention V1 =                             W.       Naturally,


                          -
                   qV.1   c(q.)
          i    =
                      r+q.
                                     <
                                          i+l



But argmax {(qV -             c(q))/(r+q)}       is increasing in V, so we immediately have

q1 < q2 <          ... < q,    i.e., it is optimal to work harder as more progress is

made.

         From equations (9) and (10), we can express q implicitly by c'(q) =                                     W -


V;      more generally, we have c'(q.) =                     - V,   i =       1, 2, ..., n.              Since q÷1 >

q.1   and c" >      0, this immediately tells us that V.:i-l-1            -   V.
                                                                                1
                                                                                     >   V.
                                                                                          1
                                                                                              -
                                                                                                   i-i
                                                                                                  V.      for i =   2,
  ..,   n.      The value of completing the th task increases with i, even though all

the tasks have been assumed to be equally difficult to complete (the same c(q)

function applies to all the tasks).

        The optimal program with stochastic progress shares two properties with

the deterministic program of Section II and the program with unknown difficulty

and an increasing hazard rate of Section III. First, it is optimal to increase

effort as more stages of the research are completed. Second, each increment of

progress is more valuable than was the previous one, i.e., the value of the

program is convex in the amount of progress that has been made.
                                     -26-




VI. Conclusions



     We have identified several reasons why a firm that is optimally pursuing a

research and development program will wish to vary the intensity of its efforts

over time. All of these reasons rely on the presence of discounting.

     First, absent any uncertainty, the firm will find it optimal to work more

and more intensively as it comes closer to completing the project. This

deterministic result may actually have greater application to conventional

investment projects than to research projects pç se.

     Second, and more generally, the firm's optimal intensity of effort should

always be an increasing function of the current value of the project itself.

If there is a relatively great likelihood that the project soon will be

completed, then it is optimal to work relatively hard. If, however, bad news

arrives, i.e., it is learned that the project is much more difficult than was

previously believed, then it may be optimal to scale back one's efforts, as the

value of the project has been diminished.

     If the uncertainty facing the researcher regards the amount of progress

that will be required for completion, then a risky project where an expected

amount of progress L is needed for success will always be preferred to a safe

project requiring L for sure. This is so despite the fact that information

about the risky project's difficulty will only be revealed over time and after

resources have been expended. Further increases in risk only are guaranteed to

raise the value of an R&D project if research expenditures are everywhere

non-decreasing under the initial program in the range of prize locations

affected by the mean preserving spread. In general, more risk can be harmful

because it postpones readjustment in situations calling for a sharp reduction

in effort.
                                       —27-




     If the researcher's uncertainty arises from a stochastic relationship

between current effort and progress, we again find that it is optimal to

increase the level of effort as further advancement is achieved. In this case

bad news (no actual progress as a result of yesterday's efforts) simply leaves

the researcher in the same position as he was yesterday, so that optimal effort

should be unchanged; good news, on the other hand, leads to an increase in the

optimal rate of expenditures.

     Our analysis in this paper has been limited to the case of a single firm -

either   a monopolist or a perfect competitor. It is not immediatly evident

whether the presence of direct rivalry between firms would accentuate the

general principle that has emerged here, namely the tendency of optimal

research efforts to increase as progress is made and as time goes by. To the

extent that a firm is induced to redouble its efforts when it falls behind, we

could have increasing efforts over time in a race. This pattern would also

occur if competition intensified when a firm that was formerly behind suddenly

caught up. It may be the case, however, that one firm's progress early in the

race causes its rival to slow down (or give up entirely); this would be a

reason for intense effort early on. We are currently studying R&D rivaly with

progress in order to sort out these various effects.
                                     -28-




                                  References




Dasgupta, P. and J. Stiglitz, (1980) "Industrial Structure and the Nature of
   Innovative Activity," Economic Journal, 90, P. 266-293.

Fudenberg, D., Gilbert, R., Stiglitz, J., and Tirole, J. (1983) "Preemption,
   Leapfrogging and Competition in Patent Races," European Economic Review,
   22, pp. 3-31.

Harris, C. and Vickers, J. (1985), "Perfect Equilibrium in a Model of a Race,"
   Review of Economic Studies, 52, pp. 193-209.

Judd, K. (1985), "Closed-Loop Equilibrium in a Multi-Stage Innovation
   Race," Discussion Paper No. 647, Management Economics and Discussion
   Science, Kellogg Graduate School of Management, Northwestern University.

Kamien, M. and N. Schwartz (1971), "Expenditure Patterns for Risky R and D
   Projects,'t Journal of Applied Probability, 8, pp. 60-73.

Lee, T. and Wilde, L. (1980), "Market Structure and Innovation: A
   Reformulation," Quarterly Journal of Economics, 94, pp. 429-436.

Lucas, R. (1971), "Optimal Management of a Research and Development
   Project," Management Science, 17, p. 679-697.

Reinganum, J. (1981), "Dynamic Games of Innovation," Journal of Economic
   Theory, 25, pp. 21-41.
    R&D
Expenditure
  C
                       Larger W



                           N                   Base Path




                                               Higher L




                                                     Distance
      0                             L     L'     x

              Optimal Expenditure Paths

                      Figure 1
        Paths Satisfying
    V       Equation (8)                          V (x)
            /
w




                                                              x
0
        L                                                 L




                     Non—Decreasing Hazard Rate


                             Figure 2
    V




0                                                      x
         L—
                     '(x)<   0



               Figure 3a: Hazard Rate Falls

    V




0
                                                           x

                     '(x)< 0



        Figure 3b: Hazard Rate and Expenditure Rate Fall
                V



            w




                                                       x
            0
                                x


                    Figure 3c: Abandon Research at x

                V



            w




g(V)(W—V)




                                                       x
            0



                    Figure 4: Constant Hazard Rate
                Path for Prize at
                                        Path for Prize at
                L1 with Certainty
                                      pL1+(1—p)L2 with Certainty

(rW)




                                                          V.      Path with Two—Point
                                                                    Distribution




                                      Path for Prize at        with Certainty


                                                                            x
                                 L1         pL1+(1—p)L2            L2




           Figure 5:   Expenditure Pattern for a Two—Point Distribution




       C




(rW)
                        Safe Path
                          c(x)


                                                               Risky Path
                                                                 CR(x)




                                                                            x
       0                                      Ii



                       Figure 6: Safe vs. Risky Expenditure Patterns
