                                NBER WORKING PAPER SERIES




   GROUPTHINK: COLLECTIVE DELUSIONS IN ORGANIZATIONS AND MARKETS

                                           Roland Bénabou

                                        Working Paper 14764
                                http://www.nber.org/papers/w14764


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                     March 2009




I am particularly grateful to Jean Tirole, as the paper builds on some of our earlier joint work. I am
also thankful for valuable comments to George Akerlof, Daron Acemoglu, Alan Blinder, Markus Brunnermeier,
Andrew Caplin, Sylain Chassang, Rafael Di Tella, Xavier Gabaix, Bob Gibbons, Boyan Jovanovic,
Alessandro Lizzeri, Glenn Loury, Kiminori Matsuyama, Ben Polak, Eric Rasmussen, Ricardo Reis,
Jean-Charles Rochet, Tom Romer, Julio Rotemberg, Tom Sargent, Hyun Shin, Glen Weyl, Muhamet
Yildiz and to seminar participants at Princeton, NYU, Cornell, George Mason, INSEAD, Oxford, the
Harvard-MIT workshop on the Economics of Organizations, Brown, Yale, Chicago G.S.B., Berkeley,
UCSD, UCLA, LSE, PSE, Penn and Duke universities. Rainer Schwabe and Andrei Rachkov provided
superb research assistance. Support from the Canadian Institute for Advanced Research is gratefully
acknowledged. The views expressed herein are those of the author(s) and do not necessarily reflect
the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2009 by Roland Bénabou. All rights reserved. Short sections of text, not to exceed two paragraphs,
may be quoted without explicit permission provided that full credit, including © notice, is given to
the source.
Groupthink: Collective Delusions in Organizations and Markets
Roland Bénabou
NBER Working Paper No. 14764
March 2009
JEL No. D03,D23,D53,D83,D84,E32,G01,Z1

                                              ABSTRACT

I develop a model of (individually rational) collective reality denial in groups, organizations and markets.
Whether participants' tendencies toward wishful thinking reinforce or dampen each other is shown
to hinge on a simple and novel mechanism. When an agent can expect to benefit from other's delusions,
this makes him more of a realist; when he is more likely to suffer losses from them this pushes him
toward denial, which becomes contagious. This general "Mutually Assured Delusion" principle can
give rise to multiple social cognitions of reality, irrespective of any strategic payoff interactions or
private signals. It also implies that in hierachical organizations realism or denial will trickle down,
causing subordinates to take their mindsets and beliefs from the leaders. Contagious "exuberance"
can also seize asset markets, leading to evidence-resistant investment frenzies and subsequent deep
crashes. In addition to collective illusions of control, the model accounts for the mirror case of fatalism
and collective resignation. The welfare analysis differentiates valuable group morale from harmful
groupthink and identifies a fundamental tension in organizations' attitudes toward free speech and
dissent.


Roland Bénabou
Department of Economics
and Woodrow Wilson School
Princeton University
Princeton, NJ 08544
and NBER
rbenabou@princeton.edu
         “It appears that there are enormous diﬀerences of opinion as to the probability of a failure
         with loss of vehicle and of human life. The estimates range from roughly 1 in 100 to 1 in
         100,000. The higher figures come from the working engineers, and the very low figures from
         management. What are the causes and consequences of this lack of agreement? Since 1 part
         in 100,000 would imply that one could put a Shuttle up each day for 300 years expecting to
         lose only one, we could properly ask ‘What is the cause of management’s fantastic faith in
         the machinery?’ ”                    (Richard Feynman, in Rogers Commission Report, 1986)

         “We have a wealth of information we didn’t have before,” Joe Anderson, then a senior
         Countrywide executive, said in a 2005 interview. “We understand the data and can price
         that risk.”                                    (BusinessWeek, “Not So Smart,” August 2007)


       This paper examines how collective beliefs and delusions arise and persist in organizations
such as teams, firms, bureaucracies and markets. In the aftermath of corporate and public-policy
disasters, it often emerges that participants fell prey to a collective form of overconfidence and
willful blindness: mounting warning signals were systematically ignored or met with denial,
evidence avoided, cast aside or selectively reinterpreted, dissenters discouraged and shunned.
Market bubbles and manias exhibit the same pattern of investors acting “color-blind in a sea of
red flags”, followed by a crash.1
       Janis (1972), analyzing policy decisions such as the Bay of Pigs invasion, the Cuban missile
crisis and the escalation of the Vietnam war, identified in those that ended disastrously a cluster
of symptoms for which he coined the term “groupthink”.2                       Although some later work was
critical of his characterization of those episodes, the concept has flourished and spurred a large
literature in social and organizational psychology. Defined in Merriam-Webster’s dictionary
as “a pattern of thought characterized by self-deception, forced manufacture of consent, and
conformity to group values and ethics”, groupthink was strikingly documented in the oﬃcial
inquiries conducted on the Challenger and Columbia space shuttle disasters. It has also been
invoked as a contributing factor in the failures of companies such as Enron and Worldcom, in
some decisions relating to the second Iraq war, and most recently in the housing and mortgage-
related financial crisis.3 At the same time, one should keep in mind that the mirror opposite of
harmful “groupthink” is precious “group morale” and seek to understand how they diﬀer, even
though both involve the maintenance of collective optimism in spite of negative signals.

   1
     I borrow here the evocative title of Norris’ (2008) account of Merrill Lynch’s mortgage securitization debacle.
For detailed accounts of market manias and crashes, see Shiller (2005).
   2
     The eight symptoms were: (a) illusion of invulnerability; (b) collective rationalization; (c) belief in inherent
morality; (d) stereotyped views of out-groups; (e) direct pressure on dissenters; (f) self-censorship; (g) illusion of
unanimity; (h) self-appointed mindguards. The model developed here will address (a) to (g).
   3
     On the space shuttle accidents, see Rogers Commission (1986) and Columbia Accident Investigation Board
(2003). On Enron, see Samuelson (2001), Bryce (2002), Cohan (2002), Eichenwald (2005) and Pearlstein (2006).
On Iraq, see e.g., Hersh (2004), Suskind (2004) and Isikoﬀ and Corn (2007). On self-deception and self-serving
rationalizations as key enablers of corporate misconduct, see Huseman and Driver (1979), Sims (1992), Tenbrunsel
and Messick (2004), Anand, Ashforth and Joshi (2005) and Schrand and Zechman (2008).


                                                          1
       To analyze these issues, I develop a model of (individually rational) collective reality denial
in groups and organizations, or among participants in a market. The model, which builds on and
extends the selective-awareness (attention, memory) framework of Bénabou and Tirole (2002,
2006a), allows me to ask when individual tendencies toward wishful thinking and overoptimism
reinforce or dampen each other. To make clear that groupthink is entirely distinct from standard
linkage mechanisms, the benchmark model has no complementarities or substitutabilities in
agent’s actions, nor any private signals that could give rise to social learning or herding. What
emerges is thus a novel and surprisingly simple mechanism generating interdependencies in
information processing, beliefs and behavior. Intuitively, whenever an agent benefits (on average)
from other’ delusions, this tends to make him more of a realist; and whenever their disconnect
from reality makes him worse oﬀ this pushes him toward denial, which is then contagious. This
Mutually Assured Delusion (MAD) principle can, in particular, give rise to multiple equilibria
with diﬀerent “social cognitions” of the same reality.
       The same general principle implies that, in organizations where some agents have a greater
impact on others’ welfare than the reverse (e.g., managers and workers), strategies of realism
or denial will “trickle down” the hierarchy, so that subordinates will in eﬀect take their beliefs
from the leader. In addition to collective illusions of control, it can also account for the mirror
case of collective fatalism and resignation, such as public apathy in a crisis or “looking away”
from humanitarian disasters.
       The model’s welfare analysis makes clear what factors distinguish valuable group morale
from harmful groupthink and leads to interesting results concerning attitudes toward dissenting
speech. In particular, it explains why organizations and societies find it desirable to set up
ex-ante commitment mechanisms protecting and encouraging dissent (constitutional guarantees
of free speech, whistle-blower protections, devil’s advocates, etc.), even when ex-post everyone
would unanimously want to ignore or “kill” the messengers of bad news.
       In market interactions, prices typically introduce a substitutability between agents’ decisions
that works against collective belief. Nonetheless I show how, in markets with time-to-build
features (housing, startups in a new sector) or more generally where outstanding asset positions
are subject to (endogenous) capital gains and losses, contagious wishful thinking can again take
hold, leading to “exuberant” investment frenzies and, ultimately, deep crashes.
       This work ties into four literatures. The first one centers on cognitive dissonance, self-
deception and other forms of belief distortion.4 The second, closely related, concerns anticipatory
feelings.5 Most of these papers have focused on individual rather than social beliefs, and none
has asked the question which I take up here: when does wishful thinking or reality avoidance
become “infectious”, when is it self-limiting, and what are the welfare implications in each case?

   4
     See, e.g., Akerlof and Dickens (1982), Schelling (1986), Kuran (1993), Rabin (1994), Carrillo and Mariotti
(2000), Bénabou and Tirole (2002, 2004, 2006b) and Di Tella et al. (2007).
   5
     See, e.g., Loewenstein (1987), Caplin and Leahy (2001), Landier (2000), Caplin and Eliaz (2005), Brunner-
meier and Parker (2005), Bernheim and Thomadsen (2005), Köszegi (2006) and Bénabou and Tirole (2007).


                                                      2
The paper’s analysis of group morale and groupthink in organizations relates it to a third strand
of literature, which deals with overoptimism and heterogeneous beliefs in firms.6 In this work
beliefs are most often exogenous (reflecting diﬀerent priors), whereas here they endogenously
spread, horizontally or vertically, through all or part of the organization. Beyond economics, the
paper relates to the management literature on corporate culture and to the work in psychology
on “social cognition”.7
    Finally, the model’s application to market manias and crashes links the paper to the litera-
tures on bubbles and herding, although the mechanism is entirely diﬀerent.8 With informational
cascades, the key problem is a failure to aggregate private signals and its cure resides in more
communication. Moreover, agents display the usual “hunger” for accurate knowledge and dis-
regard their own signal only when the choices of others are likely to embody more information.
In market groupthink, by contrast, investors have access to the same or very similar informa-
tion, but their processing of it is distorted by wishful thinking and this pattern of thought
becomes contagious. Increasing communication and information sharing among participants
(e.g., through intensified media reporting) only reinforces the mania, while dissonant advice
from outsiders is systematically ignored or discounted.9
    The paper is organized as follows. Section 1 presents the general model and the main results.
Section 2 examines the implications for welfare and the treatment of dissenting speech. Section
3 extends the analysis to asset-market manias and crashes. Section 4 considers fatalism and
collective apathy in the face of crises. Section 5 concludes.
    Appendix A oﬀers a complement to the introduction and the paper’s thesis. The events
of recent months perhaps obviate the need to argue the relevance of wishful delusions in orga-
nizations and markets. Nonetheless, it is worth documenting certain patterns that strikingly
recur across very diﬀerent settings —from NASA to the FED, SEC and Fannie Mae, from Enron
to major investment banks, A.I.G and individual investors. Another important point is the
inadequacy of moral hazard as the sole explanation for these events: rather than substitutes,
overoptimistic hubris and gambling with other people’s money or lives are most often indisso-
ciable complements (especially when fraud is involved). Appendix A first reviews what actors
in the above episodes said: absurd probability assessments, “this time is diﬀerent” and other
flawed rationales, “fantastic faith in the machinery”. It then turns to what they did, exam-

   6
     On the theoretical side, see, e.g. Rotemberg and Saloner (1993), Bénabou and Tirole (2003), Fang and
Moscarini (2005), Van den Steen (2005), Gervais and Goldtsein (2007) and Landier, Sraer and Thesmar (2009).
On the empirical side and focussing on CEO overconfidence, see, e.g. Malmendier and Tate (2005, 2008) or
Camerer and Malmendier (2007).
   7
     See, e.g., Jost and Major (2001) on “system justification”, Leung et al. (2002) on “social axioms” and Kahan
and Braman (2006)on “cultural cognition”.
   8
     See, e.g., Banerjee (1992), Bikhchandani, Hirshleifer and Welch (1992), Caplin and Leahy (1994), Chamley
and Gale (1994) or Scheinkman and Xiong (2003).
   9
     Standard “rational” bubbles also involve no motivated thinking or distorted information processing. Investors
are under no illusion about the asset’s fundamental value, the fact that the price must eventually collapse back
to it and can do so at any instant, or the risk inherent in their transactions.



                                                        3
ining both investment behaviors (failure to divest or hedge, leading to large personal losses)
and informational decisions: refusal to gather or even look at available evidence, dismantling
of risk-management systems both ex-ante and once warning signals start flashing red, “normal-
ization of deviance” in response to ever-larger anomalies. Appendix A ends with pointing out
the recurrent role of forgetting by both individuals and institutions. All proofs are gathered in
Appendix B.


1         Groupthink in teams and organizations
“The Columbia accident is an unfortunate illustration of how NASA’s strong cultural bias and its opti-
mistic organizational thinking undermined eﬀective decision-making.” (CIAB Final Report, 2003)


1.1        The benchmark model
• Technology. A group of risk-neutral agents,  ∈ {1 }  are engaged in a joint project (team,
firm, military unit) or other activities generating a public good or spillovers. At  = 1 each
chooses an eﬀort level  = 0 or 1 with cost     0 At  = 2, he will reap expected utility
                                                 £                ¤
(1)                                       2 ≡   + (1 − )− 

where − denotes the average eﬀort of others,

                                                        1 X 
(2)                                            − ≡       
                                                       −1
                                                               6=


and 1 −  ∈ [0 1 − 1] the degree to which the agent is vested in the group, reflecting the
collective nature of the activity or the presence of cross-interests.10 Depending on  the choice
of  thus ranges from a pure private good (or bad) to a pure public one. This linear payoﬀ
structure is maximally simple: all agents play symmetric roles, there is a fixed value to inaction
 = 0, normalized to 0 and no complementarity or interdependence of any kind between agents’
eﬀort decisions.11 These assumptions serve only to highlight the key mechanism, and will all be
relaxed later on.
         The overall productivity of the venture agents are engaged in is a priori uncertain:  = 
in state  (probability ) and  =  in state  (probability 1 − ) with ∆ ≡  −   0
and   0 without loss of generality. Depending on the context,  can represent the potential
value of a firm’s product or business plan, the state of the market, the suitability of a political

    10
      Another source of interdependence is altruistic concern among agents: family or kinship ties, social identity,
etc. Thus, (1) is equivalent to 2 ≡  + (1 − )2− with 1 −  ≡ (1 − ) ( − 1)  ( − )  Altruistic links are
explicitly studied in Section 4.1. Note also that while (1) suggests constant returns (“publicly provided private
goods”), crowding or scale economies can be captured by dividing  by some appropriate function of 
  11
     I intentionally abstract from complementarities and substitutabilities to demonstrate that they are neither
necessary nor suﬃcient for groupthink, which, at its core, involves only the interplay of cognitive decisions.


                                                          4
                               Period 0                        Period 1                         Period 2
                        H              H
                                                  ei  0,1        s E1 U2i                  U2i
                         L             L

                    signal        recall            action          anticipatory             final payoffs
                    about         (attention,       choice          feelings:
                    project       awareness)                        hope, dread,    U2i   ( ei  1    e  i )
                    value                          cost cei        anxiety…




                                                      Figure 1: Timeline


or military strategy, or the quality of a leader. Note that  also corresponds to the expected
social value for the group of a choice  = 1 relative to what the alternative course of action
would yield; the private value to the individual is  −  If  ≥ 0 each agent would always
prefer that others choose  = 1 (put eﬀort into the team or firm project, refrain from polluting,
etc.). If   0, however, he would like them to pursue the “appropriate” course of action for
the organization, choosing  = 1 in state  and  = 0 in state 
   • Preferences. The flow payoﬀs received during period 1 include the cost of eﬀort, − 
                                                                                          £ ¤
plus the anticipatory utility experienced from thinking about one’s future prospects, 1 2 
where  ≥ 0 parametrizes the importance of hope, anxiety, dread, and similar emotions.12 This
parameter ( stands for “savoring” or “susceptibility”) typically increases with the length of
period 1 during which uncertainty remains. It may also vary across individuals, but for the
moment I maintain symmetry.
       At the start of period 1, agent  chooses eﬀort to maximize the discounted value of payoﬀs,
                                                               £ ¤        £ ¤
(3)                                           1 = − + 1 2 + 1 2 

Given (1), his eﬀort is determined solely by his beliefs about  :  = 1 if ( + )1 []  
independently of what any one else may be doing. I shall assume that

                                                           
(4)                                                         + (1 − ) 
                                                ( + )   

Thus, absent credible information, an individual acting on his prior will choose  = 1 whereas
one who knows for sure that the state is  will abstain.13
       An agent’s beliefs at  = 1 depend on the news received at  = 0 and on how he processed
them —accepting reality or averting his eyes from it, as specified below. In doing so, he acts to

  12
     This includes the well-documented health eﬀects of chronic stress versus hopefulness. For models of antic-
ipatory utility under uncertainty see, e.g., Caplin and Leahy (2001), Landier (2000), Brunnermeier and Parker
(2005), Köszegi (2006) and Bénabou and Tirole (2007). The linear specification, 1 [2 ] avoids exogenously
building into the model either information aversion or information-loving.
  13
     This assumption is not essential but will ensure that each agent has a unique best-response awareness strategy,
given that of others; see footnote 18 for details.


                                                                5
maximize the discounted utility of all payoﬀs
                                            £           £ ¤¤          £ ¤
(5)                          0 = − + 0 − + 1 2 +  2 0 2 

where  denotes expectations at  = 0 1 and  the date-0 costs of his cognitive strategy.
The tradeoﬀ between accurate versus hopeful beliefs embodied in these preferences will manifest
itself in agents’ behavior with respect to both date-0 information and date-1 choices.
       • Information and beliefs. To represent agents’ cognitive decisions or “patterns of thought”, I
use an extended version of the endogenous-recall or awareness technology introduced in Bénabou
and Tirole (2002, 2006a). At  = 0 agents observe a common signal that defines the relevant
state of the world:  =   with probabilities  and 1 −  respectively.14 Each one then has
some flexibility in how much attention to pay to it, how to interpret it, whether to “keep it in
mind” or “not think about it”, etc. Formally, he can :
       (a) Accept the news realistically, thus truthfully encoding ̂  =  into memory or awareness
(his date-1 information set).
       (b) Engage in denial, censoring or rationalization, thus encoding ̂  =  instead of  =  or
̂  =  instead of  =  In addition to impacting later decisions, this may entail an immediate
cost  ≥ 015
       (c) Deal in partial truths, using a mixed strategy. Equivalently, the memory process itself
can be stochastic, with any recall probability  ∈ [0 1] achievable at cost  = (1 − )
       This simple informational structure captures a broad range of situations. The prior dis-
tribution ( 1 − ) could itself be conditional on some other signal being good news, such as
the appearance of a new technology or market opportunity (versus a status quo where  is low
for sure). This positive signal may also have warranted some initial investment in the activity,
including the formation of the group itself. Alternatively, it could be contemporaneous to the
realization of ;  is then a state of “mixed evidence”, whereas in  all signals are “go”.
       • Directed attention and inattention. Instead of “tuning out” unwelcome news (denial),
selective awareness can also take the form or investing extra resources in retaining good ones
(rehearsal, preserving evidence). This corresponds to the case where attention or recall is natu-
rally imperfect (  1) but can be raised at some cost; it is like setting   0 in (b) above. Both

  14
      Since  or  is only the expected value of the project conditional on  a low signal does not preclude a high
final realization, and vice versa. The perfect correlation of signals across individuals is also chosen for simplicity
(it just needs to be positive) and to make clear that the mechanism at work here has nothing to do with herding
or informational cascades, in which agents with private signals make inferences from each other’s behavior.
   15
      Self-deception can be a deliberate strategy or an unconscious tendency, and the resources expended in the
process may be material (eliminating evidence, avoiding certain people or situations, searching for and rehearsing
desirable signals) or mental ones (stress from repression, cognitive dissonance, guilt). As discussed below, any
arbitrarily small   0 suﬃces to rule out uninteresting “babbling” equilibria in which there is censoring in both
states (  1   1) Beyond this, all the paper’s key results apply equally well with  = 0 though non-zero
costs are more realistic, particularly for the welfare analysis.



                                                          6
mechanisms lead to broadly similar results and can be combined: what matters is that there
be a possibility (and a motive) for diﬀerential awareness of  and  not how this is achieved.
While costly recall may be a more familiar assumption, actual episodes of groupthink, market
manias, etc., typically involve the more striking phenomena of willful inattention, ex-post ratio-
nalizations, refusals to face the evidence, silencing of doubters and similar forms of information
disregard. For this reason, the model emphasizes “selective inattention” more than “selective
attention”.
       A first result is that, no matter how small   0 an agent will never censor signals in both
states: either  = 1 or  = 1 Given (1), moreover, intuition suggests that it is only in
the “bad-news” state  that he may do so: agents with anticipatory utility would not want to
substitute bad news for good ones.16 Verifying these claims in the appendix (Lemmas 3 and 4),
I focus for the time being on cognitive decisions in state  denoted simply

(6)                                          ≡ Pr [̂ = | = ] 

Later on I will consider payoﬀs structures more general than (1), under which either state may
(endogenously) be censored.
       While agents can selectively process information, their latitude to aﬀect beliefs remains
constrained by Bayesian rationality: at  = 1 agent  may no longer have direct access to the
original signal, but if he (as others) has a systematic tendency toward selective attention or
interpretation, he will take that into account, using Bayes’ rule to form posteriors. Thus, when
̂  =  the agent knows that the state is  but when ̂  =  his posterior belief is only
                          £                    ¤                  
(7)                     Pr  =  | ̂  =   =                             ≡ ( )
                                                          + (1 − )(1 −  )

where  is is his equilibrium degree of realism.17
       To analyze the Perfect Bayesian equilibria of this game, I proceed in three steps. First, I
fix everyone but agent ’s awareness strategy at some arbitrary − ∈ [0 1] and look for his
“best response”  18 Second, I identify the general principle that governs whether individual

  16
     An agent who likes pleasant surprises and dislikes disappointments, on the other hand, may want to. Such
preferences correspond
                         (maintaining
                                    linearity) to  = −0  0  0  1 so that the last two terms in (5)
           2          0 
become  0 2 −  1 2  By focussing on  ≥ 0 I am implicitly assuming that this disappointment-aversion
motive, if present, is dominated by anticipatory concerns. All the paper’s results could be transposed to the case
  0 leading to a (perhaps less empirically relevant) model of collective “defensive pessimism”. The social or
evolutionary value of anticipatory concerns is discussed in Section 2.
  17
     It is straightforward to allow for naiveté, parametrized for instance by a coeﬃcient  ≤ 1 multiplying (1 −
)(1 −  ) in (7). This leaves all the positive results unchanged but can aﬀect some of the welfare conclusions.
See Bénabou and Tirole (2002, 2006b) for such a treatment in diﬀerent economic contexts.
  18
      With imperfect recall, each agent’s problem is itself a game of strategic information transmission between
his date-0 and date-1 “selves”, Condition (4) and   0 will rule out any multiplicity of intrapersonal equilibria,
thus simplifying the analysis and making clear that the groupthink phenomenon is one of collectively sustained
cognitions. Note also that the focus on symmetric group equilibria, implicit in equating all  ’s to a common − 



                                                         7
cognitions are strategic substitutes (the more others delude themselves, the better informed I
want to be) or complements (the more others delude themselves, the less I also want to face
the truth). Finally, I derive conditions under which groupthink arises in its most striking form,
where both collective realism and collective denial constitute self-sustaining social cognitions.

1.2      Best-response awareness
Following bad news, agents who remain aware that  =  do not exert eﬀort, while those who
managed to ignore or rationalize away the signal have posterior ( ) ≥  and choose  = 1
Responding as a “realist” to a signal  =  thus leads for agent  to intertemporal expected
utility ( is for “realism”)

                               
                                             £                           ¤
(8)                           0 = ( + )  · 0 + (1 − )(1 − − ) 

reflecting his knowledge that only the fraction 1 − − of other agents who are in denial will
exert eﬀort. If he censors, on the other hand, he will assign probabilities ( ) to the state being
 in which case everyone exerts eﬀort with productivity   and 1 − ( ) to it being really 
in which case only the other “optimists” like him are working and their output is (1 − − ) 
Hence ( is for “denial”):

                     
                                    ¡     £                    ¤ ¢
                    0 = − +  − +   + (1 − )(1 − − ) 
                             ¡          ¡          ¢£                    ¤ ¢
(9)                      +  ( ) + 1 − ( )  + (1 − )(1 − − )  

Agent ’s incentive to deny reality, given that a fraction 1 − − of others are doing so, is thus:
            ¡       
                         ¢                                         £                  ¤
(10)         0 − 0    = − − [ − ( + )  ] + ( ) (1 − )−  + ∆ 

The second term is the net loss from mistakenly choosing  = 1 due to overoptimistic beliefs.
The third one is the gain in anticipatory utility, proportional to the post-denial belief ( ) that
the state is  and comprising two eﬀects. First, the agent raises his estimate of the fraction of
others choosing  = 1 from 1−− to 1; at the true productivity   this contributes (1−)− 
to his expected welfare. Second, he believes the project’s value to be  rather than   so that
when everyone chooses  = 1 his welfare is higher by ∆ =  −  
      The incentive for denial is increasing in the agent’s own “habitual” truthfulness   ensuring a
unique fixed point (personal equilibrium). This best response to how others think is characterized
by the following properties, illustrated in Figure 2 by the dotted curves.


is without loss of generality when there are many (identical) agents, since all best-respond to the aggregate. For
finite  and / or heterogenous groups, there can also be asymmetric equilibria; see Section 1.4.




                                                        8
Proposition 1 (Optimal awareness and the MAD principle) For any cognitive strategy
− used by other agents, there is a unique optimal awareness rate  for agent  with:
i)  = 1 for  up to a lower threshold (− )  0  strictly decreasing in  between (− ) and
an upper threshold ̄(− )  (− ) and  = 0 for  above ̄(− )
ii)  decreases with others’ awareness rate − if   0 and increases with it if   0
iii)  increases with the degree of spillovers 1 −  if   0 and decreases with it if   0

       The first result is straightforward: the more important anticipatory feelings —the consump-
tion value of beliefs— are to an agent’s welfare, the more bad news will be repressed.
       The second result brings to light a general insight which I shall term the “Mutually Assured
Delusion” (MAD) principle. If others’ blindness to bad news leads them to act in a way that is
better for an agent than if they were well informed (  0) it makes those news not as bad, thus
reducing his own incentive to engage in denial. But if their avoidance of reality makes things
worse than if they reacted appropriately to the true state of aﬀairs (  0) future prospects
become even more ominous, increasing the incentive to look the other way and take refuge in
wishful thinking.19 In the first case, individual cognitive strategies are strategic substitutes, in
the latter they are strategic complements. It is also worth emphasizing that:
       (a) This “psychological multiplier”, less than 1 in the first case and greater in the second,
arises even though agents’ payoﬀs are completely separable and there is no scope for social
learning. It thus represents a novel mechanism giving rise to interdependent beliefs and actions.
       (b) The case in which individuals’ willful blindness feeds on itself is also that in which it is
worse for everyone, as it leads to the wrong course of action ( = 1 when  = )
       • Low-risk projects and public goods. The first scenario, best epitomized by a sports team, is
that in which an individual’s motivation and “can-do” optimism are always valuable to others:
eﬀort and quality control at work, political participation and other forms of good citizenship.
More generally, it characterizes activities with a limited downside, in the sense that pursuing
them remains socially desirable for the organization even in the low state where the private
return falls short of the cost. In the financial sector, this corresponds to making “plain vanilla”
home loans or lending to secure brick-and mortar companies, which remains generally profitable
even in a mild recession (though less than in a boom).
       • High-risk projects. The second scenario corresponds to high-stakes ventures in which the
downside is so bad that persisting in that state has negative social value for the group. The
archetype is a firm such as Enron, whose strategy is potentially extremely profitable for those
involved but may also be completely wrong headed and even illegal, in which case everyone
will ultimately suﬀer heavy losses: loss of job, pension or reputation, bankruptcy, even criminal

  19
    This argument is for given costs of belief distortion, which is the case here: see (10). An isomorphic one
applies when other agents’ degree of awareness aﬀects the cost side rather than (or in addition to) the benefit side
of an individual’s belief manipulations.


                                                         9
                            i




                                                                                               si
                                                    s (1)        s (0)   s (1)    s (0)
                               i




                                                                                               si
                                    s (0)   s (0)   s (1)                s (1)



Figure 2: Group Morale (  0 upper panel) and Groupthink (  0, lower panel). The dotted lines
give agent ’s optimal awareness  when others are realists ( = 1) or deniers ( = 0) with the arrows
indicating the transition between the two. The solid lines define the social equilibria.


prosecution. More recent examples include banks investing in dot.com startups, subprime mort-
gages, CDO’s and the like. The greater is other divisions’ or coworkers’ tendency —especially
among higher-ups, as will be seen below— to ignore red flags and forge ahead with the plan
(e.g., set up yet more oﬀ-the-books partnerships and other questionable deals or loans), the
more catastrophic the losses to be expected if the scheme was flawed, fraudulent, or resting on
a bubble. Therefore, the greater the temptation for each employee whose future welfare is tied
to the firm’s fate to also look the other way, engage in rationalization, and “not think about it”.
    The proposition’s third result shows how both types of cognitive interdependencies are ampli-
fied, the more closely tied an individual’s welfare is to the actions of others.20 Three interesting
implications ensue:
    (a) Groupthink phenomena are likely to be particularly important for closed, cohesive groups
whose members perceive that they largely share a common fate and have few exit options. This
is in line with Janis’ (1972) findings, but with a more precise notion of “cohesiveness”.
    (b) In groups with asymmetric roles, such as hierarchies, there will be a tendency to “follow
the leader” into realism or denial. This idea is formalized in Section 1.4 below.
    (c) Contagious beliefs are also more likely for large-scale public goods, such as those provided
by a government, market, or other society-wide institutions which a single individual has little
power to aﬀect. This point is pursued in Bénabou (2008), where I study country-level ideologies

  20
     This intuition is reflected in (10) through the term (1 − ) −   A lower  also increases the cost of subop-
timal eﬀort when   0 and raises it when   0 reinforcing this eﬀect (term  −  ( + )  ).


                                                            10
concerning the relative eﬃcacy of markets and governments.

1.3    Social cognition
I now solve for a full social equilibrium in cognitive strategies, looking for fixed points of the
mapping − →   The main intuition stems from Proposition 1 and is illustrated by the solid
lines in Figure 2. First,  = 1 is an equilibrium for  ≤ (1) as realism is the best response
to realism; similarly,  = 0 is an equilibrium for  ≥ ̄(0) where denial is the best response to
denial. Second, when   0 (cognitive substitutes), the thresholds  and ̄ are both decreasing
in −  so (1)  ̄(1)  ̄(0) and the two pure equilibria correspond to distinct ranges. When
  0 (cognitive complements), on the other hand, both thresholds are increasing in −  and
if that eﬀect is strong enough one can have ̄(0)  (1) creating a range of overlap.

Proposition 2 (Groupthink) 1) If the following condition holds,

(11)                            (1 − ) ( −  )  (1 − ) (− ) 

then ̄(0)  (1) and for any  in this range, both realism ( = 1) and collective denial ( = 0)
are equilibria, with a mixed-strategy equilibrium in between. Under denial agents always choose
 = 1 even when it is counterproductive.
2) If (11) is reversed, (1)  ̄(0) and the unique equilibrium is  = 1 to the left of (̄(1) (0)) 
a declining function () ∈ (0 1) inside the range, and  = 0 to the right of it.

   Equation (11) reflects the MAD principle at work. The left-hand side is the basic incentive
to think that actions are highly productive ( rather than  ) when there are no spillovers
( = 1) or, equivalently, when fixing everyone else’s behavior at  = 1 in both states. The right-
hand corresponds to the expected losses —relative to what the correct course of action would
yield— inflicted on an individual by others’ delusions, and which he can (temporarily) avoid
recognizing by denying the occurrence of the bad state altogether. These endogenous losses,
which transform reality from second best to third best, must be of suﬃcient importance relative
to the first, unconditional, motive for denial.
   • Comparative statics. The proposition also yields several testable predictions. First, there
is the reversal in how agents respond to others’ beliefs (or actions) depending on the sign of
  with the very diﬀerent equilibrium patterns that result. Second, and focusing on the more
interesting case where (11) holds:
   (a) The more vested in the group outcome are its members, the more likely is collective
denial: as shown in Appendix B, both thresholds ̄(0) and (1) decrease with 1 − .
   (b) A more desirable or more plausible high state (higher  or ) has the same eﬀects.
   (c) A worse low state (lower   0) arising for instance from a more risky project, has
more subtle eﬀects. On the one hand, it makes a realistic equilibrium easier to sustain ((1)

                                                  11
increases): the cost of making the wrong decision rises, while there is no harmful delusion of
others to “escape from”. When others are in denial, on the other hand, a lower  makes it even
worse. If 1 − 1 (which must be positive by (11)) is relatively small, the first eﬀect dominates
and ̄(0) increases: suﬃciently bad news will lead people to “snap out” of their collective delusion.
With a suﬃciently common fate or high priors (1 − 1 large enough), on the other hand,
the second eﬀect dominates and ̄(0) decreases. The range over which multiplicity occurs thus
widens, and a worsening of bad news can now cause a previously realistic group to take refuge
in groupthink.
    The types of enterprises that are most prone to collective delusions are thus:
    (a) Those involving new technologies, products, markets or policies that combine a highly
attractive upside and a disastrous downside. High-powered incentives, when prevalent through-
out the organization (e.g., performance bonuses aﬀected by some common market uncertainty)
have a similar eﬀect.
    (b) Those in which participants have only limited exit options and, consequently, a lot rid-
ing on the soundness or folly of other’s judgements. Such dependence typically arises from
irreversible or illiquid prior investments: specific human capital, professional reputation or net-
work, company pension plan, etc. Alternatively, it could reflect the large-scale nature of the
problem: state of the economy, quality of the government, global warming, etc.
    The model also shows how a propensity to “can-do” optimism (high ) can be very beneficial
at the entrepreneurial stage —starting a business, mobilizing energies around a new project
(  0) but turn into a source of real danger once the organization has grown and becomes
involved in more high-stakes ventures (e.g., a mean-preserving spread in  with   0)21

1.4    Asymmetric roles: hierarchies and corporate culture
       “And if the blind lead the blind, both shall fall into the ditch.” (Matthew 15:14)

    I now demonstrate the generality of the MAD principle by relaxing all the symmetry assump-
tions, as well as the state-invariance of the payoﬀ to “inaction” ( = 0) I then use this more
general framework to show how, in hierarchical organizations, denial and realism will “trickle
down”. Let the payoﬀ structure (1) be extended to:

                        
                        X ¡               ¢
(12)            2 ≡        +       
                                    (1 −  )  for all  = 1     and  ∈ { } 
                        =1


Each agent ’s choice of  = 1 thus creates a state-dependent value 
                                                                       for agent , while
 = 0 generates value 
                         ; for  =  these correspond to agent ’s private returns to action

  21
     Similarly, throughout most of human history, collective activities (hunting, foraging, fighting, cultivation,
etc.) were typically characterized by   0 making group morale valuable and susceptibility to optimism (a low
 or ) an evolutionary advantageous trait. Modern technology and finance (e.g., leverage) now involve many
high-stakes activities (  0   ), for which those same traits can be a source of periodic trouble.


                                                       12
and inaction. All payoﬀs remain linearly separable for the same expositional reason as before,
but complementarities or substitutabilities are easily incorporated, as shown in Section 1.5.
Agents may also diﬀer in their preference and cognitive parameters        in their proclivity
to anticipatory feelings  or even in their priors    The generalization of (4) is thus

                                                    ¡       ¢        ¡       ¢
(13)                       
                          −                
                                                    
                                                        −                 
                                                              + (1 −  )  −  
                                          +

while the generalization of    ( is the better state, conditional on everyone taking the
optimal action), is
                                                  
                                                  X            
                                                               X
(14)                                                    
                                                                   
                                                                      
                                                  =1          =1


Focussing here on pure-strategy equilibria, one can again compare an agent ’s incentive to ignore
a signal  =  when surrounded by deniers ( ≡ 0) and by realists ( ≡ 1) The condition for
complementarity, generalizing   0 is now:
                                 X ³       ´
(15)                                 − 
                                            0               for all  = 1    
                                  6=


In accordance with the MAD principle, it means that others’ delusions, leading them to choose
 = 1 even when  =  are on average harmful to agent  Multiple equilibria occur when this
expected loss is suﬃciently large relative to the “unconditional” incentive to deny:
                                             ³
                                            X            ´ X³          ´
(16)                             (1 − )       
                                                  − 
                                                           
                                                                − 
                                                                     
                                            =1                      6=


Proposition 3 (Organizational cultures) Let (13)-(16) hold for all  = 1     There exists
                 £               ¤                                                 £               ¤
a non-empty range ̄ (0)  (1) for each  such that if (1      ) ∈ Π=1 ̄ (0)  (1)  then both
collective realism ( ≡ 1) and collective denial ( ≡ 0) are equilibria.

       • Directions of cognitive influence.        Going beyond multiplicity, interesting results emerge
for organizations in which members play asymmetric roles. Indeed, the thresholds ̄ (0) and
 (1) given in the appendix, confirm the intuition that each agent’s optimal awareness is most
sensitive to how the people whose decisions have the greatest impact on his welfare (the largest
contributors to (15)) deal with unwelcome news.
  As an application, consider the simplest form of hierarchy: two agents, 1 and 2 such as a
                                                                ¯          ¯
manager and a worker. If 12 − 12 is suﬃciently negative while ¯21 − 21 ¯ is relatively small,
                                                                                          
agent 2 suﬀers a lot when agent 1 loses touch with reality, while the converse is not true.22

  22
    Agent 2’s cognitive strategy will then have strong positive dependence on that of agent 1, (̄2 (0)  2 (1) as
in the bottom panel of Figure 2), while that of agent 1 will vary little with that of agent 2 (1 (1)  ̄1 (0))


                                                          13
                             2
                            s (1)


                                                                           A1 : mix
                                                                          A2 : denial



                                       A1 : realism                                          A1 : denial

                                       A2 : realism                                          A2 : denial
                                                               A1 : mix
                                                               A2 : mix



                                                            A1 : mix
                                                          A2 : realism

                                                                                                                   s1
                            s 2 (0)                   1                                  1                  2
                                                  s (1)                                 s (0)              s (1)




                    Figure 3: “Trickle down” of realism and denial in a hierarchy


Workers thus risk losing their job if management makes overoptimistic investment decisions,
whereas the latter has little to lose (perhaps the reverse) if workers put in more eﬀort than
realistically warranted. When the asymmetry is suﬃciently pronounced (conditions are given in
the appendix), this leads to a testable pattern of predominantly top-down cognitive influences,
illustrated in Figure 3. Formally,
                                      £ 1            ¤ £               ¤
(17)                                    (1) ̄1 (0) ⊂ ̄2 (0) 2 (1) ≡ 

and for all (1  2 ) ∈  ×  there is a unique equilibrium, such that:
   (a) The qualitative nature of the manager’s cognitive strategy —complete realism, complete
denial, or mixing— depends only on her own 1  not on the worker’s 2 
   (b) If the manager behaves as a systematic denier (respectively, realist), so does the worker:
where 1 = 1 it must be that 2 = 1 and similarly 1 = 0 implies 2 = 0
   (c) Only when both agents are in partial denial (between the two loci in Figure 3) does the
worker’s degree of realism also influence that of the manager.
    Let agent 2 now be replicated into  − 1 identical workers, each with influence [1 
                                                                                        +
    ¡       ¢
1       
  1 −  ]( − 1) over the manager or leader, but subject to the same influence from him as
                1 ¡     ¢
before, 1   1        1
           +  1 −   Figure 3 then remains operative, showing how the leader’s attitude
toward reality tends to spread to all his subordinates, while being influenced by theirs only in a
limited way, and over a limited range.




                                                                             14
    This result has clear applications to corporate and bureaucratic culture, explaining how
people will contagiously invest excessive faith in a leader’s “vision”.23 Likewise, in the political
sphere, a dictator who is secure in his power need not exert constant censorship or constraint
to implement his policies, as crazy as they may be: he can rely on people’s mutually reinforcing
tendencies to rationalize as “not so bad” the regime they (endogenously) have to live with.
    The model is of course an oversimplified representation of an organization; yet the same
general principles will carry over to more realistic hierarchies with multiple tiers, control rights,
transfer payments, losers and gainers from the delusions of others, etc. I leave such extensions
to future work, and return from here on to the basic, symmetric framework of Section 1.1.

1.5    Strategic interactions
To highlight the model’s new source of interdependence in beliefs and behaviors, I have until
now focussed attention on public-goods-like settings in which an agent’s welfare level depends
on others’ actions, but his return to acting does not. Strategic complementarities in payoﬀs
will, quite intuitively, reinforce the tendency for contagion, whereas substitutabilities will work
against it.24
    To see this, let agent ’ expected payoﬀ in state  =   now be Π (  e− ) where e− de-
notes the vector of others’ actions; his incentive to act is then   (e− ) ≡ Π (1 e− ) − Π (0 e− )
In state  the diﬀerential in ’s anticipatory value of denial that results from others’ “blind”
                                                          P £                        ¤
persistence, previously given by −(1 − )  is now − 6= Π (1 0) − Π (1 1)  which em-
bodies the same MAD intuition as before. The new ingredient is that others’ persistence now
also changes the material value of investing in state  (previously a fixed  ) by an amount
         P £                     ¤
equal to 6=   (1) −   (0)  with sign governed by Σ 6=  2 Π    When actions are
complements, delusion is thus less costly if others are also in denial, whereas with substitutes it
is more costly. Rather than restate general results with nonseparable payoﬀs, which would not
add much insight, I shall focus in Section 3 on an important concrete application: how, in spite
of investments being substitutes, asset markets can be seized by collective “manias”, ultimately
leading to a crash.

   23
      In Rotemberg and Saloner (1993), a manager’s “vision” (prior beliefs or preferences that favor some activities
over others) serves as a commitment device to reduce workers’ concerns about ex-post expropriation of their inno-
vations. In Prendergast (1993), managers’ use of subjective performance evaluations to assess subordinates’ eﬀort
at seeking new information leads the latter to distort their reports in the direction of the manager’s (expected)
signal. Both mechanisms thus lead workers to “conform” their behavior to managers’ prior beliefs. Unlike here,
however, in neither case do they actually espouse those beliefs, nor would the manager ever want them to report
anything but the truth. In Hermalin (1998), a leader with private information about the return to team eﬀort
works extra-hard to convince his coworkers to do so; the resulting separating equilibrium shifts up the whole
profile of eﬀorts (ameliorating the free-rider problem) but involves no mistaken belief by anyone.
   24
      At the same time, without anticipatory feelings or some similarly “non-standard” role for beliefs, no amount
of complementarity can generate results similar to those of the model: agents with standard preferences always
have (weakly) positive demand for information, and thus never engage in denial or ex-post rationalizations.




                                                        15
2          Welfare, shooting the messenger, and free-speech guarantees
Are agents in collective denial worse or better oﬀ than if they squarely faced the truth —as
an alternative equilibrium, or possibly by means of some collective commitment mechanism?
Conversely, can they benefit from preserving a high morale if everyone is able commit to ignoring
bad news?
          Consider first state  =  which occurs with probability 1 −  When agents are realists
(setting  = 1 in (8)), equilibrium welfare is 
                                                 ∗   = 0 When they are deniers (setting  = 0
in (9)), it is given by:

                               ∗
(18)                            = − −  +  +  +  (1 − )  

Collective denial following bad news is thus harmful or beneficial, depending on whether  is
below or above the threshold

                                                     +  − 
(19)                                        ∗ ≡                    
                                                    + (1 − ) 

as illustrated in Figure 4.

Proposition 4 Welfare following bad news (state ):
1) If   0 then ∗  max {̄(0) (1)}  so whenever realism ( = 1) is in the equilibrium
set, it is superior to denial ( = 0) Moreover, there exists a range in which realism is not an
equilibrium but, if it can be achieved through collective commitment, leads to higher welfare.
2) If   0 then ∗  ̄(0) The equilibrium thus involves excessive realism for  ∈ (∗  ̄(0))
and excessive denial for  ∈ ((1) ∗ )  when this interval is nonempty.

          Given how damaging collective delusion is in state  with   0 it makes sense that when
realism can also be sustained as an equilibrium it dominates, and that when it cannot the group
may try to commit to it. Conversely, with   0 boosting morale in state  ameliorates the
free-rider problem, so the group would want to commit to ignoring bad signals when  ≥ ∗ but
the only equilibrium involves realism.25
          Consider now welfare in state  which occurs with probability  : given (4), everyone chooses
   = 1 in both equilibria. Under denial, however, agents can never be sure of whether the state
is truly  or it was really  and they censored the bad news. As a result of this “spoiling”
eﬀect, welfare is only

                   ∗                                                              ∗
(20)                = − +  +  [ + (1 − )  ]  − + ( + )  =  

     25
    If  is high enough that    +  then ∗  0 : denial in state  is then socially beneficial even absent
anticipatory emotions ( = 0) Again, the best example may be team morale in sports.




                                                        16
                                             realism, 




                                                                                                                     weight of
                                                                                                                     anticipatory
                                                                                                                     feelings, s
                                                                  s            s          s*
                                                            higher under realism               higher under denial
                        Welfare in state L

                                                          welfare always higher in H when realistic about L
                        Welfare in state H

                                                                 denial always lowers ex ante welfare
                        Ex ante welfare
                                                                      welcome before
                                                                      investment stage,           unwelcome
                                                                      unwelcome after
                        Dissenter in state L

                        Free-speech                                   may be needed            always needed
                        protections,
                        devil’s advocates




                         Figure 4: Welfare and dissenting speech (groupthink case)


Averaging over the two states, finally, the mean belief about  remains fixed (by Bayes’ rule),
so the net welfare impact of denial is just

(21)                                      ∆ ≡ (1 − ) [( + )  −  − ] 

realized in state  In assessing the overall value of social beliefs, one can thus focus only on
material outcomes and ignore anticipatory feelings, which are much more diﬃcult to measure
but wash out across states of nature.26

Proposition 5 1) Welfare following good news (state ) is always higher, the more realistic
agents are when faced with bad news (the higher is ).
(2) If  ≤ 0 denial always lowers ex-ante welfare. If   0 it improves it if and only if
( + )    + 

       These results, also illustrated in Figure 4, lead to a clear (and potentially testable) distinction
between two types of collective beliefs and the situations that give rise to them.

       • Beneficial group morale. When   0  = 1 is socially optimal even in state  but
since ( + )   it is not privately optimal. If agents can all manage to ignore bad news
at relatively low cost, either as an equilibrium or through commitment, they will thus be better
oﬀ not only ex-post but also ex-ante: ∆  0 This is in line with a number of recent results
showing the functional benefits of overoptimism (achieved through information manipulation or

  26
    As long as agents are Bayesian, which seems like a reasonable assumption for types of activities in which they
engage recurrently.



                                                                          17
appropriate selection of agents by a principal) in settings where agents with the correct beliefs
would underprovide eﬀort.27
       • Harmful groupthink. The novel case is the one in which contagious delusions can arise,
  0 and it also leads to a more striking conclusion: not only can such reality avoidance greatly
damage welfare in state  but even when it improves it those gains are always dominated by the
losses induced in state  : ∆  028 This normative result has positive implications for how
organizations deal with dissenters, revealing an interesting form of time inconsistency between
ex ante and ex post attitudes. In carrying out this discussion, I shall refer interchangeably to
“the group” and to “society”, as in the case of political ideologies.
       • The curse of Cassandra. Let   0 (more generally, ( + )    + ) and consider
a denial equilibrium, as illustrated in Figure 4. Suppose now that, in state  an individual
or subgroup with a lower  or a diﬀerent payoﬀ structure attempts to bring back the facts to
everyone’s attention. If this occurs after agents have have sunk in their investment it simply
amounts to deflating expectations in (3), so they will refuse to pay attention, or may even try to
“kill the messenger” (pay a new cost to forget). Anticipating that others will behave in this way,
in turn, allows everyone to more confidently invest in denial at  = 0 To avoid this deleterious
outcome, organizations and societies will find it desirable to set up ex-ante guarantees such as
whistle-blower protections, devil’s advocates, constitutional rights to free speech, independence
of the press, etc. These will ensure that bad news will most likely “resurface” ex-post in a way
that is hard to ignore, thus lowering the ex-ante return of investing in denial.
       Similar results apply if the dissenter brings his message at an interim stage, after people
have censored but before investments are made. For   ∗ they should, in principle, welcome
the opportunity to correct course and collectively return to reality. In practice, this can be
hard to achieve: it may not be an equilibrium (case   0)  or require full coordination (case
  0) With payoﬀ heterogeneity, dissenters’ motives will also be suspect, making it hard
to convince others. The conclusion is even starker if people value maintaining hope (or dislike
anxiety) suﬃciently that   ∗  In that case, bringing (back) the bad news about the state
really being  will hurt everyone, leading to a universal unwillingness to listen and rejection
—the curse of Cassandra. And yet, free-speech guarantees and mechanisms encouraging dissent
remain desirable ex-ante, because they avoid welfare losses in state  and, on average, save the

  27
     In a team or firm context see, e.g., Bénabou and Tirole (2003), Fang and Moscarini (2005), Van den Steen
(2005) and Gervais and Goldtstein (2007). In a self-control context, see Carrillo and Mariotti (2000), Bénabou
and Tirole (2002) and Battaglini et al. (2005). Also closely related to the present framework is Dessi (2005), who
shows how one generation may want to collude in order to paint to the next one an overly optimistic picture of
the benefits of cooperation. Dessi studies only the social-planner solution achieved through centralized control of
beliefs (e.g., by an all-powerful state), and thus does not consider what equilibria arise from parents’ individual
child-rearing and indoctrination decisions, or their own ideological choices.
  28
     The “shadow of doubt” cast over the good state by the censoring of the bad state could also distort some
decisions in state  although in this simple example it does not. Conversely, departing from Bayesian updating,
for instance by introducing in (7) a “naivete” coeﬃcient  ≤ 1 multiplying 1 −  would attenuate the losses in
state  and thus allow ex-ante gains. See Bénabou and Tirole (2002, 2006c) for examples of both eﬀects.


                                                        18
                            Period 0                           Period 1                     Period 2
                                 H        H
                   ki  K                            ei  E        s E1 U2i                U2i
                                  L       L

                 1st round of signal    recall        2d round of    anticipatory        all units sold,
                 investment about       (attention,   investment     feelings:           market price P(Q)
                              market awareness)                      hope, dread,
                              prospects               cost c         anxiety…        U2i  P (k  e )  (k i  ei )




                                            Figure 5: The market game


organization or society from wasting resources on denial (including killing messengers). There
is now a strong tension between ex-ante and ex-post incentives to tolerate dissenting speech,
illustrations of which abound in corporations, bureaucracies, and polities.


3     Contagious market exuberance
“Why did the company’s chief, who routinely warned of his rivals’ lax lending practices well before the
mortgage market cracked, ultimately allow Countrywide to ardently embrace those practices?... Accord-
ing to... a former banking analyst and founder of a New York investment fund, ‘The biggest self-inflicted
wound here is they should have pulled back in ’05 and ’06 when you had these competitors doing all sorts
of crazy things. Angelo [Mozilo] talked about the danger but somehow went for the market share gains
anyway.’” (Morgenson and Fabrikant, 2007)

“I don’t think it’s a bubble, David M. Rubenstein of Carlyle Group told the Financial Times in December
2006. I think really what’s happening now is that people are beginning to use a diﬀerent investment
technique, and this investment technique, private equity, adds real value.” (BusinessWeek, 2007)


3.1    The dynamics of manias and crashes
I now extend the model to asset markets, adding an ex-ante investment stage and deriving final
payoﬀs from equilibrium prices: see Figure 5. A large number (continuum) of firms or investors
 can each produce  ≤  units of a good (housing, oﬃce space, internet startup) in period 0
and an additional  ≤  units in period 1 where  and  reflect capacity constraints or “time
to build” technological limits. The cost of production in period 0 is set to 0 for simplicity, while
in period 1 it is equal to  All units are sold at  = 2 at which time the expected market price
 () will reflect total supply  ≡ ̄ + ̄ ∈ [0  +] as well as stochastic market conditions,  ,
with  =   Between the two investment phases agents all observe the signal  then decide
how to process it, with the same information structure and preferences as before.
    To take recent examples,  may correspond to a “new economy” in which high-tech startups
will flourish and their prospects are best assessed using “new metrics”; to a permanent rise in
housing values; or to any other positive and lasting shift in fundamentals. Conversely,  would


                                                          19
reflect an inevitable return to “old” economy and valuations; the presence of a bubble that will
ultimately burst; or the unsustainability for many households of meeting future payments on
their adjustable-rate mortgages, stated-income loans and other subprime debt. Finding reasons
to believe in  even as evidence of  accumulates corresponds to what Shiller (2005) terms
“new-era thinking”, and of which he relates many examples. I provide in this section the first
analytical model of this phenomenon.29
       The absence of an interim or futures market before date 2 is a version (chosen for simplicity) of
the kind of “limits to arbitrage” commonly found in the finance literature. Specifically, I assume
that: (i) goods produced in period 0 cannot be sold before period 2 for instance because they
are still work-in-progress whose quality or market potential is not verifiable: startup company,
unfinished residential development or oﬃce complex, new type of financial asset; (ii) short sales
are not feasible.
       Such limited arbitrage possibilities are empirically descriptive of the types of markets which
the model aims to analyze.30 In the recent mortgage-related crisis, a dominant fraction of
the assets held by major U.S. investment banks did not have an active trading market and
objective price, but were instead valued according to the bank’s own model and projections,
or even according to management’s “best estimates”. Figure 6 shows the figures for Lehman
Brothers and Bear Stearns, constructed from Reilly (2007).31 Worldwide, the notional value of
outstanding Collateralized Debt Obligation (CDO) tranches stands at about $2 trillion and that
of Credit Default Swaps (CDS) around $50 trillion; and yet there is no established, centralized
marketplace where most of them they could easily be traded. These are instead very illiquid
(“buy and hold”) and hard-to-price assets: originating in private deals, highly diﬀerentiated and
exchanged only over-the-counter. In housing, finally, regional-index futures (Case-Shiller) are a
very recent innovation and their market is still small and fairly illiquid.
       Suppose (for now) that, ex-ante, the market is suﬃciently profitable that everyone invests
up to capacity at the start of period 0 :  = ̄ =  Moreover, following (4), let

                                       
(22)                    ()            ( + ) + (1 − ) ( + )
                                   +  

It is thus a dominant strategy for an agent at  = 1 to invest the maximum  =  if his posterior
is no worse than the prior  and to abstain if is sure that the state is 

  29
     As explained in the introduction, neither “rational bubbles” nor informational cascades involve any element
of wishful thinking, distorted information processing or motivated rationalization. In both cases, all investors are
acting exactly as an impartial, information-seeking statistician would advise (or allow) them to.
  30
     Shiller (2003) cites several studies documenting the fact that, in recent times, short sales never amounted to
more than 2% of stocks (whether in number of shares or value). Gabaix et al. (2007) provide specific evidence of
limits to arbitrage in the market for mortgage-backed securities.
  31
     The share of Level 3 assets, whose valuations Reilly describes as “little more than management’s guesses”,
was as high as 10% when Goldman Sachs and J.P. Morgan were included, and around 6% when Merrill Lynch
was added. Concerning Level 2 assets, the major trading houses commonly used computer programs designed for
“plain vanilla” loans to value novel and highly complex securities (Hansell, (2008)).



                                                        20
                                         Lehman Brothers    Bear Stearns


                          Level 1          96    (35.6%)    39 (17.7%)     Trade in active markets
                                                                           with readily available
                                                                           prices

                          Level 2         152    (56.3%)    163 (74.1%)    “Mark to model’’



                          Level 3          22    (8.2%)      18 (8.2%)     “Reflect management’s
                                                                           best estimates of what
                                                                           market participants would
                                                                           use in pricing the assets”
                          Total            270             220
                          ($ billions)




       Figure 6: Financial assets on balance sheet, 2d fiscal quarter of 2007. Source: Reilly (2007).


   Consider now the market subgame that unfolds when agents observe the signal  at the end
of period 0 The optimality of first-stage investment  =  (which involves expected profits in
both states) is shown in the appendix and taken here as given, for expositional simplicity.

   • Realism. If market participants acknowledge and properly respond to bad news ( ≡ 1)
they will not produce any additional units at  = 1 so the price at  = 2 will be  () For an
individual investor  with stock   the net eﬀect of ignoring the signal is thus

                           
(23)               (0 − 0 ) = − + [( + ) () − ] 
                                                +( ) [ ( + ) −  ()] ( + )

The second term reflects the expected losses from producing at  = 1 while the last one represents
the value of maintaining hope that the market is strong or will eventually recover, in which case
                                                                                   
total output will be  +  and the price  ( + ) Realism is an equilibrium if 0    
                                                                                       ≤ 0
for  = 1 and  =  or

                                       + [ −  ()] 
(24)                   ≤                                            ≡ (1)
                             [ ( + ) −  ()] ( + ) +  ()

   • Denial. If the other participants remain bullish in spite of adverse signals, they will keep
producing at  = 1 causing the already weak market to crash: at  = 2 the price will fall to
 ( + )   () The net value of denial for investor  is now

                         
(25)             (0 − 0 ) = − + [( + ) ( + ) − ] 
                                           +( ) [ ( + ) −  ( + )] (  + )

In the second term, the expected losses from overproduction are higher than when other partic-
ipants are realists. Through this channel, which reflects the usual substitutability of production
decisions in a market interaction, each individual’s cost of delusion increases when others are


                                                           21
deluded. On the other hand, the third term makes clear that the aﬀective value of denial is also
greater, since acknowledging the bad state now requires recognizing an even greater capital loss
on any preexisting holdings. This is again the MAD principle at work.
                                 
    Denial is an equilibrium if 0    
                                     ≥ 0 for  = 0 and  =  or

                                   + [ −  ( + )] 
(26)             ≥                                                     ≡ ̄(0)
                       [ ( + ) −  ( + )] ( + ) +  ( + )

When does other participants’ exuberance make each individual more likely to also be exuberant?
Intuitively, such contagion occurs when the substitutability eﬀect, which bears on the marginal
units  produced in period 1 is dominated by the capital-loss eﬀect on the outstanding position
 inherited from period 0 Formally, ̄(0)  (1) requires that  be large enough relative to 
though not so large as to preclude (24).

Proposition 6 (Market manias and crashes) If
                                             µ          ¶
                                                  +           
(27)                            ( + )                          ( + )
                                                               

there exists ∗  1 such that, for all  ∈ [ ∗  1] there is a non-empty interval for  in which both
realism and blind “exuberance” in the face of adverse news are equilibria, provided  is not too
large. Contagious exuberance leads to overinvestment and, eventually, a deep market crash.

    The model provides a microfounded and psychologically-based account of market groupthink,
investment frenzies and ensuing crashes. It also identifies some key features of the markets that
are prone to such cycles.
    First, there must be a “story” about shifts in fundamentals that is minimally plausible a
priori ( must not be too low): technology, demographics, globalization, etc. The key result is
that investors’s beliefs in the story can then quickly become resistant to any contrary evidence.32
Second, when the new opportunity first appears ( rising above the threshold), there is an initial
phase of investment buildup and rising price expectations. Finally, the assets in question must
be characterized by both significant uncertainty and limited liquidity, as discussed earlier. These
conditions are typical of assets tied to new technologies or financial instruments whose potential
will take a long time to be fully revealed.
    The model’s comparative statics also shed light on other puzzles. From (23)-(26), we obtain:
    (a) Escalating commitment at the individual level: the more an agent has produced or
invested to date ( ) the more likely he is to continue even in the face of bad news, thus
displaying a form of the sunk cost fallacy.33 Moreover, while   represents here an outstanding

  32
     By contrast, in standard models of stochastic bubbles everyone realizes that they are trading a “hot potato”
whose value does not reflect any fundamentals, must eventually collapse, and can do so at any instant.
  33
     This eﬀect is closely related to the escalating commitment studied in Bénabou and Tirole (2007), but arises
there from a somewhat diﬀerent mechanism (self-signaling).


                                                       22
inventory or financial position, any other illiquid asset with market-dependent value, such as
sector-specific human capital, clearly has the same eﬀect.
    (b) Market momentum: the larger the total market buildup ( − = ) the more likely is
each agent to continue investing in spite of bad news, under a simple condition on the price
sensitivity of demand. Indeed, in a denial equilibrium the incentive to discount negative news
stems from prospective capital losses proportional to  ( + ) −  ( + ) which increases
in  when  2   034 This occurs for instance when good fundamentals correspond to a
scarcity of some close substitute and market demand is concave:

                            () = P( + ( ))              with     0  P 0  P 00  035

A greater market buildup  then tends to makes denial easier to sustain and realism more
diﬃcult, thus raising the likelihood of continued momentum.
    This simple asset-market model could be extended in several ways. First, in a dynamic con-
text, outstanding stocks will result stochastically from the combination of previous investment
decisions and demand realizations. Second, one could relax the relatively strong form of “limits
to arbitrage” imposed here through the assumption that trades occur only at  = 2 (no forward
market). Such “early” trades could instead involve transactions costs, risk due to limited market
liquidity or, for large positions, an adverse price impact.36

3.2     Regulators, politicians and other indirect stakeholders
The preceding analysis showed how an agent’s propensity to respond to danger signals with
a “suspension of disbelief” increases with his initial investment position  , market-correlated
human capital or any other asset that cannot easily be sold oﬀ or hedged. Other, more indirect
stakes have similar eﬀects, both contributing to and feeding on the propagation of collective
blindness (and ultimate losses) to broad parts of the economy.
    Thus, if indicators point to a state of the world in which the housing sector is headed for a
crash and the economy for a recession, all three major assets of households are at risk: their job,
the value of their house and their pension —the latter especially is some of it is invested in their
employer’s stock. The worse the potential downturn is made by other agents’ feeding of the
market frenzy, the greater is the incentive not to acknowledge these risks (dismiss or rationalize
away the signal  = ). And, as a result, the greater the likelihood that the household will itself

  34
     For simplicity I focus here on the benefit side of denial, leaving aside the cost. A higher  always always
raises the latter, but if  is small relative to  this eﬀect will be dominated. Similarly, in a realistic equilibrium,
capital losses are proportional to  ( + ) −  () = [ ( + ) −  ( + )] + [ ( + ) −  ()] 
The first term is the same as before, and it will dominate the second one if  is not too large relative to 
  35
     Another example is the linear market demand ( ) =  ( −  )  leading to  = −1 ( − ) 
  36
     Trying to sell (or sell short) in period 1 could also be self-defeating, as it would reveal again to the market that
the state is  generating an immediate price collapse. For a model of how market thinness generates endogenous
limits to arbitrage and delays in trade, see Rostek and Weretka (2008).


                                                           23
contribute to the excessive buildup of debt, housing, or undiversified stock holdings.
         Another set of key actors with “value at risk” are politicians and regulators, whose career
and reputation will be badly damaged if the disaster scenario (state  worsened by market
participants’ manic overinvestment) occurs. This should normally make them try to dampen
the market’s enthusiasm, but if the buildup has proceeded far enough (high ) that large,
economy-wide losses are are unavoidable in the bad state, they will also become “believers” in
a rosy future or smooth landing. Consequently, they will fail to take the measures that could
have limited (tough not avoided) the damage, and thus further enable the investment frenzy
and subsequent crash.37 Public oﬃcials or academics may also have a more general ideological
stake in (say) the virtues of unfettered financial markets: a severe crisis that would publicly
prove such faith to be excessive would reduce the general credibility of laissez-faire arguments
and increase demand for public regulation in other parts of the economy.


4         Other applications and extensions
4.1        Collective apathy and fatalism
The form of denial considered so far has been a collective “illusion of control” or overconfidence,
leading an organization or market to persist in a costly course of action in spite of widely available
evidence that it is doomed. The opposite case is collective apathy: rather than acknowledge
a crisis that could be partly remedied through timely action, everyone pretends that things,
though perhaps not great, “could be worse”, and that “nothing can be done” to improve them
anyway. One can think of an ethnic group subject to discrimination or threatened by another
one, but whose members pessimistically deem it useless to fight back, try to escape or otherwise
improve their lot (see, e.g., Cialdini (1984) and Hochschild (1996) on minorities’ acquiescence
to a discriminatory system). A second example, examined below, is that of “tuning out” the
distress of others.
         To capture these ideas, I simply extend (1) to
                                    £                    ¤
(28)                         2 =   + (1 − )− −   where            ≷ 0

         • When   min{1  ∆} state  remains (conditional on  = 1) a more favorable
state than  and one can show that for  below a certain threshold all the results of the case
 = 0 carry over with little change. In particular, if −  0 it plays a role very similar to an
individual’s outstanding market position   in the previous section.

    37
     Asked in a 2007 Congressional testimony whether he was “at all concerned... that if one of these huge
institutions fails, it will have a horrendous impact on the national and global economy”, former FED Chairman
Alan Greenspan replied: “No, I’m not,” “I believe that the general growth in large institutions have occurred in
the context of an underlying structure of markets in which many of the larger risks are dramatically —I should
say, fully— hedged” (Goodman (2008). For other instances of blindness to red flags and even active information-
avoidance by the FED and other regulators, see Appendix A.


                                                      24
    • When   max{1  ∆} state  corresponds to a crisis state: action is called for but,
even when carried out eﬀectively ( ≡ 1) will not suﬃce to oﬀset the shock, leaving agents
worse oﬀ than in state  Intuition now suggests that an equilibrium in which agents respond
appropriately to crises can coexist with one in which they systematically censor such signals and
remain passive, even when they actually have individual “agency”.38
    Indeed, this problem is closely related to the original one, once recast in terms of the relative
eﬀectiveness of inaction. Formally, let ̃ take values ̃̃ ≡ − in state ̃ ≡  and ̃̃ ≡ −  0
in state ̃ ≡  with respective probabilities ̃ ≡ 1 −  and 1 − ̃; similarly, let ̃ ≡ − Using
these transformed variables, it is then easy to obtain “parallels” to Propositions 2 to 5. In
particular, condition (4) is replaced by

                                                                    
(29)                             + (1 − )                        
                                                         ( + )   

and the equilibrium strategies and thresholds are obtained by replacing ∆ with −∆ and
     and  with their “tilde” analogues.

Proposition 7 Assume (29) and   max{1  ∆} All the results in Proposition 2 remain,
but with denial (  1) now occurring in state  only and leading to inaction. Facing up to
crises and fatalistic inertia are both social equilibria if and only if  (∆)  (1 − )  

    The left-hand side of this modified MAD condition reflects the action-independent gain from
being in the no-crisis state, while the right-hand side measures the endogenous losses inflicted
by all those who, denying that a crisis has occurred, fail to act.
    • Helping others or tuning out. Studies of how people respond to the distress of others —
victims of accidents, wars, natural disasters, famine, etc.— display two important puzzles. First,
people show a greater willingness to help or contribute when the number of those perceived
to be in need is small than when it is large. Slovic (2007) discusses a number of experiments
documenting such “psychic numbing” (lowered aﬀective reactions and willingness to give) in
response to even small absolute increases in the size of the at-risk group. He further argues for
the importance of this phenomenon in accounting for public inertia in the face of humanitarian
disasters, poverty and genocide. A second regularity, common to most public-goods situations,
is that people give and help more when they know or expect that others are doing so.39
    The above results can help understand both phenomena. Let  be the number of people
in need, or emphasized as being in need, and let  be the severity of their situation. At cost ,

  38
     Furthermore, there is now no equilibrium in which agents censor the signal  =  just like when  = 0 (or 
suﬃciently below min{1  ∆} more generally) there is no equilibrium in which they censor  =  See Lemma
4 and the proof of Proposition 7 in the appendix, with ∆ ≡ −∆
  39
     The first phenomenon is distinct from (but combines with) the “identifiable victim eﬀect”. Small et al. (2007)
thus found that donations to a specifically identified Malawian child facing the risk of starvation decreased by
more than a half when information about the child was complemented with background statistics documenting
the scale of food shortages in Africa. An alternative explanation for the second set of findings is one of social or
personal norms; see Bénabou and Tirole (2006a).


                                                        25
each individual  = 1   can help up to  victims ( = 1) and he experiences an empathic
disutility equal to the total amount of suﬀering,
                                                £             ¤
(30)                                    2 = −  − Σ=1  

Note that this does not assume that people intrinsically undervalue “statistical lives” or actions
that represent only “a drop in the ocean”. Instead, this will be a result. Indeed, (30) corresponds
to (28) with  = 1  =  and  simply replaced by  Therefore, as  increases beyond
a critical threshold:
   (a) The loss in utility from acknowledging  =  overtakes an individual’s ability to rem-
edy it, causing him to switch from helping to “tuning out” the problem altogether. Thus, he
eﬀectively censors from awareness and recall all painful evidence of the crisis: turning the page
of the newspaper, switching the channel, rationalizing the situation as not so bad, etc.
   (b) The level at which an individual switches from response to non-response depends on
how many others he believes are helping or also tuning out: what matters to  is  − Σ6=  
Hence, within some range of  both collective generosity and collective apathy —what Slovic
terms the “collapse of compassion”— are social equilibria, even though charitable giving involves,
realistically, no increasing returns.
   (c) Vivid, memorable images of the intensity of individual suﬀering  (but not the number,
 which has the opposite eﬀect) make the crisis more diﬃcult to put “out of mind” and thus
reduce the scope of apathy. In the multiplicity range, one small such example, widely publicized,
can trigger a large equilibrium shift.

4.2    Alternative informational preferences and technologies
To highlight general-equilbrium eﬀects, the model used the simplest possible (linear) specification
of individual utility from beliefs. On the cognitive side, it emphasized ex-post information
processing —selective attention, interpretation, recall— rather than ex ante information acquisition
or avoidance. The MAD intuition is much more general, however, and provides a clear template
for generating similar “social cognition” results from preferences (axiomatic or not) that focus on
attitudes toward risk. Consider agents with a preference for late resolution of uncertainty (Kreps
and Porteus (1978)), or any other value function concave in beliefs. If an agent’s remaining
ignorant of the state of the world leads him to increase the risks borne by other participants
in the organization or market, this will push them toward also wanting to delay finding out
about the future. Thus, if information avoidance or lack of costly attention generates adverse
spillovers (now in the variance rather than mean of payoﬀs, but still without need for exogenous
complementarities), it will be contagious. Conversely, if its risk spillovers are favorable, it will
be self-dampening.



                                                  26
5         Conclusion
This paper has developed a general model of how wishful thinking and reality denial spread
through organizations and markets. The underlying mechanism does not rely on built-in com-
plementarities, agents’ herding on a subset of private signals, or exogenous biases in inference.
It is widely applicable, helping to explain corporate cultures characterized by dysfunctional
groupthink or valuable group morale, why delusions flow down hierarchies, and the emergence
of market manias sustained by “new-era” thinking, followed by deep crashes.
         In each of these applications, the institutional and market environment was kept very sim-
ple, so as to make clear the workings of the underlying “Mutually Assured Delusion” principle.
Enriching these context-specific features of the model would be quite valuable and permit new
applications. This is particularly true for hierarchical organizations, where richer payoﬀ and in-
formation structures could be incorporated, along with greater heterogeneity of interests among
agents. Potential applications include the spread of organizational corruption (e.g., Anand et
al. (2005)), corporate politics (e.g. Zald and Berger (1998)) and organizational design (optimal
mix of agents, network structure, communication mechanisms).
         “Fantastic faith” and immunity to evidence are also clearly at work in political ideology. In
Bénabou (2008) I embed the model into a political economy setting and analyze society-wide
beliefs concerning the relative merits and proper scope of the state versus the market. A common
principle is thus shown to help explain reality distortions in both organizational and political
culture. A further application to politics could be the spread and persistence of conspiracy
theories (including “dependency theory”, as described by North (1990)).
         A somewhat diﬀerent class of collective delusions are mass panics and hysterias. While
the model generates not only hard-reality crashes but also episodes of excessive doubt and
overcautiousness, the latter seem too mild to capture what goes on in a full-fledged panic.40 Un-
derstanding the sources and transmission mechanisms that underlie delusional group pessimism,
rather than optimism, is an interesting question for further research.




    40
     Recall first that, when agents censor bad news, they never fully believe in the good state ( = ) even when
it actually occurs: they cannot avoid suspecting that there could have been danger signals which they (and others)
looked away from. Second, investors who fear (perhaps from having been burned once) falling prey to the next
wave of collective overoptimism will shy away from even positive expected-value investments (this occurs when
condition (B.27) in the appendix is reversed).


                                                       27
                                 Appendix A: Patterns of Denial

       This appendix highlights certain patterns (in both words and deeds) that recur across most
instances of organizational and market meltdown, from the Space Shuttle disasters to the current
financial crisis.41
       1. Preposterous probabilities. Feynman’s simple reasoning cited in the introduction
makes clear that NASA management’s risk estimates —one thousand times lower than those of
their own engineers— made no statistical sense. The housing-related bubble and buildup to the
current financial crisis abound in even more extreme statements of confidence —nothing short of
probability one. In an August 2007 conference with analysts, Joseph Cassano, head of A.I.G.
Financial Services, asserted
       “It is hard for us, without being flippant, to even see a scenario within any kind of realm of reason
that would see us losing one dollar in any of those transactions...”.42
       As late as 2008, in a meeting with investors,
       “Lehman’s chief financial oﬃcer, Erin Callan,... exuded confidence... With firms like Citigroup and
Merrill raising capital, an investor asked, why wasn’t Lehman following suit? Glaring at her questioner,
she said that Lehman didn’t need more money at the time —after all, it had yet to post a loss during the
credit crisis. The company had industry veterans in the executive suite who had perfected the science
of risk management, she said. “This company’s leadership has been here so long that they know the
strengths and weaknesses... We know when we need to be worried, and when we don’t.” (Anderson and
Duhig (2008))
       Are such statements by top executives only cynical attempts to deceive investors and analysts
about the quality of their balance sheet? While there is surely an element of moral hazard, this
explanation falls short on several counts. First, absurd claims of zero risk in highly turbulent
times are simply not credible, and thus more likely to be read as negative signals about the
executive’s grasp of reality than reassurance about fundamentals. In fact, they typically do
nothing to bolster a company’s share price, credit rating or prevent a run (see Sorkin (2008) for
many examples).
       Second, knowingly deceiving investors often leads to criminal prosecution and prison, as
well as ruinous civil lawsuits and loss of reputation. A key aspect of self-delusion in such cases
involves the expectation of “getting away” with fraud and cover-up, rather than ultimately
sharing the fate of predecessors at Drexel Burnham Lambert, Enron, Worldcom, and many
others.43 Even abstracting from legal liability, selective blindness and collective rationalizations

  41
     In what follows, all the quotes concerning NASA come from The Rogers Commission Report (1986) and the
Columbia Accident Investigation Board Final Report (2003).
  42
     Cited in Morgenstern (2008). Not coincidentally, this is the London unit (which he founded) that sank the
company after selling over $500 billion in credit default swaps that could not be covered.
  43
     In 2007 alone the FBI made over 400 arrests in subprime-related cases (including top fund managers at Lehman
Brothers) and had ongoing criminal investigations into 26 major financial companies including Countrywide


                                                       28
about the unethical nature of an organization’s practices are key elements in the process that
leads otherwise respectable citizens to take part in those practices (e.g., Sims (1992), Cohan
(2002), Tenbrunsel and Messick (2004), Anand et al. (2005), Schrand and Zechman (2008)).
    Third, identical claims of zero risk are made in settings where no large financial gain is
involved and the downside can be truly catastrophic —as with NASA mission managers and
financial regulators. Former FED Chairman Alan Greenspan’s certainty that the new risks taken
on by financial institutions were “dramatically —I should say, fully hedged” thus turned to
“shocked disbelief” when the disaster scenario materialized a few months later.
    2. New paradigms: this time is diﬀerent, we are smarter and have better tools.
Every case also displays the typical pattern of hubris, based on claims of superior talent or
human capital. For A.I.G.’s Joseph Cassano, losses being simply unimaginable,
    “The question for us is, where in the capital markets can we gain the best opportunity, the best
execution for the business acumen that sits in our shop?”.
    What Feynman termed “fantastic faith in the machinery” is also often vested in computer
models and statistical data. Subprime lenders and the banks purchasing the derived CDO’s could
thus rely on “a wealth of information we didn’t have before” (Countrywide), fed to sophisticated
computer programs:
    “ ‘It’s like having a secret sauce; everyone had their own best formulas,” says Edward N. Jones, CEO
of ARC Systems, which sold [underwriting and risk-pricing] technology to HSBC... and many of their
rivals.” (BusinessWeek (2007))
    Closely related is the argument that previous rules of accounting, risk management or eco-
nomics no longer apply, due to some radical shift in fundamentals. Shiller (2005) documents
how such “new era thinking”, variously linked to railroads, electricity, internet, demography
or deregulation, was involved in nearly all historical episodes of financial bubbles and manias.
Section 3 mentioned its latest incarnation —private equity as “a diﬀerent investment technique...
[that] adds real value.” One can also see it at work in government:
    “The [senior White House] aide said that guys like me were “in what we call the reality-based
community,” which he defined as people who “believe that solutions emerge from your judicious study of
discernible reality.” I nodded and murmured something about enlightenment principles and empiricism.
He cut me oﬀ. “That’s not the way the world really works anymore,” he continued.” We’re an empire
now, and when we act, we create our own reality. And while you’re studying that reality — judiciously, as
you will — we’ll act again, creating other new realities, which you can study too, and that’s how things
will sort out.” (Suskind (2004))
    3. Escalation, failure to diversify, divest or hedge. Wishful beliefs show up not only in
words but also in deeds. Enron’s CEO Ken Lay resisted selling his shares throughout the long

Financial, A.I.G., Lehman Brothers, Fannie Mae and Freddie Mac. These companies and their top executives
(e.g., most of those cited in this appendix) are also being sued by several State attorney generals, in addition to
countless shareholders groups, investors and borrowers.


                                                        29
downfall, pledging other assets to meet collateral requirements, even buying stock back later
on and ending up ruined well before his legal troubles began (Eichenwald (2005), Pearlstein
(2006)). The company’s employees, whose pension portfolios had on average 58% in Enron
stock, could have moved out at nearly any point, but most never did (Samuelson (2001)). At
Bears Stearns, 30% of the stock was held until the last day by employees —with presumably
easy access to diversification and hedging instruments— who thus lost their capital together with
their job. CEO James Cayne alone owned an unusually high 6% and went from billionaire to
small millionaire in the process (spending most of the intervening months away playing golf and
bridge). The pattern is similar at Lehman Brothers and other financial institutions.
    Without looking to such extremes, Malmendier and Tate (2005, 2008) document many CEO’s
tendency to delay exercising their stock options and how this measure of overconfidence is a
predictor of overinvestment. Studying individual investors, finally, Karlsson, Loewenstein and
Seppi (2006) find that many more go online to check the value of their portfolios on days when
the market is up than when it is down.
    Some of the most interesting evidence comes from cases in which an oﬃcial inquiry or trial
was conducted following a public- or private-sector disaster. Extensive records of meeting notes,
memos, emails and sworn depositions reveal how key participants behaved, in particular with
respect to information.
    4. Information avoidance, repainting red flags green and overriding alarms. The
most literal case of willful blindness occurred after the Columbia mission sustained a large foam
strike to its wing’s thermal shield:
    “At every juncture of [the mission], the Shuttle Program’s structure and processes, and therefore the
managers in charge, resisted new information. Early in the mission, it became clear that the Program
was not going to authorize imaging of [damage to] the Orbiter because, in the Program’s opinion, images
were not needed. Overwhelming evidence indicates that Program leaders decided the foam strike was
merely a maintenance problem long before any analysis had begun.”
    Similar “head-in the sand” behavior was extensively documented at the Securities and Ex-
change Commission, even before its decade-long ignorance of Bernard Madoﬀ’s giant Ponzi
scheme was revealed. The Inspector General’s Report (S.E.C. (2008)) thus states:
    “The audit found that [the Division of] Trading and Markets became aware of numerous potential
red flags prior to Bear Stearns’ collapse, regarding its concentration of mortgage securities, high leverage,
shortcomings of risk management in mortgage-backed securities and lack of compliance with the spirit of
Basel II standards, but did not take actions to limit these risk factors.”
    Instead, as reported in Labaton (2008), “the commission assigned [only] seven people to
examine [the major investment banks] —which last year controlled... combined assets of $4
trillion. Since March 2007, the oﬃce has not had a director. And as of last month, the oﬃce
had not completed a single inspection since it was reshuﬄed by Mr. Cox [the SEC chairman]
more than a year and a half ago.”

                                                     30
   Similarly, at the FED...
   “Edward M. Gramlich, a Federal Reserve governor... warned nearly seven years ago that a fast-
growing new breed of lenders was luring many people into risky mortgages they could not aﬀord. But
when Mr. Gramlich privately urged Fed examiners to investigate mortgage lenders aﬃliated with national
banks, he was rebuﬀed by Alan Greenspan... Mr. Greenspan and other Fed oﬃcials repeatedly dismissed
warnings about a speculative bubble in housing prices... The Fed was hardly alone in not pressing to clean
up the mortgage industry. When states like Georgia and North Carolina started to pass tougher laws
against abusive lending practices, the Oﬃce of the Comptroller of the Currency successfully prohibited
them from investigating local subsidiaries of nationally chartered banks.” (Morgenson and Fabrikant
(2007))
   ... and the Treasury:
   “In 1997, the Commodity Futures Trading Commission,... led by a lawyer named Brooksley E.
Born... was concerned that unfettered, opaque trading could “threaten our regulated markets or, indeed,
our economy without any federal agency knowing about it,” she said in Congressional testimony. She
called for greater disclosure of trades and reserves to cushion against losses. Ms. Born’s views incited
fierce opposition from Mr. Greenspan and Robert E. Rubin, the Treasury secretary then. Treasury
lawyers concluded that merely discussing new rules threatened the derivatives market... In the fall of
1998, the hedge fund Long Term Capital Management nearly collapsed, dragged down by disastrous bets
on, among other things, derivatives. Despite that event, Congress froze the Commission’s regulatory
authority for six months. The following year, Ms. Born departed. In November 1999, senior regulators
—including Mr. Greenspan and Mr. Rubin— recommended that Congress permanently strip the C.F.T.C.
of regulatory authority over derivatives.” (Goodman (2008))
   To avoid having to override alarms systems, it is sometimes simplest to turn them oﬀ from
the start:
   “The Commission was surprised to realize after many hours of testimony that NASA’s safety staﬀ
was never mentioned... No one thought to invite a safety representative or a reliability and quality
assurance engineer to the [prelaunch] January 27, 1986, teleconference between Marshall [Space Center]
and Thiokol. Similarly, there was no representative of safety on the Mission Management Team that
made key decisions during the countdown on January 28, 1986. The Commission is concerned about the
symptoms that it sees.”
   Similarly, at Fannie Mae:
   “Between 2005 and 2007, the company’s acquisitions of mortgages with down payments of less than
10% almost tripled... For two years, Mr. Mudd operated without a permanent chief risk oﬃcer to guard
against unhealthy hazards. When Enrico Dallavecchia was hired for that position in 2006, he told Mr.
Mudd that the company should be charging more to handle risky loans. In the following months to come,
Mr. Dallavecchia warned that some markets were becoming overheated and argued that a housing bubble
had formed... But many of the warnings were rebuﬀed... Mr. Dallavecchia was among those whom Mr.
Mudd forced out of the company during a reorganization in August.” (Duhig (2008))

                                                   31
   The cavalier misuse of computerized models and simulations beyond their intended purposes
is also mirrored between the engineering and financial worlds. Thus,
   “Even though [Columbia’s] debris strike was 400 times larger than the objects [the computer program]
Crater is designed to model, neither Johnson engineers nor Program managers appealed for assistance
from the more experienced Huntington Beach engineers, who might have cautioned against using Crater
so far outside its validated limits. Nor did safety personnel provide any additional oversight.”
   In the subprime-credit boom,
   “Some trading desks [at major banks] took the most arcane security, made of slices of mortgages, and
entered it into the computer if it were a simple bond with a set interest rate and duration... But once
the mortgage market started to deteriorate, the computers were not able to identify all the parts of the
portfolio that might be hurt.” (Hansell, 2008)
   5. Normalization of deviance, changing standards and rationales.
   How do organizations react when what was not supposed to happen does, with increasing
frequency and severity?
   “This section [of the report] gives an insider perspective: how NASA defined risk and how those
definitions changed over time for both foam debris hits and O-ring erosion. In both cases, engineers and
managers conducting risk assessments continually “normalized” the technical deviations they found...
Evidence that the design was not performing as expected was reinterpreted as acceptable and non-deviant,
which diminished perceptions of risk throughout the agency... Engineers and managers incorporated
worsening anomalies into the engineering experience base, which functioned as an elastic waistband,
expanding to hold larger deviations from the original design. Anomalies that did not lead to catastrophic
failure were treated as a source of valid engineering data that justified further flights... NASA documents
show how oﬃcial classifications of risk were downgraded over time.”
   The same pattern of normalizing close calls with disaster shows up as a precursor to corporate
scandals and financial meltdowns. Several years before Ken Lay failed to heed V.P. Sherron
Watkins’ urgent plea that he and the CAO “sit down and take a good, hard, objective look at
what is going to happen to Condor and Raptor [ventures] in 2002 and 2003”, lest the company
“implode in a wave of accounting scandals”, he had refused to fire two high-revenue-generating
oil traders after learning that they had stolen millions from the company and forged financial
documents to hide it. A year later, those very same “rogue” traders used again falsified books to
make huge unauthorized bets on oil prices, which went sour and exposed the company to several
hundred millions dollars of potential losses (Eichenwald (2005)). In a near repeat scenario, in
2004 AIG Financial Services caused the parent company to be fined $126 million for helping
clients engage in tax and accounting fraud. Yet the same manager (J. Cassano) remained in
charge and was even put on the newly formed committee in charge of quality and risk control
—until his unit blew up the company four years later.




                                                    32
       6. Reversing the burden of proof. At the Beech-Nut Corporation in late 1970’s, tests
by the main food scientist suggested that the apple concentrate from a new (and cheaper) major
supplier was probably adulterated. Top management responded by telling scientists that the
company would not switch suppliers unless they could absolutely prove that it was. At the same
time, they made it more diﬃcult for them to conduct inspections.44 Similarly, at NASA,
       “When managers... denied the team’s request for imagery, the Debris Assessment Team was put in
the untenable position of having to prove that a safety-of-flight issue existed without the very images
that would permit such a determination... Organizations that deal with high-risk operations must always
have a healthy fear of failure — operations must be proved safe, rather than the other way around. NASA
inverted this burden of proof...”
       Similar reversals of evidentiary standards and shifting rationales were also documented in
the decision process leading to the second Iraq war, particularly on the issue of weapons of mass
destruction (Hersh (2004), Isikoﬀ and Corn (2007)).
       7. Malleable memories: forgetting the lessons of history. The commission investi-
gating the Columbia accident was struck by how the same patterns had repeated themselves six
years after Challenger:
       “The Board found that dangerous aspects of NASA’s 1986 culture, identified by the Rogers Commis-
sion, remained unchanged... Despite the constraints that the agency was under, prior to both accidents
NASA appeared to be immersed in a culture of invincibility, in stark contradiction to post-accident
reality. The Rogers Commission found a NASA blinded by its “Can-Do” attitude... which bolstered
administrators’ belief in an achievable launch rate, the belief that they had an operational system, and
an unwillingness to listen to outside experts.”
       In the financial and regulatory worlds, the lessons of LTCM were also quickly forgotten, as
were those of the internet bubble a few years later. Such failures of individual and collective
memory are recurrent. They were even pointed out (and then forgotten) by a key observer and
participant:
       “An infectious greed seemed to grip much of our business community... The trouble, unfortunately,
is that the shock of what has happened will keep malfeasance down for a while. But human nature
being what it is —and memories fade— it will be back. And it is important that at that time appropriate
legislation be in place to inhibit activities that we would perceive to be inappropriate.” (Greenspan (2002))




  44
     The product was later shown to be 100% artificial. Beech-Nut was convicted and paid several million in fines
and class-action settlements, while the CEO and the former Vice-President of manufacturing were sentenced to
jail (Sims (1992)).


                                                       33
                                        Appendix B: Proofs

       In the proofs of Proposition 1 and 2 given below, I maintain the text’s focus on cognitive
decisions in state , implicitly fixing everyone’s recall strategy in state  to  = 1 Then, in
Lemmas 3 and 4, I show that this is not a binding restriction: with the payoﬀs (1) there exists no
equilibrium with   1 and no profitable individual deviation to   1 from any equilibrium
in which  = 145 These and other results are proved using a more general specification that
also serves to establish Proposition 7:
                                            £                ¤
(B.1)                                2 ≡   + (1 − )− + 

where the intercept  like the slope  is now also state-dependent and ∆ ≡   −   can be
of either sign.

Proof of Proposition 1 i) Let ≡ Ψ(  |− ) denote the right-hand side of (10). Since it is
increasing in   agent ’s optimal awareness strategy is uniquely determined as follows
       (a)  = 1 if Ψ(1 |− ) ≤ 0 By (10), and noting that  + ∆ + (1 − )−  ≥
min {∆  }  0 this means

                                          +  − 
(B.2)                           ≤                            ≡ (− )
                                      + ∆ + (1 − )− 
                                                                       £                  ¤
       (b)  = 0 if Ψ(0 |− ) ≥ 0 By (10), and noting that  +  ∆ + (1 − )−  ≥
min {∆  + (1 − )  }  min {∆ ( + )}  0 this means

                                          +  − 
(B.3)                         ≥          £             −
                                                            ¤ ≡ ̄(− )
                                    +  ∆ + (1 − ) 

Moreover, (− )  ̄(− ) since

(B.4)                ∆ + (1 − )−  ≥ ∆ + (1 − )− min {  0}
                                          ≥ ∆ + min {  0} = min {  ∆}  0

       (c)  ∈ (0 1) is the unique solution to Ψ(  |− ) = 0 for Ψ(0 |− )  0  Ψ(1 |− )
which corresponds to (− )    ̄(− )
       ii) and iii) follow from the monotonicity properties of Ψ with respect to  and  Note
that assumption of symmetry in strategies was imposed (− could, a priori, be the mean of
heterogenous recall rates); therefore, the only equilibria are the symmetric ones described in the
proposition. ¥

  45
     Under the very weak condition that each agent encodes his own information (for future recall) in a cost-
eﬀective manner, which Lemma 3 shows can always be ensured. This is seen most clearly for  =  = 0 which
is informationally equivalent to  =  = 1 but wastes  in each state.


                                                     34
Proof of Proposition 2 By Proposition 1,  = 1 is an equilibrium when Ψ(1 |1) ≤ 0, or

                                   +  −         +  − 
(B.5)                     ≤                         =                ≡ (1)
                                 + ∆ + (1 − )        

and  = 0 is an equilibrium when Ψ(0 |0) ≥ 0 or

                                             +  − 
(B.6)                                  ≥                  ≡ ̄(0)
                                              + ∆

Finally,  ∈ (0 1) is an equilibrium if and only if Ψ( |) = 0 Now, from (10) and (7),
                                                                µ                        ¶
                                                                    ∆ + (1 − )
(B.7)           Ψ( |) = − −  + ( + )  +                                       
                                                                     + (1 − )(1 − )

This function is either increasing or decreasing in  depending on the sign of (1 − ) +
(1 − ) ∆ One can also check, using (B.2)-(B.3), that the same expression governs the sign of
(1) − ̄(0) The equilibrium set is therefore determined as follows:
   a) If (11) does not hold, Ψ( |) is increasing, so Ψ(0 |0)  Ψ(1 |1) or equivalently
(1)  ̄(0) by (B.2)-(B.3). There is then a unique equilibrium, equal to  = 1 if Ψ(1 |1) ≤ 0
interior if Ψ(0 |0)  0  Ψ(1 |1) and equal to  = 0 if 0  Ψ(0 |0)
   b) If (11) does hold, Ψ( |) is decreasing, so Ψ(1 |1)  Ψ(0 |0) or equivalently ̄(0) 
(1) by (B.2)-(B.3), and
   −  = 1 is the unique equilibrium for Ψ(0 |0) ≤ 0 meaning that  ≤ ̄(0) while  = 0 is
the unique equilibrium for Ψ(1 |1) ≥ 0 meaning that  ≥ (1);
   − for Ψ(1 |1)  0  Ψ(0 |0) or ̄(0)    (1) both  = 1 and  = 0 are equilibria,
together with the unique solution to Ψ( |) = 0 which is interior. ¥

Proof of Proposition 3 Following the same steps as in the symmetric case and denoting Λ−
the vector of other agents’ strategies, it is easy to show that
                                                             ¡          ¢
                          −               +  −         
                                                                 − 
(B.8)                 (Λ ) ≡      ³           ´             ³           ´             
                              Σ=1 
                                       −  
                                                + Σ6 = 
                                                               
                                                                  − 
                                                                          +  − 
                                                                                   



                                                          ¡         ¢
                         −             +  −        
                                                             − 
(B.9)           ̄ (Λ ) ≡ h     ³           ´              ³           ´i             
                          Σ=1 
                                    −  
                                             + Σ 6 = 
                                                            
                                                               −  
                                                                         +  − 
                                                                                  


Setting  ≡ 1 in the first equation and  ≡ 0 in the second yields the result. I next prove the
claims for the case with  = 2 that follow the proposition and are illustrated in Figure 3. To make
things simple, let 1 = 1  1 = 2   1 =  2  11   22 11      22      11     11 22   22
                                                     =    =  and  − =  − ≡  
                                                                                      ¡          ¢
0; finally, set  = 0 for all   The asymmetry in roles is then captured by  ≡ 12      12
                                                                                          −  
   ¡            ¢                                   ¡ 12      ¢        ¡ 21       ¢
 21        21                                            12                  21
       −   ≡  and, especially,  ≡ −  −    −  −   ≡  I shall first


                                                     35
provide conditions ensuring

(B.10)                          ̄2 (0)  1 (0)  1 (1)  ̄1 (0)  ̄1 (1)  2 (1)

which implies (17). From (B.8)-(B.9), the middle inequality is equivalent to   (1 − )(1 + )
which can always be ensured given   1 The inequalities 1 (0)  1 (1) and ̄1 (0)  ̄1 (1)
hold for all   0 (complementarity). Turning finally to the two outer conditions, we have
̄2 (0)  1 (0)   if
                              ¡                   ¢
                              12   12   22   22   21   21   11   11
                                 −  +  −    −  +  −  

or    + 1 −  while ̄1 (1)  2 (1) if
               £                             ¤
               21   21   11   11   21   21   12   12   22   22   12   12
                  −  +  −  +  −    −  +  −  +  −  


or    +  −  + 1 − ; both are clearly satisfied for  suﬃciently larger than  and 
suﬃciently larger than  I can now prove the claims (a)-(c) made in the text.
    (a) The result follows from the fact that ̄2 (0) ≤  ≤ 2 (1) and the definitions of these two
thresholds in Proposition 1.
    (b) The same definitions imply that an equilibrium with (1  2 ) = (1 1) (respectively,
(1  2 ) = (0 0)) exists if and only if 2 ≤ 2 (1) and 1 ≤ 1 (1) (respectively, 2 ≥ ̄2 (0)
and 1 ≥ ̄1 (0)), which corresponds to the left (respectively, right) region in Figure 3 In the
middle region one must therefore have 1 = ∗1 (1 ; 2 ) ∈ (0 1), where ∗1 is the mixed-strategy
best-response characterized in Proposition 1. It is decreasing in 1 and increasing (respectively
increasing) in 2 since for 21   21
                              −  = −  0
     (c) Consider now the boundary loci within the middle region. An equilibrium with (1  2 ) =
                                            £               ¤
(∗1 (1 ; 1) 1) exists if and only if 1 ∈ 1 (1) ̄1 (1) and 2 ≤ 2 (∗1 (1 ; 1)) This is a decreasing
function of 1  which declines from 2 (∗1 (1 (1); 1)) = 2 (1) at 1 = 1 (1) to 2 (∗1 (̄1 (0); 1)) at
                  ¯          ¯
1 = ̄1 (0); For ¯21 − 21 ¯  =  small enough, ∗1 (̄1 (0); 2 ) is very insensitive to the value of
                             
2  so 1 (̄ (0); 1) ≈ 1 (̄ (0); 0)) = 0 so 2 (∗1 (̄1 (0); 1)) ≈ 2 (0)  ̄2 (0) Therefore the curve
            ∗ 1              ∗ 1

2 (∗1 (1 ; 1)) cuts the lower boundary of 2 at a point 1  ̄1 (0) as on Figure 3.
                                                                                       £            ¤
     Similarly, with (1  2 ) = (∗1 (1 ; 0) 0) exists if and only if 1 ∈ 1 (0) ̄1 (0) and 2 ≥
̄2 (∗1 (1 ; 0)) This is a decreasing function of 1  which declines to ̄2 (∗1 (̄1 (0); 0)) = ̄2 (0) at
1 = ̄1 (0), from ̄2 (∗1 (1 (1); 0) at 1 = 1 (1); For  small enough, ∗1 (1 (1); 2 ) is very insensitive
to the value of 2  so ∗1 (1 (1); 0) ≈ ∗1 (1 (1); 1) = 1 so ̄2 (∗1 (1 (1); 1)) ≈ ̄2 (1)  2 (0)
Therefore, the curve ̄2 (∗1 (1 ; 0)) cuts the upper boundary of 2 at a point 1  1 (1) as in
Figure 3. Finally, for 21           21
                              −  = 0


(B.11)                  2 (∗1 (1 ; 1)) = 2 (∗1 (1 ; 0))  ̄2 (∗1 (1 ; 0)) = ̄2 (∗1 (1 ; 1))

since agent 1’s behavior is independent of that of agent 2 For  small enough, it remains


                                                              36
the case that 2 (∗1 (1 ; 1))  ̄2 (∗1 (1 ; 1)) by continuity. These properties of the two curves
imply that equilibria of the form (1  2 ) = (∗1 (1 ; 1) 1) (1  2 ) = (∗1 (1 ; 0) 0) and (1  2 ) =
(∗1 (1 ; 2 ) ∗2 (2 ; 1 )) exist only in the three respective regions indicated in Figure 3. The
equilibrium is therefore unique, except possibly in the middle region where both agents mix.
But since it is unique for  =  = 0 by continuity it remains so for  and  small enough. ¥

Proof of Propositions 4 and 5 For   0 it is easily seen that
                                        ½                                         ¾
             +  −                     +  −   +  − 
    ∗ ≡                     max                                                    = max {̄(0) (1)} 
            + (1 − )                    + ∆          

For   0 it is easily seen that ∗  ̄(0) but ∗  (1) requires that

                        +  −  −  (1 − )     +  − 
                                                                                     or
                                 + ∆                   + ∆
                           (1 − ) ∆ [ +  −  ]   (1 − )   

which can go either way. This finishes to establish Proposition 4. The first part of Proposition
5 follows from (20). Turning to the second, the diﬀerence in average welfare between the  = 0
and the  = 1 cases (whether as equilibria or through commitment) is
                     ¡ ∗      ∗
                                  ¢          ¡ ∗      ∗
                                                          ¢
(B.12)                −    + (1 − )  − 
                    = − (1 − ) ∆ + (1 − ) (− −  + ( + ) + ∆) 

since (1) = 1 and (0) = ; hence the result. ¥

Proof of Proposition 8 Assume that at  = 0 everyone else produces  − =  and denote
the proportions of realists as −  Since producing at  = 1 (respectively, not producing) is a
dominant strategy given posterior  = ( ) ≥  (respectively,  = 0) the price in state 
will be  ( + (1 − − )) and the date-0 expected utilities of realism and denial equal to

(B.13)  (  − ;  ) = ( + ) ( + (1 − − ))  
(B.14)  (  − ;  ) = − + ( + ) ( + (1 − − ))( + ) − 
                                          £                                 ¤
                                  +( )  ( + ) −  ( + (1 − − )) (  + )

The net incentive for denial, ∆ ≡  −   is thus given by
                                            £                              ¤
(B.15)      [∆ (  − ; ̄; ) + ] = ( + ) ( + (1 − − )) −  
                                                   £                                 ¤
                                          + ( )  ( + ) −  ( + (1 − − )) ( + )

Setting ( ) = 1 realism is a (personal-equilbrium) best response to − for an agent entering
period 1 with stock  if


                                                       37
                             £                               ¤
(B.16)             ≥       ( + ) ( + (1 − − )) −  
                                 £                               ¤
                             +  ( + ) −  ( + (1 − − )) ( + )

Conversely, denial (( ) = ) is a (personal-equilibrium) best response for  if
                            £                               ¤
(B.17)             ≤      ( + ) ( + (1 − − )) −  
                                £                                ¤
                            +  ( + ) −  ( + (1 − − )) ( + )

For given   and −  these two conditions are mutually exclusive. When neither holds, there
is a unique  ∈ (0 1) that equates ∆ equal to zero, defining a mixed-strategy (personal
equilibrium) best-response. The next step is to solve for (symmetric) social equilibria.

   1. Realism. From (B.16),  = − = 1 is an equilibrium in cognitive strategies if

(B.18)          [( + ) () − ]  +  [ ( + ) −  ()] ( + ) ≤ 

This condition holds for all  ≤  if and only if

                                  + [ −  ()] 
(B.19)             ≤                                           ≡ (1; )
                        [ ( + ) −  ()] ( + ) +  ()

Moving back to the start of period 0 one now verifies that it is indeed an equilibrium for everyone
to produce  =  Since agents will respond to market signals  =   the expected price is
 ( + ) + (1 − ) ()  0 whereas the cost of period-0 production is 0 (more generally,
it suﬃces that it be small enough). Thus, it is optimal to produce to capacity.

   2. Denial equilibrium. From (B.17),  = − = 0 is a cognitive equilibrium if

(B.20)        [( + ) ( + ) − ]  +  [ ( + ) −  ( + )] (  + ) ≥ 

This condition holds for   =  if

                                  + [ −  ( + )] 
(B.21)                                                               ≡ ̄(0;  )
                      [ ( + ) −  ( + )] ( + ) +  ( + )

An agent with low   however, has less incentive to engage in denial. In particular, for  
(1; ) (B.18) for  = 0 precludes (B.20) from holding at   = 0 Let ̄( ) therefore denote
the unique solution in   to the linear equation

(B.22)        [( + ) ( + ) − ]  +  [ ( + ) −  ( + )] (  + ) = 




                                                38
Subtracting from (B.22) the equality obtained by evaluating (B.20) at  = ̄(0;  ) yields

                    [ ( + ) −  ( + )] ( − ̄)
               = ( − ̄) ( + ) + ( − ̄) [ ( + ) −  ( + )] ( + )

where the arguments are dropped from ̄ and ̄ when no confusion results. Thus,
                     µ            ¶µ                                         ¶    ³
                          − ̄         ( + ) + (1 − ) ( + )                ̄ ´
(B.24)     − ̄ =                                                     +        1−      ( + ) 
                                         [ ( + ) −  ( + )]                  

Note that ̄ ≤  (and is thus feasible) if and only if  ≥ ̄ One can now examine the optimal
choice of  at  = 0 which will be either  =  or some   ≤ ̄

    (a) For    ̄( ) (B.22) implies that denial is the unique best response to − = 0 leading
agent  to produce  =  in both states at  = 1 . These units and the initial  will be sold at
the expected price ̄ ( + ) ≡  ( + ) + (1 − ) ( + )  0 Therefore, producing up
to capacity  in period 0 is optimal among all levels   ̄( ) and yields ex-ante utility

(B.25)             (0  ) = ( + )̄ ( + )( + ) −  − (1 − )

    (b) For   ≤ ̄(; ) on the other hand, agent ’s continuation (personal-equilibrium) strategy
is some  = ( ) ≥ 0 : in state  he weakly prefers to be a realist. This leads to
                                                  ¡      ¢
(B.26)     (  0  ) = ( + )̄ ( + )  +  − 
                                           ©¡     ¢                                ª
                                − (1 − ) 1 −   −  [ − ( + ) ( + )]  

The agent prefers  =  (even though it will lead him into denial if state  occurs) to any
 ≤ ̄(; ) if  (0  )   (  0  ) or

(B.27)         ( + )̄ ( + )( −  )  (1 − )  { + [ − ( + ) ( + )] } 

Using (B.24) and  ≤ 1 it suﬃces that
(B.28)
 [1 − ̄(0;  )] ̄ ( + ) ( + ) ≥ (1 − ) { [( + )] + [( + ) −  ( + )] } 

Since ̄ ( + ) tends to  ( + ) as  tends to 1 this condition will hold for  close enough
to 1 provided  − ̄(0;  ) remains bounded away from 0 The following two lemmas formalize
this and related intuitions.

Lemma 1 Under (27), there exists ̃  1 such that, for all  ∈ [̃ 1] ̄(0;  )  (1; )

    Proof: By (B.19)-(B.21) ̄(0;  )  (1; ) means that


                                                        39
(B.29)
             + [ −  ( + )]                          + [ −  ()] 
                                                                                           
 [ ( + ) −  ( + )] ( + ) +  ( + )   [ ( + ) −  ()] ( + ) +  ()

If (B.29) holds for  = 0 the first denominator must be greater than the second, as  ( +) 
 () Therefore, (B.29) holds for all  ≥ 0 if and only if it holds for  = 0 or

           −  ( + )    [ ( + ) −  ( + )] ( + ) +  ( + )
                          
             −  ()                 ( + )( + ) −  ()
        ( + )( + ) −  ( + )              [ ( + ) −  ( + )] ( + )
     =                                    − (1 − )
          ( + )( + ) −  ()                   ( + )( + ) −  ()
                                  [ ( + ) −  ( + )] ( + )
                      ⇐⇒ (1 − )
                                     ( + )( + ) −  ()
                    ( + )( + ) −  ( + )         −  ( + )
                                                      −                  
                      ( + )( + ) −  ()             −  ()

Finally, the condition takes the form
                           µ                              ¶µ                                 ¶
                               ( + ) −  ( + )           () −  ( + )
              1−                                                                               
                                      −  ()                ( + ) −  ( + )

Condition (27) ensures that ( + )   ( + ) hence the result. k

Lemma 2 Assume (27). For any  ∈ (0 12) define  (0; 1 ) ≡ (1 − )̄(0; 1 ) + (1; )
There exists  ∗ ()  1 such that, for all  ∈ ( ∗ () 1] condition (B.28) holds for all  in the
nonempty interval 2 () ≡ (2 (0; 1 )) (1; ))

    Proof: For  close to 1 ̄(0;  ) is close to ̄(0; 1 ) so there exists ̂() ∈ (̃ 1] such that,
for all  ∈ (̂() 1] :

                   ̄(0;  )  (1 − )̄(0; 1 ) + (1; ) ≡  (0; 1 )  (1; )

This implies, for any  ∈ 2 () :
                                                      µ                           ¶     µ               ¶
   − ̄(0;  )   2 (0; 1 ) −  (0; 1 )          (1; ) − ̄(0; 1 )             ̄(0; 1 )
                                                =                                   = 1−
                              (1; )                          (1; )                       (1; )

Therefore, condition (B.28) holds provided that
                µ                ¶µ                                                           ¶
                     ̄(0; 1 )                       ̄ ( + ) ( + )
(B.30) 1 −  ≤  1 −                                                                            
                       (1; )       [ ( + )] + [( + ) + ̄(0; 1 ) −  ( + )] 

which will be the case for all  in some nonempty subinterval ( ∗ () 1] of (̃ 1] k

    The proof of Proposition 8 concludes by showing that for any  ∈ 2 () both ( =   =
1) and ( =   = 0) are equilibria of the two-stage game provided  ∈ ( ∗ () 1]Indeed, for


                                                    40
such parameters we have  ∈ 2 () ⊂ (̄(0;  ) (1; )) and: (i) for   (1; ) it was
shown that when others play ( − =  − = 1) agent  finds it optimal to also be a realist
and to produce  in period 0; (ii) for   ̄(0;  ) it was shown that when others play
( − =  − = 0) agent  prefers to produce  in period 0 with full knowledge that this will
lead him to engage in denial if state , rather than follow any other (   ) strategy. ¥

Proofs for Proposition 7 and the restriction to  = 1 in Proposition 1 A strategy
profile for agent  at  = 0 (his “self 0”) is a pair  = (   ) of probabilities with which
he truthfully encodes ̂  =  in each state   =   A strategy profile for the same agent at
 = 1 (his “self 1”) is a pair   = (     ) of probabilities with which he chooses  = 1 in each
recall state ̂  =   An intrapersonal equilibrium consists of a quadruplet (   ;      )
                            ) in each recall state that together constitute a Perfect Bayesian
and posterior beliefs (    
Equilibrium for agent  (keeping fixed the strategies of all  6= ):
    (i) The posterior beliefs (or “reliability”) of each recall state are given by Bayes’ rule:

                          
                                £                  ¤               
(B.31)                    ≡ Pr   =  | ̂  =  =                              
                                                            
                                                             + (1 − )(1 −  )
                                 £                  ¤        (1 − ) 
(B.32)                    ≡ Pr   =  | ̂  =  =                           
                                                       (1 − )  + (1 −  )

    (ii) Date-1 actions are optimal:   = 1 if [ | ̂  ]   and   = 0 if [ | ̂  ]  0
    (iii) At  = 0 the agent in each state  =   optimally chooses (or randomizes between)
which ̂ =   to encode, taking (i) and (ii) as given.
                                                       −     −
Lemma 3 Let   0 and fix any strategies (    ) (whether equilibrium or not) of players
                                                                                 −     −
 6=  If (   ) is an intrapersonal equilibrium for  such that max{    }  1 then (1 1)
is also an equilibrium and it makes him strictly better oﬀ in both states.

    Proof. I shall omit time-0 subscripts for simplicity. For any ( ̂) ∈ { }2  let ̂
                                                                                           

denote the date-0 expected value of 1 that agent  could achieve in state  by encoding it as ̂
if his behavior at date 1 was guided by “naive” posteriors, i.e.   = 1 when ̂ =  and   = 0
                   ’s do not depend on any actual or conjectured mixing probabilities used
when ̂ =  The ̂
                                      from the same encoding choices as    but anticipating
by the agent at  = 0 Next, define ̂                                  ̂
that beliefs at  = 1 will be derived from (   ) using (B.31)-(B.32). Finally, let  be the
date-0 expected utility achieved in state  by following the mixing strategy (   ) Thus, for
all  ̂ and ̃ 6= 

                                
(B.33)                         ̂ ≡ ̂ ̂
                                            
                                                 + (1 − ̂ )̃
                                                               
                                                                   
                                                                  ¡      ¢
(B.34)                           =   
                                                  + (1 −  ) ̃ 
                                                                       − 

                                                   0
For any alternative candidate strategy (0   ) I use the same notations but with “primes” on


                                                       41
all the variables. I first show that

                                     0       ¡     0     
                                                               ¢¡        
                                                                              ¢
(B.35)                  =    ⇐⇒         1 −   −       −       
                                        0      ¡              ¢ ¡           ¢
(B.36)              = 
                                
                                        ⇐⇒ 1 − 0    
                                                        −        
                                                                     
                                                                     −      

In each case the equality comes from the fact that   1 so that denial is an optimal strategy
in state , and the equivalence between inequalities then follows from (B.33) applied to both
(   ) and (0  0 ) Next, note that for (   ) to be a personal equilibrium the inequalities
in (B.35)-(B.35) must be reversed when (0  0 ) = (   ) meaning that
                          ¡         
                                       ¢    ©                
                                                                   ª
(B.37)                     1 −  −    min  −    −    ≥ 

                     +   ≤ 1 implying  
Suppose first that                                             
                                           −   0 and  −   0 Consider then
                                                                 0
(0  0 ) ≡ (1 1) which by (B.31)-(B.32) leads to (
                                                           0    ) = (1 1) Equations (B.35)-(B.35) are
                                                                 
                                             and   are both replaced by 1 Therefore, systematic
clearly satisfied, and the same is true if       
truthfulness leads to higher expected utility in each state than the original (   ) and it is
also an equilibrium.
                        +    1 From (B.31)-(B.32), we have
    Suppose next that     

                                           
(B.38)                                 +   1 ⇔  +   1
                                       ¡         ¢
Since max{   }  1 this implies    ∈ (0 1)2 : the agent mixes in both states, requiring
  
                                   ¡               ¢
         =   −   =  1 −   −    0 However, by definition of the   ’s,
  −                                                                           ̂

                      ¡        
                                   ¢                           ¡       ¢
(B.39)                    −     = ( + ) ( − ) +   −  
                        ¡      
                                   ¢                           ¡       ¢
(B.40)                    −     = ( +  ) −  +   −  

where  ≡ (1 − ) −
                        +  is the true final payoﬀ that agent  will receive in state  from
the (aggregate) eﬀort decisions  −
                                   of the other players, and exogenously (last term). The two
expressions diﬀer by  (∆)  0 so (   ) cannot be an equilibrium. ¥
    Intuitively, any strategy with distortion or memory censoring in both states represents an
ineﬃcient way of encoding information, wasting   0 with positive probability. It does not
corresponds to a best response to others’ behavior since the agent can, on his own, improve
upon it (under the very weak assumption that he can coordinate his “self 0” and “self 1” on a
Pareto-superior intrapersonal equilibrium, which always exists). I therefore restrict attention,
throughout the paper, to eﬃcient encoding strategies, meaning that  = 1 or  = 1 for every
 This also implies, by (B.31)-(B.32),

                                             
(B.41)                           ≥  ≥ 1 −         and       = 1 ≥   



                                                      42
Finally, as explained in footnote 18, I generally restrict attention to symmetric equilibria (except
in Section 1.4, or when there is a large number ( → +∞) of identical agents, as in Section 3).
These two conditions will be implicit in the use of the word “equilibrium”.

Lemma 4 1) For ∆ ≥ − (1 − ) min{  ∆} there can be no equilibrium with  = 0 and
no profitable individual deviation to   1 from any equilibrium in which  = 1
2) For ∆  − min {(1 − )  (1 − ) ∆ ∗ ()∆)}  where ∗ ()  0 is given by (B.45)
below, there can be no equilibrium with   1 Thus, the results of Propositions 2-5 remain
unchanged, up to the substitution of ∆ + ∆ for ∆ everywhere.

   Proof. Following the same reasoning as in text (or directly from (B.33)-(B.34)) and omitting
time subscripts to lighten the notation, the incentive to misinterpret or misremember  as 
(gross of the cost ) is given by
          ³             ´       ¡                 ¢                ¡           ¢
                                          
(B.42)      −  +   =  1 −     −        (  −   ) +   −   [ −  ]
                                  ©£¡        
                                               ¢          
                                                                ¤      £¡       
                                                                                  ¢        
                                                                                               ¤ ª
                            +       1 −        −       − 1 −           −    
                                          ¡                 ¢ £ − − ¡              ¢ − ¤
                            +  (1 − ) 1 −      
                                                      − 
                                                              {    + 1 − −      
                              £             ¡            ¢ − ¤
                            − −    −               −
                                    + 1 −      }


The incentive to miscode  as  is given by the same expression, with  and  switched:
          ³             ´       ¡                ¢                 ¡          ¢
                                          
(B.43)      −  +   =  1 −      −      (  −   ) +   −   [ −  ]
                                  ©£¡        
                                               ¢           
                                                               ¤      £¡      
                                                                                ¢       
                                                                                              ¤ ª
                            +       1 −        −       − 1 −         −     
                                          ¡                 ¢ £ − − ¡             ¢ − ¤
                            +  (1 − ) 1 −     
                                                     −  
                                                             {    + 1 − −     
                              £             ¡           ¢ − ¤
                            − −    −              −
                                    + 1 −      }


From Lemma 3 and (B.41) we know that  = 1 or  = 1 and that in either case,   = 1 so
in a symmetric equilibrium,  −    
                               =   = 1
                                             = 1 so   = 0 =  − and (B.42) becomes
   1. Equilibria with  = 1 This implies                     
     ³             ´
                        
       −  +   = −  (  −   ) + [ −  ]
                           £        ¡         ¢ ¤                 £    ¡        ¢ ¤
                       −    + 1 −    
                                                  −  
                                                            (1 − )  − 1 − −
                                                                               
                                                                        
                              = −[( + )(  + (1 −  ) ) − ] −  ∆
                                          
                             − ∆[(1 −        
                                            ) +               
                                                    (1 − )] −  (1 − ) −
                                                                              

                                   ≥  so it suﬃces that
The first term is negative since 

                   
                                   
                     ∆ ≥ −∆[(1 −        
                                        ) +               
                                                (1 − )] −  (1 − ) −
                                                                          


                                                 43
                               and holds for   = 0 For   = 1 it takes the form ∆ ≥
This inequality is linear in                             
        £        −
                      ¤
−(1−) ∆ +    which holds whatever the sign of  when ∆ ≥ −(1−) min {∆  } 
Thus, an individual deviation to miscoding  as  is never profitable. As to miscoding  as 
(B.43) becomes
         ³             ´                         £¡       ¢            ¤
                                                             
           −  +   = − [ −  ] +  1 −        +  
                                          £       ¡       ¢ ¤
                                        
                           +  (1 − )    − 1 − −              
                                                           +  (  −   )
                                                        £                        ¤
                                                      
                           = − [ − ( + )  ] +    ∆ + ∆ + (1 − ) −
                                                                               


which is identical to (10) except that ∆ is replaced by ∆ + ∆ Therefore, all the previous
results and formulas shown for ∆ = 0 and imposing  ≡ 1 remain the same, provided
∆ + ∆  replaces ∆ wherever it appears.
   2. Ruling out equilibria with   1 =   If   1 then  = 1 by Lemma 3, so 
                                                                                        = 1

and hence   = 1 =  −
                         Therefore, (B.42) simplifies to:
   ³             ´       ¡       ¢
         
     −  +   = − 1 −   [( + )  − ]
                           © £                    ¤                 ¡       ¢ ª
                         
                     −   ∆   + (1 − )  −                −      −
                                                 + ∆ + (1 − )  1 −     


In (symmetric) equilibrium   =   and  = −
                                                    so this expression is strictly negative and
no equilibrium with   1 exists, when
                                           ¡        ¢
(B.44)                              ∆ + 1 −    (1 − )  + ∆ ≥ 0

For ∆ +∆ ≥ 0 we can rule out any equilibrium with   = 1 and in particular any equilibrium
with  = 0 (which implies 
                              = 1 −  so   = 1) As to an equilibrium with    1 given
                                                                                
 = 1 this requires that  not be below the critical value that makes an agent indiﬀerent to
working or not, given ̂  =  :  + [1 −  (  1)] ∆ ≤  ( + )  or
                         µ        ¶               µ        ¶∙   µ     ¶µ                  ¶¸
                                                              1−     ( + ) − 
(B.45)      (1 − )                ≥ (1 − )              1−                              ≡ ∗ ()
                             ∆                       ∆                 −  ( + )

Therefore, by (B.44), any equilibrium with    1 is ruled out for ∆ ≥ −∆ min {1 ∗ ()}.
   Note finally, that since ∗ () is increasing, if the second inequality in (4) is strengthened to

(B.46)                                      + (1 − )   

then ∗ (0)  0 and such equilibria are ruled out for any  if ∆ min {1 ∗ (0)} + ∆  0 ¥

Proof of Proposition 7 I again show the result for the more general specification (B.1),
under which  ≥ max{1  ∆} is a special case of ∆ ≤ − max{∆  }Note first that since
      ≤  (29) implies that   = 0 and thus, in a equilibrium,  − =   = 0
1 −                                                                    


                                                             44
   1. Ruling out equilibria with   1 =   If   1 then  = 1 = −
                                                                             in equilibrium by
                           = 1 and hence   = 0 =  −  Therefore, (B.43) simplifies to:
Lemma 3 and symmetry, so                           
    ³             ´                                        £¡       ¢            ¤
                      
      −  +   =   ∆ −   [ −  ] +   1 −          
                                                                       +  
                                          £ −      ¡         ¢ ¤
                          
                      +   (1 − )  −                  −
                                           − 1 −   
                                                       ©         £                   ¤ª
                      = −  [ − ( + ) ] + 
                                                        ∆ +   ∆ + (1 − )   
               £                   ¤
Since ∆ +   ∆ + (1 − ) −             
                                 ≤ ∆ +   [∆ + max {0   }]  0 the previous expression
is strictly negative, and no equilibrium with   1 exists.
                                             = 1 and so   = 1 =  − and (B.43) becomes
   2. Equilibria with  = 1 This implies                        
         ³             ´
               
           −              
                    +   = − (  −   ) − [ −  ] +  +  (1 − ) −
                                                                                     
                                                              
                              = −[ − ( + )(   + (1 −    ) )]
                                                                 £                   ¤
                                  
                              +             
                                    ∆ − (1 −  )∆ +  
                                                                  ∆ + (1 − ) −
                                                                                   

                                   ≤ 1 −  so it suﬃces that
The first term is negative since 
                                                   £                      ¤
(B.47)                  
                                  
                          ∆ ≤ (1 −            
                                       )∆ −   ∆ + (1 − ) −
                                                                         

                               and holds for   = 0 For   = 1 it takes the form ∆ ≤
This inequality is linear in                             
 £                 −
                        ¤                     
− ∆ + (1 − )    which holds for all  if ∆ ≤ − [∆ + (1 − )  ]  This expression
is greater than − max{∆  } whatever the sign of   hence the result ruling out any profitable
individual deviation to   1 As to (B.42), it becomes
      ³             ´
                                                                           −
        −  +   = −  (  −   ) + [ −  ] −  −  (1 − )   
                                                      £                   ¤
                        = − [( + ) − ] −   
                                                       ∆ + (1 − ) −
                                                                       


Since −∆ −   0  = 1 is an equilibrium (implying 
                                                          = 1) if and only if


                                        +  − 
(B.48)                            ≤                  ≡ (1)
                                         −∆ − 

Similarly,  = 0 is an equilibrium (implying 
                                                 = 1 − ) if and only if


                                         +  − 
(B.49)                          ≥                       ≡ ̄(0)
                                     (1 − ) (−∆) − 

if −∆    (1 − )  otherwise, let ̄(0) ≡ +∞ Multiple equilibria occur for ̄(0)  (1)
i.e.  (−∆)  (1 − )   The treatment of the mixed-strategy equilibrium is similar to that
in Proposition 2. ¥



                                                45
                                       REFERENCES

Akerlof, G., and W. Dickens (1982) “The Economic Consequences of Cognitive Dissonance,”
American Economic Review, 72, 307–319.
Anand, V., Ashforth, B. and J. Mahendra (2005) “Business as Usual: The Acceptance and
Perpetuation of Corruption in Organizations,” Academy of Management Executive, 19(4), 9-23.
Anderson, J. and C. Duhig (2008) “Death and Near-Death Experiences on Wall Street,” The
New York Times, September 21. Andrews, E. (2007) “Fed and Regulators Shrugged as the
Subprime Crisis Spread”. The New York Times, December 18.
Banerjee, A.(1992) “A Simple Model of Herd Behavior,” Quarterly Journal of Economics, 107(3),
797-817.
Battaglini, M., Bénabou, R., and J. Tirole (2005) “Self-Control in Peer Groups,” Journal of
Economic Theory, 123, 105—134.
Bénabou, R. (2008) “Ideology,”Journal of the European Economic Association, 6(2-3), 321—352.
Bénabou, R. and J. Tirole (2002) “Self—Confidence and Personal Motivation,” Quarterly Journal
of Economics, 117 , 871—915.
Bénabou, R. and J. Tirole (2004) “Willpower and Personal Rules,” Journal of Political Econ-
omy, 112, 848—887.
Bénabou, R. and J. Tirole (2006a) “Incentives and Prosocial Behavior,” American Economic
Review, 96(5), December , 1652-1678.
Bénabou, R. and J. Tirole (2006b) “Belief in a Just World and Redistributive Politics,” Quar-
terly Journal of Economics, 121(2), May, 699-746.
Bénabou, R. and J. Tirole (2007) “Identity, Dignity and Taboos: Beliefs as Assets,” CEPR
Discussion Paper no. 6123, February.
Bernheim, D. and R. Thomadsen (2005) “Memory and Anticipation,” The Economic Journal,
115, 271—304.
Bikhchandani, S. Hirshleifer, D., and I. Welch (1992) “A Theory of Fads, Fashion, Custom, and
Cultural Change as Informational Cascades,” Journal of Political Economy, 100(5), 992-1026.
Brunnermeier, M. and J. Parker (2005) “Optimal Expectations,” American Economic Review,
90, 1092-1118.
Bryce, R. (2002) Pipe Dreams: Greed, Ego, and the Death of Enron. New York, NY: PublicAf-
fairs.
Camerer, C. and U. Malmendier (2007) “Behavioral Economics of Organizations,” in Behavioral
Economics and Its Applications, P. Diamond and H. Vartiainen (eds.), Princeton University
Press.
Caplin, A. and J. Leahy (1994) “Business as Usual, Market Crashes, and Wisdom After the
Fact,” American Economic Review, 84(3), 548-565.
Caplin, A. and J. Leahy (2001) “Psychological Expected Utility Theory and Anticipatory Feel-
ings,” Quarterly Journal of Economics, 116, 55—79.

                                             46
Carrillo, J. and Thomas Mariotti (2000), “Strategic Ignorance as a Self-Disciplining Device,”
Review of Economic Studies, 66 , 529—544.
Chamley, C. and D. Gale (1994) “Information Revelation and Strategic Delay in a Model of
Investment," Econometrica, 62(5), 1065-85.
Cialdini, R. (1984) Influence: The Psychology of Persuasion.    New York, NY: HarperCollins
Publishers.
Cohan, J. (2002) “ ‘I Didn’t Know’ and ‘I Was Only Doing My Job’: Has Corporate Governance
Careened Out of Control? A Case Study of Enron’s Information Myopia”. Journal of Business
Ethics, 40, 275-299.
Columbia Accident Investigation Board (2003) CIAB Final Report, especially Chapters 6, 7 and
8. Available at http://caib.nasa.gov/.
Dessi, R. (2005) “Collective Memory, Identity, and Cultural Investments,” IDEI mimeo.
Di Tella, R., Galiani, S., and E. Schargrodsky, (2007) “The Formation of Beliefs: Evidence from
the Allocation of Land Titles to Squatters,” Quarterly Journal of Economics, 122(1), 209-241.
Duhig, C. (2008) “Pressured to Take More Risks, Fannie Mae Reached Tipping Point,” The
New York Times, October 5.
Eichennwald, K. (2005) Conspiracy of Fools: A True Story. New York, NY: BroadwayBooks.
Fang, H., and Moscarini, G. (2005) “Morale Hazard,” Journal of Monetary Economics, 52(4),
749-778.
Gabaix, X., Krishnamurthy, A. and O. Vigneron (2007) “Limits of Arbitrage: Theory and
Evidence from the Mortgage-Backed Securities Market”, Journal of Finance, 62(2), 557-595,
Gervais, S. and Goldtsein, I. (2007) “The Positive Eﬀects of Self-Biased Perceptions in Teams,”
Review of Finance, 11(3), 453-496.
Goodman, P. (2008) “The Reckoning: Taking Hard New Look at a Greenspan Legacy,” The
New York Times, October 8.
Greenspan, A. (2002). Testimony to the United States House Financial Services Committee,
July 17.
Hansell, S. (2008) “How Wall Street Lied to Its Computers,” The New York Times, September
18.
Haslam, A. (2004). Psychology in Organizations: The Social Identity Approach (2nd ed.). Lon-
don, UK & Thousand Oaks, CA: Sage.
Hermalin, B. (1998) “An Economic Theory of Leadership: Leading by Example,” The American
Economic Review, 88(5), 1188-1206.
Hersh, S. (2004) Chain of Command. New York, NY: HarperCollins Publishers.
Huseman, R. and R. Driver (1979) “Groupthink: Implications for Small Group Decision Making
in Business,” in Readings in Organizational Behavior: Dimensions of Management Action, R.
Richard Huseman and Archie Carral, eds.. Boston, MA: Allyn and Bacon.
Isikoﬀ, M. and D. Corn (2007) Hubris. New York, NY: Three Rivers Press.



                                              47
Janis, I. (1972) Victims of Groupthink: Psychological Studies of Policy Decisions and Fiascoes.
Boston, MA: Houghton Miﬄin Company.
Jost, J., and Major, B. (Eds.) (2001). The Psychology of Legitimacy: Emerging Perspectives on
Ideology, Justice, and Intergroup Relations. New York: Cambridge University Press.
Kahan, D. and D. Braman (2002) “Cultural Cognition and Public Policy,” Yale Law and Policy
Review, 24, 147-170.
Karlsson, N., Loewenstein, G. and D. Seppi (2005) “The ‘Ostrich Eﬀect’: Selective Attention to
Information about Investments,” Carnegie Mellon University mimeo, May.
Köszegi, B. (2006) “Emotional Agency,” Quarterly Journal of Economics, 21(1), 121-156.
Kreps, D. and Porteus, E. (1978), “Temporal Resolution of Uncertainty and Dynamic Choice
Theory,” Econometrica, 46(1), 185—200.
Kuran, T. (1993) “The Unthinkable and the Unthought,” Rationality and Society, 5, 473-505.
Labaton, S. (2008) “Agency Rule Let Banks Pile Up Debt,” The New York Times, October 3.
Landier, A., “Wishful Thinking: A Model of Optimal Reality Denial,” Massachusetts Institute
of Technology mimeo, 2000.
Landier, A., Sraer, D. and D. Thesmar (2009) “Optimal Dissent in Organizations,” Review of
Economic Studies, forthcoming.
Leung, K., Bond, M., de Carrasquel, S., Muñoz, C., Hernández, M., Murakami, F., Yamaguchi,
S., Bierbrauer, G. and T. Singelis (2002) “Social Axioms: The Search for Universal Dimensions
of General Beliefs about How the World Functions,” Journal of Cross-Cultural Psychology, 33(3),
286-302.
Malmendier, U. and G. Tate (2005) “CEO Overconfidence and Corporate Investment,” Journal
of Finance, 60 (6), 2661-2700.
Malmendier, U. and G. Tate (2008) “Who Makes Acquisitions? CEO Overconfidence and the
Market’s Reaction,” Journal of Financial Economics, forthcoming.
Morgenson, G. (2008) “Behind Insurer’s Crisis, Blind Eye to a Web of Risk,” The New York
Times, September 28.
Morgenson, G. and G. Fabrikant (2007) “Countrywide’s Chief Salesman and Defender,” The
New York Times, November 2007.
Norris, F. (2008) “Color-Blind Merrill in a Sea of Red Flags.” The New York Times, May 16.
North, D. (1990) Institutions, Institutional Change and Economic Performance. Cambridge,
UK: Cambridge University Press.
Pearlstein, S. (2006) “Years of Self-Deception Killed Enron and Lay,” The Washington Post,
July 8th.
Prendergast, C. (1993) “A Theory of ‘Yes Men’,” American Economic Review, 83(4), 757-770.
Reilly, D. (2007) “Marking Down Wall Street.” The Wall Street Journal, September 14, C1.
Rogers Commission (1986). Report of the Presidential Commission on the Space Shuttle Chal-
lenger Accident. http://history.nasa.gov/rogersrep/genindex.htm.



                                              48
Rostek, M. and M. Weretka (2008) “Dynamic Thin Markets,” University of Madison-Wisconsin
mimeo, December.
Rotemberg, J. and G. Saloner (2000) “Visionaries, Managers, and Strategic Direction,” Rand
Journal of Economics 31, Winter, 693-716.
Samuelson, R. (2001) “Enron’s Creative Obscurity.” The Washington Post, December 19.
Scheinkman, J. and W. Xiong (2003) “Overconfidence and Speculative Bubbles,” Journal of
Political Economy 111, 1183-1219.
Schelling, T. (1986) The Mind as a Consuming Organ,” in D. Bell, Raiﬀa H. and A. Tversky,
eds., Decision Making : Descriptive, Normative, and Prescriptive Interactions. Cambridge, MA:
Cambridge University Press.
Schrand, C. and S. Zechman (2008) “Executive Overconfidence and the Slippery Slope to Fraud,”
Wharton School mimeo, University of Pennsylvania, December.
Securities and Exchange Commission (2008) SEC’s Oversight of Bears Stearns and Related
Entities: Consolidated Supervised Entity Program. Inspector General’s Report, Oﬃce of Audits,
September 25, viii-ix. Available at http://www.sec-oig.gov.
Shiller, R. (2003) “From Eﬃcient Markets Theory to Behavioral Finance,” Journal of Economic
Perspectives, 17(1), 83-104
Shiller, R. (2005) Irrational Exuberance. Second Edition, Princeton, NJ: Princeton University
Press.
Sims, R. (1992) “Linking Groupthink to Unethical Behaviors in Organizations,” Journal of
Business Ethics, 11, 651-662.
Slovic, P. (2007) “If I Look at the Mass I will Never Act: Psychic Numbing and Genocide,”
Judgment and Decision-Making, 2(2), 79-95.
Small, D., Loewenstein, G. and Slovic, P. (2007) “Sympathy and Callousness: The Impact
of Deliberative Thought on Donations to Identifiable and Statistical Victims,” Organizational
Behavior and Human Decision Processes, 143—153.
Sorkin, A. (2008) “What Goes on Before a Fall? On Wall Street, Reassurance,” The New York
Times, September 30.
Suskind, R. (2004) “Without a Doubt,” The New York Times, October 17.
Tenbrunsel, A. and D. Messick (2004) “Ethical Fading: The Role of Self-Deception in Unethical
Behavior,” Social Justice Research, 17(2), 223-662.
Van den Steen, E. (2005) “On the Origins of Shared Beliefs (and Corporate Culture),” MIT
Sloan School Working Paper, August.
Zald, M. and M. Berger (1978) “Social Movements in Organizations: Coup d’Etat, Insurgency,
and Mass Movements,” The American Journal of Sociology, 83(4), 823-861.




                                              49
