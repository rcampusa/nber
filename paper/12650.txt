                                NBER WORKING PAPER SERIES




                       LONG TERM RISK: AN OPERATOR APPROACH

                                          Lars Peter Hansen
                                          Jose Scheinkman

                                        Working Paper 12650
                                http://www.nber.org/papers/w12650


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                     October 2006




Comments from Rene Carmona, Vasco Carvalho, Junghoon Lee, Angelo Melino, Chris Rogers, Mike
Stutzer, Grace Tsiang and Yong Wang were very helpful in preparing this paper. This material is based
upon work supported by the National Science Foundation under Award Numbers SES0519372 and
SES0350770. The views expressed herein are those of the author(s) and do not necessarily reflect
the views of the National Bureau of Economic Research.

© 2006 by Lars Peter Hansen and Jose Scheinkman. All rights reserved. Short sections of text, not
to exceed two paragraphs, may be quoted without explicit permission provided that full credit, including
© notice, is given to the source.
Long Term Risk: An Operator Approach
Lars Peter Hansen and Jose Scheinkman
NBER Working Paper No. 12650
October 2006
JEL No. G12

                                              ABSTRACT

We create an analytical structure that reveals the long run risk-return relationship for nonlinear continuous
time Markov environments. We do so by studying an eigenvalue problem associated with a positive
eigenfunction for a conveniently chosen family of valuation operators. This family forms a semigroup
whose members are indexed by the elapsed time between payoff and valuation dates. We represent
the semigroup using a positive process with three components: an exponential term constructed from
the eigenvalue, a martingale and a transient eigenfunction term. The eigenvalue encodes the risk adjustment,
the martingale alters the probability measure to capture long run approximation, and the eigenfunction
gives the long run dependence on the Markov state. We establish existence and uniqueness of the relevant
eigenvalue and eigenfunction. By showing how changes in the stochastic growth components of cash
flows induce changes in the corresponding eigenvalues and eigenfunctions, we reveal a long-run risk
return tradeoff.

Lars Peter Hansen
Department of Economics
The University of Chicago
1126 East 59th Street
Chicago, IL 60637
and NBER
l-hansen@uchicago.edu

Jose Scheinkman
Department of Economics
Princeton University
Princeton, NJ 08544-1021
and NBER
joses@princeton.edu
1     Introduction
In financial economics risk-return tradeoffs show how expected rates of return over small
intervals are altered as we change the exposure to the underlying shocks that impinge
on the economy. In continuous time modeling, the length of interval is driven to zero
to deduce a limiting local relationship. We study alternative notions of a risk-return
relationship that feature the pricing of exposure to stochastic growth risk of cash flows.
In contrast to the local analysis, we focus on what happens as the length of time between
valuation and payoff becomes large.
    The continuous time local analysis is facilitated by the use of stochastic differential
equations driven by a vector Brownian motion and jumps. An equilibrium valuation
model gives the prices of the instantaneous exposure of payoffs to these risks. Values
over alternative horizons can be inferred by integrating appropriately these local prices.
Such computations are nontrivial when there are nonlinearities in the evolution of state
variables or valuations. This leads us to adopt an alternative approach based on an
operator formulation of asset pricing. As in previous research, we model asset valuation
using operators that assign prices today to payoffs in future dates. Since these operators
are defined for each payoff date, we build an indexed family of such pricing operators.
This family is referred to as a semigroup because of the manner in which the operators are
related to one another.1 We show how to modify valuation operators in a straightforward
way to accommodate stochastic cash flow growth. It is the evolution of such operators as
the payoff date changes that interests us. Long run counterparts to risk-return tradeoffs
are reflected in how the limiting behavior of the family of operators changes as we alter
the stochastic growth of the cash flows.
    We study the evolution of the family of valuation operators in a continuous-time
framework, although important aspects of our analysis are directly applicable to discrete-
time specifications. Our analysis is made tractable by assuming the existence of a Markov
state that summarizes the information in the economy pertinent for valuation. The
operators we use apply to functions of this Markov state and can be represented as:

                                Mt ψ(x) = E [Mt ψ(Xt )|X0 = x]

for some process M appropriately restricted to ensure intertemporal consistency and to
   1
     See Garman (1984) for an initial contribution featuring the use of semigroups in modeling asset
prices.


                                                 1
guarantee that the Markov structure applies to pricing. The principal restriction we
impose is that M has a “multiplicative” property, resulting in a family of operators
indexed by t that is a semigroup.
   A central mathematical result that we establish and exploit is a multiplicative de-
composition:
                                                φ(X0 )
                                Mt = exp(ρt)M̂t                                    (1)
                                                φ(Xt )
where M̂ is a martingale and its logarithm has stationary increments.2 While such a
representation is typically not unique, there is one such decomposition that is of value
in our study of long term approximation. In this decomposition, ρ is a deterministic
growth rate, and the ratio of positive random variables φ(x     0)
                                                             φ(xt )
                                                                    is a transitory contribution.
In our analysis, we use the martingale {M̂t } to change the probability measure prior to
our study of approximation. The principal eigenfunction φ gives the dominant transient
component of the operator family in the long run.
    We use the multiplicative decomposition (1) to study two alternative long-run coun-
terparts to risk-return tradeoffs. It allows us to isolate enduring components to cash-flows
or prices and to explore the how these components are valued. For instance, cash flows
with different stochastic growth components are valued differently. One long-run notion
of a risk-return tradeoff characterizes how the asymptotic rate of return required as com-
pensation depends on the cash flow risk exposure. A second approach cumulate returns
that are valued in accordance to a local risk return tradeoff. A corresponding long-run
tradeoff gives the asymptotic growth rates of alternative cumulative returns over long
time horizons as a function of the risk exposures used to construct the local returns.
    Previous papers have explored particular characterizations of the term structure of
risk pricing of cash flows. (For instance, see Hansen et al. (2005) and Lettau and Wachter
(2005).) In this regard local pricing characterizes one end of this term structure and our
analysis the other end. Hansen et al. (2005) characterize the long-run cash flow risk
prices for discrete time log-normal environments. Their characterization shares our goal
of pricing the exposure to stochastic growth risk, but they exclude potential nonlinearity
and temporal variation in volatility, in order to obtain analytical results. Hansen et al.
(2005) examines the extent to which the long-run cash-flow risk prices from a family
   2
    Alvarez and Jermann (2005) proposed the use of such a decomposition to analyze the long run
behavior of stochastic discount factors and cited an early version of our paper for proposing the link
between this decomposition and principal eigenvalues and functions. We develop this connection formally
and establish existence and uniqueness results for a general class of multiplicative functionals.


                                                  2
of recursive utility models can account for the value heterogeneity observed in equity
portfolios with alternative ratios of book value to market value. Our paper shows how to
produce such pricing characterizations for more general nonlinear Markov environments.
    The positive function φ and the scalar ρ are the principal eigenfunction and eigenvalue
respectively of the semigroup. Specifically,

                                 Mt φ(x) = exp(ρt)φ(x).                                (2)

so that φ is an eigenfunction of all of the operators Mt of the semigroup. There is a
corresponding equation that holds locally, obtained essentially by differentiating with
respect to t and evaluating the derivative at t = 0. More generally, this time derivative
gives rise to the generator of the semigroup. By working with the generator, we exploit
some of the well known local characterizations of continuous time Markov models from
stochastic calculus to provide a solution to (2). While continuous-time models achieve
simplicity by characterizing behavior over small time increments, operator methods have
promise for enhancing our understanding of the connection between short run and long
run behavior.
    The remainder of the paper is organized as follows. In sections 2 and 3 we develop
some of the mathematical preliminaries pertinent for our analysis. Specifically, in section
2 we give the underlying generation of the Markov process and introduce the reader
to the concepts of additive and multiplicative functionals. Both functionals are crucial
ingredients to what follows. In section 3 we introduce the reader to the notion of a
semigroup. Semigroups are used to evaluate contingent claims written on the Markov
state indexed by the elapsed time between trading date and the payoff date. In sections
4, 5 and 6 we consider three alternative multiplicative functionals that are pertinent in
intertemporal asset pricing. In section 4 we use a multiplicative functional to model a
stochastic discount factor process and the corresponding pricing semigroup. In section 5
we introduce valuation functionals that are used to represent returns over intervals of any
horizon. In section 6 we introduce growth functionals to model nonstationary cash flows.
Section 7 gives alternative notions of the generator of semigroup and discusses their
relation. In section 8 we introduce principal eigenvalues and functions and use these
objects to establish a representation of the form (1). In section 9 we establish formally
the long run domination of the principal eigenfunction and eigenvalue and establish
uniqueness of such objects for the purposes of approximation. In section 10 we discuss


                                            3
sufficient conditions for the existence of principal eigenvalues needed to support our
analysis. Applications to financial economics are given in section 11.


2     Markov and related processes
We first describe the underlying Markov process and then we build other convenient
processes from this underlying Markov process.


2.1    Baseline process
Let {Xt : t ≥ 0} be a continuous time, strong Markov process defined on a probability
space {Ω, F, P r} with values on a state space D0 that is locally compact and separable.
The sample paths of X are continuous from the right and with left limits, and we will
sometimes also assume that this process is stationary and ergodic. Let Ft be completion
of the sigma algebra generated by {Xu : 0 ≤ u ≤ t}.
    Throughout we restrict the Markov process X to be a semimartingale. As a conse-
quence, we can extract a continuous component X c and what remains is a pure jump
process X j . To characterize the evolution of the jump component:
                                                  Z
                                       dXtj   =           zζ(z, dt)
                                                  Rn


where ζ = ζ(ω, ·; ·) is a random counting measure. That is, for each ω, ζ(b, [0, t]; ω) gives
the total number of jumps in [0, t] of a size in b, in the realization ω. In general, the
associated Markov stochastic process X may have an infinite number of small jumps in
any time interval. In what follows we will assume that this process has a finite number
of jumps over a finite time interval. This rules out most Levy processes, but greatly
simplifies the notation. In this case, there is a finite measure η(dy|x)dt that is the
compensator of the random measure ζ. It is the (unique) predictable random measure,
such that for each predictable stochastic function f (x, t; ω), the process
             Z tZ                                     Z tZ
                        f (y, s; ω)ζ(dy, ds; ω) −                  f (y, s; ω)η[dy|Xs− (ω)]ds
               0   Rn                                     0   Rn


is a martingale. The measure η encodes both a jump intensity and a distribution given
that a jump occurs. The jump intensity is the implied conditional measure of the entire


                                                      4
state space D0 , and the jump distribution is the conditional measure divided by the jump
intensity.
    We presume that the continuous sample path component satisfies the stochastic evo-
lution:
                              dXtc = ξ(Xt− )dt + Γ(Xt− )dBt

where B is a multivariate Ft -Brownian motion and Γ(x)Γ(x)0 is nonsingular. Given the
rank condition, the Brownian increment can be deduced from the sample path of the
state vector via:

                      dBt = [Γ(Xt− )0 Γ(Xt− )]−1 Γ(Xt− )0 [dXtc − ξ(Xt− )dt].

Example 2.1. Finite State Markov Chain Consider a finite state Markov chain with
states xj for j = 1, 2, ..., N . The local evolution of this chain is governed by an N × N
intensity matrix U. An intensity matrix encodes all of the transition probabilities. The
matrix exp(tU) is the matrix of transition probabilities over an interval t. Since each
row of a transition matrix sums to unity, each row of U sums to zero. The diagonal
entries are negative and represent minus the intensity of jumping from the current state
to a new one. The remaining row entries, appropriately scaled, represent the conditional
probabilities of jumping to the respective states.

Example 2.2. Markov Diffusion
   In what follows we will often use the following example. Suppose the Markov process
X has two components, X f and X o , where X f is a Feller square root process and is
positive and X o is an Ornstein-Uhlenbeck process and ranges over the real line:
                                                           q
                             dXtf    =   ξf (x̄f − Xtf ) + Xtf σf dBtf ,
                             dXto    =   ξo (x̄o − Xto ) + σo dBto
                                                                      #  "
                                                                    f
                                                                  B
with ξi > 0, x̄i > 0 for i = f, o and 2ξf x̄f ≥ σf2 where B =           is a bivariate stan-
                                                                  Bo
dard Brownian motion. The parameter restrictions guarantee that there is a stationary
distribution associated with X f with support contained in R+ . 3
   3
     We could accommodate the case where B f or B o contain more than one entry, by considering a
filtration {Ft } larger than the one generated by X. In effect, we would enlarge the state space in ways
that were inconsequential to the computations that interest us. However, for simplicity we have assumed
throughout this paper that {Ft } is the filtration generated by X.


                                                   5
    Given an underlying Markov process X, we now explore ways of studying valuation
and stochastic growth. This requires that we construct processes for stochastic discount
factors and cash flow growth from the underlying Markov process. We do this by using
building block processes that are additive and multiplicative functionals. In what follows
we define formally a functional, an additive functional and a multiplicative functional and
discuss their properties.


2.2     Additive functionals
A functional is a stochastic process constructed from the original Markov process:
Definition 2.1. A real-valued process {At : t ≥ 0} is a functional if it is adapted (At
is Ft measurable for all t) and is right continuous conditioned on X0 = x for almost
everywhere for each x in D0 .
   Let θ denote the shift operator. Using this notation, we define Au (θt ) to be the
corresponding function of the X process shifted forward t time periods. Since Au is
constructed from the Markov process X between dates zero and u, Au (θt ) depends only
on the process between dates t and date t + u.
Definition 2.2. A functional A is additive if A0 = 0 and At+u = Au (θt ) + At , for each
nonnegative t and u.4
   While the joint process {(Xt , At ) : t ≥ 0} is Markov, by construction the additive
functional does not Granger cause the original Markov process. Instead it is constructed
from that process. No additional information about the future values of X are revealed by
current and past value of A. When X is restricted to be stationary, an additive functional
can be nonstationary but it has stationary increments. The following are examples of
additive functionals:
Example 2.3. Given any continuous function ψ, At = ψ(Xt ) − ψ(X0 ).
Example 2.4. Let β be a Borel measurable function on D0 and construct:
                                               Z   t
                                        At =           β(Xu )du
                                               0

        Rt
where    0
             β(Xu )du < ∞ with probability one for each t.
  4
    Notice that we do not restrict additive functionals to have bounded variation as, e.g. Revuz and
Yor (1994).

                                                   6
Example 2.5. Form:                                             Z       t
                                                        At =               γ(Xu )0 dBu
                                                                0
         Rt
where     0
              |γ(Xu )|2 du is finite with probability one for each t.

Example 2.6. Form:
                                                               X
                                                       At =                κ(Xu , Xu− )
                                                              0≤u≤t

where κ : D0 × D0 → R, κ(x, x) = 0.5

    Sums of additive functionals are additive functionals. We may thus use examples
2.4, 2.5 and 2.6 as building blocks in a parameterization of additive functionals. This
parameterization uses a triple (β, γ, κ) that satisfies:
                               Rt
a) β : D0 → R and               0
                                    β(Xu )du < ∞ for every positive t;
                                Rt
b) γ : D0 → Rm and                  0
                                        |γ(Xu )|2 du < ∞ for every positive t;
                                                                                R
c) κ : D0 ×D0 → R, κ(x, x) = 0 for all x ∈ D0 ,                                     exp(κ(y, x))η(dy|x) < ∞ for all x ∈ D0 .

      Form:
                  Z    t                   Z     t                             X
       At =                β(Xu )du +                γ(Xu− )0 dBu +                    κ(Xu , Xu− ),
                   0                         0                                 0≤u≤t
                  Z    t                   Z     t
              =      β(Xu )du +    γ(Xu− )0 [Γ(Xu− )0 Γ(Xu− )]−1 Γ(Xu− )0 [dXuc − ξ(Xu− )du]
                   0 X           0
                  +     κ(Xu , Xu− ).
                       0≤u≤t


This additive functional is a semi-martingale.
    While we will use extensively these parameterizations of an additive functional, they
are not exhaustive as the following example illustrates.

Example 2.7. Suppose that {Xt : t ≥ 0} is a standard scalar Brownian motion, b a
Borelian in R, and define the occupation time of b up to time t as
                                                               Z       t
                                                           .
                                                        At =               1{Xu ∈b} du.
                                                                   0
  5
      Since the process has left limits, Xu− = limt↑u Xt is well defined.


                                                                           7
At is an additive functional. As a consequence, the local time at a point r defined as
                                            Z   t
                                .      1
                             Lt = lim               1{Xu ∈(r−,r+)} du,
                                   ↓0 2   0


is also an additive functional.

    Multiplicative functionals can be built from additive functionals.

Definition 2.3. The functional M is multiplicative if M0 = 1, and Mt+u = Mu (θt )Mt .

Products of multiplicative functionals are multiplicative functionals. Exponentials of
additive functionals are strictly positive multiplicative functionals. Conversely, the loga-
rithm of strictly positive multiplicative functional is an additive functional.


3     Multiplicative functionals and semigroups
Given a multiplicative functional M , our aim is to establish properties of the family of
operators:
                            Mt ψ(x) = E [Mt ψ(Xt )|x0 = x] .                          (3)


3.1    Semigroups
Let L be a Banach space with norm k · k, and let {Tt : t ≥ 0} be a family of operators
on L. The operators in these family are linked according to the following property:

Definition 3.1. A family of linear operators {Tt : t ≥ 0} is a one-parameter semigroup
if T0 = I and Tt+s = Tt Ts for all s, t ≥ 0.

One possibility is that these operators are conditional expectations operators, in which
case this link typically follows from the Law of Iterated Expectations restricted to Markov
processes. We will also use such families of operators to study valuation and pricing.
From a pricing perspective, the semigroup property follows from the Markov version of
the Law of Iterated Values, which holds when there is frictionless trading at intermediate
dates.
   We will often impose further restrictions on semigroups such as:

Definition 3.2. The semigroup {Tt : t ≥ 0} is positive if for any t ≥ 0, Tt ψ ≥ 0
whenever ψ ≥ 0.

                                                    8
3.2    Multiplicative semigroup
Let (L, k · k) denote the Banach space of bounded functions of a Markov state under the
sup norm. Among other things, the following assumption guarantees that (3) defines a
bounded operator on L for every t.

Assumption 3.1. The multiplicative functional M has finite first moments for each t.

Proposition 3.1. Suppose the multiplicative functional M satisfies Assumption 3.1.
Then
                        Mt ψ(x) = E [Mt ψ(Xt )|X0 = x] .

is a semigroup on the space of bounded measurable functions.

Proof. Suppose that ψ is a bounded measurable function. Then

                Mt+u ψ(x) =     E (E [Mt+u ψ(Xt+u )|Ft ] |X0 = x)
                          =     E [E (Mt Mu (θt )ψ[Xu (θt )]|Ft ) |X0 = x]
                          =     E [Mt E [Mu (θt )ψ[Xu (θt )]|X0 (θt )] |X0 = x]
                          =     E [Mt Mu ψ(xt )|X0 = x]
                          =     Mt Mu ψ(x),

which establishes the semigroup property.

In what follows we will refer to semigroups constructed from multiplicative functionals
as in this proposition as multiplicative semigroups.
    Since the logarithm of a strictly positive multiplicative process is an additive process
we will consider parameterized versions of strictly positive multiplicative processes by
parameterizing the corresponding additive process. For instance, if M = exp(A) when
A is parameterized by (β, γ, κ) satisfying the parameterization in section 2, we will say
that the multiplicative process M is parameterized by (β, γ, κ). Notice that Ito’s lemma
guarantees that:

                         |γ(Xt− )|2
                                   
         dMt
             = β(Xt− ) +              dt + γ(Xt− )0 dBt + exp [κ(Xt , Xt− )] − 1.
         Mt−                 2

The multiplicative process {Mt : t ≥ 0} of this form is a local martingale if, and only if,

                          |γ|2
                                   Z
                       β+      +       (exp [κ(y, ·)] − 1) η(dy|·) = 0.                 (4)
                           2

                                              9
   We next consider a variety of ways in which multiplicative functionals and their
semigroups can be used when building models of asset prices and characterizing the
resulting implications.


4       Pricing semigroup
For a fixed time interval t and any ψ in L, consider a state-contingent payoff ψ(Xt ). A
pricing operator St applied to ψ gives the time zero price of this state-contingent payoff.
This price is a function of the date zero state. We construct such an operator for every
horizon t, giving us a family of operators that are naturally restricted to be a semigroup.
    Formally, we build the pricing semigroup using a stochastic discount factor process
{St : t ≥ 0} via:
                               St ψ(x) = E [St ψ(Xt )|x0 = x] .                         (5)

The stochastic discount factor process is restricted to be a strictly positive multiplicative
functional satisfying Assumption 3.1. With intermediate trading dates, the time t +
s payoff ψ(Xt+s ) can be purchased at date zero or alternatively the claim could be
purchased at date t at the price Ss ψ(Xt ) and in turn this time t claim can be purchased
at time zero. The semigroup property captures the notion that the date zero prices of
ψ(Xt+s ) and Ss ψ(Xt ) must coincide. Thus the semigroup property is an iterated value
property that connects pricing over different time intervals. It is a version of the Law of
One Price as it applies over time in a Markov version of a frictionless market model with
intermediate trading dates.6
    Although we use the stochastic discount factor to price claims that are functions of
the Markov state at a future date, once we choose a stochastic discount factor we can
also price claims which are functions of the whole history up to a certain date.

Example 4.1. Breeden model
   Using the Markov process given in example 2.2, we consider a special case of Breeden
(1979)’s consumption-based asset pricing model. Suppose that equilibrium consumption
evolves according to:                  q
                              dct = Xto dt +     Xtf ϑf dBtf + ϑo dBto .                          (6)
    6
   This semigroup property is related to the “consistency axiom” in Rogers (1998). In fact, adding the
Markov property to the “axiomatic approach” of Rogers (1998) yields equation (5) with a multiplicative
S.


                                                 10
where ct is the logarithm of consumption Ct . Suppose also that investor’s preferences are
given by:                         Z ∞
                                                Ct 1−a − 1
                                E     exp(−bt)
                                   0              1−a
for a and b strictly positive. The implied stochastic discount factor is St = exp(Ast ) where
                             Z     t                     Z tq              Z t
                                                              f
                Ast   = −a             Xso ds   − bt − a             f
                                                             Xs ϑf dBs − a     ϑo dBso .
                               0                          0                          0


Example 4.2. Kreps-Porteus model
    As an alternative specification of preferences, suppose consumers have preferences that
satisfy the recursion:

                            E (Wt+ − Wt |Ft )
                      lim                      = Wt [b(a − 1)ct + b log Wt ]
                      ↓0           

where −Wt is the continuation value for the consumption plan, a > 1 and b > 0. These
preferences can be viewed as a continuous time version of the preferences suggested by
Kreps and Porteus (1978) and is a special case of the stochastic differential utility model
of Duffie and Epstein (1992) and Schroder and Skiadas (1999). For these preferences
the intertemporal composition of risk matters. Bansal and Yaron (2004) have used this
feature of preferences in conjunction with predictable components in consumption and
consumption volatility as a device to amplify risk premia. The particular utility recursion
we use imposes a unitary elasticity of intertemporal substitution.
    Suppose again that consumption evolves according to equation (6). Conjecture a con-
tinuation value process of the form:
                                           h                                           i
                            Wt = exp (1 −           a)(wf Xtf   +   wo Xto   + ct + w̄)

The coefficients satisfy:

                               (1 − a)σf2                              (1 − a)ϑ2f
                  −ξf wf +                (wf )2 + (1 − a)ϑf σf wf +              = bwf
                                   2                                        2
                                                                       −ξo wo + 1 = bwo
                                          2
                                (1 − a)σ o                             (1 − a)ϑ2o
        ξf x̄f wf + ξo x̄o wo +             (wo )2 + (1 − a)ϑo σo wo +            = bw̄.
                                    2                                       2

The stochastic discount factor is the product of two multiplicative functionals. One has



                                                         11
the same form as the Breeden model with a = 1. It is the exponential of:
                             Z    t                         Z tq                     Z       t
                  Ast   =−            Xso ds    − bt −             Xsf ϑf dBsf   −               ϑo dBso .
                              0                               0                      0


The other is a martingale. It is the contribution from the continuation value and is the
exponential of:
                             Z tq                                                    Z       t
         Aw
          t   = (1 − a)                   Xsf (ϑf      +   wf σf )dBsf   + (1 − a)               (ϑo + wo σo )dBso
                             0                                                           0
                                          t
                    (1 − a)2                        |ϑf + wf σf |2      (1 − a)2
                                      Z
                  −                           Xsf                  ds −          t
                       2              0                   2                2


5    Valuation functionals and returns
A valuation process is constructed to have the following property. If the future value of
the process is the payout, the current value is the price of that payout. For instance a
valuation process could be the result of continually reinvesting dividends in a primitive
asset. Equivalently, it can be constructed by continually compounding realized returns
to an investment. To characterize local pricing, we use valuation processes that are
multiplicative functionals. Recall that the product of two multiplicative functionals is a
multiplicative functional. The following definition is motivated by the connection between
the absence of arbitrage and the martingale properties of properly normalized prices.

Definition 5.1. A valuation functional {Vt : t ≥ 0} is a multiplicative functional such
that the product functional {Vt St : t ≥ 0} is a martingale.

   Provided that V is strictly positive, the associated gross returns over any horizon u
can be calculated by forming ratios:

                                                                  Vt+u
                                                      Rt,t+u =
                                                                  Vt−

Thus increments in the value functional scaled by the current value gives an instantaneous
net return. The martingale property of the product V S gives a local pricing restriction
for returns.
    To deduce a convenient and familiar risk return relation, consider the multiplica-
tive functional M = V S where V is parameterized by (βv , γv , κv ) and {St : t ≥ 0} is


                                                             12
parameterized by (βs , γs , κs ). In particular, the implied net return evolution is:

                          |γv (Xt− )|2
                                      
        dVt
            = βv (Xt− ) +                dt + γv (Xt− )0 dBt + exp [κv (Xt , Xt− )] − 1.
        Vt−                    2

Thus the expected net rate of return is:

                                |γv |2
                                           Z
                         .
                      εv = βv +        +       (exp [κv (y, ·)] − 1) η(dy, ·).
                                  2

   Since both V and S are exponentials of additive processes, their product is the expo-
nential of an additive process and is parameterized by:

                                         β = βv + βs
                                         γ = γv + γs
                                         κ = κv + κs

Proposition 5.1. A valuation process parameterized by (βv , γv , κv ) satisfies the pricing
restriction:

                         |γv + γs |2
                                      Z
             βv + βs = −             − (exp [κv (y, ·) + κs (y, ·)] − 1) η(dy, ·).      (7)
                             2

Proof. This follows from the definition of a valuation functional and the martingale re-
striction (4).

   This restriction is local and determines the instantaneous risk-return relation. The
parameters (γv , κv ) determine the Brownian and jump risk exposure. The following
corollary gives the required local mean rate of return:

Corollary 5.1. The required mean rate of return for the risk exposure (γv , κv ) is:

                          |γs |2
                                     Z
     εv = −βs − γv · γs −        −       (exp [κv (y, ·) + κs (y, ·)] − exp [κv (y, ·)]) η(dy, ·)
                            2

The vector −γs contains the factor risk prices for the Brownian motion components. The
function κs is used to price exposure to jump risk. Then εv is the required expected rate
of return expressed as a function of the risk exposure. This local relation is familiar from
the extensive literature on continuous-time asset pricing.

Example 5.1. Breeden example continued

                                                13
    Consider again the Markov diffusion example 2.2 with the stochastic discount factor
given in example 4.1. This is a Markov version of Breeden’s model. The local risk price
for exposure to the vector of Brownian motion increments is:
                                           " √       #
                                            a x f ϑf
                                              aϑo

and the instantaneous risk free rate is:

                                           a2 (xf (ϑf )2 + (ϑo )2 )
                               b + axo −                            .
                                                      2

   Consider a family of valuation processes parameterized by (β, γ) where: γ(x) =
 √
( xf γf , γo ). To satisfy the martingale restriction, we must have:

                                        1
                                          xf (γf − aϑf )2 + (γo − aϑo )2
                                                                         
                    β(x) = b + axo −
                                        2

Example 5.2. Kreps-Porteus example continued
    Consider again the Markov diffusion example 2.2 with the stochastic discount factor
given in example 4.2. The local risk price for exposure to the vector of Brownian motion
increments is:              " √                 √           #
                             a xf ϑf + (a − 1) xf wf σf
                                   aϑo + (a − 1)wo σo
and the instantaneous risk free rate is:

                          a
                            xf ϑ2f + ϑ2o − (a − 1)wf xf ϑf σf − (a − 1)wo ϑo σo .
                                        
              b + axo −
                          2

    As we have seen, alternative valuation functionals reflect alternative risk exposures.
The methods we will describe will allow us to characterize the behavior of expectations of
valuation functionals over long horizons, including long-horizon returns. To accomplish
this we will be led to study semigroup {Vt : t ≥ 0} constructed using the multiplicative
functional V . While measurement of long-horizon returns in log-linear environments has
commanded much attention, operator methods can accommodate low frequency volatility
movements as well. In what follows, however, we will describe other ways to characterize
a long-term risk return tradeoff.




                                               14
6    Stochastic growth
The pricing semigroup we have thus far constructed only assigns prices to payoffs of form
ψ(Xt ). When X is stationary, this specification rules out stochastic growth. We now
extend the analysis to include payoffs with stochastic growth components by introducing
a reference stochastic growth process: {Gt : t ≥ 0} that is a positive multiplicative
functional. We will eventually restrict this process further. Consider a cash flow that
can be represented as
                                    Dt = Gt ψ(Xt )D0                                   (8)

for some initial condition D0 where G multiplicative functional. For simplicity we may
think of ψ(X) as the stationary component of the cash flow and G as the growth com-
ponent. However, as we will illustrate, the covariance between components sometimes
makes this interpretation problematic.
    The fact that the product of multiplicative functionals is a multiplicative functional
facilitates the construction of valuation operators designed for cash flow processes that
grow stochastically over time. We study cash flows with a common growth component
using the semigroup:
                             Qt ψ(x) = E [Gt St ψ(Xt )|X0 = x]

instead of pricing semigroup {St } constructed previously. The date zero price assigned
to Dt is D0 Qt ψ(X0 ). More generally, the date τ price assigned to Dt+τ is D0 Gτ Qt ψ(Xτ ).
Thus the date τ price to payout ratio is:

                      D0 Gτ Qt ψ(Xτ )   D0 Gτ Qt ψ(Xτ )   Qt ψ(Xτ )
                                      =                 =           .
                            Dτ           D0 Gτ ψ(Xτ )      ψ(Xτ )

This semigroup assigns values to cash flows with common growth component G but
alternative transient contributions ψ. To study how valuation is altered when we change
stochastic growth, we will be led to alter the semigroup.
    When the growth process is degenerate and equal to unity, the semigroup is identical
to the one constructed previously in section 4. This semigroup is useful in studying
the valuation of stationary cash flows including discount bonds and the term structure
of interest. It supports local pricing and generalizations of the analyses of Backus and
Zin (1994) and Alvarez and Jermann (2005) that use fixed income securities to make
inferences about economic fundamentals. In our investigation of long run valuation, the


                                            15
                  object              multiplicative functional semigroup
         stochastic discount factor               S                {St }
             cumulated return                     V                {Vt }
             stochastic growth                    G                {Gt }
     valuation with stochastic growth          Q = GS              {Qt }

            Table 1: Alternative Semigroups and Multiplicative Functionals

study of this particular semigroup corresponds to one with no long term risk exposure.
Nevertheless, the study of this semigroup offers a convenient benchmark for the study of
long term risk just as a risk free rate offers a convenient benchmark in local pricing.
    The decomposition (8) used in this construction is not unique. For instance, let ϕ be
a strictly positive function of the Markov state. Then
                                                   
                                        ϕ(Xt ) ψ(Xt )
                  Dt = Gt ψ(Xt )D0 = Gt                 [D0 ϕ(X0 )] .
                                        ϕ(X0 ) ϕ(Xt )

Since ψ(X t)
       ϕ(Xt )
              is a transient component, we can produce (infinitely) many such decomposi-
tions. For decomposition (8) to be unique, we must thus restrict the growth component.
    A convenient restriction is to require that Gt = exp(δt)Ĝt where Ĝ is a martingale.
With this choice, by construction G has a constant conditional growth rate δ. Later we
show how to extract martingale components, Ĝ’s, from a large class of multiplicative
functionals G. In this way we will establish the existence of such a decomposition. Even
with this restriction, the decomposition will not always be unique, but we will justify a
particular choice.
    As we have seen, semigroups used for valuing growth claims are constructed by form-
ing products of two multiplicative functionals, a stochastic discount factor functional and
a growth functional. Pricing stationary claims and constructing cumulative returns lead
to the construction of alternative multiplicative functionals. Table 1 gives a reminder of
the alternative multiplicative functionals and semigroups. For this reason, we will study
the behavior of a general multiplicative semigroup:

                             Mt ψ(x) = E [Mt ψ(Xt )|X0 = x]

for some strictly positive multiplicative functional M . An important vehicle in this study
is the generator of the semigroup.



                                            16
7         Generator of a Multiplicative Semigroup
In section 3 we defined a multiplicative semigroup {Mt : t ≥ 0} on a Banach space L∞
of bounded functions equipped with the sup-norm.


7.1         Strong continuity
Definition 7.1. The semigroup {Tt : t ≥ 0} is strongly continuous if for any ψ ∈ L:

                                              lim kTt ψ − ψk = 0
                                              t↓0


for some Banach space L.

   Strong continuity is known to imply an exponential bound on the growth of the
semigroup:
                                kTt k ≤ K exp(δt).

for some K ≥ 1 and some positive δ.
    Strong continuity of the semigroup is also known to imply the existence of the gener-
ator U of the semigroup. This generator is a closed operator defined on a dense subset,
D(U), of L as:
                                              Tt ψ − ψ
                                   Uψ = lim            .                              (9)
                                          t↓0     t
[See Ethier and Kurtz (1986) Corollary 1.6 on page 10.] The operator U is referred to as
a generator because the semigroup may be constructed from U. This construction uses
the exponential formula:
                                     Tt = exp(tU)

which is defined rigorously through the Yosida approximation.7
   Under assumption 3.1, the multiplicative semigroup {Mt : t ≥ 0} is well defined on
 ∞
L . Under the following additional restriction, this semigroup is strongly continuous.

Assumption 7.1.
                                   lim sup E ( |Mt − 1| |X0 = x) = 0.               (10)
                                   t↓0 x∈D0

Example 7.1. Markov Chain Generator
    7
        See Ethier and Kurtz (1986) page 12 for a formal construction.



                                                     17
     Recall the finite state Markov chain example 2.1 with intensity matrix U. Let uij
denote entry (i, j) of this matrix. Consider a multiplicative functional that is the product
of two components. The first component decays at rate βi when the Markov state is
xi . The second component only changes when the Markov process jumps from state i to
state j, in which case the multiplicative functional is scaled by exp[κ(xj , xi )]. From this
construction we can deduce the generator A for the multiplicative semigroup depicted as
a matrix with entry (i, j):
                                    (
                                            uii − βi        if i = j
                            aij =                                     .
                                       uij exp[κ(xj , xi )] if i 6= j

This formula uses the fact that in computing the generator we are scaling probabilities by
the potential proportional changes in the multiplicative functional. The matrix A is not
necessarily an intensity matrix. The row sums are not necessarily zero. The reason for
this is that the multiplicative functional can include pure discount effects or pure growth
effects. These effects can be present even when the βi ’s are zero since it is typically the
case that
                                 X
                                     uij exp[κ(xj , xi )] 6= −uii .
                                j6=i

   Establishing strong continuity is difficult in many applications. Even when strong
continuity can be verified, it is difficult to characterize the domain of the generator.
Moreover, the space of bounded functions used as the domain of the multiplicative semi-
group is, for many purposes, too small. It is advantageous to have more flexibility when
studying the local behavior of the semigroup.


7.2    A More General Construction
We now consider a more general definition of a generator. One of the advantages of this
extended notion is that it allows for the use of Ito’s formula to compute the generator.

Definition 7.2. A Borel function ψ belongs to the domain of the extended generator
A of the multiplicative functional M if there exists a Borel function χ such that Nt =
                       Rt
Mt ψ(Xt ) − ψ(X0 ) − 0 Ms χ(Xs )ds is a local martingale with respect to the filtration
{Ft : t ≥ 0}. In this case the extended generator assigns χ to ψ.

For strictly positive multiplicative processes M the extended generator is single valued
and linear. As we show in appendix A, if {Mt : t ≥ 0} is the semigroup defined by

                                                 18
equation (3) and ψ is in D(U), the extended generator assigns Uψ to ψ, and thus it is
actually an extension of the generator U of {Mt : t ≥ 0}.
    In the remainder of the paper, if the context is clear, we often refer to the extended
generator simply as the generator.
    The unit function is a trivial example of a multiplicative functional. In this case
the extended generator is exactly what is called in the literature the extended generator
of the Markov process X. Ito’s formula allows us to obtain a characterization of this
extended generator for any C 2 function, including ones that are not bounded. The
extended generator has a well known representation:

                                      ∂ 2 φ(x)
                                               Z
                    ∂φ(x) 1
     Aφ(x) = ξ(x) ·      + trace Σ(x)           + [φ(y) − φ(x)] η(dy|x).             (11)
                     ∂x   2           ∂x∂x0

where

a) jump measure: η(dy|x), a positive finite Borel measure for each x;

b) first derivative term: an n-dimensional vector ξ of functions;

c) second derivative term: a (pointwise) positive, semidefinite matrix Σ = ΓΓ0 of func-
   tions .

    Recall our earlier parameterization of an additive functional A in terms of the triple
(β, γ, κ). The process M = exp(A) is a multiplicative functional. We now display how to
go from the extended generator of the Markov process X, that is the generator associated
with M ≡ 1, to the extended generator of the multiplicative functional M . Suppose
that the conditional measure η is finite and the generator A of the Markov process is
parameterized by (ξ, Σ, η) as in (11). The matrix Σ is restricted to have a constant rank
on the interior of the state space.
    The formulas below use the parameterization for the multiplicative process to trans-
form the generator of the Markov process into the generator of the multiplicative semi-
group and are consequences of Ito’s lemma:

a) jump measure: exp [κ(y, x)] η(dy|x).

b) first derivative term: ξ(x) + Γ(x)γ(x);

c) second derivative term: Σ(x);


                                             19
                         |γ(x)|2       R
d) level term: β(x) +       2
                                   +       (exp [κ(y, x)] − 1) η(dy, x);

The Markov chain example that we discussed above can be seen as a special case where
γ, ξ, and Σ are all null.
    There are a variety of direct applications of this analysis. In the case of the stochastic
discount factor introduced in section 4, the generator encodes the local prices reflected
in the local risk return tradeoff of Proposition 5.1. The level term that arises gives the
instantaneous version of a risk free rate. In the absence of jump risk, the increment to
the drift gives the factor risk prices. The function κ shows us how to value jump risk in
small increments in time.
    In a further application, Anderson et al. (2003) use this decomposition to charac-
terize the relation among four alternative semigroups, each of which is associated with
an alternative multiplicative process. Anderson et al. (2003) feature models of robust
decision making. In addition to the generator for the original Markov process, a second
generator depicts the worst case Markov process used to support the robust equilibrium.
There is a third generator of an equilibrium pricing semigroup, and a fourth generator of
a semigroup used to measure the statistical discrepancy between the original model and
the worst-case Markov model.


8     Principal eigenfunctions and martingales
As a precursor to our study of long run behavior, we construct what are called prin-
cipal eigenfunctions of the generator of a multiplicative functional. We then use these
eigenfunctions to obtain a decomposition of a multiplicative functional.

Definition 8.1. A Borel function φ is an eigenfunction of the extended generator A
with eigenvalue ρ if Aφ = ρφ.

Proposition 8.1. Suppose that φ is an eigenfunction of the extended generator associated
with the eigenvalue ρ. Then
                                  exp(−ρt)Mt φ(Xt )

is a local martingale.

Proof. Since the local martingale Nt is continuous from the right with left limits it is a
semimartingale (Protter (2005), Chapter 3, Corollary to Theorem 30) and hence Yt =


                                                      20
Mt φ(Xt ) is also a semimartingale. Since dNt = dYt − ρYt− , integration by parts yields:
                          Z    t                        Z   t                   Z   t
   exp(−ρt)Yt − Y0 = −             ρ exp(−ρs)Ys− ds +           exp(−ρs)dYs =           exp(−ρs)dNs .
                           0                            0                       0




   It is the strictly positive eigenfunctions that interest us.

Definition 8.2. A principal eigenfunction of the extended generator is an eigenfunc-
tion that is strictly positive.

Corollary 8.1. Suppose that φ is a principal eigenfunction with eigenvalue ρ for the
extended generator of the multiplicative functional M . Then this multiplicative functional
can be decomposed as:                                    
                                                   φ(X0 )
                               Mt = exp(ρt)M̂t              .
                                                   φ(Xt )
                       φ(Xt )
where M̂t = exp(−ρt)Mt φ(X0)
                              is a local martingale that is a multiplicative functional.

Proof. Note that when φ is strictly positive, then

                                                            φ(Xt )
                                      M̂t = exp(−ρt)Mt
                                                            φ(X0 )

is a multiplicative functional.

   Let M̂ be the local martingale from Corollary 8.1. Since M̂ is bounded from below,
the local martingale is necessarily a supermartingale and thus
                                                 
                                         E M̂t |Fu ≤ M̂u .

We are primarily interested in the case in which this local martingale is actually a mar-
tingale:

Assumption 8.1. The local martingale M̂ is a martingale.

By examining the proof of Proposition 8.1, one verifies that a sufficient condition for
Assumption 8.1 to hold is that the local martingale N is a martingale. In appendix B
we give primitive conditions that imply Assumption 8.1.



                                                21
       When Assumption 8.1 holds we may define for each event f ∈ Ft

                                        P̂ r(f ) = E[M̂t 1f ]

The probability P̂ r is absolutely continuous with respect to P r when restricted to Ft for
each t ≥ 0. In addition, if we write Ê for the expected value taken using P̂ r, we obtain:
                                                                               
                                                        ψ(Xt )
                   E [Mt ψ(Xt )|X0 = x] = exp(ρt)φ(x)Ê        |X0 = x                          (12)
                                                        φ(Xt )

    If we treat exp(−ρt)φ(Xt ) as a numeraire, equation (12) is reminiscent of the famil-
iar risk-neutral pricing in finance. Note, however, that the numeraire depends on the
eigenvalue-eigenfunction pair, and equation (12) applies even when the multiplicative
process does not define a price.8
    Although φ does not necessarily belong to the Banach space L where the semigroup
{Mt : t ≥ 0} was defined, under Assumption 8.1 we can always define Mt φ. In fact:

Proposition 8.2. Under Assumption 8.1, for each t ≥ 0

                                         Mt φ = exp(ρt)φ

Proof.
                                             exp(−ρt)
                     1 = E[M̂t |X0 = x] =             E[Mt φ(Xt )|X0 = x].
                                               φ(x)


   This proposition guarantees that under Assumption 8.1, a principal eigenvector of
the extended generator also solves the principal eigenvalue problem:

                                        Mt φ = exp(ρt)φ.                                        (13)

On the other hand if φ ∈ L solves equation (13) for each t ≥ 0, then Uφ = ρφ where U
is the generator defined in (9). Since the extended generator extends U, φ is a principal
eigenvector of the extended generator.
    In light of the decomposition given by Corollary 8.1, when the local martingale M̂
is a martingale, we will sometimes refer to ρ as the growth rate of the multiplicative
   8
    The idea of using an appropriately chosen eigenfunction of an operator to construct and analyze a
distorted probability measure is also featured in the work of Balaji and Meyn (2000).

                                                 22
functional M, M̂ as its martingale component and φ(X      0)
                                                       φ(Xt )
                                                              as its transient or stationary
component. This decomposition is typically not unique, however. As we have defined
them, there may be multiple principal eigenfunctions even after a scale normalization.
Each of these principal eigenfunctions implies a distinct decomposition (provided that
we establish that the associated local martingales are martingales.) Sinceh the martingalei
and the stationary components are correlated, it can happen that E M̂t φ(X        0)
                                                                               φ(Xt )
                                                                                      |X0 = x
diverges exponentially challenging the interpretation that ρ is the asymptotic growth rate
of the semigroup. We take up this issue in the next section.

Remark 8.1. There are well known martingale decompositions of additive functionals
with stationary increments used in deducing central limit approximation and in charac-
terizing the role of permanent shocks in time series. The nonlinear, continuous time
Markov version of such a decomposition is:

                                   At = ωt + mt − υ(Xt ) + υ(X0 )

where {mt : t ≥ 0} is a martingale with stationary increments (see Bharttacharya (1982)
and Hansen and Scheinkman (1995)). Exponentiating this decomposition is of a sim-
ilar type to that given in Corollary 8.1 except that the exponential of a martingale is
not a martingale. When the martingale increments are constant functions of Brownian
increments, then exponential adjustment has simple consequences.9 In particular, the
exponential adjustment is offset by changing ω. With state dependent volatility in the
martingale approximation, however, there is no longer a direct link between the addi-
tive and multiplicative decompositions. In this case the multiplicative decomposition of
Corollary 8.1 is the one that is valuable for our purposes.

Example 8.1. Markov chain example
    Recall that for a finite state space, we can represent the Markov process in terms of
a matrix U that serves as its generator. Previously we constructed the corresponding
generator A of the multiplicative semigroup. For this example, the generator is a matrix.
A principal eigenvector is found by finding an eigenvector of A with strictly positive
entries. Standard Perron-Frobenius theory implies that there is such an eigenvector, and
it is unique up to scale.

      While there is uniqueness in the case of finite state chain, there can be multiple
  9
      This is the case studied by Hansen et al. (2005).

                                                    23
solutions in more general settings.

Example 8.2. Markov diffusion example continued
  Consider a multiplicative process M = exp(A) where:
                        Z   t                   Z   t                 Z tq            Z t
                                                                           f
           At = β̄t +           βf Xsf ds   +           βo Xso ds   +             f
                                                                          Xs γf dBs +     γo dBso ,   (14)
                        0                       0                      0                   0


where X f and X o are given in Example 2.2.
   Guess an eigenfunction of the form: exp(cf xf + co xo ). The corresponding eigenvalue
equation is:

                                            γf2      γ2
                ρ = β̄ + βf xf + βo xo + xf + o
                                             2       2
                    +cf [ξf (x̄f − xf ) + xf γf σf ] + co [ξo (x̄o − xo ) + γo σo ]
                              σf2         σ2
                  + (cf )2 xf     + (co )2 o
                              2            2

This generates two equations: one that equates the coefficients of xf to zero and another
that equates the coefficients of xo to zero:

                                 γf2                               σ2
                                                                  2 f
                        0 = βf +      + cf (γf · σf − ξf ) + (cf )
                                  2                                 2
                        0 = βo − co ξo .

The solution to the first equation is:
                                                    q                                      
                            (ξf − γf σf ) ±               (ξf − γf σf )2 − σf2 2βf + γf2
                   cf =                                                                               (15)
                                                              |σf |2

provided that
                                  (ξf − γf σf )2 − σf2 2βf + γf2 ≥ 0.
                                                                

Later we will argue that only one of these solutions interests us. The solution to the
second equation is:
                                            βo
                                       co = .                                     (16)
                                            ξo
The resulting eigenvalue is:

                                   γo2                                            σ2
                    ρ = β̄ +           + cf ξf x̄f + co (ξo x̄o + γo σo ) + (co )2 o .
                                   2                                               2

                                                            24
   Write
                                                              exp(cf Xtf + co Xto )
                                 M̂t = exp(−λt)Mt                                     ,
                                                              exp(cf X0f + co X0o )
Then M̂ is a martingale. It may be verified that M̂t = exp(Ât ) where:
        Z tq                                    t                                             t
                                                                             + cf σf )2                     (γo + co σo )2
                                            Z                                             Z
                                                                       (γf
Ât =          Xsf (γf   +cf σf )dBsf   +           (γo +co σo )dBso −                            Xsf ds−                  t
        0                                   0                                 2           0                      2

This martingale appends a drift to each component of the Brownian motion. The resulting
drift for X f is
                            ξf (x̄f − xf ) + xf σf (γf + cf σf ),

and distorted drift for X o is:

                                        ξo (x̄o − xo ) + σo (γo + co σf ).

We pick a solution for cf so that the implied distorted process for X f remains stationary.
Notice that
                                                                     q                               
        ξf (x̄f − xf ) + xf σf (γf + cf σf ) = ξf x̄f ± xf             (ξf − γf σf )2 − σf2 2βf + γf2 .

For mean reversion to exist, we require that the coefficient on xf be negative.

Remark 8.2. At a cost of an increase in notational complexity we could add an “affine”
jump component as in Duffie et al. (2000). Suppose that the state variable X o instead of
being an Ornstein-Uhlenbeck process satisfies:

                                  dXto = ξo (x̄o − Xto ) + σo dBto + dZt

where Z is a pure jump process whose jumps have a fixed probability distribution ν on
R and arrive with intensity $1 xf + $2 with $1 ≥ 0, $2 ≥ 0. Suppose that the additive
                                                                     .
functional A has an additional term jump term modeled using κ(y, x) = κ̄(yo − xo ) for
           R
y 6= x and exp [κ̄(z)] dν(z) < ∞.
    The generator A has now an extra term given by:
                                    Z
                   ($1 xf + $2 )        [φ(xf , xo + z) − φ(xf , xo )] exp [κ̄(z)] dν(z).



                                                             25
Hence when φ(x) = exp(cf xf + co xo ) the extra term reduces to:
                                                   Z
               ($1 xf + $2 ) exp(cf xf + co xo )        [exp(co z) − 1] exp [κ̄(z)] dν(z).

As before we must have
                                                        βo
                                                co =
                                                        ξo
and hence cf must solve:


             γf2                            σf2
                                                             Z             
                                                                      βo
    0 = βf +     + cf (γf σf − ξf ) + (cf )2 + $1               exp      z − 1 exp [κ̄(z)] dν(z).
             2                              2                         ξo

The resulting eigenvalue is

        γ2                                            σ2
                                                                Z             
                                                                         βo
ρ = β̄ + o + cf ξf x̄f + co (ξo x̄o + γo σo ) + (co )2 o + $2      exp      z − 1 exp [κ̄(z)] dν(z).
         2                                             2                 ξo


9     Long Run Dominance
We investigate long term risk by changing the reference growth functionals. These func-
tionals capture the long term risk exposure of the cash flow. As we will demonstrate, the
valuation of cash flows with common reference growth functionals will be approximated
by a single dominant component when the valuation horizon becomes long. Thus the
contributions to value that come many periods into the future will be approximated by
a single pricing factor that incorporates an adjustment for risk. Changing the reference
growth functional alters the long term risk exposure with a corresponding adjustment in
valuation. Each reference growth functional will be associated with a distinct semigroup.
We will characterize long term risk formally by studying the limiting behavior of the
corresponding semigroup.
    In this section we establish approximation results for the principal eigenvalue and
eigenfunction as a device for the study of behavior of valuation of cash flows with payout
dates far into the future and for the construction of asymptotic growth rates and discount
rates of cash flows.
    We first illustrate this dominance in the case of a Markov chain.




                                                   26
9.1    Markov chain
Consider again the finite state Markov example with intensity matrix U. In this section
we will study the long run behavior of the semigroup by solving the eigenvalue problem:

                                         Aφ = ρφ

for an eigenvector φ with strictly positive entries and a real eigenvalue ρ. Given this
solution, then
                            Mt φ = exp (tA) φ = exp(ρt)φ.

    The beauty of Frobenius-Perron theory is that ρ is the eigenvalue that dominates
in the long run. Its real part is strictly larger than the real parts of all of the other
eigenvalues. This property dictates its dominant role. To see this, suppose that the
matrix A has distinct eigenvalues:

                                      A = TDT−1 .

where T is a matrix with eigenvectors in each column and D is a diagonal matrix of
eigenvalues. Let the first entry of D be ρ and the first column of T beφ. Then the first
row of T−1 is the eigenvector φ∗ associated with the principal eigenvalue ρ normalized so
that φ∗ · φ = 1. Thus
                                exp (tA) = T exp (tD) T−1 .

Scaling by exp(−ρt) and taking limits:

                          lim exp(−ρt) exp (tA) ψ = (φ∗ · ψ)φ.
                          t→∞


Thus ρ determines the long-run growth rate of the semigroup. After adjusting for this
growth, the semigroup has an approximate one factor structure in the long run. Provided
that φ∗ · ψ is not zero, exp(−ρt)Mt ψ is proportional to the dominant eigenvector φ.


9.2    General analysis
To establish this dominance more generally, we use the same martingale construction as
in the decomposition of Corollary 8.1 to build an alternative family of distorted Markov
transition operators and apply known results about Markov operators to this alternative


                                           27
family.
   In what follows we will maintain Assumption 8.1 and let Â denote the extended
generator of the martingale M̂ . We will also call the semigroup M̂ associated with M̂ the
principal eigenfunction semigroup. This semigroup is well defined at least on the space
L∞ , and it maps constant functions into constant functions.
   Consistent with the applications that interest us, we consider only multiplicative
functionals that are strictly positive.

Assumption 9.1. The multiplicative functional M is strictly positive with probability
one.

   We presume that there exists a stationary density for the process X under distorted
evolution.

Assumption 9.2. There exists a probability measure ςˆ such that
                                        Z
                                                ς=0
                                            Âψdˆ


for all ψ in the L∞ domain of the generator Â.

This second assumption implies that ςˆ is a stationary distribution for the distorted
Markov process. (For example, see Proposition 9.2 of Ethier and Kurtz (1986).) In
what follows we use the notation Ê and Pr    ˆ to denote the expectation operator and the
probability measure associated with M̂ and ςˆ. The process M̂ determines the distorted
transition probabilities and ςˆ is the initial distribution.
   Let ∆ ˆ > 0 and consider the discrete time Markov process obtained by sampling the
             ˆ for j = 0, 1, .... In what follows we assume that the resulting discrete time
process at j ∆
process is irreducible.

Assumption 9.3. There exists a ∆   ˆ > 0 such that the discretely sampled process {X ˆ :
                                                                                    ∆j
j = 0, 1, ...} is irreducible. That is, for any Borel set Λ of the state space D0 with
ςˆ(Λ) > 0,                       "∞                  #
                                  X
                              Ê     1{X∆j
                                        ˆ ∈Λ}
                                              |X0 = x > 0
                                  j=0

for all x ∈ D0 .



                                             28
Under Assumption 9.1 it is equivalent to assume that this irreducibility restriction holds
under the original probability measure.10
   We establish approximation results by imposing a form of stochastic stability under
the distorted probability measure. We assume that the distorted Markov process satisfies:

Assumption 9.4. The process X is Harris recurrent under the measure P̂ r. That is,
for any Borel set Λ of the state space D0 with positive ςˆ measure,
                                       Z    ∞                         
                                P̂ r             1{Xt ∈Λ} = ∞|X0 = x       =1
                                         0


for all x ∈ D0 .

Among other things, this assumption guarantees that the stationary distribution ςˆ is
unique.
   Under these assumptions, we characterize the role of the principal eigenvalue and
function on the long run behavior of the semigroup.

Proposition 9.1. Suppose that M̂ satisfies Assumptions 8.1, 9.1 - 9.4, and let ∆ > 0.
                            R
a. For any ψ for which          (|ψ|/φ)dˆ
                                        ς < +∞
                                                                     Z
                                                                           ψ
                                       lim exp(−ρ∆j)M∆j ψ = φ                dˆ
                                                                              ς
                                   j→∞                                     φ

   for almost all (ˆ
                   ς ) x.

b. For any ψ for which ψ/φ is bounded,
                                                                 Z
                                                                       ψ
                                        lim exp(−ρt)Mt ψ = φ             dˆ
                                                                          ς
                                        t→∞                            φ

   for x ∈ D0 .

Proof. Note that                                        
                                                        ψ
                                 exp(−ρt)Mt ψ(x) = M̂t     φ(x).
                                                        φ
  10
    Irreducibility and Harris recurrence are defined relative to a measure. This claim uses the ςˆ measure
when verifying irreducibility for the original probability measure. Since irreducibility depends only on
the probability distribution conditioned on X0 , it does not require that the X process be stationary
under the original measure.


                                                       29
It follows from Theorem 6.1 of Meyn and Tweedie (1993a) that,
                                         Z
                                        ψ    ψ
                           lim sup M̂t    −    dˆ
                                                ς = 0,
                          t→∞ 0≤ψ≤φ     φ    φ

which proves (b). Consider any sample interval ∆ > 0. Then
                                          Z
                                         ψ    ψ
                           lim sup M̂∆j    −    dˆ
                                                 ς = 0.
                          j→∞ 0≤ψ≤φ      φ    φ

From Proposition 6.3 of Nummelin (1984), the sampled process {Xj∆ : j = 0, 1, ...} is
                                                                    R ψ
aperiodic and Harris recurrent with stationary density ςˆ. Hence if   φ
                                                                             ς (x) < ∞,
                                                                        (x) dˆ

                                            Z
                                           ψ    ψ
                                 lim M̂∆j    =    dˆ
                                                   ς
                                j→∞        φ    φ

for almost all (ˆ
                ς ) x, which proves (a). (See for example, Theorem 5.2 of Meyn and
Tweedie (1992).)


    The approximation implied by Proposition 9.1, among other things, gives a formal
sense in which ρ is a long run growth rate. It also provides more precise information,
namely that after eliminating the deterministic growth, application of the semigroup to
ψ is approximately proportional to φ where the scale coefficient is ψφ dˆ
                                                                     R
                                                                         ς . Subsequently,
we will consider other versions of this approximation. We will also impose additional reg-
ularity conditions that will guarantee convergence without having to sample the Markov
process.

9.2.1   Uniqueness

Recall that there may exist more than one principal eigenfunction of the extended gen-
erator even after a scale normalization is imposed. Stochastic stability requirements
typically eliminate this multiplicity.

Example 9.1. Consider again the Markov diffusion specification given in examples 2.2,
4.1, 4.2 and 8.2. We constructed two solutions to the generalized eigenvalue problem.
Only one of these two solutions will be stochsatically stable. The other solution will
result in Markov process that fails to be stationary. Recall that the two candidate drift


                                           30
distortions are:                      q                                 
                        ξf x̄f ± xf       (ξf − γf σf )2 − σf2 2βf + γf2 .

By selecting the solution associated with the negative root, we obtain a process with a
stationary density.

   It turns out that this approach to uniqueness works much more generally.

Proposition 9.2. Suppose that Assumption 9.1 is satisfied and that there exists a sam-
pling interval ∆ such that {Xj∆ : j = 0, 1, ...} is irreducible. There is at most one (up to
scale) principal eigenfunction φ of the extended generator A of a multiplicative process
M for which the associated {M̂t : t ≥ 0} satisfies Assumptions 8.1, 9.2-9.4.

Proof. Consider two such principal eigenfunctions, φ and φ∗ , and let ρ ≥ ρ∗ be the
corresponding eigenvalues. By Proposition 8.2 each eigenfunction-eigenvalue pair must
solve the principal eigenvalue problem:

                               Mt φ(x) = exp(ρt)φ(x)
                               Mt φ∗ (x) = exp(ρ∗ t)φ∗ (x).

If M̂ is the martingale associated with the eigenvector φ, then

                            φ∗ (Xt )                          φ∗ (x)
                                           
                      E M̂t          |X0 = x = exp[(ρ∗ − ρ)t]        .
                            φ(Xt )                            φ(x)

Since the discrete-time sampled Markov process associated with M̂ is Harris recurrent,
aperiodic and has a unique stationary distribution, the left-hand side converges to:

                                                 φ∗ (X0 )
                                                           
                                              Ê
                                                 φ(X0 )

for t = ∆j as the integer j tends to ∞. While the limit could be +∞, it must be strictly
positive, implying, since ρ ≥ ρ∗ , that ρ∗ = ρ and

                                         φ∗ (X0 )     φ∗ (x)
                                                 
                                      Ê            =        .
                                         φ(X0 )       φ(x)

Hence the ratio of the two eigenfunctions is constant.



                                                    31
9.2.2   Lp approximation

When there exists a stationary distribution, it follows from Nelson (1958) that the semi-
group {M̂t : t ≥ 0} can be extended to L̂p for any p ≥ 1 constructed using the measure
 ς . The semigroup is a weak contraction. That is, for any t ≥ 0,
dˆ

                                                   kM̂t ψkp ≤ kψkp

where k · kp is the L̂p norm.

Proposition 9.3. Under Assumption 9.2, for p ≥ 0
                      Z                            p1       Z         p1
                                  p       1                           p  1
                            |Mt ψ|                  ς ≤ exp(ρt)
                                                   dˆ              |ψ|      dˆ
                                                                             ς
                                          φp                             φp
                            
                            1
                R
provided that       |ψ|p   φp
                                  ς < ∞.
                                 dˆ

Proof. This follows from the weak contraction property established by Nelson (1958)
together with the observation that
                                                            
                                               1              ψ
                                     exp(−ρt)     Mt ψ = M̂t     .
                                               φ              φ



Remark 9.1. This proposition establishes an approximation in an Lp space constructed
using the transformed measure φ1p dˆ
                                   ς . Notice that φ itself is always in this space. In
particular, we may view the semigroup {Mt : t ≥ 0} as operating on this space.

    Proposition 9.3 shows that when the distorted Markov process constructed using
the eigenfunction is stationary, ρ can be interpreted as an asymptotic growth rate of the
multiplicative semigroup. The eigenfunction is used to characterize the space of functions
over which the bound applies. We now produce a more refined approximation.
                                                                          R
    Let Ẑ p denote the set of Borel measurable functions ψ such that ψdˆ     ς = 0 and
R    p
  |ψ| dˆ
       ς < ∞. Suppose that

Assumption 9.5. For any ψ ∈ Ẑ p ,

                                                   lim kM̂t ψkp = 0.
                                                   t→∞


                                                          32
In the case of p = 2, Hansen and Scheinkman (1995) give sufficient conditions for As-
sumption 9.5 to be satisfied.11
                                                                                               p
                                                                                           ψ
                                                                                       R
Proposition 9.4. Under Assumptions 9.2 and 9.5, for any ψ such that                        φ
                                                                                                    ς < ∞,
                                                                                                   dˆ

                       Z                       Z        p       p1
                                                    ψ      1
                            exp(−ρt)Mt ψ − φ          dˆ
                                                       ς       ς ≤ c exp(−ηt).
                                                              dˆ
                                                    φ      φp

for some rate η > 0 and positive constant c.

Proof. Notice that
                                            Z                     Z
                                                ψ                ψ    ψ
                        exp(−ρt)Mt ψ − φ          dˆ
                                                   ς = φ M̂t       −    dˆ
                                                                         ς .
                                                φ                φ    φ

Moreover,
              Z           Z      p         Z       Z      p
                   p     ψ    ψ       1               ψ    ψ
                  φ M̂t    −    dˆ
                                 ς         dˆ
                                            ς=   M̂t    −    dˆ
                                                              ς dˆς.
                         φ    φ       φp              φ    φ

Assumption 9.5 implies that the right-hand side converges to zero as t gets large. By the
semigroup property, this convergence is necessarily exponentially fast.

9.2.3      Liapunov functions

Meyn and Tweedie (1993a) establish, under an additional mild continuity condition,
sufficient conditions for the assumptions in this section using a “Liapunov function”
method. In this subsection we will assume:

Assumption 9.6. The process X is a Feller process under the probability measure asso-
ciated with M̂ .12

       We use Liapunov functions that are restricted to be norm-like.

Definition 9.1. A continuous function V is called norm-like if the set {x : V (x) ≤ r}
is precompact for each r > 0.
  11
    Assumpion 9.5 for p = 2 is equivalent to requiring that the distorted Markov process be rho-mixing.
  12
    By a Feller process we presume that the implied conditional expectation operators map continuous
functions on the one-point compactification of D into continuous functions. In fact, Meyn and Tweedie
(1993b) permit more general processes. The restriction that the process be Feller implies that all compact
subsets are what Meyn and Tweedie (1993b) refer to as “petite sets.”


                                                    33
A norm-like function converges to +∞ along any sequence {xj } that converges to ∞.
We will consider here only norm-like functions V for which ÂV is continuous.
    A sufficient condition for the existence of stationary distribution (Assumption 9.2)
and for Harris recurrence (Assumption 9.4) is that there exists a norm-like function V
for which
                                 A(φV )
                                        − ρV = ÂV ≤ −1
                                   φ
outside a compact subset of the state space. (See Theorem 4.2 of Meyn and Tweedie
(1993b).)
    In subsection 9.2.2 we established Lp approximations results. The space L̂p is largest
for p = 1. It is of interest to ensure that the constant functions are in the corresponding
domain for the semigroup {Mt : t ≥ 0}. This requires that 1/φ have a finite first moment
under the stationary distribution ςˆ. A sufficient condition for this is the existence of a
norm-like function V such that

                              A(φV ) − ρφV = φÂ (V ) ≤ − max {1, φ}

for x outside a compact set. (Again see Theorem 4.2 of Meyn and Tweedie (1993b).)
    Finally, Proposition 9.4 only applies when the process is weakly dependent under the
stationary distribution.13 By weakening the sense of approximation we can expand the
range of applicability. Consider some function ψ̂ ≥ 1. For any t, we use
                                                         Z
                                          sup M̂t ψ −        ψdˆ
                                                               ς
                                          |ψ|≤ψ̂


for each x as a measure of approximation. When ψ̂ = 1 this is equivalent to what is
                                                    R
called the total variation norm by viewing M̂t ψ and ψdˆς applied to indicator functions
as measures for each x. It follows from Meyn and Tweedie (1993b) Theorem 5.3 that if
there exists a norm-like function V and a real number a such that

                                     A(φV )
                                            − ρV = ÂV ≤ −ψ̂
                                       φ
                                     A(φψ̂)
                                            − ρψ̂ = Âψ̂ ≤ aψ̂                        (17)
                                       φ
 13
      In contrast, Proposition 9.1 applies more generally.




                                                    34
outside a compact set, then
                              Z                                      Z
                     ψ            ψ                                      ψ
       φ lim sup M̂t −               ς = lim sup exp(−ρt)Mt ψ − φ
                                    dˆ                                     dˆ
                                                                            ς = 0.
         t→∞
             |ψ|≤φψ̂ φ            φ      t→∞
                                             |ψ|≤φψ̂                     φ

Note that in inequality (17) the constant a can be positive. Hence this inequality only
requires the existence of an upper bound on rate of growth of the conditional expectation
of the function ψ̂ under the distorted probability. While the approximation is uniform in
functions dominated by φψ̂ it is pointwise in the Markov state x.
    The approximation results obtained in this section have a variety of applications
depending upon our choice of the multiplicative functional M . In these applications M is
constructed using stochastic discount factor functionals, growth functionals or valuation
functions. These applications are described in section 11.


10     Existence
Thus far we have proceeded constructively. That is, we suppose that we can find solutions
to principal eigenvalue problem and then proceed to check the alternative solutions. We
now explore when solutions exist to this problem. For this, we follow Kontoyiannis and
Meyn (2003) and Kontoyiannis and Meyn (2005) by working with a weighted L∞ space.
Suppose that there exist norm-like functions V ≥ 1 and W ≥ 1 such that
Assumption 10.1.
                                  AV
                                       ≤ −W + a
                                   V
for x ∈ D0 and some positive number a.
    In addition we will assume a continuity restriction on the multiplicative process M
that is implied by Assumption 7.1 given previously
                                                      R
Assumption 10.2. There exists an  > 0 such that exp(−at)E(Mt |X0 = x)dt ≥  for
all x.
An alternative sufficient condition for Assumption 10.2 is that there exists a lower bound
on the level term of the extended generator associated with M .
   Our main result in this section is:
Proposition 10.1. Suppose that Assumptions 10.1 and 10.2 hold. Then there exists a
positive eigenfunction in the space of all functions of the form ψV where ψ is bounded.

                                            35
Proof. Construct the multiplicative process:

                                                                                     V (Xt )
                                       Mt∗ = exp(−at)Mt                                      .
                                                                                     V (X0 )

Then                                                          Z       t                        
                                                                                    AV (Xu )
                           Nt∗   =   Mt∗     −1−                          Mu∗                − a du
                                                                  0                  V (Xu )
is a local martingale, as we now verify. Note that
                                                                                    Z    t
                           Nt = Mt V (xt ) − V (x0 ) −                                       Mu AV (xu )du
                                                                                     0

                                      1
                                             Rt
is a local martingale. Thus        V (x0 )       0
                                                     exp(−au)dNu is also a local martingale and,
                                             Z       t
                                    1
                                                         exp(−au)dNu
                                 V (x0 )      0
                                          V (xt )
                           = exp(−at)Mt            −1
                                Z t       V (x 0 )
                                                    V (xu )
                             +a      exp(−au)Mu             du
                               Z t0                 V (x0 )
                                                   V (xu ) AV (xu )
                             −      exp(−au)Mu                       du = Nt∗
                                0                  V (x 0 ) V (x u )

   Since {Nt∗ } is a local martingale, Fatou’s Lemma implies that
                                                         Z    t
                      E   (Mt∗ |x0   = x) +                       E [Mu∗ W (xu )|x0 = x] du ≤ 1.
                                                          0


Since this holds for any t,
                 Z    ∞                                     
                                       V (Xt )W (Xt )               1
                          exp(−at)E Mt                |X0 = x dt ≤                                           (18)
                  0                    V (X0 )W (X0 )              W (x)

   Use the multiplicative process:

                                                                   V (Xt )W (Xt )
                                           M̃t = Mt                               .
                                                                   V (X0 )W (X0 )




                                                                          36
to construct the operator:14
           Z     ∞                                                Z ∞
     .                            V (Xt )W (Xt )
  Fψ =               exp(−at)E Mt                ψ(Xt )|X0 = x dt =     exp(−at)M̃t ψ(x)dt.
             0                    V (X0 )W (X0 )                     0


Inequality (18) establishes that this operator maps the unit ball in L∞ into a compact
subset. Assumption 10.2 implies that F V 1W ≥  V 1W , and as a consequence the spectral
radius of F is strictly positive. (see Krasnosel’skij et al. (1989) Lemma 9.1 on page 89.)
The Krein-Rutman theorem (See Krein and Rutman (1948) or Bonsall (1963)) guarantees
that there exists a non-negative eigenfunction φ:

                                                     Fφ = λφ

with a positive eigenvalue λ. Assumptions 9.3 and 9.1 guarantee that φ is strictly positive.
Moreover,                                   Z ∞
                    λM̃t φ(x) = M̃t Fφ(x) =     exp(−as)M̃t+s φ(x)ds,
                                                        0

where the right-side follows from Tonelli’s Theorem. Hence
                                                                      Z    t
                      λM̃t φ(x) = exp(at)Fφ(x) − exp(at)                       exp(−as)M̃s φ(x)ds
                                                                      Z0   t
                                = exp(at)λφ(x) − exp(at)                       exp(−as)M̃s φ(x)ds
                                                                       0


For a fixed x, define the function of t:

                                         g(t) = exp(−at)M̃t φ(x).

Then                                                        Z   t
                                         λg(t) = λφ −               g(s)ds
                                                            0

and g(0) = φ(x). The unique solution to this integral equation is
                                                               
                                                      t
                                         g(t) = exp −                φ(x).
                                                      λ

      We now show that φ is an eigenfunction of the extended generator for the multiplica-
 14
      F is a special case of a resolvent operator.



                                                       37
tive functional {M̃ }. Consider
                                                          Z t
                             .                           1
                         Ñt = M̃t φ(Xt ) − φ(X0 ) − a −        M̃s φ(Xs )ds.
                                                         λ   0


Take expectations conditioned on Fu for 0 ≤ u < t,
                                                                          Z u
                                         1                                 1
 E Ñt |Fu           = exp (t − u) a −          M̃u φ(Xu ) − φ(X0 ) − a −           M̃s φ(Xs )ds
                                          λ Z                               λ    0
                                               t                    
                               1                                      1
                       − a−         M̃u φ(Xu )     exp (s − u) a −         ds
                               λ              u       Z u           λ
                                                     1
                     = M̃u φ(Xu ) − φ(X0 ) − a −            M̃s φ(Xs )ds
                                                     λ   0
                     = Ñu ,

which proves that {Ñt } is a martingale.
   Since φ satisfies:
                                                           
                                h                        i 1
                           E M̃t φ(Xt )|X0 = x = exp t a −      φ(x),
                                                           λ
                                                              
                                                              1
               E [Mt V (Xt )W (Xt )φ(Xt )|X0 = x] = exp t a −      V (x)W (x)φ(x).
                                                              λ
Therefore, V (x)W (x)φ(x) is the eigenfunction of interest. Finally, φW is bounded be-
cause of inequality (18).

    Proposition 10.1 shows that a principal eigenfunction exits. Moreover, as is evident
from the proof, the resulting M̂ is martingale, not just a local martingale. Also, the proof
gives us some further insights into the probability distribution implied by M̂ . Using the
parametrization in the proof, represent the principal eigenfunction as V W φ. Since W
is a norm-like function and W φ is bounded, φ1 is a norm-like function. Let ρ be the
corresponding principal eigenvalue of the extended generator. Rewrite equation (18) in
the proof as:
     hR                                                    i
           ∞                          1
Ê        0
               exp[−(a − ρ)t]       φ(Xt )
                                                 dt|X0 = x
                                                                      Z   ∞                                  
                                                                                       V (Xt )W (Xt )
                                                                  =     exp(−at)E Mt                  |X0 = x
                                                                     0               V (x)W (x)φ(X0 )
                                                                        1
                                                                  ≤
                                                                    φ(x)W (x)

                                                                 38
The operator on the left is a resolvent operator applied to the norm-like function φ1 . It
is obtained by taking the Laplace transform of the semigroup. We may use the stability
methods of Down et al. (1995) to establish the stationarity of X under the distorted
distribution and the convergence of the conditional expectation operators. Thus the
approximation method developed in section 9 is applicable using the eigenfuntion shown
to exist by Proposition 10.1.15


11      Long-Term Risk
A familiar result from asset pricing is the characterization of the short term risk return
tradeoff. This tradeoff reflects the compensation, expressed in terms of expected returns,
from being exposed to risk in the short run. Continuous time models of financial markets
are revealing because they give a sharp characterization of this tradeoff by looking at
the instantaneous limits. Our construction of valuation functionals in section 5 reflects
this tradeoff in a continuous time Markov environment. Formally, the tradeoff is given
in Corollary 5.1. In this section we explore another extreme, the tradeoff pertinent for
the long run.
    In the study of dynamical systems, long run analysis gives an alternative characteri-
zation that reveals different features from the short run dynamics. For linear systems it
is easy to move from the short run to the long run. Nonlinearity makes this transforma-
tion much less transparent. This is precisely why operator methods are of value. It has
long been recognized that steady state analysis provides a useful characterization of a
dynamical system. For Markov processes the counterpart to steady state analysis is the
analysis of a stationary distribution. We are led to a related but distinct analysis for two
reasons. First, we consider economic environments with stochastic growth. Second, our
interest is in the behavior of valuation, including valuation of cash flows with long run
risk exposure. These differences lead us to study stochastic steady distributions under
alternative probability measures.
    As we have seen, these considerations lead naturally to the study of multiplicative
semigroups that display either growth in expectation or decay in value. The counterpart
to steady state analysis is the analysis of the principal eigenvalues and eigenfunctions,
the objects that characterize the long run behavior of multiplicative semigroups. We
  15
    As in our discussion Liapunov functions in section 9, we are presuming that compact subsets of the
state space are petite.


                                                 39
use appropriately chosen eigenvalues and eigenfunctions to change probability measures.
Changing probability measures associated with positive martingales are used extensively
in asset pricing. Our use of this tool is distinct from the previous literature because of
its role in long run approximation.
    We now explore three alternative applications.


11.1    Decomposition of stochastic discount factors (M = S)
Alvarez and Jermann (2005) characterize the long run behavior of stochastic discount
factors. Their characterization is based on a multiplicative decomposition on a perma-
nent and a transitory component (see their Proposition 1). Corollary 8.1 delivers this
decomposition, which we write as:

                                                   φ(X0 )
                                 St = exp(ρt)M̂t                                     (19)
                                                   φ(Xt )

for some martingale M̂ . The eigenvalue ρ is typically negative. We illustrated that
such a decomposition is not unique. For such a decomposition to be useful in long-run
approximation, the probability measure implied by martingale M̂ must imply that the
process X remains stationary. Proposition 9.2 shows that only one such representation
implies that the process X remains recurrent and stationary under the change of measure.
    Decomposition (19) of a stochastic discount factor funcational shows how to extract
a deterministic growth component and a martingale component from the stochastic dis-
count factor functional. Long run behavior is dominated by these two components vis a
vis a transient component. Hansen et al. (2005) show that the transient component can
often include contributions from habit persistence or social externalities as modeled in
the asset pricing literature. As featured by Alvarez and Jermann (2005), this stochastic
discount factor decomposition can be used to approximate prices of long term discount
bonds:                                                       
                                                         1
                         exp(−ρt)E (St |X0 = x) ≈ Ê            φ(x)
                                                       φ(Xt )
Thus φ is the dominant pricing factor in the long run. This approximation result extends
more generally to stationary cash flows as characterized by Proposition 9.1.




                                           40
11.2     Changing valuation functionals (M = V )
Alternative valuation functionals imply alternative risk exposures and growth trajecto-
ries. For one version of a long term risk return frontier, we change the risk exposure of
the valuation functional subject to pricing restriction (7). This gives a family of valu-
ation functionals that are compatible with a single stochastic discount factor. We may
then apply the decomposition in Corollary 8.1 restricted so that the distorted Markov
process is stationary to find a corresponding growth rate associated with each of these
valuation functionals. Thus alternative valuation functionals as parameterized by the
triple (βv , γv , κv ) and restricted by the pricing restriction of Proposition 5.1 imply return
processes with different long-run growth rates. The principle eigenvalues of the corre-
sponding semigroups give these rates. In effect the valuation functionals can be freely
parameterized by their risk exposure pair (γv , κv ) with βv determined by the local pricing
restriction. The vector γv gives the exposure to Brownian risk and κv the exposure to
jump risk.
    Thus a long run risk-return frontier is given by the mapping from the risk exposure
pair (γv , κv ) to the long run growth rate of the valuation process. The growth rate may
be computed by solving an eigenvalue problem that exploits the underlying Markovian
dynamics. This characterizations allows us to move beyond the log-linear, log-normal
specification implicit in many studies of long-horizon returns. The dominant eigenvalue
calculation allows for conditional heteroskedasticity with long run consequences and it
allows jumps that might occur infrequently. The principal eigenfunction (along with the
eigenvalue) can be used to construct the martingale component as in Corollary 8.1.

Example 11.1. Application to the Markov diffusion example
    Recall that in Breeden’s model and the Kreps-Porteus model, the implied stochastic
discount factor is St = exp(Ast ) where
                            Z       t                    Z       t                  Z tq            Z t
                                                                                         f s
           Ast       s
                 = β̄ t +               βfs Xsf ds   +               βos Xso ds   +             f
                                                                                        Xs γf dBs +     γos dBso   (20)
                                0                        0                           0                 0


where the alternative models give rise to alternative interpretations of the parameters.
To parameterize a valuation functional V = exp(Av ), we construct
                            Z       t                    Z       t                  Z tq            Z t
                                                                                         f v
           Avt      v
                 = β̄ t +               βfv Xsf ds   +               βov Xso ds   +             f
                                                                                        Xs γf dBs +     γov dBso
                            0                                0                       0                 0




                                                                         41
where

                                                                xf s            1
         β̄ v + βfv xf + βov xo = −β̄ s − βfs xf − βos xs −       (γf + γfv )2 − (γos + γov )2 .
                                                                2               2

This equation imposes the local risk-return relation and determines β̄ v , βfv and βov as a
function of the stochastic discount factor parameters and the risk exposure parameters γfv
and γov .
    To infer the growth rates of valuation processes parameterized by (γfv , γov ), we find the
principal eigenvalue for the multiplicative semigroup formed by setting M = V . Applying
the calculation in Example 8.2, this eigenvalue is given by

                                (γov )2                                                σ2
                  ρv = β̄ v +           + cvf ξf x̄f + cvo (ξo x̄o + γov σo ) + (cvo )2 o .
                                  2                                                     2

where cvf and cvo are given by formulas (15) and (16) respectively. The terms on the right-
hand side exclusive of cvf ξf x̄f give the continuous time log-normal adjustments, while
cvf ξf x̄f adjusts for the stochastic volatility in the cumulative return. A long-run risk
return tradeoff is given by mapping of (γfv , γov ) into the eigenvalue ρv .


11.3     Changing cash flows (M = G,M = GV )
Consider next a risky cash flow of the form:

                                          Dt = Gt ψ(Xt )D0

where G is a multiplicative functional. This cash flow grows over time. We could parame-
terize the multiplicative functional as the triple (βg , γg , κg ), but this over-parameterizes
the long-term risk exposure. The transient components to cash flows will not alter the
long run risk calculation. One attractive possibility is to apply Corollary 8.1 and Propo-
sitions 9.1 and 9.2 with (M = G) and use the martingale from that decomposition for our
choice of G. Thus we could impose the following restriction on the G parameterization:

                             |γg |2
                                         Z
                        βg +        +        (exp [κg (y, ·)] − 1) η(dy, ·) = δ
                               2

for some positive growth rate δ. Given δ this relation determines a unique βg . In addition
we restrict these parameters so that the distorted probability measure associated with


                                                    42
an extended generator built from:

a) jump measure: exp [κg (y, x)] η(dy|x).

b) first derivative term: ξ(x) + Γ(x)γg (x);

c) second derivative term: Σ(x);

imply a semigroup conditional expectation operators that converge to the corresponding
unconditional expectation operator.
    Hansen et al. (2005) explore the valuation consequences by constructing a semigroup
using M = GS where S is a stochastic discount factor functional. They only consider
the log-linear/log-normal model, however. Provided that we can apply Proposition 9.1
for this choice of M and ψ, the negative of the eigenvalue −ρ is the overall rate of decay
in value of the cash flow.
    Consider an equity with cash flow D. For appropriate specifications of ψ, the values
of the cash flows far into the future are approximately proportional to the eigenfunction
                         1
φ. Thus we may view −ρ      as the limiting contribution to the price dividend ratio. The
decay rate ρ reflects both a growth rate effect and discount rate effect. To net out the
growth rate effect, we compute −ρ + δ as an asymptotic rate of return that encodes a
risk adjustment. Heuristically, this is linked to Gordon growth model because −ρ is the
difference between the asymptotic rate of return −ρ + δ and the growth rate δ.
    Following Hansen et al. (2005), we explore the consequences of altering the cash flow
risk exposure. Such alterations induce changes in the asymptotic decay rate in value
                                                        1
(−ρ) and hence in the long-run dividend price ratio −ρ    and the asymptotic rate of return
−ρ + δ. The long-run cash flow risk return relation is captured by the mapping from the
cash flow risk exposure pair (γg , κg ) to the corresponding required rate of return −ρ + δ.
    Hansen et al. (2005) use this apparatus to produce such a tradeoff using empirical
inputs in a discrete-time, log linear environment. The formulation developed here al-
lows for extensions to include nonlinearity in conditional means, heteroskedasticity that
contributes to long run risk and large shocks modeled as jump risk.

Example 11.2. Application to the Markov diffusion example
   Returning to the Breeden model or the Kreps-Porteus model, suppose the growth
process G is the exponential of the additive functional:

                                                                                    Xsf (γfg )2 + (γog )2
                           Z tq                      Z   t                  Z   t
            Agt   = δt +          Xsf γfg dBsf   +           γog dBso   −                                 ds.
                           0                         0                      0                 2

                                                         43
The parameters γfg and γfo parameterize the cash flow risk exposure. We limit the cash
flow risk exposure by the inequality:

                                                2(ξf + σf γfg )x̄f ≥ σf2 .

This limits the martingale component so that it induces stationarity under the probability
measure induced by the M̂ associated with M = G.
   We use again the parameterization St = exp(Ast ) where Ast is given by (20). Hence
A = As + Ag is given by
                          Z     t                   Z   t                 Z tq            Z t
                                                                               f
            At = β̄t +              βf Xsf ds   +           βo Xso ds   +             f
                                                                              Xs γf dBs +     γo dBso
                            0                       0                         0              0

                 g 2                      (γ g )2
here β̄ = δ − (γo2 ) + β̄ s , βf = f2 + βfs , βo = βos , γf = γfg + γfs and γo = γog + γos . The
formulas given in Example 8.2 discussed previously give us an asymptotic, risk adjusted
rate of return,

                       (γos )2                                                                      σ2
       −ρ + δ = −              − γos γog − β̄ s − cf ξf x̄f − co [ξo x̄o + (γog + γos )σo ] − (co )2 o .
                         2                                                                           2

Recall that co = βos /ξo and cf is a solution to a quadratic equation (15). This allows us
to map exposures to the risks B o and B f into asymptotic rates of return. For instance,
the long run risk prices to the cash flow risk exposure to the B o risk is:

                                                                     βos
                                                        −γos −           σo
                                                                     ξo

Because volatility is state dependent, the cash flow risk exposure to B f is encoded in the
coefficient cf of the eigenfunction. Since this coefficient depends on γfg in a nonlinear
manner, there is nonlinearity in the long-run price of the volatility risk.

Hansen (2006) gives some other continuous time examples motivated by the work of
Hansen et al. (2005) and Lettau and Wachter (2005) on cash flow risk and duration.
   Hansen et al. (2005) also decompose the one period return risk to equity into a
portfolio of one-period holding period returns to cash flows. Consider a cash flow of the
form:
                                    Dt = D0 Gt ψ(Xt )



                                                                44
where G is a multiplicative growth functional. The limiting gross return is given by:

                            E (St Dt /S1 |F1 )             φ(X1 )
                         lim                   = exp(−ρ)G1
                        t→∞  E(St Dt |F0 )                 φ(X0 )

where ρ and φ are the principal eigenvalue and eigenfunction of the semigroup constructed
using M = GS. This limit presumes that Êψ(Xt ) is positive. The limiting holding period
return has a cash flow growth component G1 , an eigenvalue component exp(−ρ) and an
eigenfunction component φ(X  1)
                          φ(X0 )
                                 . The limit is independent of the transient contribution to
the cash flow provided that assumptions of Proposition 9.1 are satisfied.


12     Conclusions
In this paper we characterized the long run risk-return relationship for nonlinear con-
tinuous time Markov environments. This long term relationship shows how alternative
cash flow risk exposures are encoded in asymptotic risk-adjusted discount rates. To
achieve this characterization we decompose a multiplicative functional built from the
Markov process into the product of three components: (i) a deterministic exponential
trend, (ii) a martingale whose logarithms has stationary increments and (iii) a transitory
component. The transitory component is constructed from the principal eigenfunction
evaluated of the semigroup associated with the multiplicative functional, and the rate of
growth of the exponential trend is given by the corresponding eigenvalue. Hence we were
led to study Frobenius-Perron notions of domination of semigroup.
    There are several natural extensions of this work. First, while we have established
existence and uniqueness of principal eigenvalues and eigenfunctions, it remains impor-
tant to develop methods for computing these objects. There are only a limited array
of examples for which quasi analytical solutions are currently available. We suspect
that the weighted spaces we used in section 10 to establish existence will be helpful
for computation. Second, while we have focused on dominant eigenvalues, more refined
characterizations are needed to understand how well long run approximation works and
how it can be improved. Results in Chen et al. (2005) could be extended and applied to
achieve more refined characterizations, at least the case of multivariate diffusions. Third
we considered only processes with a finite number of jumps in any finite interval of time.
Extending this Frobenius-Perron theory to more general Levy processes may add new
insights into characterizing long-term risk.


                                            45
A        Full generator
For a given multiplicative functional M , let L̃ be the space of all real valued functions ψ
such that for every t ≥ 0,
                                 sup E[Ms |ψ(Xs )|] < ∞.
                                 0≤s<t

Consider a semigroup
                             Mt ψ(x) = E [Mt ψ(Xt )|X0 = x] .

Heuristically, we wish to compute a derivative with respect to time

                                               Mt ψ(x) − ψ(x)
                               χ(x) = lim                     .
                                         t↓0          t

Formally, we use the operator counterpart of the relation between an integral and its
derivative to define what is referred to as the full generator.
Definition A.1. The full generator of the semigroup {Mt : t ≥ 0} is the subset of
functions                                   Z t       
                     A = (ψ, χ) : Mt ψ − ψ =     Ms χds .
                                                         0
    This notion of a generator is an extension of the generator given in section 7. Specif-
ically, if ψ is in D(U), the pair (ψ, Uψ) is in the full generator A. (See Davies (1980)
Proposition 1.2.) The next Proposition establishes that the extended generator A extends
the full generator.
                                                                       Rt
Proposition A.1. If (ψ, χ) ∈ A then Nt = Mt ψ(Xt ) − ψ(X0 ) − 0 Ms χ(Xs )ds is a
martingale with respect to the filtration {Ft : t ≥ 0}.
Proof.
                                                                 Z   t+u        
                                   E[Mt+u ψ(Xt+u )|Ft ] − E        Ms χ(Xs )ds|Ft =
                                                              0
                               Z t                 Z t+u                         
 Mt E [Mu (θt )ψ(Xt+u )|Ft ] −     Ms χ(Xs )ds − E        Mt Ms−t (θt )χ(Xs )ds|Ft =
                                0                    t
                                   Z u             Z t
                 Mt Mu ψ(Xt ) −         Ms χ(Xt )ds −      Ms χ(Xs )ds = Nt + ψ(X0 ),
                                    0                        0


since (ψ, χ) ∈ A.

    .

                                                46
B       Martingales and Absolute Continuity
In this appendix we state some conditions that insure that Assumption 8.1 holds. Our
result is inspired by the approach developed in chapter 7 of Liptser and Shiryaev (2000).
Let M̂ denote a multiplicative functional parameterized by (β̂, γ̂, κ̂) that is restricted to
be a local martingale. Thus M̂ = exp(Â) where
        Z   t             Z t                                                         X
Ât =           β̂(Xu )du+ γ̂(Xu− )0 [Γ(Xu− )0 Γ(Xu− )]−1 Γ(Xu− )0 [dXuc −ξ(Xu− )du]+   κ̂(Xu , Xu− ),
        0                        0                                                                        0≤u≤t


and

Assumption B.1.

                                        |γ̂|2
                                                       Z
                                  −β̂ −       −            (exp[κ̂(y, x)] − 1) η(dy|x) = 0.
                                          2

    The extended generator for M̂ is given by:

                                                             ∂ 2 φ(x)
                                                                     
                                      ∂φ(x)    1
        Âφ(x) = [ξ(x) + Γ(x)γ̂(x)] ·       +    trace Σ(x)
                                       ∂x     Z2             ∂x∂x0
                                            +     [φ(y) − φ(x)] exp[κ̂(y, x)]η(dy|x).


Assumption B.2. There exists a probability space (Ω̌, F̌, P̌ r), a filtration F̌t , an n-
dimensional F̌t Brownian motion B̌ and a semi-martingale X̌ = X̌ c + X̌ j , where

                                 dX̌tc = [ξ(X̌t− ) + Γ(X̌t− )γ̂(X̌t− )]dt + Γ(X̌t− )dB̌t                             (21)

and X̌ j is a pure jump process with a finite number of jumps in any finite interval that
has a compensator exp[κ̂(y, X̌t− )]η(dy|X̌t− )dt

In this case,

            dB̌t = [Γ(X̌u− )0 Γ(X̌u− )]−1 Γ(X̌u− )0 dX̌uc − ξ(X̌u− )du − Γ(X̌u− )γ̂(X̌u− )du .
                                                                                           


    Use the process X̌ to construct a multiplicative functional M̌ = exp(Ǎ) where
                  Z    t                  Z   t
Ǎt = −                    β̂(X̌u )du −           γ̂(X̌u− )0 [Γ(X̌u− )0 Γ(X̌u− )]−1 Γ(X̌u− )0 [dX̌uc − ξ(X̌u− )du]
                   0                      0


                                                                  47
                X
         −              κ̂(X̌u , X̌u− )
               0≤u≤t
               Z th                             i
                                            2
     = −               β̂(X̌u ) + |γ(X̌u− )|        du
               Z0 t
         −   γ̂(X̌u− )0 [Γ(X̌u− )0 Γ(X̌u− )]−1 Γ(X̌u− )0 [dX̌uc − ξ(X̌u− )du − Γ(X̌u− )γ̂(X̌u− )du]
           0
           X
         −      κ̂(X̌u , X̌u− ).
               0≤u≤t


   The multiplicative functional M̌ is parameterized by:

                                                    β̌ = −β̂ − |γ̂|2
                                                    γ̌ = −γ̂
                                                    κ̌ = −κ̂.

Assumption B.3. The parameterization (β̌, γ̌, κ̌) of the multiplicative functional M̌ sat-
isfies:
    Rt
a) 0 β̌(X̌u )du < ∞ for every positive t;
    Rt
b) 0 |γ̌(X̌u )|2 du < ∞ for every positive t.
Notice that                       Z                               Z
                                      exp[κ̌(y, x)]η̂(dy|x) =         η(dy|x) < ∞

for all x ∈ D0 . Moreover,

     |γ̌|2                                                 |γ̂|2
               Z                                                         Z
β̌ +       +          (exp[κ̌(y, x)] − 1) η̂(dy|x) = −β̂ −       −            (exp[κ̂(y, x)] − 1) η(dy|x) = 0.
       2                                                     2

Thus the multiplicative functional M̌ is a local martingale.
Proposition B.1. Suppose that assumptions B.1, B.2 and B.3 are satisfied. Then the
local martingale M̂ is a martingale.
Proof. We show that M̂ is a martingale in three steps:
  i) Since M̌ is a local martingale, there is an increasing sequence of stopping times
     {τ̌N : N = 1, ...} that converge to ∞ such that
                                                             (
                                                               M̌t t ≤ τ̌N
                                                    M̌tN =
                                                              M̌τ̌N t > τ̌N

                                                             48
    is a martingale and
                                        Ě(M̌tN |X̌0 = x) = 1

    for all t ≥ 0.
                                                                  
ii) Next we obtain an alternative formula for Ě 1{t≤τ̌N } |X0 = x represented in terms
    of the original X process. The stopping time τ̌N can be represented as a function of
    X̌. Let τN be the corresponding function of X, and construct:
                                                 (
                                                    M̂t t ≤ τN
                                      M̂tN =                   .
                                                   M̂τN t > τN

    Recall that
                                               M̂tN = Φt (X)

    for some Borel measurable function Φt . By construction,

                                                             1
                                               Φt (X̌) =
                                                            M̌tN

    Then
                                                                            
                  E M̂t 1{t≤τN } |X0 = x        = E        M̂tN 1{t≤τN } |X0
                                                                         =x
                                                                                      
                                                        N       1
                                                = Ě M̌t              1{t≤τ̌N } |X̌0 = x
                                                              M̌tN      
                                                = Ě 1{t≤τ̌N } |X̌0 = x

    where the second equality follows from the Girsanov Theorem.

iii) Note that
                                     lim Ě(1{τ̌N ≤t} |X̌0 = x) = 1
                                  N →∞

    by the Dominated Convergence Theorem. Thus

           E(M̂t |X0 = x) ≥ lim E(M̂t 1{τN ≤t} |X0 ) = lim Ě(1{τ̌N ≤t} |X̌0 = x) = 1.
                              N →∞                                 N →∞


    Since M̂ is a nonnegative local martingale, we know that

                                        E(M̂t |X0 = x) ≤ 1.


                                                  49
Therefore E(M̂t |X0 = x) = 1 for all t ≥ 0 and M̂ is a martingale.




                                      50
References
Alvarez, F. and U. Jermann. 2005. Using Asset Prices to Measure the the Persistence in the Marginal
  Utility of Wealth. Econometrica 73:1977–2016.

Anderson, E. W., L. P. Hansen, and T. J. Sargent. 2003. A Quartet of Semigroups for Model Specification,
  Robustness, Prices of Risk and Model Detection. Journal of the European Economic Association 1.

Backus, D. and S. Zin. 1994. Reverse Engineering the Yield Curve. NBER Working Paper No. 4676.

Balaji, S. and S. P. Meyn. 2000. Multiplicative Ergodicity and Large Deviations for an Irreduciable
  Markov Chain. Stochastic Processes and their Applications 90:123–144.

Bansal, Ravi and Amir Yaron. 2004. Risks for the Long Run: A Potential Resolution of Asset Pricing
  Puzzles. Journal of Finance 59 (4):1481–1509.

Bharttacharya, R. N. 1982. On the Functional Central Limit Theorem and Law of the Iteratered
  Logarithm for Markov Processes. Zietschrift for Wahrscheinlichkeits-theorie und verwandte Gebeite
  60.

Bonsall, F. F. 1963. Linear Operators in Complete Positive Cones. Proceedings of the London Mathe-
  matical Society 53–75.

Breeden, D. 1979. An Intertemporal Asset Pricing Model with Stochastic Consumption and Investment
  Opportunities. Journal of Financial Economics 7:265–296.

Chen, X., L. P. Hansen, and J. Scheinkman. 2005. Principal Components and the Long Run. University
  of Chicago.

Davies, E. B. 1980. One-Parameter Semigroups. Academic Press.

Down, D., S. P. Meyne, and R. L. Tweedie. 1995. Exponential and Uniform Ergodicity of Markov
  Processes. Annals of Probability 23:1671–1691.

Duffie, D. and L. Epstein. 1992. Stochastic Differential Utility. Econometrica 60:353–394.

Duffie, D., J. Pan, and K. J. Singleton. 2000. Transform Analysis and Asset Pricing for Affine Jump-
  Diffusions. Econometrica 68:1343–1376.

Ethier, S. N. and T. G. Kurtz. 1986. Markov Processes: Characterization and Convergence. New York:
  John Wiley and Sons.

Garman, M. B. 1984. Towards a Semigroup Pricing Theory. Journal of Finance 40:847–861.

Hansen, L. P. 2006. Modeling the Long Run: Valuation in Dynamic Stochastic Economies. Fisher-Schultz
  Lecture presented in the European Meetings of the Econometric Society.



                                                  51
Hansen, L. P. and J. A. Scheinkman. 1995. Back to the Future: Generating Moment Implications for
  Continuous-Time Markov Processes. Econometrica 63:767–804.

Hansen, L. P., J. C. Heaton, and N. Li. 2005. Consumption Strikes Back?: Measuring Long Run Risk.
  University of Chicago.

Kontoyiannis, I. and S. P. Meyn. 2003. Spectral Theory and Limit Theorems for Geometrically Ergodic
  Markov Processes. ANNAP 13:304–362.

———. 2005. Large deviations asymptotics and the spectral theory of multiplicatively regular Markov
 processes. Electron. J. Probab. 10 (3):61–123 (electronic).

Krasnosel’skij, M. A., J. A. Lifshits, and A. V. Sobolev. 1989. Positive Linear Systems: The Method of
  Positive Operators. Sigma Series in Applied Mathematics. Berlin: Heldermann Verlag.

Krein, M. G. and M. Q. A. Rutman. 1948. Linear Operators Leaving Invariant a Cone in a Banach
  Space. Uspehi Mat. Nauk (N.S.) 3 (1(23)):3–95.

Kreps, D. M. and E. L. Porteus. 1978. Temporal Resolution of Uncertainty and Dynamic Choice.
  Econometrica 46:185–200.

Lettau, M. and J. A. Wachter. 2005. Why is Long-Horizon Equity Less Risky? A Duration-Based
  Explanation of the Value Premium. Journal of Finance forthcoming.

Liptser, R. S. and A. N. Shiryaev. 2000. Statistics of Random Processes: I. General Theory. Applications
  of Mathematics: Stochastic Modelling and Applied Probability. Berlin: Spriger, 2nd ed.

Meyn, S. P. and R. L. Tweedie. 1992. Stability of Markovian Processes I: Criteria for Discrete-Time
  Chains. Advances in Applied Probability 24:542–574.

———. 1993a. Stability of Markovian Processes II: Continuous-Time Processes and Sampled Chains.
 Advances in Applied Probability 25:487–517.

———. 1993b. Stability of Markovian Processes III: Foster-Lyapunov Criteria for Continuous Time
 Processes. Advances in Applied Probability 25:518–548.

Nelson, E. 1958. The Adjoint Markov Process. Duke Mathematical Journal 25:671–690.

Nummelin, E. 1984. General Irreducible Markov Chains and Non-negative Operators. Cambridge: Cam-
  bridge University Press.

Protter, P. E. 2005. Stochastic Integration and Differential Equations: A New Approach. Springer.

Revuz, D. and M. Yor. 1994. Continuous Martingales and Brownian Motion. Berlin: Springer-Verlag,
  second ed.




                                                  52
Rogers, L. C. G. 1998. The Origins of Risk-neutral Pricing and the Black-Scholes Formula. In Risk
  Management and Analysis, edited by C. O. Alexandre, Wiley, and Chichester, chap. 2, 81–94. Wiley?

Schroder, M. and C. Skiadas. 1999. Optimal Consumption and Portfolio Selection with Stochastic
  Differential Utility. Journal of Economic Theory 89:68–126.




                                                53
