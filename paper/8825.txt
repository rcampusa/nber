                                     NBER WORKING PAPER SERIES




    IS THE THREAT OF REEMPLOYMENT SERVICES MORE EFFECTIVE THAN THE
    SERVICES THEMSELVES? EXPERIMENTAL EVIDENCE FROM THE UI SYSTEM


                                                   Dan A. Black
                                                  Jeffrey A. Smith
                                                  Mark C. Berger
                                                    Brett J. Noel


                                              Working Paper 8825
                                      http://www.nber.org/papers/w8825


                          NATIONAL BUREAU OF ECONOMIC RESEARCH
                                   1050 Massachusetts Avenue
                                     Cambridge, MA 02138
                                         March 2002

We thank the U.S. Department of Labor for financial support through a contract between the Kentucky Department of
Employment Services and the Center for Business and Economic Research at the University of Kentucky. Smith also
thanks the Social Science and Humanities Research Council of Canada for financial support. We thank Bill Burris,
Donna Long, and Ted Pilcher of the Kentucky Department of Employment Services for their assistance, and Steve Allen,
Susan Black, Amitabh Chandra, and Roy Sigafus for research assistance. Seminar participants at Boston University,
Colorado, Cornell, the Econometric Society meetings, Houston, Indiana, the Institute for Fiscal Studies, Louisiana State,
Maryland, MIT, Missouri, Ohio State, the Society of Labor Economists meetings, the Stockholm School of Economics,
SUNY-Buffalo, Syracuse, the Tinbergen Institute, UBC, the University of Toronto, the Upjohn Institute and the
University of Western Ontario provided useful comments. We especially thank Jaap Abbring, Joshua Angrist,
Christopher Taber and Bruce Meyer for their suggestions, along with two anonymous referees. The views expressed
herein are those of the authors and not necessarily those of the National Bureau of Economic Research.


© 2002 by Dan A. Black, Jeffrey A. Smith, Mark C. Berger and Brett J. Noel. All rights reserved. Short sections of text,
not to exceed two paragraphs, may be quoted without explicit permission provided that full credit, including © notice,
is given to the source.
Is the Threat of Reemployment Services More Effective than the Services Themselves?
Experimental Evidence from the UI System
Dan A. Black, Jeffrey A. Smith, Mark C. Berger and Brett J. Noel
NBER Working Paper No. 8825
March 2002
JEL No. H0, J6, C9



                                            ABSTRACT

         This paper examines the effect of the Worker Profiling and Reemployment Services (WPRS)
system. This program “profiles” UI claimants to determine their probability of benefit exhaustion (or
expected spell duration) and then provides mandatory employment and training services to claimants with
high predicted probabilities (or long expected spells). Using a unique experimental design, we estimate
that the WPRS program reduces mean weeks of UI benefit receipt by about 2.2 weeks, reduces mean UI
benefits received by about $143, and increases subsequent earnings by over $1,050. Much (but not all)
of the effect results from a sharp increase in early exits from UI in the experimental treatment group
compared to the experimental control group. These exits coincide with claimants finding out about their
mandatory program obligations rather than with actual receipt of employment and training services. While
the program targets those with the highest expected durations of UI benefit receipt, we find no evidence
that these claimants benefit disproportionately from the program. In addition, we find strong evidence
against the “common effect” assumption, as the estimated treatment effect differs dramatically across
quantiles of the untreated outcome distribution. Overall, the profiling program appears to successfully
reduce the moral hazard associated with the UI program without increasing the take-up rate.



Dan A. Black                                                    Jeffrey A. Smith
Center for Policy Research                                      Department of Economics
426 Eggers Hall                                                 University of Maryland
Syracuse University                                             3105 Tydings Hall
Syracuse, NY 13244-1020                                         College Park, MD 20742
danblack@maxwell.syr.edu                                        and NBER
                                                                smith@econ.umd.edu

Mark C. Berger                                                  Brett J. Noel
Department of Economics                                         American Express - TRS
Gatton College of Business and Economics                        10030 North 25th Avenue
University of Kentucky                                          Building 10400
Lexington, KY 40506-0034                                        Phoenix, AZ 85021
mberger@pop.uky.edu                                             Brett.J.Noel@aexp.com
1 Introduction
It is well known that the UI system provides incentives for workers to lengthen their spells of

unemployment by providing a subsidy to their job search and leisure. This paper examines the

behavioral effects of a new program that “profiles” Unemployment Insurance (UI) claimants

based on the predicted length of their unemployment spell or the probability that they will

exhaust their UI benefits. Established in 1993 and formally called the “Worker Profiling and

Reemployment Services” (WPRS) system, the program forces claimants with long predicted UI

spells or high predicted probabilities of benefit exhaustion to receive employment and training

services early in their spell in order to continue receiving benefits. 1

        We consider the effects of the profiling program on claimant behavior using data from

Kentucky. Our data embody a unique experimental design. The randomization in our

experiment occurs only to satisfy capacity constraints and only at the margin. UI claimants are

assigned “profiling scores” that take on integer values from 1 to 20, with higher scores indicating

claimants with longer expected durations. The requirement to receive reemployment services is

allocated by profiling score up to capacity. Within the marginal profiling score – the one at

which the capacity constraint is reached – random assignment allocates the mandatory services

requirement. Thus, if there are 10 claimants with a profiling score of 11 but only seven

remaining slots, seven claimants are randomly assigned to the treatment group and three are

assigned to the control group.

        Campbell (1969) terms this experimental design a “tie-breaking experiment.” Apparently,

Thistlethwaite and Campbell (1960) first advocated it as a means of evaluating the impact of




1
  See U.S. Department of Labor (1999) for a more detailed description of the program and of how it varies across
states. See Blackmore and Welsh (1983) for a description of a related debate regarding statistical models for
sentencing in the criminology literature.
                                                                                                                     2

receiving a college scholarship. 2 To our knowledge, our experiment is the first to use this

design. In general, the “tie-breaking experiment” does not directly identify many commonly

estimated parameters, such as the impact of treatment on the treated. Instead, further

assumptions are required, which we discuss in Section 4.

        A large empirical literature provides evidence consistent with the view that UI reduces

the incentive to find a job quickly. For example, Meyer (1990) documents spikes in the empirical

hazard function as workers approach the exhaustion of their UI benefits, and Card and Levine

(2000) and Noel (1998) document that increasing the length of time that claimants may receive

benefits causes the empirical hazard function to fall substantially. 3 Looking at search behavior

directly, Barron and Mellow (1979) find that those workers receiving UI searched 1.6 fewer

hours per week than unemployed workers not receiving payments. St. Louis, Burgess, and

Kingston (1986) offer compelling evidence that claimants systematically violate the search

requirements that UI imposes.

        Several policies have modified the system by reducing the incentives for excess benefit

receipt while at the same time not punishing workers for whom a longer search is optimal. The

reemployment bonus experiments surveyed in Meyer (1995) tested one such policy. In these

studies, claimants who find a job quickly and keep it receive a cash payment. 4 These

experiments indicate that the unemployment spells of UI claimants can be shortened without loss

of post-program earnings. 5 Though reemployment bonuses reduce the length of UI spells, they

prove expensive because many claimants receive bonuses who would have exited quickly


2
  We thank Joshua Angrist for bringing these citations to our attention. Campbell (1969) notes the relationship
between the “tie-breaking experiment” and the regression discontinuity design. See Heckman, LaLonde and Smith
(1999) and Angrist and Krueger (1999) for discussions of the regression discontinuity design.
3
  See also Ehrenberg and Oaxaca (1976), Moffitt (1985), Katz and Meyer (1990) and many others.
4
  In the Illinois experiment, for a subset of the treatment group it was the employer rather than the employee who
received the bonus. This form of the bonus had a much lower utilization rate and was omitted from subsequent
experiments.
                                                                                                                    3

without them. Moreover, Meyer argues convincingly that permanent adoption of reemployment

bonuses would substantially increase the UI take-up rate as eligible persons who expect short

spells and who do not at present file for benefits would do so in order to collect the bonus. This

response would further increase the cost of the program without increasing its benefits. 6

        While the UI bonus schemes represent a “carrot” designed to lure claimants back into

employment, other experiments used “sticks,” such as greater enforcement of UI job search

requirements, to push claimants who could find work back into employment by raising the costs

of staying on UI. Ashenfelter, Ashmore and Deschênes (1999) present experimental evidence on

work search enforcement programs in four states that suggests at most a small deterrent effect.

Meyer (1995) reviews other experiments that examined programs that combined stricter

enforcement with job search assistance. These programs had stronger effects and passed

standard cost-benefit tests. Such “stick” policies have the potential to shorten UI spells without

causing the increases in the take-up rate generated by reemployment bonuses.

        The profiling program we examine in this paper combines aspects of both types of UI

reforms. For some claimants, the services they must receive may represent a “stick” that raises

the cost of staying on UI and thereby induces early exit. In essence, the services operate as a

leisure tax for these claimants. 7 For others, the services may represent a “carrot” that augments

their human capital and job search skills.

        We have four major findings. First, using our unique experimental data, we evaluate the

WPRS system for persons at the profiling score margin. We estimate that for this group, the

program reduces mean weeks of UI benefit receipt by about 2.2 weeks, reduces mean UI benefits


5
  See Anderson (1992), Decker (1994), Decker and O'Leary (1995) and Woodbury and Spiegelman (1987) for
analyses of the individual bonus experiments.
6
  O'Leary, Decker and Wandner (1998) propose using profiling to allocate eligibility for reemployment bonuses to
get around the problem of increases in the take-up rate and of subsidizing current claimants who would have short
spells even without the bonuses.
                                                                                                                  4

received by about $143, and increases subsequent earnings by about $1,000. Given its very low

cost, the program easily passes standard cost-benefit tests. Our findings suggest that programs

that combine carrots and sticks early on in a benefit spell may be more cost-effective than other

programs types, such as bonuses and tighter eligibility monitoring, examined in recent years.

           Second, the dynamics of the treatment effect provide important evidence about how the

program works. The experimental treatment group has significantly higher earnings in the first

two quarters after filing their UI claims than the control group, while there are no significant

differences in the third through sixth quarters. This suggests that the earnings gains result

primarily from earlier return to work in the treatment group. Moreover, examination of the exit

hazard from UI suggests that much of the impact results from persons in the treatment group

leaving UI upon receiving notice of the requirement that they receive reemployment services,

rather than during or after the receipt of those services. Thus, the program induces some job-

ready claimants to exit quickly, thereby reducing the extent of moral hazard in the UI program.

           Third, using the framework in Heckman, Smith, and Clements (1997) we estimate the

distribution of impacts from the WPRS treatment. We find strong evidence against the

“common effect” assumption in our data, as the estimated impact of treatment varies widely

across quantiles of the outcome distributions. The pattern of impacts suggests that the treatment

has its largest effect on persons whose spells without treatment would be of moderate duration.

           Fourth, we evaluate the use of profiling scores based on expected UI claim duration as a

means of allocating the treatment. If this is an efficient method of treatment allocation, we

would expect to find that the impact of treatment increases in the profiling score. Instead, we

find little evidence of any systematic relationship between the estimated impact of treatment and

the profiling score. This suggests that such profiling does not increase the efficiency of


7
    See, among others, Besley and Coate (1992), Coate, Johnson and Zeckhauser (1994) and Black and Smith (2001)
                                                                                                                   5

treatment allocation and indicates the potential value of further research on econometric

methods of treatment allocation before extending profiling to other programs. 8

         The paper proceeds as follows: In the next section, we describe the Kentucky WPRS

system and the design of the experiment. Section 3 presents a theoretical framework for our

investigation. Section 4 discusses the parameters of interest in evaluating the WPRS program and

indicates what assumptions are required to obtain estimates of these parameters using our data.

The fifth section analyzes the experimental data and the final section concludes.


2 How the WPRS System Works
States are afforded a great deal of leeway in the design and implementation of their WPRS

systems. In Kentucky, the Department of Employment Services contracted with the Center for

Business and Economic Research (CBER) of the University of Kentucky to develop an

econometric model of expected UI spell duration.

         CBER estimated the profiling model using five years of UI claimant data and variables

obtained from various administrative and public use data sets. The profiling model contains

local economic and labor market conditions along with worker characteristics. 9 U.S. Department

of Justice regulations prevent states from using sex, age, race, ethnicity, and veteran status in

their profiling models. While the econometric profiling model provides a continuous measure of

the expected number of weeks of benefit receipt, CBER provides the Department of Employment

Services with a discrete profile score ranging from 1 to 20. Claimants predicted by the profiling

model to exhaust between 95 and 100 percent of their unemployment benefits receive a score of


for discussions of leisure taxes and related issues such as work requirements in transfer programs.
8
  See Berger, Black, and Smith (2000) for a more detailed discussion of this issue.
9
  See Berger, Black, Chandra, and Allen (1997) for a more detailed description of the model. The profiling model
has moderate success in predicting claimants who will exhaust their UI benefits. Berger, et al. report that selection
based on the profiling model results in a treated group whose members receive 78.3 percent of their possible benefits
while random assignment would result in a treated group whose members receive only 66.6 percent of their possible
benefits. “Perfect” assignment based on realized spell lengths would yield a treatment group whose members
receive about 93 percent of their potential benefits.
                                                                                                              6

20, claimants predicted to exhaust between 90 and 95 percent of their unemployment benefits

receive a 19, and so on. The WPRS system was implemented in October of 1994; we make use

of UI spells starting between that date and June 30, 1996.

        The Kentucky WPRS system begins with claimants providing information about their

employment history and characteristics while filing their claims. For claimants found to be

eligible for profiling, the Kentucky DES provides CBER with data from the claimants' intake

forms. 10 CBER then provides local Department of Employment Services' offices with the

profiling scores of claimants in their area. Finally, those claimants selected to receive

reemployment services are contacted through the mail to inform them of their rights and

responsibilities under the program. A copy of the letter sent by the Department of Employment

Services appears in Exhibit 1.

        Because of capacity constraints, local offices at some times during the year are not able to

serve the entire population of claimants, making it necessary to ration entry into the program.

CBER allocates program slots at each local office, serving those claimants with the highest

profiling scores. In the marginal score group, where there are enough slots to serve some but not

all claimants with a given score, CBER randomly assigns persons to either an experimental

treatment group required to participate in reemployment services as a condition of continued UI

receipt or an experimental control group exempt from this requirement. We call these sets of

claimants “profiling tie groups,” or PTGs – groups of claimants in a given office filing claims in

a given week who have the marginal profiling score for that office in that week. This design

differs from typical experimental evaluations of employment and training programs wherein all

program applicants are randomly assigned.



10
  Individuals who have a definite recall-to-work date or who are hired through a union hall are exempt from
profiling.
                                                                                                                     7

         Unfortunately for the experiment but fortunately for the claimants, the Kentucky

economy was extremely strong from October 1994 to June 1996, the period for which we

currently have data. As a result, local offices were often able to treat the entire claimant

population. Indeed, of the 57,779 claimants in this period, 48,002 were selected for treatment, or

slightly over 83 percent. Of the 2,748 potential PTGs, there are only 286 actual PTGs, ranging in

size from 2 to 54. The mean size of a PTG is 6.9, with a median of 4, a 25th percentile of 3, and

a 75th percentile of 8. Profiling scores within the PTGs range from 6 to 19 with the median and

the mode at 16. 11 Combining all of the PTGs yields a treatment group of 1,236 claimants and a

control group of 745 claimants. Thus, the experimental design uses only about 2.6 percent of the

treated population and 7.6 percent of the untreated population. Table 1 compares the

demographic characteristics of the treatment and control groups as well as the population of

treated claimants.

         Figure 1 provides a time line for the typical claimant, although there is considerable

heterogeneity among claimants in the timing of these events. Unemployment insurance checks

are usually sent fortnightly in Kentucky. The first check is received in week two of the spell.

The letter in Exhibit 1 is typically received after the first check but before the second – that is, in

week three or four. Claimants need to contact the UI office in week three or four to verify their

continuing eligibility in order to receive the second check. Thus, if the letters, and the

mandatory reemployment services they imply, are to have a deterrent effect, we would expect to

observe it between weeks two and four. Within ten working days following notification of the

program, claimants selected for treatment report to a local office for an orientation where they

learn about the program and complete a questionnaire. Using this information, Employment


11
  Most of the variation in the marginal profiling score among the PTGs consists of variation across local offices. A
regression of the marginal profiling score on a vector of local office indicators using PTGs as the unit of observation
                                                                                                                        8

Services staff assess the claimants and then refer them to specific services, such as assisted job

search, employment counseling, job search workshops, and retraining programs.

         Among those claimants who attended the orientation, 76.7 percent were referred to less

expensive job search and job preparation activities. These less expensive services are also less

intensive, typically consuming from four to six hours of claimant time. In contrast, only 13.8

percent were referred to (relatively) more expensive education and training programs. 12 The

average number of services received following orientation was 1.02. Conditional on completing

at least one service, the average number of additional services received was 2.10. Of those

referred to services, only 61.3 percent completed at least one. Another 5.7 percent started at least

one service but returned to employment before completing any. Overall, 31.8 percent of those

referred received no services because they had returned to employment, chose not to claim

benefits, or were exempted because their previous employer provided similar services. 13


3 Theoretical Framework
To get a better feel for the potential impact of the program, in this section we outline a simple

model of an unemployed worker's job search in the presence of unemployment insurance. We

begin by considering the value of being unemployed in the absence of the WPRS system. In the

U.S. unemployment insurance system, benefits are paid for a limited duration, usually 26 weeks.

As a result, the value of being unemployed decreases over time up to the point of benefit

exhaustion. After benefit exhaustion the value of being unemployed remains a constant,

reflecting the assumed stationarity of the distribution of wage offers. A worker will maximize

his or her discounted, expected utility by setting the reservation wage so that the value of


explains 64 percent of the variation in profiling scores. There are, however, at least two different offices for each
profiling score among the PTGs.
12
   Individuals could be referred to more than one service and some persons were referred to miscellaneous other
services. See Noel (1998) for a detailed description of the available services.
                                                                                                                         9

employment at the reservation wage just equals the value of being unemployed, as in standard

search models. Therefore, the declining value of being unemployed implies that the worker's

reservation wage declines until the worker exhausts his or her benefits.

         There are at least two ways in which the WPRS system may influence workers’

valuations of unemployment. First, if the reemployment services are effective they will improve

the distribution of wage offers during and after receipt of the services. This has the further effect

of increasing the value of being unemployed prior to the start of services, as claimants anticipate

receiving them. There are a couple of reasons to believe, however, that any impact of

reemployment services on wage offers will be small. Past experience with government training

programs suggests that they are often ineffective (Heckman, LaLonde and Smith, 1999). In

addition, most of the services provided to the unemployed under WPRS are of modest duration

and cost relatively little to provide. Assuming reasonable rates of return on investment, their

modest cost suggests at best a modest effect.

         Second, because the reemployment services take time, receiving services reduces the

quantity of leisure that unemployed workers may consume. This “leisure tax” lowers the value of

remaining unemployed both before and during the period of service receipt. 14 Time spent in

reemployment services also reduces the time available for job search, which further reduces the

value of being unemployed before and during the services.

         The net effect of the profiling system on the value of unemployment, and hence on the

probability of leaving UI in each week, depends on the signs and magnitudes of these two

effects. If the services are effective, then the two factors work in opposite directions prior to and


13
   The fraction exempted due to receiving similar services from their previous employer is not precisely known, but
program staff indicate that it is small. The remaining 1.2 percent were either referred in error or have incomplete
data on service completion.
14
   If the requirements of the WPRS system are sufficiently onerous, they may lead eligible unemployed persons to
avoid UI entirely. Interestingly, even in the absence of the profiling system, empirical studies find UI take-up rates
                                                                                                            10

during the services. Once done with services, only the wage offer effect persists and the

employment hazard is increased. If the services are ineffective, then the net effect prior to and

during receipt of services is to lower the value of unemployment and speed exit from UI, but the

program has no effect after receipt of services. If the program works for some claimants but not

for others, then we might observe a mixture of effects, including a situation where the hazard rate

out of UI increases prior to service receipt due to claimants for whom the services represent a

cost, and after service receipt due to claimants for whom they represent a benefit.

        While we have couched this argument in terms of the workers' reservation wages,

workers may care about other dimensions of their employment. To the extent that the WPRS

program causes workers to accept less attractive job matches, it will lead to greater job turnover

and more frequent subsequent spells of unemployment. Unfortunately, this effect is difficult to

detect in the data when the treatment has the effect of inducing earlier return to work, because an

earlier return to work increases the time at risk of subsequent unemployment even in the absence

of any effect operating through match quality.


4 Parameters of Interest, Identification and Estimation
In this section, we discuss different parameters of interest and outline how we can use our

experimental data to identify them. For simplicity, suppose that the experimental data are

generated from the linear model

                                yi = X iγ + Ti βi + εi ,                                                    (1)

where yi is the dependent variable for the ith individual, X i is a vector of covariates, Ti is the

treatment indicator, εi is white noise, γ is a vector of unknown parameters, and βi is the person-

specific impact of the treatment.


of substantially less than one. See Blank and Card (1991) and Anderson and Meyer (1997) for estimates and
extended discussion of the measurement issues involved.
                                                                                                  11

       Because many members of the experimental treatment group do not receive

employment and training services, it is important to distinguish the impact of actually receiving

reemployment services from the impact of being assigned to treatment per se. We use

“treatment” to mean receiving the letter in Exhibit 1 and being subject to the requirement to

receive services in order to continue receiving UI, rather than actual receipt of employment and

training services. It is this treatment whose impact is captured by βi .


4.1 Parameters of Interest
We now define three parameters of interest. The most common parameter in the evaluation

literature is the mean impact of treatment on the treated ( TT ). In our notation, it is

                                         TT = E( βi |Ti = 1) .

The TT parameter indicates the mean effect of treatment as it is currently allocated and provides

the key input for a cost-benefit analysis of the profiling treatment as presently allocated.

       Another parameter of interest is the mean impact of treatment on a randomly selected

claimant. This parameter is called the average treatment effect ( ATE ), and is given by

                                            ATE = E ( βi ) ,

where the expectation is taken over the population of claimants. 15 The ATE parameter provides

the key input for a cost-benefit analysis of a program in which the treatment is given to all

claimants, regardless of profiling score.

       The third parameter of interest consists of what Imbens and Angrist (1994) call a local

average treatment effect (LATE). It is local in the sense that it represents the mean impact of

treatment on the treated for persons in the profiling groups, and thus on the margin of being

treated. The implicit instrument is a particular change in the program budget, one that would
                                                                                                                   12

leave all the treated persons in the PTGs untreated. Define PTG-specific mean impacts by

βj = E( βi |PTG = j ) , where PTG = 0 for persons not in a PTG and PTG = j ∈{ 1,..., 286 }

where j indexes the 286 PTGs for persons in a PTG. In this notation, the LATE parameter is

given by

                        LATE = E( βi |Ti = 1,PTG > 0 ) = Ei ( βj |Ti = 1,PTG > 0 ) .

The LATE parameter is a weighted average of the βi where the weights are proportional to the

number of treated persons in each PTG. 16


4.2 Identification
We now consider how our experimental data can be used to identify the parameters defined in

the preceding section. To begin, we assume that the standard set of assumptions regarding

experimental data hold, including the assumption that the impact on one person does not depend

on which other, or how many other, persons receive the treatment. 17

        Under these assumptions the experimental data from the PTGs identify the βj . Within


                                              i εi ) = 0 in equation (1). As LATE is a
each PTG, random assignment assures that cov(T,

weighted average of the βj , it too is identified by our experimental data. Identification of the




15
   The imposition of the profiling treatment on the population of claimants could affect the composition of that
population, by encouraging or discouraging some eligible persons from taking up their UI benefits, or even by
affecting who becomes unemployed.
16
   We could define other LATEs corresponding to different weighted averages of the PTG-specific impacts. For
example, we could consider the mean impact on all persons in a PTG, given by
                                         E( βi |PTG > 0 ) = Ei ( βj |PTG > 0 ) ,
or the average impact among PTGs, given by
                                                 E j ( βj |PTG > 0 ) .
These parameters correspond to different policy experiments than the LATE defined in the text. In a world of
heterogeneous impacts, these different parameters will differ in value. See Black, McKinnish and Smith (2001) for
further discussion.
17
   This condition is called the stable unit treatment value assumption (SUTVA) in the statistics literature. The
remaining standard assumptions are no randomization bias, no treatment group dropout and no control group
substitution into the same or similar treatments. These assumptions are discussed in detail in Heckman and Smith
(1995) and Heckman, LaLonde and Smith (1999).
                                                                                                                    13

LATE parameter requires no additional assumptions about the person-specific impacts βi .

They can vary across persons as a function of X i or in ways unrelated to X i .

           Because the impact of treatment may differ between persons in the PTGs and persons not

in the PTGs, the experimental data from the PTGs do not directly identify the average treatment

effect or the impact of treatment on the treated without some additional structure. The simplest

assumption to make is the “common effect” assumption, whereby the impact of treatment is the

same for all persons, so that βi = β for all i . The same conclusions follow for the slightly more

general case where βi = β +νi but νi , the person-specific component of the impact, is either not

known or known but not acted upon. 18 In the common effect case, all three parameters are the

same, so that

                                      ATE = TT = LATE .

Given that the experimental data identify the LATE parameter, under the common effect

assumption they also identify the average treatment effect and the effect of treatment on the

treated.

           The common effect assumption, though frequently used (often implicitly) in the applied

literature, is quite strong. A second assumption relaxes the common effect assumption to allow

variation in impacts across persons, but only as a function of observed covariates. In notation, it

assumes that βi = β( X i ) .19 In this case, the experimental data from the PTGs can be used to

identify the β( X i ) function. To obtain estimates of the ATE or TT parameters requires only

applying the estimated β( X i ) function to the distribution of the X i among all claimants or

among treated claimants, respectively. Thus, for example, we would estimate TT as


18
  In fact, even this condition is stronger than is strictly necessary. What is required is that the idiosyncratic
component of the impact is uncorrelated with whether or not the claimant is in a PTG.
                                                                                                                   14

                              TT = ∫ β( Xi ) f ( Xi |Ti = 1)dX i .                                             (2)

We apply this method to estimate the TT parameter in Section 5.6 below.

         This method works so long as the support of X i in the PTGs includes the support of X i

in the broader population for which an estimate is being constructed. The problem of a sufficient

support for X i within the population of persons in a PTG is not of merely theoretical interest.

Suppose that the impact of the program is a function of the profiling score, Pi , so that

βi = β( Pi ) . In this case, if we wished to estimate the average treatment effect for all UI

claimants, the support condition would prevent us from doing so, because the population of

treated claimants includes values of Pi from 1 to 20 while the population of claimants in PTGs

includes only values of Pi from 6 to 19.

         This discussion of identification reveals an important aspect of our tie-breaking

experimental design. The tie-breaking design may be acceptable in contexts where traditional

random assignment designs are not, because it requires less random assignment and does not

randomly assign those most in need. These political benefits come at the cost of the additional

assumptions required in the tie-breaking design to identify the TT and ATE parameters, which

are the usual objects of evaluation interest. 20


4.3 Estimation
To produce our experimental impact estimates, we estimate versions of

                                 yi = µj + β* Ti + υi ,                                                           (3)




19
   As in the common effect case, in this case it can also be assumed that there is additional variation in the person-
specific impact, so long as it either not known or not acted upon.
20
   Identification in the general case wherein βi = β( Xi ) + νi and νi is known and acted upon is beyond the scope of
this paper. See Heckman, Smith and Clements (1997) and Heckman and Smith (1998) for extended discussions of
this case.
                                                                                                                      15

where yi is the outcome for the ith individual, Ti is a binary indicator for whether or not the

ith individual received treatment, µj is a vector of PTG fixed effects to control for differences

in expected earnings in the absence of treatment across PTGs, and υi is a random disturbance

term. β* and µj are parameters to be estimated, and the µj correspond to the X i in equation

(1).

         Conditioning on the PTG fixed effects has two important consequences for the estimates.

First, because the proportion of claimants in the treatment group varies across PTGs, failure to

control for PTGs would result in biased estimates of the impact parameters if expected earnings

in the absence of treatment differ across PTGs. Second, because each PTG consists of

individuals with a specific profiling score at a particular location on a particular week, including

the µj implicitly conditions on the profiling score, location, and time period. Conditioning on

these factors substantially reduces the residual variation in these data and thereby increases the

precision of our estimated treatment effects. 21

         In a common effect world, unweighted estimation of equation (3) provides efficient

estimates of the all three parameters of interest defined in Section 4.1. Similarly, estimation of a

version of equation (3) with interaction terms provides consistent estimates of the β( X i )

function when the βi = β( X i ) assumption holds.

         When the common effect assumption does not hold and there are different impacts across

PTGs, unweighted estimation of equation (3) does not provide a consistent estimate of any of the

three parameters of interest. Instead, the β* from unweighted estimation of equation (3) consists

of a weighted average of the βj that is difficult to interpret in a meaningful way. For our


21
  Adding additional X i in an attempt to soak up more of the residual variance has little effect on the coefficient
estimates (as expected given random assignment) and little effect on the estimated standard errors.
                                                                                                                          16

purposes, two features of the implicit weights on the βj are interesting. First, for a given

random assignment ratio within a PTG, increases in the number of claimants in the PTG

increases the implicit weight on that PTG in the estimate β* . Second, for a given size of PTG

the weight is larger the closer the random assignment ratio is to 0.5. 22

           To estimate the LATE parameter when the common effect assumption does not hold

requires estimating a weighted version of equation (3). To estimate the mean impact of

treatment on the treated persons in a PTG, we weight the data so that                P r (T i ) =   1
                                                                                                        2   within each

PTG. Exact formulae for the weights are given in Black, McKinnish and Smith (2001).


5 Empirical Analyses

5.1 Aggregate Estimates
We focus on three outcomes of interest: the number of weeks that a claimant receives benefits,

the amount of benefits that the claimant receives, and the claimant's earnings in the quarters

following initiation of the UI claim. All data elements are taken from administrative records of

the Kentucky Department of Employment Services.

           The measure of earnings after the unemployment event is less than ideal for three

reasons. 23 First, because UI records are only for the Commonwealth of Kentucky, no earnings

are recorded for claimants who crossed state lines to begin employment. This is likely to be

particularly problematic in the urban areas of Kentucky. Of the seven Metropolitan Statistical

Areas in Kentucky, only Lexington is not located on the border of an adjoining state. While this

does not interject any bias into the experiment per se, it is important to keep in mind that we are

measuring the earnings of claimants in Kentucky, not their total earnings.


22
     The derivation of the weights on the βj implicit in the unweighted estimation of equation (3) is beyond the scope
of this paper; see Black, McKinnish and Smith (2001) for the derivation.
23
   See Hotz and Scholz (2000) for a general discussion of the advantages and disadvantages of administrative data
and Kornfeld and Bloom (1999) for a comparison of UI data and survey data in an evaluation context.
                                                                                                              17

        Second, earnings are not observed for claimants who work in a non-covered sector.

Third, UI records do not include any “informal” activities. To the extent that claimants work “off

the books,” the UI records understate total earnings. If the treatment increases participation in the

formal labor market and reduces participation in the informal labor market, then our measure of

earnings will tend to overstate the earnings impact of treatment. These problems are standard in

all analyses that use earnings variables constructed from state-level UI records.

        Table 2 presents the basic impact estimates from the experiment, obtained by estimating

equation (3) above. In column (1) we report the results for the unweighted data. In a common

effect world, these constitute consistent estimates of all three parameters of interest introduced in

Section 4.2. We find that the treatment group collects payments for about 2.2 fewer weeks than

the control group. The treatment group receives about $143 less in benefits than the control

group, but this difference is statistically significant only at the ten percent level. Finally, the

treatment group earned, on average, $1,054 more than the control group in the year following

initiation of the UI claim. Thus, in terms of mean impacts, the WPRS treatment does what it is

intended to do. It shortens the duration of UI claims, reduces total benefits paid, and raises

earnings. 24

        The reductions in weeks paid and amount of benefits paid, however, give conflicting

estimates of the magnitude of the treatment effect. The mean weekly benefit payment is

approximately $168, which suggests that a 2.2 week reduction in weeks paid should reduce the

amount paid by about $370. In contrast, a savings of $143 suggests a reduction of only 0.85 in

weeks paid. This latter estimate is similar to estimates from other programs in the existing

literature; see Meyer (1995). We examine this apparent discrepancy in detail in the Appendix.


24
  We wondered if the impact of treatment might diminish over calendar time as later cohorts of claimants learned
about the relatively modest time commitment that the program usually requires. We found, however, no systematic
pattern over time.
                                                                                                   18

In short, we find evidence of more repeat UI spells in the treatment group. Our evidence

suggests that for some of these repeat spells, the benefits paid variable was updated in the

administrative records to reflect the second spell but the weeks paid variable was not. This

finding suggests an upward bias in our impact on weeks paid. As a whole, the evidence

presented in the Appendix suggests that the weeks paid impact estimates in Table 2 may have a

modest upward bias.

       Column (2) presents estimates obtained using the alternative weighting scheme described

in Section 4.3. Under the common effect assumption, these estimates, along with those in

column (1), represent alternative consistent estimates of all three parameters of interest. In this

context, comparing the two sets of estimates gives a sense of the sensitivity of the substantive

findings to alternative weighting schemes. Under the assumption that the effects of treatment

vary among individuals, however, the estimates in column (2) represent consistent estimates of

the LATE parameter defined in Section 4.2, while the estimates in column (1) do not correspond

to any of our parameters. In this case, the differences across columns result from estimating

different parameters, rather than from estimating the same parameter in different ways.

       Turning now to the estimates themselves, the two estimates for the weeks paid measure

are virtually identical at about two weeks. For the amount paid measure, however, the LATE

estimate is lower at -$81.94. In contrast, the LATE earnings impact estimate of $1,600 exceeds

the corresponding unweighted estimate. Although the point estimates differ, the 95 percent

confidence interval of the unweighted estimates contain all of the corresponding LATE

estimates in column (2). Thus, while it is conceptually important to distinguish between these

estimates, in this application (though perhaps not in others) it does not make a statistically

significant difference.
                                                                                                  19

       In what follows, we present only unweighted estimates. We do so for three reasons.

First, they are the simplest to construct and discuss. Second, in a common effects world the

unweighted estimates are the most efficient. Third, and most importantly, in all cases the same

substantive conclusions result from using the unweighted estimates and the weighting scheme

corresponding to the LATE parameter. A complete set of tables constructed using the LATE

weighting scheme is available from the authors upon request.


5.2 Putting the Aggregate Estimates in Perspective
To put these estimated impacts into perspective, consider the estimates from the UI bonus

experiments that Woodbury and Spiegelman (1987) present. They estimate that a $500 bonus to

UI claimants who found a job within 11 weeks resulted in a reduction in the duration of UI spells

of about 1.1 weeks. The earnings of those offered a bonus were comparable to the earnings of

those not offered a bonus. Thus, relative to the Illinois bonus experiment, the Kentucky WPRS

appears to have had a substantial impact on claimants. This may reflect the fact that claimants

have until week 11 to find alternative employment under the Illinois bonus, but to avoid

reemployment services under WPRS claimants must find a job within the first few weeks of their

unemployment spell. The WPRS program has the further advantage that it is unlikely to increase

the UI take-up rate.

       The WPRS impacts reported here also tend to be larger than those from experimental

evaluations of job search assistance programs for UI claimants summarized in Meyer (1995). 25

Most of these programs (see his Tables 5A and 5B) have estimated impacts equal to or less than

one week of benefit receipt. Decker, Freeman, and Klepinger (2000) analyze the recent Job

Search Assistance (JSA) experiment, which used profiling to assign workers to job search

assistance in Washington, DC, and Florida. They find that structured job search assistance in
                                                                                                                  20

Washington lowered the number of weeks receiving benefits by 1.13 weeks and reduced

payments by $182, while the impacts in Florida were -0.41 weeks and $39, respectively. The

larger impacts we find here are consistent with the somewhat more intensive employment and

training services being offered, which presumably raise the cost of continued UI receipt for those

who do not value them and raise the benefits of service receipt for those who do.

         It is interesting to consider the costs and benefits of the profiling program from the point

of view of the UI system. Our estimates from column (1) of Table 2 indicate that treated

claimants receive $143 less in benefits than untreated claimants. We can compare these average

benefits with the average costs per treated claimant in the Kentucky UI system. To construct the

average costs per treated claimant, we use data on the average hours spent per week on profiling

in each of the 28 local offices and the state UI office, the average compensation per hour for

employees of the Kentucky Department for Employment Services, the annual cost of the contract

with CBER at the University of Kentucky to maintain the profiling model and data system, and

the number of treated claimants in the first 86 weeks of profiling. 26 These costs sum to $11.93 per

treated claimant. Even if one adds approximately $0.5 million in start-up costs and initial model

development and spreads them over the treated claimants from the first 86 weeks of profiling, the

costs are still only $22.35 per recipient. Thus, the profiling system appears to save the UI

program a substantial amount of money. 27


5.3 What if there Was No Random Assignment?
In the spirit of LaLonde (1986), Heckman and Hotz (1989), Heckman, Ichimura, Smith, and

Todd (1998) and others we consider whether a simple nonexperimental estimator can replicate


25
   See Corson, Long, and Nicholson (1985), Anderson, Corson, and Decker (1991) and Johnson and Klepinger
(1994) for analyses of the individual job search experiments.
26
   These data were provided by Ted Pilcher of the Kentucky DES.
27
   The costs shown here do include short-term training provided by UI staff but do not include the cost of long-term
training referrals to outside providers. A full cost-benefit analysis would include these additional costs. A cost-
                                                                                                                  21

our experimental estimates. Using data on all claimants –both treated and untreated –during

our experiment, we estimate equation (3) including a treatment dummy along with variables for

each claimant's race, sex, age, tenure at last job, experience, education, month and year of filing a

claim and the region of residence within Kentucky. We estimate the model with and without

dummy variables for each profiling score. This econometric model assumes a common effect

world and that any selection into treatment depends linearly on the observable characteristics

included in the model. Black and Smith (2001) discuss this point in detail and explore the ability

of various nonexperimental estimators to replicate the experimental estimates in Table 2.

         For the weeks paid measure, the regression estimates with and without the profiling score

dummies show reductions of 2.4 and 2.0 weeks, respectively. These estimates closely resemble

those in Table 2. For the amount of benefits received, we estimate a $66 reduction in benefits

paid when using the profiling score dummies, and a $240 increase without them. Finally, for

annual earnings, we obtain an impact estimate of about $350 without the profiling score controls,

but only $82 with them.

         Dickinson, Kreutzer, and Decker (1997) evaluate the WPRS using nonexperimental

methods for three states: Delaware, Kentucky, and New Jersey. Like ours, their estimators

depend on the assumption of linear selection on observables. For Kentucky, they find that the

program reduced weeks of benefit receipt by 0.72, reduced benefits paid by $96 and had no

impact on earnings. Overall, both our estimates and those from Dickinson, Kreutzer and Decker

(1997) suggest that simple nonexperimental estimators do not do a very good job of replicating

the experimental impact estimates, which is consistent with the usual findings in the literature.




benefit analysis from the standpoint of society (rather than of the UI system) would also include the increased
earnings of the treated claimants and some measure of the value of their foregone leisure.
                                                                                                                 22

5.4 The Effect of Treatment Over Time
Figure 2 displays hazard rates for leaving UI for the experimental treatment and control groups. 28

It documents a large impact of treatment after receipt of the letter notifying claimants of their

obligation to receive reemployment services. About 13 percent of the treatment group exits after

the first two weeks but only about four percent of the control group exits. Subsequently, the

hazard rate of the treatment group is almost always higher than that of the control group,

although the difference is statistically significant only a couple of times. We may use the hazard

function estimates to calculate the survivor function. The maximum difference between the

treatment and control group survivor functions is 0.11, which is achieved in week 12. The

difference after just two weeks is 0.083 or about 75 percent of the maximum difference.

         That the exit hazard in the treatment group continues to lie above that for the control

group for most of the eligibility period is consistent with a positive impact of employment and

training services on those who receive them. The latter explanation is consistent with the

evidence of modest but detectable impacts in the AFDC work/welfare experiments documented

in Gueron and Pauly (1991). Alternatively, it is possible that persons with low hazard rates in the

treatment group exit UI in the first few weeks at a higher rate than similar persons in the control

group.

         In Figures 3 and 4, we graph mean earnings and employment by quarter after the start of

the UI spell for the treatment and control groups. The earnings estimates illustrate the impact of

early exit from unemployment in the treatment group. In the first quarter, treatment group

members average $525 more in earnings than control group members, indicating that about half

of the earnings gain occurs in the first quarter. In the second quarter the earnings impact is about


28
  Parameter estimates are presented in Appendix Table B1 of Black, Smith, Berger, and Noel (1999). Most benefits
are paid bi-weekly. Technically, these data are not true hazards because we do not observe whether the weeks of
benefit receipt are consecutive. Rather, they represent counts of the number of weeks within the benefit year that a
                                                                                                                   23

$344. By the third quarter, the difference, while positive, is no longer statistically significant,

and for subsequent quarters there is virtually no difference in mean earnings. The impact of

treatment on employment – where employment is defined as positive earnings during a quarter –

indicates a substantial increase in the probability of employment in the first quarter, a modest

increase in the second quarter and little effect after that. Only the first quarter effect is

statistically significant. 29

        Experimental evaluations of mandatory job search assistance in other contexts report

similar results. Corson and Decker’s (1989) analysis of the New Jersey search experiments and

Johnson and Klepinger’s (1994) analysis of the Washington search experiment both find

evidence of early return to work. Decker, Freeman, and Klepinger’s (2000) analysis of JSA

experiments in Washington, DC, and Florida also find sharp increases in the hazard rate in the

second and third weeks of the JSA program. Dolton and O’Neill’s (1996) experimental

examination of the Restart component of Britain's UI system parallels our findings on a different

dimension. After receiving benefits for six consecutive months, the Restart program requires

recipients to participate in an interview with a case worker. Dolton and O’Neill (1996) document

a sharp spike in the hazard rate of the treatment group relative to the control group when

claimants receive notice of the interview. Johnson and Klepinger (1991, Table 4) find a similar

spike in the UI exit hazard in response to a letter notifying the recipient of an eligibility review

interview in the Washington Alternative Work Search Experiment.

        Our results are consistent with the idea that the WPRS system lowers the worker’s

reservation wage and increases search intensity early in the unemployment spell. A faster return

to employment implies worse matches on average in the treatment group. This in turn implies


claimant receives payments. Over 80 percent of claimants in PTGs, of treated claimants, and of all claimants had
either no interruption or one of two weeks or less.
                                                                                                                    24

that we should observe treatment group members having more interrupted spells of

unemployment as more of their matches fail to result in stable employment. To test this

prediction, we estimated a linear probability model based on equation (3) with an indicator for

the presence of an interrupted spell as the dependent variable. The results indicate that the

treatment group had a 0.06 higher probability of having an interrupted spell than the control

group (with a p-value of 0.003), which corresponds to about a 36% increase in the number of

interrupted spells. 30 At the same time, the absence of significant earnings impacts in quarters

three through six after the start of the claim indicates that there is no long term diminution in

match quality due to the treatment.

         In sum, we have strong evidence that the earnings gains we document result from more

early exits from UI in the experimental treatment group. Most of these exits take place prior to

possible receipt of reemployment services. Instead, they coincide with receipt of the letter

indicating the claimant's obligation to receive services. Earnings are significantly higher in the

first and second quarters after claimants' file their claims, and we find no evidence that claimants

ever suffer substantially reduced earnings through the first six quarters after their claims. This

evidence suggests that the WPRS treatment is an effective tool for reducing the extent of moral

hazard in the UI program.




29
   We also consider whether a claimant returned to a previous employer. We find that the treatment group is more
likely to have earnings at the same firm in the quarter before and the quarter after their UI spell compared to control
group, but the difference is not statistically significant.
30
   If the WPRS program lowers claimants' reservation wages early in their unemployment spells, then treatment
group members who exited early should have lower earnings than control group members who exit early. To test
this, we interacted the treatment indicator with an indicator for whether or not the claimant exited early -- that is,
within four weeks of the start of the UI claim. We find strong evidence of lower earnings among treatment group
members exiting early compared to control group members who do so. See Black, Smith, Berger, and Noel (1999)
for these estimates.
                                                                                                   25

5.5 Are the Treatment Effects “Common Effects?”
Recent work by Heckman, Smith, and Clements (1997) and others emphasizes variation in the

impact of treatment across persons as an important aspect of the evaluation problem. In this

section, we examine variation in the impacts of the WPRS treatment in two ways.

       First, we consider variation in impacts as a function of observable characteristics. We

interacted the treatment indicator in equation (3) with a variety of individual characteristics.

Though the point estimates sometimes differed across subgroups, the differences were

statistically significant only in the case of age, where older claimants, surprisingly, had a larger

impact of treatment. 31 In addition to looking at variation as a function of individual

characteristics, we also tested for variation in impacts among the 286 PTGs. The p-values from

F-tests of the null of equal impacts across PTGs (i.e., that βj = β for all j ) are 0.842 for weeks

of benefits paid, 0.706 for amount of benefits paid and 0.823 for annual earnings. Thus, we fail

to reject the null in all three cases. Unfortunately, given the large number of PTGs the sample

size for the each PTG is quite small and the statistical power of our test is limited.

       Second, we consider person-specific impacts based on a generalization of the common

effect model. This generalization preserves the property that the ranks of persons in the treated

and untreated distributions are the same, which arises in the common effect model from the fact

that in the population the treatment group outcome distribution is just the control group outcome

distribution shifted by a constant. At the same time, it relaxes the assumption that the size of the

impact is the same for each person. Under this generalization, impact estimates are constructed

by taking differences across quantiles of the treated and untreated outcome distributions. The

difference between the analysis here and that in Heckman, Smith and Clements (1997) is that we

remove the PTG fixed effects from the outcomes prior to differencing across quantiles.
                                                                                                                26

        Formally, we construct

                                    y%1ij = y1ij − µ
                                                   ˆj                                                     (4)

                                    y% 0 ij = y0 ij − µ
                                                      ˆj                                                  (5)

where y%1ij ( y% 0ij ) is the outcome for the ith member of the treatment (control) group in the jth

PTG with the PTG fixed-effect removed, y1ij ( y0ij ) is the unadjusted outcome for the ith

member of the treatment (control) group in the jth PTG, and µ̂j is the estimated fixed effect for

the jth PTG. We calculate impacts by running quantile regressions of y% on an intercept and a

treatment indicator. The impact estimate for a given quantile of the y% 0ij distribution is just the

coefficient on the treatment indicator from the corresponding quantile regression. Under the null

hypothesis of a common effect, these impact estimates should not vary over quantiles. Figure 5

plots the estimates. 32

        In their analysis of the JTPA program, Heckman, Smith, and Clements (1997) find

reasonably strong support for the common effect model; in their data the estimated impact is

relatively constant across much of the control group outcome distribution. In contrast, we find a

great deal of heterogeneity in the impact of treatment. For weeks of benefits paid the impact

estimates range from 1.1 to 3.7 weeks, for the amount paid the impacts range from about -$400

to $130, and for earnings they range from about $280 to over $1300. Indeed, there are

statistically significant positive and negative estimates of the impact of treatment on the amount

of benefits paid. Thus, this analysis finds little evidence for the common effects model. The

estimated impacts depend strongly on the untreated outcome for all of the variables we examine.


31
   These estimates are available on request from the authors. The estimates for age appear in Table 4 of Black,
Smith, Berger and Noel (1999).
32
   In Appendix Table B3 of Black, Smith, Berger, and Noel (1999) we report the estimates. Like Heckman, Smith
and Clements (1997), we use quantiles of the outcome distributions, rather than simply matching individuals across
distributions, because the treatment and control groups are of unequal size.
                                                                                                    27

       The estimated impacts also tell an interesting story. For all three outcome variables, the

impacts are not monotonic in y% 0ij . For the weeks of benefits paid and amount of benefits paid

variables, Figure 5 shows that the impacts of the program are concentrated in the middle of the

control group outcome distribution. The treatment appears to have very little impact on persons

who would otherwise exhaust or come close to exhausting their benefits, but a very large impact

on persons who would otherwise be between the 25th and 75th percentiles in terms of either

outcome. For those expected to have short spells and receive few benefits, there appears to be a

modest impact on weeks of benefits paid but little or no impact on amount of benefits paid.

These findings represent further evidence that allocating the treatment on the basis of the

expected duration of UI benefit receipt may not represent an optimal strategy.


5.6 Estimates of TT When βi = β( X i )
In Section 4.2, we discussed how to construct estimates of the mean impact for populations

broader than that for which we actually have experimental data in the cases where the treatment

effect is a function of covariates, or βi = β( X i ) . Table 3 presents estimates of the mean impact

of treatment on the treated ( TT ) constructed by re-weighting the conditional (on X i )

experimental impact estimates using the distribution of each X i in the treated sample. 33

       Table 3 presents impact estimates based on re-weighting. Not surprisingly, our estimates

of the impact depend on the particular X variable used to do the re-weighting. For example, the

mean impact estimates for earnings range from a high of $1,362 to a low of $828. In general,

however, the impact estimates tell the same substantive story as our estimates in Table 2. In no

case do the reweighted estimates based fall outside of the 95 percent confidence bounds of the

estimates in column (1) of Table 2. This is consistent with the fact that we did not find many
                                                                                                                  28

statistically significant differences in impacts among subgroups. This evidence provides some

support for thinking that our impact estimates provide a guide to the effect of the profiling

treatment for populations broader than just the PTG members in our experimental data.


5.7 Evaluating Profiling as an Allocation Mechanism
In addition to evaluating the impact of the profiling treatment on those assigned to it, we also

briefly consider a different evaluation question: How well does the profiling mechanism allocate

the treatment? 34 If the goal of profiling is to increase the efficiency of treatment allocation then,

assuming that the costs of the treatment do not vary across persons, it should allocate the

treatment to those for whom it has the largest impact. To address this question, we assume that

the individual impacts depend on the profiling score, so that βi = β( Pi ) . If the profiling

mechanism enhances the efficiency of treatment allocation, then the impact of treatment should

increase with the profiling score, as those with higher scores are much more likely to get treated.

         Table 4 presents estimates of β( Pi ) for our three outcome variables. To perform this

analysis, we divide claimants into four groups based on their profiling scores: 6-13 (about 26

percent of the treatment group), 14 or 15 (about 20 percent of the treatment group), 16 (about 21

percent of the treatment group) and 17 to 19 (about 33 percent of the treatment group). The

results suggest that the impact varies nonlinearly with the profiling score, but we can reject the

null of equal impacts across profiling score subgroups only for earnings.

         The assumption underlying the WPRS is that those with the longest expected UI spells

benefit the most from the profiling treatment. The estimates in Table 4 provide little justification

for this assumption, as there does not appear to be a monotonic relationship between the profiling

score and the impact of treatment. Thus, like the evidence on person-specific impacts in Figure


33
   For some variables, the support condition discussed in Section 4.2 comes into play. As a result, we perform the re-
weighting using the conditional density in the treated population over the region of common support.
34
   See Berger, Black and Smith (2000) for an extended discussion of these issues.
                                                                                                   29

5, the evidence in Table 4 calls into question the wisdom of using expected UI spell duration

(rather than, say, predicted impacts) as a means of allocating treatment.


6 Conclusion
In this paper, we use unique experimental data to examine the impact of the Worker Profiling

and Reemployment Services (WPRS) initiative. Our experimental data are for persons in

marginal profiling groups – that is, persons whose expected UI spells are just long enough to put

them in the group required to receive reemployment services in return for continued receipt of

benefits. This design, called a tie-breaking experiment by Thistlethwaite and Campbell (1960),

allows the introduction of random assignment without major program disruption and without

denying services to those most in need. In so doing, it may reduce both line worker resistance to

random assignment and the negative publicity sometimes associated with random assignment

experiments in the social services.

       For this group, we find that random assignment to the WPRS treatment results in a 2.2

week reduction in benefit receipt relative to the control group. This represents a reduction in

mean benefits payments of slightly over $143 per recipient. In addition, the experimental

treatment group had significantly higher earnings in the year after the start of their UI claim. This

earnings difference arises almost entirely from higher earnings in the first two quarters after the

start of the claim. This suggests that earnings gains are due primarily to the earlier return to work

of some treatment group members rather than due to higher wages conditional on employment.

We find no evidence that the earnings of the treatment group are lower through the first six

quarters after the unemployment spell, suggesting that the program does not have a strong

adverse impact on job-match quality.

       The reduction in the length of recipiency in the treatment group is largely accomplished

by early exits from UI. Many of these early exits coincide in time with the letters sent out to
                                                                                                  30

treatment group members to notify them of their obligations under the program. These

findings suggest that the gains from the program result in large part from removing claimants

from the UI rolls who were job ready and had little trouble locating employment. Hence, the

WPRS treatment appears to be successful at reducing the moral hazard associated with the UI

program. Moreover, from the perspective of the UI system, and likely from that of society as

well, it produces a wide excess of benefits over costs.

       We find strong evidence against the “common effect” assumption. For the WPRS

program, the estimated treatment effect appears to differ dramatically across quantiles of the

untreated outcome distribution. In particular, for both the weeks of benefits paid and the amount

of benefits paid outcomes, the impact of the program is concentrated in the middle of the

untreated outcome distribution. That is, the program reduces weeks paid and benefits paid for

persons who would otherwise have had moderate values of those variables. It has little effect on

persons who would otherwise exit very early and receive few benefits and on those who would

otherwise exhaust or come close to exhausting their benefits.

       Finally, the underlying assumption of the WPRS program is that those with the longest

expected UI spell durations would benefit the most from the requirement that they participate in

reemployment services in order to continue receiving their UI benefits. It is also assumed that

treating these claimants will result in the largest budgetary savings for state UI systems. Our

results provide little justification for either assumption as we do not find a monotonic

relationship between the profiling score and the impact of treatment. If the goal of profiling is to

allocate the treatment to those claimants with the largest expected impact from it, or to save the

state UI system the most money, then our findings call into question the wisdom of using the

expected benefit duration as a means allocating treatment. They also suggest the value of further

thought and study before extending profiling to other programs.
                                                                                                    31


7 Appendix
We noted in Section 5.1 that the estimated impacts on weeks of benefits paid and on the amount

of benefits paid presented in Table 2 seem inconsistent. The impact on weeks of benefits paid in

Table 2 is constructed using the weeks paid variable recorded in the UI administrative data. In

this appendix, we compare unweighted impact estimates obtained using the weeks paid variable

with alternative estimates based on a measure of weeks paid constructed indirectly from other

elements of the administrative data. We construct this alternative measure, which we call

“imputed weeks of benefits paid” by dividing the total benefits paid variable by the weekly

benefit level variable. Because the weekly benefit amount may change over a spell, this measure

may contain some error, but it provides a useful check on the weeks paid variable.

       The weeks paid variable and the imputed weeks paid variable are highly correlated

(0.884), but the correlation is higher for the control group (0.947) than for the treatment group

(0.849). On closer examination, we found that most of the disagreements occurred for treatment

group members with four or fewer weeks paid (using the weeks paid variable), where a

disagreement occurs when imputed weeks paid exceed the weeks paid variable by at least 1.5

weeks. In Table A1, we provide a breakdown of whether or not the weeks paid and imputed

weeks paid variables disagree by whether or not the claimant exited early. Among those who did

not exit early, we find only three disagreements, two in the treatment group and one in the

control group. Among those who exit early, the two measures of weeks paid differ for only 2 of

the 105 claimants in the control group but for 116 of the 290 claimants in the treatment group.

       Using the information in the administrative data, we can calculate the elapsed calendar

time from the first week each claimant received benefits to the last week. If the elapsed calendar

time exceeds the imputed weeks paid by two weeks or more, we assume that there was an

interruption in the spell. That is, we assume the claimant had a spell of UI receipt, followed by a
                                                                                                     32

spell of non-receipt (presumably due to employment) followed by a second spell of UI receipt

within the benefit year. For the sample of all early exits, the median difference between elapsed

calendar time and imputed weeks paid is 17 weeks. Among the early exits, 66 claimants – 2 in

the control group and 64 in the treatment group – appear to have an interrupted spell. In these

cases, we believe that the weeks of benefits paid variable was not updated to reflect the second

spell of UI receipt while the amount of benefits paid variable was. This is consistent with the

fact that the latter, but not the former, plays an important role in the UI administrative system.

This interpretation helps to account for the apparent inconsistency in the estimates in Table 2. It

also leads to a somewhat different interpretation of the spike in the hazard at week 2 in Figure 1,

as it suggests that many of those who leave early in response to the “threat” of reemployment

services end up returning to UI after a spell of employment.

       Of course, our measure of interrupted spells depends on correct reporting of the first and

last weeks paid variables. For 16 recipients, we have doubts about the accuracy of these data

elements. Although they have no interruptions according to our measure, each has either a value

of weeks paid in excess of 13 weeks combined with positive earnings in the first quarter or

imputed earnings (calculated by dividing quarterly earnings by 13 minus the value of the

imputed weeks paid variable) in the first quarter in excess of $2,000 a week. We believe that

these observations probably have interrupted spells combined with coding errors in the first or

last week paid variables. For the remaining 35 observations where the weeks paid and imputed

weeks paid variables disagree we find no evidence of an interrupted spell and have no

explanation for the disagreement.

       The impact of treatment on earnings provides an indirect means of assessing the impact

of treatment on the number of weeks of employment and thereby on the number of weeks of

benefits paid. With an estimate of weekly earnings, we can use the estimated earnings impacts to
                                                                                                    33

estimate the impact of treatment on the number of weeks of employment. To estimate mean

weekly earnings, we use earnings in the quarter before the start of the UI spell, which is the

quarter with the highest earnings. To be conservative, we exclude observations with less than

$2,500 in quarterly earnings and estimate weekly earnings by dividing mean quarterly earnings

by 12 rather than 13 weeks, which represents an implicit unemployment rate during the quarter

of about 7.7 percent. Even with these restrictions, the mean weekly earnings of claimants is only

$523 ($6,277/12). This suggests that, if the impact of treatment is independent of earnings (a

strong assumption), then the WPRS treatment increases weeks of employment by about 2.02

weeks. This estimate almost certainly understates the true effect because we have very likely

overestimated the weekly earnings of claimants. Nevertheless, this estimate is surprisingly

similar to the estimates for weeks of benefits paid in Table 2.

       In addition to measurement problems, the seeming inconsistency in the estimated impacts

in Table 2 could be due to a correlation between the impact of treatment and the benefit level. If

the treatment has a stronger effect, in terms of reductions in weeks of benefits paid, on persons

with low benefit levels, this would account for the seeming inconsistency. We examined this

relationship and found that it exhibited a U-shaped pattern. Thus, while impacts and benefits do

not appear to be independent, neither does this relationship account for the seeming

inconsistency.

       Taking all of the evidence into account suggests that there may be some upward bias in

the estimates of the impact of the WPRS treatment on weeks of benefits paid reported in Table 2.

Thus, this evidence constitutes an important reminder that administrative data are not a panacea

and must be used with care. While they avoid some problems associated with survey data, such

as non-response, administrative data often have unique problems of their own.
                                                                                              34


References

Anderson, Patricia. 1992. “Time-Varying Effects of Recall Expectation, a Reemployment Bonus,
      and Job Counseling on Unemployment Durations.” Journal of Labor Economics. 10(1):
      99-115.

Anderson, Patricia, Walter Corson, and Paul Decker. 1991. “The New Jersey Unemployment
      Insurance Reemployment Demonstration Project: Follow-up Report.” Unemployment
      Insurance Occasional Paper 91-1. U.S. Department of Labor, Employment and Training
      Administration, Unemployment Services.

Anderson, Patricia and Bruce Meyer. 1997. “Unemployment Insurance Takeup Rates and the
      After-Tax Value of Benefits.” Quarterly Journal of Economics. 112(3): 913-937.

Angrist, Joshua D. and Alan B. Krueger. 1999. “Empirical Strategies in Labor Economics” in
       Handbook of Labor Economics, Volume 3A, eds. Orley Ashenfelter and David Card.
       Amsterdam: North-Holland. 1277-1366.

Ashenfelter, Orley, David Ashmore, and Olivier Deschênes. 1999. “Do Unemployment
      Insurance Recipients Actively Seek Work? Randomized Trials of Four US States.”
      National Bureau of Economic Research Working Paper #6982.

Barron, John M. and Wesley Mellow. 1979. “Search Effort in the Labor Market.” Journal of
       Human Resources. 14(3): 427-41.

Berger, Mark C., Dan A. Black, Amitabh Chandra and Steven N. Allen. 1997. “Kentucky's
       Statistical Model of Worker Profiling for Unemployment Insurance.” Kentucky Journal
       of Economics and Business. 16: 1-18.

Berger, Mark C., Dan A. Black and Jeffrey A. Smith. 2000. “Evaluating Profiling as a Means of
       Allocating Government Services.” in Econometric Evaluation of Labour Market Policies,
       eds. Michael Lechner and Friedhelm Pfeiffer. Heidelberg: Physica-Verlag. 59-84.

Besley, Timothy and Stephen Coate. 1992. “Workfare Versus Welfare: Incentive Arguments for
       Work Requirements in Poverty-Alleviation Programs.” American Economic Review.
       81(2): 249-261

Black, Dan A., Terra McKinnish and Jeffrey A. Smith. 2001. “Weight a Moment: Identification
       in Natural Experiments” Unpublished manuscript, Syracuse University.

Black, Dan A. and Jeffrey A. Smith. 2001. “Employment Subsidies and Leisure Taxes in the
       Design of Transfer Programs.” Unpublished manuscript, University of Maryland.

Black, Dan A., Jeffrey A. Smith, Mark C. Berger, and Brett J. Noel, 1999. “Is the Threat of
       Training More Effective than Training Itself? Experimental Evidence from the UI
       System” University of Western Ontario Research Report #9913.
                                                                                           35

Black, Dan A. and Jeffrey A. Smith. 2001. “A Comparison of Econometric and Experimental
       Evaluation Using Cross-Section, Panel Data, and Matching Models.” Unpublished
       manuscript, University of Maryland.

Blakemore, John and Jane Welsh. 1983. “Selective Incapacitation: Sentencing According to
      Risk.” Crime & Delinquency. 29(4): 504-528.

Blank, Rebecca and David Card. 1991. “Recent Trends in Insured and Uninsured
       Unemployment: Is There an Explanation?” Quarterly Journal of Economics. 106(4):
       1157-90.

Campbell, Donald T. “Reforms as Experiments.” 1969. American Psychologist. 24: 409-29.

Card, David and Phillip B. Levine. 2000. “Extended Benefits and the Duration of UI Spells:
       Evidence from the New Jersey Extended Benefit Program.” Journal of Public Economics
       78:1-2, 107-38.

Coate, Stephen, Stephen Johnson and Richard Zeckhauser. 1994. “Pecuniary Redistribution
       through In-Kind Programs.” Journal of Public Economics. 55(1): 19-40.

Corson, Walter, and Paul T. Decker. 1989. “The Impact of Reemployment Services on
       Unemployment Insurance Benefits: Findings from the New Jersey Unemployment
       Insurance Reemployment Demonstration.” Unpublished manuscript, Mathematica Policy
       Research.

Corson, Walter, David Long, and Walter Nicholson. 1985. “Evaluation of the Charleston
      Claimant Placement and Work Test Demonstration.” Unemployment Insurance
      Occasional Paper 85-2. US Department of Labor, Employment and Training
      Administration, Unemployment Services.

Decker, Paul T. 1994. “The Impact of Reemployment Bonuses on Insured Unemployment in the
       New Jersey and Illinois Reemployment Bonus Experiments.” Journal of Human
       Resources. 29(3): 718-741.

Decker, Paul T. and Christopher J. O'Leary. 1995. “Evaluating Pooled Evidence from the
       Reemployment Bonus Experiments.” Journal of Human Resources. 30(3): 534-550.

Decker, Paul T., Lance Freeman, and Daniel H. Klepinger, 2000. “Assisting Unemployment
       Insurance Claimants: The One-Year Impacts of the Job Search Assistance
       Demonstration” Unpublished Manuscript, Mathematica Policy Research.

Dickinson, Katherine P., Suzanne D. Kreutzer, and Paul T. Decker, 1997. “Evaluation of Worker
       Profiling and Reemployment Services Systems.” Unpublished manuscript, Social Policy
       Research Associates.

Dolton, Peter and Donal O'Neill. 1996. “Unemployment Duration and the Restart Effect: Some
       Experimental Evidence.” Economic Journal. 106(435): 387-400.
                                                                                              36

Ehrenberg, Ronald and Ronald Oaxaca. 1976. “Unemployment Insurance, Duration of
      Unemployment and Subsequent Wage Gain.” American Economic Review. 66(5): 754-
      766.

Gueron, Judith and Edward Pauly. 1991. From Welfare to Work. New York, NY: Russell Sage
      Foundation.

Heckman, James and V. Joseph Hotz. 1989. “Choosing Among Alternative Nonexperimental
     Methods for Estimating the Impact of Social Programs: The Case of Manpower
     Training.” Journal of the American Statistical Association. 84(408): 862-874.

Heckman, James J., Hidehiko Ichimura, Jeffrey A. Smith, and Petra Todd. 1998. “Characterizing
     Selection Bias Using Experimental Data.” Econometrica. 66(5): 1017-1098.

Heckman, James J., Robert J. LaLonde and Jeffrey A. Smith. 1999. “The Economics and
     Econometrics of Active Labor Market Programs.” in Handbook of Labor Economics,
     Volume 3A, eds. Orley Ashenfelter and David Card. Amsterdam: North-Holland. 1865-
     2097.

Heckman, James J., Jeffrey A. Smith, and Nancy Clements. 1997. “Making the Most Out Of
     Programme Evaluations and Social Experiments: Accounting for Heterogeneity in
     Programme Impacts.” Review of Economic Studies. 64(4): 487-36

Heckman, James J., and Jeffrey A. Smith. 1995. “Assessing the Case for Social Experiments.”
     Journal of Economic Perspectives. 9(2): 85-110.

Heckman, James J., and Jeffrey A. Smith. 1998. “Evaluating the Welfare State,” in Econometrics
     and Economic Theory in the 20th Century: The Ragnar Frisch Centennial, ed. Steiner
     Strom. Cambridge, UK: Cambridge University Press for Econometric Society
     Monograph Series. 241-318.

Hotz, V. Joseph and Karl Scholz. 2000. “Measuring Employment and Income Outcomes for
       Low-Income Populations with Administrative and Survey Data.” Unpublished
       manuscript, UCLA.

Imbens, Guido and Joshua Angrist. 1994. “Identification and Estimation of Local Average
      Treatment Effects.” Econometrica. 62(2): 467-76.

Johnson, Terry R. and Daniel H. Klepinger. 1991. “Evaluation of the Impacts of the Washington
       Alternative Work Search Experiment.” Unemployment Insurance Occasional Paper 91-4.
       U.S. Department of Labor, Employment and Training Administration, Unemployment
       Services.

Johnson, Terry R. and Daniel H. Klepinger. 1994. “Experimental Evidence on Unemployment
       Insurance Work-Search Policies.” Journal of Human Resources. 29: 695-717.
                                                                                               37

Katz, Lawrence and Bruce Meyer. 1990. “The Impact of the Potential Duration of
       Unemployment Benefits on the Duration of Unemployment.” Journal of Public
       Economics. 41(1): 45-72.

Kornfeld, Robert and Howard Bloom. 1999. “Measuring Program Impacts on Earnings and
       Employment: Do Unemployment Insurance Wage Reports from Employers Agree with
       Surveys of Individuals?” Journal of Labor Economics. 17(1): 168-197.

LaLonde, Robert, 1986. “Evaluating the Econometric Evaluation of Training Programs with
      Experimental Data.” American Economic Review. 76(4): 604-20.

Meyer, Bruce D. 1990. “Unemployment Insurance and Unemployment Spells.” Econometrica.
       58(4): 757-782.

Meyer, Bruce D. 1995. “Lessons from the US Unemployment Insurance Experiments.” Journal
       of Economic Literature. 33(1): 91-131.

Moffitt, Robert. 1985. “Unemployment Insurance and the Distribution of Unemployment
        Spells.” Journal of Econometrics. 28: 85-101.

Noel, Brett J. 1998. Two Essays on Unemployment Insurance. Unpublished dissertation,
       University of Kentucky.

O'Leary, Christopher J., Paul Decker and Stephen A. Wandner. 1998. “Reemployment Bonuses
       and Profiling.” W.E. Upjohn Institute Staff Working Paper #98-51.

St. Louis, Robert D., Paul L. Burgess, and Jerry L. Kingston. 1986. “Reported vs. Actual Job
       Search by Unemployment Insurance Claimants.” Journal of Human Resources. 21(1):
       92-117.

Thistlethwaite, D. L. and D. T. Campbell. 1960. “Regression Discontinuity Analysis: An
        Alternative to ex post facto Experiment.” Journal of Educational Psychology. 51: 309-17.

U.S. Department of Labor. 1999. “Evaluation of Worker Profiling and Reemployment Services
       Policy Workgroup: Final Report and Recommendations.” Employment and Training
       Administration.

Woodbury, Stephen and Robert Spiegelman. 1987. “Bonuses to Workers and Employers to
     Reduce Unemployment: Randomized Trials in Illinois.” American Economic Review.
     77(4): 513-530.
                                                                                                                 38

    Table 1: Demographic Characteristics of Treatment and Control Groups:
             Kentucky WPRS Experiment, October 1994 to June 1996


                                Control Group         Treatment        P-values for               Treated
                                                        Group            tests of                Population
                                                                       differences
                                                                        in means

Age                                   37.0               37.1              0.717                     37.4
                                     (10.9)             (11.1)                                      (11.2)

Years of schooling                    12.3               12.6              0.221                     12.4
                                     (2.10)             (2.14)                                      (2.06)

White male                           0.564               0.518             0.095                    0.517

White female                         0.352               0.372             0.060                    0.398

Nonwhite male                        0.040               0.055             0.433                    0.042

Nonwhite female                      0.044               0.055             0.691                    0.043

Earnings in year before            $19,759             $19,047             0.666                   $19,168
claim                              (13,678)            (13,636)                                    (14,588)


Weekly benefit amount               $168.35            $167.36             0.747                   $173.11
                                    (68.90)            (64.70)                                     (64.77)



N                                     745                1,236               ---                   48,002


Source: Authors’ calculations from the Kentucky WPRS Experiment. Standard deviations are given in parentheses.
Means are unweighted. Tests for differences in means are for the treatment and control groups and are based on a
linear regression that also conditions on the 286 PTGs. The treated population consists of all claimants assigned to
the profiling treatment, not just those in the PTGs. All claimants are eligible for 26 weeks of UI benefits.
                                                                                                                39


Table 2: Impact of Treatment on Duration of Benefits and Earnings: Kentucky
                WPRS Experiment, October 1994 to June 1996

Outcome Measures                                           Impact of Treatment

                                            Unweighted                 Treatment on the Treated in
                                                                           the PTGs (LATE)
Number of weeks receiving                      -2.241                            -2.045
UI benefits                                    (0.509)                          (0.411)
                                               [0.000]                          [0.000]

UI benefits received                           -143.18                             -81.44
                                               (100.3)                              (81.6)
                                               [0.077]                             [0.159]

Earnings in the year after                    1,054.32                            1,599.99
the start of the UI claim                      (588.0)                             (475.2)
                                               [0.037]                             [0.001]

Earnings in 1 st quarter                       525.58                              684.31
                                               (192.8)                             (144.4)
                                               [0.003]                             [0.000]

Earnings in 2nd quarter                        344.05                              463.51
                                               (161.4)                             (128.9)
                                               [0.017]                             [0.000]

Earnings in 3rd quarter                        220.67                              397.73
                                               (181.5)                             (145.7)
                                               [0.112]                             [0.003]

Earnings in 4th quarter                        -35.99                               54.44
                                               (176.1)                             (142.1)
                                               [0.582]                             [0.351]

N                                               1,981                               1,981


Source: Authors’ calculations from the Kentucky WPRS Experiment. Each of the regressions controls for the
Profiling Tie Group (PTG) of the recipients. There are 745 claimants in the control group, 1,236 claimants in the
treatment group and 286 PTGs. Standard errors are in parentheses and p-values from one-tailed tests are in brackets.
                                                                                                                  40

 Table 3: Estimates of the Impact of Treatment on the Treated Based on the
                          Assumption that βi = β( X i ) :
           Kentucky WPRS Experiment, October 1994 to June 1996

Weights                              Number of weeks             UI benefits         Earnings in year
                                       receiving UI               received             after claim
                                         benefits

Unweighted                                 -2.241                 -$143.18               $1,054.32
                                            (.509)                 (100.3)                 (588.0)
                                           [0.000]                 [0.077]                 [0.037]
Profiling score weights*                   -2.239                  -$86.67               $1,362.19
                                           (0.547)                (109.55)                (656.87)
                                           [0.000]                 [0.215]                 [0.019]
Local office weights*                      -2.424                 -$128.91               $1,250.81
                                           (0.560)                (110.44)                (644.75)
                                           [0.000]                 [0.122]                 [0.027]
Time weights*                              -2.327                 -$150.48               $1,139.57
                                           (0.506)                 (99.46)                (591.82)
                                           [0.000]                 [0.065]                 [0.027]

Age category weights                       -2.316                 -$154.11                $828.21
                                           (0.502)                (100.12)                (586.82)
                                           [0.000]                 [0.062]                 [0.079]
Education category weights                 -2.276                 -$151.20               $1,070.49
                                           (0.500)                 (98.52)                (563.82)
                                           [0.000]                 [0.063]                 [0.029]
Sex weights                                -2.284                 -$154.95               $1,036.86
                                           (0.509)                (100.66)                (596.27)
                                           [0.000]                 [0.062]                 [0.041]
Race category weights                      -1.979                 -$140.81                $989.40
                                           (0.508)                (101.71)                (597.99)
                                           [0.000]                 [0.083]                 [0.049]

N                                           1981                     1981                   1981


Source: Authors’ calculations from the Kentucky WPRS Experiment. Each of the regressions controls for the
Profiling Ties Group (PTG) of the recipients. Standard errors are given in parentheses and p-values from one-tailed
tests are given in brackets. An asterisk denotes that the support of the experimental sample is smaller than the
support in the treated sample. In these cases, we integrate using equation (2) only over the region of common
support. The categories are as follows: for profiling score, each individual score from 6 to 19; for time, each
calendar week; for education, less than high school, high school graduate, more than high school; for age, under 35,
35 to 49 and 50 and above; for race, white and nonwhite.
                                                                                                               41

  Table 4: Estimates of the Impact of Treatment on the Treated Under the
  Assumption that the Impact is a Function of the Profiling Score ( b i = b ( Pi ) ):
            Kentucky WPRS Experiment, October 1994 to June 1996

                                                 Weeks paid       Amount paid        Annual earnings


Profiling score between                            -2.238           -$270.08              $939.51
6 and 13                                           (0.913)          (179.74)             (1052.05)
                                                   [0.007]           [0.067]              [0.186]
Profiling score between                            -1.891            -$14.42            -$1,257.14
14 and 15                                          (1.050)          (206.77)            (1,210.25)
                                                   [0.036]           [0.472]              [0.851]
Profiling score of 16                              -3.057           -$465.73             $4,175.83
                                                   (1.102)          (216.94)            (1,269.76)
                                                   [0.003]           [0.016]              [0.001]
Profiling score between                            -1.861            $182.09              $689.71
17 and 19                                          (1.039)          (204.60)            (1,197.55)
                                                   [0.037]           [0.813]              [0.283]

P-value for test of equal impacts                   0.851             0.132                0.021
across approximate profiling score
quartiles

Source: Authors’ calculations from the Kentucky WPRS Experiment. Each of the regressions controls for the
Profiling Tie Group (PTG) of the recipients. There are 745 claimants in the control group, 1,236 claimants in the
treatment group and 286 PTGs. The approximate quartiles for the profiling scores are scores 6 to 13 (515 members),
scores 14 and 15 (390 members), score 16 (424 members), and scores 17 to 19 (652 members).
                                                                                          42

Table A1: A Comparison of Weeks Paid and Imputed Weeks Paid: Kentucky
               WPRS Experiment, October 1994 to June 1996

                                                                   Control    Treatment
Weeks of benefits paid is greater than 4 weeks                     Group       Group

Weeks paid and imputed weeks paid agree                               639        943
                                                                   (99.84%)   (99.79%)
Weeks paid and imputed weeks paid disagree                              1          2
                                                                    (0.16%)    (0.21%)
N                                                                     640        945
                                                                   (100.0%)   (100.0%)

Weeks of benefits paid is less than 5 weeks

Weeks paid and imputed weeks paid agree                               103       174
                                                                   (98.10%)   (60.21%)

Weeks paid and imputed weeks paid disagree

        Interrupted spell of benefit recipiency                        2          64
                                                                   (1.90%)    (22.15%)
        Apparent interruption of benefit recipiency,                   0          16
        imputed earnings in excess of $2,000 per week                          (5.54%)

        No apparent interruption of benefit recipiency                0          35
                                                                              (12.11%)

N                                                                     105       290
                                                                   (100.0%)   (100.0%)


Source: Authors’ calculations from the Kentucky WPRS Experiment.
                                                                           43




    Week        0        1        2         3         4        5



           Claim filed                                      Services end
                                         Letter
                                         received
                             First check         Orientation
                              received           and other
                                                 services
                                                 received;
                                                 second
                                                 check
                                                 received




Figure 1: Timeline for Typical UI Claimant in Kentucky WPRS Program
                                                                                                               45


                  0.140


                  0.120


                  0.100
    Hazard Rate




                  0.080


                  0.060


                  0.040


                  0.020


                  0.000
                          1   2   3   4   5   6   7   8   9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
                                                                  Week

                                                      Control Group      Treatment Group




Figure 2: Hazard Functions of the Treatment and Control Groups,
Kentucky WPRS Experiment, October 1994 to June 1996

Notes: Authors’ calculation from Kentucky WPRS Experiment. Triangles denote significant differences at the five-
percent level. The parameter estimates used to construct the graph appear in Table B1 of Black, Smith, Berger, and
Noel (1999).
                                                                                                                          45

           6000.000


           5000.000


           4000.000
Earnings




           3000.000


           2000.000


           1000.000


              0.000
                        -4        -3       -2        -1        1             2      3       4         5         6
                                                                   Quarter

                                                      Control Group      Treatment Group




                             Figure 3: Earnings of the Treatment and Control Groups,
                              Kentucky WPRS Experiment, October 1994 to June 1996


           Notes: Authors’ calculation from Kentucky WPRS Experiment. Triangles denote significant differences at the five-
           percent level. The parameter estimates used to construct the graph appear in Table B2 of Black, Smith, Berger, and
           Noel (1999).
                                                                                                                  46

                    1.000

                    0.900

                    0.800

                    0.700
Fraction Employed




                    0.600

                    0.500

                    0.400

                    0.300

                    0.200

                    0.100

                    0.000
                            -4   -3    -2    -1           1             2         3       4   5      6
                                                              Quarter

                                                  Control Group         Treatment Group




                            Figure 4: Employment of the Treatment and Control Groups,
                              Kentucky WPRS Experiment, October 1994 to June 1996

   Notes: Authors’ calculation from Kentucky WPRS Experiment. Triangles denote significant differences at the five-
   percent level. The parameter estimates used to construct the graph appear in Table B2 of Black, Smith, Berger, and
   Noel (1999).
                       0                                                                                                                                 1600
                                                                                                                                                                                                                47
                                                                                                                                                         1400

Impact on Weeks Paid




                                                                                                                                    Impact on Earnings
                       -1                                                                                                                                1200
                                                                                                                                                         1000
                       -2                                                                                                                                800
                                                                                                                                                         600
                       -3                                                                                                                                400
                                                                                                                                                         200
                       -4                                                                                                                                  0
                            0               20             40                                      60        80         100                                     0        20         40                60   80        100
                                                                      Percentile                                                                                                         Percentile



                                                                                        300
                                                                                        200
                                                                Impact on Amount Paid



                                                                                        100
                                                                                          0
                                                                                        -100
                                                                                        -200

                                                                                        -300
                                                                                        -400
                                                                                        -500
                                                                                               0        20        40                60                              80        100
                                                                                                                       Percentile


                                  Figure 5: Impact of Treatment on Weeks Paid, Benefits Paid, and Earnings at Quantiles of the Untreated
                                              Outcome Distribution, Kentucky WPRS Experiment, October 1994 to June 1996
                                Notes: Authors’ calculation from Kentucky WPRS Experiment. Triangles denote significant differences at the five-percent level. The parameter estimates used
                                to construct the graph appear in Table B3 of Black, Smith, Berger and Noel (1999).
                                           CABINET FOR HUMAN RESOURCES
                                           COMMONWEALTH OF KENTUCKY
                                                 FRANKFORT 40621



   DEPARTMENT FOR EMPLOYMENT SERVICES

                                                                                             DATE:
                                                                                             SS #:
                                                                                             LO #:


               Dear Claimant:

               You have been identified as a dislocated worker and selected under the UI Claimant Profiling
               Program to receive job search assistance services. You are obligated under the law to
               participate. Failure to report or participate in reemployment services without justifiable cause
               may result in denial of your unemployment insurance benefits

               This program is designed to provide job search assistance services to those UI claimants
               identified as being most likely to need assistance in finding new employment. We will assess
               your needs and work with you to decide which services may increase your chances of finding
               a good job. Services may include counseling, job search workshops, testing, job referral and
               placement, or if needed, referral to more intensive services, such as training.

               If you are presently enrolled in training, have recently received job search services, or are
               engaged in any job search services that you believe may exempt you from participation in this
               program, bring all documents or relevant information concerning your participation with you
               when you report to the local office.

               You are REQUIRED BY LAW, KRS 341 .350(2)(b), to attend the Orientation Session at the
               place, date and time specified below:

               PLACE:


               DATE:

               TIME:

               You may be determined ineligible to receive unemployment insurance benefits for failure to
               report to your local office as instructed or failure to participate in required services.


               If you are UNABLE TO ATTEND,



               Your participation in orientation may be postponed if you have a compelling reason to prevent
               you from attending on the date and time stated above, BUT it must be for circumstances
               beyond your control. Any postponement will be reported to UI for review of your availability.

               BRING THIS LETTER WITH YOU WHEN YOU COME IN.

UI-P-100

(Rev. 09/94)                                             JOB SERVICE

                                                         Exhibit 1
