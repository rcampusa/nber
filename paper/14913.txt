                               NBER WORKING PAPER SERIES




                       U.S. STOCK MARKET CRASH RISK, 1926-2006

                                          David S. Bates

                                       Working Paper 14913
                               http://www.nber.org/papers/w14913


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                                     April 2009




I am grateful for comments on earlier versions of the paper from seminar participants at Iowa, Turin,
Birkbeck, McGill’s 2008 Risk Management Conference, the 18th Annual Derivatives Securities and
Risk Management Conference in Arlington, VA, and Princeton’s 2008 Conference on Implied Volatility
Models. I also thank Ken French for providing the stock turnover data from French (2008). The views
expressed herein are those of the author(s) and do not necessarily reflect the views of the National
Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2009 by David S. Bates. All rights reserved. Short sections of text, not to exceed two paragraphs,
may be quoted without explicit permission provided that full credit, including © notice, is given to
the source.
U.S. Stock Market Crash Risk, 1926-2006
David S. Bates
NBER Working Paper No. 14913
April 2009
JEL No. C22,C46,G1,G13

                                           ABSTRACT

This paper applies the Bates (RFS, 2006) methodology to the problem of estimating and filtering time-
changed Lévy processes, using daily data on U.S. stock market excess returns over 1926-2006. In
contrast to density-based filtration approaches, the methodology recursively updates the associated
conditional characteristic functions of the latent variables. The paper examines how well time-changed
Lévy specifications capture stochastic volatility, the “leverage” effect, and the substantial outliers
occasionally observed in stock market returns. The paper also finds that the autocorrelation of stock
market excess returns varies substantially over time, necessitating an additional latent variable when
analyzing historical data on stock market returns. The paper explores option pricing implications,
and compares the results with observed prices of options on S&P 500 futures.


David S. Bates
Henry B. Tippie College of Business
Department of Finance
University of Iowa
Iowa City, IA 52242-1000
and NBER
david-bates@uiowa.edu
What is the risk of stock market crashes? Answering this question is complicated by two features
of stock market returns: the fact that conditional volatility evolves over time, and the fat-tailed
nature of daily stock market returns. Each issue affects the other. What we identify as outliers
depends upon that day’s assessment of conditional volatility. Conversely, our estimates of current
volatility from past returns can be disproportionately affected by outliers such as the 1987 crash.
In standard GARCH specifications, for instance, a 10% daily change in the stock market has 100
times the impact on conditional variance revisions of a more typical 1% move.


       This paper explores whether recently proposed continuous-time specifications of time-
changed Lévy processes are a useful way to capture the twin properties of stochastic volatility and
fat tails. The use of Lévy processes to capture outliers dates back at least to Mandelbrot’s (1963)
use of the stable Paretian distribution, and there have been many specifications proposed; e.g.,
Merton’s (1976) jump-diffusion, Madan and Seneta’s (1990) variance gamma; Eberlein, Keller and
Prause’s (1998) hyperbolic Lévy; and Carr, Madan, Geman and Yor’s (2002) CGMY process. As
all of these distributions assume identical and independently distributed returns, however, they are
unable to capture stochastic volatility.


       More recently, Carr, Geman, Madan and Yor (2003) and Carr and Wu (2004) have proposed
combining Lévy processes with a subordinated time process. The idea of randomizing time dates
back to at least to Clark (1973). Its appeal in conjunction with Lévy processes reflects the increasing
focus in finance – especially in option pricing – on representing probability distributions by their
associated characteristic functions. Lévy processes have log characteristic functions that are linear
in time. If the time randomization depends on underlying variables that have an analytic conditional
characteristic function, the resulting conditional characteristic function of time-changed Lévy
processes is also analytic. Conditional probability densities, distributions, and option prices can then
be numerically computed by Fourier inversion of simple functional transforms of this characteristic
function.


       Thus far, empirical research on the relevance of time-changed Lévy processes for stock
market returns has largely been limited to the special cases of time-changed versions of Brownian
                                                   2

motion and Merton’s (1976) jump-diffusion. Furthermore, there has been virtually no estimation
of newly proposed time-changed Lévy processes solely from time series data.1 Papers such as Carr
et al (2003) and Carr and Wu (2004) have relied on option pricing evidence to provide empirical
support for their approach, rather than providing direct time series evidence. The reliance on options
data is understandable. Since the state variables driving the time randomization are not directly
observable, time-changed Lévy processes are hidden Markov models – a challenging problem in
time series econometrics. Using option prices potentially identifies realizations of those latent state
variables, converting the estimation problem into the substantially more tractable problem of
estimating state space models with observable state variables.


       While options-influenced parameter and state variable estimates should be informative under
the hypothesis of correct model specification, the objective of the paper is to provide estimates of
crash risk based solely upon time series analysis. Such estimates are of interest in their own right,
and can exploit a longer history of extreme stock market movements than can studies constrained
by the availability of options data only since the 1980’s. For instance, the       stock market crash
of October 19, 1987 was the only daily stock market movement over 1945-2006 to exceed 10% in
magnitude, whereas there were seven such movements over 1929-32. Furthermore, time-series
based estimates can be relevant even for testing option pricing hypotheses. For instance, it has been
asserted that deep OTM index put options appear overpriced, based on their surprisingly large
negative returns since the ‘87 crash. But all such tests require reliable estimates of downside risk;
and it can be difficult to establish whether puts are indeed overpriced based only on the limited
amount of data since the 1987 crash.2 Time series estimates can exploit a longer history of downside
risk, and can be used to generate estimates of option prices that can be compared with observed
option prices.




       1
           Li, Wells and Yu (2008) use MCMC methods to estimate some models in which Lévy
shocks are added to various stochastic volatility models. However, the additional Lévy shocks are
i.i.d., rather than time-changed.
       2
        See Broadie, Chernov, and Johannes (2006) for a Monte Carlo study of unhedged 1-month
excess returns for puts on S&P 500 futures over August 1987 to June 2005. They find excess return
estimates often lack statistical significance, especially when volatility is stochastic.
                                                    3

        This paper provides direct time series estimates of some proposed time-changed Lévy
processes, using the Bates (2006) approximate maximum likelihood (AML) methodology. AML is
a filtration methodology that recursively updates conditional characteristic functions of latent
variables over time given observed data. Filtered estimates of the latent variables are directly
provided as a by-product, given the close link between moments and characteristic functions. The
paper primarily focuses on the time-changed CGMY process, which nests various other processes
as special cases. The approach will also be compared to the time-changed jump-diffusions
previously estimated in Bates (2006).


        A concern with any extended data set is the possibility that the data generating process may
not be stable over time. Indeed, this paper identifies a major instability in the autocorrelation of
daily stock market returns. Autocorrelation estimates appear to be nonstationary, and peaked at the
extraordinarily high level of 35% in 1971, before trending downwards to the near-zero values
observed since the 1980’s. The instability is addressed directly, by treating the autocorrelation as
another latent state variable to be estimated from observed stock market returns. The paper also
finds apparent instabilities or specification issues in the 1-factor volatility process used, and explores
the implications for volatility filtration and option pricing.


        Overall, the time-changed CGMY process is found to be a slightly more parsimonious
alternative to the Bates (2006) approach of using finite-activity stochastic-intensity jumps drawn
from a mixture of normals, although the fits of the two approaches are not dramatically different.
Interestingly, one cannot reject the hypothesis that stock market crash risk is adequately captured
by a time-changed version of the Carr-Wu (2003) log-stable process. That model’s implications for
upside risk, however, are strongly rejected, with the model severely underpredicting the frequency
of large positive outliers.


        Section I of the paper progressively builds up the time series model used in estimation.
Section I.1 discusses basic Lévy processes and describes the processes considered in this paper.
Section I.2 discusses time changes and the equivalence with stochastic volatility. Section I.3
contains further modifications of the model to capture leverage effects, time-varying
autocorrelations, and day-of-the-week effects. Section I.4 describes how the model is estimated,
                                                   4

using the Bates (2006) AML estimation methodology for hidden Markov models.


        Section II describes the data on excess stock market returns over 1926-2006, and presents
parameter estimates, diagnostics, and and filtered estimates of latent autocorrelation and volatility.
Section III examines option pricing implications, while Section IV concludes.


I. Time-changed Lévy processes
I.1 Lévy processes
A Lévy process         is an infinitely divisible stochastic process; i.e., one that has independent and
identically distributed increments over non-overlapping time intervals of equal length. The Lévy
processes most commonly used in finance have been Brownian motion and the jump-diffusion
process of Merton (1976), but there are many others. All Lévy processes without a Brownian
motion component are pure jump processes. Such processes are characterized by their Lévy density
    , which gives the intensity (or frequency) of jumps of size x. Alternatively and equivalently,
Lévy processes can be described by their generalized Fourier transform

                                                                                                    (1)

where u is a complex-valued element of the set           for which (1) is well-defined. If        is real,
        is the characteristic function of     , while          is the cumulant generating function of
    . Its linearity in time follows from the fact that Lévy processes have i.i.d. increments.
Following Wu (2006), the function             will be called the cumulant exponent of        .3


        The Lévy-Khintchine formula gives the mapping between jump intensities                    and the
cumulant exponent for arbitrary             . Lévy processes in finance are typically specified for the
log asset price, and then exponentiated:                    . For such specifications, it is convenient
to write the Lévy-Khintchine formula in the form

                                                                                                    (2)

where               is the continuously-compounded expected return on the asset:


        3
        Carr et al (2003) call      the “unit time log characteristic function.” Bertoin (1996) uses
the characteristic exponent, which takes the form                      .
                                                   5

                                                                                                   (3)

Pure-jump Lévy processes can be thought of as a drift term plus an infinite sum                      of
independent point processes, each drift-adjusted to make                 a martingale:

                                                                                                    (4)

where      is an integer-valued Poisson counter with intensity          that counts the occurrence of
jumps of fixed size x. The log characteristic function of a sum of independent point processes is the
sum of the log characteristic functions of the point processes, yielding equation (2). Exponential
martingale processes of the form                       for   defined in (4) will be termed compensated
Lévy processes, as will also diffusions of the form                 .


        As discussed in Carr et al (2002), Lévy processes are finite-activity if                  , and
infinite-activity otherwise. Finite-activity jumps imply there is a non-zero probability that no jumps
will be observed within a given time interval.               Lévy processes are finite-variation if
                 , and infinite-variation otherwise. An infinite-variation process has sample paths
of infinite length – a property also of Brownian motion. All Lévy processes must have finite
                     , in order to be well-behaved, but need not have finite variance                    –
the stable distribution being an counterexample. A priori, all financial prices must be finite-activity
processes, since price changes reflect a finite (but large) number of market transactions. However,
finite-activity processes can be well approximated by infinite-activity processes, and vice versa; e.g.,
the Cox, Ross and Rubinstein (1979) finite-activity binomial approximation to Brownian motion.
Activity and variation will therefore be treated as empirical specification issues concerned with
identifying which functional form          for jump intensities best fits daily stock market excess
returns.


        I will consider two particular underlying Lévy processes for log asset prices. The first is
Merton (1976)’s combination of a Brownian motion plus finite-activity normally distributed jumps:

                                                                                                   (5)

where       is a Wiener process,
                                                 6

           is a Poisson counter with intensity   ,
                       is the normally distributed jump conditional upon a jump occurring, and
                         is the expected percentage jump size conditional upon a jump.
The associated intensity of jumps of size x is


                                                                                               (6)


while the cumulant exponent takes the form




The approach can be generalized to allow alternate distributions for   – in particular, a mixture of
normals:


                                                                                                (7)




        Second, I will consider the generalized CGMY process of Carr, Madan, Geman and Yor
(2003), which has a Lévy density of the form


                                                                                               (8)




where                      and             . The associated cumulant exponent is


                                                                                               (9)


where      is a mean-normalizing constant determined by                 ;
        V is the variance per unit time, and
           is the fraction of variance attributable to the downward-jump component.
The corresponding intensity parameters           in (8) are
                                                      7


                                                                                                   (10)


where           is the gamma function.


        As discussed in Carr et al (2002), the      parameters are key in controlling jump activity near
0, in addition to their influence over tail events. The process has finite activity for            , finite
variation for              , but infinite activity or variation if             is greater or equal to 0 or
1, respectively. The model conveniently nests many models considered elsewhere. For instance,
                   is the finite-activity double exponential jump model of Kou (2002), while
                 includes the variance gamma model of Madan and Seneta (1990). As                 and
approach 2, the CGMY process converges to a diffusion, and the cumulant exponent converges to
the corresponding quadratic form

                                                                                                   (11)



        As G and M approach 0 (for arbitrary              ,   and fixed         ), the Lévy density (8)
approaches the infinite-variance log stable process advocated by Mandelbrot (1963), with a “power
law” property for asymptotic tail probabilities. The log-stable special case proposed by Carr and
Wu (2003) is the limiting case with only negative jumps (             ). While infinite-variance for log
returns, percentage returns have finite mean and variance under the log-stable specification. For
daily stock market returns of less than 25% in magnitude, the log-stable process is well
approximated by a finite-variance CGMY process with minimal exponential dampening; e.g.,
          .


        The cumulant exponent of any finite-variance Lévy process can written in the form

                                                                                                   (12)

where                is variance per unit time and            is a standardized cumulant exponent with
unitary variance. One can also combine Lévy processes, to nest alternative specifications within a
broader specification. Any linear combination                         of Lévy densities for nonnegative
                                                     8

weights that sum to one is also a valid Lévy density, and generates an associated standardized
weighted cumulant exponent of the form                               , where           is the standardized
cumulant exponent associated with           for          1,2. The various           specifications that will
be considered in this paper are listed in Table 1.


I.2 Time-changed Lévy processes and stochastic volatility
Time-changed Lévy processes generate stochastic volatility by randomizing time in equation (1).
Since the log transform (1) can be written as                               , randomizing time is funda-
mentally equivalent to randomizing variance. As the connection between time changes and
stochastic volatility becomes less transparent once “leverage” effects are added, I will use an explicit
stochastic volatility (or stochastic intensity) representation of stochastic processes.


       The leverage effect, or correlation between asset returns and conditional variance
innovations, is captured by directly specifying shocks common to both. I will initially assume that
the log asset price           follows a process of the form


                                                                                                     (13)


The log increment        consists of the continuously-compounded return, plus increments to two
exponential martingales.        is a Wiener increment, while          is the increment to a compensated
Lévy process, with finite instantaneous variance                    . Further refinements will be added
below, to match properties of stock market returns more closely.


       This specification has various features or implicit assumptions. First, the approach allows
considerable flexibility regarding the distribution of the instantaneous shock             to asset returns,
which can be Wiener, compound Poisson, or any other fat-tailed distribution. Three underlying
Lévy processes are considered:
    1) a second diffusion with variance                    that is independent of      (Heston, 1993);
    2) finite-activity jumps drawn from a normal distribution or a mixture of normals; and
    3) the generalized CGMY (2003) Lévy process from (8) above.
Combinations of these processes will also be considered, to nest the alternatives.
                                                  9

       Second, the specification assumes a single underlying variance state variable       that follows
an affine diffusion, and which directly determines the variance of diffusion and jump components.
This approach generalizes the stochastic jump intensity model of Bates (2000, 2006) to arbitrary
Lévy processes.


       Two alternate specifications are not considered, for different reasons. First, I do not consider
the approach of Li, Wells and Yu (2008), who model log-differenced asset prices as the sum of a
Heston (1993) stochastic volatility process and a constant-intensity fat-tailed Lévy process that
captures outliers. Bates (2006, Table 7) found the stochastic-intensity jump model fits S&P returns
better than the constant-intensity specification, when jumps are drawn from a finite-activity normal
distribution or mixture of normals. Second, the diffusion assumption for     rules out volatility-jump
models, such as the exponential-jump model proposed by Duffie, Pan and Singleton (2000) and
estimated by Eraker, Johannes and Polson (2003). Estimation on simulated data indicates that the
AML filtration methodology described below has difficulty identifying whether there are jumps in
an underlying conditional variance state variable that is not directly observed.


       Define                as the discrete-time return observed over horizon             , and define
                             as the cumulant exponent of         conditional upon knowing        . By
construction,        is a standardized cumulant exponent, with              and variance                .
A key property of affine models is the ability to compute the conditional generalized Fourier
transform of            . This can be done by iterated expectations, conditioning initially on the
future variance path:




                                                                                                 (14)




for                                                   . This is the generalized Fourier transform of
the future spot variance   and the average future variance                      . This is a well-known
                                               10

problem (see, e.g., Bakshi and Madan, 2000), with an analytic solution if           follows an affine
process. For the affine diffusion above,             solves the Feynman-Kac partial differential
equation

                                                                                                (15)

subject to the boundary condition                            . The solution is

                                                                                               (16)

where



                                                                                               (17)




                                                                                                (18)



                                                                                                (19)




                                                                                                (20)




                                                                                                (21)



The specifications of       considered in this paper are listed above in Table 1.


I.3 Autocorrelations and other refinements
That stock indexes do not follow a random walk was recognized explicitly by Lo and MacKinlay
(1988), and implicitly by earlier practices in variance and covariance estimation designed to cope
                                                  11

with autocorrelated returns; e.g., Dimson (1979)’s lead/lag approach to beta estimation. The
positive autocorrelations typically estimated for stock index returns are commonly attributed to stale
prices in the stocks underlying the index. A standard practice in time series analysis is to pre-filter
the data by fitting an ARMA specification; see, e.g., Jukivuolle (1995). Andersen, Benzoni and
Lund (2002), for instance, use a simple MA(1) specification to remove autocorrelations in S&P 500
returns over 1953-96; a data set subsequently used by Bates (2006).


        Prefiltering the data was considered unappealing in this study, for several reasons. First, the
1926-2006 interval used here is long, with considerable variation over time in market trading
activity and transactions costs, and structural shifts in the data generating process are probable.
Indeed, Andersen et al (2002, Table 1) find autocorrelation estimates from their full 1953-96 sample
diverge from estimates for a 1980-96 subsample. Second, ARMA packages use a mean squared
error criterion that is not robust to the fat tails observed in stock market returns. Finally, explicit
consideration of autocorrelation is needed when assessing the variance of relevance to option
pricing.


        Consequently, autocorrelations were treated as an additional latent variable, to be estimated
as part of the overall time series model. I will explore below two alternate models for daily log-
differenced stock index excess returns     :

                                                                                                  (22)
        or

                                                                                                  (23)
where




                                                                                                  (24)




   is the effective length of a business day,     determines is the daily autocorrelation,       is the
instantaneous intradaily underlying shock to log asset prices, and                              is the
instantaneous conditional variance of     . The intradaily shocks             are given by (13) above.
                                                     12

        Both models add an autocorrelation state variable               that captures the fact that auto-
correlations of stock market returns are not constant over time.4 Following the literature on time-
varying coefficient models, the autocorrelation is modeled as a simple random walk, to avoid
constraining estimates of       . Estimation of the autocorrelation volatility parameter     endogenously
determines the appropriate degree of smoothing to use when filtering the current autocorrelation
value       from past data.


        The two models differ in ease of use, in their implications for the interaction between
volatility and autocorrelation, and in the pricing of risks. Model 1 assumes the stock market excess
return residual                        is stationary (i.e., with a stationary conditional variance process),
and that the current value of       affects only the conditional mean of       . Autocorrelation filtration
in the model is consequently closer to standard autocorrelation estimation, and becomes identical
when         is i.i.d. Gaussian and the autocorrelation is constant (        ). Model 1 is also somewhat
more convenient for estimation, in that it has a “semi-affine” structure that can be directly estimated
using the methodology of Bates (2006).


        In Model 2,           is the permanent impact of daily shocks to stock index excess returns, and
is again assumed stationary. The model assumes that infrequent trading in the component stocks
(proxied by       ) slows the incorporation of such shocks into the observed stock index, but that the
index ultimately responds fully once all stocks have traded.5 Unlike Model 1, Model 2 is consistent
with LeBaron’s (1992) observation that annual estimates of daily stock market volatility and
autocorrelation appear inversely related. Higher autocorrelations smooth shocks across periods,
reducing observed market volatility. Furthermore, the model is more suitable for pricing risks; i.e.,
identifying the equity premium, or the (affine) risk-neutral process underlying option prices. The
current value of       affects both the conditional mean and higher moments of              , resulting in a



        4
        See, e.g., Andersen, Benzoni and Lund (2002, Table I), who estimate different
autocorrelations for 1953-96 and 1980-96.
        5
         Jukivuolle (1995) distinguishes between the “observed” and “true” stock index when trading
is infrequent, and proposes using a standard Beveridge-Nelson decomposition to identify the latter.
This paper differs in assuming that the parameters of the ARIMA process for the observed stock
index are not constant.
                                                 13

significantly different filtration procedure for estimating     from past excess returns. The time
series model is not semi-affine, but I develop below a transformation of variables that makes
filtration and estimation as tractable as for Model 1.


        Both models build upon previous time series and market microstructure research into stock
market returns. For instance, the effective length    of a business day is allowed to vary based upon
various periodic effects. In particular, day-of-the-week effects, weekends, and holidays are
accommodated by estimated time dummies that allow day-specific variation in       . In addition, time
dummies were estimated for the Saturday morning trading available over 1926-52, and for the
Wednesday exchange holidays in the second half of 1968 that are the focus of French and Roll
(1986).6 Finally, the stock market closings during the “Bank Holiday” of March 3-15, 1933 and
following the September 11, 2001 attacks were treated as        - and    -year returns, respectively.
Treating the 1933 Bank Holiday as a 12-day interval substantially reduces the influence of its
+15.5% return on parameter estimation. September 17, 2001 saw a smaller movement, of -4.7%.


        For Model 1, the cumulant generating function of future returns and state variable
realizations conditional upon current values is analytic, and of the semi-affine form


                                                                                               (25)


where                                         , and             and             are given in (17) and
(18) above. For model 2, the conditional cumulant generating function is of the non-affine form

                                                                                               (26)

given the shocks to      are scaled by          .7



        6
        Gallant, Rossi and Tauchen (1992) use a similar approach, and also estimate monthly
seasonals.
        7
        Dilip Madan informs me that practitioners distinguish between time-scaled and space-scaled
models of time-varying volatility. GARCH models are typically space-scaled, whereas Model 1 is
a time-scaled model of stochastic volatility. Model 2 contains both (stationary) time scaling via
and the time dummies, and (non-stationary) space scaling via         .
                                                   14

I.4 Filtration and maximum likelihood estimation
If the state variables         were observed along with returns, it would in principle be possible to
evaluate the joint transition densities of the data and the state variable evolution by Fourier inversion
of the joint conditional characteristic function                         , and to use this in a maximum
likelihood procedure to estimate the parameters of the stochastic process. However, since
are latent rather than directly observed, this is a hidden Markov model that must be estimated by
other means.


        For Model 1, the assumption that the cumulant generating function (25) is affine in the latent
state variables          implies that the hidden Markov model can be filtered and estimated using
the approximate maximum likelihood (AML) methodology of Bates (2006). The AML procedure
is a filtration methodology that recursively updates the conditional characteristic functions of the
latent variables and future data conditional upon the latest datum. Define                            as
the data observed up through period t, and define

                                                                                                  (27)

as the joint conditional characteristic function that summarizes what is known at time t about
         . The density of the observation          conditional upon       can be computed by Fourier
inversion of its conditional characteristic function:


                                                                                                  (28)



Conversely, the joint conditional characteristic function                         needed for the next
observation can be updated given          by the characteristic-function equivalent of Bayes’ rule:


                                                                                                  (29)


        The algorithm begins with an initial joint characteristic function                and proceeds
recursively through the entire data set, generating the log likelihood function                     used
in maximum likelihood estimation. Filtered estimates of the latent variables can be computed from
derivatives of the joint conditional moment generating function, as can higher conditional moments:
                                                15


                                                                                             (30)




       The above procedure, if implementable, would permit exact maximum likelihood function
estimation of parameters. However, the procedure would require storing and updating the entire
function         based on point-by-point univariate numerical integrations. As such a procedure
would be slow, the AML methodology instead approximates                at each point in time by a
moment-matching joint characteristic function, and updates the approximation based upon updated
estimates of the moments of the latent variables. Given an approximate prior          and a datum
    , (30) is used to compute the posterior moments of              , which are then used to create
an approximate            . The overall procedure is analogous to the Kalman filtration procedure
of updating conditional means and variances of latent variables based upon observed data, under the
assumption that those variables and the data have a conditional normal distribution. However, the
equations (29) and (30) identify the optimal nonlinear moment updating rules for a given prior
      , whereas standard Kalman filtration uses linear rules. It will be shown below that this
modification in filtration rules is important when estimating latent autocorrelations and variances
under fat-tailed Lévy processes. Furthermore, Bates (2006) proves that the iterative AML filtration
is numerically stable, and shows that it performs well in estimating parameters and latent variable
realizations.


       Autocorrelations can be negative or positive, while conditional variance must be positive.
Consequently, different two-parameter distributions were used to summarize conditional
distributions of the two latent variables: Gaussian for autocorrelations, gamma for variances.
Furthermore, since volatility estimates mean-revert within months whereas autocorrelation estimates
evolve over years, realizations of the two latent variables were assumed conditionally independent.
These assumptions resulted in an approximate conditional characteristic function of the form

                                                                                             (31)

The following summarizes key features of joint conditional distributions of the latent variables.
                                                   16

                              Autocorrelation                      spot variance
     Distribution
     conditional
     cumulant
     generating function

     initial CGF


                                                assumed independent for all t.


        Initial variance was assumed drawn from its unconditional gamma distribution, with the
parameters              given above.     Since autocorrelations were assumed nonstationary, no
unconditional distribution exists. Consequently, the AML algorithm for Model 1 was initiated using
a relatively diffuse conditional distribution for the initial autocorrelation – one much wider than the
plausible (-1, +1) range.


        The parameters                            – or, equivalently the moments
– summarize what is known about the latent variables. These were updated daily using the latest
observation         and equations (29) - (30). For each day, 5 univariate integrations were required:
1 for the density evaluation in (29), and 4 for the mean and variance evaluations in (30). An upper
was computed for each integral which upper truncation error would be less than            in magnitude.
The integrands were then integrated over                       to a relative accuracy of         , using
IMSL’s adaptive Gauss-Legendre quadrature routine DQDAG and exploiting the fact that the
integrands for negative      are the complex conjugates of the integrands evaluated at positive        .
On average between 234 and 448 evaluations of the integrand were required for each integration.8


        The non-affine specification                                in Model 2 necessitates additional
restrictions upon the distribution of latent    . In particular, it is desirable that the scaling factor
       be nonnegative, so that the lower tail properties of        originating in the underlying Lévy



        8
         The FFT approach used in Carr et al (2002) uses 16,384 functional evaluations.
                                                     17

specifications do not influence the upper tail properties of        . Consequently, the distribution of
latent         for Model 2 is modeled as inverse Gaussian – a 2-parameter unimodal distribution with
conditional mean             and variance        . Appendix A derives the resultant filtration procedure
for this model, exploiting a useful change of variables procedure. The filtration is initiated at
                , and it is again assumed that      and    are conditionally independent for all t.


II. Properties of U.S. stock market returns, 1926 - 2006
II.1 Data
There are two readily available value-weighted measures of the U.S. stock market: the CRSP value-
weighted index, and the S&P Composite Index. This paper will primarily focus upon the former for
time series analysis, but will also consider the latter when assessing options on S&P 500 futures. The
CRSP data consist of 21,519 daily cum-dividend returns over January 2, 1926 through December
29, 2006. CRSP daily returns for each month were converted to daily log excess returns using
Ibbotson and Associates’ data on monthly Treasury bill returns, and the formula


                                                                                                  (32)


where        is the daily CRSP cum-dividend return;
             is that month’s return on Treasury bills of at least 1 month to maturity;
         N is the number of calendar days spanned by the monthly Treasury bill return; and
             is the number of calendar days spanned by the “daily” return       .
The monthly interest rate data were downloaded from Ken French’s Web site, and extended
backwards through 1926 using data in Ibbotson and Associates’ SBBI Yearbook.


         The Schwert (1990) data set of daily U.S. stock market returns provides cum-dividend
returns on the S&P Composite Index from January 4, 1928 onwards.9 The S&P index was based
upon 90 stocks until March 4, 1957, and 500 stocks thereafter. I updated Schwert’s data through
2006 using Schwert’s data methodology: ex-dividend daily S&P 500 returns from CRSP were
augmented by an average daily dividend yield computed from monthly S&P 500 dividend yields


         9
         Schwert also has daily data extending back to 1885, based on the (price-weighted) Dow
Jones Industrial Average.
                                                 18

from Bloomberg. Cum-dividend returns were then converted into log excess returns using (32).
Furthermore, CRSP value-weighted returns were used instead of the S&P 90 returns prior to March
5, 1957, for two reasons. First, that delivers data over 1926 and 1927, which is important for
volatility assessment prior to the 1929 stock market crash. Second, the S&P Composite Index is
only reported to two decimal places, which creates significant rounding error issues for the low S&P
index values (around 5) observed in the 1930’s.


II.2 Parameter estimates
Table 2 describes and provides estimates of the time dummies from the most general time-changed
CGMY model,10 with Wednesday returns (Tuesday close to Wednesday close) arbitrarily selected
as the benchmark day. Daily variance tended to be highest at the beginning of the week and decline
thereafter, but day-of-the-week effects do not appear to be especially pronounced. The major
exception is the Saturday morning (10 AM to noon) trading generally available over 1926-52.11
Saturdays were effectively 43% as long as the typical Wednesday. Total weekend variance (Friday
close to Monday close) was (.43 + 1.05) / 1.10 - 1 = 34.5% higher when Saturday trading was
available (over 1926-52) than when it was not (over 1945-2006).12 This is qualitatively similar to
but less pronounced than the doubling of weekend variance found by Barclay, Litzenberger and
Warner (1990) in Japanese markets when Saturday half-day trading was feasible. Barclay et al
lucidly discuss market microstructure explanations for the increase in variance.


       Holidays generally did not have a strong impact on the effective length of a business day –
with the exception of holiday weekends spanning 4 calendar days. Consistent with French and Roll
(1986), 2-day returns spanning the Wednesday exchange holidays in 1968 (Tuesday close to
Thursday close) had a variance not statistically different from a typical 1-day Wednesday return, but



       10
         Estimates from other specifications were virtually identical, with estimates typically within
±0.01 of the YY model’s estimates.
       11
       Saturday trading was standard before 1945. Over 1945-51, it was increasingly eliminated
in summer months, and was permanently eliminated on June 1, 1952.
       12
          As the time dummy estimates are estimated jointly with the volatility and autocorrelation
filtrations, the estimates of weekend variances with versus without Saturday trading control for
divergences in volatility and autocorrelation levels in the two samples.
                                                  19

substantially less than the 1 + .94 = 1.94 two-day variance observed for returns from Tuesday close
to Thursday close in other years. Overall, the common practice of ignoring day-of-the-week effects,
weekends, and holidays when analyzing the time series properties of daily stock market returns
appears to be a reasonable approximation, provided the data exclude Saturday trading.


         Tables 3A and 3B report estimates for various specifications listed in Table 1, while Figure
1 presents associated normal probability plots for model 2. (The plots for Model 1 were similar.)
As noted above, all specifications capture the leverage effect by a correlation      with the diffusion
shock to conditional variance. The specifications diverge in their modeling of the Lévy shocks
orthogonal to the variance innovation. SV is the Heston model, while SVJ1 and SVJ2 have a
diffusion for small asset return shocks, plus finite-activity normally-distributed jumps to capture
outliers. The other models examine the generalized time-changed CGMY model, along with
specific parameter restrictions or relaxations.


         Most specifications using either Model 1 or Model 2 have similar estimates for the
parameters determining the conditional mean and stochastic variance evolution. The evidence for
a variance-sensitive equity premium (          ) is stronger for Model 2 specifications, but      is not
typically significantly different from zero for either model. Latent permanent variance in Model 2
mean-reverts towards an estimated average level around             , with a half-life about 1.6 months.
The SV and LS models are the outliers, with different estimates of the equity premia and variance
process from other specifications. As discussed below in section II.6, this reflects these two
specifications’ substantially different approach to variance filtration, given different assessments of
tail risk.


         The various specifications primarily diverge in how they capture tail risk. The Merton-based
SVJ1 and SVJ2 results in Table 3B largely replicate the jump risk results in Bates (2006). The SVJ1
model has symmetric normally-distributed jumps with standard deviation 3 - 3.4% and time-varying
jump intensities that occur on average             = 3.3 - 3.7 jumps per year. As shown in Figure 1,
this jump risk assessment fails to capture the substantial 1987 crash. By contrast, the SVJ2 model
adds a second jump component that directly captures the 1987 outlier. The resulting increase in log
likelihood from is statistically significant under a likelihood ratio test, with a marginal significance
                                                  20

level around 3% for Models 1 and 2.


       The various CGMY models primarily diverge across the specification of the
parameters – whether they are set to specific levels, and whether they diverge for the intensities of
positive versus negative jumps. The DEXP model with                      is conceptually similar to the
jump-diffusion model SVJ1, but uses instead a finite-activity double exponential distribution for
jumps. Despite the fatter-tailed specification, Figure 1 indicates the DEXP model has difficulties
comparable to SVJ1 in capturing the 1987 crash. The VG model replaces the finite-activity double
exponential distribution with the infinite-activity variance process (             ), and does slightly
better in fit. Both models include a diffusion component, which captures 73-74% of the variance
of the orthogonal Lévy shock        .


       Specifications Y, YY, and LS involve pure-jump processes for the orthogonal Lévy process
  , without a diffusion component. Overall, higher values of Y fit the data better – especially the
1987 crash, which ceases to be an outlier under these specifications. Relaxing the restriction
         leads to some improvement in fit, with the increase in log likelihood (YY versus Y) having
P-values of 1.8% and 0.8% for Models 1 and 2, respectively. Point estimates of the jump parameters
              governing downward jump intensities diverge sharply from the parameters
                  governing upward jump intensities when the                   restriction is relaxed,
although standard errors are large. The dampening coefficient       is not significantly different from
zero, implying one cannot reject the hypothesis that the downward-jump intensity is from a
stochastic-intensity version of the Carr-Wu (2003) log-stable process. By contrast, the upward
intensity is estimated as a finite-activity jump process – which, however, still overestimates the
frequency of big positive outliers (Figure 1, sixth panel).


       Motivated by option pricing issues, Carr and Wu (2003) advocate using a log-stable
distribution with purely downward jumps. An approximation to this model generated by setting
           and         fits stock market returns very badly. The basic problem is that while the LS
model does allow positive asset returns, it severely underestimates the frequency of large positive
returns. This leads to a bad fit for the upper tail (Figure 1, last panel). However, the YY estimates
indicate that the Carr-Wu specification can be a useful component of a model, provided the upward
                                                   21

jump intensity function is modeled separately.


         Unrestricted CGMY models generate at least one Y parameter in the infinite-activity,
infinite-variation range [1, 2], and typically near the diffusion value of 2. This suggests that the
models may be trying to capture considerable near-zero activity. However, adding an additional
diffusion component to the time-changed YY Lévy specification to capture that activity separately
(specification YY_D) led to no significant improvement in fit.


         Overall, Figure 1 suggests the differences across the alternate fat-tailed specifications are
relatively minor, and fit the data similarly over most of the data range (           ). The models SV,
SVJ1, DEXP, VG, and LS appear less desirable, given their failure to capture the largest outliers.
The SVJ2, Y, and YY specifications appear to fit about the same. All models appear to have a small
amount of specification error (deviations from linearity) in the                  range and in the upper
tail (     ).


II.3 Unconditional distributions
A further diagnostic of model specification is the models’ ability or inability to match the
unconditional distribution of returns – in particular, the tail properties of unconditional distributions.
Mandelbrot (1963) and Mandelbrot and Hudson (2004) argue that empirical tails satisfy a “power
law:” tail probabilities plotted against absolute returns approach a straight line when plotted on a
log-log graph. This empirical regularity underlies Mandelbrot’s advocacy of the stable Paretian
distribution, which possesses this property and is nested within the CGMY model for                      .


         Mandelbrot’s argument is premised upon i.i.d. returns, but the argument can be extended to
time-changed Lévy processes. Conditional Lévy densities time-average; if the conditional intensity
of moves of size x is                       , the unconditional frequency of moves of size x is
                       . Since unconditional probability density functions asymptotically approach the
unconditional Lévy densities for large          , while unconditional tail probabilities approach the
corresponding integrals of the unconditional Lévy densities, examining unconditional distributions
may still be useful.
                                                  22

       Figure 2a provides estimates of unconditional probability density functions of stock market
excess return residuals                    for various specifications under Model 1, as well as data-
based estimates from a histogram of filtered residuals                        . Given the day-of-the-
week effects reported in Table 2, the unconditional density functions are a horizon-dependent
mixture of densities, with mixing weights set equal to the empirical frequencies. (The two shocks
spanning the market closings in 1933 and 2001 were omitted.) The substantial impact of the 1987
crash outlier upon parameter estimates is apparent. The SVJ2 estimates treat that observation as a
unique outlier, while the CGMY class of models progressively fatten the lower tail as greater
flexibility is permitted for the lower tail parameter    . As noted above, the lower tail approaches
the Carr-Wu (2003) log-stable (LS) estimate. However, the LS model is unable to capture the
frequency of large positive outliers, and behaves similarly to the SV model in the upper tail. All
models closely match the empirical unconditional density function in the ±3% range where most
observations occur; and all models underestimate the unconditional frequency of moves of 3% - 7%
in magnitude.


       Figure 2b provides similar estimates for unconditional lower and upper tail probabilities.
In addition, 1000 sample paths of stock market excess return residuals over 1926-2006 were
simulated via a Monte Carlo procedure using YY parameter estimates, in order to provide
confidence intervals on tail probability estimates.13 Unsurprisingly, the confidence intervals on
extreme tail events are quite wide. The underestimation of moves of 3% - 7% in magnitude is again
apparent, and is statistically significant. This rejection of the YY model does not appear attributable
to misspecification of the Lévy density      , which in Figure 1 captures conditional densities quite
well. Rather, the poor unconditional fit in Figures 2a and 2b appears due to misspecification of
volatility dynamics. Half of the 3-7% moves occurred over 1929 - 1935 – a prolonged high-
volatility period that simulated volatility realizations from the 1-factor variance process of equation
(13) generally do not match.




       13
         Conditional variance sample paths were simulated using the approach of Bates (2006,
Appendix A.6), while Lévy shocks      conditional upon intradaily average variance and data-based
daily time horizons were generated via an inverse CDF methodology, with CDF’s computed by
Fourier inversion. The two shocks spanning the market closings in 1933 and 2001 were omitted.
                                                    23

        Figure 3 plots model-specific tail probability estimates for the YY model on the log-log
scales advocated by Mandelbrot, along with data-specific quantiles for 20,004 stock market residuals
that have roughly a 1-day estimated time horizon (±11%). The lower tail probability does indeed
converge to the unconditional tail intensity

                                                                                                        (36)



where                                                    and         is the incomplete gamma function.
Furthermore, given G estimates near 0,                               is roughly a power function in y,
implying near linearity when plotted on a log-log scale.


        However, the graph indicates that the convergence of tail probabilities to the tail intensity
occurs only for observations in excess of 5% in magnitude – roughly 5 standard deviations. As this
is outside the range of almost all data, it does not appear that log-log scales provide a useful
diagnostic of model specification and tail properties for daily data. This is partly due to stochastic
volatility, which significantly slows the asymptotic convergence of unconditional tail probabilities
to       for large      . Absent stochastic volatility (         ), the tail probabilities of an i.i.d. YY
Lévy process converge to           for observations roughly in excess of 3% in magnitude (3 standard
deviations).


        No power law properties are observed for upper tail probabilities, given substantial estimated
exponential dampening. The failure of both lower and upper unconditional tail probabilities to
capture the frequency of moves of 3-7% in magnitude is again apparent, and statistically significant.


II.4 Subsample estimates
Table 4 provides estimates for data subsamples, as a test of the stability of the time series process.
The mean, stochastic volatility and jump parameters were allowed to differ before and after March
5, 1957.14 The time dummies (similar to those in Table 2) that capture day-of-the-week effects were


        14
         The data split was chosen so that the second subsample’s estimates could be compared with
estimates from S&P 500 returns, as well as with other studies that use data starting in the 1950’s
(Andersen et al (2002), Bates (2006), Chernov et al (2003)).
                                                  24

kept common across subsamples; but some of those dummies also capture subsample-specific
phenomena (Saturday trading before 1953; exchange holidays in 1968). The estimation and
filtration over the two subsamples nest the full-sample estimates of Table 3, so that standard
likelihood ratio tests can be used to test whether the divergence in subsample parameter estimates
are statistically significant.


        Parameter estimates diverge strongly across subsamples, with P-values less than           , but
in different fashions for the SVJ1 and YY models. For the SVJ1 model, the major divergence was
clearly in the estimated volatility process. The 1926-57 period includes the highly volatile 1930’s,
yielding an overall average variance of         over 1926-57, as opposed to          over 1957-2006.
The volatility dynamics also diverge, with volatility more volatile and with faster mean reversion
over 1926-57 than over 1957-2006. Jump risk estimates also diverge, with more frequent but
smaller jumps in the first half than in the second half. Progressively relaxing full-sample constraints
on parameter categories (mean;     ; stochastic volatility parameters; jump parameters) indicates that
between 71% and 86% of the subsample improvement in log likelihood comes from using
subsample stochastic volatility parameters. Between 8% and 22% of the change in log likelihood
comes from using subsample jump parameters, depending on whether stochastic volatility or jump
parameters are relaxed first.


        The 1957-2006 subsample estimates for the YY model are more heavily affected by the 1987
crash than are the full-sample estimates. The parameter G approaches its lower bound of zero,
implying that the lower tail density is approaching the time-changed version of the infinite-variance
log-stable distribution. Correspondingly, the subsample estimate of unconditional variance
=       becomes substantially meaningless, and cannot be compared with estimates from other
models or other periods. By contrast, the estimates over 1926-57 are strictly finite-variance. Given
strong interactions between stochastic volatility and jump parameters, it is not clear which is more
responsible for the strong rejections of parameter stability across subsamples.


II.5 Autocorrelation filtration
Given that the prior distribution            is assumed                 , it can be shown that the
autocorrelation filtration algorithm (30) for Model 1 updates conditional moments via the robust
                                                    25

Kalman filtration approach of Masreliez (1975):


                                                                                                      (33)



                                                                                                      (34)



If            were conditionally normal, the log density would be quadratic in          , and (33) would
be the linear updating of standard Kalman filtration. More generally, the conditionally fat-tailed
properties of       are explicitly recognized in the filtration.15 The partial derivatives of log densities
can be computed numerically by Fourier inversion.


       Figure 4 illustrates the autocorrelation filtrations estimated under various models. For model
1, the autocorrelation revision is fairly similar to standard Kalman filtration for observations within
a ±2% range – which captures most observations, given a unconditional daily standard deviation
around 1%. However, the optimal filtration for fat-tailed distributions is to downweight the
information from returns larger than 2% in magnitude. The exceptions are the stochastic volatility
(SV) and Carr-Wu log-stable (LS) specifications.            Those specifications do not particularly
downweight outliers occurring in non-fat tails: in both tails for SV, in the upper tail for LS.


       The autocorrelation filtration under Model 2 is different. Since                                 in
that model, large observations of         are attributable either to large values of        (small values
of   ), or to large values of the Lévy shocks captured by         . The resulting filtration illustrated in
the lower panels of Figure 2 is consequently sensitive to medium-size movements in a fashion
substantially different from the Model 1 specifications.


       Figure 5 presents filtered estimates of the daily autocorrelation from the YY model. The
most striking result is the extraordinarily pronounced increase in autocorrelation estimates from
1941 - 1971, with a peak of 35% reached in June 1971. Estimates from other models give



       15
            See Schick and Mitter (1994) for a literature review of robust Kalman filtration.
                                                 26

comparable results, as do crude sample autocorrelation estimates using a 1- or 2-year moving
window.16 After 1971, autocorrelation estimates fell steadily, and became insignificantly different
from zero after 2002. This broad pattern is observed both for Models 1 and 2, although the precise
estimates diverge given the different filtration methodologies. Filtered autocorrelation estimates
appear inversely related to measures of annual stock turnover computed by French (2008), attaining
values closer to zero in the high-turnover periods before 1933 and after 1982. This is consistent with
the standard stale-price explanation of autocorrelation in stock index returns.


       Figure 5 also indicates that the estimates of daily autocorrelation are virtually nonstationary,
indicating that fitting ARMA processes with time-invariant parameters to stock market excess
returns is fundamentally pointless. The conditional standard deviation asymptotes at about 4½%,
implying a 95% confidence interval of ±9% for the autocorrelation estimates.


II.6 Volatility filtration
When returns follow an autocorrelated process with i.i.d. shocks of the form

                                                                                                (35)

there are various ways of measuring variance:

       Conditional (or residual) variance:


       Unconditional variance of returns:


       Conditional permanent variance:


where L is the lag operator. These measure of variance are also approximately relevant in the above
models with stochastic conditional volatility and slow-moving autocorrelation. The              values
in Table 3A are estimates of the average level of residual variance for model 1, but estimates of
average permanent variance for model 2; hence the higher estimates for the latter. Furthermore, the



       16
        See LeBaron (1992, Figure 1) for annual estimates of the daily autocorrelation of S&P
composite index returns over 1928-1990.
                                                    27

ratio of return variance to permanent variance is                                          , which is less
than 1 for         and is monotonically decreasing in          . If permanent conditional variance is
stationary and autocorrelation evolves independently of permanent variance, as is assumed in model
2, periods of high autocorrelation will generate periods of low observed variance of returns – a
property consistent with the inverse relationship between annual estimates of daily autocorrelation
and volatility over 1928-1990 reported in LeBaron (1992).


       The left panel of Figure 6 illustrates how the estimated conditional volatility                  is
updated for the various specifications under model 1. The conditional volatility revisions use
median parameter values                                  for the prior gamma distribution of   , implying
a conditional mean                    that is close to the              median value observed for
estimates from the YY model.17 For comparability with GARCH analyses such as Hentschel (1995),
Figure 4 shows the “news impact curve,” or revision in conditional volatility estimates upon
observing a given excess return, using the methodology of Bates (2006, pp.931-2).


       All news impact curves are tilted, with negative returns having a larger impact on volatility
assessments than positive returns. This reflects the leverage effect, or estimated negative correlation
between asset returns and volatility shocks. All specifications process the information in small-
magnitude asset returns similarly. Furthermore, almost all specifications truncate the information
from returns larger than 3 standard deviations. This was also found in Bates (2006, Figure 1) for
the SVJ1 model, indicating such truncation appears to be generally optimal for arbitrary fat-tailed
Lévy processes. The SV and LS exceptions support this rule. The LS model has a fat lower tail but
not an especially fat upper tail, and truncates the volatility impact of large negative returns but not
of large positive returns. The fact that volatility revisions are not monotonic in the magnitude of
asset returns is perhaps the greatest divergence of these models from GARCH models, which almost
invariably specify a monotonic relationship.18 However, since moves in excess of ±3 standard


       17
        As     estimates have substantial positive skewness, the median is substantially below the
mean estimate of        reported in Table 3A.
       18
        An exception is Maheu and McCurdy (2004), who put a jump filter sensitive to outliers into
a GARCH model. They find that the sensitivity of variance updating to the latest squared return
should be reduced for outliers, for both stock and stock index returns.
                                                   28

deviations are rare, all specifications will generate similar volatility estimates most of the time. The
volatility filtrations for model 2 shown in the right panel of Figure 6 for median parameters
= (.00385, 6.01) are qualitatively similar to those for model 1.


        Figure 7 presents the filtered estimates of conditional annualized permanent volatility over
1926-2006 from the YY model 2, as well as the associated conditional standard deviation.19
Volatility estimates from other models (except SV and LS) are similar – as, indeed, is to be expected
from the similar volatility updating rules in Figure 4. The conditional standard deviation is about
2.8%, indicating a 95% confidence interval of roughly ±5½% in the annualized volatility estimates.
Because of the 81-year time scale, the graph actually shows the longer-term volatility dynamics not
captured by the model, as opposed to the intra-year volatility mean reversion with 2-month half-life
that is captured by the model. Most striking is, of course, the turbulent market conditions of the
1930's, unmatched by any comparable volatility in the post-1945 era. The graph indicates the 1-
factor stochastic variance model is too simple, and suggests that multifactor specifications of
variance evolution are worth exploring.20


        The inset to Figure 5 compares adjusted filtered volatility estimates                       over
1987-89 with realized volatility estimates computed daily from intradaily 15-minute log-differenced
S&P 500 futures prices. (Open-to-close futures returns were 86.55% as volatile as close-to-close
futures returns over 1982-2001.) The inset shows that the AML filtration methodology using daily
data generally tracks realized intradaily volatility quite closely. The filtered estimates do not capture
major realized volatility spikes – especially over October 19-28, 1987. The models estimated in this
paper interpret such spikes and the accompanying large daily stock market movements as stock
market jumps. However, the clustering of high intradaily volatility values is important time series


        19
         “Annualized” volatility refers to the choice of units. Since time is measured in years,
is variance per year, while the daily volatility estimate for a Wednesday return with an estimated
length of          years (from Table 2) is approximately                . Since variance mean-reverts
with an estimated half-life of roughly 2 months, it is not appropriate to interpret Figure 5 as showing
the volatility estimate for a 1-year investment horizon.
        20
          The inadequacies of AR(1) representations of conditional variance are already well-known
in volatility research, and have motivated research into long-memory processes.
                                                    29

evidence against the models’ diffusive-volatility assumption, and supports an alternate volatility-
jump specification.


          Filtered volatility estimates do appear sensitive to the data interval used in estimation, via
the underlying parameter estimates. For instance, the subsample SVJ1 estimates in Table 4 yield
filtered annualized          ’s that are 1.86% higher on average over 1926-57 than the full-sample
estimates, and 1.29% lower over 1957-2006. A significant underlying factor is the estimate of
unconditional volatility          in Table 4, which is higher in the first than in the second subsample,
and which significantly influences volatility filtration. A similar influence of unconditional variance
estimates upon conditional volatility estimates is observed in GARCH models.21


III. Option pricing implications
Do these alternative models imply different option prices? Exploring this issue requires identifying
the appropriate pricing of equity, jump, and stochastic volatility risks. Furthermore, the presence
of substantial and stochastic autocorrelation raises issues not previously considered when pricing
options. In particular, the observed stock index level underlying option prices can be stale, while
the relevant volatility measure over the option’s lifetime is also affected. The variance of the sum
of future stock market returns is not the sum of the variances when returns are autocorrelated.


          To examine these issues, I will focus upon Model 2, with its interpretation in equations (23) -
(24) of        as the permanent shock to the log stock market level. Furthermore, I will use the myopic
power utility pricing kernel of Bates (2006) to price the various risks:

                                                                                                  (36)



          This pricing kernel constrains both the equity premium estimated under the objective time
series model, and the transformations of those estimates into the risk-neutral process appropriate for



          21
        See, e.g., Andersen et al (2005, p.7), who note that GARCH(1,1) models diverge from the
RiskMetrics approach in taking into account mean reversion of conditional variance towards the
unconditional variance. This implies that GARCH conditional volatility estimates are affected by
sample-specific estimates of the unconditional variance.
                                                     30

pricing options. In particular, the instantaneous equity premium is

                                                                                                  (37)

which implies



                                                                                                   (38)



where               is the fraction of variance attributable to an orthogonal diffusion term. The
approximation follows from first-order Taylor expansions, and from the fact that jumps account for
a fraction                   of overall variance     . The equity premium (37) is well-defined for the
SVJ1 and SVJ2 models. For the CGMY models, the restriction                is required for a finite equity
premium; the intensity of downward jumps must fall off faster than an investor’s risk aversion to
such jumps. The log-stable process is inconsistent with a finite equity premium for              .22


        The change of measure from objective to risk-neutral jump intensities takes the form

                                                                                                  (39)

under a myopic power utility pricing kernel. This has assorted implications for parameter
transformations that depend upon the precise specification of the Lévy density           . For the SVJ
models, as discussed in Bates (2006), this modified jump intensity shifts the mean jump size           by
an amount           , while leaving the jump standard deviation     unchanged. For the CGMY model,
the risk adjustment replaces the downward and upward exponential dampening parameters                  and
M by             and        , respectively, while leaving the C and Y parameters unchanged.23 These
risk adjustments alter the           and           functions in equation (14). Table 5 summarizes the
parameter transformations under the various models.




        22
        Carr and Wu (2003) specify a log-stable process for the risk-neutral process underlying
option prices. This can be generated from a CGMY process for the actual process with only
downward jumps, and with        .
        23
             Wu (2006) discusses this transformation.
                                                  31

       The key risk aversion parameter R used for change of probability measure was estimated by
imposing the equity premium restrictions (37), and re-estimating all times series models. The
additional parameter restriction        was also imposed upon all CGMY models, and was binding
for the YY model.24 Parameter estimates reported in Table 6 changed little relative to those in Table
3B, while risk aversion was estimated at roughly 2.5 for all models. Furthermore, the restriction of
a purely variance-sensitive equity premium (           ) was not rejected for any model.


       I address the potential impact of autocorrelations upon option prices by examining prices of
options on S&P 500 futures. I assume that stock index futures prices respond instantaneously and
fully to the arrival of news, whereas lack of trading in the underlying stocks delays the incorporation
of that news into the reported S&P 500 stock index levels. Furthermore, I assume that index
arbitrageurs effectively eliminate any stale prices in the component stocks on days when futures
contracts expire, so that stale stock prices do not affect the cash settlement of stock index futures.
MacKinlay and Ramaswamy (1988) provide evidence supportive of both assumptions.


These assumptions have the following implications under Model 2 (equations 23 and 24):
   1. the observed futures price       underlying options on S&P 500 futures is not stale;
   2. log futures price innovations equal the intradaily innovations         of equation (13):

                                                                                                 (40)

Consequently, European options on stock index futures can be priced directly using a risk-neutral
version of (40) – which is affine, simplifying option evaluation considerably. Furthermore, option
prices do not depend upon    , except indirectly through the impact of autocorrelation filtration upon
the filtration of latent permanent variance    . Following Bates (2006), European call prices on an
S&P 500 futures contract can be priced as



                                                                                                 (41)




       24
          Wu (2006) proposes an alternate pricing kernel with negative risk aversion for downside
risk, thereby automatically imposing        .
                                                     32

where            and       are risk-neutral variants25 of those in equations (17)-(21);
             is the effective maturity of the option, given individual days’ length from Table 2;
                       is the maturity associated with the continuously compounded Treasury bill yield
             , given   calendar days until option maturity; and
                                     is the filtered cumulant generating function of   that summarizes
        what is known about        given past data        .
The associated implicit standard deviations (ISD’s) for standardized maturity             can then be
computed using the Black (1976) formula for European options on futures.


        The ISD’s from the various models are graphed in Figure 8, and are compared with observed
ISD’s computed from settlement prices for American options on S&P 500 futures with non-zero
trading volume on December 29, 2006. Figure 8 also shows 95% confidence intervals, computed
as in Bates (2006) based on parameter uncertainty alone, and on parameter and state uncertainty
associated with        estimation. All models, including the SV model, generate virtually identical
option prices at end-2006 over a range of ±2 standard deviations – a range that contains the most
actively traded options. The estimated level of the ATM ISD was roughly the same across all
specifications, reflecting an absence of recent major outliers that would induce divergences in
estimated volatility from different specifications . The tilt of the volatility smirk for near-the-money
options appears to be driven primarily by the “leverage effect,” or correlation between shocks to
variance and stock market returns. Only for deep out-of-the-money put options do the divergences
in estimated tail properties generate substantially different ISD patterns across models.26
Furthermore, those divergences across models generally decrease at longer maturities, as the impact
of jumps falls in importance relative to the projected dynamics of stochastic volatility. The maturity
profile of the YY model is the exception, reflecting the fact that the risk-neutral distribution is
almost infinite-variance.


        25
          The parameters                are replaced by               , while the function
is replaced by a risk-adjusted function      given in Table 5 for specific models that captures the
risk-adjusted jump intensities from (39).

        26
         These results differ from Bates (2000, Table 3), who reports substantial divergences
between the SV and SVJ models based substantially upon implicit parameter estimation. It would
appear that implicit parameter estimates are strongly affected by the prices of deep OTM options.
                                                     33

         Figure 9 chronicles estimated and observed at-the-money ISD’s over 1983-2006 for the
short-term options with maturities of 14 days or more. The overall evolution is broadly comparable
to the estimates in Bates (2006, Figure 7). However, the ISD estimates are substantially closer to
observed ISD’s, with average values over 1988-2006 of 15.8% and 16.8%, respectively. The results
differ from the larger divergences in Bates (2006), for two reasons. First, the earlier study used
Anderson, Benzoni and Lund’s (2002) data, who prefiltered S&P returns over 1953-1996 by
estimating an MA(1), and then rescaled estimated residuals to match the mean and variance of the
original data. Prefiltration removes the autocorrelation structure of the data, and consequently
underestimates the average level            of permanent variance relevant for pricing options. Re-
estimating SVJ2 Model 2 on the raw S&P returns underlying the Anderson et al data over 1953-96
raises        estimates from           to        .


         Second, as shown above in Table 6,          estimates are substantially higher when data from
the volatile 1930's are included:           over 1926-2006 for the SVJ2 model, as opposed to
over 1957-2006. A higher            estimate affects ISD estimates at all maturities, through its impact
on the filtration algorithm for estimating spot variance      as well as through its impact on forecasts
of future variance. For instance, some resulting filtered measures of risk-neutral volatility over
1988-2006 using the two sets of SVJ2 parameter estimates are:

                                                          Average values over 1988-2006
                                                              1-month       1-month        difference
 Estimation                                                                                 in ISD’s
 1926-2006               18.7%                 15.9%          15.8%          16.8%           1.0%
 1957-2006               16.3%                 14.4%          14.4%          16.8%           2.4%
 difference                2.4%                 1.5%           1.4%


         Nevertheless, the broad assessment of previous studies appears unchanged. Observed ISD’s
from options on index futures do appear higher on average over the post-1987 period than is justified
by risk-adjusted valuations based upon time series analysis, even when volatility assessments
include data from the 1930's.
                                                  34

IV. Summary and Conclusions
This paper provides time series estimates of the time-changed CGMY (2003) Lévy process, and
compares them to the time-changed finite-activity jump-diffusions previously considered by Bates
(2006). Overall, while it is important to use adequately fat-tailed distributions when filtering
volatility and other latent variables, it does not seem especially important which fat-tailed
distribution one uses.    Estimates of the volatility process and realizations are substantially
unchanged across most specifications, while the option pricing implications are virtually identical
for all but the deepest out-of-the-money options. The exceptions are Heston’s (1993) stochastic
volatility model, which underestimates upper and lower tail risk, and the log-stable model of Carr
and Wu (2003), which underestimates upper tail risk. This underestimation of tail risk makes
volatility estimates excessively sensitive to outliers, and also affects estimates of the volatility
process. Conditional upon similar volatility estimates, however, even the Heston model fits option
prices similarly to the fat-tailed distributions for all but deep OTM options. For these stochastic
volatility/stochastic intensity models, the tilt of the volatility smirk for near-the-money options ( 2
standard deviations) appears primarily driven by the “leverage” effect.


       The paper also documents some structural shifts over time in the data generating process.
Most striking is the apparently nonstationary evolution of the first-order autocorrelation of daily
stock market returns, which rose from near-zero in the 1930's to 35% in 1971, before drifting down
again to near-zero values after 1987. Autocorrelation estimates are inversely related to stock
turnover, and are of considerable importance when assessing stock market volatility. The paper
develops methods of dealing with time-varying autocorrelation, by treating it as an additional latent
state variable to be filtered from observed data. Longer-term trends in volatility are also apparent
in the filtered estimates, suggesting a need for multifactor models of conditional variance.
                                               35

                                          References
Andersen, Torben G., Luca Benzoni, and Jesper Lund (2002). “An Empirical Investigation of
Continuous-Time Equity Return Models.” Journal of Finance 57, 1239-1284.

Andersen, Torben G., Tim Bollerslev, Peter F. Christoffersen, and Francis X. Diebold (2005).
“Practical Volatility and Correlation Modeling for Financial Market Risk Management.” NBER
working paper 11069, January.

Bakshi, Gurdip and Dilip B. Madan (2000). “Spanning and Derivative-Security Valuation.” Journal
of Financial Economics 55, 205-238.

Barclay, Michael J., Robert H. Litzenberger, and Jerold B. Warner (1990). “Private Information,
Trading Volume, and Stock-Return Variances.” Review of Financial Studies 3, 233-254.

Bates, David S. (2000). “Post-‘87 Crash Fears in the S&P 500 Futures Option Market.” Journal
of Econometrics 94, 181-238.

Bates, David S. (2006). “Maximum Likelihood Estimation of Latent Affine Processes.” Review of
Financial Studies 19, 909-965.

Bertoin, Jean (1996). Lévy Processes, Cambridge: Cambridge University Press.

Black, Fischer (1976). “The Pricing of Commodity Contracts.” Journal of Financial Economics
3, 167-179.

Broadie, Mark N., Mikhail Chernov, and Michael Johannes (2006). “Understanding Index Option
Returns,” Columbia University working paper.

Carr, Peter, Hélyette Geman, Dilip B. Madan, and Marc Yor (2002). “The Fine Structure of Asset
Returns: An Empirical Investigation.” Journal of Business 75, 305-332.

Carr, Peter, Hélyette Geman, Dilip B. Madan, and Marc Yor (2003). “Stochastic Volatility for Lévy
Processes.” Mathematical Finance 13, 345-382.

Carr, Peter and Liuren Wu (2003). “The Finite Moment Log Stable Process and Option Pricing.”
Journal of Finance 58, 753-777.

Carr, Peter and Liuren Wu (2004). “Time-changed Lévy Processes and Option Pricing.” Journal
of Financial Economics 71, 113-141.

Chernov, Mikhail, A. Ronald Gallant, Eric Ghysels, and George Tauchen (2003). “Alternative
Models for Stock Price Dynamics. Journal of Econometrics 116, 225-257.

Clark, Peter K. (1973). “A Subordinated Stochastic Process Model with Finite Variance for
Speculative Prices.” Econometrica 41, 135-155.
                                               36

Cox, John C., Stephen A. Ross, and Mark Rubinstein (1979). “Option Pricing: A Simplified
Approach.” Journal of Financial Economics 7, 229-263.

Dimson, Elroy (1979). “Risk Measurement When Shares are Subject to Infrequent Trading.”
Journal of Financial Economics 7, 197-226.

Duffie, Darrell, Jun Pan, and Kenneth J. Singleton (2000). “Transform Analysis and Asset Pricing
for Affine Jump-Diffusions.” Econometrica 68, 1343-1376.

Eberlein, Ernst, Ulrich Keller, and Karsten Prause (1998). “New Insights into Smile, Mispricing,
and Value at Risk: The Hyperbolic Model.” Journal of Business 71, 371-405.

Eraker, Bjorn, Michael Johannes, and Nicholas G. Polson (2003). “The Impact of Jumps in
Volatility and Returns.” Journal of Finance 58, 1269-1300.

French, Kenneth R. (2008). “The Cost of Active Investing.” Journal of Finance 63, 1537-1573.

French, Kenneth R. and Richard Roll (1986). “Stock Return Variances: The Arrival of Information
and the Reaction of Traders.” Journal of Financial Economics 17, 5-26.

Gallant, A. Ronald, Peter E. Rossi, and George Tauchen (1992). “Stock Prices and Volume.”
Review of Financial Studies 5, 199-242.

Hentschel, Ludger (1995). “All in the Family: Nesting Symmetric and Asymmetric GARCH
Models.” Journal of Financial Economics 39, 71-104.

Heston, Steve L. (1993). “A Closed-Form Solution for Options with Stochastic Volatility with
Applications to Bond and Currency Options.” Review of Financial Studies 6, 327-344.

Jukivuolle, Esa (1995). “Measuring True Stock Index Value in the Presence of Infrequent Trading.”
Journal of Financial and Quantitative Analysis 30, 455-464.

Kou, Steve (2002). “A Jump Diffusion Model for Option Pricing.” Management Science 48,
1086-1101.

LeBaron, Blake D. (1992). “Some Relations between Volatility and Serial Correlations in Stock
Returns.” Journal of Business 65, 199-219.

Li, Haitao, Martin T. Wells, and Cindy L. Yu (2008). “A Bayesian Analysis of Return Dynamics
with Stochastic Volatility and Lévy Jumps.” Review of Financial Studies 21, 2345-2378.

Lo, Andrew W. and A. Craig MacKinlay (1988). “Stock Market Prices Do Not Follow Random
Walks: Evidence from a New Specification Test.” Review of Financial Studies 1, 41-66.

MacKinlay, A. Craig and Krishna Ramaswamy (1988). “Index-Futures Arbitrage and the Behavior
of Stock Index Futures Prices.” Review of Financial Studies 1, 137-158.
                                               37

Madan, Dilip B. and Eugene Seneta (1990). “The Variance Gamma (V.G.) Model for Share Market
Returns.” Journal of Business 63, 511-525.

Maheu, John M. And Thomas H. McCurdy (2004). “News Arrival, Jump Dynamics and Volatility
Components for Individual Stock Returns.” Journal of Finance 59, 755-793.

Mandelbrot, Benoit B. (1963). “The Variation of Certain Speculative Prices.” Journal of Business
36, 394-419.

Mandelbrot, Benoit B. and Richard L. Hudson (2004). The (mis)Behavior of Markets: A Fractal
View of Risk, Ruin, and Reward. New York: Basic Books.

Masreliez, C. J. (1975). “Approximate Non-Gaussian Filtering with Linear State and Observation
Relations.” IEEE Transactions on Automatic Control 20, 107-110.

Merton, Robert C. (1976). “Option Pricing When Underlying Stock Returns are Discontinuous.”
Journal of Financial Economics 3, 125-144.

SBBI Yearbook, 2006. Chicago: R. G. Ibbotson Associates.

Schick, Irvin C. And Sanjoy K. Mitter (1994). “Robust Recursive Estimation in the Presence of
Heavy-tailed Observation Noise.” The Annals of Statistics 22, 1045-1080.

Schwert, G. William (1990). “Indexes of U.S. Stock Prices from 1802 to 1987.” Journal of Business
63, 399-426.

Wu, Liuren (2006). “Dampened Power Law: Reconciling the Tail Behavior of Financial Security
Returns.” Journal of Business 79, 1445-1473.
                                                38

Appendix A. Filtration under Model 2
From equation (26), the cumulant generating function (CGF) for future
conditional upon knowing                is

                                                                                                (A.1)

The filtered CGF conditional upon only observing past data      can be computed by integrating over
the independent conditional distributions of the latent variables          :



                                                                                                (A.2)



where                             is the gamma conditional CGF for latent       . Under the change
of variables                                 , and under the assumption that the scaling term
               , the Fourier inversion used in evaluating              from (A.2) becomes




                                                                                                (A.3)



where          denotes the real component of complex-valued c, and the 1/x term in the integrand
reflects the Jacobean from the change of variables.


        It is convenient to use the two-parameter inverse Gaussian distribution to approximate
         :


                                                                                                (A.4)


where                 and                      are t-dependent parameters that summarize what is
known about x (and about     ) at time t. Under this specification, the inner integration inside (A.3)
can be replaced by the analytic function
                                                  39




                                                                                               (A.5)




for                                 .   Consequently, evaluating (A.3) involves only univariate
numerical integration.1


Similar univariate integrations are used for filtering      and   conditional upon observing       .
The noncentral posterior moments of          are given by


                                                                                               (A.6)


where the derivatives with respect to        inside the integrand can be easily evaluated from the
specifications for        and      in equations (17) - (18) . The posterior moments of      can be
computed by taking partials of (A.2) with respect to , and then again using change of variables to
reduce the Fourier inversion to a univariate integration. The resulting posterior mean and variance
of        are


                                                                                               (A.7)




                                                                                               (A.8)


where




      1
    A more “natural” choice would be to represent x by a beta distribution over the range [0, 2].
That would constrain              , and results in an        term that involves the confluent
hypergeometric U-function. However, I could not find a method for evaluating that function that
was fast, accurate, and robust to all parameter values.
                                                 40



                                                                        (A.9)


and


                                                                       (A.10)


Finally, the conditional distribution function        that is used in QQ plots
takes the form


                                                                       (A.11)
Table 1
Standardized cumulant exponents (with unitary variance) for various compensated Lévy specifications

diffusion:


Normally distributed jumps:



CGMY jump process:


                              with   such that


General specification:


                                       Weights
                                                                                  Parameter
 Model                                                                            restrictions

 SV                      1
 SVJ1



 SVJ2



 DEXP

 VG

 Y                                                                      1

 YY                                                                     1
 LS                                                                     1

 YY_D

For SVJ1 and SVJ2, the fraction      of variance attributable to jumps is   and          , respectively.
Table 2: Effective length of a business day, relative to 1-day Wednesday returns: 1926-2006. Estimates from YY model. Estimates from
other models are almost identical.

                                                                       Model 1                   Model 2
                                                      NOBS
    #days   Description                                       estimate     std. error   estimate     std. error
      1     Monday close 6 Tuesday close              3831     1.02          (.04)       1.03          (.03)
      1     Tuesday close 6 Wednesday close           4037     1                         1
      1     Wednesday 6 Thursday                      3998       .94         (.03)         .94         (.03)
      1     Thursday 6 Friday                         3924       .93         (.03)         .92         (.03)
      1     Friday 6 Saturday (1926-52)               1141       .43         (.02)         .44         (.02)
      2     Saturday close 6 Monday close (1926-52)   1120     1.05          (.05)       1.07          (.05)
      2     Weekday holiday                            341     1.25          (.11)       1.26          (.10)
      2     Wednesday exchange holiday in 1968          22      .73          (.33)        .81          (.35)
      3     Weekend and/or holidaya                   2755     1.10          (.04)       1.10          (.04)
      4     Holiday weekend                            343     1.58          (.14)       1.56          (.13)
      5     Holiday weekend                              6     1.31         (1.00)       1.25          (.93)
                                                      21518
            Annualization factor: Wednesday 6                 259.8         (5.6)       260.3         (5.5)
            yearly

a
Includes one weekday holiday (August 14 - 17, 1945)
Table 3A: Estimates of parameters affecting the conditional means and volatilities. Data: daily CRSP value-weighted excess returns, 1926-
2006. See equations (6) - (10), (13), and (25) for definitions of parameters. Models with             combine Lévy jump processes with an additional
independent diffusion, with variance proportions                     , respectively. Standard errors are in parentheses.


                                                          Model 1:

                                         Conditional mean                                          Stochastic volatility
   Model
                  ln L                                                                                                                   HL
                                                                                                                                       (mths)
 SV           74,940.85     .013 (.015)      2.16 (.90)    .029 (.007)      .153 (.004)    5.83 (.44)    .452 (.010)     .625 (.018)    1.4 (.1)
 SVJ1         75,043.90     .042 (.015)       .91 (.91)    .030 (.006)      .155 (.005)    4.39 (.40)    .374 (.011)    -.641 (.020)    1.9 (.2)
 SVJ2         75,048.49     .042 (.003)       .87 (.76)    .030 (.007)      .155 (.007)    4.34 (.37)    .371 (.015)    -.642 (.018)    1.9 (.2)
 DEXP         75,047.33     .043 (.015)       .87 (.90)    .031 (.007)      .155 (.005)    4.23 (.38)    .368 (.012)    -.587 (.020)    2.0 (.2)
 VG           75,049.09     .043 (.015)       .92 (.91)    .030 (.006)      .155 (.005)    4.22 (.39)    .366 (.012)    -.586 (.020)    2.0 (.2)
 Y            75,049.63     .042 (.015)       .90 (.92)    .030 (.006)      .156 (.009)    3.89 (.38)    .351 (.020)    -.576 (.032)    2.1 (.2)
 YY           75,052.56     .041 (.015)       .87 (.92)    .030 (.006)      .158 (.009)    4.00 (.38)    .360 (.019)    -.571 (.031)    2.1 (.2)
 YY_D         75,052.81     .042 (.015)       .93 (.91)    .030 (.006)      .156 (.006)    3.99 (.38)    .355 (.013)    -.579 (.021)    2.1 (.2)
 LS           75,007.86     .018 (.015)      1.50 (.73)    .031 (.007)      .171 (.006)    4.60 (.40)    .431 (.015)    -.541 (.020)    1.8 (.2)

                                                     Model 2:

 SV          74,999.87    -.014 (.020)     3.04 (.90)     .043 (.005)    .170 (.004)      8.01 (.57)    .562 (.015)    -.658 (.017)    1.0 (.1)
 SVJ1        75,092.10     .033 (.020)     1.69 (1.04)    .036 (.005)    .171 (.004)      5.80 (.49)    .457 (.015)    -.674 (.018)    1.4 (.1)
 SVJ2        75,096.68     .037 (.020)     1.25 (.89)     .036 (.005)    .172 (.004)      5.71 (.49)    .456 (.015)    -.673 (.018)    1.4 (.1)
 DEXP        75,094.20     .034 (.020)     1.44 (.90)     .036 (.005)    .171 (.004)      5.67 (.49)    .452 (.015)    -.625 (.018)    1.5 (.1)
 VG          75,094.70     .034 (.020)     1.42 (.90)     .037 (.005)    .171 (.004)      5.56 (.48)    .447 (.016)    -.623 (.018)    1.6 (.1)
 Y           75,093.68     .036 (.021)     1.35 (.90)     .036 (.005)    .172 (.007)      5.18 (.46)    .432 (.021)    -.613 (.027)    1.6 (.1)
 YY          75,097.20     .033 (.020)     1.44 (.90)     .036 (.005)    .172 (.006)      5.23 (.47)    .437 (.018)    -.613 (.022)    1.6 (.1)
 YY_D        75,097.49     .035 (.020)     1.36 (.90)     .036 (.005)    .172 (.005)      5.23 (.47)    .436 (.016)    -.616 (.020)    1.6 (.1)
 LS          75,045.48     .053 (.019)     1.50 (.76)     .031 (.003)    .174 (.005)      4.68 (.41)    .436 (.015)    -.576 (.019)    1.8 (.2)
Table 3B: Estimates of jump parameters. Standard errors in parentheses.

                                                          Model 1:

                                                       CGMY parameters                                               Merton parameters
  Model
                                              G               M
 SVJ1        .150 (.017)                                                                                142.7 (22.7)      .000 (.002)     .032 (.002)
 SVJ2        .156 (.054)                                                                                162.9 (30.9)      .000 (.002)     .029 (.002)
                                                                                                          0.5 (1.6)      -.189 (.094)     .005 (.189)
 DEXP        .253 (.027)      .49 (.01)   66.1 (6.0)      45.4 ( 8.4)              -1
 VG          .272 (.030)      .52 (.07)   41.1 (5.4)      31.6 (9.1)                 0
 Y               1            .59 (.06)    7.0 (4.6)       2.3 (7.3)            1.87 (.03)
 YY              1            .88 (.03)    1.6 (4.5)      40.1 (31.3)     1.94 (.01)    -.24 (1.36)
 YY_D          .436           .72 (.15)    6.9 (9.0)      49.2 (34.9)     1.71 (.35)    -.72 (1.57)
 LS              1              1          .001                           1.96 (.01)

                                                   Model 2:
 SVJ1       .133 (.015)                                                                               114.1 (19.2)      -.001 (.003)     .034 (.002)
 SVJ2       .140 (.015)                                                                               126.4 (23.7)       .000 (.002)     .031 (.002)
                                                                                                        0.41 (.04)      -.198 (.022)     .010 (.046)
 DEXP       .236 (.026)     .53 (.06)     55.4 (5.4)    50.0 (4.8)                   -1
 VG         .257 (.030)     .54 (.07)     41.1 (4.9)    31.6 (10.7)                  0
 Y               1          .59 (.05)     6.8 (4.2)     3.2 (8.2)                1.87 (.03)
 YY              1          .89 (.03)      2.6 (4.1)    71.1 (57.8)     1.935 (.014) -1.96 (2.62)
 YY_D       .380 (.158)     .90 (.30)     8.1 (8.7)     51.8 (51.7)     1.619 (.403) -1.08 (2.36)
 LS              1              1            .001                       1.965 (.006)
Table 4: Subsample estimates for Model 2. Estimates “w/o Oct ’87" exclude daily data observed in October 1987, but include the full month’s return
of -20.6%. Split-sample estimates involve different parameter values before/after March 5, 1957, apart from time dummies. Standard errors are in
parentheses.

                                                      Conditional mean                                        Stochastic volatility
 Model    Period
                             ln L                                                                                                                  HL
                                                                                                                                                 (mths)


 SVJ1     full             75,092.10    .033 (.020)      1.69 (1.04)     .036 (.005)    .171 (.004)   5.80 (.49)    .457 (.015)   -.674 (.018)   1.4 (.1)
 SVJ1     1926 - 1957                   .051 (.034)      1.35 (1.38)     .050 (.009)    .202 (.007)   8.82 (1.03)   .678 (.035)   -.661 (.027)   0.9 (.1)
                           75,183.99
          1957 - 2006                   .003 (.027)      2.90 (1.61)     .027 (.005)    .149 (.005)   4.93 (0.60)   .314 (.015)   -.725 (.023)   1.7 (.2)
 YY       full             75,097.20    .033 (.020)      1.44 (.90)      .036 (.005)    .172 (.006)   5.23 (.47)    .437 (.018)   -.613 (.022)   1.6 (.1)
 YY       w/o Oct ’87      75,065.01    .036 (.020)      1.37 (.91)      .035 (.005)    .170 (.005)   5.12 (.46)    .427 (.016)   -.620 (.019)   1.6 (.1)
 YY       1926 - 1957                   .056 (.034)      1.03 (1.15)     .051 (.009)    .201 (.008)   6.81 (.88)    .657 (.033)   -.585 (.026)   1.2 (.2)
                           75,196.14
          1957 - 2006                   .012 (.027)       .35 (.67)      .025 (.005)    .365 (.320)   4.89 (.56)    .404 (.026)   -.281 (.247)   1.7 (.2)


                                                               CGMY parameters                                           Merton parameters
  Model
                                                          G               M
 SVJ1      full          .133 (.015)                                                                          114.1 (19.2)   -.001 (.003) .034 (.002)
 SVJ1      1926 - 1956 .167 (.015)                                                                            216.8 (54.9) .000 (.003) .028 (.003)
           1957 - 2006 .093 (.020)                                                                             49.5 (12.0) -.003 (.007) .043 (.004)
 YY        full               1         .89 (.03)      2.6 (4.1)      71.1 (57.8) 1.94 (.01)   -1.96 (2.6)
 YY        w/o Oct ’87        1         .89 (.03)      5.6 (5.3)      72.0 (60.8) 1.93 (.02)   -1.76 (2.6)
 YY        1926 - 1957        1         .86 (.04)      20.7 (7.9) 97.8        1.82 (.05)       -3.1 (4.5)
           1957 - 2006        1         .92 (.15)       0.0 (0.0) (107.2)     1.54 (.41)       1.94 (.03)
                                                                   6.0 (13.4)
Table 5: Change of parameters (objective versus risk-neutral) under a myopic power utility
pricing kernel                     .

                           Objective                   Risk-neutral
Equity premium
                                                       0

General jump intensity

Variance process
       mean reversion
       UC mean

Merton jump process
      mean jump size
       jump SD
       jump intensity




CGMY jump process
                           G                                          (must be $0)
                           M
Table 6: Parameter estimates over 1926-2006 on spliced CRSP/S&P 500 data with constrained equity premium:                                     ,        .

                             LR test of                Conditional mean                                             Stochastic volatility
    Model
                ln L         (p-value)                                                                                                                        HL
                                                                                                                                                            (mths)
    SV       74,028.53         .383       2.49 (.62)       2.49 (.62)   .043 (.005)        .172 (.004)     7.18 (.48)   .534 (.014)     -.649 (.016)        1.2 (.1)
    SVJ1     74,119.26         .265       2.44 (.61)       2.44 (.61)   .038 (.005)        .173 (.004)     5.76 (.43)   .448 (.015)     -.678 (.017)        1.4 (.1)
    SVJ2     74,125.33         .507       2.43 (.57)       2.44 (.58)   .037 (.005)        .174 (.004)     5.76 (.42)   .449 (.015)     -.679 (.017)        1.4 (.1)
    DEXP     75,121.73         .247       2.44 (.61)       2.44 (.61)   .037 (.005)        .174 (.004)     5.68 (.43)   .444 (.015)     -.632 (.017)        1.5 (.1)
    VG       74,122.51         .206       2.50 (.61)       2.50 (.61)   .037 (.005)        .174 (.004)     5.62 (.43)   .441 (.015)     -.631 (.017)        1.5 (.1)
    Y        74,122.19         .185       2.42 (.61)       2.42 (.61)   .037 (.005)        .174 (.006)     5.29 (.41)   .427 (.018)     -.623 (.022)        1.6 (.1)
    YYa      74,124.33         .212       2.38             2.42         .037               .175            5.26         .429            -.621               1.6
    Estimates on S&P 500 data over 1957-2006
    SVJ2     43,707.25                    2.97 (.88)       2.98 (.88)       .026 (.006)    .149 (.006)     3.97 (.44)   .289 (.014)     -.721 .024)        2.1 (.2)


                                                             CGMY parameters                                                     Merton parameters
    Model
                                                       G                M
    SVJ1       .126 (.015)                                                                                        108.7 (18.2)        -.001 (.003)     .034 (.002)
    SVJ2       .138 (.021)                                                                                        122.7 (23.1)         .000 (.002)     .031 (.002)
                                                                                                                    0.43 (.38)        -.219 (.027)     .003 (.150)
    DEXP       .228 (.026)        .55 (.06)    51.6 (5.0)        53.9 (12.7)                   -1
    VG         .247 (.028)        .53 (.07)    35.9 (4.6)        34.4 (11.1)                   0
    Y               1             .58 (.05)    5.4 (4.0)          4.5 (8.7)                1.87 (.03)
    YYa             1             .90           2.4              64.3                 1.94         -1.29
    Estimates on S&P 500 data over 1957-2006
    SVJ2       .096 (.050)                                                                                        81.0 (30.1)          .002 (.004)     .030 (.005)
                                                                                                                   .55 (1.32)         -.213 (.035)     .003 (.020)

a
Parameter constraint            was binding for the YY model; standard errors could not be computed.
                                                                                                                                                                          Normal Probability Plot SVJ2
                                                   Normal Probability Plot SVJ1




                                                                                                                          0.999
                        0.999
                                                                                                                          0.997
                        0.997
                                                                                                                             0.99
                        0.99                                                                                                 0.98
                        0.98
                                                                                                                             0.95
                        0.95
                                                                                                                             0.90
                        0.90
                                                                                                                             0.75
                        0.75




                                                                                                      Probability
          Probability




                                                                                                                             0.50
                        0.50
                                                                                                                             0.25
                        0.25
                                                                                                                             0.10
                        0.10
                                                                                                                             0.05
                        0.05
                                                                                                                             0.02
                        0.02                                                                                                 0.01
                        0.01
                                                                                                                          0.003
                        0.003
                                                                                                                          0.001
                        0.001



                                                                                                                                      -6         -5        -4        -3          -2          -1      0       1       2       3       4
                               -6   -5   -4   -3        -2      -1       0        1   2   3   4                                                                                             Data
                                                               Data
                                                                                                                                                                           Normal Probability Plot VG
                                                   Normal Probability Plot DEXP




                                                                                                                             0.999
                        0.999
                                                                                                                             0.997
                        0.997
                                                                                                                                0.99
                        0.99                                                                                                    0.98
                        0.98
                                                                                                                                0.95
                        0.95
                                                                                                                                0.90
                        0.90
                                                                                                                                0.75
                        0.75




                                                                                                        Probability
          Probability




                                                                                                                                0.50
                        0.50

                                                                                                                                0.25
                        0.25
                                                                                                                                0.10
                        0.10
                                                                                                                                0.05
                        0.05
                                                                                                                                0.02
                        0.02                                                                                                    0.01
                        0.01
                                                                                                                             0.003
                        0.003
                                                                                                                             0.001
                        0.001



                                                                                                                                       -6        -5        -4        -3           -2         -1      0       1       2       3       4
                               -6   -5   -4   -3        -2      -1       0        1   2   3   4                                                                                             Data
                                                               Data
                                                                                                                                                                               Normal Probability Plot YY
                                                     Normal Probability Plot Y




                                                                                                                                    0.999
                        0.999
                                                                                                                                    0.997
                        0.997
                                                                                                                                    0.99
                        0.99
                                                                                                                                    0.98
                        0.98
                                                                                                                                    0.95
                        0.95
                                                                                                                                    0.90
                        0.90

                                                                                                                                    0.75
                        0.75
                                                                                                               Probability
          Probability




                                                                                                                                    0.50
                        0.50

                                                                                                                                    0.25
                        0.25

                                                                                                                                    0.10
                        0.10
                                                                                                                                    0.05
                        0.05
                                                                                                                                    0.02
                        0.02
                                                                                                                                    0.01
                        0.01
                                                                                                                                    0.003
                        0.003
                                                                                                                                    0.001
                        0.001




                                                                                                                                           -6     -5        -4        -3           -2         -1         0       1       2       3       4
                               -6   -5   -4   -3        -2      -1       0        1   2   3   4
                                                                                                                                                                                             Data
                                                               Data
                                                                                                                                                                                Normal Probability Plot LS




                                                                                                                                    0.999
Figure 1. Normal probability plots for the                                                                                          0.997
                                                                                                                                     0.99

normalized returns                                                                                ,                                  0.98
                                                                                                                                     0.95
                                                                                                                                     0.90

for different specifications under Model 2.                                                                                          0.75
                                                                                                                      Probability




  Diagonal line: theoretical quantiles conditional                                                                                   0.50


        upon correct specification                                                                                                   0.25

                                                                                                                                     0.10
  +: Empirical quantiles                                                                                                             0.05
                                                                                                                                     0.02
                                                                                                                                     0.01
                                                                                                                                    0.003
                                                                                                                                    0.001




                                                                                                                                            -6        -5        -4        -3           -2      -1        0       1       2       3       4
                                                                                                                                                                                              Data
Figure 2a. Unconditional probability density functions from Model 1 specifications. Data-
based estimates are from a histogram of residuals (.25% cell width).

   1.E+02

   1.E+01
                                                                                    SVJ1
   1.E+00                                                                           SVJ2
                                                                                    DEXP
   1.E-01
                                                                                    VG
              871019
   1.E-02                                                                           Y
              SVJ2                                                                  YY
   1.E-03                                                                           LS
         YY
                                                                                    data
   1.E-04
                         SVJ1                              LS
   1.E-05
        -20%         -15%     -10%     -5%   0%       5%        10%   15%




Figure 2b. Unconditional tail probability estimates. The dotted lines give 95% confidence
intervals, based upon 1000 simulations of the 1926-2006 data set under YY parameter estimates.
          1

                                                                                    SVJ1
        0.1                                                                         SVJ2
                                                                                    DEXP
      0.01                                                                          VG
                                                                                    Y
                                                                                    YY
     0.001                                                                          LS
                                                                                    data
    0.0001                                                                          2.5%
                                                                                    97.5%

  0.00001
        -20%           -15%     -10%   -5%   0%      5%      10%      15%
Figure 3. Unconditional tail probabilities and tail intensity functions versus      . Log scales on both axes. Data-based estimates from
excess returns’ residuals for 20,004 business days with estimated time horizons of approximately 1 day (±11%). Dotted lines give 95%
confidence intervals, based upon 1000 simulated sample paths under YY parameter estimates.


                               y<0                                                                y>0
                                                              1        1


                                                              0.1    0.1


                                                              0.01 0.01
                        data
                                                              0.001
                                                                  0.001


                                                              0.0001
                                                                 0.0001


                                                             0.00001
                                                              0.00001
  100.0%             10.0%             1.0%              0.1%        0.1%                 1.0%             10.0%            100.0%
Figure 4: Autocorrelation revision                     conditional on observing        , and conditional
on
                                            Model 1


  0.8%                                                0.8%
                    Kalman                                                        LS
         SV                                                                                  SV
                                                                                                          SV
                                                                                                          SVJ1
                                                                                                          SVJ2
                                                                                                          DEXP

  0.0%                                                0.0%                                                VG
                                                                                                          Y
                                                                                                          YY
                                                                                                          LS
                                                                                                          Kalman

                                         SV                      SV
                                        LS            -0.8%
                                                                        Kalman
  -0.8%
       -5%    -3%    -1%     1%        3%    5%            -5%    -3%     -1%    1%     3%       5%



                                            Model 2




                                                                                                      SV
0.0%                                              0.0%                                                SVJ1
                                                                                                      SVJ2
                                                                                                      DEXP
                                                                                                      VG
                                                                                                      Y
                                                                                                      YY
                                                                                                      LS


        SV                   LS   SV                       SV                    LS    SV
-1.5%                                             -1.5%
     -8%      -4%      0%         4%        8%         -8%   -4%          0%     4%         8%
Figure 5: Autocorrelation estimates and standard errors from YY model, and stocks’ annual
turnover from French (2008).


   40%                                                                               250%
                                                         (Model 2)


   30%                                                                               200%


   20%                                                                               150%
                                                 (Model 1)

   10%                                                                               100%
                                 SE (Model 1)
                                 SE (Model 2)
    0%                                                                               50%
                                                             Annual turnover
                                                             (right scale)
  -10%                                                                               0%
         26 31 36 41 46 51 56 61 66 71 76 81 86 91 96 01 06
 Figure 6: News impact curves for various models

                        Model 1                                                         Model 2
  6%                                                        6%
                        SV              LS                                  SV                                      LS

                                              SV                                                                              SV
  4%                                                        4%
                                                                                                                                                       SV
                                                                                                                                                       SVJ1
                                                                                                                                                       SVJ2
                                                                                                                                                       DEXP
  2%                                                        2%
                                                                                                                                                       VG
                                                                                                                                                       Y
                                                                                                                                                       YY
                                                                                                                                                       LS
  0%                                                        0%
        -8        -4          0         4          8              -8         -4                0                    4                  8



  -2%                                                       -2%
                  Asset return, in SD units                                 Asset return, in SD units

 The graph show the revision in estimated annualized standard deviation
 conditional upon observing a standardized return of magnitude                                                          .
                                                                            100.0%



                                                                             10.0%
                                                                                                                                                           Qvol
50%                                                                                                                                                        filtered
                                                                             1.0%



                                                                             0.1%

40%                                                                              1/87   5/87   9/87   1/88   5/88   9/88     1/89   5/89   9/89




30%


20%


10%


0%
      26     31    36    41       46   51    56        61         66   71         76       81           86              91          96            01          06

 Figure 7: Estimates of annualized permanent volatility (YY model 2) and standard errors.
 Inset compares daily (open to close) filtered volatility estimates over 1987-89 with the realized
 volatilities computed daily from 15-minute log-differenced S&P 500 futures prices, on a log scale.
Figure 8: Estimated and observed ISD’s for options on S&P 500 futures on December 29, 2006. Moneyness is measured in standard deviation units,
given the maturity-specific at-the-money ISD from options. 95% confidence intervals from the SVJ2 model are shown for parameter uncertainty (dark
grey), and parameter and state uncertainty (light grey).



                                                    1 SD = 2.3%                                                      1 SD = 3.5%




        YY                                                                        YY
                                                     1 SD = 5.3%                                                     1 SD = 8.6%




                            ln(X/F ), in SD units                                            ln(X/F ), in SD units
                                                (left scale)




                                                               (right scale)




Figure 9: Estimated and observed at-the-money ISD’s, 1983-2006. Observed ISD’s are from short-term options on S&P 500 futures
with at least 14 days to maturity, while estimated ISD’s are based on the SVJ2 specification’s parameter and volatility estimates. The grey
area is the 95% confidence interval for the difference, given both parameter and state uncertainty.
