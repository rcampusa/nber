                              NBER WORKING PAPER SERIES




                       ADVERSE SELECTION IN MEDICAID:
                 EVIDENCE FROM DISCONTINUOUS PROGRAM RULES

                                          Betsy Q. Cliff
                                           Sarah Miller
                                       Jeffrey T. Kullgren
                                        John Z. Ayanian
                                          Richard Hirth

                                      Working Paper 28762
                              http://www.nber.org/papers/w28762


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                                     May 2021

The authors are grateful for assistance with data and project management from Erica Solway,
Erin Beathard, Sarah Clark, and Lisa Cohn at the University of Michigan. We are also grateful to
Michigan's Department of Health and Human Services for help with technical aspects of the
program and support for the evaluation. Finally, we acknowledge valuable suggestions on our
analysis from Jeffrey McCullough, Robert Lieberthal, Paul Jacobs, Tom Seldon and other
participants in seminars at the Chicago Health Economics Workshop, American Society of Health
Economists, and the Agency for Healthcare Research and Quality. The University of Michigan
Institute for Healthcare Policy and Innovation (IHPI) is conducting the evaluation required by the
Centers for Medicare and Medicaid Services (CMS) of the Healthy Michigan Plan (HMP) under
contract with the Michigan Department of Health and Human Services (MDHHS). Data collected
for this paper was funded by MDHHS and CMS for the purposes of the evaluation but does not
represent the official views of either agency. DHHS had the right to review the paper for
consistency with reports prepared by the authors under terms of the contract. The views expressed
herein are those of the authors and do not necessarily reflect the views of the National Bureau of
Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2021 by Betsy Q. Cliff, Sarah Miller, Jeffrey T. Kullgren, John Z. Ayanian, and Richard Hirth.
All rights reserved. Short sections of text, not to exceed two paragraphs, may be quoted without
explicit permission provided that full credit, including © notice, is given to the source.
Adverse Selection in Medicaid: Evidence from Discontinuous Program Rules
Betsy Q. Cliff, Sarah Miller, Jeffrey T. Kullgren, John Z. Ayanian, and Richard Hirth
NBER Working Paper No. 28762
May 2021
JEL No. I1,I12,I13

                                         ABSTRACT

Recent expansions of Medicaid eligibility have come with increased experimentation with
enrollee cost-sharing. In this paper, we exploit a discontinuous premium increase at the federal
poverty level in Michigan's Medicaid expansion program to test low-income individuals'
sensitivity to premiums using linked enrollment and claims data. At the cutoff, average premiums
increase by $3.15 and the probability of disenrollment increases by 2.3 percentage points.
Increased disenrollment occurs among those with fewer documented medical needs at baseline,
but not among those with greater medical needs. These results suggest healthier low-income
individuals may be sensitive to even modest health insurance premiums, and that premiums may
induce adverse selection in Medicaid plans.

Betsy Q. Cliff                                  John Z. Ayanian
University of Illinois Chicago                  University of Michigan
School of Public Health                         Institute for Healthcare Policy & Innovation
bqcliff@uic.edu                                 ayanian@umich.edu

Sarah Miller                                    Richard Hirth
Ross School of Business                         University of Michigan
University of Michigan                          rhirth@umich.edu
701 Tappan Street
Ann Arbor, MI 48109
and NBER
mille@umich.edu

Jeffrey T. Kullgren
University of Michigan
2800 Plymouth Rd., Bldg 16
Ann Arbor, MI 48103
jkullgre@med.umich.edu




A data appendix is available at http://www.nber.org/data-appendix/w28762
In the wake of Medicaid expansion under the Affordable Care Act (ACA), states have sought increased flexibility

from the federal government in how to design and implement their Medicaid programs. Several states have

implemented provisions that obligate Medicaid enrollees to pay for an increased share of their health care, either

through utilization-based cost-sharing or regular monthly premiums. Others, particularly recent expansion states,

are considering cost-sharing provisions as a way to link insurance expansion to conservative principles (Carroll

2018). Proponents of these provisions argue cost-sharing will promote personal responsibility among Medicaid

enrollees and encourage them to make better decisions about their health care (Singer, Nelson, and Tipirneni

2017; Galewitz 2014). However, cost-sharing may impose a high burden on an already disadvantaged population,

and may limit access to care by curtailing participation in Medicaid programs (Saloner, Sabik, and Sommers

2014). Prior studies have assessed whether premiums have meaningful effects on program participation in low-

income populations (Artiga, Ubri, and Zur 2017; Dague 2014; Finkelstein, Hendren, and Shepard 2019), but

evidence is limited regarding effects in recent Medicaid expansion programs and on differences in price

sensitivity by health status.


Michigan was one of the first states to pursue a federal waiver under the ACA to use increased cost-sharing in its

Medicaid expansion program, including premium contributions (Ayanian 2013). Within the program, premium

contributions of up to 2% of monthly income are required for enrollees with incomes at or above the federal

poverty level (FPL). Co-payments are required for enrollees regardless of income for certain services. All cost-

sharing responsibilities can be reduced through completion of a health risk assessment with a physician, and total

cost-sharing is capped at 5% of income.1 The imposition of a premium creates a discontinuous change in cost-

sharing at the FPL and levies the only cost-sharing responsibility unrelated to medical utilization. In addition,

enrollees are not assessed program-related cost-sharing until after they have been enrolled for six months,

providing a baseline period in which to assess differences in enrollee characteristics in the absence of cost-sharing

responsibilities. We use the FPL cutoff in a regression discontinuity (RD) design to evaluate the impact of a

monthly premium on enrollees' propensity to disenroll from the program, and use discontinuities in the average


1
    As a result, individuals with no income have no cost-sharing.

                                                                                                                     3
amount of premiums to estimate the price sensitivity in this population. We further use enrollee health status in

the baseline period to characterize which enrollees are more likely to disenroll.


Using administrative data on enrollment and enrollee characteristics, we find evidence that at the FPL cutoff

disenrollment increases by 2.3 percentage points, a relative increase of 11.7%. The size and significance of these

effects, however, are somewhat sensitive to model specification, bandwidth choice, and method of inference.

Because income relative to FPL is not perfectly measured and not all enrollees above the FPL are subject to

premiums, we also implement a fuzzy RD approach to estimate the treatment effect of being exposed to

premiums. We find that facing a premium increases disenrollment by 11.7 percentage points. For every $1

increase in monthly premiums, we find an increase in disenrollment of 0.7 percentage points, which is similar to

previous estimates of price sensitivity in low-income populations (Finkelstein, Hendren, and Shepard 2019),

though slightly lower than estimates in other Medicaid populations (Dague 2014).


As premiums are not assessed until after six months of enrollment, we evaluate the heterogeneity of premium

assessment across groups with different apparent baseline health care needs. Among those with either below-

median health spending or no chronic disease claims in a baseline period that does not have cost-sharing, we find

that facing a premium increases the likelihood of disenrollment by just above 13 percentage points. In these

healthier subgroups, our disenrollment estimates are robust to a variety of model specifications and bandwidths.

We estimate a $1 increase in premiums is associated with a 0.8 percentage point increase in disenrollment in these

two groups. By contrast, the effect of premiums on disenrollment among enrollees with above-median health

spending or a chronic disease claim in the baseline period is smaller and statistically indistinguishable from 0. We

interpret our results as showing that Medicaid program participation for populations with more apparent clinical

needs is not substantially affected by the imposition of premiums, but that healthier enrollees do respond to

premium cost. These results align with recent work showing low-income households in the subsidized individual

insurance exchange market with fewer expected medical costs are more price sensitive (Tebaldi 2017) .


Our study adds to the small but growing literature on how insurance premiums in Medicaid affect enrollment.

Dague (2014) used a similar discontinuity to examine the effects of a premium on enrollment for adults in a

                                                                                                                     4
slightly higher-income population. However, to our knowledge, no analysis has been able to characterize the

health attributes of marginal Medicaid recipients who disenroll due to a premium or describe how premiums

change the composition of Medicaid enrollees. Our results imply premium-based cost-sharing may induce adverse

selection in these plans, by incenting healthier enrollees to leave at higher rates than they otherwise would. That

finding has implications for the expected spending and risk-adjustment for the remaining Medicaid population.

Additionally, our results have implications for other insurance markets that target low-income populations, such

as the ACA health insurance exchanges. The high degree of sensitivity to even very small premiums documented

here suggests that subsidies would need to cover nearly all premium costs if they are to induce healthy enrollees

to remain in the market. That inducement may be even more crucial to maintain enrollment in the current

environment, since the tax penalty related to the ACA's individual mandate was eliminated by Congress in 2017.




I. Background and Related Literature


Our study contributes to evidence of the impact of cost-sharing measures on the Medicaid population and low-

income individuals' price sensitivity to insurance costs more broadly. Prior to the ACA, states had less flexibility

to implement cost-sharing for the Medicaid population, although some adopted premiums in their Children's

Health Insurance Programs (CHIPs). Studies of those programs found a negative relationship between premiums

and program participation (Buchmueller, Ham, and Shore-Sheppard 2015; Marton, Ketsche, and Zhou 2010;

Kenney et al. 2006; Artiga, Ubri, and Zur 2017). Few studies have looked directly at the impact of premiums on

enrollment in the adult Medicaid population. A study of Wisconsin's joint Medicaid and CHIP program, which

imposed premiums for families beginning at 150% of the federal poverty level in 2008, found that going from a

$0 to a $10 monthly premium was associated with a 12 percentage point increase in probability of disenrollment

within a year (Dague 2014). A second study found that enrollment in Oregon's Medicaid program declined by

44% within the first 6 months after implementation of monthly premiums for some members in 2003 (Wright et

al. 2010). Most relevant to this context, premiums structured in a similar way as those in our study may have



                                                                                                                       5
limited coverage gains when Indiana expanded its Medicaid program under the ACA (Freedman, Richardson, and

Simon 2018).


More broadly, prior work has found that low-income individuals have a low willingness to pay for health

insurance. A study using results from the Oregon Health Insurance Experiment estimated that the value of

Medicaid to enrollees is less than half the government's cost of providing it, implying willingness to pay below

medical costs (Finkelstein, Hendren, and Luttmer 2019). Relatedly, studies of the subsidized private health

insurance markets for low-income individuals in Massachusetts and California found enrollees are willing to pay

less, sometimes much less, than their expected medical costs (Tebaldi 2017; Finkelstein, Hendren, and Shepard

2019). These findings demonstrate that cost-sharing, even at modest amounts, reduces uptake of insurance and

contrast with conventional models of health insurance, in which willingness to pay is above expected medical cost

for a risk-averse consumer. Both previous work and our study question the applicability of that model to low-

income populations.


We also contribute to literature showing heterogeneity in price sensitivity across health status. In particular, we

find that healthier enrollees are more price sensitive, and more likely to disenroll from Medicaid when facing a

premium, than are enrollees with apparent medical needs. This finding is closely related to recent work by Tebaldi

(2017) who shows younger households with lower expected medical costs are less willing to pay for insurance

coverage on the California exchange. It is also consistent with a large body of theoretical and empirical work on

adverse selection against various health insurance markets including the subsidized individual market and the

Medicare supplemental coverage market (Arrow 1963; Geruso and Layton 2017; Bundorf and Simon 2006;

LoSasso and Lurie 2009). Because of the limited use of premiums in Medicaid prior to the ACA, there has been

little opportunity to study the effect of premiums in this population. A priori, it is uncertain how premiums will

affect enrollees in this setting. Low-income populations have greater access to implicit insurance through charity

care, care provided at no or low cost to them, which can decrease their valuation of formal insurance. These

populations also have higher liquidity constraints than people with higher incomes, and they may be unable or

unwilling to pay even small cost increases. However, cost-sharing amounts in Medicaid are typically much lower


                                                                                                                      6
than in private insurance and capped at 5% of income in our study population. Additionally, enrollees in

Michigan's program have the opportunity to reduce their cost-sharing obligations through healthy behaviors and,

in this setting, cannot be disenrolled for non-payment. Nevertheless, we find the standard model of adverse

selection holds in this population: as prices increase, those with the lowest expected medical costs drop coverage.

Indeed, we find demographically-adjusted average medical spending in the first six months of the program is 40%

less for those who later disenroll than for those who remain in the plan. Even among disenrollers, however,

average medical spending substantially exceeds average cost-sharing; unadjusted monthly medical spending for

this group is $166 while enrollees pay an average of $4.50 in premiums each month.




II. Setting and Data


    A. Setting: Healthy Michigan Plan


In April 2014, Michigan expanded its Medicaid program by creating the Healthy Michigan Plan (HMP) with

enhanced federal funding provided by the ACA. It was among the first states with both a Republican governor

and Republican legislature to expand the program under the ACA and received a Section 1115 waiver from the

federal government to include several provisions aimed at encouraging enrollees to take responsibility for their

health and care costs (Ayanian 2013). A key feature was higher cost-sharing than had historically been used in

Medicaid. All enrollees with reported income are required to make copayments for certain medical services.

Enrollees with incomes between 100% and 138% of the federal poverty level are additionally required to pay

premiums regardless of their use of health care services.


All cost-sharing obligations, premiums and copayments, are based on service use or income and are not billed

until after six months of enrollment in a Medicaid managed care plan. All cost-sharing is assessed through

quarterly statements, which include both service-based copayments and monthly premiums (see sample statement,

Figure S1), and is collected by an independent vendor working with the state. Enrollees generally are expected to

pay monthly (1/3 of the quarterly statement) although they can pay all at once. Premiums are linked to income


                                                                                                                    7
and household size; program-defined premium estimates for relevant years from the state for households with up

to three enrollees are shown in Table S1 and range from $20-$45 per month. Copayments tend to be much smaller

than premiums. Except for an elective inpatient hospital stay, copayments are between $1-$3 for those under

100% FPL and $2-$8 for those above 100% FPL (Table S2). Many health care services, including labs, imaging,

preventive services, and those associated with a chronic disease visit are not subject to copayments. Thus,

enrollees are not always responsible for utilization-based cost-sharing each quarter even if they do use services. In

practice, the average cost-sharing invoice for individuals above the FPL conditional on a positive invoice is

smaller than theoretical estimates; over the first 18 months of the program, the average monthly invoice for both

copayments and premiums in this population was approximately $10. The discrepancy between the theoretical

and actual invoiced amounts is primarily due to the ability to reduce cost-sharing by completing a health risk

assessment.


All enrollees have an opportunity to reduce their premiums by half through completion of a health risk assessment

with a primary care physician in which the enrollee agrees to work toward a healthy behavior goal. Additionally,

certain populations are exempt from all cost-sharing including those who become pregnant while enrolled in

HMP, enrollees under age 21, enrollees receiving nursing home or hospice care, Native Americans and Alaskan

Natives, and individuals who are eligible for Children's Special Health Care Services (CSHCS). If an enrollee

fails to pay required cost-sharing, after a six-month grace period, state law directs the state health agency to

pursue certain penalties or avenues for collection including taking the overdue amount from tax refunds or state

lottery winnings. Non-compliant enrollees may also give up payment reductions earned through the health risk

assessment. Enrollees cannot be disenrolled or prohibited from services due to failure to comply with payment

requirements. They can voluntarily disenroll from the program at any time by contacting their caseworker, via

phone or in person at a state health agency office. (Now there is also an online way to access the program, though

it was not available during our study period.) Enrollees are also required to complete renewal paperwork and

redetermination of eligibility after 12 months of continuous enrollment; someone who wished to disenroll could

do so by failing to complete that process. After an individual has left the program for a period longer than 2


                                                                                                                    8
months, their cost-sharing obligations reset such that they have another 6-month period without obligations upon

re-enrollment.




    B. Data


We use administrative data obtained from the Michigan Department of Health and Human Services (MDHHS)

and provided as part of a required evaluation of HMP under its federal waiver from the Centers for Medicare and

Medicaid Services. Our data include monthly program enrollment, demographics (age, gender, race, county of

residence, percent of federal poverty level) measured at the time of enrollment, and cost-sharing statements for the

state Medicaid expansion population. We have both premium and copayment amounts by quarter, the period for

which payment obligations are assessed, for any enrollee who was sent a cost-sharing statement, regardless of

whether they were obligated to pay anything. Additionally, while we do not have all individual medical claims,

we have information on total spending and key medical utilization measures derived from the administrative

claims file. We have data for the entire population who enrolled between April 2014 through March 2015. We

followed enrollees through September 2016.


We include only enrollees who are in an HMP managed care plan for at least seven continuous months such that

they were eligible to receive at least one cost-sharing statement. We exclude enrollees who we could identify as

exempt from cost-sharing, including those in nursing home care, hospice care, or special-needs Medicaid

populations and enrollees 21 and younger in 2014. We also exclude those age 62 and older in 2014, who may

become Medicare eligible on the basis of age during our study period. As a final analytic step, we exclude

enrollees with no income ever reported, which excludes about half of those otherwise eligible. In our RD design,

they should not affect our estimates and we test whether they do in sensitivity analyses.


We measure likelihood of disenrollment over the six months subsequent to an enrollee's seventh continuous

month in the program, which is when the first premium statement would be expected: Prob (disenrollment by

month 13| enrollment at month 7). We define disenrollment as any enrollee who leaves the Medicaid program


                                                                                                                   9
entirely for more than 6 consecutive months. Enrollees continuously enrolled for seven months in a managed care

plan who then leave and come back to any Medicaid program within six months are retained in the data set as an

enrolled individual, as we assume this represents something other than disengagement from the program (e.g.

delayed completion of paperwork to maintain enrollment). Enrollees who switch out of an HMP managed care

plan to another Medicaid program (post 7-months enrollment in managed care) are also defined as remaining in

Medicaid. To be at risk for disenrollment through our study period, which ends in September 2016, we require

enrollees to be in an HMP managed care plan by August 2015. If an enrollee has multiple 13-month episodes in a

managed care plan, we include the first 13-month episode.


We define a contribution or copayment obligation as any positive invoice amount of either type when it is

assessed, regardless of the amount or whether the invoice was paid. Monthly copayment or contribution

obligations are further defined as one-third of the average of a quarterly contribution or copayment invoice

received by an enrollee. These invoices include reductions from completion of a health risk assessment but not

past due amounts.


    C. Data Limitations


While we are able to leverage very granular and complete data for Michigan's Medicaid program, these data have

some limitations. We observe income based on the amount reported to and verified by the state, corrected to

reflect the state's most current information. However, this amount may be different from the income level

originally reported to the state. For example, suppose an enrollee reported an income at 40% FPL from January

through September, and faced cost-sharing based on that level. Then, in September, the enrollee reported to the

state a new job that began in June, which gave the enrollee an income at 110% FPL. The state would correct the

FPL from June through September in the data file, though the invoices from those months would reflect the

previous income information. The dataset did not have reliable information about whether FPL was corrected

between the time when cost-sharing was assessed and when we observe FPL, causing some potential

mismeasurement of income in our data. To mitigate this limitation, we test whether reported income roughly

corresponds to predicted cost-sharing obligations (Figure 1; Table S3) and whether we see dynamic manipulation

                                                                                                                  10
of income over time (Table S4). Additionally, we adjust for enrollment date--the month HMP managed care

enrollment is first reported--in regression models.


Second, we are unable to observe some features of the population that lessen or eliminate cost-sharing

responsibilities. For example, we do not have complete claims information or other data flags that allow us to

exclude pregnant women, who are exempt from cost-sharing. Some enrollees have characteristics we would

typically associate with cost-sharing, but we do not observe positive invoices. We are unable to determine why

cost-sharing was not levied on these enrollees. These measurement errors are not a particular concern for our

empirical approach, but they do indicate that a "fuzzy" regression discontinuity design--where the discontinuity

is used as an instrument for our variable of interest, monthly premiums--is appropriate for our setting.


Lastly, there is a potential relationship between cost-sharing and diagnosis of medical needs. Given that enrollees

can reduce their cost-sharing obligations through completion of a health risk assessment, which occur at primary

care visits, enrollees who use health services may be more likely to have lower cost-sharing obligations. This

effect changes the marginal Medicaid enrollee who is affected by the premium. As a result, our estimates may not

generalize to settings where no such ability to reduce premiums exists. For this reason, we both adjust for receipt

of a health risk assessment in regression models, and estimate the elasticities of premiums for each subgroup in

addition to the effects of having any premium.


    D. Population characteristics


Table 1 shows the characteristics of the HMP population >0% FPL who were enrolled for at least 7 continuous

months, split by whether they were still enrolled after 13 months (n=195,495). Compared to those who are

continuously enrolled for at least 13 months, individuals who disenroll are more likely to be male, younger, and

non-black minorities. Disenrollers also have lower mean monthly spending on healthcare ($166 vs $297) and a

lower likelihood of receiving a statement with a copayment.


Plotting demographics of the population by FPL shows few differences at 100% of FPL (Figure S2; Table S5).

Age of enrollees shows a sine pattern across the FPL distribution; the percent of enrollees who are white and


                                                                                                                   11
having a later enrollment date are directly related to percent of FPL. Notably, the proportion of enrollees

completing a health risk assessment, which can affect cost-sharing amount, is weakly related to income and shows

no discontinuities at the FPL. In contrast to the demographic and health risk assessment, however, there are

distinct changes in premium obligations at the FPL (Figure 1; Table S3). Specifically, for those with an average

income between 99 and just below 100% FPL, 22.8 percent are billed a premium; those with an average income

between 100 and 101% FPL 41.2 percent are billed a premium. The average premium amount also jumps at the

FPL, from $3.05 to $6.77. By contrast, we see no jump in the percentage of the population assessed a copayment

or, despite a program-defined difference, amount of copayments at this threshold (Table S3; Figure S3). Across

the population, the average copayment is approximately $0.84. This continuity in copayment amounts could be

due to the program-defined amount of copayments being similar in absolute terms for most services (especially

with a 50% discount for completing a health risk assessment) or to the fact that most common services, including

imaging and lab studies, are copay-exempt. Other analyses of this program found 80% of enrollees used at least

one copay-exempt service; 56% used at least one copay-likely service without differences by FPL (Hirth et al.

2018).


Compared with those below 100% FPL, a higher percentage of enrollees above the FPL disenroll from the

program between 7 and 13 months (17.9 vs 24.6%; Table S3). Indeed, a naïve regression of disenrollment on FPL

returns a positive estimate. However, this estimate is misleading as a causal effect due to higher enrollment churn

among those with higher incomes, particularly close to the eligibility cap at 138% FPL.


The correlation between cost-sharing obligations and likelihood of disenrollment differs depending on both

whether the entire invoice is considered, or whether premium and copayments are separated. When considering

the entire invoice, the probability of disenrollment by cost-sharing level differs depending on whether a person is

above or below the FPL. For those below the FPL, for whom cost-sharing is almost entirely due to service-based

copayments, higher cost-sharing is correlated with lower demographically-adjusted probability of disenrollment

(Figure S4). However, as the figure shows, for those above the FPL, the relationship between disenrollment and

cost-sharing is concave, peaking at approximately $75 in 6-month costs and declining at higher amounts. When


                                                                                                                   12
copayments are separated out, as in Figure S5, there is no difference by FPL; higher copayments are related to a

lower subsequent probability of disenrollment regardless of income. These graphs suggest that premiums as

assessed by HMP may impact enrollment decisions in a different way than do copayments for services. To test

that hypothesis directly, we use a regression discontinuity analysis described below.




III. Analysis: Regression Discontinuity Design


Our analysis makes use of a policy that changes discontinuously at the FPL. Individuals whose household income

falls just below this cutoff are less likely to experience premiums relative to those with incomes just above, even

though they are likely similar across other dimensions. Although the probability of having a premium obligation

increases discontinuously at 100% of the FPL, it does not jump from 0 to 1 (Figure 1); this motivates our fuzzy

RD analysis in this setting. We therefore present two versions of the model. The first, a reduced form or sharp RD

estimate, measures the discontinuous change in disenrollment propensity at the cutoff using the following

functional form:


                       =  + 1 ( ) + 2 ( ) +  +  +  ; -    +


                                 where  = 1{ >  ,  = 100}


In this equation,  is the probability that an enrollee who is in the program at 7 months is still enrolled in HMP at

13 months, as defined above. We are primarily interested in whether the effect changes discontinuously at the

cutoff point, D, which is at 100% of the FPL. We adjust for individual-level demographic and program-related

covariates (age in bands, gender, race, region of residence, receipt of healthy behavior reward, and enrollment

date) captured in the vector  . We estimate the discontinuity using a local linear regression with a mean squared

error-optimal bandwidth to minimize bias. To facilitate comparisons across subgroups, we also show the results

using other selected bandwidths in our main results. We use a triangular kernel for all specifications and

conventional standard error approaches due to the discrete nature of the running variable (Kolesár and Rothe

2018).

                                                                                                                   13
The above estimation measures the change in disenrollment probability in the entire sample around the cutoff,

even though some of the individuals above the cutoff are not "treated" (i.e., charged a premium). We thus

estimate a second version that scales this reduced form estimate by the change in the treatment probability at the

cutoff to estimate the effect of the premium among those actually charged a premium using a fuzzy RD approach.

From this estimate, we report effects of treatment on the treated reflecting the change in probability of

disenrolling for enrollees with premium obligations.


In order for our approach to be plausibly causal, we assume that those with incomes just below the FPL and just

above it are otherwise similar. For this assumption to be reasonable, it must be the case that enrollees are not able

to precisely manipulate the characteristics that determine whether or not they are subject to the treatment, in this

case, income relative to FPL (Lee and Lemieux 2010). While income is reported by enrollees, it is verified using

paychecks, tax forms or other documentation by the state. This verification, along with the complication that the

threshold value depends on both household size and income, may make it difficult for enrollees to precisely

manipulate income around the threshold value.


We test whether percent of FPL is manipulated by looking cross-sectionally at the density of FPL and

dynamically by examining whether enrollees over the threshold adjust their incomes to be below the FPL

threshold to avoid paying the premium. We conduct these tests in several ways. Figure S6 shows a histogram of

percent of FPL for our eligible population with income between 70% and 130% FPL. This plot shows a small

spike just above 100% FPL and a larger spike near the eligibility cut-off of 133%, but no apparent spike just

below 100% FPL, which is where we would expect bunching if FPL were being manipulated to avoid premiums.

This visual spike is confirmed by a McCrary density test (Figure S7), which shows a log increase in density of

0.14 (p=0.02) just above 100% FPL (McCrary 2008). We account for the potential effect of such bunching in

sensitivity analyses by estimating donut hole regressions in which we leave out particular bandwidths of FPL

(Barreca, Lindo, and Waddell 2016). We also test for the dynamic manipulation of percent of FPL that is

differential lowering of income level by those with premiums, perhaps to avoid these payments. To test for this

type of manipulation, we use a Markov transition matrix to look at probabilities of moving above or below the


                                                                                                                   14
FPL between initial and final, or 13th, month of enrollment in a managed care plan. We find that 87.8% of those

who initially report incomes over the 100% of FPL are still above that threshold in their final observation (Table

S4). This likelihood does not differ substantially by whether a person is required to make a premium contribution

or not, and aligns with other evidence from this population showing a lack of strategic manipulation of income in

the context of Medicaid recertification (Pei 2017). Taken together, the evidence does not suggest that individuals

report lower incomes either initially or over time to avoid paying premiums.


As previously discussed, we also examine whether demographic characteristics--age, gender, race, region of

residence, healthy behavior reward receipt and enrollment date--vary discontinuously at the cutoff. Here, we do

detect some small but statistically significant differences at the cutoff income for age, gender, and enrollment

date, though not for race, region or receipt of a healthy behavior reward (Figure S2; Table S5). To account for

these differences at the cutoff, we control for age, gender, race, region, enrollment date and healthy behavior

reward receipt in all of our specifications unless otherwise noted.




IV. Results


Figure 1 displays the relationship between the fraction of enrollees required to pay a premium and enrollee

income relative to the FPL. There is an obvious discontinuous jump in this fraction that occurs at the threshold of

100% FPL. Figure 2 shows a graph of disenrollment plotted against FPL, with linear fit lines on either side of the

discontinuity. There is some noise in the data, yet disenrollment rates do appear to be elevated for those with

incomes above the 100% FPL threshold.


Table 2 presents the main results of our RD model; we discuss results at the MSE-optimal bandwidth and present

other bandwidths for comparison. Column 1, which formalizes the relationship shown in Figure 1, shows that the

estimated probability of a premium contribution increases by about 19 percentage points at the FPL cutoff. The

mean monthly premium amount increases by $3.15 at the cutoff (Column 2; see Figure S8 for the corresponding

graph). In the third column, we show the change in the probability of disenrolling at the 100% FPL cutoff, which


                                                                                                                   15
corresponds to the sharp RD estimate. We find a statistically significant increase of 2.3 percentage points in the

probability of disenrollment at the cutoff (standard error = 0.0085); compared with the disenrollment rate of 19.5

just below the FPL, this estimate represents a relative increase of 11.7%.


In the next two columns, we present the treatment effects of exposure to monthly premiums (column 4) and the

amount of the premium (column 5). We find the assessment of a premium increases the probability of

disenrollment by 11.7 percentage points (standard error = 0.045). Each additional dollar of premium cost

increases disenrollment probability by about 0.71 percentage points (standard error=0.0028). Both estimates are

statistically significant at conventional levels (p<0.05). The premium elasticity estimate implies that with a price

change of $3.72, the average unadjusted difference in monthly premiums for those just above and just below the

poverty line, an additional 2.6% percent of the population will disenroll.


    A. Subgroup analyses


We next examine disenrollment stratified by health need, proxied by either higher than median medical spending

or the presence of a chronic disease diagnosis in claims data, both measured during an enrollee's first continuous

7-month period of enrollment in which they are not obligated to pay copayments or premiums. (Invoices sent in

the seventh month of managed care enrollment are due in the eighth month; our data show the modal invoice is

received in the eighth month.) There are no differences in likelihood of belonging to one of these groups across

the FPL (Figure S9). There is considerable overlap among the subgroups; approximately 75% of those with above

median spending have a chronic disease diagnosis. As in the main analysis, these two subgroups have an obvious

discontinuity at the FPL in both likelihood and amount of a premium (Figures S10 and S11). However, we

estimate different effects of the premium on disenrollment for each group. Figure 3 plots the likelihood of

disenrollment for each subgroup; the data and linear fit lines appear to show larger increases in disenrollment for

those with lower medical spending or without a chronic disease diagnosis compared with groups with higher

baseline medical needs.




                                                                                                                     16
We present estimates from the regression discontinuity model described above on each subgroup in Table 3 and

discuss the estimates at the MSE-optimal bandwidth. The reduced form estimates show that for those with either

no chronic disease claims or below median medical spending, disenrollment jumps by 3.3 and 3.6 percentage

points, respectively; for those with a chronic disease or above median medical spending the jump is smaller in

magnitude and not statistically different from 0. In the fuzzy RD design, individuals across all subgroups have

the expected strong first-stage coefficients (Table 3, column 1). The first-stage coefficients are higher for the

groups with lower medical needs, possibly because those with higher median spending or a chronic disease

diagnosis may be more likely to engage with the medical system through health risk assessment completion as

discussed above, and thus lower their premiums. For those with below-median baseline expenses, having a

premium increases their likelihood of disenrollment by 13.4 percentage points (standard error=0.587). For those

with above-median baseline expenses, a premium obligation increases their likelihood of disenrollment by 4.5

percentage points, and this estimate is not statistically significant. For those without a chronic disease diagnosis, a

premium contribution increases their likelihood of disenrollment by 13.6 percentage points (standard error =

0.067); the estimate for those with chronic disease is negative (-3.1 percentage points) though the magnitude of

the standard error (0.10) indicates the estimate is statistically indistinguishable from 0. These results imply that

premiums will induce adverse selection in the program; with adjustments via linear regression for demographic

and program covariates, the mean medical cost of disenrollers in the first 7 months of program enrollment is

$175.84 compared with $293.15 for those who stay enrolled (Table S7).


Price sensitivity also appears affected by clinical need. For every dollar increase in monthly premium for those

with below-median spending, disenrollment increases by 0.82 percentage points (standard error=0.0036); for

every dollar increase in monthly premium for those with above-median spending, disenrollment increases by a

statistically insignificant 0.40 percentage points (standard error=0.0048). Similar patterns emerge when we model

the difference in disenrollment stratified by whether an enrollee has a claim for a chronic disease (Table 3). An

increase of $1 in monthly premium increases the rate of disenrollment by 0.84 percentage points (standard

error=0.0042) for those without a chronic disease claim within their first 7 months of enrollment, and by


                                                                                                                       17
statistically insignificant 0.53 percentage points (standard error=0.0041) for those with a chronic disease claim.

To compare price sensitivity of each group, we use the estimates with the same bandwidth (10). These estimates

shows that the price sensitivity for enrollees with above-median medical spending or a chronic disease diagnosis

is roughly one-third to one-fourth the magnitude of that for those without a chronic disease diagnosis or below-

median spending. These estimates imply that for the average increase in premium of $3.72, an additional 3% of

apparently healthier enrollees will disenroll, while the same increase would cause less than 1 percent of more

medically needy enrollees to leave the program.


    B. Sensitivity Analyses


In Figures S12 and S13, we present the results from several alternative specifications and bandwidth selection

procedures. First, we include testing sensitivity to a bandwidth selector with a small coverage error rate (CER)

rather than optimizing the mean squared error (Calonico, Cattaneo, and Farrell 2016). This bandwidth selector

optimizes the construction of the confidence interval and may be preferable if the focus is on the confidence

interval rather than the point estimate itself. Second, we also estimate a global linear rather than a local linear

model to ensure our results are not sensitive to the exact way in which we model the running variable. We also

probe the robustness of our results to retaining enrollees with no income, following enrollees for 12 months

(rather than 6) after their initial 7 months of continuous enrollment to ensure results are robust over a longer time

period, and to using the minimum, rather than average, income observed for a household to construct the running

variable, which allows to capture enrollees always above the FPL threshold. We additionally measure outcomes

when disenrollment is defined as 2 months out of the program rather than 6 to explore whether disenrollment

patterns changed at the HMP program defined point where cost-sharing reset, and taking the subset of enrollees

who had no copayments to mitigate confounding by the potential for copayment increases at the FPL. Although

most of these 13 additional specifications provide similar estimates to those reported in Table 2, using narrow

bandwidths selected through the CER method we do find negative small impacts of the premium on

disenrollment. We suspect this result is due to the bunching observed in Figure S6 and, indeed we find a




                                                                                                                      18
statistically significant positive estimate using this same specification and dropping enrollees with 100% or 101%

FPL incomes from the analysis.


Figures S14 and S15 show estimates of the reduced form effect for a series of placebo cutoff points from 20%

FPL through 85% FPL. In these tests, we are comparing the estimate at 100% FPL to placebo cut-off points;

evidence it is larger than most placebo cut-off points would provide reassurance the effect is not spurious. For the

main effects we find that 46% of placebo cutoff points have an absolute value smaller than our main estimate.

When we examined some of the larger estimates (some are more than 10% at the placebo cutoff point) they fell

around eligibility cutoffs for other programs commonly used in this population, including the state's Temporary

Assistance for Needy Families eligibility. It may be that enrollment in these programs keeps people attached to a

greater degree to the Medicaid program, leading to an increase in disenrollment just beyond these thresholds. We

know of no such programs with eligibility cutoffs at the FPL that would confound our estimates. Split by medical

spending, we find that 60% of placebo values are smaller in absolute value than our estimated effect for those

with low medical spending and 17% of values have an absolute value smaller than our estimated effect for the

high medical spenders. Split by chronic disease diagnosis, 65% of placebo values are smaller in absolute value

than our estimated effect for those without a chronic disease and 15% of our estimated values are smaller in

absolute value than our estimated effect for those with a diagnosed chronic disease. These placebo cutoff results

support an interpretation of the disenrollment results from the full sample as suggestive rather than conclusive and

bolster the stratified results showing a relationship between clinical need and disenrollment. Finally, we

performed donut-hole regressions in which we excluded symmetric bands of FPLs around the threshold value to

test whether the estimates are sensitive to the specific behavior of observations around the cutoff and to potential

FPL manipulation (Cattaneo, Idrobo, and Titiunik 2018; Barreca, Lindo, and Waddell 2016). Figures S16 and S17

show the results from those series of regressions for the entire sample and for each subgroup split by medical

need. These estimates are clustered around the main estimates (shown with the red line in the figures) and the

confidence intervals run through the main estimates in most cases. This analysis shows that dropping estimates




                                                                                                                   19
just above the FPL--where Figures S6 shows a small amount of bunching--leads to higher estimates of the

treatment effect; income manipulation in those bands may bias the main estimates downward slightly.




V. Discussion


We find a jump in disenrollment when monthly premiums are assessed in Michigan's Medicaid expansion

program. That jump is evident among those with less medical spending or no chronic medical conditions, though

not for those with chronic conditions or higher medical spending. These results indicate the imposition of monthly

premiums may limit program participation, and that this effect is strongest in those who use less medical care,

indicating that enrollees who remain in Medicaid programs that include premiums are less healthy on average

than in Medicaid programs without premiums. While it may lower overall program spending, this result implies

that the per-member spending in Medicaid programs with premiums is higher than in programs without

premiums. Capitation based on membership should take into account the effect of cost-sharing on population

health risk, particularly if initial risk adjustment fails to account for this disproportionate drop out of healthier

enrollees in the Medicaid program.


Our results show lower disenrollment than earlier work on cost-sharing among Medicaid enrollees (Wright et al.

2010). Unlike Oregon, cost-sharing was a feature of the Healthy Michigan Plan from its inception, and some

potential enrollees may have stayed out of the program entirely due to the prospect of cost-sharing. Also,

Michigan's expansion both allowed enrollees to reduce their level of cost-sharing by completing a health risk

assessment and remain in the program even if non-compliant with payment, though they could become subject to

collections actions. Additionally, as noted above, enrollees who leave for more than 2 months and then return

reset their cost-sharing schedule such that they are not subject to cost-sharing for 6 months after re-enrollment.

These features may have limited attrition from the program and, thus, our results could represent a lower bound

on price responsiveness. In surveys, the majority of HMP enrollees agreed the program is fair and affordable

(Goold et al., 2018), and few who were no longer enrolled (2.1%) reported dissatisfaction with costs as the


                                                                                                                        20
primary reason for ending enrollment (Clark and Goold, 2018). Yet, even in these circumstances, in which

enrollees can mitigate or even avoid cost-sharing altogether, premiums appear to encourage disenrollment among

healthier enrollees.


Our elasticity results are similar to previous findings of high price sensitivity for insurance among low-income

individuals. A closely related paper, Dague (2014), suggests that a $1 increase in premium would cause a 1.2

percentage point drop in enrollment; our main estimate finds each $1 in additional premiums causes a 0.7

percentage point drop. Given a churn of 20% just below the FPL threshold and an average increase of $3.72 in

premium amount at the FPL, our elasticity estimates demonstrate that in this program the imposition of premiums

increases attrition by a relative 13 percent. Attrition from the program also occurs because of income increases,

other health insurance coverage, or administrative problems with re-enrollment (Clark and Goold 2018). Previous

work has shown that low income enrollees value insurance at less than its actuarial value (Finkelstein, Hendren,

and Shepard 2019). We add to these findings by showing heterogeneity in insurance valuation by clinical need,

consistent with the notion that premiums could contribute to adverse selection in this setting.


A clear policy implication from this analysis is that premium-based cost-sharing as implemented in Michigan may

limit efforts toward higher rates of insurance coverage, as some people are unwilling or unable to pay the

additional costs imposed through monthly premiums. We do not know the extent to which those who disenroll

due to cost-sharing experience are subsequently uninsured. In a survey of former enrollees in Michigan's

Medicaid program, 81% said they would have had no viable insurance options without the program, and 55% said

they had a gap in health coverage of longer than 3 months once they left the program (Clark and Goold 2018).


Because the premium amounts are lower than average expenses even for relatively healthy disenrollers, the short-

run effect of this policy would be expected to yield savings for public budgets, particularly the federal and state

budgets for Medicaid expansion. In addition to a smaller Medicaid population, there are potential savings that

arise from the fact that capitated payments to managed care plans are based on claims data from prior to the

imposition of premiums, when the patient pool is relatively healthier. In Michigan, managed care plans are paid

using capitated rates that are risk adjusted using encounter data for the case mix of each plan's population at the

                                                                                                                      21
beginning of a fiscal year. 2 As a result, in the short-run, the selection out of Medicaid by healthy enrollees

implies that the state both pays for fewer enrollees and underpays Medicaid managed care plans for the remaining

patient population covered. However, those who disenroll may take advantage of implicit insurance (i.e. access to

health care services outside of formal health insurance) offered by statute or safety-net health care providers, or of

conditional coverage, the ability to enroll in Medicaid after a health shock (Cutler and Gruber 1996; Finkelstein,

Hendren, and Luttmer 2019; Mahoney 2015). More research following those who disenroll from Medicaid due to

premiums is needed to fully understand the experiences of these disenrollers and subsequent fiscal consequences.

If those who disenroll continue to use medical services subsidized by the state or federal governments, the cost

savings may be lower than expected or non-existent.


While states may save money by paying for remaining enrollees at a rate calculated on a healthier population,

such changes could impact managed care plans' profitability and disrupt the managed care market. The revenue

lost to managed care organizations in this setting when relatively healthy beneficiaries leave the program amounts

to slightly less than 1% of their total revenue for the expansion population on average.3 These losses are not

trivial; Michigan builds margins of about 2% into their capitation rates across plans (Tapperna et al. 2017). If

losses are concentrated in a small number of plans or correlated with plan characteristics, they could be

particularly disruptive. Previous work in Kentucky's Medicaid program has shown that higher-cost enrollees tend

to switch plans more often, and move toward higher quality plans, than do low-cost enrollees (Marton, Yelowitz,

and Talbert 2017). Like Kentucky, Michigan allows Medicaid enrollees to switch plans. HMP enrollees can




2
  State of Michigan Contract No. Comprehensive Health Care Program for the Michigan Department of Health and Human
Services (https://www.michigan.gov/documents/contract_7696_7.pdf) . Accessed March 30, 2021. Capitated plan
payments are made from the state to plans based on monthly enrollment, fully re-calculated based on enrollee expected health
risk annually and, to some extent, risk adjusted six months into the year to account for changes in enrollment (Brandel, Pettit,
and Gordon 2018).
3
  We use a "back of the envelope" estimate to calculate the lost revenue as follows. Assume those who do not disenroll due
to premiums have spending $272.67 of while the 2.3 percent of enrollees who disenroll due to premiums have the average
spending of the typical disenroller ($165.67, Table 1). Averaging these two groups results in the observed average
expenditure we observe in the expansion population ($270.21; Table S3). Assume further that plans receive as per member
revenue average spending ($270.21). After premiums are imposed, plans' revenue remains $270.21 per member but costs
per member become the average expenditure of those who do not disenroll only, $272.67 per member. Loss is therefore
$272.67-$270.21=$2.46 per member per month, or about 0.9% relative to monthly revenue per member (2.46/270.21).

                                                                                                                             22
choose a plan at the beginning of their initial enrollment or annually during an open enrollment period. While we

do not know whether the adverse selection we identify affects managed care plans differentially by quality, if

lower-cost enrollees are more likely to leave health plans after premium imposition, and higher-cost enrollees

both stay and gravitate toward higher-quality plans, it could result in higher-quality plans with a significantly

costlier population over time. If not sufficiently compensated through regular risk adjustment, this effect may

destabilize the Medicaid managed care market. Our results suggest this threat; future work is needed to measure

and confirm the differential effect of cost-sharing across Medicaid managed care plans.


This study represents the Medicaid cost-sharing experience of one early-adopting Medicaid expansion state,

which may limit its generalizability. Nonetheless, we believe our results show the potential for increased

disenrollment in low-income populations with even modest premiums. States should be aware of this effect and of

the potential for adverse selection when making policy decisions about enrollees' cost-sharing responsibilities.




                                                                                                                    23
References

Arrow, Kenneth J. 1963. "Uncertainty and the Welfare Economics of Medical Care." The American Economic
       Review 53 (5): 941­73.
Artiga, Samantha, Peter Ubri, and Julia Zur. 2017. "The Effects of Premiums and Cost Sharing on Low-Income
        Populations: Updated Review of Research Findings." Issue Brief. Henry J. Kaiser Family Foundation.
        https://www.kff.org/medicaid/issue-brief/the-effects-of-premiums-and-cost-sharing-on-low-income-
        populations-updated-review-of-research-findings/.
Ayanian, John Z. 2013. "Michigan's Approach to Medicaid Expansion and Reform." New England Journal of
       Medicine 369 (19): 1773­75.
Barreca, Alan I., Jason M. Lindo, and Glen R. Waddell. 2016. "HeapingInduced Bias in Regression
        Discontinuity Designs." Economic Inquiry 54 (1): 268­93.
Brandel, Shelley, Christopher Pettit, and Alisa Gordon. 2018. "University of Maryland, Baltimore County:
       Medicaid Managed Care Rate Setting and Payment Innovation Study." Milliman Inc.
       https://www.manatt.com/Manatt/media/Documents/Articles/Medicaid-Managed-Care-Rate-Setting-and-
       Payment-Innovation-Study.pdf.
Buchmueller, Thomas, John C. Ham, and Lara D. Shore-Sheppard. 2015. "The Medicaid Program." National
      Bureau of Economic Research.
Bundorf, M. Kate, and Kosali I. Simon. 2006. "The Effects of Rate Regulation on Demand for Supplemental
       Health Insurance." American Economic Review 96 (2): 67­71.
Calonico, Sebastian, Matias D. Cattaneo, and Max H. Farrell. 2016. Coverage Error Optimal Confidence
       Intervals for Regression Discontinuity Designs.
Carroll, Aaron. 2018. "Finally, Some Answers on the Effects of Medicaid Expansion." The New York Times, July
         2, 2018, sec. The Upshot. https://www.nytimes.com/2018/07/02/upshot/finally-some-answers-on-the-
         effects-of-medicaid-expansion.html.
Cattaneo, Matias D., Nicolás Idrobo, and Rocío Titiunik. 2018. A Practical Introduction to Regression
       Discontinuity Designs: Volume I. Cambrigde University Press, forthcoming.
Clark, Sarah, and Susan Dorr Goold. 2018. "Report on the Healthy Michigan Voices 2016-17 Survey of
        Individuals No Longer Enrolled in the Healthy Michigan Plan." University of Michigan Institute for
        Healthcare Policy and Innovation.
Cutler, David M., and Jonathan Gruber. 1996. "Does Public Insurance Crowd out Private Insurance?" The
        Quarterly Journal of Economics 111 (2): 391­430.
Dague, Laura. 2014. "The Effect of Medicaid Premiums on Enrollment: A Regression Discontinuity Approach."
       Journal of Health Economics 37: 1­12.
Finkelstein, Amy, Nathaniel Hendren, and Erzo FP Luttmer. 2019. "The Value of Medicaid: Interpreting Results
        from the Oregon Health Insurance Experiment." Journal of Political Economy 127 (6): 2836­74.
Finkelstein, Amy, Nathaniel Hendren, and Mark Shepard. 2019. "Subsidizing Health Insurance for Low-Income
        Adults: Evidence from Massachusetts." American Economic Review 109 (4): 1530­67.
Freedman, Seth, Lilliard Richardson, and Kosali I. Simon. 2018. "Learning from Waiver States: Coverage Effects
      under Indiana's HIP Medicaid Expansion." Health Affairs 37 (6): 936­43.
Galewitz, Phil. 2014. "Michigan To Reward Medicaid Enrollees Who Take `Personal Responsibility.'" Kaiser
       Health News, June 11, 2014.


                                                                                                             24
Geruso, Michael, and Timothy J. Layton. 2017. "Selection in Health Insurance Markets and Its Policy Remedies."
        Journal of Economic Perspectives 31 (4): 23­50.
Hirth, Richard A., Elizabeth Q. Cliff, Jeffrey T. Kullgren, A. Mark Fendrick, Sarah Clark, Erin Beathard, Erica
        Soloway, Lisa Cohn, and John Z. Ayanian. 2018. "Report on the Impact of Cost Sharing in the Healthy
        Michigan Plan. Evaluation Domain V/VI." Submitted to the Michigan Department of Health and Human
        Services.
Kenney, Genevieve, R. Andrew Allison, Julia F. Costich, James Marton, and Joshua McFeeters. 2006. "Effects of
       Premium Increases on Enrollment in SCHIP: Findings from Three States." INQUIRY: The Journal of
       Health Care Organization, Provision, and Financing 43 (4): 378­92.
Kolesár, Michal, and Christoph Rothe. 2018. "Inference in Regression Discontinuity Designs with a Discrete
        Running Variable." American Economic Review 108 (8): 2277­2304.
Lee, David S., and Thomas Lemieux. 2010. "Regression Discontinuity Designs in Economics." Journal of
       Economic Literature 48 (2): 281­355.
LoSasso, Anthony T., and Ithai Z. Lurie. 2009. "Community Rating and the Market for Private Non-Group Health
       Insurance." Journal of Public Economics 93 (1­2): 264­79.
Mahoney, Neale. 2015. "Bankruptcy as Implicit Health Insurance." American Economic Review 105 (2): 710­46.
Marton, James, Patricia G. Ketsche, and Mei Zhou. 2010. "SCHIP Premiums, Enrollment, and Expenditures: A
       Two State, Competing Risk Analysis." Health Economics 19 (7): 772­91.
Marton, James, Aaron Yelowitz, and Jeffery C. Talbert. 2017. "Medicaid Program Choice, Inertia and Adverse
       Selection." Journal of Health Economics 56: 292­316.
McCrary, Justin. 2008. "Manipulation of the Running Variable in the Regression Discontinuity Design: A Density
      Test." Journal of Econometrics 142 (2): 698­714.
Pei, Zhuan. 2017. "Eligibility Recertification and Dynamic Opt-in Incentives in Income-Tested Social Programs:
        Evidence from Medicaid/CHIP." American Economic Journal: Economic Policy 9 (1): 241­76.
Saloner, Brendan, Lindsay Sabik, and Benjamin D. Sommers. 2014. "Pinching the Poor? Medicaid Cost Sharing
        under the ACA." New England Journal of Medicine 370 (13): 1177­80.
Singer, Phillip M., Daniel B. Nelson, and Renuka Tipirneni. 2017. "Consumer-Directed Health Care for Medicaid
        Patients: Past and Future Reforms." American Journal of Public Health 107 (10): 1592­94.
Tapperna, Sara, Jeff Goldman, Luke Smith, and Steve Tutewohl. 2017. "Medicaid Managed Care Organizations:
       Considerations for Calculating Margin in Rate Setting." Society of Actuaries.
       https://www.soa.org/globalassets/assets/Files/Research/medicaid-managed-report.pdf.
Tebaldi, Pietro. 2017. "Estimating Equilibrium in Health Insurance Exchanges: Price Competition and Subsidy
        Design under the Aca." Working paper. Becker Friedman Institute for Research in Economics Working
        Paper No. 2017-05. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3020103.
Wright, Bill J., Matthew J. Carlson, Heidi Allen, Alyssa L. Holmgren, and D. Leif Rustvold. 2010. "Raising
        Premiums and Other Costs for Oregon Health Plan Enrollees Drove Many to Drop Out." Health Affairs
        29 (12): 2311­16.




                                                                                                              25
Table 1: Descriptive Statistics of Healthy Michigan Plan Managed Care Population, by
disenrollment status
                                                 Disenroller         Continuously Enrolled
                                                 (N=39,289)              (N=156,206)
                               Female (%)           51.1                     63.1

                                   Age (mean)               37.6                              40.4

          First enrollment month (median)                 Nov-14                            Oct-14

                                  FPL percent               85.0                              76.4
Region
                     Northern Michigan(%)                   9.9                               10.4

                       Central Michigan(%)                  30.9                              31.1

                          Southern Michigan                 22.9                              19.4
                                        Detroit             36.3                              39.1

Race
                                         White              61.8                              66.6
                                          Black             17.7                              19.8

                                         Other              20.5                              13.5
       Monthly medical spending (mean $)                  165.67                            296.51

       Monthly number of chronic disease                    0.24                              0.42
                          claims (mean)
        Received premium statement (%)                      24.5                              20.1

             Received copay statement (%)                   27.4                              40.4
                Monthly Premium (mean $)                    4.49                              3.39

             Monthly Copayment (mean $)                     0.53                              0.92

       Received Healthy Behavior Reward                     14.9                              25.3
Notes: Population Inclusion Criteria: 1) Not part of special population (e.g. hospice, nursing home care, children's
health programs) 2) Between 22 and 62 years of age 3) Enrolled in Healthy Michigan Plan Managed Care (HMP-
MC) before Sept 2015, so that we have at least 13 months of potential observation 4) At least 7 months of
continuous HMP-MC enrollment 5) Income between 1% and 133% FPL
Disenroller: Drops HMP-MC after a spell of at least 7 months in the program up to 13 months in program.
Disenrollers must not come back to any Michigan Medicaid program for at least 6 months. Must have dropped from
HMP-MC, i.e. not switched into another program and then dropped. Premium contribution and copayment means
calculated by taking mean of 1/3 of an enrollee's quarterly contribution or copayment invoices, net of any program
reductions but not including past due amounts.




                                                                                                                       26
Table 2. Main Estimates: Effect of Premiums on Medicaid Disenrollment

                                                                   Effect of exceeding cutoff on                                                     Treatment effect of
                                                                                                            Disenrolled
                                                 Any premium                        Premium                 (percentage                 Any premium                Premium Amount ($)
                                               (percentage points)                 Amount ($)                 points)                 (percentage points)           (percentage points)
Full Sample
       Estimate at MSE-Optimal                           19.4                          3.15                     2.3                           11.7                          0.71
       BW                                             (0.0993)                        (0.17)                 (0.0085)                        (0.045)                      (0.0028)
                                                      [<0.001]                      [<0.001]                  [0.007]                        [0.009]                      [0.0109]
                                                     BW= 11.3                       BW=11.2                 BW =11.4                        BW=11.3                       BW=11.2
       Estimate at BW=10                                 19.1                          3.12                     2.0                           10.6                          0.65
                                                       (0.010)                        (0.18)                 (0.0092)                        (0.049)                      (0.0030)
                                                      [<0.001]                      [<0.001]                  [0.027]                        [0.029]                       [0.030]
       Estimate at BW=15                                 20.1                          3.23                     2.3                           11.5                          0.72
                                                      (0.0081)                        (0.14)                 (0.0074)                        (0.037)                      (0.0023)
                                                      [<0.001]                      [<0.001]                  [0.002]                        [0.002]                       [0.002]
Means of Dependent variables                           22.8/41.2                     3.05/6.77               19.5/22.7
below/above cutoff (FPL split)                         (99/100)                  (95-99/100-194)         (95-99/100-104)
Notes: Each row shows estimates using a various FPL bandwidths (BW) around 100% FPL (e.g. BW=10 is the regression run on the sample with an FPL from 90% to 109% FPL). Columns
1-3 present estimates of a "sharp" regression discontinuity design on the probability an enrollee faces any premium (column 1), the amount of premium they are asked to contribute (column
2), and the probability that they disenroll (column 3). Columns 4 and 5 scale the disenrollment effect by the probability of receiving a premium (column 4) or the premium amount (column
5), presenting the estimates from a fuzzy RD design. All estimates controlled for gender, race, region of residence, age in bands, receipt of a healthy behavior reward and enrollment date.
Standard errors are in parentheses and p-values are in brackets.




                                                                                                                                                                                               27
 Table 3. Effect of Premiums on Medicaid Disenrollment: Healthier and Sicker Enrollees

                                                         Effect of exceeding cutoff on                             Treatment effect of

                                                                                         Disenrolled
                                           Any premium                 Premium           (percentage     Any premium          Premium Amount ($)
                                        (percentage points)           Amount ($)           points)     (percentage points)     (percentage points)
 Above Median Spending in first 7 months enrollment (>$77/month)
      Estimate at MSE-Optimal                   14.1                     2.25              -0.13              4.5                      0.40
      BW                                      (0.014)                   (0.23)            (0.014)           (0.083)                 (0.0048)
                                             [<0.001]                  [<0.001]           [0.924]           [0.589]                  [0.405]
                                             BW=10.7                   BW=12.8            BW=8.3           BW=10.7                  BW=12.8
      Estimate at BW=10                         13.9                     2.22               0.49              3.5                      0.22
                                               (0.014)                  (0.26)            (0.012)           (0.088)                 (0.0055)
                                             [<0.001]                  [<0.001]           [0.690]           [0.691]                 [0.6913]
 Below Median Spending in first 7 months enrollment (<$77/month)
      Estimate at MSE-Optimal                   23.8                      3.87               3.6             13.4                       0.82
      BW                                       (0.014)                   (0.25)            (0.012)          (0.058)                  (0.0036)
                                              [<0.001]                  [<0.001]           [0.002]         [0.0217]                   [0.025]
                                              BW=9.97                   BW=9.6            BW=13.2          BW=9.97                   BW=9.6
      Estimate at BW=10                         23.8                      3.90               3.2             13.4                       0.82
                                               (0.014)                   (0.24)            (0.014)          (0.058)                  (0.0035)
                                              [<0.001]                  [<0.001]           [0.018]          [0.020]                   [0.021]
Chronic Disease Claims
      Estimate at MSE-Optimal                   14.8                       2.47               1.3             -3.1                     0.53
      BW                                       (0.016)                   (0.021)           (0.010)           (0.10)                 (0.0041)
                                              [<0.001]                  [<0.001]           [0.191]          [0.750]                  [0.199]
                                              BW=7.6                    BW=13.9           BW=14.2           BW=7.6                  BW=13.9
      Estimate at BW=10                         15.0                       2.44              0.61             4.1                      0.25
                                               (0.014)                   (0.025)           (0.012)          (0.082)                 (0.0050)
                                              [<0.001]                  [<0.001]           [0.616]          [0.618]                  [0.618]
 No Chronic Disease Claims
      Estimate at MSE-Optimal                   22.8                      3.69               3.3             13.6                       0.84
      BW                                       (0.015)                   (0.27)            (0.013)          (0.067)                  (0.0042)
                                              [<0.001]                  [<0.001}           [0.016]          [0.043]                   [0.044]
                                              BW=8.5                    BW=8.5            BW=10.4           BW=8.5                   BW=8.5
      Estimate at BW=10                         23.3                      3.77               3.3             14.2                       0.88
                                               (0.014)                   (0.25)            (0.014)          (0.060)                  (0.0037)
                                              [<0.001]                  [<0.001]           [0.016]          [0.018]                   [0.019]




                                                                                                                                                     28
Notes: Each row shows estimates using a various FPL bandwidths (BW) around 100% FPL (e.g. BW=10 is the regression run on the sample with an FPL from 90% to 109% FPL).
Columns 1-3 present estimates of a "sharp" regression discontinuity design on the probability an enrollee faces any premium (column 1), the amount of premium they are asked to
contribute (column 2), and the probability that they disenroll (column 3). Columns 4 and 5 scale the disenrollment effect by the probability of receiving a premium (column 4) or the
premium amount (column 5), presenting the estimates from a fuzzy RD design. All estimates are controlled for gender, race, region of residence, age in bands, receipt of a healthy
behavior reward and enrollment date. Standard errors are in parentheses and p-values are in brackets




                                                                                                                                                                                        29
Figure 1: Proportion of the Population with Premiums by Mean Federal Poverty Level




Notes: These data represent the share of enrollees with a premium at each income percentile relative to the federal poverty level, with a linear fit line on either
side of the premium cutoff. The population represented here includes all enrollees in Michigan's Medicaid program with a positive income who were enrolled in
a managed care plan for at least 7 months (n=195, 495)




                                                                                                                                                                 30
Figure 2: Disenrollment by Mean Federal Poverty Level




Notes: These data represent percentage of disenrollers at each federal poverty level, binned in groups of 4 to reduce noise, with a best-fitting line drawn through
each scatterplot above and below the federal poverty line. The population represented here includes all enrollees in Michigan's Medicaid program with a positive
income who were enrolled in a managed care plan for at least 7 months (n=195, 495). Data come from individual enrollment and premium files provided by
Michigan DHHS.




                                                                                                                                                                 31
Figure 3: Disenrollment by Mean Federal Poverty Level split by 1) Below and Above Median Medical Spending and 2) Chronic Disease
Diagnosis, both in first 7 months of HMP Managed Care Enrollment
Panel A: Below Median Medical Spending                                                     Panel B: Above Median Spending




Panel C: No Chronic Disease Diagnosis                                                      D. Chronic Disease Diagnosis




Notes: These data represent percentage of disenrollers each federal poverty level, at each federal poverty level, binned in groups of 4 to reduce noise with a best-
fitting line drawn through each scatterplot, above and below the federal poverty line. The population represented here includes all enrollees in Michigan's
Medicaid program with a positive income who were enrolled in a managed care plan for at least 7 months (n=195, 495). The population is split by those who, at

                                                                                                                                                                 32
7 months, spent at or above the median amount ($77) and those who spent below that amount. Data come from individual enrollment and cost-sharing files
provided by Michigan DHHS.




                                                                                                                                                         33
