                                NBER WORKING PAPER SERIES




                THE VALUE OF INFORMATIVENESS FOR CONTRACTING

                                          Pierre Chaigneau
                                            Alex Edmans
                                           Daniel Gottlieb

                                        Working Paper 20542
                                http://www.nber.org/papers/w20542


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                     October 2014




We thank seminar participants at Wharton and at the Risk Theory Society meeting for helpful comments,
and Shiying Dong for excellent research assistance. The views expressed herein are those of the authors
and do not necessarily reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2014 by Pierre Chaigneau, Alex Edmans, and Daniel Gottlieb. All rights reserved. Short sections
of text, not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including © notice, is given to the source.
The Value of Informativeness for Contracting
Pierre Chaigneau, Alex Edmans, and Daniel Gottlieb
NBER Working Paper No. 20542
October 2014
JEL No. D86,J33

                                                ABSTRACT

The informativeness principle demonstrates qualitative benefits to increasing signal precision. However,
it is difficult to quantify these benefits - and compare them against the costs of precision - since we
typically cannot solve for the optimal contract and analyze how it changes with informativeness. We
consider a standard agency model with risk-neutrality and limited liability, where the optimal contract
is a call option. The direct effect of reducing signal volatility is a fall in the value of the option, benefiting
the principal. The indirect effect is a change in the agent's effort incentives. If the original option is
sufficiently out-of-the-money, the agent can only beat the strike price if he exerts effort and there is
a high noise realization. Thus, a fall in volatility reduces effort incentives. As the agency problem
weakens, the gains from precision fall towards zero, potentially justifying pay-for-luck.


Pierre Chaigneau                                        Daniel Gottlieb
HEC Montreal                                            The Wharton School
3000 chemin de la côte-Sainte-Catherine                 University of Pennsylvania
Montreal H3T 2A7                                        3303 Steinberg Hall-Dietrich Hall
Canada                                                  3620 Locust Walk
pierre.chaigneau@hec.ca                                 Philadelphia, PA 19104
                                                        dgott@wharton.upenn.edu
Alex Edmans
The Wharton School
University of Pennsylvania
2460 Steinberg Hall - Dietrich Hall
3620 Locust Walk
Philadelphia, PA 19104
and NBER
aedmans@wharton.upenn.edu
    A major result in contract theory is the informativeness principle (Holmstrom
(1979), Shavell (1979), Gjesdal (1982), Grossman and Hart (1983), Kim (1995)). It
argues that the principal should maximize the precision of the performance measure
used to evaluate the agent. Greater precision (in the sense of second-order stochastic
dominance) allows the principal to use a cheaper contract to implement at least the
same e¤ort level. However, increasing informativeness is costly in practice. Investing
in a superior monitoring technology involves direct costs. Engaging in relative per-
formance evaluation (“RPE”) involves the indirect costs of forgoing the bene…ts of
pay-for-luck documented by prior research (e.g. Oyer (2004), Raith (2008), Axelson
and Baliga (2009), and Gopalan, Milbourn, and Song (2010)). Potentially for this rea-
son, numerous violations of RPE have been found in practice. Aggarwal and Samwick
(1999) and Murphy (1999) show that CEO pay is determined by absolute, rather than
relative performance. Jenter and Kanaan (2013) …nd an absence of RPE in CEO …ring
decisions. Whether these violations are an e¢ cient response to the indirect costs of
RPE is unclear. Bertrand and Mullainathan (2001) show pay-for-luck is strongest in
poorly-governed …rms, consistent with the view that it is ine¢ cient. Indeed, Bebchuk
and Fried (2004) argue that the absence of RPE is a key piece of evidence that CEO
compensation results from rent extraction by CEOs rather than e¢ cient contracting
with shareholders.1
    The informativeness principle argues that there are qualitative bene…ts to increas-
ing signal precision. However, for a principal to decide whether to invest in greater
precision, she must quantify these bene…ts –in particular, relate them to the underlying
parameters of the contracting problem –so that she can compare them against the cost
of precision. Similarly, to evaluate whether the general absence of RPE is e¢ cient, it is
useful to understand under which settings the bene…ts of informativeness are smallest,
and compare them against the cases in which RPE is particularly absent in reality.
Such quanti…cation is di¢ cult under the general framework in which the informative-
ness principle was derived. As is well-known (e.g. Grossman and Hart (1983)), in a
general setting it is not possible to solve for the optimal contract. We cannot analyze
precisely how the contract changes in response to increased informativeness, and thus
quantify the cost savings from contract redesign.
    This paper addresses this open question. We consider the standard setting of risk
   1
    In contrast, Brookman and Thistle (2013) …nd that luck is a relatively unimportant determinant
of managerial pay, compared to skill and labor market conditions.


                                                2
neutrality and limited liability on the agent, which allows us to take an optimal con-
tracting approach. These restrictions lead to optimal contracts that we observe in
practice –as shown by Innes (1990), the agent has a call option on the signal. A fall in
the strike price increases the option’s delta and thus the agent’s e¤ort incentives, but
also augments the value of the option and thus his expected wage. Thus, the strike
price is the minimum possible to satisfy the agent’s incentive constraint.
    We start by considering general signal distributions. We show that an increase
in informativeness has two e¤ects, each of which has a clear economic interpretation.
First, ignoring the incentive constraint, a fall in volatility reduces the value of the
option and thus the agent’s expected wage: the direct e¤ect. Second, the increase in
precision changes the agent’s incentives. The heart of the paper analyzes this incentive
e¤ect and shows how its direction depends on the model’s underlying parameters.
    The agent’s e¤ort incentives stem from the di¤erence in value between two options
–the (less valuable) option that he receives when he shirks (“option-when-shirking”),
and the (more valuable) option that he receives when he works and improves the signal
distribution (“option-when-working”). Changes in signal precision a¤ect the values
of these options di¤erentially. If the option satis…es increasing di¤erences, i.e. e¤ort
and precision are complements (an increase in precision raises the sensitivity of the
option’s value to e¤ort), then a rise in informativeness augments e¤ort incentives. The
principal can thus increase the strike price of the option, i.e. reduce its delta, without
violating the agent’s incentive constraint. This strike price increase further reduces
the expected wage, and reinforces the …rst, direct e¤ect. In contrast, if the option
satis…es decreasing di¤erences, i.e. e¤ort and precision are substitutes, an increase in
informativeness weakens e¤ort incentives, o¤setting the …rst e¤ect. In the limit, it fully
o¤sets it, rendering the total bene…t of precision zero. The key result from the general
model is that we derive a simple condition, which holds for any signal distribution
and is easy to verify, that governs whether the option satis…es increasing or decreasing
di¤erences and thus whether a rise in informativeness raises or lowers e¤ort incentives.
    We then consider signal distributions with a location parameter, i.e. where e¤ort
shifts the signal distribution rightwards but does not change its shape. Doing so allows
us to relate whether the option satis…es increasing or decreasing di¤erences to its initial
strike price, which in turn depends on the severity of the agency problem: a severe
agency problem (i.e. a high cost of e¤ort) requires the principal to set a low strike
price to induce e¤ort. We can thus relate the e¤ect of informativeness on incentives to

                                            3
the underlying agency problem.
    When the initial strike price is below a threshold, i.e. the agency problem is suf-
…ciently strong, then e¤ort and informativeness are complements. The intuition is as
follows. A decrease in informativeness, i.e. an increase in signal volatility that aug-
ments both tails of the distribution, raises the value of an option. The magnitude of the
gain is thus increasing in the asymmetry of the option’s payo¤. For a low initial strike
price, the signal distribution when the agent shirks is centered around the strike price.
Thus, the option’s payo¤ is highly asymmetric: high signal realizations lie to the right
of the strike price and lead to the option being exercised, and low signal realizations
lie to the left and lead to no exercise. As a result, when volatility increases, the agent
bene…ts from the greater probability of very high signal realizations and does not lose
from the greater probability of very low signal realizations, and so the value of the
option-when-shirking rises signi…cantly. Put di¤erently, for a low initial strike price,
the option-when-shirking is relatively close to at-the-money, and thus has a relatively
high vega (sensitivity to volatility).
    In contrast, if the agent works, the signal distribution lies largely to the right of
the initial strike price, and so the payo¤ function is less asymmetric: most signal
realizations lead to the option being exercised. Thus, the agent bene…ts less from
increases in volatility – he gains from the growth in the right tail, but loses from
the growth in the left tail. Put di¤erently, for a low initial strike price, the option-
when-working is signi…cantly in-the-money, and thus has a low vega. Thus, a fall in
informativeness increases the value of the option-when-shirking more than the option-
when-working, and lowers the agent’s incentives. Intuitively, when volatility is high,
the agent’s e¤ort incentives are weak because, even if he shirked, he would still earn
a high wage if he received a positive shock. The agent is not worried about the fact
that, if he shirks and receives a negative shock, the signal will be very low, because his
payo¤ cannot fall below zero due to limited liability.
    When the initial strike price is above a second (higher) threshold, i.e. the agency
problem is su¢ ciently weak, then e¤ort and informativeness are substitutes due to
the reverse intuition. The option-when-shirking is deeply out-of-the-money, and the
option-when-working is closer to at-the-money. Thus, the vega of the latter option is
greater, and its value increases with volatility faster than the option-when-shirking,
raising incentives. Intuitively, when the strike price is high, the agent will only receive
a positive wage if he exerts e¤ort and receives a su¢ ciently positive shock. When

                                            4
volatility rises, such shocks are more likely, and so the agent is more likely to be paid
if he works. Thus, his e¤ort incentives increase.
    For initial strike prices between the two thresholds, e¤ort and informativeness can
either be complements or substitutes. This is because, for general distributions, a
decrease in informativeness may not have a consistent e¤ect on the signal distribution.
While it is clear that it increases the left and right tails, thus leading to unambiguous
results for low or high initial strike prices, a fall in informativeness can have any e¤ect on
the center of the distribution. For example, it could shift some mass away from a tail, as
long as it also moves mass towards a more extreme tail point. Under a simple regularity
condition which guarantees that decreases in informativeness consistently shift mass
from the center of the distribution to the tails, the two thresholds now coincide at a
single point and there is no ambiguous intermediate region. A su¢ cient (although not
necessary) condition for regularity is that the signal distribution has a scale as well as
a location parameter –i.e. can be characterized by its mean and standard deviation,
as with the Normal, uniform, and logistic distributions. Intuitively, when volatility can
be fully characterized by a scale parameter, changes in this parameter have a consistent
e¤ect on the shape of the distribution, moving mass towards its tails.
    Under regular distributions, the e¤ect of informativeness on incentives depends on
whether the initial strike price of the option is above or below a single threshold. Thus,
when incentives are strong (weak) to begin with, e.g. for CEOs (rank-and-…le workers),
an increase in informativeness further increases (reduces) incentives, amplifying (low-
ering) the gains from informativeness. In contrast, an analysis focusing only on the
direct e¤ect of informativeness, and ignoring the incentive constraint, would suggest
that the gains from informativeness are highest when the option is at-the-money –i.e.
a moderate initial strike price and a moderate agency problem.
    In addition to studying whether a …rm should endogenously choose to increase
informativeness, our analysis also investigates the impact of exogenous changes in in-
formativeness. An exogenous increase in volatility (see Gormley, Matsa, and Milbourn
(2013) and DeAngelis, Grullon, and Michenaud (2013) for natural experiments) will
increase (reduce) the e¤ort incentives of agents with out-of-the-money (in-the-money)
options. Thus, if …rms recontract in response to these exogenous shocks, …rms with
in-the-money options should increase their CEOs’incentives relative to …rms with out-
of-the-money options, either by granting additional options, or reducing the strike price



                                              5
of new grants or existing options.2
    For tractability, the analysis features a binary e¤ort level. In the continuous-e¤ort
analog, in order to implement a given e¤ort level, the contract must ensure that the
agent will not deviate to a slightly lower or a slightly higher e¤ort level (i.e. the
incentive constraint will be “local”). This situation resembles a binary model in which
the low e¤ort level is very close to the (implemented) high e¤ort level. In this case, the
threshold for the initial strike price –that determines whether informativeness increases
or decreases e¤ort – is the expected value of the signal. If the initial strike price is
above (below) this threshold, increases in informativeness lower (raise) the strike price
towards the threshold. Thus, improvements in informativeness (e.g. increases in stock
market e¢ ciency) move the strike price closer to the expected value of the signal, and
thus closer to at-the-money. Bebchuk and Fried (2004) argue that the almost universal
practice of granting at-the-money options is suboptimal and that out-of-the-money
options are more e¤ective because the agent is paid only if performance is very high
(see also Rappaport (1999)). Our analysis suggests that at-the-money options can be
close to optimal if informativeness is high. This result also suggests that accounting or
taxation considerations that favor at-the-money options need not induce suboptimal
contracting.
    Dittmann, Maug, and Spalt (2013) also consider the incentive constraint when as-
sessing the bene…ts of a speci…c form of increased informativeness –indexing stock and
options –and similarly show that indexation may weaken incentives. They use a quite
di¤erent setting, which re‡ects the di¤erent aims of each paper. Their primary goal is
to calibrate real-life contracts, and so their model incorporates risk aversion to allow
them to input risk aversion parameters into the calibration. However, under risk aver-
sion, it is di¢ cult to solve for the optimal contract. They therefore restrict the contract
to comprising salary, stock, and options, and hold stock constant when changing the
contract to restore the agent’s incentives upon indexation. They acknowledge that the
actual savings from indexation will be di¤erent if the principal uses an initially optimal
contract and responds optimally to changes in incentives. In contrast, our primary
goal is theoretical. We incorporate risk neutrality and limited liability, allowing us to
take an optimal contracting approach and to achieve analytical solutions. In addition,
   2
    Acharya, John, and Sundaram (2000) also study the repricing of stock options theoretically,
although in response to changes in the mean rather than volatility of the signal. Brenner, Sundaram,
and Yermack (2000) analyze repricing empirically.


                                                 6
our model allows the analysis of reductions in volatility through other means than
indexation, for example investing in a superior monitoring technology.
    Other explanations for pay-for-luck have been proposed in the literature, partially
reviewed by Edmans and Gabaix (2009). Oyer (2004) shows that pay-for-luck may be
optimal if the value of workers’outside options vary with economic conditions and if
re-contracting is costly. Raith (2008) shows that it may be preferable to base compen-
sation on measures of output rather than input when the agent has private information
on the production technology. Axelson and Baliga (2009) argue that, for contracts to
be renegotiation-proof, the manager must have private information that causes him
to have a di¤erent view from the board on the value of his long-term pay. Industry
performance is an example of such information, and so it may be e¢ cient not to …lter it
out. Gopalan, Milbourn, and Song (2010) show that tying the CEO’s pay to industry
performance induces him to choose the …rm’s industry exposure correctly.
    This paper proceeds as follows. Section 1 presents the model. Section 2 shows that
the optimal contract takes the form of a call option. Section 3 derives the gains from a
reduction in the variance of the performance measure. Section 4 concludes. Appendix
A contains all proofs not in the main text.


1    The Model
We consider a standard principal-agent model with risk neutrality and limited liability,
similar to Innes (1990). The timing is as follows. At time t = 1, the principal (…rm)
o¤ers a contract W to the agent (manager). At t = 0, the agent chooses his e¤ort level
e 2 f0; eg. E¤ort of e = 0 is of zero cost to the agent, and e = e costs him C > 0. We
will sometimes refer to e = e as “high e¤ort” or “working”, and e = 0 as “low e¤ort”
or “shirking”.
    At t = 1, the agent’s contribution to …rm value (“output”) q is realized. As in the
literature on performance measurement (e.g. Baker (1992)), output is not contractible:
for example, it is di¢ cult to measure an employee’s contribution independently of his
colleagues’. Instead, contracts can depend on a performance measure (“signal”)

                                      s=q+ ;

where   is a mean-zero random variable that is uncorrelated with e¤ort: E [ je] = 0.

                                           7
For example, may be a market or industry shock, the contribution of other workers,
or measurement error.
    We assume that output q is not contractible and the contract depends on a sepa-
rate signal s, so that we can change signal precision without a¤ecting output volatility.
However, the model allows for the case in which output is contractible, which corre-
sponds to the degenerate distribution concentrated at = 0 (i.e. signal equals output).
Our results also hold in the case in which output equals the signal, and so the analysis
considers changes in the variance of output.
    Conditional on e¤ort e, the signal s is continuously distributed on the real line
according to the probability density function (“PDF”) f (sje), although it needs not
have full support over the real line. Let F (sje) denote the cumulative distribution
function (“CDF”) of s. A high signal is good news about e¤ort in the sense of the
strict monotone likelihood ratio property (“MLRP”). Formally, for all and for all
signals s1 and s0 with s1 > s0 ,

                                   f (s1 je)   f (s0 je)
                                             >           :
                                   f (s1 j0)   f (s0 j0)

Strict MLRP implies that the distribution of the signal is ordered according to strict
…rst-order stochastic dominance (“FOSD”): F (sj0) > F (sje) 8 s; . Combined with
E [ je] = 0, the above also implies that e¤ort improves output in terms of FOSD.
    The real-valued parameter , which lies in an interval , captures the informative-
ness or precision of the signal, and orders the distributions in terms of second-order
stochastic dominance. Formally, the mean of the signal is independent of , and
                                   Z   t                Z   t
                          0
                              =)           F (sje) ds           F 0 (sje) ds;        (1)
                                       1                    1


8 t 2 ( 1; 1). Thus, increases in generate more precise signal distributions in the
sense of mean-preserving spreads.
    Our analysis solves for the optimal contract for each given level of precision . This
approach applies to settings in which signal precision depends on exogenous forces
(such as technological change); the analysis derives empirical predictions on how these
changes a¤ect the optimal contract. Our approach can easily be extended to settings in
which the principal can choose the level of precision at a cost ( ). Under the inter-


                                                8
pretation that arises from measurement error, removing the shock corresponds to im-
proving the monitoring technology at cost ( ). For example, Cornelli, Kominek, and
Ljungqvist (2013) show that boards of directors engage in extensive (and thus costly)
monitoring to gather soft information on the CEO’s competence, strategic choice, and
e¤ort. Under the interpretation that is a market or industry shock, increasing
corresponds to relative performance evaluation (RPE), in which case the cost ( )
stems from two sources. First, it can arise from the literal cost of implementing RPE.
While the actual calculation of industry performance, given a peer group, is relatively
costless, the determination of the peer group may involve the hiring of compensation
consultants. Second, the cost can also represent the loss of the bene…ts of pay-for-luck
highlighted by prior work, e.g. Oyer (2004), Raith (2008), Axelson and Baliga (2009),
and Gopalan, Milbourn, and Song (2010).
    The discount rate is normalized to zero. Given a contract W ( ) and a level of e¤ort
e, the agent’s expected wage is
                                           Z   1
                          E [W (s) je] =           W (s) f (sje) ds:
                                               1


The agent is risk-neutral and so maximizes his expected wage, less the cost of e¤ort.
His reservation utility is zero. The principal is also risk-neutral and chooses a contract
W ( ) and an e¤ort level e to maximize expected output E [q] less the expected wage
E [W ].
   Following Innes (1990), we make two assumptions on the set of feasible contracts.
First, the agent is protected by limited liability: W (s)           0 8 s. Second, pay-
performance sensitivity lies between 0 and 1:

                W (s + )     W (s) and s +            W (s + )     s   W (s)

for all s and all      0. These constraints must be satis…ed if the agent can freely
borrow to arti…cially increase output and the principal can freely destroy output. If
the constraint on the left did not hold, the agent would arti…cially increase output,
increasing the signal and thus his payo¤. If the constraint on the right did not hold,
the principal would exercise her control rights to “burn” output, reducing the signal




                                               9
and increasing her payo¤. These constraints can be expressed as

                                           W (s + )      W (s)
                                      1                           0                      (2)

8 . It thus follows that W ( ) is Lipschitz continuous and, therefore, di¤erentiable
almost everywhere. Hence, without loss of generality, we can assume that the contract
W ( ) is a cadlag function satisfying 0 W 0 (s) 1 at all points of di¤erentiability.3
   In the …rst best, e¤ort is veri…able. There is no incentive constraint and only a
participation constraint. If the principal wishes to induce high e¤ort, the participation
constraint is given by:
                                   E[W (s)je] C 0:                                    (3)

To satisfy (3), the principal pays an expected wage E [W (s) je] that equals the agent’s
cost of e¤ort C. Thus, if
                                  E [qje] E [qj0] > C;                               (4)

high e¤ort is optimal for the principal. We assume (4) throughout, else even under the
…rst-best, the principal would not want to induce e¤ort.
   In the second best, the agent’s e¤ort is unveri…able and so the contract must satisfy
an incentive constraint. The agent will exert e¤ort if and only if:

                                     E[W (s)je]    E [W (s)j0]    C:                     (5)

Following standard arguments, this incentive constraint will bind, in which case the
participation constraint will be slack and can be ignored in the analysis that follows.
    We de…ne X implicitly by
                             Z   1
                                     (s   X ) [f (sje)   f (sj0)] ds = C:                (6)
                               X


We will show in Lemma 1 that X exists and is unique. The intuition behind (6) is
that, if the agent is given a call option on s, X is the strike price such that working
increases the value of the agent’s option by an amount equal to the cost of e¤ort, so
that the incentive constraint is satis…ed with equality.
  3
      A cadlag function is everywhere right-continuous and has left limits everywhere.




                                                   10
   We make the following assumption to ensure that e = e is second-best optimal:
                                         Z   1
                     E [qje]   E [qj0]           (s   X )f (sje)ds   0:              (7)
                                          X


The …rst term, E [qje] E [qj0], is the bene…t to the principal of inducing e = e. The
second term is the cost of the contract required to do so. If (7) did not hold, the
principal would allow the agent to shirk, in which case the problem would be trivial
and the contract would involve a constant wage.
    Given informativeness , the principal’s problem is to choose a contract W ( ) to
minimize the expected wage E [W (s) je] subject to the agent’s incentive and limited
liability constraints, plus the constraints on the slope of the contract:

            E [W (s) je]   E [W (s) j0] + C;                                         (8)
                      0    W (s) 8 s; and                                            (9)
                      0    W 0 (s)   1 at all points of di¤erentiability of W:      (10)

    Our contracting problem is the dual to the one in Innes (1990). In his model, the
agent (entrepreneur) chooses a …nancing contract subject to his own incentive con-
straint and the participation constraint of the principal (investor). Here, the principal
(…rm) chooses an employment contract subject to the incentive and participation con-
straints of the agent (manager). In both models, the optimal contract has the same
form; the only di¤erence is in the division of the rents. Since Innes studies a …nancing
setting, the optimal contract for the principal is debt. Thus, the agent has equity,
which is a call option on the …rm’s assets; here, we will show that the agent receives a
call option on the signal.
    Another di¤erence is that Innes features a continuous action set. His focus was
to derive the form of the optimal contract and thus he wishes to do so in the most
general setting. Our goal is di¤erent: given that the optimal contract is a call option,
we study how changes in informativeness a¤ect the agent’s incentives and thus the
strike price. We thus specialize to a binary e¤ort level. With a continuous e¤ort level,
a change in informativeness may alter the optimal e¤ort level. It is well known that
solving for the optimal e¤ort level in addition to the cheapest contract that induces a
given e¤ort level is extremely complex (see, e.g., Grossman and Hart (1983)), and thus
many papers focus on the implementation of a given e¤ort level. For example, Biais et

                                              11
al. (2010) consider a binary e¤ort choice and conditions to guarantee that high e¤ort
is optimal, as in our setting, and Dittmann and Maug (2007) and Dittmann, Maug,
and Spalt (2010, 2013) consider the implementation of a given e¤ort level out of a
continuum. (Indeed, Innes (1990) does not solve for the optimal e¤ort level or study
how it is a¤ected by the parameters of the setting, but shows that an optimum exists.)
Edmans and Gabaix (2011) show that, if the bene…ts of e¤ort are multiplicative in …rm
size and the …rm is su¢ ciently large, it is always optimal for the principal to implement
the highest e¤ort level and so the optimal e¤ort level is indeed …xed. We thus consider
a binary e¤ort setting where high e¤ort is optimal.


2    The Optimal Contract
This section solves for the optimal contract for a given level of informativeness . The
analysis is similar to Innes (1990). Our main results will come in Section 3, which
analyzes the gains from increasing .
   Let W ( ) denote the optimal contract for a given . Lemma 1 establishes that
W ( ) is a call option on s, where the strike price X is chosen to satisfy the incentive
constraint (6).

Lemma 1 (Optimal contract): For each given , there exists a unique optimal con-
tract, characterized by e = e, and

                               W (s) = maxf0; s      X g;                            (11)

where X is determined by the unique solution of (6).

    The setting is slightly di¤erent from Innes (1990), since the principal is contracting
on a signal rather than output. We show that the Innes (1990) result of the optimality
of a call option extends to this case, and the intuition is the same. The absolute value
of the likelihood ratio is highest in the tails of the distribution of s, so the signal is
most informative about e¤ort in the tails. The left tail cannot be used for incentive
purposes due to limited liability, and so incentives are concentrated in the right tail.
This maximizes the likelihood that positive payments are received by a working agent.
With an upper bound on the slope, the optimal contract involves call options on s with
the maximum feasible slope, i.e. W 0 (s) = 1.

                                           12
   Lemma 2 below shows that the strike price falls with the cost of e¤ort, which
parameterizes the severity of the agency problem.

Lemma 2 (E¤ect of e¤ort cost on strike price): Let X be the strike price in the
optimal contract for a given . Then, X is strictly decreasing in the cost of e¤ort C.


3     The Value of Informativeness
This section calculates the gains from increasing informativeness. Section 3.1 con-
siders general signal distributions and provides a condition under which increases in
informativeness raise e¤ort incentives. Section 3.2 studies distributions with a location
parameter and shows that whether this condition is satis…ed depends on the initial
strike price and thus the severity of the agency problem. Section 3.3 graphically il-
lustrates the bene…ts of informativeness for the Normal distribution. It also proves
analytically that, for this distribution, the bene…ts from informativeness are monoton-
ically increasing in the cost of e¤ort, and thus monotonically decreasing in the initial
strike price.


3.1    General Distributions
The total e¤ect of increasing informativeness on the expected wage can be decomposed
as follows:
                  d                @               @              dX
                    E [W (s)je] =    E [W (s)je] +    E [W (s)je]      :        (12)
                 d                |@    {z     } |@X               d
                                                          {z         }
                                      direct e¤ ect      incentive e¤ ect

    The …rst component is the direct e¤ect, @@ E [W (s)je]. Holding constant the strike
price, an increase in signal precision changes the value of the option; we will later prove
that this e¤ect is negative. This reduction in the cost of compensation is the bene…t
of informativeness highlighted by Bebchuk and Fried (2004) in their argument that
the lack of RPE is ine¢ cient. In the Holmstrom (1979) setting of a risk-averse agent,
an increase in informativeness reduces the risk borne by the agent and thus allows
the principal to lower the expected wage without violating the agent’s participation
constraint. In our setting of risk neutrality and limited liability, an increase in precision
reduces the value of the option.


                                                13
    The second component is the incentive e¤ect, @X  @
                                                        E [W (s)je] dX
                                                                     d
                                                                       , which arises be-
cause the increase in precision requires the strike price to rise by dX  d
                                                                             to maintain
                           @
incentive compatibility. @X E [W (s)je] is negative – any increase in the strike price
reduces the value of the option –but the sign of dX
                                                  d
                                                      is unclear. We thus seek to derive
conditions under which an increase in precision raises or lowers the optimal strike price.
The following de…nition will be useful:

De…nition 1 (Increasing di¤erences): Let ( ; E) R2 . A function g ( ; e) :                    E!
R satis…es increasing di¤erences if, for all L < H and eL eH ,

                      g(   H ; eH )     g(   H ; eL )        g ( L ; eH )    g ( L ; eL ) :    (13)

It satis…es decreasing di¤erences if g satis…es increasing di¤erences.        and e are
complements if g ( ; e) satis…es increasing di¤erences, substitutes if g ( ; e) satis…es
decreasing di¤erences, and neutral if g ( ; e) satis…es both increasing and decreasing
di¤erences.

    The increasing di¤erences condition (13) means that the incremental gain (i.e., in-
crease in g) from e¤ort, g ( ; eH ) g ( ; eL ), is increasing in : e¤ort and informativeness
are complements in terms of their e¤ect on g. Conversely, decreasing di¤erences means
that the incremental gain from e¤ort is decreasing in : Thus, e¤ort and informative-
ness are substitutes. Indeed, increasing (decreasing) di¤erences is the most common
de…nition of complementarity (substitutability).4 In our setting, if g is di¤erentiable,
increasing di¤erences is equivalent to the single-crossing condition:

                                      @g            @g
                                         ( ; e)        ( ; 0) ds            0:
                                      @             @
   We are concerned with how changes in precision a¤ect the incentive constraint (5).
The agent’s incentives stem from the fact that exerting e¤ort increases the value of his
option. If he works, his option is worth E [W (s) je]; we refer to this as an “option-
when-working.”If he shirks, he receives an “option-when-shirking”worth E [W (s) j0].
His e¤ort incentives are given by the di¤erence in the values of these options, i.e.

                                      E [W (s) je]       E [W (s) j0] :                        (14)
   4
    There is a very large literature using these concepts for understanding outcomes of games – e.g.
Bulow, Geanakoplos, and Klemperer (1985) and Milgrom and Roberts (1990).

                                                        14
Since a change in precision a¤ects the option-when-working and the option-when-
shirking to di¤erent degrees, it a¤ects the agent’s e¤ort incentives (14). When precision
and e¤ort are complements, i.e. E [W (s)je] satis…es increasing di¤erences, increases in
precision augment the agent’s e¤ort incentives:

                             @
                               fE [W (s) je]        E [W (s) j0]g > 0;                              (15)
                             @
We thus wish to understand the conditions under which E [W (s)je] satis…es increasing
di¤erences. We do so by using integration by parts (see Appendix A) to rewrite the
agent’s expected wage as
                                                          Z   X
                        E [W (s)je] = E [sje]       X +            F (sje) ds:                      (16)
                                                              1


The area under the CDF for signals below X (the third term) is the value of a put
option with a strike price of X :
                                                Z   X                               Z   X
  Pr (s < X je) E [(X        s) js < X ; e] =           (s        X ) f (sje)ds =           F (sje) ds;
                                                    1                                   1


where the last equality follows from integration by parts. Therefore, equation (16)
can be interpreted as the put-call parity equation. The agent’s call option equals the
expected value of the signal, minus the strike price, plus the value of a put option. Let
            RX
  X ( ; e)     1
                  F (sje) ds denote the value of a put option with a strike price of X.
By second-order stochastic dominance (equation (1)), the value of the put option is
                  @
decreasing in ( @X ( ; e) 0).5
    To study whether E [W (s)je] satis…es increasing di¤erences, we examine each of the
three terms on the right-hand side (“RHS”) of (16). While E [sje] depends on e, it is
independent of since changes in represent mean-preserving spreads. In addition, X
depends on but not e. Thus, and e are neutral in their e¤ect on both of these terms,
                                                        RX
and non-neutral only in their e¤ect on the third term 1 F (sje) ds. This observation
leads to the following Lemma:
   5
    In the Black-Scholes model, we have a strict inequality. This is because the Black-Scholes model
assumes a lognormal distribution for stock returns, so an increase in precision (which corresponds
to a decrease in volatility) a¤ects the whole distribution. However, in our setting with a general
distribution, a change in may only a¤ect the part of the distribution above the strike price X ,
where the put option has zero payo¤, and so its value does not change.


                                                15
Lemma 3 (Condition for increasing di¤erences): The agent’s expected pay E [W (s)je]
                                                                     RX
satis…es increasing di¤erences if and only if the area under the CDF, 1 F (sje) ds,
satis…es increasing di¤erences.

    The usefulness of Lemma 3 lies in the fact that, while the value of the call option
(16) involves several terms, it is relatively easy to verify whether the area under the
      RX
CDF 1 F (sje) ds satis…es increasing di¤erences. While it may seem intuitive that
the value of the call option satis…es increasing di¤erences if and only if the value of
the put option satis…es increasing di¤erences, the value of Lemma 3 is that we can
check whether expected pay satis…es increasing di¤erences by studying a single term
RX
   1
     F (sje) ds –not that this term can be interpreted as the value of a put option. The
condition in Lemma 3 is simple to check and general: it holds for all signal distributions
that satisfy MLRP (so that the optimal contract is a call option). De…nition 1 then
allows us to determine the e¤ect of informativeness on the strike price X :
                                                                            RX
Proposition 1 (E¤ect of informativeness on strike price): Let X ( ; e)        1
                                                                                F (sje) ds:
The optimal strike price X is increasing in informativeness if X ( ; e) satis…es in-
creasing di¤erences at X , decreasing in informativeness if X ( ; e) satis…es decreasing
di¤erences at X , and constant if it satis…es both increasing and decreasing di¤erences
at X .

    When precision and e¤ort are complements, exerting e¤ort augments the value of
the call option by a greater amount when precision is high. As a result, the agent’s
marginal bene…t from e¤ort (equation (14)) is increasing in informativeness. Increases
in precision loosen the incentive constraint and allow the principal to increase the strike
price while still inducing e¤ort. Thus, in addition to the direct bene…t of informative-
ness (it reduces the expected wage, holding constant the strike price X ), the principal
further bene…ts from its incentive e¤ect (it allows the strike price X to increase, further
reducing the expected wage). Proposition 1 in turn leads to Corollary 1 below.

Corollary 1 (Partial and total e¤ects of informativeness on expected wage):

              d               @                                       dX
                E [W (s)je] >   E [W (s)je]          if and only if      > 0:         (17)
              d               @                                        d



                                            16
Proof. From equation (12), we have:

d                @               @             dX
  E [W (s)je] =    E [W (s)je] +   E [W (s)je]
d               |@    {z     } |@X              d
                                       {z         }
                        direct e¤ ect           incentive e¤ ect

                    @   X  ( ; e)           @   X ( ; e) dX   @    X ( ; e)                     dX
                =                       1                   =                 [1    F (X je)]      :
                          @                      @X       d         @                            d

d
d
   E [W (s)je] and @@ E [W (s)je] are both negative, and the former is more negative
(i.e. its absolute value is higher) if and only if dX d
                                                          > 0, i.e. e¤ort and precision are
complements.
    The direct e¤ect, @@ E [W (s)je], is negative. An increase in precision decreases
                                  @
the value of the put option ( @X           0) and thus the expected wage. Turning to
the incentive e¤ect, higher precision augments the strike price by dX      d
                                                                             , which in turn
                                                   dX
requires the principal to pay an additional d dollars whenever the price exceeds
X , which occurs with probability 1 F (X je). The sign of dX         d
                                                                         in turn depends on
whether informativeness and e¤ort are substitutes or complements. When they are
complements, then dX  d
                          > 0. The strike price increases, further reducing the expected
wage and reinforcing the direct e¤ect. When they are substitutes, then dX           d
                                                                                        < 0,
opposing the direct e¤ect.
    Even when dX d
                    < 0 and the incentive e¤ect counteracts the direct e¤ect, it can never
outweigh it. The total e¤ect dd E [W (s)je] is always weakly negative, i.e. increasing
precision weakly reduces the expected wage. This result arises from revealed preference.
If reducing precision reduced the expected wage, the principal would have added in
randomness to the contract, and so the initial contract would not have been optimal.
Even though the incentive e¤ect cannot outweigh the direct e¤ect, it is still important
to consider as it a¤ects the optimal level of precision that the principal should choose,
since increasing precision is costly. Indeed, it is possible that the incentive e¤ect exactly
o¤sets the direct e¤ect, and so that the total gains from informativeness equal exactly
zero: see Appendix B for an example.6
    6
     While we consider the e¤ect of changes in signal informativeness, Chaigneau, Edmans, and Got-
tlieb (2014) derive a general condition for whether the addition of a new signal has strictly positive
value for contracting.




                                                       17
3.2    Distributions in the Location Family
Section 3.1 shows that, with general distributions, the e¤ect of precision on incentives
depends on whether e¤ort and precision are complements or substitutes. We now grad-
ually add more structure to the signal distribution, which allows us to relate whether
we have complements or substitutes – and thus the e¤ect of precision on the agent’s
incentives –to the underlying parameters of the agency problem.
    Since the expected signal is strictly increasing in e¤ort, we can always normalize
e¤ort to be measured in units of the average signal: e = E[sje]. Hence, for any signal
distribution, we can write the signal as s = e + "; where we de…ne the noise term "
as the di¤erence between e¤ort and the signal. Thus, if G (") denotes the CDF of
the noise, we have G (") = G (s e) = F (sje). While the conditional mean of noise
is zero (E["je] = 0), higher moments of " may, in general, depend on the e¤ort e.
We now assume that the whole distribution of noise G (not only its …rst moment) is
independent of e. This assumption is equivalent to specifying that the distribution of
s has a location parameter –changes in e¤ort shift the location of the distribution but
do not change its shape.
    To ensure that lim"& 1 G (") and lim"%1 G (") are di¤erentiable with respect to ,
we make the technical assumptions that G is di¤erentiable with respect to and that
the sequences fG ( n)gn2N ; @G     @
                                     ( n) n2N ; fG (n)gn2N ; @G@
                                                                 (n) n2N are uniformly
convergent. These assumptions are automatically satis…ed if the noise has bounded
support and are also satis…ed under standard unbounded distributions (such as the
Normal, logistic, Cauchy, and Laplace distributions).
    With a slight abuse of terminology, we say that s belongs to a location family if the
two above conditions –independence between e and and the technical di¤erentiability
condition –are satis…ed. When the signal belongs to the location family, we can show
that whether e¤ort and informativeness are complements or substitutes depends on the
level of the initial strike price:
Lemma 4 (E¤ect of informativeness on the strike price): Suppose that the signal
                                                            b1 and X
distribution belongs to a location family. Then there exist X      b2 X
                                                                      b1 such that
dX
       0 if X < X b1 and  dX
                                 0 if X > Xb2 .
 d                         d

   E¤ort and precision are complements when the initial strike price X is below a
          b1 , substitutes when X exceeds a higher threshold X
threshold X                                                  b2 , and may be either
complements or substitutes for Xb1 X     Xb2 .

                                           18
    The intuition is as follows. Recall from inequality (15) that the e¤ect of informa-
tiveness on e¤ort depends on its di¤erential e¤ects on the values of the option-when-
working and the option-when-shirking. We thus study how changes in informativeness
a¤ect the value of each option.
    A decrease in informativeness (from to 0 ) increases both the left and right tails
of the signal distribution. If the initial strike price of the option is su¢ ciently low
(X < X   b1 ), then the signal distribution upon shirking lies on both sides of X . The
agent bene…ts from high signal realizations (s > X ), since the option-when-shirking
is in-the-money (“ITM”) and so he exercises it, but does not lose from low signals
(s < X ) as he does not exercise the option. Thus, when informativeness falls, a shirking
agent bene…ts from the growth in the right tail, but does not lose from the growth in
the left tail, and so the value of the option-when-shirking increases signi…cantly.
    Since the signal distribution has a location parameter, working shifts it rightwards.
Thus, for X < X    b1 , the signal distribution upon working is mostly to the right of X ,
and remains this way after informativeness falls. Since the option usually ends up ITM,
the agent usually exercises it. Thus, a working agent bene…ts from the growth in the
right tail and loses from the growth in the left tail, and so the value of the option-when-
working is relatively unchanged. Put di¤erently, reductions in informativeness increase
the value of an option due to its asymmetric payo¤: the agent bene…ts from s > X ,
but does not lose from s < X . When X is low and the agent shirks, the mean
signal 0 is close to the kink X and the agent bene…ts from the asymmetry. When
the agent works, the mean signal e is far from the kink X , and so he enjoys little
asymmetry. Overall, a fall in raises the value of the option-when-shirking more than
the option-when-working and reduces e¤ort incentives: e¤ort and informativeness are
complements. In simple language, the agent thinks “I’m not going to bother working
hard, because even if I do, I might be unlucky and so pro…ts will be low. I might as well
shirk, because even if I get unlucky and pro…ts become very low, that doesn’t matter,
because I can’t get paid less than zero no matter how low pro…ts get.”
    The existence of a location parameter is central to the above intuition, as it means
that e¤ort shifts the signal distribution rightward and reduces the probability of very
low signals (s < X ). If, in contrast, e¤ort increased the dispersion of the signal in
addition to its mean, it could increase the probability of very low signals. Thus, the
e¤ect on e¤ort incentives would be ambiguous.
    For a su¢ ciently high strike price (X > X   b2 ), the signal distribution upon shirking

                                            19
is mostly to the left of X –and remains this way even after informativeness falls and
the right tail expands. Thus, the option-when-shirking remains usually OTM and its
value is little changed. In contrast, if the agent works, this shifts the signal distribution
rightward and so decreases in informativeness now push the right tail above X . Thus,
when informativeness falls, a working agent bene…ts from the growth in the right tail
(since he can now exercise the option) but does not lose from the growth in the left tail
(since he does not exercise the option). Put di¤erently, when X is high and the agent
works, the expected signal e is close to the kink X and the agent bene…ts from the
asymmetry. When the agent shirks, the expected signal 0 is far from the kink X , and
so he enjoys little asymmetry. Overall, a fall in informativeness raises the value of the
option-when-working more than the option-when-shirking, and increases the agent’s
e¤ort incentives: e¤ort and informativeness are substitutes. In simple language, the
agent thinks “If informativeness were high, I wouldn’t bother working because the
target X is so high that I wouldn’t meet it, even if I did work. But, now that the
signal is more noisy, I will work –because if I do, and I get lucky, I’ll meet the target.”
    From Lemma 2, the initial strike price X is decreasing in the cost of e¤ort, and
thus the severity of the agency problem. When the agency problem is mild (severe),
the initial strike price is high (low); increases in informativeness reduce (increase) e¤ort
incentives, causing the strike price to fall (rise).
    However, without any restrictions on the distribution, it is unclear how changes in
  a¤ect the tails of the distribution between X    b1 and Xb2 . The source of the ambiguity
is that, for arbitrary distributions, decreases in precision in a SOSD sense need not
consistently shift mass from the center of the distribution towards the tails. It may be
that a fall in shifts some mass away from a tail, as long as it also moves mass towards
a more extreme tail point. Figure 1 shows that, while a fall in increases G (s) for
low s below a threshold s1 (i.e. increases the left tail) and increases 1 G (s) for high
s above a threshold s2 > s1 (i.e. increases the right tail), the e¤ect of on G (s) is
unclear for intermediate s. The CDFs G and G 0 could cross many times between X            b1
and Xb2 .




                                            20
                    Figure 1: Distributions in the location family.


    De…nition 2 below introduces a simple regularity condition that guarantees that
falls in informativeness have a “consistent”e¤ect on the distribution –they shift mass
towards the tails away from the center. Proposition 2 shows that, for regular noise dis-
tributions, X b1 = X
                   b2 = X,
                         b and so there is a single threshold below (above) which e¤ort
and precision are complements (substitutes): the CDFs cross at a single point X,  b as
shown in Figure 2. There is no intermediate range in which changes in informativeness
have an ambiguous e¤ect.




                                          21
                        Figure 2: Regular signal distributions.


                                                          b such that
De…nition 2 The distribution G is regular if there exists X
                             (       )                 (   )
                                 <       b =) @G (s)
                         s               X                     0:
                                 >             @

Proposition 2 (E¤ect of informativeness with regular distributions): Suppose that the
signal distribution F belongs to a location family and that the noise distribution G is
regular. Then there exists Xb such that dX               b and dX
                                               0 if X < X,              0 if X > X.b
                                          d                       d


    Regularity is not automatically implied by SOSD, but is satis…ed by most stan-
dard distributions. Indeed, Corollary 2 shows that regularity is satis…ed by any signal
distribution that has a scale parameter (in addition to a location parameter).



                                             22
Corollary 2 (Distributions with a scale parameter): If the signal distribution F has
a scale parameter, i.e. its CDF and PDF can be written as F (sje) = G s e and
                                                                                 b such
f (sje) = 1 g s e , then the noise distribution G is regular and so there exists X
that dX               b and dX
            0 if X < X,             0 if X > X. b
      d                       d


   A distribution with a location and scale parameter can be fully characterized by its
mean e and standard deviation . Since the volatility of a signal is the inverse of its
precision, we have = p1 and so:
                                                              (
                  @      s   e       s       e        s   e       < 0 if s > e
                    G            =       2
                                                 g                                  (18)
                 @                                                > 0 if s < e

as required by De…nition 2. Intuitively, the existence of a scale parameter means that
informativeness is characterized by this parameter, and so changes in this parameter
have a consistent e¤ect on the shape of the distribution, moving mass towards its tails,
thus satisfying the regularity condition.
    While regularity guarantees a single cuto¤ X, b for general distributions we do not
know where this cuto¤ lies. Indeed, Claim 1 in Appendix C shows that, for distrib-
utions with a scale parameter, X  b may lie anywhere between 0 and e. Proposition 3
shows that, when the distribution is not only regular (for which a scale parameter is
su¢ cient but not necessary) but also symmetric (as with the Normal, uniform, logistic,
Cauchy, and Laplace distributions), X b lies half-way between 0 and e, i.e. X
                                                                            b = e , as is
                                                                                 2
intuitive. Thus, we can compare the initial strike price, which depends on the under-
lying parameters of the agency problem (see Lemma 2) to the threshold 2e . Hence, we
can relate whether e¤ort and informativeness are complements or substitutes to model
primitives.

Proposition 3 (Symmetric regular distributions): Suppose that the signal distribu-
tion F belongs to a location family and that the noise distribution G is regular and
symmetric. Then, dX      0 if X < X,b and dX     0 if X > X,b where Xb    e
                                                                            .
                   d                       d                              2


    In addition to being su¢ cient for regularity, the presence of a scale parameter also
clari…es the intuition because we can fully parameterize changes in precision by changes
in volatility . We can thus examine how changes in a¤ect the values of the two
options using the familiar concept of the option “vega”: the sensitivity of its value to

                                                 23
  . In turn, the vega of each option will depend on the initial strike price, and thus the
underlying parameters of the agency problem. With a scale parameter, equation (15)
now becomes
                             @
                               fE [W (s) je] E [W (s) j0]g < 0:                        (19)
                            @
The left-hand side (“LHS”) of inequality (19) – the vega of the option-when-working
minus the vega of the option-when-shirking – represents the e¤ect of changes in
on incentives. The vega of an option is always positive, highest for an at-the-money
(“ATM”) option (see Claim 2 in Appendix C7 ), and declines when the option moves
either ITM or OTM. Thus, the vega of the option-when-working is highest at X = e,
and so if it has a strike price of Xb = e , then it is ITM by e . The vega of the option-
                                         2                      2
when-shirking is highest at X = 0, and so if it has a strike price of X     b = e , then it
                                                                                 2
is OTM by 2e . Overall, at a strike price of X   b = e , both options are equally away-
                                                        2
from-the-money and have the same vega (see Claim 3 in Appendix C), and so e¤ort
incentives are independent of . We thus have dX         = 0 for X = X.b
                                                    d
     When X < X, b then Y (0; X) is closer to being ATM than Y (e; X), and so it has a
higher vega. Thus, an increase in reduces e¤ort incentives, and so dX       d
                                                                               < 0. When
       b
X < X, then Y (e; X) is closer to being ATM than Y (0; X), and so it has a higher
vega. Thus, an increase in lowers e¤ort incentives, and so dX     d
                                                                      > 0.
     Proposition 3 implies that, for all symmetric regular distributions, regardless of
the initial strike price X, improvements in informativeness draw X towards X        b = e.
                                                                                         2
When the initial strike price is high (low), a fall in volatility reduces (increases) e¤ort
incentives, causing the strike price to fall (rise). In the current discrete model, there
are two e¤ort levels, e and 0. In a continuous-e¤ort analog, where the principal wishes
to implement e¤ort of e, the contract must ensure induce the agent to exert e¤ort of e
rather than e + " or e ", i.e. the incentive constraint must be “local”. In our discrete
model, a local incentive constraint resembles the case in which the (implemented) high
                                                                         b ' 0. Moreover,
e¤ort level (e) is very close to the low e¤ort level (0). If e ' 0, then X
since the contract induces the agent to exert e¤ort of e, the mean value of the signal
is e and so an ATM option will have a strike price of e ' 0. Thus, if the initial strike
price is higher (lower) than X  b ' 0, improvements in informativeness (e.g. increases
in stock market e¢ ciency) will lower (raise) the optimal strike price towards 0, i.e.
   7
    It is well-known that for lognormal distributions, the vega is highest for ATM options. Claim 2
in Appendix C extends this result to all distributions with a location and scale parameter.



                                                24
bring the option closer to ATM. (Indeed, Appendix E sketches a continuous e¤ort
model which shows that increases in informativeness bring the option closer to ATM.)
Bebchuk and Fried (2004) argue that the almost universal practice of granting ATM
options is ine¢ cient and that OTM options would be cheaper for the …rm. Similarly,
Rappaport (1999) advocates OTM options as they reward the agent only for exceptional
performance. However, such views ignore the incentive e¤ect: OTM options have lower
deltas and so more would be required to achieve incentive compatibility. Murphy (2002)
notes that ITM options would provide the strongest incentives, but that the tax code
discourages such options. One interpretation is that the tax code leads to …rms choosing
ATM options when ITM options may be more e¢ cient. Our analysis instead suggests
that increases in informativeness lead to options optimally being close to ATM.8
    In addition, Proposition 2 suggests that exogenous increases in informativeness will
have di¤erent e¤ects on the incentives of agents depending on the moneyness of their
options. In particular, it will reduce (increase) the incentives of agents with OTM
(ITM) options. Thus, …rms may wish to reduce the strike prices of OTM options to
restore incentives. Option repricing is documented empirically by Brenner, Sundaram,
and Yermack (2000), although they do not study if it is prompted by falls in volatility.
Acharya, John, and Sundaram (2000) also study the repricing of options theoretically,
although in responses to changes in the mean rather than volatility of the signal.
    Finally, note that the above analysis takes an optimal contracting approach, so the
slope of the contract is the maximum possible without violating the constraint (10).
We thus have W 0 (s) = 1: the agent is the residual “claimant” of any increase in the
signal (as long as s X ). Thus, the principal changes X to ensure that the incentive
constraint binds. An alternative approach is to restrict the contract to comprising ATM
options, e.g. for accounting or tax reasons9 , and instead meet the incentive constraint
by varying the slope of the contract. Appendix D demonstrates an analogous result for
this case. With ATM options, we have X = e X       b = e and so e¤ort and precision are
                                                         2
substitutes. An increase in informativeness requires the number of options granted to
   8
     Hall and Murphy (2000) restrict the contract to consist of options, rather than taking an optimal
contracting approach, and calibrate the optimal strike price depending on the CEO’s risk aversion,
the proportion of his wealth in stock, and the proportion of his wealth in options. They show that, in
most cases, the range of optimal strike prices includes the current stock price, i.e. corresponds to an
ATM option. In contrast, Dittmann and Yu (2011) feature a risk-taking as well as e¤ort decision, and
restrict the contract to consisting of …xed salary, stock, and options. They show that ITM options are
typically optimal.
   9
     Murphy (1999) documents that ATM options are almost universally granted.


                                                  25
increase to maintain incentive compatibility. This augments the expected wage, just
like a decrease in the strike price, and so the total e¤ect of informativeness on expected
pay is less than the direct e¤ect. Thus, the results of the core model, where X > X,    b
extend to the case of ATM options.


3.3    Normal Distribution
We now demonstrate graphically the direct and incentive e¤ects. We need to assume
a speci…c distribution to enable us to calculate the derivatives, and so we consider the
common case of a Normal distribution. Let ' and denote the PDF and CDF of the
standard Normal distribution, respectively. As we show in Appendix A, the total e¤ect
and the direct e¤ect are respectively given by:
                                                             X   e         X
   dE [W (s) je]        X     e               X     e    '            '
                 ='                   1                      X         X       e
                                                                                   ; and   (20)
       d
   @E [W (s) je]        X     e
                 ='               :                                                        (21)
       @

Figure 3 illustrates how these e¤ects change as we vary the severity of the moral hazard
problem (parameterized by the the cost of e¤ort C). As is standard for graphs of option
values, the …gure contains the strike price X on the x-axis; since X is strictly decreasing
in C (equation (31)), there is a one-to-one mapping between X and C.




                                            26
Figure 3: Total and partial derivative of expected pay with respect to             for a range of values of
                                    X, for e = 1 and = 1.


    To understand Figure 3, recall from (12) that the total e¤ect is given by dE[Wd (s)je] =
@E[W (s)je]
    @
            + @E[W
                 @X
                   (s)je] dX
                           d
                             . The direct e¤ect, @E[W@ (s)je] , tends to zero as the strike price
approaches either 1 or 1. The vega of an option is greatest when the option is
ATM, i.e. X = 1. An ATM option bene…ts most from the asymmetry in an option’s
payo¤: a high noise realization leads to a large increase in the option’s payo¤, but a
low noise realization has no e¤ect as the agent will not exercise the option.
    The incentive e¤ect, @E[W    @X
                                   (s)je] dX
                                           d
                                             , consists of two components. The …rst is the
change in strike price required to maintain incentive compatibility, dX        d
                                                                                  . From Propo-
                              1 dX                                b   1
sition 3 and using = p , d > 0 if and only if X > X = 2 . Indeed, for the Normal
distribution, not only does dX turn from negative to positive as X crosses above X,            b
                                d


                                               27
but it is also monotonically increasing in X, i.e. monotonically decreasing in the cost
of e¤ort. This result is stated in Lemma 5 below:

Lemma 5 (Normal distribution, change in strike price): Suppose " is Normally dis-
tributed. Then, the bene…ts of informativeness are decreasing in the cost of e¤ort,
i.e.
                                    d2 X
                                          < 0:                                 (22)
                                    d dC
     The second is the change in the value of the option when the strike price increases,
@E[W (s)je]
   @X
            .   This change is always negative, and so the sign of the incentive e¤ect is
the opposite of the sign of dX     d
                                     : indeed, in Figure 3, the incentive e¤ect is positive
(negative) for X < (>) X.     b In addition, the magnitude of @E[W (s)je] is increasing in
                                                                       @X
                                                               b    dX
the moneyness of the option. Overall, as X falls below X, d becomes increasingly
negative (see Lemma 5), and the option becomes increasingly in the money so @E[W            @X
                                                                                              (s)je]

also becomes increasingly negative (it falls towards 1). Thus, the overall incentive
e¤ect @E[W     (s)je] dX
                         becomes monotonically more positive as X falls below X.     b However,
            @X         d
as X rises above X,      b the two components of the incentive e¤ect move in opposite
directions. On the one hand, greater informativeness becomes increasingly detrimental
to incentives ( dX     d
                         becomes more positive). On the other hand, @E[W   @X
                                                                             (s)je]
                                                                                    falls towards
zero: when the option is deeply OTM, its value is small to begin with and thus little
a¤ected by changes in the strike price. Overall, the impact of X on the incentive e¤ect is
non-monotonic. As X initially rises above X,    b the incentive e¤ect becomes increasingly
negative as the option has signi…cant value, and this value is a¤ected by the change
in the strike price required to maintain incentives ( @E[W @X
                                                             (s)je]
                                                                    is large). However, as X
continues to rise, the option’s value falls and so is little a¤ected by the strike price
( @E[W
     @X
       (s)je]
              is small). Thus, the incentive e¤ect tends to zero.
     The total e¤ect dE[Wd (s)je] combines these direct and incentive e¤ects. While the di-
rect e¤ect is initially increasing in X, this is outweighed by the fact that the incentive
e¤ect is initially decreasing in X. Thus, in Figure 3, the total gains from increased
informativeness are monotonically decreasing in X. Indeed, focusing on the Normal
distribution allows us to prove this result analytically: C is the exogenous parame-
ter that drives X, and Proposition 4 shows that the gains from informativeness are
monotonically increasing in C.



                                                28
Proposition 4 (Normal distribution, e¤ect of cost ofne¤ort onogains from informa-
                                                    d dE[W (s)je]
tiveness) Suppose " is Normally distributed. Then, dC    d
                                                                  > 0.

    An analysis focusing purely on the direct e¤ect would suggest that the gains from
informativeness are greatest when the initial option is ATM, which in turn corresponds
to a moderate strike price and a moderate cost of e¤ort. In contrast, considering
the total e¤ect (which incorporates the incentive e¤ect) shows that the gains from
informativeness are monotonically increasing in the severity of the agency problem.
Thus, workers with high-powered incentives (such as CEOs) should be evaluated more
precisely than those with low-powered incentives (such as rank-and-…le workers).
    Corollary 3 shows that, as the cost of e¤ort goes to zero, the gains from informa-
tiveness also approach zero, as does the total gain relative to the direct e¤ect.

Corollary 3 (Normal distribution, limiting cases). Suppose " is Normally distributed.
Then,
                                                   dE[W (s)je])
            dE [W (s) je]                              d
                          !C!0 0         and       @E[W (s)je]
                                                                !C!0 0:          (23)
                d
                                                       @

    As the moral hazard problem becomes weaker, the total e¤ect of informativeness
becomes very small relative to the direct e¤ect. Thus, ignoring the incentive e¤ect
and considering only the direct e¤ect would substantially overestimate the gains from
informativeness. Indeed, in Figure 3, the direct e¤ect signi…cantly overestimates the
total gains for su¢ ciently large X. For example, for     = 1 and X = 2 (which is
only one standard deviation away from the expected performance of e = 1), the gains
from a marginal change in are 10:8 times larger with the direct e¤ect than with
the total e¤ect. Thus, even for non-extreme parameter values, gains from improved
informativeness can be much lower if the incentive e¤ect is taken into account. This
ratio becomes much greater for higher X, because the total bene…ts of informativeness
fall towards zero.


4    Conclusion
This paper studies the principal’s bene…ts from increasing the informativeness of the
signal used to evaluate the agent. The direct e¤ect is that higher signal precision
reduces the value of the agent’s option and thus expected pay. The core focus of the

                                         29
paper is on the indirect e¤ect –how changes in precision a¤ect the agent’s incentives.
By taking an optimal contracting approach, we can be speci…c on how the contract
changes in response to increases in informativeness. With general signal distributions,
we show that, if e¤ort and informativeness are substitutes, increases in precision weaken
the agent’s incentives. Thus, the principal must reduce the strike price of the option
to preserve e¤ort incentives, increasing the cost of compensation and o¤setting the
direct e¤ect. Indeed, we derive a simple condition that governs whether e¤ort and
informativeness are substitutes or complements, that holds for all distributions that
satisfy the monotone likelihood ratio property.
    Focusing on signal distributions with a location parameter allows us to relate
whether e¤ort and informativeness are substitutes or complements to the initial strike
price of the option, and thus the severity of the underlying agency problem. When the
initial strike price is above a threshold, i.e. incentives are low-powered to begin with,
an increase in informativeness reduces the agent’s e¤ort incentives and thus the bene…ts
of informativeness. The principal therefore optimally invests less in improving infor-
mativeness, potentially rationalizing the scarcity of relative performance evaluation for
some agents in reality.
    In contrast, if the initial strike price is below a second (lower) threshold, i.e. in-
centives are high-powered to begin with, an increase in informativeness augments the
agent’s e¤ort incentives. This provides an additional gain from informativeness over
and above the direct e¤ect of reducing volatility traditionally focused upon. Thus, the
gains from informativeness depend critically on the strength of incentives, and thus
the magnitude of the moral hazard problem to begin with. For regular signal distri-
butions, where an increase in informativeness consistently moves mass from the tails
of the distribution to the center, both thresholds coincide at a single point. This reg-
ularity condition is satis…ed by any distribution with a location and scale parameter,
such as the Normal, uniform, and logistic distributions. Furthermore, with a Normal
distribution, the bene…ts from informativeness are monotonically increasing in the cost
of e¤ort, and thus the severity of the agency problem. Finally, if incentive constraints
are local, i.e. the implemented e¤ort level is close to other feasible e¤ort levels, then
increases in informativeness cause the strike price to move closer to at-the-money.




                                           30
References
 [1] Acharya, Viral V., Kose John, and Rangarajan K. Sundaram (2000): “On the
     optimality of resetting executive stock options.” Journal of Financial Economics
     57, 65-101.

 [2] Aggarwal, Rajesh K. and Andrew A. Samwick (1999): “Executive compensation,
     relative performance evaluation, and strategic competition: theory and evidence.”
     Journal of Finance 54, 1999–2043.

 [3] Axelson, Ulf and Sandeep Baliga (2009): “Liquidity and manipulation of executive
     compensation schemes.”Review of Financial Studies 22, 3907–3939.

 [4] Baker, George (1992): “Incentive contracts and performance measurement.”Jour-
     nal of Political Economy 100, 598–614.

 [5] Bebchuk, Lucian and Jesse Fried (2004): Pay without performance: the unful…lled
     promise of executive compensation. (Harvard University Press, Cambridge).

 [6] Bertrand, Marianne and Sendhil Mullainathan (2001): “Are CEOs rewarded for
     luck? The ones without principals are.” Quarterly Journal of Economics 116,
     901–932.

 [7] Biais, Bruno, Thomas Mariotti, Jean-Charles Rochet, and Stéphane Villeneuve
     (2010): “Large risks, limited liability and dynamic moral hazard.” Econometrica
     78, 73–118.

 [8] Brenner, Menachem, Rangarajan K. Sundaram, and David Yermack (2000): “Al-
     tering the terms of executive stock options.”Journal of Financial Economics 57,
     103–128.

 [9] Brookman, Je¤rey T. and Paul D. Thistle (2013): “Managerial compensation:
     Luck, skill, or labor markets?”Journal of Corporate Finance 21, 252–268.

[10] Bulow, Jeremy I., John D. Geanakoplos, and Paul D. Klemperer (1985): “Mul-
     timarket oligopoly: Strategic substitutes and complements.” Journal of Political
     Economy 93, 488–511.



                                         31
[11] Chaigneau, Pierre, Alex Edmans and Daniel Gottlieb (2014): “The informative-
     ness principle under limited liability.”NBER Working Paper No. 20456.

[12] Cornelli, Francesca, Zbigniew Kominek, and Alexander Ljungqvist (2013): “Mon-
     itoring managers: Does it matter?”Journal of Finance 68, 431–481.

[13] De Angelis, David, Gustavo Grullon, and Sébastien Michenaud (2013): “Downside
     risk and the design of CEO incentives: Evidence from a natural experiment.”
     Working Paper, Rice University.

[14] Dittmann, Ingolf and Ernst Maug (2007): “Lower salaries and no options? On
     the optimal structure of executive pay.”Journal of Finance 62, 303–343.

[15] Dittmann, Ingolf, Ernst Maug, and Oliver G. Spalt (2010): “Sticks or carrots? On
     the optimal structure of executive pay.”Journal of Finance 65, 2015–2050.

[16] Dittmann, Ingolf, Ernst Maug, and Oliver G. Spalt (2013): “Indexing executive
     compensation contracts.”Review of Financial Studies 26, 3182–3224.

[17] Dittmann, Ingolf and Ko-Chia Yu (2011): “How important are risk-taking incen-
     tives in executive compensation?”Working Paper, Erasmus University Rotterdam.

[18] Edmans, Alex and Xavier Gabaix (2009): “Is CEO pay really ine¢ cient? A survey
     of new optimal contracting theories.” European Financial Management 15, 486–
     496.

[19] Edmans, Alex and Xavier Gabaix (2011): “Tractability in Incentive Contracting.”
     Review of Financial Studies 24, 2865–2894.

[20] Gjesdal, Froystein (1982): “Information and incentives: the agency information
     problem.”Review of Economic Studies 49, 373–390.

[21] Gopalan, Radhakrishnan, Todd T. Milbourn and Fenghua Song (2010): “Strategic
     ‡exibility and the optimality of pay for sector performance.”Review of Financial
     Studies 23, 2060–2098.

[22] Gormley, Todd A., David A. Matsa, and Todd T. Milbourn (2013): “CEO compen-
     sation and corporate risk-taking: Evidence from a natural experiment.” Journal
     of Accounting and Economics 56, 79–101.

                                         32
[23] Grossman, Sanford J., and Oliver D. Hart (1983): “An analysis of the principal-
     agent problem.”Econometrica 51, 7–45.

[24] Hall, Brian J. and Kevin J. Murphy (2000): “Optimal exercise prices for executive
     stock options.”American Economic Review 90, 209–214.

[25] Holmstrom, Bengt (1979): “Moral hazard and observability.”Bell Journal of Eco-
     nomics 10, 74–91.

[26] Innes, Robert D. (1990): “Limited liability and incentive contracting with ex-ante
     action choices.”Journal of Economic Theory 52, 45–67.

[27] Jenter, Dirk and Fadi Kanaan (2013): “CEO turnover and relative performance
     evaluation.”Journal of Finance, forthcoming.

[28] Kim, Son Ku (1995): “E¢ ciency of an information system in an agency model.”
     Econometrica 63, 89–102.

[29] Milgrom, Paul and John Roberts (1990): “Rationalizability, learning, and equilib-
     rium in games with strategic complementarities.”Econometrica 58, 1255–1277.

[30] Murphy, Kevin J. (1999): “Executive compensation” in Handbook of Labor Eco-
     nomics, O. Ashenfelter and D. Card, eds. Elsevier/North-Holland.

[31] Murphy, Kevin J. (2002): “Explaining executive compensation: Managerial power
     versus the perceived cost of stock options.”University of Chicago Law Review 69,
     847–869.

[32] Oyer, Paul (2004): “Why do …rms use incentives that have no incentive e¤ects?”
     Journal of Finance 59, 1619–1649.

[33] Raith, Michael (2008): “Speci…c knowledge and performance measurement.”Rand
     Journal of Economics 39, 1059–1079.

[34] Rappaport, Alfred (1999): “New thinking on how to link executive pay with
     performance.”Harvard Business Review 72, 91–101

[35] Shavell, Steven (1979): “Risk sharing and incentives in the principal and agent
     relationship.”Bell Journal of Economics 10, 55–73.

                                          33
[36] Zang, Israel (1980): “A smoothing-out technique for min-max optimization.”
     Mathematical Programming 19, 61–77.




                                      34
A      Proofs
Proof of Lemma 1
    Denote the lower bound of the support of s by s, and the upper bound by s. We
will adopt a two-step approach. First, we solve for the optimal contract for a …xed
minimum payment W (s) = Z 0. As we will show, the solution involves an “option”
with a …xed minimum payment Z. Then, we will show that the ‡oor is zero.
    Formally, for a given constant Z 0, consider the following “relaxed”program:
                                            Z    s
                                     min             W (s) f (sje) ds
                                     W ()    s


subject to              Z      s
                                   W (s) [f (sje)           f (sj0)] ds           C;
                           s

                       0           _ (s)
                                   W             1; and W (s) = Z …xed.

Note that the monotonicity condition W   _ (s) 0 implies that Z 0 is both necessary
and su¢ cient for the limited liability constraint to hold.
   Introduce the auxiliary variables y (s) W    _ (s) and set up the Hamiltonian:

    H (W; y; ; ; s)    W (s)f (sje) + [W (s) [f (sje)                            f (sj0)]        C] + (s) y(s);

where W are state variables, y are control variables, are co-state variables, and is
a (state-independent) Lagrange multiplier. The necessary optimality conditions are:
                                                              (         )                (       )
                                                                    0                        <
              y (s) 2 arg max         (s) y ) y (s) =                       if     (s)                   0;   (24)
                        0 y 1                                       1                        >

                 @H
                    =          _ ) f (sje)               [f (sje)       f (sj0)] = _ (s) ;                    (25)
                 @W
and the transversality condition           (s) = 0:
   Condition (25) yields:

                                      1               f (sj0)      1                             1
                _ (s) > 0 ()              >1                  ()        >                            ;
                                                      f (sje)    LR (s)


                                                       35
where LR (s) ff (sj0)
                   (sje)
                         is the likelihood ratio, which we assumed to be increasing. Thus,
the LHS of the last inequality above is decreasing in s while the RHS is constant. Hence,
there exists a threshold s 2 [s; s] such that _ (s) > 0 for s < s and _ (s) < 0 for
s > s . (Notice that if s = s or s = s, one of these intervals vanishes). Therefore,
is bell-shaped, with a unique maximum at s and (at most) two local minima –one at
s and and another at s.
    We claim that s < s, i.e. is increasing 8 s if s = s. Then, the transversality con-
dition (s) = 0 and condition (24) implies that W (s) is constant (W (s) = W (s) = Z
8 s), which violates the incentive constraint. Thus, it cannot be a solution.
    There are two possible solutions depending on whether (s) 0 or (s) < 0. In
the former case, we must have (s) > 0 8 s 2 (s; s) (since the only candidates for
global minima are s and s and (s)            0 = (s)). In the latter case, there exists a
threshold s 2 (s; s ) such that (s) < 0 if s < s and (s) > 0 if s > s . We can
combine both cases by letting s 2 [s; s ) denote the threshold below which we have
  (s) < 0. The solution is then

                                  W (s) = Z + max fs                          s ; 0g            (26)

for some s 2 [s; s). This concludes the …rst part of the proof.
    It remains to be shown that the solution entails Z = 0. Substitute the agent’s
payment from (26) in the principal’s expected cost
                   Z    s                                    Z       s
                            W (s) f (sje)ds = Z +                        (s    s ) f (sje)ds;
                    s                                            s


and in the incentive constraint
                        Z s
                            (s s ) [f (sje)                          f (sj0)] ds       C:       (27)
                              s


Note that monotonicity is automatically satis…ed under (26) and, as before, the limited
liability constraint holds if and only if Z 0. The optimal contract must solve:
                                                    Z   s
                                  min          Z+           (s           s ) f (sje)ds          (28)
                             Z 0; s   2[s;s]        s




                                                        36
subject to (27). Since Z increases the expression in (28) but does not a¤ect the incentive
constraint in (27), the solution entails Z = 0. Thus, the solution of the relaxed program
is
                               W (s) = max fs s ; 0g ;

   With this contract, and setting X = s , we show in the proof of Lemma 2 that
                                                 Rs
the LHS of the incentive constraint (5) becomes X [F (sj0) F (sje)] ds. By FOSD,
the LHS of (27) is decreasing in X . Since both the expected cost to the principal and
the LHS of the incentive constraint are strictly decreasing in X , the optimal level of
X satis…es the incentive constraint with equality:
                             Z   s
                                     (s        X ) [f (sje)        f (sj0)] ds = C:
                                 X


   Finally, we establish that X exists. Evaluated at X = s, the LHS of the incentive
constraint is 0 < C. Evaluated at X = s; it equals
             Z    s                                      Z   s                 Z    s
                      [F (sj0)       F (sje)] ds =               sf (sje) ds            sf (sj0) ds;   (29)
              s                                          s                      s


using the same integration by parts as in the proof of Lemma 2. Since high e¤ort
is …rst-best e¢ cient, the expression in (29) exceeds C. Thus, the intermediate value
theorem and the monotonicity of the LHS ensure that a unique solution to (30) exists.
    In sum, we have established that the optimal contract is

                                          W (s) = maxfs              X ; 0g;

where the strike price X is such that the incentive constraint holds with equality.
   Proof of Lemma 2
   Denoting the upper bound of the support of s by s, we …rst show that the incentive
constraint (6) can also be rewritten as
                                     Z    s
                                              [F (sj0)       F (sje)] ds = C:                          (30)
                                      X




                                                         37
Opening the expressions inside the brackets in equation (5), we obtain:
     Z   s                                                            Z    s
             sf (sje) ds              [1    F (X je)] X =                      sf (sj0) ds           [1   F (X j0)] X + C;
         X                                                             X


which yields
                 Z   s                        Z      s
                         sf (sje) ds                     sf (sj0) ds = [F (X j0)                 F (X je)] X + C:
                 X                               X


Applying integration by parts (for e 2 f0; eg), gives
 Z   s                                                   Z                     s                                   Z   s
         sf (sje) ds = sF (sje)                              F (sje) ds            =s   X F (X je)                         F (sje) ds:
  X                                                                            X                                    X


Plugging back in the previous expression, we obtain
                                             Z   s                                                        Z   s
             s       X F (X je)                      F (sje) ds                s   X F (X j0)                     F (sj0) ds
                                              X                                                            X


                                             = [F (X j0)              F (X je)] X + C:

Canceling terms gives equation (30). Applying the implicit function theorem to (30)
yields:
                         dX               1
                             =                       < 0:                      (31)
                         dC       F (X j0) F (X je)


    Proof of Equation (16)
    Denoting the lower bound of the support of s by s, the agent’s expected pay in case
of e¤ort e is
             Z +1                     Z +1
                  (s X) f (sje) ds =        sf (sje) ds X [1 F (Xje)]
                         X                                        X

                                 Z   +1                                                 Z        X
                             =            sf (sje) ds          X [1       F (Xje)]                   sf (sje) ds:
                                 s                                                           s




                                                                      38
Applying integration by parts, we have:
     Z       X                                       Z                           X                            Z       X
                 sf (sje) ds = sF (sje)                      F (sje) ds                  = XF (Xje)                       F (sje) ds:
         s                                                                       s                                s


Substituting this into the previous equation yields:
Z   +1                                  Z     +1                                 Z       X                          Z                 X
         (s       X) f (sje) ds =                  sf (sje) ds X+                            F (sje) ds = E [sje] X+                      F (sje) ds:
 X                                        s                                          s                                            s




   Proof of Lemma 3
   Denote the lower bound of the support of s by s, and the upper bound by s. The
agent’s expected pay in the case of e¤ort e is given by
                                                             Z   s
                                    E [W (s)je] =                    (s        X ) f (sje) ds:                                            (32)
                                                              X


Integration by parts yields:
                           Z   s                                                             Z   s
                                   sf (sje) ds = s               XF (sje)                            F (sje) ds
                            X                                                                 X


and so (32) can be rewritten:
                                                                     Z    s
                    E [W (s)je] = s           XF (sje)                        F (sje) ds              X [1   F (sje)]
                                                                      X
                                                    Z    s
                                   =s         X              F (sje) ds.                                                                  (33)
                                                     X


    Since s and X are not functions of either or e, it follows that the agent’s expected
                                                 Rs
pay satis…es increasing di¤erences if and only if X F (sje) ds satis…es decreasing dif-
ferences (and vice-versa). The following Lemma will be useful for this and future
proofs:
                                   Rs
Lemma 6 For any ,                   s
                                        F (sje) ds = s               E [sje], which is not a function of .




                                                                     39
                                                      Rs
Proof. Applying integration by parts to               s
                                                           sf (qje) ds, we obtain:

         Z     s                                  Z                     s          Z    s
                   sf (qje) ds = sF (qje)             F (sje) ds            =s              F (sje) ds:
           s                                                            s           s


Since parameterizes mean-preserving spreads, the expression on the LHS, E[sje] is
not a function of .
                    Rs                                                      RX
    From Lemma 6, X F (sje) ds satis…es decreasing di¤erences if and only if s F (sje) ds
satis…es increasing di¤erences (since their sum is independent of by second-order sto-
chastic dominance). Thus, the agent’s expected pay satis…es increasing di¤erences if
            RX
and only if s F (sje) ds satis…es increasing di¤erences.
   Proof of Proposition 1
   Applying the implicit function theorem to equation (30) gives:
                                          R1 @
                             dX            X @
                                                 [F (qj0) F (qje)] dq
                                =                                     :
                              d                F (X j0) F (X je)

By FOSD, the denominator is positive. Lemma 6 yields:
                                 Z   1                          Z   X
                            @                               @
                                         F (qje)dq =                    F (qje)dq
                            @    X                          @       1


8 X; ; e. Plugging back:
                                         RX   @
                             dX             1 @
                                                  [F (qje) F (qj0)] dq
                                =                                      :
                              d                F (X j0) F (X je)
                                       RX
It is straightforward to show that if 1 F (qje) dq satis…es increasing (decreasing)
di¤erences and is di¤erentiable with respect to , then
                                 Z   X
                             @
                                          [F (qje)     F (qj0)] dq          ( )0                          (34)
                             @       1


8 e > 0: The denominator is positive by FOSD.
   Proof of Lemma 4



                                                      40
       From Lemma 3, e¤ort and informativeness are complements if and only if
                                                Z    X
                                           @
                                                            [F (sje)           F (sj0)] ds               0;                              (35)
                                           @         1


i.e. the single-crossing condition holds. Since F (sje) = G (s                                                    e), we have
              Z   X                                                           Z    X                                  Z   X
          @                                             @
                      [F (sje)            F (sj0)] ds =                                G (s           e) ds                   G (s) ds
          @       1                                     @                          1                                      1

                        Z       X   e                        Z   X                                            Z   X
                @                                                                            @
              =                         G (s) ds                      G (s) ds             =                              G (s) ds
                @               1                                1                           @                X       e
                                                                 Z   X
                                                                             @G
                                                      =                         (s) ds:                                                  (36)
                                                                  X      e    @
Therefore, e¤ort and informativeness are complements if and only if (36) > 0.
     Let ( )     lim & 1 G ( ) = 0. Since is di¤erentiable at 1, it follows that
 0
   ( ) = 0: Similarly, ^( )   lim %+1 G ( ) = 1 and the di¤erentiability of ^ at 1
implies that ^0 ( ) = 0. Moreover, it is straightforward to show that SOSD implies10
                                                    Z    X
                                                                 @G
                                                                    (s             e) ds        0                                        (37)
                                                            1     @

8 X . Thus, @G           0 for s small enough. As a result, there exists X  b1 such that
                 @
R Xb1 @G
 Xb1 e @ (s) ds < 0. Thus, (36) > 0 and so e¤ort and informativeness are complements.
     In addition, @G
                   @
                       = 0 for s ! 1. Thus, @G
                                             @
                                                 must eventually turn positive: @G@
                                                                                       0
                                                            R Xb2 @G
for s large enough. As a result, there exists Xb2 such that b          (s) ds > 0. Thus,
                                                             X2 e @
(36) < 0 and so e¤ort and informativeness are substitutes. In sum, there exists X     b1
such that dX       0 if X < X  b1 , and X
                                        b2 Xb1 such that dX      0 if X > X b2 . However,
                  d                                                                                  d
  10                                                             0
       Recall that SOSD requires that for all
                                           Z    X                              Z   X
                                                    G 0 (s        e) ds                G (s         e) ds:
                                                1                                  1

                            0
Taking the limit as             &       gives
                                                        Z   X
                                                                 @G
                                                                    (s         e) ds       0:
                                                             1    @




                                                                          41
    b1 < X < X
for X             b2 , it is possible for       @G
                                                     to alternate signs several times, and so we
                                                 @
cannot sign (36).
   Proof of Proposition 2
   From the de…nition of regular distributions (De…nition 2), @G
                                                               @
                                                                   alternates signs only
                                                   @G
once. Furthermore, we know from Lemma 4 that @             (     ) 0 for s small (large)
                                               R X @G
                                b such that
enough. Therefore, there exists X                       (s) ds is nonnegative for X <
                                                X e @
 b                           b
X, and nonpositive for X > X. It then follows from Lemma 4 that dX          0 if X < X b
                                                                      d
and dX    0 if X > X.b
     d

   Proof of Proposition 3
                                       dX
   We know from Lemma 4 that            d
                                                  ( )0 if
                                  Z   X
                                                @G
                                                   (s) ds    ( ) 0:                        (38)
                                   X        e    @

If G is regular and symmetric for any , then

                                     G(x) = 1 G( x)
                                  @G         @G
                                      (x) =     ( x)
                                   @          @
                                  @G
                                      (x) 0 , x 0:
                                   @
It follows that, for X = e=2, the LHS of equation (38) is
                                  Z    e=2
                                                 @G
                                                    (s) ds = 0:                            (39)
                                          e=2     @

For X     e    0,                 Z   X
                                                 @G
                                                    (s) ds     0;                          (40)
                                      X     e     @
and for X      0,                 Z   X
                                                 @G
                                                    (s) ds     0:                          (41)
                                      X     e     @




                                                     42
Finally, for X 2 (0; e),
                            Z   X
                  @                              @G                                @G                              @G
                                                    (s) ds                  =         (X           e)                 (X )                    0                (42)
                 @X         X           e         @                                 @                               @

                                                              dX                                           dX
Combining (39)-(42) shows that                                 d
                                                                           0 if X < 2e , and                d
                                                                                                                           0 if X > 2e .

   Proof of Equations (20) and (21)
   First, with volatility instead of precision , the decomposition in (12) can be
rewritten as
                 d                 @               @             dX
                   E [W (s)je] =     E [W (s)je] +   E [W (s)je]             (43)
                d                |@     {z     } |@X              d
                                                         {z         }
                                                                   direct e¤ ect                   incentive e¤ ect

   Second,
                                Z   1                                                                   Z      1
   @E[W (s)je]    @                                               1        s        e         @                            s+e               X        s
               =                            (s       X ) '                              ds =                                                      '           ds
      @          @                  X                                                        @             X        e

                                Z   1                                                              Z    1
                        @                        s            s                             @                      1            s
                     =                               '                ds       (X       e)                             '                 ds
                       @        X           e                                              @        X          e

                   @        h                    s i1                                         @                            X             e
             =                          '                                      (X       e)             1
                  @                                       X        e                         @
             X       e              X                e             X           e                                   X            e                 X       e
    ='                                          2
                                                         '0                         + (X           e)                       2
                                                                                                                                         '

         X       e          X               e            X             e           X      e            X            e                         X       e
  ='                                            '0                             +              '0                                ='                             (44)

where the fourth and sixth equalities use the property that '0 (x) = x'(x), and the
…fth equality uses '(x) !x!1 0. This establishes (21). In addition, it follows that

                  @                                                                           X            e                        X
                    fE [W (s) je]                         E [W (s) j0]g = '                                                '                  :
                 @

   Third,                                   Z 1
                          @E[W (s) je]    @                                               1                 s          e
                                       =        (s                                      X) '                                    ds
                             @X          @X X
                           Z 1
                                 1     s e                                                                 X            e
                         =         '        ds =                                         1                                           :                         (45)
                                X


                                                                               43
It follows that

         @                                                               X           e                          X
           fE [W (s) je]      E [W (s) j0]g =             1                                  + 1
        @X

                                             X       e                   X
                                    =                                            :

which is strictly negative because of MLRP, which implies FOSD.
   Using the results above, we can rewrite (43) as
                                                                                             X   e          X
             dE[W (s)je]        X       e                        X           e           '           '
                         ='                  + 1                                             X   e          X
                                                                                                                      (46)
                d

This establishes (20).
      Proof of Lemma 5
      As X is strictly decreasing in C (see Lemma 2), inequality (22) holds if and only
     d dX
if    dX
        d
            > 0. As established in the proof of equations (20) and (21) above,

                                                     X       e               X
                                  dX             '                   '
                                     =               X       e               X
                                                                                     :
                                   d

To simplify notation, de…ne
                                                     X           e
                                            x            ;t          :

We wish to show that 8t > 0,

     f (x; t)   ['(x)   '(x     t)]2    [ (x)            (x      t)]['0 (x)              '0 (x   t)] > 0;       8x;   (47)

where
                                                      1     x2
                                            '(x) = p e 2
                                                      2
                                                  Z x
                                            (x) =       '(y) dy:
                                                         1

    For t = 0, f (x; 0) is trivially 0. Since '(x) = '( x), we have (x) (x t) =
                              0        0          0           0
  ( x + t)      ( x) and ' (x) ' (x t) = ' ( x + t) ' ( x). As a consequence,
f (x; t) = f ( x + t; t). We thus only have to study x 2t > 0.


                                                     44
     We …rst analyze the term '0 (x)                       '0 (x      t). Since

                                                                    x           x2
                                                    '0 (x) =       p e           2   ;
                                                                    2

                         '0 (x)         '0 (x       t) = '(x          t)( xe         t(x t=2)
                                                                                                +x         t):

When x t=2, the function e t(x t=2) 1 + xt is only equal to zero at one point, since
it monotonically decreases from 2 to 1. Let that point be x0 . Then
                                                                8
                                                                            t
                                                                >
                                                                < <0        2
                                                                                   x < x0
                                    0               0
                                   ' (x)        ' (x          t) = 0             x = x0   :
                                                                >
                                                                :
                                                                  >0             x > x0

We know that when x 2 [ 2t ; x0 ], f (x; t) > 0 since ['(x) '(x t)]2 > 0 and (x)
  (x t) > 0 8x, so that (47) is proven for x 2 [ 2t ; x0 ]
    We now prove (47) for x > x0 . In this interval (we omit the argument t in what
follows):
                                                     f (x; t)
                  f (x; t) > 0 () g(x)                         > 0:
                                                ' (x) '0 (x t)
                                                 0

To prove the latter, we …rst calculate

 0         2['(x)       '(x        t)]['0 (x)           '02 ['(x) '(x                     t)]2 ['00 (x)      '00 (x      t)]
g (x) =
                                                          ['0 (x) '02
               ['(x)      '(x        t)]
           ['(x)       '(x        t)]['0 (x)            '02 ['(x) '(x                    t)]2 ['00 (x)     '00 (x      t)]
       =
                                                           ['0 (x) '02
           ['(x)      '(x t)]'(x                t)2
       =
                     ['0 (x) '02
           n                                    2
                                                                                                                                     o
                       t(x t=2)
                xe                +x        t             (x2      1)e   t(x t=2)
                                                                                           (x     t)2 + 1        e    t(x t=2)
                                                                                                                                 1
           ['(x)      '(x t)]'(x                t)2 h         t(x t=2)          2
                                                                                                       i
       =                                                  e                1         + t2 e     t(x t=2)
                     ['0 (x) '02
           < 0;      x 2 (x0 ; 1);




                                                                 45
where in the last step we used the fact that '(x) < '(x                                               t) when x > t=2. Therefore,

                         g(x) > 0 8x 2 (x0 ; 1) () lim g(x)                                                       0:
                                                                                      x!1


Since

                        ['(x)         '(x t)]2
              g(x) =                                                (x) + (x                     t)
                         '0 (x)       '0 (x t)
                                                          t(x t=2)                   2                                                  ;
                         1         (x t)2 =2       e                       1
                       =p e                                   t(x   t=2) + x
                                                                                                      (x) + (x                     t)
                         2                        xe                                      t

it is clear that
                                                      lim g(x) = 0:
                                                      x!1




     Proof of Proposition 4
     Using the chain rule,

                        d      dE[W (s)je]                           d           dE[W (s)je]                  dX
                                                          =
                       dC         d                                 dX              d                          dC
                                         n             o                       n             o
                                           dE[W (s)je]                           dE[W (s)je]
Since dX
       dC
          < 0 (see Lemma  2), we have  d
                                      dC      d
                                                         > 0 if and only if  d
                                                                            dX      d
                                                                                               <
0.
   Using (20) and '0 (x) = x'(x) for the Normal distribution, we have
                                      (                                                                                                                 )
                                                                                                                               X        e       X
 d      dE[W (s)je]         d                     X           e                                  X        e            '                    '
                         =                '                                  1                                                 X            X       e
dX         d               dX

                                                                                                                                            X   e
    1    X     e       X       e          X           e             X            e            X               X                    1
=                  '                  +                   '                                           '                            X            X       e


                                                                                                  X       e
                                  X           e                     X                        '
                       + '                             '                                 X                    X    e

                                                                                                                               !
                                      X       e                                                                            2
                           1                                             X            e                       X
                                                          2         '                                 '                                         (48)
                           X              X       e

                                              X                     X    e
Multiplying all terms by                                                             > 0, the expression in (48) has the

                                                                    46
same sign as

"                                           #
        X   e           X
    '               '                   X                       X                            X              e                       X   e          X
        X           X       e
                                                    '                       1                                                   '            1

    e       X       e                       X
        '                   1                               :                                                                                    (49)

Since the last term in (49) is always negative, the expression in (49) is negative if the
…rst line in (49) is negative. We show this in two steps.
   To start with, the hazard rate '(x)=(1        (x)) of the Normal distribution is in-
creasing, which implies that
                                                            X                               X           e
                                                    '                                   '
                                                                    X
                                                                            >                       X       e
                                                                                                                    :
                                                1                                1

Rearranging, we have

                    X                               X           e                       X           e                               X
                '               1                                               '                                   1                   >0       (50)

    De…ne
                                                                                X       e                   X
                                                                        '                           '
                                            g(X ; e)                            X                   X           e
                                                                                                                        :

If g(X ; e) < X , then combining with (50) establishes that the expression in (49) is
negative, as desired. We now show that g(X ; e) < X holds. To this end, we will show
in turn that g(X ; e) !e!0 X , and that g(X ; e) is decreasing in e.
    First,

                                    X           e                       X                               X               e
                            '                               '                       =       '0                              + O(e2 )

                                    X                       X               e           e           X
                                                                                    =       '                       + O(e2 ):

Using '0 (x) =          x'(x) for the Normal distribution, we have
                                    X       e                   X                                   X           eX
                                '                       '                                   '                       2           X
                                    X                   X           e
                                                                                !e!0            e           X
                                                                                                                            =       :
                                                                                                    '

                                                                                47
    Second,
                          (                                                )        8R X =          n                                       o      9
                                                                                    <                                                 s2
                  d           '       X        e
                                                           '       X
                                                                                 d    (X e)=
                                                                                              s exp                                   2
                                                                                                                                                ds =
                                      X                        X       e
                                                                               =      RX =
                  de                                                             de :          exp                                    s2
                                                                                                                                                ds ;
                                                                                       (X e)=                                         2

                      n                    oR                              n                o                   n                      oR                        n        o
        X   e             (X e)2                        X =                            s2                                (X e)2                  X =                 s2
    1           exp         2 2                        (X e)=
                                                                       exp             2
                                                                                                ds        exp              2 2                  (X e)=
                                                                                                                                                         s exp       2
                                                                                                                                                                              ds
=                                                                       RX =                                              2                                                        :
                                                                                                           s2
                                                                           (X      e)=
                                                                                            exp            2
                                                                                                                    ds

This expression has the same sign as
                                      Z    X =                                                   Z    X =
                      X           e                                        s2                                                              s2
                                                               exp                 ds                               s exp                           ds
                                          (X       e)=                     2                         (X     e)=                            2
                                          Z    X =
                                                                   X           e                             s2
                                  =                                                     s exp                        ds < 0:
                                           (X           e)=                                                  2
This establishes that g(X ; e) is decreasing in e, which completes the proof.
    Proof of Corollary 3
    We have dE[Wd (s)je]     0 for any X : indeed, if dE[Wd (s)je] < 0 for a given , and
considering that increasing is costless, the given level of would not be an equilibrium
for any cost of increasing informativeness (including a zero cost).
    Using (46), dE[Wd (s)je] 0 may be rewritten as

                                               X           e               X                     X                  X         e
                                      '                              '
                                                               X   e                                            X    e
                                                                                                                                  :                              (51)
                                                       '                                        1

    De…ne

                                                           X           e                    X                                 X             e
                      yN (x )                      '                               '                        1                                                    (52)


                                                                   X                        X         e                  X            e
                          yD (x )                                                                               '                               :                (53)




                                                                                   48
                      X
where x                       . Di¤erentiating yN (X ) and yD (x ) with respect to x gives

                         0                                    X           e                   X                                        X       e
                        yN (x ) =                 '0                              '0                           1


                                                              X           e                X                       X               e
                                                      '                           '                        '

                                  X           e           X           e           X               X                                        X           e
                  =                               '                           +           '                            1

                                                          X           e                    X                       X               e
                                                  '                               '                        '                               :                           (54)

 0                        X           e                       X                       X        e                       X               e                       X        X     e
yD (x ) = '0                                                                                               +'                                  '                   '

     X          e             X           e                   X                       X            e                           X           e                   X          X       e
=                   '                                                                                          +'                                  '               '                  :
                                                                                                                                                                       (55)
At any given X , (54) is larger than (55) if and only if

                               X          e               X       e               X            X                                       X       e
                                              '                               +       '                            1


                                          X           e           X           e                X                           X               e
                               >                          '                                                                                        :                   (56)

Or, for X > e,
                              X       e                   X
                      '                           '                           e     ' X                                    X                   X           e

                                          X       e
                                                                                                           <                                                           (57)
                                  '                                   X           e' X             e
                                                                                                                           1               X   e



         e     '( X       )
As                > 0 for any X > e, and because of (51), we know that (54) > (55)
             e '( X       e
     X          )
                       0         0
for any X > e, i.e., yN  (X ) > yD (X ) for any X > e.
    Using (46), we get

                               dE[W (s)je]                                            X    e               X       e                       X
                                  d
                                                                      1                            '                               '
                               @E[W (s)je]
                                                      =1                          X                    X       e               X       e
                                                                                                                                                   :                   (58)
                                  @
                                                                                                                       '

Note that the numerator and the denominator in the fraction of the RHS of (58) are

                                                                                      49
                                                             0         0
yN (x ) and yD (x ), respectively. We have shown above that yN (x ) > yD (x ) for any
x > 0. For any two given b and a such that b > a 0, we therefore have

                              yN (b)   yN (a) > yD (b)        yD (a)                          (59)

Rearranging (59) yields

                              yD (b) yD (a)   yN (b) yN (a)
                                            <                                                 (60)
                                   yN (b)          yN (b)

for any b > 21 , given that yN (x ) > 0 for x     2
                                                   1
                                                     . Setting a = 21 , (60) holds (as
b > a), and we have yN (a) = 0. In addition, we have yyDN (a)
                                                          (b)
                                                              !b!1 0, so that

                               yD (b) yD (a)      yD (b)
                                             !c!1        :                                    (61)
                                    yN (b)        yN (b)

Using (60) with yN (a) = 0, this implies that

                                           yN (b)
                                       lim               1:                                   (62)
                                       b!1 yD (b)


In addition, @E[W@ (s)je] = ' X > 0, and dE[Wd (s)je]             0 for any X , as established
                                                              yN (b)
above. It then follows from (58) that we must have            yD (b)
                                                                       1. Combining with (62)
then implies that
                                        yN (b)
                                    lim        = 1:                                           (63)
                                   b!1 yD (b)

                                                                              dE[W (s)je])
Given the de…nitions of yN (x ) and yD (x ) and (58), this establishes            d
                                                                              @E[W (s)je]    !X!0
                                                                                  @

0. The result that dE[Wd(s)je]) !X!0 0 then follows from this result and from @E[W@ (s)je] =
' X e !X !1 0.
    Given the optimal contract derived in Lemma 1, the incentive constraint in (5) for
a given X is      Z                       Z
                     1                         1
                         (s   X )f (sje)ds          (s    X )f (sj0)ds = C:
                    X                         X

As X ! 1, this equation is satis…ed if and only if C ! 0. Combining with the results
above yields (23).



                                             50
B     Informativeness Has Zero Value
This section gives an example where the value of informativeness is exactly zero. From
(16), the principal’s payo¤ is
                                                    Z    X
                              E[sje]         X +              F (sje)ds;
                                                     s


where X solves the incentive constraint (30):
                             Z   s
                                     [F (sj0)       F (sje)] ds = C:                             (64)
                               X


Let the lower bound of the support of s be s = 0 and let the upper bound be s = 2.
Suppose that, under low e¤ort, s is uniformly distributed in [0; 1] for any level of
informativeness :
                            F (sj0) = s 1 (0 s 1) :

This assumption is for concreteness only; the example can be generalized to distribu-
tions that, conditional on low e¤ort, are not functions of : F (sj0) = (s).
    Assume two possible informativeness levels: L and H . Under high informativeness,
s is uniformly distributed in [0; 2]:

                                           1            x
                                 fH (xj1) = ; FH (xj1) = :
                                           2            2
Under low informativeness, s has the following density function:
                                     8
                                         1
                                     >
                                     <   4
                                             if x      :25 or :75 x < 1
                                                3
                        fL (xj1) =                  if :25 < x < :75    :
                                     >
                                     :
                                                4
                                                    1
                                                    2
                                                       if 1 < x 2

Notice that   H   is a mean-preserving spread of              L.    Integrating, we obtain the CDF
                                     8                   x               1
                                     >
                                     >                   4
                                                             if x        4
                                     >
                                     <   1
                                         16
                                              + 34 x          1
                                                              4
                                                                    if   1
                                                                         4
                                                                             < x < 34
                        FL (xj1) =
                                     >
                                     >
                                          7
                                              + 41 x          3
                                                                    if   3
                                                                               x<1
                                     >
                                     :   16                   4          4
                                                         x
                                                         2
                                                             if x        1


                                                    51
   Suppose the parameters are such that X      1: For x 1, the CDF are the same
under both H and L so that, for X     1, the incentive constraint (64) yields:
                          Z   2
                                          s                                                       1          X2
                                   1        ds = C ) (2                        X)                   2                  =C
                           X              2                                                       2          2

                                X2
                                      X + (1        )                                          C) = 0:
                                 4
The solution to this quadratic equation is
                                                                                      p
                                                                          1                   C
                                                                    X =                           :
                                                                                  2
The relevant root is the smallest one, otherwise we can relax the incentive constraint
(64) by reducing the strike price X :
                                                                                      p
                                                                          1                   C
                                                                    X =                           ;
                                                                                  2
so the indirect e¤ect is zero (the strike price is the same for both precision levels). The
                                Rx                 Rx
direct e¤ect is also zero since 0 F H (sje)ds = 0 F L (sje)ds 8 x 1.11 Indeed, we can
calculate this expression explicitly:
                                          Z    1                           Z      1
                                                                                                   1
                                                   F H (sje)ds =                      F L (sje)ds = :
                                           0                                  0                    4

Thus, the expected wage is independent of informativeness.
  11
    This follows because, since sje has the same mean under both                                             H   and   L,   integration by parts
gives:                            Z 2               Z 2
                                      F H (sje)ds =     F L (sje)ds:
                                                    0                                 0
        R2                        R2
Thus,   1
             F   H
                     (sje)ds =    1
                                       F L (sje)ds implies that
                                                   Z    1                         Z       1
                                                            F   H
                                                                    (sje)ds =                 F L (sje)ds:
                                                    0                                 0




                                                                           52
C        Additional Results for Location-Scale Distribu-
         tions
                                                                                  b 2
Claim 1 states that, if the distribution of s has a location and scale parameter, X
(0; e).

Claim 1 Suppose the distribution of s belongs to the location-scale family. Then,
dX
      0 if X < X,b and dX        0 if X > X, b where X  b 2 (0; e). Furthermore,
 d                         d
                     b
when G is symmetric, X    e
                            .
                          2

                                           s e
Proof. Since F (sje) = G                         , condition (36) from Lemma 4 becomes
                                                      Z   X             s
                                                                  @G
                                                                            ds          0:
                                                      X       e     @

Using     =   p1   , this becomes

                                           p
                       Z   X        @G s                                    Z   X              p
                                                                                          s
                                                 ds       0 ()                           p g s         ds   0:   (65)
                       X        e     @                                     X       e   2

For a distribution symmetric about its mean of zero, this inequality holds if and only
if
                                (X     e) + X    0;                               (66)

that is, if and only if X     e
                              2
                                . Since dXd
                                             0 if (36) > 0 and dX d
                                                                        0 if (36) < 0, we
                dX                e       dX            e
conclude that d        0 if X     2
                                    , and d  0 if X     2
                                                          .
   Now consider asymmetric distributions. Since g 0, condition (65) is satis…ed for
X     0, whereas the LHS of (65) is nonpositive for X       e. In addition,
              Z    X                  p                                                           p          p
     @                           s                            X   e                                    X
                                p g s            ds       =     p g (X                       e)        p g X     (67)
    @X             X       e   2                               2                                      2

which is strictly negative for X 2 (0; e), as both terms on the RHS are negative. We
conclude that there exists a unique X ^ 2 (0; e) such that condition (36) is satis…ed if
X     ^ in which case dX
      X,                       0, whereas the LHS of (36) is nonpositive for X     e, in
                         d
            dX
which case d       0.


                                                                   53
   Under the Black-Scholes assumption that the stock price is lognormally distributed,
the vega of a stock option is highest when the option is ATM. Claim 2 shows that this
result extends to distributions with location and scale parameters.

                                                                                                               s e
Claim 2 For distributions parameterized with e and such that F (sje) = G                                             ,
the option vega is highest for an option such that X = e.

Proof. Let s be the upper bound of the support of s. By de…nition, for given e and
X    s, the vega of the associated option is
                                                                         Z   s
                        @                @
                     =    E [W (s)je] =                  s       X               F (sje) ds                     (68)
                       @                @                                    X

                                                                                                  s e
where we use (33) to derive the second equality. Since F (sje) = G                                      , we have
                           Z   s                                     Z   s
                   @                   s     e                   1           s    e       s   e
                =                  G               ds        =                        g            ds           (69)
                  @          X                                       X

                                       s e
Using the change of variable y =             gives
                                               Z   s e

                                           =                yg(y)ds                                             (70)
                                                   X    e




Given that g(y) > 0, this expression is maximized for X = e, i.e., for an ATM option.12

    Claim 3 shows that, for symmetric distributions with unbounded support, the vegas
of the option-when-working and option-when-shirking are equal for X = 2e .

Claim 3 For symmetric distributions with unbounded support parameterized by e and
  such F (sje) = G s e , the vegas of the option-when working and the option-when-
shirking are equal for X = 2e .

Proof. We rely on (70) and use the fact that, for a distribution with unbounded
support, s = 1.
  12
    With high e¤ort, e = e, so the option-when-working is ATM for X = e. With low e¤ort, e = 0,
so the option-when-shirking is ATM for X = 0.



                                                       54
       For X = 2e , the vega         e   of the option-when-working (e = e) is
                                             Z   1                           Z        1
                                     e   =                   yg(y)ds =                      yg(y)ds:                   (71)
                                                 X       e                             e
                                                                                      2



For X = 2e , the vega       0    of the option-when-shirking (e = 0) is
                                                 Z   1                       Z    1
                                         0   =               yg(y)ds =                     yg(y)ds:                    (72)
                                                     X                            e
                                                                                 2


In addition,
                        Z   1                                Z    e                         Z    1
                                                                 2
                                     yg(y)ds =                        yg(y)ds +                      yg(y)ds           (73)
                                 e                                e                              e
                                2                                2                              2

                                                                 R 2e
For a symmetric distribution, we have                                  e   yg(y)ds = 0. Equation (73) then implies
                                                                      2
that e = 0 .


D         At-The-Money Options
This Appendix shows that the model’s main results continue to hold when the principal
is restricted to granting ATM options.
    We consider the same problem described in Section 3.1, except that we assume that
the contract takes the form of ATM options. Considering ATM options requires that
we complement the model by deriving the t = 0 stock price. To simplify the exposition,
we assume that the …rm has a single share outstanding. Denoting the stock price at
time 0 by S0 , we have S0 = E[q] given the assumptions of a zero discount rate and risk
neutrality. In addition, with a symmetric distribution with location parameter e, we
have S0 = e.
    Since the strike price is …xed (at the stock price), the number n       1 of ATM
                                                            13
options granted adjusts to satisfy the incentive constraint. It follows that e = e in
equilibrium, and S0 = e. With ATM options, the exercise price is therefore X = e.
Considering the same distributions as in section 3.3, we have the following results:

                                                                                                               dn
Lemma 7 (E¤ect of volatility on number of options) With ATM options,                                           d
                                                                                                                    < 0.
  13
    We only consider the cases such that there exists an incentive compatible contract with ATM
options subject to the constraint n 1.


                                                                      55
Proof. Totally di¤erentiating the LHS of the incentive constraint in (5) with respect
to yields

 d                                            @                                                                   @                                  dn
   fE[W (s)je]    E[W (s)j0]g =                 fE[W (s)je]                          E[W (s)j0]g+                   fE[W (s)je]        E[W (s)j0]g      =0
d                                            @                                                                   @n                                  d
so that
                                               @
                                  dn          @
                                                    fE[W (s)je]                      E[W (s)j0]g
                                     =         @
                                                                                                 :                                       (74)
                                  d           @n
                                                    fE[W (s)je]                      E[W (s)j0]g
First, if the agent receives n options instead of 1, we have
                                                                         Z   1
                 E[W (s)je]                E[W (s)j0] = n                            [F (sj0)                F (sje)] ds
                                                                             X

for any given X. With distributions with a location parameter e and scale parameter
  , the numerator of the fraction on the RHS of (74) is then
                                                                             Z   1
           @                                            @                                            s                   s   e
             fE[W (s)je]               E[W (s)j0]g = n                                       G                   G                ds
          @                                            @                         X

                                   Z   1
                                               s            s            s           e           s       e
                          =n                    2
                                                    g               +            2
                                                                                         g                       ds
                                       X
                 "Z                                     Z                                        #           Z   X
                      1                                     1
            =n                yL g (yL ) ds +                       yH g (yH ) ds = n                                    yg (y) ds;
                      X                                     X   e                                                X   e



where we used the changes of variables yL = s and yH = s e . Given the symmetry of
           RX
g, we have X e yg (y) ds 0 if and only if X > X e , which is always the case with
ATM options, i.e., with X = e. We conclude that the numerator of the fraction on the
RHS of (74) is strictly positive with ATM options.
    Second, for an agent who receives n ATM options, the denominator of the fraction
on the RHS of (74) is equal to
                          Z   1                                              Z   1
                  @
                                   n(s       X)f (sje)ds                                 n(s         X)f (sj0)ds
                 @n           X                                                  X

                          Z   1                                      Z   1
                  =               (s       X)f (sje)ds                       (s              X)f (sj0)ds > 0:                            (75)
                          X                                              X

Since both the numerator and the denominator of the fraction on the RHS of (74) are

                                                                    56
strictly positive, we have
                                            dn
                                               <0                                           (76)
                                            d
with ATM options.
    If informativeness is improved (i.e. falls), n must increase to maintain incentive
compatibility. This is because X = e > 2e with ATM options: the exercise price
is higher than the threshold 2e , so that an increase in informativeness reduces e¤ort
incentives, ceteris paribus (the intuition is the same as in Section 3.3). Incentive
compatibility then requires that the agent be given additional options.
    Corollary 4 is the analogy of Corollary 1 in the main paper and compares the partial
and total e¤ects of changes in informativeness on the expected wage.

Corollary 4 (Partial and total e¤ects of informativeness on expected wage):

                                 dE[W (s)je]   @E[W (s)je]
                                             <
                                    d             @
Proof. First,
                      dE[W (s)je]   @E[W (s)je] @E[W (s)je] dn
                                  =            +
                         d             @           @n       d
Second,
                             Z   1                           Z   1
          @E[W (s)je]    @
                      =              n(s   X)f (sje)ds   =           (s   X)f (sje)ds > 0
             @n         @n   X                               X


Corollary 4 then follows from this inequality and Lemma 7.
    With ATM options, the total change in expected pay that follows a change in infor-
mativeness is smaller than the partial change: while an improvement in informativeness
lowers the value of the agent’s options, it also requires that the agent receives more
options for incentive compatibility. This incentive e¤ect partially o¤sets the bene…ts
to the principal.


E     Continuous E¤ort Model
In this section, we sketch a continuous e¤ort analog of the core model. The model
remains the same, except for the following assumptions:
   (A1) The agent chooses e¤ort in e 2 [0; 1).

                                              57
    (A2) The agent’s objective function is E[W (s)je] c (e), with c > 0, > 0; 0 >
0; 00 > 0.           n          o
                   d   fe (sje)
    (A3) MLRP: ds      f (sje)
                                  > 0, where f ( je) denotes the PDF of s conditional on e,
and fe ( je) denotes its …rst derivative with respect to e.
    (A4) E[maxfs X ; 0gje] c (e) is concave in e, and W (s) is piecewise smooth with
a right derivative, which guarantees that the …rst-order approach to the e¤ort choice
problem applies (see footnote 12 in Innes (1990)).
    As in the core model, the principal induces a given level of e¤ort e > 0. As in
Proposition 3, we consider continuously distributed symmetric and regular distributions
with a location parameter, denoted by e. This implies that we can write s = e + ",
where E ["je] = 0.
    For a given informativeness parameter , the principal’s problem is to choose a cad-
lag function W ( ) to minimize E[W (s)je] subject to the same constraints on contracting
as in the core model and the following incentive constraint:
                                  Z   1
                             d
                                          W (s)f (sje)ds = c 0 (e):                   (77)
                             de       1


Then applying Proposition 1 in Innes (1990) implies that, for a given , the optimal
contract is characterized by

                                  W (s) = max f0; s       X g:                        (78)

As in the core model, there is a unique X that satis…es the incentive constraint in (77)
with equality. Subsequent calculations require that the W (s) function be of class C 2
on the whole domain. This can be achieved by an arbitrarily small change in W (s) on
(X     u; X + u), where u ! 0, which smooths out the kink at X (Zang (1980)) while
leaving expected pay conditional on any e approximately unchanged.
    Denoting by and the PDF and CDF of the distribution of ", respectively, the
incentive constraint in (77) can be rewritten as
                             Z   1
                                      W 0 (e + ") (")d" = c 0 (e):                    (79)
                                  1


Denote by and       the PDF and CDF of ", respectively, after a decrease in . For
a distribution which is regular and symmetric, the CDFs corresponding to di¤erent

                                                58
levels of cross only once, at the mean of zero, so that (0) = (0).
    For a given exercise price, an improvement in informativeness reduces the LHS of
the incentive constraint in (77) if and only if
                          Z   1
                                  W 0 (e + ")       (")        (") d" < 0:                   (80)
                              1


Integrating by parts, this becomes
                                                Z   1
            0                           1
         W (e + ")     (")        (")    1
                                                          W 00 (e + ")   (")   (") d" < 0:   (81)
                                                    1


The …rst term is equal to zero since ( 1) = ( 1) = 0 and (1) = (1) = 1. In
addition, W 00 (s) > 0 on (X    u; X + u), and is equal to zero elsewhere. Since u ! 0
and is continuous, it follows that (81) is satis…ed if and only if (X e) > (X e).
In turn, because of single crossing of the CDFs at zero and the symmetry of , this is
satis…ed if and only if X > e.
    As in the baseline model, the LHS of the incentive constraint is strictly decreasing in
X. Therefore, for the incentive constraint to still be satis…ed following an improvement
in informativeness (i.e., a higher ), we have

                             dX
                                <0           if and only if X > e:                           (82)
                              d
Thus, as informativeness      increases, X approaches e and the option becomes closer
to ATM.




                                                59
