                              NBER WORKING PAPER SERIES




     IDENTIFICATION OF COUNTERFACTUALS IN DYNAMIC DISCRETE CHOICE
                                MODELS

                                      Myrto Kalouptsidi
                                         Paul T. Scott
                                   Eduardo Souza-Rodrigues

                                      Working Paper 21527
                              http://www.nber.org/papers/w21527


                    NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                         September 2015, Revised February 2020




Previously circulated as "Identification of Counterfactuals and Payoffs in Dynamic Discrete
Choice with an Application to Land Use." We are grateful to Victor Aguirregabiria, Ivan Canay,
Phil Haile, Bo Honore, Jakub Kastl, Yuichi Kitamura, Arthur Lewbel, Yao Luo, Rob McMillan,
Ariel Pakes, Rodrigo Pinto, John Rust, Junichi Suzuki, Elie Tamer, Ali Yurukoglu, and seminar
participants at various universities for many helpful comments. We also thank the Editor and the
anonymous referees. Charis Katsiardis and Adrian Torchiana provided excellent research
assistance. The research leading to these results has received funding from the European
Research Council under the European Community's Seventh Framework Programme Grant
Agreement no. 230589 and Agence Nationale de la Recherche Projet ANR-12-CHEX-0012-01.
All remaining errors are our own. The views expressed herein are those of the authors and do not
necessarily reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2015 by Myrto Kalouptsidi, Paul T. Scott, and Eduardo Souza-Rodrigues. All rights reserved.
Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including © notice, is given to the source.
Identification of Counterfactuals in Dynamic Discrete Choice Models
Myrto Kalouptsidi, Paul T. Scott, and Eduardo Souza-Rodrigues
NBER Working Paper No. 21527
September 2015, Revised February 2020
JEL No. C5,Q1

                                          ABSTRACT

Dynamic discrete choice (DDC) models are not identified nonparametrically, but the non-
identification of models does not necessarily imply the non-identification of counterfactuals. We
derive novel results for the identification of counterfactuals in DDC models, such as non- additive
changes in payoffs or changes to agents' choice sets. In doing so, we propose a general
framework that allows the investigation of the identification of a broad class of counterfactuals
(covering virtually any counterfactual encountered in applied work). To illustrate the results, we
consider a firm entry/exit problem numerically, as well as an empirical model of agricultural land
use. In each case, we provide examples of both identified and non-identified counterfactuals of
interest.

Myrto Kalouptsidi                                Eduardo Souza-Rodrigues
Department of Economics                          Department of Economics
Harvard University                               University of Toronto
Littauer 124                                     Max Gluskin House,
Cambridge, MA 02138                              150 St. George Street, room 324
and NBER                                         Toronto, ON, Canada
myrto@fas.harvard.edu                            edusouzarod@gmail.com

Paul T. Scott
NYU Stern School of Business
Kaufman Management Center, 7-77
New York University
New York, NY 10012
ptscott@gmail.com
1       Introduction
Since the seminal contributions of Rust (1994) and Magnac and Thesmar (2002), it is well known
that dynamic discrete choice (DDC) models are not identified nonparametrically: several payoff
functions can rationalize observed choice behavior. As a result, researchers must impose additional
restrictions to estimate DDC models, usually with the goal of performing counterfactuals. When all
models consistent with the data generate the same behavioral response in a given counterfactual,
then the counterfactual is said to be identified. In some cases, however, different models that
are consistent with the data generate different behavioral responses in a counterfactual; then, the
counterfactual is not identified. As often there is little guidance as to reasonable restrictions that
are necessary to identify the model, one may be concerned about the robustness of the empirical
findings.
    A recent body of innovative work – Aguirregabiria (2010), Aguirregabiria and Suzuki (2014),
Norets and Tang (2014), and Arcidiacono and Miller (2019) – has made valuable progress in this
area. These papers have established the identification of two important categories of counterfac-
tuals in different classes of DDC models: counterfactual behavior is identified when flow payoffs
change additively by pre-specified amounts; counterfactual behavior is generally not identified
when the state transition process changes.
    This paper builds on that body of research in three respects. First, we propose a general
framework that allows us to consider counterfactuals with non-additive changes in payoffs or with
changes to agents’ choice sets (in addition to and in combination with the cases considered in
previous studies).1 Examples include assigning the primitives of one group of agents to those
of another (e.g., assuming preferences of labor market cohorts are equal, or firm entry costs are
identical across markets) and changing payoffs proportionally (e.g., subsidies that reduce firms’
entry/sunk costs by some percentage), among others. Second, we investigate how and whether
parametric restrictions affect the non-identification of counterfactuals by considering a family of
parametric models that encompasses many studies in the literature. Third, we add to existing
results that focus on counterfactual behavior by considering the identification of counterfactual
welfare, which is often the ultimate object of interest to policy makers.
    To that end, we develop a novel approach that allows us to derive the set of necessary and
sufficient conditions to identify counterfactual behavior and welfare for a broad class of counter-
factuals. We consider counterfactuals that involve almost any change in the primitives, so our
results can be used on a case-by-case basis to investigate the identification of particular policy in-
terventions of interest. We first note that Magnac and Thesmar’s (2002) underidentification result
implies a convenient representation that directly relates counterfactual choice probabilities to a set
of “free parameters”; i.e., a subset of the payoff parameters that, if known, deliver all remaining

    1
     We consider any (simultaneous) change in all model primitives, with the exception of non-differentiable changes
in the payoff function (which are uncommon in practice).

                                                         1
unknown parameters. Based on this representation, we can determine the conditions under which
counterfactual behavior and welfare are identified. When such conditions are satisfied, it is not
necessary to identify all the individual structural parameters of the model to identify the effects
of policy interventions.2
    Our results imply that the identification of counterfactuals can be verified directly from data
on the state transition process. In some cases, identification can be determined without even
examining the data. For example, counterfactuals eliminating an action from the choice set result
in identified counterfactual behavior; counterfactuals assigning the payoff parameters from one
group of agents to another are not identified, except in special cases.3 While prior studies show
that pre-specified additive shifts in flow payoffs result in identified counterfactual behavior, we
demonstrate that all other counterfactual transformations of payoff functions are identified only
under restrictive conditions that require verification in the data.
    Given that some counterfactuals are not identified in the nonparametric setup, it is natural to
wonder whether parametric assumptions, which are prevalent in applied work, can help identify
specific sets of counterfactuals, even when the model is not fully identified. We find that they
do, assuming of course that the parametric restrictions are correctly specified. For instance, a
number of papers have implemented a counterfactual that changes the volatility or long-run mean
of market states (i.e., a change in the state transition process); while such counterfactuals are not
identified in a nonparametric setting, we show that most examples of these counterfactuals in the
literature are identified in the parametric setting.
    In addition, we consider the identification of welfare, which is often the ultimate object of
interest to policy makers (in terms of both sign and magnitude). We find that the identification
of counterfactual behavior is necessary but not sufficient for the identification of welfare. We also
provide sufficient conditions for welfare identification.
    Recognizing that static models are a special case of dynamic models, our framework can be
used to understand which counterfactuals are identified in static settings. Our results show that,
compared to dynamics, static settings do not require restrictions on state transitions for counter-
factual identification as dynamic models do. As a result, a larger set of counterfactuals is identified
in static compared to dynamic models.4
    To gain intuition and explore how sensitive counterfactuals can be to model restrictions in
practice, we turn to two applications. The first is a numerical exercise featuring a dynamic firm
entry/exit model. To identify this model, the researcher has to restrict scrap values, entry costs
or fixed costs; this is usually accomplished by fixing one of them to zero. Such an assumption

    2
      See Ichimura and Taber (2000, 2002) for direct estimation of policy impacts in the context of selection models.
    3
      Sometimes eliminating an action also eliminates states (e.g. that may reflect past actions). We also characterize
this case, providing conditions that the counterfactual state transition process (across the remaining states) must
satisfy for identification. Similarly, a counterfactual that adds an action is identified provided that the counterfactual
payoffs of the new action are a convex combination of the baseline payoffs.
    4
      We also discuss how our results can be extended to dynamic models with continuous choices; see Section 3.4.

                                                            2
is difficult to justify however as cost or scrap value data are extremely rare.5 The restrictions
can affect the parameter estimates and, for non-identified counterfactuals, alter the counterfactual
predictions as well. For instance, when fixed costs are set to zero, the estimated profit is high,
which provides the incentive to enter and stay in the market. Then, in order to match the observed
choices, estimated entry costs and scrap values must be high as well. Although the estimated
model with zero fixed costs is observationally equivalent to the true model, when we implement a
counterfactual subsidy that reduces entry costs proportionally, the predicted impact on turnover
and welfare are exaggerated in the estimated model. Specifically, as the estimated entry costs and
scrap values are magnified, it becomes profitable to enter and exit the market repeatedly under
the entry subsidy. A similar issue arises when the scrap value is set to zero instead. In this case,
the estimated entry costs must be low (or even negative) in order to rationalize observed entry:
since the scrap value is zero, entering is not as attractive to a forward-looking agent and so entry
costs must be reduced to provide incentives to enter. Applying the same subsidy again results in
incorrect counterfactual predictions (which may even go in the wrong direction).
    Next, we consider the empirical relevance of our results in the context of US agricultural
land use. Following Scott (2013), field owners decide whether to plant crops or not, and face
uncertainty (regarding commodity prices, weather shocks, government interventions, etc.) as well
as switching costs between land uses (which create dynamic incentives). To estimate the model,
Scott (2013) adopts a parametric specification and restricts the value of a subset of the switching
cost parameters. As there is little guidance in the literature concerning how to specify the particular
values, he sets them to zero. To evaluate the impact of these restrictions on counterfactual analysis,
we bring in additional data and augment Scott’s estimation strategy using land resale price data.
Similar to Kalouptsidi (2014), we treat farmland resale transaction prices as a measure of agents’
value functions. The augmented estimator allows us to test Scott’s identifying restrictions and
reject them.6
    We then implement two counterfactuals. First, we consider a long-run land use elasticity, which
measures the sensitivity of land use to a persistent change in crop returns. This elasticity is an
important input to the analysis of several policy interventions, including agricultural subsidies and
biofuel mandates (Roberts and Schlenker, 2013; Scott, 2013). The second counterfactual features
an increase in the cost of replanting crops and resembles a fertilizer tax (higher fertilizer prices
would be a likely consequence of pricing greenhouse gas emissions, as fertilizer production is very
fossil-fuel intensive). We show that while the long-run elasticity is identified, the fertilizer tax
is not. Thus, a model estimated with our augmented estimator and a model imposing Scott’s
restrictions both predict the same long-run elasticity, but they predict different responses to the
increase in fertilizer taxes (and even responses in different directions).
   5
     Using external information on entry costs and scrap values (specifically, new ship prices and demolition prices),
Kalouptsidi (2014) shows that the latter vary dramatically over states in the shipping industry.
   6
     Relating land resale price data to the model requires another set of assumptions about land markets. See
Kalouptsidi (2014) for a full discussion of these restrictions.

                                                          3
Related Literature. Our paper relates to several important prior studies. In addition to Rust’s
(1994) and Magnac and Thesmar’s (2002) seminal contributions, Heckman and Navarro (2007) con-
sider the identification of a semiparametric finite horizon optimal stopping time model that allows
for a rich time series dependence on the unobservables. Heckman, Humphries, and Veramendi
(2016) then extend the work of Heckman and Navarro (2007) by incorporating both ordered and
unordered choice sets, and by decomposing the identification of dynamic treatment effects into
direct effects and continuation values. Under a conditional independence assumption on the unob-
servables, Bajari, Chu, Nekipelov, and Park (2016) study the identification of finite-horizon models
with a terminal action, while Abbring and Daljord (2019) investigate the conditions needed to iden-
tify the discount factor. Pesendorfer and Schmidt-Dengler (2008) extend Magnac and Thesmar’s
results to dynamic games.7
    Regarding the identification of counterfactuals in DDC models, Aguirregabiria (2010) shows
identification of counterfactual choice probabilities when the experiment consists of adding a pre-
specified amount to payoffs in a finite-horizon binary choice model. Aguirregabiria and Suzuki
(2014) and Norets and Tang (2014) extend to Aguirregabiria’s (2010) result to infinite horizon
models. They both provide another important extension by showing nonidentification of behavior
under changes in transition probabilities. Arcidiacono and Miller (2019) further extend these
results to multinomial choice models for both stationary and nonstationary environments in the
presence of long and short panel data.
    We focus on infinite horizon multinomial choice models and complement the literature by (a)
providing the first full set of necessary and sufficient conditions for identification of counterfactuals
involving almost any change in the model primitives, including non-additive changes in payoffs,
(b) investigating the identification power of parametric restrictions to the basic framework, and
(c) providing identification results for counterfactual welfare. Our results extend to models with
permanent unobserved heterogeneity, provided that conditional choice probabilities and transi-
tion functions of finitely many unobserved types are identified in a first step, as in Kasahara and
Shimotsu (2009) or Hu and Shum (2012). In a companion paper (Kalouptsidi, Scott, and Souza-
Rodrigues, 2017), we consider the identification of counterfactual behavior in dynamic games.
Recently, Kalouptsidi, Kitamura, Lima, and Souza-Rodrigues (2020) extended our results to in-
vestigate partial identification of counterfactual outcomes of interest, along with uniformly valid
inference procedures based on subsampling.8


    7
      Recent work considers the identification of the distribution of the idiosyncratic shocks when agents can make
both discrete and continuous choices (Blevins, 2014), or in the presence of continuous states and exclusion restrictions
(Chen, 2017), or under linear-in-parameters payoff functions (Buchholz, Shum, and Xu, 2019).
    8
      Aguirregabiria and Suzuki (2014) provide results in the context of a monopolist entry/exit problem. In addition
to point identification, Norets and Tang (2014) relax the assumption that the distribution of the idiosyncratic
shocks is known by the econometrician and, as a consequence, obtain some partial identification results. We do
not cover partial identification as in Norets and Tang (2014), and we do not consider nonstationary settings as in
Aguirregabiria (2010) and Arcidiacono and Miller (2019).

                                                           4
    The paper is organized as follows: Section 2 presents the dynamic discrete choice framework and
reconstructs the known results on the nonparametric underidentification of standard DDC models.
Section 3 contains our main results relating to the identification of counterfactual behavior and
welfare, in both nonparametric and parametric settings. Section 4 discusses our two applications:
a numerical firm entry model and an empirical model of agricultural land use. Section 5 concludes.
The Appendix contains all mathematical proofs; and the Suplemental Material provides the details
of the dataset and the implementation of the empirical application.


2     Dynamic Framework
In each period t ∈ {1, 2, ...}, agent i chooses one action ait from the finite set A = {1, ..., A}. The
per period payoff depends on the state variables (xit , εit ), where xit is observed by the econome-
trician and εit is not. We assume xit ∈ X = {1, ..., X}, X < ∞, while εit = (ε1it , ..., εAit ) is i.i.d.
across agents and time and has joint distribution G that is absoluetly continuous with respect to
the Lebesgue measure and has full support on RA . The transition distribution function for (xit , εit )
factors as follows:
                        F (xit+1 , εit+1 |ait , xit , εit ) = F (xit+1 |ait , xit ) G (εit+1 ) .

Agents have no private information about future values of xit and εit . The per period payoff
function is given by
                                π (a, xit , εit ) = πa (xit ) + εait .

Agent i chooses a sequence of actions to maximize the expected discounted sum of current and
future payoffs. Let V (xit , εit ) denote the agent’s value function. By Bellman’s principle of opti-
mality,
                  V (xit , εit ) = max {πa (xit ) + εait + βE [V (xit+1 , εit+1 ) |a, xit ]} ,
                                      a∈A

where β ∈ [0, 1) is the discount factor. We define both the ex ante value function V (xit ) ≡
R
  V (xit , εit ) dG (εit ), and the conditional value function

                                  va (xit ) ≡ πa (xit ) + βE [V (xit+1 ) |a, xit ] .                   (1)

The agent’s optimal policy is given by the conditional choice probabilities (CCPs):
                             Z
               pa (xit ) =       1 {va (xit ) + εait ≥ vj (xit ) + εjit , for all j ∈ A} dG (εit ) ,

where 1 {·} is the indicator function. We define the vectors p (x) = [p1 (x) , ..., pA−1 (x)] and
p = [p (1) , ..., p (X)].
   It is useful to note that for any (a, x) there exists a real-valued function ψa (.) derived only



                                                          5
from G such that
                                          V (x) = va (x) + ψa (p (x)) .                                          (2)

Equation (2) states that the ex ante value function V equals the value obtained by choosing a
today and optimally thereafter (va ) plus a correction term (ψa ), because choosing action a today is
not necessarily optimal. When εit follows the extreme value distribution, ψa (p (x)) = κ − ln pa (x),
where κ is the Euler constant.9
   As we make extensive use of matrix notation below, we define the vectors πa , va , V, ψa ∈ RX ,
which stack πa (x), va (x), V (x), and ψa (p (x)), for all x ∈ X . We often use the notation ψa (p) to
emphasize the dependence of ψa on the choice probabilities p. We also define Fa as the transition
matrix with (m, n) element equal to Pr (xit+1 = xn |xit = xm , a). The payoff vector π ∈ RAX stacks
πa for all a ∈ A, and, similarly, F stacks (a vectorized version) of Fa for all a ∈ A. While we
assume a finite state space, our results can be extended to state variables with continuous support.

Nonparametric Identification of Payoffs. A dynamic discrete choice model consists of the
primitives (A, X , β, G, F, π) that generate the endogenous objects {pa , va , V, a ∈ A}. Typically,
the available data consist of agents’ actions at different states, (ait , xit ), which implies the CCPs
pa (x) and the transition F are also known. Further, we follow the literature and assume that
(β, G) is known as well.10 The objective is to identify the payoff function π. Intuitively, π has AX
parameters, and there are only (A − 1)X observed CCPs; thus there are X free payoff parameters
and X restrictions will need to be imposed (Rust, 1994; Magnac and Thesmar, 2002).
    We represent the underidentification problem as follows. For all a 6= J, where J ∈ A is some
reference action, πa can be represented as an affine transformation of πJ :

                                              πa = Aa πJ + ba (p) ,                                              (3)

where

                                        Aa = (I − βFa ) (I − βFJ )−1 ,                                           (4)
                                     ba (p) = Aa ψJ (p) − ψa (p) ,                                               (5)



    9
      Equation (2) is shown in Arcidiacono and Miller (2011, Lemma 1). It makes use of the Hotz-Miller inversion
(Hotz and Miller, 1993), which, in turn, establishes that the difference of conditional value functions is a known
function of the CCPs: va (x) − vj (x) = φaj (p (x)), where φaj (.) is again derived only from G. When εit follows the
type I extreme value distribution, φaj (p (x)) = log pa (x) − log pj (x). Chiong, Galichon, and Shum (2016) propose
a novel approach that can calculate ψa and φaj for a broad set of distributions G.
   10
      Norets and Tang (2014) have considered the problem of identifying π when G is unknown. Blevins (2014),
Chen (2017), and Buchholz, Shum, and Xu (2019) consider identification of G under different model assumptions.
Magnac and Thesmar (2002) and Abbring and Daljord (2019) investigate sufficient conditions for identification of
the discount factor. It is straightforward to combine assumptions that identify β and G with the results we present
in the current paper.

                                                         6
and I is a (comformable) identity matrix.11 In the logit model, ba (p) = ln pa − Aa ln pJ , where
ln pa is the X × 1 vector with elements ln pa (x). To simplify notation, we omit the dependence of
both Aa and ba (p) on the transition probabilities F .
    One can compute Aa and ba directly from the data (ait , xit ) for all a 6= J. Equations (3)–(5)
therefore explicitly lay out how we might estimate the payoff function if we are willing to fix the
payoffs of one action at all states a priori (e.g. πJ = 0). However, this is not the only way to obtain
identification: We simply need to add X extra restrictions. Other common possibilities involve
reducing the number of payoff function parameters to be estimated using parametric assumptions
and/or exclusions restrictions. As long as the extra assumptions add X linearly independent
restrictions to the (A − 1) X restrictions expressed by (3), π will be uniquely determined. Further,
whichever extra restrictions are imposed, they are equivalent to stipulating the payoffs of a reference
action; i.e. if πJ∗ is the vector of payoffs for the reference action identified by some set of restrictions
and (3), then that set of restrictions is equivalent to stipulating πJ = πJ∗ a priori.
    It is worth noting that in static models, where β = 0 and/or Fa = FJ for all a, J, equation (3)
simplifies to πa − πJ = ba , which becomes the standard logistic regression if the shocks ε follow
the type I extreme value distribution. As discussed later, all our results apply to static models as
well.
    For some results, it will be useful to represent (3) for all actions a 6= J as

                                                 π−J = A−J πJ + b−J ,                                        (6)

where π−J stacks πa for all a 6= J; and the matrix A−J and the vector b−J are defined similarly.
The underidentification problem is therefore represented by the free parameter πJ .

Remark 1. (Unobserved Heterogeneity.) In the presence of unobserved heterogeneity, equation (6)
holds for each unobserved type. The nature of the underidentification problem is therefore the same
after type-specific CCPs and state transitions are identified (e.g., following the strategy proposed
by Kasahara and Shimotsu (2009) or Hu and Shum (2012)).


3         Identification of Counterfactuals
This section presents our main results on the identification of counterfactuals. We begin with a
taxonomy of counterfactuals (Subsection 3.1); we then provide the necessary and sufficient con-
    11
         To see why, fix the vector πJ ∈ RX . Then,

                                πa = va − βFa V = V − ψa − βFa V = (I − βFa ) V − ψa ,
                                            −1
where for a = J, we have V = (I − βFJ ) (πJ + ψJ ). After substituting for V , we obtain the result. As an aside,
note that (I − βFJ ) is invertible because FJ is a stochastic matrix and hence the largest eigenvalue is equal or
smaller than one. The eigenvalues of (I − βFJ ) are given by 1 − βγ, where γ are the eigenvalues of FJ . Because
β < 1 and γ ≤ 1, we have 1 − βγ > 0.

                                                          7
ditions for identification of counterfactual behavior (Subsection 3.2); next, we investigate several
special cases of practical interest (Subsection 3.3); we then provide some intuition for the results,
and discuss briefly the implications for static models and continuous choice models (Subsection
3.4); we also analyze the identification of counterfactual behavior under parametric restrictions
(Subsection 3.5); finally, we investigate counterfactual welfare (Subsection 3.6).12


3.1     Taxonomy of Counterfactuals
A counterfactual is defined by the tuple {A,      e Xe, β,e G,e hs , h}. The sets Ae = {1, ..., A}
                                                                                                 e and
Xe = {1, ..., X}
              e denote the new set of actions and states respectively. The new discount factor is
β,
e and the new distribution of the idiosyncratic shocks is G.      e 13 The function hs : RA×X 2 → RA×
                                                                                                   e Xe2


transforms the transition probability F into Fe. Finally, the function h : RA×X → RA×X
                                                                                                    e e


transforms the payoff function π into the counterfactual payoff π          e, so that πe = h (π), where
h (π) ≡ [h1 (π) , ..., hAe (π)], with ha (π) = ha (π1 , ..., πA ) for each a ∈ A.e Below, we discuss a
number of special cases encountered in applied work.

Affine Payoff Counterfactuals. In affine payoff counterfactuals, the payoff π   e(a, x) at an action-
state pair (a, x) is obtained as the sum of a scalar g(a, x) and a linear combination of all baseline
payoffs, so that:
                                            e = Hπ + g,
                                            π                                                     (7)

where H ∈ RAX×AX and g is a A
                            eXe ×1 vector. It is helpful to write this in a block-matrix equivalent
           ee


form:                                                   
                              H11 H12 · · · H1A          π1        g1
                             .      .      .     .    .   . 
                       π
                       e=      .    ..     ..    ..   ..  +  ..  ,                        (8)
                             .                          
                              HA1e  HA2e  · · · HAA e    πA        gAe

where the submatrices Haj have dimension X e × X for each pair a ∈ Ae and j ∈ A.
   When the counterfactual does not change the set of actions and states (i.e. Ae = A and Xe = X ),
H is a square matrix. When, further, πea depends solely on πa , H is block-diagonal and for all
a ∈ A,
                                       π
                                       ea = Haa πa + ga .                                      (9)
  12
      For dynamic games, we can always treat the problem of solving for an individual player’s best response (holding
the opponent’s strategy fixed) as a single-agent problem. Our identification results can therefore be applied to
investigate identification of counterfactual best responses in dynamic games. A full analysis naturally requires
strategic considerations and the possibility of multiple equilibria. See Kalouptsidi, Scott, and Souza-Rodrigues
(2017) for discussion of how strategic interactions makes the identification of counterfactuals in dynamic games
particularly difficult.
   13
      As previously mentioned, the discount factor is typically assumed known. We allow however for changes in β
for completeness. When β is identified under further restrictions (Magnac and Thesmar, 2002; Abbring and Daljord,
2019), one may be interested in investigating behavior when the discount factor takes different values. For instance,
Conlon (2012) studies the evolution of the LCD TV industry when consumers are myopic in the counterfactual
experiment (i.e., βe = 0).


                                                         8
We call these “action diagonal counterfactuals.” Below, we contrast three simple special cases of
(9) that are common in applications.

    Pre-Specified Additive Changes. This counterfactual takes Haa as the identity matrix
for all a (i.e. H = I), so that π
                                ea = πa + ga . For instance, Keane and Wolpin (1997) investigate
a hypothetical college tuition subsidy. Schiraldi (2011) and Wei and Li (2014) study automobile
scrappage subsidies that depend on the car’s model and age. Duflo, Hanna, and Ryan (2012)
implement optimal bonus incentives for teachers in rural India, where the bonus depends on the
number of classes the teachers attend.
    “Pre-specified additive changes” have been considered by Aguirregabiria (2010), Aguirregabiria
and Suzuki (2014), Norets and Tang (2014), and Arcidiacono and Miller (2019). Note that g is not
allowed to depend on π, so the researcher must be able to specify g before estimating the model.
Therefore, it is not possible to represent an arbitrary counterfactual π
                                                                       e = h (π) by an “additive
changes” in practice; this would require setting g = h (π) − π. In other words, payoffs must be
changed by amounts that can be specified without estimating the model.

   Proportional Changes. In this case H is diagonal and g = 0. The counterfactual imposes
percentage changes on original payoffs, i.e. πea (x) = λa (x) πa (x). A common example involves
entry subsidies represented by percentage changes on entry/sunk costs: for instance, Das, Roberts,
and Tybout (2007) study firms’ exporting decisions; Varela (2018) studies supermarket entry; Lin
(2015) investigates entry and quality investment in the nursing home industry; and Igami (2017)
studies innovation in the hard drive industry.14

    Changes in Types. In this case, the primitives of one type of agents are replaced by those of
another, where types can be broadly defined to include markets or regions. For instance, Keane and
Wolpin (2010) replace the primitives of minorities by those of white women to investigate the racial-
gap in labor markets. Eckstein and Lifshitz (2011) substitute the preference/costs parameters of
the 1955’s cohort by those of other cohorts to study the evolution of labor market conditions.
Ryan (2012) replaces the entry costs post the Clean Air Act Amendment (CAAA) by those before
the CAAA in the cement industry. Dunne, Klimek, Roberts, and Xu (2013) substitute entry
costs in Health Professional Shortage Areas (HPSA) by those in the non-HPSA for dentists and
chiropractors.
    To represent such a counterfactual we can explicitly add a time-invariant state, denoted by s,
the type, so that the payoff is written πa (x, s). For example, if there are two types, s ∈ {s1 , s2 },




  14
      To be precise, many of these applications involve proportional changes in a component of the payoff function,
e.g., in fixed or sunk costs rather than in the whole profit function. We discuss this in Section 3.5.

                                                        9
a counterfactual in which the payoff of type s1 is replaced by that of type s2 is represented by
                                   "         # "    #"       #
                                    πea (s1 )    0 I πa (s1 )
                                              =                ,                                  (10)
                                    πea (s2 )    0 I πa (s2 )

where πa (s) ∈ RX and π
                      ea (s) ∈ RX , for each type s. Note that Haa is not diagonal in this case.
                                   e




Changes in Choice Sets and State Space. Eliminating an action j leads to Ae = A − {j}.
              e satisfies (8) with Haa = I and Hak = 0 for a ∈ Ae and k ∈ A, a 6= k. For instance,
In this case, π
if A = 3 and we drop action j = 3, (8) becomes
                                                    
                                       " # "      # π1
                                        π
                                        e1   I 0 0  
                                           =       π2  .
                                        π
                                        e2   0 I 0
                                                    π3

Rust and Phelan (1997) eliminate social security in a retirement decision model. Gilleskie (1998)
restricts access to medical care in the first days of illness. Crawford and Shum (2005) do not allow
patients to switch medications to study the impact of experimentation. Keane and Wolpin (2010)
eliminate a welfare program. Keane and Merlo (2010) eliminate the option of private jobs for
politicians who leave congress. Note that in some cases, changing the set of actions also changes
the set of states (e.g. when xt = at−1 as in many entry models).
    A counterfactual that adds a new action j can also be represented by (8): take Ae = A ∪ {j}
and let Haa = I and Hak = 0 for a 6= k, j. Note that, adding an action also requires specifying its
payoff πej , the new transition matrix Fej , the (extended) joint distribution of the unobserved shocks
G,
 e and possibly new states. Rosenzweig and Wolpin (1993), for example, add an insurance option
for farmers in rural India.

Changes in Transitions. Finally, this counterfactual is represented by a function hs that trans-
forms F to Fe; it may involve changes in the long-run mean or volatility of market-level variables.
This is the second type of counterfactual that has been considered in the literature (Aguirregabiria
and Suzuki, 2014; Norets and Tang, 2014; Arcidiacono and Miller, 2019). To give some examples
of this counterfactual, Hendel and Nevo (2006) study consumers’ long-run responsiveness to prices
using supermarket scanner data. Collard-Wexler (2013) explores the effects of demand volatility
in the ready-mix concrete industry. Kalouptsidi (2014) investigates the impact of time to build
on industry fluctuations for the case of the shipping industry. Chan, Hamilton, and Papageorge
(2016) evaluate the value, and the impact on risky behavior, of an HIV treatment breakthrough
that affects the likelihood of HIV infection.




                                                  10
3.2     Identification of Counterfactual Behavior: The General Case
We now present our main theorem, which provides a general framework to investigate identification
of counterfactual behavior; then, we turn to the special cases and provide some intuition for the
results. The starting point is equation (3). This relationship is convenient for two reasons. First,
it does not depend on continuation values. Second, the CCP vector generated by the model
primitives is the unique vector that satisfies (3).15
    The counterfactual {A,e Xe, β, e hs , h} determines a new set of primitives (A,
                                e G,                                               e Xe, β,
                                                                                         e G,
                                                                                            e Fe, π
                                                                                                  e),
with Fe = hs (F ) and π
                      e = h (π), which in turn leads to a new optimal behavior: the counterfactual
CCP, denoted by pe. The counterfactual counterpart to (3) for any a ∈ A,  e with a 6= J, is

                                            π
                                            ea = A
                                                 ea π
                                                    eJ + eba (e
                                                              p) ,                                        (11)

where

                                        Aea = (I − β            eFeJ )−1 ,
                                                     eFea )(I − β

                                                    J p) − ψ a (e
                                    eba (e
                                         p) = Aea ψ
                                                  e (e       e p) ,


the functions ψ e J and ψ
                        e a depend on the new distribution G,   e and we take without loss of generality
a reference action J that belongs to both A and A.    e
    It is clear from (3) and (11) that pe is a function of the free parameter πJ . Because the lack
of identification of the model is represented by this free parameter, the counterfactual CCP pe is
identified if and only if it does not depend on πJ . To determine whether or not this is the case,
we apply the implicit function theorem to (11).
    Before presenting the general case, we consider a binary choice example to fix ideas. Take
Ae = A, Xe = X , β   e = β, G e = G, and assume π   ea is action diagonal so that πea = ha (πa ). Take
J = 2, and rewrite (11) as
                                     h1 (π1 ) = A
                                                e1 h2 (π2 ) + eb1 (e
                                                                   p) .                            (12)

The implicit function theorem allows us to locally solve (12) with respect to pe provided the matrix

                                     ∂ h                                  i
                                          h1 (π1 ) − A
                                                     e1 h2 (π2 ) − eb1 (e
                                                                        p)
                                     ∂ pe

is invertible. We prove this matrix is indeed invertible in the general case (see Lemma 1 below).
Then, it follows from the implicit function theorem that pe does not depend on the free parameter
π2 if and only if
                               ∂ h                                 i
                                    h1 (π1 ) − A1 h2 (π2 ) − b1 (e
                                               e             e   p) = 0.
                              ∂π2

  15
     Note that a unique CCP vector p is indeed guaranteed from (3): since the Bellman is a contraction mapping,
V is unique; from (1) so are va and thus so is p.

                                                      11
Because π1 = A1 π2 + b1 (p) from (3), the above equation simplifies to

                                      ∂h1 (π1 )      e1 ∂h2 (π2 ) = 0.
                                                A1 − A                                                 (13)
                                        ∂π1               ∂π2

This equality depends on the (known) counterfactual transformation {hs , h} and on the data, F ,
through A1 and A   e1 . So, in practice, one only needs to verify whether (13) holds for the particular
combination {hs , h} of interest.
    Next, to facilitate the passage to the general case, rearrange the equality above in matrix form
as follows:                                                    " #
                                     ∂h1 (π1 )      ∂h 2 (π 2 )   A1
                                               −Ae1                  =0
                                       ∂π1            ∂π2         I
or                                               "                        #" #
                                                     ∂h1 (π)    ∂h1 (π)
                                 h           i
                                                      ∂π1        ∂π2
                                                                            A1
                                     I −A
                                        e1
                                                     ∂h2 (π)    ∂h2 (π)        = 0,
                                                      ∂π1        ∂π2
                                                                            I

where, in this example, ∂h∂π1 (π)
                               2
                                  = ∂h∂π2 (π)
                                           1
                                              = 0. Using the property of the Kronecker product
vec(ABC) = (C 0 ⊗ A)vec(B), our condition becomes:
                               h        i h     i
                                    A01 I ⊗ I −A
                                               e1 vec (∇h (π)) = 0,

                                                     ∂ha (π)
where ∇h (π) is the matrix with elements         for a, j = 1, 2. So, to identify the counterfactual
                                                      ∂πj
CCPs, vec (∇h (π)) must lie in the nullspace of a matrix determined by A1 and A     e1 .
    Now, moving from the binary to the general model, take (11) together with π     ea = ha (π) and
stack all πa for a 6= J to obtain:

                                     h−J (π) = A
                                               e−J hJ (π) + eb−J (e
                                                                  p) ,                                 (14)

where h−J (π) stacks ha (π) for all a ∈ Ae except for J, and the matrix A
                                                                        e−J and vector eb−J (e
                                                                                             p) are
defined similarly. The next lemma guarantees that the implicit function theorem can be applied
to (14).

Lemma 1. The function eb−J (.) is continuously differentiable and its Jacobian is everywhere in-
vertible.

   We state our main theorem below. vecbr (C) rearranges the blocks of matrix C into a block
column by stacking the block rows of C; the symbol  denotes the block Kronecker product.16

     16
   The block Kronecker product, , of two partitioned matrices B and C is defined by (Koning, Neudecker, and
Wansbeek, 1991):                                                   
                                              B ⊗ C11 ... B ⊗ C1b
                                   BC =         ..    ..       ..
                                                                    .
                                                                   
                                                   .       .      .
                                                     B ⊗ Cc1        ...   B ⊗ Ccb

                                                               12
Theorem 1. Consider the counterfactual transformation {A,     e Xe, β,  e hs , h} and suppose h is dif-
                                                                     e G,
ferentiable. The counterfactual conditional choice probabilities pe are identified if and only if for all
π satisfying (6),
                                        e−J ) × vecbr (∇h (π)) = 0,
                                Q(A−J , A                                                           (15)

where                                         hh         i      h      i     i
                          Q(A−J , A
                                  e−J ) =          A0−J I  I, − A0−J I  A
                                                                          e−J .

The matrix Q(A−J , A                    e − 1)XX
                   e−J ) has dimension (A     e × (A
                                                   eX)
                                                     e (AX), while vecbr (∇h (π)) has di-
mension (A e (AX) × 1.
         eX)

    Theorem 1 holds that counterfactual CCPs pe are identified if and only if the Jacobian matrix
of h is restricted to lie in the nullspace of a matrix defined by A−J and A  e−J . So model primitives,
data and counterfactual transformations have to interact with each other in a specific way to obtain
identification of counterfactual CCPs.17
    Equation (15) is the minimal set of sufficient conditions that applied researchers need to verify to
secure identification of counterfactual behavior. For instance, for “action diagonal” counterfactuals,
i.e. π
     ea = ha (πa ), equation (15) is substantially simplified: pe is identified if and only if for all π
satisfying (6) and all a ∈ A, e a 6= J,

                                               ∂ha      ea ∂hJ = 0.
                                                   Aa − A                                                          (16)
                                               ∂πa         ∂πJ

This implies that it is particularly difficult to identify counterfactual behavior when payoffs change
non-linearly, since equation (16) must be satisfied for all admissible payoffs π.18
   It is also worth noting that adding a known vector to π     e (e.g. π
                                                                       e = h(π) + g) does not affect the
Jacobian matrix of h, and so whether pe is identified or not does not depend on vector g. Similarly,
changes to the distribution of the idiosyncratic shocks G do not affect whether equation (15) holds
and so do not prevent the identification of pe.

Remark 2. (Unobserved Heterogeneity.) Theorem 1 can be extended to incorporate unobserved
heterogeneity. Following the discussion in Remark 1, we note that after finitely many type-specific
conditional choice probabilities and transition functions are identified (Kasahara and Shimotsu,
2009; Hu and Shum, 2012), equation (15) can be verified for each unobserved type.



Note that at the entry level, Kronecker rather than ordinary products are employed.
   17
      Theorem 1 requires only that h is differentiable – this is a mild restriction typically satisfied in practice.
Although the implicit function theorem involves local conditions, equation (15) must be satisfied for all payoffs
that rationalize observed choice probabilities; i.e. for all π satisfying (6). Note also that the choice of the reference
action J does not affect whether or not (15) is satisfied.
   18
      One family of counterfactuals that satisfies (16) is a class of periodic functions satisfying ∂h(By+c)
                                                                                                       ∂y    = ∂h(y)
                                                                                                                 ∂y , for
some matrix B and vector c.

                                                           13
Example: Rust’s Bus Engine Replacement Problem. Rust (1987) investigates the optimal
stopping problem of replacing a bus’s engine, trading-off aging and replacement costs. The choice
set is A = {replace, keep}; the state variable, x, is the bus mileage which evolves stochastically
and is renewed upon replacement; and the payoff function is
                                              (
                                                  −φ (x) − c (0) , if a = replace
                                 π (a, x) =
                                                     −c (x) ,       if a = keep

where φ (x) is the cost of replacing an engine and c (x) is the operating cost at mileage x. In
principle, replacement costs may reflect labor costs of rebuilding an old engine, or the price of a
new engine minus scrap values that may depend on the old engine’s resale prices. In both cases
replacement costs may potentially vary with the mileage on the (old) engine. To identify the model,
Rust (1987) adopts an exclusion restriction (i.e. state-invariant replacement costs φ(x) = φ) and
sets operating cost at x = 0 to zero (i.e. c (0) = 0). This is sufficient to identify payoffs.
    In the counterfactual analysis, Rust varies the level of replacement costs and obtains the
corresponding (long run) replacement choice probabilities, or a demand curve for engine re-
placement. One way to represent his counterfactual is to consider counterfactual payoffs as
e (replace, x) = − (1 + λ) φ (x) − c (0), for various levels of λ, where λ is a parameter captur-
π
ing the shift in replacement costs. Equivalently,

                      e (replace, x) = π (replace, x) + λ (π (replace, x) − π (keep, 0)) .
                      π

Each value of λ corresponds to one point along the demand curve for engine replacement. This
representation is appropriate, for instance, if replacement costs depend on labor costs and the
counterfactual of interest involves increasing wages. Note that the counterfactual does not affect
π (keep, x), nor β or F . In Appendix A, we show that Theorem 1 implies that this counterfactual
is not identified. Showing this for a particular specification requires only a simple calculation
evaluating equation (15).19

    Interpreted this way, Rust’s counterfactual falls within the class of affine payoff transformations,
a class of counterfactuals for which equation (15) is simplified. As we show below, we can derive
more intuitive conditions for the identification of such counterfactuals.
   19
                  e = Hπ, where H is not block-diagonal:
        Formally, π
                                                                      
                                                   (1 + λ) I   [−λ1, 0]
                                             H=                          ,
                                                       0          I

where I is the identity matrix and 1 is a vector of ones. To evaluate equation (15), consider a simple version of
the model in which a = replace, J = keep, and where the state space is simply X = {new, old} with deterministic
                           e−J ) = [Areplace ⊗ I, I ⊗ I, A0
transitions. Then Q(A−J , A                               replace ⊗ Areplace , I ⊗ Areplace ]. Finally, with β = .99 and
λ = 0.1 (representing a 10% increase in replacement costs), we obtain kQ(A−J , A    e−J )vec (∇h (π)) k = 1.89, where
k.k is the matrix 2-norm. Equation (15) is violated, implying the counterfactual is not identified.

                                                          14
3.3    Identification of Counterfactual Behavior: Special Cases
In this section, we discuss several special cases of interest following the taxonomy presented in
Section 3.1. Corollary 1 shows how the conditions of Theorem 1 simplify when the payoff trans-
                                                    P
                                 e = Hπ + g, or π
formation h (·) is affine, i.e., π              ea = j∈A Haj πj + ga . The affine case is prevalent in
applied work.

Corollary 1. (“Affine Payoff ” Counterfactual) Assume π     e = Hπ + g.
(i) The counterfactual CCP pe is identified if and only if for all a ∈ A,
                                                                       e a 6= J,

                             X                    
                                       Hal − A
                                             ea HJl Al + HaJ − A
                                                               ea HJJ = 0.                           (17)
                            l∈A,l6=J


(ii) Further, if the counterfactual is “action diagonal,” π
                                                          ea = Haa πa + ga , equation (17) becomes,
for all a ∈ A,
            e
                                        Haa Aa − Aea HJJ = 0.                                  (18)

    Recalling that Aa = (I − βFa ) (I − βFJ )−1 , and noting that the transition matrices Fa can be
estimated, it is clear that conditions (17) and (18) can be easily verified from the data. The next
set of results make direct use of Corollary 1.

Changes in Payoffs. We now consider counterfactuals that only change agents’ payoff func-
tions, holding fixed the remaining primitives. As already mentioned, previous work has shown that
one particular case here yields identified counterfactual behavior: “pre-specified additive changes,”
which are of the form πe (a, x) = π (a, x)+g (a, x) (Aguirregabiria, 2010; Aguirregabiria and Suzuki,
2014). Norets and Tang (2014) also proved identification when π      e = λπ + g, where λ is a scalar.
The identification of pe for this class of counterfactuals is an immediate implication of Corollary 1.
Note that in this case, we have Haa = λI for all a, and so equation (18) is clearly satisfied.
    Following the taxonomy, we now consider “proportional changes” counterfactuals. For this
class, recall that we take πea (x) = λa (x) πa (x), or, compactly, π
                                                                   ea = Haa πa , with Haa diagonal.

Proposition 1. (“Proportional Changes”) Consider π          ea = Haa πa with Haa diagonal. Assume
Ae = A, Xe = X , β   e = β, G e = G, and Fe = F . Then, to identify pe it is necessary that Haa = Hjj ,
for all a, j ∈ A.
    Assume the matrices Haa are identical for all a, and denote them by H. Suppose further that H
has d distinct diagonal elements λ1 , ..., λd , each occurring n1 , ..., nd times so that H can be written
as H = diag(λ1 In1 , ..., λd Ind ). The following statements are equivalent:
(i) pe is identified.
(ii) Aa is block diagonal with diagonal blocks, (Aa )i , of comformable sizes n1 , ..., nd .
(iii) Let (Fa )ij be the ni × nj submatrix of Fa that comforms with H = diag(λ1 In1 , ..., λd Ind ). For



                                                   15
all a ∈ A and i 6= j, the block partitions of Fa and FJ satisfy

                                              (Fa )ij = (Aa )i (FJ )ij ,                                          (19)

where (Aa )i ≡ (I − β(Fa )ii )(I − β(FJ )ii )−1 .
     The necessary conditions to identify pe in the case of “proportional changes” are restrictive.
For one, if we change the payoff of action a in state x by λ (x), π  e (a, x) = λ (x) π (a, x), then it
is necessary to change the payoff of any other action a in state x by exactly the same proportion
λ (x). Furthermore, identification requires special conditions on the Aa matrices (part ii), which are
equivalent to special conditions on the transition process F (part iii). In particular, an implication
of the proposition is that, if all diagonal elements of H are pairwise distinct, then identification
of pe requires Fa = FJ for all a ∈ A. This condition however will not be satisfied in any dynamic
model of interest.20
     Another set of payoff counterfactuals is the “changes in types.” We prove the following propo-
sition for two types and two actions for notational simplicity; the extension to multiple types and
actions is straightforward.
Proposition 2. (“Changes in Types”) Suppose the payoff is πa (x, s), where s is a time-invariant
state (type) that takes two values, s ∈ {s1 , s2 }, and that there are two actions A = {a, J}. Suppose
also that Ae = A, Xe = X , βe = β, Ge = G, and Fe = F .
(i) If the counterfactual replaces the payoff of type s1 by that of s2 for one of the actions, then pe
is not identified.
(ii) If the counterfactual replaces the payoff s1 by that of s2 for all actions, then pe is identified if
and only if (I − βFas1 )(I − βFJs1 )−1 = (I − βFas2 )(I − βFJs2 )−1 , where Fas is the transition matrix
corresponding to type s.
    Proposition 2 results in nonidentification if payoffs of a subset of actions are replaced; and
requires strong restrictions on transition probabilities if payoffs at all actions are replaced (much
like the “proportional changes” case). It is worth noting that if the types have the same transitions
(Fas1 = Fas2 ), the condition is satisfied and the counterfactual is identified.
    Proposition 1 and 2 express specific and verifiable restrictions on the transition process that
must hold for the identification of counterfactual behavior. A natural question then is whether
some transformations of payoffs – and which – can be said to be identified for any transition
process. In other words, when can we say a counterfactual transformation of payoffs is identified
without having to estimate or specify the specific transition process? In such a case, the researcher
can establish identification ex ante, regardless of the data at hand. Our next result holds that only
a limited set of payoff transformations can be said to be identified without verifying the restrictions
on the transition process.
   20
    In general, if a diagonal element of H is unique, i.e. ni = 1 for some i, identification requires that the i-row of
Fa and FJ are identical. That is, conditional on state xi , the transition probabilities do not depend on the action.

                                                          16
Proposition 3. Assume Ae = A, Xe = X , β       e = β, Ge = G, Fe = F , and πe = Hπ +g. Counterfactual
behavior pe is identified without restrictions on the transition process F (i.e., counterfactual behavior
is identified for every transition F ) if and only if
(i) H = H1 + H2 , where H1 = λI, λ is a scalar, and H2 has identical rows;
(ii) or, equivalently, the transformation of payoffs can be expressed in the following form for all
a ∈ A and x ∈ X :
                                     π
                                     ea (x) = λπa (x) + L (π) + ga (x) ,                             (20)
                                                                  P      P
where L (·) is the scalar-valued function given by L (π) = j∈A x∈X ρjx πj (x), and the vector
[ρ11 , ..., ρAX ] corresponds to one row of H2 .21

   Equation (20) shows that only the following changes are identified regardless of the transition
process:

   1. Pre-specified additive changes ga (x) which may depend arbitrarily on actions and states but
      does not depend on the baseline payoff function.

   2. Multiplication of baseline payoffs by a scalar λ, which does not depend on actions or states.
      For λ > 0, this resembles a change in the scale of the payoff function.22

   3. Addition of a scalar-valued function L (π), which does not depend on actions or states. This
      corresponds to a change in the level of the payoff function.23

Proposition 3 states that the only meaningful counterfactual transformations of payoffs that can be
said to be identified with no restrictions on the state transition process are (1) pre-specified additive
changes and (2) changes in the level and scale of the payoff function. As described above, different
versions of the “if” direction of Proposition 3 have been proved in the literature. Our result shows
that any other counterfactual transformations of payoffs are identified only under restrictions
on the state transition processes that require verification in the data. Theorem 1 provides the
conditions the transition process must satisfy most generally; Corollary 1 and Propositions 1 and
2 provide simpler conditions for certain classes of payoff transformations.

Changes in Choice Sets and State Space. Following the taxonomy, we now consider a
counterfactual that adds an option to agent’s choice set. This counterfactual naturally requires
pre-specifying π
               ej and Fej for the new choice j (as well as the joint distribution of the idiosyncratic
shocks G).
       e
   21
      To connect parts (i) and (ii), note that π  e = Hπ + g = H1 π + H2 π + g, and that H2 π is a constant vector
because H2 has identical rows. So, H2 π corresponds to L (π) 1, where 1 is a vector of ones.
   22
      Strictly speaking, multiplication of π by a positive scalar is not equivalent to a scale normalization of the whole
utility function, π + ε, because the distribution of the idiosyncratic shocks ε is fixed. More formally, π    e = λπ for
λ > 0 is equivalent to multiplying the variance of the idiosyncratic shocks by λ−2 .
   23
      Note that a shift in the level of payoffs by the same number L for every action and state does not affect agents’
incentives.

                                                           17
Proposition 4. (“Add an Action” Counterfactual) Suppose Ae = A ∪ {j}, where j is the new
action. Assume Xe = X , β               ea = πa for all a ∈ A, and
                        e = β, Fe = F , π

                                                       X
                                                π
                                                ej =         Hja πa + gj .
                                                       a∈A

                                                                                      P
Let 1 be an X × 1 vector of ones. Then pe is identified if and only if                    a∈A   Hja 1 = 1, and
                                                                                !
                                          X                             X
                                                              −1
                                  Fej =         Hja Fa + β         I−         Hja .
                                          a∈A                           a∈A


    In words, to obtain identification it is necessary that the payoff of the new action j is a “convex
combination” of existing payoffs, and the new transition matrix is an “affine” combination of
existing transitions. This is reminiscent of predicting consumers’ choices when a new good is
introduced in a static differentiated product demand framework. Predicting the demand for the
new good requires that the attributes of the new good are a combination of the attributes of
existing goods in the market. The same applies in the dynamic context; here we additionally need
restrictions on the transitions in order to predict behavior when a new choice is available.
    Consider next a counterfactual that eliminates one action (extensions to eliminating more
actions are straightforward).
Proposition 5. (“Eliminate an Action” Counterfactual) Suppose Ae = A − {j}, where j is the
action to be eliminated. If Xe = X , β                     ea = πa for all a ∈ A,
                                     e = β, Fea = Fa , and π                   e then pe is identified.

    Here, the key to identification is that transitions do not change.24 However, elimination of an
action often implies elimination of some states as well (e.g. when xt = at−1 as in many entry
models), which necessarily changes transitions. In that case, identification depends on how the
probability mass is reallocated from X into the remainder set of states Xe. Lemma A2 in Appendix
A provides the necessary and sufficient conditions for identification in this case. Below, we consider
a special case that is common in applied work. Decompose the state variables as x = (k, w), where
kt = at−1 , and w is an exogenous state (i.e., its evolution does not depend on choices a). Formally,
Fa = F w ⊗Fak , where F w is the transition matrix for w, Fak is the transition for k, and ⊗ denotes the
Kronecker product. The firm entry/exit problem presented in Section 4 satisfies these restrictions.
The counterfactual CCP is indeed identified in this case.
Proposition 6. (“Eliminate an Action and States” Counterfactual) Suppose Ae = A − {j}, where
j is the action to be eliminated. Without loss of generality, let the set of states be Xe = {1, ..., x}
and X = {1, ..., x, x + 1, ..., X}. Assume π
                                           ea = Haa πa with Haa = [Ix , 0] for all a ∈ A,
                                                                                        e where Ix is
the x × x identity matrix. Suppose x = (w, k) with transition matrix Fa = F w ⊗ Fak and kt = at−1 .
Then, the counterfactual CCP pe is identified.
  24
    Note that eliminating action j is not equivalent to a pre-specified additive change with gj = −∞ because the
Blackwell sufficient conditions for a contraction are not satisfied in the corresponding Bellman equation.

                                                             18
Changes in Transitions. For completeness, we mention briefly another existing result, first
proven by Aguirregabiria and Suzuki (2014) and Norets and Tang (2014), regarding counterfac-
tuals that only change the state transitions. Specifically, when the only primitive that changes
in the counterfactual is the transition process, Fe 6= F , then counterfactual behavior is identified
only under restrictive conditions on these transitions. In our notation, the necessary and sufficient
condition is Aa = A                    e a 6= J.25 In Section 3.5, we discuss how (correctly speci-
                     ea , for all a ∈ A,
fied) parametric assumptions on the payoff function can lead to less restrictive requirements on
transitions for the identification of this class of counterfactuals.


3.4     Some Intuition
Intuitively, the reason payoffs are not identified in a DDC model is twofold. First, although we can
identify the difference in continuation values va − vJ from the observed choice probabilities (Hotz
and Miller, 1993), the discrete choice nature of the data does not allow us to separate va from vJ .
(This feature is shared by static discrete choice models as well.) Second, we also cannot separate
the two components of va (x) nonparametrically, i.e. π (a, x) and E [V (x0 ) |a, x], since they both
depend on the same arguments.
    To obtain some intuition for why some counterfactuals are identified while others are not, take
a simple example of a binary choice, A = {a, J} and consider the counterfactual π   ea = Haa πa + ga ,
for all a, with A = A, X = X , β = β, and G = G. Next, note that by rearranging our main
                  e        e        e             e
equation (3), we obtain

                        (I − βFa )−1 πa − (I − βFJ )−1 πJ = (I − βFa )−1 ba (p) .

The left-hand side is the difference of the expected discounted present value obtained by always
choosing a versus always choosing J. This difference is known, as the right-hand side is known.
   For the counterfactual scenario, rearrange the equivalent counterfactual equation (11) as above.
Assuming the counterfactual is identified (i.e., Haa Aa = A
                                                          ea HJJ ), it is easy to show that


              Haa (I − βFa ) (I − βFa )−1 πa − (I − βFJ )−1 πJ + (ga − A
                                                             
                                                                       ea gJ ) = eba (e
                                                                                      p) .

In words, the counterfactual CCP pe depends on π only through the difference in present values:
(I − βFa )−1 πa − (I − βFJ )−1 πJ . All other terms of the left-hand side, as well as the function eba ,
are known. So, to calculate pe, it is not necessary to identify the payoff function π.
    To make the argument more transparent, consider the “additive changes” counterfactual.
The left-hand side now becomes the sum of two terms: (I − βFa )−1 πa − (I − βFJ )−1 πJ and

  25
     That is an implication of equation (18) in Corollary 1. Note that identification of a counterfactual that
                                  e 6= β, requires the same condition: Aa = A
only changes the discount factor, β                                         ea , for all a 6= J, but with A
                                                                                                          ea =
(I − βF        e J )−1 .
     e a )(I − βF


                                                     19
(I − βFa )−1 ga −(I − βFJ )−1 gJ . Both terms are known and thus the change in the choice probabil-
ities is also known. There is no need to re-optimize agents’ dynamic behavior in the counterfactual
                                                                           eFea )−1 π
scenario. This is possible only because the counterfactual difference (I − β                  eFeJ )−1 π
                                                                                    ea − (I − β        eJ
                                                           −1                −1
is a known function of the observed difference (I − βFa ) πa − (I − βFJ ) πJ .
    When the equality Haa Aa = A    ea HJJ is not satisfied, the counterfactual difference in contin-
uation values depends directly on π. It is no longer sufficient to know the observed differences
(I − βFa )−1 πa − (I − βFJ )−1 πJ and therefore we cannot identify the counterfactual behavior. At
least not without additional restrictions.
    Before investigating the role of additional restrictions in the next section, we discuss briefly
some implications for static discrete choice models and dynamic models with continuous choices.

Remark 3. (Static vs Dynamic Models.) Our framework can be used to understand which coun-
terfactuals are identified in a static setting, and how that compares to dynamic problems. To be
precise, a static model can be characterized by either agents being myopic (i.e., β = 0), or by state
transitions not affected by agents’ choices (i.e., Fa = FJ , for all a), or both. In such cases, it is
clear from the discussion above that counterfactual behavior is identified when it depends on π only
through the difference πa − πJ . This is intuitive as static models can only recover differences in
flow payoffs from the data. Counterfactual behavior is not identified when it depends directly on
π, i.e., when payoff levels matter.
    An alternative way to see this is to note that when β = 0 or Fa = FJ hold for all a, both in
the baseline and in the counterfactual scenarios, then Aa = A     ea = I, for all a. This implies that
condition (18) in Corollary 1 simplifies to Haa = HJJ , for all a. This in turn means that the
“additive changes,” the “eliminating actions,” and the “changes in transitions” counterfactuals
are all identified: equation (18) is satisfied trivially in all these cases (since Haa = I for all a).
On the other hand, “proportional changes” and “adding actions” are counterfactuals that are not
trivially identified. Much like in dynamic models, “proportional changes” are not identified when
we multiply different payoffs by different amounts; “adding actions” is not identified when the
payoff of the new action is not a convex combination of the payoffs of existing choices. That is
because payoff levels matter for both cases. In contrast to dynamic models though, while these two
counterfactuals require restrictions in how payoffs are changed, they do not demand restrictions
on state transitions for identification.26 In sum, not all counterfactuals of interest are identified
in static models, but they demand fewer restrictions for identification when compared to dynamic
models and so a larger number of cases are identified in static models.

Remark 4. (Discrete vs Continuous Choices.) While we do not investigate formally the identifi-
cation of counterfactuals for dynamic models with continuous choices, our approach suggests that
the same issues apply to that class of models. Intuitively, just like in a discrete choice setting,
  26
     In static models, “proportional changes” satisfy condition (ii) in Proposition 1 trivially, and “adding actions”
does not require the new state transition to be a combination of existing state transitions (see Proposition 4).

                                                         20
where the econometrician can only recover differences in payoffs, in a continuous choice setting,
we can only recover the derivative of payoffs. Consistent with this, Blevins (2014) has shown that
nonparametric identification of dynamic models with continuous actions and states requires loca-
tion restrictions on flow payoffs (in the same manner as in the class of nonseparable models studied
by Matzkin (2003)). When cardinal properties of the payoff function matter for the counterfactual,
location restrictions necessary to identify the model may prevent the identification of counterfactual
behavior, even when actions and states are continuous.27


3.5     Identification of Counterfactual Behavior Under Parametric Re-
        strictions
More often than not, applied work relies on parametric restrictions. We thus consider identification
of counterfactuals under a specific parametric model that encompasses many applied models in
the literature.
    We decompose the state space into two components, x = (k, w), where k ∈ K = {1, ..., K} are
controlled states (i.e. their evolution is affected by agents’ choices), and w ∈ W = {1, ..., W } are
exogenous (e.g. market-level states), with K and W finite. Therefore,

                                     F (x0 |a, x) = F k (k 0 |a, k) F w (w0 |w) .                               (21)

and the transition matrix Fa is written as Fa = F w ⊗ Fak , where ⊗ denotes the Kronecker product.
In addition, we assume the following parametric payoff is true:

                                   π(a, k, w) = θ0 (a, k) + Z(a, w)0 θ1 (a, k),                                 (22)

where Z (a, w) is a known function of actions and states w (e.g. observed measures of variable
profits or returns) and θ0 (a, k) is interpreted as a fixed cost component. For instance, in the firm
entry/exit problem considered in Section 4.1, Z(a, w)0 θ1 (a, k) represents variable profits which may
be either directly observed or a flexible function of observables such as market size and input prices,
while θ0 (a, k) denotes entry/exit/fixed cost depending on the action and state.
   Proposition 7 provides sufficient conditions for the identification of this parametric model. For
notational simplicity, we focus on a binary choice with A = {a, J} and assume Z (a, w) is scalar.
The proposition also holds in the more general case of F w (w0 |w, a) and multivariate Z (a, w).




  27
     Furthermore, Blevins (2014) shows in his Theorem 2 that π is nonparametrically identified only in the region in
which unobservable shocks ε are compatible with optimal choices. The fact that π is not identified nonparametrically
for all possible realizations of ε limits possible extrapolations and poses additional difficulties to counterfactual
identification. Identifying π everywhere requires further restrictions on payoffs (see, e.g., his Theorem 3).

                                                         21
Proposition 7. Assume (21) and (22) hold. Let

                                       Da = (I − βFa )−1 ,
                                       Za = [Za (1)Ik , ..., Za (W )Ik ]0 ,

and similarly for DJ and ZJ . Ik is the identity matrix of size K and e0w = [0, 0, ..., Ik , 0, ...0] with
Ik in the w position. Suppose W ≥ 3 and there exist w, w,e w such that the matrix
                                   "                                             #
                                       (e0w − e0we ) Da Za (e0we − e0w ) DJ ZJ
                                                                                                          (23)
                                       (e0w − ew0
                                                   ) Da Za (e0w − e0w ) DJ ZJ

is invertible. Then the true parameters [θ1 (a, k) , θ1 (J, k)] are identified, but [θ0 (a, k) , θ0 (J, k)] are
not identified.

    Intuitively, the “slope” coefficients θ1 are identified provided there is “sufficient variation”
in w (guaranteed by the invertibility of matrix (23)). This requires w to significantly change
the conditional expected values of Za and ZJ (naturally, it is necessary that Za 6= ZJ ).28 The
“intercept” parameters θ0 , however, are not identified. To identify this vector, we have to add K
linearly independent restrictions to the model, much as we have to impose X linearly independent
restrictions in the nonparametric setting.

Counterfactuals. In addition to the counterfactuals discussed in Section 3.1, one may be inter-
ested in changes in either θ0 , i.e.:

                              e(a, k, w) = h0 [θ0 (a, k)] + Z (a, w)0 θ1 (a, k) ;
                              π                                                                           (24)

or in Z 0 θ1 , i.e.:
                             e(a, k, w) = θ0 (a, k) + h1 Z (a, w)0 θ1 (a, k) .
                                                                           
                             π                                                                            (25)

These counterfactuals allow for changes in how the flow payoff responds to some state (k, w), or
to the outcome variable Z.
     We show that transformations in Z 0 θ1 result in identified counterfactuals, while transforma-
tions in θ0 (a, k) may not. Indeed, since θ1 (a, k) is identified, a counterfactual that changes Z 0 θ1
resembles a “pre-specified additive change,” which is an identified counterfactual (see Section 3.3).
In contrast, since θ0 (a, k) is not identified, one needs to follow our analysis of counterfactuals for
nonparametric payoffs to establish whether a particular counterfactual is identified or not.
     To illustrate, we consider affine action-diagonal counterfactuals as an example. In particular,
let:
                                           eθ0 (a) = H0 (a)θ0 (a)                                 (26)
   28
      Note that e0w Da Za is the expected discounted value of Z when action a is always chosen conditional on
observing state w today.

                                                         22
for a = 1, ..., J, θ0 (a) is obtained by stacking θ0 (a, k) for all k, and H0 (a) is a K × K matrix.
Extending to a more general (differentiable) function of θ0 is straightforward.

Proposition 8. (Parametric Model) Assume Ae = A, Xe = X , β        e = β, and that the conditions of
Proposition 7 hold.
    (i) pe is identified when the counterfactual only changes the term Z(a, w)0 θ1 (a, k) of π(a, k, w)
as in (25).
    (ii) pe is identified under the affine action diagonal counterfactual (26) if and only if for all
a 6= J
                                        H0 (a)Aka − Aka H0 (J) = 0

where Aka = (I − βFak )(I − βFJk )−1 .
     (iii) pe is identified when the counterfactual only changes the transition Fak if and only if Aka =
eka , a 6= J, where A
A                      eka = (I − β Feak )(I − β Fek )−1 .
                                                   J
     (iv) pe is identified when the counterfactual changes the transition F w .

    In a nonparametric setting, changes in the transition process generically result in non-identified
counterfactual behavior (in the sense that the necessary conditions are bound to be restrictive).
However, Proposition 8 shows that the intuition from the nonparametric setting does not nec-
essarily carry over to parametric models. When a counterfactual changes the transition process
for state variables that are part of the identified component of the payoff function, counterfactual
behavior is identified. For instance, the response to a change in the volatility of demand shocks
in the firm entry/exit example is identified. Even though Aguirregabiria and Suzuki (2014) and
Norets and Tang (2014) have explored changes in transitions in the nonparametric context, most
implementations of these counterfactuals in practice are done in the parametric context (Hendel
and Nevo, 2006; Collard-Wexler, 2013) and so based on our results, are in fact identified if the
parametric model is correctly specified.


3.6    Identification of Counterfactual Welfare
In this section, we discuss the identification of counterfactual welfare and provide the minimal set
of sufficient conditions for identification. For simplicity, we only consider affine action-diagonal
counterfactuals; i.e. Ae = A, Xe = X , β   e = β, and π ea = Haa πa + ga , all a. Extensions to more
general cases are straightforward, but at the cost of substantially more cumbersome notation. The
feature of interest here is the value function difference ∆V = Ve − V , where Ve is the counterfactual
value function.

Proposition 9. (Welfare) Assume Ae = A, Xe = X , β      e = β, and π
                                                                   ea = Haa πa + ga , for all a. The
welfare difference ∆V is identified if, for all a 6= J,

                                        Haa Aa − A
                                                 ea HJJ = 0,

                                                  23
and
                                    HJJ = (I − β FeJ ) (I − βFJ )−1 .                                (27)

    Proposition 9 shows that identification of pe (which is implied by the proposition’s first condition)
is not sufficient to identify ∆V ; we also need (27). The second condition is satisfied, for instance,
when the counterfactual transformation does not affect option J: HJJ = I and FeJ = FJ . For
“proportional changes” counterfactuals the two conditions are satisfied only when all matrices Haa
equal the identity matrix; i.e. πe = π, which is equivalent to saying that ∆V is not identified. On
a positive note, an immediate implication of Proposition 9 is that the welfare impact of “additive
changes” is identified. Therefore, “additive changes” are robust to nonidentification of the model
primitives: both pe and ∆V are identified.29
    Finally, the next corollary considers identification of ∆V for the parametric model of Section
3.5. As expected, identification is guaranteed when counterfactuals change Z 0 θ1 and/or F w .

Corollary 2. (Welfare, Parametric Model) Assume the conditions of Proposition 7 hold. Suppose
Ae = A, Xe = X , β
                 e = β, and e
                            θ0 (a) = H0 (a)θ0 (a). The welfare difference ∆V is identified if, for all
a 6= J,
                                    H0 (a)Aka − A eka H0 (J) = 0,

and
                                   H0 (J) = (I − β FeJk )(I − βFJk )−1 .

Furthermore, if H0 (a) = I and Feak = Fak for all a, then ∆V is identified for any counterfactual
transformation on Z(a, w)0 θ1 (a, k) and F w .


4        Applied Examples
4.1      Numerical Example: Firm Entry and Exit Problem
This section illustrates some of our theoretical results using a firm entry/exit problem; the model
adopts the parameterization of Section 3.5 and has been commonly used in the literature (Das,
Roberts, and Tybout, 2007; Aguirregabiria and Suzuki, 2014; Lin, 2015; Igami, 2017; Varela, 2018).
Consider a firm deciding between two actions: whether to be active (a = 1) or inactive (a = 0) in
a market, so that A = {0, 1}. Let the state variables be x = (k, w), where k is the lagged chosen
action, and w is an exogenous shock determining variable operating profits, π(w). The flow payoff
is                              (
                                            k × sv              if a = 0 (inactive)
                  π (a, k, w) =
                                  k (π (w) − f c) − (1 − k) ec, if a = 1 (active)

    29
     Proposition 9 is an immediate consequence of Lemma A5 in the Appendix, which provides the full set of
necessary and sufficient conditions to identify ∆V .

                                                    24
where sv is the scrap value, f c is the fixed cost, and ec is the entry cost.30 Note that the payoff
when a = 0 and k = 0 (i.e. when the firm was and remains inactive) is set equal to zero.
    We assume that w follows a first-order Markov process, and can take three values: high, medium
or low, w ∈ {wH , wM , wL }. Variable profits π (w) are determined by static profit maximization.
We assume the econometrician knows (or estimates): (a) the true CCP, Pr (active|k, w); (b) the
transition Pr (wt+1 |wt ); and (c) the variable profits π (w), which can be recovered “offline,” using
price and quantity data.31
    First, we solve the true model, obtain the baseline CCP, and recover π. Typically, researchers
identify the model by setting either sv = 0 or f c = 0. As previously discussed, there is little
guidance to justify these assumptions because cost or scrap value data are extremely rare (e.g.,
see Kalouptsidi, 2014). We estimate the model twice to compare the different sets of restrictions.
Under the first restriction that scrap values are equal to zero (sv = 0), identification of π follows
directly from equation (3), πa = Aa πJ +ba (p): in this case, note that the payoff πJ for J = inactive
is equal to zero for all states (k, w) and thus (3) directly delivers πa for a = active. Under the
alternative restriction that fixed costs are equal to zero (f c = 0), we can recover the remaining
elements of π by adding π(active, 1, w) = π (w) to the system described by (3).
    Table 1 presents the true and the two estimated payoff functions. Note that under the first
restriction (sv = 0) the estimated entry costs have the wrong sign. This is because if there is
no scrap value gained upon exiting, entering the market becomes less attractive and entry costs
must become low (in fact, negative) to explain the observed entry patterns. Under the second
restriction (f c = 0), both the estimated entry costs and scrap values are considerably larger than
their true values. To see why, consider an active firm (k = 1). Fixing f c = 0 implies higher profits
when active, which gives incentives to stay more often in the market. Therefore, the estimated
scrap value must increase in order to provide incentives to exit and match the observed exit rate.
Similarly, when the firm is out (k = 0), increasing profits when active provides incentives to enter.
Entry costs must then increase to compensate for this incentive and explain the observed entry
rate.
    Next, given the recovered payoffs, we implement four counterfactuals and compare the true

   30
      The model falls within the parametric framework of Section 3.5, with θ0 (0, 0) = 0, θ0 (1, 0) = −ec, θ0 (0, 1) = sv,
and θ0 (1, 1) = −f c. Variable profits, π (w), are assumed known/estimated outside of the dynamic problem using
price and quantity data, one may then take Z (a, w) = π (w) and θ1 (a, k) = 1. Alternatively, one might assume a
reduced form profit function π (w) = w0 γ, in which Z (a, w) = w and θ1 (a, k) = γ, with γ identified under sufficient
variation on w.
   31
      We assume the firm faces the (residual) inverse demand curve Pt = wt − ηQt and has constant marginal cost
                                   2
c, so that π (wt ; η, c) = (wt − c) /4η. The idiosyncratic shocks εit follow a type 1 extreme value distribution. We
ignore sampling variation for simplicity and set: c = 11, η = 1.5, w = (20, 17, 12) , β = 0.95, f c = 5.5, sv = 10, ec = 9,
while the transition matrix for w is
                                                                            
                                                           0.4 0.35 0.25
                                         F (wt+1 |wt ) =  0.3 0.4      0.3  .
                                                           0.2 0.2      0.6



                                                            25
                         Table 1: Numerical Example – True vs. Estimated Profits

States: (k, w)                          True Profit             Estimated Profit            Estimated Profit
                                                                  scrap value = 0               fixed cost = 0

a = inactive
π (a, k = 0, wH ) = 0                               0                            0                            0
π (a, k = 0, wM ) = 0                               0                            0                            0
π (a, k = 0, wL ) = 0                               0                            0                            0
π (a, k = 1, wH ) = sv                             10                            0                          120
π (a, k = 1, wM ) = sv                             10                            0                          120
π (a, k = 1, wL ) = sv                             10                            0                          120

a = active
π (a, k = 0, wH ) = −ec                            –9                          0.5                       –113.5
π (a, k = 0, wM ) = −ec                            –9                          0.5                       –113.5
π (a, k = 0, wL ) = −ec                            –9                          0.5                       –113.5
π (a, k = 1, wH ) = π(wH ) − f c                    8                          7.5                         13.5
π (a, k = 1, wM ) = π(wM ) − f c                  0.5                            0                            6
π (a, k = 1, wL ) = π(wL ) − f c                –5.33                        –5.83                        0.167




and the inferred counterfactual CCPs and welfare. In the first two, the government provides
subsidies to encourage entry. Counterfactual 1 is an additive subsidy that reduces entry costs:
π
e(active, 0, w) = π(active, 0, w) + g1 . Counterfactual 2 is a proportional subsidy: π  e(active, 0, w) =
                   32
H1 π(active, 0, w). As shown in Section 3, while the counterfactual CCPs and welfare are identified
in the first case, they are not identified in the second case. Specifically, counterfactual behavior
corresponding to “additive changes” (the first case) depends on the difference in present values of
always choosing a = 0 versus a = 1 (i.e., (I − βF1 )−1 π1 − (I − βF0 )−1 π0 ) plus the present value
of the subsidies (i.e., (I − βF1 )−1 g1 ). The difference in present values is itself identified from the
data, and the present value of the subsidies is known by the researcher (since g1 is pre-specified),
implying identification of the counterfactual CCPs (see Section 3.4). In contrast, “proportional
changes” (the second case) require knowledge of baseline payoffs in levels, except in special cases
unlikely to be satisfied in practice. Indeed, the current example does not satisfy these special
conditions and hence counterfactual CCP and welfare are not identified here (see Propositions 1
and 9).
    Table 2 presents the results from counterfactuals 1 and 2 for the true model and the two
estimated models. In both counterfactuals, the true counterfactual probability of entering increases
because of the subsidy; and the probability of staying in the market decreases because it is cheaper

   32
    We choose the additive and proportional subsides so that the true counterfactual CCP and welfare are the
same. As π(active, 0, w) = −ec, and the true ec = 9, we set g1 = 0.9 and H1 = 0.9, so that in both cases the true
                                  e (active, 0, w) = −8.1.
counterfactual entry cost becomes π

                                                        26
          Table 2: Counterfactuals 1 and 2 – Additive and Proportional Entry Subsidies

States: (k, w)           Baseline         True CF             Estimated CF        Estimated CF
                                                              scrap value = 0      fixed cost = 0

                                                   CF1: π
                                                        e 0 = π0 , π
                                                                   e1 = π1 + g1
CCP: Pr (active|x)
(k = 0, wH )               93.61%           94.95%                     94.95%             94.95%
(k = 0, wM )               87.48%           90.27%                     90.27%             90.27%
(k = 0, wL )               72.99%           80.33%                     80.33%             80.33%
(k = 1, wH )               99.99%           99.99%                     99.99%             99.99%
(k = 1, wM )               80.91%           69.59%                     69.59%             69.59%
(k = 1, wL )                0.48%            0.29%                      0.29%              0.29%

Welfare: Ve − V
(k = 0, wH )                    -            5.420                       5.420              5.420
(k = 0, wM )                    -            5.445                       5.445              5.445
(k = 0, wL )                    -            5.539                       5.539              5.539
(k = 1, wH )                    -            4.535                       4.535              4.535
(k = 1, wM )                    -            4.727                       4.727              4.727
(k = 1, wL )                    -            5.219                       5.219              5.219

                                                     CF2: π
                                                          e 0 = π0 , π
                                                                     e1 = H1 π1

CCP: Pr (active|x)
(k = 0, wH )               93.61%           94.95%                     93.53%             99.87%
(k = 0, dM )               87.48%           90.27%                     87.31%             99.84%
(k = 0, dL )               72.99%           80.33%                     72.53%             99.81%
(k = 1, dH )               99.99%           99.99%                     99.99%             90.59%
(k = 1, wM )               80.91%           69.59%                     81.44%              0.44%
(k = 1, wL )                0.48%            0.29%                      0.49%              0.00%

Welfare: Ve − V
(k = 0, wH )                    -            5.420                      –0.289             88.255
(k = 0, wM )                    -            5.445                      –0.290             88.829
(k = 0, wL )                    -            5.539                      –0.295             89.756
(k = 1, wH )                    -            4.535                      –0.239             77.068
(k = 1, wM )                    -            4.727                      –0.248             82.836
(k = 1, wL )                    -            5.219                      –0.278             84.802




                                              27
to re-enter in the future. So, the firm enters and exits more often in the true counterfactual. The
entry subsidies also increase the value of the firm in all states.
    In counterfactual 1 (additive subsidy), as expected, the counterfactual CCPs and welfare are
identical in the true model and under both estimated models. Thus, when the counterfactual is
identified, it does not matter what restrictions the researcher chooses when estimating the model.
In contrast, counterfactual 2 (proportional subsidy) results in very different outcomes under the
two restrictions. When we set sv = 0, the changes in the CCPs are all in the wrong direction:
while the true entry probability increases relative to the baseline, the predicted counterfactual
entry probability decreases. Similarly, the counterfactual exit probability decreases in the true
model, while it increases in the estimated model. Welfare also has the wrong sign in all states.
This is a direct consequence of the fact that the estimated entry cost under this restriction has the
wrong sign: in the true model, multiplying π(active, 0, w) by H1 represents a subsidy, but in the
estimated model, it becomes a tax. This illustrates the importance of the identifying restrictions in
driving conclusions, especially when the researcher does not know the sign of the true parameter.
When instead we restrict f c = 0, since the estimated entry costs and scrap values are magnified,
it is profitable to enter and exit the market repeatedly when the entry cost is reduced in the
counterfactual. Predicted turnover and welfare are therefore excessive.
    Counterfactual 3 changes the transition process Pr(wt+1 |wt ). As discussed previously, changes
in the transition process generically result in non-identified counterfactual behavior. However,
counterfactual behavior and welfare are identified in the present case due to the parametric re-
strictions (Proposition 8 and Corollary 2). To see why, recall that when counterfactual behavior
depends on baseline payoffs only through the (identified) difference in present values of always
choosing a = 0 versus a = 1, then the counterfactual is identified. Here, the new CCP depends on
this baseline difference in present values plus the change in present values of variable profits π̄(w)
that results from changing Pr(wt+1 |wt ). This second quantity is known not just because π̄(w) is
known, but because the evolution of the exogenous states w is known in both the baseline and the
counterfactual scenarios. Counterfactual behavior (and also welfare) are therefore identified, and
the top panel of Table 3 confirms the results.33
    Finally, counterfactual 4 implements a “change in types” experiment. In particular, we add a
second market with different parameter values: market 2 is more profitable than market 1 both
through lower entry costs and higher variable profits. We identify the parameters for market 2 as
before and perform a counterfactual that substitutes the entry cost of market 1 by the estimated
entry cost of market 2.34

   33        f (w0 |w) = 1/3, for all (w0 , w). Aguirregabiria and Suzuki (2014) also implement a change in transitions
      We set Pr
in a similar model. But they consider a change in Fak , i.e., a change in the transition of states that enter the
nonidentified part of payoffs. As expected, their counterfactual is not identified. Similar to our counterfactual 2
under the restriction sv = 0, they obtained counterfactual predictions in the wrong direction.
   34
      For market 2, we set: c2 = 9, η2 = 1.7, w2 = (18, 15, 11), f c2 = 3, sv2 = 8, ec2 = 6. The discount factor and
transition matrix in market 2 is the same as in market 1. The estimated profit under the first restriction (sv2 = 0)

                                                          28
  Table 3: Counterfactuals 3 and 4 – Change in F (wt+1 /wt ) and Change Markets’ Entry Costs

States: (k, w)         Baseline        True CF           Estimated CF                     Estimated CF
                                                         scrap value = 0                   fixed cost = 0

                                                   CF3: π          e1 = π1 , Few 6= F w
                                                        e 0 = π0 , π
CCP: Pr (active|x)
(k = 0, wH )             93.61%          86.97%                    86.97%                         86.97%
(k = 0, wM )             87.48%          86.97%                    86.97%                         86.97%
(k = 0, wL )             72.99%          86.97%                    86.97%                         86.97%
(k = 1, wH )             99.99%          99.99%                    99.99%                         99.99%
(k = 1, wM )             80.91%          80.19%                    80.19%                         80.19%
(k = 1, wL )              0.48%           1.17%                     1.17%                          1.17%

Welfare: Ve − V
(k = 0, wH )                   -           0.542                     0.542                          0.542
(k = 0, wM )                   -           1.347                     1.347                          1.347
(k = 0, wL )                   -           2.530                     2.530                          2.530
(k = 1, wH )                   -           0.468                     0.468                          0.468
(k = 1, wM )                   -           1.350                     1.350                          1.350
(k = 1, wL )                   -           1.808                     1.808                          1.808

                                                        e10 = π02 , π
                                                   CF4: π           e11 = π11

CCP: Pr (active|x)
(k = 0, wH )             93.61%          97.28%                    95.22%                        100.00%
(k = 0, wM )             87.48%          95.08%                    90.83%                        100.00%
(k = 0, wL )             72.99%          91.44%                    81.74%                        100.00%
(k = 1, wH )             99.99%          99.95%                    99.99%                             0%
(k = 1, wM )             80.91%          36.86%                    66.67%                             0%
(k = 1, wL )              0.48%           0.09%                     0.02%                             0%

Welfare: Ve − V
(k = 0, wH )                   -          19.778                     6.684                        482.861
(k = 0, wM )                   -          19.883                     6.715                        483.667
(k = 0, wL )                   -          20.198                     6.831                        484.849
(k = 1, wH )                   -          16.816                     5.602                        449.773
(k = 1, wM )                   -          17.752                     5.846                        457.934
(k = 1, wL )                   -          19.044                     6.438                        459.999




                                              29
    The bottom panel of Table 3 presents the results. Similar to counterfactual 2, turnover increases
in the true counterfactual compared to the baseline; and again, the two identifying restrictions
generate very different outcomes. This is expected given Proposition 2. Under the first restriction
(sv = 0), counterfactual CCPs and welfare are all in the right direction, even though the estimated
entry costs have the wrong sign in both markets. This happens because replacing the entry cost
of market 1 by that of market 2 amounts to an increase in entry costs in the restricted model.
However, even though the CCP moves in the right direction, the magnitude is bound to be wrong
and turnover under this restriction is not as large as the true counterfactual turnover. Under the
second identifying restriction (f c = 0), turnover and welfare are again exaggerated, to the point
that counterfactual choice probabilities are (numerically close to) either zero or one.


4.2     Empirical Example: Agricultural Land Use Model
In this section, we explore the impact of identifying restrictions on counterfactuals using actual
data on agricultural land use. We estimate a dynamic model of farmers’ planting choices and
perform two counterfactuals of interest: the long-run land use elasticity and a fertilizer tax. We
emphasize the impact of identifying restrictions on counterfactuals and relegate the details of the
estimation methodology to the Supplemental Material (Section C).

Empirical Model. Each year, field owners decide whether to plant crops or not; i.e. A = {c, nc},
where c stands for “crops” and nc stands for “no crops” (e.g. pasture, hay, non-managed land).
Fields are indexed by i and counties are indexed by m. We partition the state ximt into:

   1. time-invariant field and county characteristics, sim , e.g. slope, soil composition;

   2. number of years since field was last in crops, kimt ∈ K = {0, 1, ..., K}; and

   3. aggregate state, wmt (e.g. input and output prices, government policies).

Per period payoffs are specified as in (22) so that

                                    π(a, k, s, w) = θ0 (a, k, s) + θ1 Z (a, w) ,

where θ0 (a, k, s) captures switching costs between land uses and Z (a, w) are observable measures
of returns. The dependence of θ0 on k is what creates dynamic incentives for landowners. The
action of “no crops” leaves the land idle, slowly reverting it to natural vegetation, rough terrain,
etc. The farmer needs to clear the land in order to convert to crop and start planting. The costs of
switching to crop may be rising as the terrain gets rougher. At the same time, however, there may


is ec2 = 1.6, π 2 (active, 1, w) = (8.52, 1.89, −2.82); and under the second restriction (f c2 = 0) is: ec2 = −63, sv2 =
68, π 2 (active, 1, w) = (11.91, 5.29, 0.59).

                                                          30
be benefits to switching, e.g. planting crops may be more profitable after the land is left fallow for
a year. In summary, we expect θ0 (a, k, s) to differ across actions and states.
    The transition of state variables follows the decomposition (21), F (k 0 , w0 |a, x) =
F k (k 0 |a, k) F w (w0 |w), so that farmers do not affect the evolution of the aggregate state w; this
implies that farmers are small (price takers) and that there are no externalities across fields. The
transition rule of k is
                                         (
                                                  0           if a = c (crops)
                            k 0 (a, k) =
                                           min {k + 1, K} , if a = nc (no crops)

so that if “no crop” is chosen, the field state since last crop increases by one, up to K, while if
“crop” is chosen, the field state is reset to zero. Planting crops is therefore a “renewal” action.
We return to the market state w below. Finally, note that the type s is time-invariant.

Data. First, we employ high-resolution annual land use data in the United States from the
Cropland Data Layer (CDL) database. We then merge the CDL with an extensive dataset of
land transactions obtained from DataQuick (which includes information on price, acreage, field
address and other characteristics). Then, we incorporate detailed data from NASA’s Shuttle Radar
Topography Mission database (with fine topographical information on altitude, slope and aspect);
the Global Agro-Ecological Zones dataset (with information on soil categories and on protected
land); and various public databases on agricultural production and costs from the USDA. The
final dataset goes from 2010 to 2013 for 515 counties and from 2008 to 2013 for 132 counties.
    Further details about the construction of the dataset, as well as some summary statistics, are
presented in the Supplemental Material, Section B. Here we only emphasize that land use exhibits
substantial persistence. The average proportion of cropland in the sample is 15%; the probability
of keeping the land in crop is about 85%, while the probability of switching to crops after two years
as non-crop is quite small: 1.6%. Finally, the proportion of fields that switch back to crops after
one year as “no crop” ranges from 27% to 43% on average depending on the year, which suggests
some farmers enjoy benefits from leaving land fallow for a year.

Estimation. Our estimation strategy mostly follows Scott (2013); we augment this land use
model to allow for unobserved market states by the econometrician. In other words, we allow for
the aggregate state variable w to have an unobserved component. This may be important as the
econometrician may not be able to capture the entire information set of the land owner (commodity
prices, government policy, etc.). See the Supplemental Material (Section C) for details.35
    The parameters of interest are θ1 and θ0 (a, k, s), for all a, k, s. The slope θ1 is identified

  35
     In a previous version of this paper (see NBER Working Paper 21527) we discuss identification of DDC models
with unobserved states. This material is now part of Kalouptsidi, Scott, and Souza-Rodrigues (2018), where we
provide the details of a general setup with unobserved market states and characterize the identification of payoffs.

                                                        31
provided there is sufficient variation in Z (a, w); switching costs between land uses, θ0 (a, k, s), on
the other hand are not identified (Proposition 7). Thus, additional restrictions are required to
obtain these costs parameters. The sensitivity of certain counterfactuals to identifying restrictions
on payoffs calls out for some means to assess the accuracy of these restrictions. To do so, we
present and compare two estimators.
    First, we estimate the model using the observed data on farmers’ actions and states, fol-
lowing Scott (2013). We call this the “CCP estimator.” Naturally, in this case we need some
identifying restrictions, and as in Scott (2013), we impose θ0 (nocrop, k, s) = 0 for all k and s.
These K restrictions (for each field type s) suffice to identify the remaining switching cost pa-
rameters. Specifically, farmers’ payoffs for a = nocrop are known under these restrictions, since
π(nocrop, k, s, w) = θ1 Z (nocrop, w). Identification of θ0 (crop, k, s) now follows directly from (3):
given that π(nocrop, k, w) is known for all states (k, w), equation (3) directly delivers π(crop, k, w),
implying that θ0 (crop, k, s) is identified. However, as is common in applied work, there is little
guidance to specify the particular values that θ0 (nocrop, k, s) should take. To evaluate the impact
of these restrictions in this real-data setup, we bring in additional data, namely, the land resale
prices.
    Our second estimator makes use of resale prices to avoid the restrictions θ0 (nocrop, k, s) = 0.
We call it the “V-CCP estimator.” We assume that the resale prices provide direct information on
the value function V .36 Clearly, if V is known, so are the payoffs: if V is known at all states, we
can recover the conditional value functions va from equation (2), i.e. va = V − ψa . Then, πa can
be retrieved from the definition of va , (1), and since θ1 is identified, we can obtain θ0 . As explained
in the Supplemental Material, our estimator is designed so that the only role of the resale price
data is to avoid the identifying restrictions θ0 (nocrop, k, s) = 0 for all k, s. By construction of the
estimator, θ1 is the same as that of the CCP estimator.
    Section C of the Supplemental Material explains both estimators in detail. Here, we only
emphasize that the CCP estimator imposes restrictions on θ0 (a, k, s) for identification, while the
“V-CCP” estimator replaces these a priori restrictions with more data-driven restrictions.

Parameter Estimates. Table 4 presents the estimated parameters using the CCP and V-CCP
estimators. For brevity we only present the average of the ratio θ0 (a, k, s) /θ1 across field types
s, where we divide by θ1 so that the parameters can be interpreted in dollars per acre; θ0 (a, k)
denotes the average of θ0 (a, k, s) across s. We set K = 2 due to data limitations and because after


  36
     There are numerous ways to model resale markets, and different models may imply different mappings between
transaction prices and agents’ value function. Here, we essentially consider the simplest possible setting: in a world
with a large number of homogeneous agents, a resale transaction price must equal the value of the asset. A similar
approach is adopted in Kalouptsidi (2014, 2018). To address concerns that transacted fields may be selected, we
compare the transacted fields (in DataQuick) to all US fields (in the CDL) in Table B3 of the Supplemental Material.
Overall, the two sets of fields look similar. We also explore whether land use changes upon resale and find no such
evidence (see Table C2 in the Supplemental Material).

                                                         32
                                                Table 4: Empirical Results

                             Estimator:                            CCP                      V-CCP

                             θ̄0 (crop, 0) /θ1                   -721.93                    -1228.9
                                                              (-1350,-542)               (-2700,-804)

                             θ̄0 (crop, 1) /θ1                  -2584.4                     -1119.4
                                                             (-5500,-1740)               (-4020,-284)

                             θ̄0 (crop, 2) /θ1                  -5070.8                    -4530.4
                                                            (-11060,-3340)             (-10037,-2940)

                             θ̄0 (nocrop, 0) /θ1                      0                    -2380.3
                                                                                        (-4050,-1900)

                             θ̄0 (nocrop, 1) /θ1                      0                     470.05
                                                                                          (-777,829)

                             θ̄0 (nocrop, 2) /θ1                      0                     -454.58
                                                                                         (-1240,-229)

                             θ1−1                                734.08                     734.08
                                                               (358,1110)                 (358,1110)
                             θ0 values are means across all fields in the sample, divided by θ1 so that

                             their units are in dollars. 95% confidence intervals in parentheses.

                             Note that θ1 is proportional to standard deviation of idiosycratic shocks,

                             when payoff function is measured in dollars.




2 years out of crops there are very few conversions back to crops in the data.37
    The mean switching cost parameters from the CCP estimator are all negative and increase in
magnitude with k. One may interpret this as follows: when k = 0, crops were planted in the
previous year. According to the estimates, preparing the land to replant crops costs on average
$722/acre. When k = 1, the land was not used for crops in the previous year. In this case, it costs
more to plant crops than when k = 0. Conversion costs when k = 2 are even larger. Of course
this interpretation hinges on the assumption that θ0 (nocrop, k, s) = 0 for all k, s. As is typical
in switching cost models, estimated switching costs are large in order to explain the observed
persistence in choices; unobserved heterogeneity – which is beyond the scope of this paper – can
alleviate this issue (see Scott, 2013).
    The estimated parameters of the V-CCP estimator do not impose θ0 (nocrop, k, s) = 0. When
k = 0, switching out of crops is now expensive on average (not zero anymore). In fact we test the
   37
     We weight observations as in Scott (2013) and cluster standard errors by year. We construct the confidence
intervals for θ0 (a, k) /θ1 by sampling from the estimated asymptotic distribution of (b
                                                                                       θ0 , b
                                                                                            θ1 ). The details of the first
stage estimator are in the Supplemental Material.

                                                                    33
joint hypothesis θ0 (nocrop, k) = 0, for all k, and we reject it. This is reasonable because the “no
crops” option incorporates, in addition to fallow land, pasture, hay, and other land uses. While
staying out of crops for one year may be the result of the decision to leave land fallow, staying out
of crops for longer periods reflects other land usages (since land will likely not stay idle forever)
with their associated preparation costs. Furthermore, the estimated value of θ0 (crop, k, s) is also
affected when we drop the restriction. Indeed, the absolute value of the estimated θ0 (crop, 0) is
now larger than the absolute value of θ0 (crop, 1). This reflects the benefits of leaving land fallow
for one year (i.e. smaller replanting costs). This potential benefit is not apparent when we restrict
θ0 (nocrop, k, s). Given that the probability of planting crops after one year of fallow is lower than
the probability of planting crops after crops in the data (in most counties), in order to rationalize
the choice probabilities, the restricted model (imposing θ0 (nocrop, k, s) = 0) must assign higher
costs to crops after fallow than after crops. We view this as an appealing feature of the V-CCP
model – it is arguably not plausible that leaving land out of crops for one year would increase the
costs of planting crops in the following year dramatically.38

Counterfactuals. We implement two counterfactuals: the long-run elasticity (LRE) of land use
and an increase in the costs of replanting crops.
    The LRE measures the long-run sensitivity of land use to an (exogenous) change in crop
returns, Z(c, w). As previously mentioned, the LRE is an important input to evaluate several
policy interventions, including agricultural subsidies and biofuel mandates (Roberts and Schlenker,
2013; Scott, 2013). We compare the share of cropland in the steady-state obtained when Z(c, w)
is held fixed at their average recent levels and when Z(c, w) is held fixed at 10% higher levels. The
LRE is defined as the arc elasticity between the total acreage in the two steady states.39
    As shown in Table 5, the CCP and V-CCP estimators give exactly the same LRE. This is
no coincidence. By Proposition 7, the slope parameter θ1 is identified and by Proposition 8(i), a
counterfactual that changes only the identified part of payoffs is also identified. Intuitively, because
θ1 is identified, a counterfactual that changes θ1 Z(c, w) by 10% resembles a “pre-specified additive
change,” which is an identified counterfactual. Therefore, the LRE is not affected by identifying
restrictions on θ0 , and the only difference between the CCP estimator and the V-CCP estimator
is that the latter relies on land values to identify the profit function while the former relies on
a priori restrictions. Since the counterfactual of interest is identified, it does not matter which
restrictions are imposed when estimating the model parameters.

   38
      One could also argue that it is not plausible that staying out of crops for only two years would lead to
dramatically higher costs of planting crops. However, as mentioned previously, we observe very few fields in the
data with field state k = 2 which have not been out of crops for longer than two years; i.e., fields which have been
out of crops for at least two years have typically been out of crops for a long time.
   39
      See Scott (2013) for a formal definition and further discussion. The LREs estimated here are higher than
those found in Scott (2013) (although not significantly so). We find that this is largely due to our different sample
combined with the absence of unobserved heterogeneity: when Scott’s estimation strategy is applied to our sample
of counties ignoring unobserved heterogeneity, LREs are very similar to those presented here.

                                                         34
     The second counterfactual increases the crop replanting costs as

                   θ0 (crop, 0, s) = θ0 (crop, 0, s) + λ (θ0 (crop, 1, s) − θ0 (crop, 0, s)) .
                   e


The difference θ0 (crop, 1, s) − θ0 (crop, 0, s) captures the benefits of leaving land out of crops
for a year. One such benefit is to allow soil nutrient levels to recover, reducing the need for
fertilizer inputs. When it is difficult to measure the fertilizer saved by leaving land fallow, one
can use the switching cost parameters to implement a counterfactual that resembles a fertilizer
tax. A motivation for this type of counterfactual is that higher fertilizer prices would be a likely
consequence of pricing greenhouse gas emissions, as fertilizer production is very fossil-fuel intensive.
Here we impose λ = 0.1. So, this exercise changes the costs of replanting crops in a way that reflects
10% of the benefits of leaving land out of crops for one year.
    In terms of identification, the counterfactual choice probabilities here depend on the baseline
model parameters in levels, not just on payoff differences that can be recovered directly from the
data, as shown in Section 3.4. As such, one should expect this counterfactual to be sensitive to
model identifying restrictions. Indeed, by Proposition 8(ii), the counterfactual choice probability
is not identified here.40
    As shown in Table 5, the identifying restrictions do matter when it comes to this counterfactual.
The CCP estimator leads to a 32% increase in cropland, while the V-CCP estimator predicts a
decrease in cropland, as expected. In other words, the CCP estimator errs in predicting not just
the magnitude, but also the sign of the change in crop acreage. The reason behind this is that
the CCP estimator cannot capture the benefits from leaving land fallow (on average) and thus
interprets this counterfactual as a subsidy rather than a tax.
    To summarize, when we only change the identifying restrictions (i.e. moving from the CCP
to the V-CCP estimator), the LRE does not change, as it involves only a transformation of the
identified component of the profit function. However, the land use pattern in the second coun-
terfactual, which involves a transformation of the non-identified part of payoffs, is substantially
altered when we modify the identifying restrictions.


5        Conclusion
This paper studies the identification of counterfactuals in dynamic discrete choice models. We pro-
vide the set of necessary and sufficient conditions that determine whether counterfactual behavior

    40
     Formally, θ0 (a) is a 3 × 1 vector (omitting s in the notation   to simplify), and we take e
                                                                                                θ0 (a) = H0 (a) θ0 (a),
with H0 (nocrop) = I, and                                               
                                                          1−λ λ        0
                                           H0 (crop) =  0        1    0 .
                                                            0     0    1
These matrices do not satisfy the identification condition in Proposition 8(ii).

                                                         35
                                    Table 5: Policy Counterfactuals

                            Estimator:                         CCP                V-CCP
                            Long-run elasticity                0.57                 0.57
                            Fertilizer tax                     0.32                -0.16
                            Fertilizer tax statistic is percentage change in long-run cropland.

                            Long-run elasticity is a 10 percent arc elasticity.




and welfare are identified for a broad class of counterfactuals of interest, including non-additive
changes in payoffs or changes to agents’ choice sets. We also investigate the identification power
of parametric restrictions. For a large class of interventions, the identification conditions are
straightforward to verify in practice.
    We investigate relevant counterfactuals in two applied examples (a firm’s entry/exit decisions
and a farmer’s land use decisions). The results call for caution while leaving room for optimism:
although counterfactual behavior and welfare can be sensitive to identifying restrictions imposed
on the model, there exists important classes of counterfactuals that are robust to such restrictions.


References
Abbring, J. H., and O. Daljord (2019): “Identifying the Discount Factor in Dynamic Discrete
 Choice Models,” Quantitative Economics, forthcoming. 1, 10, 13

Aguirregabiria, V. (2010): “Another Look at the Identification of Dynamic Discrete Decision
 Processes: An application to Retirement Behavior,” Journal of Business & Economic Statistics,
 28(2), 201–218. 1, 1, 8, 3.1, 3.3

Aguirregabiria, V., and J. Suzuki (2014): “Identification and Counterfactuals in Dynamic
 Models of Market Entry and Exit,” Quantitative Marketing and Economics, 12(3), 267–304. 1,
 1, 8, 3.1, 3.1, 3.3, 3.3, 3.5, 4.1, 33

Arcidiacono, P., and R. A. Miller (2011): “Conditional Choice Probability Estimation of
 Dynamic Discrete Choice Models With Unobserved Heterogeneity,” Econometrica, 79(6), 1823–
 1867. 9

        (2019): “Identifying Dynamic Discrete Choice Models off Short Panels,” Journal of
  Econometrics, forthcoming. 1, 1, 8, 3.1, 3.1

Bajari, P., C. S. Chu, D. Nekipelov, and M. Park (2016): “Identification and semipara-
 metric estimation of a finite horizon dynamic discrete choice model with a terminating action,”
 Quantitative Marketing and Economics, 14(4), 271–323. 1



                                                            36
Blevins, J. R. (2014): “Nonparametric identification of dynamic decision processes with discrete
 and continuous choices,” Quantitative Economics, 5(3), 531–554. 7, 10, 4, 27

Buchholz, N., M. Shum, and H. Xu (2019): “Semiparametric Estimation of Dynamic Discrete
 Choice Models,” Journal of Econometrics, forthcoming. 7, 10

Chan, T. Y., B. H. Hamilton, and N. W. Papageorge (2016): “Health, Risky Behavior and
 the Value of Medical Innovation for Infectious Diseases,” Review of Economic Studies, 83(4),
 1465–1510. 3.1

Chen, L.-Y. (2017): “Identification of Discrete Choice Dynamic Programming Models with Non-
 parametric Distribution of Unobservables,” Econometric Theory, 33(3), 551–577. 7, 10

Chiong, K. X., A. Galichon, and M. Shum (2016): “Duality in dynamic discrete-choice
 models,” Quantitative Economics, 7(1), 83–115. 9

Collard-Wexler, A. (2013): “Demand Fluctuations in the Ready-Mix Concrete Industry,”
 Econometrica, 81(3), 1003–1037. 3.1, 3.5

Conlon, C. T. (2012): “A Dynamic Model of Costs and Margins in the LCD TV Industry,”
 Discussion paper, New York University. 13

Crawford, G. S., and M. Shum (2005): “Uncertainty and Learning in Pharmaceutical De-
 mand,” Econometrica, 73(4), 1137–1173. 3.1

Das, S., M. J. Roberts, and J. R. Tybout (2007): “Market Entry Costs, Producer Hetero-
 geneity, and Export Dynamics,” Econometrica, 75(3), 837–873. 3.1, 4.1

Duflo, E., R. Hanna, and S. P. Ryan (2012): “Incentives work: Getting teachers to come to
 school,” The American Economic Review, 102(4), 1241–1278. 3.1

Dunne, T., S. D. Klimek, M. J. Roberts, and D. Y. Xu (2013): “Entry, exit, and the
 determinants of market structure,” The RAND Journal of Economics, 44(3), 462–487. 3.1

Eckstein, Z., and O. Lifshitz (2011): “Dynamic Female Labor Supply,” Econometrica, 79(6),
 1675–1726. 3.1

Gilleskie, D. B. (1998): “A Dynamic Stochastic Model of Medical Care Use and Work Absence,”
 Econometrica, 66(1), 1–45. 3.1

Heckman, J. J., J. E. Humphries, and G. Veramendi (2016): “Dynamic treatment effects,”
 Journal of Econometrics, 191(2), 276 – 292, Innovations in Measurement in Economics and
 Econometrics. 1


                                              37
Heckman, J. J., and S. Navarro (2007): “Dynamic discrete choice and dynamic treatment
 effects,” Journal of Econometrics, 136(2), 341–396. 1

Hendel, I., and A. Nevo (2006): “Measuring the Implications of Sales and Consumer Inventory
 Behavior,” Econometrica, 74(6), 1637–1673. 3.1, 3.5

Hotz, V. J., and R. A. Miller (1993): “Conditional Choice Probabilities and the Estimation
 of Dynamic Models,” Review of Economic Studies, 60(3), 497–529. 9, 3.4, A.1.1

Hu, Y., and M. Shum (2012): “Nonparametric identification of dynamic models with unobserved
 state variables,” Journal of Econometrics, 171(1), 32–44. 1, 1, 2

Ichimura, H., and C. Taber (2000): “Direct Estimation of Policy Impacts,” Discussion Paper
  No 254, NBER. 2

        (2002): “Semiparametric Reduced-Form Estimation of Tuition Subsidies,” American
  Economic Review, (92), 286–292. 2

Igami, M. (2017): “Estimating the Innovator’s Dilemma: Structural Analysis of Creative De-
  struction in the Hard Disk Drive Industry, 1981–1998,” Journal of Political Economy, 125(3),
  798–847. 3.1, 4.1

Kalouptsidi, M. (2014): “Time to build and fluctuations in bulk shipping,” The American
 Economic Review, 104(2), 564–608. 1, 5, 6, 3.1, 4.1, 36

         (2018): “Detection and Impact of Industrial Subsidies: The Case of Chinese Shipbuild-
  ing,” Review of Economics Studies, 85(2), 1111–1158. 36

Kalouptsidi, M., Y. Kitamura, L. Lima, and E. Souza-Rodrigues (2020): “Partial Iden-
 tification and Inference for Dynamic Models and Counterfactuals,” Discussion Paper No 2221,
 Cowles Foundation. 1

Kalouptsidi, M., P. T. Scott, and E. Souza-Rodrigues (2017): “On the Non-identification
 of Counterfactuals in Dynamic Discrete Games,” International Journal of Industrial Organiza-
 tion, 50, 362–371. 1, 12

Kalouptsidi, M., P. T. Scott, and E. A. Souza-Rodrigues (2018): “Linear IV Regression
 Estimators for Structural Dynamic Discrete Choice Models,” NBER Working Paper 25134. 35

Kasahara, H., and K. Shimotsu (2009): “Nonparametric Identification of Finite Mixture
 Models of Dynamic Discrete Choices,” Econometrica, 77(1), pp. 135–175. 1, 1, 2

Keane, M. P., and A. Merlo (2010): “Money, Political Ambition, and the Career Decisions
 of Politicians,” American Economic Journal: Microeconomics, 2(3), 186–215. 3.1

                                             38
Keane, M. P., and K. I. Wolpin (1997): “The Career Decisions of Young Men,” Journal of
 Political Economy, 105(3), 473–522. 3.1

         (2010): “The Role of Labor and Marriage Markets, Preference Heterogeneity and the
  Welfare System in the Life Cycle Decisions of Black, Hispanic and White Women,” International
  Economic Review, 51(3), 851–892. 3.1, 3.1

Koning, R. H., H. Neudecker, and T. Wansbeek (1991): “Block Kronecker Products and
 the vecb Operator,” Linear Algebra and Its Applications, pp. 165–184. 16

Lin, H. (2015): “Quality Choice and Market Structure: A Dynamic Analysis of Nursing Home
  Oligopolies,” International Economic Review, 56(4), 1261–1290. 3.1, 4.1

Magnac, T., and D. Thesmar (2002): “Identifying Dynamic Discrete Decision Processes,”
 Econometrica, 70(2), 801–816. 1, 1, 2, 10, 13

Matzkin, R. L. (2003): “Nonparametric Estimation of Nonadditive Random Functions,” Econo-
 metrica, 71(5), 1339–1375. 4

Norets, A., and X. Tang (2014): “Semiparametric Inference in dynamic binary choice models,”
 The Review of Economic Studies, 81(3), 1229–1262. 1, 1, 8, 10, 3.1, 3.1, 3.3, 3.3, 3.5

Pesendorfer, M., and P. Schmidt-Dengler (2008): “Asymptotic Least Squares Estimators
 for Dynamic Games,” The Review of Economic Studies, 75(3), 901–928. 1

Roberts, M. J., and W. Schlenker (2013): “Identifying Supply and Demand Elasticities
 of Agricultural Commodities: Implications for the US Ethanol Mandate,” American Economic
 Review, 103(6), 2265–95. 1, 4.2

Rosenzweig, M. R., and K. I. Wolpin (1993): “Credit Market Constraints, Consumption
 Smoothing, and the Accumulation of Durable Production Assets in Low-Income Countries:
 Investments in Bullocks in India,” Journal of Political Economy, 101(2), 223–244. 3.1

Rust, J. (1987): “Optimal Replacement of GMC Bus Engines: an Empirical Model of Harold
 Zurcher,” Econometrica, 55(5), 999–1033. 3.2

         (1994): “Structural Estimation of Markov Decision Processes,” Handbook of Econometrics
  4, 4, 3081–3143. 1, 1, 2

Rust, J., and C. Phelan (1997): “How social security and medicare affect retirement behavior
 in a world of incomplete markets,” Econometrica: Journal of the Econometric Society, pp. 781–
 831. 3.1



                                              39
Ryan, S. P. (2012): “The Costs of Environmental Regulation in a Concentrated Industry,”
 Econometrica, 80(3), 1019–1061. 3.1

Schiraldi, P. (2011): “Automobile replacement: a dynamic structural approach,” The RAND
  Journal of Economics, 42(2), 266–291. 3.1

Scott, P. T. (2013): “Dynamic Discrete Choice Estimation of Agricultural Land Use,” Working
  Paper. 1, 4.2, 4.2, 37, 4.2, 39

Varela, M. J. (2018): “The costs of growth: Accelerated growth and crowd-out in the Mexican
 supermarket industry,” International Journal of Industrial Organization, 61, 1 – 52. 3.1, 4.1

Wei, C., and S. Li (2014): “The Cost of Greening Stimulus: A Dynamic Discrete Choice Analysis
 of Vehicle Scrappage Programs,” Working Papers 2014-12, The George Washington University,
 Institute for International Economic Policy. 3.1



A       Appendix: Proofs
Appendix A summarizes the proofs of the claims given in the main body of the paper. The
subsections here correspond to the main paper’s sections.


A.1     Identification of Counterfactual Behavior: The General Case
A.1.1    Proof of Lemma 1

To prove Lemma 1, we make use of Lemma A1 below. Assume without loss of generality that
J = A. Define                                           
                                Φ11   Φ12   ···  Φ1,A−1
                              Φ21    Φ22   ···  Φ2,A−1 
                                                        
                     ∂φ−J                                 ≡ Φ,
                          = .
                                      ..    ..     ..
                      ∂p      . .      .     .      .
                                                         
                                                         
                              ΦA−1,1 ΦA−1,2 ... ΦA−1,A−1
                                                   ∂φiJ (p(x))
where Φij are the X ×X matrices with elements       ∂pj (x0 )
                                                               ,   with x, x0 ∈ X for each i, j = 1, ..., A−1.
Note that each Φij is diagonal because ∂φ∂piJj(p(x))
                                               (x0 )
                                                     = 0 when x 6= x0 .
    Next, define the diagonal matrices, Pa , with diagonal element i, pa (xi ) for a = 1, ..., A − 1; and
let P = [P1 , P2 , ..., PA−1 ].

Lemma A1. The Arcidiacono-Miller function ψJ (p) is continuously differentiable with derivative:

                                              ∂ψJ
                                                  = P Φ.
                                               ∂p


                                                   40
Proof. Recall that                               Z
                               ψJ (p (x)) =          max {φkJ (p (x)) + εk } dG (ε) .
                                                     k∈A

    Because φjJ (p (x)) is a continuously differentiable function, as shown by Hotz and Miller (1993),
so is ψJ (p (x)). For x 6= x0 , ∂ψ∂pJa(p(x))
                                       (x0 )
                                             = 0 for all a, because ∂φ∂p
                                                                       kJ (p(x))
                                                                             0
                                                                         a (x )
                                                                                 = 0 for all k. For x = x0 , apply
the Chain Rule and obtain
                               Z                                       
               ∂ψJ (p (x))               ∂
                           =                   max {φkJ (p (x)) + εk } dG (ε)
                 ∂pa (x)            ∂pa (x) k∈A
                           J−1 Z                                              
                           X                                                           ∂φjJ (p (x))
                         =            1 j = arg max {φkJ (p (x)) + εk } dG (ε)
                           j=1
                                                   k∈A                                    ∂pa (x)
                              J−1
                              X              ∂φjJ (p (x))
                          =         pj (x)
                              j=1
                                               ∂pa (x)

Note that
                                                 ∂ψJ
                                                     = [Ψ1 , ..., ΨJ−1 ]
                                                  ∂p
                                                                     ∂ψJ (p(x))
where Ψa is the X × X diagonal matrix with elements                   ∂pa (x)
                                                                                ,x   ∈ X , for a = 1, ...J − 1. Hence,

                                              ∂ψJ
                                                  = [P1 , P2 , ..., PJ−1 ] Φ.
                                               ∂p



   To simplify notation, consider the function b−J , instead of eb−J . Recall the definition of b−J (p) :
R(A−1)X → R(A−1)X in Section 2. Because ψa = ψJ − φaJ , we have
                                         
                                  A1 − I
                                    ..   
                     b−J (p) = 
                                     .    ψJ (p) + φ−J (p) = Aψ J (p) + φ−J (p) ,
                                          
                                 AJ−1 − I

where A has dimension (A − 1) X × X and ψJ (p) is a column vector with entries ψJ (p(x)), x ∈ X ,
and φ−J (p) is an (A−1)X-valued function with elements φaJ (p (x)). Because both functions ψJ (p)
and φ−J (p) are differentiable, by Lemma A1 we have

                                        ∂b−J    ∂ψJ   ∂φ−J
                                             =A     +      = [AP + I] Φ
                                         ∂p      ∂p    ∂p

    Note that, by the Hotz-Miller inversion (Hotz and Miller, 1993), all block-matrices Φij of Φ
are
h invertible.
          i       Further, the blocks are all linearly independent, so Φ is invertible as well. Thus
 ∂b−J (p)
    ∂p
            will be invertible if [AP + I] is. Using the identity det(I + AB) = det(I + BA) and the



                                                            41
           P
property       a   Pa = I, we obtain

                                                     J−1
                                                                              !                        J−1
                                                                                                                      !
                                                     X                                                 X
                     det (AP + I) = det I +                 Pa (Aa − I)           = det PJ +                 P a Aa
                                                      a=1                                              a=1


But Aa = (I − βFa )(I − βFJ )−1 and therefore

                                                     J−1
                                                                                               !
                                                     X
             det (AP + I) = det PJ +                        Pa (I − βFa )(I − βFJ )−1
                                                     a=1
                                                                       J−1
                                                                                           !
                                                                       X
                                                                             Pa (I − βFa ) det (I − βFJ )−1
                                                                                                                          
                                  = det PJ (I − βFJ ) +
                                                                       a=1
                                              J
                                                                       !
                                              X
                                                    Pa (I − βFa ) det (I − βFJ )−1
                                                                                                   
                                  = det
                                              a=1
                                                      J
                                                                   !
                                                      X
                                                            Pa Fa det (I − βFJ )−1
                                                                                               
                                  = det I − β
                                                      a=1

            PJ
Note that          a=1   Pa Fa is a stochastic matrix, since all its elements are non-negative and

                                     J
                                                !           J                  J
                                                                                       !
                                     X                      X                  X
                                            Pa F a 1 =            Pa 1 =             Pa 1 = 1,
                                      a=1                   a=1                a=1

                                                            
where 1 is a X × 1 vector of ones. Thus, det I − β Ja=1 Pa Fa is nonzero and det (AP + I) 6= 0.
                                                  P


A.1.2      Proof of Theorem 1

Assume without loss of generality that action J = A belongs to both sets A and A.  e The implicit
function theorem allows us to locally solve (14) with respect to pe provided the matrix

                                ∂ h                                i   ∂
                                     h−J (π) − A−J hJ (π) − b−J (e
                                               e            e    p) = − eb−J (e
                                                                              p)
                                ∂ pe                                   ∂ pe

is invertible; this is proved in Lemma 1.41
    The vector pe does not depend on the free parameter πJ if and only if

                              ∂ h                                                          i
                                  ha (π1 , π2 ..., πJ ) − Aa hJ (π1 , π2 ..., πJ ) − ba (e
                                                          e                          e   p) = 0
                             ∂πJ




  41
      Because π ∈ RA×X , the set of payoffs that satisfies (6) is an open linear manifold. Therefore, for any point π
in this manifold, there exists a neighborhood for which the implicit function theorem is valid.

                                                                  42
for all a ∈ A,
            e with a 6= J, and all π satisfying (6). But, the above yields
                                                                                                       !
                               X ∂ha ∂πl         ∂ha                    X ∂hJ ∂πl        ∂hJ
                                               +      =A
                                                       ea                              +
                             l∈A,l6=J
                                      ∂π l ∂πJ   ∂π J
                                                                      l∈A,l6=J
                                                                               ∂πl ∂πJ   ∂πJ

                                                h i
where, for each a ∈ Ae and l ∈ A, the matrix ∂h    a
                                                 ∂πl
                                                     has dimension X   e × X; while A        e ×X
                                                                                    ea is an X   e
matrix. Using (3),                                                           !
                          X ∂ha            ∂ha         X ∂hJ            ∂h J
                                      Al +      =A
                                                 ea               Al +                         (A1)
                        l∈A,l6=J
                                 ∂π l      ∂π J
                                                     l∈A,l6=J
                                                              ∂πl       ∂πJ
or,                                               "     #                                        "     #
                       h                         i A          h                                 i A
                                                     −J                                             −J
                           ∂ha
                           ∂π1
                                 ∂ha
                                 ∂π2
                                             ∂ha
                                         ... ∂πJ          = Aa ∂h
                                                            e     J
                                                                ∂π1
                                                                                 ∂hJ
                                                                                 ∂π2
                                                                                        ... ∂hJ
                                                                                            ∂πJ
                                                    I                                              I

For a ∈ A,           e × AX matrix (recall J = A)
        e define the X
                                                         h                              i
                                                             ∂ha     ∂ha          ∂ha
                                             ∇ha (π) =       ∂π1     ∂π2
                                                                           ...    ∂πJ
                                                                                            .

Then, stacking the above expressions for all a ∈ A,
                                                 e with a 6= J, we obtain
                                                  "  #             "    #
                                                 A−J                 A
                                                        e−J ∇hJ (π) −J .
                                        ∇h−J (π)       =A
                                                  I                   I

      Now apply the property vecbr (BCA0 ) = (A  B) vecbr (C) to obtain:
           h           i                                   h            i      
                A0−J   I  I vecbr (∇h−J (π)) −                    A0−J    I  A−J vecbr (∇hJ (π)) = 0
                                                                               e

                                                                        "                #
                                 hh           i         h        i     i vecbr (∇h (π))
                                                                                   −J
                                      A0−J   I  I, − A0−J I  A   e−J                     = 0,
                                 |                    {z               } vecbr (∇hJ (π))
                                              (A−1)
                                               e    XX×(
                                                    e    A
                                                         eX)(AX)
                                                           e            |       {z       }
                                                                                                (A
                                                                                                 eX)(AX)×1
                                                                                                   e

                        h      i                           h     i   
which is (15). Note that A0−J I is an X ×AX matrix, while A0−J I  I is an (A−1)
                                                                             e    e ×
                                                                                  XX
                               h        i      
 e − 1)AXX
(A        e matrix. Similarly, A0      I    A          e − 1)XX
                                             e−J is an (A     e × AXX
                                                                    e matrix, and A
                                                                                  e−J is
                                   −J
    e − 1)X
an (A       e ×Xe matrix.42




    With abuse of notation, the identity matrix in A0−J
  42
                                                                      
                                                                      I is an X × X matrix, while the identity matrix after
      0         
 in A−J I  I is (A   e − 1)Xe × (Ae − 1)X.
                                          e


                                                               43
A.1.3     Proof of the Bus Engine Replacement Example in Section 3.2

Let a = 1 if replace, and a = 2 if keep. Then
                                           "                  #
                                          (1 + λ) I −λ [1, 0]
                                       π
                                       e=                       π,
                                              0        I

where 1 is a vector of ones and 0 is a matrix with zeros. Let J = 2. By equation (17) in Corollary
1, pe is identified if and only if
                                               
                                    H11 − A
                                          e1 H21 A1 + H12 − A
                                                            e1 H22 = 0

or (1 + λ) IA1 − λ [1, 0] − A1 = 0, which implies λA1 = λ [1, 0]. This implies A1 is non-invertible,
which is a contradiction.


A.2       Identification of Counterfactual Behavior: Special Cases
A.2.1     Proof of Corollary 1
          ∂ha
Because   ∂πl
                = Hal , equation (A1) in the proof of Theorem 1 becomes
                                                                                   !
                             X                               X
                                    Hal Al + HaJ = A
                                                   ea               HJl Al + HJJ       .
                             l6=J                            l6=J


In the “action diagonal” case, Hal = HJl = 0 for all a, J 6= l, and the condition simplifies to

                                            Haa Aa = A
                                                     ea HJJ .


A.2.2     Proof of Proposition 1

Equation (18) implies Haa = Aa HJJ A−1 a , for all a 6= J. So all Haa must be similar. Diagonal
similar matrices are equal to each other, which implies Haa = Hjj ≡ H, for all a and j.
   Let Aa be partitioned comformably with H:
                                                                        
                                                   (Aa )11 ... (Aa )1d
                                                    ..     ..   .. 
                                        Aa = 
                                                     .      .    .   
                                                   (Aa )d1 ... (Aa )dd

Then, HAa − Aa H = 0 implies that for all i 6= j, (λi − λj ) (Aa )ij = 0, and since λi 6= λj , it must
be (Aa )ij = 0 and Aa is block-diagonal. This proves the equivalence of statements (i) and (ii).
   We next prove that statement (ii) implies statement (iii). Suppose Aa is block-diagonal. Then,



                                                        44
Aa (I − βFJ ) = (I − βFa ), or
                                        I − Aa = β (Fa − Aa FJ )                                       (A2)

The left-hand side is block diagonal and its (i, j) block is equal to zero. Therefore,
                                                     X
                                     0 = (Fa )ij −          (Aa )ik (FJ )kj
                                                       k


Since Aa is block-diagonal, (Aa )ik = 0 for i 6= k and thus (Fa ) ij = (Aa )ii (FJ ) ij . Moreover, if we
equate the diagonal blocks in (A2), we have:

                                 I − (Aa )ii = β ((Fa )ii − (Aa )ii (FJ )ii )

and (Aa )ii (FJ ) ii = (Aa FJ ) ii , since Aa is block-diagonal. Rearranging, we establish the claim.
   Finally, we show the reverse.                     Consider the first block-row of Aa , a1 =
[(Aa )11 (Aa )12 ... (Aa )1d ]. Let e1 = [I 0 ...0]. Then a1 = e1 Aa = e1 (I − βFa )(I − βFJ )−1 .
But e1 (I − βFa ) = [I − β(Fa )11 ...I − β(Fa )1d ] and statement (iii) implies that

        e1 (I − βFa ) = [(Aa )11 (I − β(FJ )11 ) ...(Aa )11 (I − β(FJ )1d )] = (Aa )11 e1 (I − βFJ )

Therefore,

             a1 = e1 Aa = (Aa )11 e1 (I − βFJ ) (I − βFJ )−1 = (Aa )11 e1 = [(Aa )11 0 ...0]

We conclude that (Aa )1j = 0 for j 6= 1. The same argument applied to all block-rows shows that
Aa is block diagonal with block entries given by (Aa )i .

A.2.3    Proof of Proposition 2

Suppose the counterfactual replaces the payoff of type s1 by that of s2 for action J only. Then:
Haa = I and                                     "     #
                                                  0 I
                                        HJJ =                                               (A3)
                                                  0 I
   From Corollary 1 for affine counterfactuals, identification requires that, Haa Aa = Aa HJJ . We
partition Aa comformably with HJJ , i.e.
                                                   "              #
                                                 A11 A12
                                            Aa =
                                                 A21 A22

The identification condition then leads to A11 = A21 = 0 with A12 , A22 arbitrary.
  But in the case of time-invariant types, Aa is block diagonal, as it is not possible to transit


                                                       45
from one type to the other (i.e. Aii = (I − βFasi )(I − βFJsi )−1 , for i = 1, 2 and A12 = A21 =
0). Invertibility of Aa implies that the diagonal blocks are invertible as well, and therefore, the
counterfactual is not identified.
    Next, suppose the counterfactual replaces the payoff of type s1 by that of s2 for all actions.
Then, Haa = HJJ and both are given by (A3).
    Therefore identification requires HA = AH, or, A21 = 0 and A11 + A12 = A22 , A21 + A22 = A22 .
Given the form of Aa , A21 = 0 is automatically satisfied, while A12 = 0 implies that identification
requires A22 = A11 and A22 arbitrary.

A.2.4    Proof of Proposition 3

The equivalence of statements (i) and (ii) and the sufficiency part are obvious. Next we prove
necessity. Assume π e = Hπ + g. We prove the statement in three steps. First we show that all
off-diagonal submatrices Haj , a 6= j, must have identical rows. Second, we show that, when J ≥ 3,
the off-diagonal blocks in column a of H must be identical to each other; i.e., Hja = Hla = H a ,
for any combination of j 6= l 6= a. Finally, we show that all diagonal blocks must be of the form
Haa = λI + H a for any choice a, for some scalar λ.
    (a) By Corollary 1, equation (17) must hold for all a 6= J and for any arbitrary process F .
Take an action a 6= J and post-multiply (17) by (I − βFJ ). We get
                 X
                           (Hal − Aa HJl ) (I − βFl ) + HaJ (I − βFJ ) − Aa HJJ (I − βFJ ) = 0.
                l∈A,l6=J


Take FJ = I (this is allowable), then Aa = (I − βFa ) (1 − β)−1 for all l 6= J, and
        X 
                  Hal − (1 − β)−1 (I − βFa ) HJl (I − βFl ) + (1 − β) HaJ − (I − βFa ) HJJ = 0.
                                                          
     l∈A,l6=J


Rearranging, we get
                X 
                   Hal − (1 − β)−1 HJl + (1 − β) HaJ − HJJ + (1 − β)−1 βHJl − βHal Fl
                                                                                
            l∈A,l6=J

            +Fa (1 − β)−1 βHJl + βHJJ − Fa (1 − β)−1 β 2 HJl Fl = 0.
                                                         


This equals
                                         A + BFa + Fa C + Fa DFa = 0,                             (A4)




                                                        46
where
          X                                                                                         X
             Hal − (1 − β)−1 HJl + (1 − β) HaJ − HJJ +                                                         (1 − β)−1 βHJl − βHal Fl
                                                                                                                                  
 A =
         l∈A,l6=J                                                                               l∈A,l6=a,J
                    −1
 B = (1 − β) βHJa − βHaa
      X                                                               X
            (1 − β)−1 βHJl + βHJJ −                                                (1 − β)−1 β 2 HJl Fl
                                                                                                  
 C =
         l∈A,l6=J                                                 l∈A,l6=a,J
                         −1    2
 D = − (1 − β)                β HJa

with Fa ≥ 0 and Fa 1 = 1, where 1 is a vector of ones. Fix FJ and Fl for l 6= a. The left hand side
of equation (A4) can be viewed as a quadratic function in Fa . If this identity is satisfied for all
Fa ≥ 0, then all derivatives of the quadratic function with respect to Fa must be equal to zero.
    Let the columns of Fa be
                                               h                  Pn−1 i
                                           Fa = f1 f2 ... fn−1 1 − i fi

where n is the number of columns (note that n = X). We first take the second derivative, and so
we focus on the term Fa DFa . For j 6= n, the (i, j) entry is:
                                                                 X                       X
                                         (Fa DFa )i,j =                fik dlk fkj =            dlk fik fkj
                                                                 l,k                      l,k


Isolate the last entry and substitute in:

                                                                                                                     n−1
                                                                                                                                 !
                               X                       X                           X                                 X               X
     (Fa DFa )i,j =                    dlk fik fkj +         dlk fin fkj =               dlk fik fkj +        1−           fm            dnk fkj
                              l6=n,k                     k                      l6=n,k                                m              k
                               X
                     =                 fik fkj (dlk − dnk )
                              l6=n,k


and therefore we must have
                                                       dlk = dnk , for all k, l 6= n

Consider now j = n. Then,

                                                                          n−1
                                                                                      !                       n−1
                                                                                                                           !              n−1
                                                                                                                                                      !
                    X                          X                          X                     X             X                           X
(Fa DFa )i,n =             fik dlk fkn =               fik dlk     1−           fkm       +            1−            fil       dlk   1−         fkm
                     l,k                      l6=n,k                      m=1                    k             l=1                        m=1
                    X
              =               fil fkm (dnk − dlk )
                    k.l.m


which already holds. We conclude that D has identical rows, which implies HJa also has identical
rows. Because this argument holds for any a 6= J, and because the choice of J is arbitrary, each


                                                                         47
off-diagonal submatrix Haj must have identical rows for any pair of actions a and j.
    The following facts will be useful below. First note that Aa 1 = 1 for any a, since
                                                                      ∞
                                             −1
                                                                      X                    1
          Aa 1 = (I − βFa ) (I − βFJ )            1 = (I − βFa )            β n FJn 1 =       (I − βFa ) 1
                                                                      n=0
                                                                                          1−β
                    1                 1
                 =     (1 − βFa 1) =     (1 − β) 1 = 1.
                   1−β               1−β

Given that, take any two actions, j and l, and let Hjl = [ρ1jl 1, ..., ρXjl 1]. Then,

                     Aa Hjl = Aa [ρ1jl 1, ..., ρXjl 1] = [ρ1jl Aa 1, ..., ρXjl Aa 1] = Hjl .

   (b) Next, consider the case J ≥ 3, and take j 6= a, J. Return to equation (17). Rearrange it
and isolate the terms involving j:

                 (Haj − Aa HJj ) (I − βFj ) = Aa HJJ (I − βFJ ) − HaJ (I − βFJ )
                                                  X
                                              −         (Hal − Aa HJl ) (I − βFl ) .
                                                         l∈A,l6=j,J


Fix FJ and Fl , for all l 6= j, J, and view this as a function of Fj . The right-hand-side does not
depend on Fj , and the term (Haj − Aa HJj ) on the left-hand-side is fixed. We need the equality to
hold for any Fj . Because (I − βFj ) is full rank, the only way this equality can be satisfied for all
choices of Fj is for
                                          Haj − Aa HJj = 0.

We have shown that Aa Hjl = Hjl for any pair of actions j and l. We therefore obtain

                                                   Haj = HJj .

The argument holds for any combination of j 6= a 6= J. Take the block-column j of H, then all
off-diagonal blocks in column j are identical to each other (in addition to having identical rows
each). Denote the off-diagonal matrices in the block-column j by H j . I.e., H j = Haj , for all pairs
a 6= j.
    (c) Now, return to the case J ≥ 2. We investigate the block-diagonal terms of H. Again, take
(17) for a 6= J,
                                           X
                (Haa − Aa HJa ) Aa +                 (Hal − Aa HJl ) Al + HaJ − Aa HJJ = 0.
                                        l∈A,l6=a,J


Given that all off-diagonal terms Hal , for all pairs a 6= l, must satisfy Hal − Aa HJl = 0, equation
(17) simplifies to
                              (Haa − Aa HJa ) Aa + HaJ − Aa HJJ = 0.

                                                        48
In addition, for all pairs a 6= l, we have that Hal = H l , which implies
                                                               
                                     Haa − H a Aa − Aa HJJ − H J = 0.

Furthermore, if we take Fa = FJ (this is allowable), we get
                                                              
                                          Haa − H a = HJJ − H J .

If we take FJ = I instead, we get
                                                                        
                              Haa − H a (I − βFa ) − (I − βFa ) HJJ − H J = 0.

Rearranging, we obtain
                                                                 
                                       Haa − H a Fa = Fa Haa − H a .
             
So, Haa − H a and Fa must commute, where Fa is an arbitrary (stochastic) matrix. This implies
          
 Haa − H a must be of the form
                                             
                                    Haa − H a = λI,

for all a, where λ is a constant. Finally, note that, for H with diagonal blocks Haa = λI + H a , and
off-diagonal blocks Haj = H j , we obtain
                                                               "          #
                                                                X
                                    e = Hπ + g = λπ +
                                    π                                H j πj 1 + g
                                                               j∈A

                    P                                                                         P
where all rows of       j∈A   H j πj are identical, and therefore all elements of the vector [ j∈A H j πj ]1
are the same.

A.2.5    Proof of Proposition 4

Suppose A = {1, 2, ..., A}. Without loss of generality, take the reference action to be J = 1 and
suppose action j = A + 1 is new, so that Ae = {1, 2, ..., A + 1}. Assume Xe = X , Fea = Fa , and
e = Hπ + g, with π
π                ea = πa for all a ∈ A, and

                                                    A
                                                    X
                                             π
                                             ej =         Hja πa + gj .
                                                    a=1


The identification condition (17) becomes Aa = A
                                               ea , for a = 2, ..., A, and

                                                    A
                                                    X
                                            Hj1 +         Hja Aa = A
                                                                   ej ,                                (A5)
                                                    a=2




                                                          49
for j = A + 1, since Hal = 0 and Haa = I for all a, l 6= j. The first set of restrictions are satisfied,
since transitions are unaffected. Now, post-multiply (A5) by (I − βF1 ) = (I − β Fe1 ) to obtain:

                                                  A
                                                  X
                            Hj1 (I − βF1 ) +            Hja (I − βFa ) = I − β Fej
                                                  a=2

or                                                                                !
                                        A
                                        X                            A
                                                                     X
                                Fej =         Hja Fa + β −1     I−         Hja
                                        a=1                          a=1

Since transitions are stochastic matrices, we have that Fej 1 = 1, so that

                                        A                           A
                                                                              !
                                        X                           X
                                1=            Hja 1 + β −1    1−          Hja 1
                                        a=1                         a=1

     PA
or    a=1   Hja 1 = 1.

A.2.6       Proof of Proposition 5

If Xe = X , Fea = Fa , and π
                           ea = πa for all a ∈ A,
                                                e then Haa = I and Hak = 0 for a ∈ Ae and k ∈ A,
a 6= k, and so (17) becomes Aa = A  ea for all a ∈ A,
                                                   e which is satisfied because Fea = Fa for all a.


A.2.7       Proof of Proposition 6

The proof relies on the following lemma:

Lemma A2. Set the reference action to be J = 1 and suppose action A is eliminated. Suppose
further that the first m states are maintained and the remaining X − m are eliminated. The
counterfactual is specified by:              h     i
                                        π
                                        ea = Im 0 πa                                   (A6)

We partition the transition matrix as follows:
                                                        "       #
                                                     Fba fa
                                                Fa =                                               (A7)
                                                     ga qa

where Fba is the m × m top left submatrix of Fa , corresponding to the maintained states; fa has
dimension m × (X − m); ga is (X − m) × m; and qa is (X − m) × (X − m). Counterfactual
transitions adjust the maintained states as follows,

                                                 Fea = Fba + fa r                                  (A8)

where r is a (X − m) × m matrix such that r1 = 1, to secure that Fea is a stochastic matrix. The

                                                         50
counterfactual is identified if and only if

                                      (I − β Fba )−1 fa = (I − β Fb1 )−1 f1                       (A9)

or fa = Âa f1 , where Âa = (I − β Fba )(I − β Fb1 )−1 .

Proof. The identification condition is Haa Aa = Ãa Haa or Haa (I − βFa ) = Ãa Haa (I − βF1 ). Com-
bining (A6) and (A7), we obtain:
                             h              i h                      i
                              I − β F̂a −βfa = Ãa I − β F̂1 −β Ãa f1

or                                                                 
                                          I − β F̂a = Ãa I − β F̂1                             (A10)

and
                                                    fa = Ãa f1

We show that (A10) is redundant when (A8) holds. Indeed, (A10) is written I − Ãa = β(F̂a − Ãa F̂1 ),
while by definition, I − Ãa = β(F̃a − Ãa F̃1 ). Thus, F̂a − Ãa F̂1 = F̃a − Ãa F̃1 and using (A8),
F̂a − Ãa F̂1 = Fba + fa r − Ãa (Fba + fa r), or fa r = Ãa f1 r, which holds because of (A10).

     Next, we return to Proposition 6. Assume x = (k, w), then
                                                                          
                                                a
                                               f11 F w f12
                                                        a
                                                           F w ... f1K
                                                                    a
                                                                        Fw
                                              .          ..          .. 
                            Fa = Fak ⊗ F w = 
                                              .
                                                  .        .   ...     .  
                                                a    w  a    w      a    w
                                              fK1 F    fK2 F   ... fKK F

where fija = Pr (k 0 = j|k = i, a) are the elements of Fak . Because kt = at−1 , Fa is a matrix with
zeros except in the a − th block-column. The a − th block-column is a block-vector with blocks
F w . If action a = A is eliminated from A = {1, 2, ..., A}, then for all a 6= A, we have fa = 0, where
fa is defined in (A7). Because fJ = 0 as well, condition (A9) in Lemma A2 is trivially satisfied.


A.3      Identification of Counterfactual Behavior Under Parametric Re-
         strictions
A.3.1     Proof of Proposition 7

We make use of two lemmas. Lemma A3 provides sufficient conditions for the identification of
parametric models with linear-in-parameters payoff functions.

Lemma A3. If πa (x) satisfies
                                             πa (x; θ) = π a (x) θ,                             (A11)


                                                        51
where θ is a finite dimensional parameter.                   The parameter θ is identified provided
rank [π −J − A−J π J ] = dim (θ), where π −J = [π 1 , ..., π J−1 , π J+1 , ..., π A ].

Proof. Equation (A11) implies π−J = π −J θ. Then (6) becomes [π −J − A−J π J ] θ = b−J . So, if the
rank of the matrix [π −J − A−J π J ] equals dim (θ), then θ is uniquely determined.

   Next, Lemma A4 provides results that are used to prove Proposition 7.

Lemma A4. Let Da = [I − β(F w ⊗ Fak )]−1 , where I is the identitymatrix of size KW × KW . Let
                                                                      Ik
                                                                    .
Ik be the identity matrix of size K, and 1 be the block vector 1 =  .. 
                                                                    
                                                                          of size KW × K. Finally,
                                                                      Ik
                                 −1
let Aka = Ik − βFak Ik − βFJk . The following properties hold:
    (i) Da−1 1 = I − β(F w ⊗ Fak ) 1 = 1(Ik − βFak ).
                                    

    (ii) Da 1 = I − β(F w ⊗ Fak ) −1 1 = 1(Ik − βFak )−1 .
                                   

    (iii) Aa 1 = 1Aka .
    Statements (ii) and (iii) state that the sum of block entries on each block row of Da and Aa is
constant for all block rows.

Proof. (i) Since F w is a stochastic matrix, its rows sum to 1:                       fijw = 1, where fijw is the (i, j)
                                                                               P
                                                                                  j
element of F w . By the definition of the Kronecker product,
                                                                 P w  k 
                                                                           j f1j Fa 
                               w k        w k           w
                              f11 Fa     f12 Fa   ...  f1W Fak   Ik
                                  ..        ..           ..   ..           ..
                                                                  
         (F w ⊗ Fak )1 =                                 .   .  = 
                                                                                         k
                                                                               .   = 1Fa
                                                                                    
                                  .         .    ...
                                                                       P            
                               w    k  w    k          w    k                  w   k
                              fW 1 Fa fW 2 Fa     ... fW W Fa    Ik       j fW j Fa


Thus, (I − β(F w ⊗ Fak ))1 = 1(Ik − βFak ).
   (ii) Let n be a non-negative integer. Then, (F w )n is a stochastic matrix with rows summing to
1. Therefore,
                                   (F w ⊗ Fak )n = (F w )n ⊗ (Fak )n

and following the proof of (i), we obtain (F w ⊗ Fak )n 1 = 1(Fak )n . Now,
                            ∞
                            X                                ∞
                                                             X
                   Da 1 =          β n (F w ⊗ Fak )n 1 = 1         β n (Fak )n = 1(Ik − βFak )−1 .
                            n=0                              n=0


   (iii) The proof is a direct consequence of (i) and (ii). Indeed,

Aa 1 = (I − β(F w ⊗ Fak ))DJ 1 = (I − β(F w ⊗ Fak ))1(Ik − βFJk )−1 = 1(Ik − βFak )(Ik − βFJk )−1 = 1Aka .




                                                        52
    We now prove Proposition 7; we focus on the binary choice {a, J} for notational simplicity, but
the general case is obtained in the same fashion. Let θ be the vector of 4K unknown parameters
(e.g. θ0a = [θ0 (a, 1), ..., θ0 (a, K)]0 ),          
                                                  θ0a
                                                J 
                                                θ0 
                                            θ= θa  .
                                                      
                                                1 
                                                 θ1J
   The parametric form of interest is linear in the parameters; stacking the payoffs for a given w
and all k we have:
                                 πa (w) = [Ik , 0k , Za (w)Ik , 0k ] θ

and
                                        πJ (w) = [0k , Ik , 0k , ZJ (w) Ik ] θ

Collecting πa (w) for all w, we get πa = π a θ, where
                                                                 
                                              Ik 0k Za (1)Ik 0k
                                             . .       ..     .. 
                                        πa =  .. ..     .      .                                          (A12)
                                                                 
                                              Ik 0k Za (W )Ik 0k

and similarly for πJ . In Lemma A3, we showed that identification hinges on the matrix
(π a − Aa π J ). This matrix equals:
                                               h                      i
                                 π a − Aa π J = 1, −Aa 1, Za , −Aa ZJ                                       (A13)

where Za = [Za (1)Ik , ..., Za (W )Ik ]0 (the same for ZJ ).
   It follows from Lemma A4 that the first two block columns of (A13) consist of identical blocks
each (the first block column has elements Ik , and the second, −Aka ). As a consequence, the
respective block parameters θ0a , θ0J , are not identified unless extra restrictions are imposed.43 The
remaining parameters, θ1a , θ1J , are identified as follows.
   Consider (π a − Aa π J ) θ = ba , or using (A13):
                                                                             −1
              1θ0a − 1Aka θ0J + Za θ1a − I − β F w ⊗ Fak     I − β F w ⊗ FJk      ZJ θ1J = ba .
                                                         

                                                   −1
Left-multiplying both sides by Da = I − β F w ⊗ Fak      and using Lemma A4, we obtain:
                               −1                       −1
                 1 Ik − βFak         θ0a − 1 Ik − βFJk         θ0J + Da Za θ1a − DJ ZJ θ1J = Da ba .


  43
     In the multiple choice one block column is a linear combination of the remaining (J − 1) corresponding to θ0 ;
therefore we need to fix θ0J for one action J to identify θ0−J .

                                                         53
Take the w block row of the above:
                              −1                     −1
                  Ik − βFak         θ0a − Ik − βFJk         θ0J + e0w Da Za θ1a − e0w DJ ZJ θ1J = e0w Da ba        (A14)

where e0w = [0, 0, ..., Ik , 0, ...0] with Ik in the w position. Since W ≥ 3, take two other distinct block
rows corresponding to w,     e w and difference both from the above to obtain the parameter θ1a , θ1J .

A.3.2    Proof of Proposition 8

(i) Consider the counterfactual payoff π    e(a, k, w) = θ0 (a, k) + h1 [Z 0 (a, w)θ1 (a, k)]. Since the term
Z 0 (a, w)θ1 (a, k) is known for all (a, k, w), we can write this as an “additive changes” as follows:
e(a, k, w) = π(a, k, w) + g, where g = h1 [Z 0 (a, w)θ1 (a, k)] − Z 0 (a, w)θ1 (a, k) is known.
π
     (ii) Consider the counterfactual

                                      e(a, w) = H0 (a) θ0 (a) + Z 0 (a, w) θ1 (a)
                                      π

for a = 1, ..., J, where we stack θ0 (a, k) and θ1 (a, k) for all k and H0 (a) is a K × K matrix. From
the proof of Proposition 7, equation (A14), we know that for any w, the w block row of (3) is
                           −1                     −1
             Ik − βFak           θ0a − Ik − βFJk         θ0J + e0w Da Za θ1a − e0w DJ ZJ θ1J = e0w Da ba (p) .

   The corresponding w block row for the counterfactual scenario is
                  −1                            −1
      Ik − βFak         H0 (a) θ0a − Ik − βFJk           H0 (J) θ0J + e0w Da Za θ1a − e0w DJ ZJ θ1J = e0w Da ba (e
                                                                                                                 p) .

    Lack of identification of θ0 is represented by the free parameter θ0J . Using (A14), we prove the
claim.
    (iii) From item (ii) above, it is clear that when Fak changes, pe is identified if and only if for all
a 6= J, Aka = A
              ek .
                a
    (iv) When Few 6= F w and Feak = Fak , the equality Aka = A
                                                             ek trivially holds.
                                                               a



A.4     Identification of Counterfactual Welfare
A.4.1    Proof of Proposition 9

Proposition 9 is a direct consequence of Lemma A5 below.

Lemma A5. Assume Ae = A, Xe = X , β      e = β, and let ha (πa ) = Haa πa + ga , all a. Let C =
          e−J HJJ and D = (I − β FeJ ) (I − βFJ )−1 − HJJ . Then ∆V is identified if and only if
H−J A−J − A
                                                   h     i
                                                 P C − AD = D.
                                                 e     e                                                           (A15)


                                                              54
where the matrices A
                   e and Pe are defined as in Lemma 1 (but based on A
                                                                    ea and pe).

Proof. We know that
                                            V = (I − βFJ )−1 (πJ + ψJ (p))

and similarly for Ve                              −1
                                    Ve = I − β FeJ     (hJ (πJ ) + ψJ (e
                                                                       p)) .

Then,
                        ∂∆V           −1       ∂ψJ (ep) ∂ pe
                                                                
                            = I − β FJ
                                    e       HJJ +                 − (I − βFJ )−1 .
                        ∂πJ                         ∂ pe ∂πJ
               ∂∆V
Therefore,     ∂πJ
                     = 0 if and only if
                                                     ∂ψJ (ep) ∂ pe
                                                                   =D                        (A16)
                                                       ∂ pe ∂πJ
From Lemma A1, we know that
                                                          ∂ψJ
                                                                = PeΦ,
                                                                    e
                                                           ∂ pe
where Pe and Φe are the counterfactual counterpart of P and Φ defined in Lemma A1. By the
Implicit Function Theorem, we know that
                                       "            #−1
                                ∂ pe     ∂eb−J (ep)                       
                                     =                    H−J A−J − A
                                                                    e−J HJJ .
                                ∂πJ         ∂ pe

and, by Lemma 1,                        "                #−1
                                            ∂eb−J (ep)                        −1
                                                                e −1 A
                                                               =Φ     e Pe + I     ,
                                               ∂ pe

Thus (A16) becomes:
                                                             −1
                                                 Pe Ae Pe + I     C=D                        (A17)

Note that44                                       −1                 −1
                                        A
                                        e Pe + I          =I −A
                                                              e I + PeA
                                                                      e     Pe.

Define M = (I + PeA).
                  e Then,

                         e Pe + I)−1 = Pe − PeAM
                      Pe(A                    e −1 Pe = Pe − (M − I) M −1 Pe = M −1 Pe

Then, (A17) becomes M −1 PeC = D, or PeC = M D = (I + PeA)D,
                                                        e    or Pe(C − AD)
                                                                       e   = D, which is
(A15).




  44                                                           −1                  −1
       The equality makes use of the identity (I − BA)              = I + B (I − AB)    A.

                                                                    55
A.4.2    Proof of Corollary 2

Lack of identification of θ0 is represented by the free parameter θ0J . So, applying the same argument
as in Lemma A5, but differentiating ∆V with respect to θ0J , we prove the claim.




                                                 56
Supplement to “Identification of Counterfactuals
      in Dynamic Discrete Choice Models
              Myrto Kalouptsidi∗, Paul T. Scott†, Eduardo Souza-Rodrigues‡
        Harvard University, CEPR and NBER, NYU Stern School of Business, University of Toronto

                                              February 2020


This supplemental material consists of the following sections: Section B presents the data sources,
explains the construction of the variables used in the empirical application, and shows some sum-
mary statistics. Section C discusses the implementation of the empirical exercise based on a
dynamic model of farmers land use decisions.


B        Data and Summary Statistics
Table B1 lists our data sources. All are publicly available for download save DataQuick’s land
values. Our main sample is based on a sub-grid of the Cropland Data Layer (CDL), a high-
resolution (30-56m) annual land-use data that covers the entire contiguous United States since
2008. We took a 840m sub-grid of the CDL within those counties appearing in our DataQuick
database.1 DataQuick collects transaction data from about 85% of US counties and reports the
associated price, acreage, parties involved, field address and other characteristics. The coordinates
of the centroids of transacted parcels in the DataQuick database are known. To assign transacted
parcels a land use, we associate a parcel with the nearest point in the CDL grid.
    A total of 91, 198 farms were transacted between 2008 to 2013 based on DataQuick. However,
we dropped non-standard transactions and outliers from the data. First, because we are interested
in the agricultural value of land (not residential value), we only consider transactions of parcels for
   ∗
     Department of Economics, Harvard University, Littauer Center, Cambridge, MA 02138, myrto@fas.harvard.edu
    †
     Stern School of Business, New York University, Kaufman Management Center, 44 W. 4th St., New York, NY
10012, ptscott@stern.nyu.edu.
   ‡
     Department of Economics, University of Toronto, Max Gluskin House, 150 St. George St., Toronto, Ontario
M5S 3G7, Canada, e.souzarodrigues@utoronto.ca
    1
      The 840m grid scale was chosen for two reasons. First, it provides comprehensive coverage (i.e., most large
agricultural fields are sampled) without providing too many repeated points within any given parcel. Second, the
CDL data changed from a 56m to a 30m grid, and the 840 grid size allows us to match points across years where
the grid size changed while matching centers of pixels within 1m of each other. The CDL features crop-level land
cover information. See Scott (2013) for how “crops” and “non-crops” are defined.

                                                       1
                                        Table B1: Data Sources

Dataset               Description                              Source
Cropland Data Layer   Land cover                               http://nassgeodata.gmu.edu/CropScape/
DataQuick             Real estate transactions, assessments    DataQuick
US Counties           County boundaries                        http://www.census.gov/cgi-bin/geo/shapefiles2010/layers.cgi

GAEZ Database         Protected land, soil type                http://www.gaez.iiasa.ac.at/
SRTM                  Topographical – altitude and slope       http://dds.cr.usgs.gov/srtm/
NASS Quick Stats      Yields, prices, pasture rental rates     http://www.nass.usda.gov/Quick {}{}{}{}{}{}Stats/
ERS                   Operating costs                          http://www.ers.usda.gov/data-products/commodity-costs-and-returns.aspx

NOOA Urban Centers    Urban center locations and populations   %{}{}{}{}{} http://www.nws.noaa.gov/geodata/catalog/national/html/urban.




   which the municipal assessment assigned zero value to buildings and structures. Additionally, we
   drop transactions featuring multi-parcels, transactions between family members, properties held
   in trust, and properties owned by companies. Finally, we drop transactions with extreme prices:
   those with value per acre greater than $50,000, total transaction price greater than $10,000,000,
   or total transaction price less than $60; these are considered measurement error. After applying
   the selection criteria, there remained 24, 643 observations (transactions).
       To obtain a rich set of field characteristics, we use soil categories from the Global Agro-
   Ecological Zones database and information on protected land from the World Database on Pro-
   tected Areas. Protected land was dropped from all analyses. The NASA’s Shuttle Radar To-
   pography Mission (SRTM) database provides detailed topographical information. The raw data
   consist of high-resolution (approx. 30m) altitudes, from which we calculated slope and aspect, all
   important determinants of how land is used. Characteristics such as slopes and soil categories are
   assigned to fields/parcels using nearest neighbor interpolation.
       To derive a measure of nearby developed property values, we find the five restaurants nearest
   to a field, and we average their appraised property values. For each field, we also compute the
   distance to the nearest urban center with a population of at least 100,000. Location of urban
   centers were obtained from the National Oceanic and Atmospheric Administration (NOAA).
       Finally, we use various public databases on agricultural production and costs from the USDA.
   The final dataset goes from 2010 to 2013 for 515 counties and from 2008 to 2013 for 132 counties.
   Crop returns are based on information on yields, prices received, and operating expenditures;
   non-crop returns are based on more sparse information on pasture land rental rates (see Scott
   (2013)).
       Table B2 presents some summary statistics. Table B3 compares the transacted fields (in
   DataQuick) to all US fields (in the CDL). Overall, the two sets of fields look similar. In par-
   ticular, the probability of keeping (switching to) crops is very similar across the two datasets.




                                                   2
                                       Table B2: Summary Statistics

Statistics                                                            Mean Std Dev Min     Max
In Cropland                                                           0.147   0.354    0      1
Switch to Crops                                                      0.0162   0.126    0      1
Keep Crops                                                            0.849   0.358    0      1
Crop Returns ($)                                                        228     112   43    701
Slope (grade)                                                         0.049   0.063    0  0.702
Altitude (m)                                                            371     497 −6     3514
Distance to Urban Center (km)                                          79.8    63.7 1.22    362
Nearest commercial land value ($/acre)                               159000 792000 738 73369656
Land value ($/acre)                                                    7940    9720 5.23  50000
A slope of 1 refers to a perfect incline and a slope of 0 refers to perfectly horizontal land.




       Table B3: Dataquick vs CDL Data – Time Invariant Characteristics

            Mean by dataset                                                       DataQuick    CDL
            In Cropland                                                                0.147  0.136
            Switch to Crops                                                           0.0162 0.0123
            Keep Crops                                                                 0.849  0.824
            Crop Returns ($)                                                             228    241
            Slope (grade)                                                              0.049  0.078
            Altitude (m)                                                                 371    688
            Distance to Urban Center (km)                                               79.8    103
            Nearest commercial land value ($/acre)                                   159000 168000




                                                                3
C         Dynamic Land Use Model and Estimation
C.1         Model with Unobserved States
As mentioned in the main text, we augment the empirical model by allowing for unobserved market
states, following Scott (2013). The per period payoff becomes:

        π (a, kimt , wmt , sim , εimt ) = θ0 (a, kimt , sim ) + θ1 Z (a, wmt ) + ξ (a, kimt , wmt , sim ) + εimt   (C1)

where ξ (a, k, w, s) captures unobservable variation in returns, and the idiosyncratic shock εit has a
logistic distribution. (Without loss of generality, ξ (a, k, w, s) is mean-zero for all (a, k, w, s).) We
                      a
construct returns Zmt    ≡ Z (a, wmt ) using county-year information (expected prices and realized
yields for major US crops, as well as USDA cost estimates) as in Scott (2013).2 As described
below, identification requires exclusion restrictions on ξ (a, k, w, s) (see also Kalouptsidi, Scott,
and Souza-Rodrigues, 2018).


C.2         Payoff Parameter Estimation
Throughout this section, we use t-subscripts in place of explicitly writing the aggregate state
variable wmt . We also omit the subscripts i (fields) and m (counties) to simplify notation. The
derivation relies on two crucial assumptions: (a) agents are small; i.e., changing the action of any
agent at time t does not affect the distribution of wt+1 , and (b) agents have rational expectations.
    Here, we consider two estimators for the payoff function. Let pct (k, s) denote the probability of
choosing action “crops” at time period t given state k for a field of type s, and let σ be the scale
parameter of the logit shocks (we discuss this further below). We begin with Scott’s (2013) linear
estimating equation for a dynamic model with logit errors; we refer the interested reader to Scott
(2013) (see also Kalouptsidi, Scott, and Souza-Rodrigues, 2018) for the derivation of the following
equation:
                    Yt (k, s) = θ̃0 (k, s) + θ1 (Zt (c, s) − Zt (nc, s)) + ξ̃ k,s,t + ẽk,s,t    (C2)




    2
     We refer the interested reader to Scott (2013) for details of constructing the measure of observed returns Z.
Due to data limitations, we restrict Z to depend only on (a, wmt ). One important difference from Scott (2013) is
that we have field level observable characteristics sim and they affect land use switching costs.

                                                              4
where
                                                                                       pct+1 (0,s)
                                                                                                      
                                                     pct (k,s)
                            Yt (k, s) ≡ ln          1−pct (k,s)
                                                                      + β ln       pct+1 (k0 (nc,k),s)



                            θ̃0 (k, s) ≡ (θ0 (c, k, s) − θ0 (nc, k, s)) /σ
                                         +β (θ0 (c, 0, s) − θ0 (c, k 0 (nc, k) , s)) /σ

                                θ1       ≡ 1/σ

                              ξ̃ k,s,t   ≡ ξt (c, k, s) − ξt (nc, k, s)
                                           +β (ξt+1 (c, 0, s) − ξt+1 (c, k 0 (nc, k) , s))

                        ẽk,s,t ≡ β (Et [Vt (0, s)] − Vt (0, s))
                                  −β (Et [Vt+1 (k 0 (nc, k) , s)] − Vt+1 (k 0 (nc, k) , s)) .
Ultimately, this is a linear equation that can be used to estimate the parameters of the payoff
function with no need to solve the agent’s dynamic optimization problem.
   On the left hand side of equation (C2), we have a dependent variable which is a function of
conditional choice probabilities (which are estimated in a first stage, described below in Section
C.3) and the discount factor (which is imputed; we assume it equals 0.95).
   On the right hand side of (C2), the intercept term θ̃0 is a combination of intercepts of the
payoff function θ0 . We discuss the identification of θ0 in more detail below, for this is essentially
where the two estimators differ.
   The error term has two components, ξ̃ and ẽ. The term ξ̃ is a function of ξ, representing
unobservable variation in returns, while ẽ is a function of expectational error terms. Because Z
and ξ may be correlated, we follow Scott (2013) and implement an instrumental variable estimator.
To do so, we need exclusion restrictions of the form
                                            h                        i
                                           E νk,s,t ξ̃ k,s,t + ẽk,s,t = 0,                                         (C3)

where νk,s,t is a vector of instrumental variables. Given that agents have rational expectations, ẽk,s,t
is uncorrelated with any function of variables in the time-t information set by construction. For
this reason, E [νk,s,t ẽk,s,t ] = 0 holds for any νk,s,t in the time-t information set and the question of
whether equation (C3) is valid becomes a question of whether E[νk,s,t ξ̃ k,s,t ] = 0. Such a restriction
is a substantive assumption as exclusion restrictions for instrumental variables typically are.3
    We take first-differences for each field and field state, implicitly allowing for ξ̃ k,s,t to have fixed
effects for s and k (interacted).4 After taking first differences, the instruments we use are: a

    3                                        c     nc
      If we were willing to assume that E[(Zs,t −Zs,t )ξ̃ k,s,t ] = 0, then we could estimate equation (C2) using ordinary
least squares.
    4
      Note that we predict CCPs for each field state k, not just for the field state actually observed on the field, so
we can take these first differences for each k regardless of the actual path of k for the field.

                                                                  5
                                                              c     nc 5
constant term, caloric yields, and the lagged value of Zs,t      − Zs,t . The moment restrictions are
used to estimate θ1 . We then form estimates of θ̃0 (k, s) by averaging over the residuals for each
(k, s) pair.
     Up to this point, our two estimators coincide; i.e., our two estimators agree on the estimates
of θ1 and θ̃0 (k, s). The estimators differ when it comes from mapping the estimates of θ̃0 (k, s) to
estimates of θ0 (·, k, s). Notice that for each type s, equation (C2) includes one intercept parameter
θ̃0 (k, s) for each field state k. However, the original payoff function involves two intercept param-
eters (θ0 (c, k, s) and θ0 (nc, k, s)) for each (s, k) combination. Hence, the need for restrictions
for the identification of the model (and our claim in Section 3.5 that θ0 is not identified without
restrictions).
     Our first estimator (the CCP estimator) imposes the following restrictions on θ0 :

                                             ∀k, s :    θ0 (nc, k, s) = 0.                                     (C4)

After imposing (C4), we can solve for θ0 (c, k, s) from our θ̃0 (k, s) estimates, recalling that

             θ̃0 (k, s) ≡ (θ0 (c, k, s) − θ0 (nc, k, s)) /σ + β (θ0 (c, 0, s) − θ0 (c, k 0 (nc, k) , s)) /σ,   (C5)

noting that equations (C4) and (C5) represent six linearly independent equations in six unknowns
for each (k, s) pair. (And noting that the scale parameter σ is identified given that θ1 ≡ 1/σ.)
    Our second estimator (the V-CCP estimator) does not impose equation (C4), and instead uses
additional information in resale prices. In order to relate observed resale prices to farmer’s payoff
and value functions, we need a model of transaction prices. We assume that resale prices measure
farmer’s ex-ante value functions; i.e.,
                                                                    
                                            ln pRS
                                                t  = ln   Ṽ t (k, s)  + ηt ,                                  (C6)

where pRSt  is the resale price of a field, ηt is measurement error, and we will explain the reason for
the tilde on the value function below. Using resale prices as signals of the value function can be
justified by assuming that there is a competitive market for buying farms – see Kalouptsidi (2014)
for further discussion of this assumption in the context of bulk shipping.
    We estimate a flexible model of how resale prices depend on (k, s, t), much like Kalouptsidi
(2014) (see Section C.4 for details about the implementation). Fitted values from this regression
can be used as estimates of the value function, but an important caveat is that we must consider the
scale of the utility function when interpreting the estimates. In econometric discrete choice models,
we typically impose a scale normalization on the model that sets the variance of the idiosyncratic
shocks equal to a convenient number (e.g., unity for a probit model of π 2 /6 for a logit model). In our
parametric land use model, the coefficient on returns, θ1 , reflects this normalization: the parameter
   5
       See Scott (2013) for the measurement of caloric yields.

                                                           6
θ1 can be understood as the scalar we need to multiply by to convert the units from dollars to
utils. When we estimate a hedonic model of the value function, the value function is measured
in dollars. Therefore, to convert from the estimated value function to the scale-normalized value
function we should multiply by θ1 :

                                             Vt (k, s) = θ1 Ṽt (kit , sit ) .

    A relationship between value functions and the payoff function can be derived as follows:

                    Vt (k, s) = vt (c, k, s) + ψc (pct (k, s))

                                = πt (c, k, s) + βEt [Vt+1 (k 0 (c, k) , s)] + ψc (pct (k, s))

                                = πt (c, k, s) + βVt+1 (k 0 (c, k) , s) + ek,s,t + ψc (pct (k, s))

where
                               ek,s,t ≡ β (Et [Vt (k 0 (c, k) , s)] − V (k 0 (c, k) , s)) .

Ultimately, we can write the payoff function as a function of conditional choice probabilities (es-
timated in a first stage), value functions (estimated using retail prices in a first stage), and an
expectational error term (mean zero):

                     πt (c, k, s) = Vt (k, s) − βVt+1 (k 0 (c, k) , s) − ψc (pct (k, s)) − ek,s,t .           (C7)

Recalling that the measured version of the value function needs to be converted from dollars to
utils to be on the same scale as the normalized payoff function, we have
                                                                        
                  πt (c, k, s) = θ1 Ṽt (k, s) − β Ṽt+1 (k 0 (c, k) , s) − ψc (pct (k, s)) − ek,s,t .        (C8)

Noting that an estimate of θ1 can be obtained from the CCP estimator, we can then obtain
estimates of payoffs using equation (C8), simply by plugging in the estimated values of θ1 , Ṽ and
p.6 More to the point, we can obtain estimates of the intercept parameters:
                                                                             
       θ0 (c, k, s) = −θ1 Zt (c, s) + θ1 Ṽt (k, s) − β Ṽt+1 (k 0 (c, k) , s) − ψc (pct (k, s)) − ek,s,t .   (C9)

The V-CCP estimator uses equation (C9) to estimate θ0 (c, k, s) by averaging the right-hand-side
of (C9) over time. Finally, the estimates of θ0 (nc, k, s) are then recovered from equation (C5).
    Note that we could alternatively estimate θ0 (nc, k, s) from an equation like (C9), but using non-

   6
    Recall that estimating θ1 with the CCP estimator does not require any identifying restrictions on θ0 . Consider
equation (C2), a regression equation that allows us to estimate θ1 and θ̃0 . The identifying restrictions are only
needed if we want to map from θ̃0 to θ0 .

                                                            7
crops as the action instead of crops. Thus, we have over-identifying restrictions. As the primary
reason we consider the V-CCP estimator is to replace the a priori identifying restrictions in the
CCP estimator with a more data-driven approach, we only take as much information as we need
from the resale prices to fully identify the payoff function. If we were to use more information from
the resale prices, then the two estimators might not agree on the value of θ̃0 (k, s), an object that
is identified from CCP data without imposing identifying restrictions. Our two estimators only
differ when it comes to parameters that cannot be identified from CCP data without restrictions.
Thus, by comparing these two estimators, we isolate the impact of identifying restrictions.


C.3     Conditional Choice Probabilities
We estimate conditional choice probabilities using a semiparametric logit model. The model is
fully flexible over field states and year, but smooth across counties. In particular, we maximize
the following log likelihood function:
                                                     (                                                      )
                  X X                                       I [aimt = c] log (pmt (c, k, sim ; θckt ))
          max                   wm,m0 I [kimt = k]
          θckt
                 m0 ∈Sm i∈Im0
                                                         +I [aimt = nc] log (1 − pmt (c, k, sim ; θckt ))

where Sm is the set of counties in the same US state as m, Im is the set of fields in county m, wm,m0
is the inverse squared distance between counties m and m0 , and I[.] is the indicator function. The
conditional choice probability is parameterized as follows:

                                                                   exp (s0im θckt )
                                     pmt (c, k, sim ; θckt ) =                        .
                                                                 1 + exp (s0im θckt )

Note that without fields’ observable characteristics, this regression would amount to taking fre-
quency estimates for each county, field state, and year, with some smoothing across counties.
Including covariates allows for within-county field heterogeneity. The final specification for the
conditional choice probabilities only uses slopeim among regressors because it proved to be the
most powerful predictor of agricultural land use decisions (after conditioning on county and field
state).
     The set of counties in Sm only includes counties which also appear in the DataQuick database.
For some states, the database includes a small number of counties, so in these cases we group two
or three states together. For example, only one county in North Dakota appears in our sample, and
it is a county on the eastern border of North Dakota, so we combine North Dakota and Minnesota.
Thus, for each county m in North Dakota or Minnesota, Sm represents all counties in both states
in our sample.7

   7
     In particular, we form a number of groups for such cases: Delaware and Maryland; North Dakota and Min-
nesota; Idaho and Montana; Arkansas, Louisiana, and Mississippi; Kentucky and Ohio; Illinois, Indiana, and
Wisconsin; Nebraska and Iowa; Oregon and Washington; Colorado and Wyoming.

                                                             8
                                  Table C1: Land Resale Price Regression

                                                                                   (1)
                            VARIABLES                                        log(land value)

                            log(distance to urban center)                       -0.471***
                                                                                 (0.0297)
                            commercial land value                                0.102***
                                                                                (0.00930)
                            slope                                               -1.654***
                                                                                  (0.160)
                            alt                                                -0.000226**
                                                                                (9.00e-05)
                            Observations                                          24,643
                            R-squared                                              0.318
                             Robust standard errors in parentheses *** p<0.01, ** p<0.05, * p<0.1

                                     Ommitted: soil, county, year, and field state dummies

                                             as well as interactions with returns.




    For the sake of precision, rather than only estimating CCPs using the CDL sample that was
merged with resale data, we used the full 840m sub-grid of fields from the CDL (848,384 fields)
for the CCP estimation. We then predicted CCPs and estimated payoff functions using fields that
were merged with the resale data.


C.4     Resale Price Regression
Next, we discuss how we estimate the value function from resale prices. We view that our resale
market assumptions are not overly restrictive in the context of rural land which features a large
number of small agents. The land resale market is arguably thick, with a large number of transac-
tions taking place every year.8 Moreover, we are able to control for a rich set of field characteristics.
Finally, we did not find evidence of selection on land use changes upon resale, as discussed below.
    As our transaction data is much more sparse than our choice data, we adopt a more restrictive
(parametric) form for modeling land values. We estimate the following regression equation:

                                                          0
                                                ln pRS
                                                    it = Xit θV + ηit ,                               (C10)

where pRS
        it is a transaction price (in dollars per acre), and Xit is a vector of characteristics for the
corresponding field. The covariates Xit include all variables in Table B2 (i.e. k, slope, altitude,
distance to urban centers, nearby commercial values). They also include year dummies, returns
interacted with year dummies, field state dummies interacted with year dummies, and county
   8
     Comparing DataQuick with the CDL data we see that 1.4–2% of fields are resold every year. Moreover, the
USDA reports that in Wisconsin there are approximately 100 thousand acres transacted every year (about 1000
transactions) out of 14.5 million acres of farmland (seemingly information on other states is not available).

                                                               9
                                    Table C2: Land use and transactions

                                        (1)                   (2)                    (3)                    (4)
              VARIABLES            incrops2010           incrops2011            incrops2012            incrops2013

              soldin2009             0.000647
                                     (0.00604)
              soldin2010             0.000116               0.00364
                                     (0.00326)             (0.00334)
              soldin2011              -0.00117             0.000629               -0.00159
                                     (0.00316)             (0.00324)             (0.00330)
              soldin2012                                   -0.000620              -0.00472               0.00411
                                                           (0.00306)             (0.00313)              (0.00265)
              soldin2013                                                        -0.00962***             -0.000445
                                                                                 (0.00306)              (0.00256)

              Observations             23,492                 23,492                23,492                 23,492
              R-squared                0.666                  0.698                 0.717                   0.757
                                 Standard errors in parentheses *** p<0.01, ** p<0.05, * p<0.1

                    Linear probability model. Omitted covariates include current returns, field state, US state,

                      slope, local commercial land value, distance to nearest urban center, and interactions.




dummies.
    Table C1 presents the estimated coefficients. Although not shown in the table, the estimated
coefficients of k are significant and have the expected signs (the large number of interactions makes
it difficult to add them all in the table). This is important for the second stage estimation, as k is
the main state variable included in the switching cost parameters θ0 (a, k).
    Note that, because field acreage is available only in the DataQuick dataset, when merging with
the CDL and remaining datasets we lose this information. This implies, for example, that acreage
cannot be a covariate in the choice probabilities. For this reason, we choose a specification for the
value function that regresses price per acre on covariates. The value of our R2 in our regression
is a direct consequence of this fact. When we use total land prices as the dependent variable and
include acres on the covariates we obtain R2 as high as 0.8.
    Finally, we briefly discuss the possibility of selection on transacted fields. As shown previously
in Table B3 of Section B, the characteristics of the transacted fields (in DataQuick) look similar
to all US fields (in the CDL). Furthermore, we investigate whether land use changes upon resale.
Using a linear probability model we find no such evidence (see Table C2). We regress the land use
decision on dummy variables for whether the field was sold in the current, previous, or following
year as well as various control variables. In regressions within each cross section, ten of the
eleven coefficients on the land transaction dummy variables are statistically insignificant, and the
estimated effect on the probability of crops is always less than 1% (see Table C2). We have tried
alternative specifications such as modifying the definition of the year to span the planting year


                                                                10
rather than calendar year, and yet we have found no evidence indicating that there is an important
connection between land transactions and land use decisions.


References
Kalouptsidi, M. (2014): “Time to build and fluctuations in bulk shipping,” The American
 Economic Review, 104(2), 564–608. C.2

Kalouptsidi, M., P. T. Scott, and E. A. Souza-Rodrigues (2018): “Linear IV Regression
 Estimators for Structural Dynamic Discrete Choice Models,” NBER Working Paper 25134. C.1,
 C.2

Scott, P. T. (2013): “Dynamic Discrete Choice Estimation of Agricultural Land Use,” Working
  Paper. 1, B, C.1, C.1, C.2, 2, C.2, 5




                                               11
