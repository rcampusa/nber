                                NBER WORKING PAPER SERIES




                           REGULATION AND MARKET LIQUIDITY

                                          Francesco Trebbi
                                            Kairong Xiao

                                        Working Paper 21739
                                http://www.nber.org/papers/w21739


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                    November 2015




The authors would like to thank Daron Acemoglu, Paul Beaudry, Matilde Bombardini, Andrea Frazzini
for their comments and suggestions. Nathan Canen provided excellent research assistance. Francesco
Trebbi gratefully acknowledges support by the Canadian Institute For Advanced Research and the
Social Sciences and Humanities Research Council of Canada. Part of this research was written while
Trebbi was visiting the Bank of Canada Financial Stability Department, whose hospitality is gratefully
acknowledged. The views expressed herein are those of the authors and do not necessarily reflect the
views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2015 by Francesco Trebbi and Kairong Xiao. All rights reserved. Short sections of text, not to exceed
two paragraphs, may be quoted without explicit permission provided that full credit, including © notice,
is given to the source.
Regulation and Market Liquidity
Francesco Trebbi and Kairong Xiao
NBER Working Paper No. 21739
November 2015
JEL No. E43,E52,E58,G18,G28

                                              ABSTRACT

The aftermath of the 2008-09 U.S. financial crisis has been characterized by regulatory intervention
of unprecedented scale. Although the necessity of a realignment of incentives and constraints of financial
markets participants became a shared posterior after the near collapse of the U.S. financial system,
considerable doubts have been subsequently raised on the welfare consequences of the Dodd-Frank
Wall Street Reform and Consumer Protection Act of 2010 and its various subcomponents, such as
the Volcker Rule. The possibility of permanently inhibiting the market making capacity of large banks,
with dire consequences in terms of under-provision of market liquidity, has been repeatedly raised.
This paper presents systematic evidence from four different estimation strategies of the absence of
breakpoints in market liquidity for fixed-income asset classes and across multiple liquidity measures,
with special attention given to the corporate bond market. The analysis is performed without imposing
restrictions on the exact dating of breaks (i.e. allowing for anticipatory response or lagging reactions
to regulation) and focusing both on levels and dynamic latent factors. We report both single breakpoint
and multiple breakpoint tests and analyze the liquidity of corporate bonds matched to their main underwriters
making markets on those assets. Post-crisis U.S. regulatory intervention does not appear to have produced
structural deteriorations in market liquidity.


Francesco Trebbi
University of British Columbia
1873 East Mall
Vancouver, BC, V6T1Z1
Canada
and CIFAR
and also NBER
ftrebbi@mail.ubc.ca

Kairong Xiao
Sauder School of Business
University of British Columbia
2053 Main Mall, Vancouver, BC
V6T 1Z2 Canada
kairong.xiao@sauder.ubc.ca
1       Introduction
The aftermath of the 2008-09 nancial crisis has witnessed one of the most active periods
of regulatory intervention in U.S. nancial history since the New Deal (Barr, 2012). A
centerpiece of this sweeping reaction to the near collapse of the nancial system, the Dodd-
Frank Wall Street Reform and Consumer Protection Act (Dodd-Frank), was signed into
law in July 2010. With Dodd-Frank, hundreds of regulatory rulemaking requirements have
been subsequently met, a¤ecting virtually every dimension of modern nancial activity, from
derivatives trading to housing nance to capital requirements for depository institutions. In
the backdrop of this intervention, a lack of rigorous assessment of the complex costs and
bene ts of the new rules has been highlighted (Cochrane, 2014).
    Pertinently to this debate, this paper investigates the claim that U.S. post-crisis nancial
regulatory overreach might have adversely a¤ected the provision of market liquidity in a vast
class of nancial assets, structurally decreasing liquidity levels and increasing liquidity risk
in xed-income markets.
    Such claim is linked, although not uniquely, to a speci c set of provisions embedded
within recent legislation, the so-called Volcker Rule, statutorily delineated in Section 619
Title VI of the 2010 Dodd-Frank Act and nalized by multiple regulatory agencies in Jan-
uary 2014. According to this provision, any banking entity is prohibited from engaging in
proprietary trading or from acquiring or retaining an ownership interest in, sponsoring or
having certain relationships with a hedge fund or private equity fund, subject to certain ex-
emptions. Although this is in no way the only dimension of Dodd-Frank along which serious
welfare losses or liquidity shortages could have been potentially triggered, it emerged as one
of the most hotly debated, with roughly 17; 000 public comments led during the process
of regulatory rulemaking (Bertrand, Bombardini and Trebbi, 2015). Speci cally, some com-
mentators1 have highlighted how by placing undue arti cial limits on securities inventory
    1
     For instance regulators write in the nal version of the Volcker Rule (p.5578 Federal Register / Vol.
79, No. 21 / Friday, January 31, 2014 / Rules and Regulations) "As discussed above, several commenters
stated that the proposed rule would impact a banking entitys ability to engage in market making related
activity. Many of these commenters represented that, as a result, the proposed exemption would likely result
in reduced liquidity[...] " and the Federal Register explicitly mentions on the matter of reduced liquidity
comments received from "AllianceBernstein; Rep. Bachus et al. (Dec. 2011); EMTA; NASP; Wellington;
Japanese Bankers Assn.; Sen. Hagan; Prof. Du¢e; Investure; Standish Mellon; IR&M; MetLife; Lord
Abbett; Commissioner Barnier; Quebec; IIF; Sumitomo Trust; Liberty Global; NYSE Euronext; CIEBA;
EFAMA; SIFMA et al. (Prop. Trading) (Feb. 2012); Credit Suisse (Seidel); JPMC; Morgan Stanley;
Barclays; Goldman (Prop. Trading); BoA; Citigroup (Feb. 2012); STANY; ICE; BlackRock; SIFMA (Asset
Mgmt.) (Feb. 2012); BDA (Feb. 2012); Putnam; Fixed Income Forum/Credit Roundtable; Western Asset
Mgmt.; ACLI (Feb. 2012); IAA; CME Group; Wells Fargo (Prop. Trading); Abbott Labs et al. (Feb.14,
2012); Abbott Labs et al. (Feb. 21, 2012); T. Rowe Price; Australian Bankers Assn. (Feb. 2012); FEI;
AFMA; Sen. Carper et al.; PUC Texas; ERCOT; IHS; Columbia Mgmt.; SSgA (Feb. 2012); PNC et al.;
Eaton Vance; Fidelity; ICI (Feb. 2012); British Bankers Assn.; Comm. on Capital Markets Regulation;


                                                     2
and retained risk and directly a¤ecting inter-dealer trading, the Volcker Rule could have
severely limited market liquidity2 . When recently the Congressional debate shifted on the
merits of regulatory relief, one of the provisions considered for rolling back within Dodd-
Frank included the prohibition of proprietary trading on the part of insured banking entities
and their a¢liates below certain thresholds3 .
    A balanced view of the potential adverse welfare consequences of such provision is sum-
marized in Du¢e (2012): The Agencies proposed implementation of the Volcker Rule would
reduce the quality and capacity of market making services that banks provide to U.S. investors.
Investors and issues of securities would nd it more costly to borrow, raise capital, invest,
hedge risks, and obtain liquidity for their existing positions. Eventually, non-bank providers
of market-marking services would ll some or all of the lost market making capacity, but
with an unpredictable and potentially adverse impact on the safety and soundness of the -
nancial system. These near-term and long-run impacts should be considered carefully in the
Agencies cost-bene t analysis of their nal proposed rule. Regulatory capital and liquidity
requirements for market making are a more cost e¤ective method of treating the associated
systemic risks. Du¢e (2012) further remarks on the needs for an appropriate assessment
of the cost and bene ts of the rule, an assessment that the empirical analysis we perform
systematically complements. Thakor (2012) raises similar issues.
    This paper formally assesses the e¤ect of the U.S. post-crisis regulatory intervention,
encompassing the Dodd-Frank Act and its corollary parts as the Volcker Rule, on market
liquidity of the U.S. xed-income market. The biggest empirical challenge that we face is
the complicated anticipatory response or lagging reaction during ve years of protracted
rulemaking process. To address this challenge, we employ a statistical method which allows
Union Asset; Sen. Casey; Oliver Wyman (Dec. 2011); Oliver Wyman (Feb. 2012) (providing estimated
impacts on asset valuation, borrowing costs, and transaction costs in the corporate bond market based on
hypothetical liquidity reduction scenarios); Thakor Study. The Agencies respond to comments regarding the
potential market impact of the rule in Part IV.A.3.b.3., infra."
  Available at http://www.gpo.gov/fdsys/pkg/FR-2014-01-31/pdf/2013-31511.pdf
   2
     For example, on May 20, 2015 The Wall Street Journal in an article titled "Why Liquidity-Starved
Markets Fear the Worst" reports "[..] a large part of the explanation lies in changes to regulation aimed at
addressing weaknesses exposed by the nancial crisis. Banks must now hold vastly more capital, particularly
against their trading books. The ring-fencing of proprietary trading in the U.S. and retail banking in the
U.K. has also squeezed liquidity. " Similar reasoning is implied by Alan Greenspan on the Financial Times
on August 17, 2015, who writes "Lawmakers and regulators, given elevated capital bu¤ers, need to be far less
concerned about the quality of the banks loan and securities portfolios since any losses would be absorbed
by shareholders, not taxpayers. This would enable the Dodd-Frank Act on nancial regulation of 2010 to be
shelved, ending its potential to distort the markets  a potential seen in the recent decline in market liquidity
and exibility."
   3
     See S.1484 - Financial Regulatory Improvement Act of 2015, Title I: Regulatory Relief and Protection
of Consumer Access To Credit. The bill is sponsored by Senate - Banking, Housing, and Urban A¤airs
Chairman Richard Shelby (R-AL).



                                                       3
us to estimate the dates of breaks in liquidity without requiring a priori knowledge of the
exact timing. We provide systematic evidence of a lack of structural breaks in both liq-
uidity levels and latent covariance and autocorrelation structure for a large set of liquidity
proxies in xed-income markets over the period associated to the post-crisis regulatory in-
tervention. We also present concordant evidence from microeconometric approaches based
on di¤erence-in-di¤erences of matched bonds samples that support these ndings. Our work
both quali es frequent informal discussion on the lack of evidence of large deterioration in
market liquidity provision (Dudley, 2015) and is relevant to the rigorous assessment of the
welfare consequences of the Dodd-Frank Act in terms of hindering the market making ca-
pacity of large nancial institutions, one of the main welfare costs observers have ascribed
to the recent regulatory surge.
    This paper employs four di¤erent estimation strategies. We rst produce a large set of
aggregate liquidity measures for the U.S. xed-income markets and employ standard multiple
breakpoint testing (Bai and Perron, 1998, 2003) on the liquidity level and liquidity risk time
series. We explore the market for U.S. corporate bonds, an heterogenous asset class directly
a¤ected by the Volcker Rule. We also study U.S. Treasuries, an asset class not covered by
the Volcker Rule directly, but one in which recent episodes of trading disruption have been
observed (e.g. the ash crash of October 15, 2014). Several commentators have ascribed
these phenomena to liquidity depletion.
    For corporate bonds, we then disaggregate liquidity measures by classifying bonds by
lead underwriters identity. Given that original underwriters typically tend to make markets
on the speci c securities underwritten, this allows us to potentially identify bank-speci c
liquidity breaks and more nuanced disaggregated dynamics, as we further di¤erentiate by
issue size and credit rating. To this large panel of disaggregated liquidity measures we apply
recent econometric approaches based on large factor models (Stock and Watson, 2011),
appropriate to capture breaks in latent factor structures in the data. Speci cally, our second
methodology focuses on single breakpoint testing for large dynamic factor models (Chen et
al., 2014). Our third methodology extends to more realistic multiple breakpoint testing for
large dynamic factor models, transposing the intuition of Chen et al. (2014) to Bai and
Perron (2003) type tests. Such methodologies robustly capture breaks in latent liquidity
dynamics at the start and at the end of the 2008-09 crisis (and indeed can be employed
to precisely time the beginning and end of the liquidity crisis). This reassures us on the
tests having su¢cient power within this speci c empirical application. However, we detect
no systematic statistical evidence of deterioration in liquidity provision due to overreaching
regulation in the data from 2009 to the end of 2014.
    As opposed to time series approaches delineated above, our fourth estimation strategy


                                              4
relies on a standard microeconometric approach in estimating liquidity deterioration around
the nalization of the Volcker Rule, namely di¤erence-in-di¤erences matching (Heckman,
Ichimura, Todd, 1997; Heckman, Ichimura, Smith, and Todd, 1998; Smith and Todd, 2005).
In this part of the analysis we construct a dataset of bonds matched by issue size and credit
rating, split between treatment and control based on whether the original underwriter is
covered or not by Volcker Rule provisions. Matching allows for balancing between covered
and non-covered bonds, assuaging concerns of attenuation due to heterogeneity across the
two groups of securities.
    Consistently across all four estimation strategies, this paper reports a lack of any form of
systematic evidence of deterioration in liquidity levels or breaks in liquidity risk for corporate
bonds. Moreover, during periods of heightened regulatory interventions, with big banks clos-
ing their proprietary trading desks and shedding bond inventories, market liquidity continued
to improve. This is in stark contrast to the popular claim that the post-crisis regulatory in-
tervention adversely a¤ected market liquidity. To the best of our knowledge, this is one of
the very rst studies to statistically assess liquidity depletion related to regulatory activity
post-2008.
    Our work is related to several strands of literature in both economics and nance. The
  rst strand of literature studies how balance sheets of nancial intermediaries a¤ect market
liquidity. Early theoretical works by Garman (1976), Amihud and Mendelson (1980) and Ho
and Stoll (1981) show that decrease in dealer inventories can lead to lower liquidity levels.
Recent theoretical work by Gromb and Vayanos (2002) and Brunnermeier and Pedersen
(2009) further shows that limited market maker capital can explain why market liquidity
varies over time. Many empirical works have since con rmed the main theoretical predictions
of these models. Comerton-Forde et al. (2010) show that NYSE specialist inventory positions
and trading revenues explain time variation in liquidity. Aragon and Strahan (2012) nd
that stocks held by Lehman-connected hedge funds experienced greater declines in market
liquidity following the bankruptcy than other unconnected stocks. Dick-Nielsen et al. (2012)
show how corporate bonds underwritten by Lehman Brothers and Bear Stearns experienced
strain in liquidity during the subprime crisis. As validation, in this paper we also discuss in
some detail the ability of our approach in picking up structural breaks for corporate bonds
underwritten by Lehman Brothers and Bear Stearns.
    A second strand of connected literature studies how liquidity a¤ects asset prices. The
idea that investors demand a liquidity premium for illiquid securities originates with Amihud
and Mendelson (1986). Amihud, Mendelson, and Pedersen (2005) provide a comprehensive
survey on how liquidity inuences asset prices. Corporate bond liquidity has received ex-
tensive attention because of the so-called credit spread puzzle (i.e. spreads on corporate


                                                5
bonds tend to be many times wider than what is implied by expected default losses alone,
see Amato and Remolona, 2003). Longsta¤, Mithal, and Neis (2005) suggest that illiquidity
may be a possible explanation for this puzzle. Later research has focused on measuring
bond-speci c liquidity. Edwards, Harris, and Piwowar (2007) estimate the e¤ective bidask
spread of corporate bonds, and nd that transaction costs decrease signi cantly with trade
size. Bao, Pan and Wang (2011) construct a closely related measure based on the theo-
retical model of Roll (1984). They nd that illiquidity in corporate bonds is signi cantly
greater than what can be explained by quoted bidask spreads. Feldhutter (2011) estimates
imputed round-trip trades cost as the spread charged by a dealer in a dealer-intermediated
trade. Dick-Nielsen et al, (2012) de ne a new liquidity measure as the rst principal com-
ponent of eight commonly used liquidity measures. They use this measure to study the
corporate bond liquidity in the subprime crisis. Our dynamic factor model is somewhat
related to this approach. For the Treasury market, Krishnamurthy (2002) studies the on-
the-run premium and shows that variation in this premium is driven by the Treasury supply
as well as aggregate factors a¤ecting investors preference for liquid assets. Hu, Pan and
Wang (2012) proposes a liquidity measure for Treasury market as the observed noise in
U.S. Treasury bonds in tting a yield curve. They show that their noise measure captures
episodes of liquidity crises of di¤erent origin.
    A third and important strand of literature pertains to the cost-bene t analysis of -
nancial regulation. By every stretch of imagination, this literature remains considerably
underdeveloped relative to the potential welfare bene ts of rigorous and data-driven regula-
tory intervention. Such limitations have been lamented not only by nancial economists such
as Cochrane (2014), but have been central motivation of judicial intervention4 . Cochrane
(2014) discusses at length the complexity of deriving meaningful assessments of regulatory
counterfactuals in nancial and banking regulation, question also discussed in Posner and
Weyl (2013, 2014). Relative to the pessimistic assessment in Coates and John (2014) of
the infeasibility of meaningful cost-bene t analysis in nancial and banking regulation5 ,
our paper o¤ers a more optimistic counterpoint, at least in terms of ex-post quantitative
assessment6 along the speci c dimension of market liquidity depletion.
   4
      Coates and John (2014) referring to Business Roundtable et al. v. SEC, 647 F. 3d 1144 (D.C. Cir.
2011), report that "One panel of the U.S. Court of Appeals for the District of Columbia Circuit, composed
entirely of Republican-appointed judges, has held that existing law requires the SEC to quantify the costs and
bene ts of its proposed rules".
    5
      Speci cally speaking about the Volcker Rule, Coates and John (2014, p.73): "Could the agencies go
beyond conceptual CBA and conduct a reliable, precise, quanti ed CBA/FR? The short answer is no. There
is simply no historical data on which anyone could base a reliable estimate of the bene ts of preventing banks
from engaging in proprietary trading or investing in hedge and private equity funds."
    6
      See also Cochrane (2014)s discussion of retrospective analysis of nancial regulation.



                                                      6
    A fourth literature touched by this paper revolves around the post- nancial crisis policy
responses. McCarthy, Poole, and Rosenthal (2013) debate political distortions in post-crisis
responses, an issue also explored in Frieden (2015) and Mian, Su , and Trebbi (2014). More
explicitly, Mian, Su and Trebbi (2010) focus on the legislative response to the nancial
crisis pre-dating the Dodd-Frank Act, while Kaiser (2013) o¤ers an interesting and detailed
discussion of the congressional evolution of the Dodd-Frank Act. Finally, the regulatory rule-
making of Dodd-Frank is fully explored from a systematic empirical perspective by Bertrand,
Bombardini, and Trebbi (2015).
    The remainder of this paper is organized as follows. In Section 2 we provide a brief history
of the Volcker Rule, as way of motivating our analysis through a most salient example. In
Section 3 we discuss the main empirical measures, the variables construction, and provide
a descriptive analysis of our samples. In Section 4 we discuss our econometric model and
single breakpoint/multiple breakpoint testing in dynamic factor models. Our main empirical
results on U.S. corporate bonds are reported in Section 5 and on Treasuries in Section 6.
Section 7 concludes.


2       A Brief History of the Volcker Rule
The Volcker Rule refers to Section 619 Title VI of the 2010 Dodd-Frank Act, originally
proposed by former Federal Reserve Chairman Paul Volcker to restrict U.S. banks from
proprietary trading and investing in hedge funds and private equities. As a long-time skeptic
of nancial innovation, Volcker argued that such speculative activity played a central role in
the nancial crisis of 20082009.
    The Volcker Rule rst appeared in a January 2009 Group of Thirty Report, but was
not embraced at the time (Krawiec and Liu, 2015). Inuential members of the Obama
Administration, including former Treasury Secretory Timothy Geithner and Director of the
National Economic Council Larry Summers, actively opposed the Volcker Rule, which they
believed to be overly restrictive for banks. As a result, the Volcker Rule was not even part
of the initial nancial reform legislation proposed by the Treasury Department7 .
    Throughout the summer and fall of 2009, the initial Treasury proposal were hammered
by critics as one catering to Wall Street. As discontent brewed, the Obama administration
started to shift towards Paul Volckers proposal (Skeel, 2010). On January 21, 2010, Presi-
dent Obama, with Paul Volcker by his side, publicly announced his support for the rule. On
    7
    Department of The Treasury, Financial Regulatory Reform: A New Foundation: Rebuilding Financial
Supervision and Regulation (2009), available at
  http://www.treasury.gov/initiatives/Documents/FinalReport_web.pdf



                                                7
July 21, 2010, the Volcker Rule, together with other provisions of the Dodd-Frank Act, was
signed into law.
    Like many other provisions of the Dodd-Frank Act, the Volcker Rule was highly incom-
plete when the legislation was passed. The speci c rulemaking was delegated to ve federal
agencies, including the Federal Reserve Board, FDIC, OCC, CFTC and SEC. Given the
substantial incompleteness of the legislative statute, the rulemaking process ignited a heated
debate among regulators and industry special interest groups: over 17; 000 public comments
were led. Big banks such as Bank of America, Goldman Sachs, and JP Morgan expressed
concerns about the rule. Conservative politicians such as the Chairman of the House Fi-
nancial Services Committee, Representative Spencer Bachus, vowed to limit the e¤ect of
the Volcker Rule8 . Industry lobbyists were also pushing for loosening the restrictions or
extending the compliance deadlines.
    Due to all the above controversies, the implementation of the Rule was delayed multiple
times. Congress originally mandated that the Volcker Rule go into e¤ect in July 2012, two
years after Dodd-Frank passed. However, during his report to Congress on February 29, 2012,
Federal Reserve Chairman Ben Bernanke said that the central bank and other regulators
would not meet that deadline. After missing the rst deadline, regulators estimated that
the rule would be nished during the rst few months of 2013. Again, this second deadline
was missed. On December 10, 2013, all ve of the necessary regulatory agencies approved
a version of the Volcker Rule which had a longer compliance period and fewer metrics than
earlier proposals9 . However, the approval was immediately followed by an emergency lawsuit
  led by the American Bankers Association, bringing the ve regulatory agencies back to the
reviewing process. On January 14, 2014, revised nal regulations were approved by all
  ve regulatory agencies. The e¤ective date was set on April 1, 2014 and the deadline of
conformance was extended to July 21, 2015. By that time, the Volcker Rule had grown into
a 953-page document, adding to the 2; 400 page Dodd-Frank Act. In contrast, the Federal
Reserve Act of 1913 which created the the Federal Reserve System was only 31 pages long,
and the Glass-Steagall Act of 1933, the most important regulatory legislation post the Great
Depression, was only 37 pages.
    Anticipating tighter regulation, big banks started to gradually retreat from businesses
prohibited by the Rule well before details were nalized. In September 2010, two months
after the passage of Dodd-Frank, JP Morgan rst announced the closing of its proprietary
  8
    See "Bachus Urges Regulators Not to Rigidly Implement Volcker Rule", by Deboarah Solomon, The
Wall Street Journal, November 4, 2010
  9
    See "Volcker Shrugged", PwC Financial Services Regulatory Practice, December, 2013.




                                               8
trading desks10 . Two days later, Goldman Sachs followed11 . Several other banks such as
Morgan Stanley, Bank of America, Citi Group, and RBC announced the shutdown of their
proprietary trade desks one after another from January 2011 to April 2014, spanning the
whole rulemaking period12 .
     With banks retreating from proprietary trading due to the anticipation of tighter regu-
lation, market participants started to worry about unintended consequences of the Volcker
Rule on banks market making capacity. Although the Volcker Rule exempts market-making
related trading activities, critics argued that the proposed metrics of exemption would never-
theless substantially discourage the use of market making discretion (Du¢e, 2012). Support-
ing this claim, there seemed to be evidence that banks started shedding their corporate bond
inventories. Figure 1 shows one of the most cited stylized facts: the amount of corporate
bonds held by dealer banks declined by nearly 80% since their peak of $235 billion in 2007
according to Federal Reserve data13 . In terms of the percentage of the total corporate bond
outstanding, the decline is from more than 5% in 2007 to under 1% in 2014. Because the
corporate bond market relies heavily on the banks to make market, this dramatic decline of
dealer inventories has fed concerns about deteriorating market liquidity under Dodd-Frank
and the Volcker Rule.
     As the above discussion should have made clear, the protracted rulemaking process and
complicated anticipatory response by market participants posit a daunting challenge for
researchers trying to pin down when regulation started to take e¤ect on market liquidity, or
if it had any e¤ect at all. To address this challenge, we employ statistical methods which
allow us to estimate the dates of breaks in liquidity without requiring a priori knowledge of
the exact timing. We also complement this approach with a standard di¤erence-in-di¤erences
matching design around a salient regulatory event.
  10
     See "J.P. Morgan to Close Proprietary-Trading Desks" by Matthias Rieker, The Wall Street Journal,
Sep 1, 2010.
  11
     See "Goldman shutting proprietary trading", The Globe and Mail, September 3, 2010.
  12
     See "Morgan Stanley Team to Exit In Fallout From Volcker Rule" by Aaron Lucchetti, The Wall Street
Journal, January 11, 2011; "Bank Of America Is Shutting Down Merrills Bond Prop Trading Desk" by
Katya Wachtel, Business Insider, June 10, 2011; "Citigroup to Close Prop Trading Desk" by Kevin Roose,
The New York Times, January 27, 2012; "RBC to Close Proprietary-Trading Desk", by Rob Copeland, The
Wall Street Journal, April 15, 2014.
  13
     See "Markets: The Debt Penalty" by Tracy Alloway, Financial Times, September 10, 2013. See also
"Investors Raise Alarm Over Liquidity Shortage" by Christopher Whittall and Juliet Samuel, The Wall
Street Journal, March 18, 2015.




                                                  9
3     Data
3.1     U.S. Corporate Bonds Sample Description
The rst main data set used for this paper is the Financial Industry Regulatory Authoritys
(FINRA) TRACE. This data currently provides transaction-level information of approxi-
mately 99% of all secondary corporate bond market transactions (not the primary o¤ering).
Trade reports are time stamped and include information on the clean price and par value
traded, although the par value traded is truncated at $1 million for speculative grade bonds
and at $5 million for investment grade bonds14 . TRACE also reports whether a trade is a
buy or sell, and whether a trade is between two dealers or between a dealer and a customer15 .
TRACE has expanded its coverage through three phases. In Phase I on July 1, 2002, FINRA
began disseminating price and volume data for trades in selected investment-grade bonds
with initial issue of $1 billion or greater, and 50 high-yield securities disseminated under
FIPS. Phase II, implemented on April 14, 2003, expanded dissemination to smaller invest-
ment grade issues, bringing the number of bonds to approximately 4; 650. Finally, Phase
III, implemented completely on February 7, 2005, required reporting on approximately 99%
of all public transactions. To obtain a balanced panel, our sample covers the post Phase III
period, April 1, 2005 to December 31, 2014, which covers essentially all the U.S. corporate
bonds. We lter out erroneous trades following Dick-Nielsen et al. (2012).
    We merge the cleaned TRACE transactions to bond characteristics provided by FISD.
This data provides bond-level information such as issue date, issuance size, coupon rate,
maturity date, credit ratings, underwriter identity and roles. Following Dick-Nielsen et al.
(2012), we limit the sample to xed-rate bonds that are not callable, convertible, putable, or
have sinking fund provisions. We drop bonds issued more than 10 years ago, since these old
bonds present very few transactions. Since our goal is to provide the most comprehensive
coverage of U.S. corporate bond market, we keep bonds with semi-annual coupons because
they are the most common bonds in the U.S. This is di¤erent from Dick-Nielsen et al. (2012),
who keep the no-coupon bullet bonds. The raw TRACE data contains 34; 422 bonds. After
applying the above lters, our nal sample contains 18; 632 semi-annual coupon bonds. In
comparison, Dick-Nielsen et al. (2012) cover 5; 376 bullet bonds.
    Using the underwriting information from FISD, we can link each bond to its lead un-
derwriters. There are several issues that need addressing. First, FISD does not provide
  14
     Non-truncated trade volume is provided in TRACE enhanced, a new version of TRACE. However,
TRACE enhanced has 18 months of time lag in disseminating.
  15
     In a regulatory version of TRACE used by Goldstein and Hotchkiss (2007), it can be directly identi ed
whether the dealer for a given trade is a member of the underwriting syndicate for that bond. However,
such information is not available in the public version.


                                                   10
a unique identi er for each underwriter. Instead, whenever an underwriter changes name,
FISD creates a new ID. For example, J P Morgan Securities Incorporated and J P Morgan
Securities LLC are assigned two di¤erent IDs. The second problem is that FISD under-
writers are typically at the subsidiary level. For example, after Bank of America acquired
Merrill Lynch in 2008, there are still bonds underwritten by Merrill Lynch, while the num-
ber of bonds underwritten by Bank of America goes down to zero. To create a consistent
time series measure for each underwriter, we standardize the name provided by FISD and
create a new ID for each underwriter. We further assign bonds issued by subsidiaries to the
corresponding holding companies. Lastly, we combine two merged identities to compute the
pre-merger liquidity measures to maintain a balanced bond portfolio.
    We rst construct liquidity measures for each corporate bond in our sample. Then
we aggregate the bond-level liquidity to underwriter-level and aggregate-level. For the
underwriter-level sample, we calculate the equal weighted average by bond rating group
(investment-grade v.s high-yield) and issue size (above $1 billion v.s. below $1 billion) for
each underwriter. Since smaller underwriters only underwrite a limited number of bonds,
this makes the underwriter-level measure of liquidity quite noisy. Therefore, we keep the top
4 biggest underwriters, Bank of America (Merrill Lynch), JPMorgan Chase, Morgan Stanley
and Goldman Sachs, and combine the rest into a residual Others group. In our analysis
on the bankruptcy of Lehman Brothers and the takeover of Bear Stearns, we separate these
two banks from the Others group.


3.2     Corporate Bonds Liquidity Measures: Construction
We rst construct the following nine measures of liquidity for each corporate bond in our
sample. Then we calculate the equal weighted average for each underwriter16 . All measures
below are decreasing in the level of liquidity. Some measures require a minimum number of
trades to compute. This leads to many missing observations for some thinly traded bonds.
To avoid introducing noises into our underwriter-level measure, we drop those measures for
a bond if more than 25% of observations are missing17 . For those measures with less 25%
missing observations, we back ll the missing observations with lagged values.
   1. Amihud measure. Amihud (2002) constructs an illiquidity measure based on the
theoretical model of Kyle (1985). We use a slightly modi ed version of this measure following
Dick-Nielsen et al. (2012). The Amihud proxy measures the price impact of a trade per unit
traded. For a given bond, de ne rj;i;t as the return and Qj;i;t as the trade size (in million
  16
    We also experimented with value-weighted averages with similar results to the ones reported below.
  17
    We still keep other measures of the same bond, because requiring all the measures to be non-missing is
overly restrictive.


                                                   11
$) of the j th trade on day i in month t. The daily Amihud measure is the average of the
absolute returns divided by the corresponding trade size within day i:

                                                     Ni;t
                                                 1 X jrj;i;t j
                                 Amihudi;t    =
                                                Ni;t j=1 Qj;i;t

where Ni;t + 1 is the number of trades recorded on day i. We exclude retail trades (i.e. trades
below $100; 000 in volume), as they are unlikely to have price impact. At least two trades are
required on a given day to calculate the measure, and we de ne a monthly Amihud measure
by taking the median of the daily measures within month t.
    2. Imputed round-trip cost (IRC). Feldhutter (2012) shows that if a bond that does
not trade for days suddenly has two or three trades with the same volume within a short
period of time (one day in our de nition), then such trades are likely part of a pre-matched
arrangement in which a dealer has matched a buyer and a seller. These trades are de ned
as a set of imputed round-trip trades. The di¤erence between highest and lowest price in
a set of imputed round-trip trades is the bid-ask spread collected by the dealer, which is a
measure of liquidity of the bond. We follow this approach. Speci cally, for a given bond,
on each day i we identify sets of imputed round-trip trades indexed by k. A set of imputed
round-trip trades involves two or more transactions with the same trading volume. De ne
  max           min
Pk;i;t (resp. Pk;i;t ) as the maximum (resp. minimum) price among all the transactions in
the k-th set of round-trip trades for that bond on day i in month t. The imputed round-trip
cost of k-th set of round-trip trade is de ned as:

                                                max        min
                                               Pk;i;t    Pk;i;t
                                  IRCk;i;t   =        min
                                                                :
                                                    Pk;i;t
We de ne a monthly IRC measure by taking the mean of the IRC of each set of imputed
round-trip trades within month t, weighted by the number of transactions involved in each
set of imputed round-trip trades.
    3. Roll measure. The intuition of the Roll measure is as follows: the transaction price
tends to bounce between the bid and ask price, which causes consecutive trade returns to be
negatively correlated. Under certain assumptions as shown in Roll (1984), the Roll measure
equals to the bid-ask spreads. We follow Dick-Nielsen et al. (2012) in the construction of
the Roll measure. The Roll measure is de ned as two times the square root of the negative
covariance between two consecutive daily returns ri;t ; ri 1;t in month t. If the covariance is
negative, the covariance is replaced with zero.
                                            q
                                Rollt = 2       Cov (ri;t ; ri   1;t )



                                                12
    4. Non-block trades. A trade is de ned as non-block trade if the trading volume is
less than $5 million for investment-grade bonds, and $1 million for high-yield bonds. The
frequency of non-block trades is de ned as the ratio between the number of non-block trades
and the total number of trades in month t.
    5. Corporate bond spreads. The corporate bond spread is de ned as the di¤erence
between corporate bond yields and a Treasury bond with the same maturity. The Treasury
yields are obtained from Gürkaynak et al. (2007). We exclude bonds with less than 2 years
or more than 30 years to maturity following Dick-Nielsen et al. (2012).
    6. Turnover (negative). The annualized turnover for month t is de ned as follows:

                                        Total Trading Volume t
                         T urnovert =                           12:
                                           Bond Issue Size

In what follows we take the negative of turnover as proxy of illiquidity, for consistency with
the other measures.
    7. Zero trading days. We de ne this measure as the ratio between days with zero trade
and the number of trading days in month t.
    8 . Variability of Amihud and 9. Variability of IRC
    Investors not only care about the current level of liquidity, but also the risk of future
liquidity. Therefore, we create the standard deviations of the daily Amihud measure and
imputed round-trip costs in a month as measures of liquidity risk.


3.3    U.S. Treasuries Sample Description
We use the CRSP Treasury database to construct our liquidity measures for the U.S. Treasury
market. The daily data le is used to construct the Roll measure, and the monthly data le
is used to construct the on-the-run premium.
    We restrict our analysis to the same period as our corporate bond sample, April 1,
2005 to December 31, 2014. Our sample consists of Treasury bills, notes, and bonds that are
noncallable, nonowering, and with no special tax treatment. We also drop observations with
obvious pricing errors such as negative prices. Treasury securities with remaining maturity
less than 30 days are also dropped because of potential liquidity problems. After applying
the lters, our nal sample contains 1; 124 bonds. In addition to bond prices, we obtain the
total Treasury trading volume from Securities Industry and Financial Markets Association
(SIFMA), and the total public debt outstanding from Bloomberg.




                                              13
3.4     Treasury Liquidity Measures: Construction
1. Yield curve tting noise
    Hu et al. (2013) proposes a market-wide liquidity measure by exploiting the connection
between the amount of arbitrage capital in the market and observed noise in U.S. Treasury
bondsthe shortage of arbitrage capital allows yields to deviate more freely from the curve,
resulting in more noise in prices. They construct the noise measure by rst tting Treasury
daily prices into a smooth yield curve, and then calculate the mean squared errors18 .
    2. On-the-run premium
    On-the-run Treasury bond (latest issue) usually enjoys a price premium over old bonds
with similar maturity. We follow Gurkaynak et al. (2007) to construct the liquidity premium
by comparing an on-the-run issue to a synthetic o¤-the-run Treasury security with the same
coupon rate and maturity date19 . The yield of the synthetic o¤-the-run Treasury security
is computed from the o¤-the-run yield curve constructed by Gurkaynak et al. (2007). The
on-the-run premium is de ned as the di¤erence between the yield of this synthetic o¤-the-run
bond and the on-the-run bond.



                            on-the-run premium t
                             = o¤-the-run yield t        on-the-run yield t :

    3. Roll measure and 4. Turnover (negative)
    Roll measure and Turnover (negative) measure are constructed similarly as in the case
of corporate bonds.


3.5     Summary Statistics and Descriptives
Figure 2 reports the full timeline of events relevant to our analysis. The summary statistics
of the aggregate-level liquidity measures of the U.S. corporate bonds for the period April
2005 to December 2014 are reported in Table 1.
    The corporate bond market is very illiquid compared to the equity market. For a typical
bond, there is no single trade on 61% of business days. The annualized turnover rate is only
40%. In comparison, stocks in NYSE have a turnover ratio of 92% in December 201420 .
  18
     We obtain the measure from the authors website at http://www.mit.edu/~junpan/Noise_Measure.xlsx
  19
     Some authors measure the on-the-run premium relative to the rst or second o¤-the-run security, but
this method introduces bias since those o¤-the-run issues will have shorter duration. The bias will become
more signi cant in recent years when the yields were very low.
  20
     See http://www.nyxdata.com/nysedata/asp/factbook/
  for the historical trading volume of NYSE stocks.


                                                   14
Among all the trades, only 5% are block trades.
    In such an illiquid market, nding a trading counterparty can be occasionally di¢cult.
For this reason, typically corporate bond investors rely on specialized dealers to make the
market rather than computerized trading platforms (as for example for Treasuries). Dealers
usually hold certain amounts of inventories and use them to absorb temporal mismatches
of supply and demand. As compensation for this service, dealers charge substantial fees for
providing liquidity.
    To get a quantitative assessment, one can compare various trading cost measures to credit
spreads, the compensation for investors to bear the credit and liquidity risk of corporate
bonds. The average credit spread of a U.S. corporate bond over a Treasury bond is 2:20%
over our sample period. In comparison, the mean Amihud measure, which is based on the
impact of $1 million dollar trade, is 0:95%, as reported in Table 1. This amounts to roughly
half of the average credit spread earned in a year. The average IRC, which measures the
cost charged by dealers in a round-trip trade, is 0:70%. This equals to a third of the average
credit spread. The average Roll measure is 1:57%, which implies a bid-ask spread as large
as three-fourth of the average credit spread.
    Additionally, investors face high uncertainty in trading cost when executing their trades,
as shown by a high time series variability of the Amihud and IRC measure. In synthesis,
Table 1 shows that the U.S. corporate bond market is typically not particularly liquid. In this
respect, the a priori concerns of public commentators of the e¤ects of regulatory intervention
on market liquidity were well placed.
    In Table 2 we report the monthly linear correlations for each pair of liquidity proxies, to
show consistency across our nine di¤erent measures of liquidity. Correlations are typically
positive and sizeable. A partial exception is the Non-block trades measure, which we will
discuss further below.
    In Table 3, we provide more information on the liquidity for di¤erent underwriters (Bank
of America, Goldman Sachs, JP Morgan Chase, Morgan Stanley, and all Others), issue sizes
(large and small), and credit ratings (high-yield vs. investment-grade). This provides a total
of 180 (= 9  5  2  2) disaggregate liquidity series. On average, large-size issues are more
liquid than small-size issues, and high-yield bonds are more liquid than investment-grade
ones. The reason why investment-grade bonds are generally less liquid is that their main
buyers are buy-and-hold investors, such as banks, insurance companies and pension funds,
while high-yield bonds attract more credit hedge funds, which trade more frequently. There
is some dispersion in liquidity across underwriters, which come from two sources. First,
the bond characteristics of di¤erent underwriters can di¤er. Second, di¤erent underwriters
may charge di¤erent fees in making markets, depending on their balance sheet capacity, risk


                                              15
appetite, market power, etc.
    Figure 3 plots the underwriter-level liquidity measures for the four biggest underwriters:
Bank of America (which includes Merrill Lynch both before and after September 2008 for
consistency), Goldman Sachs, JP Morgan Chase, and Morgan Stanley, which accounts for
40% of market share plus a cumulate of all other remaining bonds ("Others" category). For
ease of representation we aggregate the data across issue size and credit rating, in order to
report a single time series for each underwriter and each liquidity proxy. The key observation
is a strong co-movement among these time series. All liquidity measures spiked during the
2008-2009 nancial crises, indicating liquidity depletion, but most of them have recovered
since, with one partial exception: Non-block trades post-200921 . In our later analysis, we
will explore the rich information in both the aggregate-level and underwriter-level measures.


4      Econometric Model
Our goal is to formally test for structural breaks in the market liquidity of xed-income
assets in the aftermath of the nancial crisis, possibly pinning down the role of regulation
by matching estimated breakpoints with the exact timing of regulatory reform. We present
here the econometric setup that we are going to employ.
    As anticipated in Section 3 we take both an aggregate-level and a disaggregate perspective
in our analysis. We also refer to the latter as underwriter-level analysis. Let us de ne the
matrix Y of L aggregate (i.e. market-level) liquidity measures observed for T periods. Y is
of dimension (T  L). With the term "aggregate" liquidity measure we mean a measure of
liquidity (such as those listed in Subsection (3.2)) that aggregates all securities in a market
irrespective of identity of the underwriter, issue size, or credit rating. Although intuitive, this
approach may mask heterogeneity in the dynamics of di¤erent types of securities. Therefore,
in order to allow our methodology to identify speci c structural breaks that might arise
only within particular classes of securities or only for bonds where markets are made by
speci c underwriters/banks, we will refer to disaggregate liquidity measures as the matrix
X of N > L liquidity measures observed for T periods. X is of dimension (T  N ) where
  21
    Intuitively, during the nancial crisis as market liquidity dried up, it became ingreasingly di¢cult to
execute large trades (i.e. block trades). Investors had to break up their trades into smaller portions, either to
avoid excessive price movements or because dealers suddenly became less willing to take on large positions.
Non-block trades frequency increased as a consequence. This measure however does not appear to have
recovered since the nancial crisis. Anecdotal evidence suggests that this may be due to a concurrent change
in the investor population. After the crisis, more and more bond mutual funds and ETFs, which behave
di¤erently from the traditional group of investors in terms of trade sizes, appear to have entered the market.




                                                       16
each column measures liquidity grouping bonds at the level of

                    (identity of the underwriter  issue size  credit rating):

As a matter of accounting, recall that for our case we have L = 9 measures, 4 major
underwriters plus 1 for the residual Others, 2 types of issue sizes (small or large), 2 types of
credit rating (high yield and investment grade), hence N = 180. Our sample covers T = 117
months.
    To the direct question of whether regulatory intervention has produced structural breaks
in the level of liquidity, in either Y or X, standard tests for multiple breakpoint estimation
(Bai and Perron, 1998, 2003) will be employed.
    To the deeper question of whether the underlying structure of correlation and of latent
dynamics of liquidity across di¤erent assets have indeed structurally changed, we will employ
a more innovative approach through dynamic factor modeling of X, assessing structural
breaks in factor loading or in unobserved factors. Such methodologies are more recent and
deserve a more complete discussion, which we provide below. This discussion will be also
helpful in briey recalling the main features of some standard approaches in structural break
estimation.


4.1     Dynamic Factor Model
This section introduces the basic notation, econometric setup, and follows the exposition
in Chen et al. (2014), to which we refer for a detailed discussion of the proofs and the
Montecarlo evidence of power and size of the tests. Consider a set of N observed liquidity
measures constructed as in Section 3 and observed for t = 1; :::; T periods, say, at monthly
frequency. The matrix of observed underwriter-level variables22 X of dimension (T  N ) is
expressed as function of r unobserved factors F of dimension (T  r), a matrix  of factor
loadings of dimension (N  r), and a matrix of idiosyncratic errors " of dimension (T  N ).
As typical in the literature, we have in period (row) t:

                                            Xt = Ft0 + "t :                                          (1)

This formulation accommodates exibly several possible latent structures: r static factors;
or r~ dynamic factors and p = r=~
                                r 1 lags; or an arbitrary combination of static and dynamic
factors and lags (Stock and Watson, 2011).
  22
    For the dynamic factor model analysis let us indicate with an abuse of notation X as the matrix of rst
di¤erenced and normalized liquidity measures, as indicated by Stock and Watson (2011).



                                                   17
    Due to their exibility in accommodating general dynamics across correlated time series,
large factor models have enjoyed substantial success in the macroeconomics and nance
literature. Stock and Watson (2002) show that the latent factors are consistently estimable
by principal component analysis (PCA), an approach we follow here. PCA allows to estimate
the r factors of X :                     h                      i
                                    F^t  F^1t ; F^2t ; :::F^rt

by focusing on the rst r largest eigenvalues of the matrix XX 0 in the case T  N (or
of the matrix X 0 X in the case T > N ) and selecting the (appropriately orthogonalized
and normalized)
        h           corresponding
                    i                  eigenvectors. Following Chen et al. (2014) we also de ne
 ^        ^      ^
F 1t  F2t ; :::Frt .
    The integer number of factors r has to be estimated, as the true number of factors is
unknown. Let us indicate with r^ such estimated value over the full sample.
    To this goal we employ ten di¤erent estimators, some with better nite sample properties
than others, with the aim of providing an exhaustive range of r^s. Eight of the estimators
we employ follow the popular information criteria (IC) proposed by Bai and Ng (2002),
including their preferred ICp1 , ICp2 , P Cp1 , and P Cp2 . IC estimators, however, can occa-
sionally display in nite samples a somewhat undesirable dependency on one speci c para-
meter necessary to the estimation: the maximum number of admissible factors in the model
(typically indicated as kmax). This may occasionally lead to overestimation of the true
number of factors (Ahn and Horenstein, 2014). It is also the reason we additionally employ
the recent ER (eigenvalue ratio) and GR (growth ratio) estimators of Ahn and Horenstein
(2014), which do not share this drawback and, by focusing on the ratio of subsequent eigen-
values (or the ratio of their logs), also hinge on the straightforward intuition of principal
component analysis screeplots (i.e. a popular graphical representation of the progressive
explanatory power of each principal component ranked by size of its eigenvalue). We take
under consideration the range of number of factors between the minimum and the maximum
of fICp1 ; ICp2 ; ICp3 ; P Cp1 ; P Cp2 ; P Cp3 ; AIC3 ; BIC3 ; ER; GRg, allowing for at least r^ = 2
unobserved factors (a necessary condition for the statistical tests below).


4.2    Single Breakpoint Testing
We now proceed in introducing structural breaks in (1) and focus initially on the methodology
for testing a single breakpoint, leaving multiple breakpoints to Section 4.3. It is relevant
 rst to specify whether one is interested in breaks in the factor loadings  or in the factors




                                                18
F . Let us begin by representing a single structural break in all factor loadings at date  :

                                Xt = Ft0 + "t    t = 1; :::;                               (2)
                                Xt = Ft0 + "t     t =  + 1; :::; T                          (3)

where is the post-break matrix of factor loadings of dimension (N  r). An important
insight of Chen et al. (2014) is that (2)-(3) can be represented as

                                     Xt = Ft0 + G0t + "t                                   (4)

where  =        measures the change in the loadings and

                                   Gt = 0    t = 1; :::; 
                                   Gt = Ft t =  + 1; :::; T:

    The notation so far has focused on a single structural breakpoint for all r factors. At a
given breakpoint, Chen et al. (2014) distinguish between two types of breaks: small and large.
Consider k2 small breaks, of the type discussed by Stock and Watson (2002, 2009). These
are de ned as local-to-zero instabilities in the factor loadings that asymptotically average
out without a¤ecting estimation and inference under PCA. These are not the type of breaks
we are interested in. In the context of large policy shifts, one is most likely interested in big
structural breaks, indicated as k1 = r k2 . The formal de nition is given in Chen et al.
(2014), but more importantly it is proven that under k1 big breaks in (4), F^t estimated by
PCA delivers inconsistent estimates of the space of the original factors Ft . Instead, de ning
G1t the partition of Gt corresponding to the large breaks only, the full sample PCA delivers
consistent estimates of the space of the new factors [Ft G1t ]. Speci cally, over the full sample
the number of factors tends to be overestimated by k1 . Chen et al. (2014) prove that a factor
model with r unobserved factors and with 0 < k1  r big structural breaks in the factor
loadings at time  admits a representation with (asymptotically) r + k1 factors. Particularly,
given an IC estimator in Bai and Ng (2002) r^ and under general assumptions, it is shown
(Proposition 2, p.34):
                                            r = r + k1 ] = 1:
                                     lim P [^                                                 (5)
                                   N;T !1

   An important remark at this point is to notice that if the break date  were known,
one could recover a consistent estimate of r by simply splitting the sample in a before-
breakpoint and after-breakpoint subsamples and performing PCA and Bai and Ng (2002)



                                                 19
or Ahn and Horenstein (2014) in either subsample. In either case,

                                                    rbef ore = r] = 1
                                             lim P [^
                                           N;T !1

                                             lim P [^
                                                    raf ter = r] = 1:
                                            N;T !1


both r^bef ore and r^af ter typically lower than the full sample estimate r^.
    For the sake of generality, we take the exact breakpoint date  as unknown. Although we
explicitly consider the exact date of the nalization of the Volcker Rule in the di¤erence-in
di¤erences matching below, the possibility of anticipatory behavior or of delayed response
for a policy intervention so sizeable and publicly debated would caution against a known
breakpoint approach. Hence, we do not impose such restriction here.
    Chen et al. (2014) present a test for the null H0 : k1 = 0 versus the alternative of at
least one big break H1 : k1 > 0 based on detecting breaks in F^t estimated over the full
sample by PCA. The implementation is straightforward. De ne ^ the estimated (^       r 1)  1
coe¢cient vector obtained by regressing F^1t on F^ 1t and S^ its corresponding Newey-West
HAC covariance matrix23 . One can test for structural breaks in by focusing for the case of
unknown breakpoint  = T  with  2   (0 ; 1 0 ) and 0 < 0 < 1 based on Andrews
(1993) Sup-Wald statistic or Sup-LM statistic. Speci cally, for given ; and hence  =  =T ,
de ne ^1 () the estimated (^     r 1)  1 coe¢cient vector obtained by regressing F^1t on F^ 1t
for t = 1; :::;  and ^2 () the estimated (^  r 1)  1 coe¢cient vector obtained by regressing
F^1t on F^    1t   for t =  + 1; :::; T the Sup-Wald statistic is:

                             L () = sup T (1 )                                                            (6)
                                      2
                                                  0                                                 
                                     ^1 () ^2 () S^                       1       ^1 ()   ^2 ()


and the Sup-LM statistic is:

                                                 1
                           L () = sup                                                                        (7)
                                     2   (1       )
                                          T
                                                                   !0                    T
                                                                                                          !
                                       1 X^                 ^                         1 X^
                                     p       F           1t F1t        S^   1
                                                                                     p       F     ^
                                                                                                 1t F1t
                                        T t=1                                          T t=1

In the analysis we will maintain a conservative 0 = 0:3 which in our case is not overly
restrictive as it allows a search for structural breaks between January 2008 and January
2012 covering the full nancial crisis, the full legislative debate on Dodd-Frank and large
  23
       Newey and West (1987). S^ is estimated over the full sample.


                                                                20
part of the regulatory rulemaking period for the Volcker Rule. We employ the critical values
for the (6) and (7) statistics reported in Andrews (1993).
    To conclude this subsection, let us consider the matter of detecting a structural break
in the factors themselves as opposed to a break in the factor loadings at  . There are at
least two di¤erent formulations for a break in the factors one should consider. First, the
formulation discussed in Chen et al. (2014) considers maintaining unvaried the loadings ,
but changing the variance-covariance matrix of the r original factors:

                                 E [Ft Ft0 ] =  t = 1; :::;                                 (8)
                                 E [Ft Ft0 ] =  t =  + 1; :::; T                            (9)

where  is the factor covariance before the break and  after the break and both are (r  r).
Given that the approach above focused on testing breaks in the F^t PCA factors estimated over
the full sample, it may not appear surprising that the Sup tests above (based on regressing
F^1t on F^ 1t ) will be naturally able to pick up breaks of the type (8)-(9). In fact, the same
regression approach described above will reject the null of big breaks in presence of changes
in factors.
     It is possible however to discriminate between breaks in loadings and breaks in factors
by noticing that in the case of breaks in factors:

                      r = r] = lim P [^
               lim P [^               rbef ore = r] = lim P [^
                                                             raf ter = r] = 1:
              N;T !1             N;T !1                     N;T !1


This implies that in the case of breaks in the factors typically r^ estimated over the whole
sample will be identical as when estimated on subsamples either before or after the break-
point. In the case of breaks in the loadings, instead, r^ estimated over the full sample will be
higher than when estimated on subsamples either before or after the breakpoint, as evident
from the result in (5).
    A second formulation for a break in the factors is more drastic and entails a break in
the number of factors r in (1), that is the addition or subtraction of speci c factors in the
model at date  . Di¤erently from the formulation discussed in Chen et al. (2014), for the
detection of this type of breaks one cannot rely on a comparison between the whole sample r^
and any of the two subsample estimates r^bef ore and r^af ter . Rather we need to rely on directly
comparing r^bef ore and r^af ter themselves. Given a consistent estimate of the breakpoint  ,
any di¤erence in the number of estimated factors r^bef ore and r^af ter , which are consistent
estimates of the rank of the factor space within each subsample, is indication of a break in
(1).


                                                21
4.3     Multiple Breakpoint Testing
Let us now focus on multiple structural breaks M in factor loadings at unknown dates
1 ; 2 ; :::; M . This structure partitions the sample period of length T in M + 1 intervals:

                                      Xt = Ft0 + "t               t = 1; :::; 1
                                                   1
                                      Xt =             Ft0 + "t    t = 1 + 1; :::; 2
                                            :::
                                                   M
                                      Xt =              Ft0 + "t     t = M + 1; :::; T

where m with m = 1; :::; M are the post rst break matrices of factor loadings of dimension (N  r).
In the context of multiple breakpoints, standard estimators in the literature include the ones
proposed by Bai and Perron (1998, 2003), which we employ in combination to the regression
approach delineated in Section 4.2. Considering the regression of F^1t on F^ 1t with the goal
of detecting not one, but multiple breakpoints, we implement the recommended approach of
Bai and Perron (1998, 2003).
    Consider for the interval t = m +1; :::; m+1 the regression of F^1t on F^ 1t in this subsample
and call the estimated coe¢cient ^m . Notice that, like ^1 () and ^2 () in Section 4.2, ^m
depends on the breakpoint parameters,
                                  0        m = m =T and m+1 = m+1 =T . Given M , let us
also de ne =^     ^0 ^0
                    ; ; :::; ^0
                                     . Bai and Perron (1998) rst consider the Sup-F type test
                      1   2         M +1
of the null hypothesis of no structural break (M = 0) against the alternative hypothesis that
there is a known number of breaks M = k :

                               sup FT (1 ; :::; k ; r                 1)
                           (1 ;:::;k )
                                                                        
                                1       T         (k + 1) (r        1)            
                                                                             ^0 R0 RSR
                                                                                                 1
                              =                                                     ^ 0               R^
                                T                  k(r 1)
                                   0                                                       
where R is the matrix such that R ^  = ^10                              ^0 ; :::; ^0   ^0         and S^ is now an estimated
                                                                         2         k    k+1

HAC variance covariance matrix of ^ 24 .
   As the number of breaks is unknown, a second type of test is more useful: Bai and
Perron (1998) consider a test of the null hypothesis of no structural break (M = 0) against
the alternative hypothesis that there is an unknown number of breaks M = m with m
  24
    In the tests we perform we apply a short trimming of 10%. The Bai and Perron requires a minimal
admissible distance expressed as fraction of T among any pair of breakpoints m and m+1 and we set it to
10% of the sample length, in order to allow for relatively close multiple breaks. In all the test we also allow
the distribution of "t to vary across di¤erent intervals.




                                                                   22
ranging between 1 and m, which is given25 . The test is referred to as the double maximum
test and two di¤erent statistics are employed:

                               U D max FT (m;
                                            r                1)
                                = max        sup FT (1 ; :::; k ; r       1)
                                   1mm
                                        ( ;:::; )
                                           1      k



which is unweighted with respect of each break number, and

                            W D max FT (m;
                                         r            1; a1 ; :::; am )
                             = max am           sup FT (1 ; :::; k ; r        1)
                               1mm
                                             (1 ;:::;k )


which is a weighted version, where weights are de ned such that the marginal p-values are
equal across values of m 26 .
    The nal test proposed by Bai and Perron is a sequential test. One proceeds by testing
` breaks against ` + 1 breaks. The test is commonly labelled sup FT (` + 1j`) and intuitively
is built as follows. Consider the ` + 1 intervals generated by the ` break points under the
null hypothesis. Within each interval a separate test of the type sup(1 ) FT (1 ; r 1) is run,
i.e. a test of the null hypothesis of no break versus the alternative hypothesis of 1 break.
The test rejects the null hypothesis in favor of ` + 1 breaks if, relatively to the sum of
squared residuals obtained under the ` breaks model obtained by regressing F^1t on F^ 1t and
aggregated across all intervals, there is one additional break that produces a sum of squared
residuals su¢ciently smaller under the ` + 1 breaks model.
    Bai and Perron (2003) recommend to rst obtain both the U D max FT (m;             r 1) and
W D max FT (m;   r 1; a1 ; :::; am ) to test whether at least one break is detected in the entire
sample, as these tests are more prompt in rejecting the null hypothesis in presence of multiple
but contiguous breaks (e.g. which would be the case for instance if there were a break at
the beginning of the crisis and one at its end). If at least one break is detected, then the
sequential approach should be employed. Speci cally one should select M = m such that
sup FT (` + 1j`) are insigni cant for `  m: We follow this approach here.
  25
     In the tests we perform we allow for a maximum of m   = 5 total breakpoints (which, as shown below,
will prove to be su¢ciently high and is also the value suggested in Bai and Perron, 2003).
  26
     Speci cally a1 = 1 and am = c(r 1; ; 1)=c(r 1; ; m), for m > 1, where is the signi cance level
of the test and c(r 1; ; m) is the asymptotic critical value of the corresponding Sup-F test for m breaks,
which is reported by Bai and Perron (1998, 2003).




                                                       23
5     Results for Market Liquidity of U.S. Corporate Bonds
For U.S. corporate bonds we present four di¤erent estimation strategies. We will begin by
applying multiple breakpoint tests to measures of market liquidity provisions.
    Subsequently we will focus on a dynamic factor model and presents results of both single
and multiple breakpoints in factor loadings, with the understanding that also further testing
for factor breaks is available.
    Finally we will focus on di¤erence-in-di¤erences matching results. A nal analysis of the
cases of bonds underwritten by Lehman Brothers and Bear Stearns will conclude the section.


5.1    Multiple Breakpoint Tests for Liquidity Levels and Liquidity
       Risk
We begin by studying break in means of our main nine liquidity measures (or properly seven
measures of liquidity levels and two measures of liquidity risk) employing the Bai and Perron
(1998, 2003) estimation approach for multiple unknown breakpoints in the undi¤erenced and
unstandardized time series. At the onset we will not separate bonds by underwriter, issue
size, and credit rating. Rather we aggregate all bonds and plot their time series in Figure 4.
These nine aggregate time series do not behave much di¤erently than their more disaggregate
counterparts in Figure 3, but given their more manageable number, are amenable of more
careful discussion. The estimated means for each sub-period (red line) are also reported,
where the break dates are estimated by the Bai and Perron (1998-2003) approach and are
breaks signi cant at the 5% con dence level.
    Table 4 presents the estimated breakpoints in the mean at the 5% con dence levels for
Amihud, Amihud (standard deviation), IRC, IRC (standard deviation), Roll measure, Non-
block trade, Spread, Turnover (negative), and Zero trading frequency. The corresponding
double maximum tests for the simple breaks in means of the liquidity proxies are reported in
Table 5. This table indicates the presence of at least a structural break at the 5% con dence
level in all nine proxies, with the exception of the U D max for the Spread variable. However,
for the same variable W D max reject the null that there is no break. Concerning the dating
of the structural breaks, a reasonable prior would be picking up at least the drastic reduction
in liquidity produced by the near collapse of the U.S. nancial system in September 2008 and
the subsequent break towards more normal market liquidity levels at the end of 2009 (see
Figure 3). Any detection of subsequent structural breaks towards lower levels of liquidity
over the periods 2010-2014 should instead be carefully examined, as potential telltale sign
of liquidity depletion concurrent with and possibly caused by regulatory intervention.
    The sequential sup FT (` + 1j`) indicates three breakpoints for the IRC, IRC (standard

                                              24
deviation), Roll measure, Non-block trades, and Zero trading; one for the Amihud, Amihud
(standard deviation), and Spread; four for the Turnover (negative)27 . As clari ed by Figure
4, the Bai-Perron approach indicates clearly intuitive breaks in liquidity around the nancial
crisis. None of the structural breaks happen during the period of regulatory intervention
around the approval of Dodd-Frank, at the time of major banks shutdowns of proprietary
trading desks, or at the time of the approval of the proposed or the nalized Volcker Rule.
    While this is prima facie evidence against drastic reductions in liquidity following regu-
latory intervention, it is still possible that at the level of speci c types of corporate bonds
structural breaks may arise. In Figure 5 we present a graph tracing for each month the
fraction of our 180 underwriter-level market liquidity variables that are described to have a
statistically signi cant (at 5% con dence level) break in that month and in what direction
(i.e. towards lower liquidity -in blue- or higher liquidity -in red).The bulk of the struc-
tural breaks toward lower liquidity happens in July and August 2008, right before Lehman
Brothers failure. As it appears clear in Figure 5, if anything, around subsequent periods
of regulatory intervention the disaggregate liquidity measures pointed systematically toward
higher liquidity, not lower.
    To understand the source of the disaggregate-level structural breaks, Figure 6 shows the
decomposition of break dates by underwriting bank. We can see that the bankruptcy of
Lehman Brothers in September 2008 caused similar liquidity reductions for all underwrit-
ers. In comparison, the later recoveries are more heterogenous: bonds underwritten by JP
Morgan and Goldman Sachs experienced earlier recovery in liquidity than bonds of other
underwriters. This is consistent with anecdotal evidence that these two banks had relatively
stronger balance sheets throughout the crisis.
    The most important observation from this graph, however, is from the later period when
banks start to shutdown their proprietary trading desks after the passage of the Dodd-Frank
Act. Were proprietary trading indispensable for market making, one would expected to see
bank-speci c liquidity reductions line up with an announced trading desk shutdown by the
same bank. This is hardly the case: no large bank speci c liquidity reduction is observed
after 2010 (all the bank-speci c frequencies of liquidity reduction are below 5% after 2010).
On the contrary, many banks experience liquidity increases around July 2012, in the midst
of regulatory interventions28 . There appears to be no clear evidence that the shutting down
of proprietary trading desks was associated with an adverse impact on market liquidity.
    Figure 7 further breaks down all the structural breaks by bond type. This graph reveals
  27
    In Appendix we report the relevant statistics for the sup FT (` + 1j`) tests.
  28
    A gradual shutdown of the trading desk would not be a problem for our test, since the estimated break
points will show up sometime after the announcement date. However, we see none of this lagged liqudity
reduction.


                                                   25
more heterogeneity in the cross-section. The liquidity reductions in high-yield bonds, a
sign of trouble in the nancial sector, preceded investment-grade breaks before the crisis.
The subsequent recovery of high-yield bonds (around July 2012) appears also much slower
than the investment-grade (around January 2010). Interestingly, investment-grade bonds
experienced large illiquidity spikes in the middle of the crisis. This is probably because
the main clientele of investment-grade bonds, banks and insurance companies, were hit
particularly hard by the shock of Lehman Brothers bankruptcy. Similar patterns can also be
found in the comparison between large-size bonds and small-size bonds. During the period
of regulatory intervention, the only series that exhibits relatively large liquidity reductions
is the large-size bonds during November 2011. However, their liquidity seems to recover
immediately afterwards, as shown by several breaks towards higher liquidity following the
initial reduction.
    Since di¤erent measures proxy di¤erent aspects of liquidity, in Figure 8 we break down
all the structural breaks by measure. Amihud, Amihud (standard deviation), Roll measure
and Spread experienced early illiquidity spikes during July 2007, when initial signs of trouble
started to emerge in the housing market. When Lehman Brothers went bankrupt in Septem-
ber 2008, IRC, IRC (standard deviation) and Non-block trade had huge illiquidity spikes.
During the later stage of crisis from December 2008 to May 2009, trading activities started
to pick up, as shown by red spikes of Turnover (negative) and Zero trading. Recoveries in
other liquidity measures soon followed. The only exception is Turnover (negative), which
experienced several breaks towards lower liquidity after 2010. Although this measure seems
to suggest liquidity deterioration post 2010, the caveat is that similar breaks also occurred
as early as March 2006, a year before the start of crisis. In fact, using a subsample of bonds
which allows us to extend the sample period to 2002, we are able to show that corporate
bond turnover has been on a downward trend for more than ten years (this result is available
upon request). The breaks in Turnover (negative) post 2010 could simply be a continuation
of this downward trend.
    Overall, from the decomposition of liquidity breaks, we can see an intuitive pattern of
liquidity reductions at the onset of the nancial crisis and liquidity increases in the recov-
ery. During periods of regulatory intervention (2010-2014), with the possible exception of
Turnover (negative), no systematic evidence of liquidity reduction is found for the whole
cross-section of underwriters, bond type, and liquidity measures. The evidence in this sub-
section consistently supports the view that post-crisis U.S. regulatory intervention did not
appear related to structural deteriorations in market liquidity.




                                              26
5.2    Single Breakpoint Tests for the Dynamic Factor Model
This subsection shifts the attention to a dynamic factor model with the goal of assessing
whether the underlying structure of correlation and of latent dynamics of liquidity across
di¤erent bond types displays salient breaks during the period of crisis and post-crisis reg-
ulatory intervention. Rather than focusing on levels of liquidity or liquidity risk as in the
previous subsection, we focus here on the underlying structure of autocorrelation and cross-
dependence across a large set of liquidity measures. Detection of structural breaks in the
factor structure of corporate bond liquidity around dates of regulatory intervention could in
fact point to more subtle e¤ects of regulation on market liquidity provision.
    We discuss here the application of Chen et al. (2014) using the 2005-14 monthly sample
and our full matrix X of N = 180 di¤erenced and standardized underwriter-level time series.
As reported in Figure 2, the presence of a long period of regulatory intervention between 2010
and 2015 with multiple potential points of structural change suggests a exible approach,
leaving the breakpoint date unknown.
    A rst preliminary step requires to estimate the number of factors over the full sample
T = 117. According to our discussion in Section 4.2 this approach will not deliver a consistent
estimate of the number of true factors in (1), but rather the sum of the true factors r and the
number of big breaks in these factor loadings k1 . In Table 6 we report the full set of estimates
based on Bai and Ng (2002) and Ahn and Horenstein (2014). Here we impose a kmax = 10
and notice that the estimates for fICp1 ; ICp2 ; ICp3 ; P Cp1 ; P Cp2 ; P Cp3 ; AIC3 ; BIC3 ; ER; GRg
range from 1 to 10. Although this is less than ideal for the goal of assessing the exact number
of factors in the data, this is of little e¤ect for the interpretation of our main ndings in
Figure 9.
    Figure 9 reports the Sup-Wald and the Sup-LM test statistics of the full interval over
which the unknown breakpoint is allowed to belong given a conservative 0 = 0:3. Such
sample restriction is due to power loss concerns for the Sup tests (Andrews, 1993). Our
interval of search of breakpoints covers the period between January 2008 and January 2012.
Figure 9 also reports the Andrews (1993) critical values above which the structural break is
signi cant at the 10% and 5% con dence. We perform the analysis for any possible number
of factors in the range estimated in Table 6.
    As evident from Figure 9, the Sup tests systematically pick breaks in factor loadings
(at 5% con dence) when we allow a number of estimated factors above 3. Typically the
Sup statistic indicates the breakpoint as occurring during the 2008-2009 recession or shortly
after. This is informative because again such dating does not correspond to regulatory events
of prominence (such as the passage of the Dodd-Frank Act or the proposal of the Volcker
Rule), but rather corresponds to dynamics within the nancial crisis itself. In essence what

                                                 27
the Chen et al. (2014) methodology allow us to exclude is that a structural break in the
underlying factor structure of the underwriter-level liquidity occurred around dates of post-
crisis regulatory activity.
      In Table 7 we explore more in detail whether the structural breaks we observe can be
attributed to breaks in the factor loadings of our model or to breaks in the factors themselves
based on the discussion in Section 4.2. To maintain the presentation tractable, we focus here
only on the ER estimates for the number of factors (potentially we could perform this
exercise with all estimators in Table 6). We perform the ER estimation on the subsamples
before and after the estimated breakpoints under the di¤erent models, allowing the number
of factors on the whole sample to range from 2 to 10. The breakpoint dates are also reported
in Table 7. With the exception of the case of 2 factors, the number of ER estimated factors
r^bef ore and r^af ter are typically di¤erent, with r^bef ore = 2 and r^af ter = 1 for most models. This
appears to suggest drastic breaks in the number of factors in (1), rather than breaks in the
factor loadings . Given the magnitude of the nancial impact of the crisis, the presence of
drastic changes in the liquidity factor structure in 2008-09 does not appears unreasonable.
      So far the methodology in this subsection has focused on a single breakpoint, a restriction
that, given the multitude of potential shocks a¤ecting the U.S. nancial system during our
period of analysis, one should nd unwarranted. We relax this restriction in the following
subsection.


5.3     Multiple Breakpoint Tests for the Dynamic Factor Model
This subsection employs the Bai and Perron (1998, 2003) approach within the dynamic factor
model, transposing the logic of Chen et al. (2014) to the multiple breakpoint setting.
    Table 6 is still the reference for the allowed number of factors, a range which we will
fully explore. Table 8 presents the estimated breakpoints in the factor loadings at the 5%
con dence levels across di¤erent factor models ranging from r^ = 2; :::; 10 estimated factors,
employing the Bai and Perron (1998, 2003) preferred approach to the rst r^ PCA estimated
factors of the matrix X of di¤erenced and standardize underwriter-level liquidity measures29 .
    The corresponding double maximum tests for the breaks in the factor loadings are re-
ported in Table 9. This table indicates the presence of at least a structural break at the 5%
con dence level in nine out of ten dynamic factor models, with the exception of r^ = 2 where
both the U D max and W D max cannot reject the null that there is no break. The sequential
sup FT (` + 1j`) indicates at most two breakpoints for the models with r^ = 3; 4; 5; 6; 7, all
  29
   Given the small number of time series available for the analysis of liquidity of Treasuries we do not
employ dynamic factor model approaches in this Section.



                                                  28
essentially coincident with the start and end of the recession and the nancial crisis30 . As in
the previous section, such dating does not correspond to regulatory events of prominence (the
passage of the Dodd-Frank Act in July 2010 or the announcement of the nalized Volcker
Rule in January 2014), but rather appears to correspond to dynamics within the con nes of
the nancial crisis itself.
    With r^ = 8; 9; 10, more breakpoints in the factor loadings appear, speci cally around
September 2010 and October 2011. These, however, as we have seen in Figure 5, are also
dates of frequent breakpoints in means of liquidity measures pointing at liquidity increases,
not liquidity reductions. With a su¢ciently exible 8 10 factors model, the tests are likely
picking up similar changes. While speculative, one likely explanation could be the ability
of our model to pick up an increasing role for electronic trading and for open-end mutual
funds31 .
    In Table 10 we return to the issue of detecting breaks in factor loadings versus breaks in
factors themselves across di¤erent subperiods. The subperiods are de ned by the estimated
breakpoints indicated in Table 8. As in Table 7, for tractability, we focus here only on the
ER estimates for the number of factors. Under various models allowing a number of factors
on the whole sample ranging from 2 to 10, we perform the ER estimation on all subsamples
(up to a maximum of 6). For all models, we detect at least one breakpoint where the number
of factors decreases or increases across adjacent subperiods, pointing at likely breaks in the
factors. Di¤erently from Table 7, such breaks in the factors are detected not just around the
 nancial crisis, but also in 2010M9 and 2011M10 in two of the models (^   r = 8; 10).


5.4       Di¤erence-in-Di¤erences Matching for Liquidity Levels and
          Liquidity Risk
We now present a more standard estimation strategy based on a di¤erence-in-di¤erences exer-
cise augmented by matching of corporate bonds based on pre-treatment covariates (Heckman,
Ichimura, Smith, and Todd, 1998; Smith and Todd, 2005). Here, for reason that will become
clear in the construction of the test, we will focus only on the nalization of the Volcker Rule
in January 2014 as our treatment date. Given the limitation in our post sample of just 12
months available, we will take a symmetric 12-month window around January 2014.
    Relative to the analysis above, the approach of this subsection is more restrictive, as
it focuses on a single regulatory dimension and relies on a di¤erence-in-di¤erences type of
identi cation, but it is also an approach much more familiar to applied econometricians.
 30
      In Appendix we report the relevant statistics for the sup FT (` + 1j`) tests.
 31
      See Dudley (2015).



                                                       29
In addition, by relying on di¤erent identifying assumptions, complements nicely the macro-
econometric estimation strategy above.
    We proceed as follows. First, we manually classify the top 40 underwriters into two groups
one covered by Volcker Rule and the other not covered based on the revised nalized version
of Volcker Rule32 . Then we identify the set of bonds who have at least one underwriter not
covered by the Volcker Rule, that is a non-banking entity for which proprietary trading is
not restricted. This set of bonds is a useful benchmark as at least one of the underwriters
who typically make market on that bond is virtually unconstrained by the main regulatory
restriction in the rule, and hence virtually free to provide liquidity services in case banking
entities were so impaired. For each of these 1; 936 non-Volcker Rule bonds that are traded
between January 2013 and December 2014, we nd a match among all the Volcker Rule
bonds issued in the same quarter, that matures in the same year, has the same credit rating
(investment grade/high yield), and has a relative size di¤erence less than 50% of the average
size of the pair33 . If more than one bond satis es the above criteria, we keep the one with
smallest relative size di¤erence. Since the Volcker Rule bonds are signi cantly larger than
non-Volcker Rule bonds34 , many observations are dropped due to the last criterion on relative
size. We ended up with a matched sample of 316 pair of bonds.
    Table 11 reports the results for a di¤erence-in-di¤erences model for each of our nine
liquidity proxies where the treatment is administered to the Volcker Rule bonds after January
2014 and each regression controls for a second order polynomial in issue age, bond xed
e¤ects, and month xed e¤ects. Standard errors are two-way clustered at the bond and month
level. In eight our of nine measures the treatment does not predict reductions in liquidity
with a con dence level of 5%. Only for IRC (standard deviation) we nd a statistically
signi cant e¤ect. This is not particularly worrying since only 50 non-Volcker Rule bonds
have non-missing IRC (standard deviation) measure. Overall, there seems to be no robust
evidence of liquidity depletion as consequence of the Volcker Rule.
    The regression evidence is also supported by the graphical representation. In Figure 10
we show the time series of the Volcker Rule bonds and non-Volcker Rule bonds around the
time when the revised nalized version of the Rule was approved (the vertical line, 2014M1).
Both time series are normalized to take value of 0 at 2013M12. Were evidence of liquidity
depletion present in the data, one would expect to see systematically higher levels of the
blue line after the treatment, a sign of reduced liquidity or heightened liquidity risk. This
  32
     See the the following document from Federal Register for details of the                   nal rule:
http://www.gpo.gov/fdsys/pkg/FR-2014-01-31/pdf/2013-31476.pdf
  33
     There are fewer non-Volcker Rule bonds so we start our matching with them.
  34
     In the unmatched sample, the average size of Volcker Rule bonds are 28 times larger than non-Volcker
Rule bonds.



                                                   30
is hardly the case both in reporting unconditional time series as in Figure 10 or time series
where bond and month xed e¤ects are conditioned out (not reported to save space).
    As discussed above, the di¤erence-in-di¤erences matching approach restricts our analysis
to a speci c event and a small matched sample of bonds. One may wonder whether non-
Volcker Rule bonds in general have higher liquidity than Volcker Rule bonds during periods
of post-crisis regulatory intervention. A graphical representation of the data shows virtually
no di¤erential behavior by bonds underwritten by banks limited by the rule. In Figure 11 we
compute the mean liquidity for all the 10; 634 Volcker Rule bonds and 4; 673 non-Volcker Rule
bonds (instead of using the small matched sample) for each month, then report the di¤erence
between the mean liquidity of the two groups. Intuitively if both classes of bonds were equally
liquid the lines should hover around zero. To this time series we also overlay the estimated
breaks in means using Bai and Perron (1998, 2003) approach. Again in all measures, with
the possible exception of IRC, we do not detect any di¤erential deterioration in liquidity due
to the proposed Volcker Rule passage (2011M7) or nal rule passage (2014M1).


5.5     Sanity Check: Lehman Brothers
As highlighted in Figure 6, our approach allows for bank-speci c breakpoint testing of all
main liquidity measures. The reader interested in bank-speci c liquidity breaks results,
applying the Bai and Perron (1998,2003) approach to the undi¤erenced and unstandardized
main liquidity measures may obtain them upon request. There is however a set of banks
that deserve speci c attention because the circumstances of their demise can help assessing
the power of the tests we perform when comparing them to the rest of the market.
   Consider the case of Lehman Brothers, the fourth largest investment bank in the country
at the time of its bankruptcy on September 15, 2008. Lehman Brothers was a proli c
underwriter and a case could be made for its failure producing an e¤ect on the liquidity of the
corporate bonds for which this bank was making markets. That is, Lehmans sudden demise
should produce a sizeable drop in liquidity for bonds it had underwritten (corresponding to
an increase across our nine (il)liquidity measures above and beyond the rest of the market).
   Figure 12 shows the time series of liquidity di¤erences between bonds underwritten by
Lehman Brothers and other underwriters (blue line), and the estimated mean for each sub-
period (red line). The break dates are estimated by the Bai and Perron (1998, 2003) approach
with 5% signi cance level. The liquidity measures are constructed using only bonds under-
written before September 200835 . If the liquidity of the Lehman Brothers bonds matched
  35
    Since Lehman Brothers stopped underwriting new bonds after its bankruptcy, and newly issued bonds
are more liquid than the old ones, to make the comparision fair, we drop bonds issued by other underwriters
after the bankruptcy of Lehman Brothers (September 2008) so that the liquidity deterioration of Lehman


                                                    31
exactly the liquidity of the rest of the market for that type of securities, all blue lines
should be at and hover around zero. Instead, for IRC, the Roll measure, Non-block trades,
Turnover (negative), and Zero trading, Lehman Brothers-underwritten bonds strongly de-
teriorate in their liquidity relative to the rest of the market over time. Our methodology
detects several signi cant structural breakpoints around the nancial crisis. In addition, the
Amihud measure also breaks towards lower liquidity in 2008 (but also shows a counterintu-
itive down-break in 2014). At least six out of nine measure of liquidity present behavior over
time consistent with our approach and in ve measures we are able to pick up a statistically
signi cant structural break in relative liquidity around the appropriate date (Amihud, IRC,
IRC sd, Roll, Non-block trades).
    In Appendix Figure 1 we perform the same exercise for Bear Stearns, focusing there only
on bonds underwritten before March 2008. Although early breaks are occasionally detected,
the persistent illiquidity identi ed for Lehman Brothers is not present in the data. The
fact that instead of failing, this bank was taken over by JP Morgan Chase is the most likely
crucial di¤erence for interpreting this nding, as most likely JP Morgan took over the market
making on Bear Stearns underwritten bonds as well, muting the validity of our approach in
this speci c instance.


5.6     Comments on the Decline of Dealer Corporate Bond Invento-
        ries
With systematic evidence supporting the absence of structural breaks in corporate bond
liquidity, we will now conclude this section by going back to the dramatic decline in dealer
corporate bond inventories, which may appear counterintuitive.
    We apply the Bai and Perron (1998, 2003) approach on this series, and overlay the
estimated mean with the time series of the raw data in Figure 1. Three lessons can be
learned from this test.
    First, the estimation shows, as is obvious in observing the time series of the raw data,
that the major reductions in dealer inventories occurred at the onset of the nancial crisis
(2008M10), far ahead of the initial proposal of the Volcker Rule. Therefore, at a minimum,
there are other important factors driving the reductions of the inventories unrelated to the
Volcker Rule.
    Second, the abnormally high level of bond holdings in 2007 seems the result of a pre-crisis
run-up of risk-taking, as shown by a series of breaks towards greater holding amounts between
2002 and 2007. In this light, the dramatic reduction during the crisis appears actually more
bonds is not driven mechanically comparing old bonds to new bonds.


                                                 32
a getting back to normal. In this sense, using the pre-crisis level as a baseline to calculate
the change of inventory is somewhat misleading.
   Third, there are two minor breaks, one in August 2011 and the other in March 2013,
that fall into periods of regulatory intervention. However, as our tests on market liquidity
have systematically shown, no structural reductions in market liquidity occurred during this
period. This seems to suggest that not all the bonds held by dealers might be for liquidity-
enhancing market-making36 . Some of the holdings may be purely for risk-taking purposes,
exactly the kind of activities that the Volcker Rule restrains.


6      Results for Market Liquidity of U.S. Treasuries
This section extends our analysis to the U.S. Treasuries market. Much of the interest and
the discussion pertinent to this markets liquidity can be ascribed to the salience of events
like the ash crash of October 15th, 2014 when the yield of the U.S. 10-year note dropped by
34 basis points from 2:2% to 1:86% in the eight minutes between 9:33 and 9:45AM Eastern
Time.
    In Table 12 we report the summary statistics for this asset class, including Noise, On-
the-run premium, Roll measure (all expressed in basis points) and Turnover (negative) over
the April 2005-December 2014 sample, again calculated at the monthly frequency. The
correlations among these proxies are intuitively positive, with the exception of Turnover
(negative), as reported in Table 13. The reason for this counterintuitive negative correlation
is given by the construction of the measure for the Treasuries. As the denominator in
the Turnover variable is the total stock of public debt outstanding, the explosion of U.S.
sovereign debt as consequence of the automatic stabilizers and the 2009 Fiscal Stimulus
appear to severely a¤ect the quality of this measure post 2009, an issue that will become
clearer below.
    Table 14 presents the estimated breakpoints in the mean at the 5% con dence levels
across our four liquidity level measures, employing the Bai and Perron (1998, 2003) pre-
ferred approach to the undi¤erenced and unstandardized Noise, On-the-run premium, Roll
measure and Turnover (negative)37 . The corresponding double maximum tests for the sim-
ple breaks in means of the liquidity proxies are reported in Table 15. This table indicates
the presence of at least one structural break at the 5% con dence level in all four proxies,
  36
     In a speech by Federal Reserve Governor Lael Brainard at Salzburg Global Forum on July 1, 2015, he
also mentioned that "since not all broker-dealer inventories are used for market-making activities, the extent
to which lower inventories are a¤ecting liquidity is unclear."
  37
     Given the small number of time series available for the analysis of liquidity of Treasuries we do not
employ dynamic factor model approaches in this Section.


                                                     33
with the exception of the U D max for the Noise variable. However, for the same variable
W D max reject the null that there is no break. The sequential sup FT (` + 1j`) indicates
three breakpoints for the Noise and Roll measures, one for the On-the-run premium and
four for the Turnover (negative)38 . Figure 13 reports an informative visualization of when
the breakpoints happen over time and in which direction the series breaks. For both the
Noise and Roll measures this approach clearly captures the sudden deterioration of market
liquidity around the 2008-09 nancial crisis and a return to normality mid-2009. The Roll
measures seems to suggest further liquidity amelioration in December 2011 (in fact close
to the release of the rst Proposed Volcker Rule published in 2011M11). The On-the-run
premium exhibits qualitatively very similar dynamics, as evident from the North-East panel
in Figure 13, but our approach fails to pick up a structural break at the start of the crisis.
The only proxy that seems to systematically break in terms of lower liquidity levels for Trea-
suries is Turnover (negative) in October 2008. However, looking at the components of this
measure, this result appears mainly driven by two factors: 1. Treasury issuance dramatically
increased after 2008. 2. The Federal Reserve balance sheet structurally increased, holding a
very large portfolio of public debt due to the Quantitative Easing. Since the Fed typically
is not actively trading, the turnover should intuitively drop.


7       Conclusions
This paper complements, both methodologically and substantively, a rigorous retrospective
analysis of post-crisis regulatory intervention in domestic nancial markets. Such analy-
sis has been surprisingly bare in terms of systematic empirical evidence and it appears to
be a necessary exercise in informing future legislative and rulemaking activities aimed at
improving nancial markets stability (Cochrane, 2014).
    We speci cally focus on the aftermath of the 2008-09 U.S. nancial crisis and on the role
played by the Dodd-Frank Act of 2010 and its corollary Volcker Rule as potential triggers
of liquidity shortages driven by retrenchment of nancial institutions adversely a¤ected by
overreaching regulation.
    Several market participants have claimed this assessment to be crucial in the context of
an informed cost-bene t analysis of regulatory intervention and rulemaking.
    We initially focus on a large set of liquidity proxies with emphasis on the U.S. corpo-
rate bond market (an asset class likely to be adversely a¤ected by regulatory tightening
through disruption of ordinary market-making activities) and with particular attention paid
to di¤erent underwriters, credit ratings, and issue sizes.
 38
      In Appendix we report the relevant statistics for the sup FT (` + 1j`) tests.


                                                       34
    Our analysis is based on multiple estimation strategies, including both dynamic factor
models and more standard structural breaks and di¤erence-in-di¤erences matching analysis.
Reassuringly, the data display no statistical evidence of substantial deterioration in market
liquidity after 2010. The tests presented are powerful enough to pick structural breaks in the
data -they clearly pinpoint the crisis itself as a liquidity breakpoint- yet they consistently
show no signi cant breaks in the models factors or in their loadings around the approval of
the Dodd-Frank Act, at the time of major banks shutdowns of proprietary trading desks, or
at the time of the proposal and nalization of the Volcker Rule.
    Evidence from the U.S. Treasuries market, by and large, con rms the absence of big
liquidity breaks, in line with our ndings on U.S. corporate bonds, calling into question
the most negative welfare assessments of the post-crisis regulatory e¤ort, at least along the
dimension of market liquidity deterioration.




                                             35
 REFERENCES

 1. Ahn S.C., Horenstein A., 2013. Eigenvalue ratio test for the number of factors.
    Econometrica 81 (3), 12031227.

 2. Amato, J. D., and Remolona, E. M., 2003. "The credit spread puzzle", BIS
    Quarterly Review.

 3. Amihud, Y., Mendelson, H., 1980. Dealership market: market making with inven-
    tory. The Journal of Financial Economics 8, 3153.

 4. Amihud, Y., Mendelson, H.,.1986.. Asset pricing and the bid-ask spreads. The
    Journal of Financial Economics 17 (2), 223249.

 5. Amihud, Y., 2002. Illiquidity and stock returns: cross-section and time-series e¤ects.
    Journal of Financial Markets 5, 3156.

 6. Andrews, D., 1993. Tests for parameter instability and structural change with un-
    known change point. Econometrica 61 (4), 821856.

 7. Aragon, G., Strahan P., 2012, Hedge funds as liquidity providers: Evidence from
    the Lehman bankruptcy, Journal of Financial Economics, 103(3), 570587.

 8. Bai, J., Ng, S., 2002. Determining the number of factors in approximate factor
    models. Econometrica 70 (1), 191221.

 9. Bai, J., Perron, P., 1998. Estimating and testing linear models with multiple struc-
    tural changes. Econometrica 66 (1), 4778.

10. Bai, J., Perron, P., 2003. Computation and analysis of multiple structural change
    models. Journal of Applied Econometrics 18 (1), 122.

11. Bao, J., Pan, J., Wang, J., 2011. The illiquidity of corporate bonds. Journal of
    Finance 66, 911946.

12. Barr, M.S., 2012. The nancial crisis and the path of reform. Yale Journal on
    Regulation, 29, 91-120

13. Bertrand, M, Bombardini, M., Trebbi, F. 2015. Lobbying the Dodd-Frank Act
    of 2010. mimeo UBC.

14. Brunnermeier, M. K., Pedersen L. H. 2009 Market liquidity and funding liquidity,
    Review of Financial Studies, 22(6), 22012238.

15. Chen, L., Dolado, J. Gonzalo, J., 2014. Detecting big structural breaks in large
    factor models. Journal of Econometrics 180, 3048.

16. Coates, I. V., John, C. 2014. Cost-Bene t Analysis of Financial Regulation: Case
    Studies and Implications. Yale Law Journal, Forthcoming.


                                          36
17. Cochrane, J.C. 2014. Challenges for Cost-Bene t Analysis of Financial Regulation.
    Journal of Legal Studies, 43, S63-S105.

18. Comerton-Forde C., T. Hendershott, C.M. Jones, P.C. Moulton, M.S. Seasholes,
    2010. Time Variation in Liquidity: The Role of Market-Maker Inventories and Rev-
    enues The Journal of Finance 65, 1.

19. Dick-Nielsen, J., Feldhütter, P., Lando, D., 2012. Corporate bond liquidity
    before and after the onset of the subprime crisis. Journal of Financial Economics 103,
    471492.

20. Dudley, W., 2015. Regulation and liquidity provision. Remarks at the SIFMA Liq-
    uidity Forum, NYC, 9/30/2015.

21. Du¢e, D., 2012 Market making under the proposed Volcker Rule. Public comment
    to Federal Reserve Board.

22. Edwards, A. K., Harris L. E. and Piwowar M. S., 2007, "Corporate Bond Market
    Transaction Costs and Transparency", The Journal of Finance 62, pp. 14211451.

23. Feldhutter, P., 2012. The same bond at di¤erent prices: identifying search frictions
    and selling pressures. Review of Financial Studies 25, 11551206.

24. Frieden, J., 2015. The Political Economy of Adjustment and Rebalancing, Journal
    of International Money and Finance 52, 4-14.

25. Garman, M.B., 1976. Market microstructure. The Journal of Finance 3 (2), 257
    275.

26. Goldstein, M.A., Hotchkiss, E.S., 2007. Dealer behavior and the trading of newly
    issued corporate bonds, in: AFA 2009 San Francisco Meetings Paper.

27. Gromb, D., Vayanos, D., 2002. Equilibrium and welfare in markets with nancially
    constrained arbitrageurs, Journal of Financial Economics, 66, 316407.

28. Gürkaynak, R.S., Sack, B., Wright, J.H., 2007. The US Treasury yield curve:
    1961 to the present. Journal of Monetary Economics 54, 22912304.

29. Heckman, J. J., H. Ichimura, J. A. Smith, P. E. Todd 1998. Characterizing
    Selection Bias Using Experimental Data, Econometrica, 66, 10171099.

30. Heckman, J. J., H. Ichimura, P. E. Todd 1997. Matching as an Econometric
    Evaluation Estimator: Evidence from Evaluating a Job Training Programme, The
    Review of Economic Studies, 64(4,), 605654.

31. Ho, T.S.Y., Stoll, H.R., 1981. Optimal dealer pricing under transactions and return
    uncertainty. The Journal of Financial Economics 9 (1), 4773

32. Hu, G. X. and Pan, J. and Wang, J., 2013. Noise as information for illiquidity.
    The Journal of Finance 68 (6), 23412382

                                           37
33. Kaiser R. G., 2013, Act of Congress: How Americas Essential Institution Works,
    and How It Doesnt, Knopf.

34. Krawiec, K. D. and Liu, G., 2015, The Volcker Rule: a brief political history,
    Capital Markets Law Journal 10 (4), 507522

35. Krishnamurthy, A., 2002, "The bond/old-bond spread", Journal of Financial Eco-
    nomics 66, 2, pp. 463506.

36. Kyle, A.S., 1985. Continuous auctions and insider trading. Econometrica 13151335.

37. Longsta¤, F. 2004. The ight-to-liquidity premium in U.S. treasury bond prices.
    Journal of Business 77 (3), 511526

38. Longsta¤, F., Mithal, S. and Neis, E., 2005, "Corporate yield spreads: Default
    risk or liquidity? New evidence from the credit default swap market", The Journal of
    Finance 60, 5, pp. 22132253.

39. McCarty, N.,Poole K., Rosenthal H. 2013. Political Bubbles: Financial Crises
    and the Failure of American Democracy. Princeton University Press.

40. Mian, A. Su , A. Trebbi, F., 2010. The Political Economy of the US Mortgage
    Default Crisis, American Economic Review, December 2010, 100(5), 1967-98.

41. Mian, A. Su , A. Trebbi, F., 2014. Resolving Debt Overhang: Political Constraints
    in the Aftermath of Financial Crises, American Economic Journal: Macroeconomics,
    6(2),1-28.

42. Newey, W., West, K., 1987. A simple, positive semi-de nite, heteroskedasticity and
    autocorrelation consistent covariance matrix. Econometrica 55 (3), 703708.

43. Posner, E. A., Weyl, E. G., 2013. Bene t-cost analysis for nancial regulation.
    American Economic Review Papers and Proceedings, 103(3), 1-5.

44. Posner, E. A., Weyl, E. G., 2014. Bene t-cost paradigms in nancial regulation.
    Journal of Legal Studies, 43, S1-S34.

45. Smith, J. A., P. E. Todd 2005. Does Matching Overcome LaLondes Critique of
    Nonexperimental Estimators? Journal of Econometrics, 125(1-2), 305353

46. Roll, R. 1984. A Simple Implicit Measure of the E¤ective Bid-Ask Spread in an
    E¢cient Market. The Journal of Finance, 39 (4), 11271139

47. Skeel, D. 2010. The new nancial deal: understanding the Dodd-Frank Act and its
    (unintended) consequences. John Wiley & Sons.

48. Stock, J., Watson, M.W., 2002. Forecasting using principal components from a
    large number of predictors. Journal of the American Statistical Association 97 (460),
    11671179.


                                          38
49. Stock, J. Watson, M.W., 2011. Dynamic Factor Models. In Oxford Handbook of
    Forecasting, Michael P. Clements and David F. Hendry (eds) Oxford: Oxford University
    Press.

50. Thakor, A. 2012 The Economic Consequences of the Volcker Rule. Working Paper
    Center for Capital Markets Competitiveness.




                                          39
                           Figure 1. Primary Dealer Corporate Bond Holding

This graph shows the time series of the U.S. primary dealer corporate bond holding as the percentage of total
corporate bond outstanding (blue line) and the estimated mean for each sub-period (red line). The break
dates are estimated by the Bai and Perron (1998, 2003) approach with 5% significance level. Primary dealers
are a list of banks and non-bank financial firms which serve as trading counterparties of the New York Fed in
its implementation of monetary policy. Almost all the major corporate bond underwriters are in the list. The
bond holding data is from Federal Reserve Bank of New York, and the amount of outstanding bond is from
Securities Industry and Financial Markets Association (SIFMA). The sample period is from January 2002 to
December 2014. The data frequency is monthly. The grey area indicates recession.
                                             Figure 2. Timeline of Crisis and Post-Crisis Regulatory Activity



                                                           2010m7: The Dodd-Frank Act
                                                                 signed into law
                                                                          2011m6: Announced proprietary
                                                                          trading desk shutdown by Bank            2014m4: Effective date of the
                                       2009m6: The end of recession                 of America                                Rule
                                                            2010m9: Announced proprietary
                          2008m9: The bankruptcy of            trading desk shutdown by                                           2015m7: Deadline of Compliance
                              Lehman Brothers                       Goldman Sachs                                                          of the Rule




       ʹͲͲ͹              ʹͲͲͺ               ʹͲͲͻ               ʹͲͳͲ             ʹͲͳͳ           ʹͲͳʹ       ʹͲͳ͵             ʹͲͳͶ                ʹͲͳͷ



                                                            2010m9: Announced proprietary
                                                              trading desk shutdown by JP
                                                                        Morgan
                                 2009m1: The Vocker Rule first     2011m1: Announced proprietary                 2014m1: The revised final
                                          proposed                    trading desk shutdown by                   version of the Volcker rule
                                                                           Morgan Stanley                                 approved
2007m1: The start of recession                     2010m1: The Vocker Rule first
                                                   publicly endorsed by President
                                                               Obama
                  Figure 3. Time Series of Liquidity Measures (Underwriter-Level)

This graph shows the time series of liquidity measures of U.S. corporate bonds underwritten by four big
banks and all the other underwriters combined. The sample period is from April 2005 to December 2014.
The data frequency is monthly. The grey area indicates recession.

                                               Amihud




                                            Amihud (sd)
Figure 3 (continued). Time Series of Liquidity Measures (Underwriter-Level)

                                   IRC




                                 IRC (sd)
Figure 3 (continued). Time Series of Liquidity Measures (Underwriter-Level)

                                   Roll




                             Non-block Trade
Figure 3 (continued). Time Series of Liquidity Measures (Underwriter-Level)

                                  Spread




                           Turnover (negative)
Figure 3 (continued). Time Series of Liquidity Measures (Underwriter-Level)

                            Zero-trading Days
                         Figure 4. Time Series of Liquidity (Aggregate-level)

This graph shows the time series of 9 aggregate-level liquidity measures of U.S. corporate bond market (blue
line), and the estimated mean for each sub-period (red line). The break dates are estimated by the Bai and
Perron (1998, 2003) approach with 5% significance level. The sample period is from April 2005 to December
2014. The data frequency is monthly. The grey area indicates recession.
              Figure 5. Frequency of Break Dates of Mean Liquidity (Underwriter-level)

This graph shows the frequency of break dates in means of 180 underwriter-level liquidity measures for the
U.S. corporate bond market. The x-axis shows the break date and the y-axis shows the corresponding fraction
of the 180 liquidity measures which have a break at this break date. The break dates are estimated using the
Bai and Perron (1998, 2003) approach with 5% significance level. Each underwriter has four liquidity
measures: large issue size, small issue size, investment-grade, and high-yield. The sample period is from April
2005 to December 2014. The data frequency is monthly. We run the test iteratively for each measure, and the
following figure shows the frequency across all the 180 measures. The grey area indicates recession.
             Figure 6. Decomposition of Break Dates by Underwriter (Underwriter-level)

This graph shows the decomposition of break dates by underwriter. The x-axis shows the break date and the
y-axis shows the corresponding fraction of the 36 (=9×2×2) liquidity measures of each underwriter which
have a break at this break date. The break dates are estimated using the Bai and Perron (1998, 2003) approach
with 5% significance level. The sample period is from April 2005 to December 2014. The data frequency is
monthly.
             Figure 7. Decomposition of Break Dates by Bond Type (Underwriter-level)

This graph shows the decomposition of break dates by bond types. The x-axis shows the break date and the
y-axis shows the corresponding fraction of the 45 (=9×5) liquidity measures of each bond type which have a
break at this break date. The break dates are estimated using the Bai and Perron (1998, 2003) approach with 5%
significance level. The sample period is from April 2005 to December 2014. The data frequency is monthly.
               Figure 8. Decomposition of Break Dates by Measure (Underwriter-level)

This graph shows the decomposition of break dates by bond types. The x-axis shows the break date and the
y-axis shows the corresponding fraction of the 20 (=5×2×2) series of each liquidity measure which have a
break at this break date. The break dates are estimated using the Bai and Perron (1998, 2003) approach with 5%
significance level. The sample period is from April 2005 to December 2014. The data frequency is monthly.
       Figure 9. Test Statistics of Breaks on the Liquidity Factor Structure: Single Break Test

This graph shows the test statistics of a single break in factor structure of 180 underwriter-level liquidity
measures employing the Chen et al. (2014) approach. Each underwriter has four liquidity measures: large issue
size, small issue size, investment-grade, and high-yield. The sample period is from April 2005 to December
2014. The full interval over which the unknown breakpoint is allowed to belong is from February 2008 to
December 2011. The liquidity measures are differenced and standardized. The data frequency is monthly. The
grey area indicates recession. The critical values are obtained from Chen et al. (2014).
        Figure 10. Liquidity of Volcker Rule and Non-Volcker Rule Bonds (Matched Sample)

This graph shows the time series of liquidity of Volcker Rule bonds and non-Volcker Rule bonds around the
time when revised finalized version of the Volcker Rule is approved (January 2014). A non-Volcker Rule
bond is defined as a bond which at least one of the underwriters is not subject to the Volcker Rule. A Volcker
Rule bond is defined as a bond which all of the underwriters are subject to the Volcker Rule. Each of the
non-Volcker Rule bonds in our sample is matched to a Volcker Rule bond which is issued at the same month,
matures in the same year, has the same rating (investment-grade/high-yield), and has a relative size difference
less than 50% of the average size of the pair. If there are more than one bond satisfies the above criteria, we
keep the one with smallest relative size difference. Both time series are normalized to 0 in December 2013.
The red vertical line indicates the date when the revised finalized version of the Volcker Rule was approved
(2014m1). The sample period is from January 2013 to December 2014. The data frequency is monthly.
         Figure 11. Liquidity Difference between Volcker Rule and Non-Volcker Rule Bonds

This graph shows the time series of liquidity difference between of bonds underwritten by Volcker Rule
underwriters and non-Volcker Rule underwriters (blue line), and the estimated mean for each sub-period (red
line). The break dates are estimated by the Bai and Perron (1998, 2003) approach with 5% significance level.
The sample period is from April 2005 to December 2014. The data frequency is monthly. The grey area
indicates recession.
         Figure 12. Liquidity Difference between Lehman Brothers and Other Underwriters

This graph shows the time series of liquidity difference between of bonds underwritten by Lehman Brothers
and all the other underwriters (blue line), and the estimated mean for each sub-period (red line). The break
dates are estimated by the Bai and Perron (1998, 2003) approach with 5% significance level. The liquidity
measures are constructed using bonds issued before September 2008. The sample period is from April 2005
to December 2014. The data frequency is monthly. The grey area indicates recession.
                   Figure 13. Time Series of Liquidity of the U.S. Treasury Liquidity

This graph shows the time series of liquidity measures of U.S. Treasury market (blue line), and the estimated
mean for each sub-period (red line). The break dates are estimated by the Bai and Perron (1998, 2003)
approach with 5% significance level. The sample period is from April 2005 to December 2014. The data
frequency is monthly. The grey area indicates recession.
       Appendix Figure 1. Liquidity Difference between Bear Stearns and Other Underwriters

This graph shows the time series of liquidity difference between bonds underwritten by Bear Stearns and all
the other underwriters (blue line), and the estimated mean for each sub-period (red line). The break dates are
estimated by the Bai and Perron (1998, 2003) approach with 5% significance level. The liquidity measures are
constructed using bonds issued before March 2008. The sample period is from April 2005 to December 2014.
The data frequency is monthly. The grey area indicates recession.
           Table 1: Summary Statistics of the U.S. Corporate Bond Liquidity (Aggregate Level)

   This table shows the summary statistics of 9 aggregate-level liquidity measures for the U.S. corporate bond
   market. The sample period is from April 2005 to December 2014. The data frequency is monthly. The unit of
   Amihud, Amihud (sd), IRC, IRC (sd), Roll and Spread is percentage point. The unit of Non-block trade,
   Turnover (negative)and Zero-trading is 1.


Measures              N        mean              sd            p10       p25         p50         p75             p90

Amihud                117       0.95            0.43           0.57      0.63        0.79        1.14            1.63
Amihud (sd)           117       1.45            0.47           1.03      1.10        1.28        1.67            2.25
IRC                   117       0.70            0.25           0.41      0.49        0.68        0.82            1.10
IRC (sd)              117       0.62            0.21           0.42      0.46        0.59        0.69            0.94
Roll                  117       1.57            0.56           0.93      1.19        1.47        1.83            2.43
Non-block trade       117       0.95            0.01           0.93      0.94        0.96        0.96            0.97
Spread                117       2.20            1.37           1.14      1.33        1.67        2.44            4.15
Turnover
(negative)            117       -0.40           0.06           -0.48     -0.44       -0.40      -0.37            -0.32
Zero-trading          117       0.61            0.08           0.51      0.55        0.59       0.69             0.72




            Table 2: Correlation Table of the U.S. Corporate Bond Liquidity (Aggregate Level)

   This table shows the correlations among 9 aggregate-level liquidity measures for the U.S. corporate bond
   market. The sample period is from April 2005 to December 2014. The data frequency is monthly.


                                        Amihud                   IRC             Non-block              Turnover
                            Amihud                     IRC              Roll                 Spread
                                         (sd)                    (sd)              trade                (negative)

    Amihud (sd)              0.99
    IRC                      0.85        0.84
    IRC (sd)                 0.90        0.88           0.98
    Roll                     0.92        0.91           0.97     0.97
    Non-block trade          0.31        0.36          -0.13    -0.03   -0.01
    Spread                   0.97        0.95           0.86     0.91   0.91       0.28
    Turnover
    (negative)               0.18        0.11          0.14      0.13   0.21       -0.27      0.13
    Zero-trading             0.33        0.28          0.66      0.57   0.59       -0.72      0.33        0.53
                                Table 3. Sample Mean and Standard Deviation of Liquidity (Underwriter Level)

This table shows the sample mean and standard deviation (in brackets) of 180 underwriter-level liquidity measures for the U.S. corporate bond market.
The list of underwriters includes Bank of America (BOA), Goldman Sachs (GS), JP Morgan (JPM), Morgan Stanley (MS), and all the other underwriters
(OT). Each underwriter has four liquidity measures: large issue size, small issue size, investment-grade, and high-yield. The sample period is from April
2005 to December 2014. The data frequency is monthly. The unit of Amihud, Amihud (sd), IRC, IRC (sd), Roll and Spread is percentage point. The
unit of Non-block trade, Turnover (negative)and Zero-trading is 1.

                                                                                                        Non-
                                                 Amihud                                                                          Turnover        Zero-
                                   Amihud                       IRC         IRC (sd)       Roll         block        Spread
                                                  (sd)                                                                           (negative)     trading
  Bank          Bond Type                                                                               trade

  BOA            High-yield           0.70         1.14          0.54         0.56          1.32         0.70         4.46          -0.48        0.49
                                     (0.26)       (0.29)        (0.17)       (0.19)        (0.42)       (0.08)       (2.15)         (0.1)       (0.07)
  BOA        Investment-grade         0.99         1.47          0.81         0.66          1.73         0.98         2.04         -0.34         0.70
                                     (0.46)        (0.5)        (0.27)       (0.22)        (0.56)       (0.01)       (1.35)        (0.06)       (0.07)
  BOA            Large-size           0.91         1.54          0.70         0.71          1.28         0.93         2.13          -0.68        0.14
                                     (0.51)       (0.55)        (0.33)        (0.3)         (0.6)       (0.02)       (1.33)        (0.17)       (0.04)
  BOA            Small-size           0.97         1.41          0.80         0.65          1.74         0.97         2.14          -0.33        0.72
                                     (0.42)       (0.46)        (0.26)       (0.21)        (0.55)       (0.01)       (1.38)        (0.06)       (0.06)
   GS            High-yield           0.78         1.25          0.62         0.60          1.52         0.74         4.68          -0.47        0.50
                                      (0.3)       (0.42)        (0.18)       (0.18)         (0.5)       (0.07)       (1.97)        (0.11)       (0.12)
   GS        Investment-grade         0.99         1.48          0.61         0.59          1.43         0.95         1.69         -0.49         0.47
                                     (0.44)       (0.46)        (0.21)       (0.19)        (0.54)       (0.02)       (1.02)        (0.08)       (0.09)
   GS            Large-size           0.89         1.54          0.73         0.73          1.26         0.94         1.75          -0.79        0.11
                                     (0.59)       (0.56)        (0.37)       (0.31)        (0.58)       (0.02)       (1.02)        (0.16)       (0.05)
   GS            Small-size           0.98         1.46          0.59         0.56          1.47         0.93         2.00          -0.44        0.52
                                     (0.39)       (0.43)        (0.18)       (0.16)        (0.52)       (0.03)       (1.11)        (0.07)       (0.08)
                           Table 3 (continued). Sample Mean of Liquidity (Underwriter Level)

                                     Amihud                                         Non-block            Turnover      Zero-
                          Amihud                   IRC       IRC (sd)      Roll                 Spread
Bank     Bond Type                    (sd)                                            trade              (negative)   trading

JPM       High-yield       0.70        1.14        0.54        0.56        1.32        0.70      4.46       -0.48      0.49
                          (0.26)      (0.29)      (0.17)      (0.19)      (0.42)      (0.08)    (2.15)      (0.1)     (0.07)
JPM    Investment-grade    0.99        1.47        0.81        0.66        1.73        0.98      2.04      -0.34       0.70
                          (0.46)       (0.5)      (0.27)      (0.22)      (0.56)      (0.01)    (1.35)     (0.06)     (0.07)
JPM       Large-size       0.91        1.54        0.70        0.71        1.28        0.93      2.13      -0.68       0.14
                          (0.51)      (0.55)      (0.33)       (0.3)       (0.6)      (0.02)    (1.33)     (0.17)     (0.04)
JPM       Small-size       0.97        1.41        0.80        0.65        1.74        0.97      2.14      -0.33       0.72
                          (0.42)      (0.46)      (0.26)      (0.21)      (0.55)      (0.01)    (1.38)     (0.06)     (0.06)
MS        High-yield       0.78        1.25        0.62        0.60        1.52        0.74      4.68      -0.47       0.50
                           (0.3)      (0.42)      (0.18)      (0.18)       (0.5)      (0.07)    (1.97)     (0.11)     (0.12)
MS     Investment-grade    0.99        1.48        0.61        0.59        1.43        0.95      1.69      -0.49       0.47
                          (0.44)      (0.46)      (0.21)      (0.19)      (0.54)      (0.02)    (1.02)     (0.08)     (0.09)
MS        Large-size       0.89        1.54        0.73        0.73        1.26        0.94      1.75      -0.79       0.11
                          (0.59)      (0.56)      (0.37)      (0.31)      (0.58)      (0.02)    (1.02)     (0.16)     (0.05)
MS        Small-size       0.98        1.46        0.59        0.56        1.47        0.93      2.00      -0.44       0.52
                          (0.39)      (0.43)      (0.18)      (0.16)      (0.52)      (0.03)    (1.11)     (0.07)     (0.08)
OT        High-yield       0.74        1.24        0.59        0.60        1.43        0.72      4.64       -0.49      0.52
                          (0.25)       (0.3)      (0.18)      (0.17)      (0.41)      (0.07)    (2.17)      (0.1)     (0.07)
OT     Investment-grade    0.98        1.48        0.71        0.63        1.59        0.97      2.12      -0.39       0.63
                          (0.47)      (0.51)      (0.26)      (0.22)      (0.59)      (0.01)     (1.4)     (0.06)     (0.08)
OT        Large-size       0.75        1.38        0.63        0.65        1.18        0.92      1.92      -0.69       0.12
                          (0.46)       (0.5)      (0.31)      (0.27)      (0.57)      (0.02)    (1.14)     (0.14)     (0.05)
OT        Small-size       0.98        1.46        0.71        0.63        1.62        0.96      2.33      -0.38       0.66
                          (0.44)      (0.48)      (0.25)      (0.21)      (0.57)      (0.01)    (1.45)     (0.06)     (0.07)
                   Table 4. Break Dates in the Means of Liquidity (Aggregate-level)

This table lists break dates in the means of 9 aggregate-level liquidity measures of the U.S. corporate bond
market. The dates are estimated by the Bai and Perron (1998, 2003) approach with 5% significance level. The
sample period is from April 2005 to December 2014. The data frequency is monthly.

                    Measures                            Break Dates
                    Amihud                 2007m8
                    Amihud (sd)            2007m7
                    IRC                    2008m8      2009m9         2012m3
                    IRC (sd)               2008m8      2009m8         2012m2
                    Roll                   2008m2      2009m10        2012m6
                    Non-block trade        2007m10     2008m10        2012m12
                    Spread                 2007m10
                    Turnover (negative)    2006m5      2007m6         2009m4     2010m4
                    Zero trading           2006m6      2009m5         2013m1




  Table 5. Double Maximum Test Statistics of Breaks in the Means of Liquidity (Aggregate-level)

This table lists the Dmax statistics of break dates in the means of 9 aggregate-level liquidity measures of the
U.S. corporate bond market. The dates are estimated by the Bai and Perron (1998, 2003) approach with 5%
significance level. The sample period is from April 2005 to December 2014. The null hypothesis is that there
is no break, and the alternative hypothesis is that there is at least one break. The data frequency is monthly.
The critical values are obtained from Bai and Perron (1998).

                                                        5% critical                 5% critical
                      Measures             WDmax         value of       UDmax        value of
                                                         WDmax                       UDmax
               Amihud                          70.42         10.39         41.56          9.52
               Amihud (sd)                     62.73         10.39         37.02          9.52
               IRC                            118.75         10.39         78.69          9.52
               IRC (sd)                        65.80         10.39         49.45          9.52
               Roll                            62.63         10.39         36.96          9.52
               Non-block trade                370.07         10.39        245.22          9.52
               Spread                          14.19         10.39          8.38          9.52
               Turnover (negative)             34.08         10.39         29.66          9.52
               Zero trading                   397.48         10.39        298.77          9.52
                      Table 6. Number of Dynamic Factors (Underwriter-level)

This graph shows the estimated number of factors in 180 underwriter-level liquidity measures for the U.S.
corporate bond market. Each underwriter has four liquidity measures: large issue size, small issue size,
investment-grade, and high-yield. The sample period is from April 2005 to December 2014. The liquidity
measures are differenced and standardized. The data frequency is monthly. The maximum number of
possible breaks is 10.



                                                                 Number of
                                                                 Estimated
                                        Method                    Factors
                              Ahn & Horenstein (2013) ER             1
                              Ahn & Horenstein (2013) GR             1
                                  Bai & Ng (2002) IC1                10
                                  Bai & Ng (2002) IC2                 7
                                  Bai & Ng (2002) IC3                10
                                 Bai & Ng (2002) PC1                 10
                                 Bai & Ng (2002) PC2                  9
                                 Bai & Ng (2002) PC3                 10
                                Bai & Ng (2002) AIC3                 10
                                 Bai & Ng (2002) BIC3                4
     Table 7. Number of Factors Before and After Break: Single Break Test (Underwriter-level)

This graph shows the estimated number of factors before and after the break dates in a panel of underwriter-
level liquidity measures for the U.S. corporate bond market. The break dates are estimated using the sup-
Wald test from Chen et al. (2014), and the numbers of factors before and after break are estimated using the
eigenvalue ratio (ER) estimator from Ahn and Horenstein (2013). The sample period is from April 2005 to
December 2014. The liquidity measures are differenced and standardized. The data frequency is monthly.

                                            Number of Factors:
                              Whole         Before       After      Break
                              Sample        Break        Break      Dates
                                  2           1            1         2008m7
                                 3            2            1         2008m9
                                 4            2            1         2008m9
                                 5            2            1         2008m9
                                 6            2            1         2008m9
                                 7            2            1         2008m9
                                 8            2            1         2008m9
                                 9            1            3         2009m8
                                 10           1            3         2009m8
                 Table 8: Break Dates of Liquidity Factor Structure (Underwriter-level)

This table shows the break dates in factor structure of the U.S. corporate bond market liquidity employing the
Bai and Perron (1998, 2003) approach with 5% significance level. Liquidity measures are in underwriter-level.
Each underwriter has four liquidity measures: large issue size, small issue size, investment-grade, and high-
yield. The sample period is from April 2005 to December 2014. We estimate the top 10 principal components
from the differenced and standardized liquidity measures, then run the tests iteratively assuming that there are
k principal factors, where k = 2 to 10. The following table shows the break dates estimated in each test.

          Number of factors                                    Break Dates
                    2                  None
                    3                 2008m8      2009m8
                    4                 2008m9
                    5                 2008m9
                    6                 2008m8      2009m8
                    7                 2008m9
                    8                 2007m9      2008m9        2009m9         2010m9      2011m10
                    9                 2007m9      2008m9        2009m11
                   10                 2006m3      2007m9         2008m9        2009m9       2010m9
        Table 9: Double Maximum Test Statistics of Breaks in the Liquidity Factor Structure

                                             (Underwriter-level)

This table shows the double maximum test statistics of break in factor structure of the U.S. corporate bond
market liquidity employing the Bai and Perron (1998, 2003) approach with 5% significance level. Each
underwriter has four liquidity measures: large issue size, small issue size, investment-grade, and high-yield.
The sample period is from April 2005 to December 2014. The data frequency is monthly. We estimate the
top 10 principal components from the differenced and standardized liquidity measures, then run the tests
iteratively assuming that there are k principal factors, where k = 2 to 10. The null hypothesis is that there is
no break, and the alternative hypothesis is that there is at least one break. The critical values are obtained
from Bai and Perron (1998).

                                                 5% critical                     5% critical
                   Number
                                  WDmax           value of        UDmax           value of
                   of factors
                                                  WDmax                           UDmax
                       2             4.17          10.39            3.26            9.52
                       3            20.59          13.66            17.63          12.59
                       4            181.24         16.07           129.73          14.85
                       5            164.98         18.38           111.14          17.00
                       6           3604.73         20.30          2508.65          18.91
                       7          57642.80         22.55         40677.60          21.01
                       8          1.18E+13         24.34         8.42E+12          22.80
                       9          1.27E+05         26.10         9.78E+04          24.56
                       10         5.52E+15         27.99         4.04E+15          26.48
      Table 10. Number of Factors of Each Subperiod: Multiple Break Test (Underwriter-level)

This graph shows the estimated number of factors of each subperiod in a panel of underwriter-level liquidity
measures for the U.S. corporate bond market. The break dates are estimated using Bai and Perron (1998,
2003) approach with 5% significance level, and the number of factors of each subperiod is estimated using
the eigenvalue ratio (ER) estimator from Ahn and Horenstein (2013). The sample period is from April 2005
to December 2014. The liquidity measures are differenced and standardized. The data frequency is monthly.

                                             Number of Factors
           Whole        Subperiod    Subperiod    Subperiod      Subperiod Subperiod Subperiod
           Sample           1            2            3              4         5         6
              2            NA
              3             1            1             3
              4             2            1
              5             2            1
              6             1            1             3
              7             2            1
              8             3            1             1            1            2           2
              9             3            1             1            3
             10             1            3             1            1            1           3
                                                   Table 11. Difference-in-Difference Regression

This table shows the difference-in-difference regression of Volcker Rule bonds and non-Volcker Rule bonds around the time when revised finalized
version of the Volcker Rule is approved (January 2014). A non-Volcker Rule bond is defined as a bond which at least one of the underwriters is not
subject to the Volcker Rule. Each of the non-Volcker Rule bonds in our sample is matched to a Volcker Rule bond which is issued at the same month,
matures in the same year, has the same rating (investment-grade/high-yield), and has a relative size difference less than 50% of the average size of the
pair. The sample period is from January 2013 to December 2014. The data frequency is monthly. The standard errors are two-way clustered at the bond
and month level.


                           (1)          (2)          (3)         (4)          (5)          (6)              (7)          (8)            (9)
                                        Amihud                                             Non-block                     Turnover       Zero-
                           Amihud                    IRC         IRC (sd)     Roll                          Spread
                                        (sd)                                               trade                         (negative)     trading

 Volcker Bond*Post
 Volcker                   0.211        0.363        0.101       0.0987**     0.0976       0.000547         0.125        0.00304        0.00120
                           [0.145]      [0.283]      [0.0615]    [0.0380]     [0.165]      [0.000642]       [0.0833]     [0.0418]       [0.00639]

 1/Issue Age               -8.076***    -6.296**     -0.0927     -0.00775     -5.866***    -0.0148          1.822**      1.762*         0.567***
                           [2.513]      [2.910]      [0.588]     [0.495]      [1.939]      [0.0151]         [0.867]      [0.883]        [0.133]

 1/(Issue Age)^2           13.20**      8.890*       -0.265      -0.0589      6.384*       -0.0131          -2.736**     -6.032***      -1.269***
                           [5.159]      [4.903]      [0.965]     [0.742]      [3.192]      [0.0295]         [1.323]      [1.703]        [0.232]

 Time F.E.                 Y            Y            Y           Y            Y            Y                Y            Y              Y
 Bond F.E.                 Y            Y            Y           Y            Y            Y                Y            Y              Y

 Observations               1011         1011         2969       1533         3401         9380             9347         9380           9380
 Adjusted R-squared         0.200        0.322        0.335      0.463        0.275        0.582            0.695        0.229          0.845

 Standard errors in brackets
 * p<0.1 ** p<0.05 *** p<0.01
                      Table 12. Summary Statistics of the U.S. Treasury Liquidity

This table shows the summary statistics of liquidity measures for the U.S. Treasury market. The sample period
is from April 2005 to December 2014. The data frequency is monthly. The unit of Noise, On the run
premium and Roll measure is basis point. The unit of Turnover (negative) is 1.

          Measure           N      mean        sd            p10         p25      p50        p75     p90

   Noise                   117     3.14      3.24            1.20        1.48     1.93        3.33    6.51
   On the run premium      117     13.48     12.62           3.33        6.23     8.94       16.39   28.73
   Roll                    117     13.37      4.09           8.62       10.35     12.73      15.83   19.23
   Turnover                117    -11.48      3.93          -17.64      -14.76    -9.79      -8.11   -7.39




                       Table 13. Correlation Table of the U.S. Treasury Liquidity

This table shows the correlations between liquidity measures for the U.S. Treasury market. The sample period
is from April 2005 to December 2014. The data frequency is monthly.

                                                                     On the run
                                                     Noise            premium        Roll

                    On the run premium               0.90
                    Roll                             0.62               0.72
                    Turnover                         0.03              -0.08         -0.37
                            Table 14: Break Dates of the U.S. Treasury Liquidity

This table lists break dates in the means of liquidity measures of U.S. Treasury market. The dates are
estimated by the Bai and Perron (1998, 2003) approach with 5% significance level. The sample period is from
April 2005 to December 2014. The data frequency is monthly.




                  Measure                                   Break Dates
                  Noise                        2007m6       2008m6     2009m6
                  On the run premium           2011m1
                  Roll                         2007m10      2009m7     2011m12
                  Turnover (negative)          2006m3       2008m10    2010m4      2011m11




  Table 15: Double Maximum Test Statistics of Multiple Breaks in the Means of the U.S. Treasury
                                           Liquidity

This table lists the double maximum statistics of break dates in the means of liquidity measures of U.S.
Treasury market. The dates are estimated by the Bai and Perron (1998, 2003) approach with 5% significance
level. The sample period is from April 2005 to December 2014. The data frequency is monthly. The null
hypothesis is that there is no break, and the alternative hypothesis is that there is at least one break. The
critical values are obtained from Bai and Perron (1998).

                                                             5% critical                5% critical
                          Measure               WDmax         value of     UDmax         value of
                                                              WDmax                      UDmax
          Noise                                     12.10         10.39          7.14         9.52
          On the run premium                        54.14         10.39         35.88         9.52
          Roll                                     119.05         10.39         87.48         9.52
          Turnover (negative)                      276.59         10.39       276.59          9.52
        Appendix Table 1: Sequential Test Statistics of Multiple Breaks in the Means of Liquidity
                                           (Aggregate-level)

This table lists the sequential test statistics of break dates in the means of 9 aggregate-level liquidity measures
of the U.S. corporate bond market. The dates are estimated by the Bai and Perron (1998, 2003) approach with
5% significance level. The sample period is from April 2005 to December 2014. The data frequency is
monthly. The critical values are obtained from Bai and Perron (1998).

                                  5%                     5%                        5%                     5%
                                  critical               critical                  critical               critical
                                  value of               value of                  value of              value of
 Measure                 ‫ ்ܨ‬ሺʹȁͳሻ ‫ ்ܨ‬ሺʹȁͳሻ      ‫ ்ܨ‬ሺ͵ȁʹሻ ‫ ்ܨ‬ሺ͵ȁʹሻ ‫ ்ܨ‬ሺͶȁ͵ሻ         ‫ ்ܨ‬ሺͶȁ͵ሻ ‫ ்ܨ‬ሺͷȁͶሻ      ‫ ்ܨ‬ሺͷȁͶሻ
 Amihud                     4.77       9.10
 Amihud (sd)                4.20       9.10
 IRC                       38.60       9.10       24.08       10.55       6.13      11.36
 IRC (sd)                  45.50       9.10       35.85       10.55       7.17      11.36
 Roll                      15.55       9.10       21.60       10.55       3.60      11.36
 Non-block trade            9.44       9.10       28.85       10.55       9.15      11.36
 Spread                     2.15       9.10
 Turnover (negative)       20.29       9.10       20.31       10.55      20.31      11.36        2.12      12.35
 Zero trading             124.21       9.10       15.45       10.55       6.65      11.36
  Appendix Table 2: Sequential Test Statistics of Multiple Breaks in the Liquidity Factor Structure
                                       (Underwriter-level)

This table shows the sequential test statistics of break in factor structure of the U.S. corporate bond market
liquidity employing the Bai and Perron (1998, 2003) approach with 5% significance level. Each underwriter
has four liquidity measures: large issue size, small issue size, investment-grade, and high-yield. The sample
period is from April 2005 to December 2014. The data frequency is monthly. We estimate the top 10
principal components from the differenced and standardized liquidity measures, then run the tests iteratively
assuming that there are k principal factors, where k = 2 to 10. The critical values are obtained from Bai and
Perron (1998).



                          5%                      5%                      5%                     5%
   Number                 critical                critical                critical               critical
     of                   value of               value of                value of               value of
   factors     ‫ ்ܨ‬ሺʹȁͳሻ   ‫ ்ܨ‬ሺʹȁͳሻ     ‫ ்ܨ‬ሺ͵ȁʹሻ   ‫ ்ܨ‬ሺ͵ȁʹሻ    ‫ ்ܨ‬ሺͶȁ͵ሻ    ‫ ்ܨ‬ሺͶȁ͵ሻ    ‫ ்ܨ‬ሺͷȁͶሻ   ‫ ்ܨ‬ሺͷȁͶሻ
      2
      3         19.07       12.25        4.91       13.83
      4         14.35       14.60
      5         14.88       16.76
      6         32.27       18.68       19.72       20.57
      7         20.21       20.76
      8         185.50      22.62      185.50       24.64       85.77      25.57       50.42       26.54
      9         46.89       24.34       46.89       26.42       22.85      27.66
      10       3265.60      26.20      538.61       28.23      590.41      29.44       590.41      30.31
 Appendix Table 3: Sequential Test Statistics of Multiple Breaks in the Means of the U.S. Treasury
                                             Liquidity

This table lists the double maximum statistics of break dates in the means of liquidity measures of U.S.
Treasury market. The dates are estimated by the Bai and Perron (1998, 2003) approach with 5% significance
level. The sample period is from April 2005 to December 2014. The data frequency is monthly. The critical
values are obtained from Bai and Perron (1998).

                                 5%                     5%                   5%                   5%
                                 critical               critical             critical             critical
         Measure
                                 value of               value of             value of            value of
                        ‫ ்ܨ‬ሺʹȁͳሻ ‫ ்ܨ‬ሺʹȁͳሻ ‫ ்ܨ‬ሺ͵ȁʹሻ      ‫ ்ܨ‬ሺ͵ȁʹሻ ‫ ்ܨ‬ሺͶȁ͵ሻ    ‫ ்ܨ‬ሺͶȁ͵ሻ ‫ ்ܨ‬ሺͷȁͶሻ    ‫ ்ܨ‬ሺͷȁͶሻ

 Noise                     10.56       9.10     21.63      10.55      9.65      11.36

 On the run premium         5.65       9.10

 Roll                      25.12       9.10     31.19      10.55      1.26      11.36

 Turnover (negative)       34.26       9.10     16.50      10.55     16.50      11.36     12.23      12.35
