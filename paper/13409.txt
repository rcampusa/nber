                               NBER WORKING PAPER SERIES




             DETERMINACY AND IDENTIFICATION WITH TAYLOR RULES

                                         John H. Cochrane

                                       Working Paper 13409
                               http://www.nber.org/papers/w13409


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                    September 2007




I gratefully acknowledge research support from CRSP and the NSF via a grant administered by the
NBER. I am grateful for many comments and suggestions in this paper’s long gestation. Among many
others, I thank 5 referees, Fernando Alvarez, Marco Bassetto, David Backus, Florin Bilbiie, Mark
Gertler, Eric Leeper, Lars Hansen, Peter Ireland, Henrik Jensen, Pat Kehoe, Sophocles Mavroeidis,
Edward Nelson, Yoshio Nozawa, Monika Piazzesi, Stephanie Schmitt-Grohé, Christopher Sims, Eric
Sims, Robert Shimer, Lars Svensson, Martín Uribe, Michael Woodford, and participants at the Spring
2005 Inidiana University Monetary Economics Conference, Fall 2006 NBER EFG Conference and
University of Chicago Money Workshop. The views expressed herein are those of the author(s) and
do not necessarily reflect the views of the National Bureau of Economic Research. The Appendix
is available on my webpage http://faculty.chicagobooth.edu/john.cochrane/research/Papers/.

© 2007 by John H. Cochrane. All rights reserved. Short sections of text, not to exceed two paragraphs,
may be quoted without explicit permission provided that full credit, including © notice, is given to
the source.
Determinacy and Identification with Taylor Rules
John H. Cochrane
NBER Working Paper No. 13409
September 2007, Revised September 2010
JEL No. E31,E52,E58

                                              ABSTRACT

The new-Keynesian, Taylor-rule theory of inflation determination relies on explosive dynamics. By
raising interest rates in response to inflation, the Fed induces ever-larger inflation or deflation, unless
inflation jumps to one particular value on each date. However, economics does not rule out inflationary
or deflationary equilibria. Attempts to fix this problem assume that people believe the government
will choose to blow up the economy if alternative equilibria emerge, by following policies we usually
consider impossible. Therefore, inflation is just as indeterminate under “active” interest rate targets
as it is under fixed interest rate targets.

If one accepts the new-Keynesian solution, the parameters of the Taylor rule relating interest rates
to inflation and other variables are not identified without unrealistic assumptions. Thus, Taylor rule
regressions cannot be used to argue that the Fed conquered inflation by moving from a “passive” to
an “active” policy in the early 1980s.

The updated version presented here merges the content of two companion papers, w13409 and w13410,
into a single current version. Thus, as of September 2010, w13409 and w13410 are identical.


John H. Cochrane
Booth School of Business
University of Chicago
5807 S. Woodlawn
Chicago, IL 60637
and NBER
john.cochrane@gsb.uchicago.edu




An online appendix is available at:
http://www.nber.org/data-appendix/w13409
1    Introduction

How is the price level determined? The new-Keynesian, Taylor-rule theory (sometimes also called
“DSGE”) provides the current standard answer to this, perhaps the most fundamental, question of
macroeconomics. In this theory, inflation is determined because the central bank systematically
raises nominal interest rates more than one-for-one with inflation. This “active” interest rate target
is thought to eliminate the indeterminacy that results from fixed interest rate targets, and thus to
provide the missing “nominal anchor.”
    Theories ultimately rise and fall on their ability to organize facts. Keynes had the General
Theory of the great depression. Friedman and Schwartz had the Monetary History. The central
new-Keynesian story is that U. S. inflation was conquered in the early 1980s, by a change from
a “passive” policy in which interest rates did not respond suﬃciently to inflation to an “active”
policy in which they do so. Most famously, Clarida, Galí and Gertler (2000) ran regressions of
federal funds rates on inflation and output. They found inflation coeﬃcients below one up to 1980,
and above one since then. (Complex new-Keynesian models also “fit the data” well, but so do other
models. While important reassurance for applying models, this observation is not a useful test of
a model’s basic structure.)
    I challenge this theory and its interpretation of the data. First, I conclude that the Taylor
rule, in the context of a new-Keynesian model, leaves the same inflation indeterminacy as with
fixed interest rate targets. Second, if the model is true, the parameters of the Fed’s reaction
function are not identified, so regression evidence does not say anything about determinacy in a
new-Keynesian model.
    The same key point drives both observations: New-Keynesian models do not say that higher
inflation causes the Fed to raise real interest rates, which in turn lowers “demand,” which reduces
future inflation. That’s “old-Keynesian,” stabilizing logic. In new-Keynesian models, higher in-
flation leads the Fed to set interest rates in a way that leads to even higher future inflation. For
only one value of inflation today will inflation fail to explode, or, more generally, eventually leave a
local region. Ruling out non-local equilibria, new-Keynesian modelers conclude that inflation today
must jump to the unique value that leads to a locally-bounded equilibrium path.
    But there is no reason to rule out nominal explosions or “non-local” nominal paths. Transver-
sality conditions can rule out real explosions, but not nominal explosions. I conclude that the
multiple non-local equilibria are perfectly valid. Furthermore, if we do rule out the non-local paths,
interest rates that generate explosive inflation are an outcome that is never realized in the observed
equilibrium, so that response cannot be measured.

Responses: determinacy and dilemma
    These points are known, if perhaps not fully appreciated. Many authors have advanced propos-
als to trim new-Keynesian multiple equilibria by adding to the policy description. One can always
add such assumptions; for example if one assumes that the government will blow up the world in
any but one desired equilibrium, then alternative equilibria are ruled out. The question is whether
the assumptions made to rule out multiple equilibria are at all reasonable. In particular, to bring
a model to data, the assumptions must be vaguely plausible descriptions of what people currently
believe our government would do, and not wildly at odds with what governments actually do in
similar circumstances.
    Most proposals to trim equilibria sound superficially like sensible descriptions of what govern-


                                                   2
ments do to stop extreme inflation or deflation — switch to a commodity standard, exchange-rate
peg, money growth rule, or undertake a fiscal expansion. However, stopping an inflation or de-
flation is a completely diﬀerent act than disallowing an equilibrium. If an inflation-stopping policy
still describes how an equilibrium forms at each date, then the inflation or deflation and its end
remain an equilibrium path and we have ruled nothing out. To rule out equilibria, somewhere
along the path the government must specify policy so that it is impossible for an equilibrium to
form. Some proposals specify a commodity standard, which implies zero inflation, but also a very
high interest rate. Others specify a commodity standard with a tight and inconsistent limit on
money supply. Still others specify inconsistent fiscal and monetary policies, introduce arbitrage
opportunities, or set infinite inflation. It is these inconsistent or overdetermined policies, not the
inflation stabilization, which trims equilibria.
    Such assumptions seem wildly implausible, as descriptions of government behavior or as de-
scriptions of people’s current beliefs about government behavior. A policy configuration for which
“no equilibrium can form” or “private first-order conditions cannot hold” means a threat to blow
up the economy. Why would a government choose to blow up the economy, when tested policies
that stop inflation or deflation, while allowing equilibria to form at each date, are sitting on the
shelf? Governments that stop inflations do not also insist that the real quantity of money remain
at a low level, do not try to target hyperinflationary interest rates, do not introduce arbitrage
opportunities, and do coordinate fiscal and monetary policies.
   In fact, in most (Ramsey) analyses of policy choices, we label such policy configurations as
“impossible,” not just “implausible.” We think of governments choosing policy configurations,
while taking private first-order conditions as constraints; we think of governments acting in markets.
We don’t think governments can follow policies for which private first-order conditions don’t hold.
For example, to operate a commodity standard, we would say that a government must oﬀer to
exchange currency for the commodity freely at the stated price; it simply cannot also maintain a
low limit on money supply or a very high interest rate target.
    The dilemma is unavoidable. If we specify that the government will stop an inflation or deflation
in such a way that equilibria can form on each date, we get quite sensible proposals and descriptions
of what governments might do — can do, and have done — to end inflations or deflations, but we
don’t rule out any equilibria. To rule out equilibria, people must believe that the government will
blow up the economy. Whether the rest of the policy description resembles historically successful
stabilizations is irrelevant. Whether the impossible policies occur on the date of stabilization or at
any other point on the path is irrelevant. I survey the extensive literature, and do not find any
successful escape from this dilemma.

Responses: identification
    The literature also contains many attempts to rescue identification. One can also always add
assumptions to produce identification. But we can and must ask whether identification assumptions
are reasonable, as a description of Fed behavior, of people’s expectations of Fed behavior, and of
the theory with which the regressions are interpreted.
    The central identification problem is that the theory predicts there is no movement in the crucial
right hand variable, the diﬀerence between actual inflation and inflation in the desired equilibrium.
(The issue is not “in” vs. “out of” equilibrium, the issue is selection between multiple equilibria.)
At a deep level, then, we must assume that the correlations between interest rates and inflation
in the equilibrium are the same as the Fed’s response to movements away from that equilibrium.
More deeply, the right “natural rate,” the behavior of interest rates in the desired equilibrium, is

                                                  3
a completely diﬀerent issue from determinacy; how the interest rate should vary if inflation veers
away from the desired equilibrium. To identify the latter from the former, we must assume they
are the same.
    But then a second classic problem arises. In the equilibrium, the Taylor-rule right hand variables
(inflation, output) and all potential instruments are correlated with the monetary policy disturbance
term. This correlation is not accidental; it is central to the theory: If a monetary policy shock
occurs, then inflation and other right hand variables are supposed to jump to the unique values that
lead to a locally-bounded equilibrium. Really, identification depends on the right hand variables,
not the errors. The errors are structural shocks about which we can say little. The right hand
variables are determined by the model. It takes restrictions on the model to produce right hand
variables which are uncorrelated with the error terms.
    Furthermore, new-Keynesian theory also advocates a “stochastic intercept,” that the central
bank should vary the interest rate to follow variations in the “natural rate” induced by other shocks.
These movements are part of the empirical monetary policy disturbance, so the theory predicts that
these other shocks, and variables which depend on them, cannot be used as instruments. All of the
disturbances are structural shocks, not forecast errors, so they are serially correlated, invalidating
lags as instruments. And even if the disturbances were serially uncorrelated, then lags of endogenous
variables would not be correlated with right hand variables.
    In sum, New-Keynesian models specify policy rules that are a snake-pit for econometricians.
There is no basis for all the obvious devices, such as excluding variables from the policy rule, the
use of instruments, assuming monetary policy disturbances are orthogonal to other variables, and
lag-length restrictions on shocks. (Lag length and exclusion restrictions as approximations are
not a problem; restrictions to produce identification are.) Not only might these problems exist,
but theory predicts that most of them do exist. Empiricists must throw out key elements of the
theory to identify parameters. Finally, even if one could identify parameters from a determinate
new-Keynesian equilibrium (1980s), no one has ever addressed what one measures if the world is
indeterminate, as supposedly was the case in the 1970s. The change in coeﬃcients is a crucial part
of the story.



If not this then what?
    If not this theory, what theory can account for price-level determination, in a modern fiat-money
economy whose central bank follows an interest rate target? This paper is entirely negative, and
long enough, so it does not exposit or test an alternative theory. But it is worth pointing out one
logical conclusion that one can take from a negative result, and a glimmer of hope that a positive
result exists.
    The new-Keynesian Taylor rule model is an “active money, passive fiscal” regime, in Leeper’s
(1991) terminology: It assumes that the valuation equation for government debt, which states that
the real value of nominal debt equals the present value of real primary surpluses, holds by ex-post
lump-sum taxation, and therefore plays no role in price level determination. The opposite possi-
bility is the “active fiscal, passive money” regime, in which the valuation equation for government
debt determines the price level, but the central bank follows an interest rate rule that does not
destabilize the economy. Since this model of price-level determination relies on ruling out real,
rather than nominal explosions, through the consumer’s transversality condition, it does uniquely
determine the price level. It is not inconsistent with Taylor Rule regressions. It therefore does
provide a coherent economic theory of the price level, that can address current institutions.

                                                  4
    This paper and my conclusion are not a criticism of new-Keynesian economics in general. In
particular I do not have anything to say here that criticizes its basic ingredients: an intertempo-
ral, forward-looking “IS” curve, or an intertemporally-optimizing, forward-looking model of price-
setting subject to frictions, as captured in the “new-Keynesian Phillips curve.” The “passive
money, active fiscal” regime of such a model can determine inflation. Whether such a model can
fully address the data is another as-yet unanswered question.

An acknowledgement
    Indeterminacy, multiple equilibria, and identification in dynamic rational-expectations models
are huge literatures that I cannot possibly adequately cite, acknowledge, or review in the space of
one article. The body of the paper reviews specific important contributions in the context of new-
Keynesian models. This is not a critique of those specific papers. I choose these papers as concrete
and well-known examples of general points, repeated throughout the literature. The web Appendix
contains a much more comprehensive review, both to properly acknowledge others’ eﬀorts, and to
establish that no, these problems have not been solved.
    The equations in this paper are simple and not new. In this field, however, there is great debate
over how one should read and interpret simple and fairly well-known equations. This paper’s novelty
is a contribution to that worthwhile and subtle debate.


2     Simplest model

We can see the main points in a very simple model consisting only of a Fisher equation (consumer
first order conditions) and a Taylor rule describing Fed policy,
                                            it = r + Et π t+1 ,                                      (1)
                                           it = r + φπ t + xt ,                                      (2)
where it = nominal interest rate, π t = inflation, r = constant real rate.
    The monetary policy disturbance xt represents variables inevitably left out of any regression
model of central bank behavior, such as responses to financial crises, exchange rates, time-varying
rules, mismeasurement of potential output, and so on. It is not a forecast error, so it is serially
correlated,
                                         xt = ρxt−1 + εt .                                      (3)
(Equivalently, applying (1 − ρL) to both sides of (2), the target may be smoothed and react to past
inflation. )
   We can solve this model by substituting out the nominal interest rate, leaving the equilibrium
condition
                                      Et π t+1 = φπ t + xt .                                   (4)


2.1   Determinacy

Equation (4) has many solutions. This observation forms the classic doctrine (Sargent and Wallace
(1975)) that inflation, to say nothing of the price level, is indeterminate with an interest rate target.
We can write the equilibria of this model as
                                π t+1 = φπ t + xt + δ t+1 ; Et (δ t+1 ) = 0                          (5)

                                                     5
where δ t+1 is any conditionally mean-zero random variable. Multiple equilibria are indexed by
arbitrary initial inflation π 0 , and by the arbitrary random variables or “sunspots” δ t+1 .
    If kφk > 1, all of these equilibria except one eventually explode, i.e. Et (π t+j ) grows without
bound. If we disallow such solutions, then a unique locally-bounded solution remains. We can
find this solution by solving the diﬀerence Equation (4) forward, or by undetermined coeﬃcients
(which assumes a bounded solution, depending only on xt ),
                                          ∞
                                          X         1                   xt
                                 πt = −         j+1 Et (xt+j )    =−       .                           (6)
                                                φ                      φ−ρ
                                          j=0

Equivalently, by this criterion we select the variables π 0 , {δ t+1 }, which index multiple equilibria, as
                                              x0             εt+1
                                    π0 = −       ; δ t+1 = −      .                                    (7)
                                             φ−ρ             φ−ρ

    Thus we have it: if the central bank’s interest rate target reacts suﬃciently to inflation — if
kφk > 1 — then it seems that a pure interest rate target, with no control of monetary aggregates, no
commodity standard or peg, and no “backing” beyond pure fiat, can determine at least the inflation
rate, if not quite the price level. It seems that making the peg react to economic conditions overturns
the classic doctrine that inflation is indeterminate under an interest-rate peg.
    This simple example makes it crystal-clear that inflation determination does not come from
the stabilization of inflation in old-Keynesian stories. Real rates are constant. Nominal rate rises
cannot raise real rates and so dampen “demand.” If the Fed increases the nominal rate, it must
allow expected inflation to increase, thus de-stabilizing inflation. As King (2000) emphasizes,
φ < −1, oscillating hyper-inflation and deflation, works just as well as φ > 1 to ensure determinacy.
That example is hard to describe by “stabilizing” intuition.
    But what’s wrong with non-local equilibria? Transversality conditions can rule out real explo-
sions, but not nominal explosions. Hyperinflations are historic realities. This condition didn’t come
from any economics of the model. I conclude there’s nothing wrong with them, and this model
does not determine inflation.
    This is an example, which needs fleshing out. First, I need to write down a fully-specified
model, to show there truly is nothing wrong with non-local equilibria. Second, I need to examine
the standard three-equation model, including varying real rates and price stickiness, to verify that
this simple frictionless model indeed captures the same issues. Third, haven’t the legions of people
who have addressed these issues solved all these problems? I review the literature to verify they
have not done so.


2.2   Identification

Now, suppose the solution (6) is in fact correct, what are its observable implications? Since π t is
proportional to xt , the dynamics of equilibrium inflation are simply those of the disturbance xt ,

                                            π t = ρπ t−1 + wt .                                        (8)
(wt ≡ −εt /(φ − ρ), but εt and xt are not directly observed, so we can summarize observable
dynamics with the new error wt .) Using (1) and (8), we can find the equilibrium interest rate,
                                                it = r + ρπ t .                                        (9)

                                                        6
    Equation (9) shows that a Taylor-rule regression of it on π t will estimate the disturbance serial
correlation parameter ρ rather than the Taylor rule parameter φ.
    What happened to the Fed policy rule, Equation (2)? The solution (6) shows that the right hand
variable π t and the disturbance xt are correlated — perfectly correlated in fact. That correlation
is no accident or statistical assumption, it is central to how the model behaves. The whole point
of the model, the whole way it generates responses to shocks, is that endogenous variables (π t )
“jump” in response to shocks (εt ), so as to head oﬀ expected explosions.
   Perhaps we can run the regression by instrumental variables? Alas, the only instruments at
hand are lags of π t and it , themselves endogenous, and thus invalid. For example, if we use all
available lagged variables as instruments, we have from (8) and (9)

                              E(π t |π t−1 , it−1 , π t−2 , it−2 ....) = ρπ t−1
                               E(it |π t−1 , it−1 , π t−2 , it−2 ....) = r + ρ2 π t−1 .

Thus the instrumental variables regression gives exactly the same estimate

                 E(it |π t−1 , it−1 , π t−2 , it−2 ....) = r + ρE(π t |π t−1 , it−1 , π t−2 , it−2 ....).

If the disturbance xt were i.i.d., then the correlation of instruments with errors would be removed,
but so would the correlation of instruments with right hand variables.
     Is there nothing clever we can do? No. The equilibrium dynamics of the observable variables
{it , π t } are completely described by equations (8) and (9). The equilibrium dynamics, and the
resulting likelihood function, do not involve φ. φ is not identified from data on {it , π t } in the
equilibrium of this model. Inflation is supposed to jump to the one value for which accelerating
inflation at rate φ is not observed. If it does so, there is no way to measure how fast the inflation
would accelerate if it did not.
    Absence of φ from equilibrium dynamics and the likelihood function means that we can’t even
test whether the data are generated from the region of determinacy kφk > 1, abandoning hope of
measuring the precise value of φ, as Lubik and Schorfheide (2004) try to do. For every equilibrium
generated by a φ∗ with kφ∗ k > 1, the same equilibrium dynamics (8) and (9) can be generated by
a diﬀerent φ with kφk < 1. The web Appendix elaborates this point.
   Again, this is the beginning. I need to show that the same problems occur in more complex
models, including the standard three-equation new-Keynesian model that Clarida, Galí and Gertler
(2000) and other authors use, and that the many attempts at identification don’t convincingly
surmount them.


3     An explicit frictionless model

3.1   The model

To keep the discussion compact and consistent with the literature, I simplify standard sources,
Benhabib Schmitt-Grohé and Uribe (2002) and Woodford (2003). Consumers maximize a utility
function
                                           ∞
                                           X
                                   max Et     β j u(Ct+j ).
                                                        j=0



                                                            7
Consumers receive a constant nonstorable endowment Yt = Y ; markets clear when Ct = Y . Con-
sumers trade in complete financial markets described by real contingent claims prices mt+1 and
hence nominal contingent claims prices
                                                              Pt
                                                  Qt,t+1 =        mt+1 .
                                                             Pt+1
The nominal interest rate is related to contingent claim prices by
                                                    1
                                                         = Et [Qt,t+1 ] .
                                                  1 + it

    The government issues one-period nominal debt; Bt−1 denotes the face value issued at time t−1
and coming due at date t. The government levies lump-sum taxes St , net of transfers. St denotes
the real primary surplus. I follow Benhabib Schmitt-Grohé and Uribe (2002), Woodford (2003),
Cochrane (2005) and many others in describing a frictionless economy. The dollar can be a unit
of account even if, in equilibrium, nobody chooses to hold any dollars overnight.
   The consumer faces a present-value budget constraint
                          ∞
                          X                                       ∞
                                                                  X
                     Et         Qt,t+j Pt+j Ct+j = Bt−1 + Et             Qt,t+j Pt+j (Yt+j − St+j ) .   (10)
                          j=0                                      j=0

or, in real terms,
                                ∞
                                X                               X  ∞
                                                      Bt−1
                          Et          mt,t+j Ct+j =        + Et   mt,t+j (Yt+j − St+j ) .               (11)
                                                       Pt
                                j=0                                j=0


3.2   Equilibria

The consumer’s first order conditions state that marginal rates of substitution equal contingent
claims price ratios, and equilibrium Ct = Y implies a constant real discount factor,

                                             uc (Ct+1 )            uc (Y )
                                         β              = mt+1 = β         = β.                         (12)
                                              uc (Ct )             uc (Y )

Therefore, the real interest rate is constant,
                                                  1
                                                     = Et (mt+1 ) = β
                                                 1+r
and the nominal discount factor is
                                                          Pt            Pt
                                              Qt,t+1 =        mt+1 = β      .                           (13)
                                                         Pt+1          Pt+1

   The interest rate follows a Fisher relation,
                                                             µ          ¶              µ          ¶
                             1                                    Pt           1            1
                                  = Et (Qt,t+1 ) = βEt                      =     Et                    (14)
                           1 + it                                Pt+1         1+r          Πt+1

The usual relation (1) follows by linearization.

                                                             8
   From the consumer’s present value budget constraint (10), and using contingent claim prices
from (13), equilibrium Ct = Y also requires
                                             ∞
                                   Bt−1 X    1
                                       =           Et (St+j ) .                                   (15)
                                    Pt    (1 + r)j
                                            j=0

The value of government debt is the present value of future tax payments. This is not a “government
budget constraint,” it is an equilibrium condition, an implication of supply = demand or Ct = Yt in
goods markets, as you can see directly by looking at (11). Section 1 of the web Technical Appendix
and Cochrane (2005) discuss this issue in more P detail.   I assume that the present value of future
primary surpluses is positive and finite, 0 < ∞         1
                                                 j=0 (1+r)j Et (St+j ) < ∞.

    The Fisher equation (14) and the government debt valuation equation (15) are the only two
conditions that need to be satisfied for the price sequence {Pt } to represent an equilibrium. If
they hold, then the allocation Ct = Y and the resulting contingent claims prices (13) imply that
markets clear and the consumer has maximized subject to his budget constraint. The equilibrium
is not yet unique, in that many diﬀerent price or inflation paths will work. Unsurprisingly, we need
some specification of monetary and fiscal policy to determine the price level.


3.3   New - Keynesian policy and multiple equilibria

The new-Keynesian/Taylor-rule analysis maintains a “Ricardian” fiscal regime; net taxes St+j are
assumed to adjust so that the government debt valuation equation (15) holds given any price level.
(Woodford (2003) p. 124.) It also specifies a Taylor rule for monetary policy.
    We have answered the first question needed from this explicit model: yes, solutions of the
simple model consisting of a Fisher equation and a Taylor rule (1)-(2), as I studied above, do in
fact represent the full set of (linearized) equilibrium conditions of this explicit model, if we assume
a Ricardian fiscal regime. My simple model didn’t leave anything out.
    Are the non-local equilibria really globally valid? Here I follow the standard sources, in part
to emphasize agreement that they are. (Woodford (2003) Ch. 2.4, starting p. 123, and Ch. 4.4
starting on p. 311, with a review; Benhabib Schmitt-Grohé and Uribe (2002).)
    Restrict attention to perfect foresight equilibria. Adding uncertainty (sunspots) can only in-
crease the number of equilibria. Consider an interest rate (Taylor) rule

                                1 + it = (1 + r)Φ(Πt ); Πt ≡ Pt /Pt−1 .                           (16)

Φ(·) is a function allowing nonlinear policy rules. The consumer’s first order condition (14) reduces
to
                                          Πt+1 = β(1 + it ).                                     (17)
We are looking for solutions to the pair (16) and (17). As before, we substitute out the interest
rate and study the equation
                                          Πt+1 = Φ(Πt ).                                     (18)
We have a nonlinear, global, perfect-foresight version of the analysis in Section 2.
    As Benhabib Schmitt-Grohé and Uribe emphasize, a Taylor rule with slope greater than one
should not apply globally to an economy in which consumers can hold money, because nominal
interest rates cannot be negative. Thus, if we want to specify a Taylor rule with Φπ > 1 at

                                                  9
some point, we should think about the situation as illustrated in Figure 1. The equilibrium at
Π∗ satisfies the Taylor principle, and is a unique locally bounded equilibrium. Any value of Π0
other than Π∗ leads away from the neighborhood of Π∗ as shown. With a lower bound on nominal
interest rates, however, the function Φ(Π) must also have another stationary point, labeled ΠL .
This stationary point must violate the Taylor principle. Therefore, many paths lead to ΠL and
there are “multiple local equilibria” near this point. In addition, the equilibria descending from
Π∗ to ΠL are “bounded” though not “locally bounded.”
   (Yes, Π∗ is the “good” equilibrium and ΠL is the “bad” equilibrium. The point is to find deter-
minacy by ruling out multiple equilibria. Π∗ is a unique locally-bounded equilibrium. “Stability”
near ΠL comes with “indeterminacy.”)

                                    Π t +1




                        0 nominal rate




                                                                           Πt
                                                    ΠL     Π0 ?    Π*



                  Figure 1: Dynamics in a perfect foresight Taylor-rule model.

     All of these paths are equilibria. Since these paths satisfy the policy rule and the consumer’s
first-order conditions by construction, all that remains is to check that they satisfy the government
debt valuation formula (15), i.e. that there is a set of ex-post lump-sum taxes that can validate
them and hence ensure the consumer’s transversality condition is satisfied. There are lots of ways
the government can implement such a policy. We only need to exhibit one. If the government
simply sets net taxes in response to the price level as
                                                      r Bt−1
                                             St =                                               (19)
                                                    1 + r Pt
then the real value of government debt will be constant, and the valuation formula will always hold.
    To see why this is true, start with the flow constraint, proceeds of new debt sales + taxes =
old debt redemption,
                                         Bt
                                              + Pt St = Bt−1 .
                                       1 + it
With 1 + it = (1 + r)Pt+1 /Pt , this can be rearranged to express the evolution of the real value of

                                                     10
the debt,                                                      µ            ¶
                                        Bt                         Bt−1
                                            = (1 + r)                   − St .                    (20)
                                       Pt+1                         Pt
Substituting the rule (19) we obtain
                                                     Bt    Bt−1
                                                         =      .
                                                    Pt+1    Pt
We’re done. With constant real debt and the flow relation (20) the transversality condition holds,
and (20) implies (15). All the “explosive” equilibria of the simple model of Section 2 are, in fact,
perfectly valid. Deflationary equilibria that approach ΠL are also valid equilibria, as is ΠL itself.
If we write the Taylor rule such that i = 0 at ΠL (for example, it = max(0, r + φπ t )), the “liquidity
trap” equilibrium it = 0, ΠL = β (deflation at the rate r) is also a valid equilibrium.


3.4   Non-Ricardian Policy

The price level is uniquely determined in this frictionless model if we strengthen, rather than throw
out, the government valuation equation — if the government follows a “non-Ricardian” fiscal regime.
This is a natural alternative theory to consider, it is the basis for a lot of equilibrium-trimming and
related discussion that follows, and it clarifies the fundamental issue.
    As the simplest example, suppose fiscal policy sets the path of real net taxes {St } independently
of the price level. (A proportional income tax achieves this result.) The initial stock of government
debt Bt−1 is predetermined. Then, (15) determines the price level Pt ,

                                                  X       ∞
                                        Bt−1           1
                                             = Et            St+j .                               (21)
                                         Pt         (1 + r)j
                                                         j=0

This is the same mechanism by which stock market prices are determined as the present value of
dividends (Cochrane (2005)).
    The government can still follow an interest rate rule. By varying the amount of nominal debt
sold at each date, the government can control expected future prices and hence the interest rate.
                              1
Multiplying (21) at t + 1 by 1+r  and taking expectations,
                               µ                ¶                      X  ∞
                       Bt            1    Pt            Bt 1                1
                          Et                        =             = Et            St+j .
                       Pt          1 + r Pt+1           Pt 1 + it        (1 + r)j
                                                                          j=1

Pt is determined by (21). Then, by changing debt sold at time t, Bt , the government can determine
it and Et (Pt /Pt+1 ). Alternatively, the government can simply auction bonds at the interest rate
it , and this equation tells us how many Bt it will sell.
   Ex-post inflation is determined by the ex-post value of (21), which we can write in a pretty
proportional form
                                   ³       ´               P
                      (Et+1 − Et ) 1+π1t+1     (Et+1 − Et ) ∞       1
                                                             j=1 (1+r)j St+j .
                                             =        P                                    (22)
                            Et 1+π1t+1             Et ∞        1
                                                        j=1 (1+r)j St+j

Linearizing in the style of Section 2, innovations to the present value of surpluses determine ex-post
inflation, the quantity δ t+1 = π t+1 − Et π t+1 which indexed multiple equilibria in (5).


                                                           11
    In this regime, the price level (not just inflation) is determinate, even with a constant interest
rate target it = i. This regime also overturns the doctrine that interest rate targets lead to
indeterminacy. (Leeper (1991), Sims (1994), Woodford (1995).)
    Since it is free to set interest rates, the government can follow a Taylor rule. Thus, the empirical
finding that a Taylor rule seems to fit well is not inconsistent with this theory, nor is the observation
that central banks can and do set interest rates. A Taylor rule with φ > 1 will generically lead
to equilibria that are not locally bounded,unless fiscal shocks happen to select the new-Keynesian
equilibrium. Thus, we obtain the usual doctrine following Leeper (1991) that “active” fiscal policy
should be paired with “passive” (φ < 1) monetary policy.
    Without direct observations of δ t+1 , similar identification problems remain, discussed in Section
3.1 of the web Appendix. However, estimates of φ are not particularly important in this regime, as
price level determinacy or the control of inflation do not hinge on φ. In fact, problems in measuring
φ are to some extent welcome. They mean we do not have to take regression estimates as strong
evidence for a troublesome structural φ > 1 despite stable inflation. Non-Ricardian models can
generate spurious φ > 1 as easily as new-Keynesian models can do.
    At a minimum, the fiscal regime oﬀers a way to understand U.S. history in periods that even
new-Keynesians believe are characterized by passive (φ < 1) monetary policy. This oﬀers an
improvement over “indeterminacy” or “sunspots” which give few restrictions on the data. Woodford
(2001) applies this regime to the Fed’s interest rate peg in the late 1940s and early 1950s. Applying
it to the 1970s is an obvious possibility.


3.5   Ricardian asymmetry, asset prices, and observational equivalence.

Equations (21) and (22) also describe an equilibrium in which a variable, the price level, is a forward-
looking expectation, and jumps to avoid an explosive root. Recall the evolution of government debt
(20) as                                            µ           ¶
                                    Bt               Bt−1
                                         = (1 + r)        − St .                                    (23)
                                   Pt+1               Pt
Again, we have an unstable root. If Pt is too low, then the real value of government debt explodes.
In response to a shock, Pt jumps to the unique value that prevents such an explosion.
   How do I accept explosive solutions in the new-Keynesian model, while I deny them in the
non-Ricardian regime? Why do I solve asset pricing equations pt+1 = Rt+1 pt − dt+1 forward, but
not π t+1 = φπ t − xt ? There is a fundamental diﬀerence. There is a transversality condition forcing
the consumer to avoid real explosions, explosions of Bt−1 /Pt or the real value of assets. There is
no corresponding condition forcing anyone to avoid nominal explosions, explosions of Pt itself.
    Correspondingly, there is an economic mechanism forcing (21) to hold in a non-Ricardian regime.
If the price level is below the value specified by (21), nominal government bonds appear as net wealth
to consumers. They will try to increase consumption. Collectively, they can’t do so, therefore this
increase in “demand” will push prices back to the equilibrium level. Supply equals demand and
consumer optimization are satisfied only at the unique equilibrium. Stock prices are pushed to the
present value of dividends by the same mechanism.
    There is no corresponding mechanism to push inflation to the new-Keynesian value (6). In
the new-Keynesian model we are choosing among equilibria; supply equals demand and consumer
optimization hold for any of the alternative paths, any choice of δ t+1 ; we’re finding the unique
locally bounded equilibrium, not the unique equilibrium itself. The economy is supposed simply to


                                                   12
jump to the right equilibrium.
   In asset pricing equations such as (23) and pt+1 = Rt+1 pt − dt+1 we can also measure the
“explosive eigenvalue,” the rate of return, despite the forward-looking solution. This occurs because
we can measure the dividend directly. In a deep sense, the reason we can’t measure φ is because
we have no independent measure of the monetary policy shock.
    Alas, new-Keynesian and fiscal regimes are observationally equivalent without further assump-
tions that are well beyond the scope of this paper. All the equilibrium conditions hold in each case.
We cannot test whether inflation occurred, and this caused the government to “passively” change
taxes ex-post, or whether people knew that taxes were going to change, and the price level jumped
in their expectation. Canzoneri, Cumby and Diba’s (2001) fiscal test has the same flaw as Clarida,
Galí and Gertler’s (2000) monetary test, shown in Cochrane (1998).
    Really, the regimes are not so distinct. From a fiscal point of view, a commodity standard is just
a device to communicate and enforce a fiscal commitment. If the government will always buy and
sell a commodity at a given price, it must adjust lump-sum taxes ex post to have suﬃcient stocks
of the commodity on hand. One could say that the government valuation equation (21) “really”
determines the price level, and the commodity standard with “Ricardian regime” just communicates
the fiscal commitment. Commodity standards and pegs fall apart precisely when the underlying
fiscal commitment is no longer credible. Similarly, if the new-Keynesian equilibrium selection were
successful, one could say from a fiscal point of view that the government valuation equation (21)
“really” determines the price level, with interest rate policy merely a way to communicate and
enforce that fiscal commitment. Alas, however, the new-Keynesian interest rate regime does not
select a unique equilibrium, and thus a unique fiscal commitment. So the bottom line is that one
must find expectations of future surpluses in (21) somewhere else.


4     New-Keynesian Solutions

Of course, the New Keynesian literature is aware of these issues. How do they pick the locally-
bounded solution Π∗ and get rid of the other ones?


4.1   Reasonable expectations?

Much of the approach is simply to argue about what is reasonable. For example, Woodford (p.128)
argues that

         “The equilibrium ..[Π∗ ].. is nonetheless locally unique, which may be enough to allow
      expectations to coordinate upon that equilibrium rather than on one of the others.”

Similarly, King (2000, p. 58-59) writes

          “By specifying [φ > 1] then, the monetary authority would be saying, ‘if inflation
      deviates from the neutral level, then the nominal interest rate will be increased relative
      to the level which it would be at under a neutral monetary policy.’ If this statement is
      believed, then it may be enough to convince the private sector that the inflation and
      output will actually take on its neutral level.


                                                 13
Needless to say, these are rather weak arguments on which to hang the foundational question of
macroeconomics. They are especially weak in ruling out equilibria between ΠL and Π∗ . One might
think that expectations of accelerating inflation are not reasonable, but if 2% inflation expectations
are reasonable, is 1% — which sends us oﬀ on a spiral to ΠL — really so unreasonable?
    Importantly for judging the reasonableness of alternative equilibria, Woodford argues that we
should not think of an economy or Fed making a small “mistake” and therefore slipping from Π∗
into an explosive equilibrium; instead we should think of expectations of future inflation driving
inflation today: (p. 128)

         Indeed it is often said that .. the steady state with inflation rate Π∗ is “unstable”
     implying that an economy should be expected almost inevitably to experience either a
     self-fulfilling inflation or a self-fulfilling deflation under such a regime.
         Such reasoning involves a serious misunderstanding of the causal logic of the dif-
     ference equation [(18)]. This equation does not indicate how the equilibrium inflation
     rate in period t + 1 is determined by the inflation that happens to have occurred in the
     previous period. If it did it would be correct to call Π∗ an unstable fixed point of the
     dynamics—even if that point were fortuitously reached, any small perturbation would
     result in divergence from it. But instead, the equation indicates how the equilibrium
     inflation rate in period t is determined by expectations regarding inflation in the fol-
     lowing period... The equilibria that involve initial inflation rates near (but not equal
     to) Π∗ can only occur as a result of expectations of future inflation rates (at least in
     some states) that are even further from the target inflation rate. Thus the economy
     can only move to one of these alternative paths if expectations about the future change
     significantly, something that one may suppose would not easily occur.”

    A “serious misunderstanding of causal logic” is a strong charge, and I think unwarranted here.
The equations of the model do not specify a causal ordering. They are just equilibrium conditions.
And I think Woodford has slipped in a small misunderstanding of his own, by thinking of expec-
tations that are formed exogenously, or in a prior causal chain. If you are observing an unstable
dynamic system, and you see a small change today, the fact of that change causes a large change
in your expectations of the future. If you see the waiter trip, it’s a good bet the stack of plates
he is carrying will crash. In these models, agents might well see a disturbance, know the Fed will
feed back on its past mistakes, think “oh no, here we go,” and radically change their expectations
of the future. They don’t need to wake up and think “gee, I think there will be a hyperinflation”
before reading the morning paper. The forward-looking solutions rely exactly on endogenous ex-
pectations: They rely on a fortuitous jump in near-term expectations in response to a shock, to
put the economy back on the saddle path that has no change in asymptotic expectations.
    Still, there is some appeal to the argument that expectations of hyperinflations or liquidity
traps seem far-fetched. But expectations that are far-fetched in our intuitive understanding of our
world are not necessarily so far-fetched for agents in this model, once we recognize that this model
may not represent our world. In this model, the Fed is absolutely committed to raising interest
rates more than one for one with inflation, forever, no matter what. In this model, real rates are
constant, so the rise in nominal rates must correspond to a rise in inflation — precisely the opposite
of the stabilizing language that pours out of the real-world Federal Reserve’s account of its actions.
If we really lived in such a world, I, for one, would confidently expect hyperinflation. If we think
that forecast is “unreasonable,” it means we don’t believe the model describes the world in which
we live.

                                                 14
4.2     Solutions and dilemma

Recognizing, I think, the weakness of these arguments—if not, they would not need to go on—New-
Keynesian theorists have explored a variety of ways to trim multiple equilibria. Alas, these fall in
the logical conundrum explained in the introduction: To trim equilibria, we must assume that the
government will blow up the world — to set policy in such a way that private first order conditions
cannot hold — even though policies exist that would allow the government to stop inflation or
deflation while letting the economy operate.

4.2.1     Stabilizations; shift to commodity standard or money growth rule

Woodford’s (2003) section 4.3 studies proposals to cut oﬀ inflationary equilibria to the right of Π∗ .
Woodford’s main suggestion is (p. 138):

            ...self-fulfilling inflations may be excluded through the addition of policy provisions
        that apply only in the case of hyperinflation. For example, Obstfeld and Rogoﬀ (1986)
        propose that the central bank commit itself to peg the value of the monetary unit in
        terms of some real commodity by standing ready to exchange the commodity for money
        in event that the real value of the total money supply ever shrinks to a certain very low
        level. If it is assumed that this level of real balances is one that would never be reached
        except in the case of a self-fulfilling inflation, the commitment has no eﬀect except to
        exclude such paths as possible equilibria. ...[This proposal could] well be added as a
        hyperinflation provision in a regime that otherwise follows a Taylor rule.

    In real life governments often stop inflations by a firm peg to a foreign currency (with a fiscal
reform, to make credible the Ricardian fiscal policy commitment), which is the modern equivalent
of a commodity standard. Atkeson, Chari and Kehoe (2009) advocate a similar idea, but specify
that the government switches to a money growth rule in a model with non-interest-elastic money
demand. Switching to a non-Ricardian regime to enforce a fixed price level would have the same
eﬀect.
    However, this quote and the surrounding discussion does not explain how stabilizing an inflation
serves to rule out an equilibrium path. First-order conditions can hold throughout the inflation
and stabilization, and then the path is not ruled out.
    The answer is that each of these proposals implicitly or pairs the stabilization with another,
superfluous, inconsistent policy specification, in such a way that equilibrium cannot form. Incon-
sistent policy rules out the equilibrium path, not inflation stabilization. The key assumption in
Woodford’s quote is “otherwise follows a Taylor rule.” His government continues to follow the Tay-
lor rule even after it has switched to a commodity standard! You can’t have two monetary policies
at once; if you do, no equilibrium can form.
    To be precise, suppose that at inflation past some level ΠU the government changes to a commod-
ity standard (a peg), switches to a money growth rule with interest-inelastic demand, or switches a
non-Ricardian regime. At date T − 1, ΠT −1 < ΠU , so the consumer obeys his first order conditions,
the Fed follows the Taylor rule, and equilibrium inflation still follows
                                     ΠT = β(1 + iT −1 ) = Φ(ΠT −1 ).

   Now, suppose ΠT > ΠU so at date T , the government freezes this price level at PT by one of
the above policies, and PT +1 = PT . Equilibrium at date T therefore requires iT = r, from the

                                                    15
consumer’s first order conditions
                                       ΠT +1 = 1 = β(1 + iT ).

   The hyperinflation had ended, but this fact does not “exclude such paths as possible equilibria.”
The key to “excluding equilibria” is that Woodford, Atkeson, Chari and Kehoe, etc., assume that
the Fed also continues to follow the Taylor rule, 1 + iT = (1 + r)Φ(ΠT ) which is a huge number,
and inconsistent with iT = r demanded by first-order conditions.
    We would normally say it’s impossible to both run a commodity standard which requires iT = r
and set interest rates to hyperinflationary levels which requires iT to be a huge number. As Wood-
ford explains, the government implements a commodity standard by “standing ready to exchange
the commodity for money.” It can’t both do that and control the quantity of money to follow an
interest rate target. If the government really could commit to such a thing there would be “no
equilibrium.” But does it really make any sense that the government would try to do such a thing,
that people would believe that it would try to do such a thing, that a government even can do such
a thing, and persist long enough to “rule out equilibrium,” whatever that means?
    At a minimum, we see that stabilizing accelerating inflation has nothing to do with ruling out
the equilibrium path. One period of inconsistent policy anywhere along the path would have been
enough to accomplish the latter.
    Atkeson, Chari and Kehoe (2009) recognize the problem, are explicit about their assumptions,
and carefully set up policy so that equilibrium can form on every date past T . However, they
also assume that the Taylor rule requiring high interest rates coexist for one period with a money
growth rule that demands low interest rates, in order to rule out equilibrium. Blowing up the world
for one period is enough. The web Appendix reviews their proposal in detail.
    What about Obstfeld and Rogoﬀ (1983) (1986) and the related large literature that tries to trim
indeterminacies in models with fixed money supply and interest-elastic money demand? Didn’t they
solve all these problems years ago, as Woodford seems to suggest? Since it requires setting up a
diﬀerent model, I review Obstfeld and Rogoﬀ in detail in the web Appendix. The story is the same,
however. Obstfeld and Rogoﬀ also specify that the government switches to a commodity standard
at a very high level of inflation. This stops the inflation, but it allows an equilibrium at each date,
so the accelerating-inflation equilibrium path is not ruled out. To prevent the formation of an
equilibrium, Obstfeld and Rogoﬀ also specify that the nominal money supply after the reform must
be no higher than it was before the inflation started, or before the reform. They thus disallow the
recovery in real money balances which accompanies the end of hyperinflations. Their government
specifies both a low quantity M and a large price level. Again, however, what government would
do this? How would a government even do this? How could a government freely trade currency
for the commodity at a given price, and impose an upper limit on the money supply? I conclude
that models with M V (i) = P Y and fixed M have exactly the same unsolved indeterminacies as
the Taylor rule models.


4.3   Fiscal equilibrium-trimming

Benhabib, Schmitt-Grohé and Uribe (2002), mirrored in Woodford (2003) section 4.2, try to trim
equilibria by adding fiscal commitments to the Taylor rule. Their ideas are aimed at trimming
deflationary equilibria, but either set of ideas could apply to both inflations and deflations. They
specify that in low-inflation states, the government will lower taxes so much that real debt grows
explosively, the consumer’s transversality condition is violated, and the government debt valuation


                                                  16
equation no longer holds. Ergo, this region and all the equilibria below Π∗ in Figure 1 that lead to
it are ruled out. Specifically, (their equations (18)-(20)) they specify that in a neighborhood of ΠL ,
the government will commit to surpluses St = α(Πt ) (Bt−1 /Pt ) with α(ΠL ) < 0 in place of (19).
    They also show that the same result can be implemented by a target for the growth rate of
nominal liabilities, a “4% rule” for nominal debt. If deflation breaks out with such a commitment,
real debt will then explode; to keep nominal debt on target, the government would need to start
borrowing and spending as above. Woodford suggests this implementation as well (p. 132): “let
total nominal government liabilities Dt be specified to grow at a constant rate μ̄ > 1 while monetary
policy is described by the Taylor rule ...” “Thus, in the case of an appropriate fiscal policy rule, a
deflationary trap is not a possible rational expectations equilibrium.”
    As the above proposals are grounded in sensible policies to stabilize hyperinflations, these
proposals sound like sensible and time-honored prescriptions to inflate the economy, i.e., to head
back to the desired equilibrium Π∗ . Benhabib, Schmitt-Grohé and Uribe describe them this way
(p. 548):

           Interestingly, this type of policy prescription is what the U.S. Treasury and a large
      number of academic and professional economists are advocating as a way for Japan to
      lift itself out of its current deflationary trap...A decline in taxes increases the household’s
      after-tax wealth, which induces an aggregate excess demand for goods. With aggregate
      supply fixed, price level must increase in order to reestablish equilibrium in the goods
      market.

(They didn’t know that zero interest rates and $1.5 trillion deficits would so soon follow!) And this
is, indeed, how a coordinated fiscal-dominant regime works, it is good intuition for operation of the
fiscal theory of the price level, and undoubtedly what real-world proponents of these policies have
in mind.
    But that’s not their proposal. The proposal does not “lift the economy out of a deflationary
trap” back to Π∗ . Their proposal sits at ΠL with an uncoordinated policy and lets government
debt explode. If their proposal did successfully steer the economy back to Π∗ then the whole
path to ΠL and back would have been an equilibrium. As in the last section, they change tax
policy while also maintaining the Taylor rule Φ(Π) and the dynamics of Figure 1. In Woodford’s
quote “while monetary policy is described by the Taylor rule” is the key. We are switching to a
Ricardian regime, which demands higher inflation, while simultaneously keeping the Taylor rule
in place, which demands continued low inflation. The transversality condition is a consumer first-
order condition. We are setting policy parameters for which consumer first order conditions cannot
hold.
    Once we see that central point, we can think of many monetary-fiscal policies that preclude
deflationary equilibria equivalently and more transparently. If inflation gets to an undesired level,
tax everything. Burn the money stock. Introduce an arbitrage opportunity. Best of all, specify
a Φ(Π) function that includes negative nominal interest rates — just eliminate the ΠL equilibrium
in the first place! Bassetto (2004) suggests this option. Since there can be no equilibrium at
negative nominal rates, such a Φ(Π) function works exactly the same way to rule out equilibria: In a
deflationary state, the government commits to a policy that allows no equilibrium. Negative nominal
rates are no more or less possible than letting debt explode, or running a commodity standard with
high rates or low money stock. In retrospect, it doesn’t make sense to demand a Ramsey approach
in setting up the problem — the Taylor rule must not prescribe negative nominal rates, because that

                                                    17
would violate first order conditions — and then patch it up with policy prescriptions that do violate
first order conditions. Why not just commit to negative nominal rates in the first place?
   It’s not hard to understand why the issue has become so confused. Benhabib, Schmitt-Grohé and
Uribe, Woodford, and Obstfeld and Rogoﬀ before them, did not follow my alternative suggestions
— to specify policy paths that clearly and decisively forbid equilibrium. Instead, they thought
about a very reasonable-sounding response to inflation or deflation, and then subtly (and doubtless
unintentionally) snuck in an extra step that rules out equilibrium. It’s very easy to confuse “stopping
an inflation” with “ruling out this equilibrium path.” The easy-to-miss little extra step matters,
not the seductively sensible policy that gets us there.


4.3.1   Weird Taylor rules

Woodford starts “Policies to prevent an inflationary panic” by suggesting (p.136) a stronger Taylor
rule, that the graph in Figure 1 becomes vertical at some finite inflation ΠU above Π∗ , i.e. that the
Fed will set an infinite interest rate target. Similarly, Alstadheim and Henderson (2006) remove
the ΠL equilibrium by introducing discontinuous policy rules, or V-shaped rules that only touch
the 45◦ line at the Π∗ point. Bassetto (2004), mentioned above, likewise suggested that the Taylor
rule ignore the i ≥ 0 bound and promise negative nominal rates in a deflation.
    These proposals blow up the economy directly. At one level, however, these proposals are not as
extreme as they sound. After all, the Taylor principle in new-Keynesian models amounts to people
believing unpleasant things about alternative equilibria. The more unpleasant the beliefs, the more
eﬀective at ruling out equilibria, so hyperinflating away the entire monetary system, introducing an
arbitrage opportunity (i < 0), and so forth, certainly removes these equilibria, and perhaps more
eﬀectively than an inflation or fiscal imbalance that slowly gain steam.
    On the other hand, the real-world economy would presumably substitute to other moneys or
electronic barter of mutual fund shares before the value of money reached zero, making this hyper-
inflationary path possible, if admittedly unpleasant. And, while they are possible commitments
one might ask a future Fed to make, none of these are vaguely plausible descriptions of current
beliefs about Fed behavior, or current Fed statements.


4.3.2   Residual money demand; letting the economy blow up

Schmitt-Grohé and Uribe (2000) and Benhabib, Schmitt-Grohé and Uribe (2001) oﬀer a similar
way to rule out hyperinflations, without assuming the Fed directly blows up the economy with
infinite interest rates, by adding a little money. This idea is also reviewed by Woodford (2003
p. 137), and has long roots in the literature on hyperinflations with fixed money supply and
interest-elastic demand (Sims (1994)).
   Schmitt-Grohé and Uribe’s idea is easiest to express with real balances in the utility function.
With money, the Fisher equation contains monetary distortions:
                                            uc (Y, Mt /Pt )
                          1 + it = Πt+1                        = Πt+1 (1 + rt ),                  (24)
                                          βuc (Y, Mt+1 /Pt+1 )

where rt denotes the real interest rate. (This is a perfect foresight model, so the expectation is
missing.) Suppose the Taylor rule is
                                                 1
                                         1 + it = Φ(Πt ).
                                                 β

                                                    18
   Substituting it from the Taylor rule into (24), and rearranging the money vs. bonds first order
condition as Mt /Pt = L(Y, it ), inflation dynamics follow

                                                 uc [Y, L(Y, Φ(Πt+1 ))]
                                 Πt+1 = Φ(Πt )                                                     (25)
                                                  uc [Y, L(Y, Φ(Πt ))]

instead of (18).
    The idea, then, is that this diﬀerence equation may rise to require Πt+1 = ∞ above some bound
ΠU , even if the Taylor rule for nominal interest rates 1 + it = Φ(Πt )/β remains bounded for all Πt .
Woodford and Schmitt-Grohé and Uribe give examples of specifications of u(C, M/P ) for which
this can happen.
    Is this the answer? First and most importantly, if we do not regard the a belief that the Fed will
directly blow up the economy (it rises to ∞) as a reasonable characterization of expectations, why
would people believe that the Fed will to take the economy to a state in which the economy blows
up all on its own? Infinite inflation and finite interest rates mean infinitely negative real rates;
a huge monetary distortion. Surely the Fed would notice that real interest rates are approaching
negative infinity!
    Second, it is delicate. In general, this approach relies on particular behavior of the utility
function or the cash-credit goods specification at very low real balances. Are monetary frictions
really important enough to rule out inflation above a certain limit, sending real rates to negative
infinity, or to rule out deflation below another limit? We have seen some astounding hyperinflations;
real rates did not seem all that aﬀected.
    Sims (1994) pursues a similar idea. Perhaps there is a lower limit on nominal money demand,
so that real money demand explodes in a deflation. Perhaps not; perhaps the government can print
any number it wants on bills, or will run periodic currency reforms; perhaps real money demand is
finite for any price level.
    In sum, these proposals require two things: First, they require expectations that the government
will follow the Taylor rule to explosive hyperinflations and deflations, beyond anything ever ob-
served, and despite the presence of equilibrium-preserving stabilization policies such as the switch
to commodity standard, money growth, or non-Riciardian regime. Second, they require belief
in a deep-seated monetary non-neutrality suﬃcient to send real rates to negative infinity or real
money demand to infinity, though even the beginning of such events has never been observed. At
a minimum, this sounds like a weak foundation for the founding question of macroeconomics.


5    Determinacy and identification in the three-equation model

One may well object at the whole idea of studying identification and determinacy in such a stripped-
down model, with no monetary friction, no means by which the central bank can aﬀect real rates,
and a single disturbance. Typical verbal (old-Keynesian) explanations of Taylor rules and inflation,
and typical Federal Open Market Committee statements, involve at least the Phillips curve and Fed
control of real rates of interest: nominal rates rise, gaps appear, these gaps drive down inflation. You
can’t do that in a frictionless model. Empirical Taylor rule estimates are much more sophisticated
than it = φπ t + εt regressions. It turns out that the simple model does in fact capture the relevant
issues, but one can only show that by examining “real” new-Keynesian models and regressions in
detail and seeing that the same points and same logic emerge.


                                                   19
    The excellent exposition in King (2000) makes the non-identification and determinacy theorems
clear. The basic model is

                                   yt = Et yt+1 − σ (rt − r) + xdt                                      (26)
                                   it = rt + Et π t+1                                                   (27)
                                   π t = βEt π t+1 + γ (yt − ȳt ) + xπt                                (28)

where y denotes output, r denotes the real interest rate, i denotes the nominal interest rate, π
denotes inflation, ȳt is potential output, and the x are serially correlated structural disturbances.
I use x not ε and the word “disturbance” rather than “shock” to remind us of that fact.
   While seemingly ad-hoc, the point of the entire literature is that this structure has exquisite
micro-foundations, which are summarized in King (2000), and Woodford (2003). The first two
equations derive from consumer first order conditions for consumption today vs. consumption
tomorrow. The last equation is the “new-Keynesian Phillips curve,” derived from the first order
conditions of forward-looking optimizing firms that set prices subject to adjustment costs. There is
an active debate on the right specification of (28), including additional inflation dynamics and the
diﬀerence between output and marginal cost, but these diﬀerences do not aﬀect my conclusions.
     For both determinacy and identification questions, we can simplify the analysis by studying
alternative equilibria as deviations from a given equilibrium, following King (2000). Use yt∗ etc.
to denote equilibrium values. yt∗ is a stochastic process, i.e. a moving average representation
yt∗ ({xdt , xπt , xit , ..}) or its equivalent. There are many such equilibria. For example, given any
stochastic process for {yt∗ } you can construct the corresponding {π ∗t } , {rt∗ } , {i∗t } from (28),(26),
and (27) in order.
    Use tildes to denote deviations of an alternative equilibrium yt from the ∗ equilibrium, ỹt ≡
yt − yt∗ . Subtracting, deviations must follow the same model as (26)-(28), but without constants
or disturbances

                                          ı̃t = r̃t + Et π̃ t+1                                         (29)
                                          ỹt = Et ỹt+1 − σr̃t                                         (30)
                                         π̃ t = βEt π̃ t+1 + γ ỹt .                                    (31)


5.1    Determinacy

Now, if the Fed sets it = i∗t , i.e. ı̃t = 0, then π̃ t = 0, ỹt = 0 are an equilibrium. But setting it = i∗t
does not determine that this is the only equilibrium. To see this point, write (29)-(31) with ı̃t = 0
in a standard form as           ∙            ¸      ∙                 ¸∙       ¸
                                    Et ỹt+1      1 β + σγ −σ             ỹt
                                               =                                 .                      (32)
                                   Et π̃ t+1      β       −γ       1      π̃ t
Since the model only restricts the dynamics of expected future output and inflation, we have
multiple equilibria. Any
                        ∙        ¸     ∙          ¸∙       ¸ ∙         ¸
                          ỹt+1      1 β + σγ −σ      ỹt      δ y,t+1
                                   =                        +                           (33)
                          π̃ t+1     β   −γ    1      π̃ t     δ π,t+1

with Et δ y,t+1 = 0, Et δ π,t+1 = 0 is valid, not just δ y,t+1 = δ π,t+1 = 0 and hence ỹt = π̃ t = 0 for all
t.


                                                     20
    Perhaps however the dynamics of (32) are explosive, so at least ỹ = π̃ = 0 is the only locally-
bounded equilibrium; the only one in which Et (ỹt+j ) and Et (π̃ t+j ) stay near zero. Alas, this hope
is dashed as well: One of the eigenvalues of the transition matrix in (32), derived below, is less
than one. We have just verified in this model the usual doctrine that an interest rate peg does not
determine inflation.
    To determine output and the inflation rate, then, new-Keynesian modelers add to the specifica-
tion it = i∗t of what interest rates will be in this equilibrium, a specification of what interest rates
would be like in other equilibria, in order to rule them out. King (2000) specifies Taylor-type rules
in the form
                                  it = i∗t + φπ (π t − π ∗t ) + φy (yt − yt∗ )                      (34)
or, more simply,
                                           ı̃t = φπ π̃ t + φy ỹt .
(Both King and the web Appendix allow responses to expected future inflation and output as well.
The simpler version in (34) is enough for all my points however.)
    For example, with φy = 0 the deviations from the ∗ equilibrium now follow
                       ∙           ¸     ∙                       ¸∙      ¸
                         Et ỹt+1      1 β + σγ −σ (1 − βφπ )       ỹt
                                     =                                     .                       (35)
                         Et π̃ t+1     β    −γ           1          π̃ t

The eigenvalues of this transition matrix are
                         1 ³                p                             ´
                   λ=        (1 + β + σγ) ± (1 + β + σγ)2 − 4β (1 + σγφπ ) .                       (36)
                        2β
If we impose σγ > 0, then both eigenvalues are greater than one in absolute value if

                                                  φπ > 1

or if                                        µ          ¶
                                                    1+β
                                       φπ < − 1 + 2       .                                        (37)
                                                     σγ

    Thus, if the policy rule is suﬃciently “active,” any equilibrium other than ı̃ = ỹ = π̃ = 0 is
explosive. Ruling out such explosions, we now have the unique locally-bounded equilibrium. (The
web Appendix treats determinacy conditions with output responses and responses to expected
future inflation and output.)
   As in the simple model, the point of policy is to induce explosive dynamics, eigenvalues greater
than one, not to “stabilize” so that the economy always reverts after shocks. As pointed out
by King (2000), p. 78, the region of negative φπ described by (37), which generates oscillating
explosions, works as well as the conventional φπ > 1 to determine inflation.
    The analysis so far has exactly mirrored my analysis of the simple model of Section 2. So, in fact,
that model does capture the determinacy issues, despite its absence of any frictions. Conversely,
determinacy in the new-Keynesian model does not fundamentally rely on frictions, or the Fed’s
ability to control real rates, “demand,” etc.
    As in the simple model, no economic consideration rules out the explosive solutions. One might
complain that I have not shown the full, nonlinear model in this case, as I did for the frictionless
model. This is a valid complaint, especially since output may also explode in the linearized non-
local equilibria. I do not pursue this question here, as I find no claim in any new-Keynesian writing

                                                     21
that this route can rule out the non-local equilibria. Its determinacy literature is all carried out in
simpler frameworks, as I have done. And there is no reason, really, to suspect that this route will
work either. Sensible economic models work in hyperinflation or deflation. If they don’t, it usually
reveals something wrong with the model rather than the impossibility of inflation. In particular,
while linearized Phillips-curve models can give large output eﬀects of high inflations, we know that
some of their simple abstractions, such as fixed intervals between price changes, are only useful
approximations for low inflation. The Calvo fairy seems to visit more often in Argentina.
    In one respect, this analysis is quite diﬀerent from the simple model of Section 2. Determinacy
is a property of the entire system, and depends on other parameters of the model, not just φπ . Here,
for σγ < 0, there is a region with φπ > 1 in which both eigenvalues are not greater than 1, so we have
indeterminacy despite an “active” Taylor rule. There is another region in which both eigenvalues
are greater than one despite 0 < φπ < 1, so we have local determinacy despite a “passive” Taylor
rule. σγ < 0 is not a plausible parameter configuration but as models become more complex,
determinacy involves more parameters, and can often involve plausible values of those parameters.
King (2000) and the web Appendix give some examples in this model, generalizing to Taylor rules
that react to current and future output and inflation.
    Fundamentally, the point of Fed policy is to perturb the dynamics so the whole system is
unstable. The regions of determinacy are not as simple as φπ > 1, and testing for determinacy is
really not as simple as testing the parameters of the Fed reaction function. Alas, noone has tried
a test for determinacy in a more complex model.
    King’s expression of the Taylor rule (34) is particularly useful because it clearly separates “in-
equilibrium” or “natural rate” i∗t and “alternative-equilibrium” or determinacy φπ (π t − π ∗t ) issues
so neatly. One can read its instructions as: First, the Fed should set the interest rate to the “natural
rate” i∗t that appropriately reflects other shocks in the economy. Then, the Fed should react to
inflation away from the desired equilibrium in order to induce local determinacy of that equilibrium.
The two issues are completely separate.
    For example, many theoretical treatments find that interest rates which move more than one
for one with inflation are desirable, for reasons other than determinacy, or one may accept em-
pirical evidence that they do so. But both of these observations are essentially observations that
equilibrium interest rates i∗t should, or do, vary more than one for one with with equilibrium in-
flation, π ∗t . King’s expression emphasizes that these observations tell us nothing, really, about
determinacy issues, whether deviations from equilibrium should or do follow the same patterns. In
particular, one might object on these grounds to a Non-Ricardian regime, which requires φ < 1
to avoid explosions. But King’s expression (34) shows us that a more than one-for-one relation
between i∗t and π ∗t is perfectly consistent with a less than one-for-one relationship φ < 1 between
deviations (i − i∗ ) and (π − π ∗ ).


5.2   Identification

King’s expression of the Taylor rule (34) makes the central identification point very clear. In the
* equilibrium, we will always see π t − π ∗t = 0 and yt − yt∗ = 0. Thus, a regression estimate of
(34) cannot possibly estimate φπ , φy . There is no movement in the necessary right hand variables.
More generally, φπ and φy appear nowhere in the equilibrium dynamics characterized simply by
π̃ = ỹ = ı̃ = 0, so they are not identified. Taylor determinacy depends entirely on what the Fed
would do away from the * equilibrium, which we can never see from data in that equilibrium.



                                                  22
   King recognizes the issue, in footnote 41:

          “The specification of this rule leads to a subtle shift in the interpretation of the
      policy parameters [φπ , φy ]; these involve specifying how the monetary authority will
      respond to deviations of inflation from target. But if these parameters are chosen so
      that there is a unique equilibrium, then no deviations of inflation will ever occur.”

   He does not address its implications for empirical work.
   This issue is not particular to the details of the three equation model. In the general solution
method for these sorts of models, we set to zero movements of the linear combinations of variables
that correspond to unstable eigenvalues. As a result, we cannot measure those unstable eigenvalues.
The web Appendix makes this point with equations.
   So, what assumptions do people make to escape this deep problem? The prototype theoretical
Taylor rule (34), repeated here,
                                 it = i∗t + φπ (π t − π ∗t ) + φy (yt − yt∗ ) ,                      (38)
describes how the central bank would react to potential deviations from the equilibrium π ∗ , y ∗ , in
order to make yt∗ and π ∗t the unique locally-bounded equilibrium. To identify φπ , φy , then, we have
to make two assumptions:
     Assumption 1: The Fed’s reaction φπ , φy to a deviation of inflation π t and output yt from the
desired-equilibrium value π ∗t and yt∗ is the same as the relation between equilibrium interest rates
i∗t and equilibrium inflation π ∗t and yt∗ ; we must assume that the φ in (38) are the same as the φ in
a relation such as
                                       i∗t = φπ π ∗t + φy yt∗ + ... + xit                          (39)
where xit denotes a residual combination of shocks with suﬃcient orthogonality properties to allow
some estimation. (Of course, leads and lags and other variables may appear in both (38) and (39).)
    Making this assumption is (for once) relatively uncontroversial, since there are no obvious
observations one could make to refute it. Still, it’s worth making the assumption explicit and at
least worth reading Fed statements to see if they support it.
      The key question is whether we are able to make Assumption 1. Doing so requires restric-
tions on the model and equilibrium. The equilibrium quantities i∗t , yt∗ , π ∗t , are functions of shocks,
i∗t ({xdt , xπt , xit , ...}), “moving averages.” To be able to make assumption 1, we need a second as-
sumption:
    Assumption 2: The model and Fed’s choice of equilibrium (diﬀerent i∗ imply diﬀerent y ∗ , π ∗
for a given model) must be such that equilibrium quantities can be expressed in the “autoregres-
sive” representation (39), with φ in the zone of determinacy, and with the error xit orthogonal to
something we can use as instruments.
   Many models and many equilibria of a given model do not have this property. As an example,
consider the failure of Section 2. The equilibrium there is, in response-to-shock form,
                                             π ∗t = kxt
                                              i∗t = r + ρkxt
where k is a constant. We can express the interest rate equation as a relationship among endogenous
variables,
                                            i∗t = r + ρπ ∗t .

                                                      23
However, kρk < 1, so we cannot use this relationship among endogenous variables as a Taylor rule
for interest rate policy. This example violates the qualification “with φ in the zone of determinacy.”
If we try to express this equilibrium as a rule with larger φπ ,

                                      i∗t = r + φπ π ∗t + (ρ − φπ ) kxt

we obtain an “error term” — the xit in (39) — that is hopelessly correlated with the right hand
variables π ∗t , and all instruments, exactly the point of Section 2. This relationship violates the
qualification on the error term in Assumption 2.
    Even “φ in the zone of determinacy” is really too lose. For example, suppose the correlations
between variables in an equilibrium require φπ = 10. This equilibrium can be supported by φπ = 10,
but it also can be supported by a more sensible φπ = 1.5. We can assume they are the same,
identifying φπ = 10, but maybe we would not want to make the basic assumption in this case.
   The no-gap equilibrium is a particularly good example in the three-equation context, since
minimizing output gaps is a natural objective for monetary policy. To see this result most simply,
suppose all the shocks follow AR(1) processes xjt = ρj xjt−1 + εjt . Then, substituting yt∗ = ȳt in
(26)-(28), the no-gap equilibrium is
                                        1
                             π ∗t =          xπt                                                   (40)
                                     1 − βρπ
                                         1 − ρȳ          ρπ        1
                             i∗t   = r−          ȳt +         xπt + xdt .                         (41)
                                           σ           1 − βρπ      σ

I.e., if the Fed sets interest rates to this i∗t , equilibrium output can always equal potential output.
However, there is no way for the Fed to implement this policy and attain this equilibrium with a
rule that does not depend explicitly on shocks, and thus with an error term that is uncorrelated
with available instruments. We could try to substitute endogenous variables for shocks in (41) as
far as
                                              1 − ρȳ ∗              1
                                    i∗t = r −          yt + ρπ π ∗t + xdt ,
                                                   σ                 σ
                                                                       ¡    ¢
and implement i∗t as a Taylor rule with φπ = ρπ and φy = − 1 − ρȳ /σ. However, xdt remains
in the rule, and since it is not spanned by yt∗ and π ∗t , there is no way to remove it. xdt thus must
become part of the monetary policy disturbance. With no reason to rule out correlation between
the disturbances xdt and xπt , ȳt , nor any reason to limit serial correlation of xdt , we do not have
any instruments.
    But even this much is false progress. The coeﬃcient ρπ < 1 so these attempted values of φy
and φπ lie outside the zone of determinacy. To try implement i∗t as a Taylor rule with coeﬃcients
in the zone of determinacy, we have to strengthen the inflation response in an almost silly way,
                              µ         ¶              ½                    ¾
                      ∗         1 − ρȳ    ∗        ∗                ∗  1
                     it = r −             yt + φπ π t + (ρπ − φπ ) π t + xdt .                 (42)
                                  σ                                     σ

The term in brackets is the new monetary policy disturbance. The right hand variable is now
hopelessly correlated with the error term. (The web Appendix shows the same result directly and
more generally: assuming a Taylor rule without shocks, you can’t produce the no-gap equilibrium
with finite coeﬃcients.) Here, the attempt to equate the correlation between i∗t and π ∗t in the
no-gap equilibrium with the Fed’s response to alternative equilibria must fail.



                                                     24
Stochastic Intercept
    The term in brackets in (42) is often called a “stochastic intercept.” In order to attain the
no-gap equilibrium in this model, the central bank must follow a policy in which the interest rate
reacts directly to some of the structural shocks of the economy, as well as reacting to output
and inflation; the Taylor rule must have an intercept that varies over time as well as output and
inflation responses. Since it helps to produce equilibria with less output and inflation variability, or
other desirable properties, the stochastic intercept is a crucial part of New-Keynesian policy advice.
Woodford (2003) for example argues for “Wicksellian” policy in which the interest rate target varies
following the “natural” rate of interest, determined by real disturbances to the economy, and then
varies interest rates with inflation and output so as to produce local uniqueness. King’s (2000)
expression (34) oﬀers the clearest separation between “natural rate” and “determinacy” roles.
    Given this fact, it is a substantial restriction to omit the intercept from empirical work, and
from policy discussion surrounding empirical work. For example, Clarida, Galí and Gertler (2000)
and Woodford (2003, Ch. 4) calculate the variance of output and inflation using rules with no
intercepts, and discuss the merits of larger φ for reducing such variance. Yet all the time equilibria
with zero variance of output or inflation are sitting under our noses, as in the no-gap equilibrium,
if only we will allow the policy rule to depend on disturbances directly.
    The stochastic intercept of theory is often left out of empirical work because it becomes part
of the monetary policy disturbance in that context. It is inextricably correlated with the other
structural shocks of the model, and hence with the endogenous variables which depend on other
shocks of the model. Things were bad enough with genuine monetary policy disturbances — an
xit unrelated to other shocks of the model — because the new-Keynesian model predicts that right
hand variables should jump when there are shocks to the disturbance, as highlighted in Section
2. The stochastic intercept makes things even worse, because theory then predicts strong correla-
tion between the composite monetary policy disturbance and other shocks, and other endogenous
variables which depend on those shocks.
    When one assumes away the stochastic intercept — or, equivalently, assumes that the monetary
policy disturbance is uncorrelated with other variables — that assumption is really a restriction on
the set of equilibrium paths the economy is following, and it is an assumption on Fed policy that
it does not pick, by interest rate policy i∗t , any of those equilibria. Many equilibria are left out,
including the one with no gaps.
   This discussion reinforces two general principles: First, don’t take error term properties lightly.
As Sims (1980) emphasizes, linear models are composed of identical-looking equations, distinguished
only by exclusion restrictions and error-orthogonality properties. The IS curve

                               yt = Et yt+1 − σ (it − r − Et π t+1 ) + xdt ,

after all, can be rearranged to read
                                                   1                  1
                             it = r + Et π t+1 +     (Et yt+1 − yt ) + xdt .
                                                   σ                  σ
If we regress interest rates on output and inflation, how do we know that we are recovering the Fed’s
policy response, and not the parameters of the consumer’s IS function? Only the orthogonality of
the shocks (xdt ) with instruments distinguishes the two equations.
    Second, orthogonality is a property of the model and a property of the right hand variables not
really a property of the errors. You really have to write down a full model to understand why the

                                                    25
endogenous right hand variables or instruments would not respond to the shocks in the monetary
policy disturbance.
   With this background of possibilities and implicit assumptions, I can review the explicit as-
sumptions in classic estimates.


5.3     Clarida, Galí and Gertler

Clarida Galí and Gertler (2000) specify an empirical policy rule in partial adjustment form (in my
notation),
                     ©                                                        ª
  it = (1 − ρ1 − ρ2 ) r + (φπ − 1) [Et (π t+1 ) − π] + φy Et [∆yt+1 − ∆ȳt+1 ] + ρ1 it−1 + ρ2 it−2 (43)

where

                                    π =       inflation target, estimated
                    ∆yt+1 − ∆ȳt+1 =          growth in output gap
                                    r =       “long run equilibrium real rate”, estimated

(See their (4) p. 153 and Table II p. 157.) What are the important identification assumptions?
    First, there is no error term, no monetary policy disturbance at all. The central problem of
my simple example is that any monetary policy disturbance is correlated with right hand variables,
since the latter must jump endogenously when there is a monetary policy disturbance. Clarida,
Galí, and Gertler simply assume this problem away. They are also assume away the stochastic
intercept, the component of the monetary policy disturbance that reflects adaptation to other
shocks in the economy.
   A regression error term appears when Clarida, Galí, and Gertler replace expected inflation and
output with their ex-post realized values, writing
                           ©                                   ª
        it = (1 − ρ1 − ρ2 ) r + (φπ − 1) [π t+1 − π] + φy ∆yt+1 + ρ1 it−1 + ρ2 it−2 + εt+1 . (44)

In this way, Clarida, Galí, and Gertler avoid the 100% R2 prediction which normally results from
assuming away a regression disturbance. The remaining error εt+1 is a pure forecast error, so it is
serially uncorrelated. This fact allows Clarida, Galí and Gertler to use variables observed at time t
as instruments to remove correlation between the forecast error εt+1 and the ex-post values of the
right hand variables π t+1 and ∆yt+1 . Validity for this purpose does not mean such instruments
would be valid if we were to recognize a genuine monetary policy disturbance.
   Clarida, Galí and Gertler (1998) consider a slightly more general specification that does include
a monetary policy disturbance.1 In this case, they specify (their equation 2.5, my notation)
                                     £                                              ¤
                 it = ρit−1 + (1 − ρ) α + φπ E (π t,t+n |Ωt ) + φy E (yt − ȳt |Ωt ) + vt       (45)

where ȳ denotes potential output, separately measured, and Ωt is the central bank’s information
set at time t, which they assume does not include current output yt . vt is now the monetary policy
disturbance, defined as “an exogenous random shock to the interest rate.” They add, “Importantly,
we assume that vt is i.i.d.” They estimate (45) by instrumental variables, using lagged output,
inflation, interest rates, and commodity prices as instruments.
   1
    Curiously, Clarida Gali and Gertler (2000) mention the disturbance vt below their equation (3), p. 153, but it
does not appear in the equations or the following discussion. I presume the mention of vt is a typo in the 2000 paper.


                                                         26
    Obviously, the assumption of an i.i.d. disturbance is key, and restrictive. Many commentators
accuse the Fed of deviating from the Taylor rule for years at a time in the mid 2000s, for example.
This assumption means that any other shocks in the monetary policy disturbance — stochastic
intercepts, variation in the “natural rate,” — are also i.i.d. There is no reason preference shifts
(IS curve) or marginal cost shocks (Phillips curve shifts) should be i.i.d. But some other shock
must not be i.i.d., so that there is persistent variation in the right hand variables. Therefore ,
the monetary policy disturbance must not include a “stochastic intercept” that responds to the
non-i.i.d. shocks.


5.4   Giannoni, Rotemberg, Woodford

Rotemberg and Woodford (1997, 1998, 1999), followed by Giannoni and Woodford (2005) (see
also the summary in Woodford 2003, Ch. 5) follow a diﬀerent identification strategy, which allows
them to estimate the parameters of the Taylor rule by OLS rather than IV regressions. Giannoni
and Woodford (2005 p. 36-37) write the form of the Taylor rule in these papers:

          We assume that the recent U.S. monetary policy can be described by the following
      feedback rule for the Federal funds rate
                    n                         nw                  nw                         ny
                    X                         X                   X                          X
        it = ı̄ +         φik (it−k − ı̄) +         φwk ŵt−k +         φπk (π t−k − π̄) +         φyk Ŷt−k + εt   (46)
                    k=1                       k=0                 k=0                        k=0

      where it is the Federal funds rate in period t; π t denotes the rate of inflation between
      periods t − 1 and t; ŵt is the deviation of the log real wage from trend at date t, Ŷt
      is the deviation of log real GDP from trend, ı̄ and π̄ are long-run average values of
      the respective variables. The disturbances εt represent monetary policy “shocks” and
      are assumed to be serially uncorrelated. ...To identify the monetary policy shocks and
      estimate the coeﬃcients in [(46)], we assume ... that a monetary policy shock at date t
      has no eﬀect on inflation, output or the real wage in that period. It follows that [(46)]
      can be estimated by OLS...(p.36-37)

     Since they lay out so many of the assumptions that identify this policy rule with such clarity, we
can easily examine their plausibility. First, they assume that the monetary policy disturbance εt is
i.i.d. — uncorrelated with lags of itself and past values of the right hand variables. This is again a
strong assumption, given that εt is not a forecast error, but instead represents the natural rate or
stochastic intercept, responding to the “natural rate” or structural disturbances in the economy,
preferences of the Fed, and other endogenous variables that the Fed may respond to.
    Second, they assume that the disturbance εt is also not correlated with contemporaneous values
of ŵt , π t and Ŷt . This is an especially surprising result of a new-Keynesian model, because ŵt , π t
Ŷt are endogenous variables. From the very simplest model in this paper, endogenous variables
have jumped in the new-Keynesian equilibrium when there is a monetary policy (or any other)
disturbance. The whole point of new-Keynesian, forward-looking solutions is that endogenous
variables jump, so that disturbances do not lead to accelerating inflation. How can ŵt , π t and Ŷt not
jump when there is a shock εt ? To achieve this result, Giannoni, Rotemberg and Woodford assume
as part of their economic model that ŵt , π t Ŷt must be predetermined by at least one quarter, so
they cannot move when εt moves. (In the model as described in their Technical Appendix, output
Ŷ is actually fixed two quarters in advance, and the marginal utility of consumption μt is also

                                                              27
fixed one quarter in advance.) On the one hand, it is wonderful that Giannoni, Rotemberg and
Woodford explain the properties of the model which generate the needed correlation properties of
the instruments. But needless to say, these are strong assumptions. Are wages, prices, output and
marginal utility really fixed one to two quarters in advance in our economy, and therefore unable to
react within the quarter to monetary policy disturbances? They certainly aren’t forecastable one
to two quarters in advance!
    Most of all, if ŵt , π t Ŷt do not jump when there is a monetary policy disturbance, something
else must jump, to head oﬀ the explosive equilibria. What jumps in this model are expectations of
future values of these variables, among others ŵt+1 = Et ŵt+1 , π t+1 = Et π t+1 , and Ŷt+2 = Et Ŷt+2
as well as the state variable Et μt+1 , the marginal utility of consumption. All of these variables are
determined at date t. Now, we see another implicit assumption in the policy function (46) — none
of these future variables are present in the policy rule. Thus, Giannoni, Rotemberg, and Woodford
achieve identification by a classic exclusion restriction. In contrast to the literature that argues
for the empirical necessity and theoretical desirability of Taylor rules that react to expected future
output and inflation, and to other variables that the central bank can observe, those reactions are
assumed to be absent here.
    In sum, Giannoni and Woodford identify the Taylor rule in their model, by two assumptions
about Fed behavior: 1) The disturbance, including “natural rate” “stochastic intercept” reactions
to other shocks, is not predictable by any variables at time t − 1, and 2) The Fed does not react to
expected future output, or wage, price inflation, or other state variables. There is an assumption
about the economy: 3) Wages, prices, and output are fixed a period in advance.


6    Old-Keynesian models

Determinacy and identification are properties of specific models, not general properties of variables
and parameters. Old-Keynesian models reverse many of the determinacy and identification propo-
sitions. In these models, an inflation coeﬃcient greater than one is the key for stable dynamics, to
produce system eigenvalues less than one, and to solve the model backward. Since the model does
not have expected future terms, such a backward solution gives determinacy. The policy rules are
identified, at least up to the usual (Sims 1980) issues with simultaneous-equation macro models.
I think much of the determinacy and identification confusion stems from misunderstanding the
profound diﬀerences between new-Keynesian and old-Keynesian models. Alas, the old-Keynesian
models lack economic foundations, so can’t be a serious competitor for the basic question I started
with: What, fundamentally, determines the price level or inflation rate?
   Taylor (1999) gives us a nice explicit example of a “old-Keynesian” model (my terminology)
which forms a good basis for explicit discussion of these points. (As everywhere else, this is just
a good example, not a critique of a specific paper; thousands of papers adopt “old-Keynesian”
models.) Taylor adopts a “simple model” (p. 662, in my notation)
                                     yt = −σ(it − π t − r) + ut                                     (47)
                                     π t = π t−1 + γyt−1 + et                                       (48)
                                      it = r + φπ π t + φy yt .                                     (49)
We see a striking diﬀerence — all the forward-looking terms are absent.
    Taylor states (p. 663) that “it is crucial to have the interest rate response coeﬃcient on the
inflation rate ... above a critical ‘stability threshold’ of one,” (p. 664)

                                                   28
          The case on the left [φπ > 1] is the stable case...The case on the right [φπ < 1 ]
      is unstable... This relationship between the stability of inflation and the size of the
      interest rate coeﬃcient in the policy rule is a basic prediction of monetary models used
      for policy evaluation research. In fact, because many models are dynamically unstable
      when φπ is less than one... the simulations of the models usually assume that φπ is
      greater than one.

    This is exactly the opposite philosophy from the new-Keynesian models. In new-Keynesian
models, φπ > 1 is the condition for a “dynamically unstable” model. New-Keynesian models want
unstable dynamics, in order to rule out multiple equilibria and force forward-looking solutions. In
Taylor’s model, φπ > 1 is the condition for stable dynamics, eigenvalues less than one, in which we
solve for endogenous variables (including inflation) by backward-looking solutions. “φπ > 1” sounds
superficially similar, but in fact its operation is diametrically the opposite.
   A little more formally, and to parallel the analysis of the new-Keynesian model following (26)-
(28), the standard form of Taylor’s model is
              ∙    ¸ "       1−φπ      1−φπ
                                             #∙        ¸ "      1      1−φπ
                                                                             #∙    ¸
                yt       σγ 1+σφ    σ 1+σφ       yt−1         1+σφ  σ 1+σφ      ut
                     =           y         y             +        y        y         .        (50)
                πt           γ          1        π t−1          0       1       et

(Substitute (49) into (47).) The eigenvalues of this transition matrix are

                                                       1 − φπ
                                        λ1 = 1 + σγ           ; λ2 = 0.
                                                      1 + σφy

Therefore, φπ > 1 (with the natural restrictions φy > −1/σ, σγ > 0) generates values of the first
eigenvalue less than one. Following the usual decomposition, we can then write the unique solution
of the model as a backward -looking average of its shocks,
                 ∙        ¸                              ∙                ¸X
                                                                           ∞          ∙          ¸
                     yt                   1                   λ1 − 1 λ1                   ut−j
                              =                                                 λj1                  .
                     πt         1 + σφy + σγ (1 − φπ )       1 + σφy 0                    et−j
                                                                          j=0

There is no multiple-equilibrium or indeterminacy issue in this backward-looking solution.
    More intuitively, take φy = 0, and assume φπ > 1. Then if inflation π t rises in the policy rule
(49), the Fed ends up raising the real rate (as defined here without forward-looking terms) it −π t . In
the IS curve (47) this lowers output yt and lower output in the Phillips curve (48) lowers Et (π t+1 ).
This model thus embodies the classic concept of “stabilization” that more inflation makes the
Fed raise real interest rates which lowers demand and lowers future inflation. This is exactly the
opposite of the new-Keynesian dynamics. In the New-Keynesian model, a rise in inflation π t leads
to an explosion; “stabilization” by φπ > 1 means we count on π t to have jumped to the unique
value that heads oﬀ such explosions.
    Why do the two models disagree so much on the desired kind of dynamics? The equations
of Taylor’s model have no expected future terms. Hence, there are no expectational errors. All
the shocks (ut , et ) driving the system are exogenous economic disturbances. By contrast, the new-
Keynesian model has expected future values in its “structural” equations (26)-(28), so the shocks in
its standard representation such as (33) contain expectational errors. To avoid multiple equilibria,
we have to change Fed behavior to induce unstable dynamics, and then solve forward to remove
these expectational errors as shocks to the economy. The diﬀerence isn’t happenstance; the whole


                                                       29
point of the New-Keynesian enterprise is to microfound behavioral relationships, and microfounded
behavior is driven by expectations of the future, not memory of the past.
    Taylor regards this model as a “reduced form” in which expectations have been “solved out,”
so that parameters γ, σ, r may change if φ changes. He claims that nonetheless “these equations
summarize more complex forward-looking models” (p. 662). I do not think this is true. Taylor’s
model is fundamentally diﬀerent, not a simpler “reduced form,” or rough guide to give intuition
formalized by a more complex new-Keynesian eﬀort. The diﬀerence between this model and the
new-Keynesian model (26)-(28) is not about “policy invariance.” We want to analyze dynamics for
given policy parameters φπ , φy . Even if γ, σ and r change with diﬀerent φπ ,φy , they are constant
for a given φπ ,φy . Equations (47)-(49) are not a “simpler” or “reduced form” version of (26)-(28).
They are the same equations — with the same algebraic complexity — with diﬀerent t subscripts.
Diﬀerent t subscripts dramatically change dynamics, including stability and determinacy. The
operation of the models is completely diﬀerent. The response to shocks in an old-Keynesian model
represents the means by which structural equations are brought back to balance. The response to
shocks of a new-Keynesian model represents a jump to a diﬀerent equilibrium, a choice among many
diﬀerent possibilities, in each of which the structural equations are all in balance. King (2000) p.
72 also details a number of fundamental diﬀerences between “new” and “old” Keynesian models of
this sort.
    New-Keynesian models are often described with old-Keynesian intuition, or old-Keynesian intu-
ition is used to explain quantitative results from new-Keynesian models. This is a mistake. There
is a deep tension between how may economists write about inflation determination and how their
new-Keynesian models actually work.
    Identification in Taylor’s model does not suﬀer the central problem of identification in new-
Keynesian models. The behavior we are assessing is not how the Fed would respond to the emer-
gence of alternative equilibrium paths, it is completely revealed by the Fed’s behavior in equilibrium.
The parameters φπ , φy appear in the equilibrium dynamics (50) and hence the likelihood function.
That doesn’t mean identification is easy; it means we “only” have to face the standard issues in
simultaneous-equation models as reviewed by Sims (1980) and studied extensively by the VAR
literature since then.
    Since it easily delivers a unique equilibrium, and thus inflation determinacy, why not conclude
that Taylor’s model is the right one to use? Alas, our quest is for economic models of price
determinacy. This model fails on the crucial qualification — as Taylor’s (p. 662) discussion makes
very clear. If in fact inflation has nothing do to with expected future inflation, so inflation is
mechanistically caused by output gaps which are directly under the Fed’s control; if in fact the
output gap driving inflation has nothing to do with expected future output, then, yes, the Taylor
rule does lead to inflation determinacy. But despite a half-century of looking for them, economic
models do not deliver the “if” part of these statements. If we follow this model, we are giving
up on an economic understanding of price-level determination, in favor of (at best) a mechanistic
description.


7    Extensions and responses

The web Appendix contains an extensive critical review of the literature, responses to many
objections, and extensions left out of the text for reasons of space. If you want to know “What
about x’s approach to determinacy or identification?” you are likely to find an answer there.


                                                  30
    I investigate identification in the other equilibria of the simple model. For kφk < 1, φ is not
identified in any equilibrium. For kφk > 1, however, you can identify φ for every equilibrium except
the new-Keynesian local equilibrium. If explosions occur, you can measure their rate. I explore the
impulse response functions of the simple model, and contrast new-Keynesian and non-Ricardian
choices in terms of impulse-response functions. I generalize the simple mode to include an “IS”
shock in (1). In this case, we can’t even estimate ρ.
    I address the question, what happens if you run Taylor rule regressions in artificial data from
new-Keynesian models? This discussion generalizes the finding in section 2, in which regressions
recovered the shock autocorrelation process rather than the Taylor rule parameter, to the three-
equation model. Unsurprisingly, Taylor-rule regressions do not recover Taylor-rule parameters in
artificial data from typical models.
    One may ask, “well, if not a change in the Taylor rule, what did Clarida Galí and Gertler
measure?” The right answer is really “it doesn’t matter” — once a coeﬃcient loses its structural
interpretation, who cares how it comes out? At a minimum, the right answer is “you need a diﬀerent
model to interpret the coeﬃcient.” However, the web Appendix gives an example of how other
changes in behavior can show up as spurious Taylor rule changes. In the example, the Taylor rule
coeﬃcient is constant at φ = 1.1, but the Fed gets better at oﬀsetting IS shocks, i.e. following
better the “natural rate.” This change in policy causes mis-measured Taylor rule coeﬃcients to rise
as they do in the data.
    An obvious question is whether full likelihood approaches, involving dynamics of the entire
model, might be able to identify parameters where the single-equation methods I surveyed here
are faltering. Equivalently, perhaps the impulse response function to other shocks can identify the
Taylor-rule parameters (or, more generally, system eigenvalues). I survey these issues in the web
Appendix. While identification in full systems has been studied and criticized, nobody has tried to
use full-system methods to test for determinacy. This literature imposes determinacy and explores
model specification to better fit second moments. This is not a criticism; “fitting the data” rather
than “testing the model” is a worthy goal. But it means I have no useful results to report or
literature to review on whether this approach can overcome identification problems in order to test
for determinacy.
   I explore leads and lags in Taylor rules in the context of the simple frictionless model, continuous
time models, and the three-equation model. It turns out that determinacy questions depend quite
sensitively on the timing assumptions in the Taylor rule. The problem is particularly evident on
taking the continuous-time limit. Given that changing a time index, e.g. Et π t+1 in place of π t−1 ,
can reverse stability properties, this finding is not surprising, but it does counter the impression
that stability is “robust” to changes in specification.
   A separate web Technical Appendix collects documentation and calculation details. I explain
budget constraints from Section 3.1 in more depth. I also collect analytic solutions to the standard
three-equation model.


8    Conclusions and implications

Determinacy
    Practically all verbal explanations for the wisdom of the Taylor principle — the Fed should in-
crease interest rates more than one-for-one with inflation — use old-Keynesian, stabilizing, logic:


                                                  31
This action will raise real interest rates, which will dampen demand, which will lower future infla-
tion. New-Keynesian models operate in an entirely diﬀerent manner: by raising interest rates in
response to inflation, the Fed induces accelerating inflation or deflation, or at a minimum a large
“non-local” movement, unless inflation jumps to one particular value.
    Alas, there is no economic reason why the economy should pick this unique initial value, as
inflation and deflation are valid economic equilibria. No supply/demand force acts to move infla-
tion to this value. The attempts to rule out multiple equilibria basically state that the government
will blow up the economy should accelerating inflation or deflation occur. This is not a reasonable
characterization of anyone’s expectations. Such policies also violate the usual criterion that the
government must operate in markets just like agents. I conclude that inflation is just as indeter-
minate, in microfounded new-Keynesian models, when the central bank follows a Taylor rule with
a Ricardian fiscal regime, as it is under fixed interest rate targets.
   The literature — understandably, I think — confused “stopping an inflation” with “ruling out an
equilibrium path.” Alas, now that confusion is lifted, we can see the latter goal is not achieved.

Identification
    The central empirical success of New Keynesian models are estimates such as Clarida, Galí and
Gertler’s (2000) that say inflation was stabilized in the U.S. by a switch from an “indeterminate” to
a “determinate” regime. My main point is that the crucial Taylor-rule parameter is not identified
in the new-Keynesian model, so we cannot interpret regressions in this way. The new-Keynesian
model has nothing to say about inflation in an indeterminate regime, so Taylor-rule regressions in
the 1970s are doubly uninterpretable in the new-Keynesian context.
   Clarida, Galí, and Gertler’s coeﬃcients range from 2.15 (Table IV) to as much as 3.13 (Table
V). These coeﬃcients are not only greater than one, they are a lot greater than one. These
coeﬃcients imply that if the US returned to the 12% inflation of the late 1970s, (a 10 percentage
point rise), the Federal Reserve would raise the funds rate by 21.5 to 31.3 percentage points. If
these predictions seem implausibly large, digesting the estimates as something less than structural
helps a great deal.
    The identification issue stems from the heart of all new-Keynesian models. The models have
multiple equilibria. The modelers specify policy rules which lead to explosive dynamics, and
then pick only the locally-bounded equilibrium. But locally-bounded equilibrium variables are
stationary, so cannot reveal the strength of the explosions, which only occur in the equilibria we
do not observe. In the model, endogenous variables jump in response to disturbances, to head oﬀ
explosions. Such jumps induce correlation between right hand variables of the policy rule and its
error, so that rule will be exquisitely hard to estimate. One can only begin to get around these
central problems by strong assumptions, in particular that the central bank does not respond to
many variables, and to “natural rate” shocks in particular, in ways that would help it to stabilize
the economy.
   The literature — understandably, I think — did not appreciate that “determinacy” and “desir-
able rate in equilibrium” are separate issues; that new-Keynesian models, unlike their old-Keynesian
counterparts, achieve “determinacy” by responses to alternative equilibria, which are not measur-
able, not by responses to equilibrium variation in inflation, which are; and that “achieving deter-
minacy” is a diﬀerent reading of history than “raising rates to lower inflation.” Again, however,
now that the distinction is clear we need not persist in mis-interpreting the regressions.



                                                 32
If not this, then what?
    The contribution of this paper is negative, establishing that one popular theory does not, in
the end, determine the price level or the inflation rate. So what theory can determine the price
level, in an economy like ours? Commodity standards and MV=PY can work in theory, but do
not apply to our economy, with fiat money, interest-elastic money demand and no attempt by the
central bank to target quantities.
    The price level can be determined for economies like ours in models that adopt — or, perhaps,
recognize — that governments follow a fiscal regime that is at least partially non-Ricardian. Such
models solve all the determinacy and uniqueness problems in one fell swoop. And the change is
not really so radical. Though the deep question of where the price level comes from changes, the
vast majority of the new-Keynesian ingredients can be maintained. Whether the results are the
same, and whether such models can account for the data is an open question.
    “Economic” is an important qualifier. Most of the case for Taylor rules in popular and central
bank writing, FOMC statements, and too often in academic contexts, emphasizes the old-Keynesian
stabilizing story. This is a pleasant and intuitively pleasing story to many. However, it throws out
the edifice of theoretical coherence — explicit underpinnings of optimizing agents, clearing markets
etc. — that is the hallmark achievement of the new-Keynesian eﬀort. If inflation is, in fact,
stabilized in modern economies by interest rate targets interacted with backward -looking IS and
Phillips curves, economists really have no idea why this is so.




                                                33
9   References
Alstadheim, Ragna, and Dale W. Henderson, 2006, “Price-Level Determinacy, Lower Bounds on
    the Nominal Interest Rate, and Liquidity Traps,” The B.E. Journal of Macroeconomics 6:1
    (Contributions), Article 12.
    http://www.bepress.com/bejm/contributions/vol6/iss1/art12

Atkeson, Andrew, Chari, V.V. and Patrick J. Kehoe, 2009, “Sophisticated Monetary Policies,”
    Federal Reserve Bank of Minneapolis Research Department Staﬀ Report 419.

Bassetto, Marco, 2004, “Negative Nominal Interest Rates,” American Economic Review 94 (2),
    104-108.

Benhabib, Jess, Stephanie Schmitt-Grohé, and Martín Uribe, 2002, “Avoiding Liquidity Traps,”
    Journal of Political Economy 110, 535-563

Canzoneri, Matthew, Robert Cumby and Behzad Diba, 2001, “Is the Price Level Determined by
    the Needs of Fiscal Solvency,” American Economic Review 91, 1221 - 1238.

Clarida, Richard, Jordi Galí, and Mark Gertler, 1998, “Monetary Policy Rules in Practice: Some
    International Evidence,”European Economic Review, 42,1033-1067.

Clarida, Richard, Jordi Galí, and Mark Gertler, 2000, “Monetary Policy Rules and Macroeconomic
    Stability: Evidence and Some Theory,” Quarterly Journal of Economics, 115, 147-180.

Cochrane, John H., 1998, “A Frictionless model of U.S. Inflation,” in Ben S. Bernanke and Julio
    J. Rotemberg, Eds., NBER Macroeconomics Annual 1998 Cambridge MA: MIT press, p.
    323-384.

Cochrane, John H., 2005, “Money as Stock,” Journal of Monetary Economics 52, 501-528.

Giannoni, Marc P., and Michael Woodford, 2005, “Optimal Inflation Targeting Rules,” in Bernanke,
    Benjamin S. and Michael Woodford Eds., Inflation Targeting, Chicago: University of Chicago
    Press, 2005.
    (pdf available at http://www.columbia.edu/~mw2230/; Technical Appendix at
    http://www2.gsb.columbia.edu/faculty/mgiannoni/prog/nberit_programs/model_nberit.pdf.)

King, Robert G., 2000 “The New IS-LM Model: Language, Logic, and Limits,” Federal Reserve
    Bank of Richmond Economic Quarterly 86, 45-103.

Klein, Paul, 2000, “Using the Generalized Schur Form to Solve a Multivariate Linear Rational
    Expectations Model,” Journal of Economic Dynamics and Control 24, 1405-1423.

Leeper, Eric , 1991, “Equilibria Under ‘Active’ and ‘Passive’ Monetary and Fiscal Policies, Journal
    of Monetary Economics 27, 129-147.

Obstfeld, Maurice and Kenneth Rogoﬀ, 1983, “Speculative Hyperinflations in Maximizing Models:
    Can we Rule them Out?,” Journal of Political Economy 91, 675-687.

Obstfeld, Maurice and Kenneth Rogoﬀ, 1986,“Ruling out Divergent Speculative Bubbles,” Journal
    of Monetary Economics 17, 349-362.



                                               34
Rotemberg, Julio and Michael Woodford, 1997, “An Optimization-Based Econometric Model for
    the Evaluation of Monetary Policy,” NBER Macroeconomics Annual 12, 297-346

Rotemberg, Julio and Michael Woodford, 1998, “An Optimization-Based Econometric Model for
    the Evaluation of Monetary Policy,” NBER Technical Working Paper no. 233.

Rotemberg, Julio and Michael Woodford, 1999, “Interest-Rate Rules in an Estimated Sticky-Price
    Model,” in Taylor, John B., Ed., Monetary Policy Rules, Chicago: University of Chicago Press.

Sargent, Thomas J., and Neil Wallace, 1975, “‘Rational’ Expectations, the Optimal Monetary
    Instrument, and the Optimal Money Supply Rule,” Journal of Political Economy 83, 241-
    254.

Schmitt-Grohé, Stephanie and Martín Uribe, 2000, “Price Level Determinacy and Monetary Policy
    Under a Balanced Budget Requirement,” Journal of Monetary Economics 45, 211-246.

Sims, Christopher A., 1980, “Macroeconomics and Reality,” Econometrica 48, 1-48.

Sims, Christopher A., 1994, “A Simple Model for Study of the Determination of the Price Level
    and the Interaction of Monetary and Fiscal Policy,” Economic Theory 4, 381-99.

Taylor, John B. 1999, “The Robustness and Eﬃciency of Monetary Policy Rules as Guidelines for
    Interest Rate Setting by the European Central Bank,” Journal of Monetary Economics 43,
    655-679.

Woodford, Michael, 1994, “Monetary Policy and Price Level Determinacy in a Cash-in-Advance
   Economy,” Economic Theory 4, 345-380.

Woodford, Michael, 1995, “Price Level Determinacy Without Control of a Monetary Aggregate,”
   Carnegie Rochester Conference Series on Public Policy, 43, 1-46.

Woodford, Michael, 2001, “Monetary Policy in the Information Economy,” in Economic Policy
   for the Information Economy, Kansas City: Federal Reserve Bank of Kansas City.

Woodford, Michael, 2003, Interest and Prices, Princeton: Princeton University Press.




                                              35
