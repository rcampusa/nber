                                 NBER WORKING PAPER SERIES




   IDENTIFICATION AND ESTIMATION OF GAUSSIAN AFFINE TERM STRUCTURE
                               MODELS

                                          James D. Hamilton
                                           Jing Cynthia Wu

                                         Working Paper 17772
                                 http://www.nber.org/papers/w17772


                       NATIONAL BUREAU OF ECONOMIC RESEARCH
                                1050 Massachusetts Avenue
                                  Cambridge, MA 02138
                                      January 2012




We are grateful to Michael Bauer, Bryan Brown, Frank Diebold, Ron Gallant, Ken Singleton, anonymous
referees, and seminar participants at the University of Chicago, UCSD, Federal Reserve Board, Pennsylvania
State University, Society for Financial Econometrics, Midwest Macroeconomics Conference, Rice
University, University of Colorado, and the Federal Reserve Bank of San Francisco for comments
on earlier drafts of this paper. The views expressed herein are those of the authors and do not necessarily
reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2012 by James D. Hamilton and Jing Cynthia Wu. All rights reserved. Short sections of text, not
to exceed two paragraphs, may be quoted without explicit permission provided that full credit, including
© notice, is given to the source.
Identification and Estimation of Gaussian Affine Term Structure Models
James D. Hamilton and Jing Cynthia Wu
NBER Working Paper No. 17772
January 2012
JEL No. C13,E43,G12

                                           ABSTRACT

This paper develops new results for identification and estimation of Gaussian affine term structure
models. We establish that three popular canonical representations are unidentified, and demonstrate
how unidentified regions can complicate numerical optimization. A separate contribution of the paper
is the proposal of minimum-chi-square estimation as an alternative to MLE. We show that, although
it is asymptotically equivalent to MLE, it can be much easier to compute. In some cases, MCSE allows
researchers to recognize with certainty whether a given estimate represents a global maximum of the
likelihood function and makes feasible the computation of small-sample standard errors.


James D. Hamilton
Department of Economics, 0508
University of California, San Diego
9500 Gilman Drive
La Jolla, CA 92093-0508
and NBER
jhamilton@ucsd.edu

Jing Cynthia Wu
Booth School of Business
University of Chicago
5807 S Woodlawn Ave
Chicago, IL 60637-1610
Cynthia.Wu@chicagobooth.edu
1         Introduction.

The class of Gaussian affine term structure models1 developed by Vasicek (1977), Duffie and

Kan (1996), Dai and Singleton (2002), and Duffee (2002) has become the basic workhorse in

macroeconomics and finance for purposes of using a no-arbitrage framework for studying the

relations between yields on assets of different maturities. Its appeal comes from its simple

characterization of how risk gets priced by the market which, under the assumption of no

arbitrage, generates predictions for the price of any asset. The approach has been used to

measure the role of risk premia in interest rates (Duffee, 2002; Cochrane and Piazzesi, 2009),

study how macroeconomic developments and monetary policy affect the term structure of

interest rates (Ang and Piazzesi, 2003; Beechey and Wright, 2009; Bauer, 2011), characterize

the monetary policy rule (Ang, Dong, and Piazzesi, 2007; Rudebusch and Wu, 2008; Bekaert,

Cho, and Moreno, 2010), determine why long-term yields remained remarkably low in 2004

and 2005 (Kim and Wright, 2005; Rudebusch, Swanson, and Wu, 2006), infer market expec-

tations of inflation from the spread between nominal and inflation-indexed Treasury yields

(Christensen, Lopez, and Rudebusch, 2010), evaluate the effectiveness of the extraordinary

central bank interventions during the financial crisis (Christensen, Lopez, and Rudebusch,

2009; Smith, 2010), and study the potential for monetary policy to affect interest rates when

the short rate is at the zero lower bound Hamilton and Wu (forthcominga).

        But buried in the footnotes of this literature and in the practical experience of those

who have used these models are tremendous numerical challenges in estimating the necessary
    1
    By Gaussian affine term structure models we refer to specifications in which the discrete-time joint dis-
tribution of yields and factors is multivariate Normal with constant conditional variances. We do not in this
paper consider the broader class of non-Gaussian processes.



                                                     1
parameters from the data due to highly non-linear and badly behaved likelihood surfaces. For

example, Kim (2008) observed:


            Flexibly specified no-arbitrage models tend to entail much estimation difficulty

         due to a large number of parameters to be estimated and due to the nonlinear

         relationship between the parameters and yields that necessitates a nonlinear opti-

         mization.


       Ang and Piazzesi (2003) similarly reported:


            difficulties associated with estimating a model with many factors using maxi-

         mum likelihood when yields are highly persistent....We need to find good starting

         values to achieve convergence in this highly non-linear system....[T]he likelihood

         surface is very flat in λ0 which determines the mean of long yields....


       This paper proposes a solution to these and other problems with affine term structure

models based on what we will refer to as their reduced-form representation. For a popular

class of Gaussian affine term structure models– namely, those for which the model is claimed

to price exactly a subset of N` linear combinations of observed yields, where N` is the number

of unobserved pricing factors– this reduced form is a restricted vector autoregression in the

observed set of yields and macroeconomic variables.2 We explore two implications of this fact

that seem to have been ignored in the large preceding literature on such models.

       The first is that the parameters of these reduced-form representations contain all the

observable implications of any Gaussian affine term structure model for the sample of observed
   2
      For more general models where all yields are priced with measurement error, the reduced form is a
restricted state-space representation for the set of observed variables. The same tools developed here could
still be applied in that setting, though we leave exploration of such models for future research.


                                                     2
data, and can therefore be used as a basis for assessing identification.         If more than one

value for the parameter vector of interest is associated with the same reduced-form parameter

vector, then the model is unidentified at that point and there is no way to use the observed

data to distinguish between the alternative possibilities. Although as a general econometric

principle this idea dates back to Fisher (1966) and Rothenberg (1971), it has not previously

been applied to affine term structure models. In this paper, we use it to demonstrate that

the preferred representations proposed by Ang and Piazzesi (2003) and Pericoli and Taboga

(2008) are in fact unidentified, an observation that our paper is the first to point out. We

also use this approach to show that the representation proposed by Dai and Singleton (2000)

is unidentified.   Although this latter fact has previously been inferred by Collin-Dufresne,

Goldstein, and Jones (2008) and Aı̈t-Sahalia and Kimmel (2010) using other methods, we

regard the proof here based on the reduced form to be more transparent and direct.              We

further demonstrate that it is common for numerical search methods to end up in regions of

the parameter space that are locally unidentified, and show why this failure of identification

arises. These issues of identification are one factor that contributes to the numerical difficulties

for conventional methods noted above.

   A second and completely separate contribution of the paper is the observation that it is

possible for the parameters of interest to be inferred directly from estimates of the reduced-

form parameters themselves. This is a very useful result because the latter are often simple

OLS coefficients. Although translating from reduced-form parameters into structural param-

eters involves a mix of analytical and numerical calculations, the numerical component is far

simpler than that associated with the usual approach of trying to find the maximum of the


                                                 3
likelihood surface directly as a function of the structural parameters. In the case of a just-

identified structure, the numerical component of our proposed method has an additional big

advantage over the traditional approach, in that the researcher knows with certainty whether

the equations have been solved, and therefore knows with certainty whether one has found the

global maximum of the likelihood surface with respect to the structural parameters or simply

a local maximum.     In the conventional approach, one instead has to search over hundreds

of different starting values, and even then has no guarantee that the global maximum has

been found. In the case where the model imposes overidentifying restrictions on the reduced

form, one can still estimate structural parameters as functions of the unrestricted reduced-

form estimates by the method of minimum-chi-square estimation (MCSE). This minimizes

a quadratic form in the difference between the reduced-form parameters implied by a given

structural model and the reduced-form parameters as estimated without restrictions directly

from the data, with the weighting matrix given by the information matrix, in other words,

minimizing the value of the chi-square statistic for testing whether the restrictions are indeed

consistent with the observed reduced-form estimates.

   Again while the general econometric method of minimum-chi-square estimation is well

known, our paper is the first to apply it to affine term structure models and demonstrate its

considerable advantages in this setting. Estimating parameters by minimizing the chi-square

statistic was to our knowledge first proposed by Fisher (1924) and Neyman and Pearson (1928).

Rothenberg (1973, pp. 24-25) extended the approach to more general parametric inference,

demonstrating that when (as in our proposed application) the reduced-form estimate is the

unrestricted MLE and the weighting matrix is the associated information matrix, the resulting


                                               4
MCSE is asymptotically equivalent to full-information MLE. MCSE has also been used in

other settings by Chamberlain (1982) and Newey (1987).

      More generally, MCSE could be viewed as a special case of minimum distance estimation

(MDE) discussed for example by Malinvaud (1970), in which one minimizes a quadratic form

in the difference between restricted and unrestricted statistics. We follow Rothenberg (1973)

in using the expression MCSE to refer to the special case of MDE in which the unrestricted

statistics are the unrestricted MLE and weights come from their asymptotic variance, in which

case MDE is asymptotically efficient. Another well-known example of MDE is the generalized

method of moments (GMM, Hansen (1982)), in which the unrestricted statistics are sample

moments.3 Bekaert, Cho, and Moreno (2010) used GMM to estimate parameters of an affine

term structure model. GMM in this form misses what we see as the two main advantages

of MCSE, namely, the OLS estimates are known analytically and MCSE, unlike GMM, is

asymptotically efficient.

      Another popular example of MDE is the method of indirect inference proposed by Gallant

and Tauchen (1992), Smith (1993) and Gourieroux, Monfort, and Renault (1993). With indi-

rect inference, the unrestricted parameter estimates are typically regarded as only approximate

or auxiliary characterizations of the data, and numerical simulation is typically required to

calculate the values for these auxiliary parameters that are implied by the structural model.

Duffee and Stanton (2008) suggested that for highly persistent data such as interest rates,

indirect inference or MLE may work substantially better than other moment-based estima-
  3
    In our application of MCSE, the unrestricted estimates (OLS coefficients and variances) are nonlinear
functions of sample moments. This connection between MCSE and GMM is explored further in Chamberlain
(1982, p. 18).




                                                   5
tors. One could view our application of MCSE as a special case of indirect inference in which

the unrestricted estimates are in fact sufficient statistics for the likelihood function and the

mapping from structural parameters to these coefficients is known analytically, precisely the

features from which our claimed benefits of MCSE derive.

   In particular, we demonstrate in this paper that use of MCSE captures all the asymptotic

benefits of MLE while avoiding many of the numerical problems associated with MLE for

affine term structure models. Among other illustrations of the computational advantages, we

establish the feasibility of calculating small-sample standard errors and confidence intervals

for this class of models and demonstrate that the parameter estimates reported by Ang and

Piazzesi (2003) in fact correspond to a local maximum of the likelihood surface and are not

the global MLE.

   There have been several other recent efforts to address many of these problems in affine

term structure models. Christensen, Diebold, and Rudebusch (2011) developed a no-arbitrage

representation of a dynamic Nelson-Siegel model of interest rates that gives a convenient repre-

sentation of level, slope and curvature factors and offers significant improvements in empirical

tractability and predictive performance over earlier affine term structure specifications. Joslin,

Singleton, and Zhu (2011) proposed a canonical representation for affine term structure mod-

els that greatly improves convergence of maximum likelihood estimation.         Collin-Dufresne,

Goldstein, and Jones (2008) proposed a representation in terms of the derivatives of the term

structure at maturity zero, arguing for the benefits of using these observable magnitudes rather

than unobserved latent variables to represent the state vector of an ATSM. Each of these

papers proposes canonical representations that are identified, and the Christensen, Diebold,


                                                6
and Rudebusch (2011) and Joslin, Singleton, and Zhu (2011) parameterizations lead to better

behaved likelihood functions than do the parameterizations explored in detail in our paper.

   The chief difference between our proposed solution and those of these other researchers

is that they focus on how the ATSM should be represented, whereas we examine how the

parameters of the ATSM are to be estimated. Thus for example Christensen, Diebold, and

Rudebusch (2011) require the researcher to impose certain restrictions on the ATSM, whereas

Joslin, Singleton, and Zhu (2011) cannot incorporate most auxiliary restrictions on the P dy-

namics. It is far from clear how any of these three approaches could have been used to estimate

a model of the form investigated by Ang and Piazzesi (2003). By contrast, our MCSE algo-

rithm can be used for any representation, including those proposed by Christensen, Diebold,

and Rudebusch (2011) and Joslin, Singleton, and Zhu (2011), and can simplify the numerical

burden regardless of the representation chosen. Indeed, some of the numerical advantages of

Joslin, Singleton, and Zhu (2011) come from the fact that a subset of their parameterization

is identical to a subset of our reduced-form representation, and their approach, like ours, takes

advantage of the fact that the full-information MLE for this subset can be obtained by OLS

for a popular class of models.    However, Joslin, Singleton, and Zhu (2011) estimated the

remaining parameters by conventional MLE rather than using the full set of reduced-form

estimates as in our approach. As Joslin, Singleton, and Zhu (2011) noted, their representa-

tion becomes unidentified in the presence of a unit root. When applied to highly persistent

data, we illustrate that their MLE algorithm can encounter similar problems to those of other

representations, which can be avoided with our approach to parameter estimation.

   The rest of the paper is organized as follows. Section 2 describes the class of Gaussian affine


                                                7
term structure models and three popular examples, and briefly uses one of the specifications

to illustrate the numerical difficulties that can be encountered with the traditional approach.

Section 3 investigates the mapping from structural to reduced-form parameters. We establish

that the canonical forms of all three examples are unidentified and explore how this contributes

to some of the problems for conventional numerical search algorithms. In Section 4 we use

the mapping to propose approaches to parameter estimation that are much better behaved.

Section 5 concludes.




2     Gaussian Affine Term Structure Models.

2.1    Basic framework

Consider an (M × 1) vector of variables Ft whose dynamics are characterized by a Gaussian

vector autoregression:

                                      Ft+1 = c + ρFt + Σut+1                                      (1)


with ut ∼ i.i.d. N (0, IM ). This specification implies that Ft+1 |Ft , Ft−1 , ..., F1 ∼ N (µt , ΣΣ0 )

for

                                           µt = c + ρFt .                                         (2)


Let rt denote the risk-free one-period interest rate. If the vector Ft includes all the variables

that could matter to investors, then the price of a pure discount asset at date t should be a

function Pt (Ft ) of the current state vector. Moreover, if investors were risk neutral, the price




                                                  8
they’d be willing to pay would satisfy



                  Pt (Ft ) = exp(−rt )Et [Pt+1 (Ft+1 )]
                                       Z
                           = exp(−rt )     Pt+1 (Ft+1 )φ(Ft+1 ; µt , ΣΣ0 ) dFt+1         (3)
                                             RM




for φ(y; µ, Ω) the M -dimensional N (µ, Ω) density evaluated at the point y:


                                                           (y − µ)0 Ω−1 (y − µ)
                                                                               
                                         1
                   φ(y; µ, Ω) =                      exp −                        .      (4)
                                  (2π)M/2 |Ω|1/2                     2


   More generally, with risk-averse investors we would replace (3) with



                   Pt (Ft ) = Et [Pt+1 (Ft+1 )Mt,t+1 ]
                              Z
                            =      Pt+1 (Ft+1 ) [Mt,t+1 φ(Ft+1 ; µt , ΣΣ0 )] dFt+1       (5)
                                  RM




for Mt,t+1 the pricing kernel. In many macro models, the pricing kernel would be


                                                       βU 0 (Ct+1 )
                                     Mt,t+1 =
                                                  U 0 (Ct )(1 + π t+1 )


for β the personal discount rate, U 0 (C) the marginal utility of consumption, and π t+1 the

inflation rate between t and t + 1.

   Affine term structure models are derived from the particular kernel


                                          h            0       0
                                                                      i
                            Mt,t+1   = exp −rt − (1/2)λt λt − λt ut+1                    (6)



                                                     9
for λt an (M × 1) vector that characterizes investor attitudes toward risk, with λt = 0 in the

case of risk neutrality. Elementary multiplication of (4) by (6) reveals that for this case



                        Mt,t+1 φ(Ft+1 ; µt , ΣΣ0 ) = exp(−rt )φ(Ft+1 ; µQ     0
                                                                        t , ΣΣ )               (7)



for

                                           µQ
                                            t = µt − Σλt .                                     (8)


Substituting (7) into (5) and comparing with (3), we see that for this specification of the

pricing kernel, risk-averse investors value any asset the same as risk-neutral investors would if

the latter thought that the conditional mean of Ft+1 was µQ
                                                          t rather than µt . A positive value


for the first element of λt , for example, implies that an asset that delivers the quantity F1,t+1

dollars in period t + 1 would have a value at time t that is less than the value that would

be assigned by a risk-neutral investor, and the size of this difference is bigger when the (1, 1)

element of Σ is bigger.      An asset yielding Fi,t+1 dollars has a market value that is reduced

by Σi1 λ1t relative to a risk-neutral valuation, through the covariance between factors i and 1.

The term λ1t might then be described as the market price of factor 1 risk.

      The affine term structure models further postulate that this market price of risk is itself

an affine function of Ft ,

                                            λt = λ + ΛFt                                       (9)


for λ an (M × 1) vector and Λ an (M × M ) matrix. Substituting (9) and (2) into (8), we see




                                                  10
that

                                          µQ    Q   Q
                                           t = c + ρ Ft



for

                                            cQ = c − Σλ                                     (10)


                                           ρQ = ρ − ΣΛ.                                     (11)


In other words, risk-averse investors value assets the same way as a risk-neutral investor would

if that risk-neutral investor believed that the factors are characterized by a Q-measure VAR

given by

                                     Ft+1 = cQ + ρQ Ft + ΣuQ
                                                           t+1                              (12)


with uQ
      t+1 a vector of independent standard Normal variables under the Q measure.


      Suppose that the risk-free 1-period yield is also an affine function of the factors


                                                         0
                                           rt = δ 0 + δ 1 Ft .                              (13)



Then, as demonstrated for example in Appendix A of Ang and Piazzesi (2003), under the

above assumptions the yield on a risk-free n-period pure-discount bond can be calculated as



                                           ytn = an + b0n Ft                                (14)




                                                  11
where


                        1h       Q0
                                                i
                                             Q0 n−1
                 bn   =    IM + ρ + · · · + ρ       δ1                                                   (15)
                        n
                an = δ 0 + b01 + 2b02 + · · · + (n − 1) b0n−1 cQ /n
                                                             
                                                                                                         (16)

                         − b01 ΣΣ0 b1 + 22 b02 ΣΣ0 b2 + · · · + (n − 1)2 b0n−1 ΣΣ0 bn−1 /2n.
                                                                                       




If we knew Ft and the values of cQ and ρQ along with δ 0 , δ 1 , and Σ, we could use (14), (15),

and (16) to predict the yield for any maturity n.

       There are thus three sets of parameters that go into an affine term structure model: (a)

the parameters c, ρ, and Σ that characterize the objective dynamics of the factors in equation

(1) (sometimes called the P parameters); (b) the parameters λ and Λ in equation (9) that

characterize the price of risk; and (c) the Q parameters cQ and ρQ (along with the same Σ

as appeared in the P parameter set) that figure in (12). If we knew any two of these sets of

parameters, we could calculate the third4 using (10) and (11). We will refer to a representation

in terms of (a) and (b) as a λ representation, and a representation in terms of (a) and (c) as

a Q representation.

       Suppose we want to describe yields on a set of Nd different maturities. If Nd is greater

than N` , where N` is the number of unobserved pricing factors, then (14) would imply that

it should be possible to predict the value of one of the ynt as an exact linear function of

the others.     Although in practice we can predict one yield extremely accurately given the

others, the empirical fit is never exact. One common approach to estimation, employed for
   4
    We will discuss examples below in which Σ is singular for which the demonstration of this equivalence is
a bit more involved, with the truth of the assertion coming from the fact that for such cases certain elements
of λ and Λ are defined to be zero.


                                                     12
example by Ang and Piazzesi (2003) and Chen and Scott (1993), is to suppose that (14) holds

exactly for N` linear combinations of observed yields, and that the remaining Ne = Nd − N`

linear combinations differ from the predicted value by a small measurement error.                     Let Yt1

denote the (N` × 1) vector consisting of those linear combinations of yields that are treated as

priced without error and Yt2 the remaining (Ne × 1) linear combinations. The measurement

specification is then

                                                                                   
                     Yt1             A1              B1                   0        
                    (N` ×1)           (N` ×1)           (N` ×M )              (N` ×Ne )    e
                              =               +                 Ft +                 ut          (17)
                                                                    
                
                                                                                           (Ne ×1)
                      Yt2
                                                                    
                                        A2                B2                    Σe
                    (Ne ×1)           (Ne ×1)           (Ne ×M )              (Ne ×Ne )



where Σe is typically taken to be diagonal. Here Ai and Bi are calculated by stacking (16) and

(15), respectively, for the appropriate n, while Σe determines the variance of the measurement

error with uet ∼ N (0, INe ). We will discuss many of the issues associated with identification

and estimation of affine term structure models in terms of three examples.



2.2    Example 1: Latent factor model.

In this specification, the factors Ft governing yields are treated as if observable only through

their implications for the yields themselves; examples in the continuous-time literature include

Dai and Singleton (2000), Duffee (2002), and Kim and Orphanides (2005). Typically in this

case, the number of factors N` and the number of yields observed without error are both taken

to be 3, with the 3 factors interpreted as the level, slope, and curvature of the term structure.

The 3 linear combinations Yt1 regarded as observed without error can be constructed from



                                                        13
the first 3 principal components of the set of yields. Alternatively, they could be constructed

directly from logical measures of level, slope, and curvature.     Yet another option is simply

to choose 3 representative yields as the elements of Yt1 .       Which linear combinations are

claimed to be priced without error can make a difference for certain testable implications of

the model, an issue that we explore in a separate paper (Hamilton and Wu, forthcomingb)

which addresses empirical testing of the overidentifying restrictions of affine term structure

models. For purposes of discussing identification and estimation, however, the choice of which

yields go into Yt1 is immaterial, and notation is kept simplest by following Ang and Piazzesi

(2003) and Pericoli and Taboga (2008) in just using 3 representative yields. In our numerical

example, these are taken to be the n = 1-, 12-, and 60-month maturities, with data on 36-

month yields included separately in Yt2 . Thus for this illustrative latent-factor specification,

equation (17) takes the form

                                                             
                            1                  0
                         yt       a1   b1               0 
                                                           
                                                           
                         y 12     a   b0                0 
                         t        12   12                   e
                                =     +           Ft +      ut                      (18)
                                                           
                         y 60     a   b0                0 
                         t        60   60                  
                                                           
                                                           
                          yt36       a36     b036              Σe


where an and bn are calculated from equations (16) and (15), respectively.

   We will use for our illustration a Q representation for this system.      Dai and Singleton

(2000) proposed the normalization conditions Σ = IN` , δ 1 ≥ 0, c = 0 and ρ lower triangular.

Singleton (2006) used parallel constraints on the Q parameters (Σ = IN` , δ 1 ≥ 0, cQ = 0, ρQ

lower triangular). Our illustration will use Σ = IN` , δ 1 ≥ 0, c = 0 and ρQ lower triangular.


                                               14
For the N` = 3, Ne = 1 case displayed in equation (18), there are then 23 unknown parameters:

3 in cQ , 6 in ρQ , 9 in ρ, 1 in δ 0 , 3 in δ 1 , and 1 in Σe , which we collect in the (23 × 1) vector θ.

The log likelihood is


                         T
                         X
            L(θ; Y ) =         {− log [|det(J)|] + log φ(Ft ; c + ρFt−1 , IN` ) + log φ(uet ; 0, INe )}   (19)
                         t=1



for φ(.) the multivariate Normal density in equation (4) and det(J) the determinant of the

Jacobian, with                                                              
                                                      B1           0        
                                                     (N` ×N` )   (N` ×Ne )
                                           J =
                                                                            
                                                                             
                                                                            
                                                       B2          Σe
                                                     (Ne ×N` )   (Ne ×Ne )


                                               Ft = B1−1 (Yt1 − A1 )


                                  uet = Σ−1  Yt − A2 − B2 B1−1 (Yt1 − A1 ) .
                                             2
                                         e



The Chen-Scott procedure is to maximize (19) with respect to θ by numerical search.

       As a simple example to illustrate the difficulties with this traditional estimation and some

of the advantages of the procedure that we will be recommending to replace it, we simulated

a sample of 1000 observations using parameters specified in the first block of Table 1 below.

These parameters were chosen to match the actual observed behavior of the four yields used

here. On this sample we tried to choose θ so as to maximize (19) using the fminunc algorithm

in MATLAB.5 Since numerical search can be sensitive to different scaling of parameters, we
   5
    MATLAB numerical optimizers have been used by Cochrane and Piazzesi (2009), Aı̈t-Sahalia and Kimmel
(2010), and Joslin, Singleton, and Zhu (2011), among others. Duffee (2011) found that numerical search
problems can be reduced using alternative algorithms. Our purpose here is to illustrate the difficulties that
can arise in estimation. We will demonstrate that these identical MATLAB algorithms have no trouble with
the alternative formulation that we will propose below.


                                                          15
tried to scale parameters in a way consistent with a researcher’s prior expectation that risk

prices were small, multiplying cQ by 10 and δ 1 and Σe by 1000 so that a unit step for each

of these parameters would be similar to a unit step for the others.6                 We used 100 different

starting values for this search, using a range of values for ρQ and starting the other parameters

at good guesses. Specifically, to obtain a given starting value we would generate the 3 diagonal

elements of ρQ from U [0.5, 1] distributions, set off-diagonal elements to zero, and set the initial

guess for ρ equal to this value for ρQ . We set the starting value for each element of δ 1 and Σe

to 1.e-4, δ 0 = 0.0046 (the average short rate), and cQ = 0.

       In only 1 of these 100 experiments did the numerical search converge to the values that

we will establish below are indeed the true global MLE. These estimates, reported in the

second block of Table 1, in fact correspond very nicely to the true values from which this

sample was simulated. However, in 81 of the other experiments, the procedure satisfied the

convergence criterion (usually coming from a sufficiently tiny change between iterations) at a

large range of alternative points other than the global maximum. The third block of Table

1 displays one of these. All such points are characterized by an eigenvalue of ρ being equal

or very close to unity; we will explain why this happens in the following section.                     For the

other 18 starting values, the search algorithm was unable to make any progress from the initial

starting values. Although very simple, this exercise helps convey some sense of the numerical

problems researchers have encountered fitting more complicated models such as we describe

in our next two examples.
   6
    To give the algorithm the best chance to converge, for each starting value we allowed the search to continue
for up to 10,000 function evaluations, then restarted the search at that terminal value to allow an additional
10,000 function evaluations, and so on, for 10 repetitions with each starting value.




                                                      16
2.3       Example 2: Macro finance model with single lag (MF1).

It is of considerable interest to include observable macroeconomic variables among the factors

that may affect interest rates, as for example in Ang and Piazzesi (2003), Ang, Dong, and

Piazzesi (2007), Rudebusch and Wu (2008), Ang, Piazzesi, and Wei (2006), and Hördahl,

Tristani, and Vestin (2006). Our next two illustrative examples come from this class. We

first consider the unrestricted first-order macro factor model studied by Pericoli and Taboga

(2008).    This model uses Nm = 2 observable macro factors, consisting of measures of the

inflation rate and the output gap, which are collected in an (Nm × 1) vector ftm . These two

observable macroeconomic factors are allowed to influence yield dynamics in addition to the

traditional N` = 3 latent7 factors ft` ,

                                                                   
                                                           ftm     
                                                          (Nm ×1)
                                             Ft =                  ,
                                                                   
                                           (Nf ×1)
                                                            ft`
                                                                   
                                                          (N` ×1)



for Nf = Nm + N` . The P dynamics (1), Q dynamics (12), and short-rate equation (13) can

for this example be written in partitioned form as



                           ftm                  m
                                    = cm + ρmm ft−1        `
                                                    + ρm` ft−1 + Σmm um
                                                                      t                                     (20)
                         (Nm ×1)

                            ft`                 m
                                    = c` + ρ`m ft−1        `
                                                    + ρ`` ft−1 + Σ`m um        `
                                                                      t + Σ`` ut
                          (N` ×1)

   7
    Pericoli and Taboga evaluated a number of alternative specifications including different choices for the
number of latent factors N` , number of lags on the macro variables, and dependence between the latent and
macro factors. They refer to the specification we discuss in the text as the M (3, 0, U ) specification, which is
the one that their tests suggest best fits the data.




                                                       17
                                                     Q `            Qm
                         ftm      = cQ    Q   m
                                     m + ρmm ft−1 + ρm` ft−1 + Σmm ut                                     (21)
                       (Nm ×1)

                          ft`     = cQ    Q m        Q `            Qm
                                     ` + ρ`m ft−1 + ρ`` ft−1 + Σ`m ut  + Σ`` uQ`
                                                                              t
                        (N` ×1)




                                        rt = δ 0 + δ 01m ftm + δ 01` ft` .                                (22)


Pericoli and Taboga proposed the normalization conditions8 that Σmm is lower triangular,

Σ`m = 0, Σ`` = IN` , δ 1` ≥ 0, and cQ
                                    ` = 0.


       Our empirical illustration of this approach will use t corresponding to quarterly data and

will take the 1-, 5-, and 10-year bonds to be priced without error (Yt1 = (yt4 , yt20 , yt40 )0 ) and the

2-, 3-, and 7-year bonds to be priced with error (Yt2 = (yt8 , yt12 , yt28 )0 ). Details of how the log

likelihood is calculated for this example are described in Appendix A.



2.4       Example 3: Macro finance model with 12 lags (MF12).

A first-order VAR is not sufficient to capture the observed dynamics of output and inflation.

For example, Ang and Piazzesi (2003) suggested that the best fit is obtained using a monthly

VAR(12) in the observable macro variables and a VAR(1) for the latent factors:9



                         ftm = ρ1 ft−1
                                   m         m
                                       + ρ2 ft−2                m
                                                 + · · · + ρ12 ft−12 + Σmm um
                                                                            t


                                          `
                          ft` = c` + ρ`` ft−1 + Σ`` u`t .
   8
      Pericoli and Taboga imposed f0` = 0 as an alternative to the traditional c` = 0 or cQ
                                                                                          ` = 0, though we will
follow the rest of the literature here in using a more standard normalization.
    9
      Ang and Piazzesi refer to this as their Macro Model.




                                                       18
Our empirical example follows Ang and Piazzesi in proxying the 2 elements of ftm with the

first principal components of a set of output and and a set of inflation measures, respectively,

which factors have mean zero by construction. Ang and Piazzesi treated the macro dynamics

as independent of those for the unobserved latent factors, so that terms such as ρ`m and ρm`

in the preceding example are set to zero.

   Ang and Piazzesi (2003) further proposed the following identifying restrictions: Σmm is

lower triangular, Σ`` = IN` , c` = 0, ρ`` is lower triangular, and the diagonal elements of ρ`` are

in descending order. Further restrictions and details of the model and its likelihood function

are provided in Appendix B. In the specification we replicate, Ang and Piazzesi postulated

that the short rate depends only on the current values of the macro factors:


                                                  0           0
                                    rt = δ 0 + δ 1m ftm + δ 1` ft` .



They further noted that since ft` is independent of ftm under their assumptions, the values of

δ 0 and δ 1m in the short-rate equation can be obtained by OLS estimation of


                                                      0
                                      rt = δ 0 + δ 1m ftm + vt .                              (23)



   To further reduce the dimensionality of the estimation, Ang and Piazzesi (2003) proposed

some further restrictions on this set-up that we will discuss in more detail in Section 4.4.




                                                  19
3     Identification.

The log likelihood function for each of the models discussed– and indeed, for any Gaussian

affine term structure model in which exactly N` linear combinations of yields are assumed to be

priced without error– takes the form of a restricted vector autoregression. The mapping from

the affine-pricing parameters to the VAR parameters allows us to evaluate the identifiability

of a given structure. If two different values for the structural parameters imply the identical

reduced-form parameters, there is no way to use observable data to choose between the two.

We now explore the implications of this fact for each of the three classes of models described

in the previous section.



3.1    Example 1: Latent factor model.

Premultiplying (1) by B1 (and recalling the normalization c = 0 and Σ = IN` ) results in



                               B1 Ft = B1 ρB1−1 B1 Ft−1 + B1 ut .



Adding A1 to both sides and substituting Yt1 = A1 + B1 Ft establishes



                                   Yt1 = A∗1 + φ∗11 Yt−1
                                                      1
                                                         + u∗1t                            (24)



                                    A∗1 = A1 − B1 ρB1−1 A1                                 (25)


                                        φ∗11 = B1 ρB1−1 .                                  (26)




                                               20
Likewise the second block of (17) implies



                                            Yt2 = A∗2 + φ∗21 Yt1 + u∗2t                           (27)



                                               A∗2 = A2 − B2 B1−1 A1                              (28)


                                                  φ∗21 = B2 B1−1                                  (29)
                                                                      
                                    u∗1t       0   Ω∗ 0 
                                          ∼ N   ,  1                                      (30)
                                                         
                                     u∗2t          0     0 Ω∗2

                                                               0
                                                   Ω∗1 = B1 B1                                    (31)


                                                   Ω∗2 = Σe Σ0e .                                 (32)


Equations (24) and (27) will be recognized as a restricted Gaussian VAR for Yt , in which

                  1
a single lag of Yt−1 appears in the equation for Yt1 and in which, after conditioning on the

contemporaneous value of Yt1 , no lagged terms appear in the equation for Yt2 . Note that when

we refer to the reduced-form for this system, we will incorporate those exclusion restrictions

along with the restriction that Ω∗2 is diagonal.

      Table 2 summarizes the mapping between the VAR parameters and the affine term struc-

ture parameters implied by equations (24)-(32).10                   The number of VAR parameters minus

the number of structural parameters is equal to (Ne − 1)(N` + 1). Thus the structure is

just-identified by a simple parameter count when Ne = 1 and overidentified when Ne > 1.

Notwithstanding, the structural parameters can nevertheless be unidentified despite the ap-
 10
      The value of δ 1 turns out not to appear in the product φ∗21 = B2 B1−1 .


                                                        21
parent conclusion from a simple parameter count.

       Consider first what happens at a point where one of the eigenvalues of ρ is unity, that

is, when the P -measure factor dynamics exhibit a unit root.11                    This means that one of

the eigenvalues of B1 ρB1−1 is also unity (B1 ρB1−1 x = x for some nonzero x) requiring that

(IN` − B1 ρB1−1 )x = 0, so the matrix IN` − B1 ρB1−1 is noninvertible. In this case, even if we

knew the true value of A∗1 , we could never find the value of A1 from equation (25). If Â1 is

proposed as a fit for a given sample, then Â1 + kx produces the identical fit for any k. Note

moreover from (16) that A1 and A2 are the only way to find out about cQ and δ 0 ; if we don’t

know the 4 values in A1 and A2 , we can never infer the 4 values of cQ and δ 0 . This failure of

local identification accounts for the numerous failed searches described in Section 2.2. When

the search steps in a region in which ρ has a near unit root, the likelihood surface becomes

extremely flat in one direction (and exactly flat at the unit root), causing the numerical search

to become bogged down. Because the true process is quite persistent, it is extremely common

for a numerical search to explore this region of the surface and become stuck.12

       If instead we used the normalization cQ = 0 in place of the condition c = 0 just analyzed, a

similar phenomenon occurs in which a unit root in ρQ results in a failure of local identification

of δ 0 .

       Even when all eigenvalues of ρ are less than unity, there is another respect in which the

latent factor model discussed here is unidentified.13 Let H denote any (N` × N` ) matrix such
  11
     Note we have followed Ang and Piazzesi (2003) and Joslin, Singleton, and Zhu (2011), among others, in
basing estimates on the likelihood function conditional on the first observation. By contrast, Chen and Scott
(1993) and Duffee (2002) included the unconditional likelihood of the first observation as a device for imposing
stationarity.
  12
     This point has also been made by Aı̈t-Sahalia and Kimmel (2010).
  13
     This has also been recognized by Ang and Piazzesi (2003), Collin-Dufresne, Goldstein, and Jones (2008)
and Aı̈t-Sahalia and Kimmel (2010).


                                                      22
                                                                                          0
that H 0 H = IN` . It is apparent from equations (24)-(32) that if we replace Bj by Bj H and

ρ by HρH 0 , there would be no change in the implied value for the sample likelihood. The

question then is whether the conditions imposed on the underlying model rule out such a

transformation. From equation (16), such a transformation requires replacing cQ with HcQ ,

and from (15) we need now to use Hδ 1 and HρQ H 0 . Since our specification imposed no

restrictions on ρ or cQ , the question is whether the proposed lower triangular structure for ρQ

and nonnegativity of δ 1 rules out such a transformation. The following proposition establishes

that it does not.

   Proposition 1. Consider any (2 × 2) lower triangular matrix:

                                                           
                                               Q
                                         Q
                                             ρ11 0 
                                         ρ =
                                                     .
                                                      
                                               Q   Q
                                              ρ21 ρ22


Then for almost all (2×1) positive vectors δ 1 , there exists a unique orthogonal matrix H other

than the identity matrix such that HρQ H 0 is also lower triangular and Hδ 1 > 0. Moreover,

HρQ H 0 takes one of the following forms:

                                                             
                                  ρQ
                                    22    0         ρQ
                                                       22 0 
                                             or           .
                                                          
                                   ρQ
                                    21
                                          Q
                                         ρ11          Q   Q
                                                    −ρ21 ρ11


For ρQ an (N` × N` ) lower triangular matrix, there are N` ! different lower triangular repre-

sentations, characterized by alternative orderings of the principal diagonal elements.

   There thus exist 6 different parameter configurations that would achieve the same maxi-

mum for the likelihood function for the latent example explored in Section 2.2. The experiment


                                                 23
did not uncover them because the other difficulties with maximization were sufficiently severe

that for the 100 different starting values used, only one of these 6 configurations was reached.

Dai and Singleton (2000) and Singleton (2006) originally proposed lower triangularity of ρ

or ρQ and nonnegativity of δ 1 as sufficient identifying conditions.     Our proposition estab-

lishes that one needs a further condition such as ρQ     Q     Q
                                                   11 ≥ ρ22 ≥ ρ33 to have a globally identified


structure.

   Nevertheless, this multiplicity of global optima is a far less serious problem than the failure

of local identification arising from a unit root.     The reason is that any of the alternative

configurations obtained through these H transformations by construction has the identical

implications for bond pricing. By contrast, the inferences one would draw from Local 53 in

Table 1 are fundamentally flawed and introduce substantial practical difficulties for using this

class of models.

   There is another identification issue, which has separately been recognized by Joslin, Sin-

gleton, and Zhu (2011) using a very different approach from ours: not all matrices ρQ can be

transformed into lower triangular form. For example, for N` = 2, if ρQ is written as lower

triangular, then ρQ
                  22 would have to be one of its eigenvalues. However, it is possible for an


unrestricted real-valued matrix ρQ to have complex eigenvalues, in which case there is no way

to transform it as Υ = HρQ H 0 for Υ a real-valued lower triangular matrix. We propose in the

following proposition an alternative normalization for the case N` = 2 that, unlike the usual

lower-triangular form, is completely unrestrictive.




                                               24
   Proposition 2. Consider ρQ any (2 × 2) real-valued matrix:

                                                            
                                               ρQ
                                                 11    ρQ
                                                        12   
                                       ρQ = 
                                            
                                                             .
                                                             
                                                ρQ   Q
                                                 21 ρ22




For almost all δ 1 ∈ R2+ , there exist exactly two transformations of the form Υ = HρQ H 0 such

that Υ is real, H 0 H = I2 , Hδ 1 > 0, and the two elements on the principal diagonal of Υ are

the same. Moreover, one of these transformations is simply the transpose of the other:

                                                               
                                   a b                    a c 
                             Υ1 = 
                                  
                                        
                                                     Υ2 = 
                                                           
                                                                 .
                                                                 
                                    c a                      b a


   Hence one approach for the N` = 2 case would be to choose the 3 parameters a, b, and c

so as to maximize the likelihood with

                                                        
                                              a b 
                                        ρQ = 
                                             
                                                   
                                                   
                                               c a


subject to the normalization b ≤ c. This has the advantage over the traditional lower-

triangular formulation in that the latter imposes additional restrictions on the dynamics

(namely, lower-triangular ρQ rules out the possibility of complex roots) whereas the Υ formu-

lation does not.

   Unfortunately, it is less clear how to generalize this to larger dimensions. If ρQ has complex

eigenvalues, these always appear as complex conjugates. Thus if one knew for the case N` = 3




                                                25
that ρQ contained complex eigenvalues, a natural normalization would be

                                                       
                                          Q
                                        ρ11 0   0      
                                                       
                                                       
                                  ρQ =   Q      Q
                                        ρ21 a ρ23
                                                        
                                                                                       (33)
                                                       
                                                       
                                         ρQ   Q
                                          31 ρ32 a


with ρQ     Q
      23 ≤ ρ32   The value of a is then uniquely pinned down by the real part of the complex

eigenvalues. However, if the eigenvalues are all real, this is a more awkward form than the

usual                                                  
                                           ρQ0
                                             11   0     
                                                       
                                                       
                                  ρQ =   Q   Q
                                        ρ21 ρ22 0
                                                        
                                                                                       (34)
                                                       
                                                       
                                         ρQ   Q   Q
                                          31 ρ32 ρ33


with ρQ     Q     Q
      11 ≥ ρ22 ≥ ρ33 . The estimation approach that we propose below will instantly reveal


whether or not the lower triangular form (34) is imposing a restriction relative to the full-

information maximum likelihood unrestricted values.     If (34) is determined not to impose

a restriction, one can feel confident in using the conventional parameterization, whereas if

it does turn out to be inconsistent with the estimated unrestricted dynamics, the researcher

should instead parameterize dynamics using (33).




                                              26
3.2    Example 2: Macro finance model with single lag.

We next examine the MF1 specification of Pericoli and Taboga (2008). Calculations similar

to those for the latent factor model show the reduced form to be



                ftm      =    A∗m + φ∗mm ft−1
                                          m
                                              + φ∗m1 Yt−1
                                                       1
                                                          + u∗mt                           (35)
               (Nm ×1)       (Nm ×1)   (Nm ×Nm )          (Nm ×N` )

                 Yt1     =    A∗1 + φ∗1m ft−1
                                          m
                                              + φ∗11 Yt−1
                                                       1
                                                          + ψ ∗1m ftm + u∗1t               (36)
               (N` ×1)       (N` ×1)   (N` ×Nm )         (N` ×N` )    (N` ×Nm )

                 Yt2     =    A∗2 + φ∗2m ftm + φ∗21 Yt1 + u∗2t .                           (37)
               (Ne ×1)       (Ne ×1)   (Ne ×Nm )        (Ne ×N` )




Once again it is convenient to include the contemporaneous value of ftm in the equation for

Yt1 and include contemporaneous values of both ftm and Yt1 in the equation for Yt2 in order to

orthogonalize the reduced-form residuals u∗jt ; the benefits of this representation will be seen

in the next section. The mapping between structural and reduced-form parameters is given




                                                   27
by the following equations and summarized in Table 3 with Nf = Nm + N` :



                                      −1
                      A∗m = cm − ρm` B1` A1                                                 (38)

                    φ∗mm = ρmm − ρm` B1`
                                      −1
                                         B1m                                                (39)

                     φ∗m1 = ρm` B1`
                                 −1
                                                                                            (40)

                                                     −1
                        A∗1 = A1 + B1` c` − B1` ρ`` B1` A1                                  (41)

                     φ∗1m = B1` ρ`m − B1` ρ`` B1`
                                               −1
                                                  B1m                                       (42)

                      φ∗11 = B1` ρ`` B1`
                                      −1
                                                                                            (43)

                     ψ ∗1m = B1m                                                            (44)

                                        −1
                        A∗2 = A2 − B2` B1` A1                                               (45)

                     φ∗2m = B2m − B2` B1`
                                       −1
                                          B1m                                               (46)

                      φ∗21 = B2` B1`
                                  −1
                                                                                            (47)


                                                                                   
                  u∗mt           Ω∗m   0     0       Σmm Σ0mm     0         0      
                                                                                   
                                                                                   
           Var 
                u∗1t
                           =  0
                                        Ω∗1   0  =
                                                            0            0
                                                                     B1` B1`     0      
                                                                                           (48)
                                                                                   
                                                                                   
                 u∗2t           0         0     Ω∗2          0         0       Σe Σ0e


with Ω∗2 diagonal and B1 and B2 partitioned as described in Appendix A.

   Once again inspection of the above equations reveals that the structure is unidentified.

One can see this immediately for the case N` = 3, Nm = 2, Ne = 3 simply by counting

parameters– there are 69 unknown structural parameters and only 66 reduced-form parameters

from which they are supposed to be inferred. The problem arises in particular from the fact


                                                 28
that, for the example we have been discussing, the observable implications of the 30 structural

parameters in ρQ and δ 1 are completely captured by the 27 values of ψ ∗1m , φ∗2m , φ∗21 , and Ω∗1 .

More fundamentally, the lack of identification would remain with this structure no matter

how large the value of Ne . One can see this by verifying that the following transformation

is perfectly allowed under the stated normalization but would not change the value of any

reduced-form parameter: B1` → B1` H 0 , c` → Hc` , ρm` → ρm` H 0 , ρ`` → Hρ`` H 0 , ρ`m → Hρ`m ,

and B2` → B2` H 0 , where H could be any (N` × N` ) orthogonal matrix.

   There is also a separate identification problem arising from the fact that only maturi-

ties for which n is an even number are included in the observation set.          This means that

only even powers of ρQ appear in (15) and (16), which allows observationally equivalent sign

transformations through H as well.



3.3    Example 3: Macro finance model with 12 lags.

Last we consider the MF12 example, for which the reduced form is



                      ftm     = φ∗mm Ft−1
                                       m
                                          + u∗mt                                               (49)
                      (2×1)      (2×24)

                       Yt1    = A∗1 + φ∗1m Ft−1
                                             m
                                                + φ∗11 Yt−1
                                                         1
                                                            + ψ ∗1m ftm + u∗1t                 (50)
                      (3×1)               (3×24)        (3×3)   (3×2)

                       Yt2    = A∗2 + φ∗2m Ftm + φ∗21 Yt1 + u∗2t                               (51)
                      (2×1)               (2×24)    (2×3)




                                                   29
                                                                        
                           φ∗mm    =       ρ1 ρ2 · · ·             ρ12

                                                −1
                            A∗1 = A1 − B1` ρ`` B1` A1
                                  "               #                                      "                    #
                                              (1)                                              (0)      (1)
                           φ∗1m    =        B1m           0                    −1
                                                                    − B1` ρ`` B1`            B1m      B1m
                       (3×24)              (3×22)    (3×2)                   (3×3)           (3×2)   (3×22)

                            φ∗11              −1
                                   = B1` ρ`` B1`

                                           (0)
                           ψ ∗1m = B1m

                                            −1
                            A∗2 = A2 − B2` B1` A1

                           φ∗2m = B2m − B2` B1`
                                             −1
                                                B1m

                           φ∗21 = B2` B1`
                                       −1
                                                                                                           
                                                                                     0
                  u∗mt                Ω∗m      0         0   Σmm Σmm   0      0                            
                                                                                                           
                                                                          0
                                                                                                                  
          Var 
               u∗1t
                           =  0
                                                 Ω∗1       0  =
                                                                      0    B1` B1`  0                            
                                                                                                                  
                                                                                                           
                                                                                                           
                  u∗2t            0                 0         Ω∗2      0      0     Σe Σ0e


with Ω∗2 again diagonal and details on the partitioning of B1 and B2 in Appendix B. Table

4 summarizes the mapping between reduced-form and structural parameters. Note that the

only reduced-form parameters relevant for inference about the 6 elements of δ 0 and λ are the

5 values for A∗1 and A∗2 , establishing that these structural parameters are in fact unidentified.

One might have thought that perhaps δ 0 could be inferred separately from the OLS regression

(23), freeing up the parameters A∗1 and A∗2 for estimation solely of λ. However, this is not the

case, since the short-term interest rate is the same dependent variable in both regression (23)

and in the first OLS regression from which A∗1 is inferred. Another way to see this is to note

that at most what one can expect to uncover from the 5 values of A∗1 and A∗2 are the 5 values

of A1 and A2 . The first element of A1 is exactly equal to δ 0 , so even if δ 0 were known a priori,

                                                              30
the most that one could infer from A1 and A2 is 4 other parameters. Hence A1 and A2 would

not be sufficient to uncover the 5 unknowns in λ even if δ 0 were known with certainty.

    Ang and Piazzesi’s (2003) Macro Model with its proposed identifying restrictions thus turns

out to be unidentified at all points of the parameter space. In their empirical analysis, Ang and

Piazzesi imposed an additional set of restrictions that were intended to improve estimation

efficiency, though as we have just seen some of these are necessary for identification.      We

discuss these further in Section 4.4 below.




4     Estimation.

The reduced-form parameters are trivially obtained via OLS. Hence a very attractive alter-

native to numerical maximization of the log likelihood function directly with respect to the

structural parameters θ is to let OLS do the work of maximizing the likelihood with respect

to the reduced-form parameters, and then translate these into their implications for θ. We

demonstrate in this section how this can be done.



4.1    Minimum-chi-square estimation.

Let π denote the vector consisting of reduced-form parameters (VAR coefficients and nonre-

dundant elements of the variance matrices), L(π; Y ) denote the log likelihood for the entire

sample, and π̂ = arg max L(π; Y ) denote the full-information-maximum-likelihood estimate.




                                               31
If R̂ is a consistent estimate of the information matrix,


                                                           ∂ 2 L(π; Y )
                                                                         
                                                    −1
                                       R = −T            E
                                                             ∂π ∂π 0


then we could test the hypothesis that π = g(θ) for θ a known vector of parameters by

calculating the usual Wald statistic



                                       T [π̂ − g(θ)]0 R̂ [π̂ − g(θ)]                               (52)



which would have an asymptotic χ2 (q) distribution under the null hypothesis where q is the

dimension of π. Rothenberg (1973, p. 24) noted that one could also use (52) as a basis for

estimation by choosing as an estimate θ̂ the value that minimizes this chi-square statistic.

   Following Rothenberg (1973, pp. 24-25), we can obtain asymptotic standard errors by

considering the linear approximation g(θ) ' γ +Γθ for Γ = ∂g(θ)/∂θ0 |θ=θ0 and γ = g(θ0 )−Γθ0
           p
where π̂ → π 0 and we assume there exists a value of θ0 for which the true model satisfies
                                                                              ∗
g(θ0 ) = π 0 . Define the linearized minimum-chi-square estimator θ̂ as the solution to



                               min T [π̂ − γ − Γθ]0 R [π̂ − γ − Γθ] ,
                                 θ



          ∗                                 ∗                      ∗                         √
that is, θ̂ satisfies Γ0 R(π̂ − γ − Γθ̂ ) = 0 or θ̂ = (Γ0 RΓ)−1 Γ0 R(π̂ − γ). Since              T (π̂ −
     L                                 √        ∗              L
π 0 ) → N (0, R−1 ), it follows that       T (θ̂ − θ0 ) → N (0, [Γ0 RΓ]−1 ) . Hence our proposal is to

approximate the variance of θ̂ with T −1 (Γ̂0 R̂Γ̂)−1 for Γ̂ = ∂g(θ)/∂θ0 |θ=θ̂ .

   We show in Appendix E that this is in fact identical to the usual asymptotic variance


                                                          32
for the MLE as obtained from second derivatives of the log likelihood function directly with

respect to θ. In other words, the MCSE and MLE are asymptotically equivalent, and the

MCSE inherits all the asymptotic optimality properties of the MLE. If in a particular sample

the MCSE and MLE differ, there is no basis for claiming that one has better properties than

the other.

   In the case of a just-identified model, the minimum value attainable for (52) is zero, in

which case one can without loss of generality simply minimize



                                    [π̂ − g(θ)]0 [π̂ − g(θ)] .                           (53)



Note that in this case, if the optimized value for this objective is zero, then θ̂ is numeri-

cally identical to the value that achieves the global maximum of the likelihood written as a

function of θ. Although θ̂M CSE in this case is identical to θ̂M LE , arriving at the estimate

by the minimum-chi-square algorithm has two big advantages over the traditional brute-force

maximization of the likelihood function. First, one knows instantly whether θ̂ corresponds

to a global maximum of the original likelihood surface simply by checking whether a zero

value is achieved for (53). By contrast, under the traditional approach, one has to try hun-

dreds of starting values to be persuaded that a global maximum has been found, and even

then cannot be sure. A second advantage is that minimization of (52) or (53) is far simpler

computationally than brute-force maximization of the original likelihood function.

   In addition, the greater computational ease makes calculation of small-sample confidence

intervals feasible. The models considered here imply a reduced form that can be written in



                                               33
companion form as

                                        Yt = k + ΦYt−1 + ΣY ut


for Yt the (N × 1) vector of observed variables (yields, macro variables, and possible lags

of macro variables) and ut ∼ N (0, IN ), where the parameters k, Φ, and ΣY are known

functions of π. We can then obtain bootstrap confidence intervals for θ as follows.                     For
                                                          (j)
artificial sample j, we will generate a sequence {ut }Tt=1 of N (0, IN ) variables for T the
                                                           (j)                    (j)             (j)
original sample size, and then recursively generate Yt           = k(π̂) + Φ(π̂)Yt−1 + ΣY (π̂)ut        for
                                 (j)
t = 1, 2, ..., T, starting from Y0     = Y0 , the initial value from the original sample, and using

the identical parameter values k, Φ, and ΣY (as implied by the original π̂) for each sample

j. On sample j we find the FIML estimate π̂ (j) on that artificial sample and then calculate
  (j)
              h            i0    h             i
θ̂ = arg minT π̂ (j) − g(θ) R̂(j) π̂ (j) − g(θ) . We generate a sequence j = 1, 2, ..., J of such
            θ

samples, from which we could calculate 95% small-sample confidence intervals for each element

of θ. The small-sample standard errors for parameter i reported in the following section were
                q
                             (j)
calculated from J −1 Jj=1 (θ̂i,M CSE − θ̂i )2 where θ̂i is the MCSE estimate for the original
                      P

                                                                                            (j)
sample (whose original FIML π̂ was used to generate each artificial sample j) and θ̂i,M CSE is

the minimum-chi-square estimate for artificial sample j.

   We now illustrate these methods and their advantages in detail using the examples of affine

term structure models discussed above.



4.2    Example 1: Latent factor model.

In the case of Ne = 1, the latent factor model is just-identified, making application of

minimum-chi-square estimation particularly attractive.            The reduced-form parameter vec-

                                                  34
tor here is


                            0 0                              0 0                !0
                                               ∗   0                                  ∗   0
      π=       vec    A∗1 φ∗11        , [vech(Ω1 )] , vec    A∗2 φ∗21        , [diag(Ω2 )]



where vec(X) stacks the columns of the matrix X into a vector. If X is square, vech(X) does

the same using only the elements on or below the principal diagonal, and diag(X) constructs a

vector from the diagonal elements of X. Because u∗1t and u∗2t are independent, full-information-

maximum-likelihood (FIML) estimation of π is obtained by treating the Y1 and Y2 blocks

separately.   Since each equation of (24) has the same explanatory variables, FIML for the

ith row of [A∗1 , φ∗11 ] is obtained by OLS regression of Yit1 on a constant and Yt−1
                                                                                   1
                                                                                      , with Ω̂∗1 the

matrix of average outer products of those OLS residuals:


                                   T
                                   X                       ∗                            ∗
                     Ω̂∗1 = T −1         (Yt1 − Â∗1 − φ̂11 Yt−1
                                                              1
                                                                 )(Yt1 − Â∗1 − φ̂11 Yt−1
                                                                                       1
                                                                                          )0 .
                                   t=1



FIML estimates of the remaining elements of π are likewise obtained from OLS regressions

of Yit2 on a constant and Yt1 .

   The specific mapping in Table 2 suggests that we can use the following multi-step algorithm

to minimize (53) for the latent factor model with N` = 3 and Ne = 1.

   Step 1. The estimate of Σe is obtained analytically from the square root of Ω̂∗2 .

   Step 2. The estimates of the 9 unknowns in ρQ and δ 1 are found by numerically solving

the 9 equations in (29) and (31)


                                                                              ∗
                                    [B2 (ρ̂Q , δ̂ 1 )][B1 (ρ̂Q , δ̂ 1 )]0 = φ̂21 Ω̂∗1


                                                          35
                                          [B1 (ρ̂Q , δ̂ 1 )][B1 (ρ̂Q , δ̂ 1 )]0 = Ω̂∗1 .

                                              h      ∗
                                                              i0
Specifically, we do this by letting14 π̂ 2 = ( vec(φ̂21 Ω̂∗1 ) , [vech(Ω̂∗1 )]0 )0 and g2 (ρQ , δ 1 ) = ([vec(B2 B10 )]0 ,
               0
[vech(B1 B1 )]0 )0 and finding ρ̂Q and δ̂ 1 by numerical minimization of [π̂ 2 − g2 (ρQ , δ 1 )]0 [π̂ 2 −

g2 (ρQ , δ 1 )].

       Step 3. The estimate of ρ can then be obtained analytically from (26):


                                                                        ∗
                                                      ρ̂ = B̂1−1 φ̂11 B̂1                                     (54)



where B̂1 is known from Step 2.

       Step 4. Numerically solve the 4 unknowns in δ 0 and cQ from the 4 equations in Â∗1 and

Â∗2 using (25) and (28):


                                                           
                                       I3 −   B̂1 ρ̂B̂1−1       A1 (δ 0 , cQ , ρ̂Q , δ̂ 1 ) = Â∗1



                           A2 (δ 0 , cQ , ρ̂Q , δ̂ 1 ) − B̂2 B̂1−1 A1 (δ 0 , cQ , ρ̂Q , δ̂ 1 ) = Â∗2 .


       Although Steps 2 and 4 involve numerical minimization, these are computationally far sim-

pler problems than that associated with traditional brute-force maximization of the likelihood

function with respect to the full vector θ.                        To illustrate this, we repeated the experiment

described in Section 2.2 with the same 100 starting values. Whereas we saw in Section 2.2
  14
     To assist with scaling for numerical robustness, we multiplied each equation in step 2 by 1200 × 1.e+7 and
those in step 4 below by 1.e+8. If we were minimizing (52) directly one would automatically achieve optimal
scaling by using R̂ in place of a constant k times the identity matrix as here. However, our formulation takes
advantage of the fact that the elements of π̂ can be rearranged in order to avoid inversion of B1 inside the
numerical optimization, in which case R̂ is no longer the optimal weighting matrix. The minimization was
implemented using the fsolve command in MATLAB. We also multiplied δ 1 by 1000 to improve numerical
robustness.


                                                                   36
that only one of these efforts found the global maximum under the traditional approach, with

our method all 100 converge to the global MLE in one of the 6 configurations that are observa-

tionally equivalent for the original normalization. One of the reasons for the greater robustness

is that the critical stumbling block for the traditional method– numerical search over ρ– is

completely avoided since in our approach (54) is solved analytically. Another is that cQ and

uncertainties about its scale are completely eliminated from the core problem of estimation of

ρQ and δ 1 .

       Joslin, Singleton, and Zhu (2011) have recently proposed a promising alternative parame-

terization of the pure latent affine models that shares some of the advantages of our approach.

They parameterize the system such that A∗1 and φ∗11 in (24) are taken to be the direct ob-

jects of interest, and as in our approach, estimate these directly with OLS. But whereas our

approach also uses the OLS estimates of A∗2 and φ∗21 in (27) to uncover the remaining affine-

pricing parameters, their approach finds these by maximizing the joint likelihood function of

Y1 and Y2 . Although they report that the second step involves no numerical difficulties, our

experience is that while it offers a significant improvement over the traditional method, it is

still susceptible to some of the same problems.              For example, we repeated the experiment

described above with the same data set and same starting values for δ 0 and the 3 unknown

diagonal elements in ρQ that appear in their parameterization as we used in the simulations

described above, starting the search for Ω∗1 from the OLS estimates as they recommend. We

found that the algorithm found the global maximum in 54 out of the 100 trials15 , but got

stuck in regions with diagonal elements of ρQ equal to unity in the others, in a similar failure
  15
     To assist the numerical search, we multiplied Ω∗1 by 1000. Without this scaling, the searches only succeeded
in finding the global maximum in 14 of the 100 trials.



                                                       37
of local identification that we documented above can plague the traditional approach.

      We applied our method directly to the Ang and Piazzesi interest rate data described in

more detail in Section 4.4 below. Table 5 reports the resulting minimum-chi-square estimates

(identical in this case to the full-information-maximum-likelihood estimates). The table also

reports asymptotic standard errors in parentheses and small-sample standard errors in square

brackets. The latter were calculated by applying our method to each of 1000 separate data

sets, each generated from the vector autoregression estimated from the original data set. Note

that the fact that we can verify with certainty that the global maximum has been found on

each of these 1000 simulated data sets is part of what makes calculation of small-sample

standard errors feasible and attractive. Finding the FIML estimate on 1000 data sets takes

about 90 seconds on a PC. For this example, we find that the asymptotic standard errors

provide an excellent approximation to the true small-sample values.

      Although our original inference was conducted in terms of a Q representation, we report

the implied λ representation values in the right-hand columns of Table 5, since that is the

form in which parameter estimates are often reported for these models.      Our suggestion is

that the approach we illustrate here, of beginning with a completely unrestricted model to

see which parameters appear to be most significant, has many advantages over the traditional

approach16 in which sundry restrictions are imposed at a very early stage, partly in order to

assist with identification and estimation.
 16
      See for example Duffee (2002) and Duarte (2004).




                                                     38
4.3    Example 2: Macro finance model with single lag.

We also applied this procedure to estimate parameters for our MF1 example using a slightly

different quarterly data set from Pericoli and Taboga. We used constant-maturity Treasury

yields as of the first day of the quarter, dividing the numbers as usually reported by 400 in

order to convert to units of quarterly yield on which formulas such as (14) are based.     We

estimated inflation from the 12-month percentage change in the CPI and the output gap by

applying the Hodrick-Prescott filter with λ = 1600 to 100 times the natural log of real GDP.

Data run from 1960:Q1 to 2007:Q1 and were obtained from the FRED database of the Federal

Reserve Bank of St. Louis.

   If we impose 3 further restrictions on ρQ
                                           `` relative to the original formulation, the MF1


model presented above would be just-identified in terms of parameter count, for which we

would logically again simply try to invert the reduced-form parameter estimates to obtain

the FIML estimates of the structural parameters. Once again orthogonality of the residuals

across the three blocks of (35) through (37) means FIML estimation can be done on each block

separately, and within each block implemented by OLS equation by equation. Our estimation

procedure on this system is then as follows.

   Step 1. The ftm and Yt2 variance parameters are obtained analytically from (48), that is,

Σ̂mm from the Cholesky factorization of Ω̂∗m and Σ̂e from the square root of Ω̂∗2 .

   Step 2. Using (44), (46), (48), and (47), choose the values of ρQ and δ 1 so as to solve the




                                               39
following equations numerically17 :


                                                                           ∗
                                                  B1m (ρQ , δ 1 ) = ψ̂ 1m


                                                                   ∗           ∗   ∗
                                          B2m (ρQ , δ 1 ) = φ̂2m + φ̂21 ψ̂ 1m

                                     n                               0 o        
                                       B1` (ρQ , δ 1 ) B1` (ρQ , δ 1 )     = vech Ω̂∗1
                                                      
                           vech

                                                                      0   ∗
                                       B2` (ρQ , δ 1 ) B1` (ρQ , δ 1 ) = φ̂21 Ω̂∗1 .
                                                     



We initially tried to solve this system for ρQ
                                             `` of the lower-triangular form (34), but found no


solution exists, indicating that the FIML estimate of ρQ
                                                       `` has complex roots. We accordingly


reparameterized ρQ
                 `` in the form (33), for which an exact solution was readily obtained.


       Step 3. From these estimates one then analytically can calculate ρ̂m` , ρ̂mm , ρ̂`` , and ρ̂`m
          ∗    ∗     ∗           ∗
from φ̂m1 , φ̂mm , φ̂11 , and φ̂1m , respectively.

       Step 4. Since cm and c` are unrestricted, the values of δ 0 and cQ can be inferred solely

from A∗2 by numerical solution of (45):



                                                               −1
                          A2 (δ 0 , cQ , ρ̂Q , δ̂ 1 ) − B̂2` B̂1` Â1 (δ 0 , cQ , ρ̂Q , δ̂ 1 ) = Â∗2 .



       Step 5. We then can calculate the remaining parameters analytically using (38) and (41):



                                                                   −1
                                               ĉm = Â∗m + ρ̂m` B̂1` Â1
  17
    To improve accuracy of the numerical algorithm, we multiplied the last two equations by 400 and then
the whole set of equations by 1.e+7. The parameter δ 1 was also scaled by 100.




                                                              40
                                                                        
                                     −1                            −1
                             ĉ` = B̂1`   Â∗1 − Â1 + B̂1` ρ̂`` B̂1` Â1 .


   Table 6 reports the FIML estimates obtained by the above algorithm along with asymptotic

standard errors. These estimates would cause one to be cautious about the proposed model–

standard errors are quite large, and 3 eigenvalues of the estimated ρQ matrix are outside the

unit circle. We found small-sample standard errors much more difficult to calculate for this

example, in part because the value of ρQ associated with a given π̂ (j) can have anywhere from

zero to four complex eigenvalues, with eigenvalues of the ρQ
                                                           `` submatrix sometimes greater than


2 in modulus. Our interpretation is that further restrictions on the interaction between the

macro and latent factors could be helpful for this class of models.



4.4    Example 3. Macro finance model with 12 lags.

Here our data set follows Ang and Piazzesi (2003) as closely as possible, using zero-coupon

bond yields with maturities of 1, 3, 12, 36 and 60 months from CRSP monthly treasury file,

each divided by 1200 to quote as monthly fractional rates. We obtained two groups of monthly

US macroeconomic key indicators, seasonally adjusted if applicable, from Datastream. The

first group consists of various inflation measures which are based on the CPI, the PPI of finished

goods, and the CRB Spot Index for commodity prices. The second group contains variables

that capture real activity: the Index of Help Wanted Advertising, Unemployment Rates, the

growth rate of Total Civilian Employment and the growth rate of Industrial Production. All

growth rates and inflation rates are measured as the difference in logs of the monthly index

value between dates t and t−12. We first normalized each series separately to have zero mean



                                                  41
and unit variance, then extracted the first principal component of each group, designated the

“inflation” and “real activity” indices, respectively, with each index having zero mean and unit

variance by construction. The sample period for yields is from December 1952 to December

2000, and that for the macro indices is from January 1952 to December 2000. We assume

that 1-, 12- and 60-month yields are priced exactly, and 3- and 36-month yields are priced

with error (Ne = 2). We use the Ang and Piazzesi (2003) Macro Model with their additional

proposed zero restrictions to illustrate minimum-chi-square estimation for an overidentified

model.

   The reduced-form equations (49)-(51) form 3 independent blocks. If we interpret Ytm =

ftm , we can write the structure of block i for i = 1, 2, m as



                                     Yti =         Π0i xit + u∗it
                                   (qi ×1)      (qi ×ki )(ki ×1)   (qi ×1)




                                             u∗it ∼ N (0, Ω∗i ).


The information matrix for the full system of reduced-form parameters is

                                                                    
                                           R̂m 0 0                  
                                                                    
                                                                    
                                     R̂ = 
                                           0 R̂1 0
                                                                     
                                                                     
                                                                    
                                                                    
                                             0  0 R̂2




                                                      42
where as in Magnus and Neudecker (1988, p. 321)

                                                                                                           
                                                   PT             0
                             Ω̂∗−1
                                i     ⊗T    −1
                                                     t=1   xit xit                       0                  
                R̂i = 
                                                                                                 
                                                                                                            
                                                                                                            
                                                                                 0
                                                0                          (1/2)Dqi Ω̂∗−1
                                                                                      i   ⊗ Ω̂∗−1
                                                                                              i   Dqi


for DN the N 2 × N (N + 1)/2 duplication matrix satisfying DN vech(Ω) = vec(Ω).

   The structural parameters Σe appear only in the last half of the third block, no other

parameters appear in this block, and these 2 structural parameters are just-identified by

the 2 diagonal elements of Ω∗2 . Thus the minimum-chi-square estimates of Σe are obtained

immediately from the square roots of diagonal elements of Ω̂∗2 .                               The structural parameters

ρ1 , ..., ρ12 appear directly in the first block and, through ρQ , in the second and third blocks

as well, so FIML or minimum-chi-square estimation would exploit this. However, to reduce

dimensionality, we follow Ang and Piazzesi in replacing ρ2 , ..., ρ12 where they appear in ρQ with

the OLS estimates ρ̂2 , ..., ρ̂12 . In order to try to replicate their setting as closely as possible,

we also follow their procedure of imposing δ̂ 1m on the basis of OLS estimation of (23). Hence

the minimum-chi-square analog to their problem is to minimize an expression of the form of

(52) with
                                     h          i0 h     i0 h    i0 0
                                                              ∗
                              π̂ =        vec Π̂1    , vech Ω̂1 , vec Π̂2                                                       (55)

                                                                                                                               
                              PT           0
           Ω̂∗−1
              1     ⊗T   −1
                                t=1   x1t x1t                              0                            0                       
                                                                                                                               
                                                                                                                             
                                                              0
   R̂ = 
                         0                         (1/2)D3 Ω̂∗−1
                                                              1   ⊗ Ω̂∗−1
                                                                      1   D3                            0                       
                                                                                                                                
                                                                                                                               
                                                                                                           PT             0
                                                                                                                                
                          0                                                0                 Ω̂∗−1
                                                                                               2   ⊗ T −1       t=1   x2t x2t

                                                            m0
                                                x1t = (1, Ft−1     10
                                                               , Yt−1 , ftm0 )0



                                                                      43
                                                x2t = (1, Ftm0 , Yt10 )0

                                      T
                                                      !        T
                                                                               !−1
                             0                   0                        0
                                      X                        X
                           Π̂i =            Yti xit                  xit xit         for i = 1, 2
                                      t=1                      t=1

                                               T                                   0
                                                                     0          0
                                               X
                              Ω̂∗1   =T   −1
                                                         Yt1               1
                                                               − Π̂1 x1t Yt − Π̂1 x1t
                                               t=1
                                                                                                
                                             [û2t (1)]2 · · ·                       0          
                                         T                                                      
                                                    ..      ..                         ..
                                        X
                               ∗     −1
                                                                                                
                             Ω̂2 = T        
                                                    .       .                          .        
                                                                                                 
                                        t=1                                                     
                                                                                                
                                                   0      ···                    [û2t (Ne )]2

                                                 0
with û2t (j) the jth element of Yt2 − Π̂2 x2t .

       Ang and Piazzesi also imposed a further set of restrictions on parameters, setting parame-

ters with large standard errors as estimated in their first stage to zero. Their understanding

was that the purpose of these restrictions was to improve efficiency, though we saw in Section

3.3 that some of these restrictions are in fact necessary in order to achieve identification. Our

purpose here is to illustrate the minimum-chi-square method on an overidentified structure,

and we therefore attempt to estimate their final proposed structure using our method. The

additional parameters that Ang and Piazzesi fixed at zero include the (2,1) and (3,1) elements

of ρ`` (which recall was already lower triangular), the (1,2), (2,2), (3,2) and (1,3) elements of

Λ`` , both elements in λm , and the 2nd and 3rd elements of λ` . Our goal is then to minimize

(52) with respect to the 17 remaining unknown parameters, 1 in λ` , 4 in Λmm , 5 in Λ`` , 4 in

ρ`` , and 3 in δ 1` .18
  18
     We made one other slight change in parameterization that may be helpful. Since Λ`` always enters
either the minimum-chi-squared calculations or the original maximum likelihood estimation in the form of
high powers of the matrix ρQ`` = ρ`` − Λ`` , the algorithms will be better behaved numerically if the unknown
elements of ρQ
             `` rather than those of Λ`` are taken to be the object of interest. Specifically, for this example



                                                                44
    The results of this estimation for 100 different starting values are reported in Table 7.

Our procedure uncovered three local minima to the objective function. The parameters we

report as Local1 correspond to the values reported in Table 6 of Ang and Piazzesi.                       The

small differences between our estimates and theirs are due to some slight differences between

the data sets and the fact that, in an overidentified structure, the minimum-chi-square and

maximum-likelihood estimates are not numerically identical. Our procedure establishes that

the estimates reported by Ang and Piazzesi in fact represent only a local maximum of the

likelihood– both the estimates we report as Local2 and Global achieve substantially higher

values for the log likelihood function relative to Local1. Moreover, the differences between

estimates in terms of the pricing of risk are substantial.            In the original reported Ang and

Piazzesi estimates, an increase in inflation lowers the price of inflation risk and raises the price

of output risk, whereas the values implied by Global reverse these signs. This is consistent

with their finding that the prices of observable macro risk behave very differently between

their Macro Model and Macro Lag Model specifications– we find they also differ substantially

across alternative local maxima of the log likelihood function even within their single Macro

Model specification. Note that the large prices of risk for these higher local maxima can make

them easy to miss with conventional estimation and conventional starting values of zero price

of risk.

    Another benefit of the minimum-chi-square estimation is that the value for the objective
we implemented this subject to the proposed restrictions by parameterizing
                                                                        
                                     θ1 0 0                    θ5 0 0
                             ρ`` =  0 θ2 0           ρQ
                                                        `` =
                                                              θ6 θ2 θ7  ,
                                      0 θ3 θ4                  θ8 θ3 θ9

and then translated back in terms of the implied values for Λ`` for purposes of reporting values in Table 7.



                                                     45
function itself gives us an immediate test of the various overidentifying restrictions. There

are 152 parameters in the reduced form vector π in (55). The 17 estimated elements of θ then

leave 135 degrees of freedom. The 1% critical value for a χ2 (135) variable is 176. Thus the

observed minimum value for our objective function (462.15) provides overwhelming evidence

that the restrictions imposed by the model are inconsistent with the observed data.




5    Conclusion.

There are considerable benefits from describing affine term structure models in terms of their

implications for the reduced-form representation of the data, which for a popular class of

models is simply a restricted Gaussian vector autoregression.     In this paper we used this

representation to develop an approach to characterizing identification that has not previously

been used for affine term structure models. We demonstrated that three popular canonical

representations are in fact not identified, and showed how convergence to an unidentified

region of the parameter space can complicate numerical search.        A second and separate

contribution of the paper was to propose inferring structural parameters from the unrestricted

OLS estimates by the method of minimum-chi-square estimation, which is an approach to

parameter estimation that again has not previously been used for affine term structure models.

We demonstrated that among other benefits, this method is asymptotically equivalent to

maximum likelihood estimation and can in some cases make it feasible to calculate small-

sample standard errors, to know instantly whether estimates represent a global or only a local

optimum, and to recognize whether a given structure is unreasonably restricting the class of



                                             46
possible models.

   By missing these insights, previous researchers have instead often imposed arbitrary re-

strictions in order to obtain estimates and in other cases failed to find the true global maximum

of the likelihood function.   By showing how to recognize an unidentified structure, greatly

reducing the computational burden of estimation, and providing an immediate specification

test of any proposed restrictions, we hope that our methods will help to make these models a

more effective tool for research in macroeconomics and finance.




                                               47
References

Aı̈t-Sahalia, Yacine, and Robert L. Kimmel, 2010, Estimating Affine Multifactor Term Struc-

  ture Models Using Closed-Form Likelihood Expansions. Journal of Financial Economics,

  98.


Ang, Andrew, Sen Dong, and Monika Piazzesi, 2007, No-Arbitrage Taylor Rules. National

  Bureau of Economic Research, Working paper no. 13448.


Ang, Andrew, and Monika Piazzesi, 2003, A No-Arbitrage Vector Autoregression of Term

  Structure Dynamics with Macroeconomic and Latent Variables. Journal of Monetary Eco-

  nomics, 50, 745–787.


Ang, Andrew, Monika Piazzesi, and Min Wei, 2006, What Does the Yield Curve Tell Us About

  GDP Growth. Journal of Econometrics, 131, 359–403.


Bauer, Michael D., 2011, Term Premia and the News. Federal Reserve Bank of San Francisco,

  Working paper.


Beechey, Meredith J., and Jonathan H. Wright, 2009, The High-Frequency Impact of News

  On Long-Term Yields and Forward Rates: Is It Real? Journal of Monetary Economics, 56,

  535–544.


Bekaert, Geert, Seonghoon Cho, and Antonio Moreno, 2010, New Keynesian Macroeconomics

  and the Term Structure. Journal of Money, Credit, and Banking, 42, 33–62.


Chamberlain, Gary, 1982, Multivariate Models for Panel Data. Journal of Econometrics, 18,

  5–46.

                                            48
Chen, Ren-Raw, and Louis Scott, 1993, Maximum Likelihood Estimation for a Multifactor

  Equilibrium Model of the Term Structure of Interest Rates. The Journal of Fixed Income,

  3, 14–31.


Christensen, Jens H. E., Francis X. Diebold, and Glenn D. Rudebusch, 2011, The Affine

  Arbitrage-Free Class of Nelson-Siegel Term Structure Models. Journal of Econometrics,

  164, 4 – 20.


Christensen, Jens H. E., Jose A. Lopez, and Glenn D. Rudebusch, 2009, Do Central Bank Liq-

  uidity Facilities Affect Interbank Lending Rates? Working paper 2009-13, Federal Reserve

  Bank of San Francisco.


Christensen, Jens H. E., Jose A. Lopez, and Glenn D. Rudebusch, 2010, Inflation Expectations

  and Risk Premiums in an Arbitrage-Free Model of Nominal and Real Bond Yields. Journal

  of Money, Credit, and Banking, 42, 143 – 178.


Cochrane, John H., and Monika Piazzesi, 2009, Decomposing the Yield Curve. AFA 2010

  Atlanta Meetings Paper.


Collin-Dufresne, Pierre, Robert S. Goldstein, and Christopher S. Jones, 2008, Identification

  of Maximal Affine Term Structure Models. Journal of Finance, 63, 743–795.


Dai, Qiang, and Kenneth J. Singleton, 2000, Specification Analysis of Affine Term Structure

  Models. The Journal of Finance, 55, 1943–1978.


Dai, Qiang, and Kenneth J. Singleton, 2002, Expectation Puzzles, Time-Varying Risk Premia,

  and Affine Models of the Term Structure. Journal of Financial Economics, 63, 415–441.

                                            49
Duarte, Jefferson, 2004, Evaluating an Alternative Risk Preference in Affine Term Structure

  Models. Review of Financial Studies, 17, 379–404.


Duffee, Gregory R., 2002, Term Premia and Interest Rate Forecasts in Affine Models. The

  Journal of Finance, 57, 405–443.


Duffee, Gregory R., 2011, Forecasting with the Term Structure: The Role of No-Arbitrage

  Restrictions. Working Paper, Johns Hopkins University.


Duffee, Gregory R., and Richard H. Stanton, 2008, Evidence on Simulation Inference for Near

  Unit-Root Processes with Implications for Term Structure Estimation. Journal of Financial

  Econometrics, 6, 108 – 142.


Duffie, Darrell, and Rui Kan, 1996, A Yield-Factor Model of Interest Rates. Mathematical

  Finance, 6, 379–406.


Fisher, Franklin M., 1966, The Identification Problem in Econometrics. New York: McGraw-

  Hill.


Fisher, R.A., 1924, The Conditions Under Which χ2 Measures the Discrepancey Between

  Observation and Hypothesis. Journal of the Royal Statistical Society, 87, 442 – 450.


Gallant, A. Ronald, and George E. Tauchen, 1992, A Nonparametric Approach to Nonlinear

  Time Series Analysis: Estimation and Simulation. In New Directions in Time Series Analysis

  Part II, edited by David Brillinger, Peter Caines, John Geweke, Emanuel Parzen, Murray

  Rosenblatt, and Murad S. Taqqu, Springer-Verlag.




                                             50
Gourieroux, Christian, Alain Monfort, and Eric Renault, 1993, Indirect Inference. Journal of

  Applied Econometrics, 8S, S85 – S118.


Hamilton, James D., and Jing Cynthia Wu, forthcominga, The Effectiveness of Alternative

  Monetary Policy Tools in a Zero Lower Bound Environment. Journal of Money, Credit &

  Banking.


Hamilton, James D., and Jing Cynthia Wu, forthcomingb, Testable Implications of Affine

  Term Structure Models. Journal of Econometrics.


Hansen, Lars P., 1982, Large Sample Properties of Generalized Method of Moments Estima-

  tors. Econometrica, 50, 1029 – 1054.


Hördahl, Peter, Oreste Tristani, and David Vestin, 2006, A Joint Econometric Model of

  Macroeconomic and Term-Structure Dynamics. Journal of Econometrics, 131, 405 – 444.


Joslin, Scott, Kenneth J. Singleton, and Haoxiang Zhu, 2011, A New Perspective On Gaussian

  Dynamic Term Structure Models. Review of Financial Studies, 24, 926–970.


Kim, Don H., 2008, Challenges in Macro-Finance Modeling. BIS Working Paper No. 240,

  FEDS Working Paper No. 2008-06.


Kim, Don H., and Athanasios Orphanides, 2005, Term Structure Estimation with Survey

  Data On Interest Rate Forecasts. Federal Reserve Board, Finance and Economics Discussion

  Series 2005-48.


Kim, Don H., and Jonathan H. Wright, 2005, An Arbitrage-Free Three-Factor Term Structure



                                            51
  Model and the Recent Behavior of Long-Term Yields and Distant-Horizon Forward Rates.

  Federal Reserve Board, Finance and Economics Discussion Series 2005-33.


Magnus, Jan R., and Heinz Neudecker, 1988, Matrix Differential Calculus with Applications

  in Statistics and Econometrics. John Wiley & Sons, Ltd.


Malinvaud, Edmond, 1970, Statistical Methods of Econometrics, Third Revised Edition. New

  York: North-Holland.


Newey, Whitney K., 1987, Efficient Estimation of Limited Dependent Variable Models with

  Endogenous Explanatory Variables. Journal of Econometrics, 36, 231–250.


Neyman, J., and E. S. Pearson, 1928, On the Use and Interpretation of Certain Test Criteria

  for Purposes of Statistical Inference: Part II. Biometrika, 20A, 263 – 294.


Pericoli, Marcello, and Marco Taboga, 2008, Canonical Term-Structure Models with Observ-

  able Factors and the Dynamics of Bond Risk Premia. Journal of Money, Credit and Banking,

  40, 1471–1488.


Rothenberg, Thomas J., 1971, Identification in Parametric Models. Econometrica, 39, 577–

  591.


Rothenberg, Thomas J., 1973, Efficient Estimation with A Priori Information. Yale University

  Press.


Rudebusch, Glenn D., Eric T. Swanson, and Tao Wu, 2006, The Bond Yield ‘Conundrum’

  From a Macro-Finance Perspective. Monetary and Economic Studies (Special Edition), 83–

  128.

                                             52
Rudebusch, Glenn D., and Tao Wu, 2008, A Macro-Finance Model of the Term Structure,

  Monetary Policy and the Economy. The Economic Journal, 118, 906–926.


Singleton, Kenneth J., 2006, Empirical Dynamic Asset Pricing. Princeton University Press.


Smith, Jr., Anthony A., 1993, Estimating Nonlinear Time-Series Models Using Simulated

  Vector Autoregressions. Journal of Applied Econometrics, 8S, S63 – S84.


Smith, Josephine M., 2010, The Term Structure of Money Market Spreads During the Finan-

  cial Crisis. Ph.D. thesis, Stanford University.


Vasicek, Oldrich, 1977, An Equilibrium Characterization of the Term Structure. Journal of

  Financial Economics, 5, 177–188.




                                               53
Appendix A. Log likelihood function for the MF1 specification.
The coefficients relating Yt1 and Yt2 to macro and latent factors can be partitioned as
                                                      0 
                                                        b4
                                                   b020 
                                      B1m B1`         0 
                                    (3×2) (3×3)  =  b40
                                                           
                                                         0
                                                            
                                      B2m B2`         b 
                                                         8
                                                      0 
                                      (3×2) (3×3)     b 
                                                                          12
                                                                          0
                                                                         b28

for bn given by (15). The conditional density for the tth observation is then
                                                        1
                    f (ftm , Yt |ft−1
                                  m
                                      , Yt−1 ) =              f (ftm , ft` , uet |ft−1
                                                                                   m      `
                                                                                       , ft−1 , uet−1 )
                                                    | det(J)|

where
              f (ftm , ft` , uet |ft−1
                                   m      `
                                       , ft−1 , uet−1 ) = f (ftm |ft−1
                                                                   `      m
                                                                       , ft−1 )f (ft` , |ft−1
                                                                                          `      m
                                                                                              , ft−1 )f (uet )
                                                                                                   0
                   f (ftm |ft−1
                            `      m
                                , ft−1 ) = φ(ftm ; cm + ρmm ft−1
                                                             m          `
                                                                 + ρm` ft−1 , Σmm Σmm )
                          f (ft` |ft−1
                                   `      m
                                       , ft−1 ) = φ(ft` ; c` + ρ`m ft−1
                                                                    m          `
                                                                        + ρ`` ft−1 , IN` )
                                               f (uet ) = φ(uet ; 0, INe )
                                                −1
                                         ft` = B1` (Yt1 − A1 − B1m ftm )
                                   uet = Σ−1   2             m       `
                                          e (Yt − A2 − B2m ft − B2` ft )
                                                          
                                                   B1` 0
                                             J=              .
                                                   B2` Σe
For the Q representation and our N` = 3, Nm = 2, Ne = 3 example, there are 25 unknown
elements in ρ, 25 in ρQ , 5 in c, 2 in cQ , 5 in δ 1 , 1 in δ 0 , 3 in Σmm , and 3 in Σe . The traditional
approach is to arrive at estimates of these 69 parameters by numerical maximization of
                                                  T
                                                  X
                                   L(θ; Y ) =            log f (ftm , Yt |ft−1
                                                                           m
                                                                               , Yt−1 )
                                                   t=1

as calculated using the above formulas.




                                                            54
Appendix B. Log likelihood for the MF12 specification.
The P dynamics can again be represented as a special case       of (1) by using the companion
             m0  `0 0    m    m0        m0    0       0       0 0
form Ft = (Ft , ft ) , Ft = (ft , ..., ft−11 ) , c = 024×1 , c` , and

                                       ρ2 ρ3 · · ·
                                                                                              
                                  ρ1                              ρ11 ρ12                 0
                            (2×2)                                                             
                            I2
                                  0                 0      ···   0         0             0    
                                                                                               
                            0
                                  I2                0      ···   0         0             0    
                                                                                               
                            ..     ..               ..     ...   ..        ..            ..
                         ρ= .
                                                                                               
                                    .                .            .         .             .   
                                                                                               
                            0
                                  0                 0      ···   0         0           0      
                                                                                               
                            0
                                  0                 0      ···   I2        0           0      
                                                                                               
                               0   0                 0      ···   0         0          ρ``
                                                                                      (3×3)

                                                                                     
                                       Σmm 0 · · ·                0        0
                                      (2×2)                                          
                                
                                          0              0 ··· 0          0          
                                                                                      
                              Σ=          ..             .. . . ..        ..
                                                                                      .
                                                                                     
                                            .              .    . .         .
                                                                                     
                                
                                          0              0 ··· 0           0         
                                                                                      
                                           0              0 ··· 0          Σ``
                                                                       (3×3)

Ang and Piazzesi assumed that the risk associated with lagged macro factors is not priced
and imposed the restriction
                      0    in a λ representation that the values in (9) are characterized by
λ = λ0m , 0022×1 , λ0` and
                                                                                         
                                           Λmm 0 · · ·                 0         0
                                           (2×2)                                         
                                    
                                               0           0 ··· 0              0        
                                                                                          
                               Λ =             ..          .. . . ..            ..
                                                                                          .
                                                                                         
                                                 .           .    . .             .
                            (27×27)                                                      
                                    
                                               0           0 ··· 0           0           
                                                                                          
                                                0           0 ··· 0          Λ``
                                                                            (3×3)

                                                                                            0
                                                                                   0      Q0
From (10) and (11) it follows that the parameters in (12) are given by cQ = cQ0
                                                                             m  , 0    ,
                                                                                   22×1 `c
and                           Q                                   
                                 ρ1 ρ2 ρ3 · · · ρ11 ρ12        0
                              (2×2)                               
                              I2      0 0 ··· 0         0     0 
                                                                  
                              0      I2 0 · · · 0       0     0 
                                                                  
                              .       .. .. . .    ..   ..    .. 
                        ρQ = 
                                 .
                                  .     .  .     .   .    .     . .
                              0
                                      0 0 ··· 0         0     0  
                              0
                                      0   0 · · · I  2  0     0   
                                                                   
                                  0    0 0 ··· 0         0    ρQ
                                                                  
                                                                ``
                                                                                      (3×3)



                                                           55
Ang and Piazzesi used N` = 3 and Ne = 2, assuming that the 1-, 12-, and 60-month yields
were priced without error, while the 3- and 36-month yields were priced with error, so that
the B matrices can be written in partitioned form as
                                                      0 
                              (0)                      b1
                                         (1)
                                                   
                                B1m B1m B1`           b012 
                              (3×2) (3×22) (3×3)       0
                                                             
                              (0)       (1)       =  b 60
                                                             
                                B2m B2m B2`           0 
                                                      b 
                                (2×2) (2×22) (2×3)         3
                                                          0
                                                        b36
                       (1)
where for example B1m are the coefficients relating the observed yields to 11 lags of the 2
macro factors.
   The conditional density for this case is then
                                                     1
                  f (ftm , Yt |Ft−1
                                 m
                                    , Yt−1 ) =             f (ftm , ft` , uet |Ft−1
                                                                                 m     `
                                                                                    , ft−1 , uet−1 )
                                                 | det(J)|

                   f (ftm , ft` , uet |Ft−1
                                         m     `
                                            , ft−1 , uet−1 ) = f (ftm |Ft−1
                                                                         m
                                                                            )f (ft` |ft−1
                                                                                      `
                                                                                          )f (uet )
                                                                                                 0
                f (ftm |Ft−1
                          m
                             ) = φ(ftm ; ρ1 ft−1
                                             m         m
                                                 + ρ2 ft−2                m
                                                           + · · · + ρ12 ft−12 , Σmm Σmm )
                                     f (ft` |ft−1
                                              `
                                                  ) = φ(ft` ; ρ`` ft−1
                                                                   `
                                                                       , IN` )
                                         f (uet ) = φ(uet ; 0, INe )
                                                        h                 i    
                                    −1                        (0)     (1)
                            ft` = B1`     Yt1 − A1 − B1m             B1m Ftm
                                                   h                i                
                       uet = Σ−1e   Yt
                                      2
                                        −  A  2 −       (0)
                                                      B2m B2m
                                                                 (1)
                                                                       F t
                                                                          m
                                                                             − B  f
                                                                                2` t
                                                                                    `

                                                               
                                                     B1` 0
                                           J=                      .
                                                     B2` Σe

Appendix C. Proof of Proposition 1.
Write                                                            
                                                           u x
                                                H=                    .
                                                           v y
Since columns of H have unit length, without loss of generality we can write (u, v) = (cos θ, sin θ)
for some θ ∈ [−π, π]. The second column of H is also a point on the unit circle, for which
orthogonality with the first column also requires it to be located on the line ux + vy = 0, with
the two solutions x = −v, y = u and x = v, y = −u. Thus the set of orthogonal (2 × 2)
matrices can be represented as either rotations
                                                            
                                             cos θ − sin θ
                                  H1 (θ) =                                                  (C.1)
                                             sin θ cos θ



                                                           56
or reflections                                                      
                                                   cos θ sin θ
                                    H2 (θ) =                              .                (C.2)
                                                   sin θ − cos θ
The condition that the (1, 2) element of H1 (θ)ρH1 (θ)0 be zero requires

                               (ρQ     Q                   Q     2
                                 11 − ρ22 ) sin θ cos θ − ρ21 sin θ = 0.

One way this could happen is if sin θ = 0. But this would imply either H1 (−π/2) = −I2 ,
violating the sign requirement Hδ 1 ≥ 0, or else the identity transformationH1 (π/2) = I2 .
Hence the condition of interest is

                                  (ρQ     Q             Q
                                    11 − ρ22 ) cos θ − ρ21 sin θ = 0.                      (C.3)

If θ1 satisfies condition (C.3), then one can show

                                                                ρQ
                                                                             
                                         Q              0        22  0
                                 H1 (θ1 )ρ H1 (θ1 ) =                             .
                                                                ρ21 ρQ
                                                                 Q
                                                                     11

   Alternatively for H2 (θ) we have the requirement

                               (ρQ     Q                   Q     2
                                 11 − ρ22 ) sin θ cos θ + ρ21 sin θ = 0

for which the solution sin θ = 0 would violate H2 (θ)δ 1 ≥ 0, leaving the sole condition

                                  (ρQ     Q             Q
                                    11 − ρ22 ) cos θ + ρ21 sin θ = 0.                      (C.4)

For any θ2 satisfying (C.4),

                                                                 ρQ
                                                                             
                                        Q           0             22  0
                                H2 (θ2 )ρ H2 (θ2 ) =                                  .
                                                                −ρ21 ρQ
                                                                   Q
                                                                      11

   Now consider the nonnegativity condition. Since cot θ is monotonic on (0, π) and repeats
the pattern on (−π, 0), there are two values θ ∈ [−π, π] satisfying (C.3). We denote the first
by θ1 ∈ [0, π], in which case the second is given by θ1 − π. The two solutions to (C.4) can
then be written as −θ1 and −θ1 + π. We are then looking at 4 possible transformations:
                                                                                  ∗ 
                         cos θ1 − sin θ1       δ 11      δ 11 cos θ1 − δ 12 sin θ1        δ 11
        H1 (θ1 )δ 1 =                                =                                  ≡
                         sin θ1 cos θ1         δ 12      δ 11 sin θ1 + δ 12 cos θ1        δ ∗12

                                                                              −δ ∗11
                                                                                 
                                        − cos θ1 sin θ1           δ 11
                    H1 (θ1 − π)δ 1 =                                    =
                                        − sin θ1 − cos θ1         δ 12        −δ ∗12
                                                                     ∗ 
                                        cos θ1 − sin θ1         δ 11         δ 11
                     H2 (−θ1 )δ 1 =                                    =
                                       − sin θ1 − cos θ1        δ 12        −δ ∗12
                                                                            −δ ∗11
                                                                              
                                         − cos θ1 sin θ1       δ 11
                     H2 (−θ1 + π) =                                    =              .
                                          sin θ1 cos θ1        δ 12          δ ∗12

                                                    57
Apart from the knife-edge condition δ ∗11 = 0 or δ ∗12 = 0 (which would require a particular
relation between the elements of the original ρQ and δ 1 ), one and only one of the above four
vectors would have both elements positive, and this matrix produces HρQ H 0 of one of the two
specified forms.
    For N` > 2, one can construct a family of such orthogonal matrices, for example using a
matrix like                                                 
                                           cos θ 0 − sin θ
                               H(θ) =  0        1      0    
                                           sin θ 0 cos θ
for θ satisfying ρQ               Q     Q                                                      Q
                  31 sin θ = (ρ11 − ρ33 ) cos θ, which swaps the (1,1) and (3,3) elements of ρ .
Exactly one of the 4 possible matrices performing this swap will preserve positive Hδ 1 . There
are N` choices for the value one can put into the (1,1) element as a result of such swaps, N` − 1
remaining choices for ρQ  22 , or a total of N` ! permutations.


Appendix D. Proof of Proposition 2.
Consider first rotations H1 (θ) as specified in (C.1). The (1,1) element of Υ = H1 (θ)ρQ [H1 (θ)]0
is seen to be
                      h1 (θ) = ρQ     2       Q     Q                  Q     2
                                11 cos θ − (ρ21 + ρ12 ) cos θ sin θ + ρ22 sin θ.           (D.1)
We claim first that there exists a θ ∈ [0, π/2] such that h1 (θ) equals (ρQ           Q
                                                                               11 + ρ22 )/2. To see
this, note that at θ = 0, the value of h1 (θ) is ρQ 11 , whereas at θ = π/2, it is instead equal to
 Q
ρ22 . Since h1 (θ) is continuous in θ, there exists a value θ1 such that h1 (θ1 ) is exactly halfway
between ρQ           Q
           11 and ρ22 .
     Notice next that the eigenvalues of Υ = HρQ H 0 are identical to those of ρQ , and hence the
trace of Υ (which is the sum of the eigenvalues) is the same as the trace of ρQ :

                                       Υ11 + Υ22 = ρQ     Q
                                                    11 + ρ22 .

Thus since Υ11 = (ρQ         Q                         Q     Q                       Q           0
                       11 + ρ22 )/2, then also Υ22 = (ρ11 + ρ22 )/2. Hence H1 (θ 1 )ρ [H1 (θ 1 )] is of
the desired form with elements along the principal diagonal equal to each other. As in the
proof of Proposition 1, H1 (θ1 − π) is the other rotation that works.
   Alternatively, H could be a reflection matrix H2 (θ) as in (C.2), for which the (1,1) element
of H2 (θ)ρQ [H2 (θ)]0 is found to be:

                           ρQ     2      Q     Q                   Q     2
                            11 cos θ + (ρ21 + ρ12 ) cos θ sin θ + ρ22 sin θ                      (D.2)

This turns out to equal (ρQ           Q
                              11 + ρ22 )/2 at θ 2 = −θ 1 and θ 2 = −θ 1 + π. As in the proof of
Proposition 1, in the absence of knfe-edge conditions on δ 1 , exactly one of the transformations
H1 (θ1 ), H1 (θ1 − π), H2 (−θ1 ), H2 (−θ1 + π) preserves positivity of Hδ 1 , establishing existence.
     For uniqueness, suppose we have found a transformation HρQ H 0 = Υ of the desired form.
Then any alternative transformation H ∗ ρQ H ∗0 can equivalently be written as H̃ΥH̃ 0 for H̃H =
H ∗ . Hence the result will be established if we can show that the only transformations H̃ΥH̃ 0
that keep the diagonal elements equal to each other and also satisfy H̃δ 1 ≥ 0 are the identity
and transposition. Since a = Υ11 = Υ22 and since the transformation preserves eigenvalues,

                                                  58
we know that if the (1,1) and (2,2) elements of H̃ΥH̃ 0 are equal to each other, each must again
be the value a. Thus if H̃ = H1 (θ) for some θ, we require as in (D.1) that

                        a cos2 θ − (Υ21 + Υ12 ) cos θ sin θ + a sin2 θ = a

which can only be true if
                                  (Υ21 + Υ12 ) cos θ sin θ = 0.                               (D.3)
This requires either cos θ = 0, sin θ = 0, or Υ21 = −Υ12 . For cos θ = 0, H1 (θ)δ 1 would
violate the nonnegativity condition, while sin θ = 0 corresponds to H1 (θ) = ±I2 . Finally, if
Υ21 = −Υ12 , one can verify that H1 (θ)Υ[H2 (θ)]0 = Υ for all θ. Alternatively, for reflections
applied to a matrix Υ for which a = Υ11 = Υ22 , we see as in (D.2) that a cos2 θ + (Υ21 +
Υ12 ) cos θ sin θ + a sin2 θ = a, which again can only hold for θ satisfying (D.3). In this case,
sin θ = 0 is ruled out by the constraint H2 (θ)δ 1 ≥ 0, but for cos θ = 0 we have
                                                                        
                                     0 1                           0 −1
                       H2 (π/2) =             and H2 (−π/2) =                .
                                     1 0                          −1 0

Both of these give HΥH 0 = Υ0 but only H2 (π/2)δ 1 > 0. Finally, when Υ21 = −Υ12 , then
H2 (θ)Υ[H2 (θ)]0 = Υ0 for any θ. Thus the only transformation H̃ΥH̃ 0 that preserves equality
of diagonal elements is transposition, as claimed.

Appendix E. Asymptotic standard errors of MLE.
Here we demonstrate that under the usual regularity conditions,
                             "                      #
                               ∂ 2 L(π(θ); Y )
                           E                          = −T Γ0 RΓ
                                    ∂θ∂θ0      θ=θ0


for                                          "          #
                                           ∂π(θ)
                                    Γ=
                                             ∂θ0 θ=θ0
                                           "                #
                                               2
                                             ∂   L(π; Y )
                               R = −T −1 E                    .
                                                ∂π∂π 0 π=π0
Note
                                                                      ∂π 1         ∂π 1
                                                                                         
                                                                      ∂θ1
                                                                             ···   ∂θN
                   ∂L(π(θ); Y ) h    ∂L(π)            ∂L(π)
                                                              i
                                                                   ..        ..    ..
                               =             ···
                                                                                          
                                                                   .          .     .
                      ∂θ0             ∂π 1             ∂π q                               
                                                                      ∂π q         ∂π q
                                                                      ∂θ1
                                                                             ···   ∂θN




                                                 59
                                                                                                 
                                                                 ∂ 2 L(π)            ∂ 2 L(π)             ∂π 1           ∂π 1
                                                                                                                                 
                                                                 ∂π 1 ∂π 1
                                                                              ···    ∂π 1 ∂π q            ∂θ1
                                                                                                                   ···   ∂θN
         2
        ∂ L(π(θ); Y )           h
                                    ∂π 1          ∂π q
                                                         i
                                                                      ..       ..          ..      .
                                                                                                    ..            ..      ..
                      =                    ···                                                                                    (E.1)
                                                                                                                                 
                                                                      .        .           .                        .       .
           ∂θi ∂θ0                  ∂θi           ∂θi     
                                                                 ∂ 2 L(π)            ∂ 2 L(π)
                                                                                                  
                                                                                                          ∂π q           ∂π q
                                                                 ∂π q ∂π 1
                                                                              ···    ∂π q ∂π q            ∂θ1
                                                                                                                   ···   ∂θN
                                                                            ∂ 2 π1               ∂ 2 π1
                                                                                                         
                                                                           ∂θ1 ∂θi
                                                                                     ···        ∂θN ∂θi
                                                                              ..      ..           ..
                                    h                             i
                                        ∂L(π)            ∂L(π)
                                +                ···                                                      .
                                                                                                         
                                         ∂π 1             ∂π q                .       .            .
                                                                            ∂ 2 πq               ∂ 2 πq
                                                                           ∂θ1 ∂θi
                                                                                     ···        ∂θN ∂θi

Evaluate (E.1) at θ = θ0 , take expectations with respect to the distribution of Y, and use the
fact that Γ is not a function of Y :
                                                      2                                                  
                                                          ∂ L(π)                    ∂ 2 L(π)
                                                                              · · ·
                                                      ∂π1 ∂π1 π=π0                 ∂π 1 ∂π q
               "                         #
                                                                                               π=π 0 
                 ∂ 2 L(π(θ); Y )               0 0                .             .            .
            E                0              = ei Γ E 
                                                                 .
                                                                  .             .
                                                                                .            .
                                                                                             .            Γ
                                                                                                          
                                                                                                                   (E.2)
                      ∂θi ∂θ        θ=θ0              2                                                  
                                                          ∂ L(π)                    ∂ 2 L(π)
                                                          ∂π q ∂π 1
                                                                              · · · ∂πq ∂πq
                                                                    π=π                        π=π 0
                                                                 20                                            
                                                                      ∂ π1                      ∂ 2 π1
                                                                                     · · · ∂θN ∂θi
                                                           io  ∂θ1 ∂θi θ=θ0                               θ=θ0 
                                                                           ..           ..             ..
               n h
                       ∂L(π)                 ∂L(π)
            + E                       · · ·                     
                                                                                                                .
                                                                                                                
                        ∂π 1                  ∂π q
                                                                 2 .                    .              .
                                                                
                               π=π 0                π=π 0
                                                                                                  2
                                                                                                                
                                                                      ∂ πq                      ∂ πq
                                                                     ∂θ1 ∂θi
                                                                                     · ·   ·   ∂θN ∂θi
                                                                                      θ=θ0                           θ=θ0
                                              
But the usual regularity conditions imply E ∂L(π)/∂π j |π=π0 = 0, so the second term in
(E.2) vanishes. Stacking the row vectors represented by the first term into a matrix produces
                                             2                                    
                                               ∂ L(π)             ∂ 2 L(π)
                                                           · ·  ·
                                             ∂π1 ∂π1 π=π0        ∂π 1 ∂π q
               "                      #
                                                                             π=π 0 
                 ∂ 2 L(π(θ); Y )          0            .     .            .
             E             0            =ΓE
                                                      ..    ..           ..       Γ
                                                                                   
                      ∂θ∂θ       θ=θ0        2                     2
                                                                                   
                                               ∂ L(π)             ∂ L(π)
                                               ∂π q ∂π 1
                                                           · ·  · ∂π q ∂π q
                                                                             π=π 0                         π=π 0

as claimed.




                                                              60
                 True values           Global maximum              Local 53
   cQ       0.0407 0.0135 0.5477 0.0416 0.0085 0.5316 -0.5562 0.0204           0.0527
   ρQ       0.9991        0       0 0.9985        0       0 0.9986        0         0
            0.0101 0.9317         0 0.0116 0.9328         0 0.0113 0.9316           0
            0.0289 0.2548 0.7062 0.0219 0.2500 0.7202 0.0203 0.2438            0.7352
    ρ       0.9812 0.0069 0.0607 0.9696 0.0141 0.0671 0.9794 0.0063            0.0840
           -0.0010 0.8615 0.1049 -0.0027 0.8533 0.1175 -0.0028 0.8380          0.1267
            0.0164 0.1856 0.6867 0.0085 0.1985 0.6993 0.0333 0.1923            0.7202
    δ0      0.0046                   0.0046                  0.1344
    δ1   1.729E-4 1.803E-4 4.441E-4 1.71E-4 1.71E-4 4.45E-4 1.72E-4 1.59E-4   4.54E-4
   Σe    9.149E-5                  9.105E-5                9.110E-5
eig(ρ)      0.9879 0.9341 0.6074 0.9734 0.9448 0.6040         1.000 0.9306     0.6070
  LLF                               28110.4                 28096.5

Table 1: Parameter values used for simulation and estimates associated with (1) the global
maximum and (2) a representative point of local convergence.
 VAR         No. of        Σe         ρQ       δ1     ρ     cQ   δ0
 parameter   elements      Ne    N` (N` + 1)/2 N`     N`2   N`   1
 Ω∗2         Ne            X
 φ∗21        N` Ne                     X
 Ω∗1         N` (N` + 1)/2             X         X
 φ∗11        N`2                       X         X    X
 A∗2         Ne                        X         X          X    X
 A∗1         N`                        X         X    X     X    X
Table 2: Mapping between structural and reduced-form parameters for the latent factor model.
VAR         No. of        Σe     Σmm         ρQ δ 1 ρm` ρmm ρ`` ρ`m δ 0 cQ cm c`
parameter   elements      Ne Nm (Nm + 1)/2   Nf2 Nf Nm N` Nm
                                                           2
                                                             N`2 N` Nm 1 Nm Nm N`
Ω∗2         Ne            X
Ω∗m         Nm (Nm + 1)/2         X
ψ ∗1m       N` Nm                            X   X
φ∗2m        Ne Nm                            X   X
φ∗21        Ne N`                            X   X
Ω∗1         N` (N` + 1)/2                    X   X
φ∗m1        Nm N`                            X   X   X
φ∗mm        Nm2
                                             X   X   X   X
φ∗11        N`2                              X   X           X
φ∗1m        N` Nm                            X   X           X   X
A∗2         Ne                    X          X   X                   X X
A∗m         Nm                    X          X   X   X               X X X
A∗1         N`                    X          X   X           X       X X   X
 Table 3: Mapping between structural and reduced-form parameters for the MF1 model.
VAR         No. of     Σe   Σmm   ρ1,...,12   Λmm   δ 1m   ρ``   Λ``   δ 1`   δ0   λ
parameter   elements   2     3      48         4      2     6     9     3     1    5
Ω∗2         2          X
Ω∗m         3               X
φ∗mm        48                       X
ψ ∗1m       6                        X        X     X
φ∗21        6                                              X     X     X
Ω∗1         6                                              X     X     X
φ∗11        9                                              X     X     X
φ∗2m        48                       X        X     X      X     X     X
φ∗1m        72                       X        X     X      X     X     X
A∗2         2               X        X        X     X      X     X     X      X    X
A∗1         3               X        X        X     X      X     X     X      X    X
Table 4: Mapping between structural and reduced-form parameters for the MF12 model.
     Estimated Q representation parameters Implied λ    representation parameters
cQ      0.0407    0.0135         0.5477   λ −0.0407      −0.0135      −0.5477
       [0.0063]  [0.0399]       [0.1194]    [0.0063]     [0.0399]     [0.1194]
       (0.0062)  (0.0378)       (0.1073)
ρQ      0.9991       0              0     Λ −0.0178       0.0069        0.0607
       [0.0005]                             [0.0109]     [0.0231]      [0.0303]
       (0.0004)
        0.0101    0.9317            0       −0.0111      −0.0701        0.1049
       [0.0033]  [0.0050]                   [0.0102]     [0.0323]      [0.0331]
       (0.0032)  (0.0046)
        0.0289    0.2548         0.7062     −0.0125      −0.0693      −0.0195
       [0.0193]  [0.0206]       [0.0507]    [0.0090]     [0.0354]     [0.0449]
       (0.0185)  (0.0172)       (0.0439)
 ρ      0.9812    0.0069         0.0607
       [0.0110]  [0.0231]       [0.0303]
       (0.0067)  (0.0226)       (0.0294)
       −0.0010    0.8615         0.1049
       [0.0113]  [0.0343]       [0.0331]
       (0.0094)  (0.0309)       (0.0318)
        0.0164    0.1856         0.6867
       [0.0187]  [0.0289]       [0.0353]
       (0.0174)  (0.0277)       (0.0350)
δ0      0.0046
       [0.0011]
       (0.0011)
δ1    1.729E-4 1.803E-4        4.441E-4
      [2.31E-5] [3.80E-5]      [1.75E-5]
      (2.28E-5) (3.74E-5)      (1.62E-5)
Σe    9.149E-5
      [2.81E-6]
      (2.70E-6)

Table 5: FIML estimates with small-sample standard errors (in square brackets) and asymp-
totic standard errors (in parentheses) for latent factor model fit to Ang and Piazzesi (2003)
data set.
 cQ        0.0306 −0.0458                 0           0           0
           (0.5291)   (1.1382)
     c   −0.1028       0.2414 −0.9632 −1.5301              2.4063
          (0.4951)     (0.4672)   (7.2480)    (1.4128)     (4.4009)
     Q
 ρ         0.7725      0.2933      0.0436 −0.2138 −0.3565
           (0.2895)    (0.2801)    (1.0688)   (0.1332)    (0.3900)
         −0.3933       1.2411      0.2376 −0.0197 −0.0574
          (0.3857)     (0.3706)    (0.2437)   (0.1470)    (0.5579)
           0.2036 −0.2046          0.8579             0           0
           (0.3691)   (0.3852)     (0.1435)
         −0.1035       0.1035 −0.0054          0.8826 −0.1926
          (0.2083)     (0.2373)   (0.5723)     (0.0672)   (0.1464)
           0.1001 −0.1415          0.0223      0.0303      0.8826
           (0.6387)   (0.6661)     (0.1215)    (0.0810)    (0.0672)
     ρ     0.9461      0.2203 −0.0428 −0.0210              0.0639
           (0.0325)    (0.0508)   (0.2005)    (0.0456)     (0.1531)
           0.0002      0.8735 −0.0435 −0.0233 −0.0517
           (0.0310)    (0.0487)   (0.1618)    (0.0538)    (0.1555)
           0.0932      0.1683      0.8203 −0.0844          0.1378
           (0.3903)    (0.1686)    (0.6723)   (0.2453)     (1.0303)
         −0.0827       0.0852 −0.1110          0.8715      0.0978
          (0.1190)     (0.1295)   (0.3430)     (0.1127)    (0.2066)
           0.1220      0.0449      0.0756      0.0555      0.4728
           (0.2649)    (0.5693)    (1.0167)    (0.1468)    (0.7418)
 δ0      −0.0082
          (0.0062)
 δ1       6.86E-4     1.02E-3     2.03E-3     1.92E-4     7.67E-4
          (2.88E-4)   (3.03E-4)   (2.35E-3)   (1.33E-3)   (6.31E-3)
 Σe       2.02E-4     1.87E-4     1.09E-4
          (1.29E-5)   (1.19E-5)   (6.97E-6)
Σmm        0.6996             0
           (0.0448)
           0.1174      0.6617
           (0.0604)    (0.0424)

         Table 6: FIML estimates and asymptotic standard errors for the MF1 model.
                        Global                     Local1                     Local2
       ρ``       0.9921       0        0 0.9918          0        0 0.9920          0        0
                      0 0.9462         0         0 0.9412         0        0 0.9437          0
                      0 -0.0034 0.9021           0 -0.0095 0.7712          0 -0.0032 0.9401
       δ 1`   1.11E-04 4.27E-04 1.98E-04 1.09E-04 4.30E-04 1.92E-04 1.22E-04 4.26E-04 1.92E-04
        λ`      -0.0409       0        0 -0.0441         0        0 -0.0388         0        0
     Λmm         2.8783 0.4303             -0.3430 0.1474             1.5633 0.1341
                -6.1474 -0.8744             1.7675 -0.0607           16.0624 7.4290
       Λ``      -0.0048       0        0 -0.0045         0        0 -0.0056         0        0
                -0.0445       0 0.2910 -0.0474           0 0.2881 -0.0423           0 0.3000
                -0.0322       0 0.3687 -0.0331           0 0.2110 -0.0299           0 0.4120
       χ2        462.15                     530.69                    503.10
     LLF          20703                      20668                     20679
Frequency            14                         84                         2
Table 7: Three local minima for the chi-square objective function for the restricted MF12
specification.
