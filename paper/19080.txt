                                NBER WORKING PAPER SERIES




                 PARTISAN BIAS IN FACTUAL BELIEFS ABOUT POLITICS

                                           John G. Bullock
                                            Alan S. Gerber
                                             Seth J. Hill
                                          Gregory A. Huber

                                        Working Paper 19080
                                http://www.nber.org/papers/w19080


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                      May 2013




The views expressed herein are those of the authors and do not necessarily reflect the views of the
National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2013 by John G. Bullock, Alan S. Gerber, Seth J. Hill, and Gregory A. Huber. All rights reserved.
Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided
that full credit, including © notice, is given to the source.
Partisan Bias in Factual Beliefs about Politics
John G. Bullock, Alan S. Gerber, Seth J. Hill, and Gregory A. Huber
NBER Working Paper No. 19080
May 2013
JEL No. H0,H1

                                              ABSTRACT

Partisanship seems to affect factual beliefs about politics. For example, Republicans are more likely
than Democrats to say that the deficit rose during the Clinton administration; Democrats are more
likely to say that inflation rose under Reagan. We investigate whether such patterns reflect differing
beliefs among partisans or instead reflect a desire to praise one party or criticize another. We develop
a model of partisan survey response and report two experiments that are based on the model. The experiments
show that small payments for correct and “don't know” responses sharply diminish the gap between
Democrats and Republicans in responses to “partisan” factual questions. The results suggest that the
apparent differences in factual beliefs between members of different parties may be more illusory
than real.


John G. Bullock                                      Seth J. Hill
Institution for Social and Policy Studies            University of California, San Diego
Yale University                                      Department of Political Science
PO Box 208209                                        9500 Gilman Drive, #0521
New Haven, CT 06520-8209                             La Jolla, CA 92093
john.bullock@aya.yale.edu                            sjhill@ucsd.edu

Alan S. Gerber                                       Gregory A. Huber
Yale University                                      Yale University
Institution for Social and Policy Studies            Institution for Social and Policy Studies
77 Prospect Street                                   77 Prospect Street
New Haven, CT 06520                                  New Haven, CT 06520
and NBER                                             gregory.huber@yale.edu
alan.gerber@yale.edu
A persistent pattern in American public opinion is the presence of large differences between Democrats

and Republicans in stated attitudes about factual matters. For example, in 2010, Harris Interactive

surveyed U.S. adults to determine their beliefs about whether Barack Obama was born in the United

States. Forty-five percent of Republicans stated that he was born abroad, compared to only eight percent

of Democrats (Harris Interactive 2010). This partisan divide appears in many other surveys and on other

topics, e.g., whether weapons of mass destruction had been found in Iraq (Harris Interactive 2006; see

also Duelfer 2004). Partisan divisions would be expected for questions about political attitudes or tastes,

but they extend even to evaluations of economic trends during a president’s tenure (Bartels 2002,

133-38).

        Systematic partisan differences in responses to factual questions about politics are not mere

curiosities. Some of the strongest defenses of democracy rest on theories of retrospective voting: even if

voters know little, these theories maintain, they can administer “rough justice” by rewarding or punishing

incumbents for things that have happened during their terms (Fiorina 1981, 4). But partisan differences in

responses to factual questions call into question voters’ abilities to vote retrospectively (see also Healy

and Malhotra 2009). And partisan bias in voters’ memories of incumbent performance may give

incumbents weaker incentives to seek true improvements in voter welfare.

        More generally, both recent and classic research supports the notion that partisanship has a

powerful influence on attitudes and behaviors (e.g., Gerber, Huber, Washington 2010; Campbell et al.

1960). In light of this tradition, it is not surprising that scholars often take survey respondents’ statements

of beliefs at face value (e.g., Bartels 2002; Shapiro and Bloch-Elkon 2008; Jerit and Barabas 2012). If

partisanship is a “perceptual screen,” partisan differences in factual beliefs are a natural consequence of

the influence of partisanship on information acquisition and processing. This paper, however, considers a

distinct alternative: partisan differences in survey responses may not solely indicate differences in true

beliefs. Instead, they may also reflect the expressive value of offering survey responses that portray one’s

party in a favorable light. A partisan pattern of survey response follows when this expressive value

outweighs the utility that survey respondents would receive from stating their sincere beliefs. Partisan


                                                       3
divergence may therefore reflect the joy of partisan “cheerleading” rather than sincere differences in

beliefs about the truth. Despite the reality that survey respondents have limited incentives to respond

accurately to survey questions, almost no research has attempted to determine the extent to which partisan

divergence in responses to factual questions with partisan implications reflects sincere beliefs.

        This paper reports results from two novel experiments designed to distinguish sincere from

expressive partisan differences in responses to factual questions. In both experiments, all subjects were

asked factual questions, but some were given financial incentives to answer correctly. In both

experiments, we find that the incentives reduce partisan divergence substantially—on average, by about

55% and 60% across all of the questions for which partisan gaps appear when subjects are not

incentivized. But offering an incentive for accurate responses will not deter cheerleading among those

who are unsure of the correct factual response, because such people stand to gain little by forgoing it. In

our second experiment, we therefore implement a treatment in which subjects were offered incentives

both for correct responses and for admitting that they did not know the correct response. We find that

partisan gaps are even smaller in this condition—about 80% smaller than for unincentivized responses.

This finding suggests that partisan divergence is driven by both expressive behavior and by respondents’

knowledge that they do not actually know the correct answers.

        These results have important implications for our understanding of public opinion. Most

importantly, they call into question the claim that partisan divergence in beliefs about factual questions is

ground for concern about voters’ abilities to hold incumbents accountable for their performance. Partisans

may disagree in surveys, but we should not take these differences at face value. 1

        These results may also affect our understanding of partisan polarization in the mass electorate. At

least in the realm of factual evaluations, partisan differences exist, but our results suggest that they are not

as large as naïve analysis of survey data suggests. Just as people enjoy rooting for their favorite sports

team and arguing that their team’s players are superior, even when they are not, surveys give citizens an

1
 These results also have implications for the literature on economic voting, because our results confirm
concerns (e.g., Ansolabehere, Meredith, and Snowberg 2013) that survey reports of economic conditions
may be contaminated by expressive partisan responding.

                                                       4
opportunity to cheer for their partisan team (Green, Palmquist, and Schickler 2002). Deep down,

however, individuals understand the true merits of different teams and players—or, at the minimum, they

understand that they don’t know enough to support their expressive responding as correct.

        Our work also has important methodological implications. In particular, how should one interpret

experiments that show partisan cues increase partisan divisions in survey response? Such results are

commonly taken to show that partisanship affects attitudes. Our results suggest, however, that partisan

cues may merely remind participants about the expressive utility that they gain from offering partisan-

friendly survey responses. A key task for researchers is thus to understand when survey responses reflect

real attitudes and when they reflect these more expressive tendencies. Such an understanding is essential

if survey attitudes are used to explain vote choices or other salient political outcomes, a topic we take up

in the conclusion.

        The remainder of this paper proceeds as follows. We begin by reviewing prior theory and

evidence about partisan response patterns in answers to factual questions. We then present a model of

survey response that incorporates the possibility of expressive benefits to offering partisan responses. This

model informs the design of our two experiments, which we present in the next sections. The final section

considers the implications of our results and avenues for future research.



THEORY AND PRIOR EVIDENCE
Prior research documents partisan differences in expressed factual beliefs (e.g., Jerit and Barabas 2012;

Gaines et al. 2007; Jacobson 2006), and some of it focuses on differences in evaluations of retrospective

economic conditions (e.g., Conover, Feldman, and Knight 1986, 1987; Bartels 2002, 133-38). 2 Many of

these partisan gaps arise because members of one party issue retrospective economic assessments that

deviate starkly from objective conditions. For example, despite the large improvement in unemployment

and inflation during Ronald Reagan’s presidency, Bartels (2002) shows that, in 1988, Democrats were

more likely than Republicans to incorrectly report that unemployment and inflation had increased since

2
  A related but distinct literature concerns partisan differences in responses to non-factual questions (e.g.,
is the president evil?) or to questions whose answers are not readily observable (see, e.g., Berinsky 2012).

                                                      5
1980. This pattern was reversed in 2000, at the end of the Clinton presidency, when Republicans were

more likely to offer negative retrospective evaluations. 3

          The key question is how to interpret these partisan gaps. Bartels presents the common view when

he argues that partisans likely believe their divergent assessments: “Absent some complicated just-so

story involving stark differences in the meaning of ‘unemployment’ and inflation…among Democrats and

Republicans, these large differences can only be interpreted as evidence of partisan biases in perceptions”

(Bartels 2002, 136-37). An alternative view is that differences in survey responses are the result of a

combination of motivations. Individuals may express responses consistent with their partisanship not

because they believe those responses, but because doing so gives them opportunity to support their

“team” (e.g., Gerber and Huber 2010; Green, Schickler, and Palmquist 2002).

          Of course, many social scientists have wrestled with the problem of insincere survey responses

(e.g., Berinsky 2005; Kuklinski, Cobb, and Gilens 1997; Noelle-Neumann 1993). But they typically focus

on responses to sensitive topics (e.g., race) rather than on problems that may be caused by “expressive

benefits” in survey response. 4 And the methods used to overcome problems associated with responses to

sensitive topics—for example, “list experiments” (Kuklinski, Cobb, and Gilens 1997)—may not apply to

the problem of eliciting sincere responses when people derive expressive benefits from answering

insincerely.

          Instead, researchers have long turned to incentives to induce honest responses or rational

behavior. In a review of experiments involving incentives, Morton and Williams (2010, 358-61) argue

that incentives often reduce the size and frequency of decision-making errors. But almost all of the studies

that they review are apolitical and do not involve tests of factual knowledge. Prior and Lupia (2008) do


3
  Additional work examines conditions that can exacerbate apparent partisan gaps. Asking political
questions prior to economic ones increases the correlation between partisanship and subjective economic
evaluations (Lau, Sears, and Jessor 1990; Palmer and Duch 2001; Sears and Lau 1983; Wilcox and
Wlezien 1993), and partisan gaps are larger when elections are more salient (Lavine, Johnston, and
Steenbergen 2012, ch. 4; see also Stroud 2008). What is unclear in this work, however, is how to interpret
these patterns. Do circumstances that make partisanship more salient provide factual information to
survey respondents or do they simply increase the expressive value of partisan responses?
4
    An exception to this characterization is the literature on economic voting discussed above.

                                                       6
study the effects of financial incentives on responses to factual questions about politics, and they find that

the effects of offering incentives are real but weak. 5 However, they do not examine the effects of

incentives on partisan patterns in responding.

        To date, only one study has examined the effects of incentives on partisan response patterns to

factual questions about politics: Prior (2007). Subjects in the study were asked 14 questions about

politics; some were assigned at random to receive $1 for each correct answer. The results were mixed, but

they suggest that $1 incentives can reduce party differences in responses to such questions. 6 One

unanswered question in that work, however, is how respondents who do not know the correct answers

should be expected to behave in the presence and absence of incentives. It may be, for example, that

partisan responses are insincere, but that respondents continue to offer them when given incentives to

provide a correct response because they do not know what other answer might be correct.

        To address these questions, we present a model of survey response that incorporates the

possibility that individuals (a) receive utility from offering partisan-tinged responses and (b) differ in their

underlying knowledge of the truth. We use this model to understand the effect of incentives on a

respondent’s tendency to answer questions in a manner that reflects either her partisan affinity or her

sincere beliefs about the truth. We also show that our model can be used to understand the proportion of

partisan differences that arise because individuals are uncertain about the truth.



A THEORY OF EXPRESSIVE SURVEY RESPONSE
To understand the role that expressive survey response plays in the partisan polarization of survey

responses, and to motivate our experimental design, we present a model of survey response in the

presence and absence of financial incentives. Our objective is to provide intuitions about how sincere


5
  All subjects in the Prior and Lupia (2008) study were asked 14 factual questions about politics. Subjects
in a control condition averaged 4.5 correct answers, while those who were paid $1 for each correct answer
averaged 5.0 correct answers (Prior and Lupia 2008, 175).
6
  Incentives reduced partisan gaps in responses to four items. Results on a fifth item were mixed. Results
were null for two other items. There was no partisan gap in the control group for three further items, and
results for the remaining four items were not reported.

                                                       7
differences in beliefs about the truth, the expressive value of partisan responding, and incentives may

interact to shape polarization in survey responses. The model allows us to clarify expectations about our

experimental findings. As in our experimental design, financial incentives in the model take two forms:

Respondents may be paid for offering a correct response or for admitting that they “don’t know” the

correct answer.

        We begin by focusing on incentives for a correct response. Our model shows that incentives

allow us to assess the degree to which partisan divergence arises because people simultaneously

(1) understand that they would otherwise provide inaccurate partisan responses, (2) give low value to this

“cheerleading” relative to the size of the offered incentive, and (3) maintain strong beliefs about the

correct answer that are common to members of both parties. Under these conditions, a surveyor can

reduce partisan divergence by offering incentives for correct responses.

        A consequential aspect of our models is the third condition: a shared bipartisan belief about the

truth. Holding all else constant, if members of different parties have different beliefs about the truth, then

financial incentives will not cause their survey responses to converge. This, of course, is what most

existing research assumes is true: that partisan differences in factual beliefs are sincere. Alternatively,

however, competing partisans may not differ in their beliefs about the truth, but they may still be

uncertain enough about the truth that a reward will not cause them to deviate from their partisan-tinged

response. Put another way, if I’m being paid for a correct response but I believe that my preferred partisan

response is as likely to be correct as any other (i.e., I am completely uniformed), then my expected utility

is maximized by continuing to offer the response that gives me the most expressive partisan utility.

        In light of this ambiguity, we extend the model by incorporating incentives for admitting one’s

lack of knowledge. When respondents are offered incentives for both correct and “don’t know” answers,

our analysis shows that the proportion of respondents choosing “don’t know” is increasing in the

proportion of respondents who (1) give low value to partisan cheerleading relative to the size of the

incentive for choosing “don’t know,” and (2) have sufficiently weak beliefs about the truth that they are

better off choosing “don’t know” than any other option. Overall, incentives for “don’t know” responses


                                                       8
allow us to estimate the proportion of partisan divergence that arises because respondents know that they

don’t know the truth and instead offer expressive partisan responses in the absence of incentives for

choosing “don’t know.”


Basic Model
We begin with a model in which respondents derive utility from their survey responses in three ways: by

offering answers that cast their party in a favorable light, by expressing their sincere beliefs, and by

earning financial rewards. For now, we set aside the possibility that people can choose to say “don’t

know.” For simplicity, we focus on the case in which there are two survey responses, r1 and r2.

Individuals, indexed by the subscript i, are either Democrats (T = D) or Republicans (T = R). Individuals

differ in their taste for partisan cheerleading and their beliefs about the truth.

        Turning first to expressive benefits, individual i’s taste for partisan cheerleading is denoted by the

parameter ci, for cheerleading, which ranges from 0 (no taste for it) to any positive number. Beliefs about

the truth are described by the function pi(rj), which is the probability that i believes response rj, j = 1 or 2,

is correct. In this example, we assume that response r1 portrays Democrats most favorably, that response

r2 portrays Republicans most favorably, and that these assumptions are shared by respondents from both

parties. Specifically, the expressive function e(T, rj) maps an individual’s partisanship T to the personal

benefit of offering response rj, and is defined as e(T = D, r1) = e(T = R, r2) =1 and e(T = D, r2) =

e(T = R, r1) = 0. That is, Democrats and Republicans receive an expressive partisan utility boost from

offering the response that portrays their party in a favorable light, and they receive no partisan utility from

offering the response that is inconsistent with their partisan leanings.

        The utility associated with providing a sincere response is measured by the “honesty” function

hi(rj). For simplicity, we assume hi(rj) = pi(rj), i.e., the honesty value of offering response rj is the

probability that the respondent believes it is true. Finally, some respondents may also receive an

incentive, I > 0, which is the additional reward for a correct response. We assume utility is linear in I.

        These assumptions allow us to describe a respondent’s expected utility for offering response rj as

the sum of three terms. We omit the individual subscript i for clarity:

                                                         9
        (1) EU(rj|.) = h(rj) + I × p(rj) + c × e(T,rj).

The first term is simply the honesty value of response rj. The second term is the additional value of

providing response j in the presence of incentive I (realized with the probability that response is correct).

The third term is the partisan value of offering response rj weighted by the respondent’s value of

expressive partisan responding, c. Using the assumption that h() is equivalent to p(), we rewrite (1) as:

        (2) EU(rj|.) = (1+I) × p(rj) + c × e(T,rj),

which is the form of the expected utility we focus on here. A respondent will offer the response rj from

(r1,r2) that maximizes (2).

        To make the exposition as clear as possible, we suppose that the respondent is a Democrat

(T = D). The analysis for the Republican partisan mirrors that for the Democratic partisan and is omitted.

Recall that r1 is the partisan Democratic response, and so e(D, r1) = 1 and e(D, r2) = 0.

        First, consider how our model predicts that partisans will respond to a survey in the absence of

incentives for correct responses. In this case, equation (2) reduces to

        (3) EU(rj|.) = p(rj) + c × e(T,rj).

        Using (3), the utility from reporting response r1 is p(r1) + c, and the utility from reporting r2 is

p(r2) = 1 – p(r1). Therefore the Democrat will report r1 whenever c ≥ c* = 1– 2p(r1).

        As c is weakly positive, whenever p(r1) > .5 (that is, the Democrat believes response r1 is at least

as likely to be correct as r2), the Democrat will offer the partisan response r1 even in the absence of

expressive returns (i.e., even if c = 0). By contrast, as p(r1) grows small (i.e., as the Democrat becomes

increasingly likely to believe the pro-Republican response is correct), larger values of c are required to

cause her to offer r1. To produce a response of r1, the partisan expressive return must be larger to offset

the greater cost of providing an answer that is likely to be untrue.

        This relationship is displayed graphically in Panel A of Figure 1, which shows that for each value

of p(r1) there is a value of expressive partisan responding such that, for those Democrats with c at least

this large, r1 will be their survey response. Democrats offering r1 are therefore composed of two groups.

The first group consists of those who believe that r1 is more likely to be correct than r2; this group is


                                                          10
represented by the right-hand side of the panel, for which p(r1) > .5. The second group consists of those

who believe that r2 is more likely to be correct, but for whom that belief is offset by a larger return from

offering an expressive partisan response. This group is represented by the upper segment of the left-hand

side of the panel, which is labeled “insincere choice of r1.”

        To link expressive returns to polarization of partisan responses, consider Panels B and C. Panel B

shows the response pattern for Republicans, which is a mirror image of Panel A. And Panel C displays

both partisan response patterns at once. It shows that in the presence of expressive returns, Democrats and

Republicans who share common beliefs about the truth (are at the same position on the horizontal axis)

can nonetheless offer polarized survey responses if their value of expressive partisan responding is large

enough. When beliefs about the truth are shared, polarization is most prevalent when beliefs are most

uncertain, i.e., when p(r1) = p(r2) =.5. Polarization will also arise, even in the absence of returns to

expressive partisan responding (i.e., when c = 0), if Democrats and Republicans hold different beliefs

about the truth.

        We next consider what happens when incentives are offered for correct responses, i.e., when

I > 0. From equation (2), for a given value of I, there is a unique c*’= (1+I)(1 – 2p(r1)) such that all

Democrats with an expressive responding parameter greater than c*’ will offer r1. As before, incentives

have no effect on the responses of Democrats who believe that response r1 is correct (i.e., p(r1) > .5). But

for Democrats who believe response r2 is more likely to be correct, a larger return to cheerleading is now

required to offset the earnings that are likely to be lost by offering response r1. Formally, c*’ = c* + (I ×

(1 – 2p(r1)). This relationship is shown in Panel A of Figure 2. (For simplicity, we assume throughout

Figure 2 that I = 1.)

        Comparison of Panel A in Figure 1 and Panel A in Figure 2 draws out a basic but important

result: incentives for correct responses reduce expressive partisan responding by causing some of those

who know that response r1 is less likely to be true to offer response r2 instead. In Figure 2, these

respondents are represented by the region that is labeled “induced choice of r2.”

        Figure 2 draws out a second important result: when a Democrat believes that r2 is more likely to


                                                       11
be correct, the additional value of expressive returns (c) that is required to make her offer response r1

increases in her belief that r2 is correct. Formally, c*’ – c* is increasing in p(r2). To see this result

graphically, note that the vertical gap between the dashed and solid lines increases as one approaches the

left side of the x-axis. This gap increases because the difference between c*’ and c* is a function of p(r1).

In other words, for those who are more uncertain (p(r1) is closer to .5), incentives have smaller effects. At

the extreme, an individual who believes that r1 and r2 are equally likely to be true—that is, she knows that

she doesn’t know the truth—continues to offer r1 regardless of incentives for correct responses because

she won’t (in expectation) do better by giving up the certain benefit of a partisan response.

         To illustrate the effect of incentives on polarization, Panel B of Figure 2 shows the effect of

incentives for Republican partisans, and Panel C displays both partisan response patterns at once.

Comparison of Panel C in Figure 1 to Panel C in Figure 2 shows that increasing incentives decreases

polarization. In particular, incentives reduce the frequency with which Democrats and Republicans who

share common beliefs about the truth offer different survey responses, apart from the case in which

p(r1) = p(r2) = .5.

         This exposition leads us to two conclusions. First, incentives for correct answers reduce partisan

divergence in the presence of shared beliefs about the truth. Second, partisan divergence may persist in

the face of incentives. It is clear that if partisan groups have different sincere beliefs about which response

is most likely to be true, paying respondents for correct responses will not reduce polarization. However,

although it may seem intuitive that persistent partisan divergence in the presence of incentives for correct

responses implies underlying differences in beliefs about the truth, our analysis suggests partisan

divergence may nonetheless persist for two other reasons. First, the taste for expressive partisan

cheerleading (c) may be large. Second, even if that taste is small, individuals may be uncertain about the

truth. In that case, they will offer partisan responses even in the face of large incentives for correct

responding.

         We have considered respondents who must provide either a partisan-consistent or a partisan-

inconsistent response. But giving respondents the option to decline to provide a response may reduce


                                                        12
observed polarization. To explore this possibility, we consider a model with an additional response

option: “don’t know.”


Incorporating “Don’t Know” Responses

To incorporate a “don’t know” response option, we must specify the utility that a respondent receives

from selecting “don’t know.” For simplicity, we assume that a “don’t know” response (rdk) yields some

fixed positive psychological benefit Vdk > 0 plus whatever financial incentive is offered for giving that

response (Idk). Specified this way, U(rdk) = Vdk + Idk. One can think of Vdk as the honesty value of

choosing “don’t know” relative to an incorrect response. As before, the individual is offered an incentive I

for providing a correct response.

        When will a respondent choose “don’t know”? Note that the value of “don’t know” is unaffected

by c or p(), so a respondent chooses “don’t know” when the values of c and p() make both r1 and r2 less

attractive than “don’t know.” Recall from the previous analysis (illustrated in Panel A of Figure 2) that a

Democrat’s selection of r1 or r2 depends on whether c is greater or less than c*’ = (1+I)(1 –2p(r1)).

        Consider first a Democrat who would otherwise choose the “Republican” response, r2. Her

expected utility for choosing this response is (1+I) × (1 – p(r1)). This utility is greater than the utility

associated with selecting “don’t know” when p(r1) < p*(r1) = 1 – (Vdk + Idk) / (1+I). This p*(r1) is the

lowest probability that the Democratic response (r1) is correct for which the Democrat will select “don’t

know” rather than the Republican response. When p(r1) is below this critical value, the Democrat prefers

to report the Republican response. Note that this critical value of p*(r1) is unaffected by the expressive

value of partisan responding c, because the return to r2 is unaffected by c.

        Figure 3 illustrates this logic. For presentation, we assume that I = 1, Idk = .75, and Vdk = .5. 7 The

value of p*(r1) is thus 1 – (.5 + .75) / (1 + 1) = .375. Graphically, this solution is represented in Panel A

by the leftmost line that defines the “induced don’t know” region. Substantively, the point is that when

7
 We choose a relatively high level of Idk because Figure 3 illustrates the logic of our model when there
are only two survey responses (in addition to “don’t know”). Given only two responses, even complete
uncertainty means that one is, in expectation, correct half of the time. In a model with more response
options, the value of Idk necessary to sustain don’t know responses would be smaller.

                                                       13
p(r1) exceeds the critical value p*(r1), all cases in which the Democrat would have offered the Republican

response are replaced by “don’t know” answers.

        We next examine how a Democrat who otherwise would have chosen the “Democratic” response,

r1, behaves in the presence of incentives for “don’t know.” We have already shown that if c = c*’, the

Democrat is indifferent between the Democratic and the Republican responses, and that if p(r1) = p*(r1),

she is also indifferent between those responses and “don’t know.” However, as p(r1) rises above p*(r1),

the expected return from choosing the “Democratic” response increases. This means that as the

Democratic response becomes more likely to be true, smaller returns to expressive responding are

required to keep the Democratic response more attractive than “don’t know.” In Panel A of Figure 3, this

condition is illustrated by the downward-sloping line that defines the top of the region labeled “induced

don’t know.” Formally, c = c*’’ = (Vdk + Idk) / (p(r1)(1+I)) is the critical value, such that when c > c*’’

(and c > c*’), the Democrat chooses the Democratic response over “don’t know.”

        Parallel analysis for Republicans appears in Panel B of Figure 3. For both Democrats and

Republicans, the subjects who offer “don’t know” responses are drawn from those who are most uncertain

about which answer is correct, i.e., from subjects for whom p(r1) is close to .5. Our analysis above

establishes that it is this uncertainty that makes incentives for correct answers least likely to affect survey

responses. Accordingly, for these uncertain respondents, the “sure thing” of a “don’t know” payment is a

more effective inducement than the smaller probability of earning a potentially larger payment for a

correct response.

        Combining these analyses, as we do in Panel C, and comparing that plot to panel C of Figure 2

allows us to assess the effect on observed polarization of offering incentives for both correct and “don’t

know” responses. Relative to simply offering incentives for correct responses, adding incentives for

“don’t know” responses decreases the frequency with which Democrats and Republicans who share

common beliefs about the correct response provide divergent (non-“don’t know”) survey responses.

        We now describe the design of our two experiments. The first experiment focuses on differences

in survey responses in the presence and absence of incentives for correct responses. The second


                                                      14
experiment also incorporates incentives for “don’t know” responses.



EXPERIMENT 1: THE EFFECT OF FINANCIAL INCENTIVES FOR
CORRECT RESPONSES ON PARTISAN DIVERGENCE
        Our first experiment was fielded on the 2008 Cooperative Congressional Election Study, an

Internet survey of U.S. citizens that was conducted by YouGov/Polimetrix in October 2008.

YouGov/Polimetrix uses sampling and matching techniques to generate a sample that approximates the

demographic composition of the adult U.S. population. (See Appendix A for further information about the

construction of the 2008 CCES sample.) Six hundred and twenty-six participants were randomly assigned

to the control group (N = 312) or the treatment group (N = 314). 8 We restrict our analysis to the 419

participants who identified as either Democrats or Republicans. 9

        We told control-group subjects that they would be asked questions about politics, that they would

have 20 seconds to answer each question, and that their scores would not be shared with anyone. Treated

subjects received the same instructions and were also told that answering correctly would increase their

chance of winning a prize:

        For each question that you answer correctly, your name will be entered in a drawing for a $200
        Amazon.com gift certificate. For example, if you answer 10 questions correctly you will be
        entered 10 times. The average chance of winning is about 1 in 100, but if you answer many
        questions correctly, your chance of winning will be much higher.

        After receiving their instructions, all subjects were asked the twelve factual questions shown in

Table 1. The first ten items had closed response options and were similar to questions for which other

research has found partisan differences. No “don’t know” option was offered. Each question included a

reference to a salient partisan issue, e.g., the war in Afghanistan under a Republican president. The last

two “placebo” questions required participants to enter numerical responses and were fielded to ascertain


8
 Of these 419 partisans, 81% were white, 7% were black, 8% were Hispanic and 54% were female. Their
mean age was 48 years old, their median level of educational attainment was “some college,” and 67%
were married or in a domestic partnership
9
  We defined partisanship as responding either “Democrat” or “Republican” to the first question in the
standard party identification stem question, “Generally speaking, do you think of yourself as a …?” We
present question wording for both experiments in the appendix.

                                                     15
whether participants were using their allotted 20 seconds to look up answers using outside references.

These questions demanded knowledge of obscure historical facts. Using these questions, we find little

evidence that participants “cheated”: rates of correct responding in the control and payment conditions

were statistically indistinguishable.10

        This experiment allows us to understand whether some partisan divergence in responses to factual

questions arises because of the expressive benefit of providing partisan responses. We can do so by

comparing divergence in the treatment and control conditions. As we discussed earlier, divergence will

decrease only if our incentives are large enough to overcome the expressive value of partisan responding

and if participants have beliefs about the correct responses that are both common across parties and

sufficiently strong. Given the modest size of the incentives that we offered, we view these estimates as

providing a lower bound on the importance of expressive partisan responding in explaining partisan

divergence.

        To measure partisan divergence, we create scale scores by coding all responses to range linearly

from 0 to 1. The most Republican responses to each question are coded 0; the most Democratic responses

are coded 1. If partisans are answering in a manner consistent with their partisanship, Democrats should

offer “larger” responses than Republicans.

        Table 1 shows the average partisan difference, by question, for those in the control group.

Questions were asked in fixed order, but in Table 1 they are ordered by the size of the partisan gap

observed in the control group, with the two placebo questions at the bottom. For nine of the ten non-

placebo questions, we find positive partisan gaps that are consistent with our expectations about patterns

of partisan responding. 11 Eight of those differences are significant at p < .10 (one-tailed). The gaps vary

substantially in size, with the largest gaps for the questions about changes in causalities in Iraq between


10
  Correct-response rates in the control and treatment groups were 3% and 3% (Bangladesh) and 1% and
1% (price of gold), respectively. We also fielded an open-ended question about the offices held by George
von L. Meyer. No participant answered this question correctly.
11
  The exception is the question about the change in the deficit under George W. Bush. There was almost
no partisan divergence in responses to this question: Fully 88% of Democrats and 90% of Republicans
correctly reported that the deficit increased under Bush.

                                                      16
2007 and 2008 and Bush’s economic performance. For the placebo question about the price of gold we

find an unexpected partisan gap, whereas for the question about Bangladesh’s date of independence there

is no gap. Those placebo questions are not included in our remaining analyses.

        What effect do incentives for correct responses have on observed partisan divergence? To

measure these effects, we estimate a model in which we predict differences in scale score R for individual

i and question j:

        Rij = b0 + b1Democrati + b2PayCorrecti + b3(Democrati × PayCorrecti) + Questionj + ei,

where Democrat takes on the value 1 for Democratic participants and 0 for Republicans, PayCorrect = 1

for those assigned to the incentive condition, and Question is a vector of question-specific fixed effects. b1

is therefore the average party difference in mean scale scores in the control condition, while b1 + b3 is the

average party difference in the incentive condition. Prior research suggests b1 > 0, while the theoretical

model introduced above predicts that b3 will be negative if partisans offer partisan-tinged responses in the

absence of incentives, share common and sufficiently strong beliefs about the truth, and give less weight

to partisan responding than to the expected value of the incentive. OLS estimates, with standard errors

clustered at the respondent level, appear in Table 2.

        Pooling across the eight non-placebo questions for which we observe statistically significant

partisan gaps in the control condition, column (1) provides estimates of the average effect of incentives on

responses. 12 The .118 (p < .001) coefficient for Democrat (b1) is the average gap between Democrats and

Republicans in the control condition. The –.065 (p < .001) coefficient for Democrat × PayCorrect (b3)

means that this gap is reduced to .053 (.118 – .065), or by 55%, when incentives are offered. In column

(2), we add demographic controls; the results are nearly unchanged.

        These results show that even modest incentives can substantially reduce partisan divergence in

factual assessments. In this experiment, participants were told that answering correctly would improve

12
  This analysis excludes cases in which participants didn’t provide a response, which occurs 3% of the
time in both treatment and control conditions. Replacing those responses with party averages for that
question produces substantively similar results. Analysis is available upon request. In Table A1 of the
appendix, we repeat these analyses for each questions individually. In all eight cases, the estimate for b3 is
negative, although it is not usually statistically significant.

                                                        17
their chances of earning a $200 gift certificate, and that the baseline chance of winning was around 1 out

of 100. Assuming that participants estimate that answering all questions correctly would double their

chances of winning this prize, the expected value of answering any given question correctly is $0.167. 13

In turn, the finding that incentives reduced partisan gaps by more than 50% implies that more than half of

the party gap may be generated by participants for whom partisan responding is worth less than $0.17.

          Of course, we cannot ascertain why the remaining proportion (about 45%) of the partisan gap

remains. Following our model, the individuals responsible for this gap may value partisan cheerleading

more highly (high values of expressiveness, c), disagree about which response is correct (difference in

p(rj) across parties), or be sufficiently uncertain about which response is correct that they cannot improve

their chances of earning the incentive by deviating from their partisan response (uncertainty). To

understand the role of awareness of one’s own lack of knowledge, we now turn to our second experiment.



EXPERIMENT 2: THE EFFECT OF FINANCIAL INCENTIVES FOR
CORRECT AND “DON’T KNOW” RESPONSES ON PARTISAN
DIVERGENCE
          We fielded our second experiment in 2012 with subjects whom we recruited from Amazon.com’s

Mechanical Turk marketplace. 14 Subjects were required to pass a two-question attention screener and

were then randomly assigned to a control group (N = 156) or to one of three treatment groups, two of

which we examine here. 15 In the first treatment group, participants were paid for correct responses

(N = 534). In the second treatment group, participants were paid for both correct and “don’t know”

responses (N = 660). Below, we restrict our analysis to the 795 individuals in these three groups who


13
     (1/100 × $200)/12 questions = $0.167 per question.
14
  We recruited 1,506 participants for the MTurk study over the web from March 29, 2012 to April 16,
2012. See Appendix A for details. Because MTurk samples tend be more Democratic than the general
population, we invited equal numbers of Democrats and Republicans who had previously taken our
surveys to participate in this study. Of the 795 partisans analyzed, age ranged from 19 to 75 with a mean
of 33, 54 percent were female, and 46 percent had at least a four-year college degree.
15
  In a third treatment, we paid participants a flat fee to answer questions post-treatment, the same
incentive provided to the control group. However, we also allowed respondents to express “don’t know”
answers.

                                                     18
identified as either Democrats or Republicans. 16

        There are three major differences between this experiment and Experiment 1. First, and of

greatest importance theoretically, we introduce a new treatment here, in which we offer subjects the

opportunity to select “don’t know” and incentives for both correct and “don’t know” responses. Doing so

allows us to estimate the degree to which partisan responding arises because participants are unaware 17 of

correct responses, but are aware of their lack of knowledge. Therefore, unlike Experiment 1, Experiment

2 permits us to assess the extent to which partisan divergence that persists in the face of incentives for

correct responses reflects knowing ignorance, rather than partisan cheerleading (as driven by large

expressive returns) or sincere differences in beliefs.

        Second, in both treatment conditions, we randomly vary the amount offered for correct responses.

In the treatment that includes payment for “don’t know” responses, we also vary the amount offered for

that response. These randomizations allow us to assess the degree to which partisan divergence is affected

by the size of incentives.

        Third, for all of the questions asked in this experiment, we used a novel graphical input device to

measure participants’ attitudes. Figure 4 displays an example of the “slider” that we used to gather

answers to each of the questions we asked. After we trained participants to use this interface (complete

instructions appear in Appendix B), we asked them to respond to each question by manipulating the

slider. As before, we gave subjects 20 seconds to answer each question to limit opportunities for

consulting outside information sources. Additionally, in the conditions in which participants were paid for

correct responses, subjects were informed that a response would be scored as correct if the slider

overlapped the correct answer. The primary advantage of this input device is that it allows individuals to


16
  As in our first experiment, we defined partisanship as responding either “Democrat” or “Republican” to
the first question in the standard party identification stem question, “Generally speaking, do you usually
think of yourself as a Democrat, a Republican, an Independent, or what?” Of the 795 partisans in our
sample, 65% were Democrats, 89 were assigned to the control group, 327 to the pay-for-correct-response
group, and 379 to the pay-for-correct-and-“don’t know” group.
17
   We use “unaware” loosely: “unaware” subjects include those who believe that one response option is
most likely to be true, but for whom there is only a small difference in assessments of which answer is
true (i.e., |p(r1) – p(r2)| is small).

                                                         19
provide responses continuously across the entire range of possible responses instead of requiring

categorical responses.

        In all conditions, participants were initially asked five questions that were selected at random

from a larger list that we describe below. All questions had a closed response format and we did not

present a “don’t know” response option. Their treatment was then introduced, and they were then asked

seven more questions: two new questions followed by the same five questions that they had previously

been asked. (See Appendix B for the text that we used to introduce each treatment.) In the control

condition, participants were paid a flat $0.50 bonus to answer those seven post-treatment questions. In the

pay-for-correct condition, participants were informed that they would be paid for each correct response,

and the amount offered for each correct response was randomly assigned to be $0.10 with probability .25,

$0.25 with probability .25, $0.50 with probability .25, $0.75 with probability .15, and $1.00 with

probability .10.

        Finally, in the pay-for-correct-and-“don’t know” condition, participants were again informed they

would be paid for each correct response, and the amount offered for each correct response was assigned

as in the prior treatment. Participants in this treatment were also given “don’t know” response options and

told that they would be paid for selecting “don’t know.” The amount paid for “don’t know” responses was

also assigned randomly, and was a fraction of the amount offered for a correct response: 20% of the

payment for a correct response with probability .33, 25% with probability .33, and 33% with

probability .33.

        We list the 12 questions that we fielded in this experiment in Table 3, which also shows the

correct response and the range of the response options (i.e., the lower and upper bound of the labeled

horizontal line) that we offered to participants. These questions were chosen so that correct responses

varied across the entire range of potential answers: they were not concentrated at either end of the scale or

in the middle. The direction of partisan responding also varied: sometimes, higher responses favored the

Democratic Party; sometimes, they favored the Republican Party. As before, we used a placebo question




                                                     20
designed to assess whether or not participants were consulting outside references. 18

          As with Experiment 1, we recoded all responses to range from 0 to 1, with 1 indicating the most

Democratic response. The right-hand column of Table 3 reports, for each question, the observed pre-

treatment difference in mean scale scores between Democrat and Republican participants. (Recall that

each participant was asked five pre-treatment questions.) We find statistically significant (p < .10, one-

tailed) partisan gaps for ten of these questions, with the largest gaps for questions about unemployment

under Bush and Obama, and the smallest gaps for a question about the proportion of the population that is

foreign-born and for the placebo question about baseball. Our subsequent analysis is restricted to the ten

non-placebo questions for which there are statistically significant pre-treatment partisan gaps.


The Effect of Incentives for Correct and “Don’t Know” Responses

We begin by reporting the effect of the treatments on the frequency of selecting “don’t know.” Our model

suggests that the rate at which participants select “don’t know” when offered a payment for doing so

indicates the degree to which they understand that they don’t know the correct response to these

questions. In particular, if beliefs about correct responses are sufficiently weak (i.e., uninformative about

the truth) and preferences for expressive partisan responding are not too large, then choosing “don’t

know” when paid to do so will yield greater expected utility than either expressive or sincere responses.

          Pooling across the non-placebo questions for which we found pre-treatment partisan gaps, we

find that 47.8% of responses in the payment-for-correct-and-“don’t know” condition are “don’t know.” 19

That is, nearly half of participants forgo a response that would allow them to support their party or give

them a chance to earn a larger monetary incentive for a correct response.

          Recall that for “don’t know” responses, participants were randomly assigned to receive 20%,

25%, or 33% of the payment that they received for correct responses. Across these conditions, the

frequency of “don’t know” is 46%, 47%, and 50%, respectively. These differences are ordered as the
18
     See Appendix A for an analysis of reported efforts to look up correct responses using outside sources.
19
  By contrast, in the other treatment that we fielded, in which participants were paid a flat fee for their
responses and also offered a “don’t know” option (see note 15), only 14.8% of responses were “don’t
know.”

                                                      21
theoretical model predicts, but only the difference in means between the 20% and 33% conditions

approaches statistical significance (p < .07, one-tailed).

         This pattern—frequent “don’t know” responses when subjects are paid to say “don’t know,” even

though they are also offered more for correct responses—implies that participants are sufficiently

uncertain about the truth that they expect to earn more by selecting “don’t know.” For example, given that

46% of participants selected “don’t know” when paid 20% of the correct-answer payment for “don’t

know” responses, and given that the slider covers 20% of the response space, we infer that participants’

beliefs about the probability that a response is correct are nearly equal across responses. By contrast, if

participants were confident that even 20% of the range of the scale did not include the correct answer,

they would do better in expectation by simply guessing randomly from among the remaining 80% of the

scale range. 20

         This great willingness to select “don’t know” has important implications for our understanding of

partisan divergence. In particular, participants who offer “don’t know” responses behave in a manner that

is consistent with this hypothesis: they know that their responses are otherwise partisan and that they

don’t know the truth. In the absence of incentives for “don’t know” responses, they would offer insincere

partisan responses, even if paid for correct ones, because they are both uninformed about the truth and

aware of their ignorance. Overall, absent sufficiently strong beliefs about what the truth is, they cannot

expect to earn more if paid only for correct responses.

         To incorporate “don’t know” responses into our analysis of partisan divergence, we must decide

where to place those responses on the 0-1 scale that we use to analyze other responses. Because

participants who admit that they don’t know thereby forgo the opportunity to express support for their

party, we treat these responses as being non-polarized. That is, we assign both Democrats and

Republicans who choose “don’t know” to the same position on the 0-1 scale. In particular, we assign



20
  This is so because the slider can cover up to 1/6th of the response range, so random guessing from the
entire range would be correct about 16.7% of the time. If 20% of the scale range is eliminated, randomly
guessing from the remaining 80% of the scale would be correct about 20.8% of the time. This calculation
assumes risk neutrality.

                                                      22
“don’t know” responses for a given question to the average pre-treatment response that participants

offered to that question. In practice, the particular value makes little difference to our analyses; the

important point is that Democrats and Republicans are assigned to the same position on the scale if they

say “don’t know.” One implication of this choice is that if all partisans chose “don’t know,” we would

find no divergences between the parties.

        As in the previous section, we study the effect of the treatments on party polarization by

examining whether post-treatment partisan gaps differ between the control and treatment conditions. 21

Our analysis initially takes the following form:

        Rij = b0 + b1PayCorrecti + b2PayCorrectDKi + b3(Controli × Democrati) + b4(PayCorrecti ×

        Democrati) + b5(PayCorrectDKi × Democrati) + Questionj + ei,

where Democrat = 1 for Democratic participants and 0 for Republicans, Control = 1 for those assigned to

the control condition, PayCorrect = 1 for those assigned to the pay-for-correct-response condition,

PayCorrectDK = 1 for those assigned to the pay-for-correct-and-“don’t know” condition, and Question is

a vector of question-specific fixed effects. In this specification, b3, b4, and b5, are the amount of partisan

divergence in the control condition and the two treatment conditions. (This specification does not exploit,

within treatment, variation in the amounts that we paid for correct and “don’t know” responses.) Our

expectation is that b3 > b4 and b3 > b5, that is that each treatment will reduce partisan divergence relative to

the control (flat fee) condition. Additionally, our theoretical model suggests that some partisans who will

not respond to incentives for correct responses will nonetheless respond to incentives for “don’t know”

responses. For this reason, we also predict b4 > b5.

        The first column of Table 4 reports OLS estimates of the equation. (Parallel analysis for each

individual question appears in Table A2 of Appendix A.) The estimate of b3 is .145 (p < .01), which

means that, on average, Democrats and Republicans in the control condition differ in their answers by

about 15% of the range of the scale. The estimate of b4 is only .058, and the difference between these two

21
   One alternative would be to compare pre-treatment responses to post-treatment responses in a given
treatment condition. That analysis, however, would conflate the effect of the treatment with the effect of
answering some questions a second time.

                                                       23
estimates is significant at p < .01. (This test statistic is reported in the second-to-last row of the table.) The

difference indicates that only 40% of the previously observed party gap remains when participants are

paid small amounts for correct responses. Despite the differences in subject pools, questions, and details

of the experiment, this effect is similar in size to what we find in our analysis of Experiment 1. And, like

Experiment 1, this result shows that analysis of survey responses as sincere expressions of factual beliefs

likely overstates true partisan polarization.

        This experiment also allows us to estimate the effect on apparent partisan polarization of

incentives for “don’t know” responses. The estimate of b5 is .028, or about 80% smaller than the

corresponding control-condition estimate and about 50% smaller than the pay-only-for-correct-response

estimate. Both differences are significant at p < .05. In practical terms, this means that whereas the

baseline (control-group difference) between Democrats and Republicans was about 15% of the scale

range, it shrinks to 3% of the range when we offer incentives for both correct and “don’t know”

responses. To give a more concrete understanding of the importance of these differences, in the case of

the question about change in unemployment under Bush, the response scale ranged from –2% to 4%, and

the estimates imply that control-group Democrats offered a response that was about .9 percentage points

higher than control-group Republicans. Among those paid for a correct response, these estimates suggest

that gap was only .4 percentage points, and among those paid for both a correct and don’t know response,

it was only .2 percentage points.

        From the perspective of voters trying to evaluate a president, an annual change in the

unemployment rate of .2 points or greater happens more than 80 percent of the time, and a change of .4

points or greater happens 65 percent of the time. By contrast, a change of .9 points or greater happens

only about 25 percent of the time. 22 Partisan gaps in survey response in the presence of incentives are

therefore far more appropriately calibrated to year-to-year variation than the gaps suggested by

unincentivized responses.

22
  Annual change in the unemployment rate from 1970 to 2012 retrieved from the BLS at
http://data.bls.gov/timeseries/LNU04000000?years_option=all_years&periods_option=specific_periods&
periods=Annual+Data.

                                                       24
        We consider the robustness of these results in columns (2) through (4). In column (2) we estimate

a Tobit specification, which allows us to account for the fact that our response scales were finite and

therefore unable to accommodate extreme responses. The Tobit estimates are similar to those shown in

column (1) and indications of statistical significance do not change. In columns (3) and (4) we examine

different subsets of the questions that each respondent answered. Column 3 reports results only for those

questions that respondents had also been asked at the pre-treatment stage. Column 4 reports results only

for those questions that respondents had not been asked at the pre-treatment stage. Dividing the analysis

in this way reduces the size of the sample in each column, but the pattern of effects remains: The partisan

gap is largest in the control condition, around 60% smaller in the pay-for-correct-response condition, and

around 80% smaller in the pay-for-correct-and-“don’t know” condition. Indications of statistical

significance are marginal in the column (4) specification, which is restricted to only two questions per

respondent.

        We can also leverage the variation in the incentive amounts provided to assess more fully the

effect of differences in correct and “don’t know” payments on observed divergence. A specification that

exploits this variation appears in column (5). It includes indicators for each level of payment. These

indicators appear separately and are interacted with partisanship. The resulting specification is highly

flexible because it does not make any assumptions about the functional form of the effects of changes in

payments.

        The estimated .145 (p < .05) coefficient for Democrat is the average difference between

Democrats and Republicans in the control condition. As expected, of the five interactions between

amount paid for a correct response and Democrat, all are negative and statistically significant at p < .10,

which means that party gaps are smaller when participants are offered incentives for correct responses.

With one exception, they are also ordered in decreasing fashion. That is, larger payments are associated

with smaller partisan gaps relative to the control group. The exception is the $0.75 payment for a correct

response, which is associated with a decrease in the partisan gap of .06 (p < .10), smaller than the .08




                                                     25
decrease associated with a $0.10 payment for a correct response.23 Focusing just on the comparison of the

effect of the $1.00 and $.10 payment and acknowledging concerns about multiple comparisons, we

estimate that partisan gaps are 56% smaller in the $0.10 payment condition than in the control group and

80% smaller in the $1.00 payment condition. The difference between the two coefficients (Amount

correct = $0.10 × Democrat and Amount correct = 1.00 × Democrat) is marginally significant (p < .10,

one-tailed test).

        We can also assess the effects of variation in the amount paid for “don’t know” responses. All of

the interactions between the fractional payment amounts and partisanship are in the expected negative

direction, meaning that adding incentives for “don’t know” reduces partisan gaps. For payments that are

20% or 33% as large as the payments for correct responses, the estimates are statistically significant at

p < .10 (two-tailed), and the pooled estimate of the effect of “don’t know” payments is significant at

p < .05. To interpret these coefficients, one can fix the payment for a correct response at $0.10, in which

case the estimated partisan gap is .063 (.145 – .082, p < .01). Adding the “don’t know” payment is

estimated to reduce this party gap by between .02 (a 25% reduction for a “don’t know” payment of

$0.025) and .04 (a 65% reduction for a payment of $0.033).

        The ordering of the effects for the proportional payments is mixed. The largest reduction in

partisan divergence is associated with the 33% payment for “don’t know” responses, the next-largest

reduction is associated with the 20% payment, and the smallest reduction is associated with the 25%

payment. None of these coefficients are statistically distinguishable from one another, perhaps reflecting

the relatively small sample sizes in each condition. 24 At the same time, the point estimates imply that the

combination of a $1.00 payment for a correct response and a $0.33 payment for a “don’t know” response

will eliminate the entire partisan gap between Democrats and Republicans in responses to partisan factual


23
  We note that this is one of two treatment conditions, the other being the $1.00 payment, which we
undersampled for reasons of cost. There are 574 respondent-answers in the $0.75 payment condition,
compared to 1000 on average in the $0.10, $0.25, and $0.50 payment conditions.
24
  For example, among those 1130 cases assigned to the $0.50 payment for a correct response, there are
571 [50%] in which no payment was offered for “don’t know.” The remaining cases were split almost
equally across the three levels of proportional “don’t know” payments.

                                                     26
questions. 25

           Taken as a whole, these results have two implications. First, as in Experiment 1, modest

incentives substantially reduce partisan gaps, which is consistent with some portion of these gaps being

due to expressive responding rather than to sincere differences in beliefs. Second, at least half of the

partisan divergence that remains even in the presence of incentives for correct responses arises because

people know that they do not know the correct response. On average, payments for correct responses in

this experiment reduce partisan gaps by 60%. Adding “don’t know” payments reduces partisan gaps by an

additional 20 percentage points, leaving only 20% of the original gap. This implies that fully half of the

remaining gap arose because participants were unaware of the correct response and understood their lack

of knowledge. Indeed, the relatively high rate of selecting “don’t know” (about 48% across “don’t know”

payment rates) suggests a great deal of self-aware lack of knowledge about the world. When offered a

payment both for a correct response and a “don’t know” response, nearly half of participants chose “don’t

know.” In doing so, they gave up both the chance to engage in expressive partisan responding and the

opportunity to earn a larger payment by offering a correct response.



DISCUSSION AND IMPLICATIONS
Our results have important implications for both political science and understandings of contemporary

public opinion. Regarding the former, persistent partisan gaps, if sincere, suggest important limitations to

democratic accountability. If Democrats and Republicans perceive different realities, then the incentives

for incumbent politicians to pursue policies that generate objectively good policies may be reduced. Our

results imply that such concerns are overstated. Democrats and Republicans may diverge in their survey

reports of facts, but such responses should not be taken at face value as sincere expressions of partisan

worldviews.

           To make the magnitude of this concern clear, we use Experiment 1 to assess the correlation

between survey assessments of factual matters and reported candidate preference. By comparing the


25
     This calculation is .145 – .116 – .041, which is actually slightly smaller than 0.

                                                        27
correlations in the control and treatment conditions, we can understand whether the use of cross-sectional

survey measures to predict vote choice is biased when those measures are affected by partisan

cheerleading. In particular, we estimate

        PresVotei = b0 + b1FactualAssessmentsi + b2PayCorrecti + b3(PayCorrecti × FactualAssessmentsi) + ei,

where PresVote = 1 indicates an intended vote for Obama and PresVote = 0 indicates an intended vote for

McCain. (We exclude from the analyses those who aren’t registered, prefer other candidates, or report

that they won’t vote.) FactualAssessments is a mean scale created from the eight items included in our

earlier analysis of the experiment, with each item coded so that 1 is the most Democratic response and 0

is the most Republican response. PayCorrect is an indicator for assignment to the pay-for-correct-

response condition. Existing research suggest b1 > 0, that is, more Democratic assessments are associated

with voting for the Democratic candidate. If those factual assessments are affected by partisan-consistent

cheerleading when incentives are not offered, then that correlation should be reduced in the treatment

condition, implying b3 < 0.

        We present OLS estimates with clustered standard errors in Table 5.26 Per these estimates, a one-

standard-deviation increase (.124) in the factual assessments scale is associated with a 22-percentage-

point increase in the likelihood of voting for Obama (p < .01). Among those assigned to the treatment

group, however, the negative estimate for b3 means that this effect is substantially reduced (p < .05). In

particular, the same shift in the assessments scale now increases the probability of voting for Obama by

only 13 percentage points, a decrease of more than 40% in the effect of those assessments on voting. This

means that the observed correlation between normal (unincentivized) survey reports of factual

assessments and voting is exaggerated by the partisan “contamination” of those responses. Analysts

should therefore craft research designs that allow them to distinguish the true relationship between sincere

factual assessments and political choices from the apparent relationship that exists when factual

assessments are affected by partisan expressive responding. Failure to do so likely biases inference about



26
  In this sample, the mean FactualAssessments score is .59 and 50% of the sample prefers Obama. Probit
results are substantively similar.

                                                     28
the effect of the “perceptual screen” on retrospective voting.

         Extending beyond political science, our results also inform understandings of contemporary

public opinion. Scholarly and popular analysts alike frequently take survey responses at face value,

assuming that what individuals choose in a survey context reflects their true underlying beliefs. While this

assumption has been called into question for sensitive topics, our results suggest that the concern should

be far more widespread. Indeed, in light of this concern, ongoing efforts to assess the dynamics of public

opinion must grapple with the possibility that changes in partisan responses to many questions may not

reflect changes in factual beliefs but changes in the degree to which different responses are understood as

conveying support for one’s party. (They may also reflect changes in the social returns to partisan

cheerleading: see Iyengar, Sood, and Lelkes 2012). Further, if our results about factual questions extend

to responses to non-factual survey items, our findings have important implications for partisan divergence

in attitudinal self-reports.



CONCLUSION
A common feature of American politics is the existence of differences between Democrats and

Republicans in survey assessments of factual beliefs. How should those differences be interpreted? One

view is that they represent the stark reality of partisan bias, in which Democrats and Republicans perceive

different realities. Another possibility, highlighted in this paper, is that differences in survey responses

arise because surveys offer partisans low-cost opportunities to express their partisan affinities.

         To highlight the distinction between sincere beliefs about the truth and survey responses, we have

presented a model of survey response that incorporates the possibility of expressive partisan responding.

The model shows that incentives for correct responses can be used to distinguish sincere from insincere

partisan responding. It also shows that incentives will fail to reduce partisan responding if respondents

understand that they are unaware of the truth. However, by providing incentives for both correct and

“don’t know” responses, one can estimate the proportion of partisan responding that arises because of

either informed or uninformed partisan cheerleading.



                                                      29
          Building from this model, we designed and fielded two novel experiments. In the first

experiment, some participants were paid for correct responses to factual questions. The payments reduced

observed partisan gaps by about 55%. In the second experiment, we also paid some participants for “don’t

know” responses. In this experiment, incentives for correct responses reduced partisan gaps by 60%, and

incentives for “don’t know” did so by an additional 20%, yielding partisan gaps that were 80% smaller

than those that we observed in the absence of incentives. Taken together, these results provide a lower-

bound estimate on the proportion of partisan divergence that arises because of the combination of

expressive partisan returns and self-aware ignorance of the truth. Extending our analysis, we found that

paying people for correct responses sharply reduces the power of factual assessments to predict vote

choice.

          Our work also highlights areas for subsequent research. The imprecision of our estimates about

the effects of increasing incentives, for example, suggests the value of conducting additional experiments

with larger samples. The apparent increasing effect of those incentives also implies that it would be

desirable to ascertain whether even larger incentives can further reduce apparent bias by overcoming the

tendency for individuals to engage in expressive partisan cheerleading. There is also the question of

whether individual-level factors can explain which individuals are more likely to engage in expressive

cheerleading, and which individuals are most responsive to these financial inducements. 27

          These questions aside, the core of our paper is the exposition of a model of expressive survey

response and the implementation of a pair of experiments designed to distinguish that cheerleading

behavior from sincere partisan divergence. We find that small financial inducements for correct responses

can substantially reduce partisan divergence, and that these reductions are even larger when inducements

are also provided for “don’t know” answers. In light of these results, survey responses that indicate

partisan polarization with respect to factual matters should not be taken at face value. Researchers and

general analysts of public opinion should consider the possibility that the appearance of polarization is to

a great extent an artifact of survey measurement rather than evidence of real differences in beliefs.

27
     See Appendix C for a preliminary discussion of accuracy.

                                                      30
REFERENCES
Ansolabehere, Stephen, Marc Meredith, and Erik Snowberg. 2013. “Asking about Numbers:

Why and How.” Political Analysis 21 (January): 48-69.


Bartels, Larry M. 2002. “Beyond the Running Tally: Partisan Bias in Political Perceptions.”

Political Behavior 24 (June): 117-50.


Berinsky, Adam J. 2005. Silent Voices: Public Opinion and Participation in America. Princeton,

NJ: Princeton University Press.


Berinsky, Adam J. 2012. “Rumors, Truths, and Reality: A Study of Political Misinformation.”

Massachusetts Institute of Technology. Manuscript.


Campbell, Angus, Philip E. Converse, Warren E. Miller, and Donald E. Stokes. 1960. The

American Voter. Chicago: University of Chicago Press.


Conover, Pamela J., Stanley Feldman, and Kathleen Knight. 1986. “Judging Inﬂation and

Unemployment: The Origins of Retrospective Evaluations.” Journal of Politics 48 (3): 565-88.


Conover, Pamela J., Stanley Feldman, and Kathleen Knight. 1987. “The Personal and Political

Underpinnings of Economic Forecasts.” American Journal of Political Science 31 (August): 559-

583.


Duelfer, Charles. 2004. “Comprehensive Report of the Special Advisor to the Director of Central

Intelligence on Iraq’s Weapons of Mass Destruction.”

http://www.gpoaccess.gov/duelfer/index.html (accessed October 1, 2009).



                                               31
Fiorina, Morris P. 1981. Retrospective Voting in American National Elections. New Haven, CT:

Yale University Press.


Gaines, Brian J., James H. Kuklinski, Paul J. Quirk, Buddy Peyton, and Jay Verkuilen. 2007.

“Same Facts, Different Interpretations: Partisan Motivation and Opinion on Iraq.” Journal of

Politics 69 (November): 957-74.


Gerber, Alan S., and Gregory A. Huber. 2010. “Partisanship, Political Control, and Economic

Assessments.” American Journal of Political Science 54 (January): 153-73.


Gerber, Alan S., Gregory A. Huber, Ebonya Washington. 2010. “Party Affiliation, Partisanship,

and Political Beliefs: A Field Experiment.” American Political Science Review 104 (4

November): 720-744.


Green, Donald, Bradley Palmquist, and Eric Schickler. 2002. Partisan Hearts and Minds:

Political Parties and the Social Identities of Voters. New Haven, CT: Yale University Press.


Harris Interactive. 2006 July 21. “Belief that Iraq Had Weapons of Mass Destruction Has

Increased Substantially.” http://news.

harrisinteractive.com/proﬁles/investor/ResLibraryView.asp?

ResLibraryID=34134&GoTopage=4&Category=1777&BzID=1963&t=8.


Harris Interactive. 2010 March 24. “‘Wingnuts’ and President Obama.”

http://news.harrisinteractive.com/proles/investor/ResLibraryView.asp?ResLibraryID=37050&C

ategory=1777&BzID=1963.


Healy, Andrew, and Neil Malhotra. 2009. “Myopic Voters and Natural Disaster Policy.”


                                               32
American Political Science Review 103 (3): 387-406.


Iyengar, Shanto, Gaurav Sood, and Yphtach Lelkes. 2012. “Affect, Not Ideology: A Social

Identity Perspective on Polarization.” Public Opinion Quarterly 76 (Fall): 405-31.


Jacobson, Gary C. 2006. A Divider, Not a Uniter: George W. Bush and the American People.

Upper Saddle River, NJ: Pearson.


Jerit, Jennifer, and Jason Barabas. 2012. “Partisan Perceptual Bias and the Information

Environment.” Journal of Politics 74: 672-684.


Kuklinski, James H., Michael D. Cobb, and Martin Gilens. 1997. “Racial Attitudes and the ‘New

South’.” Journal of Politics 59 (May): 323-49.


Lau, Richard R., David O. Sears, and Tom Jessor. 1990. “Fact or Artifact Revisited: Survey

Instrument Effects and Pocketbook Politics.” Political Behavior 12 (3): 217-242.


Lavine, Howard G., Christopher D. Johnston, and Marco R. Steenbergen. 2012. The Ambivalent

Partisan: How Critical Loyalty Promotes Democracy. Oxford University Press.


Morton, Rebecca C., and Kenneth C. Williams. 2010. Experimental Political Science and the

Study of Causality: From Nature to the Lab. New York: Cambridge University Press.


Noelle-Neumann, Elisabeth. 1993. The Spiral of Silence: Public Opinion, Our Social Skin.

Chicago: University of Chicago Press.


Palmer, Harvey D., and Raymond M. Duch. 2001. “Do Surveys Provide Representative or

Whimsical Assessments of the Economy?” Political Analysis 9 (1): 58-77.


                                                 33
Prior, Markus. 2007. “Is Partisan Bias in Perceptions of Objective Conditions Real? The Effect

of an Accuracy Incentive on the Stated Beliefs of Partisans.” Presented at the Annual Conference

of the Midwest Political Science Association, Chicago.


Prior, Markus, and Arthur Lupia. 2008. “Money, Time, and Political Knowledge: Distinguishing

Quick Recall and Political Learning Skills.” American Journal of Political Science 52 (January):

169-83.


Sears, David O., and Richard R. Lau. 1983. “Inducing Apparently Self-Interested Political

Preferences.” American Journal of Political Science 27 (May): 223-252.


Shapiro, Robert Y., and Yaeli Bloch-Elkon. 2008. “Do the Facts Speak for Themselves? Partisan

Disagreement as a Challenge to Democratic Competence.” Critical Review 20 (1): 115-39.


Stroud, Natalie J. 2008. “Media Use and Political Predispositions: Revisiting the Concept of

Selective Exposure.” Political Behavior 30 (3): 341-366.


Wilcox, Nathaniel, and Christopher Wlezien. 1993. “The Contamination of Responses to Survey

Items: Economic Perceptions and Political Judgments.” Political Analysis 5 (1): 181-213.




                                               34
                                                              Figure 1: Patterns of Survey Response in the Absence of Incentives
                                                       by Value of Expressive Partisan Responding and Beliefs about Correct Responses

                                                               A) Democrats’ Survey Responses                                                                                                                                                B) Republicans’ Survey Responses

                                              2                                                                                                                                                                               2

                                             1.8                                                                                                                                                                             1.8
c, Value of Expressive Partisan Responding




                                                                                                                                                                                c, Value of Expressive Partisan Responding
                                             1.6                                                                                                                                                                             1.6

                                             1.4                                                                                                                                                                             1.4

                                             1.2                  Insincere                                                                                                                                                  1.2                                                   Insincere
                                                                                                                                                   Sincere                                                                                        Sincere
                                                                (expressive)                                                                                                                                                                                                     (expressive)
                                              1                                                                                                  choice of r1                                                                 1                 choice of r2
                                                                choice of r1                                                                                                                                                                                                     choice of r2

                                             0.8                                                                                                                                                                             0.8

                                             0.6                                                                                                                                                                             0.6

                                             0.4                                                                                                                                                                             0.4
                                                          Sincere                                                                                                                                                                                                                          Sincere
                                             0.2        choice of r2                                                                                                                                                         0.2                                                         choice of r1

                                              0                                                                                                                                                                               0
                                                   0     0.1     0.2   0.3     0.4                                             0.5       0.6      0.7     0.8      0.9     1                                                       0    0.1      0.2    0.3    0.4   0.5   0.6    0.7    0.8     0.9    1
                                                       p(r1), Belief Democratic-Expressive Response r1 is Correct                                                                                                                      p(r1), Belief Democratic-Expressive Response r1 is Correct




                                                                                                                                                          C) Observed Polarization
                                                                                                                               2

                                                                                                                              1.8
                                                                                 c, Value of Expressive Partisan Responding




                                                                                                                              1.6

                                                                                                                              1.4                                   Polarization region
                                                                                                                                                                  (Democrats choose r1,
                                                                                                                              1.2                                 Republicans choose r2)

                                                                                                                               1

                                                                                                                              0.8

                                                                                                                              0.6

                                                                                                                              0.4
                                                                                                                                         Democrats and                                                                                        Democrats and
                                                                                                                              0.2         Republicans                                                                                          Republicans
                                                                                                                                           choose r2                                                                                            choose r1
                                                                                                                               0
                                                                                                                                     0     0.1      0.2     0.3      0.4       0.5                                             0.6     0.7      0.8    0.9     1
                                                                                                                                         p(r1), Belief Democratic-Expressive Response r1 is Correct


 Note: Panel A displays Democrats’ survey responses in the absence of incentives for different levels of returns to expressive
 partisan responding and beliefs about whether response r1 is correct. Panel B displays responses for the same parameters for
 Republicans. Finally, the grey area in panel C is the range of parameters for which Democrats and Republicans offer different
 survey responses despite common beliefs about which response is correct.
                                                   Figure 2: Patterns of Survey Response Given Incentives for Correct Responses (I=1)
                                                    by Value of Expressive Partisan Responding and Beliefs about Correct Responses

                                                                A) Democrats’ Survey Responses                                                                                                                                                 B) Republicans’ Survey Responses

                                              2                                                                                                                                                                                 2

                                             1.8                                                                                                                                                                               1.8
c, Value of Expressive Partisan Responding




                                                                                                                                                                                  c, Value of Expressive Partisan Responding
                                             1.6                          Insincere                                                                                                                                            1.6                                             Insincere
                                                                        (expressive)                                                                                                                                                                                         (expressive)
                                             1.4                        choice of r1                                                                                                                                           1.4                                           choice of r2

                                             1.2                                                                                                                                                                               1.2
                                                        Induced                                                                                      Sincere                                                                                        Sincere                                    Induced
                                              1        choice of r2                                                                                choice of r1                                                                 1                 choice of r2                                choice of r1


                                             0.8                                                                                                                                                                               0.8

                                             0.6                                                                                                                                                                               0.6

                                             0.4                                                                                                                                                                               0.4
                                                           Sincere                                                                                                                                                                                                                            Sincere
                                             0.2         choice of r2                                                                                                                                                          0.2                                                          choice of r1

                                              0                                                                                                                                                                                 0
                                                   0      0.1     0.2     0.3    0.4                                             0.5       0.6      0.7     0.8      0.9     1                                                       0    0.1      0.2    0.3    0.4   0.5   0.6   0.7      0.8     0.9      1
                                                        p(r1), Belief Democratic-Expressive Response r1 is Correct                                                                                                                       p(r1), Belief Democratic-Expressive Response r1 is Correct




                                                                                                                                                            C) Observed Polarization
                                                                                                                                 2

                                                                                                                                1.8
                                                                                   c, Value of Expressive Partisan Responding




                                                                                                                                1.6

                                                                                                                                1.4                                   Polarization region
                                                                                                                                                                    (Democrats choose r1,
                                                                                                                                1.2                                 Republicans choose r2)

                                                                                                                                 1

                                                                                                                                0.8

                                                                                                                                0.6

                                                                                                                                0.4
                                                                                                                                           Democrats and                                                                                        Democrats and
                                                                                                                                0.2         Republicans                                                                                          Republicans
                                                                                                                                             choose r2                                                                                            choose r1
                                                                                                                                 0
                                                                                                                                       0     0.1      0.2     0.3      0.4       0.5                                             0.6     0.7      0.8    0.9     1
                                                                                                                                           p(r1), Belief Democratic-Expressive Response r1 is Correct


 Note: Panel A displays Democrats’ survey responses given incentives I=1 for correct responses for different levels of returns to
 expressive partisan responding and beliefs about whether response r1 is correct. Panel B displays responses for the same param-
 eters for Republicans. Finally, the grey area in panel C is the range of parameters for which Democrats and Republicans offer
 different survey responses despite common beliefs about which response is correct.
                Figure 3: Patterns of Survey Response Given Incentives for Correct (I=1) and Don’t Know (Idk=.75) Responses
                              by Value of Expressive Partisan Responding and Beliefs about Correct Responses


                                                                A) Democrats’ Survey Responses                                                                                                                                                    B) Republicans’ Survey Responses

                                              2                                                                                                                                                                                    2

                                             1.8                                                                                                                                                                                  1.8
c, Value of Expressive Partisan Responding




                                                                                                                                                                                     c, Value of Expressive Partisan Responding
                                             1.6                          Insincere                                                                                                                                               1.6                                               Insincere
                                                                        (expressive)                                                                                                                                                                                              (expressive)
                                             1.4                        choice of r1                                                                                                                                              1.4                                             choice of r2

                                             1.2                                                                                                                                                                                  1.2
                                                        Induced                                                                                      Sincere                                                                                           Sincere                                      Induced
                                              1        choice of r2                                                                                choice of r1                                                                    1                 choice of r2                                  choice of r1


                                             0.8                                                                                                                                                                                  0.8

                                             0.6                                                                                                                                                                                  0.6

                                             0.4                                                                                                                                                                                  0.4
                                                           Sincere                                                                                                                                                                                                                                 Sincere
                                             0.2         choice of r2                                                                                                                                                             0.2                                                            choice of r1
                                                                                   Induced                                                                                                                                                                                 Induced
                                                                                  don’t know                                                                                                                                                                              don’t know
                                              0                                                                                                                                                                                    0
                                                   0      0.1     0.2     0.3    0.4                                             0.5       0.6      0.7     0.8      0.9        1                                                       0    0.1      0.2    0.3    0.4    0.5    0.6   0.7      0.8     0.9      1
                                                        p(r1), Belief Democratic-Expressive Response r1 is Correct                                                                                                                          p(r1), Belief Democratic-Expressive Response r1 is Correct




                                                                                                                                                            C) Observed Polarization
                                                                                                                                 2

                                                                                                                                1.8
                                                                                   c, Value of Expressive Partisan Responding




                                                                                                                                1.6

                                                                                                                                1.4                                   Polarization region
                                                                                                                                                                    (Democrats choose r1,
                                                                                                                                1.2                                 Republicans choose r2)

                                                                                                                                 1

                                                                                                                                0.8

                                                                                                                                0.6

                                                                                                                                0.4
                                                                                                                                           Democrats and                                                                                           Democrats and
                                                                                                                                0.2         Republicans                    Dem. and/or Rep.                                                         Republicans
                                                                                                                                             choose r2                         choose                                                                choose r1
                                                                                                                                                                             don’t know
                                                                                                                                 0
                                                                                                                                       0     0.1      0.2     0.3      0.4          0.5                                             0.6     0.7      0.8    0.9     1
                                                                                                                                           p(r1), Belief Democratic-Expressive Response r1 is Correct

 Note: Panel A displays Democrats’ survey responses given incentives for correct (I=1) and don’t know (Idk=.75) responses for
 different levels of returns to expressive partisan responding and beliefs about whether response r1 is correct. In all panels, Vdk=.5.
 Panel B displays responses for the same parameters for Republicans. Finally, the grey area in panel C is the range of parameters for
 which Democrats and Republicans offer different non-don’t know survey responses despite common beliefs about which
 response is correct.
Figure 4: Example of Graphical Input Slider for Experiment #2
                                                                   Table 1: Experiment 1, Question Wording and Baseline Partisan Differences in Scale Scores


                                                                                                                                                                                                  Control Group
                                                                                                                                                                  Control Group, Control Group,   Difference in  P-value of
                                                                                                                                                                      Mean           Mean         Scale Scores, Difference of
                                                                                                                                                                   Democratic     Republican       Democrats - party means, 1-
Question                             Question wording                                                                  Correct response                            Response       Response         Republicans    tailed test     N
Iraq 07 to 08 Change Casualties      Was the number of U.S. soldiers killed in Iraq in the first half of 2008 lower,   Lower (0), About the same (.5), Higher (1)     0.416          0.177            0.239         0.000        212
                                     about the same, or higher than the number who were killed in the second half
                                     of 2007?
Bush Inflation Change                Compared to January 2001, when President Bush first took office, has the          Increased (1), Stayed about the same          0.894           0.694           0.201          0.000        207
                                     level of inflation in the country increased, stayed the same, or decreased?       (.5), Decreased (0)

Bush Unemployment Change             Compared to January 2001, when President Bush first took office, has the          Increased (1), Stayed about the same          0.766           0.598           0.168          0.002        208
                                     level of unemployment in the country increased, stayed the same, or               (.5), Decreased (0)
                                     decreased?
Est. Bush Approval                   About what percentage of Americans approve of the way that George W.              20% (1), 30% (.75), 40% (.5), 50% (.25),      0.909           0.817           0.092          0.000        216
                                     Bush is handling his job as President?                                            60% (0)
Iraq Total Casualties                About how many U.S. soldiers have been killed in Iraq since the invasion in       4,000 (0), 8,000 (.25), 12,000 (.5), 16,000   0.200           0.114           0.087          0.013        210
                                     March 2003?                                                                       (.75), 20,000 (1)
Est. Bush Approval Among Reps.       About what percentage of Republicans approve of the way that George W.            40% (1), 50% (.75), 60% (.5), 70% (.25),      0.794           0.724           0.070          0.039        211
                                     Bush is handling his job as President?                                            80% (0)
Obama Age                            How old is Barack Obama?                                                          37 (0), 42 (.33), 47 (.66), 52 (1)            0.558           0.508           0.050          0.055        213
McCain Age                           How old is John McCain?                                                           62 (0), 67 (.33), 72 (.66), 77 (1)            0.681           0.637           0.044          0.035        215
Afgh. 07 to 08 Change Casualties     Was the number of U.S. soldiers killed in Afghanistan in the first half of 2008   Lower (0), About the same (.5), Higher (1)    0.608           0.598           0.010          0.430        208
                                     lower, about the same, or higher than the number who were killed in the
                                     second half of 2007?
Bush Deficit Change                  Compared to January 2001, when President Bush first took office, has the          Increased (1), Stayed about the same          0.938           0.944           -0.006         0.589        212
                                     federal budget deficit in the country increased, stayed the same, or              (.5), Decreased (0)
                                     decreased?
Placebo, Gold Price 1980             What was the price of gold, in dollars per ounce, on January 18, 1980?       In dollars, 0=0, 1000=1, Correct is             0.791              0.680         0.111            0.005        128
                                                                                                                  between $800 and $900
Placebo, Bangladeshi Indpc. Date  In what year did Bangladesh become independent of Pakistan?                     In years, 1800=0, 2000=1, Correct is            0.151              0.185        -0.034            0.755        123
                                                                                                                  1971
Note: Source: 2008 CCES Study. Questions are ordered by size of partisan gap in Control Group responses, with placebo questions at the bottom. All responses scaled 0 to 1, with 1 the most Democratic response.
              Table 2: Experiment 1: Effect of Payment for Correct Responses on Partisan Divergence in Scale Scores

                                                                               (1)                             (2)
                                                                                    Mean Scale Score (0 to 1)
                                                                 (Pooled for 8 questions with partisan gap, p<.10, among control
                                                                                              cases)
Democrat (1=Yes, 0=Republican)                                                0.118                              0.105
                                                                           [0.015]***                        [0.016]***
Payment for Correct Response * Democrat                                      -0.065                             -0.059
                                                                           [0.022]***                        [0.022]***
Payment for Correct Response                                                  0.038                              0.031
                                                                            [0.016]**                          [0.016]*
Knowledge (0-1)                                                                                                  0.013
                                                                                                                [0.015]
Race: White (1=yes)                                                                                              0.017
                                                                                                                [0.024]
Race: Hispanic (1=yes)                                                                                           0.040
                                                                                                                [0.028]
Race: Other Race (1=yes)                                                                                         0.051
                                                                                                               [0.030]*
Female (1=yes)                                                                                                   0.016
                                                                                                                [0.012]
Age (Years)                                                                                                      0.001
                                                                                                                [0.002]
Age-squared/100                                                                                                 -0.001
                                                                                                                [0.002]
Region: Northeast                                                                                                0.043
                                                                                                             [0.017]***
Region: Midwest                                                                                                  0.042
                                                                                                             [0.016]***
Region: South                                                                                                    0.014
                                                                                                                [0.014]
Income (1=<10k; 14=>150k; 15=RF/Missing)                                                                         0.005
                                                                                                              [0.002]**
Income Missing                                                                                                  -0.046
                                                                                                               [0.024]*
Education (1=No HS; 6=Post-grad)                                                                                 0.000
                                                                                                                [0.006]
Education: No HS                                                                                                 0.006
                                                                                                                [0.024]
Education: Some college                                                                                          0.019
                                                                                                                [0.014]
Education: 2-year college                                                                                        0.032
                                                                                                                [0.026]
Education: 4-year college                                                                                       -0.003
                                                                                                                [0.019]
Married/Domestic Partnership (1=yes)                                                                            -0.007
                                                                                                                [0.013]
Religious Attendance (1-6)                                                                                      -0.002
                                                                                                                [0.004]
Constant                                                                      0.239                              0.160
                                                                           [0.021]***                        [0.059]***
Observations                                                                  3321                               3299
R-squared                                                                     0.398                              0.407
Note: Source: 2008 CCES study. Includes only Democrats and Republicans. Cases included are from control and paid for correct
response condition. OLS Coefficients with robust standard errors, clustered by respondent. Question fixed effects not reported. *
significant at 10%; ** significant at 5%; *** significant at 1% (two-tailed tests).
                                                                             Table 3: Question Wording and Baseline Partisan Differences in Scale Scores, 2012 MTURK Study


                                                                                                                                                                                                           Pre-Treatment
                                                                                                                                                                          Pre-treatment, Pre-treatment,     Difference in P-value of
                                                                                                                                                                              Mean           Mean          Scale Scores, Difference of
                                                                                                                                                                           Democratic     Republican        Democrats - party means, 1-
Question                          Question wording                                                                Range of response line         Correct response           Response       Response         Republicans    tailed test     N
Obama Unemployment                From January 2009, when President Obama first took office, to February          -2 (Unemployment decreased) to increased by 0.5 %           0.552          0.378              0.174        0.000        389
                                  2012, how had the unemployment rate in the country changed?                     4% (Unemployment increased)
Bush II Unemployment              From January 2001, when President Bush first took office, to January 2009,      -2 (Unemployment decreased) to increased by 3.6 %           0.715            0.583             0.132       0.000        383
                                  when President Bush left office, how had the unemployment rate in the country   4% (Unemployment increased)
                                  changed?
Defense Spending                  For every dollar the federal government spent in fiscal year 2011, about how    3 to 27 cents                   19.4 cents                  0.731            0.631             0.101       0.000        355
                                  much went to the Department of Defense (US Military)?
Obama Vote 08                     In the 2008 Presidential Election, Barack Obama defeated his Republican         50 to 62%                       53.70%                      0.544            0.444             0.100       0.001        366
                                  challenger John McCain. In the nation as a whole, of all the votes cast for
                                  Obama and McCain, what percentage went to Obama?
Iraq deaths % Black               Approximately 12 to 13% of the US population is Black. What percentage of       9 to 21%                        9.90%                       0.430            0.344             0.085       0.006        373
                                  US Soldiers killed in Iraq since the invasion in 2003 are Black?
Medicaid Spending                 Medicaid is a jointly funded, Federal-State health insurance program for low-   3 to 27 cents                   7.5 cents                   0.577            0.502             0.075       0.013        343
                                  income and needy people. For every dollar the federal government spent in
                                  fiscal year 2011, about how much went to Medicaid?
TARP % Paid Back                  The Treasury Department initiated TARP (the first bailout) during the financial 1 (Less repaid) to 100 (More    69.56%                      0.391            0.324             0.068       0.027        349
                                  crisis of 2008. TARP involved loans to banks, insurance companies, and auto repaid)
                                  companies. Of the $414 billion spent, what percentage had been repaid, as of
                                  March 15, 2012?
Global Warming Amount             According to NASA, by how much did annual average global temperatures, in -1 (Temperatures cooler) to 2         increased by 1.1            0.685            0.640             0.045       0.013        382
                                  degrees Fahrenheit, differ in 2010 from the average annual global temperature (Temperatures warmer)             degrees
                                  between 1951 and 1980?
Iraq deaths                       About how many U.S. soldiers were killed in Iraq between the invasion in 2003 1000 to 7000                      4,486                       0.549            0.504             0.044       0.072        382
                                  and the withdrawal of troops in December 2011?
Debt Service Spending             The Treasury Department finances U.S. Government debt by selling bonds         3 to 27 cents                    6.2 cents                   0.501            0.458             0.043       0.095        360
                                  and other financial products. For every dollar the federal government spent in
                                  fiscal year 2011, about how much went to pay interest on those Treasury
                                  securities?
Foreign Born %                    According to the Census Bureau, in 2010 what percentage of the total            1 to 100%                       12.92%                      0.785            0.772             0.013       0.239        388
                                  population of the United States was born outside of the United States (foreign-
                                  born)?
Placebo: Mantle home runs '61     In 1961, Roger Maris broke Babe Ruth's record for most home runs hit in a       36 to 60                        54                          0.339            0.319             0.019       0.236        362
                                  major league baseball season. He hit 61 home runs that year. How many
                                  home runs did his Yankees teammate Mickey Mantle hit in that year?
Note: Source 2012 Mturk Study. Questions are ordered by size of partisan gap in pre-treatment responses with placebo question at the bottom. All responses scaled 0 to 1, with 1 the most Democratic response.
                        Table 4: Experiment #2: Effect of Payment for Correct Responses on Partisan Divergence in Scale Scores

                                                                             (1)               (2)               (3)               (4)               (5)
                                                                                                            Second time        First time
                                                                                                           answering any     answering any       All 10 non-
                                                                                                             of 10 non-        of 10 non-         placebo
                                                                        All 10 non-placebo questions
                                                                                                              placebo           placebo        questions with
Sample                                                                 with partisan-gaps (p<.10) pre-
                                                                                                           questions with    questions with    partisan-gaps
                                                                                  treatment
                                                                                                           partisan-gaps     partisan-gaps      (p<.10) pre-
                                                                                                            (p<.10) pre-      (p<.10) pre-       treatment
                                                                                                             treatment         treatment
Specification                                                                OLS               Tobit            OLS                OLS              OLS
Flat fee * Democrat (1=Yes, 0=Republican)                                    0.145             0.152            0.160              0.109
                                                                          [0.028]***        [0.029]***       [0.029]***         [0.052]**
Payment Correct * Democrat                                                   0.058             0.061            0.062              0.047
                                                                          [0.012]***        [0.013]***       [0.015]***          [0.025]*
Payment DK and Correct * Democrat                                            0.028             0.029            0.033              0.015
                                                                          [0.009]***        [0.009]***       [0.011]***           [0.015]
Payment for Correct Response                                                 0.018             0.018            0.022              0.007
                                                                            [0.025]           [0.026]          [0.027]            [0.048]
Payment for DK and Correct Response                                          0.049             0.052            0.056              0.033
                                                                           [0.024]**         [0.025]**        [0.026]**           [0.046]
Democrat (1=Yes, 0=Republican)                                                                                                                       0.145
                                                                                                                                                 [0.028]***
Amount correct = 0.10 * Democrat                                                                                                                    -0.082
                                                                                                                                                  [0.033]**
Amount correct = 0.25 * Democrat                                                                                                                    -0.092
                                                                                                                                                 [0.033]***
Amount correct = 0.50 * Democrat                                                                                                                    -0.096
                                                                                                                                                 [0.033]***
Amount correct = 0.75 * Democrat                                                                                                                    -0.061
                                                                                                                                                   [0.036]*
Amount correct = 1.00 * Democrat                                                                                                                    -0.116
                                                                                                                                                 [0.036]***
Prop. payment for DK=.20 * Democrat                                                                                                                 -0.031
                                                                                                                                                   [0.018]*
Prop. payment for DK=.25 * Democrat                                                                                                                 -0.016
                                                                                                                                                    [0.020]
Prop. payment for DK=.33 * Democrat                                                                                                                 -0.041
                                                                                                                                                  [0.020]**
Amount correct = 0.10                                                                                                                                0.010
                                                                                                                                                    [0.027]
Amount correct = 0.25                                                                                                                                0.028
                                                                                                                                                    [0.027]
Amount correct = 0.50                                                                                                                                0.020
                                                                                                                                                    [0.027]
Amount correct = 0.75                                                                                                                                0.005
                                                                                                                                                    [0.029]
Amount correct = 1.00                                                                                                                                0.042
                                                                                                                                                    [0.029]
Prop. payment for DK=.20                                                                                                                             0.023
                                                                                                                                                   [0.013]*
Prop. payment for DK=.25                                                                                                                             0.030
                                                                                                                                                   [0.017]*
Prop. payment for DK=.33                                                                                                                             0.034
                                                                                                                                                  [0.016]**
Constant                                                                    0.614             0.617            0.608             0.628               0.614
                                                                          [0.026]***        [0.026]***       [0.027]***        [0.048]***        [0.026]***
Observations                                                                 4608              4608             3275              1333               4608
R-squared                                                                   0.179                              0.190             0.157               0.181
F-test, Flat fee * Dem. > Pay Correct * Dem.                                0.000             0.000            0.000             0.140
F-test, Pay Correct * Dem. > Pay DK and Correct * Dem.                      0.020             0.020            0.060             0.130

Source: 2012 MTURK study. Includes only Democrats and Republicans. Comparison of post-treatment responses in control, pay correct, and pay
correct and don't know conditions. OLS Coefficients with robust standard errors in columns (1) and (3)-(5). Tobit results shown in column (2). Standard
errors are clustered by respondent. Question fixed effects not reported. * significant at 10%; ** significant at 5%; *** significant at 1% (two-tailed tests).
      Table 5: Experiment #1: Vote Choice by Average Factual Assessments Scale Score in Control and Pay Correct Conditions

                                                                                                          Presidential Vote
                                                                                                      (1=Dem., 0=Rep., .=Else)
Average factual assessments scale score (0=Most Republican, 1=Most Democratic)                                  1.770
                                                                                                             [0.222]***
Pay Correct * Average factual assessments scale score                                                           -0.741
                                                                                                              [0.367]**
Pay Correct condition                                                                                            0.418
                                                                                                               [0.224]*
Constant                                                                                                        -0.548
                                                                                                             [0.135]***
Observations                                                                                                      373
R-squared                                                                                                        0.130
Percentage of Scale Score Effect on Vote Eliminated in Pay Correct Condition                                    41.9%
Note: Source: 2008 CCES. Includes only Democrats and Republicans. Scale score is pooled across 8 non-placebo questions with
partisan gaps in control condition. * significant at 10%; ** significant at 5%; *** significant at 1%
APPENDIX A

Experiment 1: Construction of the 2008 CCES Sample

The survey sample was part of a private module on the 2008 CCES, with a target population sample of

1,800 individuals. These questions were asked of a subset, drawn at random, of 626 of the 1,800

individuals in the full sample. The full sample is based on the 2005-06 American Community Study,

November 2008 Current Population Survey, and the 2007 Pew Religious Life Survey. Thus, this target

sample is representative of the general population on a broad range of characteristics including a variety

of geographic (state, region and metropolitan statistical area), demographic (age, race, income, education

and gender), and other measures (born-again status, employment, interest in news, party identification,

ideology and turnout). Polimetrix invited a sample of their opt-in panel of 1.4 million survey respondents

to participate in the study. Invitations were stratified based on age, race, gender, education and by simple

random sampling within strata. For more detailed information on this type of survey and sampling

technique see Vavreck and Rivers (2008). More broadly, see Baker et al. (2010) for a report on the

potential strengths and limitations of online panels.


Experiment 2: Construction of MTurk Sample

Subjects for the experiment were recruited with an advertisement for “A quick survey to see what you

know and how you learn.” We also invited 868 previous participants in our surveys, 115 each strong

Democrats and Republicans, 208 each Democrats and Republicans, and 111 each weak Democrats and

Republicans, in an attempt to attract more Republicans than are ordinarily found in MTurk samples.


Experiment 2: Instructions to Subjects

The experiment had three conditions: a control condition, the pay-for-correct condition, and the pay-for-

correct-and-“don’t know” condition. (It also had a fourth condition that we do not analyze here: see

Footnote 15.)

        Instructions in the control condition: “Once again, your answers will be timed. By answering



                                                        2
these questions, you will earn an additional 50 cent bonus.”

        Instructions in the pay-for-correct condition: “Once again, your answers will be timed.

Additionally, we are now going to give you a [X] cent bonus for each question you answer correctly.

We'll tell you how many questions you get right at the end of the survey. You'll get credit for answering a

question correctly if the thick horizontal bar underneath your arrow covers the correct answer. So, for

example, in the picture below, the arrow is at 5. If the correct answer were 5.25, which is under the bar,

you would earn the bonus. If the correct answer was 7, however, you would not earn the bonus.”

        Instructions in the pay-for-correct-and-“don’t know” condition: “Once again, your answers will

be timed. Additionally, we are now going to give you a X cent bonus for each question you answer

correctly. We'll tell you how many questions you get right at the end of the survey. You'll get credit for

answering a question correctly if the thick horizontal bar underneath your arrow covers the correct

answer. So, for example, in the picture below, the arrow is at 5. If the correct answer were 5.25, which is

under the bar, you would earn the bonus. If the correct answer was 7, however, you would not earn the

bonus. As an alternative to being paid for a correct answer, you can instead earn a X × Y cent bonus for

each question you tell us you don't know the answer to. We'll pay you for saying ‘don’t know’ if you

click the check box next to ‘don’t know,’ but when you do so, the location of your arrow, whether correct

or incorrect, does not affect your payment. Because the payment for ‘don’t know’ is (Y × 100)% of the

payment for getting an answer correct, you will on average earn more by selecting don't know than your

best guess if you are less than (Y × 100)% sure that the bar underneath the arrow covers the correct

answer.”


Experiment 2: Analysis of Consultation of Outside References

After the survey was over, we asked participants if they had looked up the answers to each question that

they were asked, noting explicitly that “Your bonus is already determined, and we won't change your

bonus in any way on the basis of your answer to these questions.” Of our 795 partisan participants, only

20 (2.5 percent) reported looking up the answer to 41 questions (0.74 percent of all questions asked). The

percentages of user-questions by treatment assignment are 0.32 percent (control), 0.96 percent (pay for

                                                     3
correct), and 0.64 percent (pay for correct and pay for don’t know).


Appendix References

Baker, Reg, Stephen J. Blumberg, J. Michael Brick, Mick P. Couper, Melanie Courtright, J.

Michael Dennis, Don Dillman, Martin R. Frankel, Philip Garland, Robert M. Groves, Courtney

Kennedy, Jon Krosnick, Paul J. Lavrakas, Sunghee Lee, Michael Link, Linda Piekarski, Kumar

Rao, Randall K. Thomas, and Dan Zahs. 2010. “Research Synthesis: AAPOR Report on Online

Panels.” Public Opinion Quarterly 74 (4): 711-81.


Vavreck, Lynn, and Douglas Rivers. 2008. “The 2006 Cooperative Congressional Election

Study.” Journal of Elections, Public Opinion and Parties 18 (4): 355-66.




                                                     4
APPENDIX B
(Begins on following page)




                             5
You are being asked to complete an online research survey that will take approximately 7-9 minutes. The survey is

conducted by researchers at Yale University to study how people learn. This page describes your consent.



Findings from this study may be reported in scholarly journals, at academic seminars, and at research association

meetings. The data will be stored at a secured location and retained indefinitely. No identifying information about you will

be made public and all of your choices will be kept completely confidential. Your participation is voluntary. You are free to

stop the survey at any time without penalty.



There are no known risks associated with this study beyond those associated with everyday life. Although this study will

not benefit you personally, we hope that our results will add to the knowledge about how people learn. You will receive

$0.50 for completing the survey, paid through Amazon Mechanical Turk. You will also have the opportunity to earn a

bonus of $0.50 or more, although not everyone will receive a bonus.



To participate in the study, you must be at least 18 years old and a United States resident. JavaScript must be activated

on your browser so that the graphics in the survey will work properly. The next page will test your browser.



If you have any questions about the research, you can contact Seth Hill at seth.hill@yale.edu. If you have any questions

about your rights as a research participant or concerns about the conduct of this study, you may contact the Yale

University Human Subjects Committee, Box 208010, New Haven, CT 06520-8010, 203-785-4688,

human.subjects@yale.edu.



When you are ready to begin, please elect to participate and press the Submit button. You will then be taken to the first

page of the survey.



    I agree to participate.
    I do not agree to participate.
To confirm that our survey graphics will work with your browser, please follow the instructions in the graphic
below. You have 20 seconds to complete this task. After 20 seconds, your browser will automatically proceed
to the next page.


     Please drag the arrow as far as you can to the right. You can move the arrow by
     clicking on the arrowhead and dragging.


                                                                                                  Arrow




You have 16 seconds to submit your answer before your current answer is automatically submitted.
Please read carefully and answer t he following quest ions.

Here are two personality traits that may or may not apply to you. Please check the box to indicate the extent to
which you agree or disagree with each statement. You should rate the extent to which the pair of traits applies
to you, even if one characteristic applies more strongly than the other. To demonstrate that you've read this
much, just go ahead and select both disagree strongly and agree strongly for both questions below, no matter
how you would actually answer each question. In other words, to confirm that you are paying attention, for
each question please check both of these two boxes.


I see myself as: Dependable, self-disciplined.
   Agree strongly.
   Agree moderately.
   Agree a little.
   Neither agree nor disagree.
   Disagree a little.
   Disagree moderately.
   Disagree strongly.




I see myself as: Disorganized, careless.
   Agree strongly.
   Agree moderately.
   Agree a little.
   Neither agree nor disagree.
   Disagree a little.
   Disagree moderately.
   Disagree strongly.
Please read carefully and answer t he following quest ions.


What is the highest level of education that you have achieved?
    No high school diploma.
    High school diploma or equivalent.
    Some college.
    Two year degree.
    Four year college graduate.
    Post-graduate.



What is the year of your birth?




What is your gender?
    Female.
    Male.



What is your state of residence?




Generally speaking, do you usually think of yourself as a Democrat, a Republican, an Independent, or what?
   Democrat.
   Republican.
   Independent.
   Other.
Please read carefully and answer t he following quest ions.


Some people seem to follow what's going on in government and public affairs most of the time, whether
there's an election going on or not. Others aren't that interested. Would you say you follow what's going on in
government and public affairs...?
   Most of the time.
   Some of the time.
   Only now and then.
   Hardly at all.



We are interested in the kinds of things people do when they use the internet. What kinds of things have you
used the internet for in the LAST SEVEN DAYS? (Choose as many as apply to you)
   Get directions.
   Plan vacations.
   Keep in touch with friends.
   Look at sports highlights.
   Find restaurants.
   Pay bills.
   Look up movie times.
   Shopping.
   Read the news.
   Read about politics.



Do you happen to know how much of a majority is required for the United States Senate and House to
override a Presidential veto?
   A majority (fifty percent plus one vote).
   Two-thirds (sixty-seven percent).
   Three-fourths (seventy-five percent).
   Ninety percent.
   Don't know.



Do you think most professional athletes are good role models for children today?
   Yes.
   No.
   Don't know.
In this study, we'd like you to tell us what you think the correct answer is to a number of questions. We don't
want you to look up those answers or talk to someone else, so even if you don't know please just give us your
best guess. For each question, we'll give you a short period of time -- 30 seconds -- to answer the question
before we automatically take you to the next question.


To indicate your answer, we will ask you to slide the arrow on a line like that below to the point that is closest
to your answer. You can slide that arrow by clicking your mouse on the arrowhead and dragging it to the left or
right.



         How tall is the average NBA player?




                                                                                 Your guess



                     3ft               4ft               5ft              6ft                 7ft
         Shorter                                                                                        Taller

For example, in the above graphic, if you though the correct answer was 6 feet 6 inches, you would slide the
arrow to the point midway between the lines marked 6 and 7 ft.


Give it a try! Once you are happy with where the arrow is located, you can click "Next." On the next page, we'll
give you a timed example with another question.
     How tall is the Statue of Liberty, in feet, from the base of the feet to the top of the
     torch?


                                                     Your guess



                    140ft            180ft             220ft            260ft             300ft
     Shorter                                                                                          Taller

In this example, we are asking you to indicate your best guess as to how tall the Statue of Liberty is. You can
also see how the countdown timer works -- you have 45 seconds to indicate your answer (see below). After
you've indicated your best guess, click "Next" or just wait to go to the next page. When the timer is up, you will
automatically be routed to the next page.


You have 45 seconds to submit your answer before your current answer is automatically submitted.
We're almost ready to begin. Before we proceed, we just want to make sure we've been clear about what we
are asking you to do.



     Dave has two dozen apples. He eats half of them, and then eight more. How many
     apples are left?


                                                             A guess



                        -1            1                3                5               7


In the graph above, we've placed the arrow at a certain point to indicate somebody's response to the question.
Which of the following has that person indicated is their best guess?


Their best guess is...
    1.
    2.
    3.
    4.
    5.
    None of the above.
    Dave has two dozen apples. He eats half of them, and then eight more. How many
    apples are left?


                                                           A guess



                    -1               1               3               5        7


The arrow is located midway between 3 and 5, so the person's response is 4.
We will now send you to the actual survey. On the next screen, you will be presented with your first question
and will only have a limited amount of time to respond.


Please do not use the back button in your browser during this survey. Any questions your answer a second
time by using the back button will not be recorded. When you are ready, please click Next.
Please drag the slider to your best guess to the following



     About how many U.S. soldiers were killed in Iraq between the invasion in 2003 and
     the withdrawal of troops in December 2011?


                                                              Your guess



                    2000             3000              4000            5000         6000




You have 27 seconds to submit your answer before your current answer is automatically submitted.
Please drag the slider to your best guess to the following



     According to the Census Bureau, in 2010 what percentage of the total population of
     the United States was born outside of the United States (foreign-born)?


         Your guess



                      18%             34%              50%          67%              84%




You have 28 seconds to submit your answer before your current answer is automatically submitted.
Thank you for answering those questions, we'd now like you to answer a few more questions.


Once again, your answers will be timed.


By answering these questions, you will earn an additional 50¢ bonus.


Again, please do not use the back button in your browser. Any questions your answer a second time by
using the back button will not be recorded. When you are ready to proceed, please click Next.
Please drag the slider to your best guess to the following



     In the 2008 Presidential Election, Barack Obama defeated his Republican
     challenger John McCain. In the nation as a whole, of all the votes cast for Obama
     and McCain, what percentage went to Obama?

                        Your guess



                    52.0%            54.0%            56.0%        58.0%            60.0%




You have 28 seconds to submit your answer before your current answer is automatically submitted.
Please drag the slider to your best guess to the following



     For every dollar the federal government spent in fiscal year 2011, about how much
     went to the Department of Defense (US Military)?


                                                                    Your guess



                   7 cents          11 cents         15 cents     19 cents         23 cents




You have 26 seconds to submit your answer before your current answer is automatically submitted.
Thank you for your part icipat ion!
Your bonus is already determined, and we won't change your bonus in any way on the basis of your answer to
these questions. For research purposes...


Did you look up the answer to this question?
In the 2008 Presidential Election, Barack Obama defeated his Republican challenger John McCain. In the
nation as a whole, of all the votes cast for Obama and McCain, what percentage went to Obama?
    No, I did not look up th answer to this question.
    Yes, I did look up the answer to this question.



Did you look up the answer to this question?
For every dollar the federal government spent in fiscal year 2011, about how much went to the Department of
Defense (US Military)?
    No, I did not look up th answer to this question.
    Yes, I did look up the answer to this question.



Did you look up the answer to this question?
About how many U.S. soldiers were killed in Iraq between the invasion in 2003 and the withdrawal of troops in
December 2011?
    No, I did not look up th answer to this question.
    Yes, I did look up the answer to this question.



Did you look up the answer to this question?
According to the Census Bureau, in 2010 what percentage of the total population of the United States was
born outside of the United States (foreign-born)?
    No, I did not look up th answer to this question.
    Yes, I did look up the answer to this question.



Did you look up the answer to this question?
Compared to January 2001, when President Bush first took office, how had the level of unemployment, as
measured using the unemployment rate, in the country changed by the time he left office in January 2009?
    No, I did not look up th answer to this question.
    Yes, I did look up the answer to this question.
Did you look up the answer to this question?
The Treasury Department initiated TARP (the first bailout) during the financial crisis of 2008. TARP involved
loans to banks, insurance companies, and auto companies. Of the $414 billion spent, what percentage had
been repaid, as of March 15, 2012?
   No, I did not look up th answer to this question.
   Yes, I did look up the answer to this question.



Did you look up the answer to this question?
Medicaid is a jointly funded, Federal-State health insurance program for low-income and needy people. For
every dollar the federal government spent in fiscal year 2011, about how much went to Medicaid?
   No, I did not look up th answer to this question.
   Yes, I did look up the answer to this question.
Thank you for your part icipat ion!
What is the total number of Mechanical Turk surveys you have taken about current events or politics?




What is the total number of Mechanical Turk surveys you have taken about current events or politics in the
last month?




If you would like to be contacted when we have future studies, please leave your email here. If not, leave
blank:


If you would like to leave any comments or feedback, please do so here (up to 500 characters):




Pleast continue to the next page to retrieve your code for payment!
Thank you for your participation!


You have now completed the survey.
If you have any questions, please contact seth.hill@yale.edu. If you have any questions about your rights as a
research participant or concerns about the conduct of this study, you may contact the Yale University Human
Subjects Committee at human.subjects@yale.edu.


For the purposes of getting paid on Mechanical Turk, please enter the following code into the box on the
survey's Mechanical Turk HIT page. You must enter this code to get your bonus.




If you are curious about the sources we used to score your answers, please contact us through the
Mechanical Turk interface and we are happy to provide references to you. Thank you!
APPENDIX C: ACCURACY
While the analysis reported in the main text focuses on polarization, a distinct question is whether or not

offering incentives affects accuracy, or the degree to which expressed survey responses are correct. In the

second experiment, we can examine the absolute distance between participants’ survey responses across

treatment conditions to assess the effect of incentives on accuracy. (That is, in the same 0 to 1 scale, we

can calculate the difference between a respondent’s slider placement and the correct answer in that 0 to 1

scale and then take the absolute value of the difference between those two numbers.) As before, however,

we have to decide how to treat responses from those who select “don’t know.” We code those responses

as accurate in this analysis, which means that selecting “don’t know” will mechanically (if weakly)

increase accuracy.

        We find that there is no difference between the control (flat fee) condition and the pay for correct

condition in accuracy: The average distance from the truth across questions and treatments is .28 in both

cases. 1 Our earlier results show that offering incentives for correct responses substantially reduces

partisan divergence. The analysis here suggests that convergence is, on average, no more likely to be

toward the truth than away from it. Such a pattern is consistent either with shared bipartisan but

inaccurate beliefs or, alternatively, very weak beliefs and small returns to expressive partisan responding

such that individuals are effectively guessing across some range of the scale. Indeed, the relatively high

frequency of selecting “don’t know” in the pay for correct and don’t know condition implies that many

participants understand they don’t have well-informed beliefs about the truth. Not surprisingly, therefore,

we find substantially higher accuracy in that treatment condition: The average distance from the truth in

the Pay for Correct and Don’t Know treatment is .13, or 55% smaller than in either of the other conditions

(p<.01 for tests of differences). Overall, then, when given the option to choose don’t know, it appears that

those who do so may understand that they systematically know less than those who do not.

1
 Regression results estimated from the model Absolute Value of Distance from the Truthi = b0 + b1
PayCorrecti + b2 PayCorrectDKi + Question + ei produce results substantively similar to simple
difference in average Absolute Value of Distance from the Truth scores across treatments and are
available upon request.



                                                      6
        This assertion leads naturally to our last analysis: Among those assigned to the Pay for Correct

and Don’t Know condition, how are the pre-treatment survey responses of those who will be induced to

select don’t know different from those who will continue to give a response when offered a payment both

for a correct and don’t know answer? Are those who will select don’t know less accurate, before being

treated, then those who will continue to offer a response? Is this lack of knowledge, if it exists, associated

with more or less partisan divergence? In order to understand this question, we can examine the pre-

treatment survey responses, both in terms of absolute value of distance from the truth and partisan

divergence. For the former, we estimate

        Distance from the Truthijt=0 = b0 + b1 Will Say Don’t Know ijt=1 + Question + ei,

where Distance from the Truth is the pre-treatment (t=0) absolute value of the distance from the correct

response for question j and Will Say Don’t Know=1 if the participants will select don’t know the second

time (t=1) they answer that question when offered incentives for doing so. If individuals who will later

select “don’t know” know less and understand that lack of knowledge, then we would predict b1 > 0. OLS

estimates employing this specification appear in column (1) of Appendix C Table C1. The distance from

the truth among those who will continue to offer a response rather than selecting don’t know is .185.

Among those who will select don’t know, this difference increases by .024, or about 13% (p<.05, one-

tailed), indicating that those participants who say they don’t know post-treatment were less accurate when

answering the questions pre-treatment.

        If these participants are less knowledgeable, is this associated with different levels of pre-

treatment polarization? To answer this question, we estimate

        Rijt=0 = b0 + b1 Democrati + b2 Will Say Don’t Know ijt=1 + b3 Democrati × Will Say Don’t Knowijt=1

        + Question + ei,

which is similar to our earlier models for assessing partisan divergence but instead examines pre-

treatment responses by whether the participant will subsequently choose “don’t know.” In this model, b1

is the baseline level of pre-treatment polarization between Democrats and Republicans, and b3 is how

much larger or smaller that estimate is among those who will later choose don’t know. OLS estimates


                                                      7
appear in column (2) of Table C1. Here, we find that those who will later choose don’t know are no more

or less polarized than those who will continue to offer a response. Put differently, an apparent lack of

knowledge (as demonstrated by a willingness to choose “don’t know”) is a marker of lack of knowledge

about the truth, but those partisans still diverge by a similar amount that their more informed partisan

counterparts. Divergence therefore persists but is centered on a different (less true) response than among

those who appear to have greater knowledge.




                                                      8
                                     Appendix Table A1: Experiment #1: Effect of Payment for Correct Responses on Partisan Divergence in Scale Scores by Question

                                                                           (1)           (2)              (3)                (4)             (5)              (6)               (7)               (8)
                                                                     Iraq 07 to 08                       Bush                                            Est. Bush
                                                                        Change     Bush Inflation Unemployment          Est. Bush        Iraq Total       Approval
                                                                       Casualties     Change           Change            Approval       Casualties      Among Reps.       Obama Age         McCain Age
Democrat (1=Yes, 0=Republican)                                            0.239         0.201            0.168              0.092           0.087            0.070             0.050             0.044
                                                                       [0.052]***    [0.044]***       [0.056]***         [0.023]***       [0.038]**        [0.039]*           [0.031]          [0.025]*
Payment for Correct Response * Democrat                                  -0.078        -0.026           -0.074             -0.100          -0.064           -0.072            -0.048            -0.053
                                                                         [0.077]       [0.061]          [0.079]          [0.034]***        [0.054]          [0.055]           [0.045]           [0.033]
Payment for Correct Response                                              0.043         0.059            0.091              0.018           0.051            0.026             0.005             0.010
                                                                         [0.051]       [0.052]          [0.058]            [0.024]         [0.036]          [0.039]           [0.034]           [0.024]
Constant                                                                  0.177         0.694            0.598              0.818           0.114            0.724             0.508             0.637
                                                                       [0.033]***    [0.036]***       [0.042]***         [0.016]***      [0.024]***       [0.029]***        [0.023]***        [0.019]***
Observations                                                               415           409              407                421             412              416               419               422
R-squared                                                                 0.064         0.093            0.032              0.044           0.014            0.008             0.008             0.012
Source: 2008 CCES study. Includes only Democrats and Republicans. Cases included are from control and paid for correct response condition. OLS Coefficients with robust standard errors. * significant at
10%; ** significant at 5%; *** significant at 1% (two-tailed tests).
                                             Appendix Table A2: Experiment #2: Effect of Payment for Correct and Don't Know Responses on Partisan Divergence in Scale Scores by Question

                                                                          (1)              (2)              (3)             (4)              (5)              (6)             (7)            (8)               (9)              (10)
                                                                                                                                                                                           Global
                                                                            Obama       Bush II      Defense                        Iraq deaths %      Medicaid      TARP % Paid         Warming                         Debt Service
                                                                        Unemployment Unemployment  Spending      Obama Vote 08            Black        Spending            Back            Amount        Iraq deaths        Spending
Flat fee * Democrat (1=Yes, 0=Republican)                                    0.293        0.239        0.118            0.126             0.219           0.136            0.107            0.133             0.051            0.010
                                                                          [0.065]***   [0.068]***     [0.085]          [0.086]         [0.081]***        [0.086]          [0.091]         [0.057]**          [0.072]          [0.089]
Payment Correct * Democrat                                                   0.083        0.142        0.097            0.035             0.013           0.048            0.048            0.026             0.009            0.073
                                                                           [0.042]**   [0.036]***    [0.038]**         [0.039]           [0.045]         [0.042]          [0.043]          [0.027]           [0.037]          [0.044]
Payment DK and Correct * Democrat                                            0.109        0.037        0.026            0.070             0.011          -0.003            0.016            0.039            -0.001           -0.025
                                                                          [0.032]***     [0.026]      [0.024]         [0.033]**          [0.030]         [0.025]          [0.032]         [0.019]**          [0.028]          [0.024]
Payment for Correct Response                                                 0.021       -0.049       -0.053           -0.028             0.113           0.081           -0.019            0.058            -0.009            0.042
                                                                            [0.057]      [0.072]      [0.080]          [0.080]           [0.069]         [0.079]          [0.073]          [0.055]           [0.064]          [0.082]
Payment for DK and Correct Response                                         -0.019        0.079        0.059           -0.031             0.158           0.067            0.053            0.038             0.013            0.039
                                                                            [0.054]      [0.068]      [0.076]          [0.078]          [0.064]**        [0.073]          [0.071]          [0.053]           [0.062]          [0.076]
Constant                                                                     0.401        0.586        0.630            0.467             0.241           0.489            0.346            0.605             0.522            0.490
                                                                          [0.048]***   [0.066]***   [0.073]***       [0.073]***        [0.060]***      [0.071]***       [0.066]***       [0.050]***        [0.057]***       [0.074]***
Observations                                                                  444          485          446              457               470             442              452              466               479              467
R-squared                                                                    0.077        0.099        0.050            0.029             0.023           0.022            0.017            0.028             0.005            0.029
F-test, Flat fee * Dem. > Pay Correct * Dem.                                 0.000        0.100        0.410            0.170             0.010           0.180            0.280            0.050             0.300            0.260
F-test, Pay Correct * Dem. > Pay DK and Correct * Dem.                       0.310        0.010        0.060            0.250             0.490           0.150            0.280            0.340             0.420            0.030
Source: 2012 MTURK study. Includes only Democrats and Republicans. Comparison of post-treatment responses in control, pay correct, and pay correct and don't know conditions. OLS Coefficients with robust standard errors. * significant
at 10%; ** significant at 5%; *** significant at 1% (two-tailed tests).
      Appendix Table C1: Experiment #2: Are Individuals who will be induced to select "Don't Know" more Polarized or less Knowledable?

                                                                                    (1)                               (2)
                                                                       Pre-treatment scale score       Pre-treatment absolute value of
                                                                         (+= More Democratic)           distance from correct answer
Democrat (1=Yes, 0=Republican)                                                     0.078
                                                                                [0.021]***
Will say Don't Know * Democrat                                                    -0.011
                                                                                  [0.031]
Will say Don't Know Post-treatment                                                -0.033                            0.024
                                                                                  [0.026]                          [0.012]*
Constant                                                                           0.657                            0.185
                                                                                [0.025]***                        [0.013]***
Observations                                                                       1547                              1547
R-squared                                                                          0.146                            0.157
Note: Source: 2012 MTURK study. Includes only Democrats and Republicans in pay correct and don't know condition. Robust standard errors,
clustered by respondent. Question fixed effects not reported. Number of participants is 379.
