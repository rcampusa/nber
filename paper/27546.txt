                                NBER WORKING PAPER SERIES




        POLICY EVALUATION WITH MULTIPLE INSTRUMENTAL VARIABLES

                                          Magne Mogstad
                                       Alexander Torgovitsky
                                       Christopher R. Walters

                                        Working Paper 27546
                                http://www.nber.org/papers/w27546


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                       July 2020




We thank Vishal Kamat and Ed Vytlacil for helpful comments. The views expressed herein are
those of the authors and do not necessarily reflect the views of the National Bureau of Economic
Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2020 by Magne Mogstad, Alexander Torgovitsky, and Christopher R. Walters. All rights reserved.
Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided
that full credit, including © notice, is given to the source.
Policy Evaluation with Multiple Instrumental Variables
Magne Mogstad, Alexander Torgovitsky, and Christopher R. Walters
NBER Working Paper No. 27546
July 2020
JEL No. C01,C1,C26,C31

                                         ABSTRACT

Marginal treatment effect methods are widely used for causal inference and policy evaluation
with instrumental variables. However, they fundamentally rely on the well-known monotonicity
(threshold-crossing) condition on treatment choice behavior. Recent research has shown that this
condition cannot hold with multiple instruments unless treatment choice is effectively
homogeneous. Based on these findings, we develop a new marginal treatment effect framework
under a weaker, partial monotonicity condition. The partial monotonicity condition is implied by
standard choice theory and allows for rich heterogeneity even in the presence of multiple
instruments. The new framework can be viewed as having multiple different choice models for
the same observed treatment variable, all of which must be consistent with the data and with each
other. Using this framework, we develop a methodology for partial identification of clearly
stated, policy-relevant target parameters while allowing for a wide variety of nonparametric shape
restrictions and parametric functional form assumptions. We show how the methodology can be
used to combine multiple instruments together to yield more informative empirical conclusions
than one would obtain by using each instrument separately. The methodology provides a
blueprint for extracting and aggregating information about treatment effects from multiple
controlled or natural experiments while still allowing for rich heterogeneity in both treatment
effects and choice behavior.

Magne Mogstad                                    Christopher R. Walters
Department of Economics                          Department of Economics
University of Chicago                            University of California, Berkeley
1126 East 59th Street                            530 Evans Hall #3880
Chicago, IL 60637                                Berkeley, CA 94720-3880
and NBER                                         and NBER
magne.mogstad@gmail.com                          crwalters@econ.berkeley.edu

Alexander Torgovitsky
University of Chicago
1126 E. 59th Street
Chicago, IL, 60637
atorgovitsky@gmail.com
      1    Introduction
      Heckman and Vytlacil (1999) introduced the marginal treatment effect (MTE) as a
      unifying concept for program and policy evaluation.1 Since then, MTE methods have
      become a fundamental tool for empirical work, and have been applied in a variety of
      different settings including the returns to schooling (Moffitt, 2008; Carneiro, Heckman,
      and Vytlacil, 2011; Carneiro, Lokshin, and Umapathi, 2016; Nybom, 2017) and its
      impacts on wage inequality (Carneiro and Lee, 2009), discrimination (Arnold, Dobbie,
      and Yang, 2018; Arnold, Dobbie, and Hull, 2020), the effects of foster care (Doyle Jr.,
      2007), the impacts of welfare (Moffitt, 2019) and disability insurance (Maestas, Mullen,
      and Strand, 2013; French and Song, 2014; Autor, Kostøl, Mogstad, and Setzler, 2019)
      programs on labor supply, the performance of charter schools (Walters, 2018), health
      care (Kowalski, 2018; Depalo, 2020), the effects of early childhood programs (Kline and
      Walters, 2016; Cornelissen, Dustmann, Raute, and Sch¨
                                                          onberg, 2018; Felfe and Lalive,
      2018), the efficacy of preventative health products (Mogstad, Santos, and Torgovitsky,
      2017), the quantity­quality theory of fertility (Brinch, Mogstad, and Wiswall, 2017),
      and the effects of incarceration (Bhuller, Dahl, Løken, and Mogstad, 2020), among
      many others. Mogstad and Torgovitsky (2018) provide a recent review of the MTE
      methodology and its connection to other instrumental variable (IV) approaches.
          A key assumption underlying the MTE methodology is that shifts in the instru-
      ment have a uniform effect on the treatment choices of all individuals. This is the
      well-known "monotonicity" condition introduced by Imbens and Angrist (1994), which
      Vytlacil (2002) showed is equivalent to the type of separable threshold-crossing selec-
      tion equation that had been extensively used in prior econometric work (e.g. Heckman,
      1974, 1976, 1979). Heckman and Vytlacil (2005) and Heckman, Urzua, and Vytlacil
      (2006) observed that the content of the monotonicity condition makes it more appro-
      priately described as a uniformity condition, since it restricts unobserved heterogeneity
      in how treatment choice can respond to the instruments.
          Building on their intuition, we showed elsewhere (Mogstad, Torgovitsky, and Wal-
      ters, 2020) that the Imbens-Angrist monotonicity (IAM) condition cannot hold when
      there are multiple distinct instruments unless there is no unobserved heterogeneity in
      treatment choice behavior. Yet, as we also documented in that paper, empirical re-
      searchers frequently combine multiple distinct instruments together using the two-stage
  1
     Heckman and Vytlacil (1999) initially referred to the MTE as the local instrumental variable (LIV)
before later drawing a distinction between the MTE, as an unobservable parameter, and the LIV as an
estimand that can potentially identify the MTE (Heckman and Vytlacil, 2001c,a). The ideas behind the
MTE also appear in earlier work by Bj¨
                                     orklund and Moffitt (1987), Heckman (1997), and Heckman and Smith
(1998).


                                                  1
least squares estimator, presumably motivated by the efficiency and overidentification
that arises in the classical linear IV model under homogeneous treatment effects. These
estimators do not necessarily answer a well­posed counterfactual even when IAM is
satisfied. When it is not satisfied, as with multiple instruments, they can even apply
negative weights to some complier groups (Mogstad et al., 2020). MTE methods can
be used to conduct inference on specific parameters that answer clear counterfactuals,
but again, the MTE methodology is premised on IAM, which generically does not hold
with multiple instruments.
   In this paper, we provide a solution to this problem by developing the MTE method-
ology under a strictly weaker, partial version of the IAM condition called partial mono-
tonicity (PM). The PM condition for multiple instruments is that IAM is satisfied for
each instrument separately, holding all of the other instruments fixed. The condition
is satisfied if each instrument by itself makes every individual weakly more likely to
choose treatment. While PM restricts the sign of the effects of each instrument on
treatment choices, it still allows for rich heterogeneity in the relative magnitudes of
these effects. This contrasts with IAM, which requires homogeneity in the relative
impact (Mogstad et al., 2020).
   We show that PM with multiple instruments gives rise to multiple threshold-
crossing selection equations, one for each instrument. Each selection equation is sepa-
rable in a single scalar unobservable that is derived from the marginal potential choices
induced by a single instrument. This unobservable is independent of the instrument
from which it was derived after conditioning on all of the other instruments as control
variables. This sets up a complex and unique structure that can be viewed as having
multiple different models for the same observed treatment variable, all of which must
be consistent with the data and with each other if the model is correctly specified.
   We exploit this structure by expanding the framework of Mogstad, Santos, and
Torgovitsky (2018). The flexibility of this framework allows us to incorporate multiple
different selection equations by including additional constraints that ensure they are all
consistent with one another. We call these constraints logical consistency, since they
enforce the requirement that the multiple models of treatment choice do not contradict
each other on the collection of unobserved instrument­invariant parameters for which
they all predict values. As we show through analytic examples and a numerical simu-
lation, the logical consistency condition allows information from different instruments
to be aggregated even while allowing for rich unobserved heterogeneity in both choices
and treatment effects. This provides a blueprint for thinking about how to combine
exogenous variation from multiple controlled or natural experiments.
   Other authors have considered modified MTE frameworks for settings in which the

                                            2
IAM condition is unattractive. Carneiro, Hansen, and Heckman (2003), Heckman et al.
(2006), Heckman and Vytlacil (2007b) and Cunha, Heckman, and Navarro (2007) con-
sidered multivalued ordered treatments. Heckman et al. (2006), Heckman, Urzua, and
Vytlacil (2008), Kline and Walters (2016), Heckman and Pinto (2018), Lee and Salani´
                                                                                   e
(2018) and Mountjoy (2019) analyzed settings with a discrete, unordered treatment.
Lee and Salani´
              e (2018) also considered a double hurdle model for a binary treatment,
which ends up being somewhat related to the multiple selection equations that arise un-
der PM. Gautier and Hoderlein (2015) and Gautier (2020) consider threshold-crossing
selection equations with a random coefficient structure.
    The organization of the paper is as follows. In Section 2 we introduce the model,
discuss the differences between IAM and PM, and show how PM leads to multiple
selection equations. In Section 3, we develop the MTE methodology under PM with a
particular emphasis on the concept of logical consistency that arises as a consequence
of the multiple selection equations. In Section 4, we provide analytic and numerical
examples to provide further intuition as to how logical consistency works to aggregate
information across different instruments. Section 5 contains some brief concluding
remarks.


2     Model
2.1    Potential Outcomes and Treatments
For each individual we observe an outcome Y , their binary treatment status, D  {0, 1},
an L­vector of instruments, Z with support Z  RL , and a vector of covariates, X .
To keep the notation more concise, we will suppress X throughout the paper, but all
assumptions and results can be understood to hold conditional­on­X .
    For each d  {0, 1} and z  supp(Z )  Z , let Y (d, z ) denote an individual's latent
potential outcome that they would have realized had their treatment and instrument
been externally set to d and z . Similarly, for each z  Z , let D(z ) denote their
latent potential treatment choice if the instrument were z . The observed and potential
outcomes and treatments are related through

         Y =                1[D = d, Z = z ]Y (d, z )   and D =         1[Z = z ]D(z ),   (1)
               d{0,1} z Z                                         z Z


where 1[·] is the indicator function that is 1 if · is true and 0 otherwise.
    We maintain the following standard conditions throughout the paper:
      Assumptions E.


                                                3
E.1 Y (d, z ) = Y (d, z )  Y (d) for all d  {0, 1} and z, z  Z .
E.2 E [Y (d)|Z, {D(z )}z Z ] = E [Y (d)|{D(z )}z Z ] and E[Y (d)2 ] <  for d  {0, 1}.
E.3 {D(z )}z Z  Z , where  denotes statistical independence.
Assumption E.1 is the traditional exclusion restriction that the instruments have no
direct causal effect on outcomes. Given this assumption, we can write the first part of
(1) more simply as

                              Y = DY (1) + (1 - D)Y (0).                              (2)

Assumptions E.2 and E.3 are exogeneity conditions on the instruments. These are
usually stated together as one stronger condition: (Y (0), Y (1), {D(z )}z Z  Z , see e.g.
Imbens and Angrist (1994, Condition 1) or Vytlacil (2002, L-1(i)). We have weakened
full independence to mean independence because our methodological framework will
focus on quantities that can be expressed as a mean effect of D on Y . This is common
in the MTE literature, see e.g. Heckman and Vytlacil (2007b) or Mogstad et al. (2018).
The moment condition in Assumption E.2 merely serves to ensure the existence of the
relevant conditional means.

2.2   The Imbens-Angrist Monotonicity Condition
Imbens and Angrist (1994, "IA") introduced the following assumption about the po-
tential treatment states. They described it as "monotonicity."

Assumption IAM. (IA Monotonicity) For all z, z  Z either D(z )  D(z )
almost surely, or else D(z )  D(z ) almost surely.

Assumption IAM requires a shift from one instrument value z to another value z to
either act as an incentive to take treatment for all individuals, or as a disincentive for
all individuals. It does not allow some individuals to respond positively and others
negatively. There is no presumption in Assumption IAM that Z is a scalar as opposed
to a vector, or indeed, some more exotic random object. The possibility that Z is a
vector was explicitly entertained by Imbens and Angrist (1994, pg. 470).
   Vytlacil (2002) showed that Assumptions E.2, E.3 and IAM together were equiva-
lent to assuming that D(z ) obeys a threshold-crossing model

                                  D(z ) = 1[V   (z )],                                (3)

for some unknown function  and some continuously distributed unobservable V such
that E[Y (d)|Z, V ] = E[Y (d)|V ] and V  Z . Intuitively, the potential choices {D(z )}z Z

                                            4
can be viewed as discretizations of some underlying latent proneness to take treatment,
V . Individuals with smaller values of V are more likely to take treatment, while those
with larger values of V are less likely. As Vytlacil (2002) discusses, this one-dimensional
ordering by V is a different--but equivalent--way of viewing Assumption IAM. The
primary benefit is in providing a tidy, unidimensional measure of unobserved hetero-
geneity.
   It is important to emphasize, however, that the interpretation of V is inextricable
from the definition of the instrument, Z . Indeed, Vytlacil's (2002) equivalence argu-
ment constructs V directly from the potential choices, {D(z )}z Z . Different instru-
ments thus yield different unobservables, V . Intuitively, an individual who responds to
one instrument may not respond to another. If so, their V for one instrument would
be different than their V for another instrument. This distinction becomes especially
salient when the instrument vector Z is comprised of multiple different economic vari-
ables.
   Selection equations like (3) have long been used in econometrics, typically with
additional parametric assumptions on  and/or the distribution of V (e.g. Heckman,
1974, 1976; Heckman, Tobias, and Vytlacil, 2001). Vytlacil's (2002) result shows that
these traditional econometric models can be viewed as parameterized special cases of
the potential outcomes model with Assumptions E and IAM. This observation forms
the cornerstone of the MTE literature. It implies that the potential outcomes model
under Assumptions E and IAM--the standard model of many authors since Imbens
and Angrist (1994)--can be simply viewed as a nonparametric descendent of a lineage
of fully parametric selection models. Choosing to analyze or implement these models
nonparametrically or parametrically is a research decision that comes with an attendant
trade-off between the strength of the assumptions and the strength of the conclusions.
These two poles and a broad range of research decisions in between can be unified
using the MTE (Mogstad and Torgovitsky, 2018).

2.3      Implications of IAM with Multiple Instruments
In Mogstad et al. (2020), we showed that Assumption IAM/(3) is an extremely strong
condition if Z is a vector comprising multiple distinct economic variables. It effectively
rules out any heterogeneity in treatment choice behavior. Our results amplify the obser-
vation by Heckman and Vytlacil (2005, pp. 715-716) that Assumption IAM requires
uniformity across individuals, not monotonicity in the instrument. The assumption
that all individuals respond in a uniform direction can be a reasonable assumption if
the instrument is something like a price. However, it is a strong assumption if the



                                            5
instrument consists of multiple types of incentives or disincentives.
   For example, suppose that D(z )  {0, 1} is the decision to attend college, and that
z = (z1 , z2 ), where z1  {0, 1} is a tuition subsidy and z2  {0, 1} is proximity to
college. These two instruments have been widely used in the empirical literature (e.g.
Kane and Rouse, 1993; Card, 1995). If Assumption IAM is satisfied, then it is not
possible that some individuals respond to tuition subsidies but not to distance, while
other individuals respond to distance but not to tuition subsidies. If this were the case,
then we would have

    P[1 = D(1, 0) > D(0, 1) = 0] > 0         and    P[1 = D(0, 1) > D(1, 0) = 0] > 0,    (4)
       respond to tuition, not distance               respond to distance, not tuition


which contradicts Assumption IAM, since it implies both

                P[D(0, 1)  D(1, 0)] < 1       and    P[D(1, 0)  D(0, 1)] < 1.

   Alternatively, suppose that we start with a threshold-crossing model such as

                                  D(z ) = 1[B0 + B1 z1 + z2  0],                         (5)

where B0 and B1 are both unobservable random variables with (B0 , B1 )  Z . If we
view the index in (5) as the net indirect utility from attending college, then B1 can be
interpreted as the marginal rate of substitution between tuition and proximity. This
model cannot generally be re-written in the form of (3) with a single unobservable V
unless Var(B1 ) = 0. That is, unless the marginal rate of substitution is homogeneous
across individuals.
   Proceeding anyway with the assumption that there is no heterogeneity in selection
seems unpalatable. Unobserved heterogeneity is routinely found to be important in
empirical work (Heckman, 2001), and it is an emphasis of the modern literature on
causal inference (Imbens, 2014). Indeed, the very motivation for Assumption IAM was
to make sense of linear IV estimators in the presence of unobserved treatment effect
heterogeneity (Imbens and Angrist, 1994). Allowing for unrestricted heterogeneity in
outcomes but assuming away all heterogeneity in treatment choice behavior would be an
even more extreme form of what Heckman and Vytlacil (2005) called the "fundamental
asymmetry" in IV models that maintain Assumption IAM.




                                                6
     2.4    Partial Monotonicity
     To allow for heterogeneity in treatment choices, we replace Assumption IAM with a
     weaker assumption called partial monotonicity (Mogstad et al., 2020).2 To state the
     condition, we divide vectors z  Z  RL into their th component, z , and all other
     (L - 1) components, z- . We write z = (z , z- ) to emphasize the separation of the
      th component.

     Assumption PM. (Partial Monotonicity) Take any                 = 1, . . . , L, and let (z , z- )
     and (z , z- ) be any two points in Z . Then either D(z , z- )  D(z , z- ) almost surely,
     or else D(z , z- )  D(z , z- ) almost surely.

         It is immediate that Assumption IAM implies Assumption PM, and that the two
     assumptions are equivalent when there is only a single instrument (L = 1). When
     L > 1, Assumption PM is strictly weaker than Assumption IAM; see Mogstad et al.
     (2020) for more detail. A simple sufficient condition for Assumption PM is that D(z ) is
     an increasing function of z with respect to the usual vector partial order on Z (Mogstad
     et al., 2020). Such a condition still allows for unobserved heterogeneity in the responses
     to these incentives, unlike Assumption IAM.
         For example, with the two binary college attendance instruments, Assumption PM
     is satisfied if all individuals are more likely to attend college when it is closer and/or
     subsidized. That is, if

             D(1, z2 )  D(0, z2 ) for z2 = 0, 1   and D(z1 , 1)  D(z1 , 0) for z1 = 0, 1.

     This does not involve a comparison between D(0, 1) and D(1, 0), and thus allows for
     (4), so that some individuals may respond to distance but not to subsidies, and vice-
     versa. In terms of the random coefficient threshold-crossing model (5), Assumption PM
     allows for Var(B1 ) > 0, as long as B1 is non-negative (or non-positive) with probability
     1. Using the net utility interpretation of this equation, Assumption PM allows for
     unobserved heterogeneity in the magnitude of the marginal rate of substitution, just
     not in the sign.
2
    Mountjoy (2019) used a similar assumption in a setting with multiple unordered treatments.




                                                   7
2.5      Selection Equations under PM
Assumption PM can be used to derive selection equations similar to (3). Consider first
the marginal potential treatments, defined for each      as

                 D (z )            1[Z- = z- ]D(z , z- )  D(z , Z- ),                      (6)
                           z- Z-


where Z denotes the support of Z  R, and Z- denotes the support of Z-  RL-1 .
For example, if there are two binary instruments, so that Z = {0, 1}2 , then there are
two sets of marginal potential treatments, and (6) can be written for          = 1, 2 as

                            D1 (z1 ) = Z2 D(z1 , 1) + (1 - Z2 )D(z1 , 0)
                    and     D2 (z2 ) = Z1 D(1, z2 ) + (1 - Z1 )D(0, z2 ).                  (7)

That is, D1 (z1 ) is the treatment choice an individual would have made had Z1 been set
to z1 while Z2 remained at its observed realization, whereas D2 (z2 ) is the treatment
choice they would have made if Z2 were set to z2 with Z1 unchanged.
   Conditional on Z- , each marginal potential treatment is equal to a single joint
potential treatment:

                          P[D (z ) = D(z , z- )|Z- = z- ] = 1.                             (8)

As a consequence, Assumption PM implies that each collection of marginal potential
treatments {D (z )}z   Z    satisfies Assumption IAM conditional on any realization of
Z- , since

  P[D (z )  D (z )|Z- = z- ] = P[D(z , z- )  D(z , z- )|Z- = z- ]  {0, 1}                  (9)

for any z , z  Z and any z-  Z- . With two binary instruments, this means that
either

           P[D1 (1)  D1 (0)|Z2 = z2 ] = 1   or   P[D1 (0)  D1 (1)|Z2 = z2 ] = 1

for both z2  {0, 1}, as well as the analogous condition with the roles of the two
instruments flipped.
   Notice that Assumption E.3 does not imply that {D (z )}z          Z       Z . That is, the
marginal potential treatments are not independent of the instrument. This is because
D (z ) directly depends on Z- , which is itself a subvector of Z ; see (6) and the special


                                             8
case (7). However, Assumption E.3 does imply the weaker condition

                    {D (z )}z   Z    Z |Z-        for every    = 1, . . . , L,      (10)

so that each set of marginal potential treatments is independent of the single instrument
from which it was derived, conditional on the other instruments.
   Combining (9) with (10) means that Vytlacil's (2002) equivalence result can still be
applied to construct L different threshold-crossing equations of the form (3). Specifi-
cally, the result implies that for each   = 1, . . . , L,

                              D (z ) = 1 [V   (z , Z- )] ,                          (11)

for some unknown function  and some continuously distributed unobservable V such
that V  Z |Z- and

                     E[Y (d)|Z, V ] = E[Y (d)|Z- , V ]        for d = 0, 1.         (12)

This is the same as (3), but now there is one selection equation for each component Z of
the L­dimensional vector of instruments, Z , and each selection equation is conditional
on a set of "controls" consisting of all other instruments, Z- .
   As in the usual analysis under Assumption IAM, we will normalize (8) so that
the distribution of the unobservable is uniform. This follows because the distribution
function of V conditional on Z- --call it F --is strictly increasing on its support, so
that (11) can be written as

          D (z ) = 1 [F (V |Z- )  F ( (z , Z- )|Z- )] = 1[U  p(z , Z- )],           (13)

where U  F (V |Z- ) is uniformly distributed over [0, 1] for each , conditional on
any value of Z- . The second equality here follows because

               p(z , Z- ) = P[D (z ) = 1|Z = z , Z- ]
                          = P[V   (z , Z- )|Z- ] = F ( (z , Z- )|Z- ),

as a consequence of V being independent of Z , conditional on Z- .
   As in the standard threshold-crossing model, (3), U can be interpreted as a latent
proneness to take the treatment, with smaller values corresponding to higher proneness.
However, now there is a different U for each instrument, so that this proneness is
measured against the incentive (or disincentive) created by the th instrument. This


                                              9
    U2    1                                                             U2   1

     p(1, 1)                                                            p(1, 1)

                                            D=0
     p(1, 0)                                                            p(1, 0)
                                                                                           Unconditional support
     p(0, 1)                                                            p(0, 1)


     p(0, 0)       D=1                                                  p(0, 0)


          0                                                                  0
               0   p(0, 0)   p(0, 1)   p(1, 0)      p(1, 1)   1                   0   p(0, 0)   p(0, 1)   p(1, 0)   p(1, 1)   1
                                                              U1                                                              U1

   (a) Support of (U1 , U2 ) given Z = (0, 1).                          (b) Unconditional support of (U1 , U2 ).

Figure 1: The joint support of (U1 , U2 ) when L = 2 and Z = {0, 1}2 . While both U1 and U2
have uniform marginal distributions over [0, 1] by construction, their joint support will be a proper
subset of the unit square conditional on Z . If Z has finite support, as in this example, then the
unconditional support of U will also be a proper subset of the unit square.


      reflects the point raised earlier that the interpretation of the latent variable V (or
      U ) is derived from the instrument, and so cannot be interpreted in isolation from the
      instrument. It is therefore possible for individuals to have a high value of U1 and a low
      value of U2 or vice versa, since these variables measure proneness to take treatment
      along different preference dimensions.
          However, these possibilities have limits. This is because each selection model pro-
      vides a different representation of the same observed treatment status through (13). As
      a consequence, the components of (U1 , . . . , UL ) must be statistically dependent, even
      though each of its marginal distributions are uniform. That is, its distribution--which
      is a copula given the normalizations--cannot be the product copula. Not only that,
      but (U1 , . . . , UL ) will also generally be dependent with the entire vector Z , since each
      U is only independent of Z given Z- , but is not generally independent of Z- , as
      observed in (6) and (7).
          To visualize these properties, return to the case with two binary instruments and
      consider the joint distribution of (U1 , U2 ) conditional on Z = (z1 , z2 ). In order for (13)
      to hold for both         = 1 and           = 2, one must have that

                         P 1 [U1  p(z1 , z2 )] = 1 [U2  p(z1 , z2 )] Z = (z1 , z2 ) = 1,

      for any realization of (z1 , z2 ). That is, either U1 and U2 are both smaller than p(z1 , z2 ),
      or else U1 and U2 are both larger than p(z1 , z2 ). This region of support is depicted

                                                                   10
in Figure 1a. Taking the union of this set across all four values of (z1 , z2 ) gives the
unconditional support of (U1 , U2 ), which is depicted in Figure 1b. Two subsets of the
unit square necessarily have zero mass: It is not possible to have either U1  p(0, 0)
and U2  p(1, 1) together, nor U1  p(1, 1) and U2  p(0, 0). The reason is that under
(13), either pair of realizations would entail always choosing both D = 1 and D = 0
for any realization of Z .
    Instead of deriving (13) from Assumption PM, one can also derive it directly from
a non separable threshold-crossing equation with multiple unobservables. For example,
suppose that L = 2 with potential outcomes determined by the random coefficients
specification of indirect utility in (5). From (5), the two pre-normalized selection
equations (11) can be derived as

                     V1
                                  1 (z )                            V2          2 (z )
                   (B0 + Z2 )
    D1 (z1 ) = 1 -                 z1      and D2 (z2 ) = 1 -(B0 + B1 Z1 )       z2      .
                      B1

Notice in particular that even though (B0 , B1 ) is independent of (Z1 , Z2 ), this will
not be the case for (V1 , V2 ). Instead, V1 is dependent with Z2 , and in general only
independent with Z1 after conditioning on Z2 . Similarly, V2 is dependent with Z1
with independence between V2 and Z2 only guaranteed after conditioning on Z1 . In
addition, V1 and V2 are clearly dependent, since they are both functions of B0 and B1 .
    If Var(B1 ) = 0, so that B1 = b1 is constant, then we can write

         D1 (z1 ) = 1 [-B0  b1 z1 + Z2 ]    and D2 (z2 ) = 1 [-B0  b1 Z1 + z2 ] ,

so that both equations could be rationalized by a single threshold-crossing equation
with a single unobservable,

                                             V       (z1 ,z2 )

                             D(z1 , z2 ) = 1 -B0  b1 z1 + z2 .

That is, (5) could be written in form (3), and Assumption IAM would be satisfied.
Without the assumption that Var(B1 ) = 0--that is, homogeneity in the marginal rate
of substitution--such a reformulation is not generally possible.


3     Methodology
In this section, we develop the MTE methodology under Assumption PM. We begin
in Section 3.1 by defining different instrument­specific MTEs as the fundamental unit


                                            11
     of analysis in the model. In Section 3.2, we describe the class of target parameters
     that we focus on. In Section 3.3, we review the identification analysis developed by
     (Mogstad et al., 2018, "MST" hereafter), which showed how to flexibly move between
     point and partial identification under Assumption IAM. In Section 3.4, we then adapt
     this methodology to Assumption PM by using the concept of "logical consistency,"
     which links together the various instrument­specific MTEs into a greater whole. In
     Section 3.5 we discuss some implications for testing whether Assumptions IAM and
     PM hold.

     3.1    Marginal Treatment Response Functions
     For each instrument, Z , and its unobservable, U , we define the marginal treatment
     response (MTR) function

                    m (d|u , z- )  E [Y (d)|U = u , Z- = z- ]       for d = 0, 1.         (14)

     The MTR function describes variation in potential outcomes as a function of the
     propensity to take treatment along the th margin, U , again conditioning on all other
     instruments, Z- = z- . Each MTR function, m , generates a marginal treatment
     effect (MTE) function (Heckman and Vytlacil, 1999, 2001c, 2005, 2007a,b) formed as
     m (1|u , z- ) - m (0|u , z- ). We let m  (m1 , . . . , mL ), and assume that m belongs
     to a known parameter space M  M1 × · · · × ML that encodes prior information
     (assumptions) that the researcher wants to impose about the MTR pairs.3
         Each MTR and its corresponding MTE is defined in terms of a different margin of
     selection, U , which is itself defined by the th instrument component. Since the MTRs
     are instrument-specific, they are not directly comparable. However, a key point for our
     discussion ahead is that each MTR still describes the entire population, just organized
     along a different dimension of choice behavior. Thus, while the MTRs for different
     will typically be different, they cannot be arbitrarily different.
         For example, consider again the case with two binary instruments. Figure 2a plots
     m1 (1|·, z2 ) assuming (for simplicity) that this function does not vary with z2 , and so
     can be represented by a single solid line. It also plots m2 (1|·, z1 ) for both z1 = 0 and
     z1 = 1. While m1 is not directly comparable to m2 , both functions are a conditional
     mean for the same random variable, Y (1). To be logically consistent then, it should
3
    We assume throughout that each M is contained in a vector space.




                                                 12
         Two MTRs that are logically consistent                  Two MTRs that are logically in consistent
   MTR




                                                               MTR
                 m1 (1|u1 , 0) = m1 (1|u1 , 1)                           m1 (1|u1 , 0) = m1 (1|u1 , 1)
                 m2 (1|u2 , 0)                                           m2 (1|u2 , 0)
                 m2 (1|u2 , 1)                                           m2 (1|u2 , 1)
         0         0.2       0.4    0.6          0.8      1          0     0.2       0.4    0.6          0.8     1
                             u1 and u2                                               u1 and u2

   (a) Both m1 and m2 imply the same value                     (b) The value of E[Y (1)] implied by m1
   of E[Y (1)]. These MTR pairs are logically                  is different (smaller) from that implied by
   consistent.                                                 m2 . These MTR pairs are logically incon-
                                                               sistent.

Figure 2: MTRs along different margins of selection (different U ) are not directly comparable.
Nevertheless, they are not completely unrelated, since both MTRs provide a description of the entire
population.


         be the case that

                                 E [m1 (1|U1 , Z2 )] = E[Y (1)] = E [m2 (1|U2 , Z1 )] ,                   (15)

         so that both m1 and m2 generate the same mean for Y (1). In Figure 2a this is the
         case, since the integrals of both dotted curves are the same as the integral of the solid
         line.
             In contrast, the m2 function in Figure 2b is not logically consistent with m1 . The
         areas under m2 (1|·, 0) and m2 (1|·, 1) are clearly greater than the area under m1 (1|·, 0) =
         m1 (1|·, 1). It cannot be the case that both m1 and m2 are describing the conditional
         mean of Y (1), since these two MTRs would imply different values of E[Y (1)] through
         (15). In the following, we will develop a method that requires logical consistency, so
         that pairs like those in Figure 2b are excluded from consideration. As we show later,
         excluding such pairs allows information gained about one instrument's MTR be used
         to restrict the MTR of another instrument.




                                                          13
3.2     The Target Parameter
We assume that the researcher has a well-posed empirical or policy question that can
be informed by a specific target parameter,  . We require the target parameter to be
a linear function of the L MTR pairs, having the form

              L             L                   1
    (m) =           (m )                E           m (d|u , Z- ) (d|u , Z , Z- ) du       ,   (16)
              =1            =1 d{0,1}       0


where  are weighting functions specified by the researcher. The weighting functions
are assumed to be known given knowledge of the joint distribution of (Y, D, Z ). Heck-
man and Vytlacil (2005, 2007b), MST, and Mogstad and Torgovitsky (2018) provided
catalogues of weighting functions for common target parameters. When L = 1, (16)
reduces to the form used for the target parameter by MST.
   When L > 1, there might be several ways to express the same target parameter.
For example, if  is the population average treatment effect (ATE), E[Y (1) - Y (0)],
then one could take  (1|u , z ) = 1 and  (0|u , z ) = -1 for any , while setting all
other weight functions to 0. This is another manifestation of the logical consistency
issue illustrated in Figure 2. When using multiple instruments, we will impose logical
consistency, so that the implied value of the ATE is the same for any . Thus, as a
practical matter, any choice of will yield the same inference on an instrument-invariant
parameter such as the ATE, the average effect of the treatment on the treated (ATT),
or the average effect of the treatment on the untreated (ATU).
   Other interesting target parameters might be instrument-specific. For example, the
class of policy-relevant treatment effects (PRTEs) introduced by Heckman and Vytlacil
(2001a, 2005) includes parameters that measure the impact of changing the incentive
associated with a given instrument. A special case of a PRTE is an extrapolated local
average treatment effect (LATE), such as

                                                                      
      LATE1 (+ %)  E Y (1) - Y (0) p(0, Z2 ) < U1               1+         × p(1, Z2 ) ,       (17)
                                                                     100

which is the LATE that would result if the Z1 instrument were changed sufficiently
to cause a  % increase in participation under Z1 = 1. This target parameter can be
used to gauge the sensitivity of point identified IV estimates to the definition of the
complier group. See Heckman and Vytlacil (2005), Carneiro, Heckman, and Vytlacil
(2010), and MST for further discussion and additional examples of PRTEs.
   When the definition of the target parameter depends on the instrument, as in (17),
the weights will also need to depend on the instrument, and the logical consistency


                                                14
issue will not immediately arise. Nevertheless, there will still be a benefit to requiring
instrument-invariant parameters to be logically consistent across different MTRs. As
we demonstrate ahead, this requirement will allow information to flow between different
instruments, so that their exogenous variation can be aggregated. The surprising
implication is that even if the target parameter is instrument-specific, inference on
that target parameter can still benefit from combining multiple instruments.

3.3   Using Each Instrument Separately
In this section, we briefly review the MST methodology for inference on  under
Assumption IAM. In the multiple instrument setting, this can be equivalently viewed
as using one instrument at a time, conditioning on the rest as covariates. In the next
section, we then augment the methodology to combine multiple instruments together
using the concept of logical consistency.
   Suppose that (Y (0), Y (1), D) were generated by (13) for any , with MTR function
m . Then Proposition 1 of MST shows that for any (measurable) known or identified
function s,

                                              1
         E[s(D, Z )Y ] =             E            m (d|u , Z- ) s (d|u , Z ) du                 (18)
                            d{0,1}        0

   where       s (0|u, Z )  s(0, Z )1[u > p(Z )]           and  s (1|u, Z )  s(1, Z )1[u  p(Z )].

MST refer to a choice of s as an IV­like specification, and show that by choosing s
appropriately, one can reproduce any linear IV estimand on the left-hand side of (18).
Given a collection S of IV­like specifications, we say that an MTR m is consistent
with the observed data under S if it satisfies (18) for every s  S . We denote the set
of such pairs by

                      Mobs  {m : m satisfies (18) for each s  S} .

   The identified set for the th MTR pair is defined as

                                         Mid  M  Mobs .

That is, Mid is the collection of MTR pairs for the th instrument that satisfy the
researcher's prior assumptions (m  M ) and are consistent with the observed data
for the choice of IV­like estimands in S (m  Mobs ). The identified set for the th




                                                      15
component of the target parameter in (16) is the projection of Mid under  , or

                                       B id   (m ) : m  Mid .

If M is a convex set, then B id is an interval, [ ,  ], with endpoints given by

                                 inf        (m )               and             sup  (m ),
                              m Mid                                          m Mid


see Proposition 2 in MST.
   To compute the endpoints of this interval, MST assume that M has a linear­in­
parameters form, so that each m  M can be written as

                      K
 m (d|u , z- ) =             k b k (d|u , z- )              for some   ( 1 , . . . ,    K   )    RK , (19)
                      k=1

where b   k   are known basis functions. If  can be specified as a set of linear equalities
and inequalities, then this assumption makes  (and  ) the optimal value of a finite­
dimensional linear program with  as the variables of optimization:

                          K                                K
           = min               k       k    s.t.                k sk = E[s(D, Z )Y ]    for all s  S ,   (20)
                  
                       k=1                             k=1

where
                                                       1
                          k                 E              b k (d|u , Z- ) (d|u , Z , Z- ) du     ,
                                 d{0,1}            0

                                                       1
                and   sk                    E              b k (d|u , Z- ) s (d|u , Z , Z- ) du   ,
                                 d{0,1}            0


are both identified quantities that can be directly estimated from the observed data.
MST, Mogstad and Torgovitsky (2018), and Shea and Torgovitsky (2019) discuss dif-
ferent ways of specifying  to incorporate nonparametric or parametric specifications,
with or without additional shape constraints.

3.4     Combining Instruments through Logical Consistency
Condition (18) can be applied for each                           to restrict each of the L MTR functions
in isolation. We connect them by requiring logical consistency in the unobservable
quantities they imply. For example, in Figure 2 we noted that every m implies a value



                                                               16
      for E[Y (1)] given by

                                                             1
                                     E[Y (1)] = E                m (1|u , Z- ) du .                     (21)
                                                         0

      We will restrict attention to choices of m for which the right-hand side of (21) is
      invariant to      = 1, . . . , L.4 This restricts our attention to MTRs like those in Figure
      2a, while ruling out inconsistent pairs like those in Figure 2b. The result will be tighter
      inference on each  , as well as on the overall target parameter,  .
          We formalize the property of logical consistency in a similar fashion to the data
      consistency condition, (18). A straightforward modification of Proposition 1 in MST
      shows that if (Y (0), Y (1), D) were generated by (13) with MTR function m , then

                                                             1
                            E[s(D, Z )Y (d)] = E                               s (u , Z )du
                                                                 m (d|u , Z- )¯
                                                         0

                          where      ¯ (u, Z )   (0|u, Z ) +  s (1|u, Z ).
                                      s              s
                                                                                                        (22)

      This equation is like (18) with the important difference that it is in terms of the latent
      potential outcomes, Y (d). In contrast to (18), where the left-hand side quantity was a
      direct function of the observed data, in (22) the left-hand side is in general not point
      identified. Nevertheless, the left-hand side of (22) does not vary with , so the right-
      hand side should not either. Thus, we say that a collection of MTRs m  (m1 , . . . , mL )
      is logically consistent under S if

                     E[s(D, Z )Y (d)] implied by m                      E[s(D, Z )Y (d)] implied by m


              E                     s (u , Z ) du
                      m (d|u , Z- )¯                     =E                          s (u , Z ) du
                                                                       m (d|u , Z- )¯

                   for d = 0, 1, all s  S , and all ,               {1, . . . , L}.                     (23)

          Given a set of IV­like specifications, S , the set of logically consistent MTRs is

                               Mlc  {m  (m1 , . . . , mL ) : m satisfies (23)} .
   4
     This is similar in spirit to the concept of a "coherent model" (e.g. Heckman, 1978; Tamer, 2003; Lewbel,
2007; Chesher and Rosen, 2012). However, it is different because (21) is an unobservable quantity--not a
feature of the observed data--and so one could proceed without requiring (21) to be invariant to as in the
previous section. Note that Maddala (1983, Section 7.5) uses the phrase "logical consistency" to describe
a coherency condition in a simultaneous binary response model, so our use of this phrase differs from his.
Torgovitsky (2019, Section S6.2) showed how logical consistency arises in an overlapping dynamic potential
outcomes model of state dependence.




                                                             17
                                                       m1
                                              n                    info
                                         atio                             rma
                                                                             tion
                                 inform                   .
                                                          .
                                                          .
                                                                                      Logical consistency:
        Data consistency:        information                       information
                                                       m                             Implied E[s(D, Z )Y (d)]
        Implied E[s(D, Z )Y ]
                                                                                       does not vary with
        matches data for all
                                 info                                               for both d = 0 and d = 1
                                        rm                .                 tion
                                          atio            .            rma
                                              n           .        info
                                                      mL




Figure 3: The data consistency condition (18) constrains each m to be consistent with the
observed data is isolation. Logical consistency (23) ties the m together across = 1, . . . , L. This
allows the information contained in different instruments to flow in the direction of the arrows, and
therefore be combined across models that use different instruments.


      To combine multiple instruments together, we focus on the identified set

                                             Mid  M  Mobs  Mlc ,

      where Mobs  Mobs          obs
                   1 × · · · × ML . The identified set for the target parameter is then
      the projection of Mid under  , or

                                        B id   (m) : m  Mid .

         Figure 3 illustrates how the logical consistency condition allows information to flow
      between different MTR functions. Intuitively, (18) places restrictions on m for each
      by requiring it to match the observed data, whereas the logical consistency condition
      propagates these restrictions from m to m . The result is a sort of equilibrium in
      which none of the MTR functions contradict each other on their implications for the
      instrument-invariant quantities E[s(D, Z )Y (d)] equated in (23). Limiting attention to
      the smaller set of MTRs that are consistent with this equilibrium mechanically shrinks
      the identified set for the target parameter as well.
         The logical consistency condition is a collection of linear equality constraints, so
      adding it does not fundamentally alter the conclusions or procedure in MST. In par-
      ticular, if M is a convex set, then a minor change to Proposition 2 of MST shows that
      B id is an interval, [ ,  ], with endpoints given by

                                 inf       (m)      and         sup  (m),
                                mMid                             mMid



                                                     18
If the linear­in­parameters representation (19) is maintained for all                        = 1, . . . , L with
  (1 , . . . , L )  , then  can be found by modifying (20) to incorporate all MTRs
as well as the logical consistency constraint:

                        L     K
            = min                  k   k
                 
                        =1 k=1
                        K
                 s.t.          k sk = E[s(D, Z )Y ]          for all s  S ,         = 1, . . . , L,
                        k=1
                         K                 K1
                               k¯s =             1k ¯s     for all s  S ,     = 2, . . . , L,              (24)
                                  k                  1k
                        k=1            k=1

where for shorthand we have defined
                                           1
                         ¯s  E
                                                               s (u , Z )du
                                               b k (d|u , Z- )¯                 .
                           k
                                       0

If  consists only of linear equalities and inequalities, then (24) remains a finite-
dimensional linear program in terms of quantities that are all point identified.

3.5   Testable Implications
Under Assumption IAM, the nonparametric IV model in Section 2 has testable impli-
cations (Balke and Pearl, 1997; Imbens and Rubin, 1997), and several authors have
developed formal statistical tests of these implications in different forms (Huber and
Mellace, 2014; Kitagawa, 2015; Mourifi´
                                      e and Wan, 2016). MST observe that these
testable implications manifest themselves in the MTE methodology through the pos-
sibility that the identified set is empty. When using each instrument separately, as
in Section 3.3, this would mean that Mid is empty, and would imply that either the
th instrument does not satisfy Assumption IAM, conditional on Z- , or that some
aspect of Assumptions E are false. If the researcher specified M to include additional
assumptions, then finding Mid to be empty could also call these into question.
   This logic also holds when combining instruments, as in Section 3.4. Suppose that
Assumptions E and the researcher's specification of M are beyond question. Then
finding Mid empty implies that Assumption PM is violated. Now suppose that we add
the following assumption as part of the specification of M:

                  m (d|u, z- ) = m1 (d|u, z1 )  m0 (d|u)
                         for all d = 0, 1, u  [0, 1], all l, and z-  Z- .                                  (25)



                                                     19
This assumption says that all of the L MTR functions are in fact the same, which
among other things implies that they cannot depend on any component of Z . When
(25) is imposed, the logical consistency condition (23) is immediately satisfied, and
Mid reduces to the identified set obtained by using all instruments together under
Assumption IAM. Thus, finding an empty identified set when (25) is imposed, but not
when it is not, is evidence that Assumption IAM can be rejected, but that the strictly
weaker Assumption PM cannot be rejected.


4     Aggregating Multiple Instruments
In this section, we demonstrate how the logical consistency condition allows multiple
instruments to be aggregated for more informative inference. In Section 4.1, we provide
an algebraic example that shows how a model that would normally be just­identified
becomes over­identified when logical consistency is imposed. In Section 4.2, we show
that the same principles are at work even without point identification. In Section 4.3,
we describe the results of a numerical simulation that shows how logical consistency
interacts with the choice of target parameter and the auxiliary identifying assumptions
maintained by the researcher.

4.1    An Illustrative Example with Point Identification
The following example demonstrates how the logical consistency condition yields addi-
tional over­identifying information that can be used to relax assumptions or to power
a specification test.
    Consider a setting with two binary instruments, so that Z = {0, 1}2 . As discussed,
these two instruments give rise to two selection equations like (13) with two unobserv-
ables U1 and U2 , and therefore two marginal treatment response functions, m1 and m2 .
To simplify the example, we will focus solely on the MTR function evaluated at the
treated state, d = 1, so that our objects of concern are m1 (1|u1 , z2 ) and m2 (1|u2 , z1 ),
viewed as functions of (u1 , z2 )  [0, 1] × {0, 1} and (u2 , z1 )  [0, 1] × {0, 1}, respectively.
    Suppose that we assume m1 (1|u1 , z2 ) is a linear function of u1 for each value of z2 ,
so that

                        m1 (1|u1 , z2 ) = 0 + 1 u1 + 2 z2 + 3 z2 u1 ,                       (26)

for some unknown parameters   (0 , 1 , 2 , 3 ). Brinch, Mogstad, and Wiswall
(2012; 2017) showed that  is point identified as long as p(1, 0) = p(0, 0), and p(1, 1) =
p(0, 1). Their argument uses the implications of (26) for the observed mean of the


                                               20
treated group:

                    E[Y |D = 1, Z1 = z1 , Z2 = z2 ]
                         = E[Y (1)|U1  p(z1 , z2 ), Z2 = z2 ]
                                         p(z1 ,z2 )
                              1
                         =                          m1 (1|u1 , z2 ) du1
                           p(z1 , z2 ) 0
                                  1                               1
                         = 0 + p(z1 , z2 )1 + z2 2 + p(z1 , z2 )3 .                       (27)
                                  2                               2

Thus, if p(1, 0) = p(0, 0), then 0 and 1 are point identified by a linear regression of
                    1
Y on a constant and 2 p(Z1 , Z2 ) in the Z2 = 0 subpopulation, while p(1, 1) = p(0, 1)
ensures that 2 and 3 can be point identified off of the same linear regression in the
subpopulation with Z2 = 1.
   The logical consistency condition exploits the observation that (26) also has impli-
cations for the conditional mean of the treated outcome for the untreated group. This
quantity is not observed, but it can be expressed in terms of  using an argument
similar to (27):

            E[Y (1)|D = 0, Z1 = z1 , Z2 = z2 ]
                           1                             1
                   = 0 +     (1 + p(z1 , z2 )) 1 + z2 2 + (1 + p(z1 , z2 )) 3 .           (28)
                           2                             2

Since  is point identified, these counterfactual mean outcomes are also point identified.
They could be used to evaluate treatment parameters that can be expressed in terms
of the first selection model with unobservable U1 . The more surprising finding is that
they could also be used as additional identifying information for the second selection
model with unobservable U2 .
   One way to see this is to consider a specification for m2 (1|u2 , z1 ) that would typically
not be point identified in the current setting. For example, suppose that

                    m2 (1|u2 , z1 ) = 0 + 1 u2 + 2 z1 + 3 z1 u2 + 4 u2
                                                                     2,                   (29)

so that m2 (1|u2 , z1 ) is more flexible than m1 (1|u1 , z2 ) in having an additional quadratic
term. While this function now has five unknown parameters,   (0 , 1 , 2 , 3 , 4 ),
there are still only four observed conditional means: E[Y |D = 1, Z1 = z1 , Z2 = z2 ] for
(z1 , z2 )  {0, 1}2 . If the selection model for U2 were viewed in isolation, then  would
not be point identified. However, the logical consistency condition effectively provides
four more moments via (28). Since  is point identified, these moments can be treated



                                              21
       as known.
          With eight moments total, it is possible to point identify (indeed, overidentify) the
       five parameters in  . In analogy to (27) and (28), the system of equations is given by:

                p(0,0)                       p(0,0)2
                                                    
         1                0       0
                                                                                              
                  2                             3                  E[Y |D = 1, Z = (0, 0)]
         
         1      p(1,0)                       p(1,0)2 
                  2       0       0             3
                                                              
                                                               E[Y |D = 1, Z = (1, 0)] 
                                                                                         
                                             p(0,1)2  0
                                                       
                p(0,1)          p(0,1)                                                   
         1                1                                    E[Y |D = 1, Z = (0, 1)] 
         
                  2               2             3       
                                             p(1,1)2  1 
                                                                                         
                p(1,1)          p(1,1)
                                                        
         1                1
                                                              
                                                               E[Y |D = 1, Z = (1, 1)] 
                                                                                         
                  2               2             3
                                            1-p(0,0)3  2     =E[Y (1)|D = 0, Z = (0, 0)] . (30)
                                                        
               1+p(0,0)
                                                                                         
         1                0       0
         
                  2                        3(1-p(0,0))   
                                                        
                                            1-p(1,0)3  3 
                                                                                         
         1     1+p(1,0)                                                                  
                  2       0       0        3(1-p(1,0)) 
                                                              E[Y (1)|D = 0, Z = (1, 0)]
                                            1-p(0,1)3  4
                                                                                         
               1+p(0,1)       (1+p(0,1))
                                                       
         1                1                                   E[Y (1)|D = 0, Z = (0, 1)]
                                                                                         
                  2               2        3(1-p(0,1)) 
               1+p(1,1)       (1+p(1,1))    1-p(1,1)3         E[Y (1)|D = 0, Z = (1, 1)]
         1        2       1       2        3(1-p(1,1))


       The entire right-hand side of (30) is known: The first four quantities are observed in
       the data, and the second set of four are identified using the selection model for the first
       instrument via (28), since  is point identified. The coefficient matrix on the left-hand
       side of (30) can be full rank, depending on the values of the propensity score.5 When
       this is the case, the linear system of equations either has no solution, or a unique
       solution. If there is no solution, then the model is misspecified, while if there is a
       unique solution, then  is point identified.6 Thus, the quadratic MTR specification
       (29) can be point identified even though the only source of exogenous variation in the
       second selection model is the binary instrument, Z2 . The reason is that the second
       selection model also harnesses some of the information from the first model--that is,
       some of the exogenous variation in Z1 --through the logical consistency condition.

       4.2    An Illustrative Example with Partial Identification
       The next example shows that the implications of the previous example are not specific
       to cases with point identification.
          Suppose again that there are two instruments, Z1 and Z2 . As before, assume that
       Z1  {0, 1} is binary, but now suppose that Z2 is continuous. Actually, assume that
       Z2 is not only continuous, but that it has full support, in the sense that the support
       of p(z1 , Z2 )|Z1 = z1 is [0, 1] for both z1 = 0, 1. It is well­known that in this case the
       average treatment effect (ATE) is point identified, since for each z1 there exists (at
   5
     For example, take p(0, 0) = .3, p(1, 0) = .45, p(0, 1) = .55, and p(1, 1) = .7.
   6
     It is common to call  point identified regardless of which case holds, since the identified set consists of
no more than a single element for both cases. The ambiguity comes from whether one is tacitly assuming
that the model is correctly specified, which in our notation means M is not empty. We maintain a distinction
between the two cases here just for clarity.

                                                       22
least in the limit) an instrument value z
                                        ¯2 such that p(z1 , z
                                                            ¯2 ) = 1. This implies that

      E[Y (1)|Z1 = z1 ] = E[Y (1)|Z1 = z1 , Z2 = z
                                                 ¯2 ] = E[Y |D = 1, Z1 = z1 , Z2 = z
                                                                                   ¯2 ],

with a similar argument applying to the case with d = 0. See, for example, Heckman
(1990), Manski (1990) and Heckman and Vytlacil (2001b).
   However, suppose that our interest is not in the ATE, but in an instrument­specific
target parameter involving the first instrument. For example, suppose that we are
interested in the average treatment effect among the 99% of the population who are
most likely to take treatment when measured according to Z1 . This parameter can be
written as

                        LATE1 (0, .99)  E[Y (1) - Y (0)|U1  .99].                          (31)

This object is nearly the same as the ATE; it differs only by the 1% of the population
excluded from the conditioning event. If we only had the first instrument at our
disposal, we would be trying to identify an object that is very nearly the ATE with
only a binary instrument. The bounds could be expected to be quite wide if p(0, Z2 )
and p(1, Z2 ) are far from 0 and 1 for "many" realizations of Z2 .
   On the other hand, this line of reasoning ignores the information that we have from
the second instrument. That information is sufficient to point identify the ATE, which
is nearly the same as the generalized LATE in (31). The relationship between the two
objects can be written as

                                   1
               LATE1 (0, .99) =       (ATE - .01 E[Y (1) - Y (0)|U1 > .99]) .
                                  .99

Since the ATE is point identified from the second instrument, this expression implies
that the identified set for LATE1 (0, .99) can actually be quite narrow. Indeed, if y and
                                                                                    ¯
y
¯ are the logical bounds on Y , then the identified set for LATE1 (0, .99) is contained in
the interval

                     1                      1
                        ATE - .01(¯
                                  y - y) ,               y - y)
                                               ATE + .01(¯               ,
                    .99               ¯    .99               ¯
                           .02
which has width of only         y-
                           .99 (¯    y ).
                                     ¯
4.3    Numerical Simulation
In this section, we illustrate how logical consistency interacts with additional assump-
tions on the MTR functions using a numerical simulation.

                                             23
                                z = (z1 , z2 ) P[Z = z ]      p(z )
                                    (0, 0)            .4       .3
                                    (0, 1)            .3       .5
                                    (1, 0)            .1       .6
                                    (1, 1)            .2       .7

     Table 1: The distributions of Z and D|Z = z in the numerical simulation.


   The simulation is like the example in Section 4.1 with two binary instruments.
The joint distribution of (Z1 , Z2 ) and the propensity score p(z ) are shown in Table 1.
The propensity score is increasing in each component of Z , so that both instruments
can be viewed as incentives that make choosing D = 1 more attractive, as in the
college attendance example. We assume that Y  {0, 1} is binary, so that conditional
expectations of Y are bounded between 0 and 1, and we generate the data using model
 = 1 with an MTR that is linear in u1 and does not depend on z2 :

                  m1 (0|u1 , z2 ) = .5 - .1u1   and m1 (1|u1 , z2 ) = .8 - .4u1 .

In all results that follow, we use a saturated specification of S , so that S consists of
indicator functions 1[(D, Z ) = (d, z )] for all possible combinations of d and z .
   Figure 4 reports bounds on the average treatment on the treated (ATT). These
bounds are derived under specifications of m (d|u , z- ) that are K th order Bernstein
polynomials in u , and fully interacted in z- , with different parameters for d = 0 and
d = 1. We implement these polynomials using the Bernstein basis so that it is easy
to impose shape constraints (see Mogstad et al., 2018, Section S.2). There are three
sets of bounds shown for increasing values of K1 = K2 , as well as exact nonparametric
bounds indicated with horizontal lines.
   The two wider sets of bounds are derived using the                 = 1 and   = 2 instruments
in isolation. The bounds are different because with           = 1, the instrument is Z1 , with
Z2 serving as a control variable, while with          = 2 the instrument is Z2 , with Z1 as a
control. The third set of bounds is computed while also imposing logical consistency
between the two models. This substantially tightens both the nonparametric bounds
and the polynomial bounds at all polynomial degrees.
   Notice in particular that the logical consistency bounds are tighter than the inter-
sections of the      = 1 and      = 2 bounds. This shows that logical consistency is not
just a matter of taking intersection bounds across differ instruments used separately.
Instead, it involves harmonizing the intricate common predictions about instrument-


                                                 24
                                               Bounds on the average treatment on the treated (ATT)


                                     0.8              (Nonparametric)


                                     0.6
           Upper and lower bounds



                                     0.4


                                     0.2


                                       0


                                    -0.2
                                                 = 1 without logical consistency
                                    -0.4         = 2 without logical consistency
                                                With logical consistency

                                           1     2       3      4      5      6     7      8      9
                                                     Polynomial degree for both models (K1 = K2 )

Figure 4: Imposing logical consistency tightens bounds on the average treatment on the treated
(ATT) for both parametric and nonparametric specifications of the MTR functions.


     invariant quantities that one would obtain using each instrument separately, as for-
     malized through the set of equalities (23). These equalities effectively combine the
     information from the two instruments into a whole that is greater than the sum of
     their parts. As Figure 4 shows, this can substantially tighten inference. For example,
     the nonparametric bounds under logical consistency are as tight as the bounds using
     each instrument separately with a 5th order polynomial.
         In Figure 5, we report bounds on LATE1 (+ %), as defined in (17) for  = 20.
     This quantity can only be expressed in terms of the unobservable U1 for the first in-
     strument. Nevertheless, comparing the four sets of bounds in Figure 5 shows that the
     second instrument provides information on LATE1 (+20%) through the logical consis-
     tency condition. Thus, the logical consistency condition allows information from the
     second instrument to propagate to the first instrument. This extra information results
     in tighter bounds than would be possible using the first instrument in isolation. In
     this data generating process, the additional information is small (but still present)
     when m2 is left nonparametric. Adding the nonparametric shape constraints that
     m2 (0|·, z1 ), m2 (1|·, z1 ) and m2 (1|·, z1 ) - m2 (0|·, z2 ) are decreasing functions for every z1


                                                                        25
                                      Bounds on an extrapolated LATE for model          = 1 (LATE1 (+%20))


                                    0.3

                                   0.25
         Upper and lower bounds


                                    0.2

                                   0.15

                                    0.1

                                   0.05

                                      0

                                  -0.05        = 2 model
                                              Not used (no logical consistency)
                                  -0.1        Nonparametric
                                              Nonparametric, decreasing
                                  -0.15       Linear

                                          1    2      3     4       5      6          7     8       9
                                                   Polynomial degree for the      = 1 model (K1 )

Figure 5: The = 2 model provides identifying content for parameters, such as LATE1 (+%20),
that can only be defined using the = 1 model.


     provides substantially more information.
         A vivid case occurs when m2 is specified as linear (K2 = 1). Under this assumption,
     all instrument-invariant quantities are point identified using only variation in Z2 . A
     parameter that is specific to the first instrument, like LATE1 (+20%), generally remains
     partially identified. Suppose, however, that we impose the assumption that m1 is
     quadratic (K1 = 2). If we were using only variation in Z1 , then we would still expect
     LATE1 (+20%) to be partially identified. Indeed we can see that this is the case in
     Figure 5, where the bounds without imposing logical consistency are approximately
     [.075, .175] when K = 2. Imposing logical consistency with m2 linear collapses these
     bounds into a single point, consistent with the example discussed in Section 4.1.


     5            Conclusion
     A central conclusion of the modern IV literature is that the parameter estimated by
     a traditional linear IV estimator depends on the instrument itself. This conclusion
     gives cause for concern; certain instruments may lead to less relevant parameters and


                                                                      26
there might be no available instrument that answers the researcher's specific scientific
or policy question. MTE methods address this dilemma by returning primary focus to
the definition of the target parameter, leaving the specifics of how it can be identified
(parametrically, nonparametrically, partially, etc.) as a separate and conceptually dis-
tinct issue. However, MTE methods crucially depend on the monotonicity condition
(threshold-crossing equation) introduced by Imbens and Angrist (1994). This condi-
tion is extremely strong when there are multiple instruments, since it assumes away
all meaningful choice heterogeneity (Mogstad et al., 2020).
   In this paper, we have extended the MTE methodology under a weaker, par-
tial monotonicity condition. Partial monotonicity allows for rich patterns of unob-
served heterogeneity in choices, while still remaining rooted in an interpretable choice-
theoretic model that is fundamentally nonparametric. We showed how to modify the
general partial identification framework of Mogstad et al. (2018) to allow for par-
tial monotonicity instead of the stronger, traditional monotonicity condition. The
framework provides a general, flexible way for researchers to explore the assumptions­
conclusion frontier through different parametric and nonparametric shape restrictions
on the underlying marginal treatment response functions. It can be implemented at
scale using linear programming.
   An unusual feature of the framework is that it can be viewed as having multiple
different selection models for the same treatment. In order to rationalize these models
simultaneously, we imposed a condition called logical consistency. The logical consis-
tency condition effectively allows information from one instrument about one marginal
treatment response function to be transferred to another marginal treatment response
function defined by a different instrument. This allows for the accumulation of iden-
tifying content from multiple instruments, ensuring that the whole is greater than the
sum of its parts. The method provides a path for extracting and aggregating infor-
mation about treatment effects from multiple different sources of exogenous variation
while still maintaining plausible conditions on choice behavior and allowing for rich
unobserved heterogeneity.

References
Arnold, D., W. Dobbie, and C. S. Yang (2018): "Racial Bias in Bail Decisions," The
  Quarterly Journal of Economics, 133, 1885­1932. 1

Arnold, D., W. S. Dobbie, and P. Hull (2020): "Measuring Racial Discrimination in Bail
  Decisions," Working Paper 26999, National Bureau of Economic Research. 1

Autor, D., A. Kostøl, M. Mogstad, and B. Setzler (2019): "Disability Benefits, Con-

                                           27
  sumption Insurance, and Household Labor Supply," American Economic Review, 109, 2613­
  54. 1

Balke, A. and J. Pearl (1997): "Bounds on Treatment Effects From Studies With Imperfect
  Compliance," Journal of the American Statistical Association, 92, 1171­1176. 19

Bhuller, M., G. B. Dahl, K. V. Løken, and M. Mogstad (2020): "Incarceration,
  Recidivism, and Employment," Journal of Political Economy, 128, 1269­1324. 1

  ¨ rklund, A. and R. Moffitt (1987): "The Estimation of Wage Gains and Welfare Gains
Bjo
  in Self-Selection Models," The Review of Economics and Statistics, 69, 42­49. 1

Brinch, C. N., M. Mogstad, and M. Wiswall (2012): "Beyond LATE with a Discrete
  Instrument," Working paper. 20

------ (2017): "Beyond LATE with a Discrete Instrument," Journal of Political Economy,
  125, 985­1039. 1, 20

Card, D. (1995): "Using Geographic Variation in College Proximity to Estimate the Return to
  Schooling," in Aspects of Labour Market Behaviour: Essays in Honour of John Vanderkamp,
  ed. by L. N. Christofides, K. E. Grant, and R. Swidinsky, Toronto: University of Toronto
  Press, 201­222. 6

Carneiro, P., K. T. Hansen, and J. J. Heckman (2003): "2001 Lawrence R. Klein
  Lecture Estimating Distributions of Treatment Effects with an Application to the Returns to
  Schooling and Measurement of the Effects of Uncertainty on College Choice," International
  Economic Review, 44, 361­422. 3

Carneiro, P., J. J. Heckman, and E. Vytlacil (2010): "Evaluating Marginal Policy
  Changes and the Average Effect of Treatment for Individuals at the Margin," Econometrica,
  78, 377­394. 14

Carneiro, P., J. J. Heckman, and E. J. Vytlacil (2011): "Estimating Marginal Returns
  to Education," American Economic Review, 101, 2754­81. 1

Carneiro, P. and S. Lee (2009): "Estimating Distributions of Potential Outcomes Using
  Local Instrumental Variables with an Application to Changes in College Enrollment and
  Wage Inequality," Journal of Econometrics, 149, 191­208. 1

Carneiro, P., M. Lokshin, and N. Umapathi (2016): "Average and Marginal Returns to
  Upper Secondary Schooling in Indonesia," Journal of Applied Econometrics, 32, 16­36. 1

Chesher, A. and A. Rosen (2012): "Simultaneous Equations Models for Discrete Outcomes:
  Coherence, Completeness and Identification," cemmap working paper 21/12. 17




                                             28
Cornelissen, T., C. Dustmann, A. Raute, and U. Scho        ¨ nberg (2018): "Who Benefits
  from Universal Child Care? Estimating Marginal Returns to Early Child Care Attendance,"
  Journal of Political Economy, 126, 2356­2409. 1

Cunha, F., J. J. Heckman, and S. Navarro (2007): "The Identification and Economic
  Content of Ordered Choice Models with Stochastic Thresholds," International Economic
  Review, 48, 1273­1309. 3

Depalo, D. (2020): "Explaining the Causal Effect of Adherence to Medication on Cholesterol
  through the Marginal Patient," Health Economics, n/a. 1

Doyle Jr., J. J. (2007): "Child Protection and Child Outcomes: Measuring the Effects of
  Foster Care," The American Economic Review, 97, 1583­1610. 1

Felfe, C. and R. Lalive (2018): "Does Early Child Care Affect Children's Development?"
  Journal of Public Economics, 159, 33­53. 1

French, E. and J. Song (2014): "The Effect of Disability Insurance Receipt on Labor
  Supply," American Economic Journal: Economic Policy, 6, 291­337. 1

Gautier, E. (2020): "Relaxing Monotonicity in Endogenous Selection Models and Application
  to Surveys," arXiv:2006.10997 [math, stat]. 3

Gautier, E. and S. Hoderlein (2015): "A Triangular Treatment Effect Model with Random
  Coefficients in the Selection Equation," arXiv:1109.0362 [math, stat]. 3

Heckman, J. (1974): "Shadow Prices, Market Wages, and Labor Supply," Econometrica, 42,
  679­694. 1, 5

------ (1997): "Instrumental Variables: A Study of Implicit Behavioral Assumptions Used in
  Making Program Evaluations," The Journal of Human Resources, 32, 441­462. 1

Heckman, J., J. L. Tobias, and E. Vytlacil (2001): "Four Parameters of Interest in the
  Evaluation of Social Programs," Southern Economic Journal, 68, 210. 5

Heckman, J. J. (1976): "The Common Structure of Statistical Models of Truncation, Sample
  Selection and Limited Dependent Variables and a Simple Estimator for Such Models," Annals
  of Economic and Social Measurement. 1, 5

------ (1978): "Dummy Endogenous Variables in a Simultaneous Equation System," Econo-
  metrica, 46, 931­959. 17

------ (1979): "Sample Selection Bias as a Specification Error," Econometrica, 47, 153­161. 1

------ (1990): "Varieties of Selection Bias," The American Economic Review, 80, 313­318. 23




                                             29
------ (2001): "Micro Data, Heterogeneity, and the Evaluation of Public Policy: Nobel Lec-
  ture," The Journal of Political Economy, 109, 673­748. 6

Heckman, J. J. and R. Pinto (2018): "Unordered Monotonicity," Econometrica, 86, 1­35.
  3

Heckman, J. J. and J. A. Smith (1998): "Evaluating the Welfare State," NBER Working
  Paper 6542. 1

Heckman, J. J., S. Urzua, and E. Vytlacil (2006): "Understanding Instrumental Vari-
  ables in Models with Essential Heterogeneity," Review of Economics and Statistics, 88, 389­
  432. 1, 3

------ (2008): "Instrumental Variables in Models with Multiple Outcomes: The General Un-
  ordered Case," Annales d'Economie et de Statistique, 91/92, 151­174. 3

Heckman, J. J. and E. Vytlacil (2001a): "Policy-Relevant Treatment Effects," The Amer-
  ican Economic Review, 91, 107­111. 1, 14

------ (2005): "Structural Equations, Treatment Effects, and Econometric Policy Evaluation,"
  Econometrica, 73, 669­738. 1, 5, 6, 12, 14

Heckman, J. J. and E. J. Vytlacil (1999): "Local Instrumental Variables and Latent Vari-
  able Models for Identifying and Bounding Treatment Effects," Proceedings of the National
  Academy of Sciences of the United States of America, 96, 4730­4734. 1, 12

------ (2001b): "Instrumental Variables, Selection Models, and Tight Bounds on the Average
  Treatment Effect," in Econometric Evaluations of Active Labor Market Policies in Europe,
  ed. by M. Lechner and F. Pfeiffer, Heidelberg and Berlin: Physica. 23

------ (2001c): "Local Instrumental Variables," in Nonlinear Statistical Modeling: Proceedings
  of the Thirteenth International Symposium in Economic Theory and Econometrics: Essays
  in Honor of Takeshi Amemiya, ed. by K. M. C Hsiao and J. Powell, Cambridge University
  Press. 1, 12

------ (2007a): "Chapter 70 Econometric Evaluation of Social Programs, Part I: Causal Mod-
  els, Structural Models and Econometric Policy Evaluation," in Handbook of Econometrics,
  ed. by J. J. Heckman and E. E. Leamer, Elsevier, vol. Volume 6, Part 2, 4779­4874. 12

------ (2007b): "Chapter 71 Econometric Evaluation of Social Programs, Part II: Using the
  Marginal Treatment Effect to Organize Alternative Econometric Estimators to Evaluate
  Social Programs, and to Forecast Their Effects in New Environments," in Handbook of
  Econometrics, ed. by J. J. Heckman and E. E. Leamer, Elsevier, vol. Volume 6, Part 2,
  4875­5143. 3, 4, 12, 14




                                             30
Huber, M. and G. Mellace (2014): "Testing Instrument Validity for LATE Identification
  Based on Inequality Moment Constraints," Review of Economics and Statistics, 97, 398­411.
  19

Imbens, G. W. (2014): "Instrumental Variables: An Econometrician's Perspective," Statistical
  Science, 29, 323­358. 6

Imbens, G. W. and J. D. Angrist (1994): "Identification and Estimation of Local Average
  Treatment Effects," Econometrica, 62, 467­475. 1, 4, 5, 6, 27

Imbens, G. W. and D. B. Rubin (1997): "Estimating Outcome Distributions for Compliers
  in Instrumental Variables Models," The Review of Economic Studies, 64, 555­574. 19

Kane, T. J. and C. E. Rouse (1993): "Labor Market Returns to Two- and Four-Year
  Colleges: Is a Credit a Credit and Do Degrees Matter?" Working Paper 4268, National
  Bureau of Economic Research. 6

Kitagawa, T. (2015): "A Test for Instrument Validity," Econometrica, 83, 2043­2063. 19

Kline, P. and C. R. Walters (2016): "Evaluating Public Programs with Close Substitutes:
  The Case of Head Start*," The Quarterly Journal of Economics, 131, 1795­1848. 1, 3

Kowalski, A. E. (2018): "Behavior within a Clinical Trial and Implications for Mammography
  Guidelines," Working Paper 25049, National Bureau of Economic Research. 1

Lee, S. and B. Salanie ´ (2018): "Identifying Effects of Multivalued Treatments," Economet-
  rica, Forthcoming. 3

Lewbel, A. (2007): "Coherency and Completeness of Structural Models Containing a Dummy
  Endogenous Variable," International Economic Review, 48, 1379­1392. 17

Maddala, G. S. (1983): Limited-Dependent and Qualitative Variables in Econometrics, 3,
 Cambridge university press. 17

Maestas, N., K. J. Mullen, and A. Strand (2013): "Does Disability Insurance Receipt
 Discourage Work? Using Examiner Assignment to Estimate Causal Effects of SSDI Receipt,"
 The American Economic Review, 103, 1797­1829. 1

Manski, C. F. (1990): "Nonparametric Bounds on Treatment Effects," The American Eco-
 nomic Review, 80, 319­323. 23

Moffitt, r. (2008): "Estimating Marginal Treatment Effects in Heterogeneous Populations,"
 Annales d'Economie et de Statistique, 239­261. 1

Moffitt, R. A. (2019): "The Marginal Labor Supply Disincentives of Welfare Reforms,"
 Working Paper 26028, National Bureau of Economic Research. 1


                                            31
Mogstad, M., A. Santos, and A. Torgovitsky (2017): "Using Instrumental Variables
 for Inference about Policy Relevant Treatment Parameters," NBER Working Paper. 1

------ (2018): "Using Instrumental Variables for Inference About Policy Relevant Treatment
  Parameters," Econometrica, 86, 1589­1619. 2, 4, 12, 24, 27

Mogstad, M. and A. Torgovitsky (2018): "Identification and Extrapolation of Causal
 Effects with Instrumental Variables," Annual Review of Economics, 10. 1, 5, 14, 16

Mogstad, M., A. Torgovitsky, and C. R. Walters (2020): "The Causal Interpretation
 of Two-Stage Least Squares with Multiple Instrumental Variables," Working paper. 1, 2, 5,
 7, 27

Mountjoy, J. (2019): "Community Colleges and Upward Mobility," Working paper. 3, 7

       ´, I. and Y. Wan (2016): "Testing Local Average Treatment Effect Assumptions,"
Mourifie
 The Review of Economics and Statistics, 99, 305­313. 19

Nybom, M. (2017): "The Distribution of Lifetime Earnings Returns to College," Journal of
  Labor Economics, 000­000. 1

Shea, J. and A. Torgovitsky (2019): "Ivmte: An R Package for Implementing Marginal
  Treatment Effect Methods," Working Paper. 16

Tamer, E. (2003): "Incomplete Simultaneous Discrete Response Model with Multiple Equi-
  libria," The Review of Economic Studies, 70, 147­165. 17

Torgovitsky, A. (2019): "Nonparametric Inference on State Dependence in Unemployment,"
  Econometrica, 87, 1475­1505. 17

Vytlacil, E. (2002): "Independence, Monotonicity, and Latent Index Models: An Equiva-
  lence Result," Econometrica, 70, 331­341. 1, 4, 5, 9

Walters, C. R. (2018): "The Demand for Effective Charter Schools," Journal of Political
 Economy, 126, 2179­2223. 1




                                           32
