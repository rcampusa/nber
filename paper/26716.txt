                              NBER WORKING PAPER SERIES




                    FORECASTING THE RESULTS OF EXPERIMENTS:
                       PILOTING AN ELICITATION STRATEGY

                                       Stefano DellaVigna
                                          Nicholas Otis
                                           Eva Vivalt

                                      Working Paper 26716
                              http://www.nber.org/papers/w26716


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                                    January 2020




We are grateful for financial support from the Alfred P. Sloan Foundation (G-2019-12325), and
an anonymous foundation. Vivalt is also supported by the John Mitchell Economics of Poverty
Lab at the Australian National University. We thank seminar participants at the ASSA 2020, and
especially our discussant, David McKenzie. The paper will appear in the 2020 AEA Papers and
Proceedings. We also thank the authors of the forecast studies for their support and contributions
to the survey and the respondents for their time. The views expressed herein are those of the
authors and do not necessarily reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2020 by Stefano DellaVigna, Nicholas Otis, and Eva Vivalt. All rights reserved. Short sections
of text, not to exceed two paragraphs, may be quoted without explicit permission provided that
full credit, including © notice, is given to the source.
Forecasting the Results of Experiments: Piloting an Elicitation Strategy
Stefano DellaVigna, Nicholas Otis, and Eva Vivalt
NBER Working Paper No. 26716
January 2020
JEL No. O1,O17

                                          ABSTRACT

Forecasts of experimental results can clarify the interpretation of research results, mitigate
publication bias, and improve experimental designs. We collect forecasts of the results of three
Registered Reports preliminarily accepted to the Journal of Development Economics , randomly
varying four features: (1) small versus large reference values; (2) whether predictions are in
raw units or standard deviations; (3) text-entry versus slider responses; and (4) small versus
large slider bounds. Forecasts are generally robust to elicitation features, though wider slider
bounds are associated with higher forecasts throughout the forecast distribution. We make
preliminary recommendations on how many forecasts should be gathered.


Stefano DellaVigna                               Eva Vivalt
University of California, Berkeley               Research School of Economics
Department of Economics                          Australian National University
549 Evans Hall #3880                             Acton ACT 2601
Berkeley, CA 94720-3880                          Australia
and NBER                                         eva.vivalt@anu.edu.au
sdellavi@econ.berkeley.edu

Nicholas Otis
University of California, Berkeley
2121 Berkeley Way West
Berkeley, CA 94720
notis@berkeley.edu
  In the last decade, economics has increasingly focused on ways to encourage research

transparency, such as through pre-registration and pre-analysis plans. These efforts are

intended to improve the informativeness and interpretation of research results, but

relativelylittleattentionhasbeenpaidtoanotherpracticethatcouldhelptoachievethis

goal:relatingresearchfindingstotheviewsofthescientificcommunity,policy-makers,and

the general public by eliciting forecasts of research results. The idea of this practice is to

collectandstorepredictionsofresearchresultsbeforetheresultsareknown.Thismakesit

possibleexposttorelatethefindingstopriorexpectations.Suchforecastscanimprovethe

informativeness of research results in three main ways, as discussed in more detail in

DellaVigna,Pope,andVivalt(2019).

  First, forecasts can improve the interpretation of research results since they put those

results in context and are often of independent interest. For example, in research on the

replication of experiments, Camerer et al. (2016) capture the expected probability that a

study would replicate. In a behavioral context, DellaVigna and Pope (2018) compare the

effects of different behavioral motivators to experts' predictions about which motivators

wouldbemosteffective.Inbothcases,thepredictionsarehighlycorrelatedwiththeactual

outcomes;thisisimportanttoknow,sinceitimpliesthatresearchers'intuitionaboutwhich

studieswouldreplicate,andaboutbehavioralmotivators,areonaveragemostlycorrect.In

athirdexample,VivaltandCoville(2017)documentthatpolicy-makersoverestimatethe

effectivenessofRCTinterventions.Thesethreeexamplesillustratehowpredictionscanadd

anextralayerofunderstandingtothestudyitself.Importantly,predictionsmustbecollected

inadvance,toavoidhindsightbias("Weknewitalready").




                                                                                            2
  Second,forecastscanmitigatepublicationbiasagainstnullresults.Nullresultsareless

likelytobepublished,evenwhenauthorshaveusedrigorousmethodstoanswerimportant

questions(Francoetal.2014).Ifpriorsarecollectedbeforeastudyiscarriedout,theresults

canbecomparedtotheaverageexpertprediction,ratherthantothenullhypothesisofno

effect.

  Third,forecastsmayhelpwithexperimentaldesign.Forexample,supposethataresearch

team could select one of ten different interventions to be evaluated in a randomized

controlledtrial.Forecastscouldbeusedtogaugewhichpotentialtreatmentarmwouldhave

ahighervalueofinformation.

  Withthesethreemotivationsinmind,wearedevelopinganonlineplatformresearchers

canusetocollectforecastsofsocialscienceresearchresults(www.socialscienceprediction.org).

Theplatformaimstomakeiteasiertoelicitforecastsbyprovidingsurveytemplatesand

makingitpossibletotrackforecastsforanindividualacrossdifferentstudies.Thisinturn

enablesresearchonthedeterminantsofforecastaccuracy.Acentralizedplatformcanalso

helpbycoordinatingrequestsforforecastssoastoreduceforecasterfatigue.

  Beforethisplatformcanbeausefultoolfortheprofession,however,importantquestions

must be answered about how to elicit predictions. In particular, we focus on four survey

designconsiderations.

  First,priortoelicitingpredictions,wemaywishtogiveforecastersanexampletoensure

thattheyunderstandwhattheirresponsescouldmean.Towhatextentmightthisexample

anchor subsequent forecasts? Second, raw units may be more familiar or intuitive to

forecasters,butinsomecontextsonlyforecastsofstandarddeviations(SDs)canbeelicited,

suchasforindices.Thus,wewouldliketounderstandwhetherforecastsdifferifpredictions



                                                                                      3
were gathered using raw units or standard deviations. Third, there is no consensus on

whetheritispreferabletousesliderbarsoratextentryresponse.Comparedtosliderbars,

textentrymayavoidanchoringeffects,butcouldincreaseerrorssuchastypos.Finally,if

sliderbarsareused,doesthewidthofthesliderbarsaffectthepredictions?

  Inthispre-registeredpilot,weexperimentallytestwhetherthesefourfeaturesaffectthe

predictionsofresearchersandpractitioners(DellaVignaetal.,2020).

I.ForecastStudies

  We collected forecasts of the results of three large field experiments preliminarily

acceptedbytheJournalofDevelopmentEconomics,usingtheir"pre-resultsreview"track,

which evaluates research on the basis of rigor, feasibility, and importance (Journal of

DevelopmentEconomics,2018).Thethreestudieshaveundergonepeerreviewandtheir

resultsareunknown,makingthemexcellenttargetsforprediction.

  Study 1. Yang et al. (2019) are running an experiment in Mozambique examining the

effects of health and education interventions targeting households with orphaned and

vulnerablechildrenonavarietyofHIVoutcomes.Wecollectedforecastsoftheimpactof

being assigned to receive home visits from a local community worker; these visits were

supposedtoincludereferralsforHIVtesting,toprovideinformationrelatedtoHIV/AIDS,

and to involve discussions to reduce concerns about stigma. Our forecast outcome was

whetherhouseholdsreportedhavinganymemberreceiveHIVtestinginthelastyear.

  Study2.In2016,Rwandareformedanentrepreneurshipcourserequiredforallstudents

ingrades10­12.BlimpoandPugatch(2019)areexaminingtheeffectsofateacher-training

program implemented in the same year, which included multiday training sessions,

exchangevisitsacrossparticipatingschools,andsupportfromtrained"YouthLeaders."We


                                                                                     4
collectedforecastsoftheimpactofthisinterventionon(1)thepercentageofstudentswho

droppedout(reversecoded);(2)thepercentageofstudentswhoreportedearningmoney

fromabusinessinthepriormonth;and(3)standardizedentrepreneurshiptestscores.

  Study3.BouguenandDillon(2019)arerunningarandomizedcontrolledtrialevaluating

theimpactofanunconditionalcash,asset,andnutritiontransferprogram.Randomization

tookplaceatthevillagelevel,withpoorhouseholdsintreatedvillagesreceiving(1)acash

transfer,(2)acombinedcashandassettransfer,or(3)acombinedcash,asset,andnutrition

transfer.Wecollectedforecastsoftheimpactoftheseinterventionson(1)foodconsumption

and(2)healthconsumption.

II.ForecastElicitation

  We worked with each of the three project teams to develop a short description of the

study,includinginformationonsetting,experimentaldesign,andoutcomesofinterest.Each

teamreviewedandapprovedoursurveysbeforewebegandatacollection.

  Consenting respondents were randomized to provide predictions for one of the three

studiesdescribedabove.Theyfirstreadthestudydescription,whichincludedalinktothe

registered report. We then asked them to forecast the experimental impacts of the

treatments.Participantswereabletorevisitthestudydescriptioninanewwindowwhile

providingresponses.TheywerealsogiventhemeanandSDofthepredictedoutcomesfrom

areferenceconditiontocontextualizeresponses.Whenastudyhadmorethanoneoutcome,

we randomly varied the order in which participants provided their forecasts. After

participantscompletedpredictionsforonestudy,theyweregiventhechoicetocontinueand

providepredictionsforoneoftheothertwostudies(oftheirchoosing),ortoendthesurvey.

Thosepredictingtheresultsofasecondstudyweregivenasimilarchoiceforthethirdstudy.


                                                                                    5
A. RandomizedSurveyFeatures

  We randomized four features of our forecast elicitation at the individual level. (1) We

randomizedthereferencevalue(±0.1or±0.3SDs)usedinanexamplejustbeforeforecasts

wereprovided.(2)WevariedwhetherresponsesweregiveninSDsorinrawunits.(3)We

randomized whether respondents gave their predictions via a slider scale or simple text

entry.Fortextentries,weboundedresponsesat2.0SDs.(4)Amongthesampleproviding

responsesonasliderscale,wevariedwhetherthesliderwasboundedat±0.5or±1.0SDs.

B.SampleofForecasters

  We sent our forecasting survey to individuals in several research organizations (the

BusaraCenterforBehavioralEconomics,GiveWell,theGlobalPrioritiesInstitute,IDinsight,

andtheWorldBank).WealsosentittotheBerkeleydevelopmenteconomicsListservand

postedalinktothesurveyonTwitter.Finally,theauthorsofthethreestudiesprovidedalist

of35totalrespondentstheywantedtosendtheirsurveyto(forthese,thefirstpredicted

studywasnotrandomized).

  We offered incentives to Listserv and Twitter respondents who completed all three

studies. Listserv respondents received a $10 Amazon Gift Card, and Twitter respondents

withanacademicemailaddresshada10%chanceofreceivinga$50VisaCashCard.Overall,

106peoplerespondedtooursurvey,foratotalof772predictions.

III.Results

  Wecompareforecastsofexperimentaltreatmenteffectsforthethreepredictedstudies

acrossourfourexperimentalelicitationconditions.Tocompareresultsacrossstudiesand

outcomes, we standardize predictions made in real units using the SD of a reference

condition.


                                                                                       6
  Table1summarizespredictionsacrossthethreeforecaststudies.Theaveragepredicted

effect size is 0.16 SD, which is comparable to the average treatment effect of 0.12 SD

estimated from 635 results from development interventions (Vivalt, forthcoming). Even

within a study, forecasters are differentiating across outcomes. For example, the average

forecasteffectofteachertrainingonstudentdropout(reversecoded)is0.02SD,compared

toapredicted0.29effectonentrepreneurshiptestscores(PanelC).

  Weobtainpreciseestimatesofpredictedtreatmenteffects.Forexample,forYangetal.

(2019)(PanelB),with73responsestheaveragepredictedtreatmenteffectis0.23SD,with

aconfidenceintervalof[0.19,0.27].Whentheexperimentiscompleteandtreatmenteffects

areknown,theauthorscouldcomparetheirestimateswiththeseforecastedeffects.

  Wecanthenconsiderwhetherforecastsdifferacrossourfoursurveyelicitationfeatures.

AsTable2shows,threefeaturesofelicitationhavenoimpact.First,thereferencevalueused

inanexample(e.g.,0.1vs.0.3SD)doesnotaffecttheresults.Second,thereisnodifference

inforecastselicitedinrawunits(e.g.,percentageofhouseholdmemberstestedforHIV)or

standard deviations. (In the table we translate predictions in raw units into standard

deviationstoallowforcomparison.) Third,theaverageforecastiscomparablewhenusing

sliderbarsortextentry.

  Thislastcomparison,however,masksanimportantdimensionofheterogeneity.When

thesliderhasawiderrange(±1.0SD),theelicitedforecastsarelargerthanwhentheslider

hasanarrowerrange(±0.5SD).

  Figure 1 shows that this is not due to censoring at the top in the narrow slider bar

condition;onlyonerespondentinthisconditionprovidedapredictionof0.5SD.Infact,the

entiredistributionisshiftedtotherightwhenwidersliderboundswerepresented.Thismay



                                                                                       7
reflect that forecasters are making an inference from the bounds, or that the bounds are

anchoring their responses. To the extent that the researcher is interested in comparing

forecastsacrossstudies,itisimportanttouseconsistentsliderranges.

   Finally, one may wonder if the forecasts differ by type (faculty, PhD students, or

researchers) or by recruitment channel (Twitter, the development Listserv, or direct

emailing).InAppendixTableA1,weshowthatforecastsdonotvaryacrossthesecategories.

IV.Conclusion

   In this paper we pilot approaches that researchers can use to collect predictions of

research results for their own projects. We obtain estimates for the average forecast

treatmenteffectforthreedevelopmentexperiments.Theaverageforecastishighlyprecise

with a sample of 106 forecasters, suggesting that for similar projects a sample of 15-30

forecastersshouldbesufficient.Predictionsarerobusttomostsurveyelicitationfeatures,

withtheexceptionofsliderbounds,wherewiderboundsshiftthedistributionofpredicted

treatmenteffects.

                          




                                                                                      8
  

References
Bouguen,Adrien,andAndrewDillon.2019."TheImpactofaMultidimensionalProgram
 onNutritionandPovertyinBurkinaFaso."Acceptedbasedonpre-resultsreviewatthe
 JournalofDevelopmentEconomics,June20th,2019.
Blimpo, Moussa and Todd Pugatch. 2018. "Teacher Training and Entrepreneurship
 Education: Evidence from a Curriculum Reform in Rwanda." Accepted based on pre-
 resultsreviewattheJournalofDevelopmentEconomics,May5th,2019.
Camerer, Colin et al. 2016. "Evaluating replicability of laboratory experiments in
 economics."Science351,no.6280:1433-1436.
DellaVigna, Stefano, Nicholas Otis and Eva Vivalt. 2020. "Forecasting the Results of
 Experiments: Piloting an Elicitation Strategy." AEA RCT Registry. January 06.
 https://doi.org/10.1257/rct.5211-1.1.
DellaVigna, Stefano, Devin Pope, and Eva Vivalt. 2019. "Predict science to improve
 science."Science,366(6464),pp.428-429.
DellaVigna,Stefano,andDevinPope.2018."Predictingexperimentalresults:whoknows
 what?"JournalofPoliticalEconomy,126(6),pp.2410-2456.
JournalofDevelopmentEconomics.2018."Pre-ResultsReview(RegisteredReports)
 GuidelinesforAuthors."
 https://www.elsevier.com/__data/promis_misc/JDE_RR_Author_Guidelines.pdfAccessed
 on2020-1-5.
Franco,Annie,NeilMalhotra,andGaborSimonovits.2014."Publicationbiasinthesocial
 sciences:Unlockingthefiledrawer."Science.345,no.6203:1502-1505.
Yang,Deanetal."DirectandSpilloverImpactsofaCommunity-LevelHIV/AIDSProgram:
 EvidencefromaRandomizedControlledTrialinMozambique."Acceptedbasedonpre-
 resultsreviewattheJournalofDevelopmentEconomics,July22,2019.
VivaltEva,andAidanCoville.2017."HowDoPolicymakersUpdate?"Unpublished.
Vivalt, Eva. (forthcoming). "How Much Can We Generalize From Impact Evaluations?"
 JournaloftheEuropeanEconomicsAssociation.




                                                                                  9
                                                               
                                         
                 Figure1.ForecastsbySmallVersusLargeSliderBounds

Notes:ThisfigurepresentsCDFsofforecastsfromparticipantsassignedtosmall(0.5SD)
versus large (1.0 SD) slider conditions. Forecasts elicited in raw units are standardized
relativetoareferencemean.




                                                                                      10
                            TABLE1--FORECASTSBYEXPERIMENT
                                 Mean        SD         SE                    ni         nf
                                   (1)       (2)        (3)                  (4)        (5)
 Panel A: All pred.               0.16     (0.20)     (0.01)                 106        772
 Panel B: Yang et al
  HIV testing                       0.23         (0.18)        (0.02)         73         73
 Panel C: Blimpo et al.
  Dropout (reversed)                0.02         (0.13)        (0.01)         85         85
  Business participation            0.12         (0.12)        (0.01)         85         85
  Test scores                       0.29         (0.34)        (0.04)         85         85
 Panel D: Bouguen et al.
 Food consumption
  T1 (Cash)                         0.19         (0.12)        (0.01)         74         74
  T2 (T1+Asset)                     0.20         (0.18)        (0.02)         74         74
  T3 (T2+Nutrition)                 0.21         (0.21)        (0.02)         74         74
 Health consumption
  T1 (Cash)                         0.11         (0.09)        (0.01)         74         74
  T2 (T1+Asset)                     0.14         (0.12)        (0.01)         74         74
  T3 (T2+Nutrition)                 0.14         (0.16)        (0.02)         74         74
Notes: This table reports summary statistics for forecasts of causal effects from three
randomized controlled trials. Columns 1, 2, and 3 present the forecast mean (raw units are
standardized), standard deviation, and standard error. In Panel A, standard errors are
clustered at the individual level. ni (col. 4) and nf (col. 5) are the number of respondents and
forecasts per row. Panel A pools forecasts across all studies. Panel B reports forecasts of the
impact of a bundled health and education program on self-reported HIV testing. Panel C
presents forecasts of the impact of a teacher training program on student dropout (reverse
coded), self-reports of earning money from a business in the last month (dichotomous), and
scores on an entrepreneurship test. Panel D reports forecasts of the impact of cash, cash and
asset, and cash, asset, and nutrition transfers on food and health consumption.




                                                                                                   11
                   TABLE 2-- FORECASTS BY SURVEY FORMAT
                       Mean       SD         SE      ni                     nf        p
                        (1)        (2)       (3)    (4)                    (5)       (6)
Panel A: Reference
 Small (0.1 SD)        0.16      (0.18)    (0.01)   50                     393
 Large (0.3 SD)        0.17      (0.21)    (0.02)   56                     379      0.53
Panel B: Units
 Raw units             0.16      (0.21)    (0.01)   52                     332
 Standard deviations   0.17      (0.18)    (0.02)   54                     440      0.75
Panel C: Entry
 Text                  0.16      (0.25)    (0.02)   36                     266
 Slider                0.17      (0.16)    (0.01)   70                     506      0.93
Panel D: Slider bounds
 Small (0.5 SD)        0.12      (0.12)    (0.01)   33                     241
 Large (1.0 SD)        0.21      (0.18)    (0.02)   37                     265      0.00
Notes: This table reports summary statistics for forecasts of results from three randomized
controlled trials by randomly assigned survey format. Columns 1, 2, and 3 present the
forecast mean (raw units are standardized), standard deviation, and standard errors
(clustered at the individual level). ni (col. 4) and nf (col. 5) are the number of respondents
and forecasts per row. Column 6 presents clustered p values comparing groups within
each panel. Panel A presents forecasts by whether a small (0.1 SD) or large (0.3 SD)
reference was used in an example. Panel B presents forecasts made in raw units or
standard deviations. Panel C presents forecasts made using text or slider responses. Panel
D presents slider responses from small (0.5 SD) or large (1.0 SD) slider bounds.




                                                                                                 12
                            ONLINE APPENDIX
                 Forecasting the Results of Experiments:
                        Piloting an Elicitation Strategy
        Stefano DellaVigna             Nicholas Otis                           Eva Vivalt
     UC Berkeley and NBER               UC Berkeley               Australian National University




Contents
1 Additional Tables                                                                                 1

2 Survey Instruments                                                                                2

3 Treatment Comparison                                                                             13


1   Additional Tables

                             Table A1: Forecasts by Sample and Type
                                    Mean     SD       SE     ni  nf                p
                                     (1)     (2)      (3)   (4) (5)               (6)
                  Panel A: Sample
                   Listserv     0.15           (0.16)    (0.01)     39   336
                   Twitter      0.19           (0.22)    (0.02)     39   271      0.16
                   Other        0.15           (0.21)    (0.02)     28   165      0.89
                  Panel B: Type
                   Faculty      0.15           (0.23)    (0.02)     33   193
                   PhD student  0.17           (0.17)    (0.01)     40   331      0.48
                   Researcher   0.17           (0.18)    (0.02)     27   222      0.59
                   Practitioner 0.13           (0.22)    (0.02)     6    26       0.45
                  Notes: This table reports summary statistics for forecasts of results
                  from three randomized controlled trials by study sample (Panel A) or
                  self-reported type (Panel B). In Panel A, "Other" includes respondents
                  from the Busara Center for Behavioral Economics, GiveWell, the Global
                  Priorities Institute, IDinsight, and the World Bank. Columns 1, 2, and
                  3 present the forecast means (raw units are standardized relative to
                  a reference mean), standard deviations, and standard errors clustered
                  at the individual level. ni (col. 4) and nf (col. 5) are the number
                  of respondents and forecasts per row. Column 6 presents clustered
                  p values comparing groups within each panel. This analysis was not
                  pre-registered.



                                                    1
                             Table A2: Forecasts by Experiment and Survey Format
                                  Reference            Units               Entry                         Slider bounds
                                 Small     Large     Raw units      Std. dev.      Text     Slider     Small       Large
 Panel A: Yang et al.
  HIV testing                     0.23      0.22        0.22           0.24        0.25      0.22      0.20         0.23
                                 (0.18)    (0.18)      (0.13)         (0.22)      (0.26)    (0.13)    (0.11)       (0.15)
 Panel B: Blimpo et al.
  Dropout (reversed)      -0.01             0.06        0.04           0.00        0.01      0.03      0.01         0.06
                         (0.10)            (0.15)      (0.11)         (0.15)      (0.07)    (0.16)    (0.12)       (0.18)
  Business participation  0.11              0.14        0.13           0.12        0.09      0.14      0.11         0.17
                         (0.11)            (0.13)      (0.11)         (0.13)      (0.10)    (0.13)    (0.10)       (0.15)
  Test scores              0.24             0.34        0.35           0.24        0.38      0.25      0.18         0.32
                         (0.21)            (0.42)      (0.43)         (0.22)      (0.53)    (0.2 )    (0.13)       (0.23)
 Panel C: Bouguen et al.
 Food consumption
     T1 (Cash)                    0.19      0.19        0.18           0.19        0.19      0.19      0.15         0.22
                                 (0.13)    (0.11)      (0.10)         (0.13)      (0.15)    (0.10)    (0.07)       (0.11)
      T2 (T1+Asset)               0.21      0.20        0.16           0.24        0.23      0.19      0.12         0.26
                                 (0.2 )    (0.16)      (0.16)         (0.18)      (0.2 )    (0.16)    (0.12)       (0.17)
      T3 (T2+Nutrition)           0.22      0.20        0.17           0.24        0.21      0.22      0.15         0.28
                                 (0.26)    (0.16)      (0.14)         (0.25)      (0.29)    (0.16)    (0.11)       (0.18)
 Health consumption
     T1 (Cash)                    0.11      0.10        0.11           0.11        0.09      0.12      0.08         0.15
                                 (0.11)    (0.07)      (0.13)         (0.07)      (0.07)    (0.10)    (0.08)       (0.12)
      T2 (T1+Asset)               0.15      0.12        0.11           0.15        0.11      0.15      0.11         0.19
                                 (0.14)    (0.09)      (0.14)         (0.10)      (0.09)    (0.13)    (0.10)       (0.15)
      T3 (T2+Nutrition)           0.15      0.14        0.12           0.16        0.10      0.17      0.10         0.23
                                 (0.17)    (0.16)      (0.19)         (0.14)      (0.10)    (0.19)    (0.12)       (0.21)
 ni                                50        56          52             54          36        70        33           37
 nf                               393       379         332            440         266       506       241          265
 Notes: This table reports summary statistics for predictions of results of three randomized controlled trials by randomly
 assigned elicitation strategy. Predictions are of causal treatment effects standardized relative to a reference mean for
 raw-unit elicitations. Standard deviations are presented in parentheses. Panel A reports forecasts of the impact of a
 bundled health and education intervention on self-reported HIV testing. Panel B presents forecasts of the impact of a
 teacher training intervention on student dropout (reverse coded), self-reports of earning money from a business in the last
 month (dichotomous), and scores on an entrepreneurship test. Panel C reports forecasts of the impact of cash, cash and
 asset, and cash, asset, and nutrition transfers on food and health consumption. ni and nf are the number of individuals
 making forecasts and the total forecasts for each column. Columns 1 and 2 present forecasts by whether a small (0.1 SD)
 or large (0.3 SD) reference was used in an example. Columns 3 and 4 present forecasts made in raw units or standard
 deviations. Columns 5 and 6 present forecasts made using text or slider responses. Columns 7 and 8 present slider
 responses from small (0.5 SD) or large (1.0 SD) slider bounds.




2     Survey Instruments
This section contains the entire forecasting survey for one randomization. A direct comparison of the different
randomizations (for the HIV testing outcome) can be found at the end of the survey.




                                                             2
3
4
5
6
7
8
9
10
11
12
3   Treatment Comparison

    0.1 standard deviation reference                                       0.3 standard deviation reference




    Standard deviations (text entry)                                       Raw units (text entry)



    Respondents providing forecasts in standard deviations are also provided with the following statement: As a reference, a recent survey of many
    impact evaluations in development economics suggests that the average effect size is around 0.10 standard deviations (Vivalt, 2019).

    Slider in raw units (0.5 standard deviation bounds)                    Slider in raw units (1.0 standard deviation bounds)




    Slider in standard deviations (0.5 standard deviation bounds)          Slider in standard deviations (1.0 standard deviation bounds)




                                                                         13
