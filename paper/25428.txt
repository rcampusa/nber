                              NBER WORKING PAPER SERIES




 URGENT CARE CENTERS AND THE DEMAND FOR NON-EMERGENT EMERGENCY
                        DEPARTMENT VISITS

                                          Lindsay Allen
                                       Janet R. Cummings
                                       Jason Hockenberry

                                       Working Paper 25428
                               http://www.nber.org/papers/w25428


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                                    January 2019




We thank participants in seminars at Emory University, West Virginia University, and the 2016
Southeastern Health Economics Study Group in Richmond VA for helpful feedback. This work
was funded by a grant (R36HS2484501) from the Agency for Healthcare Research and Quality.
The views expressed herein are those of the authors and do not necessarily reflect the views of the
National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2019 by Lindsay Allen, Janet R. Cummings, and Jason Hockenberry. All rights reserved. Short
sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including © notice, is given to the source.
Urgent Care Centers and the Demand for Non-Emergent Emergency Department Visits
Lindsay Allen, Janet R. Cummings, and Jason Hockenberry
NBER Working Paper No. 25428
January 2019
JEL No. I11

                                         ABSTRACT

Urgent care centers (UCCs) are a cost-efficient substitute to the emergency department (ED) for
non-emergent conditions, but no study has identified their impact on ED demand. We address this
gap using a novel strategy that exploits daily UCC operating times in a differencing framework.
After UCCs close each day, local non-emergent ED visits increase by 1.43 percent (over the
adjusted mean rate of 70.58 percent) in areas with multiple UCCs. This effect occurs only among
the privately insured population, the target customers of UCCs. Our results suggest that UCCs are
successfully substituting for EDs in the treatment of non-emergent conditions.


Lindsay Allen                                   Jason Hockenberry
West Virginia University                        Department of Health Policy and Management
lindsay.allen@hsc.wvu.edu                       Rollins School of Public Health
                                                Emory University
Janet R. Cummings                               1518 Clifton Rd
Emory University                                Atlanta, GA 30322
Department of Health Policy                     and NBER
  and Management                                jason.hockenberry@emory.edu
1518 Clifton Rd
Atlanta GA, 30322
jrcummi@emory.edu
1. Introduction
       Reducing non-emergent emergency department (ED) use (i.e., visits that
could have been safely delayed for 24 hours) is a well-known goal of health policy.
Treatment for non-emergent conditions in the ED is more costly compared to that
delivered in other care settings, without any concomitant rise in quality (Institute
of Medicine 2007, Weinick, Burns, and Mehrotra 2010, Uscher-Pines et al. 2013a).
Research indicates that up to half of the 137 million ED visits that take place
annually in the U.S. could be treated at a care site other than the ED (Niska 2010,
Young et al. 1996, Weinick, Burns, and Mehrotra 2010, Centers for Disease Control
and Prevention 2011). A major barrier to treating these visits in a more clinically
appropriate setting is limited access to acute care in the community, due to
physician shortages, long wait times for appointments, and/or a lack of after-hours
availability (O'Malley 2013, Kellermann 1994, Nadel 1993, Rask et al. 1994, Gindi,
Cohen, and Kirzinger 2012, Cunningham 2006).
       Urgent care centers offer a substitute care site for the treatment of
unscheduled, acute, non-emergent conditions (Bohmer 2007, Mehrotra et al. 2009).
Comprising an $18 billion industry, these centers are freestanding facilities that
provide after-hours and weekend care for injuries or illnesses that are “not life or
limb threatening,” but which are beyond the scope or availability of primary care
facilities (Stoimenoff and Newman 2017, Urgent Care Association of America
2011). Care delivered in urgent care centers is less costly, more efficient, and of
similar or better quality than that delivered in the ED (Weinick, Burns, and
Mehrotra 2010, Institute of Medicine 2007, Uscher-Pines et al. 2013a, Bohmer
2007). Weinick et al. estimate that about 27 percent of all ED visits could take place
at an urgent care center instead (Weinick, Burns, and Mehrotra 2010) .
       Despite the potential impact of urgent care centers on healthcare cost and
access, well identified estimates of their effect on ED demand are conspicuously
lacking. Two empirical challenges account for this gap in the literature. First, there
are data limitations concerning the timing of market entry and exit of urgent care
centers, and unreliable measures of urgent care use. Second, a patient’s decision to
choose the ED versus an urgent care center is likely an endogenous one, partly
determined by unobserved patient preferences or knowledge (e.g., about the
ailments treatable at urgent care centers, whether their symptoms are life-
threatening).
         Slightly more established is a mixed literature on retail clinics, for which
data are more widely available and which share some similarities with urgent care
centers, including walk-in availability and later hours of operation 1. Alexander,
Currie, and Schnell, use individual-level New Jersey data to examine the impact of
retail clinics on ED visits for a small subset of six minor illnesses. They find that
individuals living near an open retail clinic are between 4.7 and 11.4 percent less
likely to go to the ER for these particular illnesses (Alexander, Currie, and Schnell
2017). Further, they estimate that expanding the retail clinic market across the state
could result in an annual cost savings of over $70 million from reduced ED use.
Hollingsworth finds that Florida retail clinics decrease the number of ED visits for
bronchitis and upper respiratory infection (Hollingsworth 2014). In contrast,
Martsolf et al. find no impact of retail clinic penetration on low-acuity ED visits
(Martsolf et al.). Given their small market size and the limited scope of services
and resources they offer, retail clinics are not as close of a substitute for the ED as
urgent care centers are. For example, urgent care centers offer diagnostic imaging
and laceration repair, both of which are not provided in retail clinics (Stoimenoff
and Newman 2017). This underscores the need for urgent care-specific research.




1
  Retail clinics differ from urgent care centers in that they are definitionally located within a retail
location (rather than operating as a stand-alone entity), are much more limited in number, are often
staffed by nurse practitioners (rather than MDs), treat a much smaller set of routine/minor
conditions, have fewer clinical resources, and have lower out-of-pocket costs for patients.
       In this paper, we identify the effect of urgent care centers on demand for
non-emergent ED visits. We employ a novel difference-in-differences strategy that
uses daily opening and closure times of urgent care centers as proxies for market
entry and exit. Hours of operation data were obtained from a dataset that has not
previously been used in the literature. We merged this new, rich data source on
urgent center operation times with ED visit records measuring the demand for non-
emergent ED visits. Specifically, we compared pre- and post-daily opening/closure
rates of non-emergent ED use in ZIP codes with urgent care centers to those in ZIP
codes without urgent care centers, at the same time of day. Since urgent care centers
are smaller than EDs and may require more than one clinic per area to meaningfully
impact ED use, we divided our analysis into areas with single and multiple centers.
We focused on treatment effects for patients who are privately insured, since they
are the target market for urgent care facilities. In our framework, the uninsured
population serves as a placebo test for our identification strategy. Unlike EDs,
urgent care centers are not required by law to treat uninsured individuals, and
therefore do not treat many individuals in this population (American College of
Emergency Physicians 2018)
       We estimate that the daily closure of nearby urgent care centers leads to a
1.43 percent increase in the rate of privately insured non-emergent visits
immediately following closure. This extrapolates to about 2.4 million ED visits per
year. Notably, this impact is only seen when there are multiple urgent care centers
in a given geographical market. We do not find a meaningful effect of urgent care
centers on the demand for non-emergent ED visits in areas with only one urgent
care center, possibly due to capacity constraints of urgent care centers. As
predicted, we find no effect of urgent care centers on non-emergent ED visits for
uninsured individuals. Our results suggest that privately insured individuals living
in communities with more than one urgent care center have lower non-emergent
ED visits during the hours these centers are open.
2. Background
2.1.The Urgent Care Market
        Urgent care centers provide a potential ED substitute site of treatment of
many acute, yet non-emergent conditions. In addition to primary care services,
practitioners at these facilities can provide immunizations, lab tests, x-rays, fracture
and laceration care, and intravenous fluids (Urgent Care Association of America
2011). More than 7,600 urgent care clinics are in operation, with about 122 million
annual patient visits (an average of 44 patients a day per facility), and hundreds of
new clinics are opening each year (Urgent Care Association of America 2011,
2015, Stoimenoff and Newman 2017, Urgent Care Association of America 2017).
In comparison, the 4,200 non-critical access hospitals (non-CAH) EDs in the US
host 137 million visits per year ((an average of 89 patients a day per facility), and
1,800 retail clinics see only 10.5 million annual visits ((an average of 16 patients a
day per facility) (Camargo and Sullivan 2018, Bachrach et al. 2015).
        Despite its large size, the urgent care industry remains largely unregulated.
To date, only Arizona and New Hampshire require urgent care centers to be
licensed beyond what is required for any medical clinic (State of Arizona 2004,
State of New Hampshire). Two states, Illinois and Delaware, regulate the use of the
term “urgent care,” but not the facilities themselves (Urgent Care Association of
America 2015). Other than these exceptions, clinics can choose to label themselves
as urgent care centers, or as any one of a number of related designations including
“immediate care,” “convenient care”, and “walk-in care.”
        The Urgent Care Association of America (UCAOA) delineates urgent care
centers from other delivery models based on whether a facility 1.) is open on
weekday evenings and on weekends, 2.) does not require an appointment, 3.) has
onsite x-ray, and 4.) has the ability to perform suturing and casting procedures
(Urgent Care Association of America 2015). Nonetheless, services offered in an
urgent care center can vary widely, from primary care to less common offerings,
such as occupational medicine, weight loss, and physical therapy services (Urgent
Care Association of America 2015).
       This variability in regulation and designations makes it difficult collect
valid data on the urgent care market, especially concerning when urgent care
centers enter and/or exit geographic markets. Therefore, identifying their effect on
the demand for ED visits is difficult using conventional yearly panel data
approaches. Another data-related challenge is that insurance claims – often used in
health care research – do not always identify which services were offered under the
auspices of urgent care. Though there are some after-hours and other urgent care-
specific insurance codes, which are pre-negotiated with an insurer, most urgent care
billing relies on the evaluation and management codes also used in other primary
care settings (Urgent Care Association of America 2015). Despite treating almost
as many patients annually than all U.S. EDs combined, urgent care center status is
also not captured in any large-scale national surveys, like the National Ambulatory
Medical Care Survey (for primary care visits) and the National Hospital
Ambulatory Medical Care Survey (for ED visits).
2.2.The Role of Patient Preferences
       Adding to the problem of data scarcity, unobservable patient preferences
make it difficult to establish the causal impact of urgent care centers on non-
emergent ED use. Given the choice between receiving treatment at an urgent care
center and an ED for a non-emergent acute condition, a patient may choose one
over the other for reasons unknowable to a researcher in the limited data available.
On the one hand, patients may prefer to visit an urgent care center due to
perceptions that urgent care centers offer shorter wait times and lower-cost
treatment. On the other hand, patients may instead choose to visit the ED, perhaps
because they are open around the clock, easily recognizable and accessible, or
perceived as offering more sophisticated or better quality treatment.
       An additional key dimension of patient preferences has to do with one’s
ability and/or willingness to act as a first-line diagnostician of their own condition.
Before deciding to go to an urgent care center instead of an ED, a patient needs to
have some idea of the seriousness of their condition, along with an idea of what
clinical resources will be needed to treat it. Some patients may be unable or
unwilling to conduct this initial triage process – thereby defaulting to the ED –
while others may have more experience or knowledge that allows them to select
their optimal care site (Uscher-Pines et al. 2013b, Jaffe, Kocher, and Ghaferi 2018).
2.3. Empirical Framework
       We address these challenges by adopting a novel difference-in-differences
strategy that hinges on daily closure times of urgent care centers. In markets with
an urgent care center, demand for acute, non-emergent care is spread across a larger
care supply of facilities (i.e., the urgent care center and the ED), as long as the
urgent care center is open. Once this center closes, the latent demand for acute
services is spread over a smaller number of suppliers. We would expect this to
manifest as an increase in non-emergent ED visit rate immediately after urgent care
closure.
       Conversely, we would expect a decrease in the non-emergent ED visit rate
when urgent care centers open in the morning. However, the advantage of urgent
care centers is that they are open on weeknights and weekends, when other care
sites are not. In the morning, there are many different options for patients seeking
non-emergent care (such as primary care physicians’ offices that offer same day
appointments, or school clinics). Therefore, we do not anticipate that urgent care
centers will have the same impact in the morning that they would in the evening,
when they close later than these other options do, becoming the only alternative to
the ED.
       Our empirical approach obviates the need for year-to-year panel data on
urgent care centers, and instead addresses the endogeneity from unobserved patient
preferences that affect observed visits using hours of operation data. For ZIP codes
with an urgent care center, we compare rates of non-emergent ED use immediately
before and immediately after those urgent care centers open for the morning, or
close for the evening. If urgent care centers are effectively drawing non-emergent
visits from EDs during the hours they are open, we would expect an increase in
non-emergent ED visits when those facilities close for the evening. We would not
expect a similar jump during the same time period in patient ZIP codes without an
urgent care center, which comprise our control group. Taking this reduced form
approach to estimate the effect on ED visit demand eliminates the need for data on
urgent care visits, which are hard to come by, as noted previously.
       Since urgent care centers are smaller than EDs, it is unlikely that a single
urgent care center will drive meaningful change in nearby ED use (Stoimenoff and
Newman 2017, Welch et al. 2012). For this reason, we divide our sample into two
parts: those with exactly one urgent care center, and those with more than one
urgent care center. For the analysis with multiple urgent care centers, we use the
latest opening/closure time of all the clinics in the ZIP code as our cutoff point.
       Unlike EDs, urgent care centers are not bound under the Emergency
Medical Treatment and Labor Act (EMTALA) to treat all patients, regardless of
their ability to pay (American College of Emergency Physicians 2018). This means
that profit-maximizing urgent care centers can preferentially treat only those
patients who can afford to pay for care, either through their insurance plan or out-
of-pocket. As such, urgent care centers and EDs have very different payer mixes.
Whereas 67% of urgent care centers visits are by the privately insured, only 12%
of visits are by uninsured individuals who are able to self-pay at the time of the visit
(Urgent Care Association of America 2017) . In the ED, these percentages were
33%, and 20% at the time our data were collected (Ashman, Rui, and Hing 2016).
Given these numbers, we would expect urgent care center closures to have a
measurable effect for patients who are insured, but not for patients who are
uninsured. For this reason, we limit our main difference-in-differences analysis to
privately insured individuals, and use the uninsured population to conduct a placebo
test of our model. We exclude publicly-insured individuals (21% of urgent care
visits) from our models, since they are not the target demographic of urgent care
centers, but represent a large enough patient base to invalidate their use as a placebo
test (Urgent Care Association of America 2017).
3. Methods
       Our data on urgent care centers came from a database, previously unused in
the literature, which contains the names, addresses, and hours of operations for
almost all of the urgent care centers in the U.S. The dataset comes from an online
searchable database that allows patients to view the urgent care centers within a
certain distance of their ZIP code. The dataset represents the most comprehensive,
independently-verified directory of walk-in clinics in the country, with over 90%
of clinics indexed (Urgent Care Location 2013, Barber 2015). The 2013 edition of
the database, which we used for this study, contains 6,655 urgent care centers,
which is in line with numbers released from industry trade organization estimates
at that time (Urgent Care Association of America 2014). Clinic addresses and hours
are regularly updated via a call center (Barber 2015). Because our identification
strategy hinges on hours of operation, we removed from our list of facilities any
clinics that did not have hours available in the dataset (17% of the list).
       Emergency department visit data come from the Healthcare Cost and
Utilization Project (HCUP) State Emergency Department Databases (SEDD),
which is the largest collection of all-payer, encounter-level ED visit data in the U.S.
(Steiner, Elixhauser, and Schnaier 2001). For states choosing to participate in the
HCUP, the data contain information on every ED visit that did not result in a
hospital admission (Steiner, Elixhauser, and Schnaier 2001). The data include
patient and visit characteristics, such as patient ZIP code, payer status (i.e.,
Medicaid, Medicare, private, uninsured), discharge code (ICD-9), and hour (but not
minutes) of ED visit (arrival time, not admission time). Six states (Arizona, Florida,
Nebraska, New Jersey, New York, and Rhode Island) included all of the variables
necessary to implement our analysis. We used data from the year 2012, the most
recent year for which all required variables were available. We aggregated the
encounter-level ED records to the ZIP code level for our analysis.
         To determine which visits are non-emergent, we used a recently updated
version of the NYU ED visit algorithm, which classifies the urgency,
preventability, and optimal care site of ED visits (Billings, Parikh, and Mijanovich
2000, Feldman 2010, Johnston et al. Forthcoming). For all discharge (ICD-9) codes
available in the SEDD, the algorithm assigns a probability that the visit fell into one
of four categories: 1) not an emergency; 2) emergent, primary care treatable; 3)
emergent, ED care needed, but preventable/avoidable; 4) emergent, ED care
needed, not preventable/avoidable (Billings, Parikh, and Mijanovich 2000). The
probability can be distributed across the four categories, reflecting the variability
of possible urgency levels within any single code 2. We sum across the first two
categories (not an emergency; emergency, primary care treatable) to obtain the
probability that any given visit is non-emergent and could have been treated in an
urgent care center.
         When the algorithm was created, visits due to injury were assigned a
probability of 100% to a carved-out injury category (instead of a one of the four
urgency categories described above) 3. Therefore, we do not have information on
whether injury-related visits were non-emergent. For this reason, our main analytic
sample excludes injury visits. However, the urgent care model is designed to treat


2
  For example, an ICD-9 code of 0340, (streptococcal sore throat) has the following probability
distribution: non-emergent, 66%; emergent, primary care treatable, 28%, emergent, ED care
needed, 6%; emergent, ED care needed, not preventable/avoidable, 0%.
3
  Visits related to drug/alcohol use, and psychiatric related visits, were also carved out into their
own categories. These carve-outs were conducted at the request of early ED algorithm users, so
that they may be tabulated separately.
minor injuries (sprains, minor fractures, etc.), and removing them completely from
the analysis may be unrealistically restrictive. Therefore, we run sensitivity
analyses in which we include injury visits, assuming varying percentages (25%,
50%, 75%, 100%) are non-emergent.
        The SEDD does not provide the day of the week on which a visit occurred;
it only provides whether the visit occurred on a weekday or weekend. Urgent care
center hours tend to be very consistent from Monday through Friday, but change
markedly from the work week to Saturday, and then again from Saturday to Sunday.
For this reason, we excluded weekend visits (28.1% of the records) from our
analysis. To further derive our ED sample, we dropped those visits for which there
was no visit time data (1.1% of the sample) and no payer information (0.1%).
Finally, we dropped all visits that occurred by people with missing or invalid ZIP
codes (0.8%), out of state home ZIP codes (3.4%), and records that had ZIPs with
only 3 digits (0.2%). After dropping observations (4.5%) carved out by the NYU
algorithm (i.e., those due to drugs, alcohol, or psychiatric conditions) and limiting
the sample to privately insured (uninsured) adults age 0-64, we were left with 3.4
(2.4) million individual ED records.
       We collapsed the individual-level SEDD data to the ZIP code level. Each
ZIP code is represented multiple times in our dataset, since we observe the ZIP-
level non-emergent visit rate at each hourly time point.
       We used data from the 2013 American Community Survey (ACS) to obtain
descriptive statistics for ZIP codes with and without urgent care centers (United
States Census Bureau 2013). Because ACS data are provided at the ZIP code
tabulation area (ZCTA) level, we cross-walked the data values to their
corresponding ZIP codes using a relationship file from the Missouri Census Data
Center (Missouri Census Data Center 2016).
       We first plotted the unadjusted zip-code level rates of non-emergent ED
visits by hour, in ZIP codes with and without urgent care centers. This confirmed
our identifying assumption that ZIP codes with and without urgent care centers
have similar pre-trends in non-emergent ED visit rates prior to the daily
opening/closure time.
        More formally, we estimated a difference-in-differences model in which
the change in the non-emergent visit rate before and after daily urgent care
opening/closure time in ZIP codes with an urgent care center is contrasted with that
same change in ZIP codes without an urgent care center. We examined the change
in non-emergent ED rate in the hour just before versus the hour just after the
opening/closure time threshold. Our model is
                     𝑌𝑌𝑖𝑖ℎ = 𝛼𝛼 + 𝛽𝛽0 𝑇𝑇𝑖𝑖 + 𝛽𝛽1 𝐶𝐶𝑖𝑖 + 𝛽𝛽2 (𝑇𝑇𝑖𝑖 ∙ 𝐶𝐶𝑖𝑖 ) + 𝜀𝜀𝑖𝑖
where 𝑌𝑌𝑖𝑖 is the rate of non-emergent ED visits for ZIP code 𝑖𝑖 at hour ℎ; 𝑇𝑇𝑖𝑖 is an
indicator equal to one if the ZIP code was assigned to the treatment group (i.e., has
an urgent care center); 𝐶𝐶𝑖𝑖 is an indicator equal to one if the visit occurred at the
urgent care closure time or later (or the opening time or later); (𝑇𝑇𝑖𝑖 ∙ 𝐶𝐶𝑖𝑖 ) is the
interaction between the two, allowing for different slopes on either side of the
closure (opening) time cut point, 𝑋𝑋𝑖𝑖 is a vector of ZIP code characteristics; and 𝜀𝜀𝑖𝑖
represents a random error term. Our key policy parameter is the coefficient on the
interaction, which estimates the causal impact on non-emergent visit rates
attributable to urgent care centers closing for the day in ZIP codes with an urgent
care center.
        Because there are likely unobserved factors that could be simultaneously
impacting our independent and dependent variables, we include ZIP code-level
fixed effects to capture any time-invariant, ZIP-code specific characteristics that
might bias our estimate of the effect of UCC availability on ED demand. All models
included dummy variables for each state. Standard errors were clustered at the
Hospital Service Area (HSA) level, which can be thought of as roughly equivalent
to a hospital’s catchment area (Dartmouth Atlas of Health Care 2018). We weighted
our estimate using analytic weights (command aweights in Stata) that we created
according to the observed number of visits coming from each ZIP code.
       To determine if ZIP codes with greater urgent care supply might present a
larger impact on non-emergent ED use, we conducted sub-analyses in which we
limited the sample first to those ZIP codes with exactly one urgent care center or
no urgent care center, then to those with more than one urgent care center or no
urgent care center.
       The choice of opening and closure times for our analyses warrants
discussion. Operating times for urgent care centers vary across locations, but we
needed a single closure (opening) time to cleanly compare visit rates across all of
our control ZIP codes. For example, if there were three ZIP codes, each with a UCC
that closed at a different hour, we wouldn’t be able to choose a single time point in
our control group to make the comparison. For this reason, we focus our analysis
on the modal closure (opening) time across all UCCs. The modal closure time for
all UCCs in our sample across all weekdays is 8 PM, and the modal opening time
is 8 AM. We first divided our “closure” ZIP code sample into those that had least
one UCC (n=835, 15%) and those that did not have any UCCs (n=4,754, 85%).
Within the group that had at least one UCC, we further divided the ZIP codes into
those that had exactly one UCC (544, 65%) versus those that had more than one
UCC (291, 35%). Of the 544 ZIPs with exactly one UCC, 267 (49%) closed at 8
PM. Of the ZIPS with multiple UCCS, 129 (44%) had 8 PM as the latest closure
time among the UCCs. ZIP codes with one UCC that did not close at 8 PM, or
multiple UCCS that closed later than 8 PM, were excluded. We created the
“opening” ZIP code sample similarly, using a “first opening” time of 8 AM in ZIPs
where there were more than one UCC.
       For each weekday, the modal UCC opening time (8:00 AM) accounted for
over 54% of our sample of urgent care centers. The next most common opening
times were 9:00 AM and 7:00 AM, accounting for 18% and 6% of the sample,
respectively4. The modal weekday closure time (8:00 PM) represented over 39%
of the sample. The next most common closure times were 9:00 PM and 7:00 PM,
representing about 14% and 11% of the sample, respectively. Openings and
closures at times other than on the hour (e.g., 8:15, 8:30) were rare in the sample,
but where they existed, we rounded that time down or up to the closest hour because
the SEDD visit records only provide time of visit by the hour, not the minute. We
conducted sensitivity analyses testing whether our results were robust to using the
next most common opening and closure times (7
AM, 9 AM; 7 PM, 9 PM) as our time thresholds. We also tested for robustness of
our main result to the size of the hourly window around the closure time threshold.
4. Results
        Table 1 shows unadjusted descriptive statistics for ZIP codes with and
without urgent care centers. Of the 5,589 ZIP codes in our sample of six states,
14.9% have at least one urgent care center. Areas with urgent care centers are much
more populated than those without. They have a younger, more racially diverse,
wealthier, and more educated populations. This likely reflects the tendency of walk-
in clinics to locate in more urban areas, relative to rural areas. ZIP codes with urgent
care centers have lower rates of Medicaid enrollment, but higher rates of uninsured
individuals, compared to those without urgent care centers.
        In Figure 1, we present the mean hourly non-emergent ED visit rate for ZIP
codes with and without urgent care centers. The dashed lines on the figure represent
the modal weekday opening (8 AM) and closing (8 PM, or 2000 hours in military
time) times among urgent care centers in our sample. In the hours leading up to
these opening and closure times, the non-emergent visit rate rises and falls similarly



4
  We use Tuesday – Friday hours to get these hourly distributions, since hours remain virtually
constant during these weekdays. Monday hours differ slightly. We use Tuesday hours for the
analysis, since Tuesday hours have the fewest number of missing data points and are most similar
to the rest of the weekdays’ hours
across areas with and without urgent care centers. This provides evidence that our
data satisfy the parallel pre-trends assumption upon which our identification
approach rests. Across both groups, we find that over 70 percent of ED visits are
not true emergencies. Though estimates of non-emergent ED visits vary widely,
these numbers are on the high end. This is likely because other studies only consider
the least emergent (i.e., routine; those that could take place in a primary care office)
visits in their estimates. Our study includes these visits, plus those that are too
serious to be treated in a primary care office, but can be successfully treated in an
urgent care office.
       Table 2 presents results from our main difference-in-differences analysis.
We first focus on the privately insured population. As shown in Panel A, we find
no impact of urgent care centers on ED use when they open in the morning, even
when there is more than one center in a ZIP code. This is consistent with our
hypothesis that demand changes during this time frame will likely be spread across
a greater provider supply, since other sources of non-emergent health care, such as
primary care physicians’ offices, tend to begin their workdays around the same time
as urgent care centers. The hallmark of an urgent care center is its extended hours
on weeknights and weekends – not its weekday morning hours.
       In contrast, we find a statistically significant increase in non-emergent ED
visits among privately insured individuals in ZIP codes with multiple urgent care
centers, when the last center in that area closes for the day. Specifically, non-
emergent ED visits rise by 1.01 percentage points (p<0.01), a 1.43 percent relative
increase. When viewed in context of the 136 million annual ED visits that take
place in the US, this translates to an additional 1.9 million ED visits.
       We do not find a statistically significant impact in areas with only one
urgent care center, possibly because their capacity is too small to meaningfully
impact visits rates in the ED. To provide a concrete example of this constraint, we
performed a back of the envelope calculation. Urgent care centers treat about 44
patients a day, while non-Critical Access Hospitals EDs are fielding an average of
89. Of those 89 patients, about 70% (62 patients) could be treated in a UCC. Our
results suggest that 1.43% of the 62 non-emergent ED patients (or just under 2
patients a day in a ZIP code with 2 UCCs) are being seen in the UCC, rather than
the ED.
       We used ED visits among the uninsured as a falsification test for our results.
Because urgent care centers primarily cater to the privately insured, we would not
expect their daily closure to impact ED use among uninsured individuals, who
comprise only 12% of urgent care patients. This is confirmed in the last two
columns of Table 2. We find no statistically significant impact of urgent care center
closure on ED use by uninsured patients.
       We ran three sets of sensitivity analyses. One shortcoming of the algorithm
we used to determine ED visit urgency is its exclusion of injury visits, an important
consideration since urgent care centers are intended to treat a range of moderate
injuries. When we included the injury visits in our sample, classifying varying
percentages of them as non-emergent, we find a statistically significant effect at the
75% and 100% thresholds. When smaller portions (i.e., 25%, 50%) of the injury
visits are considered non-emergent, we find no effect (Table 3). To put these rates
in perspective, the Agency for Healthcare Research and Quality finds that 90% of
injury visits in the ED are “mild” (as opposed to moderate or severe), and almost
all of these are treated and released (Villaveces et al. 2013). Taken together, this
suggests that urgent care centers are particularly effective ED substitutes for
patients with mild injuries.
       We also attempted to test whether our main finding was sensitive to the
daily closure/opening time chosen by running our models for the next most
common opening and closure times (7 AM, 9 AM; 7 PM, 9 PM). Using these time
thresholds, we did not find a statistically significant change in ED rates. We posit
that this is because so few of the UCCs in our sample open and close at these less
common times. For example, the 8 PM closure time accounts for over half the
sample of urgent care centers, while the next two most popular closing times
combined account for less than a quarter of the sample. If this is the case, it would
support our theory that urgent care centers are most effective in reducing ED use
when there are multiple centers available to patients.
       Though we would expect to see the largest impact of UCC closure in the
time window encompassing the hour immediately before and the hour after closure,
we also tested the robustness of our finding to a wider time window. The results
hold at both two hours before and after closure (i.e., a four-hour window; 0.80
relative increase, p<.10), and three hours before and after closure (i.e., a six hour
window; 0.74 relative increase, p<.10), in areas with more than one UCC. The
magnitudes of the effects, however, decrease as the time windows get larger, which
is to be expected.
5. Conclusions
   Urgent care centers offer a potentially important substitute care site for non-
emergent ED use, but systematic evidence of their impact has been lacking due to
data challenges and concerns about unobserved patient preferences. We addressed
these challenges by implementing a difference-in-differences model that uses daily
operation times of urgent care centers as proxies for market entry and exit.
       In a multistate analysis that used a novel data source, we found that daily
closure of urgent care centers meaningfully increases privately insured non-
emergent ED use in hours that follow, as long as there are multiple urgent care
centers in the area. We do not find corresponding impacts in areas with a single
urgent care center, which we attribute to capacity constraints. As predicted, we do
not find corresponding impacts for uninsured patients, a group comprising a very
small part of the urgent care case mix.
       The effect size we find translates to approximately 2.4 million ED visits per
year. Since it costs around $414 more to treat a non-emergent case in an ED versus
an urgent care center, this represents about $1 billion in health care costs, annually.
       While this is the first known study to assess the causal impact of UCCs on
non-emergent ED visits, we can place our findings in the context of the emerging
literature on retail clinics, a smaller and more limited market. Alexander, Currie,
and Schnell find that individuals living close to an open retail clinic are up to 11.4
percent less likely to go to an ED for sprains and strains, urinary tract infections,
conjunctivitis, upper respiratory tract infections, ear
infections, and sore throat (Alexander, Currie, and Schnell 2017). Hollingsworth
finds that Florida retail clinics decrease the number of ED visits for bronchitis and
upper respiratory infection (Hollingsworth 2014). Taken together, these studies
suggest that the walk-in clinic industry (comprising urgent care centers and retail
clinics) has the potential to meaningfully reduce non-emergent ED visits, which in
turn may reduce health care expenditures. Indeed, Sussman et al. find that
individuals who used a retail clinic had lower care costs over the following year,
compared to individuals who received care in other settings(Sussman et al. 2013).
On the other hand, another suggested that retail clinics may offset these health care
savings by encouraging visits along the extensive margin (i.e., those who would
have forgone any care if a retail clinic were not open at the time of visit) (Ashwood
et al. 2016). Additional research is needed to identify the net effect of the walk-in
industry on health care costs.
       Our results may represent an upper bound on the impact of clinics on ED
use: first, the 7,600 clinics in operation today are probably located where they
expected to find the greatest privately insured patient demand. As the market
matures, there may be diminishing returns to opening new clinics. Secondly, the
evening portion of our analysis takes place during a time of day where ED visits
are high (Pitts et al. 2012). Because the number of visits is smaller at other times of
the day, there are fewer visits for the walk-in clinics to impact. On the other hand,
only about 5% percent of ZIP codes (in our sample) have more than one urgent care
center. Since we find that meaningful change in ED use occurs only when multiple
centers locate in one area, urgent care companies may be incentivized to increase
their supply in certain areas, which would bolster their impact.
References
Alexander, Diane, Janet Currie, and Molly Schnell. 2017. Check Up Before You Check Out: Retail
       Clinics and Emergency Room Use. National Bureau of Economic Research.
American College of Emergency Physicians. 2018. "EMTALA." https://www.acep.org/life-as-a-
       physician/ethics--legal/emtala/emtala-fact-sheet/#sm.00001m2o2n7hovdd6t8x1eqactduh.
Ashman, Jill J, Pinyao Rui, and Esther Hing. 2016. Expected Source of Payment at Emergency
      Department Visits for Adults Aged 18--64 for the United States and in the Five Most Populous
      States, 2012: US Department of Health & Human Services, Centers for Disease Control and
      Prevention, National Center for Health Statistics.
Ashwood, J. S., M. Gaynor, C. M. Setodji, R. O. Reid, E. Weber, and A. Mehrotra. 2016. "Retail Clinic
      Visits For Low-Acuity Conditions Increase Utilization And Spending." Health Aff (Millwood) 35
      (3):449-55. doi: 10.1377/hlthaff.2015.0995.
Bachrach, Deborah, Jonah Frohlich, Allison Garcimonde, and Keith Nevitt. 2015. "The value proposition
       of retail clinics." Robert Wood Johnson Foundation:12.
Barber, Michael; . 2015. "Personal Communication with Michael Barber." June 12, 2015.
Billings, J., N. Parikh, and T. Mijanovich. 2000. "Emergency department use in New York City: a survey
        of Bronx patients." Issue Brief (Commonw Fund) (435):1-5.
Bohmer, Richard. 2007. "The Rise of In-Store Clinics — Threat or Opportunity?" New England Journal
      of Medicine 356 (8):765-768. doi: doi:10.1056/NEJMp068289.
Camargo, Carlos;, and Ashley; Sullivan. 2018. National Emergency Department Inventory - USA.
Centers for Disease Control and Prevention. 2011. National Hospital Ambulatory Medical Care Survey:
        2011 Emergency Department Summary Tables.
Cunningham, P. J. 2006. "What accounts for differences in the use of hospital emergency departments
       across U.S. communities?" Health Aff (Millwood) 25 (5):w324-36. doi: 10.1377/hlthaff.25.w324.
Dartmouth Atlas of Health Care. 2018. "Research Methods." accessed October.
      http://www.dartmouthatlas.org/downloads/methods/research_methods.pdf.
Feldman, J. . 2010. The NYU Classification System for ED Visits: WSHA Technical Concerns.
       Washington State Hospital Association: Health Information Program.
Gindi, Renee M, Robin A Cohen, and Whitney K Kirzinger. 2012. "Emergency room use among adults
        aged 18–64: early release of estimates from the National Health Interview Survey, January–June
        2011." National Center for Health Statistics.
Hollingsworth, Alex 2014.
Institute of Medicine. 2007. Hospital-Based Emergency Care: At the Breaking Point: The National
         Academies Press.
Jaffe, Todd A., Keith E. Kocher, and Amir A. Ghaferi. 2018. "Potentially Avoidable Emergency
        Department Use: When Policy Expects Patients to be Physicians." Annals of Emergency
        Medicine 72 (3):256-258. doi: 10.1016/j.annemergmed.2018.05.019.
Johnston, K., L. Allen, T. Melanson, and S. Pitts. Forthcoming. "An Update to the NYU Emergency
       Department Algorithm." Health Serv Res.
Kellermann, A. L. 1994. "Nonurgent emergency department visits: Meeting an unmet need." JAMA 271
       (24):1953-1954. doi: 10.1001/jama.1994.03510480077038.
Martsolf, Grant, Kathryn R. Fingar, Rosanna Coffey, Ryan Kandrack, Tom Charland, Christine Eibner,
       Anne Elixhauser, Claudia Steiner, and Ateev Mehrotra. "Association Between the Opening of
       Retail Clinics and Low-Acuity Emergency Department Visits." Annals of Emergency Medicine
       69 (4):397-403.e5. doi: 10.1016/j.annemergmed.2016.08.462.
Mehrotra, A., H. Liu, J. L. Adams, M. C. Wang, J. R. Lave, N. M. Thygeson, L. I. Solberg, and E. A.
       McGlynn. 2009. "Comparing costs and quality of care at retail clinics with that of other medical
       settings for 3 common illnesses." Ann Intern Med 151 (5):321-8.
Missouri Census Data Center. 2016. "All About ZIP Codes: 2010 Supplement." accessed July 1.
       http://mcdc.missouri.edu/geography/ZCTAs-2010.html.
Nadel, V. 1993. "Emergency departments: Unevenly affected by growth and change in patient use." US
        General Accounting Office: Report to the Chairman, Subcommittee on Health for Families and
        the Uninsured, Committee on Finance, US Senate. Washington, DC: US Government Printing
        Office.
Niska, Richard; Bhuiya, Farida; Xu, Jianmin 2010. "National Hospital Ambulatory Medical Care Survey:
        2007 Emergency Department Summary." National Health Statistics Reports 26.
O'Malley, A. S. 2013. "After-hours access to primary care practices linked with lower emergency
       department use and less unmet medical need." Health Aff (Millwood) 32 (1):175-83. doi:
       10.1377/hlthaff.2012.0494.
Pitts, S. R., J. M. Pines, M. T. Handrigan, and A. L. Kellermann. 2012. "National trends in emergency
          department occupancy, 2001 to 2008: effect of inpatient admissions versus emergency
          department practice intensity." Ann Emerg Med 60 (6):679-686.e3. doi:
          10.1016/j.annemergmed.2012.05.014.
Rask, Kimberly J, Mark V Williams, Ruth M Parker, and Sally E McNagny. 1994. "Obstacles predicting
       lack of a regular provider and delays in seeking care for patients at an urban public hospital."
       JAMA 271 (24):1931-1933.
State of Arizona, ; . 2004. "Arizona Administrative Code Department of Health Services – Health Care
         Institutions: Licensing." http://apps.azsos.gov/public_services/Title_09/9-10.pdf.
State of New Hampshire, ; . "New Hampshire Code of Administrative Rules."
         http://www.dhhs.nh.gov/oos/bhfa/documents/he-p806.pdf.
Steiner, Claudia, Anne Elixhauser, and Jenny Schnaier. 2001. "The healthcare cost and utilization project:
         an overview." Effective clinical practice: ECP 5 (3):143-151.
Stoimenoff, Laurel;, and Nate Newman. 2017. Urgent Care Industry White Paper 2018 (Unabridged): The
       Essential Role of the Urgent Care Center in Population Health.
Sussman, A., L. Dunham, K. Snower, M. Hu, O. S. Matlin, W. H. Shrank, N. K. Choudhry, and T.
      Brennan. 2013. "Retail clinic utilization associated with lower total cost of care." Am J Manag
      Care 19 (4):e148-57.
United States Census Bureau. 2013. "2009-2013 American Community Survey 5-Year Estimates."
        accessed July 18. https://www.census.gov/programs-surveys/acs/.
Urgent Care Association of America. 2011. "The Case for Urgent Care." accessed July 14, 2015.
       https://ucaoa.site-ym.com/resource/resmgr/Files/WhitePaperTheCaseforUrgentCa.pdf.
Urgent Care Association of America. 2015. "Industry Frequently Asked Questions." accessed June 01,
       2016. http://www.ucaoa.org/general/custom.asp?page=IndustryFAQs.
Urgent Care Association of America. 2017. 2017 Benchmarking Report Summary: Headlines on Growth.
Urgent Care Association of America, ;. 2014. Urgent Care Association of America Releases 2014 Urgent
       Care Survey, Shows Major Industry-Wide Expansion.
Urgent Care Location, ;. 2013. Urgent Care Locations Provides Verified Urgent Care Directory.
Uscher-Pines, L., J. Pines, A. Kellermann, E. Gillen, and A. Mehrotra. 2013a. "Emergency department
       visits for nonurgent conditions: systematic literature review." Am J Manag Care 19 (1):47-59.
Uscher-Pines, Lori, Jesse Pines, Arthur Kellermann, Emily Gillen, and Ateev Mehrotra. 2013b. "Deciding
       to Visit the Emergency Department for Non-Urgent Conditions: A Systematic Review of the
       Literature." The American journal of managed care 19 (1):47.
Villaveces, Andrés, Ryan Mutter, Pamela L Owens, and Marguerite L Barrett. 2013. "Causes of injuries
        treated in the emergency department, 2010."
Weinick, R. M., R. M. Burns, and A. Mehrotra. 2010. "Many emergency department visits could be
       managed at urgent care centers and retail clinics." Health Aff (Millwood) 29 (9):1630-6. doi:
       10.1377/hlthaff.2009.0748.
Welch, Shari J, James J Augustine, Li Dong, Lucy A Savitz, Gregory Snow, and Brent C James. 2012.
       "Volume-related differences in emergency department performance." The Joint Commission
       Journal on Quality and Patient Safety 38 (9):395-AP1.
Young, G. P., M. B. Wagner, A. L. Kellermann, J. Ellis, and D. Bouley. 1996. "Ambulatory visits to
       hospital emergency departments. Patterns and reasons for use. 24 Hours in the ED Study Group."
       JAMA 276 (6):460-5.
Table 1. Summary Statistics for ZIP Codes with and without Urgent Care Centers


                                               Without any Urgent         With at Least One
                                                   Care Center           Urgent Care Center
Total Population (n)                                  12,661                  29,782***
Age (median)                                           42.0                    40.7***
Non-Hispanic White (%)                                 74.3                    65.4***
Household Income (median)                            $28,997                 $31,095***
Did not earn high school degree (%)                    12.7                    11.5***
Insurance Status (%)
       Any Private                                     67.5                      68.0
       Any Medicaid                                    16.3                    14.5***
       Uninsured                                       13.3                     14.3**
Observations (5,589)                              4,754 (85.1%)              835(14.9%)
Notes: Significance stars reflect results from means comparisons tests. * p<0.05, ** p<0.01,
*** p<0.001
Figure 1. Unadjusted Hourly Rate of Non-emergent Emergency Department Visits in ZIP
Codes with and without Urgent Care Centers
Panel A.




Panel B.
Table 2. Effect of Daily Urgent Care Center Opening/Closure on ZIP code Non-emergent
Emergency Department Rates, by Urgent Care Center Status


                                            Privately Insured              Uninsured
                                                       % Change                  % Change
                                         Coefficient     From        Coefficient    From
                                                        Baseline                  Baseline
Panel A. Daily Opening at 8 AM
Exactly 1 Urgent Care Center               -0.463        -0.68         -0.003         0.00
                                          (0.530)                     (0.632)

 Mean                                      68.02                       71.26
 Observations                              5,377                       4,486

More than 1 Urgent Care Center             0.910          1.34         0.287          0.40
                                          (0.535)                     (0.731)

 Mean                                      67.80                       71.22
 Observations                              5,189                       4,316

Panel B. Daily Closure at 8 PM
Exactly 1 Urgent Care Center               0.575          0.81         0.288          0.40
                                          (0.366)                     (0.504)

 Mean                                      70.57                       72.82
 Observations                              5,763                       5,007

More than 1 Urgent Care Center            1.01**          1.43         0.179          0.25
                                          (0.452)                     (0.497)

 Mean                                      70.58                       72.82
 Observations                              5,527                       5,290

Notes: The analytic time window is the hour immediately prior to opening/closure, and the hour
immediately after. Means reflect the adjusted percentage of ED visits in the ZIP code that are
classified as not truly emergent. Standard errors are in parentheses. All standard errors are
clustered at the Hospital Service Area level. * p<0.05, ** p<0.01, ***p<0.001
Table 3. Effect of Daily Urgent Care Center Closure on ZIP Code Non-emergent
Emergency Department Rates, by Varying Percentages of Non-emergent Injuries


                                    Privately Insured                        Uninsured
Percent of Injury Visits
                                              % Change From                       % Change From
Assumed to be Non-             Coefficient                         Coefficient
                                                 Baseline                            Baseline
Emergent


25%                               0.824             1.5              0.449               0.74
                                 (0.569)                            (0.677)

 Mean                            54.82                               60.37
 Observations                    6,048                               5,290



50%                               0.732             1.15            -0.0846              -0.13
                                 (0.572)                            (0.616)

 Mean                            63.44                               67.05
 Observations                    6,048                               5,290

75%                              1.237*             1.72            -0.0460              -0.06
                                 (0.480)                            (0.570)

 Mean                            72.11                               73.48
 Observations                    6,048                               5,290

100%                            0.978**             1.21             0.0810               0.1
                                (0.349)                              (0.450)

 Mean                            80.83s                              79.85
 Observations                    6,048                               5,290

Notes: Means reflect the adjusted percentage of ED visits in the ZIP code that are classified as
not truly emergent. Standard errors are in parentheses. All standard errors are clustered at the
Hospital Service Area level. * p<0.05, ** p<0.01, ***p<0.001
Appendix: Weekday Opening and Closure Times of Urgent Care Centers, 6 states
