                                 NBER WORKING PAPER SERIES




               OPTIMAL TARGET CRITERIA FOR STABILIZATION POLICY

                                           Marc P. Giannoni
                                           Michael Woodford

                                         Working Paper 15757
                                 http://www.nber.org/papers/w15757


                       NATIONAL BUREAU OF ECONOMIC RESEARCH
                                1050 Massachusetts Avenue
                                  Cambridge, MA 02138
                                      February 2010




We would like to thank Pierpaolo Benigno and Lars Svensson for helpful discussions, and the NSF
for support of the authors' research under grants SES-0518770 and SES-0820438. The views expressed
herein are those of the authors and do not necessarily reflect the views of the National Bureau of Economic
Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2010 by Marc P. Giannoni and Michael Woodford. All rights reserved. Short sections of text, not
to exceed two paragraphs, may be quoted without explicit permission provided that full credit, including
© notice, is given to the source.
Optimal Target Criteria for Stabilization Policy
Marc P. Giannoni and Michael Woodford
NBER Working Paper No. 15757
February 2010
JEL No. E52,E61

                                              ABSTRACT

This paper considers a general class of nonlinear rational-expectations models in which policymakers
seek to maximize an objective function that may be household expected utility. We show how to derive
a target criterion that is: (i) consistent with the model's structural equations, (ii) strong enough to imply
a unique equilibrium, and (iii) optimal, in the sense that a commitment to adjust the policy instrument
at all dates so as to satisfy the target criterion maximizes the objective function. The proposed optimal
target criterion is a linear equation that must be satisfied by the projected paths of certain economically
relevant "target variables". It takes the same form at all times and generally involves only a small number
of target variables, regardless of the size and complexity of the model. While the projected path of
the economy requires information about the current state, the target criterion itself can be stated without
reference to a complete description of the state of the world. We illustrate the application of the method
to a nonlinear DSGE model with staggered price-setting, in which the objective of policy is to maximize
household expected utility.


Marc P. Giannoni
Columbia Business School
3022 Broadway, Uris Hall 824
New York, NY 10027-6902
and NBER
mg2190@columbia.edu

Michael Woodford
Department of Economics
Columbia University
420 W. 118th Street
New York, NY 10027
and NBER
michael.woodford@columbia.edu




An online appendix is available at:
http://www.nber.org/data-appendix/w15757
       Forecast targeting has become an increasingly popular approach, both to the organiza-
tion of monetary policy deliberations and to communication with the public about monetary
policy decisions, at central banks around the world. In this approach, a contemplated for-
ward path for policy is judged correct to the extent that quantitative projections for one
or more economic variables, conditional on the contemplated policy, conform to a target
criterion.1 The present paper considers whether the conditions required for the conduct of
policy to maximize welfare can be cast in the form of such a target criterion.2 We consider
a fairly general class of stabilization problems, in which the set of possible equilibrium evo-
lutions of the economy is determined by a system of forward-looking structural equations,
representing optimizing behavior on the part of the private sector. (Our abstract framework
need not apply only to monetary policy, though that is the leading example that motivates
our formulation of the problem.)
       We show that it is possible quite generally to choose a target criterion with two important
properties. First, we seek a target criterion that is consistent with the structural equations,
and that at the same time is strong enough to imply a determinate forward path for the
economy. Thus we must verify that there exists an evolution that satisfies the target criterion,
looking forward from any possible situation that may have been reached, and also that the
evolution consistent with the target criterion is unique. Second, we seek a target criterion
such that the state-contingent evolution determined by the criterion is optimal, in the sense
of maximizing an ex ante expected welfare criterion.
       It might be thought that a sufficient solution to this problem would simply be to com-
pute the optimal state-contingent evolution of all endogenous variables, under an optimal
commitment chosen at some initial date t0 , and to refer to the solution to this problem at
any later date t to determine what forward path for policy from date t onward is consistent
   1
       For further discussion and examples, see, e.g., Svensson (1997, 2005) and Woodford (2007).
   2
       This has previously been shown to be possible in special examples in Svensson and Woodford (2005) and
Giannoni and Woodford (2005). The present exposition offers a simpler expression for the optimal target
criterion than in our previous attempt at a general theory, in Giannoni and Woodford (2003a), in additional
to allowing a considerably more general class of possible objectives for policy, so that the present approach
can be applied to problems, like the one in section 4, where the objective of policy is assumed to be the
maximization of household utility.



                                                      1
with the optimal equilibrium. In practice, however, such a once-and-for-all description of the
optimal evolution under all possible situations that can ever arise will be impractical, even
for decision-making within an institution like a central bank, let alone for communication
with the public about the basis for policy decisions.
       Policymakers have a great deal of information about the specific situation that has arisen,
once it arises, without having any corresponding ability to list all of the situations that may
arise very far in advance. The target criterion that we seek is accordingly one that allows
a forward path for policy to be selected at each date, looking forward from the particular
situation that has arisen at that date, without any reference to all of the paths that the
economy might have taken but has not.
       Moreover, the target criterion that we propose can be stated without a complete de-
scription of the state of the world in which it is to be applied. The target criterion is a
linear equation that must be satisfied by the projected paths of certain “target variables”;
while a determination of the forward path of policy required for the economy’s evolution to
satisfy the criterion will involve fine-grained information about the current state, the target
criterion itself (which takes the same form at all times and involves only a small number of
target variables) can be stated without reference to such a complete description of the state.
       The methods that we use to derive the optimal target criterion are related to methods
used in the literature on (discrete-time, stochastic) optimal control, but our approach differs
in important respects. In the standard theory of optimal control (e.g., Anderson and Moore,
1979; Hansen and Sargent, 2010), a “policy equation” is derived that specifies a vector of
policy instruments (or “controls”) as a function of a state vector that includes a complete
description of both current disturbances and all information available at a given point in
time about future disturbances. When the theory is extended to deal with optimal policy
choice subject to forward-looking constraints, the policy equation specifies the instruments as
functions not only of the state vector but also of a vector of Lagrange multipliers measuring
the value of inducing alternative expectations about conditions at an earlier date.3
       The characterization we that seek is instead independent of the choice of the instruments
   3
       Important early expositions of this approach include Backus and Driffill (1986) and Currie and Levine
(1993).



                                                      2
of policy — for example, the optimal target criterion for monetary stabilization policy takes
the same form, regardless of whether the central bank is expected to use a short-term nominal
interest rate as its policy instrument, or the money supply, in a model where one of the
structural relations can be used to determine the money supply required to achieve a given
equilibrium interest rate and vice versa — and instead specifies only a relationship that
policy should aim to bring about among “target variables” that can be influenced by policy.
Moreover, we seek a relationship that can be stated without reference to the complete state
vector (which in practical applications must be a very large state vector, if one that can even
be written down), and that involves only economically relevant “target variables” — variables
for which quantitative projections have meaning independent of the particular model of the
economy that may be used to produce the projections — rather than abstract concepts such
as the Lagrange multipliers associated with a particular optimization problem.
    The paper is organized as follows. Section 1 presents the general class of nonlinear op-
timization problems including both backward-looking and forward-looking constraints with
which we are concerned. Section 2 derives a local linear approximation to the optimal equi-
librium dynamics in such a problem, and states some important algebraic properties of the
coefficients of the equations describing these dynamics. (Here we generalize standard re-
sults from the theory of optimal control to a case in which the controls and their effects are
not specified.) Section 3 then gives the general form of the optimal target criterion, and
establishes that it does indeed determine a (locally) unique equilibrium that coincides with
the optimal evolution characterized in section 2. Section 4 illustrates the application of the
method to a nonlinear DSGE model with staggered price-setting. Section 5 concludes.



1     A General Nonlinear Framework
We consider a general nonlinear forward-looking model describing the behavior of the private
sector and a general objective function for the policy authority, as in the analysis of Benigno
and Woodford (2008). In this section, we derive nonlinear first-order conditions for the policy
problem, and use these to define the steady state around which our local analysis of optimal
stabilization in response to shocks is conducted.


                                              3
1.1        The Model

Consider the following optimal policy problem. The policy authority seeks to determine
which state-contingent evolution of the m-dimensional vector of endogenous variables {yt }
for t ≥ t0 will maximize the objective
                                                     ∞
                                                     X
                                         Vt0 ≡ Et0          β t−t0 π (yt , ξ t ) ,                          (1.1)
                                                     t=t0

where 0 < β < 1, π (y, ξ) is a twice continuously differentiable function in all of its arguments,
and ξ t is a vector of exogenous disturbances. We assume that yt includes variables determined
at date t or possibly before. The evolution of these variables must satisfy the n constraints

                                                F (yt , ξ t ; yt−1 ) = 0                                    (1.2)

                                           Et [g (yt , ξ t ; yt+1 )] = 0                                    (1.3)

each period. Here F (·) and g (·) are respectively k-dimensional and n−k-dimensional vector-
valued functions, twice continuously differentiable with respect to all of their arguments,
where 0 ≤ k ≤ n. The vector of exogenous disturbances ξ t is assumed to evolve according to
some bounded stochastic process (specified further below).
       In order to state certain technical regularity conditions below, it is useful to state condi-
tion (1.2) in a more general form when t = t0 , instead writing
                                             ¡                   ¢
                                            F yt0 , ξ t0 ; yt0 −1 = F̄t0 ,                                  (1.4)

where F̄t0 is a vector of k small quantities that may differ from zero.4 The model structural
relations then consist of equation (1.2) for each period t > t0 , equation (1.3) for each t ≥ t0 ,
and equation (1.4), for given initial conditions yt0 −1 , F̄t0 , and a given exogenous process {ξ t }
for the disturbances.
       We assume that n < m ≤ 2n. The first inequality is necessary in order for there to
be at least one direction each period in which it is possible for policy to continuously vary
   4
       The idea is that we wish to consider perturbations of the initial conditions for the policy problem that do
not necessarily correspond to changes in the specified values for yt0 −1 and ξ t0 . The point of the distinction
is that we wish to consider optimal policy in the case of non-zero values of F̄t0 even when specifying that
the process {ξ t } is equal to ξ̄ with probability one at all times.

                                                            4
equilibrium values of one or more of the endogenous variables; the second (which simplifies
the algebraic structure of our problem,5 while it is not essential for our methods) implies
that the number of independent dimensions of policy is not too large relative to the number
of endogenous variables in the model. For example, in many classic treatments of monetary
stabilization policy, policy choice is assumed to be one-dimensional (the choice of the money
supply, or of one nominal interest rate, each period), so that m = n + 1,6 and this is the case
for which we present the most thorough analysis.
       Note that in this formulation of the optimal policy problem, we do not specify the “instru-
ments” of policy, and write a set of structural equations that should completely determine
the evolution of the endogenous variables under any given evolution of the instruments.7
Instead, equations (1.2)–(1.4) represent the conditions that must be satisfied in equilibrium
under any possible policy (as a result of optimizing private behavior), which may or may
not even involve all of the intended instruments of policy; the existence of instruments under
the control of the policy authority is represented by the incompleteness of the set of equa-
tions (1.2)–(1.4) relative to the number of endogenous variables to be determined. (Because
n < m, the variables yt are surely not uniquely determined by the structural relations, even
if some subset of them may be, as discussed in Proposition 2 below.) We do not specify the
way in which the available instruments of policy must be adjusted in order to bring about
a given state-contingent evolution of the endogenous variables, but we assume that the set
of equations (1.2)–(1.4) represents a complete set of constraints, so that any evolution of
the variables yt consistent with these equations (and satisfying certain bounds, as discussed
further below) can in fact be achieved under some policy.
       We proceed in this way in order to make it clear that the optimal target criterion does
not depend on the choice of the instrument of policy that is adjusted in order to comply
with the target criterion. For example, the instrument of monetary policy might be either
a short-term nominal interest rate, or the quantity of base money (to consider two familiar
   5
       See discussion following Assumption 2 below.
   6
       See, for example, Clarida et al., (1999), Giannoni and Woodford (2003b), or Benigno and Woodford
(2005).
   7
     This is an important difference between our current approach and the characterization of optimal policy
in Giannoni and Woodford (2003a).


                                                     5
cases). The model structural relations may include an equilibrium relation linking these two
variables (the condition required in order for the demand for money at the given interest
rate to equal the supply of money), but no equation specifying the central bank’s operating
target for either variable. The structural relation may be taken to determine the implied
nominal interest rate, if the quantity of money is the instrument (as in traditional textbook
accounts); or it may be taken to determine the endogenous quantity of base money, if the
interest rate is the central bank’s instrument (as in the case of most actual central banks).
The optimal target criterion that the central bank should seek to satisfy is the same in either
case, and depends only on the set of structural relations (possibly including the coefficients
of the money-demand relation).
       In addition, we assume that the policymaker considers only paths for the economy con-
sistent with initial pre-commitments of the form
                                         ¡                      ¢
                                        g yt0 −1 , ξ t0 −1 ; yt0 = ḡt0 ,                             (1.5)

where ḡt0 , which may depend on the exogenous state at date t0 and on predetermined
variables, is chosen according to a self-consistent rule (as discussed further below). If we
were instead to consider the problem of maximizing (1.1) subject only to constraints (1.2)–
(1.4) and the initial conditions yt0 −1 and F̄t0 , the optimal solution would in general not involve
a constant value of yt even in the absence of random disturbances (in the case that k < n,
so that one or more of the structural equations is forward-looking). As a consequence, the
unconstrained optimal (or Ramsey) policy cannot generally be described by a time-invariant
policy rule; a target criterion designed to implement this policy would have to be indexed
by the time that has elapsed since the date at which the optimization was performed.8
       Here we consider the simpler problem of characterizing policy that is optimal subject
to a particular kind of pre-commitment of the form (1.5). “Self-consistency” of the initial
pre-commitment means that ḡt0 is determined by a rule which is also satisfied for all t ≥ t0
under the policy that solves this optimization problem, so that the policy chosen can be
   8
       Even more problematic for our purposes, it would not be possible to compute a linear approximation
to optimal policy by linearizing around steady-state values of the endogenous variables; it would instead
be necessary to linearize around a non-constant path for the variables yt , greatly increasing the number of
derivatives that would have to be evaluated in order to apply such an approach.

                                                       6
viewed as fulfilling a commitment that would optimally have been made at an earlier date.9
Formally, we require that ḡt0 be determined by a function of the form ḡt0 = ḡ(ξ t0 ; et0 −1 ),
where et0 −1 is some vector of sufficient statistics for the history of the endogenous variables
up until period t0 − 1,10 with the property that under the optimal policy subject to these
pre-commitments,
                                          g(yt−1 , ξ t−1 ; yt ) = ḡ(ξ t ; et−1 )

in each period t > t0 as well.
       Choice of an initial pre-commitment of this kind results in a problem for which the
solution is a steady state (yt = ȳ for all t ≥ t0 , for some vector ȳ) in the absence of
random disturbances (i.e., in the case in which ξ t = ξ̄ with certainty for all t), and we can
approximate optimal policy in the case of small enough disturbances by linearizing around
this steady state. Moreover, the constrained-optimal policy (hereafter simply called “optimal
policy”) can be described by a time-invariant rule for the determination of yt as a function
of exogenous and pre-determined state variables, and as a consequence it is possible to
implement the policy using a time-invariant target criterion.


1.2        Nonlinear First-Order Conditions for Optimal Policy

We wish to characterize the state-contingent evolution {yt } for t ≥ t0 that maximizes (1.1)
subject to the constraints (1.2)–(1.5). A Lagrangian for this (exact) nonlinear optimal policy
problem is given by
                                 ∞
                                 X
           Lt0 = Vt0 + Et0             β t−t0 [θ0t F (yt , ξ t ; yt−1 ) + Θ0t g (yt , ξ t ; yt+1 )]
                                 t=t0
                         −1   0
                                     ¡                    ¢
                     +β Θt0 −1 g yt0 −1 , ξ t0 −1 ; yt0
                         X∞
                                      £                                                       ¡                  ¢¤
                 =   Et0      β t−t0 π (yt , ξ t ) + θ0t F (yt , ξ t ; yt−1 )   + β −1 Θ0t−1 g yt−1 , ξ t−1 ; yt      (1.6)
                         t=t0

   9
       We have elsewhere called this a policy that is “optimal from a timeless perspective.” See Woodford
(1999, 2003), Giannoni and Woodford (2003a) and Benigno and Woodford (2008) for further discussion.
  10
     This vector may include not only lagged values yt0 −j , but also lagged forecasts Et0 −j yt0 −j+k , for arbitrary
j, k ≥ 1. See section 3.3 for a precise specification.




                                                              7
where θt and Θt are vectors of Lagrange multipliers of dimensions k and n − k respectively,
associated with the constraints (1.2)–(1.3) for any date t ≥ t0 ,11 and β −1 Θ0t0 −1 is the vector
of multipliers associated with the constraints (1.5). Differentiating with respect to yt we
obtain the m first-order conditions (FOCs)

                                                                    £           ¡                ¢¤
              D1 π (yt , ξ t ) + θ0t D1 F (yt , ξ t ; yt−1 ) + βEt θ0t+1 D3 F yt+1 , ξ t+1 ; yt
                                                                                   ¡                 ¢
                               + Et [Θ0t D1 g (yt , ξ t ; yt+1 )] + β −1 Θ0t−1 D3 g yt−1 , ξ t−1 ; yt = 0      (1.7)

at each date t ≥ t0 , where Dj denotes the vector of partial derivatives with respect to the
jth argument of the function considered.
       These FOCs can be written more compactly as

                                £ ¡                         ¢    ¤          ¡                       ¢
        (D1 π (yt , ξ t ))0 + Et Ā0 yt+1 , yt , ξ t+1 , ξ t ϕt+1 − β −1 I¯0 yt , yt−1 , ξ t , ξ t−1 ϕt = 0,   (1.8)

                                             ¡                       ¢      ¡                       ¢
where ϕt+1 is an n-dimensional vector, and Ā yt+1 , yt , ξ t+1 , ξ t and I¯ yt , yt−1 , ξ t , ξ t−1 are
(n × m) matrices defined as
                                                                       
                                                                 θt+1
                                               ϕt+1 ≡                  
                                                                 Θt
                                                                 ¡                  ¢ 
                               ¡                   ¢        βD3 F yt+1 , ξ t+1 ; yt
                            Ā yt+1 , yt , ξ t+1 , ξ t ≡                              
                                                             D1 g (yt , ξ t ; yt+1 )
                                                                                      
                               ¡                       ¢    −βD1 F (yt , ξ t ; yt−1 )
                             I¯ yt , yt−1 , ξ t , ξ t−1 ≡       ¡                   ¢ .
                                                            −D3 g yt−1 , ξ t−1 ; yt

These FOCs are necessarily satisfied by the optimal equilibrium, if one exists, but a solution
to the FOCs is not necessarily an optimum. We shall assume, however, that an optimum
satisfying the FOCs does exist; and under further assumptions stated below, a bounded
solution to the FOCs will also necessarily correspond to an optimum.
       Note that (1.6) is also the Lagrangian for an alternative problem, the problem of choosing
a path {yt } to maximize the modified objective

                                                            ¡                       ¢
                                        Vt0 + β −1 Θ0t0 −1 g yt0 −1 , ξ t0 −1 ; yt0                            (1.9)
  11
       To be more precise, θt0 is the vector of multipliers associated with constraints (1.4).


                                                             8
subject to the constraints (1.2)–(1.4) for dates t ≥ t0 . In this alternative formulation, the
vector Θt0 −1 is part of the data defining the problem, just as the vector ḡt0 is in the problem
stated earlier. Since the Lagrangian for this alternative problem is the same, the set of
first-order conditions is also identical to the ones given above. Therefore, any solution to
the first type of problem for some choice of the vector ḡt0 is also a solution to a problem of
the second type for some choice of the vector Θt0 −1 , and vice versa. The modification of the
policy authority’s objective as in (1.9) is an alternative way of requiring it to take account
of the value to a policymaker at an earlier time of being able to anticipate a particular kind
of policy from date t0 onward.12
   If an optimal steady state (an optimum in which yt = ȳ for all t, under the assumption
                                                                         ¡          ¢
that ξ t = ξ̄ for all t) exists, it will be described by constant vectors ȳ, ϕ̄, ξ̄ satisfying

                                                     ¡          ¢
                                                   F ȳ, ξ̄; ȳ = 0,                                   (1.10)
                                                     ¡          ¢
                                                    g ȳ, ξ̄; ȳ = 0,                                  (1.11)
                                               ¡            ¢0
                                      (D1 π)0 + Ā − β −1 I¯ ϕ̄ = 0,                                   (1.12)

                 ¡ ¢                  ¡          ¢             ¡          ¢
where D1 π ≡ D1 π ȳ, ξ̄ , Dj F ≡ Dj F ȳ, ξ̄; ȳ , Dj g ≡ Dj g ȳ, ξ̄; ȳ for j = 1, 2, 3, and

                                                     ¡             ¢
                                            Ā ≡ Ā ȳ, ȳ, ξ̄, ξ̄ ,
                                                    ¡              ¢
                                             I¯ ≡ I¯ ȳ, ȳ, ξ̄, ξ̄ .

We shall suppose that such a steady state exists; in fact, we make the more specific assump-
tion stated below.


Assumption 1 (a) Let a vector ξ̄ of “steady state” values of the exogenous disturbances be
given. Then there exist vectors ȳ ∈ Rm and ϕ̄ ∈ Rn such that if yt0 −1 = ȳ, Θt0 −1 = Θ̄ [≡ ϕ̄2 ],
F̄t0 = 0 and ξ t = ξ̄ with certainty for all t ≥ t0 −1, the optimal policy [the one that maximizes
(1.9) subject to constraints (1.2)–(1.4)] involves yt = ȳ with certainty for all t ≥ t0 .
       (b) Moreover, for any small enough neighborhood Ny of ȳ, there exist neighborhoods NΘ
of Θ̄, Nθ of θ̄, NF of 0, and N2 ⊆ Ny such that for any yt0 −1 ∈ N2 , Θt0 −1 ∈ NΘ , F̄t0 ∈ NF ,
  12
       This alternative way of requiring the policymaker to internalize the consequences of a prior commitment
is used, for example, in Marcet and Marimon (1998), Khan et al. (2003), and Svensson and Woodford (2005).


                                                        9
and a disturbance vector ξ t = ξ̄ for all t ≥ t0 − 1, the optimal policy involves yt ∈ Ny with
yt → ȳ as t → ∞. Moreover, there exists a sequence of multipliers {ϕt } consistent both with
the specified initial conditions and with the FOCs (1.8) for all t ≥ t0 , such that ϕt ∈ NΘ × Nθ
for all t ≥ t0 , and ϕt → ϕ̄ as t → ∞. Finally, the convergence is exponential: there exists
δ > 1 such that
                            lim δ t (yt − ȳ) = 0,         lim δ t (ϕt − ϕ̄) = 0                   (1.13)
                            t→∞                            t→∞

for any initial conditions in the specified set.
   (c) There also exists a neighborhood Ng of the vector ḡ ≡ g(ȳ, ξ̄; ȳ) and a diffeomorphism

                               γ : NΘ × N 2 × N F → N g × N 2 × N F

with the properties
                               γ 2 (Θ, y, F̄ ) = y,        γ 3 (Θ, y, F̄ ) = F̄ ,

such that for any Θt0 −1 ∈ NΘ , a path {yt } for t ≥ t0 maximizes (1.9) in the case of this
vector of multipliers, initial conditions (yt0 −1 , F̄t0 ), and a specification that ξ t = ξ̄ for all t,
if and only if it maximizes (1.1) subject to the initial pre-commitments (1.5), where ḡt0 =
γ 1 (Θt0 −1 , yt0 −1 , F̄t0 ), and the same initial conditions (yt0 −1 , F̄t0 ). Moreover, the matrix Γ̄ ≡
Dγ(Θ̄) is non-singular.

   Assumption 1 implies not only that a steady state exists, but that in the case of any
initial conditions close enough to consistency with the steady state and no stochastic distur-
bances, the optimal equilibrium will remain forever near this steady state, and converge to
it asymptotically (indeed, at an exponential rate). We also assume that the Lagrange mul-
tipliers associated with the optimal policy remain forever near their steady-state values and
converge exponentially as well. It then follows that for any small enough neighborhoods of
the steady state (as specified in the statement of the assumption), there must exist a neigh-
borhood Nξ of ξ̄, such that the optimal dynamics will also involve yt ∈ Ny and ϕt ∈ NΘ × Nθ
for all t ≥ t0 as long as ξ t ∈ Nξ for all t ≥ t0 − 1, though of course there is no convergence
to the steady state in the stochastic case. This makes it possible for us to analyze optimal
stabilization policy in response to small enough disturbances through a purely local analysis
of equilibria in which the endogenous variables yt remain forever near the steady-state values
ȳ and the multipliers {ϕt } remain forever near the steady-state values ϕ̄.

                                                      10
   Assumption 1(c) implies that in the case of all initial conditions close enough to consis-
tency with the steady state (which is to say, all of those with which we shall be concerned
in this paper), there is a unique problem of the first type (defined by a vector of pre-
commitments ḡt0 ) corresponding to each problem of the second type (defined by a vector of
initial Lagrange multipliers Θt0 −1 ), and vice versa. The additional stipulation that the map-
ping γ has a non-singular Jacobian matrix is only a slight strengthening of the assumption
that the mapping is invertible near the steady state; this is necessary to allow us to assert
a similar equivalence between the linearized versions of the conditions that characterize the
two kinds of optimal plans.
   Assumption 1 implies the existence of steady-state values (ȳ, ϕ̄) that satisfy conditions
(1.12), associated with the given stationary vector of values ξ̄ for the exogenous states, and
further implies the existence of a solution to the FOCs, in which the variables yt and ϕt
remain forever near their steady-state values, in the case of any small enough perturbations
in the initial conditions. It is these local solutions to the FOCs (1.8) that we wish to
further characterize, through the linear approximation presented in the next section. Under
relatively weak regularity conditions, we show that there must be at most one solution to the
FOCs that remains forever near the steady state, which solution must (by Assumption 1) be
the optimal equilibrium. Hence it suffices to find a target criterion with the property that
a path for the endogenous variables that is feasible under some policy, that remains forever
within the neighborhood Ny , and that fulfills the target criterion at all times (i) exists in the
case of all initial conditions near enough to consistency with the steady state and all small
enough disturbances, and (ii) must also satisfy the FOCs in all periods, in order for us to
conclude that fulfillment of the target criterion is necessary and sufficient for the intended
future evolution of policy to be optimal, again in the case of all initial conditions near enough
to consistency with the steady state and all small enough disturbances.
   We do not here seek to provide more fundamental assumptions under which Assumption
1 is necessarily valid. In practice it is relatively straightforward in applications to verify
the existence of a steady-state solution to the FOCs (1.12). It is also straightforward to
evaluate the second-order conditions [SOCs] that tell whether this solution represents a local



                                               11
welfare optimum, discussed further in section 2.2.1 below,13 and to analyze convergence to
the steady state in the deterministic case for initial conditions close enough to consistency
with the steady state, as these involve algebraic properties of the derivatives of the functions
defining the problem, evaluated at the steady-state values of their arguments. The more
difficult question is verification of the global optimality of the local optimum represented
by a solution to the FOCs and SOCs. We do not address this here, but assume that it is
satisfied in an application of interest.
       Finally, note that while we assume the existence of an “optimal steady state” in the sense
that optimal policy involves constant values of the endogenous variables in the absence of
random disturbances, we do not assume that the steady state near which we conduct our
analysis is an undistorted steady state. That is, we do not assume that in the absence of
disturbances and under suitable initial conditions, there would exist a policy that achieves
the unconstrained maximum of the function π(y; ξ̄) each period. Our methods are applicable
to problems in which there exist distortions, the severity of which depends on policy, but
that cannot be eliminated at all times by any policy. For example, in the application treated
in section 4, the steady-state level of output may be inefficiently low, owing either to market
power or to tax distortions, even under the optimal monetary policy.



2        Linear Approximation of the Optimal Equilibrium
         Dynamics
As long as we are interested solely in small enough perturbations of the steady-state policy
problem, of the kind described in Assumption 1, we can approximate the optimal solution
for yt as a function of the initial conditions (yt0 −1 , ξ t0 −1 , F̄t0 , Θt0 −1 ) and the history of dis-
turbances (ξ t0 , . . . , ξ t ) by a linear function of these variables, where the coefficient on each
variable represents the partial derivative of the optimal yt with respect to that variable,
with all partial derivatives evaluated at the steady state referred to in Assumption 1. And
as usual, the implicit function theorem allows us to calculate these derivatives by solving
  13
       Benigno and Woodford (2008) present an alternative formulation of the SOCs that has some advantages
from a computational standpoint.


                                                     12
linearized versions of the conditions that describe an optimum, where the linearizations are
all computed at the steady-state solution.14
       Local approximation of the optimal equilibrium dynamics thus requires us to solve a
system of linear difference equations consisting of linearizations of two sets of nonlinear
equations: the structural equations (1.2)–(1.4) on the one hand, and the first-order conditions
(1.8) on the other. The linearized structural equations are also relevant for deriving a linear
approximation to the equilibrium dynamics consistent with a given target criterion. We turn
to this system of equations first.


2.1        Approximation of the Model Structural Equations

We linearize the system of structural equations (1.2)–(1.4) around the steady-state values of
the arguments (yt = ȳ and ξ t = ξ̄ for all t), where ȳ is the optimal steady state (assumed to
exist in Assumption 1) in the case of the constant vector ξ̄ for the exogenous variables. We
will denote the deviations from steady-state values by ỹt ≡ yt − ȳ, ξ̃ t ≡ ξ t − ξ̄, and derive
local approximations for the case in which terms of both these kinds are small. Specifically,
we consider the family of stochastic processes

                                                  ξ t = ξ̄ + ²ut

indexed by a parameter ² ≥ 0, where {ut } is some bounded process (held fixed as we consider
variations in ²). We wish to characterize optimal monetary policy for the case in which ²
is sufficiently small (though still positive), by computing solutions for the state-contingent
evolution of all endogenous variables that are accurate up to an error that is at most of
size O(²2 ). To economize on notation, we shall assume that the disturbances {ξ t } evolve in
accordance with a linear first-order vector autoregressive process,15 so that

                                                  Et ξ̃ t+1 = %ξ̃ t ,                                      (2.1)

where % is a matrix such that ||%|| < 1.
  14
       See Woodford (2003, Appendix A.3) or Benigno and Woodford (2008) for further discussion.
  15
       Note that this allows for serial correlation of arbitrary complexity in the disturbance processes, as long
as the vector ξ t is assumed to include a sufficient number of lagged disturbances.


                                                         13
2.1.1    The Linearized Structural Equations

We first recall that F (yt , ξ t ; yt−1 ) = 0 is a k-dimensional vector-valued function, and that
                  ¡         ¢
in steady state F ȳ, ξ̄; ȳ = 0. A first-order approximation of the structural equations (1.2)
yields
                               D1 F · ỹt + D3 F · ỹt−1 + D2 F · ξ̃ t = 0                  (2.2)

for all t > t0 , omitting terms that are merely of second order. In the initial period, we
correspondingly have

                            D1 F · ỹt0 + D3 F · ỹt0 −1 + D2 F · ξ̃ t0 = F̄t0 .            (2.3)

   It will often be convenient to break these equations into two separate sets of equations,
corresponding to the implications for variables forecasted a period in advance on the one
hand, and the implications for surprise changes in variables on the other. Using (2.1), we
note that (2.2) implies that

                             D1 F · Et ỹt+1 + D3 F · ỹt + D2 F % · ξ̃ t = 0               (2.4)

for any t ≥ t0 , and that
                                                         ³              ´
                            D1 F (ỹt − Et−1 ỹt ) + D2 F ξ̃ t − %ξ̃ t−1 = 0                (2.5)

for any t > t0 . Conversely, we can show that these two sets of equations imply (2.2) for all
t > t0 . Hence we can equivalently write the system of linearized structural equations (2.2)
as equations (2.3)–(2.5).
   Similarly, the structural equations (1.3) can be approximated by

                               D3 g · Et ỹt+1 + D1 g · ỹt + D2 g · ξ̃ t = 0               (2.6)

for all t ≥ t0 . We note for future reference that the initial pre-commitment (1.5) can also be
linearized as
                            D3 g · ỹt0 + D1 g · ỹt0 −1 + D2 g · ξ̃ t0 −1 = ḡt0 .         (2.7)

(This is not a structural relation that is required to hold when computing the equilibrium
evolution consistent with a given target criterion, but it is an additional constraint to be
imposed when solving for the optimal equilibrium dynamics.)

                                                     14
    Structural equations (2.4) and (2.6) can then be combined into the matrix equation

                                         ¯ t ỹt+1 = Āỹt + C̄ ξ̃ t
                                         IE                                               (2.8)

for all t ≥ t0 , where I¯ and Ā are the same matrices as in (1.12), and
                                                      
                                               βD2 F %
                                        C̄ ≡          .
                                                D2 g

In terms of this notation, equation (2.5) can be written as
                                                       ³                 ´
                             I¯1 (ỹt − Et−1 ỹt ) = D̄ ξ̃ t − Et−1 ξ̃ t                  (2.9)

for all t > t0 , where I¯1 ≡ −βD1 F is the k × m matrix consisting of the first k rows of I,
                                                                                          ¯ and

D̄ ≡ βD2 F ; and equation (2.3) can be written as

                                   I¯1 ỹt0 = Ā1 ỹt0 −1 + D̄ξ̃ t0 − β F̄t0 ,           (2.10)

where Ā1 ≡ βD3 F is the k × m matrix consisting of the first k rows of Ā. Thus the complete
system of linearized structural equations can alternatively be written as (2.8)–(2.10), given
that the exogenous disturbances satisfy (2.1).


2.1.2    Regularity Conditions

Our analysis relies upon some further properties of the matrices of coefficients of the lin-
earized structural relations. Here we state these additional assumptions and discuss some
of their implications. The assumptions are not too restrictive, but allow us to simplify our
analysis and the statement of our results in important respects.
    The linearized structural equations are valid only locally, so that it makes sense to con-
sider only solutions to these equations that are bounded, i.e., that satisfy the bound

                                      ||ỹ|| ≡ ess sup |ỹt | < ∞.                       (2.11)
                                                       t≥t0

We shall state our further regularity conditions in terms of the matrices I¯ and Ā.

Assumption 2 (a) The matrix                                  
                                                        I¯
                                                                                       (2.12)
                                                       Ā

                                                       15
is of full column rank, i.e., of rank m.
   (b) In addition, the matrix pencil I¯ − µĀ is of rank n. Hence its rows are linearly
independent; that is, there exists no vector ϕ(µ) 6= 0 of polynomial functions of µ such that

                                      ϕ(µ)0 [I¯ − µĀ] = 0                             (2.13)

for all µ. Moreover, there exists no vector ϕ̄ 6= 0 such that

                                       ϕ̄0 [I¯ − β Ā] = 0.                            (2.14)

   Assumption 2(a) requires that m ≤ 2n, as mentioned earlier; thus the number of inde-
pendent dimensions along which policy can be varied is not too great, relative to the number
of dimensions of variation that are possible in the endogenous variables. However, in the
case that m ≤ 2n, the assumption holds for generic matrices of coefficients I¯ and Ā. If
Assumption 2(a) did not hold, the vector yt would involve redundant state variables, that
could be eliminated altogether, as far as the structural equations (2.8) are concerned. These
variables may not actually be redundant, because they might nonetheless matter for equa-
tions (2.9)–(2.10); but we abstract from this complication here, and instead assume that it
is possible to write the system in terms of a vector of m endogenous variables for which
Assumption 2(a) is satisfied.
   Assumption 2(b) similarly implies that there is no redundancy among the separate struc-
tural equations (2.8); it is a stronger form of linear independence assumption, since it also
excludes the possibility that some equation in the system (2.8) is implied by conditional
expectations of leads of other equations in the system. The further stipulation in the last
sentence is the algebraic condition required for uniqueness of the steady-state Lagrange mul-
tipliers ϕ̄ associated with the optimal steady state ȳ around which we conduct our local
analysis.
   Assumption 2(a) could equivalently be stated as a property of the pencil I¯ − µĀ: there
exists no constant vector y 6= 0 such that

                                        [I¯ − µĀ] y = 0

for all µ. But it is not possible to make a similar statement about the nonexistence of
polynomial solutions; for the fact that m > n implies that there must exist polynomial

                                               16
functions y(µ) such that
                                               [I¯ − µĀ] y(µ) = 0                       (2.15)

for all µ. Assumption 2(a) implies only that all such solutions must be of order greater than
zero in µ.


2.2     Approximation of the First-Order Conditions

We similarly linearize the nonlinear first-order conditions (1.8) around the steady-state values
of all variables (which now includes the specification that ϕt = ϕ̄ for all t). Proceeding as in
the previous section, we introduce the notation ϕ̃t = ϕt − ϕ̄ for deviations from the steady-
state vector of multipliers. As shown in Appendix B, the linearized version of equations (1.8)
then takes the form
               £¡                 ¢     ¤    h¡            ¢     i    h            i
      0 = Et                                            ¯ 0 ϕ̃t+1 + Et B (L) ξ̃ t+1 ,
                    βR0 + SL + RL2 ỹt+1 + Et Ā − β −1 IL                               (2.16)

omitting terms that are merely of second order, where L denotes the lag operator and ϕ̃t is
defined as                                                                     
                                       ϕ̃1,t            θ̃t              θt − θ̄
                             ϕ̃t ≡            ≡             ≡                  .
                                       ϕ̃2,t           Θ̃t−1            Θt−1 − Θ̄
The matrices Ā and I¯ are the same as in (1.12), and we define
                     ³        ´    £       ¤ ¡         ¢        £    ¤
                        0
             R ≡ θ̄ ⊗ Im D3 (D1 F )0 + Θ̄0 ⊗ Im β −1 D1 (D3 g)0 ,
                          £          ³       ´© £
                                0¤     0                   ¤       £   ¤ª
             S ≡ D1 (D1 π) + θ̄ ⊗ Im D1 (D1 F )0 + βD3 (D3 F )0
                        ¡        ¢© £         ¤         £       ¤ª
                     + Θ̄0 ⊗ Im D1 (D1 g)0 + β −1 D3 (D3 g)0 ,

and
               n £             ³     ´                                     o
                          0¤     0         £      0¤   ¡ 0   ¢   £      0¤
       B (L) ≡  D2 (D1 π) + θ̄ ⊗ Im D2 (D1 F ) + Θ̄ ⊗ Im D2 (D1 g)           ·L
                    ¡        ¢     £    ¤        ³         ´ £       ¤
                                                     0
               +β −1 Θ̄0 ⊗ Im D2 (D3 g)0 · L2 + β θ̄ ⊗ Im D2 (D3 F )0 .

   The fact that ϕ̃2,t = Θt−1 − Θ̄ means that these multipliers are determined a period in
advance (unlike the elements of ϕ̃1,t ). Hence a further requirement for consistency of the
multipliers {ϕ̃t } with an optimal plan is that

                                               ϕ̃2,t − Et−1 ϕ̃2,t = 0                    (2.17)

                                                         17
for all t > t0 . In addition, ϕ̃2,t0 is given as an initial condition (in the case of the modified
problem defined by a vector of initial multipliers Θt0 −1 ). Alternatively, we adjoin the lin-
earized version of an initial pre-commitment (2.7) to the set of structural equations, and
leave the vector ϕ̃2,t0 to be determined endogenously.


2.2.1      Second-Order Conditions

We shall make use of a further regularity condition, involving the matrices R and S, in
addition to the regularity conditions involving the matrices I¯ and Ā stated above. This
is a second-order condition for the optimality of the steady state that represents a slight
strengthening of the conditions already implicit in Assumption 1.
      Let {yi } be a bounded sequence of vectors of dimension m, not all equal to zero, such
that
                             ¯ 0 = 0,
                             Iy                     ¯ i+1 = 0
                                             Āyi − Iy               for all i ≥ 0.         (2.18)

Then let us consider a perturbation of the path {ỹt }, replacing ỹτ +i with

                                                   ỹτ +i + εyi

for all i ≥ 0 and an arbitrary date τ ≥ t0 , while leaving ỹt unchanged for all dates t < τ .
Here ε is an arbitrary small quantity. The path {ỹt } remains consistent with the linearized
structural equations (2.8)–(2.10), and continues to satisfy the bound ||ỹ|| < ∞, for any value
of ε. Then for any small enough value of |ε|, this also approximates a feasible perturbation
under the exact structural relations (1.2)–(1.4), up to an error of order O(|ε|2 ).
      In order for the original path {ỹt } to have been optimal, no such perturbation can increase
the value of the Lagrangian (1.6). In particular, given our assumption of the optimality of the
steady state in which yt = ȳ for all t, no such perturbation of the steady state can increase
the value of the Lagrangian. In the case of any small enough value of |ε|, the increase in the
value of the Lagrangian as a result of the perturbation {yi } is proportional to
                          ∞
                          X        £                                  ¤
                                β i yi0 Syi + yi+1
                                               0
                                                   βRyi + yi0 βR0 yi+1 |ε|2 + O(|ε|3 )
                          i=0

regardless of the date τ ,16 where all derivatives are evaluated at the steady state. Hence a
 16
      See section C.2 of the Appendix for details of this calculation.

                                                       18
sufficient condition for such a perturbation of the steady-state policy to be welfare-reducing,
in the case of any small enough |ε| > 0, is that
                             ∞
                             X        £                                  ¤
                                   β i yi0 Syi + yi+1
                                                  0
                                                      βRyi + yi0 βR0 yi+1 < 0.                  (2.19)
                             i=0

   We can now state the additional regularity condition that we shall invoke.

Assumption 3 In the case of any non-zero bounded sequence {yi } such that (2.18) is sat-
isfied, (2.19) also holds.

These are second-order conditions for the optimality of the steady state defined by (1.12).
Technically, Assumption 3 is not implied by Assumption 1 as stated above, as that would
only require a weak inequality in (2.19). The present assumption is, however, only a slight
strengthening of the one already implicit in Assumption 1.


2.3     Determinacy of the Solution to the FOCs

We now show that there is a unique bounded (or determinate) solution to the nonlinear
FOCs for the optimal policy problem. We have already assumed that there exists a bounded
optimal equilibrium path (Assumption 1), and since the FOCs are necessary for optimality,
there must exist a bounded solution to the FOCs. The goal of the present section is to show
that there can be only one bounded solution to the FOCs. It will follow from this result
that in the case of a bounded solution, the FOCs are also sufficient for optimality.
   As usual, for the analysis of determinacy it suffices that we demonstrate the existence
of a unique bounded solution to the linearized versions of the equations for which we seek
to demonstrate the existence of a locally unique solution. We therefore consider the system
of equations consisting of the linearized structural equations (2.8)–(2.10) together with the
linearized FOCs (2.16)–(2.17).
   We now state our first important result.

Proposition 1 Suppose that Assumptions 1, 2(b) and 3 are satisfied. Then for any initial
conditions ỹt0 −1 , F̄t0 , any specification of the initial Lagrange multipliers Θ̃t0 −1 , and any ex-
ogenous disturbance process {ξ̃ t } satisfying ||ξ̃|| < ∞ where the norm is defined as in (2.11),

                                                     19
there exists a unique solution to the system consisting of the linearized structural equations
(2.8)–(2.10) and the FOCs (2.16)–(2.17) for all t ≥ t0 with the property that ||ỹ|| < ∞ and
||ϕ̃|| < ∞.

   The proof is in Appendix A. Note that this unique solution to the linearized FOCs
represents a local linear approximation to an optimal plan, that is, to a plan that coincides
(up to an error of order O(²2 )) with a plan that maximizes the modified objective function
(1.9) defined by the initial multipliers Θ̃t0 −1 , for the specified initial conditions. Hence any
solution to the system of FOCs with the property that ||ỹ|| < ∞ represents a local linear
approximation to an optimal plan.
   Using Assumption 1(c), we immediately obtain as a further corollary that there also
exists a unique bounded solution to the system of FOCs augmented by the linearization
of the initial pre-commitments (2.7), for any choice of ḡt0 , and that any bounded solution
to this system of FOCs represents a local linear approximation to a plan that is optimal
in the sense of maximizing (1.1) subject to the initial pre-commitments. These results
follow immediately from Proposition 1, given the existence of an invertible linear relationship
between specifications of Θt0 −1 and specifications of ḡt0 .


2.4    Essential vs. Inessential Variables

As we now show, in the somewhat special case that the equilibrium relations (2.8) are
decomposable into two sub-systems of a particular type, some of the endogenous variables
are determined independently of any policy choices. We call such variables “inessential.” To
show this, we make the following technical assumptions.

Assumption 4 Suppose that there exist non-singular matrices P (n × n) and Q (m × m)
such that                                                          
                                              J1 − µB1      0
                           I¯ − µĀ = P 0                           Q0                   (2.20)
                                                 0       J2 − µB2
where J1 , B1 are (n − q) × (m − q) and J2 , B2 are q × q square matrices, for some 0 < q < n.
   (a) Then there also exist non-singular matrices T1 (k × k) and T2 ((n − k) × (n − k))



                                                 20
such that                                                                            
                                                                 0      U10
                                                                  
                                                                  0 
                                           T1       0        0 X1 
                                                      P = 
                                                         0                                        (2.21)
                                                             0      
                                           0        T2       U2 0 
                                                                    
                                                                   0
                                                              0 X2
where                                                                              
                                                    U10                         X10
                                      U0 ≡               ,        X0 ≡             
                                                    U20                         X20
are non-singular square matrices ((n − q) × (n − q) and q × q, respectively), and the blocks
                                                        
                                 U10 0            U20 0
                                        ,               
                                       0                 0
                                  0 X1             0 X2

are k × n, and (n − k) × n respectively.
    (b) Moreover, the characteristic polynomial

                                           P (λ, µ) ≡ det[λJ2 − µB2 ]

can be factored as
                                                    k2                   q−k2
                                                    Y                    Y
                                 P (λ, µ) = c             (λ − γ i µ)           (µ − η j λ),       (2.22)
                                                    i=1                  j=1

where 0 ≤ k2 ≤ q is the number of rows of X10 in (2.21), c 6= 0, and the complex numbers
{γ i , η j } satisfy |γ i | < 1 for all i, |η j | < β for all j.

Here the blocks U10 , U20 , X10 , X20 are of dimensions

                             U10 ,               U20 ,                X10 ,                X20 ,
                            |{z}                |{z}                 |{z}                 |{z}
                          (k1 × ñ) ((ñ − k1 ) × ñ) (k2 × q) ((q − k2 ) × q)

where ñ ≡ n − q > 0, 0 ≤ k1 ≤ k, 0 ≤ k2 ≤ q, and k1 + k2 = k.
    If a decomposition of the form (2.20) exists, the system of equations (2.8) can equivalently
be written in the form

                                               ∗           ∗
                                        J1 Et y1,t+1 = B1 y1,t + Γ1 ξ̃ t                           (2.23)
                                               ∗           ∗
                                        J2 Et y2,t+1 = B2 y2,t + Γ2 ξ̃ t                           (2.24)

                                                               21
for all t ≥ t0 , where                                                       
                                         ∗
                                        y1,t                               Γ1      ¡    ¢
                                               ≡ Q0 ỹt ,                     ≡ P −1 0 C̄.
                                         ∗
                                        y2,t                               Γ2
           ∗      ∗
Note that y1,t , y2,t are two independent vectors of endogenous variables (of lengths m − q and
q, respectively), that we may refer to as the “essential” and “inessential” endogenous variables
respectively.17 Each of the subsystems (2.23) and (2.24) involves only one of these sets of
endogenous variables. Thus the system (2.8) decomposes into two independent systems of
equations for the two distinct sets of endogenous variables. Assumption 4(a) states that if
such a decomposition of the system (2.8) is possible, then it is also possible to decompose
(2.9)–(2.10) into separate systems of equations, using the same decomposition of the state
                  ¡ ∗ ∗ ¢
variables ỹt into y1,t , y2,t .
       The content of (2.9) is unchanged if we pre-multiply both sides by T1 (since T1 is non-
singular). But (2.20)–(2.21) imply that
                                                           
                              0                        0
                             U1 0       J 0           UJ   0
                  T1 I¯1 =          1      Q0 =  1 1        Q0
                                  0                        0
                             0 X1       0 J2           0  X1 J2

so that the system (2.9) can be equivalently written as

                                        ¡                          ¢                ³            ´
                               U10 J1        ∗
                                            y1,t   −         ∗
                                                       Et−1 y1,t       = ∆1 ξ̃ t − Et−1 ξ̃ t           (2.25)
                                        ¡                          ¢       ³                 ´
                              X10 J2 y2,t
                                      ∗           ∗
                                          − Et−1 y2,t                  = ∆2 ξ̃ t − Et−1 ξ̃ t           (2.26)

for all t > t0 , where                                            
                                                             ∆1
                                                                   ≡ T1 D̄.
                                                             ∆2
       Similarly, the system (2.10) can equivalently be written as

                               U10 J1 y1,t
                                       ∗
                                          0
                                            = U10 B1 y1,t
                                                      ∗
                                                         0 −1
                                                              + ∆1 ξ̃ t0 − βΦ1,t0                      (2.27)

                               X10 J2 y2,t
                                       ∗
                                          0
                                            = X10 B2 y2,t
                                                      ∗
                                                         0 −1
                                                              + ∆2 ξ̃ t0 − βΦ2,t0                      (2.28)
  17
       As explained below, the “inessential” variables are not necessarily variables that are not needed for a
description of the exact equilibrium dynamics implied by the model; they are redundant only for a description
of the linearized dynamics.




                                                                   22
for period t0 , where                            
                                          Φ1,t0
                                                  ≡ T1 F̄t0 .
                                          Φ2,t0
Thus the system of structural equations (2.8)-(2.10) can equivalently be written as two in-
dependent subsystems, one consisting of equations (2.23), (2.25) and (2.27) for the evolution
  © ∗ ª                                                                             © ∗ ª
of y1,t , and the other consisting of (2.24), (2.26) and (2.28) for the evolution of y2,t  .
   Note that Assumption 4 applies only in the case that a decomposition of the form (2.20)
exists for some 0 < q < n; we do not assume that this is the case, and indeed, for generic n×m
matrices I¯ and Ā, none exists. Rather than simply excluding the possibility of “inessential”
state variables, however, we consider the more general case in which such a decomposition
can be possible, but only in the case that the complete set of linearized structural equations
(2.8)–(2.10) is decomposable into two independent systems. One might think that, in such
                                                              © ∗ ª
a case, one should be able to simply eliminate the variables y2,t   , and write the model
                                                                     © ∗ ª
structural equations as equations for the determination of variables y1,t  alone, in which
case it would suffice to assume that a decomposition of the from (2.20) is never possible (once
redundant state variables have been eliminated). However, it may be possible to decompose
the linearized structural equations even when the original nonlinear structural equations are
not similarly decomposable.
   This possibility is illustrated by our analysis of the exact New Keynesian model in section
4. In that model, the dynamics of the index of price dispersion are, to first order, independent
of the evolution of any of the other endogenous aggregate variables, so that this variable is
“inessential” in our terminology. However, this does not mean that the evolution of the index
of price dispersion is independent of the other variables (and independent of monetary policy)
in the exact model; variations in the rate of inflation affect the index of price dispersion,
but first-order variations in inflation cause only second-order variations in the index of price
dispersion. We show below that this is a case in which Assumption 4 holds, though a
decomposition of the form (2.20) exists.
   In the case that a decomposition of the from (2.20) exists, the subsystem consisting of
equations (2.24), (2.26) and (2.28) represents q structural equations per period to determine
the q “inessential” variables. Thus there is no scope for adjustment of any of these q variables


                                                  23
as a policy decision. We state Assumption 4 only for the case in which q > 0, since in the
case that q = 0, there are no inessential variables about which such an assumption needs to
be stated. We can also neglect the case of a decomposition of the form (2.20) with q = n, as
this would violate Assumption 2(a): the matrix (2.12) would be of at most rank n < m.
   The following consequence of Assumption 4(b) is useful in what follows.

Lemma 1 Suppose that a decomposition of the matrix pencil I¯ − µĀ of the form indicated
by (2.20) exists, and that Assumptions 2 and 4 are satisfied. Then there exist non-singular
matrices N2 , R2 , (of dimensions q × q) such that
                                                                 
                                                         0
                                                  I − µG      0
                          N20 (J2 − µB2 ) R20 =                                      (2.29)
                                                            0
                                                     0     H − µI

where G is of dimension k2 × k2 and H is of dimension (q − k2 ) × (q − k2 ) , all eigenvalues
of the matrix G have modulus less than 1, and all eigenvalues of the matrix H have modulus
less than β.

The proof of this result is given in Appendix A.
   In order to establish that the subsystem consisting of equations (2.24), (2.26) and (2.28)
                                                   ∗
does indeed determine the q endogenous variables {y2,t }, one additional regularity condition
is needed. Lemma 1 implies that the stable subspace of the system (2.24) is of the right
dimension for determinacy; but we also need an assumption that guarantees consistency
between the initial conditions (2.26) or (2.28) and the stable subspace of the system (2.24).

Assumption 5 Suppose that a decomposition of the matrix pencil I¯ − µĀ of the form indi-
cated by equations (2.20) and (2.21) exists. Then the (q × q) matrix
                                                      
                                             X10
                                    h           i     
                                                     0
                                        0 Iq−k2    N 2

is invertible.

Note that this condition will be satisfied by a generic matrices satisfying our other assump-
tions; it would follow from (though is weaker than) an assumption that J2 is of full rank.
                                                              ∗
Given these assumptions, we can now show that the variables {y2t } must be unaffected by
policy.

                                             24
Proposition 2 Let the linearized structural equations (2.8)-(2.10) satisfy Assumptions 2,
4, 5, and let the exogenous disturbances {ξ̃ t } satisfy ||ξ̃|| < ∞. Then if there exists a decom-
                                                                         ∗
position of the form (2.20) for some q > 0, there is a unique solution {y2t } to the subsystem
consisting of equations (2.24), (2.26) and (2.28) for all periods t ≥ t0 such that ||y2∗ || < ∞.
Hence in the case of any equilibrium {ỹt } consistent with (2.8)-(2.10) and such that ||ỹ|| < ∞,
                                               ∗
the evolution of the “inessential” variables {y2t } must be the same, independent of any policy
choices.

The proof is in Appendix A. It follows that target criteria need be formulated only for
                                             ∗
the evolution of the “essential” variables {y1t }, and that in addressing the issues both of
determinacy of equilibrium and of the optimality of the implied equilibrium, it suffices to
consider the implications for the essential variables of the target criteria together with the
structural equations (2.23), (2.25) and (2.27).



3     The Optimal Target Criterion
We now turn to the main topic of our paper, the construction of an optimal target criterion.
Our task is to show that there exists a criterion that, when conjoined with the linearized
structural relations (2.8)–(2.10), determines a unique bounded solution for the endogenous
variables {ỹt }, and that the equilibrium evolution that it determines represents a local linear
approximation to an optimal plan, by which we mean a plan that maximizes (1.9) for some
initial Lagrange multipliers Θt0 −1 that are determined by a self-consistent rule, or that max-
imizes (1.1) subject to some initial pre-commitments (1.5) determined by a self-consistent
rule. Our method is to construct a target criterion, involving only the endogenous variables
{ỹt }, that is fulfilled each period if and only if the linearized FOCs are satisfied, where the
FOCs in question are those associated with some self-consistent selection of the initial La-
grange multipliers or of the initial pre-commitments. Then the determinacy of equilibrium
under the target criterion will follow from Proposition 1, as will the fact that the equilibrium
so determined represents a local linear approximation to an equilibrium that is optimal from
a timeless perspective.



                                               25
3.1    Target Variables

Let us recall that the linearized FOCs (2.16)–(2.17) can be written in the form
                                  h¡              ¢       i
                             Et             ¯ −1 L 0 ϕ̃t+1 = τ t − τ ∗t ,
                                       Ā − Iβ                                               (3.1)

                                           ϕ̃2,t − Et−1 ϕ̃2,t = 0,                           (3.2)

where we now define a vector of (endogenous) “target variables”

                                             £¡                 ¢      ¤
                              τ t ≡ −Et           βR0 + SL + RL2 ỹt+1

and time-varying (exogenous) “target values” for them
                                                   h            i
                                          τ ∗t ≡ Et B (L) ξ̃ t+1 .

Recall also that (3.1) must hold for all t ≥ t0 , while (3.2) must hold for all t > t0 . We add in
addition the requirement that ϕ̃2,t0 be equal to some given vector of initial multipliers Θ̃t0 −1 ,
unless we add linearized initial pre-commitments of the form (2.7) to determine ϕ̃2,t0 .
   Here the target variables τ t summarize the ways in which variations in the endogenous
variables ỹt are relevant to verification of whether the FOCs are satisfied or not; hence policy
need only be concerned with the projected paths of these particular variables. Moreover, the
target variables only enter the FOCs through their difference with respect to the exogenously
varying target values τ ∗t ; hence policy need only be concerned with the extent to which the
target variables are projected to differ from their respective target values.
   In general, the target variables may be linear combinations of the entire vector of endoge-
nous variables ỹt . However, there is one case of practical interest in which they necessarily
involve only a subset of the variables that are simultaneously determined by the structural
model. Consider the case in which the policy objective is a quadratic function

                                              1
                              π(yt ; ξ t ) = − (qt − qt∗ )0 W (qt − qt∗ ),                   (3.3)
                                              2

where W is a symmetric, positive definite matrix, where qt ≡ w0 yt is a subset of the en-
dogenous variables and qt∗ ≡ q ∗ (ξ t ) is a vector of exogenous targets for the variables qt .
The matrix w0 is mτ × m, where mτ may be much smaller than m, in the case of a policy


                                                      26
institution with a fairly complex model of the economy but a relatively simple stabilization
objective (that may, for example, reflect its legislative mandate).
   Let us suppose furthermore that the targets are achievable in steady state; this means
that in the case that ξ t = ξ̄ at all times, there would exist a constant vector ȳ of values for
the endogenous variables satisfying (1.10)–(1.11) and

                                          w0 ȳ = q ∗ (ξ̄).                                 (3.4)

In this case, a simple characterization of the target variables and target gaps is possible.

Lemma 2 Suppose that the objective of policy is a quadratic function (3.3), that the targets
q ∗ (ξ t ) are achievable in steady state, in the sense that there exists a vector ȳ satisfying
conditions (1.10)–(1.11) and (3.4), and that Assumption 2(b) is satisfied. Then the target
variables τ t are all linear combinations of the mτ variables qt − q̄, where q̄ ≡ w0 ȳ are the
steady-state values of the variables qt . Moreover, the “target gaps” appearing on the right-
hand side of (3.1) are equal to

                               τ t − τ ∗t = wW (qt − qt∗ ) + O(²2 )                         (3.5)

to first order, which means that the linearized FOCs (3.1) can be expressed entirely in terms
of the mτ target variables {qt − qt∗ } and the Lagrange multipliers {ϕ̃t }.

   The proof is in Appendix A. In this special case, at least, the optimal target criterion can
be expressed purely as a restriction upon the evolution of the mτ target variables {qt − qt∗ }.
   Regardless of whether the special assumptions required for Lemma 2 are satisfied, the
linearized FOCs (3.1) can be expressed in a canonical form.

Lemma 3 Under Assumption 2 there necessarily exist non-singular matrices P (n × n) and
Q (m × m) such that
                                                                        
                                    M (µ) · · ·   0        0
                                   1                                    
                                     ..  ..      ..        ..           
                    ¡        ¢0       .      .    .         .           
                            ¯     
                      Ā − µI = Q                                       P                 (3.6)
                                                                         
                                    0    · · · Mp (µ)     0             
                                                                        
                                     0    ···     0    B20 − µJ20

                                                27
where p = m − n ≥ 1; for each i = 1, ..., p, Mi (µ)        is an (²i + 1) × ²i matrix pencil of the form
                                                                    
                                              µ 0            ··· 0
                                                                    
                                                                 .. 
                                             1 µ                  . 
                                                                    
                                                            ...     
                                Mi (µ) ≡  0 1                    0                                (3.7)
                                                                    
                                             ..             ...     
                                             .                   µ 
                                                                    
                                              0 0            ··· 1

for some ²i ≥ 1; and B20 − µJ20 is a regular pencil of dimension q × q, where
                                                         p
                                                         X
                                            q =n−              ²i .
                                                         i=1

The proof is in Appendix A.
   This result allows the system of FOCs (3.1) to be equivalently expressed in the form

                        £ ¡       ¢        ¤
                      Et Mi β −1 L ϕ̂1i,t+1 = τ̂ 1i,t ,                (i = 1, ..., p)             (3.8)

                     B20 Et ϕ̂2,t+1 − β −1 J20 ϕ̂2,t = τ̂ 2,t ,                                    (3.9)

where we partition the vectors
                                                                                       
                                 ϕ̂11,t                                           τ̂ 11,t
                                                                                       
                                ..                                             .. 
                                .                                              . 
                 P ϕ̃t ≡ ϕ̂t = 
                               
                                        ,
                                                    Q−1 (τ t − τ ∗t ) ≡ τ̂ t = 
                                                                                
                                                                                          
                                                                                          
                                ϕ̂1p,t                                         τ̂ 1p,t 
                                                                                       
                                  ϕ̂2,t                                            τ̂ 2,t

conformably with the partition of the matrix in (3.6). We thus reduce the FOCs to separate
blocks of equations relating subsets of the Lagrange multipliers to particular subsets of
the target variables. Furthermore, each of the blocks of equations other than (3.9) has a
particular simple form.


3.2    Essential vs. Inessential Target Variables

Note that (3.6) is a decomposition of the form (2.20). Assumption 4 then allows us to
decompose conditions (3.2) into separate subsystems as well. Recall from Assumption 4



                                                    28
             h           i         h               i
that both        U1 U2       and       X1 X2           are invertible matrices, and define
                                                                          
                         V1            h            i−1                 W1        h           i−1
                             ≡           U1 U2           ,                ≡       X1 X2         .   (3.10)
                         V2                                             W2

where the blocks V1 , V2 , W1 , and W2 are of dimensions

                               V1 ,              V2 ,                W1 ,              W2 ,
                              |{z}              |{z}                |{z}              |{z}
                         (k1 × ñ) ((ñ − k1 ) × ñ) (k2 × q) ((q − k2 ) × q)

where again, ñ ≡ n − q > 0, k1 + k2 = k. This additional notation allows us to decompose
the system of equations (3.2) in a way conformable with our decomposition of (3.1).

Lemma 4 Suppose that Assumptions 2 and 4 are satisfied. Then equations (3.2) hold if and
only if
                                              £                  ¤
                                            V2 ϕ̂1,t − Et−1 ϕ̂1,t = 0                                   (3.11)
                                              £                  ¤
                                            W2 ϕ̂2,t − Et−1 ϕ̂2,t = 0                                   (3.12)

for all t > t0 .

The proof is in Appendix A.
    In the case that our problem is to maximize the modified objective (1.9) defined by a
vector of initial multipliers Θt0 −1 , we can also partition the initial conditions implied by
the initial multipliers. The requirement that ϕ̃2,t0 = Θ̃t0 −1 holds if and only if both sets of
conditions
                                                   V2 ϕ̂1,t0 = Ξ1,t0 −1                                 (3.13)

                                                   W2 ϕ̂2,t0 = Ξ2,t0 −1                                 (3.14)

hold, where we define                                 
                                                Ξ1,t
                                                       = Ξt ≡ (T2−1 )0 Θ̃t .
                                                Ξ2,t
Here Ξt0 −1 is an alternative representation of the initial multipliers Θt0 −1 , and Ξ1,t0 −1 and
Ξ2,t0 −1 are respectively the first ñ − k1 elements and the last q − k2 elements of the vector
Ξt0 −1 . The multipliers Ξ1,t correspond to the ñ − k1 forward-looking constraints among the

                                                               29
                                                                                 ∗
structural equations governing the evolution of the m − q “essential” variables y1,t , while the
multipliers Ξ2,t correspond to the q − k2 forward-looking constraints among the structural
                                                        ∗
equations that determine the q “inessential” variables y2,t .
   Thus it is possible to decompose the complete system of first-order conditions (3.1)–
(3.2) into two independent subsystems, one involving only the variables ϕ̂1,t and the other
involving only the variables ϕ̂2,t . The first subsystem consists of the conditions (3.8) that
must hold for all t ≥ t0 ; conditions (3.11), that must hold for all t > t0 ; and condition
(3.13). The second subsystem consists of the conditions (3.9), that must hold for all t ≥ t0 ;
conditions (3.12), that must hold for all t > t0 ; and condition (3.14).
   In fact, the second subsystem of FOCs necessarily has a bounded solution (where again
the norm is the one defined in (2.11)), regardless of the evolution of the target variables.

Proposition 3 Suppose that Assumptions 2, 4 and 5 are satisfied. Then there necessarily
                © ª
exists a process ϕ̂2,t such that ||ϕ̂2 || < ∞ that satisfies conditions (3.9) for all t ≥ t0 ,
(3.12) for all t > t0 , and the initial condition (3.14), regardless of the evolution of the
target variables {τ̂ 2,t } (assuming only that ||τ̂ 2 || < ∞, where the norms for both multipliers
and target variables are defined as in (2.11)). Hence necessary and sufficient conditions for
the existence of a process {ϕ̃t } such that ||ϕ̃|| < ∞ that satisfies conditions (3.1) for all
t ≥ t0 and (3.2) for all t > t0 , consistent with given initial multipliers Θ̃t0 −1 , are that the
                                                              © ª
target variables {τ̂ 1,t } be such that there exists a process ϕ̂1,t with ||ϕ̂1 || < ∞ that satisfies
conditions (3.8) for all t ≥ t0 , (3.11) for all t > t0 , and the initial condition (3.13).

The proof is in Appendix A. Accordingly, our problem reduces to the design of a target
criterion involving the variables {τ̂ 1,t } which is necessary and sufficient for the existence of
a bounded process {ϕ̂1,t } with the properties listed in the proposition.


3.3    Implications of the Target Criterion in the Case of Unidimen-
       sional Policy

We now specialize the problem by restricting our attention to the case in which there is a
single dimension of policy variation each period, so that p = m − n = 1. (Note that this case


                                                 30
covers conventional analyses of monetary stabilization policy, where the single dimension of
policy choice corresponds to a target for a short-term nominal interest rate or for the money
supply each period.) In this case, there is only a single block of equations of the form (3.8),
and we shall drop the i subscript for the remainder of this section.
   We first state the restrictions on the process {τ̂ 1,t } that are required in order for there to
exist a bounded process {ϕ̂1,t } consistent with (3.8). (These conditions are in turn necessary,
though not sufficient, for satisfaction of the complete set of linearized FOCs.) Let us first
define the ñ × (ñ + 1) matrix polynomial
                                                                                
                                        1       0             ···            0
                                                                      
                                                                      
                                    (−µ)       1              0··· 0 
                          Γ (µ) ≡     ..                    ..
                                                                       
                                                                . . .. 
                                        .                       . . . 
                                                                      
                                     (−µ)ñ−1 · · ·        (−µ) 1 0

and the ñ + 1-dimensional vector polynomial
                                          h                              i
                               δ (µ)0 ≡       1 (−µ) · · ·      (−µ)ñ       .

We can then define a moving average of the target variables
                                                ¡      ¢0
                                          zt ≡ δ β −1 L τ̂ 1,t .                               (3.15)

We can then establish the following useful result.

                                   © ª
Lemma 5 Two processes {τ̂ 1,t } and ϕ̂1,t specified for all t ≥ t0 satisfy (3.8) for all t ≥ t0
if and only if they satisfy
                                               £ ¡    ¢       ¤
                                    ϕ̂1,t = βEt Γ βL−1 τ̂ 1,t                                  (3.16)

and
                                               Et zt+ñ = 0                                    (3.17)

for all t ≥ t0 , where the implied process {zt } is defined by (3.15).

   The proof is in Appendix A. This result implies that a bounded process for the target
variables {τ̂ 1,t } is consistent with condition (3.8) if and only if the evolution of {zt } satisfies
(3.17); for given any bounded process satisfying (3.17), (3.16) defines a bounded process

                                                   31
{ϕ̂1,t } which will satisfy (3.8). It remains then only to ask what additional restrictions are
required in order for the implied process {ϕ̂1,t } to satisfy conditions (3.11) and (3.13) as well.
   Condition (3.17) is thus an example of a target criterion that is necessary for policy to be
optimal, but that is not in general sufficient for optimality; it is not in general a sufficiently
restrictive condition to uniquely determine a forward path for the economy, either. Thus
the target criterion that we seek must be stronger (except in special cases) than (3.17), but
must imply (3.17). As it happens, the desired criterion can also be stated as a restriction
upon the evolution of the scalar target variable zt , albeit a stronger condition than (3.17).
In order to state this criterion, it is useful to define a vector of revisions at date t to the
forecast path of the target variable,
                                                                         
                                            (−β) [zt − Et−1 zt ]
                                                                         
                                                                         
                                       (−β)2 [Et zt+1 − Et−1 zt+1 ]      
                           wt ≡ 
                                                    ..
                                                                          .
                                                                                           (3.18)
                                                     .                   
                                                                         
                                    (−β)ñ [Et zt+ñ−1 − Et−1 zt+ñ−1 ]

It is also useful to define the matrix of current and past forecast revisions

                     £                                                          ¤
                 Ωt ≡ (−β)−1 w̄t (−β)−2 w̄t−1 . . . (−β)−(ñ−k1 ) w̄t−(ñ−k1 −1) ,          (3.19)

where w̄t is the vector consisting of the first k1 rows of wt . (Note that Ωt is a null matrix
unless 0 < k1 < ñ; if k1 = 0, Ωt has no rows, while if k1 = ñ, it has no columns.)
   The optimal target criterion can be expressed more simply if we assume one further
regularity condition. Let the matrix V2 defined in (3.10) be partitioned as
                                               h             i
                                        V2 ≡       V21 V22       ,

where V21 is of dimension (ñ − k1 ) × k1 and V22 is of dimension (ñ − k1 ) × (ñ − k1 ) . We can
now state our final regularity condition.

Assumption 6 The submatrix V22 is non-singular (det V22 6= 0).

Note that for any k1 < ñ, this assumption holds for a generic non-singular matrix V . The
usefulness of this assumption is that it implies that any ñ-dimensional vector v such that

                                                   32
V2 v = 0 (i.e., vector that is a linear combination of the columns of U1 ) can be reconstructed
from its first k1 elements. That is, partitioning
                                      
                                    v1    } first k1 elements
                             v≡       
                                    v2    } last ñ − k1 elements,
one must have                                                
                                                        Ik1
                                               v=             v1 ,
                                                        Φ
where
                                                Φ ≡ −V22−1 V21 .

       We now state the optimal target criterion: this is the requirement that at each date
t ≥ t0 , the projected evolution of the process {zt } must be such that

                                        Et zt+k1 = (−β)−k1 tr[ΦΩt ].                                      (3.20)

In evaluating this criterion in any period t, the references to forecasts at date t−1 and earlier
are understood to refer to policy authority’s historical forecasts, whether or not they were
made on the basis of an expectation regarding policy in period t and later that corresponds
to current policy intentions. (In particular, forecasts dated t0 − 1 may not be consistent with
the policy regime that is adopted beginning in period t0 , but the target criterion refers to
these historical forecasts nonetheless.) The set of paths for the target variables {τ̂ 1,t } from
period t0 onward that are consistent with the target criterion depends on a vector of initial
conditions et0 −1 , which includes the historical forecast revisions w̄t0 −j for 1 ≤ j ≤ ñ − k1 − 1;
the historical forecasts corresponding to the first k1 rows of βEt0 −1 [Γ(βL−1 )τ̂ 1,t0 ]; and the
historical path of the target variables τ̂ 1,t0 −j for 1 ≤ j ≤ ñ − k1 .18
       Note that if k1 < ñ, satisfaction of (3.20) for all t ≥ t0 implies that

                                Et zt+ñ = Et [Et+ñ−k1 zt+ñ ]

                                          = (−β)−k1 tr[Φ Et Ωt+ñ−k1 ] = 0
  18
       The vectors w̄t0 −j are columns of Ωt0 (and of Ωt for the next few periods as well); the forecasts
βEt0 −1 [Γ(βL−1 )τ̂ 1,t0 ] are needed to define the forecast revisions w̄t0 , that also constitute a column of Ωt0
and of subsequent Ωt ; and the lagged variables τ̂ 1,t0 −j are needed to determine the value of zt0 +k1 , as well
as the value of zt+k1 for the next few periods, in addition to the evolution of the target variables from t0
onward.

                                                        33
for any t ≥ t0 , using the fact that Et w̄t+j = 0 for any t ≥ t0 and any j ≥ 1. But if k1 = ñ, Ωt
is a null matrix, and (3.20) also implies that Et zt+ñ = 0 in this case as well. Hence the target
criterion (3.20) implies condition (3.17), although (except when k1 = ñ) it is not implied by
it. In fact, one can show that this stronger target criterion is also a necessary condition for
optimality, at least in the case of initial pre-commitments of a particular sort.19

Proposition 4 Given Assumption 6 and any initial conditions et0 −1 , there exists a vector of
initial Lagrange multipliers Ξ1,t0 −1 , such that any processes {τ̂ 1,t } and {ϕ̂1,t } for t ≥ t0 that
satisfy conditions (3.8) for all t ≥ t0 , (3.11) for all t > t0 , and the initial condition (3.13),
must also satisfy the target criterion (3.20) for all t ≥ t0 .

       The proof of this proposition is also given in Appendix A. To be more specific, the vector
of initial Lagrange multipliers with the asserted property is

                                Ξ1,t0 −1 ≡ V22 χt0 −1 + V2 βEt0 −1 [Γ(βL−1 )τ̂ 1,t0 ],                   (3.21)

where χt−1 is the vector whose jth element is equal to
                                                                    ñ−k1 −j
                                                                     X
                        χjt−1   ≡ (−β)  k1 +j
                                                Et−1 zt+k1 +j−1 −              (−β)−i φ0j+i w̄t−i ,      (3.22)
                                                                      i=1

using the notation φ0j for the jth row of the matrix Φ. Note that each element of Ξ1,t0 −1
is a linear function of the vector of initial conditions et0 −1 defined above. Proposition 4
is established by showing that for this specification of the initial multipliers, the Lagrange
multipliers defined by (3.16) satisfy conditions (3.11) and (3.13) if and only if the evolution
of the target variables is consistent with (3.20) for each t ≥ t0 .
       The rule (3.21) for selection of initial Lagrange multipliers as a function of the initial
condition et0 −1 is an example of a self-consistent rule, because of the following result.

Lemma 6 Suppose that Assumption 6 holds and let the bounded processes {τ̂ 1,t } and {ϕ̂1,t }
for t ≥ t0 satisfy conditions (3.8) for all t ≥ t0 , (3.11) for all t > t0 , and the initial condition
  19
       In the case of more general specifications of the initial pre-commitments and/or the initial Lagrange
multipliers Ξ1,t0 −1 , we can also show that it is necessary that (3.20) be satisfied for all t after some finite
date; but this extension of Proposition 4 is not necessary for the subsequent discussion, and hence is omitted.


                                                          34
(3.13), where the initial Lagrange multipliers are given by (3.21). Then in each period t ≥ t0 ,

                                          V2 ϕ̂1,t = Ξ1,t−1 ,                                 (3.23)

where
                            Ξ1,t−1 ≡ V22 χt−1 + V2 βEt−1 [Γ(βL−1 )τ̂ 1,t ].                   (3.24)

The proof is in Appendix A. Since conditions (3.13) and (3.21) are just specializations
to period t0 of the more general relations (3.23) and (3.24), it follows that the proposed
rule for assigning the initial Lagrange multipliers is self-consistent. Because of Proposition
2(c), this assignment of the initial Lagrange multipliers as a function of the initial condition
corresponds to a rule for assigning initial pre-commitments ḡt0 as a function of the initial
condition (and the economy’s state in period t0 ), that will also represent a self-consistent
rule, in the sense defined earlier.
   Proposition 4 implies that fulfillment of the target criterion is a necessary condition for
fulfillment of the FOCs, and hence a necessary condition for optimality, in the case of a
problem involving initial pre-commitments of the kind just discussed. But consistency of the
paths of the target variables with the target criterion (3.20) is also sufficient for satisfaction
of the FOCs, as established by the following result.

Proposition 5 Suppose that Assumption 6 holds and that the evolution of the target vari-
ables {τ̂ 1,t } for t ≥ t0 satisfies the target criterion (3.20) for all t ≥ t0 , given the initial
conditions et0 −1 . Then there exists a Lagrange multiplier process {ϕ̂1,t } for t ≥ t0 that sat-
isfies conditions (3.8) for all t ≥ t0 , (3.11) for all t > t0 , and the initial condition (3.13),
where the vector Ξ1,t0 −1 is defined by (3.21).

The proof of this result as well is in Appendix A. The Lagrange multiplier process referred
to in the proposition is given by (3.16). Since (3.20) implies (3.17), as noted above, it follows
directly from Lemma 5 that these multipliers satisfy (3.8) for all t ≥ t0 . It then remains only
to show that (3.11) and (3.13) are satisfied as well, by reversing the steps used to derive
(3.20) from these conditions in the proof of Proposition 4.
   Combining Proposition 5 with Proposition 3, one sees that in the case of any bounded
process {τ̂ t } consistent with the target criterion (3.20) for all t ≥ t0 , there necessarily exists

                                                  35
a bounded multiplier process {ϕ̂t } for t ≥ t0 such that satisfies conditions (3.1) for all t ≥ t0
and (3.2) for all t > t0 , and that is consistent with given initial multipliers Θ̃t0 −1 , as long
as the vector Θ̃t0 −1 is consistent with (3.21). Moreover, since by Proposition 1(a), there is
a unique bounded solution to these equations consistent with the given initial multipliers,
there must be a unique bounded process {τ̂ t } consistent with the target criterion (3.20) for
all t ≥ t0 . (If there were multiple paths {τ̂ t } consistent with the target criterion, each of
these would have to correspond to a different solution to the FOCs consistent with the same
initial multipliers (3.21).20 But this would contradict Proposition 1(a).)
       Hence the target criterion (3.20) determines a unique bounded solution for the equilibrium
evolution of the endogenous variables, and by Proposition 1(b), the evolution determined
by this criterion represents a local linear approximation to the optimal evolution, under the
modified problem defined by initial Lagrange multipliers (3.21). Finally, this way of choosing
the initial multipliers as a function of the initial conditions et0 −1 is self-consistent, by Lemma
6. We thus obtain our main conclusion.

Proposition 6 Suppose that Assumptions 1–6 are satisfied.
       (a) Then the requirements that the evolution of the endogenous variables {ỹt } for t ≥ t0
be consistent with the target criterion (3.20) for all t ≥ t0 , and satisfy the bound ||ỹ|| < ∞,
where the norm is defined as in (2.11), determine a unique solution for the path of these
variables, given any initial conditions et0 −1 .
       (b) Moreover, the unique solution determined by these criteria represents a local linear
approximation to the evolution {yt } that maximizes the modified objective function (1.9), in
the case of initial conditions close enough to consistency with the steady state and disturbance
processes under which ξ t remains always close enough to ξ̄, if the initial Lagrange multipliers
Θt0 −1 are given by
                                             Θt0 −1 = Θ̄ + T20 Ξt0 −1 ,

where the multipliers Ξ1,t0 −1 are given by (3.21), and the multipliers Ξ2,t0 −1 (if this is not a
null vector) may be chosen arbitrarily.
  20
       Note that the initial multipliers Ξ2,t0 −1 can be chosen arbitrarily, and so could be chosen to be the same
in the case of each of these solutions.



                                                        36
    (c) The rule (3.21) for the selection of the initial multipliers is self-consistent, in the
sense that (3.24) holds for all t ≥ t0 in the linear approximation to the solution to the above
problem. Hence the equilibrium determined by the target criterion (3.20) is optimal from a
timeless perspective.



4     Application: Optimal Policy in an Exact New Key-
      nesian Model
To illustrate how the proposed optimal target criterion can be derived in a nonlinear model
in which the objective of policy is assumed to be the maximization of household utility, we
consider the exact New Keynesian model presented in Benigno and Woodford (2005). While
this very stylized model abstracts from a number of the frictions often included in larger-
scale models used for empirical analysis or for practical policy recommendations, its relative
simplicity allows us to illustrate clearly how to derive the optimal target criterion in a fully
analytical fashion, and provides intuition about the proposed target criterion.


4.1    Model

We now provide a very succinct description of the model, leaving the details to Appendix
E. In this model, each household seeks to maximize its lifetime utility which depends in a
time-separable fashion on consumption of an aggregate of all goods and (negatively) on the
amount of labor supplied. Each differentiated good is supplied by a single monopolistically
competitive producer who uses labor as the only variable input. As Benigno and Woodford
(2005) show, the utility of the representative household, which is also the policymaker’s
welfare objective function, can be expressed in the form (1.1) where the period t utility can
be written as
                        π (yt , ξ t ) = U (Yt , ∆t ; ξ t ) ≡ u (Yt ; ξ t ) − v (Yt ; ξ t ) ∆t ,

where Yt is aggregate production of the composite good, ∆t is a measure of price dispersion,
and ξ t is a vector of exogenous variables (including shocks to technology, preferences, and
fiscal policy). Here both the utility from consumption and the disutility of labor supply have

                                                         37
been expressed as functions of the total quantity produced; the disutility of labor supply also
depends on price dispersion, as this affects the composition of output and hence the labor
required to produce a given amount of the composite good.
   The producers are wage takers on the labor market and choose their prices to maximize
the present discounted value of future profits. As in Calvo’s (1983) model of staggered
pricing, we assume that producers fix the prices of their goods for a random interval of
time, with a constant fraction α ∈ [0, 1) of prices remaining unchanged in any given period.
Aggregating the producers’ optimal pricing decisions yields a short-run aggregate supply
relation between inflation and output of the form
                                                       µ        ¶ 1+ωθ
                                                                   θ−1
                                      1 − αΠθ−1
                                            t              Ht
                                                =                                          (4.1)
                                        1−α                Kt
where Πt ≡ Pt /Pt−1 is the gross inflation rate and the variables Ht and Kt are given by the
recursive expressions
                                                                £            ¤
                    Ht = (1 − ς t ) · uY (Yt , ξ t ) · Yt + αβEt Πθ−1
                                                                    t+1 Ht+1               (4.2)
                          θµw                                 h              i
                            t                                    θ(1+ω)
                    Kt =        · vY (Yt , ξ t ) · Yt + αβEt Πt+1 Kt+1 .                   (4.3)
                         θ−1
Here ς t ∈ [0, 1) is an exogenous sales tax rate; µw
                                                   t ≥ 1 is an exogenous wage markup factor;

θ > 1 is the elasticity of substitution across individual goods; and ω ≥ 0 is the elasticity of
the function vY with respect to increases in output. The law of motion of the measure of
price dispersion is further given by
                                                           µ                ¶ θ(1+ω)
                                      θ(1+ω)                    1 − αΠθ−1
                                                                      t
                                                                                θ−1

                        ∆t =   α∆t−1 Πt        + (1 − α)                               .   (4.4)
                                                                  1−α
   While the optimal intertemporal allocation of households’ expenditures determines period-
t output as a function of expectations of future output, inflation and the nominal interest
rate, this doesn’t constitute a constraint on the policy problem, as the central bank can
always choose a nominal interest rate that satisfies this equation. As a result, the only rel-
evant constraints facing the policymaker are given by (4.1)–(4.4), describing the necessary
connections between the evolution of aggregate real activity, inflation, and price disper-
sion. Using (4.1) to substitute for the variable Πt , we can express the resulting restrictions
by a system of the form (1.2)–(1.3), where the vector of endogenous variables is given by

                                                  38
yt ≡ [Yt , ∆t , Ht , Kt ]0 , F is a single function, and g is a pair of functions. We thus have
m = 4 endogenous variables, n = 3 equilibrium restrictions per period, and k = 1 of these
restrictions involves only contemporaneous or past variables. It is also useful to note that in
this model, the functions g take the special form

                         g(yt , ξ t ; yt+1 ) = ǧ(Yt , ξ t ) − Zt + αβΦ(Zt+1 ),

where Zt ≡ [Ht , Kt ]0 is a subset of the endogenous variables, and ǧ and Φ are vectors of
nonlinear functions, each with two elements.


4.2    Characterizing the Optimal Target Criterion

By computing the nonlinear FOCs that characterize optimal policy, we show in Appendix
E that an optimal steady state exists, in which the price level remains stable so that Πt =
                                          ¯ = 1). We then log-linearize the nonlinear
Π̄ = 1 and price dispersion is zero (∆t = ∆
structural equations and FOCs around these steady-state values of the endogenous variables,
                                                                   ¯ This allows us to
and compute the canonical decomposition of the matrix pencil Ā − µI.
compute our target criterion.
   It is easy to verify that the pencil Ā − µI¯ satisfies Assumption 2. We show in Appendix
E that the minimal degree associated with Ā − µI¯ is ñ = 2. It then follows from Lemma 3
that there exist nonsingular matrices P and Q of dimensions 3 × 3 and 4 × 4 respectively
that satisfy                                                           
                           ¡           ¢0     M (µ)    0
                               Ā − µI¯ = Q                 P
                                                     0     0
                                               0    B2 − µJ2
where M (µ) is the (ñ + 1) × ñ matrix pencil
                                                            
                                                  µ 0
                                                     
                                                     
                                        M (µ) =  1 µ 
                                                     
                                                  0 1

and B20 − µJ20 is a matrix pencil of dimension 1 × 1, with B2 = α < 1, and J20 = 1.
   Given the dimension of J2 , B2 , and the fact that |B2 | < 1, it follows that q = k2 = 1,
so that the model has one inessential variable. Interestingly, while the model involves one

                                                  39
predetermined endogenous variable, namely the price dispersion measure ∆t , this variable
turns out to be inessential in the model’s linearized dynamics. Hence, while k = 1 in the
model, the number of predetermined variables when the system of equation is written only
in terms of “essential” variables is k1 = 0.
       Since k1 = 0, the general optimal target criterion (3.20) reduces to

                                                        zt = 0.

Given the definition of the variable zt in (3.15), the optimal target criterion is backward-
looking
                                                h                               i
                                       0=                  −1          −2   2       τ̂ 1t ,
                                                    1 −β        L β         L

that is, a moving average of the current and past essential target gaps
                                                h               i
                                      τ̂ 1t =       Im−q 0          Q−1 (τ t − τ ∗t ) .

       To obtain the target gaps τ t − τ ∗t , we evaluate the second derivatives of F () , g () and
the objective function π () at the steady state. As shown in Appendix E, the optimal target
criterion takes the form
                                      (1 − αL)[π t + φ (xt − xt−1 )] = 0,                                 (4.5)

where xt ≡ log(Yt /Yt∗ ) is an “output gap” relative to a target level of output; Yt∗ is a function
of the exogenous disturbances implicitly defined by the equation

                                      UY (Yt∗ , 1; ξ t ) + Θ̄0 ǧY (Yt∗ , ξ t ) = 0,                      (4.6)

where Θ̄ is the steady-state vector of Lagrange multipliers associated with the forward-
looking constraints. In the case that the flexible-price steady-state level of output is effi-
cient,21 then the zero-inflation steady state level of output Ȳ is efficient, and Θ̄ = 0. In this
special case, Yt∗ is simply the utility-maximizing level of output given technology, preferences
and government purchases at any point in time (defined by the FOC UY (Yt∗ , 1; ξ t ) = 0). It
also corresponds in this case to the flexible-price equilibrium level of output, if the distortion
  21
       This would in general require a negative steady-state sales tax ς, to offset the distortion due to market
power on the part of the monopolistically competitive producers. See Woodford (2003, chap. 6) for further
discussion of this case.

                                                            40
factors ς t and µw                                                               ∗
                 t are set equal to their steady-state values. More generally, Yt is not quite

the same as either the efficient level of output or the flexible-price equilibrium level of output,
but is closely related to both of them.
       Condition (4.5) requires that eventually

                                             π t + φ(xt − xt−1 ) = 0                                       (4.7)

each period.22 Thus optimal policy can be characterized as a form of “flexible inflation
targeting,” in which deviations of the inflation rate from its optimal long-run value (zero)
must at all times be in proportion to projected changes in the output gap. In Appendix E,
we characterize the optimal value of the coefficient of proportionality φ in terms of model
parameters. Unless both the degree of inefficiency of steady-state output and the share of
output consumed by the government are large, φ will be a positive coefficient. In this case,
the target criterion is similar to that implied by the kind of linear-quadratic policy problem
analyzed by authors such as Clarida et al. (1999). But here, both the definition of the
“output gap” and the weight φ to be put on changes in the output gap are derived from the
micro-foundations of the model, rather than an ad hoc quadratic objective function for the
central bank; and the optimal target criterion involves additional transitory dynamics.



5        Concluding Remarks
We have considered a general class of nonlinear rational-expectations models in which poli-
cymakers seek to maximize an objective function. We have proposed a procedure to derive
a target criterion that is: (i) consistent with the model’s structural equations, (ii) strong
enough to imply a unique equilibrium, and (iii) optimal, in the sense that a commitment to
adjust the policy instrument at all dates so as to satisfy the target criterion maximizes the
  22                                                  ˆ t −1 = O(²2 ), as assumed in Benigno and Woodford (2005),
       In the case of small initial price dispersion, ∆  0


it is possible to choose the initial lagged Lagrange multipliers in a self-consistent way and obtain a modified
policy problem under which optimal policy will satisfy (4.7) from period t0 onward. However, that method
cannot be extended to deal with non-trivial levels of initial price dispersion (of order O(²)) without requiring
transitory departures of the left-hand side of (4.7) from its long-run value for most initial conditions, as
implied by the target criterion derived here.


                                                        41
objective function.
   Some general remarks are possible on the form of the optimal target criterion (3.20).
We have established quite generally that there is a single composite target variable zt such
that the target criterion can be expressed purely in terms of projections for the evolution of
this variable. (This depends, however, on our assumption that policy can vary equilibrium
outcomes along only one dimension per period.)
   In general, the target criterion (3.20) has both backward-looking and forward-looking
elements. The degree to which it has one character or the other depends on the degree to
which the structural equations of the model are backward- or forward-looking. When the
model’s constraints are purely forward-looking — or more precisely, when the reduced system
of equations written in terms of the “essential” state variables contains no backward-looking
structural relations (2.25), so that k1 = 0 — the criterion (3.20) reduces to

                                             zt = 0.

In this case the optimal target criterion is necessarily purely backward-looking, i.e., it is a
linear relation between current and past values of the target variables τ̂ 1,t . This is the case
illustrated by the example in section 4.
   If, instead (as is more generally the case), lagged variables enter the structural equations,
the optimal target criterion involves forecasts as well, for a finite number of periods into the
future. In the opposite polar case in which the model’s constraints are purely backward-
looking (i.e., they do not involve expectations) — or at least this is true when the model is
written in terms of the essential variables only, so that k1 = ñ — then the criterion (3.20)
takes the form
                                           Et zt+ñ = 0.

Since zt+ñ involves elements of τ̂ 1,t+j for 0 ≤ j ≤ ñ, in this case the optimal target criterion
is purely forward-looking, in the sense that it involves only the projected paths of the target
variables τ̂ 1,t in current and future periods. In the intermediate cases, the target criterion
involves both forecasts of target variables at least one period in the future and at least one
lag of the target variables (as well as, in general, forecasts from one or more prior periods).
The number of periods that the criterion requires one to look into the future is greater the

                                                42
larger is k1 (and in this sense, the more backward-looking the model dynamics), and the
number of periods from which past values remain relevant to the target criterion is greater
the greater is ñ − k1 (and in this sense, the more forward-looking the model dynamics).
   While we have noted that the target criterion can quite generally be stated in terms
of projections for a single composite target variable zt , this variable will generally involve
                                                                           ∗
the paths (with differing lags) of all of the “essential” state variables y1,t . However, there
is a special case in which the target criterion need only involve the projections for a small
number of economically meaningful variables, regardless of the complexity of the structural
model. This is the case in which the objective function (1.1) is purely quadratic, as assumed
in the hypotheses of Lemma 2. While this is unlikely to be true in a microfounded model in
which the objective of policy is taken to be the maximization of household expected utility,
central banks are often interested in policies that are optimal from the point of view of some
quadratic loss function involving a small number of targets, though a very complex model
of the economy may be used to evaluate how well alternative policies achieve this objective.
In the case that Lemma 2 applies, the composite target variable zt is a linear function of the
paths of the mτ target variables qt − qt∗ that appear in the quadratic objective (3.3).
   The procedure to derive an optimal target criterion has been illustrated in the context
of a simple nonlinear model, but it can be readily derived in larger empirical models using
existing numerical techniques. The optimal target criterion has been derived here in the
context of models in which policy can vary equilibrium outcomes along only one dimension
per period (p = 1). The setup proposed can however accommodate cases in which policy can
vary the equilibrium along multiple dimensions. In such cases, there would be p > 1 target
criteria to satisfy each period. We leave the detailed analysis of this general case for future
work.




                                              43
A       Proof of Lemmas and Propositions
A.1     Proof of Proposition 1
Here we show that there exists a unique bounded solution to the system of equations con-
sisting of the linearized structural equations (2.8)–(2.10) together with the linearized FOCs
(2.16)–(2.17). If we adjoin to these equations the identities

                                                ỹt = ỹt ,                                 (A.1)
                                          Et ϕ̃t+1 = Et ϕ̃t+1 ,                             (A.2)

then the system consisting of (2.8), (2.16), and (A.1)–(A.2) can be rewritten in matrix form
as
                                  M̄ Et dt+1 = N̄ dt − N̄s s̄t ,                       (A.3)
where dt is the 2(m + n)-dimensional vector
                                                          
                                                    ϕ̃t
                                                 ỹt−1 
                                           dt ≡           
                                                 Et ϕ̃t+1  ,
                                                    ỹt ,

s̄t is a vector of exogenous disturbances that includes the elements of both ξ̃ t and ξ̃ t−1 , and
                           ·            ¸            ·                   ¸
                             M̄11 M̄12                 −β −1 M̄12
                                                               0
                                                                    0
                      M̄ ≡                ,     N̄ ≡                                        (A.4)
                             Im+n 0                         0     Im+n

where                         ·           ¸                             ·           ¸
                                   0 Ā             0                       0 −I¯
                     M̄11 ≡                   =   M̄11 ,   and M̄12 ≡                   .
                                  Ā0 S                                     0 βR0
                                                              0
Here we use the fact that S is symmetric to obtain M̄11 = M̄11  .
   In addition to conditions (A.3), the process {dt } must satisfy (2.9) and (2.17), and thus

                                  Fd [dt − Et−1 dt ] = Fs [s̄t − Et−1 s̄t ]                 (A.5)

for all t > t0 , where Fd is the (m + n) × 2(m + n) matrix
                                                        
                                           S2 0 0 0
                                    Fd ≡  0 0 0 I¯1  ,
                                            0 Im 0 0

using the notation
                                              S2 ≡ [0 In−k ]
for the (n − k) × n matrix that selects the last n − k elements of any n-vector. (The first
n − k rows correspond to conditions (2.17), the next k rows correspond to conditions (2.9),
and the final m rows state that the elements of ỹt−1 cannot be affected by surprises in period
t.)

                                                       44
   In period t0 , the process must satisfy (2.10) and hence

                                            Fd dt0 = ft0 ,                                     (A.6)

where ft0 is a vector of m + n initial conditions
                                                                   
                                                 Θ̃t0 −1
                             ft0 ≡  Ā1 ỹt0 −1 + D̄ξ̃ t0 − β F̄t0  ,
                                                 ỹt0 −1

all of which are either predetermined or exogenous.
    The following lemmas establish useful properties of the matrix pencil M̄ − µN̄ .

Lemma 7 Given Assumptions 2(b) and 3, the matrix pencil M̄ − µN̄ is regular; that is, its
determinant is non-zero for at least some complex µ.

Proof. The determinant of M̄ − µN̄ can be expressed as follows:
                              ·                            ¸
           ¡        ¢           M̄11 + µβ −1 M̄12
                                                0
                                                    M̄12
        det M̄ − µN̄ = det
                                        I          −µI
                                          £¡                    ¢                ¤
                       = det (−µI) · det M̄11 + µβ −1 M̄12    0
                                                                  − M̄12 (−µI)−1
                                           £                               ¤
                       = µ (−1)n+m · det M̄11 + µβ −1 M̄12   0
                                                                + µ−1 M̄12
                                           ·                                      ¸
                                 n+m               0               Ā − µ−1 I¯
                       = µ (−1)      · det                                          .          (A.7)
                                             Ā0 − µβ −1 I¯0 S + µ−1 βR0 + µR

The matrix pencil M̄ − µN̄ is regular provided that its determinant is non-zero for at least
some complex µ.
    Suppose the determinant is instead zero for all µ. This means that there must exist
finite-order vector polynomials (ϕ (µ) , y (µ)) such that
                      ·                                   ¸·       ¸
                              0             Ā − µ−1 I¯      ϕ (µ)
                                                                     =0               (A.8)
                        Ā0 − µβ −1 I¯0 S + µ−1 βR0 + µR     y (µ)

for all µ 6= 0, and (ϕ (µ) , y (µ)) are not both equal to zero for P all µ. In addition, the solution
cannot involve y (µ) = 0. For £ if0 there−1exists
                                              ¤   a function ϕ (µ) ≡ ki=0 ϕi µi satisfying (A.8) with
y (µ) = 0, one must have Ā − µβ I¯0 ϕ (µ) = 0. But this would imply that the function
           P
ϕ (µ) ≡ ki=0 ϕk−i µi must P     satisfy (2.13), violating Assumption 2(b). Hence we must have
y (µ) 6= 0. Writing y (µ) ≡ ∞              i
                                   i=0 yi µ (where all but a finite number of the yi are zero), the
first line of (A.8) implies that the sequence {yi } satisfies the hypotheses of Assumption 3.
The second line implies that
                                 ¡      ¢0 £                   ¤
                              y µ−1 β S + µ−1 βR0 + µR y (µ) = 0
                                                  P
for all µ. Writing this expression in the form jk+1               j
                                                     =−(k+1) γ j µ , where k is the order of y (µ) ,
it follows that we must have γ j = 0 for all j. In particular, we must have γ 0 = 0.¡ But γ 0 is¢
just the left-hand side of (2.19), so this violates Assumption 3. It follows that det M̄ − µN̄
cannot be zero for all µ.

                                                  45
   It is then possible to factor the polynomial det[λM̄ − ρN̄ ] as
                                       2(n+m)
                                         Y
                                               (αi λ − β i ρ),                               (A.9)
                                         i=1

where for any i, the complex numbers αi and β i are not both equal to zero. Let s be the
number of factors for which αi 6= 0 and |β i /αi | < 1. There must then be 2m + 2n − s factors
for which β i 6= 0 and |αi /β i | ≤ 1.
    This implies that the matrices M̄ and N̄ can be decomposed as stated in the following
lemma.

Lemma 8 Given Assumptions 2(b) and 3, there must exist non-singular 2(m+n)×2(m+n)
real matrices Ū , V̄ such that
                                  ·      ¸              · 0          ¸
                                    Is 0                 Λ      0
                       Ū M̄ V̄ =          , Ū N̄ V̄ =                .     (A.10)
                                    0 Ω                   0 I2n+2m−s

Here Ω is a (2m + 2n − s) × (2m + 2n − s) real matrix for which all eigenvalues have modulus
less than or equal to 1 while Λ is an s × s real matrix for which all eigenvalues have modulus
less than 1.

Proof. Under Assumptions 2(b) and 3, Lemma 7 implies that M̄ −µN̄ is a real regular matrix
pencil of dimensions (2m + 2n)×(2m + 2n) . It follows from Theorem 3 of Gantmacher (1959,
Chap. 12), or its version for a real canonical form proved in Appendix D, that there exist
real invertible matrices Ũ , V̄ of dimensions (2m + 2n) × (2m + 2n) such that
                                      ·      ¸                ·      ¸
                                        I 0                     H̃ 0
                          Ũ M̄ V̄ =           ,   Ũ N̄ V̄ =                       (A.11)
                                        0 G̃                    0 I

where G̃ is an invertible matrix of the real Jordan form and H̃ is a real nilpotent matrix of
the Jordan form.                        £           ¤
    Let us factor the polynomial det λM̄ − ρN̄ as in (A.9) and let ν (0 ≤ ν ≤ 2m + 2n) be
the number of factors (αi λ − β i ρ) for which the complex numbers β i = 0, while the numbers
αi are necessarily nonzero. (Note that since the eigenvalues of M̄ − µN̄ are the quantities
αi /β i , these ν factors correspond to the ν “infinite” eigenvalues of M̄ −µN̄ .) The existence of
a decomposition
    £             ¤ of the form (A.11) implies that the factors of the characteristic polynomial
det λM̄ − ρN̄ in (A.9) are the same as those of
                                      h         i      h         i
                                  det λI − ρH̃ · det λG̃ − ρI .
                          h        i
Since H̃ is nilpotent, det λI − ρH̃ must correspond to the ν factors for which the β i = 0
and αi 6= 0. The matrix pencil λI − ρH̃ is thus of dimensions ν × ν. This implies that the
matrix pencil λG̃ − ρI is of dimensions (2m + 2n − ν) × (2m + 2n − ν) and its determinant
is the product of the 2m + 2n − ν factors (αi λ − β i ρ) for which the complex numbers β i 6= 0.

                                                 46
(The matrix G̃ has thus 2m + 2n − ν eigenvalues denoted by αi /β i , all finite). Among these
factors, let there be 2m + 2n − s of them (with 0 ≤ s ≤ ν) for which β i 6= 0 and |αi /β i | ≤ 1,
so that there are s − ν factors for which β i 6= 0 and |αi /β i | > 1. The latter s − ν factors
necessarily have αi 6= 0 and |β i /αi | < 1.
    Recalling that G̃ is in real Jordan from, this implies that it is possible to partition it as
                                             ·        ¸
                                               G̃1 0
                                                0 G̃2

where G̃1 ∈ R(s−ν)×(s−ν) is a block-diagonal matrix with eigenvalues satisfying |αi /β i | > 1,
β i 6= 0, and G̃2 ∈ R(2m+2n−s)×(2m+2n−s) is a block-diagonal matrix with eigenvalues satisfying
|αi /β i | ≤ 1, β i 6= 0. Since all eigenvalues of G̃1 are nonzero, the matrix G̃1 is non-singular.
Combining the s − ν factors associated with G̃1 with the ν factors associated with the matrix
pencil λI − ρH̃ constitutes s factors for which αi 6= 0 and |β i /αi | < 1.
     It follows that the 2 (n + m) × 2 (n + m) real matrix
                                                               
                                            Iν    0        0
                                     Ū ≡  0 G̃−11        0     Ũ
                                            0     0 I2m+2n−s

is non-singular and satisfies (A.10), where Ω ≡ G̃2 is a (2m + 2n − s) × (2m + 2n − s) block-
diagonal matrix in real Jordan form with blocks corresponding to the factors of (A.9) for
which |αi /β i | ≤ 1. This implies that
                                              kΩk ≤ 1.                                    (A.12)
                     ·          ¸
                       H̃   0
The matrix Λ0 ≡                   is a s × s block-diagonal matrix in real Jordan form with ν
                       0 G̃−11
zero eigenvalues (i.e., the eigenvalues of H̃ corresponding to the ν factors (αi λ − β i ρ) for
which β i = 0), and another s − ν eigenvalues corresponding to the roots β i 6= 0, |β i /αi | < 1.
Thus all s eigenvalues of Λ satisfy |β i /αi | < 1, so that

                                            kΛk < 1.                                        (A.13)



   Because the inequality (A.13) is strict, there also exist values δ > 1 such that

                                            kδΛk < 1.                                       (A.14)

In what follows, we shall consider a value of δ > 1 that is small enough for both (1.13) and
(A.14) to hold.
   Now let the matrices Ū , V̄ be partitioned conformably with the partitions in (A.10):
                       ·      ¸
                          Ū1    } s rows                       £        ¤
                  Ū =                               ,      V̄ = V̄1 V̄2              (A.15)
                          Ū2    } 2m + 2n − s rows



                                                47
where V̄1 and V̄2 are respectively 2 (n + m) × s and 2 (n + m) × £(2m + 2n¤− s) matrices. It
follows from the non-singularity
                               £  of Ū and¤ V̄ that the columns of Ū10 Ū20 form a basis for
R2(n+m) , as do the columns of V̄1 V̄2 . Hence we can represent dt as
                                                      ·    ¸
                                         £         ¤ ψt
                                   dt = V̄1 V̄2              ,                         (A.16)
                                                        φt

where ψ t is of dimension s and φt is of dimension 2m + 2n − s. The vectors (ψ t , φt ) can be
uniquely re-constructed from the vector dt , and vice versa.
   The decomposition (A.10) defines stable and unstable subspaces for the matrix pencil
M̄ − µN̄ . In particular, for any δ ≥ 1, let us define the δ−stable subspace Dδ as the set of
values dt0 for which there exists a deterministic sequence {dt } for t ≥ t0 consistent with this
value of dt0 , satisfying
                                         M̄ dt+1 = N̄ dt                                 (A.17)
for all t ≥ t0 , and such that
                                            lim δ t dt = 0.                              (A.18)
                                            t→∞

(In the case that δ = 1, we shall call D ≡ D1 simply the stable subspace.) We then have the
following result regarding the dimension of this linear space.

Lemma 9 Given Assumptions 2(b) and 3, let Dδ be the δ-stable subspace of the matrix
pencil M̄ − µN̄ corresponding to a value of δ such that (A.14) holds. Then Dδ is a linear
space of dimension s, the dimension of the square matrix Λ in (A.10).

Proof. Under Assumptions 2(b) and 3, Lemma 8 holds, and we can then rewrite (A.10) as:

                                 Ū1 M̄ V̄1 = Is ,           Ū1 M̄ V̄2 = 0              (A.19)
                                 Ū2 M̄ V̄1 = 0,             Ū2 M̄ V̄2 = Ω              (A.20)

and

                           Ū1 N̄ V̄1 = Λ0 ,               Ū1 N̄ V̄2 = 0                (A.21)
                           Ū2 N̄ V̄1 = 0,                Ū2 N̄ V̄2 = I2m+2n−s .        (A.22)

We observe from these orthogonality relations that the inverse transformations can be written
as                                                         ·         ¸
                         −1
                             £               ¤        −1     Ū1 M̄
                       Ū = M̄ V̄1 N̄ V̄2 ,         V̄ =               .               (A.23)
                                                              Ū2 N̄
(Here we use the fact that because Ū and V̄ are non-singular, we know that unique inverses
exist.)
    We can then pre-multiply the equations in (A.10) by Ū −1 , using (A.23), to obtain:

                                           M̄ V̄2 = N̄ V̄2 Ω                             (A.24)
                                         M̄ V̄1 Λ0 = N̄ V̄1 .                            (A.25)



                                                     48
We can similarly post-multiply the equations in (A.10) by V̄ −1 , using (A.23), to obtain:

                                         Λ0 Ū1 M̄ = Ū1 N̄                                      (A.26)
                                            Ū2 M̄ = ΩŪ2 N̄ .                                   (A.27)


Because Ū −1 and V̄ −1 must be non-singular matrices, we observe from (A.23) that M̄ V̄1 ,
N̄ V̄2 , M̄ 0 Ū10 , and N̄ 0 Ū20 must each be matrices of full rank.
     Pre-multiplying (A.17) by Ū2 and using (A.27), we obtain

                                         ΩŪ2 N̄ dt+1 = Ū2 N̄ dt

for each t ≥ t0 . Then using (A.16) to substitute for dt on both sides of this equation, and
using (A.22), we obtain
                                        Ωφt+1 = φt ,
which in turn implies that
                                        δ t φt = (δ −1 Ω)δ t+1 φt+1                              (A.28)
for each t ≥ t0 . Repeated application of (A.28) implies that

                                       δ t φt = (δ −1 Ω)k δ t+k φt+k                             (A.29)

for arbitrary k ≥ 1. Then in the case of any sequence {dt } satisfying (A.18), (A.12) implies
that the right-hand side of (A.29) converges to zero for large k. Hence we must have φt = 0
for all t ≥ t0 in the case of any such sequence. Thus dt must be a vector of the form dt = V̄1 ψ t
for all t.
    Pre-multiplying (A.17) by Ū1 and again using (A.16) to substitute for dt , one can similarly
show that
                                           ψ t+1 = Λ0 ψ t
for all t ≥ t0 . Given a vector ψ t0 , this law of motion can be solved for the complete sequence
{ψ t } and hence for the implied sequence {dt }. Since

                                        δ t ψ t = (δΛ0 )t−t0 δ t0 ψ t0

for any t, it follows from (A.14) that (A.18) must be satisfied. Hence the δ−stable subspace
Dδ consists of all vectors of the form dt0 = V̄1 ψ t0 for some vector ψ t0 . Since V̄ is invertible,
this linear space must be of dimension s (the number of columns of V̄1 ).

    We turn now to a further characterization of the dimension s. Since M̄ − µN̄ is a regular
pencil, a pair (λ, ρ) determines an eigenvalue µ of M̄ −µN̄ if det[λM̄ −ρN̄ ] = 0 and ρ−λµ = 0.
(In particular, a pair (λ, ρ) determines an infinite eigenvalue of M̄ −µN̄ if det[λM̄ −ρN̄ ] = 0,
and ρ 6= 0, λ = 0.) Because of the symmetries in the elements of the matrices M̄ and N̄ , the
eigenvalues of the pencil M̄ − µN̄ also satisfy the following symmetry.23

  23
    This demonstration that the eigenvalues come in “reciprocal pairs” extends to our environment a stan-
dard result in the theory of linear-quadratic optimal control (e.g., Hansen and Sargent, 2010, chap. 8).

                                                     49
Lemma 10 Given Assumptions 2(b) and 3, the set of values of µ = ρ/λ for which det[λM̄ −
ρN̄ ] = 0 is such that if µ belongs to the set, so do the numbers βµ−1 , and the complex
conjugates µ̄ and βµ−1 . In particular, if the equation holds for ρ = 0 (and arbitrary λ), then
it also holds for λ = 0 (and arbitrary ρ).

Proof. Given Assumptions 2(b) and 3, Lemma 7 implies that the matrix pencil M̄ − µN̄ is
regular. Hence the matrix pencil M̄ − µN̂ where N̂ ≡ β 1/2 N̄ is also regular. Let us define
the 2 (n + m) × 2 (n + m) matrix
                                     ·              ¸
                                          0    In+m
                                 J≡                   ,
                                       −In+m     0

and observe that
                                          M̄ 0 J M̄ = N̂ 0 J N̂ ,
so that the transposed matrix pencil (M̄ − µN̂ )0 is symplectic. It follows that the generalized
eigenvalues of the transposed pencil (M̄ − µN̂ )0 are symmetric with respect to the unit circle
(see Theorems 4 and 5 of Pappas, Laub and Sandell, 1980): if µ ∈ C is a generalized
eigenvalue of the real matrix pencil (M̄ − µN̂ )0 , then so are µ−1 and the complex conjugates
µ̄, µ−1 . In particular, if µ = 0 is an eigenvalue of (M̄ − µN̂ )0 , so is µ = ∞.
    Since det[M̄ − µN̂ ] = det[M̄ 0 − µN̂ 0 ] for all µ, it follows that if µ ∈ C is an eigenvalue of
(M̄ − µN̂ ), then so are µ−1 and the complex conjugates µ̄, µ−1 . Moreover, det[λM̄ − ρN̂ ] = 0
if and only if det[λM̄ − β 1/2 ρN̄ ] = 0. Hence µ is a generalized eigenvalue of (M̄ − µN̄ ) if
and only if β −1/2 µ is a generalized eigenvalue of the transformed pencil (M̄ − µN̂ ). It then
follows that βµ−1 , µ̄, and βµ−1 must also be generalized eigenvalues of (M̄ − µN̄ ).


Lemma 11 Given Assumptions 1(b), 2(b) and 3, the dimension of the square matrix Λ in
the decomposition (A.10) must be exactly s = m + n. Hence the matrix pencil M̄ − µN̄
has exactly m + n generalized eigenvalues satisfying |µ| < β and another m + n generalized
eigenvalues (some of which may be infinite) satisfying |µ| > 1, and the stable subspace D is
of dimension m + n. The dimension of the square matrix Ω is also m + n, and this matrix
satisfies
                                         kΩk < β.                                     (A.30)

Proof. Assumption 1(b) implies that for any initial conditions close enough to consistency
with the optimal steady state, there must exist a solution to the first-order conditions (for
the deterministic case in which ξ t = ξ̄ at all times) in which (1.13) holds. It follows that for
arbitrary initial conditions ft0 , there must be a sequence {dt } satisfying the linearized FOCs
(A.17) for all t ≥ t0 , such that dt0 is consistent with (A.6), and such that {δ t dt } is a bounded
sequence.24 It is then furthermore possible to choose a δ > 1 (possibly slightly smaller than
the δ referred to in Assumption 1(b)) such that (A.18) is satisfied. For a small enough choice
of δ > 1, (A.14) must hold as well. Hence there must exist δ > 1 for which (A.14) holds, and
  24
    Note that convergence in the exact nonlinear dynamics only implies that the sequence must not explode
in the linearized dynamics, since the rate of convergence might asymptotically decrease to zero.



                                                   50
such that for any initial conditions ft0 , there exists a vector dt0 in the δ−stable subspace Dδ
consistent with (A.6).
   It follows from our characterization of the δ−stable subspace in the proof of Lemma 9
that there must exist a vector ψ t0 such that

                                           [Fd V̄1 ] ψ t0 = ft0 .                               (A.31)

It is easily seen that any values for the m + n elements of ft0 can be arranged through a
suitable specification of the n−k elements of Θ̃t0 −1 , the k elements of F̄t0 , and the m elements
of ỹt0 −1 . Hence the right-hand side of (A.31) can be any element of Rm+n . Then in order for
a solution to exist for arbitrary initial conditions, it is necessary that

                                         rank Fd V̄1 = m + n.                                   (A.32)

This requires that s ≥ m + n.
    We further note that the decomposition (A.10) implies that the generalized eigenvalues
of the pencil M̄ − µN̄ consist of the 2m + 2n − s eigenvalues µi of the matrix Ω and the
reciprocals of the s eigenvalues λj of the matrix Λ. Lemma 10 implies that for each eigenvalue
λj of Λ, βλj must also be a generalized eigenvalue of the pencil M̄ − µN̄ ; and since |λj | < 1,
this must be a generalized eigenvalue with modulus less than β, and therefore an eigenvalue
of Ω rather than the reciprocal of any eigenvalue of Λ. Hence for each eigenvalue λj of Λ,
βλj must be an eigenvalue of Ω. This requires that Ω be of at least the dimension of Λ, and
hence that s ≤ m + n. Therefore s = m + n exactly. The matrix Ω is of dimension m + n,
and its eigenvalues all satisfy |µ| < β, which implies (A.30).
    Finally, it follows that [Fd V̄1 ] must be a non-singular square matrix, so that (A.31) can be
solved for ψ t0 for any specification of the initial conditions ft0 . Since the largest eigenvalue
of Λ must have a modulus strictly less than 1, any initial condition of the form dt0 = V̄1 ψ t0
gives rise to a sequence {dt } satisfying (A.18) for δ = 1. Hence this linear space of dimension
m + n corresponds to the stable subspace.

     In the proof of Lemma 11, it has already been established that for any initial conditions
ft0 , there exists a deterministic solution {dt } to the linearized FOCs that converges expo-
nentially to the steady state for large t. This result can then be directly extended to the
case of bounded fluctuations in the exogenous disturbances {ξ̃ t }, yielding the result stated
in the proposition.
     Given a bounded stochastic process {ξ̃ t } for the exogenous disturbances and a vector
ft0 of initial conditions, we are interested in stochastic processes {dt } such that (i) {dt } is
bounded; (ii) (A.3) is satisfied for all t ≥ t0 ; (iii) (A.5) is satisfied for all t > t0 ; and (iv) dt0
satisfies (A.6). Pre-multiplying (A.3) by Ū2 , we can show as in the proof of Lemma 9 that

                                 ΩŪ2 N̄ Et dt+1 = Ū2 N̄ dt − Ū2 N̄s s̄t ,

or equivalently that
                                 Et [(I − ΩL−1 )Ū2 N̄ dt ] = Ū2 N̄s s̄t .
Using (A.16) to substitute for dt , this can alternatively be written

                                    Et [(I − ΩL−1 )φt ] = Ū2 N̄s s̄t .                         (A.33)

                                                    51
Because of (A.30), the operator I−ΩL−1 is invertible on the linear space of bounded processes
{φt }, so that for any disturbance process such that ||s̄|| < ∞, (A.33) has a unique solution
such that ||φ|| < ∞, given by

                                   φt = Et [(I − ΩL−1 )−1 Ū2 N̄s s̄t ].                       (A.34)

   Similarly, pre-multiplying (A.3) by Ū1 and using (A.16) to substitute for dt yields

                                      Et ψ t+1 = Λ0 ψ t − Ū1 N̄s s̄t .                        (A.35)

Using (A.16) to substitute for dt in (A.5), and shifting the time index by one period, yields

                Fd V̄1 [ψ t+1 − Et ψ t+1 ] = Fs [s̄t − Et−1 s̄t ] − Fd V̄2 [φt+1 − Et φt+1 ]

for each t ≥ t0 . Since Fd V̄1 is an invertible square matrix (as shown in the proof of Lemma
11), this can be solved uniquely for ψ t+1 . Substituting expression (A.35) for the conditional
expectation Et ψ t+1 in this equation, and the solution (A.34) for both φt+1 and its conditional
expectation, we obtain a law of motion of the form

                                          ψ t+1 = Λ0 ψ t + rt+1                                (A.36)

for all t ≥ t0 , where {rt } is a process satisfying ||r|| < ∞ that has been uniquely determined
as a function of the evolution of the exogenous disturbances.
    Finally, using (A.16) to substitute for dt0 in (A.6) we obtain

                                      Fd V̄1 ψ t0 = ft0 − Fd V̄2 φt0 .

Using the solution (A.34) to substitute for φt0 in this equation, the invertibility of Fd V̄1
implies that this equation has a unique solution for ψ t0 for any specification of the initial
conditions ft0 and the process for the exogenous disturbances. Given this initial condition
for ψ t0 , the law of motion (A.36) can then be integrated forward, yielding a unique solution
for the evolution of {ψ t } for all t ≥ t0 . It follows from (A.14) and the fact that ||r|| < ∞
that this solution will satisfy ||ψ|| < ∞. Our solutions for the processes {φt , ψ t } then imply
a unique solution for the process {dt }, using (A.16), and the bounds satisfied by the two
solutions imply that ||d|| < ∞ as well. Hence there is a unique solution satisfying this bound.
QED.

A.2     Proof of Lemma 1
There is no vector ϕ̂2 (µ) 6= 0 such that ϕ̂2 (µ)0 [J2 − µB2 ] = 0 for all µ. For if there did, the
vector                                          ·          ¸
                                             −1       0
                                  ϕ (µ) = P                  6= 0
                                                   ϕ̂2 (µ)
would satisfy (2.13), and this would violate Assumption 2. This implies that the pencil
J2 − µB2 must be of rank q, which (since it is a square pencil of dimension q × q) implies
that it is a regular pencil.


                                                    52
   It follows from Theorem 3 of Gantmacher (1959, Chap. 12), or its version for a real
canonical form proved in Appendix D, that J2 − µB2 can be reduced to a strictly equivalent
pencil of the form             ·                         ¸
                                 Il − µĜ0        0
                                                                                   (A.37)
                                     0      Ĥ 0 − µIq−l
where Ĝ0 ∈ Rl×l (0 ≤ l ≤ q) is a nilpotent matrix of the Jordan form (i.e., with ones on the
first super diagonal and zeros everywhere else), and Ĥ 0 ∈ R(q−l)×(q−l) is a block-diagonal
matrix of the real Jordan form. We can without loss of generality arrange the Jordan blocks
of Ĥ 0 as                                  · 0        ¸
                                        0    Ĥ11 0
                                      Ĥ =
                                              0 H0
where the invertible matrix Ĥ11 contains the eigenvalues with modulus greater than or equal
to β, and H contains only eigenvalues with modulus less than β. Premultiplying the pencil
(A.37) by the invertible block-diagonal matrix
                                                        
                                     Il      0       0
                                    0 (Ĥ110 −1
                                               )     0 
                                      0      0     Iq−k2
yields a strictly equivalent matrix pencil of the form (2.29), where all eigenvalues of
                                         · 0             ¸
                                     0      Ĝ       0
                                    G =             0 −1
                                                           .
                                             0 (Ĥ11   )

have modulus less than or equal to β −1 and all eigenvalues of H have modulus less than β.
It remains only to determine the dimensions of G and H.
    The existence of a decomposition of the form (2.29) implies that the factors of the char-
acteristic polynomial P (λ, µ) defined in Assumption 4 are the same as those of
                               det [λI − µG0 ] · det [λH 0 − µI] .
This implies the existence of a factorization of the form (2.22), where the {γ i } are the
eigenvalues of G and the {η j } are the eigenvalues of H. It follows that G must be of dimension
k2 × k2 and H must be of dimension (q − k2 ) × (q − k2 ) . Finally, since by Assumption 4(b),
|γ i | < 1 for all i, all eigenvalues of G must have modulus strictly smaller than 1.

A.3     Proof of Proposition 2
Premultiplying (2.24) by N20 yields the pair of equations
                                  Et x1,t+1 = G0 x1,t + N21
                                                         0
                                                            Γ2 ξ̃ t                       (A.38)
                                0                      0
                               H Et x2,t+1 = x2,t + N22 Γ2 ξ̃ t                           (A.39)
using the decomposition (2.29), defining
                                      ·      ¸
                                         x1t    ¡    ¢0 ∗
                                xt ≡           ≡ R2−1 y2t ,                               (A.40)
                                         x2t

                                               53
                           ·0
                               ¸
                          N21
and partitioning   N20≡     0     conformably with the partition of xt .
                          N22
   Because all eigenvalues of H 0 have modulus less than β, and {ξ̃ t } is bounded for all dates
t ≥ t0 − 1, there is a unique process {x2t } consistent with (A.39) and such that ||x2 || < ∞,
namely
                                         ∞
                                         X
                                 x2t = −     (H 0 )j N22
                                                      0
                                                         Γ2 Et ξ̃ t+j .                  (A.41)
                                                   j=0

     Then in any period t, given the past, current and expected future values of the exogenous
                                                                          ∗
disturbance process, and given the lagged expectations of J2 Et−1 y2t       , equation (2.26) deter-
                       0   ∗
mines the value of X1 J2 y2,t , while equation (A.41) determines the value of x2t and hence of
H 0 x2t . We then have a system of equations of the form
                           ·           0
                                              ¸           · 0        ∗
                                                                        ¸
                              £      X 1 ¤          ∗      X 1 J 2 y2,t
                                                J2 y2,t =
                                0 Iq−k2 N20                 H 0 x2t
                 ∗
to solve for J2 y2,t , where all elements of the matrix on the right-hand side have been com-
puted. Since the matrix on the left-hand side is invertible by Assumption 5, this system has
                            ∗
a unique solution for J2 y2,t . Using this solution, we can in turn solve for

                                             x1,t = [I 0] N20 J2 y2,t
                                                                  ∗
                                                                      .

   Combining this solution for x1t with (A.41), we have a unique solution for the entire
                                       ∗
vector xt , given values of J2 Et−1 y2,t    and the evolution of the exogenous disturbances. And
given the value of xt in any period, equations (A.38) and (A.39) uniquely determine the
values of Et [x1,t+1 ] and Et [H 0 x2,t+1 ] respectively. This allows us to uniquely determine
                                                     ·                   ¸
                                        ∗         −1      Et x1,t+1
                               J2 Et y2,t+1 = N2                           .
                                                        Et [H 0 x2,t+1 ]
                                                              ∗
Thus starting from given initial conditions J2 Et0 −1 y2,t      0
                                                                  , we can uniquely solve for xt0 , use
                                        ∗
this to uniquely solve for J2 Et0 y2,t0 +1 , use this to uniquely solve for xt0 +1 , and so on recur-
sively, eventually obtaining a unique solution for the entire process {xt } , and hence a unique
                                        ∗                           ∗
solution for the entire process {y2t      } , using the relation y2t  = R20 xt .
                          ∗
     This solution {y2t     } is the only solution such that ||y2∗ || < ∞, if any solution exists. But
one easily verifies that it is indeed such a solution. By construction, (2.26) is satisfied each
period, and also both (A.38) and (A.39), which suffice to imply that (2.24) is satisfied each
period. Moreover, the fact that all eigenvalues of G have modulus less than 1 implies that
the process {xt } constructed in this way satisfies ||x|| < ∞, so that the associated process
   ∗
{y2t } satisfies ||y2∗ || < ∞. Hence all conditions for a solution are satisfied.

A.4     Proof of Lemma 2
Using the definition of qt and the fact that the matrix W is symmetric, we may rewrite the
objective function (3.3) as
                                    1£ 0                                                           ¤
                π (yt ; ξ t ) = −     yt wW w0 yt − 2q ∗ (ξ t )0 W w0 yt + q ∗ (ξ t )0 W q ∗ (ξ t )
                                    2
                                                         54
so that
                                                     £                   ¤
                                 D1 π (yt ; ξ t ) = − yt0 w − q ∗ (ξ t )0 W w0              (A.42)
                             £                   ¤
                           D1 (D1 π (yt ; ξ t ))0 = −wW w0
                             £                   ¤
                           D2 (D1 π (yt ; ξ t ))0 = wW [Dq ∗ (ξ t )] .
                                                                                      ¡ ¢
The fact that the targets q ∗ (ξ t ) are achievable implies that in steady state, D1 π ȳ, ξ̄ = 0,
using (3.4) and (A.42). It then follows from (1.12) that
                                             ¡         ¢
                                          ϕ̄0 I¯ − β Ā = 0.

Assumption 2(b) then implies that ϕ̄ = 0, so that S, R and B (L) reduce to
                                                         £    ¡ ¢¤
                  S = −wW w0 , R = 0, B (L) = wW Dq ∗ ξ̄ · L.

   The target variables and target values are then given by

                                  τ t = wW w0 ỹt = wW (qt − q̄) ,
                                           £       ¡ ¢¤
                                  τ t∗ = wW Dq ∗ ξ̄ · ξ̃ t ,

where q̄ ≡ w0 ȳ. Performing a first-order approximation to q ∗ (ξ t ) , we obtain
                                               ¡ ¢ £     ¡ ¢¤
                         qt∗ ≡ q ∗ (ξ t ) = q ∗ ξ̄ + Dq ∗ ξ̄ · ξ̃ t + O(²2 )

so that, using (3.4), we have
                                   £       ¡ ¢¤
                                       Dq ∗ ξ̄ · ξ̃ t = qt∗ − q̄ + O(²2 ).

Using this, we can express the “target gaps” τ t − τ ∗t as

            τ t − τ ∗t = wW (qt − q̄) + wW (qt∗ − q̄) + O(²2 ) = wW (qt − qt∗ ) + O(²2 ).

A.5       Proof of Lemma 3
The fact that the pencil Ā − µI¯ is of rank n < m implies that the columns are linearly
dependent, i.e., that there exists y (µ) such that
                                       £         ¤
                                         Ā − µI¯ y (µ) = 0                       (A.43)

for all µ, though by Assumption 2, y (µ) is of order greater than zero. Let ²1 ≥ 1 be the
minimal order of solution y (µ) that exists to (A.43). (A solution of finite order ²1 necessarily
exists.) Then Theorem 4 of Gantmacher (1959, chap. 12) implies that the pencil Ā − µI¯ is
strictly equivalent to a pencil of the form
                                   ·                        ¸
                                     M1 (µ)0        0
                                                (1)     (1)
                                         0     B2 − µJ2
          (1)     (1)
where B2 − µJ2          is a pencil for which the equation
                                            (1)      (1)
                                         [B2 − µJ2 ] ŷ (1) (µ) = 0                         (A.44)

                                                      55
has no solution of order less than ²1 .
   If (A.44) nonetheless has a nonzero solution of minimal order ²2 ≥ ²1 , then Theorem 4
                                                       (1)     (1)
of Gantmacher can be applied again to the pencil B2 − µJ2 . Proceeding in this way, one
eventually transforms the pencil Ā − µI¯ into a pencil of the form shown in (3.6), where the
sequence of indices satisfies
                                    ²p ≥ ... ≥ ²2 ≥ ²1 ≥ 1,
and [B2 − µJ2 ] is a pencil for which the equation

                                    [B2 − µJ2 ] ŷ (µ) = 0

has no nonzero solution, i.e., the columns are linearly independent.
    By the same argument as in the proof of Lemma 1, Assumption 2 implies that there is
also no vector ϕ̂ (µ) 6= 0 such that

                                    ϕ̂ (µ)0 [B2 − µJ2 ] = 0,

i.e., the rows of the pencil are also linearly independent. Hence [B2 − µJ2 ] must be a square
pencil of some dimension q × q. (Note that it is possible that q = 0, i.e., that B2 and J2 are
null matrices.)
     Adding up the columns of the matrix in (3.6), one observes that
                                          p
                                          X
                                                ²i + q = n.
                                          i=1

Adding up the rows, one similarly observes that
                                    p
                                    X
                                          (²i + 1) + q = m,
                                    i=1

from which it follows that the number of Mi blocks must equal p = m − n.
   This theorem implies that there exist nonsingular square matrices P, Q of dimensions
n × n and m × m respectively that satisfy (3.6).

A.6     Proof of Lemma 4
Suppose that (3.2) holds for any period t > t0 , and suppose that Assumption 2 holds. Lemma
3 then implies that there exist matrices P, Q that define the decomposition (3.6), i.e., a
decomposition of the form (2.20). Assumption 4 then allows us to decompose conditions
(3.2) into separate subsystems as well. It follows from (2.21) that
                   ·       ¸       · 0       ¸ · ¡ −1 ¢0             ¸·         ¸
                     ϕ̂1,t           T1 0          T1          0          ϕ̃1,t
                             = P                            ¡ −1 ¢0
                     ϕ̂2,t            0 T20          0       T2           ϕ̃2,t
                                 ·                     ¸ · ¡ −1 ¢0       ¸
                                   U1 0 U2 0                T      ϕ̃
                             =                             ¡ 1−1 ¢0 1,t
                                    0 X1 0 X2               T2     ϕ̃2,t


                                                  56
so that
                                £          ¤¡¢0        £     ¤¡     ¢0
                     ϕ̂1,t =        U1 0 T1−1 ϕ̃1,t + U2 0 T2−1 ϕ̃2,t                    (A.45)
                               £      ¤ ¡ −1 ¢0        £      ¤ ¡ −1 ¢0
                     ϕ̂2,t   =   0 X1    T1     ϕ̃1,t + 0 X2     T2     ϕ̃2,t .          (A.46)

Equations (A.45) and (A.46) respectively imply that
                                        £      ¤¡     ¢0 ¡                   ¢
                  ϕ̂1,t − Et−1 ϕ̂1,t =    U1 0 T1−1 ϕ̃1,t − Et−1 ϕ̃1,t               (A.47)
                                        £      ¤ ¡ −1 ¢0 ¡                   ¢
                  ϕ̂2,t − Et−1 ϕ̂2,t =    0 X1    T1       ϕ̃1,t − Et−1 ϕ̃1,t .      (A.48)
                                          £        ¤       £          ¤
    Recall from Assumption 4 that both U1 U2 and X1 X2 are invertible matrices,
and define the matrices V1 , V2 , W1 , and W2 as in (3.10). Note that it follows from these
definitions that

                  V1 U1 = Ik1 ,       V1 U2 = 0,        V2 U1 = 0,  V2 U2 = Iñ−k1       (A.49)
                 W1 X1 = Ik2 ,        W1 X2 = 0,         W2 X1 = 0,    W2 X2 = Iq−k2 .   (A.50)

Premultiplying (A.47) by V2 yields (3.11); premultiplying (A.48) by W2 yields (3.12). Hence
(3.11)-(3.12) must hold for all t > t0 .
    Conversely, suppose that (3.11)-(3.12) hold in some period t > t0 . Using (A.45), (3.11)
implies that                £       ¤¡   ¢0 ¡              ¢
                              I 0 T2−1 ϕ̃2,t − Et−1 ϕ̃2,t = 0.
Similarly, using (A.46), (3.12) implies that
                             £     ¤ ¡ −1 ¢0 ¡                   ¢
                               0 I    T2       ϕ̃2,t − Et−1 ϕ̃2,t = 0.

Together, these conditions imply that
                               ¡ −1 ¢0 ¡                   ¢
                                T2       ϕ̃2,t − Et−1 ϕ̃2,t = 0

which implies (3.2). Hence (3.2) must hold for all t > t0 .

A.7       Proof of Proposition 3
In order to prove Proposition 3, we make use of a further preliminary result.

Lemma 12 Suppose that there exist matrices P, Q that define a decomposition of the form
(2.20), and that Assumptions 2, 4 and 5 hold. Then the q × q matrix
                                   ·                ¸
                                     £     W2¤
                                                                                 (A.51)
                                       Ik2 0 R2 J20

is invertible.




                                                   57
Proof. Let x be an arbitrary vector of length q, partitioned as in (A.40). By Assumption
5, knowing the values of the vectors X10 J2 R20 x and [0 I] N20 J2 R20 x allows one to reconstruct
the entire vector J2 R20 x, and hence all elements of
                                                    ·        ¸
                                       0      0        x1
                                     N2 J 2 R 2 x =            .
                                                      H 0 x2

Since the elements of [0 I] N20 J2 R20 x = H 0 x2 provide information only about the elements of
x2 , it must be that each of the k2 independent directions of variation of the elements of x1
affects the elements of X10 J2 R20 x in an independent direction. Thus Assumption 5 implies
that the k2 × k2 matrix                                ·     ¸
                                                0    0   Ik2
                                        Ξ ≡ X1 J2 R2                                     (A.52)
                                                          0
is invertible.
    Next, let ϕ̂ be another arbitrary vector of length q, and let
                                                   ·     ¸
                                           −1        ϕ̌1
                                    ϕ̌ ≡ N2 ϕ̂ ≡           .
                                                     ϕ̌2

One observes that
                                                              ·            ¸             ·           ¸
                                                                   I 0                        ϕ̌1
                        R2 J20 ϕ̂   =   [R2 J20 N2 ] ϕ̌   =                    ϕ̌ =                      ,
                                                                   0 H                       H ϕ̌2

Then in the case that
                                                       ϕ̂ = X1 f                                             (A.53)
for some vector f of length k2 , it follows that ϕ̌1 = Ξ0 f, where Ξ is defined in (A.52).
    Because Ξ (and hence Ξ0 ) is invertible, if for any ϕ̂ of the form (A.53), ϕ̌1 = 0, it
follows that f = 0 and hence that ϕ̂ = 0. But it follows from (A.50) that a vector ϕ̂ has
a representation of the form (A.53) if and only if W2 ϕ̂ = 0. Hence if any vector ϕ̂ satisfies
both W2 ϕ̂ = 0 and ϕ̌1 = 0, it must satisfy ϕ̂ = 0. Alternatively, if it satisfies both the linear
restrictions W2 ϕ̂ = 0 and [I 0]R2 J20 ϕ̂ = 0, it must be a zero vector. It follows from this that
the matrix (A.51) must be invertible.

       We may now proceed with the proof of Proposition 3. Let {τ̂ 2,t } be any process satisfying
||τ̂ 2 || < ∞. Because (3.6) is a decomposition of the form (2.20), Lemma 1 guarantees that
if Assumption 2 and 4 are satisfied, then there exist non-singular matrices N2 , R2 such that
(2.29) holds. Then premultiplying (3.9) by R2 and using (2.29) yields

                                            ϕ̌1t = βGEt ϕ̌1,t+1 − βτ̌ 1t ,                                   (A.54)
                                                              −1
                                     Et ϕ̌2,t+1 = (β               H)ϕ̌2,t + τ̌ 2t ,                         (A.55)

where                            ·          ¸                            ·           ¸
                                     ϕ̌1t                                    τ̌ 1t
                         ϕ̌t ≡                  ≡   N2−1 ϕ̂2t ,                          ≡ R2 τ̂ 2t .
                                     ϕ̌2t                                    τ̌ 2t


                                                              58
Because all eigenvalues of βG have modulus less than 1, (A.54) has a solution for {ϕ̌1t } such
that ||ϕ̌1 || < ∞, given by
                                          ∞
                                          X
                                ϕ̌1t = −β   (βG)j Et τ̌ 1,t+j .                        (A.56)
                                                   j=0

    Then in any period t, the value of

                                          ϕ̌1t = [I 0] R2 J20 ϕ̂2t

is given by (A.56), while the value of W2 ϕ̂2t is given by (3.12). Thus the values of both ϕ̌1t
and W2 ϕ̂2t are given as functions of variables that are exogenous and/or predetermined in
period t. But Lemma 12 implies that the mapping from the linear space of vectors ϕ̂ to the
values of ϕ̌1 and W2 ϕ̂ is an isomorphism, so this system of equations can be uniquely solved
for the value of ϕ̂2t . We thus obtain a unique solution for ϕ̂2t as a linear function of Et−1 ϕ̂2t
and the Et τ̌ 1,t+j for j ≥ 0.
    This solution for ϕ̂2t allows us to solve for ϕ̌2t , and substituting this into (A.55) yields a
value for Et ϕ̌2,t+1 as a linear function of Et−1 ϕ̂2t , τ̌ 2t , and the Et τ̌ 1,t+j for j ≥ 0. The solution
(A.56) implies that
                                                 ∞
                                                 X
                                 Et ϕ̌1,t+1 = −β     (βG)j Et τ̌ 1,t+j+1 .
                                                     j=0

Hence we can solve for the complete vector Et ϕ̌t+1 as a linear function of Et−1 ϕ̂2t and the
exogenous state. Alternatively, we can solve for Et ϕ̂2,t+1 = N2 Et ϕ̌t+1 as a linear function of
Et−1 ϕ̂2t and the exogenous state. Thus starting from an initial condition Et0 −1 ϕ̂2t0 , we can
solve for ϕ̂2t0 and Et0 ϕ̂2,t0 +1 ; using this solution we can solve for ϕ̂2,t0 +1 and Et0 +1 ϕ̂2,t0 +2 ;
and so on
    recursively.
    Thus it is possible to solve for the complete evolution {ϕ̂2t } for all t ≥ t0 , given the
initial condition Et0 −1 ϕ̂2t0 and the evolution of the exogenous state. By construction (A.54)
and (A.55) are satisfied for each t ≥ t0 , which implies that (3.9) is satisfied for each t ≥ t0 .
Likewise, (3.12) is satisfied for each t > t0 by construction. Thus we obtain a process
{ϕ̂2t } that satisfies both (3.9) for all t ≥ t0 and (3.12) for all t > t0 . Moreover, because all
eigenvalues of β −1 H have modulus less than 1, (A.55) implies that the constructed solution
satisfies ||ϕ̂2 || < ∞.

A.8      Proof of Lemma 5
Consider the case of unidimensional policy so that i = p = 1, and thus ²i = ñ.
   Suppose that (3.8) hold for all t ≥ t0 . The first element of the vector of FOCs (3.8) can
be written
                                              (1)      (1)
                                       β −1 ϕ̂1,t = τ̂ 1,t                             (A.57)
while the j-th element (for 2 ≤ j ≤ ñ) can be written as
                                             (j)      (j)         (j−1)
                                       β −1 ϕ̂1,t = τ̂ 1,t − Et ϕ̂1,t+1 .                           (A.58)



                                                      59
                                                                               (j)
This system of equations can be solved recursively for the {ϕ̂1,t }, yielding
                                         (j)      £ ¡     ¢       ¤
                                       ϕ̂1,t = βEt Γj βL−1 τ̂ 1,t                                  (A.59)

for each 1 ≤ j ≤ ñ, where Γj (µ) is the j-th row of the matrix polynomial Γ (µ) . This gives
the vector of conditions (3.16).
    The (ñ + 1)-st element of the vector of FOCs (3.8) states that
                                                      (ñ)        (ñ+1)
                                                 Et ϕ̂1,t+1 = τ̂ 1,t       .                       (A.60)
                                           (j)
Substituting solution (A.59) for ϕ̂1,t , we obtain
                                    (ñ+1)       £        ¡    ¢       ¤
                                  τ̂ 1,t     = Et βL−1 Γñ βL−1 τ̂ 1,t                             (A.61)

which implies (3.17). Here we use the fact that
                                          £                ¡    ¢¤
                           δ (µ)0 = (−µ)ñ e0ñ+1 − µ−1 Γñ µ−1

where e0ñ+1 is a 1 × (ñ + 1) vector of the form e0ñ+1 ≡ [0...0 1] . Thus both (3.16) and (3.17)
must hold in all periods t ≥ t0 .
    To prove the converse, suppose that the processes {τ̂ 1,t } and {ϕ̂1,t } satisfy (3.16) and
(3.17) in all periods t ≥ t0 . Condition (3.16) implies (A.59) for each 1 ≤ j ≤ ñ, which in turn
implies condition (A.57), and condition (A.58) for each 2 ≤ j ≤ ñ. These are just the first ñ
elements of the vector of FOCs (3.8). Condition (3.17) implies (A.61), which together with
the case j = ñ of (A.59) implies (A.60). This is just the (ñ + 1)-st element of the vector of
FOCs (3.8). Thus the entire vector of conditions (3.8) must hold in each period t ≥ t0 .

A.9      Proof of Proposition 4
To prove Proposition 4, it will be useful to appeal to the following Lemma.

Lemma 13 Suppose that the processes {τ̂ 1,t } and {ϕ̂1,t } satisfy (3.16) for all t ≥ t0 . Then
for any 1 ≤ j ≤ ñ, and any t ≥ t0 ,
                                                     h                   i
                                                          (j)        (j)
                    Et zt+j−1 − Et−1 zt+j−1 = −(−β)−j ϕ̂1,t − Et−1 ϕ̂1,t ,               (A.62)

         (j)                                                                                         (j)
where ϕ̂1,t is the j-th element of the vector ϕ̂1,t . When t = t0 , the expression Et0 −1 ϕ̂1,t0 is
taken to refer to the historical expectations βEt0 −1 [Γj (βL−1 )τ̂ 1,t0 ].

Proof. Using the definition (3.15) we have
                                  h                                     ¡     ¢j−1 (j) i
                                    (1)              (2)
   Et zt+j−1 − Et−1 zt+j−1 = Et τ̂ 1,t+j−1 − β −1 τ̂ 1,t+j−2 + ... + −β −1        τ̂ 1,t
                                      h                                     ¡ −1 ¢j−1 (j) i
                                        (1)           −1 (2)
                               −Et−1 τ̂ 1,t+j−1 − β τ̂ 1,t+j−2 + ... + −β                τ̂ 1,t
                               ¡ −1 ¢j−1 © £ j ¡ −1 ¢                 ¤      £ j ¡ −1 ¢             ¤ª
                           = −β              Et Γ βL            τ̂ 1,t − Et−1 Γ βL           τ̂ 1,t
                                        h                     i
                                            (j)           (j)
                           = −(−β)−j ϕ̂1,t − Et−1 ϕ̂1,t .

                                                             60
Here, the first equality uses the definition of δ (µ)0 , and the fact that Et τ̂ 1,t−k = Et−1 τ̂ 1,t−k
for any k ≥ 1. The second equality uses the definition of Γ (µ) , denotes by Γj (µ) its j-
th row. The third equality uses (3.16). In the case that t = t0 , the replacement of
                                     (j)                                               (j)
βEt−1 [Γj (βL−1 ) τ̂ 1,t ] by Et−1 ϕ̂1,t is justified under the definition of Et0 −1 ϕ̂1,t0 proposed
above.

   We may now proceed with the proof of Proposition 4. Condition (3.8) implies that (3.16)
and (3.17) must hold for all t ≥ t0 , using Lemma 5. The fact that (3.16) holds implies that
(A.62) must also hold for all t ≥ t0 , using Lemma 13.
   Let us first consider any period t ≥ t0 + ñ − k1 . Then
                                ñ−k
                                 X1
                  Et zt+k1 =           (Et+1−j zt+k1 − Et−j zt+k1 ) + Et−(ñ−k1 ) zt+k1
                                 j=1
                                ñ−k
                                 X1                h                           i
                                                      (k1 +j)          (k1 +j)
                            =          (−β)−(k1 +j) ϕ̂1,t+1−j − Et−j ϕ̂1,t+1−j   .            (A.63)
                                 j=1


Here the second line uses (A.62) to replace the first term on the right-hand side of the first
line, and uses (3.17) to eliminate the second term.                £            ¤
    Given Assumption 6, (3.11) implies that the entire vector ϕ̂1,t − Et−1 ϕ̂1,t can be recon-
structed from its first k1 elements, using
                                                ·    ¸
                                                  Ik1 £                    ¤
                           ϕ̂1,t − Et−1 ϕ̂1,t =         ϕ̄1,t − Et−1 ϕ̄1,t              (A.64)
                                                   Φ

for any t ≥ t0 + 1, where ϕ̄1,t is the vector consisting of the first k1 elements of ϕ̂1,t . Using
(A.64) to substitute for the terms on the right-hand side of (A.63), we obtain
                                ñ−k
                                 X1                      £                           ¤
                  Et zt+k1 =           − (−β)−(k1 +j) φ0j ϕ̄1,t+1−j − Et−j ϕ̄1,t+1−j
                                 j=1
                                ñ−k
                                 X1
                            =          (−β)−(k1 +j) φ0j wt+1−j
                                 j=1
                                             ñ−k
                                              X1
                                       −k1
                            = (−β)                  φ0j Ωjt                                   (A.65)
                                             j=1
                                       −k1
                            = (−β)           tr [ΦΩt ] ,

which establishes (3.20). Here we use the notation φ0j for the j-th row of Φ and the notation
Ωjt for the j-th column of Ωt . In addition, the second line uses Lemma 13 to substitute for
the elements of ϕ̄1,t+1−j − Et−j ϕ̄1,t+1−j , and definition (3.18), while the third line uses the
definition of Ωt .




                                                       61
   Let us now consider any period t0 ≤ t < t0 + ñ − k1 . Then
                                           t−t0
                                           X
                        Et zt+k1 =                (Et+1−j zt+k1 − Et−j zt+k1 ) + Et0 zt+k1
                                           j=1
                                                        t−t0
                                                        X
                                   = (−β)−k1                     φ0j Ωjt + Et0 zt+k1 ,                                      (A.66)
                                                           j=1

where the second line is obtained using the same reasoning as was used to derive (A.63) and
(A.65).
    For the given historical expectations et0 −1 , let Ξ1,t0 −1 be given by (3.21) where χt0 −1 is
the vector whose j-th element is given by (3.22). With this definition, (3.13) together with
(3.8) and Lemma 5 imply that
                               £     ¤            £     ¤
                            V2 ϕ̂1,t0 = V2 Et0 −1 ϕ̂1,t0 + V22 χt0 −1 .

Premultiplying by V22−1 and noting that Φ ≡ −V22−1 V21 , this yields
                                      £                      ¤
                          [−Φ Iñ−k1 ] ϕ̂1,t0 − Et0 −1 ϕ̂1,t0 = χt0 −1 ,
which can alternatively be written
                                           [Φ      (−Iñ−k1 )] wt0 = χt0 −1 ,                                               (A.67)
using Lemma 13 and definition (3.18).
   For any 1 ≤ j ≤ ñ − k1 , the j-th row of (A.67) can be written
                             φ0j w̄t0 − (−β)k1 +j [Et0 zt0 +k1 +j−1 − Et0 −1 zt0 +k1 +j−1 ]
                                                                          ñ−k1 −j
                                   k1 +j
                                                                            X
                        = (−β)             Et0 −1 zt0 +k1 +j−1 −                     (−β)−i φ0j+i w̄t0 −i ,
                                                                            i=1

or alternatively,
                                                ñ−k1 −j                                     ñ−k
                k1 +j
                                                  X                −i
                                                                                              X1
          (−β)          Et0 zt0 +k1 +j−1 =                 (−β)         φ0j+i w̄t0 −i   =           (−β)j φ0h Ωht0 +j−1 .
                                                  i=0                                        h=j

Thus if we let j = t + 1 − t0 , we find that
                                                                          ñ−k
                                                                           X1
                                    Et0 zt+k1 = (−β)−k1                              φ0h Ωht .
                                                                        h=t−t0 +1

Using this to substitute for the final term on the right-hand side of (A.66), we obtain
                                                                          ñ−k
                                                                           X1
                                                                   −k1
                                       Et zt+k1 = (−β)                           φ0j Ωjt ,
                                                                           j=1

so that (3.20) is satisfied for each t0 ≤ t < t0 + ñ − k1 . Since we have already shown that
(3.20) holds for any t ≥ t0 + ñ − k1 , it follows that (3.20) is satisfied for each t ≥ t0 .

                                                                 62
A.10      Proof of Lemma 6
For period t0 , conditions (3.23) and (3.24) hold by assumption, given the initial condition
(3.13) and the initial Lagrange multipliers (3.21). Next, (3.8) implies ϕ̂1,t = βEt [Γ(βL−1 )τ̂ 1,t ]
at all dates t ≥ t0 , by Lemma 5. Using this, conditions (3.11) in turn imply that

                          V2 ϕ̂1,t = V2 Et−1 ϕ̂1,t = V2 βEt−1 [Γ(βL−1 )τ̂ 1,t ]

for all t > t0 . Equation (3.23) thus holds in all period t ≥ t0 , where Ξ1,t−1 is given by (3.24)
in period t = t0 , and
                                  Ξ1,t−1 = V2 βEt−1 [Γ(βL−1 )τ̂ 1,t ]
for all t > t0 . To prove that (3.24) holds at all dates, we need to show that V22 χt−1 = 0 for
all periods t > t0 .
    Given the initial Lagrange multipliers Ξ1,t0 defined in (3.21) and using Proposition 4
implies that (3.20) must hold at all dates t ≥ t0 . Condition (3.20) then implies that for any
t ≥ t0 and any 1 ≤ j ≤ ñ − k1 ,

    Et zt+k1 +j−1 = Et [Et+j−1 zt+k1 +j−1 ] = (−β)−k1 tr[Φ Et Ωt+j−1 ]
                                h                                                              i
                  = (−β)−k1 Et (−β)−1 φ01 w̄t+j−1 + . . . + (−β)−(ñ−k1 ) φ0ñ−k1 w̄t+j+k1 −ñ
                             h                                                          i
                  = (−β)−k1 (−β)−j φ0j w̄t + . . . + (−β)−(ñ−k1 ) φ0ñ−k1 w̄t+j+k1 −ñ
                                        ñ−k1 −j
                             −(k1 +j)
                                         X
                   = (−β)                          (−β)−i φ0j+i w̄t−i .                        (A.68)
                                          i=0

Using this to substitute for Et−1 zt+k1 +j−1 in (3.22), we obtain

                                           χjt−1 = φ0j Et−1 w̄t = 0

for all t > t0 , and any 1 ≤ j ≤ ñ−k1 . It follows that χt−1 = 0, and hence that V22 χt−1 = 0 for
all t > t0 .

A.11      Proof of Proposition 5
Let the process {ϕ̂1,t } be given by (3.16) for all t ≥ t0 . Note that if k1 < ñ, satisfaction of
(3.20) for all t ≥ t0 implies that

                   Et zt+ñ = Et [Et+ñ−k1 zt+ñ ] = (−β)−k1 tr[Φ Et Ωt+ñ−k1 ] = 0

for any t ≥ t0 , using the fact that Et w̄t+j = 0 for any t ≥ t0 and any j ≥ 1. But if k1 = ñ,
Ωt is a null matrix, and (3.20) also implies that Et zt+ñ = 0 in this case as well. Hence the
target criterion (3.20) implies condition (3.17). Then by Lemma 5, the fact that (3.16) and
(3.17) hold for all t ≥ t0 implies that (3.8) holds for all t ≥ t0 .
    Recall from (A.68) that condition (3.20) also implies
                                                               ñ−k1 −j
                                                    −(k1 +j)
                                                                X
                       Et zt+k1 +j−1 = (−β)                               (−β)−i φ0j+i w̄t−i
                                                                 i=0


                                                         63
for any t ≥ t0 and any 1 ≤ j ≤ ñ − k1 . It follows that for all t > t0 and all 1 ≤ j ≤ ñ − k1 :

                        Et zt+k1 +j−1 − Et−1 zt+k1 +j−1 = (−β)−(k1 +j) φ0j w̄t

so that                                                                  
                                     (−β) [zt − Et−1 zt ]
                                             ..                          
                                              .                           ·     ¸
                                                                         
                          (−β)k1 [Et zt+k1 −1 − Et−1 zt+k1 −1 ]             Ik1
                    wt ≡                                                 =        w̄t .
                          (−β)k1 +1 [Et zt+k1 − Et−1 zt+k1 ]                 Φ
                                            ..                           
                                             .                           
                              (−β)ñ [Et zt+ñ−1 − Et−1 zt+ñ−1 ]
Premultiplying by V2 implies in turn that
                                                        ·          ¸
                                                            Ik1
                                  V2 wt = [V21 V22 ]                   w̄t = 0
                                                             Φ

for any t > t0 . For the process {ϕ̂1,t } given by (3.16) for all t ≥ t0 , we can apply Lemma 13
to express wt as                              £               ¤
                                    wt = − ϕ̂1,t − Et−1 ϕ̂1,t
for all t ≥ t0 . Since V2 wt = 0 for any t > t0 , equation (3.11) must hold for all t > t0 .
    To show that the initial condition (3.13) also holds, where the vector Ξ1,t0 −1 is defined
by (3.21), note that (A.68) implies
                                                        ñ−k1 −j
                                                         X
                        (−β)k1 +j Et0 zt0 +k1 +j−1 =               (−β)−i φ0j+i w̄t0 −i
                                                            i=0


for any 1 ≤ j ≤ ñ − k1 . Subtracting φ0j w̄t0 + (−β)k1 +j Et0 −1 zt0 +k1 +j−1 on both sides (where
again expectations taken at date t0 − 1 denote historical forecasts) yields

                −φ0j w̄t0 + (−β)k1 +j [Et0 zt0 +k1 +j−1 − Et0 −1 zt0 +k1 +j−1 ] = −χjt0 −1

where χjt0 −1 is the j-th element of the vector χt0 −1 , defined in (3.22). Since the previous
expression holds for any 1 ≤ j ≤ ñ − k1 , we may rewrite it in matrix form as

                                     [−Φ Iñ−k1 ] wt0 = −χt0 −1 ,

using definition (3.18). Using again definition (3.18) and Lemma 13 we can equivalently
rewrite this as                       £                      ¤
                          [−Φ Iñ−k1 ] ϕ̂1,t0 − Et0 −1 ϕ̂1,t0 = χt0 −1 ,
or as                                               £      ¤
                               V2 ϕ̂1,t0 = V2 Et0 −1 ϕ̂1,t0 + V22 χt0 −1 ,
after premultiplying on both sides by V22 . Using (3.16) to replace ϕ̂1,t0 with βEt0 [Γ(βL−1 )τ̂ 1,t0 ]
on the right-hand side yields the initial condition (3.13), where the vector Ξ1,t0 −1 is defined
by (3.21).

                                                   64
B     Linearization of the FOCs
Appendix available online.


C     Second-Order Conditions
Appendix available online.


D     Real Kronecker Canonical Form
Appendix available online.


E     Target Criterion in Model of Section 4
E.1    Some Details on the Model
In this model, each household seeks to maximize its lifetime utility
                              ∞
                              X                 ·                      Z       1                           ¸
                                         t−t0
                        Et0          β              ũ (Ct ; ξ t ) −               ṽ (ht (j) ; ξ t ) dj
                              t=t0                                         0

             hR             iθ/(θ−1)
                1
where Ct ≡ 0 ct (i)(θ−1)/θ           is a Dixit-Stiglitz aggregate of consumption of each of a
continuum of differentiated goods, with an elasticity of substitution θ > 1, and ht (j) is the
quantity supplied of labor of type j. Each differentiated good is supplied by a single mo-
nopolistically competitive producer who uses labor of a particular type. The representative
household supplies all types of labor. The preference functions are assumed to be of the form
                                     −1         −1
                               C 1−σ̃ C̄tσ̃                         λ
               ũ (Ct ; ξ t ) ≡ t       −1  , ṽ (ht (j) ; ξ t ) ≡     ht (j)1+ν h̄−ν
                                                                                   t
                                 1 − σ̃                            1+ν
                        ©       ª
where σ̃, ν > 0, and C̄t , h̄t are exogenous disturbance processes included in the vector ξ t ,
which is assumed to be bounded up to some date T, and constant for all t > T.
   Each specialized good is produced according to the production function

                                                yt (i) = At ht (i)1/φ

where At is an exogenously varying technology factor (also included in the vector ξ t ), and
φ > 1. Implicitly, we consider other factors of production such as the capital stock as
being constant or exogenously varying. Aggregate output Yt in turn relates to consumption
according to
                                      Yt = Ct + Gt
where Gt denotes exogenous government demand for the composite good and is also included
in the vector ξ t .

                                                              65
    As Benigno and Woodford (2005) show, the utility of the representative household, which
is also the policymaker’s welfare objective function, can be expressed in the form (1.1) where
the period t utility is
                       π (yt , ξ t ) = U (Yt , ∆t ; ξ t ) ≡ u (Yt ; ξ t ) − v (Yt ; ξ t ) ∆t ,              (E.1)
where
                   u (Yt , ξ t ) ≡ ũ (Yt − Gt , ξ t ) ,        v (Yt ; ξ t ) ≡ ṽ((Yt /At )φ ; ξ t )
express utility as functions of aggregate output and have the properties σ −1 ≡ −uY Y Ȳ /uY =
σ̃ −1 Ȳ /C̄ > 0, ω ≡ vY Y Ȳ /vY = vY Ȳ /v − 1 > 0, and
                                          Z 1µ         ¶−θ(1+ω)
                                                pt (i)
                                   ∆t ≡                         di ≥ 1
                                           0     Pt
is measure of price dispersion at date t, where pt (i) denotes the price of individual good i
           hR          i1/(1−θ)
              1
and Pt ≡ 0 pt (i)1−θ            is a Dixit-Stiglitz price index.
    The producers are wage takers on the labor market and choose their prices to maximize
the present discounted value of future after-tax nominal profits. As in Calvo’s (1983) model
of staggered pricing, we assume that producers fix the prices of their goods for a random
interval of time, and that a constant fraction α ∈ [0, 1) of prices remain unchanged in any
given period. As shown in Benigno and Woodford (2005), since all suppliers that revise their
prices in period t face the same problem, they all choose the same new price p∗t satisfying
the first-order condition                      µ ¶ 1+ωθ   1
                                         p∗t      Kt
                                             =                                              (E.2)
                                         Pt       Ht
where
                           "∞                                                             #
                            X
                Ht ≡ Et          (αβ)T −t (1 − ς T ) · uY (YT , ξ T ) · YT · (PT /Pt )θ−1
                            " T∞
                               =t
                                                                                                        #
                             X                  θµw
              Kt ≡ Et                (αβ)T −t     T
                                                    · vY (YT , ξ T ) · YT · (PT /Pt )θ(1+ω)
                              T =t
                                                θ−1

and ς t ∈ [0, 1) is an exogenous tax rate on sales revenues and µwt ≥ 1 is an exogenous markup
factor on the labor market.
    The price index in turn evolves according to a law of motion
                                    £                       ¤
                                                        1−θ 1/(1−θ)
                              Pt = (1 − α) p∗1−θ
                                              t    + αPt−1          .                     (E.3)
Combining (E.2) with (E.3) yields
                                                                µ        ¶ 1+ωθ
                                                                            θ−1
                                         1 − αΠθ−1
                                               t                    Ht
                                                   =                                                        (E.4)
                                           1−α                      Kt
where Πt ≡ Pt /Pt−1 is the gross inflation rate. This expression is a short-run aggregate supply
relation between inflation and output, given the current disturbances ξ t and expected future
inflation, output, and disturbances.

                                                           66
    Using again (E.3), we can also obtain an expression for the evolution of the measure of
price dispersion
                                                   µ           ¶ θ(1+ω)
                                  θ(1+ω)             1 − αΠθ−1
                                                           t
                                                                   θ−1

                     ∆t = α∆t−1 Πt       + (1 − α)                      .             (E.5)
                                                       1−α
    We assume that the government imposes lump-sum taxes on households so as to guarantee
its intertemporal solvency regardless of monetary policy actions. In addition, we abstract
from monetary frictions that would generate a demand for money, and assume that the
policymaker can control the riskless short-term nominal interest rate and that the lower
bound on nominal interest rates never binds. While the optimal intertemporal allocation of
households’ expenditures determines period-t output as a function of expectations of future
output, inflation and the nominal interest, this doesn’t constitute a constraint on the policy
problem as the central bank can always choose a nominal interest rate that satisfies this
equation. As a result, the only relevant constraints facing the policymaker are given by
(E.4) and (E.5). While the former prevents the central bank from simultaneously stabilizing
inflation and output, the latter determines the evolution of the price dispersion, i.e., a key
source of welfare losses.
    It will be convenient to rewrite the expressions for Ht , Kt in recursive form as in (4.2),
(4.3), and to use (E.4) to substitute for the variable Πt from the system. The resulting
restrictions (E.5), (4.2)–(4.3) can then be expressed as in (1.2)–(1.3) where

                              F (yt , ξ t ; yt−1 ) ≡ −∆t + fˇ (∆t−1 , Zt )                                                   (E.6)
                              g (yt , ξ t ; yt+1 ) ≡ ǧ(Yt , ξ t ) − Zt + αβΦ(Zt+1 )                                         (E.7)

where
                                "                µ           θ−1 # θ−1
                                                          ¶ 1+ωθ  θ(1+ω)
                                                                                         µ        ¶ θ(1+ω)
                                    1 1−α            Ht                                      Ht      1+ωθ
fˇ (∆t−1 , Zt ) ≡ α∆t−1               −                                    + (1 − α)
                                    α   α            Kt                                      Kt
                                                                                µ                  ³           θ−1 ¶
                                                                                                             ´ 1+ωθ               
                                                                                     1        1−α       Ht
                      ·                                  ¸                          α
                                                                                         −     α        Kt
                                                                                                                        Ht        
                          (1 − ς t ) uY (Yt , ξ t ) Yt                                                                           
    ǧ(Yt , ξ t ) =          θµw                             ,        Φ(Zt ) =  µ             ³           θ−1 ¶
                                                                                                        ´ 1+ωθ     θ(1+ω)         .
                                 v (Yt , ξ t ) Yt
                             θ−1 Y                                              1       1−α       Ht
                                                                                                                     θ−1          
                                                                                 α
                                                                                     −    α        Kt
                                                                                                                             Kt

and the vector of endogenous variables is given by yt ≡ [Yt , ∆t , Ht , Kt ]0 , while Zt ≡ [Ht , Kt ]0
is a subset of the endogenous variables.

E.2     Steady State
We now show that an optimal steady state exists in which the
                                                         ¡ inflation¢    rate is zero (Π̄ = 1).
The optimal steady state is described by constant vectors ȳ, ϕ̄, ξ̄ satisfying (1.10)–(1.12),




                                                                 67
or, in this model,
                                                             ¡        ¢
                                                    −∆¯ + fˇ ∆,¯ Z̄       = 0              (E.8)
                                        ǧ(Ȳ , ξ̄) − Z̄ + αβΦ(Z̄)        = 0              (E.9)
                                        ¡           ¢
                                    UY Ȳ , ∆; ¯ ξ̄ + ǧY (Ȳ , ξ̄)0 Θ̄   = 0             (E.10)
                              ¡        ¢ ¡            ¡     ¢      ¢
                                   ¯ ξ̄ + β fˇ∆ ∆,
                           U∆ Ȳ , ∆;                   ¯ Z̄ − 1 θ̄       = 0             (E.11)
                                ¡     ¢         ¡                 ¢
                            fˇZ ∆,¯ Z̄ 0 θ̄ + αΦZ (Z̄)0 − I2 Θ̄           = 0,            (E.12)

where Z̄ = [H̄, K̄]0 together with the steady-state versions of equation (E.4). We proceed by
conjecturing that the solution involves Π̄ = 1, and showing that a solution can be constructed
that satisfies all of the equations just listed.
   We first observe that (E.4) implies that a steady state with Π̄ = 1 must satisfy H̄ = K̄.
Given this, (E.8) requires that ∆ ¯ = 1, so that there is zero price dispersion. Condition (E.9)
holds as well if and only if Ȳ is the output level implicitly defined by
                                         ¡    ¢   θµ̄w    ¡      ¢
                            (1 − ς) uY Ȳ , ξ̄ =       vY Ȳ , ξ̄ ,                       (E.13)
                                                  θ−1
                            w   ¡       ¢
and H̄ = K̄ = (1 − αβ)−1 θµ   vY Ȳ , ξ̄ Ȳ .
              ¡     ¢     θ−1
   Because fˇZ 1, Z̄ = 0, (E.12) reduces to the eigenvector equation
                                   ¡               ¢
                                     αΦZ (Z̄)0 − I2 Θ̄ = 0                                (E.14)

where                                "                                          #
                                                θ(α−1)(ω+1)
                                         1
                                         α
                                             +    α(θω+1)
                                                                − (θ−1)(α−1)
                                                                    α(θω+1)
                        ΦZ (Z̄) =            θ(α−1)(ω+1)                            .
                                               α(θω+1)
                                                              1 − θ(α−1)(ω+1)
                                                                     α(θω+1)

Since ΦZ (Z̄)0 has an eigenvector [−1, 1]0 , with eigenvalue 1/α, (E.14) is satisfied if and only
if Θ̄2 = −Θ̄1 .
    ¡Conditions
         ¢      (E.10)–(E.11) in turn allow us to determine the values θ̄, Θ̄. Given that
 ˇ    ¯
f∆ ∆, Z̄ = α and
                                            ·         ¡              ¢ ¸
                                              (1 − ς)¡ uY Y Ȳ + u¢Y
                            ǧY (Ȳ , ξ̄) =     θµw
                                                θ−1
                                                      vY Y Ȳ + vY
we obtain                     ¡        ¢
                             v Ȳ , ξ̄                                  Ψ
                      θ̄ = −             ,       Θ̄1 = −Θ̄2 =                       ,
                             1 − αβ                             (1 − ς) (ω + σ −1 )
where
                                                      θ−11−ς
                                             Ψ≡1−
                                                       θ  µw
is a measure of the degree of inefficiency of the steady-state output level Ȳ . Here we use
the fact that UY = uY − vY = ΨuY and uY Y − vY Y = − uYȲ Y (ω (1 − Ψ) + σ −1 ) . (The first of
these equations explains our interpretation of Ψ as a measure of the degree of inefficiency: a
positive value of Ψ indicates that utility would be increased by raising Ȳ , maintaining zero
price dispersion and hence an equal level of production of each of the differentiated goods.)

                                                      68
E.3         Canonical Decomposition of Ā − µI¯
Evaluating the derivatives of F () and g () at the steady state, we can then construct the
matrices Ā and I¯ :
                                                   
                 ·         ¸       0 αβ 0        0
                    βD3 F
         Ā ≡                =  a21 0 −1 0 
                     D1 g
                                 a31 0     0 −1
                                                                                 
                 ·           ¸      0 β           0                    0
                    −βD1 F
          I¯ ≡
                                                 β(1−α)(θ−1)
                               =  0 0 −αβ +        1+ωθ
                                                                − β(1−α)(θ−1)
                                                                      1+ωθ
                                                                                  ,
                     −D3 g                  β(1−α)θ(1+ω)             β(1−α)θ(1+ω)
                                    0 0         1+ωθ
                                                             −αβ −       1+ωθ

where                            ¡         ¢
                 a21 = (1 − ς) uY 1 − σ −1 ,     a31 = (1 − ς) uY (1 + ω) .
The matrix pencil Ā − µI¯ pencil satisfies Assumption 2. We first determine the minimal
                                                ¯ Following Gantmacher (1959, chap. 12,
degree associated with the matrix pencil Ā − µI.
p. 30), the minimal degree of the matrix pencil Ā − µI¯ is the least value of the index l for
which the rank of the matrix
                                                     l+1
                                        z
                                            }|              {
                                       Ā 0 ··· 0
                                      ¯              ..     
                                      −I Ā           .     
                                               .            
                                Ml = 
                                      0 −I¯ . . 0
                                                             
                                                             
                                      .        ..           
                                      ..          . Ā      
                                        0 0 · · · −I¯
satisfies
                                   rank (Ml ) < (l + 1) m.
We observe that rank(M0 ) = 4 = (0 + 1) 4, rank(M1 ) = 8 = (1 + 1) 4, but that rank(M2 ) =
11 < (2 + 1) 4 = 12. The minimal degree of the matrix pencil Ā − µI¯ is therefore ñ = 2, so
that q = n − ñ = 1.
   It follows from Lemma 3 that there exist nonsingular matrices P and Q of dimensions
3 × 3 and 4 × 4 respectively that satisfy
                                                          
                                            µ 0      0
                                                          
                                  ¯ 0 = Q 1 µ
                           (Ā − µI)
                                                     0      P.
                                           0 1      0     
                                                   0     0
                                            0 0 B2 − µJ2
These matrices are given by
                                  
               1      0 a21 a31                                                         
                                               0 βa21 (α + 1) − q23 βa31 (α + 1) − q24
          β (1 +   α) 0 q23 q24
 Q−1 = 
                2
                                   ,
                                           P = 0       αβ 2 a21           αβ 2 a31     
             αβ       0 0    0
                                                 β         0                  0
               0      1 0    0
where rank(Q−1 ) = 4 and rank(P ) = 3, and q23 , q24 satisfy q23 − q24 = αβ (a21 − a31 ) . We
also have B2 = α and J2 = 1.

                                                69
E.4      Target Variables
When evaluating the second derivatives of F () , g () and the objective function π () at the
optimal steady state, the target variables τ t and the target values τ ∗t are given by

                         τ t = −[S ỹt + Rỹt−1 + βR0 Et ỹt+1 ]
                                © £          ¤ ¡          ¢      £ ¤ª
                         τ ∗t = D2 (D1 π)0 + Θ̄0 ⊗ I4 D2 (D1 g)0 ξ̃ t ,

where the matrices S and R reduce to
                 £         ¤           £         ¤ ¡              ¢© £          ¤          £          ¤ª
       S ≡ D1 (D1 π)0 + θ̄D1 (D1 F )0 + Θ̄0 ⊗ I4 D1 (D1 g)0 + β −1 D3 (D3 g)0
                                                                                   
                 UY Y + Θ̄0 ǧY Y UY ∆                          01×2
           =          U∆Y              0            ¡       ¢ 01×2
                                                                  ¡ 0      ¢
                                                                                    ,
                        0               0       ˇ      ¯
                                              θ̄fZZ ∆, Z̄ + Θ̄ ⊗ I2 αΦZZ
                                   ·                                   ¸
                   £         0¤       02×1          02×1          02×2
      R ≡ θ̄D3 (D1 F ) =                              ¡       ¢
                                      02×1 θ̄fˇZ∆ ∆,    ¯ Z̄ 02×2 .
                                                                                  £      ¤             £   ¤
Here, £we use properties
               ¤          of
                          £    the second
                                     ¤       derivatives
                                                  £         of
                                                             ¤ F () and g (): D3 (D3 F )0 = 0, D2 (D1 F )0 =
0, D2 (D3 F )0 = 0, D1 (D3 g)0 = 0, D2 (D3 g)0 = 0, and
                                    · 0                  ¸                               · 0           ¸
      ¡ 0      ¢     £        0¤       Θ̄ ǧY Y     0           ¡ 0      ¢    £       0¤     Θ̄ ǧY ξ
        Θ̄ ⊗ I4 D1 (D1 g) =                                ,     Θ̄ ⊗ I4 D2 (D1 g) =                     ,
                                          0       03×3                                       03×nξ

where ǧY Y = ∂ǧY (Ȳ , ξ̄)/∂Y, ǧY ξ = ∂ǧY (Ȳ , ξ̄)/∂ξ 0 . Similarly, we use
                                                       ·                              ¸
                       ¡ 0       ¢      £      0¤        02×2 ¡         02×2
                         Θ̄ ⊗ I4 D3 (D3 g) =                              ¢
                                                         02×2 Θ̄0 ⊗ I2 αβΦZZ
                     ¡         ¢
where ΦZZ = ∂vec ΦZ (Z̄)0 /∂Z 0 . Moreover, since
                                                                                         
                 © £            ¤     ¡         ¢      £         ¤ª      UY ξ + Θ̄0 ǧY ξ
                   D2 (D1 π)0 + Θ̄0 ⊗ I4 D2 (D1 g)0 =                        U∆ξ         ,
                                                                              02×1

we can express the target gaps as
                               ¡                 ¢                  ¡              ¢          
                                                              ˜ t + UY ξ + Θ̄0 ǧY ξ ξ̃ t
                                  UY Y + Θ̄0 ǧY Y Ỹt + UY ∆ ∆
                                                       ¡     ¢ 0
        τ t − τ ∗t = −                             ˇ    ¯                                     .
                         ¡         ¡ U∆Y¢Ỹt +¡ β f0 Z∆ ∆,
                                                         ¢ Z̄ θ̄E             ¡ ξ̃ t ¢
                                                                 ¢ t Z̃t+1 + U∆ξ
                           θ̄fˇZZ ∆, ¯ Z̄ + Θ̄ ⊗ I2 αΦZZ Z̃t + θ̄fˇZ∆ ∆,       ¯ Z̄ ∆    ˜ t−1

    Linearizing the relationship implicitly defining Yt∗ , (4.6), we have
                                                     ³                       ´
                          UY Y Ỹt∗ + UY ξ ξ̃ t + Θ̄0 ǧY Y Ỹt∗ + ǧY ξ ξ̃ t = 0,

where Ỹt∗ = Yt∗ − Ȳ . This allows us to rewrite the first element of τ t − τ ∗t as
                                 ¡                 ¢
                                                                 ˜ t,
                                   UY Y + Θ̄0 ǧY Y Ȳ xt + UY ∆ ∆

                                                      70
                             ³        ´
where xt = log (Yt /Yt∗ ) = Ỹt − Ỹt∗ /Ȳ + O(²2 ) measures the welfare-relevant output gap.
The target gaps τ t − τ ∗t can further be simplified, by noting that a linear approximation of
(E.4) yields
                                            1−α       ³           ´
                                 πt = −                 H̃t − K̃t
                                        (1 + ωθ) αK̄
where π t ≡ log Πt . Using this and the fact that Θ̄1 = −Θ̄2 , we obtain
                                                               ·       ¸
                                 ¡    ¢            1               1
                             ˇ     ¯
                            fZZ ∆, Z̄ Z̃t = − θ (1 + ω)                  πt
                                                  K̄              −1
                                                            ·        ¸
                        ¡ 0      ¢                               1
                         Θ̄ ⊗ I2 αΦZZ Z̃t = Θ̄1 θ (ω + 1)              πt,
                                                               −1
so that the target gaps can be rewritten as
                                    ¡                 ¢                           
                                                                     ˜t
                                       UY Y + Θ̄0 ǧY Y Ȳ xt + UY ∆ ∆
                                                ¡
                             U∆Y Ỹt + β fˇZ∆ ∆,        ¢ 0                       
                                                    ¯ Z̄ θ̄Et Z̃t+1 + U∆ξ ξ̃ t
                                         ³³           ´                    ´      
                τt − τt = − 
                      ∗
                                                                 (1−α) ˜
                             θ (ω + 1) Θ̄1 − K̄θ̄ π t − K̄θ̄ (1+θω)   ∆t−1
                                                                                   .
                                                                                        (E.15)
                                          ³³           ´                      ´   
                                                                  (1−α) ˜
                              −θ (ω + 1) Θ̄1 − K̄θ̄ π t − K̄θ̄ (1+θω)   ∆t−1

E.5     Optimal Target Criterion
Since k1 = 0, the general optimal target criterion (3.20) reduces to
                                     £                      ¤
                            0 = zt ≡ 1 −β −1 L β −2 L2 τ̂ 1t ,
where                                     £         ¤
                                τ̂ 1t =       Im−q 0 Q−1 (τ t − τ ∗t ) .
Combining this with (E.15), we obtain
             £                                                             ¤
      0 =      1 − (1 + α) L + αL2 0 a21 − q23 β −1 L a31 − q24 β −1 L (τ t − τ ∗t )
                                ³¡              ¢                ´
                                           0
         = (1 − αL) (1 − L) UY Y + Θ̄ ǧY Y Ȳ xt + UY ∆ ∆t   ˜
                                               µµ           ¶                      ¶
                                                         θ̄         θ̄ (1 − α) ˜
             + (a21 − a31 ) (1 − αL) θ (ω + 1)    Θ̄1 −       πt −             ∆t−1 , (E.16)
                                                        K̄         K̄ (1 + θω)
using (q23 − q24 ) = αβ (a21 − a31 ) to obtain the last equality.
    Noting furthermore that a first-order approximation of (E.6) around the optimal steady
state yields                              ¡     ¢            ¡     ¢
                          0 = −∆ ˜ t + fˇ∆ ∆,
                                            ¯ Z̄ ∆˜ t−1 + fˇZ ∆,
                                                               ¯ Z̄ Z̃t
or
                                        (1 − αL) ∆ ˜t = 0
for all t, we observe that the variable ∆˜ t drops out from the target criterion, so that (E.16)
reduces to
                    ·                                                     µ           ¶ ¸
                      ¡        0
                                    ¢                                              θ̄
     0 = (1 − αL) UY Y + Θ̄ ǧY Y Ȳ (1 − L) xt + (a21 − a31 ) θ (ω + 1) Θ̄1 −         πt ,
                                                                                  K̄

                                                     71
or equivalently
                              0 = (1 − αL) (π t + φ (1 − L) xt ) ,
where the weight φ on changes in output gap fluctuations is given by
                  ¡            ¢                                       Ψσ −1 (Ȳ /C̄−1)
               UY Y + Θ̄0 ǧY Y Ȳ          ω + σ −1 + Ψ (1 − σ −1 ) −     ω+σ −1
    φ=                         ³         ´=               −1             −1
                                                                                        .   (E.17)
       (a21 − a31 ) θ (ω + 1) Θ̄1 −   θ̄          θ (ω + σ + Ψ (1 − σ ))
                                      K̄


To obtain the second equality in (E.17), we use (E.13) and the properties of the prefer-
                         2      ¡             ¢              2
ence functions uY YuYY Ȳ = σ −1 σ −1 + Ȳ /C̄ and vY YvYY Ȳ = ω (ω − 1) . We thus obtain the
representation (4.5) for the optimal target criterion, as stated in the text.




                                               72
References
 [1] Anderson, Brian D.O., and John B. Moore, Optimal Filtering, Englewood Cliffs, NJ:
     Prentice Hall, 1979.

 [2] Backus, David, and John Driffill, “The Consistency of Optimal Policy in Stochastic
     Rational Expectations Models,” CEPR Discussion Paper no. 124, August 1986.

 [3] Benigno, Pierpaolo, and Michael Woodford, “Inflation Stabilization and Welfare: The
     Case of a Distorted Steady State,” Journal of the European Economic Association 3:
     1185-1236 (2005).

 [4] Benigno, Pierpaolo, and Michael Woodford, “Linear-Quadratic Approximation of Op-
     timal Policy Problems,” NBER working paper no. 12672, revised August 2008.

 [5] Calvo, Guillermo (1983), “Staggered Prices in a Utility-Maximizing Framework,” Jour-
     nal of Monetary Economics, 12: 383-398.

 [6] Clarida, Richard, Jordi Galı́ and Mark Gertler, “The Science of Monetary Policy: A
     New Keynesian Perspective,” Journal of Economic Literature 37: 1661-1707 (1999).

 [7] Currie, David, and Paul Levine, Rules, Reputation and Macroeconomic Policy Coordi-
     nation, Cambridge: Cambridge University Press, 1993.

 [8] Gantmacher, Felix R., The Theory of Matrices, Volume 2, Providence, Rhode Island:
     AMS Chelsea Publishing, 1959.

 [9] Giannoni, Marc P., and Michael Woodford, “Optimal Interest-Rate Rules: I. General
     Theory,” NBER working paper no. 9419, January 2003a.

[10] Giannoni, Marc P., and Michael Woodford, “How Forward-Looking is Optimal Mone-
     tary Policy?” Journal of Money, Credit and Banking 35: 1425-1469 (2003b).

[11] Giannoni, Marc P., and Michael Woodford, “Optimal Inflation Targeting Rules,” in B.S.
     Bernanke and M. Woodford, eds., The Inflation Targeting Debate, Chicago: University
     of Chicago Press, 2005.

[12] Hansen, Lars P., and Thomas J. Sargent, Recursive Linear Models of Dynamic
     Economies, forthcoming, Princeton NJ: Princeton University Press, 2010.

[13] Khan, Aubhik, Robert G. King, and Alexander L. Wolman, “Optimal Monetary Policy,”
     Review of Economic Studies 70: 825-860 (2003).

[14] Marcet, Albert, and Ramon Marimon (1998), “Recursive Contracts,” Universitat Pom-
     peu Fabra working paper no. 337, October.

[15] Pappas, Thrasyvoulos, Alan J. Laub, and Nils R. Sandell (1980), “On the Numeri-
     cal Solution of the Discrete-Time Algebraic Riccati Equation,” IEEE Transactions on
     Automatic Control, AC25(4), pp. 631-641.


                                           73
[16] Svensson, Lars E.O., “Inflation Forecast Targeting: Implementing and Monitoring In-
     flation Targeting,” European Economic Review 41: 1111-1146 (1997).

[17] Svensson, Lars E.O., “Monetary Policy with Judgment: Forecast Targeting,” Interna-
     tional Journal of Central Banking 1: 1-54 (2005).

[18] Svensson, Lars E.O., and Michael Woodford, “Implementing Optimal Policy through
     Inflation-Forecast Targeting,” in B.S. Bernanke and M. Woodford, eds., The Inflation
     Targeting Debate, Chicago: University of Chicago Press, 2005.

[19] Woodford, Michael, “Commentary: How Should Monetary Policy Be Conducted in an
     Era of Price Stability?” in New Challenges for Monetary Policy, Kansas City: Federal
     Reserve Bank of Kansas City, 1999.

[20] Woodford, Michael, Interest and Prices: Foundations of a Theory of Monetary Policy,
     Princeton: Princeton University Press, 2003.

[21] Woodford, Michael, “Forecast Targeting as a Monetary Policy Strategy: Policy Rules
     in Practice,” NBER working paper no. 13716, December 2007.




                                           74
