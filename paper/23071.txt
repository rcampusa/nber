                                NBER WORKING PAPER SERIES




                             ONE IN A MILLION:
FIELD EXPERIMENTS ON PERCEIVED CLOSENESS OF THE ELECTION AND VOTER TURNOUT

                                           Alan Gerber
                                         Mitchell Hoffman
                                          John Morgan
                                         Collin Raymond

                                        Working Paper 23071
                                http://www.nber.org/papers/w23071


                       NATIONAL BUREAU OF ECONOMIC RESEARCH
                                1050 Massachusetts Avenue
                                  Cambridge, MA 02138
                              January 2017, Revised June 2017


   We thank Jason Abaluck, Stefano DellaVigna, Fred Finan, Sean Gailmard, Don Green, Jennifer
   Green, Gianmarco Leon, Yusufcan Masatlioglu, Ted Miguel, Ismael Mourifie, David Myatt,
   Matthew Rabin, Gautam Rao, Jesse Shapiro, Richard Thaler, Francesco Trebbi, Rob Van
   Houweling, Leonard Wantchekon, and seminar participants at Berkeley (political economy
   seminar and psychology & economics seminar), CIFAR, Florida State, Ohlstadt, Oxford, Pitt
   Behavioral Models of Politics Conference, Princeton, SITE (Experimental Economics), Toronto,
   Toronto Rotman, and Yale for helpful comments. We are grateful to Dan Biggers for his
   guidance on the 2014 experiment. David Arnold, Christina Chew, Sandrena Frischer, Hongjia
   Hu, Faisal Ibrahim, Jeffrey Kong, Will Kuffel, Cara Lew, Elena Litvinova, Melina Mattos, Kevin
   Rapp, Nick Roth, and Irina Titova provided outstanding research assistance. Financial support
   from the National Science Foundation, the Haas School of Business, the Center for Equitable
   Growth, the Burch Center, and the Social Science and Humanities Research Council of Canada is
   gratefully acknowledged. The views expressed herein are those of the authors and do not
   necessarily reflect the views of the National Bureau of Economic Research.

   NBER working papers are circulated for discussion and comment purposes. They have not been
   peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
   official NBER publications.

   © 2017 by Alan Gerber, Mitchell Hoffman, John Morgan, and Collin Raymond. All rights
   reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit
   permission provided that full credit, including © notice, is given to the source.
One in a Million: Field Experiments on Perceived Closeness of the Election and Voter Turnout
Alan Gerber, Mitchell Hoffman, John Morgan, and Collin Raymond
NBER Working Paper No. 23071
January 2017, Revised June 2017
JEL No. D03,D72,H10,P16

                                            ABSTRACT

A common feature of many models of voter turnout is that increasing the perceived closeness of
the election should increase voter turnout. However, cleanly testing this prediction is difficult and
little is known about voter beliefs regarding the closeness of a given race. We conduct a field
experiment during the 2010 US gubernatorial elections where we elicit voter beliefs about the
closeness of the election before and after showing different polls, which, depending on treatment,
indicate a close race or a not close race. We find that subjects update their beliefs in response to
new information, but systematically overestimate the probability of a very close election.
However, the decision to vote is unaffected by beliefs about the closeness of the election. A
follow-up field experiment, conducted during the 2014 gubernatorial elections but at much larger
scale, also points to little relationship between poll information about closeness and voter turnout.


Alan Gerber                                       John Morgan
Yale University                                   Haas School, UC, Berkeley
Institution for Social and Policy Studies         545 Student Services Building, #1900
77 Prospect Street                                Berkeley, CA 94720-1900
New Haven, CT 06520                               morgan@haas.berkeley.edu
and NBER
alan.gerber@yale.edu                              Collin Raymond
                                                  Department of Economics
Mitchell Hoffman                                  Amherst College
Rotman School of Management                       305 Converse Hall
University of Toronto                             Amherst, MA 01002
105 St. George Street                             craymond@amherst.edu
Toronto, ON M5S 3E6
CANADA
and NBER
mitchell.hoffman@rotman.utoronto.ca




An online appendix is available at http://www.nber.org/data-appendix/w23071
1    Introduction

A core question in political economy is why do people vote. In classic instrumental models
of voting, such as the private values model introduced by Downs (1957) and Riker and Or-
deshook (1968) and the common values setting of Feddersen and Pesendorfer (1996), natural
assumptions lead to the prediction that individuals are more likely to vote when they believe

the election to be close. Moreover, even in some of the leading alternative models such as
the “ethical voter” framework of Feddersen and Sandroni (2006) or the signalling model of
Razin (2003), where pivotality does not directly inﬂuence the decision to vote, turnout may
still inﬂuenced by beliefs about the margin of victory.

     Researchers have employed two main approaches to test the prediction that increases

in the perceived closeness of the election increases turnout. The ﬁrst vein, as surveyed by
Cancela and Geys (2016), uses observational data from real-world elections, and shows that
turnout tends to increase in measures of actual or predicted closeness across elections. How-
ever, as noted by Shachar and Nalebuﬀ (1999) and Shachar (2007), it is hard to interpret

any estimated eﬀects as supporting theory, as numerous other factors are correlated with an
election being close (e.g., greater voter mobilization by elites and greater media coverage).

Further, observational closeness may be correlated with information asymmetries (Battaglini
et al., 2010). The second vein (e.g., Levine and Palfrey, 2007; Duﬀy and Tavits, 2008; Großer
and Schram, 2010; Agranov et al., Forthcoming) uses lab experiments to more cleanly identify

the causal eﬀect of beliefs or to study the impact of polls. However, these experiments abstract
from the context of real-life elections and so may fail to account for the various factors that
are salient outside the lab. Perhaps in part due to these challenges, recent empirical work on
voter turnout has often focused on testing non-instrumental models, e.g., that turnout reﬂects
conﬁdence (Ortoleva and Snowberg, 2015), social incentives (DellaVigna et al., 2017), habit
(Fujiwara et al., 2016), or the media (Gentzkow et al., 2011; Spenkuch and Toniatti, 2016).
     To provide a cleaner test of theory and to understand how voters form beliefs about

the closeness of elections, we combine the two approaches. We conduct two large-scale ﬁeld


                                               1
experiments in the US that exogenously shift voters’ beliefs about the election being close. In
both experiments, we ﬁnd no evidence that believing the election is close raises turnout. This
suggests that, for the case of large US elections, beliefs about the closeness of an election are
not a main driver of voter turnout.

     The ﬁrst experiment was conducted during the 2010 U.S. gubernatorial election cycle and
included over 16,000 voters. As described in Section 3, using computer surveys in 13 US states,
we asked potential voters to predict the vote margin, as well as their beliefs about the chance
that the governor’s race would be very close (e.g., decided by less than 100 votes). Exploiting

variation in real-world poll results prior to the election, we divide subjects into groups. We
informed the “Close” group of the results of a poll indicating the narrowest margin between
the two candidates, whereas the “Not Close” group saw a poll indicating the greatest gap
between the candidates. (In addition, there was a third group (“Control”) who received no
poll information and did not get surveyed.) After the election, we used administrative data

to determine whether people actually voted. Using the 6,700 voters for whom we have data
on beliefs, we obtain three main ﬁndings, which we present in Section 4:

  1. Prior to being exposed to polls, most subjects overestimate the probability of a very close

     election. The median probabilities that the gubernatorial election would be decided by
     less than 100 or less than 1,000 votes were 10% and 20%, respectively, much higher than

     the historical averages. While such overestimation of low probabilities has been widely
     observed in other contexts, we are the ﬁrst to precisely estimate its magnitude in the
     context of voting.

  2. Both in terms of margin of victory and the probability of a very close race, voters
     strongly update their beliefs about the closeness of the election in response to polls. For

     example, as a result of receiving a close poll, there was a 2.5 percentage point increase
     in the perceived probability the election would be decided by less than 100 votes, which
     represents a 25% increase relative to the pre-treatment median. Conditional on updating
     at all, there was a 7.3 percentage point increase in the perceived probability the election

                                               2
     would be decided by less than 100 votes.

  3. Most importantly, these changes in beliefs do not translate into behavior as predicted
     by instrumental voting models (even if individuals misperceived probabilities about

     closeness). Although many models imply that belief changes translate into changes
     in turnout, we ﬁnd no such connection—voter turnout is statistically independent of
     beliefs about closeness.

     While the 2010 experiment is able to establish that the eﬀect of beliefs on turnout
is small (if any), a larger sample is required to conﬁdently establish whether the eﬀect is
approximately zero or merely small. To address this, we conducted a second large-scale ﬁeld

experiment during the 2014 gubernatorial elections, described in Section 5. We randomly
mailed postcards to about 80,000 households (about 125,000 individuals) where we again

provided information from the most close or least close poll. Including the control households
that didn’t get postcards, we have a sample size of over 1.38 million voters. In this much

larger sample, we ﬁnd results consistent with the 2010 experiment. Relative to the “not-close
poll” postcard, there was no signiﬁcant impact of the “close poll” postcard on turnout. Based
on our conﬁdence intervals, we can rule out that a close poll (vs. a not-close poll) increases

turnout by more than 0.8 percentage points. (For the remainder of the paper, we abbreviate

percentage points by “pp.”)
     Section 6 presents additional evidence that helps rule out alternative explanations. We

show that our null result is robust to analyzing a person’s immediate voting intentions, thereby
helping address the concern that our null ﬁnding is driven by belief convergence after the
intervention. Our null result is robust to sub-samples that might seem more conducive for
ﬁnding impacts of closeness beliefs on turnout. In our preferred speciﬁcation combining data

from the 2010 and 2014 experiments, with 95% conﬁdence, we can rule out that more than
13% of the observed relationship between actual closeness and turnout is driven by perceptions
of closeness. Thus, the two experiments together provide substantial statistical precision.
     Overall, our results are inconsistent with an electoral calculus whereby voters compute

                                               3
the expected beneﬁt of voting (perhaps incorrectly) and then adjust turnout and voting be-
havior accordingly. Rather, the results seem to suggest that elite mobilization eﬀorts and/or
non-instrumental considerations (e.g., expressive voting) may be important for voter turnout
in large elections (though we are at pains to stress that we have no direct evidence of these

alternative considerations). We view this as an important contribution, as models that incor-
porate instrumental and pivotal motives are still very popular in top journals.1
      A common approach to testing models of turnout is to use observational data. Broadly
consistent with instrumental models, turnout tends to rise in elections that are closer or have
smaller electorates.2 But there are many confounds in comparing turnout across elections.
Close elections tend to have more campaign spending (Cox and Munger, 1989; Matsusaka,

1993; Ashworth and Clinton, 2007), more party contact (Shachar and Nalebuﬀ, 1999; Gimpel
et al., 2007), more campaign appearances (Althaus et al., 2002), and more news coverage

(Banducci and Hanretty, 2014). Like sporting events, tight races may be more interesting to
monitor and discuss than walkovers, and may spur greater attention from one’s friends. Close
elections may spur elites to increase social pressure to vote (Cox et al., 1998); alternatively,
potential impacts of electoral closeness on turnout, even if small, may be ampliﬁed by peer

eﬀects in voting (Bond et al., 2012) or social pressure (Gerber et al., 2008). Thus, it is very

hard to tell whether greater turnout occurs because individuals believe they will have a higher
probability of inﬂuencing the election or because of other reasons correlated with the election
being close (Cox, 1999, 2015).
      One way to try to address these confounds is to consider types of elections where con-
founds seem less likely. For example, in important articles, Coate and Conlin (2004) and Coate
et al. (2008) study small-town liquor ban elections and Hansen et al. (1987) study school ref-
   1
     Appendix Table C1 provides a non-comprehensive list of such papers published in “Top 5” economics jour-
nals in 2000-2015. There are 40+ papers listed, with thousands of Google Scholar citations among them, thus
indicating that instrumental voter models are not a “straw man” with no place in frontier research (Spenkuch
(2017) also makes a similar point). While some of these papers are motivated primarily by committees and
other small elections, many are motivated by trying to explain behavior in large elections.
   2
     Foster (1984) and Matsusaka and Palda (1993) provide surveys of the literature on turnout. Based on
meta-analysis of 83 studies, Geys (2006) concludes that “Turnout is higher when the population is smaller
and the election closer.” Most papers measure closeness using ex post / realized closeness, but Shachar and
Nalebuﬀ (1999) and Bursztyn et al. (2017) show that turnout is also higher when predicted closeness is higher.

                                                      4
erenda, all ﬁnding that turnout decreases with the size of the electorate. However, it is hard
to fully overcome the concern that there could have been greater attempts at mobilization in
races with a smaller electorate (or in closer races). Another promising direction is to exploit
diﬀerences in the availability of poll information, e.g., whether a region votes before or after

exit polls are known (Morton et al., 2015) or whether poll information is available in diﬀerent
regional newspapers (Bursztyn et al., 2017), with both papers ﬁnding results consistent with
instrumental models. However, it is hard to rule out that elites may respond to the presence
of poll information; that newspapers may be more likely to provide polls when there is greater

local interest in a race; or that observed eﬀects of poll-predicted closeness may be largely
driven by social pressure or peer eﬀects (given that treatments are not at the individual level)
as opposed to individual perceptions of closeness.
      A complementary approach to examine whether closeness aﬀects turnout is to use lab
experiments. Though samples are generally small, they can rule out mobilization responses

and other confounds. Duﬀy and Tavits (2008) elicit subjects’ perceived chance of being pivotal
in lab elections, showing that a higher perceived chance of being pivotal is associated with a

higher probability of turning out. Similarly, Levine and Palfrey (2007) ﬁnd strong evidence
of higher turnout in smaller elections and when the election is closer. Großer and Schram
(2010) and Agranov et al. (Forthcoming) expose lab voters to diﬀerent polling information

regarding the distribution of their induced preferences, showing that turnout is higher when

the expected margin of victory is lower.3
      While lab experiments have the advantage of full experimental control, the beneﬁt of ﬁeld

experiments is to capture the context of real-life elections. To our knowledge, our experiments
represent the ﬁrst large-scale ﬁeld experiments that randomly assign polls to voters so as to
examine the impact on turnout.4 In addition, we are aware of very few studies that seek
    3
      Duﬀy and Tavits (2008), Großer and Schram (2010), and Agranov et al. (Forthcoming) vary whether
people are randomly assigned to receive polls, which is ideal for examining whether the presence of polls
aﬀects turnout. In contrast, we additionally randomly vary whether the polls received are close or not close,
allowing us to examine how shocks to beliefs aﬀect turnout. Lab experiments have also been used to test
particular theories of voting, including swing voter theories (Battaglini et al., 2010) and expressive theories
(Tyran, 2004; Shayo and Harel, 2012; Kamenica and Brad, 2014). See Palfrey (2009) for an overview.
    4
      Ansolabehere and Iyengar (1994) randomly assign one of two polls to around 400 voters. They ﬁnd that


                                                      5
to measure or inﬂuence voter beliefs about electoral closeness.5 In removing the confounds
in observational data, our paper provides arguably the ﬁrst direct, large-scale test of the
closeness-turnout comparative static in the literature (economics or political science). Of
course, closeness beliefs may still be important in small elections.

      Arguably most related to our paper is a contemporaneous ﬁeld experiment by Enos and
Fowler (2014), who study a special Massachusetts state house race that ended previously in
a tie. The authors randomly informed some voters by phone both that the previous elec-
tion ended in a tie and that the new election is likely to be close, and, consistent with our

ﬁndings, ﬁnd no impact of the intervention on turnout (except perhaps among a subgroup of
voters with high typical turnout). Our paper goes beyond Enos and Fowler (2014) in several
respects. First, our study directly measures voter beliefs about closeness, allowing us both
to characterize voter beliefs (which is a contribution in itself) and to directly measure how
beliefs aﬀect turnout.6 Second, our sample size is much larger in both of our experiments
(Enos and Fowler (2014) had 936 contacted persons in their data), allowing us substantially

more statistical power. Third, we provide evidence from 20 elections instead of 1 election,
thereby providing greater external validity. Fourth, we consider how our results relate to a
broad range of voting theories.7
the closer poll does not aﬀect whether people intend to vote (measured with a 0/1 variable), consistent with us,
but that it does aﬀect vote choice preferences. Besides being much smaller, this study does not measure actual
turnout, nor does it measure voter beliefs about the probability of a very close race or about predicted margin
of victory (they asked voters, who do you think will win?). Kendall et al. (2015) measure and randomly shock
voters’ subjective beliefs regarding candidate valence and policies (instead of regarding election closeness).
    5
      There is a small literature on “probabilistic polling” that measures voters’ beliefs about the chance they
will turn out or vote for particular candidates (e.g., Delavande and Manski, 2010). However, to our knowledge,
this literature does not measure beliefs about electoral closeness, nor does it experimentally manipulate the
beliefs. Although they do not measure beliefs, Blais and Young (1999) conduct an experiment where they
randomly teach students about the “paradox of voting,” ﬁnding that the experiment decreases turnout by
7pp. However, they interpret their results as operating by aﬀecting respondents’ sense of duty.
    6
      This is important because it enables us to measure how diﬀerent aspects of beliefs aﬀect turnout, including
the predicted vote margin and the probability of a very close election.
    7
      In addition, beyond Enos and Fowler (2014), Gerber and Green (2000) study the eﬀects of diﬀerent
messages in canvassing, telephone calls, and direct mail on turnout. One message is: “Each year some election
is decided by only a handful of votes. Who serves in important national, state, and local oﬃces depends on
the outcome of the election, and your vote can make a diﬀerence on election day.” They ﬁnd no diﬀerential
impact of this “close message” on turnout compared to other messages. However, because their close message
does not provide any information about whether the current race is close, it may have no impact on voters’
beliefs about the closeness of the current race (and there is no way to know if such wording aﬀects closeness
beliefs because beliefs are not measured). Thus, Gerber and Green (2000) do not provide evidence on how


                                                       6
2     Theoretical Considerations

Our main empirical exercise is to study how exogenous changes in beliefs about election
outcomes aﬀect turnout. This section describes verbally to what extent diﬀerent theories of
voting predict a testable prediction (Prediction 1): that seeing a close poll leads to higher
turnout. Accompanying Section 2, Appendix D shows formally how diﬀerent classes of voting

models, in conjunction with a generalized version of Bayes’ Rule, generate Prediction 1.
      In sum, Prediction 1 (abbreviated “P1”) is generated by many instrumental voting
models, but many non-instrumental models will fail to produce the comparative static.


Prediction 1 (P1): All else being equal, observing the close poll, compared to the not-close
poll, leads to a higher chance of voting (versus abstaining).


      P1 most clearly emerges from the classic private values instrumental voting model of
Downs (1957), and later extended by Ledyard (1981), Palfrey and Rosenthal (1983), and
others. In such models, individuals compare the costs and beneﬁts of voting, where the

beneﬁts are proportional to the probability of being decisive. Thus, individuals become more
likely to vote when they believe the election to be closer.

      A more general approach contemplates that voters have both ideological and valence
elements to preferences, as in Feddersen and Pesendorfer (1997). Here, voters receive (private)
signals about the valence (i.e., quality) of candidates and vote based on their assessment of

ideology, candidate quality, and the chance of aﬀecting the outcome. Observing a poll showing
one candidate leading strongly then has two eﬀects—it potentially informs voters about quality
diﬀerences and about the likelihood of being decisive. The former eﬀect raises the value of
voting, as voters are now more certain of the quality of the leading candidate. The latter eﬀect
reduces the value of voting, since one vote is less likely to be decisive. So long as ideology
dominates valence in the mind of the voter, and we consider only individuals who support the
perceived closeness aﬀects turnout. In follow-on studies to Gerber and Green (2000), Bennion (2005) and Dale
and Strauss (2009) also ﬁnd no diﬀerential impact of very similar messages that elections have the general
potential to be close.



                                                     7
minority candidate, then P1 continues to hold.8
       A separate strand of the instrumental voting literature views voting as a means of
signaling, either to other voters or to those in power (Razin, 2003; Piketty, 2000). Such
signals presumably aﬀect the policy chosen by the election winner. Thus, even if a vote is

unlikely to change the candidate chosen, the eﬀects on policy might still motivate a voter to
come to the polls. In principle, signaling and decisiveness might operate in opposition to one
another; however, under the assumption that policies are more sensitive to vote share in close
elections than landslides, P1 holds: a voter observing a close poll sees that a vote for their
preferred candidate has more impact on the desired candidate than does a distant poll.9
       The leading alternative to instrumental voting models are ethical models. Starting with
Riker and Ordeshook (1968), scholars argue that voters are motivated to turn out by a sense

of duty, thus deriving utility from the act of turnout separate from the consequences of the
vote. Later work sharpens this idea to consider utility derived from the joint event of turning
out and voting for a particular candidate (Fiorina, 1976). P1 does not hold in such models as

the election outcome, and hence the perceived closeness of the election, is unimportant.10
       A richer view of ethical voting is developed in Feddersen and Sandroni (2006), where the
force and direction of ethical motives depends on instrumental factors (i.e., the likelihood that

the vote will aﬀect the outcome). They posit that would-be voters follow a rule-utilitarian
strategy, i.e., they vote under the hypothesis that all others sharing their ideology follow the

same strategy. Ethical payoﬀs derive from adhering to this strategy, or not. This model
predicts a tight relationship between the distribution of voters’ preferences in society (a dis-
   8
      This is because a close poll implies few A supporters are planning on voting, indicating that B should
be preferred according to valence. The opposite would be true for a not-close poll. And so both valence and
pivotality motives shift behavior in the same direction for B voters. More generally, as we discuss in Appendix
D even if ideology does not dominate valence for all voters, we can restrict our analysis to individuals, whose
preferences do not shift because of the poll results. These individuals then conform to the private values case
discussed above. We examine additional predictions of this class of models in Section 6.3.
    9
      Whether the conditions on the sensitivity of policy to vote share hold is, of course, debatable. Nonetheless,
even when these conditions fail to hold, predictions can still be obtained, as described in Appendix D, and
examined in Section 6.3.
   10
      Some models (e.g., Morgan and Várdy, 2012) combine both motives. It may be readily seen that, in large
elections, instrumental motives essentially vanish leading to the same prediction as when such motives are
ruled out entirely.



                                                        8
tribution proxied for by polls) and the decision to turn out to vote. If an election is unlikely
to be close, it would be wasteful for voters on the winning side to ask members of their group
with high voting costs to turn out, so turnout is depressed. A close poll, on the other hand,
suggests a need for large turnout among voters on a given side. Here, P1 should hold.

       Recently, several “social” models have emerged to explain voting. Some studies (e.g.,
Gerber et al., 2008) emphasize the power of conformity. They hypothesize that individuals
exposed to information about high turnout in their neighborhood will be more likely to turn
out themselves. A separate strand (e.g., Harbaugh, 1996; DellaVigna et al., 2017) hypothesizes

that voting occurs in anticipation of future interactions—if someone is likely to be asked
whether they voted, they are more likely to vote. Such models are not directly concerned
about the relationship between the perceived closeness of the election and turnout.11
       As mentioned earlier, Shachar and Nalebuﬀ (1999) posit a model based on elites where
closeness aﬀects the decision of individuals to vote, but via an indirect mechanism: closer

elections encourage party leaders to exert eﬀort to get their voters to turn out. Because our
experiment only aﬀects a very small subset of voters’ perception of the closeness, we would

expect this mechanism to predict a zero eﬀect of our treatment on turnout.
       Not only do diﬀerent voting models make diﬀerent qualitative predictions, but they also
diﬀer quantitatively, depending on various factors including the distributions of voting costs
and voting benefts; beliefs about closeness; and any aggregate uncertainty. Appendix D.6

calibrates a very simple instrumental voting model, and we discuss it later in Section 6.



3      Methods and Data for 2010 Experiment

We conducted the experiment in states with gubernatorial races in 2010, a year where there
was no presidential election. Our goal in doing this was to select highly visible elections
  11
    Nonetheless, they could, in principle, rationalize outcomes consistent with P1. For instance, if exposure
to a close poll leads an individual to believe she is more likely to be asked about her vote, then turnout should
increase. But the reverse is also consistent with these models: An individual whose neighborhood is known to
favor a given candidate might conclude that neighborhood turnout is high on seeing a distant poll result.



                                                       9
that would be salient to voters and avoid complications from the electoral college. Since
US voters often vote on many races at one time, we wanted to choose elections that would
be the most “top of mind” for voters. We avoided conducting our study with presidential
elections as the electoral college makes the election diﬀer substantially from basic theory. We

chose a “midterm” (i.e., non-presidential) year to avoid having the governor races eclipsed
by presidential elections. Political science research shows that governors are the second most
recognized elected oﬃcials in the US (after the President), with substantially more visibility
and media exposure than senators (Atkeson and Partin, 1995; Squire and Fastnow, 1994),

suggesting that voters likely view gubernatorial races as signiﬁcantly more important than
senate races. For example, in Squire and Fastnow (1994), 79% of voters could recall their
governor’s name, compared to only 52% who could recall their senator’s name.
       The experiment was administered by Knowledge Networks, a large online survey com-
pany. The Knowledge Networks KnowledgePanel is a panel of individuals that agree to take

several online surveys per month. Members are invited to join via random digit phone dialing.
Members receive surveys by email and complete them over PC or WebTV.12 Members receive
various rewards and prizes for participating in surveys. Knowledge Networks collects demo-

graphics for all members, and the panel is designed to be roughly nationally representative of
US adults along these characteristics (Liebman and Luttmer, 2015).
       In choosing our sample of states, we excluded CO, MA, ME, MN, and RI, as these were
states where there was a major third party candidate. In addition, we restricted our sample
to states (1) where the was a poll within the last 30 days indicating a vote margin between the

Democrat and Republican candidates of 6pp or less and (2) where there were two polls that
diﬀered between each other by 4pp or more. This left us with 13 states: CA, CT, FL, GA,
IL, MD, NH, NY, OH, OR, PA, TX, and WI. In each state selected, we used KnowledgePanel

members who were registered voters. From the KnowledgePanel registered voters in these
states, we had 5,413 subjects assigned to Close Poll and 5,387 subjects assigned to Not Close
  12
    For individuals without computer/WebTV or internet, Knowledge Networks provides access for free. The
KnowledgePanel has also been used in leading economics research on unrelated topics (e.g., Fong and Luttmer,
2009; Liebman and Luttmer, 2015; Rabin and Weizsacker, 2009).


                                                    10
Poll (plus an additional 5,543 subjects assigned to receive nothing and not get surveyed). We
used poll information from FiveThirtyEight.com and RealClearPolitics.com.

       First Survey. Subjects were ﬁrst sent the survey on Wednesday, October 20, 2010 (13
days before the election), and subjects could complete it up to midway through election day
(Tuesday, Nov. 2). The order for the ﬁrst survey was as follows (see Appendix Figure C1 for

a visual timeline and see Appendix E.1 for screenshots with question wording):


   1. The survey began with asking people whether they had already voted. Those who
       answered yes were removed from the survey.

   2. Subjects answered three political knowledge and interest questions.

   3. Subjects were asked for their prediction of the vote shares between Democrat and Re-
       publican.

   4. Subjects were provided with a standard “explanation of probabilities” developed in the
       pioneering working of Charles Manski and used in Delavande and Manski (2010).

   5. We then asked subjects about the chance that they would vote; their chance of voting
       for the diﬀerent candidates; and the chance the election would be decided by less than

       100 or 1,000 votes.13 We decided to ask subjects about the event of the election being
       decided by less than 100 or 1,000 votes instead of the outright event of being decisive,

       as some political scientists and psychologists we spoke to believed that such questions
       would be easier for subjects to comprehend. In addition, as emphasized by Mulligan
       and Hunter (2003), vote totals within some range of an exact tie often trigger recounts

       in US elections; elections are then oftentimes decided by courts (e.g., recall the 2000
       Presidential Election in Florida). Thus, having an election decided by less than 100 votes
  13
    To avoid any issues of anchoring or voters trying to make their answers consistent across questions, voters
were randomly assigned to be asked about either the chance the election would be decided by less than 100
or less than 1,000 votes.




                                                      11
       may be roughly equivalent to a 1 in 100 chance of being pivotal. All belief questions
       were administered without any incentives for accuracy.14

   6. We then provided the information treatment, described below.

   7. Immediately after the information treatment, subjects were again asked their prediction

       of the Democrat/Republican vote share and the questions from #5 (in the same order).
       To ensure the treatment was strong, we continued to display the two poll numbers at
       the bottom of the screen as subjects re-answered questions.15


       We decided to ask the same questions immediately after treatment so as to detect if
there was any immediate impact on voting intentions, given the possibility (discussed further

in Section 6.1) that belief impacts could conceivably attenuate between the survey and the
date of the turnout decision. The median amount of time on the survey was 4 minutes (25th
perc=3 mins, 75th perc=7 mins).

       The survey had a 62% response rate, reﬂecting that some people invited to take the
survey didn’t take it. The rate was 62% both among those assigned to receive the Close Poll

treatment (3,348 out of 5,413) and those assigned to receive the Not Close Poll treatment
(3,357 out of 5,387). It is unsurprising that the treatment didn’t aﬀect the response rate
because the treatment was only provided halfway through the survey. Given the paper’s
  14
      We decided not to use incentives for accuracy after a political scientist colleague informed us that doing
so may be illegal, possibly constituting either gambling on elections or potentially even being a form of paying
people to vote (for the question that asks people about their intended voting probability). Field experiments
that have randomized incentives for accuracy often ﬁnd little impact of using incentives on beliefs (Hoﬀman
and Burks, 2017). Especially given the wide range of backgrounds, ages, and education levels in our sample,
we suspect that adding ﬁnancial incentives for accuracy via a quadratic scoring rule would not have reduced
elicitation error (and might have even increased it). While most of our variables are binary, for the continuous
variable of predicted vote margin, we did not elicit subject’s uncertainty (see Kendall et al. (2015) for an
example that does), doing this for simplicity and time/ﬁnancial constraints from the survey company.
   15
      Although it is quite common in information provision ﬁeld experiments (e.g., Armantier et al., 2016;
Armona et al., 2016), one potential concern with asking questions twice (and doing so while continuing to
display poll numbers) is that it could lead to potential “Hawthorne Eﬀects,” e.g., where subjects feel pressure
from the experimenters to update their beliefs based on the information provided. We take comfort from the
fact that, as we document later, beyond updating on expected vote margin, subjects update on the probabilities
of less than 100 or 1,000 votes, on which no direct information was provided. Moreover, our conclusions about
closeness and turnout are unchanged if we restrict attention only to measuring beliefs using the less than 100
or 1,000 vote belief measures (instead of predicted margin).



                                                      12
focus on beliefs about electoral closeness, we perform our analyses restricting to these 6,705
individuals who did the survey, as belief data are only observed for those taking the survey.

       Selection of Polls and Information Treatment. Poll choices were ﬁnalized on
October 17, 2010. To select the polls, we identiﬁed the poll during the 40 days prior to the
start of the experiment (which started October 20) with the greatest margin between the

Democrat and Republican candidates. This served as our not-close poll. We then selected the
poll that was most close, conditional on the same candidates being ahead and behind. If two
polls were tied for being least close or most close, we selected the poll that was most recent.
In the experiment, the language we used to present the poll was as follows:
Below are the results of a recent poll about the race for governor. The poll was conducted
over-the-phone by a leading professional polling organization. People were interviewed from
all over the state, and the poll was designed to be both non-partisan and representative of the
voting population. Polls such as these are often used in forecasting election results. Of people
supporting either the Democratic or Republican candidates, the percent supporting each of the
candidates were:
Jerry Brown (Democrat): 50%
Meg Whitman (Republican): 50%16


Appendix Table C2 lists the poll numbers we provided. Across the 13 states, the average
margin of victory was 2.3% in the close polls and was 16.3% in the not close polls. For

simplicity, subjects were not informed about the number of people in our study, but subjects

likely understood that our sample size was small relative to the population because it consisted
of people from the KnowledgePanel. On the Friday before the election, subjects who had
already done the survey were sent a brief email reminding them of the poll numbers they saw
(see Appendix E.2 for wording). Of those emailed, 3,900 people (or 62%) opened the email.17
  16
      Poll numbers were calculated using the share of poll respondents favoring the Democratic (Republican,
respectively) candidate out of the total respondent favoring either the Democratic or Republican candidate
(and rounded to the nearest whole number). Our goal in doing this was to avoid having diﬀerent interpretations
of undecided voter shares represent a confound for our analysis, as well as create an experimental environment
that best corresponded to the simple environment in theory models.
   17
      The number of people opening the email each day was: 1,558 (Fri), 1,443 (Sat), 418 (Sun), 404 (Mon), and
97 (Tue, as of 12pm PST). A small share of people did the pre-election survey between Friday and Tuesday,
and they were not sent a reminder email, as a reminder would be unnecessary for them given they received
the poll quite close to election day.




                                                     13
     Post-election Survey and Voting Data. The post-election survey was sent out
on November 19, 2010, 17 days after the election, and subjects completed the survey until
November 30, 2010. Subjects ﬁrst completed a simple laboratory task designed to measure a
possible bias in probabilistic thinking. We then asked subjects whether they voted and whom

they voted for, among a few other questions (screenshots in Appendix E.3).
     The laboratory task is taken from Benjamin et al. (2013), which is based on Kahneman
and Tversky (1972). The task measures the extent of subjects displaying non-Bayesian beliefs,
speciﬁcally, “non-belief in the law of large numbers” (abbreviated NBLLN). Subjects were

asked the following question: “Imagine you had a fair coin that was ﬂipped 1,000 times.
What do you think is the percent chance that you would get the following number of heads.”
Subjects typed in a number corresponding to a percentage in each of the following bins: 0-200
heads, 201-400 heads, 401-480 heads, 481-519 heads, 520-599 heads, 600-799 heads, 800-1,000
heads. Our intent in asking this question was that NBLLN could potentially help rationalize

turnout by explaining why individuals have excessive probabilities regarding a close election.
Appendix A.2 discusses how person-level correlations between NBLLN and perceived closeness

of an election support that our belief data are sensible.
     We obtained administrative voting data on the voters in the sample for the last 10 years.
Speciﬁcally, we worked with a “vote validation ﬁrm” that collects administrative records on

whether people voted from the Secretaries of State in diﬀerent US states.

     Randomization and Summary Statistics. Randomization was carried out by Knowl-
edge Networks by sorting individuals by several characteristics (state, education, self-reported
voting in 2008, gender, race, age, and a random number), thereby stratifying by these char-

acteristics. Details are given in Appendix B.1.
     The goal of the 2010 experiment is to examine how voter beliefs aﬀect turnout. Thus,
the main individuals of interest are people who were assigned to the close poll or not-close
poll groups and who responded to the survey. Table 1 shows that across most variables,
respondents from the Close Poll group and Not Close Poll group have similar characteristics.


                                              14
There is only one characteristic which diﬀers across the two groups at the 5% level. Speciﬁcally,
voters in the not-close group had a slightly higher pre-treatment belief that the election would
be decided by less than 100 votes (but not for less than 1,000 votes or Predicted Margin). To
address this imbalance, we will often control for the pre-treatment belief about less than 100

votes.
      Even though we are using an online survey, the sample is broadly diverse both demo-
graphically and ideologically. The sample is 61% female, is 53 years old on average, and has
a signiﬁcant share with a master’s or PhD degree. Appendix Table C3 gives summary statis-

tics, including on outcome variables. The voting rate based on administrative data is 72%
(71.9% for close poll, 72.1% for not close poll), which is sizably lower than the post-election
self-reported voting rate of 84%. Such misreporting of turnout is present in many studies
(e.g., DellaVigna et al., 2017) and highlights the importance of having administrative turnout
data. Because of this, we do not use the self-reported information on whether someone voted.



4     Experimental Results for 2010 Experiment

4.1      Beliefs about whether the Election will be Close

Figure 1 shows subjects’ pre-treatment predictions about the margin of victory, both overall
and state by state. People tend to believe in closer margins of victory in states that end up

being closer, a correlation we conﬁrm with controls in Appendix Table C4.
      Figure 2 shows subjects’ subjective probabilities that the election is decided by less than
100 or less than 1,000 votes. There is a large amount of mass at 0%, 1%, or 2%, with many

voters predicting that a very close election is unlikely. However, there is also a large mass of
voters who are not 2% or less. As in many studies of subjective beliefs (e.g., Zafar, 2011),
there is signiﬁcant bunching at “round numbers” such as 10%, 20%, and 50%. The median
belief for less than 100 votes is 10% and the median for less than 1,000 votes is 20%., i.e.,
most voters overpredict the probability of a very close election.


                                               15
     How do we know that this is an overestimation? The simplest evidence is to look at
history. In the last six decades, there have been very few gubernatorial general elections
decided by less than 100 or 1,000 votes: during 1950-2009, there were nine races decided by
less than 1,000 votes (RI in 1956; VT in 1958; ME, MN, and RI in 1962; ME in 1970; AK in

1974; AK in 1994; and WA in 2004) and only one race decided by less than 100 votes (MN in
1962). In 835 contested gubernatorial general elections since 1950, the shares with margins
less than 1,000 and 100 votes were about 1% and 0.1%, respectively (and 0.6% and 0% after
1970). Appendix B.3 gives further details on these calculations.

     Alternatively, individuals might rely on models of voting to assess the chance that the
election will be close. For example, suppose individuals have a simple model of voting where
election outcomes are binomially distributed with a rate equal to the actual election outcome
proportion and the number of draws equal to the number of voters. Stated beliefs would be
an over-estimate in such a model. Even with the smallest electorate (New Hampshire, where

roughly 450,000 votes were cast) the ratio of support between the candidates would have
needed to be between 0.9934 to 1.0066 to generate even a 1% of the election being decided by

less than 100 votes (0.9887 to 1.022 when considering less than 1,000 votes). This excludes
not only the actual New Hampshire ratio (1.17), but also all realized ratios in our data (the
ratio closest to 1 occurred in Oregon, where it was 1.03).

     One reaction to Figure 2 is that many voters do not have advanced education and may

not fully understand probabilities. To address this, Appendix Figure C2 restricts to the
roughly 1,400 voters with Master’s or PhD degrees. Even among these well-educated voters,
the median perceived probabilities of less than 100 and less than 1,000 votes were 5% and
10%, respectively. Thus, the median belief is smaller among well-educated voters, but still
quite high.
     While pre-treatment closeness beliefs are very high, they seem sensible in several ways.

First, Appendix Table C4 shows that the actual ex post vote margin in a state is a positive
predictor of perceived vote margin, as well as a negative predictor of the perceived probability



                                              16
of a very close race (i.e., less than 100 or 1,000 votes). Second, this ﬁnding is consistent with
Duﬀy and Tavits (2008), who ﬁnd that students substantially overestimate the probability
of being pivotal in 10-voter lab elections. Third, as we discuss in Section 6.1 and Appendix
A.2, observed beliefs are consistent with other data and models in economics where subjects

consistently overestimate small probability events.
      Moreover, our identiﬁcation strategy is driven by changes in individual beliefs, not the
level. Thus, although individuals’ beliefs may be oﬀ in terms of the level, so long as the
close poll and not close poll diﬀerentially aﬀect beliefs, we have the necessary experimental

variation. As the next sub-section shows, our treatment leads to diﬀerential updating.


4.2    Belief Updating in Response to Polls

Table 2 provides non-parametric evidence that voters update in response to the experimental
poll information. It tabulates whether voters increase, decrease, or did not change their beliefs,

showing impacts on predicted vote margin, probability decided by less than 100 votes, and
probability decided by less than 1,000 votes. The poll information was given to them in terms
of vote margin, so it is perhaps unsurprising that voters would update on this metric. But

there is also clear updating on the less than 100 or 1,000 vote margins, even though they
were not directly manipulated by our experiment. Consider, for example, the probability the

election would be decided by less than 1,000 votes. About two-thirds of voters are not changing
their beliefs at all, a percentage which is in-line with other information ﬁeld experiments (e.g.,
Armantier et al., 2016; Armona et al., 2016). However, for the share that do change, far more

do so in the expected direction. Thus, despite being oﬀ by orders of magnitude, beliefs appear
to incorporate information, much like a pure Bayesian.
      Tables 3 and 4 conﬁrm the same results using a regression. We regress post-treatment
beliefs about the closeness of the election on the randomized treatment status and controls.
Tables 3 uses predicted vote margin as the outcome variable, whereas Table 4 analyzes the
perceived probability of an election being decided by less than 100 or less than 1,000 votes.


                                               17
      Table 3 shows that receiving the close treatment leads the average voter to decrease
their predicted vote margin by about 2.8pp, which represents a very sizable 28% decrease
in predicted margin relative to the pre-treatment median (or 16% relative to the mean). In
addition, consistent with theory, we see that voters who are less informed update more. We

measure how informed voters are using their self-expressed interest in politics (1-5 scale),
whether they could correctly identify Nancy Pelosi as the Speaker of the House, and the
share of the time they voted in the previous 5 elections. For example, a voter who identiﬁes
as having very low interest in politics updates by 4.7pp, whereas a voter with a very high

interest in politics updates by only 1.8pp.18
      Table 4 shows that receiving the close poll treatment increased the perceived probability
that the vote margin is less than 100 or 1,000 votes. Both probabilities increased by about

2.5pp after receiving the close poll treatment. Column 1 shows an insigniﬁcant eﬀect because,
as discussed earlier in Table 1, people randomly assigned to the Not Close Poll group happened
to have higher initial beliefs about the margin less than 100 votes. However, results become

stronger once one controls for pre-treatment beliefs.19 For the subjective probability of less
than 100 votes, the coeﬃcient in column 3 represents roughly a 25% increase in the believed

probability relative to the pre-treatment median (or about 10% relative to the mean). For the
subjective probability of less than 1,000 votes, the coeﬃcient in column 6 represents roughly
a 12% increase in the believed probability relative to the pre-treatment median (or about 7%
relative to the mean). Thus, these represent quite sizable impacts on beliefs.
      Appendix Table C7 shows even larger impacts on beliefs when restricting to individuals

who update their beliefs at all in either direction.
      Figure 3 graphs the average reaction of beliefs to our treatments. Appendix Figure C3
  18
     In Appendix Table C5, we repeat the analysis using a continuous version of the treatment, namely, the
vote margin in the randomly shown poll. Column 1 has a coeﬃcient of 0.42, whereas once controls are added
in column 2, the coeﬃcient shrinks to 0.22. This occurs because states with actual wider vote margins tend
to have polls with wider vote margins. Even though our treatment is randomly assigned within the state, the
level of the poll vote margins is not randomly assigned across states.
  19
     Repeating the analysis using the continuous treatment (vote margin in the poll) instead of the close poll
dummy, Appendix Table C6 shows that each additional 1pp drop in the margin in the randomly assigned poll
led to a 0.14pp increase in the probability of less than 100 or 1,000 votes.



                                                     18
graphs how the treatments aﬀect the distribution of beliefs.


4.3     Electoral Closeness Beliefs and Voting

In our empirical analysis of voter turnout, we usually present results controlling for an in-
dividual’s past voting history. As argued by McKenzie (2012), when an outcome variable is
highly persistent (such as voting, where some people always vote and others never vote), there

are often signiﬁcant gains in statistical power by controlling for pre-treatments records of the
outcome variable.20

       Believed Closeness and Turnout, OLS. Table 5 performs OLS regressions of turnout
on diﬀerent measures of beliefs about the closeness of the election. Columns 1-3 study margin

of victory, columns 4-6 study perceived probability of less than 100 votes, columns 7-9 study
perceived probability of less than 1,000 votes, and columns 10-12 study the perceived proba-
bility of less than 100 or less than 1,000 votes. The coeﬃcients are multiplied by 100 for ease

of readability, as they are throughout the paper when the outcome is whether someone voted.
We see little relationship between closeness beliefs and turnout. Column 1 implies that a 5pp

decrease in predicted margin of victory is associated with an increase in turnout of 0.15pp.
       To get a better sense of magnitudes and to see whether standard predictors of turnout
are operative in our setting, Appendix Table C9 shows a regression of turnout on demographic

characteristics in detail. We focus primarily on column 1 of Table C9, which shows results
without past voting controls. Consistent with the past literature, older, more educated, and
richer people are more likely to vote. Although our sample is not a random sample from the
US population, these basic voting trends suggest that our sample is not especially atypical.
Furthermore, the estimated coeﬃcients are much larger than the closeness coeﬃcients esti-
mated in Table 5. For example, all else equal, being aged 75+ is associated with being 43pp
  20
    In Appendix Table C10, we present our main IV results without controlling for past voting history, and
obtain the same conclusions (though with less precise standard errors). The past voting variables mostly
reﬂect whether someone chose whether to vote, but there is a small share of individuals in the data who were
too young to be eligible to vote in past elections (see Appendix B.1 for details).



                                                    19
more likely to vote (relative to being under 25), and having household income over $100,000
is associated with being 15pp more likely to vote (relative to having household income under
$25,000). The coeﬃcient on being aged 75+ is roughly 200 times larger than that associated
with a 5pp decrease in predicted margin of victory.21
       Beyond the factors already discussed in the Introduction, the OLS results may be biased
for multiple additional reasons.22 First, measurement error in beliefs could attenuate results
toward zero. Second, causation could run in the opposite direction, e.g., people who intend
to vote may develop self-serving beliefs, justifying their intention to vote by coming to believe

(or reporting) that the election is close. Third, there could be additional unobserved factors
aﬀecting both beliefs and turnout.

       Believed Closeness and Turnout, IV. Table 6 shows IV regressions of turnout on
beliefs instrumenting with our experiment (the dummy for whether the recipient received

the close poll or not), showing that exogenously aﬀected beliefs do not aﬀect turnout. We
estimate by 2SLS. In column 1, the coeﬃcient of −0.12 means that for every 1pp decrease in

the believed vote margin (i.e., the election becomes more close), turnout increases by 0.12pp.
The F-stat on the excluded instrument is high, signiﬁcantly above the rule-of-thumb of 10
often used to designate weak instruments (Stock et al., 2002). Table 6 also presents the exact

ﬁrst stage results in the ﬁnal row.23
       Columns 4-6 study the perceived probability of the margin of victory being less than 100
votes. In column 4, the F-stat on the excluded instruments is less than 1—this reﬂects the
earlier discussed initial imbalance between the Close and Not Close groups in terms of initial
  21                                                                                              43
      The coeﬃcient on margin of victory in column 1 of Appendix Table C9 is ≈ 0.04, and 5.̇04       is over 200.
  22
      Papers in the literature often regress turnout on ex post closeness across elections (in our case, an election
is a state). In contrast, in the OLS results here, we regress individual turnout on individual-level believed
closeness while controlling for state ﬁxed eﬀects. However, it seems likely that many of the inﬂuences mentioned
in the Introduction (e.g., media, social pressure, campaigning) could still bias OLS estimates conditional on
state ﬁxed eﬀects. Suppose that a person has friends who are pressuring them to vote. This might make them
more likely to vote, as well as more likely to believe the election is close (compared to someone whose friends
are not pressuring them). Despite possible bias, we still believe, though, that it is of some interest to know
the correlation between individual level beliefs and turnout (as opposed to overall closeness and turnout as in
the literature).
   23
      These results are slightly diﬀerent from those in Table 3-4 because we include past voting controls. For
reduced form results, see Appendix Table C24.


                                                        20
perceived probability of less than 100 votes. In column 5, we control for pre-treatment beliefs
and the instrument becomes strong again. In column 6, when full controls are added, the
coeﬃcient is -0.19, meaning that a 1pp increase in the perceived chance of a very close election
(margin < 100) actually slightly decreases voting (though it is not statistically signiﬁcant).

       Among columns 4-12, we have the most power in column 12. There the coeﬃcient is 0.08
(se=0.33), leading to a 95% CI of [-0.58, 0.73]. The point estimate of 0.08 means that 5pp
increase in the perceived probability of a very close election increases turnout by only 0.4pp.
The 0.73 upper limit of the 95% CI means we can rule out that a 5pp increase in the perceived

probability of a very close election would increase turnout by more than about 3.6pp. When
considering models of instrumental voting, we might expect that the probability of an election
being decided by less than 100 or 1,000 votes proxies for pivotality much more tightly than
predicted margin of victory, so the statistical zero in column 12 is more noteworthy.
       We can thus rule out that a 5pp decrease in perceived margin of victory or 5pp increase

in the perceived probability of a very close election is anywhere near as important as that of
other voting predictors like age, education, and income, where we saw relations on the order

of 10-40pp. Even though the IV estimates have standard errors that are roughly 10 times
larger (or more) than those from OLS, our estimated “zeros” still have a reasonable amount
of precision.24 Section 6.2 returns to the question of precision for our 2010 study.
       One seemingly non-standard feature of Table 6 is that we use the same instrumental

variable to instrument diﬀerent closeness variables one at a time. Our view is that the diﬀer-
ent closeness variables likely represent diﬀerent forms or constructs of a person’s underlying
perception of election closeness. To the extent that they represent diﬀerent underlying con-

structs, Appendix A.1 shows that any resulting inconsistency in the IV estimates is in the
direction away from 0, making the true impact of each closeness variable an even tighter zero
than the one we estimate.
  24
    It is hard to know the exact source of the diﬀerence between our OLS and IV estimates, but we suspect
that measurement error in the OLS is quite important. The reader should also recall that the IV results reﬂect
the treatment eﬀect among compliers, in our case, individuals who would update their beliefs in response to
close polls. We do not have strong priors as to whether treatment eﬀects among compliers would diﬀer from
those among the general population.


                                                     21
     Actual Closeness and Turnout. Having examined the relation between electoral
closeness beliefs and turnout, we now attempt to “replicate” the past literature on actual
closeness and turnout using our 2010 data. Appendix Table C8 regresses turnout and the
actual margin in an election using our 2010 data. In keeping with a lot of the literature on

closeness and turnout, columns 1-2 collapse the data by election (i.e., by state) and present
election-level regressions. Columns 3-5 do individual level regressions. In column 3, a 10pp
decrease in the vote margin is associated with 2.6pp higher turnout. This relation decreases
in size when controls are added for a voter’s past turnout decisions—while the column 5 co-

eﬃcient is statistically signiﬁcant when clustered by state, it is insigniﬁcant according to a
block bootstrap or wild bootstrap p-value (13 clusters). While the strength of inference varies
depending on the method of clustering, the 2010 experimental data provides suggestive evi-
dence supporting a correlation between actual closeness and turnout. In contrast, it provides
no evidence for a causal relation between perceived closeness and turnout.



5    Follow-up Experiment in 2014

Our 2010 experiment shows that changes in the perceived closeness of an election do not
aﬀect turnout. But it leaves some questions unanswered. First, while the ﬁrst experiment

established that the eﬀect of beliefs on turnout is small (if any), there remains an open
question whether the eﬀect is small or approximately zero. Second, the population we chose
is a population of online survey-takers. Although they have a broad range of demographics
and have been used in leading economic research, there is a question of whether they could
respond diﬀerently than a fully representative population (including people who are not willing

to do online surveys). Third, although we worked hard to provide the information in a simple
way, a skeptical reader could argue that providing a poll-based predicted margin could be
nonideal when some people polled are undecided about for whom to vote. Could other types

of information about closeness (such as information about the expected size of the electorate)
matter?

                                              22
        We did a second large-scale experiment during the 2014 gubernatorial elections that
enables us to answer these three questions. First, we treated roughly 125,000 voters (instead
of the roughly 6,700 voters from before), increasing our sample size by a factor of roughly
20, thereby allowing us to see whether the eﬀect is small or approximately zero. Second, we

draw on the population of registered US voters, as opposed to online survey-takers, allowing
us to see whether our results hold with a fully representative population. Third, in addition
to providing the close vs. not close polls to treated individuals, we also crossed this with a
high or low electorate size prediction treatment. The number of voters is a common regressor

in empirical studies of turnout (Coate and Conlin, 2004; Coate et al., 2008; Hansen et al.,
1987; Shachar and Nalebuﬀ, 1999). Using predicted number of voters provides another way
of communicating information about an individual voter’s chance of being decisive, but one
that does not involve vote margins.


        Set-up. The set-up for the 2014 experiment was very similar to the 2010 experiment,
with the main exception being that we conducted the experiment using postcards instead of
an online survey. As in 2010, there was no presidential race, and we focused on states with

gubernatorial races. As in 2010, we restrict to states with gubernatorial elections, excluding
states with a major thirty party candidate. In addition, we restricted our sample to states (i)

where there was a poll within the last 30 days indicating a vote margin between the Democrat
and Republican candidates of 6pp or less and (ii) where there were two polls that diﬀered be-
tween each other by 4pp or more.25 We obtained poll information from RealClearPolitics.com.
We also limited ourselves to states where we had access to the voter ﬁle from the Secretary
of State. This left us with 7 states: AR, FL, GA, KS, MA, MI, and WI.
        In the 2010 experiment, the main treatment was Close Poll vs. Not Close Poll. However,
there are other potential aspects of the election that aﬀect one’s chance of being decisive

besides the margin. Thus, we cross information about the closeness of the poll with information
about the predicted electorate size from election experts.26 We implemented a 2x2 design of
 25
      The postcards were ﬁnalized on October 18, 2014, so it had to have been within 30 days of that date.
 26
      We sent emails to 15 election experts, and asked them to predict turnout in each state. Seven election


                                                     23
Close Poll vs. Not Close Poll, and Large Electorate vs. Small Electorate. In each state, we
randomly selected roughly 11,500 households to receive a mailing, equally allocated among
the 4 combinations (Close Poll&Large Electorate, Close Poll&Small Electorate, Not Close
Poll&Large Electorate, Not Close Poll&Small Electorate). In addition, in each state, among

households not receiving a postcard, we randomly selected roughly 115,000 households (10x
number of treated households) to obtain their voting records and serve as a control group.
      The postcard’s wording was very similar to the 2010 online survey, with a few exceptions
(the postcard is shown in Appendix E.4). First, to make the postcard look like a “regular”

sort of election material, we added short standard voting participation messages to the top
and bottom of the postcard (Gerber and Green, 2016).27 Second, we added the source of the
poll for the polls, with the idea that when someone receives something in the mail, it would

add credibility to see the source of the poll. Third, out of an abundance of caution, we added
a sentence for respondents to recognize that the information we are sending them is only from
one poll. While we can’t observe beliefs changes directly for the 2014 study, our goal in making

the 2014 wording very similar to the 2010 wording is to ensure that the 2014 experiment would
also have sizable eﬀects on beliefs. Furthermore, while we cannot observe whether people read

the postcard, a large literature (discussed further below when we discuss magnitudes) ﬁnds
that mailers (including postcards) tend to signiﬁcantly boost turnout, sometimes by as much
as 5-8pp (Gerber and Green, 2016). Such eﬀects are clearly impossible if people don’t read
postcards. So long as our experiment is similar to postcards in past experiments (and we
designed the postcard to be similar), we would expect substantial readership of our postcard.
      The randomization was conducted using voter ﬁle records provided by an anonymous

vote validation company.28 We stratiﬁed by state, and attempted to stratify by whether
experts responded.
  27
     These were “THE ELECTION ON NOVEMBER 4 IS COMING UP” at the top and “We hope you
decide to participate and vote this November!” at the bottom. Although such standard language may make
individuals receiving a mailing more likely to vote relative to those who received no mailing, it seems unlikely
that it would interact with our treatment of interest: receiving a mailer showing a close poll relative to a
mailer showing a not close poll.
  28
     The vote validation company used a number of sample restrictions to create voter ﬁle lists for our experi-
ments, most notably that an individual had not yet requested a ballot or voted as of Oct 16-17, 2014, when
the voter ﬁle lists were extracted (see Appendix B.2 for details).


                                                      24
someone voted in the general elections of 2008, 2010, and 2012.29 We restricted attention
to households with three or fewer registered voters (to increase the chance that most voters
would see or hear about the postcard), as well as to households with a valid address. For
each household, we randomly selected one registered voter to have their name listed on the

postcard. As is common in the literature, we consider all registered voters within a household
to be treated, and our unit of analysis is a person. Our results are qualitatively similar if we
restrict attention to individuals to whom the postcard is addressed (Appendix Table C23).
      The postcards were mailed out on Friday, October 24. The bulk of the mail would

have arrived on Monday (10/27) and Tuesday (10/28), and nearly all of the mail would have
arrived no later than the Wednesday (10/29) before the election. This accomplished our goal
of making the postcards arrive very close to the election while still having all postcards arrive
before the election.
      Appendix Tables C11 and C12 show that the samples are well-balanced in terms of ob-

servables, indicating a successful randomization. In our sample, the average margin of victory
was 0.3% in the close polls and was 7.7% in the not close polls, and the “large electorate”

electoral size prediction was 25% larger on average than the “small electorate” prediction (see
Appendix Table C2).
      The 2014 voting rate among people getting close poll postcards was 53.8%, and was

53.5% among people getting not close poll postcards. The 2014 voting rates were 53.5% and

53.7% for smaller electorate postcards and larger electorate postcards, respectively. These
voting rates are substantially lower than the voting rate of 72% in our 2010 experiment. This
likely reﬂects several factors, including that people in our 2010 internet sample may have a
relatively high rate of voting, that the 2014 elections had historically low turnout, and that
  29
     Given the possibility of vote or not in three elections, this means there are 8 strata based on past votes
per state. In our data, there are several possible codings of the means by which someone voted. In doing the
stratiﬁcation for the randomization, a research assistant coded the string “unknown” as corresponding to a
person not voting as opposed to a person voting but whose means of voting was unknown. Thus, the actual
stratiﬁcation is not exactly based on whether someone voted in the past, but on whether someone voted in
the past where the means of voting (such as early, polls, etc.) is known. About one quarter of people’s voting
record ﬁelds in 2008, 2010, and 2012 have the “unknown” string. However, the treatment groups are still very
well-balanced in terms of past voting rates. In our regressions, we control for dummies for turnout in 2008,
2010, and 2012, as well as dummies for the randomization strata.


                                                      25
we have diﬀerent states across the two years.30

      Results. Table 7 regresses turnout on treatment dummies. We do this (instead of an IV
regression of turnout on beliefs instrumenting with treatment dummies as in the 2010 results)
because beliefs are not measured in the 2014 experiment. Column 1 indicates that the close

poll appeared to increase turnout by about 0.29pp relative to the not-close poll, but this is
not statistically signiﬁcant. Results are similar with further controls.
      Column 3 compares the close and not-close poll treatments relative to getting no poll.
Relative to the control, the close poll increased turnout by 0.34pp, which is marginally sig-
niﬁcantly diﬀerent from 0. However, the not-close poll also increased turnout by 0.05pp. In

our view, the main statistical comparison of interest is not whether the close poll aﬀected

turnout relative to the control, but rather whether it increased it relative to the not-close poll,
as simply getting a postcard related to the election could lead someone to be more likely to
vote. An F-test fails to reject that the treatment eﬀects from the close and not-close polls are
the same.

      Column 4 further adds the cross treatment on whether the number of voters was expected
to be small (or large). Information that the electorate is likely to be smaller decreased turnout

by 0.17pp. This is in the opposite direction of what would be predicted by instrumental
voting models (where smaller electorate means higher chance of being decisive), but it is
not statistically signiﬁcant. We can rule out with 95% conﬁdence that our small electorate
treatment would increase turnout by more than 0.31pp.
      How tightly estimated is our “zero result” from the close poll treatment compared to

the not close poll treatment? Based on the 95% conﬁdence interval in column 4, we can
rule out a treatment eﬀect of more than 0.77pp. This is small relative to many (but not all)
non-partisan interventions in the turnout literature (Gerber and Green, 2016). For example,
Gerber et al. (2008) show that two mailer social pressure treatments increase turnout by 5-
  30
     To investigate this further, we can exploit the fact that we have 3 states in both the 2010 and 2014
datasets: FL, GA, and WI. In the 2010 elections in these three states, the 2010 sample had a voting rate of
71%, whereas the 2014 sample had a voting rate of 52% (conditioning on being age 22 or older in 2014). This
suggests that most of the diﬀerence is likely due to the internet sample having a relatively high rate of voting.

                                                       26
8pp. Experiments with one get-out-the-vote postcard on Asian-Americans (Wong, 2005) and
Indian-Americans (Trivedi, 2005) increased turnout by 1.3pp and 1.1pp, respectively. Gerber
and Green (2000) do an experiment where voters got 0-3 mailings with diﬀerent messages,
showing that each additional mailing increases turnout by 0.6pp. Surveying the literature

on mail experiments, Gerber and Green (2016) report that “Pooling all mail studies together
shows that sending a piece of mail to a voter increases the subject’s turnout by about 3/4
of a percentage point”; thus, our 95% conﬁdence interval means we can roughly rule out the
average size eﬀect of a mailing.31
       We can also compare the precision of the 2014 results vs. the 2010 results. To do this,
we need the 2010 results in an analogous form. Appendix Table C24 shows analogous reduced

form regressions using the 2010 data. The standard errors are 3.25 times smaller for 2014,
which is unsurprising given that the 2014 sample size is many times larger. Further, the 2010

and 2014 reduced form point estimates are similar (≈ 0.2 for 2010 vs. ≈ 0.3 for 2014).



6      Robustness: Alternative Explanations and Additional

       Investigations

6.1     Alternative Explanations

Could the intervention have been “washed away”? One alternative explanation for
our zero impact on turnout result is that while the experiment may have aﬀected voting
tendencies, other events may have occurred in the several days before the actual election that
would have over-ridden our impact on beliefs. Individuals could have forgotten the polls we
  31
     While this summary statement was about all mailers (postcards and non-postcards), it seems that us that
postcards would be likely to be at least as eﬀective as other mailers, given that they don’t need to be opened.
The 95% CI top-end of 0.77pp is based on comparing a close poll postcard vs. a not close poll postcard. For
comparing with the literature, we can also consider the impact of a close poll postcard vs. nothing. Based on
column 3, we can rule out that getting a close poll postcard increases turnout by more than 0.69pp relative
to nothing, which is less than the 0.75pp literature rough benchmark. The pooling of studies by Gerber and
Green (2016) include a signiﬁcant number of partisan mailer studies, which generally have a negligible eﬀect
of turnout (Gerber and Green, 2016)—without these studies, the average eﬀect would be higher than 0.75pp.



                                                      27
gave them. Or, individuals who saw a poll could have taken the time to look up other polls or
could have been exposed to other polling information in the media. What presumably matters
in the theory is voter beliefs at the time of the actual turnout decision (for many potential
voters, on election day), not voter beliefs at the time of the experiment.

       We were quite conscious of this potential concern in designing our experiment. We tried
to provide the polling information as close to the election as possible, while still providing
time logistically for the information to arrive. To deal with subjects forgetting the polls, we
sent them a follow-up email reminding them about the polls we showed them (and 62% of

people opened the email we sent them). But that still doesn’t fully address potential concern
regarding washing away.
       To assess this concern quantitatively, the 2010 experiment asked respondents about their
intended probability of turning out three screens after providing the polls (Appendix E shows
screenshots). In this very short span of time between initial information provision and post-

treatment voting intention, it is very unlikely for additional information to have leaked in.32
Relative to the not close poll treatment, the close poll treatment had no impact on post-
treatment intended probability of voting (see Appendix Table C13). These IV results are

even more precise than the IV results on administrative voting, with standard errors roughly
one-quarter smaller. For example, in column 6, with the regressor of post-treatment belief
about less than 100 votes, the 95% CI is [-1.07, 0.24]. The 0.24 upper limit means we can
rule out that a 5pp increase in the perceived probability of a less than 100 vote margin would
increase intended turnout probabilities by more than about 1.2pp.

       While intended probability of voting is clearly conceptually diﬀerent from actual admin-
istratively recorded voting, the two are quite correlated, with a correlation coeﬃcient of 0.46.
The average post-treatment intended probability of voting is 87.8% for the close poll group

and 88.0% for the not close poll group. The 0 eﬀect in Appendix Table C13 is consistent with
the simple non-parametric evidence in Table 2, which shows that 88% of voters do not change
  32
    Subjects did the 2010 experiment at home and it is theoretically possible they could have gone looking
online at other polls immediately after seeing the polls we provided. However, we can see from the screen time
data that few people lingered excessively after seeing the polls we provided, so it is unlikely that this occurred.


                                                        28
their intended probability of voting after receiving poll information.33
      Another way to shed light on the “washing away” concern is to examine whether the
treatment aﬀected information acquisition, e.g., to start following all the polls and to more
closely follow the election in general. Such voters might have discovered that we provided

them with the most close recent poll, and might discard the information content once they
learn this. However, 80% of people in the post-election survey said their attention to the
campaigns didn’t change after taking our pre-election survey, and the close poll treatment
had no impact on self-reported tendency to pay greater attention relative to the not close
treatment (Appendix Table C14). One concern might be that people would naturally start to

pay more attention to the race in the last week or so after taking our survey, but only 12% of

people said that they started to pay more attention to the campaigns after taking our survey.
      Further, because people took the 2010 survey on diﬀerent days, we repeated our 2010
results weighting by the day of the survey, with the idea that any washing away of beliefs would
be lessened for those taking the survey last. Recall that survey responses began on Wed., Oct.

20, 2010 (day 1) and continued through Tue., Nov. 2, 2010 (day 14). The average day of
survey response was day 3 (Fri., Oct. 22), and the standard deviation is 3 days. Weighting

by day of survey response, the results are qualitatively similar (Appendix Table C15), though
we caveat here by noting that day of survey response is chosen by respondents.
      Last, while we could not measure beliefs a second time before the election, when in-
formation ﬁeld experiments on unrelated topics have measured beliefs on multiple occasions,
they tend to ﬁnd that experimentally-induced belief changes are quite persistent, on the order

of 50-90% two months after a one-time treatment.34 Especially given that we sent an email
reminding voters of the poll information that we provided them, we hypothesize that most of
  33
     Given that intended probability of voting involves intention instead of actual behavior, some readers could
be concerned about Hawthorne Eﬀects. However, it seems to us that if Hawthorne Eﬀects were biasing our
result on intended probability of voting, they would bias toward ﬁnding a positive eﬀect of closeness on turnout
instead of a zero.
  34
     In Armona et al. (2016), two months after providing information on past house price changes, the main
coeﬃcient for 1-year price updating is about 3/4 as large as it was immediately after treatment (columns 1-2 of
row 5 in Table 8). In Bleemer and Zafar (2015), two months after providing information on returns to college,
88% of the treatment impact on college attendance expectations persists. In Cavallo et al. (Forthcoming),
about half the impact of past inﬂation data on inﬂation expectations persists two months after treatment.


                                                      29
our experimentally-induced belief changes would have persisted until the time that subjects
decided whether to vote.


        Is observed belief updating genuine? A potential concern for the 2010 experiment is
that voters do not actually update their beliefs at all, but rather appear to change their beliefs
as a result of a Hawthorne Eﬀect, i.e., changing their stated (but not true) beliefs to please
the experimenter. While we cannot fully rule out this possibility, we provide a couple reasons
why we believe it to be unlikely to explain our results. First, as discussed previously, voters
update strongly both on the margin of victory (on which they were provided information)

and the probability of a very close election (on which they were not provided information).

If voters were simply telling the researchers what “they wanted to hear,” it is not clear that
they would update on both. Second, as noted earlier in Section 4.2, the amount of updating
is negatively correlated with political interest and information, i.e., less informed / politically

interested people update more. A pure Hawthorne eﬀect seems unlikely to deliver this result
(unless, of course, for some reason the people who are less informed, controlling for observable
characteristics, are also the ones who are more prone to Hawthorne eﬀects).

        That people update closeness beliefs in response to one poll may be surprising to some
social scientists who eagerly follow election polls online and may be very familiar with what

polls have been taken. However, our results are consistent with evidence in political science
that many voters are relatively unsophisticated and uninformed (Carpini and Keeter, 1997;
Fowler, 2016). Indeed, the correlation across all voters between the pre-treatment predicted

Democrat vote share and actual Democrat vote share is only 0.37 (though this is still highly
statistically signiﬁcantly diﬀerent from 0).35 Of course, we do not claim that all of our sample
was uninformed (and indeed, as shown earlier in Table 2, a signiﬁcant share of voters in the
2010 study do not update at all); rather, the evidence is consistent with many voters not
being informed about polling.

        Do the Zero Results Mask Important Heterogeneity? While we have presented
 35
      The correlation between post-treatment predicted Dem vote share and actual Dem vote share is 0.42.


                                                     30
our results as being indicative of no eﬀect on turnout, it is possible that signiﬁcant eﬀects could
be observed for some types of voters. For example, there is a signiﬁcant share of individuals
in our data who are always observed as having voted in past elections. Such individuals may
vote out of duty, habit, or other forces that make them much less susceptible to how close

the election is. However, as seen in Appendix Tables C16 (2010 experiment) and C17 (2014
experiment), our zero result is robust to restricting to individuals who don’t always vote.36
      Given that many people do not update beliefs (and that our experiment involves ex-
ogenously “shocking” beliefs), one question is whether our results are robust to restricting to
cases where a person updates their beliefs. Appendix Table C18 shows our results are robust

to this restriction.

      Turning to a diﬀerent issue, one may believe that closeness considerations would be
most important for “partisan” or “ideological” voters, as such people may be thought closer
to voters in a private values instrumental framework. However, Appendix Table C19 shows no
impact of beliefs on turnout when restricting to voters who rate themselves as having strong

political ideologies.37
      Another important possible source of heterogeneity is the size of the election. Closeness
considerations may be thought to be more important in smaller elections. While all the

elections we study are quite large (compared to, say, the vote of a business committee), we
can restrict attention to the elections in our sample with smaller electorates. Dropping the

“larger elections” in our sample (deﬁned here as the ones with above median electorate size
in our samples), we ﬁnd little evidence that closeness considerations aﬀect turnout, as seen in
Appendix Tables C20 (2010 experiment) and C21 (2014 experiment).

      Are Belief Levels “Sensible”? A contribution of the paper is to document that sub-
  36
     If we additionally drop people who never vote, there is also no relation between closeness and turnout
(though standard errors become larger, particularly for the 2010 experiment).
  37
     We also did the analysis restricting to “middle of the road” voters (i.e., those who are not the ideological
voters deﬁned in Appendix Table C19) and obtained the same conclusions. Likewise, impacts of turnout might
be larger among voters with low interest in government (as such voters might be less likely to know about
polls). One could also tell a story that impacts would be larger among those with high interest in government
(because these people would care about the polls). In either subpopulation, there is no relation between
closeness beliefs and turnout.


                                                       31
jects signiﬁcantly overestimate the probability of a very close election, at least relative to the
historical evidence. However, subjects’ tendency to overestimate beliefs may raise questions
for some readers about whether the beliefs data are “sensible.” Although our experimental
treatment is exploiting changes in beliefs (as opposed to belief levels), we believe it is still

useful to try to understand whether elicited belief levels are likely to represent subjects un-
derlying expectations (as opposed to measurement error in the belief elicitation). For brevity,
we discuss in detail in Appendix A.2. We argue that subjects’ beliefs are consistent with
literature in behavioral economics and we document empirically that subjects who seem more

“behaviorial” as measured on our non-belief in the law of large numbers task have greater
over-estimation. In addition, using data on the number of seconds that each subject spent on
each question, we document that subjects took signiﬁcant time to answer the various belief
questions, suggesting they took the questions seriously.

     Was the experiment “strong” enough to matter theoretically for turnout?
Though we ﬁnd strong 1st stage eﬀects of our treatment on beliefs, could it have been that
the changes in beliefs would not be large enough to aﬀect turnout theoretically? This question

is diﬃcult to answer because it depends on the particular model of voting one is considering
(recall that several classes of models predict that perceived closeness should increase turnout),

as well as numerous assumptions about key parameters (e.g., distribution of voting costs,
distribution of voting beneﬁts, current beliefs about closeness, and any aggregate uncertainty).
Nevertheless, Appendix D.6 examines the theoretical consequences of increasing beliefs in the
context of a simple instrumental model. We ﬁnd that the observed 2010 increases in perceived

chance of less than 100/1,000 votes would predict sizable changes in turnout (on the order of
5-7pp), which is substantially higher than our reduced form estimates in Appendix Table C24.
This suggests that our experiment was strong enough to matter theoretically in the context
not only of the simple model considered, but also, as discussed in Appendix D.6, in variants
and enriched versions of the model.

     Were the gubernatorial races eclipsed in importance by senate races? One

                                               32
concern is that closeness may not have aﬀected turnout because the elections we studied were
not as important to voters as senate races. As mentioned above in Section 3, we chose to
study gubernatorial elections because past research indicates that governors are substantially
more visible to voters than senators. Still, it is possible that some people in our samples would

have been more interested in the senate races than the gubernatorial races. In 2010, the only
state in our sample without a senate election was TX, whereas in 2014, only FL and WI didn’t
have senate elections. If we re-do the 2014 results restricting to FL and WI, the results are
qualitatively similar. Further, the closeness of the senate race is not a confound because we

randomized within state and control for state ﬁxed eﬀects, which control for diﬀerences across
states in non-governor races such as senate races.


6.2    The Relationship between Actual Margin and Voter Turnout:

       Perceived Closeness vs. Other Factors

How much precision do our estimates give us in assessing the importance of individual per-
ceived closeness for explaining the relationship between actual closeness and turnout? Let B

represent the impact on actual turnout of increasing the margin by 1pp. Let s denote the
share of B that is driven by perceptions of closeness, whereas 1 − s represents the share of

B that is driven by other factors, such as elite mobilization and social pressure. We found
no evidence of s > 0 in our analysis above, and the analysis here shows how we can rule out
s > 0.12 (in our preferred speciﬁcation), thereby demonstrating that we have a precise “null
result.” See Appendix A.3 for details on the discussion in this subsection.

      Set-up. Let T be voter turnout, P be perceived closeness, and E be other factors that

aﬀect turnout such as elite mobilization. Both P and E are functions of actual closeness, C.




                                               33
That is, T = T (P (C), E(C)). We diﬀerentiate turnout with respect to actual closeness:

                                     B              sB            (1−s)B
                                                    
                                    ∂T      ∂T      ∂P     ∂T ∂E
                                        =       ·        +
                                    ∂C
                                        ∂P
                                                ∂C
                                                       ∂E ∂C
                                  Table C8   IV coefs Table C4


Consider moving from Election X to Election Y where the margin of victory decreases by 10pp.
Appendix Table C8 provides estimates of B. To better correspond with much of the literature

on closeness and turnout, we use the simple cross-election regression in column 1; the estimate
of B = 0.34 implies that turnout would go up 3.4pp in response to a 10pp decrease in margin.
       For the 2010 experiment, to estimate s, note that according to Appendix Table C4,
a 10pp drop in actual margin is associated with decrease in perceived margin by 4.8pp, an

increase in perceived chance of less than 100 votes by 1.4pp, an increase in perceived chance

of less than 1,000 votes by 4.1pp, and an increase in perceived chance of less than 100/1,000
votes by 2.8pp. We multiply these changes by our IV estimates of the turnout impact of such
changes, obtained from columns 3, 6, 9, and 12 of Table 6. Then, we divide by B to get s.
       For the 2014 experiment, we can rule out that the postcard increases turnout by more

than 0.77pp. In Tables 3-4, we estimate roughly that our close polls treatment decrease
perceived margin by 2.8pp, increased the perceived chance of less than 100 votes by 2.5pp,

increased the perceived chance of less than 1,000 votes by 2.3pp, and increased perceived
chance of less than 100 or 1,000 votes by 2.4pp. We do not observe beliefs in the 2014
experiment. Instead, in order to derive estimates of s from the 2014 experiment, we assume
that the 2014 postcards aﬀect beliefs to the same extent as the 2010 online survey, a quite
strong assumption that we discuss in Appendix A.3. Then, by the logic of the two sample IV

estimator (Angrist and Krueger, 1992), we can divide our 2014 point estimate by the degree
of the 1st stage 2010 treatment eﬀect (just identiﬁed case) to obtain the 2014 estimate of how
beliefs aﬀect turnout.38
  38
    We calculate two sample IV standard errors using the Delta Method, as in, e.g., Perez-Truglia and Cruces
(Forthcoming). Details are in Appendix A.3.




                                                    34
       Results. As seen in column 4 of Table 8, our estimated s values are mostly small and
are all not signiﬁcantly diﬀerent from 0, with an average of 0.13 across the 8 fully ﬁlled-in rows.
To combine the results from the diﬀerent belief variables together, we calculate a weighted
sum of estimated s values using predicted vote margin, Pr(Marg <100 votes), and Pr(Marg

<1,000 votes), where each value is weighted according to the precision (i.e., inverse variance)
of the estimate. We use the Delta Method to form a standard error for this weighted sum. For
the 2010 results, our combined estimate of s using all three belief variables is 0.005, whereas
for the 2014 results, our combined estimate of s is 0.06.

       Last, in Panel C, we pool the 2010 and 2014 data together to run a reduced form
regression, which allows us to estimate s using both experiments at once. We estimate s =
0.05, with a 95% conﬁdence interval of [−0.02, 0.13]. A value of s = 0.05 implies that 95% of
the relationship between actual closeness and turnout is driven by factors other than perceived
closeness. Further, the 95% upper limit of 0.13 means we can rule out that more than 13% of

the relationship between actual closeness and turnout is driven by perceived closeness.
       It is important to note that this exercise partially relies on non-experimental variation

(as well as the experimental variation). In particular, we do not randomize actual closeness
                                           ∂T         ∂P
across elections, so our estimates of      ∂C
                                                and   ∂C
                                                           rely on observational data, where concerns
about potential unobserved variables and choices about particular speciﬁcations may be more

important than in experiments. Thus, the results of this exercise should be viewed as more

tentative, as least compared to our main experimental estimates. Still, the exercise suggests
that our experimental results seem inconsistent with s being more than a very modest level.


6.3     Did Information Change Preferences Over Candidates?

One potential concern is that subjects’ preferences over candidates were also aﬀected by the

polls—for example, we may observe a “Bandwagon Eﬀect, where observing that a candidate
is further ahead makes someone more likely to want to vote for them, or the opposite.39 We
  39
    The fact that polls may lead to changes in preferences has been discussed extensively in both the the-
oretical and empirical literature. This literature, beginning with Simon (1954), Fleitas (1971), and Gartner


                                                      35
examine bandwagon eﬀects by regressing a dummy for (self-reported) voting for the Demo-
cratic candidate on the perceived Democratic vote share, instrumenting with the Democratic
vote share in the randomly assigned poll. Our main ﬁnding is that we fail to ﬁnd causal
evidence of bandwagon eﬀects with respect to actual voting (Appendix Table C26). Further-

more, our main IV results on perceived closeness and turnout are robust to restricting to
people whose intended probabilities of voting for each candidate do not change after receiving
polls (Appendix Table C22). For brevity, these ﬁndings are detailed in Appendix A.4, along
with further discussion of how our results relate to past ﬁndings.



7     Conclusion

In many models of turnout, voters are more likely to vote when the election is close because
they are motivated to help decide the election. To test this prediction, we conducted large

ﬁeld experiments in 2010 and 2014 with US voters. In both cases, we fail to ﬁnd evidence
supporting the idea that believing an election is close causes individuals to be more likely to
vote, even though the 2010 data indicates that the polls strongly aﬀected beliefs.

      Like all experiments, each of the two experiments has limitations. Even though the 2010
experiment was large, we did not know whether eﬀects whether small or approximately zero,

and some readers could have concerns about external validity due to the internet sample.
The 2014 experiment was very large and used a broad national sample, but instead faced
the limitation of not being able to measure beliefs, and instead relies on the assumption that
the close poll information delivered with very similar wording via postcard would also aﬀect
closeness beliefs (given the evidence of this occurring in the online experiment). We believe,
however, that the experiments complement one another very well, and together support that

the impact on turnout of believing the election to be close is approximately zero. Of course,
(1976), suggests that polls may lead to Bandwagon Eﬀects, making poll winners win with even greater leads
than predicted. Most experimental studies ﬁnd that majority supporters vote with greater propensities than
minority ones (Duﬀy and Tavits, 2008; Großer and Schram, 2010; Kartal, 2015). Cason and Mui (2005) ﬁnd
that the participation rates of the majority are higher than the participation rates of the minority.



                                                   36
as mentioned previously, the size of any predicted relationship varies depending on a variety
of unobservable variables (e.g., voting costs, aggregate uncertainty, voting beneﬁts). While
we cannot rule out that our treatments have any eﬀect (e.g., we cannot reject that the close
poll treatment in the second experiment could increase turnout by 0.8pp), our results suggest

that beliefs about closeness are not more than a very modest determinant of turnout in US
gubernatorial elections.
     An advantage of our study is that we test a prediction shared by many theories. While
some readers may not be surprised that our results are inconsistent with a plain vanilla “pivotal

voting model,” our results also speak to many other models and concepts of voting.
     Our results seem broadly supportive for non-instrumental models of voting. These in-
clude expressive models of turnout (e.g., Morgan and Várdy, 2012; Hillman, 2010; Hamlin and
Jennings, 2011), as well as models based on social norms (e.g., Gerber et al., 2008; DellaVigna
et al., 2017). While active research is already underway on non-instrumental voting mod-

els, we hope that our results spur even greater interest (both theoretical and empirical) in
studying such models for large elections. Our results also suggest that the observed closeness-

turnout relationship in the literature is likely mostly driven by elite mobilization and other
endogenous features of close elections as opposed to believed closeness making individuals
directly more likely to vote. In our data, we can rule out that more than 13% of the observed

closeness-turnout relationship is driven by perceptions of closeness.

     Our conclusions are speciﬁc to the type of election we study. For example, in much
smaller elections, it is possible that closeness beliefs may aﬀect turnout. We would also
speculate that beyond the size of the electorate, the context of an election might be important.
US gubernatorial elections are often quite ideological; it could be that closeness beliefs may
matter for other types of elections such as referenda. Further, our results do not rule out
that closeness beliefs might be important for non-politics elections such as union certiﬁcation

elections (Farber, 2015) or shareholder votes, and these may also be smaller elections.
     Our results are relevant for policy-makers or political parties interested in boosting



                                               37
turnout (in general or for particular groups). In particular, our results suggest that increasing
a person’s belief the election will be close is unlikely to aﬀect the person’s turnout decision.
However, political parties and other elites may still ﬁnd it useful to focus campaign eﬀorts in
close elections, due to the turnout eﬀects that campaigning can have separate from altering

beliefs about electoral closeness.


References
Agranov, Marina, Jacob Goeree, Julian Romero, and Leeat Yariv, “What Makes Voters Turn Out:
  The Eﬀects of Polls and Beliefs,” Journal of the European Economic Association, Forthcoming.
Althaus, Scott L., Peter F. Nardulli, and Daron R. Shaw, “Candidate Appearances in Presidential
  Elections, 1972-2000,” Political Communication, 2002, 19 (1), 49–72.
Angrist, Joshua D and Alan B Krueger, “The eﬀect of age at school entry on educational attainment: an
 application of instrumental variables with moments from two samples,” Journal of the American statistical
 Association, 1992, 87 (418), 328–336.
Ansolabehere, Stephen and Shanto Iyengar, “Of horseshoes and horse races: Experimental studies of
 the impact of poll results on electoral behavior,” Political Communication, 1994, 11 (4), 413–430.
Armantier, Olivier, Scott Nelson, Giorgio Topa, Wilbert van der Klaauw, and Basit Zafar, “The
  Price is Right: Updating Inﬂation Expectations in a Randomized Price Information Experiment,” Review
  of Economics and Statistics, 2016, 98 (3), 503–523.
Armona, Luis, Andreas Fuster, and Basit Zafar, “Home Price Expectations and Behavior: Evidence
  from a Randomized Information Experiment,” 2016. Working paper, Fed Reserve Bank of New York.
Ashworth, Scott and Joshua D. Clinton, “Does advertising exposure aﬀect turnout?,” Quarterly Journal
  of Political Science, 2007, 2 (1), 27–41.
Atkeson, Lonna Rae and Randall W. Partin, “Economic and referendum voting: A comparison of
  gubernatorial and senatorial elections,” The American Political Science Review, 1995, 89 (01), 99–107.
Banducci, Susan and Chris Hanretty, “Comparative determinants of horse-race coverage,” European
  Political Science Review, 2014, 6 (04), 621–640.
Battaglini, Marco, Rebecca B. Morton, and Thomas R. Palfrey, “The swing voter’s curse in the
  laboratory,” Review of Economic Studies, 2010, 77 (1), 61–89.
Benjamin, Daniel J., Don Moore, and Matthew Rabin, “Misconceptions of Chance: Evidence from
  an Integrated Experiment,” 2013. Working paper, UC Berkeley.
Bennion, Elizabeth A., “Caught in the Ground Wars: Mobilizing Voters during a Competitive Congres-
  sional Campaign,” Annals of the American Academy of Political and Social Science, 2005, 601 (1), 123–141.
Blais, Andre and Robert Young, “Why Do People Vote? An Experiment in Rationality,” Public Choice,
  1999, 99 (1-2), 39–55.
Bleemer, Zachary and Basit Zafar, “Intended College Attendance: Evidence from an Experiment on
  College Returns and Costs,” 2015. Fed Reserve Bank of New York No. 739.
Bond, Robert M, Christopher J Fariss, Jason J Jones, Adam Kramer, Cameron Marlow, Jaime E
  Settle, and James H Fowler, “A 61-million-person experiment in social inﬂuence and political mobiliza-
  tion,” Nature, 2012, 489 (7415), 295–298.
Bursztyn, Leonardo, Davide Cantoni, Patricia Funk, and Noam Yuchtman, “Polls, the Press, and
  Political Participation: The Eﬀects of Anticipated Election Closeness on Voter Turnout,” June 2017. NBER
  Working Paper 23490.



                                                    38
Cancela, João and Benny Geys, “Explaining voter turnout: A meta-analysis of national and subnational
  elections,” Electoral Studies, 2016, 42, 264–275.
Carpini, Michael X Delli and Scott Keeter, What Americans know about politics and why it matters,
  Yale University Press, 1997.
Cason, Timothy N. and Vai-Lam Mui, “Uncertainty and resistance to reform in laboratory participation
  games,” European Journal of Political Economy, 2005, 21 (3), 708–737.
Cavallo, Alberto, Guillermo Cruces, and Ricardo Perez-Truglia, “Inﬂation Expectations, Learning,
  and Supermarket Prices: Evidence from Survey Experiments,” AEJ: Macro, Forthcoming.
Coate, Stephen and Michael Conlin, “A Group Rule-Utilitarian Approach to Voter Turnout: Theory and
  Evidence,” American Economic Review, 2004, 94 (5), 1476–1504.
  ,   , and Andrea Moro, “The Performance of Pivotal-voter Models in Small-scale Elections: Evidence
  from Texas Liquor Referenda,” Journal of Public Economics, 2008, 92 (3-4), 582–596.
Cox, Gary W, “Electoral rules and the calculus of mobilization,” Legislative Studies Quarterly, 1999, pp. 387–
  419.
  , “Electoral Rules, Mobilization, and Turnout,” Annual Review of Political Science, 2015, 18, 49–68.
   and Michael C Munger, “Closeness, Expenditures, and Turnout in the 1982 US House Elections.,”
  American Political Science Review, 1989, 83 (01), 217–231.
  , Frances M Rosenbluth, and Michael F Thies, “Mobilization, social networks, and turnout: Evidence
  from Japan,” World Politics, 1998, 50 (03), 447–474.
Dale, Allison and Aaron Strauss, “Don’t forget to vote: Text message reminders as a mobilization tool,”
  American Journal of Political Science, 2009, 53 (4), 787–804.
Delavande, Adeline and Charles F. Manski, “Probabilistic Polling And Voting In The 2008 Presidential
  Election: Evidence From The American Life Panel,” Public Opinion Quarterly, 2010, pp. 1–27.
DellaVigna, Stefano, John A. List, Ulrike Malmendier, and Gautam Rao, “Voting to Tell Others,”
  Review of Economic Studies, 2017, 84 (1), 143–181.
Downs, Anthony, An Economic Theory of Democracy, New York, NY: Harper, 1957.
Duﬀy, John and Margit Tavits, “Beliefs and voting decisions: A test of the pivotal voter model,” American
 Journal of Political Science, 2008, 52 (03), 603–618.
Enos, Ryan D and Anthony Fowler, “Pivotality and turnout: Evidence from a ﬁeld experiment in the
  aftermath of a tied election,” Political Science Research and Methods, 2014, 2 (2), 309–319.
Farber, Henry, “Union Organizing Decisions in a Deteriorating Environment: The Composition of Repre-
  sentation Elections and the Decline in Turnout,” ILR Review, 2015.
Feddersen, Timothy and Alvaro Sandroni, “A Theory of Participation in Elections,” American Economic
  Review, 2006, 96 (4), 1271–1282.
   and Wolfgang Pesendorfer, “The Swing Voter’s Curse,” AER, 1996, 86 (3), 408–24.
   and     , “Voting behavior and information aggregation in elections with private information,” Economet-
  rica, 1997, pp. 1029–1058.
Fiorina, Morris P., “The Voting Decision: Instrumental and Expressive Aspects,” The Journal of Politics,
  1976, 38 (2), pp. 390–413.
Fleitas, Daniel W., “Bandwagon and underdog eﬀects in minimal-information elections,” American Political
  Science Review, 1971, 65 (02), 434–438.
Fong, Christina M. and Erzo F. P. Luttmer, “What Determines Giving to Hurricane Katrina Victims?
  Experimental Evidence on Racial Group Loyalty,” AEJ: Applied, April 2009, 1 (2), 64–87.
Foster, Carroll B., “The Performance of Rational Voter Models in Recent Presidential Elections,” The
  American Political Science Review, 1984, 78 (3), pp. 678–690.
Fowler, Anthony, “A Bayesian Explanation for Incumbency Advantage,” 2016. Working paper, U.Chicago.


                                                     39
Fujiwara, Thomas, Kyle Meng, and Tom Vogl, “Habit Formation in Voting: Evidence from Rainy
  Elections,” American Economic Journal: Applied Economics, October 2016, 8 (4), 160–88.
Gartner, Manfred, “Endogenous bandwagon and underdog eﬀects in a rational choice model,” Public Choice,
 1976, 25 (01), 83–89.
Gentzkow, Matthew, Jesse M. Shapiro, and Michael Sinkinson, “The Eﬀect of Newspaper Entry and
  Exit on Electoral Politics,” American Economic Review, December 2011, 101 (7), 2980–3018.
Gerber, Alan S. and Donald P. Green, “The eﬀects of canvassing, telephone calls, and direct mail on
  voter turnout: A ﬁeld experiment,” American Political Science Review, 2000, 94 (03), 653–663.
   and    , “Field Experiments on Voter Mobilization: An Overview of a Burgeoning Literature,” in “Hand-
  book of Field Experiments (forthcoming),” Vol. 1 2016.
  ,   , and Christopher W. Larimer, “Social Pressure and Voter Turnout: Evidence from a Large-Scale
  Field Experiment,” American Political Science Review, 2008, 102 (01), 33–48.
Geys, Benny, “Explaining voter turnout: A review of aggregate-level research,” Electoral Studies, 2006, 25,
  637–663.
Gimpel, James G, Karen M Kaufmann, and Shanna Pearson-Merkowitz, “Battleground states
  versus blackout states: The behavioral implications of modern presidential campaigns,” Journal of Politics,
  2007, 69 (3), 786–797.
Großer, Jens and Arthur Schram, “Public opinion polls, voter turnout, and welfare: An experimental
  study,” American Journal of Political Science, 2010, 54 (3), 700–717.
Hamlin, Alan and Colin Jennings, “Expressive political behaviour: Foundations, scope and implications,”
 British Journal of Political Science, 2011, 41 (03), 645–670.
Hansen, Stephen, Thomas Palfrey, and Howard Rosenthal, “The Downsian Model of Electoral Par-
 ticipation: Formal Theory and Empirical Analysis of the Constituency Size Eﬀect,” Public Choice, 1987,
 52, 15–33.
Harbaugh, William T, “If people vote because they like to, then why do so many of them lie?,” Public
 Choice, 1996, 89 (1-2), 63–76.
Hillman, Arye L, “Expressive behavior in economics and politics,” European Journal of Political Economy,
  2010, 26 (4), 403–418.
Hoﬀman, Mitchell and Stephen V. Burks, “Worker Overconﬁdence: Field Evidence and Implications
 for Employee Turnover and Returns from Training,” March 2017. NBER Working Paper 23240.
Kahneman, Daniel and Amos Tversky, “Subjective probability: A judgment of representativeness,”
 Cognitive Psychology, 1972, 3 (3), 430 – 454.
Kamenica, Emir and Louisa Egan Brad, “Voters, dictators, and peons: Expressive voting and pivotality,”
 Public Choice, 2014, 159 (1-2), 159–176.
Kartal, Melis, “Laboratory elections with endogenous turnout: Proportional representation versus majori-
 tarian rule,” Experimental Economics, 2015, 18 (03), 366–384.
Kendall, Chad, Tommaso Nannicini, and Francesco Trebbi, “How Do Voters Respond to Information?
  Evidence from a Randomized Campaign,” American Economic Review, January 2015, 105 (1), 322–53.
Ledyard, John O., “The Paradox of Voting and Candidate Competition: A General Equilibrium Analysis,”
  Working Paper 224, California Institute of Technology, Division of Humanities and Social Sciences 1981.
Levine, David K. and Thomas R. Palfrey, “The Paradox of Voter Participation? A Laboratory Study,”
  American Political Science Review, 2007, 101 (01), 143–158.
Liebman, Jeﬀrey B. and Erzo F. P. Luttmer, “Would People Behave Diﬀerently If They Better Under-
  stood Social Security? Evidence from a Field Experiment,” AEJ Policy, 2015, 7 (1), 275–99.
Matsusaka, John G., “Election closeness and voter turnout: Evidence from California ballot propositions,”
 Public Choice, 1993, 76 (4), 313–334.
   and Filip Palda, “The Downsian Voter Meets the Ecological Fallacy,” Public Choice, 1993, 77 (4), 855–78.


                                                     40
McKenzie, David, “Beyond baseline and follow-up: The case for more T in experiments,” Journal of
 Development Economics, 2012, 99 (2), 210–221.
Morgan, John and Felix Várdy, “Mixed motives and the optimal size of voting bodies,” Journal of Political
 Economy, 2012, 120 (5), 986–1026.
Morton, Rebecca B., Daniel Muller, Lionel Page, and Benno Torgler, “Exit polls, turnout, and
 bandwagon voting: Evidence from a natural experiment,” European Economic Review, 2015, 77, 65 – 81.
Mulligan, Casey B and Charles G Hunter, “The Empirical Frequency of a Pivotal Vote,” Public Choice,
 2003, 116 (1-2), 31–54.
Ortoleva, Pietro and Erik Snowberg, “Overconﬁdence in Political Behavior,” American Economic Review,
  February 2015, 105 (2), 504–35.
Palfrey, Thomas R., “Laboratory experiments in political economy,” Annual Review of Political Science,
  2009, 12, 379–388.
   and Howard Rosenthal, “A strategic calculus of voting,” Public Choice, 1983, 41, 7–53.
Perez-Truglia, Ricardo and Guillermo Cruces, “Partisan Interactions: Evidence from a Field Experi-
  ment in the United States,” Journal of Political Economy, Forthcoming.
Piketty, Thomas, “Voting as communicating,” The Review of Economic Studies, 2000, 67 (1), 169–191.
Rabin, Matthew and Georg Weizsacker, “Narrow Bracketing and Dominated Choices,” American Eco-
  nomic Review, September 2009, 99 (4), 1508–43.
Razin, Ronny, “Signaling and election motivations in a voting model with common values and responsive
  candidates,” Econometrica, 2003, 71 (4), 1083–1119.
Riker, William H. and Peter C. Ordeshook, “A Theory of the Calculus of Voting,” The American
  Political Science Review, 1968, 62 (1), 25–42.
Shachar, Ron, “The Political Participation Puzzle and Marketing,” Journal of Marketing Research, 2007,
  46 (6), pp. 798–815.
   and Barry Nalebuﬀ, “Follow the Leader: Theory and Evidence on Political Participation,” American
  Economic Review, 1999, 89 (3), pp. 525–547.
Shayo, Moses and Alon Harel, “Non-consequentialist voting,” Journal of Economic Behavior & Organi-
  zation, 2012, 81 (1), 299 – 313.
Simon, Herbert A., “Bandwagon and underdog eﬀects and the possibility of elections predictions,” Public
  Opinion Quarterly, 1954, 18 (03), 245–253.
Spenkuch, Jörg, “Expressive vs. Pivotal Voters: An Empirical Assessment,” 2017. Working paper, North-
  western.
   and David Toniatti, “Political Advertising and Election Outcomes,” 2016. Working paper, Northwestern.
Squire, Peverill and Christina Fastnow, “Comparing gubernatorial and senatorial elections,” Political
  Research Quarterly, 1994, 47 (3), 705–720.
Stock, James H, Jonathan H Wright, and Motohiro Yogo, “A Survey of Weak Instruments and Weak
  Identiﬁcation in Generalized Method of Moments,” Journal of Business & Economic Statistics, 2002, 20
  (4), 518–29.
Trivedi, Neema, “The eﬀect of identity-based GOTV direct mail appeals on the turnout of Indian Ameri-
  cans,” The Annals of the American Academy of Political and Social Science, 2005, 601 (1), 115–122.
Tyran, Jean-Robert, “Voting when money and morals conﬂict: An experimental test of expressive voting,”
  Journal of Public Economics, 2004, 88 (7-8), 1645–1664.
Wong, Janelle S, “Mobilizing Asian American voters: A ﬁeld experiment,” The Annals of the American
 Academy of Political and Social Science, 2005, 601 (1), 102–114.
Zafar, Basit, “Can subjective expectations data be used in choice models? Evidence on cognitive biases,”
  Journal of Applied Econometrics, 04 2011, 26 (3), 520–544.



                                                   41
Figure 1: Distribution of Predicted Margin of Victory, Before Treatment (2010 experiment)




                                              .2
                                              .15
                                           Density
                                            .1.05
                                              0




                                                      0           10       20       30      40      50    60              70       80       90     100
                                                                                          Predicted vote margin
                                                     Median = 10, 25th Percentile = 4, 75th Percentile = 20



                                                                                         (a) Overall


                      CA (57-43)                                        TX (43-57)                                     NY (65-35)                                     FL (49-51)
           .1




                                                                                                            .1
                                                             .1




                                                                                                                                                           .1
   Density




                                                     Density




                                                                                                    Density




                                                                                                                                                   Density
    .05




                                                                                                     .05
                                                     .05




                                                                                                                                                   .05
        0




                                                          0




                                                                                                         0




                                                                                                                                                        0
                0 10 20 30 40 50 60 70 80 90100                   0 10 20 30 40 50 60 70 80 90100                0 10 20 30 40 50 60 70 80 90100                0 10 20 30 40 50 60 70 80 90100
                           Margin                                            Margin                                         Margin                                         Margin


                       IL (50-50)                                       OH (49-51)                                     PA (46-54)                                     WI (47-53)
           .1




                                                                                                                                                           .1
                                                             .1




                                                                                                            .1
   Density




                                                     Density




                                                                                                    Density




                                                                                                                                                   Density
    .05




                                                                                                                                                    .05
                                                      .05




                                                                                                    .05
        0




                                                          0




                                                                                                         0




                                                                                                                                                        0




                0 10 20 30 40 50 60 70 80 90100                   0 10 20 30 40 50 60 70 80 90100                0 10 20 30 40 50 60 70 80 90100                0 10 20 30 40 50 60 70 80 90100
                           Margin                                            Margin                                         Margin                                         Margin


                      GA (45-55)                                        MD (57-43)                                     OR (51-49)                                     CT (50-50)
           .1




                                                             .1




                                                                                                            .1




                                                                                                                                                           .1
   Density




                                                     Density




                                                                                                    Density




                                                                                                                                                   Density
    .05




                                                      .05




                                                                                                     .05




                                                                                                                                                   .05
        0




                                                          0




                                                                                                         0




                                                                                                                                                        0




                0 10 20 30 40 50 60 70 80 90100                   0 10 20 30 40 50 60 70 80 90100                0 10 20 30 40 50 60 70 80 90100                0 10 20 30 40 50 60 70 80 90100
                           Margin                                            Margin                                         Margin                                         Margin


                      NH (54-46)
          .1
   Density
   .05  0




                0 10 20 30 40 50 60 70 80 90100
                           Margin




                                                                                   (b) Across States


Notes: This ﬁgure presents the pre-treatment distribution of subjects’ beliefs about the margin of victory
among the two leading candidates. Panel (a) presents the predicted margin of victory combining all states.
The margin of victory is the diﬀerence in vote shares rounded to the nearest integer, i.e., a 50/50 election
corresponds to 0 margin, a 51/49 election corresponds42to a margin of 2, and so on. Panel (b) presents the
same information broken out by state. The numbers in parentheses for each state represent the actual vote
shares among the two leading candidates (the Democrat share is ﬁrst). Data are from the 2010 experiment.
  Figure 2: Subjective Probabilities that Gubernatorial Election Will be Decided by Less
           than 100 Votes or 1,000 Votes, Before Treatment (2010 experiment)



                     .2
                     .15
                  Density
                   .1.05
                     0




                             0       10        20       30      40     50     60     70    80   90   100
                                                             Prob margin < 100 votes
                            Median = 10, 25th Percentile = 1, 75th Percentile = 45


                                                     (a) Less than 100 Votes
                     .2
                     .15
                  Density
                   .1.05
                     0




                             0       10        20       30       40     50     60     70   80   90   100
                                                             Prob margin < 1000 votes
                            Median = 20, 25th Percentile = 5, 75th Percentile = 50


                                                    (b) Less than 1,000 Votes


Notes: These graphs plot the distribution of answers to the question asking for the probability the election in
the respondent’s state would be decided by less than 100 votes or less than 1,000 votes. These subjective
beliefs were elicited before the poll information was provided. The data are from the 2010 experiment.



                                                                      43
               Figure 3: Belief Updating in Response to Polls (2010 experiment)




                                 4        2
                    Change in Probability
                             0




                                                Vote Margin    Less than 100 votes   Less than 1,000 votes
                                 -2
                                 -4




                                                               Close             Not Close


                                                      (a) Overall impact on beliefs
                                 10         5
                      Change in Probability
                                0




                                                Vote Margin    Less than 100 votes   Less than 1,000 votes
                    -5           -10




                                                               Close             Not Close


                   (b) Impact on beliefs among those who change their response

Notes: These graphs analyze the impact of the experiment on voters’ beliefs. Each bar represents the
average change in beliefs for those receiving either the close or not close poll treatments. They are calculated
via a person-level regression of changes in beliefs (i.e., post-treatment beliefs minus pre-treatment beliefs) on
a constant using robust standard errors. Whiskers show the 95% conﬁdence interval for the coeﬃcient
estimate (i.e., plus/minus about 1.96 standard errors). Thus, the whiskers reﬂect a conﬁdence interval on
each bar in absolute terms (and not for a comparison of the close bar versus the not close bar). The
diﬀerences between the close and not close bars are highly statistically signiﬁcant, as indicated in Tables 3-4.


                                                                   44
 Table 1: Comparing Means between People Getting Close Treatment and People Getting
                      Not Close Treatment: 2010 Experiment

                                                             Close          Not Close   t-test
                                                          (N = 3, 348)     (N = 3, 357)
          Demographics:
          Male                                               0.39              0.39          0.91
          Black                                              0.08              0.08          0.87
          Hispanic                                           0.06              0.06          0.67
          Other                                              0.03              0.03          0.96
          Mixed race                                          0.02             0.02          0.34
          Age                                                53.21             53.45         0.49
          Less than high school                              0.03              0.03          0.56
          High school degree                                  0.14              0.13         0.54
          Some college or associate degree                    0.34              0.34         0.96
          Bachelor’s degree                                   0.29             0.29          0.76
          Master’s or PhD                                     0.21              0.21         0.91
          Household income $25k-$50k                          0.22              0.24         0.09
          Household income $50k-$75k                          0.24              0.23         0.14
          Household income $75k-$100k                         0.18              0.17         0.31
          Household income $100k and up                      0.24              0.25          0.32
          Political variables:
          Registered Democrat                                 0.47              0.49         0.44
          Registered Republican                               0.36              0.36         0.78
          No party aﬃl/decline state/indep                    0.14             0.13          0.53
          Other party registration                           0.03              0.02          0.79
          Identify Nancy Pelosi as Speaker                    0.82              0.83         0.23
          Interest in politics (1-5 scale)                   3.73               3.7          0.31
          Aﬃliate w/ Democrat party (1-7)                     4.23              4.24         0.87
          Ideology (1-7 Scale, 7=Ext Liberal)                 3.89              3.87         0.65
          Predicted vote margin, pre-treat                   17.05              17.1         0.91
          Prob margin < 100 votes, pre-treat                 23.44             25.44         0.04
          Prob margin < 1,000 votes, pre-treat               31.93             31.46         0.65
          Prob voting, pre-treatment                         87.08             87.04         0.95
          Prob vote Dem, pre-treatment                       49.71             50.17         0.67
          Prob vote Republican, pre-treat                    41.46             41.53         0.95
          Prob vote underdog, pre-treat                      40.79             41.52         0.49
          Share voted previous 5 elections                   0.65              0.65          0.92
Notes: This table compares means across the close and not close poll individuals in the 2010 experiment.
“Close” refers to individuals receiving the close poll treatment. “Not Close” refers to individuals receiving
the not close poll treatment. The numbers in the “t-test” column are the p-values from a two-sided t-test.
The sample is restricted to individuals who respond to the survey. To avoid any anchoring eﬀects, voters
were asked about either the probability of margin less than 100 votes or probability of margin less than 1,000
votes, so the sample is only roughly half as large for those two questions. The number of non-missing
observations is less than 6,705 for some of the other political variables, particularly for party registration
which is non-missing for 3,823 people (non-missing for 1,902 people in Not Close group and for 1,921 in
Close group). See Appendix Table C3 for exact observation counts.
                                                     45
           Table 2: Nonparametric Evidence on Changes in Beliefs and Voting Intentions After Treatment (2010 Experiment)


                                                            N      Decrease     Same      Increase         N     Decrease      Same     Increase

                                                                  Not Close Treatment                              Close Treatment

              Predicted margin of victory                 3,311     19.0%       61.8%      19.2%         3,301     30.1%       62.8%      7.1%

              Prob margin < 100 votes                     1,601     18.2%       69.3%      12.6%         1,681     11.3%       68.2%      20.5%

              Prob margin < 1000 votes                    1,749     18.4%       67.3%      14.3%         1,657     10.4%       65.3%      24.3%

              Intended prob of voting                     3,350      3.4%       88.3%      8.3%          3,347      3.7%       88.0%      8.4%

              Intended prob voting for underdog           3,357      6.1%       87.7%      6.3%          3,348      5.7%       88.2%      6.1%




46
     Notes: This table describes how voters’ perception of the vote margin, their perception the election is decided by less than 100 or 1,000 votes, their
     predicted probability of voting, and their intended probability of voting for the underdog candidate (the candidate behind in the polls) change under
     the two information treatments (close poll and not close poll). Note that it is possible to change predicted Democrat vote share without changing
     predicted margin of victory (i.e., a 52D-48R prediction changes to a 48D-52R prediction).
                      Table 3: The Eﬀect of the Close Poll Treatment on Vote Margin Predictions (2010 Experiment)


      Dep. var.:                                                    bpost       bpost        bpost        Δb         bpost        bpost       bpost          bpost
                                                                     (1)         (2)          (3)         (4)         (5)          (6)         (7)            (8)
      Close poll treatment (0=Not Close, 1=Close)                 -2.80***    -2.79***    -2.68***     -2.62***    -2.72***    -5.45***     -3.83***    -4.66***
                                                                   (0.39)      (0.36)      (0.29)       (0.34)      (0.36)      (1.44)       (1.00)      (0.78)
      Pred vote margin, pre-treat                                                         0.54***
                                                                                           (0.02)
      Close poll*Interest in politics (1-5 scale)                                                                               0.73**
                                                                                                                                (0.36)
      Close poll*Identify Nancy Pelosi as Speaker                                                                                             1.35
                                                                                                                                             (1.07)
      Close poll*Share voted previous 5 elections                                                                                                    2.98***
                                                                                                                                                      (1.01)
      Interest in politics (1-5 scale)                                                                                -0.03       -0.38        -0.03   -0.01




47
                                                                                                                     (0.21)      (0.27)       (0.21)  (0.21)
      Identify Nancy Pelosi as Speaker                                                                             -1.59***    -1.60***     -2.27*** -1.60***
                                                                                                                     (0.54)      (0.54)       (0.78)  (0.54)
      Share voted previous 5 elections (administrative)                                                             -1.16**     -1.15**      -1.17** -2.66***
                                                                                                                     (0.56)      (0.56)       (0.56)  (0.77)
      Mean DV if not close poll=1                                  16.15        16.15       16.05       -0.938       16.02       16.02       16.02           16.02
      State FE                                                       No          Yes         Yes         Yes          Yes         Yes         Yes             Yes
      Demographic Controls                                           No          Yes         Yes         Yes          Yes         Yes         Yes             Yes
      Observations                                                 6,650        6,650       6,612       6,612        6,529       6,529       6,529           6,529
      R-squared                                                     0.01         0.14        0.45        0.02         0.14        0.14        0.14            0.14
     Notes: In all columns, the dependent variable is the post-treatment predicted vote margin, except in column 4 where the dependent variable is change
     in predicted vote margin (i.e., post-treatment predicted vote margin minus pre-treatment predicted vote margin). Robust standard errors in
     parentheses. We use robust standard errors because the randomization is at the person level. Demographic controls are gender, race (Black, Hispanic,
     other, mixed), 10-year age bins (25-34, 35-44, 45-54, 55-64, 65-74, 75+), education dummies (less than high school, some college/associate degree,
     bachelor’s degree, master’s/PhD), and $25k household income bins (25k-50k, 50k-75k, 75k-100k, 100k+). The treatment variable is discrete, i.e., it is
     a dummy for getting the close poll (versus getting the not close poll). * signiﬁcant at 10%; ** signiﬁcant at 5%; *** signiﬁcant at 1%
     Table 4: The Eﬀect of the Close Poll Treatment on the Perceived Likelihood of the Election Being Decided by Less than 100
                                            or Less than 1,000 Votes (2010 Experiment)

      Dep. var.:                                   Prob < 100 votes                       Prob < 1,000 votes                    < 100 or 1,000 votes
                                             (1)         (2)          (3)           (4)           (5)           (6)          (7)          (8)           (9)

      Close poll treatment                  0.80        2.47      2.54      2.93                 2.55          2.33         1.67         2.47          2.43
                                           (1.01)    (0.53)*** (0.53)*** (1.04)***            (0.53)***     (0.52)***     (0.73)**    (0.38)***     (0.37)***
      Prob <100 votes, pre-treat                        0.87      0.85
                                                     (0.01)*** (0.01)***
      Prob <1,000 votes, pre-treat                                                               0.88          0.86
                                                                                              (0.01)***     (0.01)***
      Prob <100 or 1,000                                                                                                                 0.88          0.86
      votes, pre-treat                                                                                                                (0.01)***     (0.01)***
      Mean DV if not close poll=1          24.54       24.55         24.55         31.79         31.79         31.79        28.32        28.33         28.33




48
      State FE                               No          No           Yes           No             No           Yes          No           No            Yes
      Demographic Controls                   No          No           Yes           No             No           Yes          No           No            Yes
      Observations                         3,286       3,282         3,282         3,407         3,406         3,406        6,693        6,688         6,688
      R-squared                             0.00        0.73          0.73         0.00           0.74          0.75        0.00         0.74          0.75

     Notes: The dependent variable is a voter’s post-treatment belief that the election will be decided by less than 100 votes or less than 1,000 votes.
     Voters were either asked about 100 votes or about 1,000 votes. The data are pooled in columns 7-9. Robust standard errors in parentheses.
     Demographic controls are the same as in Table 3. The treatment variable is discrete, i.e., it is a dummy for getting the close poll (versus getting the
     not close poll). * signiﬁcant at 10%; ** signiﬁcant at 5%; *** signiﬁcant at 1%.
                 Table 5: Beliefs About the Closeness of the Election and Voter Turnout, OLS Results (2010 Experiment)

                                            (1)      (2)      (3)       (4)       (5)      (6)      (7)      (8)      (9)     (10)     (11)     (12)
        Pred vote margin, post-treat       -0.03    0.01       0.02
                                          (0.03)   (0.04)    (0.04)
        Pred vote margin, pre-treat                -0.06*     -0.03
                                                   (0.03)    (0.03)
        Pr(Marg <100 votes), post                                     -0.05**    0.01      0.03
                                                                       (0.02)   (0.04)   (0.04)
        Pr(Marg <100 votes), pre                                                 -0.07    -0.06
                                                                                (0.04)   (0.04)
        Pr(Marg <1,000 votes), post                                                                0.00      0.01     0.03
                                                                                                  (0.02)   (0.04)   (0.04)




49
        Pr(Marg <1,000 votes), pre                                                                          -0.00    -0.00
                                                                                                           (0.04)   (0.04)
        <100 or 1,000 votes, post                                                                                             -0.02    0.01       0.03
                                                                                                                             (0.01)   (0.03)    (0.03)
        <100 or 1,000 votes, pre                                                                                                       -0.03     -0.03
                                                                                                                                      (0.03)    (0.03)
        Mean DV                            72.14    72.19    72.19     72.25    72.33    72.33     71.94    71.93    71.93    72.09    72.13    72.13
        Demographic Controls                 No       No      Yes        No       No      Yes        No       No      Yes       No       No      Yes
        Observations                       6,650    6,612    6,612     3,286    3,282    3,282     3,407    3,406    3,406    6,693    6,688    6,688
        R-squared                           0.45     0.45     0.46      0.45     0.45     0.46      0.45     0.45     0.46     0.45     0.45     0.46

     Notes: The dependent variable is turnout (0-1) from administrative voting records, with coeﬃcients multiplied by 100 for ease of readability. Robust
     standard errors in parentheses. All speciﬁcations are OLS regressions. All regressions include state ﬁxed eﬀects and past voting controls (5 dummies
     for having voted in the general elections in 2000, 2002, 2004, 2006, and 2008). The voting rate based on administrative data is 72% (71.9% for close
     poll, 72.1% for not close poll). Demographic controls are as listed in Table 3. * signiﬁcant at 10%; ** signiﬁcant at 5%; *** signiﬁcant at 1%
                  Table 6: Beliefs About the Closeness of the Election and Voter Turnout, IV Results (2010 Experiment)

                                           (1)         (2)        (3)       (4)       (5)        (6)       (7)        (8)       (9)      (10)      (11)       (12)
      IV Results:
      Pred vote margin, post-treat         -0.12      -0.15      -0.16
                                          (0.29)     (0.30)     (0.30)
      Pred vote margin, pre-treat                     0.03       0.06
                                                     (0.17)     (0.17)
      Pr(Marg <100 votes), post                                             -0.52     -0.23     -0.19
                                                                           (1.47)    (0.46)    (0.45)
      Pr(Marg <100 votes), pre                                                        0.13      0.13
                                                                                     (0.40)    (0.38)
      Pr(Marg<1,000 votes), post                                                                           0.27       0.30       0.38
                                                                                                          (0.43)    (0.47)     (0.49)
      Pr(Marg<1,000 votes), pre                                                                                      -0.27      -0.30
                                                                                                                    (0.42)     (0.42)
      <100 or 1,000 votes, post                                                                                                          0.09       0.05       0.08




50
                                                                                                                                        (0.51)    (0.33)     (0.33)
      <100 or 1,000 votes, pre                                                                                                                     -0.07      -0.07
                                                                                                                                                  (0.29)     (0.29)
      F-stat on excl instrument           57.52      86.45       85.96     0.717     23.17     23.68      6.914     21.63      20.04     4.888     43.09     42.93
      Mean DV                             72.14      72.19       72.19     72.25     72.33     72.33      71.94     71.93      71.93     72.09     72.13     72.13
      Demographic Controls                 No         No          Yes       No        No        Yes        No        No         Yes       No        No        Yes
      Observations                        6,650      6,612       6,612     3,286     3,282     3,282      3,407     3,406      3,406     6,693     6,688     6,688
      First Stage Results:
      Close poll treatment               -2.80***   -2.69***   -2.67***     0.85    2.54***    2.55***   2.72***    2.44***   2.33***    1.61**   2.45***   2.42***
                                          (0.37)     (0.29)     (0.29)     (1.01)    (0.53)     (0.52)    (1.03)     (0.53)    (0.52)    (0.73)    (0.37)    (0.37)

     Notes: The dependent variable is turnout (0-1) from administrative voting records, with coeﬃcients multiplied by 100 for ease of readability. Robust
     standard errors in parentheses. In all speciﬁcations, post-treatment beliefs are instrumented with a dummy variable for receiving the close poll
     treatment. All regressions include state ﬁxed eﬀects and past voting controls (5 dummies for having voted in the general elections in 2000, 2002, 2004,
     2006, and 2008). Demographic controls are as listed in Table 3. The voting rate based on administrative data is 72% (71.9% for close poll, 72.1% for
     not close poll). After showing the IV results, we also present the exact ﬁrst stage results, where a belief variable is regressed on a dummy for the close
     poll. These results are slightly diﬀerent from those in Table 3-4 because we include past voting controls. For reduced form results, see Appendix Table
     C24. * signiﬁcant at 10%; ** signiﬁcant at 5%; *** signiﬁcant at 1%
 Table 7: Impact of Close/Not Close Postcard Treatments on Turnout (2014 Experiment)

                                                     (1)        (2)          (3)         (4)
             Close poll (vs. not close poll)        0.29        0.29                     0.29
                                                   (0.25)      (0.25)                   (0.25)
             Close poll (vs. control)                                      0.34*
                                                                           (0.18)
             Not close poll (vs. control)                                   0.05
                                                                           (0.18)
             Small electorate likely                                                     -0.17
                                                                                        (0.25)
             F(Close vs. NotClose)                                         0.242
             Mean DV if not close poll=1           53.45       53.45                    53.45
             Mean DV if control=1                                          53.43
             Additional controls                    No          Yes         Yes          Yes
             Observations                         126,126     126,126    1,385,318     126,126
Notes: The dependent variable is turnout (0-1) from administrative voting records, with coeﬃcients
multiplied by 100 for ease of readability. Turnout is deﬁned at the individual level, and is based on merging
by date of birth. An observation is a person. Standard errors clustered by household are in parentheses.
Each regression includes dummy for the 8 randomization strata; separate dummies for voting in the 2008,
2010, and 2012 elections; and state dummies. The additional controls are controls for gender, race (dummies
for Black, Hispanic, or other), age (dummies for 25-34, 35-44, 45-54, 55-64, 65-74, 75+), and party
registration (dummies for Democrat and Republican, as well as a dummy for missing party registration).
The sample size is much larger in column 3 than columns 1, 2, and 4 because column 3 includes control
households that did not receive a postcard. In contrast, columns 1, 2, and 4 are restricted to individuals in
households that received a postcard. * signiﬁcant at 10%; ** signiﬁcant at 5%; *** signiﬁcant at 1%.




                                                     51
     Table 8: The Relevance of Perceived Closeness for the Observational Relationship between Actual Closeness and Voter Turnout


                           Belief variable used:                         Δ beliefs            95% CI              95% CI             Point          95% CI
                                                                        from 10pp          for impact of       for impact of       estimate          for s
                                                                      drop in actual         beliefs on            beliefs           on s
                                                                          turnout              voting             channel
                           Panel A: 2010 Experiment                          (1)                  (2)                 (3)              (4)             (5)
                           Predicted vote margin                           -4.8pp           [-0.76, 0.43]        [-2.1, 3.7]          0.23       [-0.62, 1.08]
                           Pr(Marg <100 votes)                            +1.4pp            [-1.08, 0.69]        [-1.5, 0.9]         -0.08       [-0.44, 0.28]
                           Pr(Marg <1,000 votes)                          +4.1pp            [-0.58, 1.35]        [-2.4, 5.5]          0.46       [-0.69, 1.61]
                           <100 or 1,000 votes                            +2.8pp            [-0.58, 0.73]          [-1.6, 2]          0.06       [-0.47, 0.59]
                           Overall for 2010                                                                                          0.005       [-0.31, 0.32]
                           Panel B: 2014 Experiment                          (1)                  (2)                 (3)              (4)             (5)




52
                           Predicted vote margin                           -4.8pp           [-0.28, 0.07]        [-0.3, 1.4]          0.15       [-0.10, 0.40]
                           Pr(Marg <100 votes)                            +1.4pp            [-0.08, 0.31]        [-0.1, 0.4]          0.05       [-0.03, 0.13]
                           Pr(Marg <1,000 votes)                          +4.1pp            [-0.09, 0.34]        [-0.4, 1.4]          0.15       [-0.11, 0.40]
                           <100 or 1,000 votes                            +2.8pp            [-0.08, 0.32]        [-0.2, 0.9]          0.10       [-0.07, 0.26]
                           Overall for 2014                                                                                           0.06       [-0.01, 0.14]
                           Panel C: Pooled Data                              (1)                  (2)                 (3)              (4)             (5)
                           Overall for pooled data                                                                                    0.05       [-0.02, 0.13]
                           Reduced form regression                    coef on close poll treatment: 0.25 (se=0.24)                           N=132,831

     Notes: This table estimates s, which is the share of the observational relationship between actual closeness and voter turnout that can be attributed to individual perceptions of
     closeness. For Panels A and B, column 1 is based on the coeﬃcient estimates in columns 1, 3, 5, and 7 of Appendix Table C4. For Panel A, column 2 is based on the 95%
     conﬁdence intervals for post-treatment beliefs in columns 3, 6, 9, and 12 of Table 6. For Panel B, column 2 is based on the conﬁdence intervals from Appendix Table C25. For
     Panels A and B, column 3 equals the conﬁdence interval in column 2 multiplied by column 1. For Panels A and B, column 4 provides a point estimate of s, and it is equal to the
     midpoint of the column 3 conﬁdence interval divided by 3.4pp (10pp*B = 0.34). For Panels A and B, column 5 equals the column 3 conﬁdence intervals divided by 3.4pp. Thus,
     the column 5 conﬁdence intervals for s include estimation error from IV estimation, but ignore estimation error in estimating how perceived closeness responds to actual
     closeness and in how turnout responds to actual closeness. Panel C estimates s while pooling data together from the 2010 and 2014 experiments. First, we perform a reduced
     form regression of turnout on the close poll dummy, the share of times voted in the past, controls for race and gender, 10-year age bins, a year dummy, and state ﬁxed eﬀects,
     while clustering standard errors by household; this regression is shown in the ﬁnal line of the table. Then, we estimate s using the diﬀerent belief measures, and combine those
     estimates together to create an overall s for the pooled data. See Section 6.2 for further information on this exercise, and see Appendix A.3 for further details.
