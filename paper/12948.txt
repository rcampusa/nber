                                 NBER WORKING PAPER SERIES




                              BELIEFS, DOUBTS AND LEARNING:
                                 VALUING ECONOMIC RISK

                                           Lars Peter Hansen

                                         Working Paper 12948
                                 http://www.nber.org/papers/w12948


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                     March 2007




Prepared for the 2007 Ely Lecture of for the American Economic Association. The topics I cover
in this paper have been influenced by an extensive collaboration with Thomas Sargent. I greatly appreciate
conversations with Xiaohong Chen, John Heaton, Ravi Jagannathan, Monika Piazzesi and Martin Schneider.
I owe a special acknowledgement to Thomas Sargent and Grace Tsiang who provided many valuable
comments on preliminary drafts of this paper. Also I want to thank participants at workshops at NYU
and Federal Reserve Bank of Chicago. Junghoon Lee and Ricardo Mayer provided expert research
assistance. This material is based upon work supported by the National Science Foundation under
Award Number SES0519372. The views expressed herein are those of the author(s) and do not necessarily
reflect the views of the National Bureau of Economic Research.

© 2007 by Lars Peter Hansen. All rights reserved. Short sections of text, not to exceed two paragraphs,
may be quoted without explicit permission provided that full credit, including © notice, is given to
the source.
Beliefs, Doubts and Learning: Valuing Economic Risk
Lars Peter Hansen
NBER Working Paper No. 12948
March 2007
JEL No. C11,C32,C52,E21,E44,G1,G12

                                              ABSTRACT

This paper explores two perspectives on the rational expectations hypothesis. One perspective is that
of economic agents in such a model, who form inferences about the future using probabilities implied
by the model. The other is that of an econometrician who makes inferences about the probability model
that economic agents are presumed to use. Typically it is assumed that economic agents know more
than the econometrician, and econometric ambiguity is often withheld from the economic agents. To
understand better both of these perspectives and the relation between them, I appeal to statistical decision
theory to characterize when learning or discriminating among competing probability models is challenging.
I also use choice theory under uncertainty to explore the ramifications of model uncertainty and learning
in environments in which historical data may be insufficient to yield precise probability statements.
I use both tools to reassess the macroeconomic underpinnings of asset pricing models. I illustrate
how statistical ambiguity can alter the risk-return tradeoff familiar from asset pricing; and I show that
when real time learning is included risk premia are larger when macroeconomic growth is lower than
average.

Lars Peter Hansen
Department of Economics
The University of Chicago
1126 East 59th Street
Chicago, IL 60637
and NBER
l-hansen@uchicago.edu
    This essay examines the problem of inference within a rational expectations model from
two perspectives: that of an econometrician and that of the economic agents within the
model. The assumption of rational expectations has been and remains an important com-
ponent to quantitative research. It endows economic decision makers with knowledge of
the probability law implied by the economic model. As such, it is an equilibrium concept.
Imposing rational expectations removed from consideration the need for separately specify-
ing beliefs or subjective components of uncertainty. Thus it simplified model specification
and implied an array of testable implications that are different from those considered previ-
ously. It reframed policy analysis by questioning the effectiveness of policy levers that induce
outcomes that differ systematically from individual beliefs.
    I consider two related problems. The first is the problem of an econometrician who follows
Muth (1961), Lucas and Prescott (1971), Lucas (1972a), Sargent (1973) and an extensive
body of research by adopting an assumption of rational expectations on the part of economic
agents. In implementing this approach, researchers abstract from hard statistical questions
that pertain to model specification and estimation. The second problem is that of economic
decision-makers or investors who must forecast the future to make sophisticated investment
decisions. Should we put econometricians and economic agents on comparable footings, or
should we endow economic agents with much more refined statistical knowledge?
    From an econometric standpoint, the outcome of rational expectations approach is the
availability of extra information about the underlying economic model. This information is
reflected in an extensive set of cross-equation restrictions. These restrictions allow an econo-
metrician to extract more precise information about parameters or to refine the specification
of exogeneous processes for the model builder. To understand the nature of these restric-
tions, consider a dynamic model in which economic agents must make investment decisions
in physical, human or financial capital. The decision to invest is forward looking because
an investment made today has ramifications for the future capital stock. The forward-
looking nature of investment induces decision makers to make predictions or forecasts as
part of their current period choice of investment. The forward-looking perspective affects
equilibrium outcomes including market valuations of capital assets. Rational expectations
econometrics presumes that agents know the probabilities determining exogenous shocks as
they formulate their choices. This translates to an extensive set of cross-equation restrictions
that can be exploited to aid identification and inference.
    The cross-equation restrictions broadly conceived are a powerful tool, but to what extent
should we as applied researchers rely on it? As applied time series econometricians, we
routinely confront challenging problems in model specification. How do we model stochastic
dynamics in the short and long run? What variables are best forecasters? How do we select
among competing models?

                                               1
    A heuristic defense for rational expectations appeals to a Law of Large Numbers and gives
agents a wealth of data. This allows, at least as an approximation, for us the model builders
to presume investor knowledge of a probability model and its parameters. But statistical
inference, estimation and learning can be difficult in practice. In actual decision-making we
may be required to learn about moving targets, to make parametric inferences, to compare
model performance or to gauge the importance of long-run components of uncertainty. As
the statistical problem that agents confront in our model is made complex, rational expec-
tations’ presumed confidence in their knowledge of the probability specification becomes
more tenuous. This leads me to ask: a) how can we burden the investors with some of the
specification problems that challenge the econometrician, and b) when would doing so have
important quantitative implications? I confront these questions formally by exploring tools
that quantify when learning problems are hard, by examining the Bayesian solution to such
problems and by speculating on alternative approaches.
    In this essay I use the literature that links macroeconomics and asset pricing as a labo-
ratory for examining the role of expectations and learning. The linkage of macroeconomics
and finance is a natural choice for study. Even with a rich array of security markets, the
macroeconomic risks cannot be diversified away (averaged out across investors) and hence
are reflected in equilibrium asset prices. Exposure to such risks must be rewarded by the
marketplace. By studying asset pricing, we as model-builders specify the forward-looking
beliefs of investors and how they cope with risk and uncertainty. Prior to developing asset
pricing applications, we consider some stylized statistical decision and inferential problems
that turn out to be informative.
    I ask five questions that are pertinent to modeling the linkages between asset pricing and
macroeconomics:

  1. When is estimation difficult?

  2. What are the consequences for the econometrician?

  3. What are the consequence for economic agents and for equilibrium outcomes?

  4. What are the real time consequences of learning?

  5. How is learning altered when decision makers admit that the models are misspecified
     or simplified?

    By answering these questions we will see how statistical ambiguity alters the predicted
risk-return relation, and we will see when learning induces model uncertainty premia that
are large when macroeconomic growth is sluggish.


                                              2
1       Rational Expectations and Econometrics
The cross-equation restrictions are the novel component to rational expectations econo-
metrics. They are derived by assuming investor knowledge of parameters and solving for
equilibrium decision rules and prices. I consider two examples of such restrictions from the
asset pricing literature, and review some estimation methods designed for estimating models
subject to such restrictions. One example is the equilibrium wealth-consumption ratio and
the other is a depiction of risk prices.


1.1     Cross-equation restrictions
Consider an environment in which equilibrium consumption evolves as:

                                    ct+1 − ct = µc + αzt + σc ut+1
                                         zt+1 = Azt + σz ut+1 ,                          (1)

where ct is the logarithm of consumption, {ut } is an iid sequence of normally distributed
random vectors with mean zero and covariance matrix I and {zt } is process used to fore-
cast consumption growth rates. I take equation (1) as the equilibrium law of motion for
consumption.
    Following Kreps and Porteus (1978) and Epstein and Zin (1989), I use a model of investor
preferences in which the intertemporal composition of risk matters. I will have more to
say about such preferences subsequently. As emphasized by Epstein and Zin (1989), such
preferences give a convenient way to separate risk and intertemporal substitution. Campbell
(1996) and others have used log linear models with such investor preferences to study cross-
sectional returns.

1.1.1    Wealth-consumption ratio

Let ρ be the inverse of the intertemporal elasticity of substitution and β be the subjective
discount factor. Approximate (around ρ = 1):

                  wt − ct ≈ − log(1 − β) + (1 − ρ) βα(I − βA)−1 zt + µv
                                                                       
                                                                                         (2)

where wt is log wealth. The constant term µv includes a risk adjustment. A key part of this
relation is the solution to a prediction problem:
                        "   ∞
                                                          #
                            X
                    E             β j (ct+j − ct+j−1 − µc )|zt = βα(I − βA)−1 zt
                            j=1



                                                    3
Formula (2) uses the fact that preferences I consider are represented with a homogenous of
degree one aggregator. As a consequence, Euler’s theorem gives a simple relation between
the shadow value of the consumption process and the continuation value for that process.
This shadow value includes the corresponding risk adjustments. The intertemporal budget
constraint says that wealth should equal the value of the consumption process. The formula
follows by taking a derivative with respect to ρ.1 ,
    The restriction across equations (1) and (2) is exemplary of the type of restrictions
that typically occur in linear rational expectations models. The matrix A that governs the
dynamics of the {zt } process also shows up in the formula for the wealth-consumption ratio,
and this is the cross equation restriction. Very similar formulas emerge in models of money
demand (Saracoglu and Sargent (1978)), quadratic adjustment cost models (Hansen and
Sargent (1980)) and in log-linear approximations of present-value models (Campbell and
Shiller (1988)).

1.1.2   Shadow risk prices

Assume a unitary elasticity of substitution and a recursive utility risk parameter γ and a
discount factor β and the same consumption dynamics. Consider the price of the one-period
exposure to the shock vector ut+1 . Following the convention in finance, let the price be
quoted in terms of the mean reward for being exposed to uncertainty. For Kreps and Porteus
(1978) preferences the intertemporal composition of risk matters, and as a consequence the
consumption dynamics are reflected in the equilibrium prices, including the one-period risk
prices. This linkage that has been a focal point of work by Bansal and Yaron (2004) and
others. Specifically, the one period price vector is:

                               p = σc + β(γ − 1)α(I − βA)−1 σz .
                                                             


Later I will add more detail about the construction of such prices. For now, I simply observe
that while this price vector is independent of the state vector zt , it depends on the vectors
σc and σz along with the A matrix. Again we have cross equation restrictions, but now the
coefficients that govern variability also come into play.
    Pricing a claim to the next period shock is only one of many prices needed to price a cash
flow or a hypothetical claim to future consumption. Indeed risk prices can be computed for
all horizons. Moreover, as shown by Hansen et al. (2006b) for log linear models like this one,
and more generally by Hansen and Scheinkman (2006), the limit prices are also well defined.
  1
    See Hansen et al. (2006a) for a derivation and see Campbell and Shiller (1988) and Restoy and Weil
(1998) for closely related log-linear approximations.




                                                  4
In this example the limit price is:

                          σc + α(I − A)−1 σz + β(γ − 1)α(I − βA)−1 σz
                                                                   


Cross-equation restrictions again link the consumption dynamics and the risk prices.
     For these asset pricing calculations and for some that follow, it is pedagogically easiest
to view (1) as the outcome of an endowment economy as in Lucas (1978). However, there is
a simple production economy interpretation. Consider a so-called Ak production economy
where output is a linear function of capital and a technology shock. Since consumers have
unitary elasticity of intertemporal substitution (logarithmic utility period utility function),
it is well known that the wealth-consumption ratio should be constant. The first-difference in
consumption reveals the logarithm of the technology shock. The process {zt } is predictor of
the growth rate in the technology. Of course this is a special outcome of this model, driven
in part by the unitary elasticity assumption. The setup abstracts from issues related to
labor supply, adjustment costs and other potentially important macroeconomic ingredients,
but it gives pedagogical simplicity that we will put to good use.2 In summary, under the
simple production-economy interpretation, our exogenous specification of a consumption-
endowment process becomes a statement about the technology shock process.
     In computing the equilibrium outcomes in both of these examples, I have appealed to
rational expectations by endowing agents with knowledge of parameters. A rational ex-
pectations econometrician imposes this knowledge on the part of agents when constructing
likelihood functions, but necessarily confronts statistical uncertainty when conducting empir-
ical investigations. Economic agents have a precision that is absent for the econometrician.
Whether this distinction is important or not will depend on application, but I will suggest
some ways to explore to assess this. Prior to considering such questions, I describe some
previous econometric developments that gave economic agents more information in addition
to knowledge of parameters that generate underlying stochastic processes.


1.2     Econometrics and limited information
Initial contributions to rational expectations econometrics devised methods that permitted
economic agents to observe more data that an econometrician used in an empirical inves-
tigation. To understand how such methods work, consider again the implied model of the
wealth consumption ratio and ask what happens if the econometrician omits information
by omitting components of zt . Let Ht denote the history up to date t of data used by the
   2
    Tallarini (2000) considers a production counterpart with labor supply, but without the extra dependence
in the growth rate of technology shock and without adjustment costs.




                                                    5
econometrician. Rewrite the representation of the wealth-consumption ratio as:
                                              "   ∞
                                                                                  #         !
                                                  X
   wt − ct ≈ − log(1 − β) + µc + (1 − ρ) E              β j (ct+j − ct+j−1 − µc )|Ht + µv       + et
                                                  j=1


The “error” term et captures omitted information. Given that the econometrician solves the
prediction problem correctly based on his more limited information set, the term et satisfies:

                                        E [et |Ht ] = 0

and this property implies orthogonality conditions that are exploitable in econometric esti-
mation. Econometric relations often have other unobservable components or measurement
errors that give additional components to an error term. Alternative econometric methods
were developed for handling estimation in which information available to economic agents
is omitted by an econometrician. (See Shiller (1972), Hansen and Sargent (1980), Hansen
(1982), Cumby et al. (1983) and Hayashi and Sims (1983).) A reduced-information counter-
part to the rational expectations cross-equation restrictions are present in such estimation.
    When the only source of an “error term” is omitted information, then there is another
possible approach. The wealth-consumption ratio may be used to reveal to the econome-
trician an additional component of the information available to economic agents. See for
example the Hansen et al. (1991) and Hansen and Sargent (1991). This is the econome-
tricians’ counterpart to the literature on rational expectations with private information in
which prices reveal information to economic agents.
    There is related literature on estimating and testing asset pricing restrictions. Asset
pricing implications are often represented conveniently as conditional moment restrictions
where the conditioning information set is that of economic agents. By applying the Law of
Iterated Expectations, an econometrician can in effect use a potentially smaller information
set in empirical investigation. (See Hansen and Singleton (1982), Hansen and Richard (1987),
and others.)
    All of these methods exploit the potential information advantage of investors in deducing
testable restrictions. The methods work if the information that is omitted can be averaged
out over time. These methods lose their reliability, however, when omitted information has
has a very low frequency or time invariant component as in the case infrequent regime shifts.
    While this literature aimed at giving economic agents more information than an econo-
metrician along with knowledge of parameters, in what follows I will explore ways to remove
some of this disparity and I will illustrate some tools from statistics that are valuable in
quantifying when model selection is difficult.



                                              6
2     Statistical Precision
Statistical inference is at the core of decision making under uncertainty. According to statis-
tical decision theory, enlightened choices are those based on the data that has been observed.
When imposing rational expectations a researcher must decide with what prior information
to endow the decision maker. This specification could have trivial consequences, or it could
have consequences of central interest. In this section I consider a measure of statistical close-
ness that will be used later in this paper. This measure helps quantify statistical challenges
for econometricians as well as economic agents.
    Suppose there is some initial uncertainty about the model. This could come from two
sources: the econometrician not knowing the model (this is a well known phenomenon in
rational expectations econometrics) or the agents themselves not knowing it. Past obser-
vations should be informative in model selection for either the econometrician or economic
agent. Bayesian decision theory offers a tractable way to proceed. It gives us an excellent
benchmark and starting point for understanding when learning problems are hard.
    In a Markov setting, a decision maker observes states or signals, conditioning actions
on these observations. Models are statistically close if they are hard to tell apart given an
observed history. With a richer history, i.e. more data, a decision maker can distinguish
between competing models more easily. Rational expectations as an approximation conceives
of a limit that is used to justify private agents’ commitment to one model. When is this
a good approximation? A statistical investigation initiated by Chernoff (1952) gives a way
to measure how close probability models are, one to another. It quantifies when statistical
discrimination is hard, and what in particular makes learning challenging.
    Suppose there is a large data set available that is used prior to a decision to commit
to one of two models, say model a or model b. Consider an idealized or simplified decision
problem in which one of these models is fully embraced given this historical record without
challenge. By a model I mean a full probabilistic specification of a vector of observations
Y . Each model provides an alternative probability specification for the data. Thus a model
implies a likelihood function, whose logarithms we denote by `(y|m = a) and `(y|m = b)
respectively where m is used to denote the model. The difference in these log-likelihoods
summarizes the statistical information that is available to tell one model from another given
data, but more information is required to determine the threshold for such a decision. For
instance, Bayesian and mini-max model selection lead us to a decision rule of the form:
choose model a if
                                  `(Y |m = a) − `(Y |m = b) ≥ c

where c is some threshold value. What determines the threshold value c? Two things:
the losses associated with selecting the wrong model and the prior probabilities. Under

                                               7
symmetric losses and equal prior probabilities for each model the threshold c is zero. Under
symmetric losses, the mini-max solution is to choose c so that the probability of making a
mistake when model a is true is the same as the probability of making a mistake when model
b is true. Other choices of loss functions or priors result in other choices of c. As samples
becomes more informative, the mistake probabilities converge to zero under either Bayesian
priors that are not degenerate or under the mini-max solution.
    Limiting arguments can be informative. After all, rational expectations is itself motivated
by a limiting calculation, the limit of an infinite number of past observations in which the
unknown model is fully revealed. Chernoff’s method suggests a refinement of this by asking
what happens to mistake probabilities as the sample size of signals increases. Chernoff
studies this question when the data generation is iid, but there are extensions designed to
accommodate temporal dependence in Markov environments. (See for example Newman
and Stuck (1979).) Interestingly, the mistake probabilities eventually decay at a common
geometric rate. The decay rate is independent of the precise choice of priors and it is the
same for the mini-max solution. I call this rate the Chernoff rate and denote it by ρ.3
    In an iid environment, Chernoff’s analysis leads to the study of the following entity. Let
fa be one probability density and fb another, both of which are absolutely continuous with
respect to a measure η. This absolute continuity is pertinent so that we may form likelihood
functions that can be compared. The Chernoff rate for iid data is:

                 ρ = − log sup E (exp [α`(Yi |m = b) − α`(Yi |m = a)] |m = a) .
                             0≤α≤1


This formula is symmetric in the role of the models, as can be verified by interchanging the
roles of the two models throughout and by replacing α by 1 − α. The Chernoff rate is jus-
tified by constructing convenient bounds of indicator functions with exponential functions.4
Chernoff (1952)’s elegant analysis helped to initiate an applied mathematics literature on
the theory of large deviations.
     The following example is simple but revealing, nevertheless.

Example 2.1. Suppose that xt is iid normal. Under model a the mean is µa and under
model b the model is µb . For both models the covariance matrix is Σ. In addition suppose
that model a is selected over model b if the log-likelihood exceeds a threshold. This selection
   3
   It is often called Chernoff entropy in the statistics literature.
   4
   While it is the use of relative likelihood functions that links this optimal statistical decision theory,
Chernoff (1952) also explores discrimination based on other ad hoc statistics.




                                                     8
criterion leads us to compute the difference in the log likelihood:

                       T                                       T
                   1X                                 1X
                 −       (xt − µa )0 Σ−1 (xt − µa ) +       (xt − µb )0 Σ−1 (xt − µb ) =
                   2 t=1                              2 t=1
                     T
                     X                               T                T
                 −         (xt )0 Σ−1 (µb − µa ) +     (µb )0 Σ−1 µb − (µa )0 Σ−1 µa .
                     t=1
                                                     2                2

Notice that the random variable in the second equality is normally distributed under each
model. Under model a the distribution is normal with mean:

      T                                                         T
         −2(µa )0 Σ−1 (µb − µa ) + (µb )0 Σ−1 µb − (µa )0 Σ−1 µa = (µa − µb )0 Σ−1 (µa − µb )
      2                                                           2

and variance equal to twice this number. Under model b the mean is the negative of this
quantity and the variance remains the same. Thus the detection error probabilities are rep-
resentable as probabilities that normally distributed random variables exceeds a threshold.

   In this simple example the Chernoff rate is:

                                        1
                                          (µa − µb )0 Σ−1 (µa − µb ) .
                                                                    
                                   ρ=
                                        8

This can be inferred directly from properties of the cumulative normal distribution, although
the Chernoff (1952) analysis is much more generally applicable. The logarithm of the average
probability of making a mistake converges to zero at a rate ρ given by this formula. This
representation captures in a formal sense the simple idea that when the population means
are close together, they are very hard to distinguish statistically. In this case, the resulting
model classification error probabilities converge to zero very slowly, and conversely when the
means are far apart.
   While the simplicity of this example is revealing, the absence of temporal dependence
and nonlinearity is limiting. I will explore a dynamic specification next.

Example 2.2. Following Hansen and Sargent (2006a) consider two models of consumption,
one with a long run risk component and one without. Model a is a special case of the
consumption dynamics given in (1) and is motivated by the analysis in Bansal and Yaron
(2004):

                                ct+1 − ct = .0056 + zt + .0054u1,t+1
                                     zt+1 = .98zt + .00047u2,t+1 ,                              (3)

and model b has the same form but with zt = 0 implying that consumption growth rates are


                                                       9
iid.5

    Are the models a and b easy to distinguish? The mistake probabilities and their loga-
rithms are given in figures 1 and 2. These figures quantify the notion that the two models are
close using an extension to Chernoff (1952)’s calculations. For both models the statistician
is presumed not to know the population mean and for model a the statistician does not
know the hidden state. All other parameters are known, arguably simplifying the task of a
decision maker. Data on consumption growth rates are used when attempting to the tell the
models apart.
    From figure 1 we see that even with a sample size of one hundred (say twenty five years)
there is more than a twenty percent chance of making a mistake. Increasing the sample size
to two hundred reduces the probability to about ten percent. By sample size five hundred
a decision maker can confidently determine the correct model. Taking logarithms, in figure
2, the growth rate analyzed by Chernoff (1952) and Newman and Stuck (1979) becomes
evident. After an initial period or more rapid learning, the logarithm of the probabilities
decay approximately linearly. The limiting slope is the Chernoff rate. This is an example
in which model selection is difficult for an econometrician, and it is arguably problematic to
assume that investors inside a rational expectations model solved it ex ante.
    Arguably, sophisticated investors know more and process more information. Perhaps
this is sufficient for confidence to emerge. There may be other information or other past
signals used by economic agents in their decision making. Our simplistic one signal model
may dramatically understate prior information. To the contrary, however, the available past
history may be limited. For instance, endowing investors with full confidence in model a
applied to post war data could be misguided, given the previous era was characterized by
higher consumption volatility, two world wars and a depression.


3       Risk Prices and Statistical Ambiguity
In this section I will show that there is an intriguing link between the statistical detection
problem we have just described and what is known as a risk price vector in the finance
literature. First, I elaborate on the notion of a risk price vector by borrowing some familiar
results, and then I develop a link between the Chernoff rate from statistics and the maximal
    5
    The mean growth rate .0056 is the sample mean for post war consumption growth and coefficient on
.0054 on u1,t+1 is the sample standard deviation. In some of the some my calculations using continuous-time
approximations, simplicity is achieved by assuming a common value for this coefficient for models with and
without consumption predictability. The parameter value .0047 is the mode of a very flat likelihood function
constructed by fixing the two volatility parameters and the autoregressive parameter for {zt }. The data and
the likelihood function construction are the same as in Hansen and Sargent (2006a).



                                                    10
Sharpe ratio. With this link I quantify sensitivity of the measured tradeoff between risk and
return to small statistical changes in the inputs.


3.1    A Digression on Risk Prices
Risk prices are the compensation for a given risk exposure. They are expressed conveniently
in terms required mean rewards for confronting the risk. Such prices are the core ingredients
in the construction of mean-standard deviation frontiers and are valuable for summarizing
asset pricing implications.
    Consider an n-dimensional random vector of the form: µ + Λu where u is a normally
distributed random vector with mean zero and covariance matrix I. The matrix Λ determines
the risk exposure to be priced. This random vector has mean µ and covariance matrix
Σ = ΛΛ0 . I price risks that are lognormal and constructed as a function this random vector:
                                                            
                                                 1
                               exp ω · µ + ω Λu − ω 0 Σω
                                                0
                                                 2

for alternative choices of the n-dimensional vector ω. The quadratic form in ω is subtracted
so that this risk has mean with a logarithm given by ω · µ.
    Let exp(rf ) be the risk free return. The logarithm of the prices can often be represented
as:
                                  log P (ω) = ω · µ − rf − ω 0 Λp

for some n-dimensional vector p, where the vector p contains what are typically called the
risk prices.
    Suppose that the matrix Λ is restricted so that whenever ω is a coordinate vector, a
vector with zeros except for one entry which instead contains a one, the risk has a unit price
P (ω) or a zero logarithm of a price. Such an asset payoff is a gross return. Moreover, the
payoff associated with any choice of ω with coordinates that sum to one, i.e. ω · 1n = 1, is
also a gross return and hence has a price with logarithms that is zero. Thus, in logarithms
the excess return over the risk free return is:

                                       ω · µ − rf = ω 0 Λp

for any ω such that ω · 1n = 0. The vector p prices the exposure to shock u and is the risk
price vector. It gives the compensation for risk exposure on the part of investors in terms of
logarithms of means.
    Such formulas generalize to continuous time economies with Brownian motion risk. The
risk prices given in section 1.1.2 have this form where u is a shock vector at a future date.


                                               11
While the risk prices in that example are constant over time, in section 7 I will give examples
where they vary over time.


3.2     Sharpe Ratios
The familiar Sharpe ratio (Sharpe (1964)) is the ratio of an excess return to its volatility. I
consider the logarithm counterpart and maximize by choice of ω:

                                  ω · µ − rfb        ω 0 Λp
                          max      √          = max √
                        ω,ω·1n =1     ω 0 Σω      ω   ω 0 Σω
                                              = |p|
                                                                        1/2
                                              = (µ − rf )0 Σ−1 (µ − rf )
                                                
                                                                             .

The solution measures how steep the risk-return tradeoff is, but it also reveals how large the
price vector p should be. A steeper slope of the mean-standard deviation frontier for asset
returns imposes a sharper lower bound on |p|.
    Both risk prices and maximal Sharpe ratios are of interest as diagnostics for asset pricing
models. Risk prices give a direct implication when they can be measured accurately; but
a weaker challenge is is to compare |p| from a model to the empirical solution to (4) for
a limited number of assets used in an empirical analysis. Omitting assets will still give a
lower bound on |p|. Moreover, there are direct extensions that do not require the existence
of a risk-free rate and are not premised on log-normality (e.g. see Shiller (1982) and Hansen
and Jagannathan (1991)). Omitting conditioning information has a well a known distortion
characterized by Hansen and Richard (1987).6


3.3     Statistical Ambiguity
Even if all pertinent risks can be measured by an econometrician, the mean µ is not revealed
perfectly to an econometrician or perhaps even to investors. Both perspectives are of interest.
I now suggest an approach and answer to the question: Can a small amount of statistical
ambiguity explain part of the asset pricing anomalies? Part of what might be attributed to
a large risk price p is perhaps small statistical change in the underlying probability model.
    Suppose statistical ambiguity leads us to consider an alternative mean µ∗ . The change
µ∗ − µ alters the mean-standard deviation tradeoff. Substitute this change into the maximal
   6
    Much has been made of the equity premium puzzle in macroeconomics including, in particular, Mehra
and Prescott (1985). For our purposes it is better to explore a more flexible characterization of return
heterogeneity as described here. Particular assets with “special” returns can be easily omitted from an
empirical analysis. While Treasury bills may contain an additional liquidity premia because of their role as
close cash substitutes, an econometrician can compute the maximal Sharpe ratio from other equity returns
and alternative risk free benchmarks.


                                                    12
Sharpe ratio:
                        ∗                                             1/2
                        (µ − µ + µ − 1n rf )0 Σ−1 (µ∗ − µ + µ − 1n rf )     .

Using the Triangle Inequality,
                 ∗                   1/2                                 1/2
                 (µ − µ)0 Σ−1 (µ∗ − µ)     − (µ − 1n rf )0 Σ−1 (µ − 1n rf )
                                             
                                                                             1/2
                                           ≤ (µ∗ − 1n rf )0 Σ−1 (µ∗ − 1n rf )
                                             
                                                                                  .

It is the first inequality that interests us most, because it is shows that if
                                      ∗
                                      (µ − µ)0 Σ−1 (µ∗ − µ)
                                                           
                                                                                             (4)

is sizable and offsets the initial Sharpe ratio, then there is a sizable movement in the Sharpe
ratio.
    More can said if I give myself the flexibility to choose the direction of the change. Suppose
that I maximize the new Sharpe ratio by choice of µ∗ subject to a constraint on (4). With
this optimization, the magnitude of the constraint gives the movement in the Sharpe ratio.
    Chernoff’s formula tells us when (4) can be economically meaningful but statistically
small. Squaring (4) and dividing by eight gives the Chernoff rate. This gives a formal link
between the statistical discrimination of alternative models and what are referred to risk
prices. The link between the Chernoff rate and the maximal Sharpe ratio gives an easily
quantifiable role for statistical ambiguity either on the part of an econometrician or on the
part of investors in the interpretation of the risk-return tradeoff.
    Could the maximal Sharpe ratio be equivalent to placing alternative models the table
that are hard to discriminate statistically? Maybe it is too much to ask to have models of
risk premia that assume investor knowledge of parameters bear the full brunt of explaining
large Sharpe ratios. Statistical uncertainty might well account for a substantial portion of
this ratio.
    Consider a Chernoff rate of 1% per annum or .25% per quarter. Multiply by eight and
take the square root. This gives a increase of about .14 in the maximum Sharpe ratio.
Alternatively, a Chernoff rate of .5% per annum gives an increase of .1 in the maximum
Sharpe ratio. These are sizeable movements in the quarterly Sharpe ratio accounting for
somewhere between and a third and half of typical empirical measurements.
    There are two alternative perspectives on this link. First is measurement uncertainty
faced by an econometrician even when economic agents know the relevant parameters. For
instance the risk price model of section 1.1.2 may be correct, but the econometrician has
imperfect measurements. While the Chernoff calculation is suggestive, there are well known
ways to account for statistical sampling errors for Sharpe ratios in more flexible ways in-


                                                13
cluding, for example Gibbons et al. (1989). Alternatively, investors themselves may face this
ambiguity which may alter the predicted value of p and hence |p| coming from the economic
model. I will have more to say about this in the next section.
    The particular formula for the Chernoff rate was produced under very special assump-
tions, much too special for more serious quantitative work. Means and variances are de-
pendent on conditioning information. Normal distributions may be a poor approximations.
Anderson et al. (2003) build on the work of Newman and Stuck (1979) to develop this link
more fully. Under more general circumstances, a distinction must be made between local
discrimination rates and global discrimination rates. In continuous time models with a Brow-
nian motion information structure, the local discrimination rate has the same representation
based on a normal distributions with common covariances, but this rate can be state depen-
dent. Thus link between Sharpe ratios and the local Chernoff rate applies to an important
class of asset pricing models. The limiting decay rate is a global rate that averages the local
rate in a particular sense.


4     Statistical Challenges
In this section, I revisit model a (see equation (3)) of example 2.2 from two perspectives. I
consider results first from the vantage point of an econometrician and second from that of
investors in an equilibrium valuation model.


4.1    The Struggling Econometrician
An econometrician uses post-war data to estimate parameters that are imputed to investors.
I present the statistical evidence available to the econometrician in estimating the model.
I construct posterior distributions from alternative priors and focus on two parameters in
particular: the autoregressive parameter for the state variable process {zt } and the mean
growth rate in consumption. For simplicity and to anticipate some of the calculations that
follow, I fixed the coefficient on u1,t+1 . I report priors that are not informative (loose priors)
and priors that are informative (tight priors). It turns out that there is very little sample
information about the coefficient on u2,t+1 . As a consequence, I used a informative prior for
this coefficient in generating the “loose prior” results, and I fixed this coefficient at .00047
when generating the “tight prior” results.
    I depict the priors and posteriors in figure 3. There is very weak sample information
about the autoregressive parameter, and priors are potentially important. There is some
evidence favoring coefficients close to unity. Under our rational expectations solutions we
took the parameter to be .98, in large part because of our interest in a model with a low


                                                14
frequency component.7 The posterior distribution for the mean for consumption growth is
less sensitive to priors. Without exploiting cross equation restrictions, there is only very
weak statistical evidence about the process {zt } which is hidden from the econometrician.
Imposing the cross-equation restrictions begs the question of where investors come up with
knowledge of the parameters that govern this process.


4.2     The Struggling Investors
The rational expectations solution of imposing parameter values may be too extreme, but
for this model it is also problematic to use loose priors. Geweke (2001) and Weitzman
(2007) show dramatic asset return sensitivity to such priors in models without consumption
predictability. While loose priors are useful in presenting statistical evidence, it is less clear
that we should embrace them in models of investor behavior. How to specify meaningful
priors for investors becomes an important specification problem when Bayesian learning is
incorporated into a rational expectations asset pricing model and in the extensions that I
will consider. Learning will be featured in the next two sections, but before incorporating
this extra dimension, I want to re-examine the risk prices derived under rational expectations
and suggest an alternative interpretation for one of their components.
    In section 1.1.2 I gave the risk price vector for an economy with predictable consumption.
Since investors are endowed with preferences for which the intertemporal composition of risk
matters, the presence of consumption predictability alters the prices. Recall the one-period
risk price vector is
                            p = σc + (γ − 1) σc + βα(I − βA)−1 σz
                                                                   

One way to make risk prices large is to endow investors with large values of the risk aversion
parameter γ. While γ is a measure of risk aversion in the recursive utility model, Anderson
et al. (2003) give a rather different interpretation. They imagine investors treat the model as
possibly misspecified and ask what forms of model misspecification investors fear the most.
The answer is a mean shift in the shock vector ut+1 that is proportional to the final term
above
                                      σc + βα(I − βA)−1 σz .
                                                          
                                                                                            (5)

This is deduced from computing the continuation value for the consumption process. Instead
of a measure of risk aversion, γ − 1 is used to quantify an investors’ concern about model
misspecification.
   7
     Without this focus one might want to examine other aspects of consumption dynamics for which a
richer model could be employed. Hansen et al. (2006b) use corporate earnings as a predictor variable and
document a low frequency component using a vector autoregression provided that a cointegration restriction
is imposed.



                                                   15
    Is this distortion statistically large? Could investors be tolerating statistical departures
of this magnitude because of their concern about model misspecification? Our earlier Cher-
noff calculations are informative. Even with temporal dependence in the underlying data
generating process, the Chernoff discrimination rate is:
                                                                          2
                                            2 |σc   + βα(I − βA)−1 σz |
                                     |γ − 1|                            .
                                                           8

Consider now the parameter values given in first model example 2.2. Then
                                                              2
                                    |σc + βα(I − βA)−1 σz |
                         |γ − 1|2                           ≈ .000061|γ − 1|2 .                              (6)
                                               8

For instance when β = .998 and γ = 5, the implied discrimination rate is just about a
half percent per year. This change endows the state variable process {zt } with a mean of
−.002 and a direct mean decrease in the consumption growth equation of −.0001, which is
inconsequential. The contribution to |p| measure by the norm of (5) scaled by γ − 1 = 4
is about .09. While both distortions lower the average growth rate in consumption, only
the second one is substantial. Investors make a conservative adjustment to the mean of the
shock process {u2,t } and hence to the unconditional mean of {zt }. This calculation gives
a statistical basis for a sizeable model uncertainty premium as a component of p. Similar
calculations can be made easily for other values of γ.
    While a mean distortion of −.002 in the consumption dynamics looks sizable, it is not
large relative to sampling uncertainty. The highly persistent process {zt } makes inference
about consumption growth rates difficult.8 Moreover, my calculation is sensitive to the inputs
that are not measured well by an econometrician. Conditioned on .98, the statistical evidence
for σz is not very sharp. Reducing σz by one half only changes the log-likelihood function9 by
.3. Such a change in σz reduces the Chernoff rate and the implied mean distortion attributed
to the {zt } process by factors in excess of three.
    Suppose that investors only use data on aggregate consumption. This presumes a dif-
ferent model for consumption growth rates, but one with the same implied probabilities for
the consumption process. This equivalent representation is referred to as the innovations
representation in the time series literature and is given by:

                                  ct+1 − ct = .0056 + z̄t + .0056ūt+1
   8
     For the persistence and volatility parameters assumed in this model, µc is estimated with much less
accuracy than that shown in figure 3. The posteriors reported in this figure assign considerable weight to
processes with much less persistence.
   9
     As a rough guide, twice the log-likelihood difference is a little more than half the mean of a χ2 (1) random
variable.



                                                       16
                                    z̄t+1 = .98z̄t + .00037ūt+1

where {ūt+1 } is a scalar iid sequence of standard normally distributed random variables. The
implied distortions for the consumption growth rate given say γ = 5 are very close to those
I gave previously based on observing both consumption growth and its predictor process.
     In this subsection I used a link between distorted beliefs and continuation values to
reinterpret part of the risk price vector p as reflecting a concern about model misspecification.
This is special case of a more general approach called exponential tilting, an approach that
I will have more to say about in sections 6 and 7. Investors tilt probabilities, in this case
means of shocks, in directions that value functions suggests are most troublesome. This
tilting gives a justification for pessimism in beliefs. Cecchetti et al. (2000) and Abel (2002)
have shown how endowing investors with pessimistic beliefs can help to solve asset pricing
puzzles.10
     While the tilted probabilities in this section are represented as time invariant mean shifts,
by considering learning, I will obtain a source of time-variation for the uncertainty premia.


5     Learning
Up until now we have explored econometric concerns and statistical ambiguity without any
explicit reference to learning. Our next task is to explore the real time implications of
learning on what financial econometricians refer to as risk prices. To explore learning in
a tractable way, consider what is known in many disciplines as a hidden Markov model
(HMM). In what follows we let ξ be a realized value of the signal while s∗ denotes the signal,
which is a random vector. We make the analogous distinction between ζ and z. Suppose
that the probability density for a signal or observed outcome s∗ given a Markov state z is
denoted by f (·|z). This density is defined relative to an underlying measure dη(ξ) over the
space of potential signals S. A realized state is presumed to reside in a space Z of potential
states.
    In a HMM the state z is disguised from the decision maker. The vector z could be a) a
discrete indicator of alternative models; b) an unknown parameter; c) a hidden state that
evolves over time in accordance to a Markov process as in a regime shift model of Wonham
(1964), Sclove (1983) and Hamilton (1989). The signal or outcome s∗ is observed in the
next time period. If z were observed, we would just use f as the density for the next period
outcome s∗ . Instead inferences must be made about z to deduce the probability distribution
for s∗ . For simplicity, we consider the case in which learning is passive. That is, actions do
  10
     Abel (2002) also suggests that sampling uncertainty and a concern for robust might be important com-
ponents in justifying pessimism and doubt on the part of private agents.


                                                   17
not alter the precision of the signals.


5.1       Compound Lottery
To apply recent advances in decision theory, it is advantageous to view the HMM as specifying
a compound lottery repeated over time. Suppose for the moment that z is observed. Then
for each z, f (·|z) is a lottery over the outcome s∗ . When z is not observed, randomness of
z makes the probability specification a compound lottery. Given a distribution π, we may
reduce this compound lottery by integrating out over the state space Z:
                                                    Z
                                          f¯(ξ) =       f (ξ|ζ)dπ(ζ).

This reduction gives a density for s∗ that may be used directly in decision-making without
knowledge of z. In the applications that interest us, π is a distribution conditioned on a
history H of signals.11


5.2       Recursive Implementation
In an environment with repeated signals, the time t distribution, πt , inherits dependence on
calendar time through the past history of signals. Bayes rule tells us how to update this
equation in response to a new signal. Repeated applications gives a recursive implementation
of Bayes rule.
    Consider some special cases:

5.2.1      Case 1: Time Invariant Markov State

Suppose that z is time invariant as in the case of an unknown parameter or an indicator
of a model. Let π denote a probability distribution conditioned on a history H, and let π ∗
denote the updated probability measure given that s∗ is observed. Bayes rule gives:

                                                    f (s∗ |ζ)dπ(ζ)
                                        π ∗ (dζ) = R                .
                                                     f (s∗ |ζ)dπ(ζ)

The signal s∗ enters directly into this evolution equation. Applying this formula repeatedly
for a sequence of signals generates a sequence of probability distributions {πt } for z that
reflect the accumulation of information contained in current and past signals.
    Since z is time invariant the constructed state probability distribution {πt } is a mar-
tingale. Since πt is a probability distribution, this requires an explanation. If the set of
 11
      Formally, H is a sigma algebra of conditioning events generated by current and past signals.



                                                        18
potential states Z consists of only a finite number of entries, then each of the probabilities
is a martingale. More generally, let φ be any bounded function of the hidden state z.12 An
example of such a function is the so-called indicator functions that is one on set and zero
                                  R
on its complement. The integral φ(ζ)dπ(ζ) gives the conditional expectation of φ(z) when
dπ(ζ) is the conditional distribution for z given the current and past signal history H.
    In contrast to π, the distribution π ∗ incorporates information available in the signal s∗ .
Then

                                           f (s∗ |ζ)φ(ζ)dπ(ζ)
           Z                      Z R                       Z               
                      ∗
         E     φ(ζ)dπ (ζ)|H =              R
                                                   ∗ |ζ)dπ(ζ)
                                                                    f (s |ζ)π(dζ) dη(s∗ )
                                                                        ∗

                                    Z Z       f (s
                                =         f (s∗ |ζ)φ(ζ)dπ(ζ)dη(s∗ )
                                    Z
                                =      φ(ζ)dπ(ζ)                                            (7)

       R
since f (ξ|ζ)dη(ξ) = 1. This implies the familiar martingale property associated with
                                           R
parameter learning: the best forecast of φ(ζ)πt+1 (dζ) given current period information is
R
  φ(ζ)πt (dζ). Thus given the sequence of probability distributions {πt (dζ) : t = 0, 1, ...},
                                   R
the sequence random variables { φ(ζ)πt (dζ) : t = 0, 1, ...} is a martingale. In fact is is a
bounded martingale and it necessarily converges.
    By making an invariant z unobservable, we have introduced a strong form of stochastic
dependence as reflected by the martingale property. Note, however, that the stochastic
structure will become degenerate as the martingale converges. When learning problems are
difficult, the convergence will be slow as we have seen in our discussion of Chernoff (1952).

5.2.2      Case 2: Time Varying Markov State

Consider the case in which z is not invariant and its evolution is modeled as a Markov process.
The dynamics for this hidden Markov state influence directly the learning dynamics in ways
that I will illustrate. Let T (ζ ∗ |ζ) be the transition density of z relative to a measure λ(dζ)
over the hidden states. The measure λ is chosen for convenience depending upon the details
of the application. Later I will feature examples in which state space Z contains a finite set
of values and the measure λ just assigns one to each element of this set. Other measures are
used when z is continuous.
    Our previous calculations extend except that the updating equation for the z ∗ posterior
distribution π ∗ must accommodate this evolution. From Bayes rule:

                                                 T (ζ ∗ |ζ) f (s∗ |ζ) dπ (ζ) dλ(ζ ∗ )
                                             R
                               ∗    ∗
                             π (dζ ) =           RR
                                                    T (ζ̃|ζ)f (s∗ |ζ)dλ(ζ̃)dπ(ζ)
 12
      Formally, we also restrict φ to be Borel measurable.


                                                        19
                                   = T̄ (s∗ , π)                                               (8)

The distribution π ∗ evolves from π as a function of the signal s∗ in accordance to the
function T̄ . Given the stochastic evolution of the hidden state, we lose the martingale
property. The case in which z is invariant considered previously is a special case with
a degenerate specification of the transition law: z ∗ = z. When the hidden state has a
nondegenerate transition law, we lose the martingale property. If the transition law T is
stochastically stable (that is, there is unique stationary distribution associated with T ),
then this asymptotic stability carries over to the evolution of the probability distributions:
{πt } captured by T̄ .


5.3    A New Markov Process
It follows from what we have just shown that we can represent this form of learning as a
new Markov process. For this new process, the hidden state z is replaced by a distribution
over the hidden state. The density for the signal is
                                                Z
                                    f¯(ξ|π) =        f (ξ|ζ)dπ(ζ)

and π evolves according to ḡ given in (8). Thus we may conceive of learning as justifying a
Markov process with a “state variable” π.
    I derived this learning solution using Bayes rule, but otherwise we did not appeal to a
specific decision problem. The hidden state may be hidden to the econometrician or it may
be subjective uncertainty in the minds of investors. If the former, its estimation is only
a problem of an econometrician. If the latter, both the econometrician and the investor
being modeled may aim to integrate it out or reduce the compound lottery. For instance,
I could use this learning solution to alter the model of exogenous shock processes such
as technology shocks. I simply replace one state variable, z, by another, the distribution
π. The recursive solution becomes an input into our rational expectations model with the
additional econometric challenge of specifying an initial condition for π, a priori.13 Since π
is a distribution, for many state spaces it can be an infinite dimensional state variable; but
that is a computational, not a conceptual issue.
    Given this change, I may define a rational expectations equilibrium to determine the
endogenous state variables such as capital stocks and the endogenous prices. More generally,
I could introduce private signals and endogenously determined price signals. This approach
  13
    Moreover, since z may be disguised, identification of its dynamics as captured by T may be more
challenging.


                                                    20
to learning is an enrichment of rational expectations to include subjective uncertainty while
preserving the essential equilibrium components. The resulting equilibrium model is what
Bray and Kreps (1987) call learning within a rational expectations model. After all, Lucas
(1972b)’s use of rational expectations in a private information economy has agents learning
from price signals, so aspects of learning have been central features in rational expectations
equilibria from the outset.
    There are other ways to introduce learning that push us outside the realm of rational
expectations in a more substantial way. For instance, we might pose the learning challenge
directly on the price dynamics or the endogenous state variables. This has led to what
Bray and Kreps (1987) call a model of learning about a rational expectations equilibrium.
Adaptive control methods or Bayesian methods are applied that fail to impose some of the
internal consistency conditions of a rational expectations equilibrium. See Bray (1982), Chen
and White (1998), Marcet and Sargent (1989), Sargent (1999) and Evans and Honkapohja
(2001) for examples of what has become an important literature in macroeconomics. Agents
are assumed to apply Bayesian learning methods to misspecified but typically simpler models
or they apply adaptive methods that aim to provide a more flexible approximation. The
outcome of these misspecificied Bayesian or adaptive learning algorithms are fully embraced
as beliefs by the economic agents when making forward-looking decisions. There is typically
no acknowledgment of the potential misspecification. The dynamic systems may have limit
points, but they may imply weaker consistency requirements than a rational expectations
equilibrium.14 Since this approach to learning does not presume that decision makers in
the model fully perceive the uncertainty they confront, the resulting equilibria ignore a
potentially important source of uncertainty premia that might show up in prices that clear
security markets. The economic agents in such models experience no specification doubts.


5.4     Dynamic Learning in a Regime Shift Model
To illustrate the dynamics of learning, we use a solution first characterized by Wonham
(1964) to a filtering problem that economists sometimes refer to as a regime shift model.
The model and solution are given most conveniently in continuous time. Consider a signal:

                                       dst = κ · zt dt + σdBt

where {Bt } is standard Brownian motion and {zt } is a hidden state Markov chain with
intensity matrix A. The intensity matrix conveniently summarizes the matrix of transition
probabilities for the hidden state via the formula: exp(tA) for any positive number t. The
  14
    The weaker equilibrium concept is known as a self-confirming equilibrium. See Sargent (1999) for a
discussion.


                                                 21
realized value of zt is a coordinate vector. Thus κ · zt selects among the entries in the
vector κ in determining the local growth rate for the signal process. This specification is a
continuous-time counterpart to the regime switching model of Sclove (1983) and Hamilton
(1989). It has been used in asset pricing models by David (1997) and Veronesi (2000). Given
this model we can think of dst conditioned on the state zt as a compound lottery.
    The Wonham filter gives the solution to reducing the compound lotteries while updating
probabilities based on past data. Since zt is a coordinate vector, its conditional expectation
given the signal history is the vector of hidden state conditional probabilities. As for notation
we let z̄t = E (zt |Ht ), which is the vector of hidden state probabilities. Thus the conditional
mean z̄t contains the vector of state probabilities used to depict πt . The recursive filtering
solution is a stochastic differential equation represented in terms of an alternative standard
Brownian motion {B̄t }:

                            dst = κ · z̄t dt + σdB̄t
                            dz̄t = A0 z̄t dt + ∆(z̄) (dst − κ · z̄t dt)
                                   1
                           ∆(z̄) =     diag(z̄t ) (κ − 1n κ · z̄t )
                                   σ2

The first equation gives the continuous-time counterpart to f¯, the density for the signal, and
the second equation the counterpart to T̄ , the evolution equation for the probabilities. The
Brownian motion increment dB̄t can be inverted from the signal evolution equation.
    There are notable features of this solution. First, the matrix A used to model the hidden
state dynamics plays a central role in the dynamics for z̄. It enters directly into the formula
for the local conditional mean: A0 z̄. Second, the new information contained in the signal
evolution is captured by the increment to the Brownian motion dB̄, which we express as:

                                  dB̄t = κ · (zt − z̄t )dt + dBt .                           (9)

This represents the new information encoded in the signal history as a compound lottery.
Both Brownian motions B and B̄ are standardized (they have unit variance over a time
interval of length one). The reduced information does not alter the local accuracy of our
forecast of the signal. While this is a special property of continuous-time models with signal
noise generated by a Brownian motion, it gives us an informative limiting case. Finally, the
vector ∆ contains the local (in time) regression coefficient of the hidden state onto the new
information in the signal. These coefficients depend on the state probability vector z̄t . When
one of entries of z̄t is close to unity, the vector ∆ is close to zero.
    The following example is of some pedagogical interest because it illustrates how vary-
ing parameters of this model alters the temporal dependence of the probabilities and the


                                                22
sensitivity of these probabilities to new information.

Example 5.1. Consider the following two-state example. The two by two intensity matrix
is parameterized by:                  "          #
                                        −a1 a1
                                  A=
                                        a2 −a2
where a1 ≥ 0 and a2 ≥ 0. Since probabilities add up to one, it suffices to consider only
one of the probabilities, say the probability of being in state one. Substituting from our
parameterization of A,
                                                                                               
                                               a2                                       κ1 − κ2
             dz̄1,t   = −(a1 + a2 ) z̄1,t −               dt + z̄1,t (1 − z̄1,t )                     dB̄t .
                                            a1 + a2                                        σ

    In this example, the unconditional mean of the probability of being in state one is:
a2 /(a1 + a2 ). The local volatility of the probability scales with the difference between means
relative to the signal volatility. When the difference in the κ0 s is large relative to σ, the
probabilities are more responsive to the new information contained in the signals. This
responsiveness becomes arbitrarily small if the probability is close to zero or one. If a1 =
a2 = 0, then the probability is a positive martingale. When a1 and a2 are both positive, the
probability process is asymptotically stationary. Larger values imply more mean reversion
in the probabilities.15
    While I feature the Wonham filter in this essay, there are other well known filtering
methods including the Kalman filter, the particle filter and the Zakai equation. There are
alternative ways of characterizing the solutions to f¯ and T̄ .


5.5     Real Time Model Detection
I began this essay by considering a model detection problem posed by Chernoff (1952). The
stochastic specification of the Wonham filter gave me a way to move across regimes in real
time, but it also includes time invariant indicators of models as envisioned by Chernoff.
Such indicators are natural limits of low frequency movements in regimes. Learning about
low frequencies will be an important component to some of our calculations and therefore it
warrants special consideration.
    When time invariant indictors are included as possibilities, it is no longer fruitful to
appeal to a stochastic steady state. While such steady states exist, they are degenerate and
the interesting question becomes one of convergence. The rate of convergence is precisely
  15
    We do not mean to imply that the drift determines the pull of the process towards the center of its
distribution. Given that volatility is also state dependent, it also plays a role in pulling the distribution
away from the boundaries. When volatility is relatively low, the pull by the drift is more potent.


                                                     23
what Chernoff’s analysis allows us to investigate. The inferential problem that is presumed in
my application of the Wonham filter includes a model selection problem where the invariant
state is a model indicator indexed by an invariant state.
    I now use the stochastic structure of the Wonham (1964) filtering model to explore
dynamics of model selection.
Example 5.2. Consider an example with three states. Two states give rise to movements in
the growth rate for consumption. Movements between states are random and shift the growth
rate in the signal as in example 5.1. The third state is invariant. It cannot be reached from
the first two states. Formally, the A matrix is:
                                                           
                                                   −a1 a1 0
                                              A =  a2 −a2 0
                                                           

                                                    0   0 0

where a1 > 0 and a2 > 0. There is no possible movement from states one and two to
state three or from state three to states one and two. While the third state is invariant, the
decision-maker does not know if this third state or regime is the relevant one or not. Thus
he faces a model selection problem.
     Given the existence of a time invariant hidden state, the dynamic extension of the Cher-
noff (1952) analysis determines the asymptotic discrimination rate between models (states
one and two versus state three.) This leads to the study of the asymptotic behavior of the
filtering solution when the signal is restricted to spend all of its time in states one and two
or when the signal is restricted to spend all of its time in state three. In the former case,
the process {z̄3,t } will converge to zero eventually at an exponential rate, while in the latter
case {z̄1,t + z̄2,t } will converge to zero eventually at this same rate.
     The local counterpart to Chernoff’s discrimination rate is:
                             h                                                                i2
                                              z̄1,t                         z̄2,t
                                 κ1       z̄1,t +z̄2,t
                                                             + κ2       z̄1,t +z̄2,t
                                                                                           − κ3
                                                                                                       .
                                                              8σ 2

This rate depends on the local mean difference between the two models where the first model
is the original two-state model of example 5.1 and the second model has local mean of κ3 dt
that is time invariant. Small mean differences across the models relative to the volatility
make model discrimination challenging. Since this local rate is time varying, as I argued
before the asymptotic discrimination rate is an average of this local rate with respect to an
appropriately defined mixture model. See Newman and Stuck (1979).
    In addition to considering learning with time invariant hidden states, I will also explore
the implications of recent decision theory that will allow us to feature learning and concerns

                                                               24
about model specification but preserve many other useful features of a rational expectations
equilibrium.


6     Beliefs and Preferences
Expected utility theory embraces the axiom that compound lotteries should be reduced. If,
as suggested previously, we view f (ξ ∗ |ζ) and dπ(ζ) as a compound or two-step lottery then
the ranking induced by expected utility preferences depends on the reduced lottery:
                                              Z
                                    f¯(ξ) =       f (ξ|ζ)dπ(ζ).

The integration defines a lottery that does not condition on z = ζ, and compounding is just a
way to depict or even restrict lotteries of interest. Similarly, decisions or actions that depend
on s∗ can be represented as a compound lottery that can be reduced using the density f¯.
For the example economies that we explore, the use of expected utility theory implies that
rational learning has only modest implications for predicted risk premia. This leads me to
employ generalizations of this theory that avoid the presumption that compound lotteries
should simply be reduced. Kreps and Porteus (1978), Segal (1990) and Klibanoff et al.
(2005) provide alternative decision theories that resist the reduction of compound lotteries.
Associated with some of these formulations are alternative beliefs that are tilted in ways
that I characterize.


6.1    Irreducible Lotteries
Segal (1990) studies two-stage lotteries and axioms that do not imply reduction. Instead
the conditional composition of risk matters. We explore two distinct motivations for why
conditioning might matter. First we distinguish the riskiness of s∗ conditioned on z from
riskiness over the hidden state or time invariant parameter z. Klibanoff et al. (2005) develop
this idea further to distinguish risk or objective uncertainty, captured by the signal density
f (·|z), from subjective uncertainty, captured by probability distribution π over hidden states.
They give an axiomatic justification for a convenient representation of preferences.
     Let the adjustment for risk conditioned on z be represented by an increasing concave
function h:                                Z                     
                                        −1
                             V(a|z) = h        h[a(ξ)]f (ξ|z)dη(ξ)                         (10)

where a is some action or decision expressed as a function of the signal. The h−1 trans-
formation is convenient because if the random s∗ can be perfectly predicted given z, the
right-hand side of (10) gives the state contingent action. Construct a second-stage ranking

                                                  25
based on the utility function:        Z
                                          [g[V(a|ζ)] dπ(ζ)                                  (11)

using the strictly increasing concave utility function g. As a special case, if g = h
                     Z Z                                  Z
                           h[a(ξ)]f (ξ|ζ)dη(ξ)dπ(ζ) =         h[a(ξ)]f¯(ξ)dη(ξ)

Preferences that do not reduce compound lotteries permit h to differ from g. The behav-
ioral responses to the two different forms of risk or uncertainty are allowed to be different.
Klibanoff et al. (2005) defend this as allowing for a smooth version of ambiguity aversion
when g ◦ h−1 is concave.
    Following Kreps and Porteus (1978), we may use the same setup to consider a rather
different question. Consider two lotteries. One is a(s∗ ) where z is observed at an intermediate
date. Then V(a|z) can be thought as the conditional utility at this intermediate date and
the initial period utility is given by (11). How does this lottery compare to a second lottery
with the identical reduced distribution, but all information is revealed at the final date? The
second lottery uses the density f¯ for s∗ . At the intermediate date, no new information is
revealed about the lottery and the resulting valuation is:
                                             Z                    
                              V̄(a) = h −1
                                                  h[a(ξ)]f¯(ξ)dη(ξ) .

This valuation is not conditional on any information, so at the outset we simply evaluate g
at V̄(a) to obtain the initial period utility. Provided that g ◦ h−1 is convex, the first lottery
is preferred to the second. The converse is true if this function is concave. Knowing z at
an intermediate date alters preferences even when the a is only allowed to depend on the
signal s∗ . Thus in contrast to expected utility preferences, the timing of when uncertainty
is resolved matters.
    Thus there are two rather different motivations for building preferences that depend on
more than reduced lotteries: i) wanting to incorporate a formal distinction between risk
conditioned on a hidden state versus subjective uncertainty about that state and ii) want-
ing preferences that are sensitive to when information is revealed even when the (reduced)
decision distribution is unaltered. Epstein and Zin (1989) build on this latter motivation by
featuring an implied distinction between risk aversion and intertemporal substitution. In the
next section I will implement both of these modifications to preferences in dynamic settings.
Both can amplify the impact of learning on risk prices.




                                                  26
6.2    Exponential Tilting
For some convenient parameterizations, there are substantially different interpretations of
this utility representation that will allow us to explore implications of statistical ambigu-
ity. These different interpretations are implications of a well known result from applied
probability:                                                            
                                                                     1
                      min EmV + θE (m log m) = −θ log E exp − V                          (12)
                   m≥0,Em=1                                          θ
where V is a random variable that represents the future value of a stochastic process of
consumption and m is a random variable used to distort probabilities. The right-hand side
of (12) is a special case of:
                                         h−1 (E [h(V )])

where h is minus the negative exponential function parameterized by 1θ : h(V ) = − exp − 1θ V .
                                                                                              

As featured by Jacobson (1973), Whittle (1981) and others in the control theory literature,
the left-hand side of (12) offers a rather different perspective than the apparent risk adjust-
ment made on the right-hand side of (12). The computation:

                                             EmV

for a positive random m with a mean of one gives an alternative way to form expectations.
Formally, the random variable m induces a different probability distribution and the term
θE(m log m) is a convex penalty in the distortion m. The left-hand side of (12) explores
expectations of V using different probability distributions. By setting the parameter θ
arbitrarily large, probability distortions are penalized so severely as to approximate the
original expectation EV . Finite values of θ permit consideration of alternative probability
measures subject to penalty. Thus formula (12) gives an explicit link between robustness
(left-hand side) and risk sensitivity (right-hand side) where the latter is modeled using an
exponential risk adjustment.
    Robustness allows us to endow our decision-maker with an operational form of skepticism
about his model. It is implemented by the choice of a tilted or distorted probability measure
induced by the minimizing m. The solution is:

                                        exp − 1θ V
                                                   
                                     m=                                                    (13)
                                       E exp − 1θ V
                                                     


provided that the denominator is finite. This solution gives what is known as an exponential
tilting of the original probability. Smaller values of V receive relatively more weight than
larger values in the altered probability distribution. The altered distribution is tilted towards


                                               27
states with lower continuation values.
    The implementation via a tilted probability turns out to be of considerable value. The
minimizing solution is useful for representing uncertainty premia and providing a different
perspective on the source of those premia. Previously, I described the potential role for
statistical latitude among alternative probability models given data histories. I now have a
way to construct these alternative models and to ask how large is the resulting statistical
discrepancy between the minimized solution and the original benchmark probability model?16
    While this representation of preferences using exponential tilting relies on a particular
parametric structure, it is mathematically convenient. In what follows I will apply (12) in
multiple ways. In dynamic contexts, it is most fruitful to work with continuation values for
optimal plans because of the usefulness of Bellman-equation methods. First, I will exploit
(12) as applied to future continuation values by either endowing the decision-maker with a
concern about the specification of Markov state transition probabilities (left-hand side) or a
concern about the intertemporal composition of risk as in Kreps and Porteus (1978), Epstein
and Zin (1989) and others (right-hand side). Second, by characterizing the dependence
of future continuation values computed a function of a hidden state z, I will use (12) in
conjunction with a negative exponential specification of the g function to endow decision
makers either with a concern about the specification of the probabilities assigned to the
hidden states (left-hand side) or a smooth ambiguity adjustment as in Klibanoff et al. (2005)
(right-hand side).
    These ideas are developed more formally in several recent papers. While (12) exploits a
particular functional form, Maccheroni et al. (2006b) provide an axiomatic justification for
a more general version of this penalization formulation given by the left-hand side of (12)
where the convex function m log m is replaced by a more general convex function. Hansen
et al. (2006c) show how the intertemporal counterpart to (12) is related to the max-min
expected utility of Gilboa and Schmeidler (1989) by formally interpreting the penalization
parameter θ as a Lagrange multiplier on a constraint over a family of probability distribu-
tions. Maccheroni et al. (2006a) explore more general dynamic formulations of preferences
based on penalization. Finally, Hansen and Sargent (2006b) use two versions of negative-
exponential formulation to address simultaneously two forms of misspecification described
previously: a) misspecification in the underlying Markov law for the hidden states and b)
misspecification of the probabilities assigned to the hidden Markov states.17
  16
      In a choice problem such as an investment problem, the minimizing solution will differ as alternative
choices are considered. It will often be the case that the minimization can be done after maximization of
utility without changing the value. Thus a min-max theorem can be invoked. In such circumstances we can
still infer a worst case probability distribution by exchanging the order of minimization and maximization.
   17
      Epstein and Schneider (2003, 2006) make similar distinctions while developing other interesting formu-
lations and applications of ambiguity aversion and learning.



                                                    28
7     Learning and Uncertainty Premia
Empirical evidence suggests that risk premia move in response to aggregate fluctuations
(e.g. see Campbell and Cochrane (1999) and Lettau and Ludvigson (2003)). I now explore
how learning might contribute an explanation for this phenomenon. While I will present
some highly stylized models, the lessons from this analysis are informative for more ambi-
tious quantitative investigations. The Wonham (1964) filter will be a key input into our
characterization.
    My characterizations of prices will focus on what is usually termed the “local risk return
tradeoff”. In continuous-time environments, “local” means instantaneous and the tradeoff
answers the question: “how do we compensate investors for risk born in the immediate
future?” I use the term “uncertainty premia” to capture the additional components to pricing
that emerge from using the decision theory of section 6 that in some way or another does not
simply reduce compound lotteries. In dynamic economies valuation of cash flow exposure
uncertainty is pertinent for all horizons, not just the immediate one. The recursive nature
of asset pricing allows us to, in effect, integrate the local consequences into implications
for longer horizons. There is good reason to suspect that learning can have a more potent
impact for valuation over longer horizons. Constructing a model in which learning matters
for short term risk analysis is a tall order, but such a model will likely pay off in also implying
substantial consequences for risk-return tradeoffs for longer horizons.
    For the equilibrium calculation I imitate a device used in the rational expectations lit-
erature (see Lucas and Prescott (1971)) by introducing a fictitious social planner. Given
a consumption endowment, the role of this planner is to compute value functions and the
exponentially slanted probabilities associated with these functions. The sole purpose of this
planning problem is to characterize these implied probability distortions. If production were
incorporated, then the planner’s problem would be more ambitious but it would still include
the computation of these distortions. Behind this solution to the planner’s problem is a
counterpart to rational expectations equilibrium with decentralized prices. The distorted
or slanted probabilities and the associated equilibrium uncertainty premia will be expressed
conveniently using the continuation values of this planner. Continuation values are the util-
ity values assigned to consumption processes looking forward and they will be computed as
functions of the Markov state using continuous-time versions of Bellman’s equation.
    Conveniently, the probability distortion associated with exponential tilting, formula (13),
is computed using continuation values. This approach can be viewed as a device for com-
puting risk premia, as a way to generate alternative beliefs, or as a reflection of statistical
ambiguity on the part of investors. It is latter interpretation that I feature here.
    Following Veronesi (2000), we use the probability model assumed by Wonham (1964)


                                                29
in which the signal is the growth rate in consumption. In this specification, the expected
growth rate of consumption has infrequent jumps:

                                            dct = κ · zt + σdBt .

By solving the filtering problem, I compute a second evolution for consumption that endows
investors with less information. In this second specification the expected growth rate of
consumption moves continuously as a function of the probabilities: the z̄t ’s. To an econo-
metrician looking only at consumption data, these two specifications are indistinguishable.
I will make reference to both information structures and their implications for pricing.
   In what follows I compute alternative value functions and probability distortions, begin-
ning with expected utility. My approach in this paper will be derivation by assertion, and
the interested reader will have to look elsewhere for formal derivations.


7.1       Continuation Values for Expected Utility
Given the assumption of a unitary elasticity of substitution, we look for continuation values
of the form: Vt + ct where Vt depends either on the state vector zt or the hidden state
probabilities z̄t .
    Suppose for the moment that zt is observed as of date t. For a reference point consider
discounted expected utility in continuous time. In this case we may represent the continua-
tion value as: Vt = v · zt + ct where v is an n-dimensional vector of numbers. The vector v
satisfies the linear equation:
                                      0 = −δv + Av + κ,                                  (14)

and hence v = (δI − A)−1 κ. The continuation value when zt is not observed is: Vt = v · z̄t +ct
which may be computed by applying the Law of Iterated Expectations or equivalently by
reducing the associated compound lottery.
    When the jumps are observed, there are two risk components to price the Brownian
increment dBt and the jump process {zt }. Since the consumption does not jump (only
its conditional mean jumps), the local risk price for the jump component is zero. Since
the elasticity of substitution is unity, the Brownian motion risk price is σ. In the reduced
information economy in which the jump component is not observed, only the increment dB̄t
is priced. Since the coefficients on dBt and dB̄t are the same for both information structures,
the local risk prices remain the same for this economy. In this sense the introduction of
learning within a rational expectations equilibrium is inconsequential for the local risk price
vector.18
 18
      Arguably this conclusion takes time separability in preferences too literally in a continuous-time model.


                                                       30
    In defense of rational learning, the prices of cash flows over finite time intervals will be
sensitive to the information structure, and this sensitivity can be substantial depending on
the model specification. However, in order to generate a model in which learning alter local
prices, I explore other preferences as described previously.


7.2     Continuation Values and Exponential Tilting
Consider next a modification as in Kreps and Porteus (1978) under the assumption that
z can be observed. Let h be the negative exponential function with parameter value θf .
This function is used to adjust future continuation values. In this case we modify Bellman’s
equation:
                                                   
                                          vi           v         1 2
               0 = −δv + κ − θf diag exp       A exp −        −     σ 1n                                   (15)
                                          θf           θf       2θf

where 1n is an n-dimensional vector of ones. The new terms included in the Bellman equation
adjust the continuation values for risk both jump risk and the Brownian motion risk. (See
Anderson et al. (2003) for a derivation.) As θf gets arbitrarily large, this Bellman equation
collapses to the equation (14) used for evaluating discounted expected utility.
    This Bellman equation is the counterpart to the right-hand side of (12). Associated with
the left-hand side is probability distortions induced by exponential tilting. While we will
not formally derive this distortion, it is easy to characterize. For this continuous time limit,
the exponential tilting has a simple impact on the underlying Brownian motion. A constant
drift is added of the form − θσf . The negative of this drift is the uncertainty premia added to
the risk premium σ derived for the expected utility model.
    Under this distorted probability, consumption evolves according to:

                                                           σ2
                                      dct = κ · zt dt −       dt + σdBt .
                                                           θf
                                  2
Thus we have subtracted σθf from all of the hypothetical growth states. This constant
adjustment is a feature of other models as well including the discrete time models of Tallarini
(2000) and Hansen et al. (2006b).
     The transition probabilities for the Markov process are also distorted by the exponential
tilting. The transitions to states with the smaller continuation values will be made more
probable. The jump risk exposure now has a nonzero uncertainty premia in contrast to the
Hindy and Huang (1992) and Heaton (1995) argue that locally durability should be an important feature of
preferences specified at high frequencies. Nevertheless, I find this local analysis here to be revealing because
it shows how to amplify the role of learning.



                                                      31
zero risk premium from the expected utility economy.19
    This gives a continuous time counterpart to the discussion in section 4.2. By interpreting
the uncertainty premia as reflecting statistical ambiguity on the part of investors, Anderson
et al. (2003) argue that the statistical discrimination analysis of Chernoff (1952) suggests
how large this uncertainty component could plausibly be. It suggests how much statistical
latitude there might plausibly be in distorting the consumption growth rates from the vantage
point of skeptical investors, investors whose doubts about their model specification concerns
cannot be dismissed easily with statistical evidence.
    Alternatively, a rational expectations econometrician calibrating the model could have
made a mistake in building a rational expectations model by not endowing agents with
lower potential growth rates for consumption. A Chernoff-type calculation based on real
data controls the extent to which growth rates could be diminished, but they are set at this
new level with full investor confidence.
    This model of investor preferences increases the predicted uncertainty premia associated
with the Brownian motion increment dB̄t , but it does not cause them to be time varying. I
now examine another modification to the model which delivers time-varying premia.


7.3       Exponential Tilting and Less Information
Suppose now that the state variable z is not observed. Instead it is disguised requiring
that statistical inferences be made using the Wonham (1964) filter. I may not just average
the solution to equation (15) over the hidden states to obtain the solution to this problem.
Instead, as Kreps and Porteus (1978) and Epstein and Zin (1989) show, the intertemporal
composition of risk matters. Thus I must solve a new Bellman equation that includes an
alternative risk adjustment to the continuation value:
                                                              "                                 #
                                                                         2
                                  ∂V 1 0 ∂ 2 V           1        ∂V            ∂V
       0 = −δV + κ · z̄ + z̄ 0 A0      + ∆         0
                                                     ∆−                · ∆ + 2σ      · ∆ + σ2       (16)
                                  ∂ z̄  2 ∂ z̄∂ z̄      2θf       ∂ z̄          ∂ z̄

where the value function is V(z̄) + c. The last term captures the risk adjustment to contin-
uation values necessary for the Kreps and Porteus (1978) recursion (see Duffie and Epstein
(1992)).
   Again I use a link to robustness to construct an implied change in probability measure.
The distortion again adds a drift to the Brownian motion, but now the drift depends on
the state probabilities. Three contributions to the uncertainty premia are given in table 1.
While we will not derive this formula, it follows from the analysis in Hansen et al. (2006c).
The first term is the risk adjustment from expected utility theory when the IES is unity. The
 19
      See Jun Liu and Wang (2005) for a related example featuring jump risk.


                                                    32
second term is familiar from the our analysis of the model in which the jump component is
observed.20 The impact of learning is reflected in the third term, which depends explicitly
on z̄. The second two terms depend on the derivatives of the value function and the local
volatility. They distort the evolution of consumption and the state probabilities from the
Wonham filter via exponential tilting. Unfortunately, we lose some pedagogical simplicity
because the value function and hence its derivative must be computed numerically.
   To illustrate this solution, consider an example with two states as in Cagetti et al.
(2002).21 From example 5.1, when there are two hidden states, the vector ∆ has:
                                                                          
                                                                 κ1 − κ2
                                        z̄1,t (1 − z̄1,t )
                                                                    σ

as its first entry and the negative of this as its second entry. The scale factor z̄1,t (1 − z̄1,t )
is close to zero when there is a preponderance of evidence for one or the other states. This
term is large when it is hard to tell the two states apart, that is when z̄1,t = 1 − z̄1,t = 1/2.
The actual uncertainty prices depend on value function derivative as well, but it remains
true that uncertainty prices become large when there is ambiguity about the hidden state
probabilities, as illustrated Figure 4.
    When Cagetti et al. (2002) fit a technology shock model with two regimes using econo-
metric methods, like Hamilton (1989) they found growth rate regimes that moved over what
macroeconomists typically refer to as the business cycle. The time series of resulting uncer-
tainty prices are large at dates at which investors do not know which regime they are in:
these are dates at which both regime probabilities are one-half. Repeated observations of
low consumption growth strengthen investor beliefs that they are in the low growth regime,
thereby resolving some of the uncertainty and reducing the premium. However, I imagine
that by including more states, in particular more low frequency movements in growth rates,
I can modify this outcome so that some repeated observations with low growth increases the
uncertainty about an underlying growth rate regime.22
    While this example produces interesting time series variation in local uncertainty premia,
it does so by distorting the dynamic evolution equation for the state vector. This includes
distorting the component originally constructed as Wonham (1964)’s solution to a filter-
ing problem. Investors treat state estimates from the Wonham (1964) filter like any other
observable state variable, and they do not distort the current period state probabilities.
  20
     An astute reader will notice that I have also distorted the dynamics for z̄. We retain use of this as a
state variable, but we lose its interpretation as the solution to a simple filtering problem.
  21
     Cagetti et al. (2002) consider formally a production economy and they do not impose a unitary elasticity
of substitution.
  22
     Such extensions are worthwhile, but the value function for this model must be solved numerically. This
limits the scope of such an analysis.



                                                        33
7.4       Estimation Ambiguity
I now explore an alternative approaches that directly distort the state probabilities. To
feature the role of ambiguity in the assignment of state probabilities, I follow Klibanoff et al.
(2005) and Hansen and Sargent (2006b) by introducing a separate adjustment for ambiguity
over the probabilities assigned to states.
    Using a continuous-time counterpart to a decision model of Hansen and Sargent (2006b)
and decomposition (9), we may obtain a modified version of the Bellman equation (16). To
feature the role of hidden states, the fictitious planner modifies the equation by considering
the evolution of continuation values prior to the information reduction. Even though the
value function depends only on z̄ and c, its evolution now depends on the realized hidden
states. Hansen and Sargent (2006b) introduce a second parameter, say θb , to penalize dis-
tortions to the probability vector z̄ used by the planner for computing the averages required
for a new continuous-time Bellman equation. The resulting solution remains difficult to
compute unless the number of states is small.
    For my numerical examples, I use a second approach suggested by Hansen and Sargent
(2006b). The solution can be easier to compute, which we exploit in solving the four hundred
state Markov chain example which follows.23 Consider again the Kreps and Porteus (1978)
recursion conditioned on the hidden state z. Recall that the value function is v · z + c where v
is a vector of real numbers. I use the continuation values in conjunction with (12) for θ = θf
to infer a distortion of the hidden state probabilities. Recall that the probability distortion
results in an exponential tilting of the probability assignment toward states with the lowest
continuation values. That is, let                      
                                         ∗           vi
                                        vi = exp −
                                                     θf
for some positive value of the parameter θf . Large values of θf make vi∗ ’s close to a constant
value of unity. The distorted or exponentially tilted probabilities assigned to hidden state
are:
                                         i     vi∗ z̄i,t
                                       z̃t = P       ∗
                                                           .
                                                i vi z̄i,t

These tilted probabilities induce a distortion in the expected growth rate for consumption
and hence add a component to the uncertainty premia.
    Three contributions to the uncertainty premia are given in Table 2. The first two are
familiar from our previous example economies and the third is unique to this example. The
first is a risk premia, and the second second term is determined by the continuation values
condition and z and the parameter θf . Both are constant. The third term is unique to this
example. Since it depends on the hidden state probabilities and their distortions, this term
 23
      While computationally simpler, its game theoretic underpinnings are more subtle.


                                                     34
is time varying. It magnitude is determined in part by the parameter θb used in comput-
ing the exponential tilted state probabilities. The second term reflects the contribution of
learning. From a robustness standpoint the parameter θf reflects forward-looking skepticism
about assumed dynamics and the parameter θb a backward looking skepticism about the
constructed state probabilities.
    The time series plots in Figure 5 display the sum of the second and third components
of the uncertainty premia, which are the components associated with probability slanting.
I construct a Markov chain to approximate four different parameter configurations or sub-
models. Formally a sub-model is a collection of states for which there is no chance of leaving
that collection. I design a four hundred state Markov chain to approximate a model selection
problem or estimation problem for investors. One hundred states were used for each of the
four sub-models. The corresponding intensity matrix A is block diagonal with four blocks.
I construct the first three sub-models by approximating the consumption dynamics given in
example (2.2) in which the process {zt } is hidden from the agents. I use three different values
of the autoregressive parameter .97, .98 and .99. The corresponding coefficients on the shock
u2,t+1 (the conditional standard deviations of the hidden state process) were obtained by
maximizing the likelihood over this parameter conditioned on the autoregressive parameter
and the coefficient .0054 on the shock u1,t+1 to the consumption growth rate equation. I
use the method of Tauchen and Hussey (1991) to obtain a discrete state approximation for
each of these three models. The other one hundred states are all invariant states designed
to approximate alternative mean growth rates. I apply a standard quadrature method in
constructing the discrete states.24 For computational purposes and for the computation of
uncertainty prices, I take the discrete states literally; but the setup is designed to be similar
to an economy studied in great depth by Hansen and Sargent (2006a). In that paper, we
used Kalman filtering methods for two alternative models and computed the sequence of
posterior probabilities for these models given sample evidence on consumption. Here I use
the same data as was used in that analysis to solve the filtering problem.
    The second term in Table 2 is time invariant. By changing θf , I alter the level of the
uncertainty premia. This is reflected in Figure 5. The two lower curves were computed for
θf = .10 and upper curves for θf = .05. A smaller value of θf implies less penalization
in the investors’ search over alternative probability distributions. The third term in Table
2 induces time series variation in the uncertainty premia while having little impact on the
level. The smooth curves in Figure 5 are computed for θb = 24 and the more volatile curves
for θb = 6. By construction, the time series trajectories are similar to those reported in the
more comprehensive analysis by Hansen and Sargent (2006a) except that I have introduced
  24
   To form an (approximate) intensity matrix for the continuous-time Markov chain, I subtracted an identity
matrix from the discrete-time transition probability matrix.


                                                    35
additional models to approximate the problem of estimating the parameters governing the
dynamics of {zt }.
    I find it convenient to think of the first three sub-models as three different parameter
specifications of predictability in consumption growth. By including all three sub-models in
the analysis I have approximated an estimation problem. The fourth sub-model is different
because consumption growth rates are not predictable. As a consequence it implies less long
run uncertainty. The signal history of post-war consumption growth does not allow investors
to either confirm or reject this fourth sub-model with full confidence. Probabilities are tilted
away from this sub-model based on the continuation values. A string of relative high or rela-
tively low consumption growth rates both give evidence for consumption predictability. The
relatively high growth rates induce less tilting towards the sub-models with predictability in
consumption because if consumption is predictable it should remain high, at least temporar-
ily. In contrast, relatively low growth rates in consumption induce more tilting towards the
sub-models with predictable consumption growth and this in turn gives a larger uncertainty
premia.


8      Extensions
There are very special ingredients in my example economies. They were designed in part to
magnify the impact of learning on uncertainty prices. On the other hand there are empirical
limitations to these economies that can be anticipated from previous literature.
    My example economies have arguably withheld too much information from economic
agents. For instance, multiple signals make learning more informative, and it remains valu-
able to explore implications that allow for an econometrician to understate the knowledge
of economic agents. Learning within a rational expectations equilibrium already adds to
the econometrician’s challenge by requiring an initial specification or prior for the beliefs
about hidden Markov states, parameters, or model indicators. The decision theory that we
explored avoids the reduction of compound lotteries and thus prevents direct application of
the Law of Iterated Expectations as commonly used in rational expectations econometrics
to deduce robust implications. While econometric analysis may be more challenging, it is a
challenge with potentially valuable payoffs.
    I chose not to feature models in which there is conditional volatility present in the evo-
lution for consumption. I did this to show how learning can induce time variation in uncer-
tainty prices without an additional exogenous source of variation. Low frequency volatility
movements, however, are a potentially important additional ingredient.25
  25
    Weitzman (2007) has recently shown that for some priors on volatility, learning can be particularly
challenging and consequently can have a big impact on the predicted asset returns.


                                                  36
    Similarly, I restricted the IES (intertemporal elasticity of substitution) to be unity to
simplify the characterization of value functions and probability distortions. For models that
seek to understand better wealth and aggregate stock price dynamics, this restriction is
problematic because it implies constant wealth consumption ratios. On the other hand, ap-
proximating around an economy with IES=1 investors can be useful characterization device
as I illustrated in section 1.
    My focus on one-period (in discrete time) or local (in continuous-time) uncertainty prices
made it more difficult for learning to matter. If learning matters for short-horizon valuation,
then its impact should be more potent for longer horizons. Recent asset pricing literature
has focused on the role of long run uncertainty on cash flow valuation. (For example, see
Campbell and Vuolteenaho (2004), Bansal et al. (2005), Santos and Veronesi (2005),Hansen
et al. (2006b) and Croce et al. (2006).) Since statistical measurements for long-horizons are
known to be fragile, formally incorporating learning into such analysis is an obvious but
important extension.
    My models imposed homogeneity on investors. This allowed me to compute a single
tilted probability model and simplified my analysis. While introducing heterogeneity among
investors will complicate model solution, it has intriguing possibilities. The investors will
slant probabilities in different directions giving rise of a form of ex post heterogeneity in
beliefs. There is much more to be done.


9    Conclusion
The cross-equation restrictions used in rational expectations econometrics get much of their
empirical power by endowing agents with more precise information than econometricians.
This includes information on endowments, cash flows and technology shocks. The rational
expectations agents have done a lot of un-modeled work before the econometrician steps
in. In this paper I have explored ways to close this informational gap by giving economic
agents some skepticism about the models they use. I showed how investor concerns about
statistical ambiguity are reflected in equilibrium prices. In our example economies I avoided
endowing economic agents with full confidence in probability models that are demonstrably
hard to estimate. By introducing learning within an equilibrium, I showed how learning is
reflected in the dynamic evolution of local uncertainty prices. These uncertainty premia
reflect investors’ doubts about their probability models. Learning about very low frequency
events including the primitive model specification can lead to uncertainty premia that are
large when macroeconomic growth is sluggish. This changes the structure of cross-equation
restrictions, but not necessarily their potency. While there are other possible interpretations
for the equilibrium outcomes I displayed, including changing beliefs or embracing preferences

                                              37
that decompose risks in alternative ways, I find the relation to statistical ambiguity to be
the most appealing.
    There are analogous questions regarding the role of uncertainty in the exploration of
hypothetical government interventions. The models I used drew a distinction between risks
conditioned on a hidden model specification or a hidden state, and uncertainty about that
specification or hidden state. If this distinction is important in understanding evidence from
security market data, then use of this evidence in the analysis of stochastic interventions will
require a careful accounting of the probability structure of the policy intervention. What
skepticism will economic agents have about the alternative probability structure and what
role will learning play in validating or altering beliefs? While such distinctions are not typical
in the formal analysis of policy changes, perhaps they should become part of the normative
vocabulary as argued in the context of monetary policy by Milton Friedman. Rational
expectations models have been demonstrably successful in featuring the role of credibility in
policy making, but there is scope to explore further the role of beliefs, doubts and learning
in a formal way.




                                               38
References
Abel, Andrew B. 2002. An Exploration of the Effects of Pessimism and Doubt on Asset
 Prices. Journal of Economic Dynamics and Control 26:1075–1092.

Anderson, Evan W., Lars Peter Hansen, and Thomas J. Sargent. 2003. A Quartet of Semi-
 groups for Model Specification, Robustness, Prices of Risk, and Model Detection. Journal
 of the European Economic Association 1:69–123.

Bansal, Ravi and Amir Yaron. 2004. Risks for the Long Run: A Potential Resolution of
  Asset Pricing Puzzles. Journal of Finance 59:1481–1509.

Bansal, Ravi, Robert F. Dittmar, and Christian T. Lundblad. 2005. Consumption, Divi-
  dends, and the Cross-Section of Equity Returns. Journal of Finance 60:1639–1672.

Bray, Margaret. 1982. Learning, Estimation and the Stability of Rational Expectations.
  Journal of Economic Theory 26:318–339.

Bray, Margaret and David M. Kreps. 1987. Rational Learning and Rational Expectations.
  In Arrow and the Accent of Modern Economic Theory, edited by G. R. Feiwel, 597–625.
  New York: New York University Press.

Cagetti, Marco, Lars Peter Hansen, Thomas J. Sargent, and Noah Williams. 2002. Robust-
  ness and Pricing with Uncertain Growth. Review of Financial Studies 15:363–404.

Campbell, John. 1996. Understanding Risk and Return. Journal of Political Economy
  104:298–345.

Campbell, John and Robert Shiller. 1988. Stock Prices, Earnings, and Expected Dividends.
  Journal of Finance 43:661–676.

Campbell, John Y. and John Cochrane. 1999. Force of Habit: A Consumption-Based Expla-
  nation of Aggregate Stock Market Behavior. Journal of Political Economy 107:205–251.

Campbell, John Y. and Tuomo Vuolteenaho. 2004. Bad Beta, Good Beta. American Eco-
  nomic Review 94:1249–1275.

Cecchetti, Stephen G., Pok sang Lam, and Nelson Mark. 2000. Asset Pricing with Distorted
  Beliefs: Are Equity Returns too Good to be True? American Economic Review 90:787–
  805.

Chen, Xiaohong and Halbert White. 1998. Nonparametric Adaptive Learning with Feedback.
  Journal of Economic Theory 82:190–222.
Chernoff, Herman. 1952. A Measure of Asymptotic Efficiency for Tests of a Hypothesis
  Based on the Sum of Observations. Annals of Mathematical Statistics 23:493–507.

Croce, Mariano M., Martin Lettau, and Sydney Ludvigson. 2006. Investor Information,
  Long-Run Risk, and the Duration of Risky Assets. New York University.

Cumby, Robert, John Huizinga, and Maurice Obstfeld. 1983. Two-step Two-stage Least
  Squares Estimation in Models with Rational Expectations. Journal of Econometrics
  21:333–355.

David, Alexander. 1997. Fluctuating Confidence in Stock Markets: Implications for Returns
  and Volatility. Journal of Financial and Quantitative Analysis 32:457–462.

Duffie, Darrell and Larry G Epstein. 1992. Stochastic Differential Utility. Econometrica
 60 (2):353–94.

Epstein, Larry and Martin Schneider. 2003. Recursive Multiple Priors. Journal of Economic
  Theory 113:1–31.

———. 2006. Learning under Ambiguity. New York University and Rochester University.

Epstein, Larry and Stanley Zin. 1989. Substitution, Risk Aversion and the Temporal Be-
  havior of Consumption and Asset Returns: A Theoretical Framework. Econometrica
  57:937–969.

Evans, George W. and Seppo Honkapohja. 2001. Learning and Expectations in Macroeco-
  nomics. Princeton, New Jersey: Princeton University Press.

Geweke, John. 2001. A Note on Some Limitations of CRRA Utility. Economics Letters
 71:341–345.

Gibbons, Michael R., Stephen A. Ross, and Jay Shanken. 1989. A Test of Efficiency of a
  Given Portfolio. Econometrica 57:1121 – 1152.

Gilboa, Itzhak and David Schmeidler. 1989. Maxmin Expected Utility with a Non-Unique
  Prior. Journal of Mathematical Economics 18:141–153.

Hamilton, James D. 1989. A New Approach to the Economic Analysis of Nonstationary
  Time Series and the Business Cycle. Econometrica 57:357–384.

Hansen, Lars Peter. 1982. Large Sample Properties of Generalized Method of Moments
  Estimators. Econometrica 50:1029–1054.
Hansen, Lars Peter and Ravi Jagannathan. 1991. Implications of Security Market Data for
  Models of Dynamic Economies. Journal of Political Economy 99.

Hansen, Lars Peter and Scott F. Richard. 1987. The Role of Conditioning Information in
  Deducing Testable Restrictions Implied by Dynamic Asset Pricing Models. Econometrica
  55.

Hansen, Lars Peter and Thomas J. Sargent. 1980. Formulating and Estimating Dynamic
  Linear Rational Expectations Moddels. Journal of Economic Dynamics and Control 2:7–
  46.

———. 1991. Time Series Implications of Present-Value-Budget Balance and Martingale
 Models of Consumption and Taxes. In Rational Expectations Econometrics, edited by
 Lars Peter Hansen and Thomas J. Sargent, 121–161. Westview Press.

———. 2006a. Fragile Beliefs and Price of Model Uncertainty. University of Chicago and
 New York University.

———. 2006b. Recursive Robust Estimation and Control Without Commitment. Journal
 of Economic Theory forthcoming.

Hansen, Lars Peter and Jose Scheinkman. 2006. Long Run Risk: An Operator Approach.
  University of Chicago and Princeton University.

Hansen, Lars Peter and Kenneth J. Singleton. 1982. Generalized Instrumental Variables
  Estimation of Nonlinear Rational Expectations Models. Econometrica 50:1269–1299.

Hansen, Lars Peter, William Roberds, and Thomas J. Sargent. 1991. Exact Liner Rational
  Expectations Models. In Rational Expectations Econometrics: Specification and Estima-
  tion, edited by Lars Peter Hansen and Thomas J. Sargent, 45–76. Westview Press.

Hansen, Lars Peter, John Heaton, Junghoon Lee, and Nikolai Roussanov. 2006a. Risk
  Aversion and Intertemporal Substitution. In Handbook of Econometrics, edited by James J.
  Heckman. Elsevier. Forthcoming.

Hansen, Lars Peter, John C. Heaton, and Nan Li. 2006b. Consumption Strikes Back?:
  Measuring Long Run Risk. University of Chicago.

Hansen, Lars Peter, Thomas J. Sargent, Gauhar A. Turmuhambetova, and Noah Williams.
  2006c. Robust Control and Model Misspecification. Journal of Economic Theory 128:45–
  90.
Hayashi, Fumio and Christopher Sims. 1983. Nearly Efficient Estimation of Time-Series
  Models with Predetermined Variables. Econometrica 51.

Heaton, John C. 1995. An Empirical Investigation of Asset Pricing with Temporally Depen-
  dent Preference Specifications. Econometrica 63:681–717.

Hindy, Ayman and Chi-Fu Huang. 1992. Intertemporal Preferences for Uncertain Consump-
  tion: A Continuous Time Approach. Econometrica 60:781–801.

Jacobson, David H. 1973. Optimal Stochastic Linear Systems with Exponential Performance
  Criteria and Their Relation to Deterministic Differential Games. IEEE Transactions for
  Automatic Control AC-18:1124–131.

Jun Liu, Jun Pan and Tan Wang. 2005. An Equilibrium Model of Rare-Event Premia and
  Its Implication for Option Smirks. Review of Financial Studies 18:131–164.

Klibanoff, Peter, Massimo Marinacci, and Sujoy Mukerji. 2005. A Smooth Model of Decision
  Making Under Uncertainty. Econometrica 73:1849–1892.

Kreps, David M. and Evan L. Porteus. 1978. Temporal Resolution of Uncertainty and
  Dynamic Choice. Econometrica 46:185–200.

Lettau, Martin and Sydney Ludvigson. 2003. Measuring and Modeling Variation in the
  Risk-Return Tradeoff. In Handbook of Financial Econometrics, Forthcoming, edited by
  Yacine Ait-Sahalia and Lars Peter Hansen.

Lucas, Robert E. 1972a. Econometric Testing of the Natural Rate Hypothesis. In The
  Econometrics of Price Determination, edited by O. Eckstein, 50–59. Washington, D.C.:
  Board of Governors of the Federal Reserve Board.

———. 1972b. Expectations and Neutrality of Money. Journal of Economic Theory 4:103–
 124.

———. 1978. Asset Prices in an Exchange Economy. Econometrica 1978:1429–1445.

Lucas, Robert E. and Edward C. Prescott. 1971. Investment Under Uncertainty. Economet-
  rica 39:659–681.

Maccheroni, Fabio, Massimo Marinacci, and Aldo Rustichini. 2006a. Dynamic Variational
 Preferences. Journal of Economic Theory 128:4–44.

Maccheroni, Fabio, Massimo Marinacci, and Aldo Rustinchini. 2006b. Ambiguity Aversion,
 Robustness, and the Variational Representation of Preferences. Econometrica 74:1147–
 1498.
Marcet, Albert and Thomas J. Sargent. 1989. Convergence of Least Squares Learning Mech-
 anisms in Self-referential Linear Stochastic Models. Journal of Economic Theory 48:337–
 368.

Mehra, Rajnish and Edward C. Prescott. 1985. The Equity Premium: A puzzle. Journal of
 Monetary Economics 15:145–161.

Muth, John H. 1961. Rational Expectations and the Theory of Price Movements. Econo-
 metrica 29.

Newman, Charles M. and Barton W. Stuck. 1979. Chernoff Bounds for Discriminating
  Between Two Markov Processes. Stochastics 2:139–153.

Restoy, Fernando and Philippe Weil. 1998. Approximate Equilibrium Asset Prices. NBER
  Working Paper 6611.

Santos, Jesus and Pietro Veronesi. 2005. Cash-Flow Risk, Discount Risk, and the Value
  Premium. NBER Working Papers 11816, National Bureau of Economic Research.

Saracoglu, Rusdu and Thomas J. Sargent. 1978. Seasonality and Portfolio Balance under
  Rational Expectations. Journal of Monetary Economics 4:435–458.

Sargent, Thomas J. 1973. Rational Expectations, the Real Rate of Interest, and the Natural
  Rate of Unemployment. Brookings Papers in Economic Activity 2.

———. 1999. The Conquest of American Inflation. Princeton, New Jersey: Princeton
 University Press.

Sclove, Stanley L. 1983. Time-Series Segmentation: A Method and a Model. Information
  Science 29:7–25.

Segal, Uzi. 1990. Two-Stage Lotteries Without the Reduction Axiom. Econometrica 58:349–
  377.

Sharpe, William. 1964. Capital Asset Prices: A Theory of Market Equilibrium. Journal of
  Finance 19.

Shiller, Robert. 1972. Rational Expectations and the Structure of Interest Rates. Ph.D.
  thesis, M.I.T.

———. 1982. Consumption, Asset Markets and Macroeconomic Fluctuations. Carnegie-
 Rochester Conference Series on Public Policy 17:203–238.
Tallarini, Thomas D. 2000. Risk-sensitive real business cycles. Journal of Monetary Eco-
  nomics 45 (3):507–532.

Tauchen, George and Robert Hussey. 1991. Quadrature-Based Method for Obtaining Ap-
  proximate Solutions to Nonlinear Asset Pricing Models. Econometrica 59:371–396.

Veronesi, Pietro. 2000. How Does Information Quality Affect Stock Returns. Journal of
  Finance 55:907–837.

Weitzman, Martin. 2007. Prior Sensitive Expectations and Asset Return Puzzles. American
 Economic Review Forthcoming.

Whittle, Peter. 1981. Risk Sensitive Linear Quadratic Gaussian Control. Advances in Applied
 Probability 13:764–777.

Wonham, W. M. 1964. Some Applications of Stochastic Differential Equations to Optimal
 Nonlinear Filtering. SIAM Journal on Control 2:347–368.
A      Tables

                           Table 1: Risk and Uncertainty Premia


             Exp. Utility       exponential tilting          exponential tilting
              IES = 1         consumption dynamics       state estimation dynamics

                                                                              ∂V(z̄)
                   σ                    σ/θf                 (1/θf )∆(z̄) ·    ∂ z̄


            time invariant        time invariant                time varying

Notes: The value function has functional form: V(z̄) + c, σ is the response of consumption to
new information, and ∆(z̄) is the vector of responses of the probabilities to new information.



                           Table 2: Risk and Uncertainty Prices


                 Exp. Utility       exponential tilting      exponential tilting
                  IES = 1         consumption dynamics        state estimation

                       σ                    σ/θf               [(z̄ − z̃) · κ]/σ

                time invariant         time invariant           time varying

Notes: The value function as functional form: V(z) + c, σ is the response of consumption to
new information, z̄ is the vector of probabilities from the Wonham filter, z̃ is the exponentially
tilted counterpart and κ is the vector of alternative growth rates.
B     Figures

                                         Figure 1: Mistake Probabilities


                              0.5

                             0.45

                              0.4

                             0.35
       mistake probability




                              0.3

                             0.25

                              0.2

                             0.15

                              0.1

                             0.05

                               0
                                    0   100       200           300        400     500
                                                     sample size


Notes: This figure displays the probability of making a mistake as a function of sample size
when choosing between the predictable consumption growth rate model the iid model for
consumption growth. The probabilities assume a prior probability of one-half for each model.
The mistake probabilities are essentially the same if mini-max approach is used in which the
thresholds are chosen to equate the model-dependent mistake probabilities. The curve was
computed using Monte Carlo simulation. For the predictabale consumption growth model,
the state {zt } is unobservable and initialized in its stochastic steady state. For the iid model
the prior mean for µc is .0056 and the prior standard deviation is .0014.
                                                     Figure 2: Logarithm of Mistake Probabilities


                                          −0.5


                                           −1
       logarithm of mistake probability




                                          −1.5


                                           −2


                                          −2.5


                                           −3


                                          −3.5


                                           −4


                                          −4.5
                                                 0        100        200           300      400     500
                                                                        sample size


Note: This figure displays the logarithm of the probability of making a mistake as a function
of sample size when choosing between the predictable consumption growth model and the
iid model for consumption growth. This curve is the logarithm of the curve in figure 1.
                      Figure 3: Prior and Posterior Probabilities


       8                                       1200

                                               1000
       6
                                                800

       4                                        600

                                                400
       2
                                                200

       0                                          0
       −1     −0.5      0       0.5      1            0     2       4       6          8
                                                                                    −3
                                                                                x 10


       8                                       1200

                                               1000
       6
                                                800

       4                                        600

                                                400
       2
                                                200

       0                                          0
       −1     −0.5      0       0.5      1            0     2       4       6          8
                                                                                    −3
                                                                                x 10




Note: This figure displays the priors (the lines) and the posteriors histograms for two param-
eters of the model with predictable consumption growth. The left column gives the densities
for the autoregressive parameter for the hidden state and the right column the mean growth
rate of consumption. The results from the first row were generated using a relatively loose
prior including an informative prior on the conditional variance for the hidden state. The
prior for the variance is an inverse gamma with shape parameter 10 and scale parameter
1.83 × 10−7 . The implied prior mode for σz is .00041. The prior for the AR coefficient is
normal conditioned on σz with mean 0 and standard deviation σz × 1.41 × 106 truncated to
reside between minus one and one. The prior for µc has mean .003 and standard deviation
.27. The results from the second row were generated with a informative prior and fixed the
conditional standard for the hidden state at .00047. The prior for AR coefficient is normal
with mean .98 and standard deviation .12. The prior for µc is normal with mean .0056 and
standard deviation .00036. The posterior densities were computed using Gibbs sampling
with 50,000 draws after ignoring the first 5,000.
                        Figure 4: Uncertainty Price Function


             0.1

            0.09

            0.08

            0.07

            0.06
    price




            0.05

            0.04

            0.03

            0.02

            0.01

              0
                   0    0.2            0.4                 0.6     0.8            1
                                             probability


Notes: The uncertainty price is the sum of the second and third components given in Table 1.
It is computed for a two-state Markov chain. To produce this curve, I assumed an intensity
matrix A from Cagetti et al. (2002) with off-diagonal elements equal to .0736 and .352. The
growth rates are κ1 = .0071 and κ2 = .0013. The value function was computed taking a
quadratic approximation around the implied unconditional mean of the probability of being
in the first state with parameter values θf = .1 and δ = − log .998.
                          Figure 5: Time Series of Uncertainty Prices


            0.14


            0.12


             0.1


            0.08
    price




            0.06


            0.04


            0.02


              0
                   1950       1960       1970          1980     1990        2000
                                                date


Notes: The uncertainty prices are the sums of the second and third components given in
Table 2. The Markov chain has four hundred states, one hundred for each of four sub-models.
The four sub-models are i) AR1 with an AR coefficient of .97, a shock standard deviation
of .00058 and an unconditional mean of .0056; ii) AR1 with an AR coefficient of .98, a
shock standard deviation of .00047 and unconditional mean of .0056; iii) AR1 with an AR
coefficient of .99, a shock coefficient of .00024 and an unconditional mean of .0056; iv) iid
model with prior on the mean given by .0056 and a prior standard deviation of .00036. The
− curve was computed assuming that θb = 24, and - - curve was computed assuming that
θb = 6. The upper two plots were computed assuming that θf = .05, and the lower two plots
were computed assuming that θf = .1. For all of the plots, δ = − log .998.
