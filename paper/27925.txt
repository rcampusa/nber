                              NBER WORKING PAPER SERIES




                             HUMAN CAPITAL DEPRECIATION

                                      Michael Dinerstein
                                    Rigissa Megalokonomou
                                     Constantine Yannelis

                                      Working Paper 27925
                              http://www.nber.org/papers/w27925


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                                    October 2020




The authors wish to thank Stéphane Bonhomme, Niels Gormsen, Caroline Hoxby, Victor Lavy,
Magne Mogstad, Steve Rivkin, Jonah Rockoff, Seth Zimmerman, and seminar participants at
NBER Labor Studies and Economics of Education Summer Institute, Columbia University,
Princeton University, the University of Chicago, Athens University of Economics and Business,
CESifo Area Conference on the Economics of Education, Public Choice Conference at
Queensland University Technology, the Chicago Booth Household Finance Conference, the
Rome Junior Conference on Applied Economics, the University of Adelaide, the University of
Piraeus, the University of Toronto, University of Queensland, and Warwick University for
helpful discussion and comments. We are grateful to Spyros Kypraios and Katerina Nikalexi for
superb research assistance and to Panos Voulgaris, Veronica Blau, and Ilias Arvanitakis for
helping to compile the data. Constantine Yannelis is grateful to the Becker Friedman Institute and
Fama Miller Center for generous financial support. This work was approved by the Research
Committee by the University of Queensland (clearance number: 2020000158 / IRB19-1614). The
views expressed herein are those of the authors and do not necessarily reflect the views of the
National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2020 by Michael Dinerstein, Rigissa Megalokonomou, and Constantine Yannelis. All rights
reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit
permission provided that full credit, including © notice, is given to the source.
Human Capital Depreciation
Michael Dinerstein, Rigissa Megalokonomou, and Constantine Yannelis
NBER Working Paper No. 27925
October 2020
JEL No. H52,I26,J24

                                         ABSTRACT

Human capital can depreciate if skills are unused. But estimating human capital depreciation is
challenging, as worker skills are difficult to measure and less productive workers are more likely
to spend time in non-employment. We overcome these challenges with new administrative data
on teachers' assignments and their students' outcomes, and quasi- random variation from the
teacher assignment process in Greece. We find significant losses to output, as a one-year increase
in time without formal employment lowers students' test scores by 0.09 standard deviations.
Using a simple production model, we estimate a skill depreciation rate of 4.3% and experience
returns of 6.8%.

Michael Dinerstein                              Constantine Yannelis
Department of Economics                         Booth School of Business
University of Chicago                           University of Chicago
1126 East 59th Street                           5807 S. Woodlawn Avenue
Chicago, IL 60637                               Chicago, IL 60637
and NBER                                        and NBER
mdinerstein@uchicago.edu                        constantine.yannelis@chicagobooth.edu

Rigissa Megalokonomou
Department of Economics
University of Queensland
University Drive, St Lucia
Brisbane, QLD 4072
Australia
r.megalokonomou@uq.edu.au
1        Introduction

Human capital ­ the knowledge and skills of workers ­ is a key factor driving economic growth
in the aggregate and labor market outcomes at the individual level. Human capital can be
developed at home within the family, through formal education, and through labor market ex-
perience (Becker, 1962, 1964). But if acquired skills are not actively used, they may depreciate
over time. Thus, high rates of skill depreciation may amplify the costs to unemployment or
labor force detachment by lowering a worker's future productivity.
        Indeed, several studies find evidence of structural non-employment duration dependence,
where the probability of callbacks, probability of re-employment, and wages upon re-employment
decline in the length of the non-employment spell (e.g., Kroft, Lange and Notowidigdo (2013),
Autor, Maestas, Mullen and Strand (2015), Jacobson, LaLonde and Sullivan (1993)). Whether
this duration dependence derives from skill depreciation or other explanations, such as stigma,
changes to reservation wages (Schmieder, von Wachter and Bender, 2016), changes to match
quality (Neal, 1995), or cohort effects (Oreopoulos, Von Wachter and Heisz, 2012), is impor-
tant for optimal policy design. For instance, if unemployment costs are driven by human cap-
ital depreciation, then policies that maintain part-time or temporary employment or provide
structured activities that require using job-related skills might be particularly effective. Such
policies could include part-time working subsidies,1 public works programs, or even banning
non-compete clauses. Furthermore, high degrees of skill depreciation imply particularly large
costs from increases in aggregate non-employment through a depletion in aggregate levels of
human capital. Yet, despite their policy importance, well-identified empirical estimates of skill
depreciation rates remain elusive.
        This paper studies how human capital changes with time spent without formal employment.
To do so, we compile a new dataset on teachers in Greece and their assignments and exploit
an institutional feature that quasi-randomly assigns time spent in formal employment. We find
that an additional year without formal employment, with the associated forgone experience,
leads to a 0.09 student standard deviation () decline in a teacher's student test scores. Using
    1
    For example, the well-known German Kurzarbeit scheme subsidizes firms for part-time employment. A num-
ber of other European countries operate similar schemes to encourage firms to cut hours rather than employees.
Many countries used such policies during the 2020 pandemic recession.



                                                      1
aggregated data covering the entire country, we estimate that a district's student test scores
fall by 0.07 per-class if the teachers' mean time without formal employment increases by a
year.
       There are two challenges in measuring the changes in human capital due to non-employment.
First, in many contexts worker productivity is difficult to measure, especially over time.2 Sec-
ond, even if productivity can be measured, unproductive workers are less likely to receive job
offers, and hence are likely to spend more time not working. This may generate a negative
correlation between time spent without employment and productivity, even if time without
employment does not directly affect productivity.
       We overcome these challenges by studying teachers in Greece, using administrative data
from the entire country. We address the measurement issue by focusing on employees for
whom we have a direct measure of output. Following a large literature (e.g., Rockoff (2004);
Chetty, Friedman and Rockoff (2014)), we infer a teacher's productivity based on her students'
test scores. We use students' results on the Panhellenic Examinations, national exams that
all Greek high school students take in grade 12, and which are the primary determinants of
university admission. We also include university enrollment outcomes.
       We address the second empirical challenge by exploiting the unique system of teacher as-
signments in Greece. Individuals who graduate in good standing with an education degree are
guaranteed a public sector teaching position. In nearly all years, however, there are not enough
positions immediately available, and thus graduates enter long waitlists that determine assign-
ments. By law, all university graduates are assigned waitlist rankings in order of their date of
degree conferral. Because small differences in degree conferral dates are driven by heteroge-
neous course schedules, timing of oral defenses, and bureaucratic delays, we argue that within
a degree conferral month-year, remaining variation is exogenous. This quasi-randomness in
waitlist position can translate to considerable variation in how long similar teachers wait for
assignments to formal positions.3
   2
     We use teacher productivity and ability interchangeably to describe the amount of output teachers produce in
their students. See Bertrand and Schoar (2003) and Zivin and Neidell (2012) for a discussion on the challenges
of estimating manager and worker productivity.
   3
     Teachers lose waitlist eligibility if they take full-time employment. Because some teachers may work in the
informal sector while waiting, we refer to our estimates as human capital changes from time without formal
employment.



                                                       2
       In addition to the data on national test scores, we compile novel data from the Greek Min-
istry of Education on the universe of Greek deputy teacher waitlist rankings and assignments
between 2004 and 2011. The assignments designate the school district the teacher is assigned
to for the following year. We supplement this with hand-collected data from 23 high schools
that includes student-teacher assignments for each course and test scores by subject for all high
school grades.
       Our main specification relates a teacher's students' test scores to the accumulated number
of years the teacher spent without formal employment. To address the concern that years with-
out formal employment may be correlated with a teacher's "potential" productivity,4 we control
for the month-year in which the teacher earned her degree and further instrument for years
without formal employment with initial waitlist rank.5 Our estimates indicate significant loss
in productivity from not working formally: a 0.085 decline in test scores per year. Losses are
similar in the first and second semester exams, and continue to post-secondary outcomes. Stu-
dents with a teacher who had an additional year without formal experience are 2.2 percentage
points (3.3%) less likely to be admitted to a university.
       To extend the analysis beyond these 23 schools, we employ a second specification where
we aggregate to the school district level and estimate the effect of the labor force's average
time spent without formal employment on test scores. These estimates are robust to within-
district sorting of students to teachers. Our estimates are very similar to the estimates from the
teacher-level specification: a combined depreciation and forgone experience effect of 0.068
per class, or 1.5 percentage points in university admissions probability.
       Our identification strategy relies on the initial waitlist position, conditional on degree
month-year, being orthogonal to (1) teacher potential productivity and (2) unobserved ability
of a teacher's assigned students. We assess the validity of our identification strategy in several
ways. First, we examine attrition, which we view as the most obvious threat. We find no evi-
dence of attrition related to initial waitlist position, conditional on degree month-year. Second,
we find no evidence that teachers' initial waitlist position, conditional on degree month-year,
   4
     We refer to "potential" productivity as the teacher's productivity had she been continuously employed as a
public school teacher. We distinguish this from realized productivity, which may depend on how long a teacher
has been without formal employment.
   5
     We use initial rank as an instrument because, as we describe in Section 2, a teacher's waitlist rank evolves in
the years since graduation, sometimes for reasons related to potential productivity.


                                                         3
correlates with the teacher's university achievement. Third, we find no statistical relationship
between the mean (conditional) waitlist rank of the teachers assigned to a district and district
characteristics like unemployment rates or class size. Finally, we repeat our analysis using the
time without formal employment of a district's teachers in subjects that do not appear on the
national tests. We find no relationship between their mean time without formal employment
and students' test scores.
   The main estimates capture the combined effect of skill depreciation, independent of em-
ployment, plus forgone skill appreciation that would have accrued with experience. We de-
compose the effects of these channels by comparing teachers with the same levels of prior
experience but who have exogenously waited different amounts of time for their assignments.
Using our district-level model, we estimate that, controlling for experience, an extra year with-
out formal employment lowers test scores by 0.044 per class. We specify a simple production
model of student test scores and teacher human capital that relates our causal estimates to ex-
perience returns and depreciation rates. Our estimates imply a skill depreciation rate of 4.3%
and experience returns of 6.8% per year.
   This paper delineates a specific mechanism that generates structural unemployment dura-
tion dependence. An extensive literature has documented the duration dependence of non-
employment for callback rates (Kroft, Lange and Notowidigdo (2013), Farber, Silverman and
von Wachter (2017)), wages upon re-employment (Jacobson, LaLonde and Sullivan (1993),
Card, Chetty and Weber (2007), Centeno and Novo (2012), Schmieder, von Wachter and Ben-
der (2016)), and re-employment (Autor, Maestas, Mullen and Strand, 2015). By focusing on
a profession where output is observable, our paper distinguishes changes in productivity as
a cause of duration dependence from other explanations, primarily stigma. Several papers
have moved beyond wages to estimate effects on skills or output. Edin and Gustavsson (2008)
estimate the effect of unemployment duration on skill measures, using a panel data fixed ef-
fects approach. Benhenda (2017) and Wiswall (2013) look at teachers' absences and career
interruptions, respectively, and their effects on output. Our contribution is to combine out-
put measures with quasi-random variation in non-employment that is robust to time-varying
shocks.
   The paper also contributes to a literature on human capital and productivity by estimat-


                                               4
ing a key parameter used in many structural models in macroeconomics, labor, and finance,
many of which study duration dependence (e.g., Alvarez, Borovicková and Shimer (2016)).
Comparing estimates of depreciation across models is complicated as the form of depreciation
is often specific to the model. Keane and Wolpin (2001) estimate a large amount of depre-
ciation (31%) for white collar workers changing industries, which is similar to that in Imai
and Keane (2004). Blundell, Dias, Meghir and Shaw (2016) estimate human capital deprecia-
tion rates of 6-8%. Macroeconomic models incorporating human capital depreciation tend to
use very different parameterizations, including Ljungqvist and Sargent (1998) (20% chance of
losing skills), Kehoe, Midrigan and Pastorino (2019) (1.4% during a non-employment spell),
Jarosch (2015) (15% depreciation rate) and Manuelli and Seshadri (2014) (21% depreciation
rate). We offer a depreciation rate estimate that leverages quasi-random variation in time not
working.
   Our work also contributes to a literature in public finance and labor economics, by esti-
mating a parameter relevant to evaluating the effects of many policies. A large literature on
optimal unemployment insurance (Baily, 1978; Chetty, 2006; Shimer and Werning, 2006) de-
rives optimal benefit levels by trading off consumption smoothing benefits with changes to
labor supply. If human capital depreciates when individuals are not working, this effect can af-
fect optimal benefit levels. Non-compete clauses may also have harmful effects in the presence
of human capital depreciation (Marx, Strumsky and Fleming, 2009). Countries such as Ger-
many incentivize employers to reduce hours rather than lay off workers. Giroud and Mueller
(2017) discuss how these policies led to lower unemployment during the Great Recession,
with substitution in hours worked. These policies may have positive effects on human capital
accumulation if they prevent deterioration. The importance of policies preventing the deteri-
oration of human capital due to workers being out of the labor force is particularly relevant
at the time of writing. The COVID-19 pandemic and recession has led to historically high un-
employment and furlough rates in many countries. Our estimates suggest that the resulting
decline in human capital may have aggregate effects.
   Finally, in the most direct sense this paper joins a literature on the returns to experience
(e.g., Angrist (1990); Altonji and Williams (1992)), especially for teachers. A number of papers
have estimated high experience returns early in a teacher's career that then flatten (Rockoff,


                                               5
2004; Rice, 2013), while Wiswall (2013) and Papay and Kraft (2015) estimate positive returns
even at high levels of experience. Herrmann and Rockoff (2012) estimate the effects of teacher
absence on students, mainly driven by the productivity of the substitute teacher. Jackson,
Rockoff and Staiger (2014) provide a review of the broader literature on teacher productivity.6
This paper estimates the effect of not working on productivity and decomposes the effect into
within-worker experience returns and depreciation rates. We rely on quasi-random variation
that avoids the common assumption that teachers select into experience samples based only
on time-invariant factors.
        The remainder of this paper is organized as follows. Section 2 discusses the institutional
details that form the basis for our empirical strategy. Section 3 describes the data used in
our analysis. Section 4 introduces our empirical strategy. Section 5 presents the student-level
estimates and then Section 6 extends the analysis to the larger sample and conducts a district-
level analysis. Section 7 decomposes the effects into skill depreciation and forgone returns to
experience. Section 8 concludes and discusses avenues for future research.



2        Institutional Details

2.1        Types of Teacher Assignments in Greece

The education system in Greece appoints teachers to either permanent or temporary positions.
Permanently appointed teachers ("permanent teachers") are considered to be civil servants and
once hired they enjoy job security. Every year they have the option to remain at their previous
school. Teachers appointed to temporary positions ("temporary teachers") are employed on
a contract basis for up to ten months and have to re-apply through a centralized assignment
system for a new short-term appointment. Even if they receive an assignment in the following
year, it will almost certainly be at a different school. These temporary teachers, formally called
substitute or deputy teachers, can be either full-time, teaching 16-23 classroom hours per week
    6
    Other recent work has focused on measurement (Hanushek and Rivkin, 2010), information and evaluation
(Rockoff, Staiger, Kane and Taylor, 2012; Taylor and Tyler, 2012), instructor characteristics (Hoffmann and Ore-
opoulos, 2009), match quality (Jackson, 2013), peer effects (Jackson and Bruegmann, 2009; Opper, 2019), and
performance pay (Lavy, 2002, 2009).




                                                       6
at a standardized salary,7 or hourly, teaching up to 4 hours per week at a standardized hourly
rate.
    Schools may request a deputy teacher when there is a shortage of teaching staff. This
occurs through retirements among permanent teaching staff, teachers taking long-term un-
paid leaves (maternity, pregnancy, post-graduate studies, serious illness, or temporary moves
abroad), or unexpected demand shocks. For example, if a school's enrollment increases more
than expected, the school may request a deputy teacher to cover the additional classes. Most
temporary teacher assignments occur in September or October, but some of these events re-
quire mid-year assignments.
    The fraction of teachers in temporary assignments has grown considerably over the last
two decades. Between 2011 and 2015, there was a 35% increase in the number of deputy
teachers who were employed by schools, such that now 15-20% of the teacher workforce are
on temporary contracts (OECD, 2018). This share varies by district. Temporary teachers might
be the minority in schools in affluent urban neighborhoods, but often dominate in small and
remote areas, especially in the islands (OECD, 2018).
    There are at least two reasons behind this trend. First, budgetary pressures since the 2008
financial crisis have increased the use of temporary staff to cover teaching needs. As civil ser-
vants, permanent teachers count as a long-term liability to the national budget. In an attempt to
reduce these committed expenditures, the European Commission agreed that European struc-
tural funds could be used to cover the salaries of temporary teaching staff in Greece and other
European countries (OECD, 2018). In practice, these expenditures do not represent salaries,
but payments for educational services.8 Second, since 2009 Greece has had a hiring freeze for
permanent staff. As hiring new temporary teaching staff has became the only way to cover
teaching needs in schools, an increasing number of teachers have been hired on a contract
basis.
   7
     In practice, nearly all full-time deputy teachers teach the maximum 23 hours per week, where hours refer
to classroom instruction time. Less commonly, a full-time deputy teacher could agree to work between 5 and 15
hours per week. These teachers get monthly prorated payments. Full-time permanent teachers with fewer than
6 years of experience teach 23-24 hours per week while more experienced teachers cover 20-21.
   8
     Thus, temporary teachers do not get paid during the summer, unlike permanent teachers.




                                                     7
2.2       How the System Determines Assignments from Waitlists

University graduates with a degree in education prior to 2011 were entitled to a teaching
position in a Greek public school. Graduates, however, have to wait until a position opens in
their academic subject. For each subject, there are two main types of waitlists for teachers
depending on teachers' seniority.9
       The first list is for fresh university graduates with no prior teaching experience. Each year
fresh graduates are added to the ends of the waiting lists according to their exact date of de-
gree conferral. If graduates share the same date of degree conferral, ties are broken in favor
of the teacher with the higher university grades. Unlike other higher education systems where
a university's graduates receive their degrees on the same day, in Greece degree conferral oc-
curs once the pivotal course's grade is entered. The pivotal course is often a student-teaching
assignment or involves a written thesis or oral defense. Heterogeneous course schedules, grad-
ing congestion, and bureaucratic delays lead students to finish their degrees on different days,
and this generates considerable variation in when students graduate, as seen in the top row
of Figure 1. The left panel is a histogram of the month of the year in which teachers earn
their degrees while the right panel is a histogram of the day of the month. Some months and
days produce more degrees than others, but there is still extensive variation across and within
month.
       Once a teacher rises to the top of the list, the next time a school requests a temporary
teacher, the position is offered to this teacher. The lists do not distinguish geographically,
so the offered position may be anywhere in the country. The teacher has a week to file the
requisite paperwork to accept the position. Occasionally, the position will involve teaching at
multiple schools in the same district.
       After teachers complete their first temporary assignment, via the fresh graduates list, they
enter the second subject-specific list, which consists of teachers who have some prior teaching
   9
     To be eligible for the waitlists, the following conditions must be met: (a) the applicants must be either Greek
or from North-Epirus or Greeks from Constantinople/Istanbul and from the islands of Imvros and Tenedos (Law
No. 3832 / 1958) or European Union citizens (Law No. 2431/1996), (b) male applicants must present a military
certificate that shows that they have served their compulsory military service or a certificate that shows that the
applicant has a military exemption, and (c) expatriates from Cyprus, Egypt, Turkey and North-Epirus must submit
a birth certificate and a certificate to the Ministry certifying that they are Greeks. There is no age restriction.




                                                         8
experience or have taken a written assessment (ASEP).10 The experienced teacher waitlist is
ordered by a teacher's accumulated number of credits (having more credits is better), which
teachers collect based on their prior experience, score in ASEP, and other factors.11 Once teach-
ers rise to the top of the list, get assigned a temporary teaching position, and complete it, they
earn additional credits and return to the experienced teachers waitlist for the next temporary
assignment. Lists are released publicly, and thus there is little to no scope for manipulation or
changing one's order once assigned.
       The time waiting for an assignment depends on the teacher's waitlist position, the length
of the list, and the number of openings. We provide more descriptive statistics in Section 3,
but typical wait times during our sample period were several years (Tsakloglou and Cholezas,
2005). In recent years, the supply of teachers has outpaced demand, as the prospect of eventu-
ally receiving a permanent teaching position with a high salary and job security may overcome
the need to wait for the position.12 Furthermore, many university students choose teaching
degrees without expecting such a long wait. In Table A.1, we show summary statistics from
an online survey, which we describe further in Section 3, of 200 current and former teachers.
Just 34% of teachers were aware of the centralized assignment system at the point they were
deciding on a profession; but once they entered the system, 76% report understanding the as-
signment process and 73% knew their exact waitlist position. The increasingly long wait times
have led to large protests and politicians have recently proposed changing the system.13


2.3       Prospective Teachers' Actions

As part of this process, prospective teachers with university degrees in education have several
decisions. While they wait for an assignment, teachers may find alternate ways to generate
  10
      The ASEP examination system was introduced in 1997 (Law No. 2525/1997) to guarantee permanent posi-
tions to teachers that scored the highest on assessments that tested subject-specific and general pedagogic knowl-
edge (Stylianidou et al., 2004). The ASEP examination took place every two years until 2008, the last time it was
offered (OECD, 2018).
   11
      Teachers earn 1 teaching credit for each month of prior teaching in a school that is located in an urban area,
but they earn 2 teaching credits per month of prior teaching in remote areas and islands. They also collect credits
based on their marital status and the number of children that they have. Job performance for prior teaching does
not alter credits.
   12
      See Kathimerini for a discussion. Stylianidou et al. (2004) discusses the relative attractiveness of teaching to
other options.
   13
      See Euronews for a discussion.



                                                          9
income.14 Importantly, these activities may not include taking a full-time job, which would
remove a teacher's public school teaching eligibility.15 Greece's active informal employment
sector means that some teachers may still take full-time jobs that are hidden from the govern-
ment. In Table A.2 we document surveyed teachers' activities while waiting for assignment.
Just over half (54%) of the surveyed teachers used their time waiting to offer private lessons,
39% worked in non-education positions (e.g., as a restaurant waiter), and 33% got more for-
mal education. A smaller number of teachers used their wait to start a family or on other
activities. We will thus interpret our estimates as capturing the potential loss of skills relevant
to a worker's desired profession (teaching) when the worker is unable to work formally in her
desired profession. This, notably, does not rule out the acquisition of skills relevant for other
professions nor does it preclude all activities that might use the same skills that matter for
formal full-time employment.
       If the prospective teacher takes full-time formal employment or notifies the government
that she no longer wants to be considered for temporary public school teaching positions, then
she will no longer appear on the lists. We will explore attrition in more detail in Section 4 as
certain forms of selective attrition would violate our identification assumptions.
       Finally, if offered a position the teacher finds unattractive or unacceptable, a teacher may
reject it. Rejection, however, is quite costly. The teacher is placed at the end of the waitlist and
becomes ineligible for any assignments in the following two years. Rejections tend to be rare,
but if they were more common and selective they might pose identification challenges.
       This institutional setting has several features that might produce high skill depreciation.
First, because nearly all full-time teaching positions are in the formal sector, there are few
available ways to spend one's waiting time that approximate the desired job. Second, teachers
face limited financial or professional incentives to perform well once assigned. Student test
scores or other outcomes do not factor into any form of teacher evaluation. Neither finan-
cial compensation nor future assignments ­ both where and when ­ depends on performance.
Thus, the incentives to insure against or take investments to counteract depreciation are lim-
ited, and the available tools are directly restricted.
  14
     Waiting teachers are not eligible for unemployment insurance.
  15
     This restriction prevents teachers from working at private schools, though the Greek private education sector
is small at 7% enrollment share.



                                                       10
    The nature of work experience also stands out in this setting. On-the-job learning may
involve general and firm-specific skills. Here, because each temporary position lasts less than a
year and reassignment to the same school is exceedingly rare, the effect of experience on output
may be limited as school-specific skills generate no future return. Furthermore, the short-term
nature of the national assignment process means that each year of experience likely involves
a costly relocation to a different part of the country. Finally, unlike many settings with time
spent not working, here there is no need to search for a job, at least in the desired profession.
While there is some uncertainty about when a position will be available, the teacher's actions
do not affect it.



3     Data

We compiled novel national data on teacher waitlists, teacher assignments, and student test
scores. We supplement these data sets with comprehensive data from 23 high schools that
includes student-teacher linkages for each course taken and a survey of current and former
teachers. We provide more details about the data set construction in Online Appendix A.


3.1    Teacher Waitlists

The Ministry of Education compiles teacher waitlists centrally and maintains an online archive
in which it posts some waitlists from prior years. We tracked down the archives and constructed
the waitlists for deputy and hourly high school teachers from 2003 ­ 2011. Each year includes
separate lists for each teaching subject and for fresh graduates versus experienced teachers. A
teacher may appear on both the deputy and hourly lists, corresponding to her experience level,
in the same year. The waitlists include each teacher's position on the list plus any characteristic
or outcome that determines the waitlist order. Importantly, this includes when a teacher's
university degree was conferred and teaching experience accrued in each year. We restrict our
sample to teachers who earned their university degrees prior to 2006, as our identification
strategy, described in Section 4, will rely on cohorts where at least some members reach a
second assignment in our sample period.
    The top panel of Table 1 displays summary statistics for the waitlist data, for teachers in

                                                11
subjects that appear on the national examinations. Nearly half of the waitlist teachers have yet
to accumulate experience in the public Greek system, and prior experience in private schools or
other EU countries is rare. Teachers of Greek and History comprise the majority of the list, with
the rest are split between math and statistics, physics and biology, economics, and computer
science. We will later compare teachers in the same subject with degree conferral dates in the
same month-year. These cohorts are fairly large, with an average size of 62 teachers.
       In the bottom row of Figure 1 we show the full distribution of total (left) or consecutive
(right) years without formal employment for our sample of teachers that appear on the waitlists
between 2003 and 2011. Most teachers wait at least two years, with waits of 3-4 years being
common. While subsequent assignments beyond the first tend to occur more quickly, the distri-
bution of consecutive years without formal employment shows that total time without formal
employment consists of a few long spells rather than many short spells.


3.2       Teacher Assignment Data

The Ministry of Education and the school districts collect information on teachers' temporary
assignments to high schools around the country. They publicly announce these lists to inform
teachers about their assignments, but also for transparency reasons. These assignments come
from both teachers' waitlists ­ the fresh graduates waitlist and the experienced teachers' wait-
lists ­ and are usually announced in September or October based on schools' needs.
       We obtained the assignment lists from the online archives of the Ministry of Education and
school district authorities. These lists contain an assigned teacher's name, teaching categoriza-
tion based on the subjects that they teach,16 and the assigned school's district. We obtained
these lists from 2004 ­ 2011, with an average of 2,491 high school teachers assigned per year.
Unless a district has only a single high school, we do not know the exact school within the
district that the teacher was assigned to. But districts are fairly small; the 608 districts in our
sample have an average of 2.3 high schools.
  16
    There are several categorizations based on the subjects that teachers teach. Teachers obtain these specializa-
tions during their university undergraduate studies and they have to report their specialization when they enter
these lists. For example, PE01 teachers specialize in teaching religion studies, PE02 teachers specialize in teaching
Greek language, history and other literature subjects, PE03 teachers teach mathematics, etc. Teachers can only
teach subjects that belong to their categorization.




                                                        12
   We present summary statistics on the assigned teachers' subjects in the middle panel of Ta-
ble 1. The distribution of assignments is similar to the distribution of teachers on the waitlists,
with math and statistics and physics and biology having somewhat larger relative assignment
shares while economics and computer sciences have lower relative assignment shares. Differ-
ent regions of the country rely more on the assignment of temporary teachers. In Figure A.1
we show how the number of assignments varies geographically and note that the islands are
particularly dependent on temporary teachers.


3.3    Test Score Data

We also obtained student-level data from the Ministry of Education with test scores on the Pan-
hellenic Examinations, national exams that all Greek high school students take in twelfth grade.
Our data spans 2004 ­ 2011 and includes each student's total score and school attended. These
exams are the most important determinant for university admission; given these high stakes,
the exams are graded by external markers. The exams cover the core subjects (Mathematics,
Greek Language, History, Biology, Physics), and thus we will restrict our analysis to teachers in
these subjects unless otherwise noted. Students also take exams in other subjects depending
on whether they have chosen the Classics, Science, or Exact Science track. We convert the test
scores to student standard deviation units by normalizing scores to have mean 0 and standard
deviation 1 in each year.


3.4    Micro School Data

Our national data has two main drawbacks. We only know teachers' district, not school, and
we are limited to a single outcome in twelfth grade. We thus supplement the national data with
micro data from 23 high schools. We obtained this data by visiting these schools in person,
requesting all of their records, and digitizing them. These schools are distributed throughout
the country and cover a diverse set of areas.
   The data set's key features are student and teacher course schedules for all high school
grades that allow us to link a student to a specific teacher for each course and subject-specific
exam scores. Teachers cover an average of 2.18 subjects and teach 2.95 classes per subject


                                                13
(bottom panel of Table 1). While the sample is limited to 23 schools, the more precise match
between teacher and her students' outcomes will form the basis for our student-level empirical
analysis.
    This micro dataset's additional outcomes allow us to test for treatment effects on subjects
and grades not part of the national exam. We also observe grade point averages and semester-
specific test scores. Finally, we merged the sample to university admissions outcomes, which
allows us to extend our analysis to teacher's effects on consequential, non-test outcomes. In
our sample, 64% of students are admitted to a university and 62% to a university with an
academic focus, with considerable dispersion in the selectivity of university attended (bottom
panel of Table 1).


3.5    Teacher Survey

Finally, we supplement the national and micro data with an online survey, of 200 current and
former teachers, we conducted from December, 2019 ­ January, 2020. The responses yield
information on teachers' awareness and expectations of the assignment system, non-teaching
activities while waiting for an assignment or once assigned, and investments made to maintain
skills. We provide recruitment details and the survey text, in Greek and English, in Online
Appendix B.



4     Empirical Model and Strategy

We seek to estimate the effect of a year out of the formal labor force on teacher output, as mea-
sured by student outcomes. To fix ideas, consider the hypothetical example, illustrated below,
of two teachers who earned their degrees in July, 2004. While otherwise identical, teacher 1
had her degree conferred earlier in the month than teacher 2, so teacher 1 started with a better
waitlist position. This led to an immediate assignment in fall 2004 for teacher 1, while teacher
2 remained unassigned. Thus, at the end of the 2004-2005 school year, teacher 1 had accu-
mulated 0 years without formal employment and 1 year of formal experience while teacher 2
had accumulated 1 year without formal employment and 0 years of formal experience. For the
following school year, both teachers received assignments, such that at the end of the 2005-

                                               14
2006 school year, teacher 1 had accumulated 0 years without formal employment and 2 years
of formal experience while teacher 2 had accumulated 1 year without formal employment and
1 year of formal experience.

                                                   2004-05                         2005-06
                Teacher 1          Graduates in July and Assigned                  Assigned
                               (Years Not Emp, Experience) = (0,1)                  (0,2)
                Teacher 2        Graduates in July but Not Assigned                Assigned
                               (Years Not Emp, Experience) = (1,0)                  (1,1)

   Our target parameter is the causal effect on some output measure of a year without for-
mal employment instead of a year with formal employment. Identifying this effect involves
comparing outcomes for teachers in the same school year, but with exogenous variation in
the fraction of years since degree conferral without formal employment . Specifically, we can
compare teachers 1 and 2 in the same academic year ­ 2005-2006 ­ where the difference is
that teacher 1 has one fewer year without formal employment and one more year of formal
experience. The difference in outcomes is a relevant input for certain policymaking problems.
In this section, we further characterize this estimand with a simple production model. The
model serves several purposes: (a) it motivates the functional forms we use in our estimating
equations; (b) it clarifies the relationship between the estimand and human capital technolog-
ical parameters; and (c) it highlights the potential threats to identification. We then lay out
our empirical strategy to obtain consistent estimates.


4.1   Production Model

Let i index students, j index teachers, and t index academic years. We start with a general
model of student achievement and teacher human capital:


                                             yi t = f H j t ,      it                         (1)


                                  H j t - H j , t -1 = g H j , t -1 , e j , t -1              (2)




                                                       15
where yi t is student i 's output (e.g., test score) in year t , H j t is teacher j 's stock of teaching-
relevant human capital in year t , e j , t -1 is whether j accrued formal teaching experience in
t - 1, and    it   captures student-year shocks. We label f () as the student educational production
function and g () as the teacher human capital production function.
       We first parameterize the teacher human capital production function. We follow Rosen
(1976), Blinder and Weiss (1976), and a generalized version of Ben-Porath (1967) in assuming
that g () is homogeneous of degree one in the prior year's human capital:17


                                    H j t - H j , t -1 = e j , t -1 -  H j , t -1                          (3)


where  is the return to experience and  is the human capital depreciation rate.18 Given this
production function, we can derive human capital as a function of teacher j 's human capital
at the time of graduating from university (H j 0 ), the number of years since graduating from
                                                                                        t -1
university (N j t ), and the number of prior years of experience E j t =                s=0
                                                                                               e j ,s :


                                  H j t = (1 +  - ) E j t (1 - )N j t - E j t H j 0 .                      (4)


       The literature provides less guidance on parameterizing student achievement as a function
of teacher human capital, which is typically an unobserved input. But we follow the teacher
value-added literature in assuming that a teacher's impact on student outcomes is additively
separable from other determinants. Specifically, we adopt a log-linear specification, which is
equivalent to Cobb-Douglas if the outcome is expressed in logs:


                                              yi t =  ln(H j t ) +     it                                  (5)


       As human capital is not measured directly, we will make inference about a teacher's human
capital based on her student's output. Thus, we insert Equation 4 into Equation 5 to express
  17
     These papers focus on optimal human capital investments to maximize discounted lifetime earnings and their
production functions characterize how human capital varies with the fraction of time spent working. Here we
focus only on the technology and treat each year's work experience as binary.
  18
     The literature sometimes refers to the depreciation rate as the change in human capital only when an indi-
vidual is not working, or the change associated with a disruption like switching industries. We could redefine 
as being multiplied by non-employment and our model would be the same except the multiplicative change in
human capital while working would be  instead of  - .


                                                         16
student output as a function of the determinants of human capital:


                yi t =  ln(1 +  - ) E j t +  ln(1 - )(N j t - E j t ) +  ln(H j 0 ) +   it          (6)


If we rearrange terms to express student output in terms of number of years since graduating
and number of years not working (U j t  N j t - E j t ), we have:


          yi t =  (ln(1 - ) - ln(1 +  - )) U j t +  ln(1 +  - )N j t +  ln(H j 0 ) +         it .   (7)


This model, with student outcomes as a linear function of U j t , will form the basis for our
estimating equations, and in Section 4.2 we discuss how we identify the coefficient on U j t . As
the model clarifies, this target parameter combines experience returns () and depreciation
(), as well as a scale factor between human capital and student output (). The combined
effect is the relevant parameter for the effects of policies that shift employment status, as any
additional year spent not working automatically includes forgone experience. But in Section
7 we will decompose the total effect into depreciation and forgone experience channels.
   Before proceeding, we make several observations about the parameter interpretations and
functional forms. The return to experience, , captures any effect of formal experience on
teaching-relevant human capital. This may include increased curricular knowledge, human
capital investments complementary to being formally employed, improved time management
skills, and changes in motivation or effort from working. The effect of formal experience is
relative to the actions taken while not formally working, as characterized in Section 2.
   Similarly, the depreciation rate, , captures any changes in teaching-relevant human capi-
tal independent from whether the teacher is formally employed. This may include forgetting
material learned in formal education, (constant) age effects, and changes in motivation from
being part of a complicated assignment system. The composite parameters (, ) are rele-
vant for characterizing the current assignment process and for considering policies that shift
employment status but not the experience returns or depreciation rates. But because some of
these components might change depending on policy, might involve costly actions, or might
have spillover effects outside of education, we will comment on the extent to which the esti-
mates seem to be driven by different factors. Finally,        it   may capture student-year shocks as


                                                  17
well as any transient shocks to teacher productivity independent of experience.19
       The linear relationship we will estimate between student outcomes and teacher experience
is the subject of debate in the economics of education literature. Some consensus has formed
that experience returns are high for the first years of a teacher's career and then become flatter
(Rockoff, 2004; Rice, 2013), while Wiswall (2013) and Papay and Kraft (2015) show that
different identifying assumptions to solve the age-period-cohort problem can generate positive
returns even at high levels of experience. We are hesitant to rely on this literature to guide our
functional form choice because we view estimating experience returns as a result, rather than
an assumption, of this paper. While we will not trace out a non-parametric experience return
function, we will use exogenous variation in experience that avoids some strong assumptions in
the literature.20 That said, we address the linearity assumption in two ways. First, the papers
that find a non-linear relationship between experience and student outcomes typically find
that the relationship is close to linear at low levels of experience. As we describe below, our
variation will be largely driven by teachers early in their careers ­ just 1.1% of our estimation
sample has greater than 4 years of experience. Our variation thus lies in the experience interval
where the literature has found linear returns. Second, we will provide robustness checks to
our main results that allow student output to vary with the log of experience and that vary the
curvature in the student outcome.


4.2       Empirical Model and Identification

We now turn to our empirical implementation and how we will identify the model's parame-
ters. We would like to estimate the effect of a year without formal employment (U j t ) on an
output measure ( yi t ) where j = j (i ). But if the teacher hiring process favors more productive
  19
      Persistent shocks to teacher productivity would affect the returns to experience given Equation 3. Alternately,
if Equations 3 and 5 were additively separable in levels, Equation 7 would still be linear in experience and i t
could include persistent human capital shocks.
   20
      Most of the literature employs within-teacher estimators that rule out selection into experience levels based
on time-varying factors and estimates a combined experience and age effect. When we use these standard as-
sumptions, we estimate early career experience returns of 0.04 student standard deviations per year and later
career returns of 0.01 student standard deviations, though we cannot reject equality. For different identifying
assumptions, Wiswall (2013) relies on the exogeneity of measured career interruptions like decisions to take time
off. Herrmann and Rockoff (2012) use teacher absences before versus after student testing dates, though the
parameter of interest is the change in the productivity of the classroom's teacher rather than how an individual
teacher's productivity changes as her experience varies exogenously.



                                                        18
teachers, then regressing yi t on U j t will not yield a consistent estimate of the causal effect.
Greece's centralized assignment process provides us with useful variation in U j t that we argue
is unrelated to a teacher's potential productivity. Define teacher j 's risk set m = m( j ) in year t ,
to be the set of teachers who had their degrees conferred in the same year-month as j , teach
the same subject as j , and are eligible for assignment in year t (i.e., they have not attrited from
the lists). If we control for a teacher's risk set, then we isolate variation in U j t among teachers
who completed their education at very similar points in time. But this remaining variation
may still be related to a teacher's potential productivity. For instance, teachers may receive an
assignment through their ASEP test scores or a high number of accrued experience credits.
       Thus, we instrument for within-risk set variation in U j t with a teacher's normalized wait-
list position from the fresh graduates list in the first year the teacher appears in our sample.21
Because a teacher may appear on both the deputy and hourly lists, we use the minimum nor-
malized waitlist position across the two lists and label it as z j . We only use the waitlist position
from the fresh graduates list because the position on the experienced list may be related to a
teacher's potential productivity. The fresh graduates list position, however, still strongly pre-
dicts the speed of assignments on the experienced list because an earlier first assignment starts
the credit accrual process faster and moves the teacher up the experienced list.22
       Our empirical model is:
                                            yi t =  U j t + µmt + i t                                           (8)

                                             U j t = z j + mt +  j t                                            (9)

where µmt and mt are vectors of risk set-year fixed effects. Relating Equation 8 to the produc-
tion model (Equation 7),


                                      =  (ln(1 - ) - ln(1 +  - ))                                             (10)

                                                                 ¯ )
                                    µmt =  ln(1 +  - )N j t + ln(H                                            (11)
                                                                   j0


                                                             ¯ ) +
                                      i t =  ln(H j 0 ) - ln(H                                                (12)
                                                               j0          it

  21
     We normalize the waitlist position by the length of the list so it runs from 0 to 1. The first year the teacher
appears in our sample is the maximum of 2003 and the teacher's degree conferral year.
  22
     In the student empirical specification in Section 5, we will include some older cohorts of teachers that ap-
peared on fresh graduates lists before 2003. We describe below how we impute their original waitlist position.


                                                        19
                     ¯ ) is taken over teachers in risk set m in year t .
where the average ln(H j0

   Our exclusion restriction is that normalized waitlist position is independent of unobserved
determinants of outcome yi t once we control for risk set-year. In our context, there are two
types of identification threats: (1) waitlist position is (conditionally) correlated with a teacher's
potential productivity    [z j ln(H j 0 )|m, t ] = 0 or (2) waitlist position is (conditionally) corre-
lated with student types or choices     [z j   i t | m, t ]   = 0 . While our assumption of independence
is untestable, our knowledge of the institutional environment and related data analysis offer
support.
   As described in Section 2, waitlist position is determined by the date of degree conferral,
with ties broken by grade-point average. Teachers graduating in different semesters may differ
in many ways. Thus, we isolate only fine timing differences by controlling for the month-
year of degree conferral and argue that remaining conferral date variation within the month
is exogenous. Our identification strategy fails if within-month variation in graduation timing
correlates with a teacher's potential productivity, perhaps because more productive prospective
teachers pressure faculty members to enter grades quickly. Even if there were a pattern in
which more productive teachers graduate sooner, there is nothing special in the education
system about graduating at the beginning of a calendar month. Thus, "expedited" graduates
could earn their degrees faster than other students and still be at the end of a calendar month.
   But to provide more evidence that within-month timing of graduation appears unrelated to
teacher type, we regress the teacher's university grade point average (out of 10) on the teacher's
waitlist position percentile (position normalized by the length of the list). In the first column
of Table 2, we show a strong relationship between waitlist position, as determined by degree
conferral date, and the teacher's university GPA. This could reflect grade inflation as later
cohorts have higher (worse) waitlist positions and higher grades. In the second column, we add
fixed effects for each graduation month-year combination, separately for each academic subject
because the waitlists are subject-specific. Once we rely only on waitlist position variation from
within-month differences in graduation timing (and estimate Equation 9, but replacing the
left-hand-side with teacher's GPA and keeping each teacher's first waitlist observation), the
relationship between waitlist position and teacher grades goes away, with a high degree of
statistical precision.


                                                      20
       Even if initial waitlist position were (conditionally) uncorrelated with teacher type when
teachers graduate, the assignment process could induce a correlation over time via attrition. As
prospective teachers wait for an assignment, some may find full-time employment that would
make them ineligible for public school teaching. If the prospective teachers who attrit differ in
productivity from the teachers who remain on the waitlists, then initial waitlist position may
be correlated with teacher potential productivity among the remaining teachers, even if we
account for the direct impact of different time without formal employment. Whether attriting
teachers would be positively or negatively selected on teaching potential productivity is unclear
and depends on how teacher potential productivity correlates with productivity for other jobs.
       Attrition is quite common, which is perhaps unsurprising given the long wait times until
assignment. For example, 98% of the 2003 graduating cohort remain on the waitlists through
2004 but by 2010, 52% have dropped off. We explore the relationship between our instrument
­ fresh graduates' waitlist position conditional on degree month-year ­ and attrition in the
middle columns of Table 2, where attrition corresponds to dropping off the waitlists before
the end of the sample period and without accruing any formal experience. Our data sample
includes all teachers belonging to risk sets that lead to any assignments, as these are the risk
sets that will identify our causal estimates. We estimate Equation 9, but replace the left-hand-
side with an indicator for attrition, and we fail to reject the null hypothesis that there is no
relationship between conditional waitlist position and attrition.23 Thus, while within risk-set
variation still predicts how quickly fresh graduates receive assignments, the within risk-set
variation is much smaller than the across risk-set variation, and attrition rates only appear
responsive to these larger differences.
       We provide further visual evidence in Figure A.2, where we summarize attrition rates by the
teacher's degree conferral day. When we control for risk set, this within-month degree conferral
timing generates our identifying variation. The figure shows no clear pattern between attrition
rates and time of the month.
       Attrition appears to be unrelated to our instrument and also teachers' university academic
achievement. In the last column of Table 2 we see that teachers with higher university grade
  23
     Column 3 of Table 2 shows a negative relationship between waitlist position and attrition, when we do not
control for risk set. Recent graduating cohorts are less likely to have attrited by the end of our sample and appear
at the back of lists that grow each year.



                                                        21
point averages are no more likely to attrit when we control for risk set. Thus, while our as-
sumption that there is no selective attrition is fundamentally untestable, the balanced attrition
rates across our instrument and lack of relationship between attrition and teacher academic
achievement are encouraging. One potential reason for a lack of selective attrition is that
teachers are neither evaluated nor compensated on the basis of student performance. Thus,
the attractiveness of remaining a teacher may be relatively unrelated to productivity.
   The second threat to identification realizes if teachers' waitlist positions are unrelated to
their potential productivity but correlated with the characteristics of the students they teach.
For instance, if economic conditions worsen, family life may be more stressful and students may
perform poorly. Or perhaps some districts invest in smaller class size, which leads to better test
outcomes. If these shocks or actions are correlated with changes to a school's demand for
temporary teachers, then we might worry that our estimates confound the teacher assignment
effects with local shocks.
   We consider these threats unlikely, as schools request temporary teachers on a rolling ba-
sis, with fast churn such that it would be nearly impossible to target specific teachers. This
is consistent with Table 3, where we regress a school district's twelfth grade cohort size or
local unemployment rate on each assigned teacher's waitlist position. We find no relation-
ship between waitlist position and these district characteristics in the cross-section, nor within
district, when we compare changes over time by including district fixed effects. And the null ef-
fect remains when we add region-year fixed effects. Thus, teachers with different (conditional)
waitlist positions do not appear to be assigned to schools in different types of districts.
   Teacher assignment could still interact with student type based on within-school class as-
signments. If a principal realizes the new deputy teacher is unprepared, she may want to place
the teacher in a classroom with a non-random set of students. This is unlikely to be an issue
because Greece requires high school teachers to be assigned randomly to students (Lavy and
Megalokonomou, 2020). We also provide two empirical tests to assess this threat. First, we
will show that teacher time spent not working is unrelated to students' lagged grade-point av-
erage. And second, we will include a district-level specification that is robust to selection on
assignment of students across teachers in the same school district. We present the results after
introducing our individual and district specifications in Sections 5 and 6.


                                               22
    Teacher experience may directly affect      it   if students take actions to compensate for a low
human capital teacher. For example, students might receive additional parental tutoring or
reallocate study time toward courses with inexperienced teachers. We could consider these
actions as part of the effect of teacher experience on output that we seek to identify. But these
actions may also incur additional costs to the system (parental time; lower output in other
courses) we would not capture with a student's output in a single course. We will explore the
possibility of cross-course spillovers by testing whether the time spent not working for teachers
in non-tested subjects affects students' test scores.



5     Individual-Level Estimates

We estimate two versions of our empirical model, each adapted to a different level of aggrega-
tion in our data. First, we present a student-level model that describes how students' outcomes
vary with the years without formal employment of their assigned teacher. This model exploits
the detailed data on student outcomes and teacher classroom assignments from the 23 schools
in the micro data. Our micro data set includes student test results for each subject. We thus
extend our empirical model to a student-subject-year unit of analysis. Let i denote a student,
s denote a subject, and j = j (i , s, t ) denote student i 's teacher for subject s in year t . Let
m = m( j ) denote teacher j 's risk set. We specify our model of a student-subject exam outcome
yist as:
                                       yist =  U j t + µmt + ist                                   (13)

                                        U j t = z j + mt +  j t                                    (14)

    While our micro data only has outcomes from 23 schools, we have waitlist and experience
measures for the whole country. To leverage both sets of data, we implement a within trans-
formation on our empirical model (Frisch and Waugh, 1933; Lovell, 1963; Giles, 1984). Let
x~                                                  ist = x ist - x¯
 ist denote x ist demeaned at the risk set level ( x~              mt ). If we apply the within-risk set

transformation, our model becomes:


                                           ist =  U j t + 
                                          y~       ~      ~ist                                     (15)



                                                     23
                                                      U~j t = z~
                                                               jt + ~j t .                                                      (16)

      For the model observables that do not require student-level data (U~j t , z~
                                                                                 j t ), we can perform

this within-risk set transformation using the full national sample of teachers. But because we
only observe outcome yist for a subset of 23 schools, we cannot estimate this model on the full
sample. Instead, define ist = ~
                              ist + y¯
                                     mt and rewrite our model as:



                                                      yist =  U~j t + ist                                                       (17)


                                                      U~j t = z~
                                                               jt + ~j t .                                                      (18)

We estimate this model as our student-level specification, clustering standard errors by teacher.
We construct U~j t and z~
                        j t using the risk set means from the full sample of teachers and then

estimate the instrumental variables specification using the students and teachers in our micro
data set. Provided our micro sample is representative, the identification assumptions are un-

              jt 
changed: if [z~  ~ist ] = 0 then [z~j t ist ] = 0 by construction.
                                                                  24
                                                                     This procedure allows us to
use the national sample to control for differences across risk sets while using the micro sample
for linked outcomes.
      Before estimating the model, we present distributions of the demeaned waitlist positions
(z~                                                        ~
  j t ) and accumulated years without formal employment ( U j t ) for the full sample in Figure 2.

We see that, even when controlling for the degree month-year, there is still a lot of residual
variation left in our instrument and the years without formal employment. This occurs in
part because earlier first assignments generate faster subsequent assignments, given how the
experienced teachers waitlist is structured. Thus, we are able to implement fine controls for
degree timing and still have enough variation left over to generate precise causal estimates.
      Consistent with the details of the assignment process, we observe a strong relationship
between demeaned waitlist positions and demeaned years without formal employment. We
show a binscatter plot of the two variables in Figure 3. Worse waitlist position from the fresh
graduates list, even after controlling for risk set, strongly predicts a higher number of years
without formal employment. Relative to a teacher at the front of the waitlist, a teacher at the
 24
    Note that [z~    j t ist ] =   [z~
                                     j t ~
                                         ist ] + [z~    mt ] = 0 + [z~
                                                   j t y¯                 mt ] =
                                                                     j t y¯        mt [   [z~    mt | m, t ]] =
                                                                                            j t y¯                mt [ y¯
                                                                                                                        mt     j t ]] =
                                                                                                                             [z~
 mt [ y¯mt  0 ] = 0.



                                                               24
waitlist's median is expected to wait almost an additional year.
       We start by assessing whether within-school assignment of teachers to students might be
related to a teacher's level of human capital. We estimate Equations 17 and 18 via two-stage
least squares where the student outcome is her grade-point average in the year prior to the
assignment of a deputy teacher.25 Because the outcome realized before the deputy teacher
taught the student, it is a placebo test for whether there is selective assignment of students
to teachers.26 We present the results in Appendix Table A.5 (col. 1). We find no statistically
significant relationship, consistent with our identifying assumption. Given that we find no
evidence of selection, we will use a student's lagged GPA as a control variable for our main
analysis.
       We now turn to estimating the effect of time out of formal employment on students' average
exam score in a subject-year. In the first column of Table 4, we show OLS estimates from a
model that controls for each teacher's risk set but does not instrument for the number of years
without formal employment. We find a negative estimate of the effect of years without formal
employment on student total exam scores, but we cannot statistically reject no effect. In many
settings, we might expect the OLS estimates to be biased downward, if potential productivity
correlates negatively with years without formal employment and negatively with output. The
Greek teachers assignment process complicates this argument, however, as assignments are
driven by factors besides productivity and elements like attrition could reverse the sign of
the bias. We thus introduce our reduced form and first stage estimates, in columns 2 and
3, respectively. We find a strong relationship between (demeaned) waitlist percentile and
(demeaned) years without formal employment.
       Columns 4 through 8 display our IV estimates, starting with the average test score during
the year ("Score"). We estimate that an additional year without formal employment lowers
  25
      To gain precision for the student-level analysis, we expand our sample in two ways. First, we include deputy
teachers even if they graduated too long before our sample to appear on a fresh graduates list in our sample
period. We use the waitlist's assignment rule ­ by degree conferral date ­ to impute original waitlist positions.
Then because we do not know how many teachers were on these original fresh graduates lists, we rescale the
instrument to run from 0 to 1 within risk set. Second, we include permanent teachers in the analysis and treat
each as having her own risk set. In case permanent teachers teach at different types of schools, and thus violate
  [z~j t ~
         ist ] = 0, we add a dummy variable for whether the teacher is a deputy teacher. These permanent teachers
simply add precision to our controls, introduced below. We discuss the instrument construction in more detail in
Online Appendix D.
   26
      We use lagged GPA rather than lagged test scores because students in different grades often take courses in
different subjects.


                                                       25
student test scores by 0.085 student standard deviations, or 2.5 percentiles.27 This is a large
effect ­ the standard deviation of teacher value-added, estimated as in Chetty et al. (2014),
is 0.20 student standard deviations in our data. Thus, the effect of a year without formal
employment is equivalent to 43% of the cross-sectional standard deviation. The effect appears
to be strong for teachers in STEM fields, though for non-STEM fields our estimates are very
imprecise (Table A.6).
       Such a large effect of a year without formal employment may reflect skill loss that rebounds
quickly. Teachers who spent a few years not working may forget some curricular material;
but if they are able to re-learn the material quickly, then short-run estimates may overstate
the impact. Further, optimal unemployment benefits depend on how skill depreciation rates
vary during an unemployment spell (Shimer and Werning, 2006). We therefore break out our
estimates by first and second semester tests and end-of-year exam, in columns 6 through 8.
We see a very stable set of estimates that get slightly larger in magnitude for later tests. Thus,
the change in teacher output is persistent for at least a year.
       Students with teachers who have been out of formal employment for longer are at a large
disadvantage on tests. We show similar effects on students' grade-point averages in Table A.7.
We now explore whether this disadvantage carries over to post-secondary outcomes in Table
5. The Greek university admissions process takes the Panhellenic exam scores and reweights
the sections to generate an admissions score. Students then submit ordered preference lists
of institution-program combinations and are admitted in order of admissions score. Column 1
presents the results on the natural log of the admission score.28 Students with less experienced
high school teachers have lower admissions scores. Perhaps to compensate for these lower
scores, the students include more university-programs on their preference lists (column 2),
but they remain at an admissions disadvantage. Students with teachers who had an additional
year without formal employment are 2.2 percentage points less likely to be admitted to a
university, with a baseline admissions rate of 67% (column 3). Of this 2.2 percentage point
  27
     The 2SLS standard error on years without formal employment is lower than the OLS standard error. This
occurs when we cluster the errors, where there is no general result that 2SLS standard errors are necessarily
higher. When we do not cluster our errors, the OLS standard errors are slightly lower than the 2SLS standard
errors.
  28
     The raw scores are highly skewed so we show the effect on the log score. In Online Appendix C we show
effects on raw score.



                                                     26
effect, 1.4 percentage points comes from reduced admissions to academic university programs
(column 4) while the rest consists of students not attending technical universities. On the
margin of where a student is admitted, we see that students with inexperienced teachers are
admitted to less selective institution-programs. Column 5 shows that having a teacher with one
year fewer of formal experience causes the student to be admitted to an institution-program
that is 2.5 percentiles lower-ranked in terms of admitted students' admissions scores. These
large effects on post-secondary outcomes confirm that formal experience matters beyond the
time the student is in the teacher's class. We provide more interpretation of the estimates after
describing our district-level estimates.
       In Online Appendix C we provide robustness checks for our student-level estimates. We
explore robustness to the sample, bootstrapped standard errors, the functional form of formal
experience, our use of controls, the test score units, and our measure of university selectivity.



6       District-Level Estimates

We now turn to a model of district-year mean student outcomes. We sacrifice the precise
measurement of an individual teacher's multiple outputs for robustness to possible within-
school or within-district assignment of students to teachers' courses depending on the type of
the newly-assigned temporary teacher. We also gain external validity by extending the analysis
to the national level.
       We derive our district empirical specification from the same empirical model, Equations
8 and 9, by introducing an aggregation matrix, A. An element (A r,c ), corresponding to row
r = d t and column c = j , is the fraction of district d 's teacher deputy work force that teacher
j comprises in year t . Each column will have 0 in all elements corresponding to year t except
one, as each teacher works in a single district in a given year. If a district has 20 high school
deputy teachers in tested subjects, then each of those 20 teachers will have 1/20 as their non-
zero element.29
       We perform the within risk-set transformation on Equations 8 and 9, as in the student
  29
     We implicitly assume that teachers in the same district-year have similar numbers of students. We cannot test
this on the national sample, but for the 23 schools in the micro data, we find limited within-school variation in
class sizes.



                                                       27
empirical specification. Then, we left multiply the demeaned equations by matrix A, which
yields our district-level model:
                                                 yd t =  U~d t + d t                                     (19)

                                                   d t = z~
                                                          dt + 
                                                 U~            ~dt.                                      (20)

              1
      dt =
with x~      Nd t   j  Jd t   x~j t for each variable x where Jd t is the set of deputy teachers in district d
in year t and Nd t is the size of this set. As above, we do not demean the outcome, yd t , so

                                                          1
                                            d t = ~
                                                  dt +                    ym¯( j)t .                     (21)
                                                         Nd t   j  Jd t


   Before presenting the results, we revisit the identifying assumptions now that we have a
district model. We maintain the prior assumptions that waitlist position is conditionally in-
dependent from teacher's unobserved potential productivity and assigned student types. We
further assume that within a region assignees' (demeaned) waitlist positions are independent
from the region's other assignees' types. Otherwise, the waitlist position might be an appropri-
ate instrument at the individual level but due to aggregation, might correlate with the district-
level error. We cannot test this directly, though we do not know of any way a district could
target teachers from a specific part of the waitlist, controlling for risk set. We offer an indirect
test by checking for a statistical relationship between z~
                                                         d t and the types of risk sets contributing

the district's assignees. Specifically, we test whether z~
                                                         d t is related to the district-aggregated

mean experience, where the mean is calculated over the risk sets that include the district's
assignees. We present the test in Table A.8, where we fail to reject no statistical relationship.
   Given this assumption of independence in assignments, we might worry that the law of large
numbers eliminates any variation in the instrument or endogenous regressor across district-
years. But the small number of high school temporary teachers (in tested subjects) assigned for
most district-years leaves considerable sampling variation. We show the remaining variation
in Figure 4. Compared to Figure 2, the aggregation shrinks the dispersion, especially of our
instrument. But with controls we still have enough variation left to generate precise causal
estimates. We include district and region-year fixed effects to absorb cross-district persistent
test score differences and region-level shocks and include the log of the district's mean class



                                                         28
size as a control (demeaned by risk set).30


6.1       Baseline Estimates

We present our district-level estimates in Table 6.31 Our OLS regression in column 1 yields
a positive but statistically insignificant association between teacher time without formal em-
ployment and students' twelfth grade test scores. But the relationship flips signs once we
instrument for the district's mean teacher years without formal employment. In column 2 we
present the district-level first stage regression. Despite the aggregation, we can still predict
differences in mean years without formal employment across district-years.32 Our IV estimates
show significant decreases in student test scores when a district's teachers have spent longer
without formal employment. For each year increase in average time without formal employ-
ment, we estimate that student test scores fall by 0.34 student standard deviations (), or 8.9
test score percentiles.
       The interpretation of the effect sizes for the district results differs slightly from the in-
dividual analysis, because students' Panhellenic test scores cover multiple subjects while the
individual test scores are subject specific. Twelfth-grade students take five courses in subjects
that appear on the standard Panhellenic exams. We thus divide the estimates by 5 and report
the per-class estimate. Our individual estimates from Section 5 suggest a decrease of 0.085
for students in a given course if a teacher has an additional year out of formal employment,
while the district-level estimate is 0.068. We cannot statistically reject equality.
       We find that the effects carry over to the post-secondary outcomes of the district's twelfth
graders, though our estimates are less precise (columns 5-9 of Table 6). We estimate that
having teachers with one additional year out of formal employment lowers the log university
  30
     As in the student model, our inclusion of controls that cleave risk sets ­ in this case, the district and region-
year fixed effects ­ is not fully consistent with our within risk-set transformation. We include robustness checks
in Online Appendix C. Further, we find no relationship between a teacher's waitlist position and her assigned
district's mean class size or mean log class size.
  31
     We provide visual counterparts with binscatters for the first stage (Figure A.3) and reduced form (Figure A.4).
  32
     The interpretation of the first stage differs in the aggregated specification for two related reasons. First, to
increase precision in the individual analysis, we included teachers who already entered the experienced waitlists
by the beginning of our data sample. This led to a more experienced sample. Second, because we included these
experienced teachers, we had to use imputed waitlists positions based on the system's design, rather than actual
positions. While these imputations preserve exogeneity, the scale changes because we do not know how long the
original lists were as many teachers may have attrited prior to our sample period. In the individual analysis we
thus calculated within risk-set waitlist percentiles while here we calculate full list percentiles.


                                                         29
score by 0.024, on a per-class basis. This translates into lower university admissions rates ­
1.5 percentage points per-class ­ and enrolling at less selective institutions.


6.2      Placebo Tests

In Section 4 we discussed the primary threats to identification and offered analysis in support
of our assumptions. To establish further that the results are causal, we implement additional
placebo tests.
      We start by exploiting the timing of assignments. Our district-level estimates include dis-
trict fixed effects, which would control for time-invariant district differences, such as differ-
ential teacher attrition rates, that might relate to teacher assignment. Including district fixed
effects would be insufficient, however, if districts have particularly high attrition ­ or face some
other time-varying shock ­ in some years, for reasons that cause test score changes even if new
assignments had an average amount of time out of formal employment. If such shocks are
serially correlated, and correlate with our IV, then we would expect that the following year's
assignments' time without formal employment would correlate with this year's test score out-
comes. This would occur even though future assignees cannot have a direct effect as they only
show up in the district a year later. We therefore extend our IV specification to include the av-
erage time out of the labor force of the following year's assigned teachers to that district.33 We
present the test in Table 7. The first column runs our baseline regression, on the sample of dis-
tricts for which we have assignments the following year. The sample reduction does not change
our main point estimate. The second column includes the years out of formal employment of
the following year's assigned deputy teachers. We see no statistical relationship between future
assignees' human capital and current test scores. The coefficient on current assignees' years
waiting becomes less precise, but we can reject equality between the two coefficients.
      Our second placebo test examines the role of teachers assigned through the exact same
process but who teach subjects that do not appear on the twelfth grade exams. These subjects
include music, foreign languages, physical education, and household economics. If there is
some district- or school-level confounder that correlates with our instrument, it likely corre-
lates with waitlist percentiles among all assigned teachers, not just those in tested subjects. The
 33
      We add another instrument ­ the mean waitlist rank for the following year's assigned teachers.


                                                       30
test also evaluates whether there are spillovers, either across teachers in the same district or
from students reallocating effort across classes based on teachers' characteristics. We present
the relationship between years without formal employment, instrumented with waitlist per-
centiles, and student test scores for teachers in untested subjects in the last two columns of
Table 7. We fail to reject no statistical relationship, and we reject that the coefficient is the
same as our tested subjects' coefficient (from Table 6). Thus, the effects we find appear spe-
cific to the assignments of teachers in tested subjects. Any confounders would have to apply
specifically to these subjects.
       In Online Appendix C we provide robustness checks for our district-level estimates. We ex-
plore robustness to the sample, the functional form of formal experience, controls, the test score
units, our measure of university selectivity, the aggregation matrix, and regression weighting.


6.3       Interpretation

As in the individual model, we estimate large effects of being out of formal employment. The
effect of one year waiting for a formal position translates to 34% of the cross-sectional stan-
dard deviation in teacher value-added. Such large effects could hint at changes to effort. Effort
certainly matters for how much student output a teacher helps create; but because the edu-
cational system has no evaluation or rewards based on a teacher's performance, we speculate
that experience returns are unlikely explained by changes in effort due to incentives.34 Perhaps
a more direct effort channel comes from how teachers spend their time waiting. If teachers
develop non-teaching human capital during part-time work ­ e.g., they open a successful tutor-
ing business ­ then their teaching output may be lower once they are assigned, but this could
reflect split effort between their formal work and continuing the activities they started while
waiting. From the perspective of the formal educational system, the loss in teaching output
remains high. But in linking the change to human capital, we might overstate the losses to the
teacher's complete set of skills.
       While we cannot rule out such a possibility, we note that many deputy assignments involve
relocating to a new part of the country. Thus, the teachers' activities, to the extent they depend
on geography, are likely to change. Second, we collected survey data on teachers' activities
  34
       Changes in motivation unrelated to incentives could also constitute part of a teacher's human capital.


                                                         31
while working as a deputy and offer a summary in Table A.3. Over a quarter of teachers
engage in part-time work while serving as a deputy teacher, and the most common type of
work is offering private lessons.35 A very similar percentage of teachers reports engaging in
part-time work, and specifically private lessons, that they continued from their waiting period.
That the propensity to offer private lessons is similar for teachers continuing and not continuing
activities from their waiting period makes us skeptical that the waiting time itself is causing
teachers to change how they spend their teaching time. We further find no correlation between
the years a teacher waited until her first assignment and whether she worked part-time once
assigned (Table A.4). We thus argue our estimates of large output loss likely reflect changes in
human capital.
      The output loss from the deputy assignment system is distributed unevenly. Districts differ
in their reliance on deputy teachers, and the percentage of deputy teachers correlates nega-
tively with district mean test scores. Thus, we conduct a back-of-the-envelope exercise where
we estimate the distributional changes from an assignment system that leads to one fewer year
of waiting on average as well as a system that eliminates all waiting. Specifically, we take the
absolute value of our point estimate from column 3 of Table 6, multiply it by each district's 2010
share of teachers that are deputies, and multiply by either one year or the district's assignees'
mean years waiting, depending on the counterfactual.
      The actual cross-district standard deviation of test scores is 0.340. We estimate that elimi-
nating one year of waiting would lower the standard deviation to 0.328, a slight compression
of cross-district differences. In the top panel of Figure A.5, we plot how this system change
would reorder districts in terms of their mean scores. The x-axis shows districts' actual rank
based on mean test scores, with a higher rank better, while the y-axis shows the rank we predict
from eliminating one year of waiting. Most districts remain in the same part of the distribu-
tion they started, though a non-trivial share of districts are higher up the actual test score
distribution because they rely less on deputies. We then implement a more extreme counter-
factual, where we eliminate all waiting in the system. Because districts differ in both their
reliance on deputies and their assignees' time without formal employment, districts' test score
ranks change considerably under the counterfactual.36 In the bottom panel of Figure A.5, we
 35
      This is not specific to deputy teachers. Permanent teachers regularly offer private lessons on the side.
 36
      This latter source of variation ­ the characteristics of a district's deputies ­ varies mostly over time within


                                                         32
see that the elimination of waiting would dramatically reorder districts in terms of mean test
scores. The output effects of time without formal employment thus potentially explains much
of the cross-district variation in test scores.



7     Mechanisms

Our estimates capture the effect of a year without formal employment on worker output. This is
the policy-relevant estimate for policies that shift (formal) employment. But as the production
model in Section 4 highlighted, this effect could be driven by high levels of depreciation or by
missing out on large returns to experience, and the specific mechanism matters for some poli-
cies. For example, policies that provide unemployed workers with a structured environment
that reviews material learned in formal education might be particularly desirable if deprecia-
tion is the dominant mechanism.
    To demonstrate how we will separate the impact of forgone experience from depreciation,
we return to the motivating example given at the beginning of section 4. We have previously
described comparing the two teachers in the same academic year. Consider instead a com-
parison that controls for experience levels ­ specifically, suppose we compare teacher 1 in her
first year of experience (2004-05) with teacher 2 in her first year of experience (2005-06). We
implement this comparison by altering the risk set definition. Previously, a teacher's risk set
(m) consisted of the teachers in the same subject whose degrees were conferred in the same
year-month. We then interacted m with time to generate µmt fixed effects for the empirical
specification. We now drop the within-year comparison and add a further condition to the risk
set ­ teachers must have the same number of years of prior experience. Denote this new risk
set as m = m ( j , t ).37
    We then estimate:
                                          yi t =  c U j t + µc
                                                             m
                                                               + c
                                                                 it
                                                                                                         (22)

                                           U j t = c z j + m
                                                           c
                                                             + cj t                                      (23)

district such that much "disadvantage" is across cohorts in the same district.
   37
      We are now comparing teachers who graduated at the same time across different school years. Thus, the new
risk set takes both j and t as arguments.




                                                     33
where we index parameters with superscript c to indicate these are conditional on experience.
We again do the within-transformation, as above, but with the different risk set definition.
Relating Equation 22 to the production model (Equation 6),


                                               c =  ln(1 - )                                              (24)


                                   µc                           ¯ )
                                      =  ln(1 +  - ) E j t + ln(H                                         (25)
                                    m                             j0


                                     c                     ¯ ) +
                                        =  ln(H j 0 ) - ln(H                                              (26)
                                     it                      j0          it


                     ¯ ) is taken over teachers in risk set m .
where the average ln(H j0

       We present the results of the student-level model in the first two columns of Table 8. Our
estimates of the effect of years waiting, conditional on experience, are large but noisy. For both
test score functional forms, we estimate effects considerably larger than our baseline estimates,
but the standard errors are large enough that we fail to reject no effect. Our district-level model
generates considerably more precise estimates, as shown in the last two columns. We estimate
a per-class drop in output, conditional on experience, of 0.044, or 1.41 percentiles. Thus,
even controlling for experience levels, we still find that time out of formal employment matters.
       To translate these district-level estimates to statements about experience returns or depre-
ciation rates, we rely on our production model's relationship to the empirical model (Equations
10 and 24). Solving for  and  as functions of the empirical parameters, we have:


                                             = 1 - exp(-1  c )                                            (27)


                                   = exp(-1 ( c -  )) - exp(-1  c )                                       (28)

If we normalize  = 1 such that log human capital is expressed in per-class test score units,
we estimate that  = 0.043 and  = 0.068.38 The net gain from a year of experience ­ the
depreciation from a year passing plus the experience return associated with working ­ is 2.5%
of initial human capital. Thus, experience returns are just enough to counteract fairly large
human capital depreciation rates, and not working leads to large losses in human capital. Of
   Our individual model estimates of  c are highly imprecise. But if we use our individual model point estimates
  38

of  and  c , we estimate that  = 0.276 and  = 0.064.


                                                      34
course,  and  remain composite parameters. In particular,  includes any constant age
effects. But provided the age effect is weakly positive for early-career teachers, our estimate
of  would be a lower bound on the true human capital depreciation rate.



8    Concluding Remarks

This paper demonstrates that workers become less productive if they accrue time without for-
mal employment. We show that teachers who are quasi-randomly assigned additional years
without formal employment are less productive than teachers with less time without formal
employment. The effects are large, as an additional year without formal employment leads to a
7 - 9% of a student standard deviation reduction in student test scores. We estimate that these
effects are driven by large skill depreciation rates and that the skills gained during employment
just compensate for depreciation, while periods of not working lead to large reductions in hu-
man capital. Our paper identifies a specific channel that generates structural unemployment
duration dependence, which has been widely found in the literature.
    These large estimates describe persistent costs of unemployment and highlight a benefit of
policies that promote employment or labor force attachment. In the absence of such policies,
activities that mimic the work environment and provide structure may help non-employed
workers maintain their skills. These results are particularly important at the time of writing,
given that a large portion of the workforce is furloughed or working remotely due to the COVID-
19 pandemic. Our estimates suggest that the fact that many workers are not working may have
long term effects on productivity, which warrants further study.
    While our work demonstrates that human capital depreciates, there remain a number of
important venues for further research. Our analysis has little to say about the exact type of
skills that are depreciating. We also caution that the results focus on a particular profession
­ teachers ­ in a small European country. Human capital depreciation rates might be larger
or smaller in other professions or contexts, particularly in settings that require more or less
training and skill, or where workers are more readily substitutable. We thus encourage more
research that collects skill measurements and assesses how these skills vary with employment
status in different settings.


                                               35
References
Altonji, Joseph G and Nicolas Williams, "The Effects of Labor Market Experience, Job Se-
  niority, and Job Mobility on Wage Growth," Technical Report, National Bureau of Economic
  Research 1992.
Alvarez, Fernando E, Katarína Borovi      cková, and Robert Shimer, "Decomposing Duration
  Dependence in a Stopping Time Model," Technical Report, National Bureau of Economic
  Research 2016.
Angrist, Joshua D, "Lifetime Earnings and the Vietnam Era Draft Lottery: Evidence from Social
  Security Administrative Records," The American Economic Review, 1990, pp. 313­336.
Autor, David H, Nicole Maestas, Kathleen J Mullen, and Alexander Strand, "Does Delay
  Cause Decay? The Effect of Administrative Decision Time on the Labor Force Participation
  and Earnings of Disability Applicants," Technical Report, National Bureau of Economic Re-
  search 2015.
Baily, Martin, "Some Aspects of Optimal Unemployment Insurance," Journal of Public Eco-
  nomics, 1978, 10 (3), 379­402.
Becker, Gary, "Investment in Human Capital: A Theoretical Analysis," Journal of Political Econ-
  omy, 1962, 70 (5), 9­49.
  , "Human Capital: A Theoretical and Empirical Analysis," Columbia University Press, 1964.
Ben-Porath, Yoram, "The Production of Human Capital and the Life Cycle of Earnings," Journal
  of Political Economy, 1967, 75 (4, Part 1), 352­365.
Benhenda, Asma, "Absence, Substitutability and Productivity: Evidence from Teachers," 2017.
Bertrand, Marianne and Antoinette Schoar, "Managing with Style: The Effect of Managers
  on Firm Policies," Quarterly Journal of Economics, 2003, 118 (4), 1169­1209.
Blinder, Alan S and Yoram Weiss, "Human Capital and Labor Supply: A Synthesis," Journal
  of Political Economy, 1976, 84 (3), 449­472.
Blundell, Richard, Monica Costa Dias, Costas Meghir, and Jonathan Shaw, "Female Labor
  Supply, Human Capital and Welfare Reform," Econometrica, 2016, 84 (5), 1705­1753.
Card, David, Raj Chetty, and Andrea Weber, "Cash-on-Hand and Competing Models of In-
  tertemporal Behavior: New Evidence from the Labor Market," The Quarterly journal of eco-
  nomics, 2007, 122 (4), 1511­1560.
Centeno, Mário and Álvaro A Novo, "Excess Worker Turnover and Fixed-Term Contracts:
  Causal Evidence in a Two-Tier System," Labour Economics, 2012, 19 (3), 320­328.
Chetty, Raj, "A General Formula for the Optimal Level of Social Insurance," Journal of Public
  Economics, 2006, 90 (10), 2351­2356.
  , John Friedman, and Jonah Rockoff, "Measuring the Impact of Teachers I: Evaluating Bias
  in Teacher Value-Added Estimates," American Economic Review, 2014, 104 (9), 2633­79.
Edin, Per-Anders and Magnus Gustavsson, "Time out of Work and Skill Depreciation," ILR
  Review, 2008, 61 (2), 163­180.
Farber, Henry S, Dan Silverman, and Till von Wachter, "Factors Determining Callbacks to
  Job Applications by the Unemployed: An Audit Study," RSF: The Russell Sage Foundation
  Journal of the Social Sciences, 2017, 3 (3), 168­201.
Frisch, Ragnar and Frederick V Waugh, "Partial Time Regressions as Compared with Individ-


                                              36
  ual Trends," Econometrica: Journal of the Econometric Society, 1933, pp. 387­401.
Giles, David EA, "Instrumental Variables Regressions involving Seasonal Data," Economics Let-
  ters, 1984, 14 (4), 339­343.
Giroud, Xavier and Holger Mueller, "Firm Leverage, Consumer Demand and Employment
  Losses During the Great Recession," Quarterly Journal of Economics, 2017, 132 (1), 271­
  236.
Hanushek, Eric A and Steven G Rivkin, "Generalizations about using value-added measures
  of teacher quality," American Economic Review, 2010, 100 (2), 267­71.
Herrmann, Mariesa A and Jonah E Rockoff, "Worker Absence and Productivity: Evidence
  from Teaching," Journal of Labor Economics, 2012, 30 (4), 749­782.
Hoffmann, Florian and Philip Oreopoulos, "Professor Qualities and Student Achievement,"
  The Review of Economics and Statistics, 2009, 91 (1), 83­92.
Imai, Susumu and Michael P Keane, "Intertemporal Labor Supply and Human Capital Accu-
  mulation," International Economic Review, 2004, 45 (2), 601­641.
Jackson, C Kirabo, "Match Quality, Worker Productivity, and Worker Mobility: Direct Evidence
  from Teachers," Review of Economics and Statistics, 2013, 95 (4), 1096­1116.
   and Elias Bruegmann, "Teaching Students and Teaching Each Other: The Importance of
  Peer Learning for Teachers," American Economic Journal: Applied Economics, 2009, 1 (4),
  85­108.
Jackson, Kirabo, Jonah Rockoff, and Doug Staiger, "Teacher Effects and Teacher-Related
  Policies," Annual Review of Economics, 2014, 6.
Jacobson, Louis S, Robert J LaLonde, and Daniel G Sullivan, "Earnings Losses of Displaced
  Workers," The American Economic Review, 1993, pp. 685­709.
Jarosch, Gregor, "Searching for Job Security and the Consequences of Job Loss," Manuscript,
  Stanford University, 2015.
Keane, Michael and Kenneth Wolpin, "The Effect of Parental Transfers and Borrowing Con-
  straints on Educational Attainment," International Economic Review, 2001, 42 (4).
Kehoe, Patrick J, Virgiliu Midrigan, and Elena Pastorino, "Debt Constraints and Employ-
  ment," Journal of Political Economy, 2019, 127 (4), 1926­1991.
Kroft, Kory, Fabian Lange, and Matthew Notowidigdo, "Duration Dependence and Labor
  Market Conditions: Evidence from a Field Experiment," Quarterly Journal of Economics,
  2013, 128 (3), 1123­1167.
Lavy, Victor, "Evaluating the Effect of Teachers Group Performance Incentives on Pupil
  Achievement," Journal of Political Economy, 2002, 110 (6), 1286­1317.
  , "Performance Pay and Teachers' Effort, Productivity, and Grading Ethics," American Eco-
  nomic Review, 2009, 99 (5), 1979­2011.
   and Rigissa Megalokonomou, "Long Term Effects of Teachers: Evidence from a Teacher
  Value Added Approach," 2020.
Ljungqvist, Lars and Thomas J Sargent, "The European Unemployment Dilemma," Journal
  of Political Economy, 1998, 106 (3), 514­550.
Lovell, Michael C, "Seasonal Adjustment of Economic Time Series and Multiple Regression
  Analysis," Journal of the American Statistical Association, 1963, 58 (304), 993­1010.
Manuelli, Rodolfo E and Ananth Seshadri, "Human Capital and the Wealth of Nations,"

                                             37
  American Economic Review, 2014, 104 (9), 2736­62.
Marx, Matt, Deborah Strumsky, and Lee Fleming, "Mobility, Skills, and the Michigan Non-
  Compete Experiment," Management Science, 2009, 55 (6), 875­889.
Neal, Derek, "Industry-Specific Human Capital: Evidence from Displaced Workers," Journal
  of Labor Economics, 1995, 13 (4), 653­677.
OECD, "Education for a Bright Future in Greece," Reviews of National Policies for Education,
  OECD. Publishing, Paris., 2018.
Opper, Isaac M, "Does Helping John Help Sue? Evidence of Spillovers in Education," American
  Economic Review, 2019, 109 (3), 1080­1115.
Oreopoulos, Philip, Till Von Wachter, and Andrew Heisz, "The Short-and Long-Term Career
  Effects of Graduating in a Recession," American Economic Journal: Applied Economics, 2012,
  4 (1), 1­29.
Papay, John P and Matthew A Kraft, "Productivity Returns to Experience in the Teacher Labor
  Market: Methodological Challenges and New Evidence on Long-Term Career Improvement,"
  Journal of Public Economics, 2015, 130, 105­119.
Rice, Jennifer King, "Learning from Experience? Evidence on the Impact and Distribution of
  Teacher Experience and the Implications for Teacher Policy," Education Finance and Policy,
  2013, 8 (3), 332­348.
Rockoff, Jonah, "The Impact of Individual Teachers on Student Achievement: Evidence from
  Panel Data," American Economic Review, 2004, 94 (2), 247­252.
Rockoff, Jonah E, Douglas O Staiger, Thomas J Kane, and Eric S Taylor, "Information
  and Employee Evaluation: Evidence from a Randomized Intervention in Public Schools,"
  American Economic Review, 2012, 102 (7), 3184­3213.
Rosen, Sherwin, "A Theory of Life Earnings," Journal of Political Economy, 1976, 84 (4, Part
  2), S45­S67.
Schmieder, Johannes F, Till von Wachter, and Stefan Bender, "The Effect of Unemployment
  Benefits and Nonemployment Durations on Wages," American Economic Review, 2016, 106
  (3), 739­77.
Shimer, Robert and Ivan Werning, "On the Optimal Timing of Benefits with Heterogeneous
  Workers and Human Capital Depreciation," Technical Report, National Bureau of Economic
  Research 2006.
Stylianidou, Fani, George Bagakis, and Dimitris Stamovlasis, "Attracting, Developing and
  Retaining Effective Teachers, Country Background Report for Greece," Report, OECD Activity,
  2004.
Taylor, Eric S and John H Tyler, "The Effect of Evaluation on Teacher Performance," American
  Economic Review, 2012, 102 (7), 3628­51.
Tsakloglou, Panos and Ioannis Cholezas, "Education and Inequality in Greece," Discussion
  Paper No. 1582, 2005.
Wiswall, Matthew, "The Dynamics of Teacher Quality," Journal of Public Economics, 2013, 100,
  61­78.
Zivin, Joshua Graff and Matthew Neidell, "The Impact of Pollution on Worker Productivity,"
  American Economic Review, 2012, 102 (7), 3652­3673.



                                             38
Figure 1: Degree Conferral Months and Days and Years without Formal Employment


               .25

                                                                                                                  .1

                .2




               .15
   Density




                                                                                                     Density
                                                                                                                 .05
                .1




               .05




                0                                                                                                 0
                         0       2         4           6               8          10   12                                  0       5    10            15          20       25   30
                                         Degree Conferral Month of the Year                                                            Degree Conferral Day of the Month



               2000                                                                                              2000




               1500                                                                                              1500
   Frequency




                                                                                                     Frequency




               1000                                                                                              1000




                500                                                                                               500




                     0                                                                                                 0
                             0       2                     4                  6             8                                  0             2               4             6         8
                                                 Total Years Waiting                                                                         Consecutive Years Waiting



Notes: The top panel of this figure shows the histograms of the degree conferral month of the year (left) and
day of the month (right). The bottom panel of this figure shows the histograms of the total years without
formal employment (left) and the consecutive years without formal employment (right). An observation is a
teacher on a waitlist between 2004 and 2011 whose degree was conferred before 2006.




                                                                                                39
Figure 2: Waitlist Rank and Years without Formal Employment ­ Deviations from Risk
Set Mean


               10                                                                  1.5




                8


                                                                                    1
                6
     Density




                                                                         Density




                4
                                                                                    .5


                2




                0                                                                   0
                    -1   -.5                           0       .5                        -4   -2                             0   2
                               Waitlist Percentile Deviation                                       Years Waiting Deviation



 Notes: The figure shows histograms of the demeaned waitlist percentile (left) and years without formal
 employment (right) where the demeaning is done by risk set-year. A risk set is a degree conferral year-
 month and subject combination. The waitlist percentile is the initial position on the fresh graduates waitlist,
 normalized to vary from 0 to 1. An observation is a teacher-year. The sample includes all assigned teachers
 between 2003 and 2011 whose degree was conferred before 2006.




                                                                    40
  Figure 3: Years without Formal Employment and Waitlist Position ­ Teacher Level



                             .5
   Years Waiting Deviation




                              0




                             -.5




                             -1
                                   -.4   -.2                0                      .2                     .4
                                               Waitlist Percentile Deviation

Notes: The binscatter figure shows the relationship, at the teacher-year level, between demeaned waitlist
percentile and demeaned years without formal employment where the demeaning is done by risk set-year.
A risk set is a degree conferral year-month and subject combination. The waitlist percentile is the initial
position on the fresh graduates waitlist, normalized to vary from 0 to 1. The sample includes all teachers on
a waitlist between 2003 and 2011 whose degree was conferred before 2006.




                                                      41
Figure 4: District-Level Waitlist Position and District-Level Years Waiting ­ Deviations
from Risk Set Mean


                                                                                                   1
              8



                                                                                                   .8

              6


                                                                                                   .6
    Density




                                                                                         Density




              4

                                                                                                   .4



              2
                                                                                                   .2




              0                                                                                    0
                  -.4    -.2              0               .2              .4   .6                       -4   -3              -2               -1              0   1
                        Waitlist Percentile Deviation -- District Level                                           Years Waiting Deviation -- District Level



 Notes: The figure shows histograms of the district-year mean (demeaned) waitlist percentile (left) and (de-
 meaned) years without formal employment (right) where the district-year mean is calculated over the as-
 signed teachers' (demeaned) variables. A risk set is a degree conferral year-month and subject combination.
 The sample includes all district-years that received temporary teachers between 2003 and 2010.




                                                                                    42
                             Table 1: Summary Statistics


                                                 Obs     Mean     Std. Dev.   Min    Max
  Waitlist Data
  Degree Mark                                 455,105    6.71       0.69        0    10
  Years Experience                            455,393    1.57       1.99        0    16
  Inexperienced (0 Years)                     455,393    0.45       0.50        0     1
  Any Private Experience                      311,247    0.00       0.05        0     1
  Any EU Experience                           314,170    0.00       0.04        0     1
  Any Permanent Experience                    314,170    0.00       0.01        0     1
  Greek & History                             456,953    0.50       0.50        0     1
  Math & Stats                                456,953    0.15       0.36        0     1
  Physics & Biology                           456,953    0.20       0.40        0     1
  Economics                                   456,953     0.07       0.26       0     1
  Computer Science                            456,953     0.07       0.26       0     1
  Degree Month-Year-Subject Cohort Size        22,952    61.96      72.93       1    566
  Assignment Data
  Greek & History                             24,906      0.46      0.50        0      1
  Math & Stats                                24,906      0.21      0.41        0      1
  Physics & Biology                           24,906      0.26      0.44        0      1
  Economics                                   24,906      0.03      0.16        0      1
  Computer Science                            24,906      0.05      0.21        0      1
  Micro School Data
  Grade 10                                    105,237    0.23       0.42        0     1
  Grade 11                                    105,237    0.25       0.43        0     1
  Grade 12                                    105,237    0.52       0.50        0     1
  (Teacher) Subjects Taught                     1,101     2.18       1.15       1      6
  (Teacher) Classes Taught                       787      2.95      1.73        1     11
  GPA                                         104,355    14.68      2.94        0    20
  Subject Exam Score                           82,904    12.03       5.57       0     20
  Admitted                                     97,745     0.64      0.48        0     1
  Admitted to Acad Univ                        62,911     0.62      0.48        0     1
  Application List Length                      76,385    25.29      22.07       1    235
  Univ Selectivity Percentile                  62,911    48.88      28.30       0    100

Notes: The table shows summary statistics from the waitlist, assignment, and micro school
data. "Degree Mark" refers to the teacher's university grade-point average, out of 10.
"Degree Month-Year-Subject Cohort Size" indicates the number of teachers who had their
degrees conferred in the same year, month, and subject. "Admitted" is an indicator for
whether the student was admitted to university, "Application List Length" is the number
of degree-institution combinations the student listed in applying to university, and "Univ
Selectivity Rank" is the selectivity percentile of the university the student attended, where
selectivity is measured by the mean entrance score of the enrolled students.




                                            43
          Table 2: University Grade Point Average and Attrition by Waitlist Position



                           Teacher GPA         Teacher GPA          Attriter       Attriter        Attriter        Attriter
 Waitlist Percentile          0.199              0.00535          -0.0547         0.00533
                              (0.0180)           (0.0331)          (0.0129)       (0.0263)
 Teacher GPA                                                                                     -0.0285          0.00677
                                                                                                 (0.00437)       (0.00493)
 Mean DV                       6.852               6.860             0.428          0.346           0.412           0.347
 N                             21160               20655             19244          16366           24029           21151
 Risk Set                       No                  Yes               No             Yes             No              Yes
Notes: The table shows the relationship between teachers' university grades (out of 10), whether they attrit from the
waitlists, and their waitlist position on their first fresh graduates list. Waitlist position is normalized by the list length
to be in percentiles from 0 to 1. "Attriter" is an indicator for whether the teacher left the waitlists before the end of the
sample and without accruing any formal experience. "Risk Set" indicates whether risk set fixed effects are included,
where a risk set is a set of teachers in a single subject who have their degrees conferred in the same month-year.
The sample consists of teachers with degrees conferred before 2006 who are in risk sets that generated at least one
assignment during the sample period.  p < .1,  p < .05,  p < .01.




                                                          44
                 Table 3: Assigned District Characteristics by Waitlist Position



                          Cohort Size       UE Rate      Cohort Size      UE Rate      Cohort Size        UE Rate
 Waitlist Percentile          0.645          -0.421         -0.639          -0.324         -1.063        0.000339
                             (5.233)        (0.573)        (0.912)         (0.281)        (0.678)        (0.00217)
 Mean DV                      50.14          9.738           50.14          9.738          50.14            9.738
 N                            1653           1653            1653           1653           1653             1653
 Year FE                       Yes            Yes             Yes            Yes            No               No
 District FE                   No             No              Yes            Yes            Yes              Yes
 Reg-Yr FE                     No             No              No             No             Yes              Yes
Notes: The table shows the relationship between teachers' waitlist position, on the fresh graduates list, and the
characteristics of the district the teacher is assigned to. Waitlist position is normalized by the list length to be in
percentiles. "Cohort Size" is the average number of 12th grade students at a school in the district, while "UE Rate" is
the local unemployment rate. "Reg-Yr FE" are region-year fixed effects where regions typically include several districts.
Teachers may appear in the regressions multiple times if they have received multiple assignments during the sample
period. Standard errors are clustered by teacher.  p < .1,  p < .05,  p < .01.




                                                        45
                            Table 4: Effect of Years without Formal Employment on Students' Subject Exam Scores



                               OLS             RF                FS               IV               IV                 IV                    IV                 IV

                           Score ()        Score ()       Years Waiting       Score ()       Score (Perc)      First Sem ()        Second Sem ()          Exam ()
      Years Waiting          -0.0481                                          -0.0853          -2.467            -0.0625               -0.0712            -0.0848
                            (0.0339)                                           (0.0164)         (0.398)           (0.0204)              (0.0223)           (0.0165)
      Deputy                 -0.138         -0.134             -0.397          -0.168           -5.184              -0.118               -0.159             -0.156
                            (0.0773)       (0.0908)           (0.442)         (0.0992)          (2.730)            (0.100)              (0.121)            (0.0899)
      Prior Year GPA        0.737          0.737            0.000525           0.737            21.89             0.598                 0.645              0.703
46




                           (0.00878)      (0.00878)         (0.00175)         (0.00877)         (0.223)           (0.0123)              (0.0138)          (0.00838)
      Waitlist Perc                        -4.050            47.49
                                            (0.791)          (5.958)
      Mean DV                0.0355         0.0355           -0.0160           0.0355            51.01              0.110                0.0746             -0.0253
      Clusters                 383            383              383               383              383                383                   383                381
      N                      54851          54851             54851            54851             54851              54841                54804               54549
      Risk Set                 Yes            Yes              Yes               Yes              Yes                Yes                   Yes                Yes
     Notes: The table includes OLS, reduced form ("RF"), first stage ("FS"), and IV regressions. An observation is a student-subject-year. "Years Waiting" is the deputy
     teacher's years without formal employment and "Waitlist Perc" is the imputed waitlist position, normalized by the risk set size to be in percentiles. Both variables
     are demeaned by risk set, where a risk set is the cohort of teachers in the same subject with degrees conferred in the same month-year. "Score" is the student's
     average subject-specific test score during the year. "First Sem" and "Second Sem" are the semester-specific test scores, and "Exam" is the end-of-year exam. This
     exam is a national exam for 11th graders before 2006 and 12th graders in all years; otherwise it is the school exam. Test results are expressed in student standard
     deviation units () or percentiles. Standard errors are clustered by teacher.  p < .1,  p < .05,  p < .01.
Table 5: Effect of Years without Formal Employment on Students' Post-Secondary Out-
comes



                             IV                IV              IV              IV                     IV

                      Ln Univ Score       List Length       Admitted      Acad Univ      Selectivity (Admission)
 Years Waiting          -0.0214             2.081         -0.0222          -0.0140                -2.468
                        (0.00577)           (0.665)       (0.00709)       (0.00794)                (0.665)
 Deputy                   -0.0286            3.373          -0.00530        0.0228                  -3.327
                         (0.0228)           (2.168)         (0.0293)       (0.0314)                (2.544)
 Prior Year GPA          0.243             -3.580          0.293           0.307                  24.51
                        (0.00385)           (0.185)       (0.00404)       (0.00422)               (0.247)
 Mean DV                  9.532              25.25           0.670          0.625                  49.33
 Clusters                  363                363             383            363                    363
 N                        49175              59133           73352          49175                  49175
 Risk Set                  Yes                Yes             Yes            Yes                    Yes
Notes: The table includes instrumental variable estimates with (demeaned) imputed waitlist position as the instru-
ment. An observation is a student-subject-year where the outcomes do not vary by subject but the teachers do. "Years
Waiting" is the deputy teacher's years without formal employment, normalized by the risk set size to be in percentiles.
"Years Waiting" and the instrument are demeaned by risk set, where a risk set is the cohort of teachers in the same
subject with degrees conferred in the same month-year. "Ln Univ Score" is the natural log of the student's university
admissions score. "List Length" is the number of institution-programs the student lists on her ordered list for admis-
sions. "Admitted" and "Acad Univ" are whether the student is admitted to any university and an academic university,
respectively. The non-academic university option is a technical university. For "Selectivity (Admission)" we calcu-
late the mean university/admissions score for the class of students admitted to each university-program and order
university-programs from highest to lowest. The selectivity measure is the percentile of this ordering where 100 is the
program whose admits have the highest mean score. Standard errors are clustered by teacher.  p < .1,  p < .05, 
p < .01.




                                                       47
                          Table 6: Effect of Years without Formal Employment on Districts' Panhellenic Exam Scores



                             OLS                FS                IV              IV                  IV                IV              IV             IV             IV

                          Score ()       Years Waiting       Score ()       Score (Perc)      Ln Univ Score        List Length      Admitted      Acad Univ        Selec.
      Years Waiting        0.0911                            -0.342           -8.905              -0.120              1.040         -0.0740         -0.0728       -5.645
                          (0.0971)                            (0.121)          (3.008)            (0.0481)           (2.092)        (0.0380)       (0.0468)       (2.576)
      Ln Class Size         0.242            -0.0538          0.239            8.012              0.198               3.246          0.0225        0.0912         9.139
                           (0.164)           (0.232)         (0.0986)          (2.036)            (0.0535)           (1.675)        (0.0357)       (0.0393)       (2.262)
      Waitlist Perc                          1.785
                                             (0.834)
48




      Per Class            0.0182                             -0.0684          -1.7810            -0.0240             0.208          -0.0148        -0.0146        -1.129
      Mean DV              -0.0440           -0.155           -0.0440           49.07              9.518              25.24           0.818          0.610          48.77
      N                      390              390               390              390                390                390             390            390            390
      District FE            Yes               Yes              Yes              Yes                Yes                Yes             Yes            Yes            Yes
      Reg-Yr FE              Yes               Yes              Yes              Yes                Yes                Yes             Yes            Yes            Yes
      Risk Set               Yes               Yes              Yes              Yes                Yes                Yes             Yes            Yes            Yes
     Notes: The table includes OLS, first stage ("FS"), and IV regressions. An observation is a district-year. "Years Waiting" is the deputy teacher's years without formal
     employment and "Waitlist Perc" is the waitlist position, normalized by the list length to be in percentiles. Both variables are demeaned by risk set, where a risk
     set is the cohort of teachers in the same subject with degrees conferred in the same month-year. Test score outcomes are measures of student performance on
     the national twelfth grade exams, in student standard deviation units () or percentiles ("Perc"). "Ln Univ Score" is the natural log of the student's university
     admissions score. "List Length" is the number of institution-programs the student lists on her ordered list for admissions. "Admitted" and "Acad Univ" are whether
     the student is admitted to any university and an academic university, respectively. The non-academic university option is a technical university. For "Selec."
     we calculate the mean university/admissions score for the class of students admitted to each university-program and order university-programs from highest to
     lowest. The selectivity measure is the percentile of this ordering where 100 is the program whose admits have the highest mean score. "Per Class" indicates
     the per-class effect, which is the main coefficient divided by 5 for the 5 classes twelfth graders take in tested subjects. "Reg-Yr FE" are region-year fixed effects.
     Standard errors are heteroskedasticity-robust.  p < .1,  p < .05,  p < .01.
  Table 7: Placebo Tests ­ Future Assignments and Untested Subjects



                              Future         Future       Nontested       Nontested

                            Score ()       Score ()       Score ()       Score (Perc)
   Years Waiting t          -0.337           -0.211
                            (0.0874)        (0.214)
   Ln Class Size              0.144          0.268        0.0861           2.162
                             (0.218)        (0.320)       (0.0191)         (0.501)
   Years Waiting t+1                        0.0962
                                            (0.132)
   Years Waiting                                           -0.0158           0.555
                                                          (0.0861)          (2.354)
   Per Class t               -0.0675        -0.0422
   Per Class t+1                             0.0192
   Per Class                                               -0.0025          0.0880
   Mean DV                    -0.102        -0.102         -0.0173           49.65
   Test p-val                               0.0031
   N                           133           133             281              281
   District FE                 Yes            Yes            Yes              Yes
   Reg-Yr FE                   Yes            Yes            Yes              Yes
   Risk Set                    Yes            Yes            Yes              Yes
Notes: The table includes IV regressions that test for placebo effects. The "Future" columns
test whether future assignments affect current scores. The sample is teachers in tested
subjects and district-years with assignments the following year. The "Nontested" columns
test whether teachers in nontested subjects affect scores in tested subjects. The sample in
the last two columns is all teachers in subjects that are not included on the twelfth grade
exams. An observation is a district-year and the outcome is the mean score on the national
twelfth grade exams (in student standard deviation units or percentiles). `Years Waiting"
is the deputy teacher's years without formal employment and the instrument is the waitlist
position, in percentiles, of the deputy teachers when they were on the fresh graduates list.
Both variables are demeaned by risk set, where a risk set is the cohort of teachers in the
same subject with degrees conferred in the same month-year. "Per Class" rows indicate
the per-class effect, which is the main coefficient divided by 5 for tested subjects and 6.3
for nontested subjects. "Test p-val" tests whether the coefficients on "Years Waiting t" and
"Years Waiting t+1" are equal. "Reg-Yr FE" are region-year fixed effects. p < .1,  p < .05,

    p < .01.




                                            49
Table 8: Effect of Years without Formal Employment on Test Scores ­ Controlling for
Experience



                                   Individual        Individual         District         District

                                    Score ()       Score (Perc)       Score ()       Score (Perc)
              Years Waiting           -0.323           -10.33          -0.218           -7.037
                                     (0.553)          (17.72)          (0.1000)          (2.565)
              Deputy                 0.0175            0.551
                                     (0.207)          (6.049)
              Prior Year GPA        0.737             21.90
                                   (0.00878)          (0.224)
              Ln Class Size                                             0.151           5.838
                                                                       (0.0835)         (1.611)
              Per Class                                                -0.0436          -1.4074
              Mean DV                0.0355            51.01           -0.0440           49.07
              Clusters                 383              383
              N                      54851             54851             390              390
              District FE                                                Yes              Yes
              Reg-Yr FE                                                  Yes              Yes
              Risk Set               Incl Exp         Incl Exp         Incl Exp         Incl Exp
 Notes: This table shows IV regressions of test score outcomes on years waiting without formal employment,
 while controlling for experience. "Years Waiting" is the deputy teacher's years without formal employment
 and the instrument is the waitlist position. Both variables are demeaned by risk set, where a risk set is the
 cohort of teachers in the same subject with degrees conferred in the same month-year and with the same
 prior years of experience. In the "Individual" columns, the sample is the set of students and teachers in our
 micro data set, with a student-subject-year as an observation. In the "District" columns, the sample is all
 school districts in Greece, with a district-year as an observation. Outcomes are subject-specific test scores
 (expressed in student standard deviation units or percentiles) in the "Individual" model and Panhellenic test
 scores in the "District" model. In the "Individual" model, standard errors are clustered by teacher. "Per Class"
 indicates the per-class effect in the district model, which is the main coefficient divided by 5 for the 5 classes
 twelfth graders take in tested subjects. "Reg-Yr FE" are region-year fixed effects. District-model standard
 errors are heteroskedasticity-robust.  p < .1,  p < .05,  p < .01.




                                                        50
                     ONLINE APPENDIX: NOT FOR PUBLICATION


A     Data Appendix

A.1     Waitlists

A.1.1   Waitlist Types

The first component of the dataset is teachers' waitlists from Greece. These waitlists rank
teachers who are waiting for a school assignment as a deputy teacher (thesi anapliroti). They
can be found on the website of the Ministry of Education under e-aitisi.sch.gr, for data starting
in the 2003-04 school year. On the Ministry of Education website, there is a list of several
waitlists. Two types of waitlists are relevant for our empirical analysis. These are:


    1. Main lists for experienced high school deputy teachers

    2. Main lists for inexperienced high school deputy teachers


    The Greek translation for each one of those is "Pinakes katataxis anapliroton deuterovath-
mias ekpaideusis" and "Pinakes katataxis anapliroton deuterovathmias ekpaideusis midenikis
proipiresias" respectively.


A.1.2   Waitlist Content

There are up to fifty subject waitlists. In the main analysis, we restrict attention to five subject
categorizations that are tested on the national exams (Panhellenic). These are: PE02, PE03,
PE04, PE09, and PE19. Subject PE02 is for Greek/History/Ancient Greek teachers (filologoi),
subject PE03 is for mathematicians (including Algebra, Statistics, and Geometry), PE04 is for
science teachers, subject PE09 is for Economics teachers, and subject PE19 is for Computer
Science teachers. For PE04, we include four subcategorizations: PE04.01 (physics), PE04.02
(chemistry), PE04.04 (biology), and PE04.05 (geology). Usually, there is no PE04.03 list.
    In each waitlist, we have a list of teachers with information on the teacher's identity (first
name, last name, father's name, mother's name, date of birth), the teacher's degree (degree


                                                51
mark, degree date, subject of specialization), whether the teacher has received any other spe-
cialized training (Braille, foreign languages, etc.), and a teachers' past experiences, such as
whether obligatory military conscription was completed, that affect eligibility. The waitlists
also contain information on moria, which are points that teachers collect in order to obtain
future assignments. Moria can be collected through various ways: academic qualifications,
professional experience, social criteria, and other criteria like knowing foreign languages. We
also observe moria experience, which refers to the number of moria credits accrued through
professional teaching at a moria-eligible school after initial assignments.39


A.1.3      Ranking Teachers

Waitlist observations are ranked by sum of moria on the waitlists. This variable perfectly pre-
dicts rank on the waitlist. The only waitlist for which the sum of collected moria does not
predict a teacher's position on the list is the main waitlist for inexperienced teachers. This is
the waitlist for fresh graduates, who are ranked based on the following lexicographic ordering:
(oldest) degree year, (oldest) degree month, (oldest) degree day, (highest) degree mark. Due
to bureaucratic hurdles and subject-specific exam days, the degree date offers enough variation
that tie-breaking with the degree mark is relatively uncommon.
       Regulations for teacher assignments are governed by law 1268/1982 (25, par.12) of the
Constitution, according to which: "A student is automatically announced a degree holder
(thereby ceases to have a student status) following the end of the exam period during which
they fulfilled the requirements of their degree completion. According to Law 1268/1982
(clause 25, paragraph 12) and the decision of the Council of State (Decision 366/1994), as
well as the ensuing explanation on the relevant document from the Ministry of Education
(17-5-2004, 5/45340/B3), the date of degree conferral of the degree holder is the date of
announcement of the grade of the last exam by the member of teaching faculty."
  39
     By definition, this information is only available for the experienced teacher lists; inexperienced teachers have
yet to accrue experience.




                                                        52
A.1.4   Eligibility

For someone to be included in these waiting lists, the following conditions must be met: a) the
applicants should be either Greek or from North-Epirus or ethnic Greeks from Constantinople
and from the islands of Imbros and Tenedos (Law No. 3832 / 1958) or European Union citizens
(Law No. 2431/1996); b) male applicants should present a military certificate that shows
that they have served their compulsory military service or a certificate that shows that the
applicant has a military exemption; and c) expatriates from Cyprus, Egypt, Turkey and North-
Epirus should submit a birth certificate and a certificate to the Ministry certifying that they are
Greeks. There is no age restriction.


A.2     Assignments

The second component of our dataset is assignments. Assignment data include information
on teacher identity (first name, last name, father's name and, sometimes, mother's name),
the taught subject (PE02, PE03, etc.), and the teacher's assignment unit. The assignment is
typically at the district level and is given by a letter and a region, e.g., A Evrou, B Evrou, A
Artas, B Artas, etc. The prefix/letter refers to the regional office of the school authority of the
relevant region. For a minority of teachers, the assignment data includes the specific school
the teacher was assigned to.


A.3     Test Scores

We have test score data from the Ministry of Education. For the national sample, we have
the composite score built from the following subjects: Greek Language, History, Mathematics,
Physics, Biology, special modules, and Economics. The test score data is at the individual level,
which we aggregate to the school- or district-level in our district-level model.


A.4     Individual Level Data

There are 23 schools for which we have individual test scores and other outcomes for the
10th, 11th, and 12th grade. These schools maintained an electronic archive, with data at the



                                                53
student-teacher-class level, which we then hand-collected. The student-level data are available
for the students of all three grades for these 23 schools. The teacher-level data provides us with
a teacher id for each grade, class, year, school and subject combination. The years available
varies by school.




                                               54
B    Teacher Survey

We conducted a survey of current and former teachers between December, 2019 and January,
2020. The survey was conducted using Qualtrics, and the sample was drawn using advertise-
ments in Facebook groups for Greek teachers, as well as internet forums for Greek teachers.
The survey asked respondents about their perceptions and experiences with the waitlist sys-
tem and process, as well as the activities they engaged in while waiting and once assigned.
Respondents were offered a small Amazon gift card for participation, though take-up of the
gift card was very low.
    We attach the survey, plus an English translation, to this appendix. Table A.1 shows sum-
mary statistics for selected survey variables. Approximately three-quarters of teachers are
aware of their waitlist positions and understand the assignment process, but approximately
just one-third of teachers understood the assignment process when they decided to become a
teacher. Only 12% of teachers ever rejected an assignment. Figure A.6 shows the distribution
of the number of years on waitlists.
    The survey examined what teachers did while on the waitlists, and if they continued any
activities once assigned. Table A.2 shows the activities in which individuals participated while
waiting. Approximately one-half of teachers gave private lessons. Nearly 40% of teachers
worked in a non-education position while 19% worked in the education sector but in a non-
teaching position. One-third of teachers continued with studies and 16% started a family.
Many teachers reported engaging in multiple activities while waiting.
    Table A.3 explores jobs teachers engaged in while working as a deputy teacher, and whether
these activities had started when the teacher was on the waitlist. The top-row shows that
around 30% of teachers engage in part-time work, while teaching in the public system. Among
these teachers, the most common form of part-time work is offering private lessons, though
small fractions of teachers report working in other industries. The fraction of teachers contin-
uing an activity they started while waiting is quite similar. Conditional on continued activities,
private lessons is by far the most common.
    Table A.4 regresses whether a teacher participated in an activity or continued part time work
on a teacher's years waiting for her first assignment. In the left column the dependent variable



                                               55
is an indicator variable for whether the teacher participated in an extra activity, and in the right
column the dependent variable is an indicator variable for whether the teacher participated
in an extra activity, while working as a public school teacher, that had been started while
the teacher was waiting for an assignment. The results indicate that there is no statistically
significant relationship between years waiting and either outcome. The point estimates are
quite small as are the robust standard errors, so we can rule out even a small correlation
between years waiting and participating in an activity or continuing an activity once assigned.




                                                56
Default Question Block


The University of Chicago, Electronic Description and Participation Agreement in
the survey
Number of the Survey: 19-1614
Title of the Survey: Human Capital Depreciation
Researchers: Michael Dinerstein, Rigissa Megalokonomou, Constantine Yanellis

Description: We are academics at the University of Chicago and Queensland
conducting research on Greek teachers. We want to ask you some questions about your
experience, and what you did while waiting as a teacher. This will help us with our
research. The survey should only take 10 minutes, your responses are completely
anonymous.
Reward: If you finish the survey, we will offer you a $5 Amazon gift card that will be sent
to the email address that you will provide us with.



Contact and Questions: You can only take the survey once. Please answer all the
questions. If you have any question about the survey, please email us:
spyridon.kypraios@chicagobooth.edu

We really appreciate your input!


Participation Agreement

   Yes, I agree to participate in the survey
   No, I don't agree to participate in the survey



Section 1: Background Info
Note:
At the end of the multiple-choice questions exist a text in order to write anything you
want further


1.1 Did you start from the first day as a permanent or deputy teacher?

    Yes, I have started as permanent teacher from the 1st day
    No, I have started as deputy teacher from the 1st day
    I haven't started to work in a school yet

    None of the above



1.2 The position which you have is a full time, part-time or hourly paying position?

    Full time
    Part time
    Hourly paying

    None of the above



1.3 In what year did you get your teaching degree?




1.4 What is/was your teaching categorization (e.g. 70, 03, 02 etc)?




1.5 If you have started to teach in a school, in what year did you receive your first deputy
assignment?
1.6 If you ever left teaching, how many years post-degree did you?




1.7 What was the main reason you became a teacher?




Section 2: Understanding and Expectations of the System



2.1 If you were in the system with the waitlists. Did you know your waitlist position?

    Yes, I knew it
    No, I didn't know it

    None of the above



2.2 Did you understand the assignment process?

    Yes, I did
    No, I didn't

    None of the above



2.3 How long did you expect to wait for an assignment?




2.4 Were you aware of the waitlist and assignment systems when you chose to become a teacher?

    Yes, I was
    No, I wasn't

    None of the above
2.5 When you were on the waitlists, did ASEP performance affect position?

   Yes, it did
   No, it didn't

   None of the above



Section 3: Time Spent Waiting



3.1 While waiting for assignments, which of the following did you do? Check all that apply.

   Teaching in private lessons
   Occupation in another field of a none education sector
   Further studies
   Teaching in private school
   Create a family
   Occupied is non-teaching position related to education sector

   Other



3.2 What was your main motivation in choosing how to spend time waiting?

   Economic factors
   Improving skills

   Other



3.3 How did you support yourself financially? Check all that apply.

   Support by the family
   Support by spousal income
   Income from part time job
   Income from occupation in another field of a none education sector

   Other
3.4 Did you take any measures to improve your waitlist position (e.g., take an exam)?




Section 4: Attrition and Rejecting Assignments


4.1 Did you consider and/or end up leaving the system?

   Yes, I did
   No, I didn't

   None of the above



4.2 (If you left) How long did you consider leaving the system before you did?

   Before I have started to work in the school
   While you were waiting in the waitlist
   While you were working in school as a deputy teacher
   While you were working in school as a permanent teacher

   None of the above



4.3 What were the relevant considerations in making this decision? (more than one choice)

   Economic reasons
   Family reasons
   Physiological reasons
   Distance from the residency
   Uncertainty

   None of the above



4.4 Did you consider rejecting an assignment?

   Yes, I had rejected
   No, I hadn't rejected

   None of the above



4.5 What were the relevant considerations in making this decision?

   Economic reasons
   Family reasons
   Physiological reasons
   Distance from the residency
   Uncertainty

   None of the above



Section 5: Job Characteristics Once Assigned




(Answer for your first assignment)



5.1 Did you choose the district you ended up at?




5.2 Did you choose the school(s) you worked at?




5.3 Did you choose the classes(e.g, 1, 2 or A3 etc) you taught?
5.4 Did you choose the grades (e.g. ', ' or ' of Primary school or ', ' or ' of High
school) you taught?




5.5 What categorization did you teach? Was this subject on the national exam?




5.6 How many schools did you work in?




5.7 What were the main skills you developed while teaching (if any)?




5.8 While you were working in a school, simultaneously you were working somewhere else?

    Yes,
Please, define the kind of occupation

    No



5.9 Did you continue an unofficial work-- which you had started while you were waiting in the
waitlist-- when you took a permanent position in a school?

    Yes,
Please, define the kind of occupation

    No



Section 6: Assessment of skills most affected



6.1 While waiting, did you feel like you lost skills?
    Yes, I think this
    No, I don't think this

    None of the above



6.2 If so, which types of skills?




6.3 Did you take any steps to maintain skills? (e.g., attend workshops)



    Yes, I did
Please, define the kind of steps

    No, I didn't

    None of the above



Section 7: Miscellaneous and Open-ended Questions


7.1 Do you think teaching quality matters for national exam scores?




7.2 Do you consider the end of year tests important?




7.3 What are the incentives to do well as a teacher?




7.4 Anything else you want us to know about the system?
11/25/2019                                                               Qualtrics Survey Software




      / ;        
          


     ,      
   

    :

    :     

   /:      



   :        (The University of Chicago)    

    (The University of Queensland, Australia).      - /

    /.                 

                    .  

         10 ,        .




   :             mazon  $5

   ($5 Amazon gift card).      ,      ,   

            .    

         ,      .




    & :        .     

    .        ,      

   (email) : spyridon.kypraios@chicagobooth.edu




    :

             
https://chicagobooth.az1.qualtrics.com/Q/EditSection/Blocks/Ajax/GetSurveyPrintPreview               1/10
11/25/2019                                                               Qualtrics Survey Software


              



    1:  




   :
               
    


   1.1             ;

         ,         1 
         ,         1 
                

            



   1.2      ,    ;

          
          
          

            



   1.3         ;




   1.4            (   70,
   03, 02 );




https://chicagobooth.az1.qualtrics.com/Q/EditSection/Blocks/Ajax/GetSurveyPrintPreview               2/10
11/25/2019                                                               Qualtrics Survey Software



   1.5      ,        /
    /;




   1.6     ,      , 
            ;




   1.7            /;




    2:       



   2.1            , 
         /       
     ;

         , 
         ,  

            



   2.2         ;

         ,   
         ,    

            




https://chicagobooth.az1.qualtrics.com/Q/EditSection/Blocks/Ajax/GetSurveyPrintPreview               3/10
11/25/2019                                                               Qualtrics Survey Software



   2.3      /  
             ;




   2.4    /         
         /;

         ,  /
         ,   /

            



   2.5     /   ,
        ( )     ;




         ,  
         ,   

            



    3:  



   3.1           /,   
    ; (      )



             
           
                 
           
                  
            ,       
https://chicagobooth.az1.qualtrics.com/Q/EditSection/Blocks/Ajax/GetSurveyPrintPreview               4/10
11/25/2019                                                               Qualtrics Survey Software


          (  ):



   3.2               ;

           
           

          (  ):



   3.3         ; (   
      )

             
              / 
               
                  

          (  ):



                  
     ( :   ) ;




    4:    



   4.1            ;

         ,  
         ,   

            



   4.2  ,     ;
https://chicagobooth.az1.qualtrics.com/Q/EditSection/Blocks/Ajax/GetSurveyPrintPreview               5/10
11/25/2019                                                               Qualtrics Survey Software


              
              
                 /
                 /

            



   4.3        ;

          
          
          
            
         

          



   4.4      /;

         ,  
         ,   

            



   4.5        ;

          
          
          
            
         

          




https://chicagobooth.az1.qualtrics.com/Q/EditSection/Blocks/Ajax/GetSurveyPrintPreview               6/10
11/25/2019                                                               Qualtrics Survey Software


    5:     /


   (         )



   5.1          ;




   5.2   / /      ;




   5.3     (1, 2  A3)     ;




   5.4     ( , ', '  ' ,  ', '  ' )  
     ;




   5.5  / ;  /      
   ;




   5.6     ;


https://chicagobooth.az1.qualtrics.com/Q/EditSection/Blocks/Ajax/GetSurveyPrintPreview               7/10
11/25/2019                                                               Qualtrics Survey Software




   5.7           ;




   5.8     ,     ;

   ,
        :

         



   5.9      --     
      --     ;

   ,
        :

         



    6 :   



   6.1     / ,      
      ;

         ,   
         ,    

            



   6.2  ,   ;
https://chicagobooth.az1.qualtrics.com/Q/EditSection/Blocks/Ajax/GetSurveyPrintPreview               8/10
11/25/2019                                                               Qualtrics Survey Software




   6.3            ;
    ,  ;

   , .
        :

         ,  

            



     7 :    



   7.1            
     ;




   7.2        ;




   7.3              
   ;




   7.4             ;


https://chicagobooth.az1.qualtrics.com/Q/EditSection/Blocks/Ajax/GetSurveyPrintPreview               9/10
C     Robustness Checks

In this appendix we provide a variety of robustness checks around our individual- and district-
level estimates of the causal effect of a year without formal employment on student outcomes.


C.1     Individual-Level Estimates

C.1.1   Controls

In Table A.5 (column 2), we present our main results using demeaned lagged GPA where the
teacher-year mean is removed. Because we do not observe students' lagged GPA for every
teacher in the country, we cannot demean by risk set, as would be consistent with our model.
But we find that demeaning by a finer level ­ the teacher-year mean ­ leaves our main point
estimate essentially unchanged.


C.1.2   Functional Forms

As discussed in Section 4, the economics of education literature sometimes argues that returns
to experience are declining at higher levels of experience. Further, test score units do not have
a standard conversion rate to teacher human capital measures. We thus offer variations on our
main specification where we include log test scores and log years without formal employment.
We present the results in Table A.9. We find strong effects regardless of the functional form.
One year waiting leads to a 4.4% drop in students' test scores (column 2), while a 10% increase
in time waiting corresponds to a 0.13 effect on students' test scores (column 3). For the log-
log specification, we estimate an elasticity of student test scores with respect to years waiting
of -0.66 (column 4).


C.1.3   Standard Errors

When we demean using risk sets, the mean has a sampling distribution. We do not account
for this in our main estimates because risk sets are large enough that sampling variation in
the mean is likely to be second order. Here we incorporate such sampling variation by boot-
strapping our estimates. First, we sample from the full sample of teachers, to calculate risk


                                               74
set means. Then we run 500 wild clustered bootstrap iterations, where we sample in the
instrumental variable analysis according to the Rademacher distribution and use the same
draw for all observations in a cluster and for first stage and second stage residuals. We
construct a bootstrapped estimate for our main estimate (corresponding to Table 4, column
4). The bootstrapped standard error is 0.025. The 95% bootstrapped confidence interval is
(-0.153, -0.051), compared to (-0.117, -0.053) in Table 4.


C.1.4   Sample

We argue that within-month variation in degree conferral is orthogonal to teacher type and
plotted the distribution in Figure 1. But the distribution is not uniform either, with a peak
on the 30th of the month. We also see a peak in within-year degree conferral in July. We
confirm that our results are not sensitive to these degree months and days by dropping teachers
with degree conferrals on the 30th of the month and then by dropping teachers with degree
conferrals in the month of July. We present the results in Table A.10.


C.1.5   Outcomes

The results are robust to different functional forms of our outcomes. In Table A.11 we show
causal effects on unstandardized test scores, log test scores, and raw university score. We
also include several variations in calculating an institution-program's selectivity. In the main
analysis, we calculated selectivity based on enrollees' mean university scores. Here we show se-
lectivity based on enrollees' mean national exams scores, which are a different weighting than
the university admissions scores. In both cases, these selectivity measures are means across
multiple years, including years in our sample. To avoid any concerns of our sample affecting
the selectivity measures, we also include selectivity measures derived from 2003 admissions
outcomes only.




                                              75
C.2      District-Level Estimates

C.2.1    Controls

We present estimates that vary our use of controls in Table A.12. In the first column, we show
estimates where we residualize all fixed effects by risk sets. The point estimate is very similar
to our main result. The second and third columns add additional (demeaned) district-level
controls. The point estimates are similar and move closer to our individual-model estimates.


C.2.2    Functional Forms

As with the individual-level analysis, we vary the functional forms and present the results in
Table A.13.


C.2.3    Sample

In Table A.14, we present the results dropping teachers with degree conferrals on the 30th of
the month and then dropping teachers with degree conferrals in the month of July.


C.2.4    Outcomes

In Table A.15, we show the causal effects on the other test or selectivity outcomes.


C.2.5    Scaling and Weighting

In the district-level model, we use an aggregation matrix, which included all deputy teachers,
regardless of whether we observe them on an inexperienced list in our sample period. For
these teachers, we consider them part of their own risk sets so that their years not working
do not identify the causal estimates. In Table A.16, we explore the sensitivity of our results to
including these additional deputy teachers. We find similar estimates that are slightly smaller in
magnitude to our main estimates. Given all deputy teachers factor into a district's teaching, the
attenuation toward zero is consistent with this specification including classical measurement
error.
   As the aggregation of an individual-level model, we estimate our district-level model weight-
ing by the number of students in each district-year. In Table A.17, we show how the results

                                               76
change with different weightings. The alternate weightings lead to somewhat more negative
point estimates.




                                           77
D        Construction of Instrument

In this appendix we provide more details on how we construct our instrument, as it varies across
our individual- and district-level specifications. Even though it reverses the paper's order, here
we start with the district-level instrument as it is more straight-forward.
       For the district-level specification, we construct our instrument, z j , as a teacher's actual
waitlist position on the first inexperienced waitlist she appears on. For example, consider a
teacher who earns her degree in 2003 and immediately enters the 2003 inexperienced waitlist.
She does not get assigned in 2003 and thus moves up the inexperienced waitlist for 2004. She
gets assigned in 2004, teaches for 10 months, and then enters the experienced waitlist for
2005, after which she waits a year and gets assigned in 2006. This teacher had different
waitlist positions over the four years that spanned two different lists. We use her 2003 waitlist
position ­ the earliest one on the inexperienced waitlist ­ as exogenous variation.
       But position is a somewhat noisy measure of assignment probability given that the lists'
churn rate varies across subjects. We thus normalize waitlist position by the length of the list
the teacher is on. Suppose our example teacher's 2003 waitlist position is 250 on a list of length
500. Then we calculate her normalized waitlist position as 0.5. The teacher's risk set includes
the teachers in the same subject whose degrees were conferred in the same year-month. These
teachers will have normalized waitlist positions near 0.5 as well, such that the within risk-set
range in normalized waitlist position may be considerably less than 1. Finally, new teachers
appear on full-time and hourly lists. We take the minimum position across these lists as that is
the position more likely to generate an assignment.
       For our individual-level specification, we include experienced teachers ­ even those who
have only appeared on the experienced lists since the beginning of our sample period ­ to gain
statistical power. Because we do not observe these teachers on inexperienced lists during our
sample, we cannot construct our instrument in the same way we do for the district-level anal-
ysis. Instead, we calculate an imputed inexperienced waitlist position. We take every teacher
in our data who shares a risk set with the teacher in question. Then we order them according
to degree day (within the same degree-month) and break ties randomly.40 We then calculate
  40
    We could also break ties using the degree mark, as the actual waitlists do. But in case such tie-breaking
induces a correlation between position and teacher human capital, we avoid doing so.


                                                     78
normalized waitlist positions by dividing by the size of the risk set. Normalized waitlist posi-
tions in a single risk set thus span 0 to 1, which is a different scaling than in the instrument we
use in the district-level analysis. But we are unable to normalize in the same way because we
do not know how long the inexperienced waitlist was prior to our data sample period.41




 41
      Specifically, some teachers who were on the original list may have attrited from the system prior to 2003.


                                                        79
                Figure A.1: Number of Deputy High-School Teachers Assigned




Notes: This figure shows the number of deputy high-school teachers assigned in each Greek province.




                                                     80
                          Figure A.2: Attrition and Degree Conferral Day

                 1

                 .9

                 .8

                 .7
Attrition Rate




                 .6

                 .5

                 .4

                 .3

                 .2

                 .1

                 0
                      0                     10                           20                           30
                                                  Degree Conferral Day


         Notes: This figure shows attrition rates by the day of the month in which teachers' univer-
         sity degrees were conferred. This day of the month variation is our within risk-set timing
         variation that identifies our causal effects. Attrition is defined as leaving the waitlists before
         the end of our sample period and without ever having accrued experience.




                                                        81
 Figure A.3: Years without Formal Employment and Waitlist Position ­ District Level



                                      .2
   District Years Waiting Deviation




                                       0




                                      -.2




                                      -.4




                                      -.6

                                            -.2   -.1                     0                      .1         .2
                                                        District Waitlist Percentile Deviation

Notes: The binscatter figure shows the relationship, at the district-year level, between district demeaned
waitlist percentile and district demeaned years without formal employment where the demeaning is done by
risk set-year. A risk set is a degree conferral year-month and subject combination. The waitlist percentile is
the initial position on the fresh graduates waitlist, normalized to vary from 0 to 1. The sample includes all
teachers on a waitlist between 2003 and 2011 whose degree was conferred before 2006.




                                                                82
                          Figure A.4: Panhellenic Test Scores () and Waitlist Position ­ District Level




                                   0
   District Mean Test Scores ()




                                  -.1




                                  -.2




                                  -.3




                                  -.4

                                        -.2           -.1                     0                      .1       .2
                                                            District Waitlist Percentile Deviation

Notes: The binscatter figure shows the relationship, at the district-year level, between district demeaned wait-
list percentile and district Panhellenic test scores (in student standard deviation units) where the demeaning
is done by risk set-year. A risk set is a degree conferral year-month and subject combination. The waitlist
percentile is the initial position on the fresh graduates waitlist, normalized to vary from 0 to 1. The sample
includes all teachers on a waitlist between 2003 and 2011 whose degree was conferred before 2006.




                                                                    83
                                                           Figure A.5: Cross-District Effects of Eliminating Waiting



                                                         150
            Rank after Removing 1 Year of Waiting




                                                         100




                                                          50




                                                           0
                                                               0                50                  100                150
                                                                                      Actual Rank



                                                         150
            Rank after Removing All Waiting Since 2003




                                                         100




                                                          50




                                                           0
                                                               0                50                  100                150
                                                                                      Actual Rank


Notes: The figures show how changing the time out of formal employment affects districts' test score ranks.
The top figure reduces the number of years deputy teachers wait without formal employment by 1 year; the
bottom figure reduces the number of years deputy teachers wait to 0. We calculate each district's test score
rank, under the actual scores and under counterfactuals, where the district with the lowest mean test scores
has the rank 1. For each counterfactual, we take the absolute value of our point estimate from the district-
level model, multiply by each district's heterogeneous exposure to the deputy assignment system, and then
multiply by the number of years waiting reduced in the counterfactual.



                                                                                      84
                Figure A.6: Years Waiting for First Assignment ­ Survey



           .2




          .15
Density




           .1




          .05




           0
                0              2               4               6               8                  10
                                       Years until First Assignment


    Notes: This figure shows the distribution of the years spent waiting between degree confer-
    ral and first teaching assignment. The sample is the teachers who took our online survey.
    Responses with implied waiting times that are negative or more than 10 years have been
    excluded.




                                               85
                   Table A.1: Survey Responses


                                              Mean    Std. Dev.   Obs
 Degree Conferral Year                        2007       8        187
 Year of First Assignment                     2010       9        159
 Num Schools Worked in                        1.42      0.87       93
 Aware of System when Choosing Teaching       0.34      0.47      184
 Understand the Assignment Process            0.76      0.43      184
 Knew Waitlist Position                       0.73      0.44      184
 Considered Attriting                         0.49      0.50      200
 Rejected an Assignment                       0.12      0.33      185
 Has Left Teaching                            0.20      0.40      200
 Believes Skills Depreciated while Waiting    0.18      0.38      187
 Invested in Skill Maintenance                0.46      0.50      200

Notes: This table shows summary statistics for selected responses to the
online survey of teachers. "Num Schools Worked in" indicates the number
of different schools a teacher worked in at the same time.




                                  86
                Table A.2: Activities while Waiting


                                                     Fraction
           Private Lessons                             0.54
           Further Studies                             0.33
           Started a Family                            0.16
           Non-Teaching Work in Education Sector       0.19
           Work in Non-Education Sector                0.39
           Other                                       0.19

Notes: This table shows the fraction of survey respondents in various ac-
tivities during the time spent waiting for an assignment. Respondents in
the online survey could choose multiple activities.




                                  87
                           Table A.3: Teachers Working in Part-Time Jobs


                                     Part-Time Work while Teaching     Continued Part-Time Work while Teaching
Yes                                               0.28                                    0.33
      Private Lessons                             0.09                                    0.17
      Private School                              0.02                                    0.01
      Tourism Industry                            0.01                                    0.01
      Work in Other Private Sector                0.04                                    0.03
      Other                                       0.04                                    0.03
No                                                0.72                                    0.67
N                                                 157                                     158

Notes: This table shows the part-time jobs teachers report having, while teaching, in the online survey. "Yes"
indicates the teacher held a part-time job while teaching. "Part-Time Work while Teaching" is the distribution
of part-time jobs while "Continued Part-Time Work while Teaching" is the distribution of part-time jobs that
continue activities started while the teacher was waiting for an assignment. Respondents in the online survey
could choose multiple responses.




                                                     88
Table A.4: Relationship between Years Waiting and Activities during Teaching

                                      Activity while Teaching    Continued Activity
       Years until First Assignment           0.00706                  0.0126
                                              (0.0143)                (0.0147)
       Constant                               0.249                   0.292
                                              (0.0598)                (0.0608)
       Mean DV                                   0.273                 0.333
       N                                          132                   132
Notes: This table shows regressions of activity while teaching on years spent waiting until
first assignment. Years spent waiting is calculated as the difference between the year of
the first teaching assignment and the year of degree conferral. "Activity while Teaching" is
a dummy variable for whether the teacher participated in an extra activity ­ e.g., private
lessons ­ while working as a public school teacher. "Continued Activity" is a dummy variable
for whether the teacher participated in an extra activity, while working as a public school
teacher, that had been started while the teacher was waiting for an assignment. The sample
is the teachers responding to our online survey.  p < .1,  p < .05,  p < .01.




                                            89
     Table A.5: Prior Year Grade Point Average



                                      IV                 IV

                               Prior Year GPA       Score ()
  Years Waiting                    0.0143           -0.0723
                                  (0.0131)           (0.0224)
  Deputy                           -0.0804           -0.231
                                  (0.0500)           (0.103)
  Demeaned Prior GPA                                 0.746
                                                     (0.0102)
  Mean DV                           0.0306            0.0355
  Clusters                            385               383
  N                                 75340             54851
  Risk Set                            Yes               Yes
Notes: The table presents instrumental variable estimates. An
observation is a student-subject-year. The dependent variable is
the student's prior year grade point average (column 1) or the
student's subject-specific test score, in standard deviation units
(column 2). The instrument is the assigned teacher's imputed
waitlist position (demeaned by risk set), normalized to run be-
tween 0 and 1 within a risk set. Risk sets are teachers in the same
subject whose degrees were conferred in the same month-year.
Demeaned prior GPA is demeaned at the teacher-year level. The
sample includes students taught by deputy and permanent teach-
ers. Permanent teachers each have their own risk set. Standard
errors are clustered by teacher.  p < .1,  p < .05,  p < .01.




                               90
Table A.6: Effect of Years without Formal Employment on Students' Tests by Subject



                                          IV              IV              IV

                                      Score ()       Score ()        Score ()
                Years Waiting        -0.0853          -0.136           -3.585
                                      (0.0164)        (0.0581)        (18.51)
                Deputy                 -0.168         -0.476           -1.375
                                      (0.0992)        (0.228)         (6.971)
                Prior Year GPA        0.737           0.734          0.739
                                     (0.00877)        (0.0116)       (0.0174)
                Mean DV                0.0355          0.0529        0.0241
                Clusters                 383             158          273
                N                      54851           21693         33158
                Risk Set                 Yes             Yes           Yes
                Sample                   All           STEM         Non-STEM
                Notes: The table includes instrumental variable estimates with
                (demeaned) imputed waitlist position as the instrument. An ob-
                servation is a student-subject-year. "Years Waiting" is the deputy
                teacher's years without formal employment, normalized by the
                risk set size to be in percentiles. "Years Waiting" and the instru-
                ment are demeaned by risk set, where a risk set is the cohort of
                teachers in the same subject with degrees conferred in the same
                month-year. The outcome is the student's average full-year score
                in student standard deviation units (). STEM fields are algebra,
                geometry, mathematics, biology, physics, technology, and science.
                Standard errors are clustered by teacher.  p < .1,  p < .05, 
                p < .01.




                                               91
Table A.7: Effect of Years without Formal Employment on Students' Grade Point Average



                                            IV             IV             IV

                                        GPA ()            GPA         Log GPA
                   Years Waiting       -0.0519         -0.150        -0.00986
                                        (0.0129)       (0.0713)      (0.00518)
                   Deputy                -0.0945       -0.00620      -0.000156
                                        (0.0579)        (0.248)       (0.0170)
                   Prior Year GPA       0.930          2.589          0.178
                                       (0.00360)       (0.0146)      (0.00144)
                   Mean DV              -0.00226         14.94         2.686
                   Clusters                383            385           385
                   N                     54541           74997         74941
                   Risk Set                Yes            Yes           Yes
                 Notes: The table includes instrumental variable estimates with
                 (demeaned) imputed waitlist position as the instrument. An ob-
                 servation is a student-subject-year where the outcomes do not
                 vary by subject but the teachers do. "Years Waiting" is the deputy
                 teacher's years without formal employment, normalized by the
                 risk set size to be in percentiles. "Years Waiting" and the instru-
                 ment are demeaned by risk set, where a risk set is the cohort of
                 teachers in the same subject with degrees conferred in the same
                 month-year. The outcome is the student's grade-point-average
                 (out of 20), expressed in student standard deviation units (),
                 levels, or logs. Standard errors are clustered by teacher.  p < .1,
                 
                    p < .05,  p < .01.




                                                 92
Table A.8: District (Demeaned) Waitlist Position and Mean Expected Years without Formal
Employment



                                      Mean [Years Waiting]            Mean [Years Waiting]
           Mean Waitlist Perc                    -0.207                          -0.760
                                                (0.644)                         (0.635)
           Mean DV                               3.556                           3.556
           N                                      394                             394
           District FE                            No                              Yes
           Reg-Yr FE                              No                              Yes
        Notes: This table tests the identifying assumption behind our aggregation to a district-level
        model. An observation is a district-year. The dependent variable is the mean expected years
        without formal employment where the expected years without formal employment is the
        mean over a teacher's risk set and the first mean is taken over the teachers assigned to the
        district in a given year. The explanatory variable is the district-year's mean of its assignees'
        (demeaned) waitlist position.  p < .1,  p < .05,  p < .01.




                                                      93
     Table A.9: Student-Level Analysis ­ Different Functional Forms



                                  IV              IV              IV             IV

                             Score ()         Ln Score       Score ()        Ln Score
     Years Waiting           -0.0853         -0.0442
                              (0.0164)       (0.0186)
     Deputy                    -0.168         -0.0766          -0.204         -0.0952
                              (0.0992)       (0.0572)         (0.160)        (0.0750)
     Prior Year GPA           0.737           0.204          0.737           0.204
                             (0.00877)       (0.00450)      (0.00877)       (0.00451)
     Ln Years Waiting                                        -1.277          -0.662
                                                              (0.404)         (0.213)
     Mean DV                   0.0355          2.638          0.0355           2.638
     Clusters                   383             383             383             383
     N                         54851           54840          54851            54840
     Risk Set                    Yes            Yes             Yes             Yes
Notes: This table shows IV regressions with (demeaned) imputed waitlist position as the
instrument. We vary the functional form of the test outcome (student standard deviation
units or log scores) and the measure of years spent not working formally (levels or log). An
observation is a student-subject-year. "Years Waiting" and the instrument are demeaned by
risk set, where a risk set is the cohort of teachers in the same subject with degrees conferred
in the same month-year. Standard errors are clustered by teacher.  p < .1,  p < .05, 
p < .01.




                                             94
 Table A.10: Student-Level Analysis ­ Different Samples



                         IV                 IV                  IV

                    Score ()            Score ()           Score ()
Years Waiting       -0.0853             -0.0890            -0.0955
                     (0.0164)            (0.0275)           (0.0293)
Deputy                -0.168              -0.207              -0.196
                     (0.0992)            (0.146)             (0.140)
Prior Year GPA       0.737               0.737              0.737
                    (0.00877)           (0.00880)          (0.00879)
Mean DV               0.0355          0.0360               0.0361
Clusters                383             377                  380
N                     54851           54529                 54657
Risk Set                Yes             Yes                  Yes
Sample                  All        Month Not July        Day Not 30th
Notes: This table shows IV regressions with (demeaned) imputed waitlist
position as the instrument. We vary the sample across columns to show
robustness to excluding common degree conferral months (July) or days
(the 30th). An observation is a student-subject-year. "Years Waiting" and
the instrument are demeaned by risk set, where a risk set is the cohort of
teachers in the same subject with degrees conferred in the same month-
year. Standard errors are clustered by teacher.  p < .1,  p < .05, 
p < .01.




                                   95
                                         Table A.11: Student-Level Analysis ­ Different Outcome Definitions



                                   IV             IV              IV               IV                IV                   IV                       IV

                                 Score        Ln Score      Univ Score       Selec (Adm)       Selec (Natl)      Selec (2003 Adm)         Selec (2003 Natl)
          Years Waiting        -0.502        -0.0442         -269.8            -2.468            -2.413               -2.110                   -1.975
                                (0.194)      (0.0186)         (74.55)           (0.665)           (0.621)              (0.547)                  (0.500)
          Deputy                 -0.895        -0.0766         -318.0            -3.327           -2.831                -1.920                   -1.548
                                (0.642)       (0.0572)        (302.3)           (2.544)          (2.408)               (2.356)                  (2.182)
          Prior Year GPA       2.738          0.204          3031.5            24.51             23.78                 22.44                    21.59
96




                               (0.0469)      (0.00450)        (34.97)          (0.247)           (0.252)               (0.301)                  (0.300)
          Mean DV               14.58          2.638          14315.1           49.33             49.17                 52.56                    52.15
          Clusters               383            383             363              363               363                   363                      363
          N                     54851          54840           49175            49175             49175                 35554                    35554
          Risk Set               Yes            Yes             Yes              Yes               Yes                   Yes                      Yes
     Notes: This table shows IV regressions with (demeaned) imputed waitlist position as the instrument. We vary the functional form of the outcome across columns.
     An observation is a student-subject-year. "Years Waiting" and the instrument are demeaned by risk set, where a risk set is the cohort of teachers in the same
     subject with degrees conferred in the same month-year. "Score" is the student's average subject-specific test score during the year. "Univ Score" is the natural log
     of the student's university admissions score. For the selectivity measures ("Selec"), we order the university-programs according to their enrollees' mean statistic,
     defined below, and rank them from highest to lowest. The measure is the percentile of this ordering where 100 is the program whose admits have the highest
     mean score. "Adm" uses the university admissions score for ranking while "Natl" uses the national Panhellenica score, which is an alternate weighting. The
     "2003" measures use the 2003 cohort to construct the measures to avoid overlap with our analysis sample. Standard errors are clustered by teacher.  p < .1, 
     p < .05,  p < .01.
 Table A.12: District-Level Analysis ­ Different Controls



                          Score ()       Score ()        Score ()
     Years Waiting         -0.374        -0.413           -0.414
                           (0.160)        (0.157)          (0.158)
     Ln Class Size        -0.712         -0.810           -0.806
                           (0.184)        (0.198)          (0.198)
     Num Teachers                        0.0369
                                         (0.0120)
     Num Students                                       0.00164
                                                        (0.000559)
     Per Class             -0.0748        -0.0827         -0.0828
     Mean DV               -0.0442        -0.0442         -0.0442
     N                       394            394             394
     District FE            Resid          Resid           Resid
     Reg-Yr FE              Resid          Resid           Resid
     Risk Set                Yes            Yes             Yes
Notes: This table shows IV regressions with (demeaned) imputed wait-
list position as the instrument. The columns vary our use of controls. All
columns use (demeaned) fixed effects. The second and third columns in-
clude additional district-level controls. An observation is a district-year.
All variables are demeaned by risk set, where a risk set is the cohort of
teachers in the same subject with degrees conferred in the same month-
year. Standard errors are heteroskedasticity-robust.  p < .1,  p < .05,

    p < .01.




                                    97
    Table A.13: District-Level Analysis ­ Different Functional Forms



                              Score ()       Ln Score      Score ()       Ln Score
       Years Waiting          -0.342         -0.129
                               (0.121)       (0.0478)
       Ln Class Size           0.239         0.131         0.270         0.143
                              (0.0986)       (0.0353)      (0.0923)      (0.0335)
       Ln Years Waiting                                    -0.711        -0.268
                                                            (0.239)      (0.0992)
       Per Class               -0.0684       -0.0258        -0.1423       -0.0537
       Mean DV                 -0.0440        2.504         -0.0440        2.504
       N                         390           390            390           390
       District FE               Yes           Yes            Yes           Yes
       Reg-Yr FE                 Yes           Yes            Yes           Yes
       Risk Set                  Yes           Yes            Yes           Yes
Notes: This table shows IV regressions with (demeaned) imputed waitlist position as the
instrument. We vary the functional form of the test outcome (student standard deviation
units or log scores) and the measure of years spent not working formally (levels or log). An
observation is a district-year. "Years Waiting" and the instrument are demeaned by risk set,
where a risk set is the cohort of teachers in the same subject with degrees conferred in the
same month-year. Standard errors are heteroskedasticity-robust.  p < .1,  p < .05, 
p < .01.




                                            98
  Table A.14: District-Level Analysis ­ Different Samples



                          IV                IV                  IV

                     Score ()          Score ()            Score ()
 Years Waiting        -0.339             -0.191             -0.295
                       (0.121)           (0.0846)            (0.104)
 Ln Class Size         0.237             0.249               0.237
                      (0.0982)           (0.0850)           (0.0922)
 Per Class            -0.0679         -0.0383              -0.0589
 Mean DV              -0.0442         -0.0442              -0.0442
 N                      394             394                  394
 District FE            Yes             Yes                  Yes
 Reg-Yr FE              Yes             Yes                  Yes
 Risk Set               Yes             Yes                  Yes
 Sample                  All        Month Not Jul        Day Not 30th
Notes: This table shows IV regressions with (demeaned) imputed waitlist
position as the instrument. We vary the sample across columns to show ro-
bustness to excluding common degree conferral months (July) or days (the
30th). An observation is a district-year. "Years Waiting" and the instrument
are demeaned by risk set, where a risk set is the cohort of teachers in the
same subject with degrees conferred in the same month-year. Standard
errors are heteroskedasticity-robust.  p < .1,  p < .05,  p < .01.




                                    99
                                     Table A.15: District-Level Analysis ­ Different Outcome Definitions



                               IV           IV             IV               IV                IV                   IV                       IV

                             Score      Ln Score      Univ Score      Selec (Adm)       Selec (Natl)     Selec (2003 Adm)         Selec (2003 Natl)
       Years Waiting       -1.351       -0.129         -1153.7           -5.645            -5.097                -3.690                  -2.828
                            (0.453)     (0.0478)        (455.1)          (2.576)           (2.654)              (2.973)                 (3.140)
       Ln Class Size       1.346        0.131          1725.2            9.139            9.540                7.794                    8.047
                           (0.331)      (0.0353)        (427.1)          (2.262)          (2.236)              (1.832)                  (1.868)
100




       Per Class           -0.2702       -0.0258         -230.7           -1.129           -1.019               -0.738                   -0.566
       Mean DV              13.10         2.504         14274.0           48.77            48.58                 52.40                   52.12
       N                     390           390            390              390              390                   385                     385
       District FE           Yes           Yes             Yes              Yes              Yes                  Yes                      Yes
       Reg-Yr FE             Yes           Yes             Yes              Yes              Yes                  Yes                      Yes
       Risk Set              Yes           Yes             Yes              Yes              Yes                  Yes                      Yes
      Notes: This table shows IV regressions with (demeaned) imputed waitlist position as the instrument. We vary the functional form of the outcome
      across columns. An observation is a district-year. "Years Waiting" and the instrument are demeaned by risk set, where a risk set is the cohort of
      teachers in the same subject with degrees conferred in the same month-year. "Score" is the student's average subject-specific test score during the
      year. "Univ Score" is the natural log of the student's university admissions score. For the selectivity measures ("Selec"), we order the university-
      programs according to their enrollees' mean statistic, defined below, and rank them from highest to lowest. The measure is the percentile of this
      ordering where 100 is the program whose admits have the highest mean score. "Adm" uses the university admissions score for ranking while "Natl"
      uses the national Panhellenica score, which is an alternate weighting. The "2003" measures use the 2003 cohort to construct the measures to avoid
      overlap with our analysis sample. Standard errors are heteroskedasticity-robust.  p < .1,  p < .05,  p < .01.
Table A.16: Effect of Years without Formal Employment on Districts' Panhellenic Exam
Scores without Scaling



                              Score ()       Score (Perc)       Ln Univ Score       Admitted
           Years Waiting       -0.121           -3.152              -0.0579         -0.0442
                               (0.0603)         (1.495)            (0.0458)         (0.0222)
           Ln Class Size        0.105            2.175              0.0231           0.0102
                               (0.0535)         (1.293)            (0.0412)         (0.0166)
           Per Class            -0.0242         -0.6304            -0.0116           -0.0088
           Mean DV              -0.0440          49.07              9.518             0.818
           N                      390             390                390               390
           District FE            Yes             Yes                Yes               Yes
           Reg-Yr FE              Yes             Yes                Yes               Yes
           Risk Set               Yes             Yes                Yes               Yes
         Notes: The table include the main IV regressions without incorporating the deputies
         we lack inexperience waitlist positions for. An observation is a district-year and the IV
         outcomes are measures of student performance on the national twelfth grade exams,
         as mean level (in student standard deviation units) or mean percentile, and university
         admissions outcomes. Standard errors are heteroskedasticity-robust.  p < .1,  p <
         .05,  p < .01.




                                                   101
Table A.17: Effect of Years without Formal Employment on Districts' Panhellenic Exam
Scores with Alternate Weighting



                                    Score ()            Score ()         Score ()
               Years Waiting         -0.342              -0.452           -0.466
                                      (0.121)             (0.171)          (0.131)
               Ln Class Size          0.239              0.503            0.599
                                     (0.0986)            (0.117)          (0.0883)
               Per Class            -0.0684             -0.0904            -0.0933
               Mean DV              -0.0440              -0.150             -0.178
               N                      390                 390                390
               District FE            Yes                  Yes                Yes
               Reg-Yr FE              Yes                  Yes                Yes
               Risk Set               Yes                  Yes                Yes
               Weighting          Num Students        Num Deputies           None
              Notes: The table includes the main IV regressions using alternate weight-
              ing. An observation is a district-year and the IV outcomes are measures
              of student performance on the national twelfth grade exams, in student
              standard deviation units. Weighting is shown in the last row. Standard
              errors are heteroskedasticity-robust.  p < .1,  p < .05,  p < .01.




                                                102
