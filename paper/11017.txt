                                  NBER WORKING PAPER SERIES




              INFORMATION DYNAMICS AND EQUILIBRIUM MULTIPLICITY
                      IN GLOBAL GAMES OF REGIME CHANGE

                                        George-Marios Angeletos
                                           Christian Hellwig
                                           Alessandro Pavan

                                          Working Paper 11017
                                  http://www.nber.org/papers/w11017


                       NATIONAL BUREAU OF ECONOMIC RESEARCH
                                1050 Massachusetts Avenue
                                  Cambridge, MA 02138
                                     December 2004




For helpful comments, we thank Andy Atkeson, Pierpaolo Battigalli, Alberto Bisin, V.V. Chari, Patrick
Kehoe, Alessandro Lizzeri, Kiminori Matsuyama, Stephen Morris, Ivan Werning, and seminar participants
at Berkeley, MIT, Northwestern, NYU, UBC, UCLA, Yale, the Minneapolis FRB, and the SED conference.
The views expressed herein are those of the author(s) and do not necessarily reflect the views of the National
Bureau of Economic Research.

 © 2004 by George-Marios Angeletos, Christian Hellwig, and Alessandro Pavan. All rights reserved. Short
sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including © notice, is given to the source.
Information Dynamics and Equilibrium Multiplicity in Global Games of Regime Change
George-Marios Angeletos, Christian Hellwig, and Alessandro Pavan
NBER Working Paper No. 11017
December 2004
JEL No. C7, D7, D8, F3

                                            ABSTRACT

Global games of regime change – that is, coordination games of incomplete information in which

a status quo is abandoned once a sufficiently large fraction of agents attacks it – have been used to

study crises phenomena such as currency attacks, bank runs, debt crises, and political change. We

extend the static benchmark examined in the literature by allowing agents to accumulate information

over time and take actions in many periods. It is shown that dynamics may lead to multiple equilibria

under the same information assumptions that guarantee uniqueness in the static benchmark.

Multiplicity originates in the interaction between the arrival of information over time and the

endogenous change in beliefs induced by the knowledge that the regime survived past attacks. This

interaction also generates interesting equilibrium properties, such as the possibility that fundamentals

predict the eventual regime outcome but not the timing or the number of attacks, or that dynamics

alternate between crises and phases of tranquility without changes in fundamentals.

George -Marios Angeletos
Department of Economics
MIT
50 Memorial Drive, E51-251
Cambridge, MA 02142
and NBER
angelet@mit.edu

Christian Hellwig
UCLA
chris@econ.ucla.edu

Alessandro Pavan
Northwestern University
alepavan@northwestern.edu
1        Introduction

Coordination games in which a status quo is abandoned once a suﬃciently large number of agents
takes an action that favors regime change have been used to study a variety of socioeconomic
phenomena. Whereas the earlier contributions in the literature focused on the existence and im-
plications of multiple equilibria when agents can perfectly coordinate with each other, recent work
on global games by Carlsson and van Damme (1993) and Morris and Shin (1998, 2000, 2001)
has emphasized the fragility of this multiplicity to perturbations of the information structure away
from common knowledge: a unique equilibrium often survives when agents observe a payoﬀ-relevant
variable, such as the strength of the status quo, with small idiosyncratic noise.
        Variants of this uniqueness result have been established in the context of currency crises, bank
runs, debt crises, and political change.1 Most of this work assumes a static coordination game, thus
abstracting from the possibility that agents may have the option to take multiple shots against the
regime. For many of the applications of interest, however, this possibility seems relevant.
        In this paper, we extend the static benchmark examined in the literature by allowing agents
to take actions in multiple periods and accumulate information over time. There is a large number
of agents and two possible regimes, the status quo and an alternative. In any given period, each
agent has a binary choice: he may either “attack” the status quo (that is, take an action that favors
regime change) or “not attack”. Attacking is individually optimal if and only if the probability of
regime change in that period is suﬃciently high. The status quo, in turn, is abandoned if and only
if the fraction of agents attacking exceeds a critical value θ ∈ R, which parametrizes the strength of
the status quo. θ is the component of the payoﬀ structure — commonly referred to as the exogenous
fundamentals — which is never common knowledge among the agents. Instead, as time passes,
agents receive noisy private signals about θ.
        We show that dynamics may sustain multiple equilibria under the same information assump-
tions that guarantee uniqueness in the static benchmark, namely that the precision of the agents’
private information is suﬃciently high relative to the precision of the initial common prior. Multi-
plicity originates in the interaction between two elements: the knowledge that the regime survived
past attacks and the arrival of new private information over time.
        In the first period, agents find it dominant to attack for suﬃciently low realizations of their
private signals. This ensures that, in any equilibrium, regime change takes place in the first period
for suﬃciently low θ. At any future date, the observation that the status quo is still in place makes
it common certainty that it is not too weak, for otherwise it would have collapsed under the first
attack.
    1
        See Morris and Shin (1998) for currency crises; Goldstein and Pauzner (2000) and Rochet and Vives (2004) for
bank runs; Morris and Shin (2004) and Corsetti, Guimaraes and Roubini (2004) for debt crises; Chamley (1999) for
regime switches; Atkeson (2000) and Edmond (2004) for riots and political change.


                                                           1
    This eﬀect implies that no agent is willing to attack in any subsequent period if he expects no
other agent to attack. Hence, there always exists an equilibrium in which no attack occurs after
the first period. In fact, if no new information were to arrive over time, this would be the unique
equilibrium of the game. The possibility to take multiple shots against the regime would then add
nothing to the static analysis.

    However, as agents receive new private signals about θ, the impact of the knowledge that the
regime survived past attacks on posterior beliefs eventually vanishes. For the same reason, the
dependence of posterior beliefs on the initial common prior also diminishes over time. When the
prior is relatively aggressive, in the sense that it induces a large attack in the first period, the
increase in the precision of private information would induce less aggressive behavior even in the
absence of past attacks. In this case, no action after the first period remains the unique equilibrium.
In contrast, when the prior is relatively lenient, both the discounting of the prior and the discounting
of the knowledge that the regime survived past attacks contribute to making new attacks eventually
possible. Hence, there also exist equilibria where agents take multiple shots against the regime.
Indeed, we show that, unless the game ends for exogenous reasons in finite time, any arbitrary
number of attacks can be sustained in equilibrium.

    In the benchmark model, we deliberately assume away the possibility that the critical size
of attack necessary for regime change varies over time. This allows us to isolate the eﬀects of
changes in information, as opposed to changes in fundamentals, on the dynamics of coordination.
Nevertheless, we also show that the multiplicity result is robust to the introduction of shocks to
the fundamentals — in which case dominant actions may exist in every period — provided that the
volatility of these shocks is suﬃciently small. In the limit, as the volatility vanishes, any equilibrium
of the benchmark model can be approximated arbitrarily closely by an equilibrium in the game
with shocks. What sustains the multiplicity of equilibria and the corresponding dynamics is again
the combination of the arrival of new information over time with the endogenous upward shift
in posterior beliefs that follows from the knowledge that the regime survived past attacks. That
this shift takes the form of a truncation in the benchmark model simplifies the construction of the
equilibrium set, but is not essential for the multiplicity result.

    We also emphasize that multiplicity does not originate from the presence of exogenous public
signals or the observation of the size of past attacks. Indeed, for most of the analysis we assume
away any such source of information and concentrate on the case in which agents receive only
private signals over time. What the introduction of public news does, is to “smooth out” the
dependence of the determinacy of equilibria on the initial prior: multiple equilibria then exist
whatever the horizon of the game and for any prior mean and any relative precision of public and
private information. Finally, introducing endogenous signals about the size of past attacks — a
simple form of (noisy) social learning — does not change the equilibrium dynamics, except for the

                                                   2
possibility that the endogenous information revealed by the size of an attack may substitute for
the arrival of new exogenous information and render further attacks possible immediately after an
unsuccessful one.
    The existence of multiple equilibria leads to dynamics that might not have been possible with
either common knowledge or a unique equilibrium. For example, fundamentals may determine
the final regime outcome (e.g., whether a currency is eventually devalued) but not the timing and
number of attacks. Moreover, dynamics may take the form of sequences of periods in which attacks
can not occur and agents only accumulate information, followed by periods in which an attack is
possible but does not take place, eventually resulting in a new attack. An economy can thus transit
from phases of tranquility to crises without any change in the underlying economic fundamentals.
    Below, we discuss the relation of the paper to the pertinent literature. Section 2 then reviews the
static benchmark and introduces the dynamic model. Section 3 characterizes the set of monotone
equilibria. Section 4 establishes the multiplicity result and discusses equilibrium dynamics. Section
5 examines robustness to the introduction of shocks in the fundamentals. Section 6 introduces
public news and signals about past attacks. Section 7 concludes. Proofs omitted in the main text
are presented in the Appendix.

    Related Literature. This paper contributes to a small but growing literature on dynamic
global games. Heidhues and Melissas (2003) identify a condition of dynamic strategic complemen-
tarity that suﬃces for uniqueness in an investment model; this condition is also implicit in Gian-
nitsarou and Toxvaerd’s (2003) uniqueness theorem for recursive binary-action games. Dasgupta
(2002) examines the role of social learning in a two-period investment model with irreversible ac-
tions. Levin (2001) considers a global game with overlapping generations of players. Goldstein and
Pauzner (2001) and Goldstein (2002) consider models of contagion. Frankel and Pauzner (2000),
on the other hand, consider a complete-information dynamic coordination game, where uniqueness
is obtained by assuming aggregate shocks and idiosyncratic inertia. None of these papers, however,
examines the role of information dynamics in games of regime change.
    Closer to our analysis, Morris and Shin (1999) consider a dynamic model whose stage game
is similar to ours, but where fundamentals follow a random walk and are commonly observed at
the end of each period. This reduces the analysis to a sequence of static games with a unique
equilibrium.
    This paper departs from the above literature in that it considers dynamics as a natural source of
information. In this respect, it shares with Angeletos, Hellwig and Pavan (2003) — which considers
the signaling eﬀects of policy in a static game — the idea that endogenous information structures
may overturn uniqueness results in global games and lead to predictions that would have not been
possible with either common knowledge or a unique equilibrium.
    Finally, we share with Chari and Kehoe (2003) the motivation that understanding the dynamics

                                                  3
of information may help understand the dynamics of crises. However, whereas they focus on herding,
we examine the role of information for coordination.


2        A simple game of regime change

2.1        Static benchmark

Model set-up. There is a continuum of agents of measure one, indexed by i and uniformly
distributed over [0, 1]. Agents move simultaneously, choosing between two actions: they can either
attack the status quo (i.e., take an action that favors regime change) or refrain from attacking.
        The payoﬀ structure is illustrated in Table 1. The payoﬀ from not attacking (ai = 0) is zero,
whereas the payoﬀ from attacking (ai = 1) is 1 − c > 0 if the status quo is abandoned (R = 1)
and −c < 0 otherwise (R = 0), where c ∈ (0, 1) parametrizes the relative cost of attacking. An
agent hence finds it optimal to attack if and only if he expects regime change with probability at
least c. The status quo is in turn abandoned if and only if the measure of agents attacking, which
we denote by A, is greater than or equal to θ ∈ R, which parametrizes the strength of the status
quo. An agent’s incentive to attack thus increases with the aggregate size of attack, implying that
agents’ actions are strategic complements.2


                                              Regime Change (A ≥ θ)           Status Quo (A < θ)
                    Attack (ai = 1)                       1−c                           −c
                    Not Attack (ai = 0)                     0                            0
                                                    Table 1. Payoﬀs


        Agents have heterogeneous information about the strength of the status quo. Nature first draws
θ from a normal distribution N (z, 1/β) , which defines the initial common prior about θ. Each
agent then receives a private signal xi = θ + ξi , where ξi ∼ N (0, 1/α) is noise, i.i.d. across agents
and independent of θ. The Normality assumptions allow to parametrize the information structure
parsimoniously with (α, β, z) , that is, the precision of private information and the precision and
mean of the common prior.

        Interpretation. Although the game presented above is highly stylized, it admits a variety
of interpretations and possible applications. The most celebrated examples are self-fulfilling bank
runs, currency attacks, and debt crises. In these contexts, regime change occurs, respectively, when
a large run forces the banking system to suspend its payments, when a large speculative attack
    2
        The role of coordination is most evident when θ is commonly known by all agents: for θ ∈ (0, 1], there exist two
pure-strategy equilibria, one in which all agents attack and the status quo is abandoned (A = 1 ≥ θ) and another in
which no agent attacks and the status quo is maintained (A = 0 < θ).


                                                             4
forces the central bank to abandon the peg, or when a country/company fails to coordinate its
creditors and is forced to bankruptcy. The model can also be interpreted as one of political change,
in which a large number of citizens decide whether or not to take actions to subvert a repressive
dictator or some other political establishment.3

      Equilibrium analysis. Note that the c.d.f. of an agent’s posterior about θ is decreasing in
his private signal x. Moreover, it is strictly dominant to attack for suﬃciently low signals – namely
for x < x, where x solves Pr (θ ≤ 0|x) = c – and not to attack for suﬃcient high signals – namely
for x > x̄, where x̄ solves Pr (θ ≤ 1|x̄) = c. It is thus natural to look at monotone Bayesian Nash
equilibria in which the agents’ strategy is non-increasing in x.
      Indeed, suppose there is a threshold x̂ ∈ R such that each agent attacks if and only if x ≤ x̂.
The measure of agents attacking is then decreasing in θ and is given by A (θ) = Pr (x ≤ x̂|θ) =
  √
Φ( α(x̂ − θ)), where Φ is the c.d.f. of the standard Normal. It follows that the status quo is
abandoned if and only if θ ≤ θ̂, where θ̂ solves θ̂ = A(θ̂), or equivalently
                                                 √
                                          θ̂ = Φ( α(x̂ − θ̂)).                                     (1)

The posterior probability of regime change for an agent with signal x is then simply Pr (R = 1|x) =
Pr(θ ≤ θ̂|x). Since the latter is decreasing in x, each agent finds it optimal to attack if and only if
x ≤ x̂, where x̂ solves Pr(θ ≤ θ̂|x̂) = c, or equivalently
                                   ³p         ³                       ´´
                                                    α          β
                                Φ      α + β θ̂ − α+β  x̂ −   α+β z        = c.                    (2)

A monotone equilibrium is thus identified by a joint solution (x̂, θ̂) to (1) and (2). Such a solution
always exists and is unique for all z if and only if α ≥ β 2 / (2π) . Moreover, iterated elimination of
strictly dominated strategies implies that, when the monotone equilibrium is unique, there is no
other equilibrium. We conclude that

Proposition 1 (Static benchmark) In the static game, the equilibrium is unique if and only if
α ≥ β 2 / (2π) , and is in monotone strategies.


2.2      Dynamic game

We modify the static game reviewed above in two ways: first, we allow agents to attack the status
quo repeatedly; second, we let agents accumulate information over time.
      Time is discrete and indexed by t ∈ {1, 2, ...}. The game continues as long as the status quo
is in place and is over once the status quo is abandoned. We denote with Rt = 0 the event that
the status quo is still in place at the beginning of period t, with Rt = 1 the alternative event, with
ait ∈ {0, 1} the action of agent i, and with At ∈ [0, 1] the measure of agents attacking in period
  3
      For references, see footnote 1.


                                                    5
t. Conditional on the regime being in place at the beginning of period t (Rt = 0), the regime is
abandoned in that period (Rt+1 = 1) if and only if At ≥ θ, where θ again represents the strength
of the status quo. Agent i’s payoﬀ in period t is

                                                 πit = ait (Rt+1 − c) ,

                                                        P∞      t−1 (1
and his payoﬀ from the entire game is Πi =                 t=1 ρ         − Rt )πit , where ρ ∈ (0, 1) is the discount
factor.
      Like in the static model, θ is drawn at the beginning of the game from N (z, 1/β), which defines
the initial common prior, and never becomes common knowledge. Private information, however,
evolves over time. In each period t ≥ 1, every agent i receives a private signal x̃it = θ + ξit
about θ, where ξit ∼ N (0, 1/ηt ) is i.i.d. across i, independent of θ, and serially uncorrelated. Let
x̃ti = {x̃iτ }tτ =1 denote agent i’s history of private signals up to period t. Individual actions and the
size of past attacks are not observable,4 hence the public history in period t simply consists of the
information that the regime is still in place, whereas the private history of an agent is the sequence
                                                                       P
of own private signals x̃ti and own past actions. Finally, we let αt ≡ tτ =1 ητ and assume that

                                   ∞ > αt ≥ β 2 /(2π) ∀t and              lim αt = ∞.
                                                                         t→∞

As shown in the next section, αt parametrizes the precision of private information in period t. The
restrictions above ensure equilibrium uniqueness in the static game with precision αt , and that
private information becomes infinitely precise only in the limit.

      Remark. While this dynamic game is highly stylized, it captures two important dimensions
that are absent in the static benchmark: first, the possibility of multiple attacks against the status
quo; and, second, the evolution of beliefs about the probability of regime change. By assuming that
per-period payoﬀs do not depend on past or future actions and by ignoring specific institutional
details, the model may of course fail to capture other interesting eﬀects introduced by dynamics,
such as, for example, the role of wealth accumulation or liquidity in currency crises. However,
abstracting from these other dimensions allows us to isolate information as the driving force for the
dynamics of coordination and crises.

      Equilibrium. In what follows, we limit attention to monotone equilibria, that is, symmetric
Perfect Bayesian equilibria in which the probability an agent attacks in period t, which with a slight
abuse of notation we denote with at (x̃t ), is non-increasing in his private signals x̃t and independent
of his own past actions.5 Restricting attention to this class of equilibria suﬃces to establish our
multiplicity results.
  4
      The possibility that agents observe noisy signals about aggregate past activity is considered in Section 6.
  5
      We do not restrict the set of available strategies: we look at equilibria in which these properties are satisfied.


                                                             6
3        Equilibrium characterization

Since neither individual nor aggregate actions are observable, and Rt = 0 is always compatible with
any strategy profile at any t,6 no agent can detect out-of-equilibrium play as long as the status quo
is in place. It follows that beliefs are pinned down by Bayes’ rule in any relevant history of the game.
Furthermore, payoﬀs in one period do not depend on own or other players’ actions in any other
period and hence strategies are sequentially rational if and only if they maximize period-by-period
payoﬀs. Finally, define xt and αt recursively by

                                         αt−1       ηt
                                  xt =        xt−1 + x̃t         and αt = αt−1 + ηt ,
                                          αt        αt

with x1 = x̃1 and α1 = η1 ; and note that xt is a suﬃcient statistic for the agent’s private information
x̃t = {x̃τ }tτ =1 with respect to θ and therefore with respect to regime change as well. We conclude
that, in any monotone equilibrium,

                               at (x̃t ) ∈ arg max {(Pr [Rt+1 = 1|xt , Rt = 0] − c) a} ,                             (3)
                                              a∈[0,1]


where Pr [·] is pinned down by Bayes’ rule using {at (·)}∞
                                                         t=1 .
        This also implies that, in any equilibrium of the dynamic game, agents play in period 1 exactly
as in the static game in which they can attack only in that period: an agent attacks if and only if
his private signal is suﬃciently low and the status quo is maintained if and only if θ is suﬃciently
high. The following lemma shows that a similar property applies to subsequent periods.7

Lemma 1 For any monotone equilibrium, there is a sequence {x∗t , θt∗ }∞            ∗
                                                                      t=1 , where xt ∈ R ≡ R ∪
          ∗
{±∞} and θt−1 ∈ (0, 1), such that:
        (i) at any t ≥ 1,an agent attacks if xt < x∗t and does not attack if xt > x∗t ;
                                                                         ∗ .
        (ii) the status quo is in place at any t ≥ 2 if and only if θ > θt−1

        The fact that the status quo is in place in period t ≥ 2 makes it common certainty that
     ∗ . Since θ ∗
θ > θt−1               ∗
                t−1 ≥ θ1 > 0, this implies that there always exist equilibria in which nobody
attacks in period t ≥ 2, in which case x∗t = −∞ and θt∗ = θt−1
                                                           ∗ . In particular, there exists an

equilibrium in which an attack takes place in period 1 and never after. If this were always the
unique equilibrium, the possibility to take repeated actions against the regime would add nothing
to the static analysis and the equilibrium outcome in the dynamic game would coincide with that
in the static benchmark. In what follows we thus examine under what conditions there also exist
equilibria with further attacks.
    6
        Indeed, the regime always survives any attack for θ > 1 and no realization of the private signal rules out θ > 1.
    7
        To simplify the notation, we allow for x∗t = −∞ and x∗t = +∞, with which we denote the case where an agent
attacks for, respectively, none or every realization of his private information.


                                                             7
      By Lemma 1, the size of the attack is given by At (θ) = Pr (x ≤ x∗t |θ), which is decreasing
in θ, and the probability of regime change for an agent with suﬃcient statistic xt is Pr(Rt+1 =
                   ¡                       ¢
1|xt , Rt = 0) = Pr θ ≤ θt∗ |xt , θ > θt−1
                                       ∗     , which is decreasing in xt if θt∗ > θt−1
                                                                                   ∗ . It follows that, in

any equilibrium in which an attack occurs in period t, θt∗ and x∗t solve
                                                √
                                        θt∗ = Φ( αt (x∗t − θt∗ ))                                           (4)
                                   ³√        ³                        ´´
                                 Φ   αt + β αtα+β x∗t + αtβ+β z − θt∗
                             1 − ³√         ³                          ´´ = c.                              (5)
                                Φ   αt + β αtα+β x∗t + αtβ+β z − θt−1
                                                                  ∗


Conditions (4) and (5) are the analogs in the dynamic game of conditions (1) and (2) in the static
game: (4) states that the equilibrium size of an attack is equal to the critical size that triggers
regime change if and only if the fundamentals are θt∗ , while (5) states that an agent is indiﬀerent
between attacking and not attacking if and only if his private information is x∗t .
      Solving (4) for x∗t gives x∗t = X (θt∗ , αt ) and substituting this into (5) gives a single equation in
θt∗ , namely
                                           ¡                      ¢
                                          U θt∗ , θt−1
                                                   ∗
                                                       , αt , β, z = 0,                                     (6)

where X : [0, 1] × R+ → R and U : [0, 1] × R × R2+ × R → [−c, 1 − c] are defined as follows:8

          X (θ∗ , α) ≡ θ∗ + √1α Φ−1 (θ∗ )
                         ⎧
                         ⎪
                         ⎪ 1−c                                                            if θ∗ = 0 > θ−1
                         ⎪
                         ⎪                µ √       ∙                     ¸¶
                         ⎪
                         ⎨              Φ √
                                               α                  β
                                                      Φ−1 (θ∗ )+ √ (z−θ∗ )
                                            α+β                    α
U (θ∗ , θ−1 , α, β, z) ≡   1 − µ √α ∙                  β
                                                                  ¸
                                                                     √
                                                                                 ¶   − c if θ∗ > max{0, θ−1 }
                         ⎪
                         ⎪      Φ √       Φ−1 (θ ∗ )+ √ (z−θ∗ ) + α+β(θ ∗ −θ    )
                         ⎪
                         ⎪          α+β                 α                    −1
                         ⎪
                         ⎩
                           −c                                                             if θ∗ ≤ θ−1

The functions X and U have a simple interpretation: X (θ∗ ; α) is the “marginal agent” that im-
plements regime change for θ ≤ θ∗ when the precision of private information is α (that is, the
threshold x∗ such that, if agents attack if and only if x ≤ x∗ , the status quo is abandoned if
and only if θ ≤ θ∗ ); U (θ∗ , θ−1 , α, β, z) is the expected net payoﬀ of the marginal agent from at-
tacking, conditional on the knowledge that θ > θ−1 . Condition (6) thus simply requires that the
marginal agent is indiﬀerent between attacking and not attacking in period t ≥ 2. As for t = 1,
since the regime has never been challenged in the past, the corresponding indiﬀerence condition is
U (θ1∗ , −∞, α1 , β, z) = 0, where U (θ, −∞, α, β, z) coincides with the payoﬀ of the marginal agent
in the static benchmark.
      The next proposition then provides the complete set of necessary and suﬃcient conditions for
monotone equilibria.

  8
      With a slight abuse of notation, we let Φ(+∞) = 1, Φ(−∞) = 0, Φ−1 (1) = ∞ and Φ−1 (0) = −∞.


                                                       8
Proposition 2 (Equilibrium characterization) {at (·)}∞
                                                     t=1 is a monotone equilibrium if and
only if there exists a sequence {x∗t , θt∗ }∞
                                            t=1 such that:
       (i) for all t, at (·) = 1 if xt < x∗t and at (·) = 0 if xt > x∗t .
       (ii) for t = 1, θ1∗ solves U (θ1∗ , −∞, α1 , β, z) = 0 and x∗1 = X(θ1∗ , α1 ).
   (iii) for any t ≥ 2, either θt∗ = θt−1  ∗    > 0 and x∗t = −∞, or θt∗ > θt−1
                                                                            ∗   is a solution to
  ¡                  ¢
U θt∗ , θt−1
         ∗ , α , β, z = 0 and x∗ = X(θ ∗ , α ).
              t                t      t      t

       An equilibrium always exists.

       Proposition 2 provides a simple algorithm for constructing the entire set of monotone equilibria:
start with t = 1 and let θ1∗ be the unique solution to U (θ1∗ , −∞, α1 , β, z) = 0; proceed to period
t = 2 and let either θ2∗ = θ1∗ or θ2∗ be a solution to (6); repeat the same step for all t ≥ 3; the set
of sequences {θt∗ }∞                                                                  ∗ ∞
                   t=1 constructed this way, together with the associated sequences {xt }t=1 , gives
the set of monotone equilibria. Note that the above characterization is independent of whether the
horizon is finite or infinite: it is clearly valid even if the game ends exogenously at an arbitrary
period T < ∞.
       Existence of equilibrium follows immediately from the fact that U (θ1∗ , −∞, α1 , β, z) = 0 always
admits a solution and hence θt∗ = θ1∗ for all t is always an equilibrium. To understand whether there
are other equilibria, the next lemma investigates the properties of U and the existence of solutions
to (6).

Lemma 2 (i) U (θ∗ , θ−1 , α, β, z) is continuous in all its arguments, non-monotonic and single-
peaked in θ∗ when θ−1 ∈ (0, 1), and strictly decreasing in θ−1 and z for θ−1 < θ∗ . Furthermore, for
all θ−1 < 1 and θ∗ > θ−1 , limα→∞ U (θ∗ , θ−1 , ·) = θ∞ − θ∗ , where θ∞ ≡ 1 − c.
       (ii) Let θ̂t be the unique solution to U (θ̂t , −∞, αt , β, z) = 0. A solution to (6) exists only if
 ∗
θt−1   < θ̂t and is necessarily bounded from above by θ̂t .
                 ∗
       (iii) If θt−1 > θ∞ , a solution to (6) does not exist for αt suﬃciently high.
                ∗
       (iv) If θt−1 < θ∞ , a solution to (6) necessarily exists for αt suﬃciently high.
               ∗
       (v) If θt−1 is the highest solution to (6) for period t − 1, there exists α > αt−1 such that (6)
admits no solution for any period τ ≥ t such that ατ < α.

                                ¡                  ¢
       The non-monotonicity of U θ∗ , θt−1
                                       ∗ , α , β, z with respect to θ ∗ in any period t ≥ 2 (where
                                            t
     ∗
0 < θt−1 < 1) is a direct consequence of the fact that, for θ∗ < θt−1
                                                                  ∗ , the marginal agent attaches

probability zero to regime change. For θ∗ > θt−1
                                             ∗ , on the other hand, his belief about regime change

is necessarily positive, but converges to zero as θ∗ → 1, for then X (θ∗ , αt ) → ∞ and hence he
attaches probability one to θ > 1. His payoﬀ is thus initially increasing and then decreasing, as
illustrated by the solid line in Figure 1. Any intersection with the horizontal axis corresponds to
a solution to (6). The dashed line instead represents the payoﬀ of the marginal agent in the static

                                                          9
                            U
                     1−c




                                        θ*                    ^
                                                              θt
                       0
                                         t-1
                                                                                 θ*
                                                                             1



                       −c



                                Figure 1: The payoﬀ of the marginal agent.



game. Whereas the monotonicity of the latter ensures uniqueness, the non-monotonicity in the
dynamic game leaves open the possibility for multiple equilibria.
    The other properties identified in Lemma 2 are also quite intuitive. An increase in the mean of
the common prior implies a first-order stochastic-dominance change in the posterior beliefs about
θ, which explains why U decreases with z. To understand why U is also decreasing in θ−1 , note
that the more aggressive the attacks in the past, the stronger the regime must have been in order
to have survived these attacks, and therefore the lower the expected payoﬀ from attacking in the
current period.
    For the same reason, at any t ≥ 2, the payoﬀ of the marginal agent is always lower than
U (θ∗ , −∞, αt , β, z) , that is, the payoﬀ in the static game where the precision of private information
is αt . This explains why the static-game threshold θ̂t (which corresponds to the intersection of
the dashed line with the horizontal axis in Figure 1) is an upper bound for any solution to (6).
                                                      ∗
Nevertheless, the impact of the information that θ > θt−1 on posterior beliefs vanishes for any
                                                                              ¡                  ¢
xt > θt−1 as αt → ∞, and hence, for any θ > θt−1 , the diﬀerence between U θ∗ , θt−1
      ∗                                    ∗     ∗                                  ∗ , α , β, z
                                                                                         t
and U (θ∗ , −∞, αt , β, z) also vanishes. Combined with the fact that U (θ∗ , −∞, αt , β, z) → θ∞ − θ∗
as αt → ∞, this in turn implies that, for αt suﬃciently high, (6) admits a solution if and only if
 ∗
θt−1 < θ∞ , where θ∞ is the limit of the equilibrium threshold of the static game as the precision of
private information becomes infinite (i.e., θ∞ = limt→∞ θ̂t ).
    Finally, to understand (v), note that any unsuccessful attack causes an upward shift (a first-
order stochastic-dominance change) in the posterior beliefs about the strength of the regime, which
other things equal reduces the expected payoﬀ from attacking. It follows that, if the largest possible
attack (that is, the highest solution of (6)) is played in one period and no new information arrives
thereafter, no attack is possible in any subsequent period. By continuity then, further attacks
remain impossible as long as the change in the precision of private information is not large enough.

                                                   10
                              U
                    1−c




                         0
                                          θ'3               θ"3    θoo
                                                                                    θ*
                                    θ*
                                     1                                          1




                         −c



                                  Figure 2: Equilibria with multiple attacks.



4    Multiplicity and dynamics

Part (v) of Lemma 2 highlights that the arrival of new private information is necessary for further
attacks to become possible after period 1. Whether this is also suﬃcient depends on the initial
prior. This is because an increase in the precision of private information leads agents to discount,
not only the information conveyed by the fact that the regime survived past attacks, but also their
initial prior beliefs.
    When z is low (“aggressive prior”), an increase in the precision of private information makes
the marginal agent less aggressive in the static game (that is, θ̂t decreases with αt ). The knowledge
that the regime survived past attacks then only reinforces this eﬀect. Therefore, for z suﬃciently
low, there exists a unique equilibrium and is such that no attack ever occurs after the first period.
    When instead z is high (“lenient prior”), the arrival of new private information makes the
marginal agent more aggressive, and may eventually oﬀset the incentive not to attack induced by
the knowledge that the regime survived past attacks. Indeed, if z is high enough so that θ1∗ < θ∞ ,
Lemma 2 ensures that a second attack necessarily becomes possible once αt is suﬃciently high.
Such an example is illustrated in Figure 2. The dashed line represents the payoﬀ of the marginal
agent in period 1. Its intersection with the horizontal axis defines θ1∗ < θ∞ . The payoﬀ of the
marginal agent in period 2 is represented by the dotted line, and that in period 3 by the solid line.
Clearly, α2 is low enough that no attack is possible in period 2. In contrast, α3 is high enough that
a new attack is possible. There thus exist at least three equilibria in this example: one in which
θt∗ = θ1∗ for all t, another in which θ2∗ = θ1∗ and θt∗ = θ30 for all t ≥ 3, and a third in which θ2∗ = θ1∗
and θt∗ = θ300 for all t ≥ 3, where θ30 and θ300 correspond to the two intersections of the solid line with
the horizontal axis.

                                                      11
     In the example of Figure 2, both θ30 and θ300 are lower than θ∞ . By Lemma 2, then, a third attack
also becomes possible at some future date. More generally, if z is suﬃciently high, any solution
to (6) is bounded from above by θ∞ in all periods, which ensures that a new attack eventually
becomes possible after any unsuccessful one. Hence, for z suﬃciently high, not only there are
multiple equilibria, but any arbitrary number of attacks can be sustained in equilibrium.

Theorem 1 (Multiplicity) There exist thresholds z ≤ z ≤ z such that:
     (i) If z ≤ z, there is a unique monotone equilibrium and an attack occurs only in period one.
     (ii) If z ∈ (z, z), there are at most finitely many monotone equilibria and there exists t̄ < ∞
such that no attack occurs after period t̄.
     (iii) If z > z, there are infinitely many equilibria; if in addition z > z, for any t and N, there
is an equilibrium in which N attacks occur after period t.
     Finally, z = z = z when c ≤ 1/2, whereas z ≤ z < z when c > 1/2.


     Proof. Recall that θ1∗ = θ̂1 and, for all t ≥ 2, θt∗ < θ̂t , where θ̂t = θ̂ (αt , β, z) is the unique
solution to U (θ̂, −∞, αt , β, z) = 0. As we show in Lemma A1 in the Appendix, there exist thresholds
z ≤ z ≤ z (possibly functions of α1 and β) with the following properties: θ̂t ≤ θ̂1 for all t if z ≤ z;
θ̂1 ≤ (≥) θ∞ if and only z ≥ (≤) z; and θ̂t < θ∞ for all t if and only if z > z.
     (i) Consider first z ≤ z. Then, θ̂t ≤ θ̂1 = θ1∗ for all t, and hence, by part (ii) of Lemma 2, (6)
admits no solution at any t ≥ 2. The unique monotone equilibrium is thus θt∗ = θ1∗ for all t.
     (ii) Next, consider z ∈ (z, z), in which case θ̂1 = θ1∗ > θ∞ , but we can not rule out the
possibility that there exists a period t ≥ 2 such that θ̂t > θ̂1 and U (θ∗ , θ1∗ , αt , β, z) = 0 admits a
                               ∗
solution. Nevertheless, since θt−1 ≥ θ1∗ > θ∞ for all t, by part (iii) of Lemma 2 and the fact that
αt → ∞ as t → ∞, there exists t̄ < ∞ such that (6) admits no solution for t ≥ t̄. Moreover, since
U is single-peaked, (6) has at most two solutions for t < t̄. Hence, there are at most finitely many
monotone equilibria, and in any equilibrium no attack occurs after period t̄.
     (iii) Finally, consider z > z, in which case θ1∗ < θ∞ . Then, by part (iv) of Lemma 2, there exists
a t0 < ∞ such that U (θ∗ , θ1∗ , αt , β, z) = 0 admits a solution for all t ≥ t0 . Hence, for any t ≥ t0 ,
there is an equilibrium in which θτ∗ = θ1∗ for τ < t, θt∗ solves U (θt∗ , θ1∗ , αt , β, z) = 0, and θτ∗ = θt∗ for
all τ > t. That is, there exist (countably) infinitely many equilibria, indexed by the time at which
the second attack occurs.
     When z ∈ (z, z), the second attack may lead to a threshold θt∗ > θ∞ , in which case a third
attack might be impossible. If however z > z, then θ̂t < θ∞ for all t, and hence by part (ii) of
Lemma 2, θt∗ < θ∞ , for all t. But then by part (iv), a new attack eventually becomes possible after
any unsuccessful one. It follows that, for any t ≥ 1 and any N ≥ 1, there exist increasing sequences
{t2 , ..., tN } and {θ2 , ..., θN }, with t2 ≥ t, such that U (θ2 , θ1∗ , αt2 , β, z) = 0, U (θ3 , θ2 , αt3 , β, z) = 0,
and so on. The following is then an equilibrium: θτ∗ = θ1∗ for τ < t2 , θτ∗ = θj for τ ∈ {tj , ..., tj+1 − 1}

                                                          12
and j ∈ {2, ..., N − 1}, and θτ∗ = θN for τ ≥ tN . That is, for any t ≥ 1 and any N ≥ 1, there exists
an equilibrium in which N attacks occur after date t.

       The existence of infinitely many equilibria in the case z > z relies on the assumption that the
game continues forever as long as the status quo is in place: if the game ended for exogenous reasons
at a finite date, there would exist only finitely many equilibria. Nevertheless, as long as z > z and
αt → ∞ as t → ∞, then, for any M, there exists a finite T such that the game would have at least
M equilibria if it ended at date T . Moreover, even if T = 2, α2 high enough suﬃces for the game to
have multiple equilibria when z > z. Finally, as we show in Section 6.1, the introduction of public
signals ensures the existence of multiple equilibria for any T ≥ 2 and any z.
       In the remainder of this section, we identify equilibrium properties that may turn useful in
understanding crises phenomena.

Corollary 1 Suppose θ > θ∞ and z > z. The status quo survives in any equilibrium. Neverthe-
less, there exists t < ∞ such that, at any t ≥ t, an attack is possible, yet need not take place.
Furthermore, any arbitrary number of attacks can occur.

       This seems to square well with the common view that economic fundamentals may help predict
eventual outcomes (e.g., whether a currency is eventually devalued) but not when a crisis will occur
or whether attacks will cease. On the contrary, this view is inconsistent with the common-knowledge
version of the model, in which case fundamentals fail to predict both the timing of attacks and the
eventual regime outcome,9 as well as with unique-equilibrium models like Morris and Shin (1999),
in which both the timing of attacks and the ultimate fate of the regime are uniquely pinned down
by fundamentals.
       Consider now how the dynamics of attacks depend on the dynamics of information.

Corollary 2 After the most aggressive attack for a given period occurs, the game enters a phase
of tranquillity, during which no attack is possible. This phase is longer the slower the arrival of
private information.

       Along with the property that for θ > θ∞ and z > z a new attack eventually becomes possible
after any unsuccessful one, the above result implies that dynamics may take the form of cycles in
which the economy alternates from phases of tranquillity to periods of crisis, eventually resulting
into a new attack, without any change in the underlying fundamentals. Once again, this would not
be possible either under common knowledge or with a unique equilibrium.



   9
       Of course, this is true provided θ ∈ [0, 1]. If instead θ ∈
                                                                 / [0, 1], fundamentals predict both the timing and the final
outcome, as for θ < 0 it is dominant to attack immediately and for θ > 1 it is dominant never to attack.


                                                              13
5    Unobservable shocks
In this section, we examine the possibility that the critical size of attack that triggers regime change
varies stochastically over time due to unobservable shocks. This is not only a realistic scenario,
but also an appropriate perturbation. In the model without shocks, the knowledge that the regime
is in place at t ≥ 2 makes it common certainty that θ > 0, which explains why there always exist
equilibria in which nobody attacks at t ≥ 2. In contrast, shocks may guarantee that a positive
measure of agents attack in every period by “smoothing out” the information generated by the
knowledge that the regime survived past attacks and ensuring the existence of a lower dominance
region in every period.
    We modify the game as follows. Agents continue to receive private signals about θ as in the
benchmark model, but the regime is now abandoned in period t if and only if At ≥ θ + δωt , where
δ ≥ 0 and ωt is a real random variable with continuous c.d.f. F, independent of θ and the noise in
the agents’ signals. ωt can be interpreted as a shock to the fundamentals (i.e., the strength of the
regime) and δ as the volatility of these shocks. Denoting with Γ (δ) the game in which the volatility
is δ, the baseline model can be nested as δ = 0.

    Equilibrium characterization with δ > 0. In the presence of shocks, the regime outcome
depends, not only on θ, but also on ωt . As a result, we loose the ability to characterize the set of
monotone equilibria in terms of a sequence of truncation points for θ. Nevertheless, we can still
characterize strategies as sequences of thresholds {x̄t }∞
                                                         t=1 such that an agent attacks in period t if
and only if xt ≤ x̄t , where x̄t ∈ R.
      Consider first the regime outcomes induced by a given {x̄t }∞   t=1 . The size of the attack in
                         ¡√            ¢
period t is At (θ) = Φ αt (x̄t − θ) and hence the status quo is abandoned if and only if ωt ≤
                  £ ¡√           ¢   ¤
ω̄t (θ; x̄t , δ) ≡ Φ αt (x̄t − θ) − θ /δ. It follows that the probability of regime change in period t
conditional on θ and given that agents use monotone strategies with threshold x̄t , is

                                        pt (θ; x̄t , δ) = F (ω̄t (θ; x̄t , δ)) .
                               ¡            ¢
    Next, for any t ≥ 2, let ψt θ; x̄t−1 , δ denote the density of the common posterior about θ,
when in previous periods agents followed monotone strategies with thresholds x̄t−1 = {x̄1 , ..., x̄t−1 }.
By Bayes’ rule,
                                                 ¡             ¢
  ¡ t−1 ¢          [1 − pt−1 (θ; x̄t−1 , δ)] ψt−1 θ; x̄t−2 , δ             Πt−1 [1 − ps (θ; x̄s , δ)] ψ1 (θ)
ψt θ; x̄ , δ = R +∞                                                  = R +∞ s=1
                                                                             t−1
                                0                    0 t−2 , δ) dθ 0                       0                 0    0
                −∞ [1 − pt−1 (θ ; x̄t−1 , δ)] ψt−1 (θ ; x̄              −∞ Πs=1 [1 − ps (θ ; x̄s , δ)] ψ1 (θ ) dθ
                √     √
where ψ1 (θ) =     βφ( β (θ − z)) is the density of the initial prior. We similarly denote the density
                                                 ¡            ¢
of the corresponding private posteriors with ψt θ|x; x̄t−1 , δ for t ≥ 2 and ψ1 (θ|x) for t = 1.
                                                                       t          ¡      ¢
     Finally, consider payoﬀs. For any t ≥ 1, x ∈ R, and x̄t ∈ R , define vt x; x̄t , δ as the net
expected payoﬀ from attacking in period t for an agent with suﬃcient statistic x when all other

                                                          14
agents attack in period τ ≤ t if and only if their suﬃcient statistic in τ is less than or equal to x̄τ :
                                       Z +∞
                         ¡          ¢                         ¡              ¢
                       vt x; x̄t , δ =      pt (θ; x̄t , δ) ψt θ|x; x̄t−1 , δ dθ − c.
                                                −∞
            ¡          ¢
Note that vt x; x̄t , δ depends on both the contemporaneous threshold x̄t and the sequence of past
thresholds x̄t−1 ; the former determines the probability of regime change conditional on θ, whereas
                                                                                                        t
the latter determines the posterior beliefs about θ. Next, for               any t ≥ 1 and x̄t ∈ R , let
                                     ⎧                     ¡        ¢
                                     ⎪
                                     ⎪  limx→+∞ vt x; x̄t , δ                 if x̄t = +∞
                           ¡      ¢  ⎨     ¡             ¢
                        Vt x̄t ; δ ≡    vt x̄t ; x̄t , δ                      if x̄t ∈ R
                                     ⎪
                                     ⎪                     ¡        ¢
                                     ⎩ lim             v x; x̄t , δ           if x̄t = −∞
                                                     x→−∞ t

Vt is the analogue of the function U in the benchmark model: it represents the net payoﬀ from
attacking in period t for the marginal agent with threshold x̄t .10
                                                                    ¡       ¢
       In Lemma A2 in the Appendix, we prove that, for any δ > 0, Vt x̄t ; δ is continuous in x̄t for
              t−1
any x̄t ∈ R         × R, which we use to establish the existence, and complete the characterization, of
monotone equilibria.

Proposition 3 For any δ > 0, {at (·)}∞
                                     t=1 is a monotone equilibrium for Γ (δ) if and only if there
exists a sequence {x̄t }∞
                        t=1 such that:
       (i) for all t, at (·) = 1 if xt < x̄t and at (·) = 0 if xt > x̄t ;
       (ii) for t = 1, x̄1 ∈ R and V1 (x̄1 ; δ) = 0;
                                                  ¡       ¢                      ¡       ¢
       (iii) for any t ≥ 2, either x̄t = −∞ and Vt x̄t ; δ ≤ 0, or x̄t ∈ R and Vt x̄t ; δ = 0.
       An equilibrium exists for any δ > 0.

       Convergence to benchmark game.          We next consider the properties of the equilibrium
                                                            ¡√          ¢
set as δ → 0. Let θt (x̄t ) be the unique solution to θ = Φ αt (x̄t − θ) , with θt (−∞) = 0 and
                   ¡ ¢
θt (+∞) = 1, and θt x̄t = maxτ ≤t {θτ (x̄t )}. As δ → 0, the dependence of the regime outcome on
the shock ωt vanishes: for any x̄t and any θ 6= θt (x̄t ) ,
                                                         (
                                                                      1    if θ ≤ θt (x̄t )
                               pt (θ; x̄t , δ) → pt (θ; x̄t , 0) ≡                                                       (7)
                                                                      0    if θ > θt (x̄t )

It follows that the common posterior in any period t ≥ 2 converges pointwise to the truncated
                                                    ¡     ¢
Normal generated by the knowledge that θ > θt−1 x̄t−1 : for any x̄t−1 and any θ,
                                               ⎧                                     ¡      ¢
             ¡            ¢    ¡            ¢  ⎨ 0                        if θ ≤ θt−1 x̄t−1
           ψt θ; x̄t−1 , δ → ψt θ; x̄t−1 , 0 ≡      √    √
                                                      βφ( β(θ−z))                             (8)
                                               ⎩     √                    otherwise
                                                 1−Φ( β(θt−1 (x̄t−1 )−z))

  10
    Since the distribution of x given θ satisfies the MLRP and pt (θ; x̄t , δ) is decreasing in θ, by standard representation
                                ¡        ¢
theorems (Milgrom, 1981), vt x; x̄t , δ is decreasing in x. Since vt is also bounded in [−c, 1 − c], it follows that
            ¡        ¢                      t                ¡      ¢
limx→±∞ vt x; x̄t , δ exist for any x̄t ∈ R and therefore Vt x̄t , δ is well-defined at x̄t = ±∞.


                                                             15
                                         ¡              ¢    ¡              ¢
Similarly, for the private posteriors, ψt θ|x; x̄t−1 , δ → ψt θ|x; x̄t−1 , 0 for any x.
       The pointwise convergence of pt and ψt in turn implies pointwise convergence of the payoﬀ
of the marginal agent except when t ≥ 2 and x̄t = −∞. In particular, for t = 1 and any x̄1 ,
V1 (x̄1 ; δ) → V1 (x̄1 ; 0) ≡ U (θ1 (x̄1 ) , −∞, α1 , β, z) ; and, for any t ≥ 2, any x̄t−1 and any x̄t > −∞,
                              ¡       ¢    ¡       ¢   ¡                ¡     ¢           ¢
                            Vt x̄t ; δ → Vt x̄t ; 0 ≡ U θt (x̄t ) , θt−1 x̄t−1 , αt , β, z .
                    ¡       ¢                       ¡       ¢
To understand why Vt x̄t ; δ need not converge to Vt x̄t ; 0 = −c when t ≥ 2 and x̄t = −∞, note
that, in the presence of shocks, an agent with suﬃciently low xt may attach probability higher
than c to regime change in period t ≥ 2 even if he expects no other agent to attack in that period.
When this is the case, a positive measure of agents may attack in every period in the perturbed
game, unlike the benchmark model. Nevertheless, the pointwise convergence of Vt for any x̄t > −∞
ensures that this dominance region vanishes as δ → 0.
       More generally, we can prove that “essentially” all equilibria {x∗t }∞
                                                                            t=1 in the benchmark game
Γ(0) can be approximated by equilibria {x̄t (δ)}∞
                                                t=1 in the perturbed game Γ (δ) for δ > 0 small
enough.11 The qualification “essentially” is needed because convergence may fail in the knife-edge
             ¡       ¢                                               ¡                 ¢
case where Vt x∗t ; 0 reaches its maximum at x∗t (or equivalently U θt∗ , θt−1
                                                                           ∗ , α , β, z reaches its
                                                                                t
maximum at θt∗ ).

Theorem 2 (Shocks in fundamentals) For any ε > 0, and any T ≥ 1, there exists δ (ε, T ) > 0
such that, for all δ < δ (ε, T ) , the following is true:
                                                                        ¡          ¢
       For any equilibrium {x∗t }∞                       ∗ / arg max V x∗t−1 , x; 0 for all t ∈ {2, ..., T },
                                 t=1 of Γ (0) such that xt ∈        x t
there exists an equilibrium {x̄t (δ)}∞                                               ∗
                                     t=1 of Γ (δ) such that, for all t ≤ T, either |xt − x̄t (δ)| < ε, or
x∗t = −∞ and x̄t (δ) < −1/ε.

       The above establishes convergence of equilibrium play in the first T periods of the infinite-
horizon game, for any finite T . Since δ (ε, T ) may converge to 0 as T → ∞, the result need not
hold for an infinite number of periods. Of course, if the game ended for exogenous reasons at T,
the above would immediately imply convergence in all periods of the finite-horizon game.
       The result is illustrated in Figures 3 and 4 for T = 2. The solid line in Figure 3 repre-
sents the p.d.f. of the common posterior in period 2 generated by equilibrium play in period 1
in the game without shocks (δ = 0). This is simply the initial prior truncated at θ1∗ = θ1 (x∗1 ),
where x∗1 is the unique solution to V1 (x∗1 ; 0) = 0 (or equivalently where θ1∗ is the unique solu-
tion to U (θ1∗ , −∞, α1 , β, z) = 0). The other two lines represent the equilibrium common poste-
riors ψ2 (θ; x̄1 (δ) , δ) for the game with shocks (δ > 0), where x̄1 (δ) is the unique solution to
V1 (x̄1 (δ) ; δ) = 0; the dotted line corresponds to a relatively high δ and the dashed one to a low
  11
       Clearly, Proposition 3 applies also to the unperturbed game: {x∗t }∞
                                                                          t=1 is a monotone equilibrium of Γ (0) if and
only it satisfies (ii) − (iii) for δ = 0.


                                                           16
                                     ψ2




                                                                                                      θ
                                      0                             1


                               Figure 3: Common posteriors with and without shocks.


                             V2
                        1− c




                         0                                                                             x2
                                −∞                                                               +∞



                         −c


                       Figure 4: Payoﬀ of the marginal agent with and without shocks.



δ. Since the support of ωt is the entire real line, the probability of regime change is less than 1 for
any θ and therefore ψ2 assigns positive probability to all θ. However, as δ becomes smaller, x̄1 (δ)
converges to x∗1 and the probability of regime change converges to 1 for θ < θ1∗ and to 0 for θ > θ1∗ .
By implication, the smooth common posterior of the perturbed game in period 2 converges to the
truncated one of the benchmark model.
      In Figure 4, the solid line represents the payoﬀ V2 (x∗1 , x2 ; 0) of the marginal agent in period
2 for δ = 0, whereas the other two lines represent V2 (x̄1 (δ) , x2 ; δ) for δ > 0.12 Note that, for
x2 small enough, V2 is negative when δ = 0 but positive when δ > 0, which implies that nobody
attacking in period 2 is part of an equilibrium in the benchmark model but not in the game with

 12
      In order to illustrate V2 over its entire domain, the figure depicts V2 (x̄1 (δ) , x2 ; δ) against Φ (x2 ) rather than x2 .


                                                               17
shocks.13 Moreover, when δ is high (dotted line), V2 is monotonic in x2 and therefore has a single
intersection with the horizontal line, in which case the equilibrium would be unique if the game
ended in period 2. When, instead, δ is suﬃciently small (dashed line), V2 is non-monotonic and
has three intersections, which correspond to three diﬀerent equilibria for the two-period game with
shocks. Finally, the middle and the highest intersections approximate the two intersections of the
solid line, while the lowest intersection is arbitrarily small, thus approximating x∗2 = −∞. Along
with the fact that x̄1 (δ) converges to x∗1 , this implies that any equilibrium of the two-period game
without shocks can be approximated by an equilibrium in the perturbed game.
         In conclusion, what sustains multiplicity in the dynamic game is the non-monotonicity of the
payoﬀ of the marginal agent generated by the knowledge that the regime survived past attacks.
That this knowledge resulted in posterior beliefs that assign zero measure to suﬃciently low θ in
the benchmark model, is not essential.



6         Public news and signals about past attacks

In this section, we consider two extensions of the information structure assumed in the benchmark
model.


6.1         Exogenous public signals

To capture the eﬀect of public news, we now modify the game as follows. In addition to their private
signals, agents observe in each period t ≥ 1 a public signal z̃t = θ + εt , where εt is common noise,
normally distributed with zero mean and precision ηtz > 0, serially uncorrelated, and independent
of θ and the agent’s private noise. These signals may represent, for example, the information
generated by news analysis in the media, publication of government statistics, or announcements
by policy makers. We also allow for the possibility that the game ends for exogenous reasons at a
finite date and denote the horizon of the game with T, where T ∈ {2, 3, ...} or T = ∞.
         The common posterior about θ conditional on z̃ t ≡ {z̃τ }tτ =1 is Normal with mean zt and
precision βt , where
                                              βt−1       ηz
                                       zt =        zt−1 + t z̃t ,   βt = βt−1 + ηtz ,
                                               βt        βt
with (z0 , β0 ) = (z, β). However, since equilibrium play in past periods now depends on the realiza-
tions of past public signals, zt is not a suﬃcient statistic conditional on Rt = 0. We thus allow
agents to condition their actions on the entire sequence z̃ t , or equivalently on z t ≡ {zτ }tτ =1 . Apart
    13
         In the examples in Figures 3 and 4, an agent finds it optimal to attack in period 2 for suﬃciently low x2 , even
if he expects no other agent to attack. However, this need not be the case if ωt had a bounded support and δ were
small enough.


                                                             18
from this modification, the set of monotone equilibria can be constructed in a similar way as in the
benchmark model.

Proposition 4 {at (·)}Tt=0 is a monotone equilibrium if and only if there exists a sequence of func-
tions {x∗t , θt∗ }Tt=1 , with x∗t : Rt → R and θt∗ : Rt → (0, 1) , such that:
                                            ¡ ¢                             ¡ ¢
    (i) for all t, at (·) = 1 if xt < x∗t z t and at (·) = 0 if xt > x∗t z t ;
       (ii) at t = 1, θ1∗ (z1 ) solves U (θ1∗ , −∞, α1 , β1 , z1 ) = 0 and x∗1 (z1 ) = X(θ1∗ (z1 ) , α1 )
                                   ¡ ¢
       (iii) at t ≥ 2, either θt∗ z t solves
                                                 ¡                         ¢
                                                U θt∗ , θt−1
                                                         ∗
                                                             , αt , βt , zt = 0                                 (9)
       ¡ ¢         ¡ ¢                ¡ ¢         ¡ t−1 ¢        ¡ ¢
and x∗t z t = X(θt∗ z t , αt ), or θt∗ z t = θt−1
                                              ∗    z      and x∗t z t = −∞.

     Like in the benchmark model without public news, there always exist equilibria in which attacks
                                                          ¡ ∗           ¢
cease after any arbitrary period. However, for any θt−1        , αt , βt , (9) admits a solution if and only
                            ¡ ∗            ¢
if zt ≤ z̄t , where z̄t = z̄ θt−1 , αt , βt is always finite. Hence, there also exist equilibria in which
an attack occurs in period t for suﬃciently low realizations of zt . The following then extends and
reinforces the multiplicity result of Theorem 1.

Theorem 3 (Public news) In the game with public news, there always exist multiple equilibria,
no matter the mean z of the prior, the precisions {αt , βt }Tt=1 of private and public information, and
the horizon T of the game.

       Consider now how the introduction of public news aﬀects the ability of an “econometrician”
to predict the regime outcome and/or the occurrence of an attack in any given period. For any
                            ∗
t, any θ ∈ (0, 1), and any θt−1 < θ, (9) admits a solution higher than θ if and only if zt is low
enough, implying that, conditional on θ, the probability that the status quo is abandoned in any
given period is strictly between 0 and 1. It follows that an econometrician who can observe θ but
can not observe z t , necessarily faces uncertainty about the event of regime change. On the other
hand, if he also knows z t , he may be able to perfectly predict the regime outcome in a given period
for some combinations of θ and z t , without, however, being able to predict whether an attack will
                                                     ¡ ¢
take place. For example, at any t ≥ 2, if θ > θ̄t z t > θ1 (z1 ), where θ1 (z1 ) is the lowest solution
                                         ¡ ¢
to U (θ∗ , −∞, α1 , β1 , z1 ) = 0 and θ̄t z t the highest solution to U (θ∗ , θ1 (z1 ) , αt , βt , zt ) ,14 there is
no equilibrium in which the status is abandoned in period t, but there are both an equilibrium in
which an attack occurs and one in which no attack takes place in that period. The combination of
fundamentals and public information may help predict regime outcomes but not the occurrence of
attacks, like in the benchmark model.
  14          ∗
                  ¡ t−1 ¢                                   ¡ ¢                           ¡ ¢
       Since θt−1  z      ≥ θ1 (z1 ) in any equilibrium, θ̄t z t is an upper bound for θt∗ z t .


                                                              19
                                                                                                ∗ .
      Finally, note that the threshold z̄t , below which (9) admits a solution, decreases with θt−1
Hence, an unsuccessful attack, other things equal, causes a discrete increase in the probability the
game enters a phase of inaction during which no attack is possible. In this sense, the prediction of
the benchmark model that equilibrium dynamics are characterized by the alternation of phases of
tranquility and phases of crises, survives the introduction of public news, but the transition from
one phase to another is now stochastic, as it depends on the realization of z t .

6.2      Signals about past attacks

We now introduce an additional source of information by allowing agents to receive private and
public signals about the size of past attacks. These signals are, respectively,

                             X̃it = S (At−1 , uit )   and Z̃t = S (At−1 , υt ) ,

for t ≥ 2, where uit is idiosyncratic noise, υt is common noise, and S : [0, 1] × R → R. To
preserve Normality of the information structure, we adopt a similar specification as Dasgupta
(2002): S (A, u) = Φ−1 (A) + u, uit ∼ N (0, 1/γtx ) , and υt ∼ N (0, 1/γtz ) .
                                                                      √        ¡ ¢
    Using the property that in any monotone equilibrium At−1 = Φ( αt−1 x∗t−1 − θ ) — where x∗t−1
may depend on exogenous/endogenous public signals — and following similar steps as in Section 3,
we can again construct suﬃcient statistics xt and zt with precisions αt and βt such that
                                                         ³                            ´
                                                                         βt
                        θ|(x̃t , z̃ t , X̃ t , Z̃ t ) ∼ N αtα+β
                                                              t
                                                                t
                                                                  xt +       z ,   1
                                                                       αt +βt t αt +βt .

The only diﬀerence is that these statistics are now defined by
                                                               n                  o
                                        ηtx      1t−1 αt−1 γtx
                      xt = ααt−1
                              t
                                 xt−1 + αt tx̃ +      αt         x ∗
                                                                   t−1 − √  1
                                                                           αt−1 t ,
                                                                               X̃
                                                               n                  o
                                        ηtz      1t−1 αt−1 γtz
                       zt = βt−1 z
                             βt t−1   + βt tz̃ +      βt        x ∗
                                                                  t−1  − √ 1
                                                                          αt−1 t ,
                                                                               Z̃

                 αt = αt−1 + ηtx + 1t−1 αt−1 γtx      and   βt = βt−1 + ηtz + 1t−1 αt−1 γtz ,

where 1t is an indicator variable that takes value 1 if an attack occurrs at t (At > 0) and 0 otherwise.
      Although the realizations of (xt , zt ) and similarly the dynamics of (αt , βt ) are now partly
endogenous, the equilibrium characterization is otherwise the same as in the model with only
exogenous signals. By implication, the multiplicity results extend to the game with signals about
past attacks. Similarly, the structure of equilibrium dynamics remains as in the benchmark model,
except for the property that an unsuccessful attack does not necessarily reduce the incentives for
further attacks. This is because an unsuccessful attack now also generates new private and public
signals, which in some cases may oﬀset the impact of the knowledge that the status quo is still in
place.
      To see this, consider the case where all signals are private (γtx > 0, ηtx ≥ 0, γtz = ηtz = 0) , in
which case the only novel eﬀect is that an unsuccessful attack leads to an endogenous increase in

                                                      20
αt . A further attack is then possible only if this increase is large enough, like in the benchmark
game. On the other hand, when the endogenous signal is public (γtz > 0 = γtx ), a new attack
becomes possible if this signal is low enough, like in the case with exogenous public news.
    We conclude that signals about the size of past attacks may substitute for the exogenous arrival
of private and/or public information, but do not otherwise aﬀect the analysis.


7    Conclusion
This paper examined how the dynamics of information influences the dynamics of coordination in
a global game of regime change. We found that dynamics may sustain multiple equilibria under
the same informational assumptions that guarantee uniqueness in the static benchmark examined
in the literature.
    Although the model is highly stylized and abstracts from all sorts of institutional details and
intertemporal payoﬀ linkages, it generates a few distinctive predictions for equilibrium dynamics,
such as the possibility that fundamentals predict regime outcomes but not the timing and number
of attacks, or the succession of phases of tranquility, during which agents accumulate information
and no attacks are possible, and periods of crises, during which attacks may occur but do no
necessarily take place. These predictions may help understand the dynamics of crises phenomena
such as currency attacks, financial crashes, or political change. Extending the analysis to these
applications is a promising line for future research.




Appendix
    Proof of Proposition 1. Solving (1) for x̂ gives x̂ = θ̂ + α−1/2 Φ−1 (θ̂). Substituting this into
(2) gives a single equation in θ̂ :           ³           ´
                                          U st θ̂; α, β, z = 0,                                 (10)
where                                            ³          h                         i´
                                                      √
                     U st (θ; α, β, z) ≡ 1 − Φ       √ α     Φ−1 (θ) +   √β    (z − θ) − c.     (11)
                                                      α+β                  α

Note that U st (θ; ·) is continuous and diﬀerentiable in θ ∈ (0, 1), with limθ→0 U st (θ) = 1 − c > 0
and limθ→1 U st (θ) = −c < 0. A solution to (10) therefore always exists. Next, note that
             ∂U st (θ; .)      √    ³ √ h                        i´ h                  i
                                 α      α
                          = − √α+β φ √α+β   Φ−1 (θ) + √βα (z − θ)         1
                                                                      φ(Φ−1 (θ))
                                                                                 − √β
                                                                                     α
                                                                                         .
                   ∂θ
                 £    ¡        ¢¤ √
Since minθ∈(0,1) 1/φ Φ−1 (θ) = 2π, the condition α ≥ β 2 / (2π) is both necessary and suﬃcient
for U st to be monotonic in θ, in which case the monotone equilibrium is unique. Finally, for

                                                       21
the proof that only this equilibrium survives iterated deletion of strictly dominated strategies, see
Morris and Shin (2000, 2001).

    Proof of Lemma 1. We prove the claim by induction. At t = 1, the result necessarily holds
since in any equilibrium, the agents’ strategy for t = 1 is the same as in the static benchmark.
Consider next any t ≥ 2 and suppose that the result holds for any τ ≤ t − 1. Since at (·) is
non-increasing in x̃t , At (θ) is non-increasing in θ, implying that either At (θ) < θ (and therefore
                       ∗ , in which case θ ∗ = θ ∗ , or there exists θ ∗ > θ ∗
Rt+1 = 0) for all θ > θt−1                t     t−1                   t     t−1 such that At (θ) < θ if
and only if θ > θt∗ . In the former case, Pr(Rt+1 = 1|xt , Rt = 0) = 0 for all xt and hence x∗t = −∞.
In the latter,
                                                                        ³√        h                 i´
                                                                                    αt xt +βz     ∗
                                      ¡                       ¢       Φ   α t + β    αt +β    − θ t
     Pr(Rt+1     = 1|xt , Rt = 0) = Pr θ ≤ θt∗ |xt , θ > θt−1
                                                          ∗
                                                                = 1 − ³√         h                   i´ ,
                                                                     Φ   αt + β αtαxtt+β+βz     ∗
                                                                                             − θt−1

which is strictly decreasing in xt and converges to 1 as xt → −∞ and to 0 as xt → +∞, implying
that there exists x∗t ∈ R such that Pr(θ ≤ θt∗ |xt , θ > θt−1
                                                          ∗ ) ≥ (≤)c if and only if x ≤ (≥)x∗ . In
                                                                                     t      t
either case, At (θ) < 1 for all θ and hence θt∗ < 1, which together with θt∗ ≥ θ1∗ > 0, implies that
θt∗ ∈ (0, 1) for all t, which completes the proof.

    Proof of Proposition 2. Necessity follows from the arguments in the main text. For suﬃ-
ciency, take any sequence {x∗t , θt∗ }∞                                                  ∗
                                      t=1 that satisfies conditions (ii) and (iii); let θ0 = −∞; suppose
                                                                                       ∗ , for all t ≥ 1;
all other agents follow strategies as in (i), in which case Rt = 0 if and only if θ > θt−1
and consider the best response for an individual agent. If θt∗ = θt−1
                                                                  ∗ , in which case t ≥ 2, θ ∗
                                                                                             t−1 > 0
     ∗
                                                  ¡      ∗          ∗
                                                                       ¢
and xt = −∞, then Pr (Rt+1 = 1|xt , Rt = 0) = Pr θ ≤ θt |xt , θ > θt−1 = 0 for all xt and therefore
                                                                         ¡                 ¢
not attacking is indeed optimal. If instead θt∗ > θt−1
                                                   ∗ , in which case U θ ∗ , θ ∗ , α , β, z = 0 and
                                                                           t t−1    t
x∗t = X (θt∗ , αt ) , then, by the monotonicity of the private posterior and the definitions of X(·) and
         ¡                       ¢             ¡                 ¢
U (·), Pr θ ≤ θt∗ |xt , θ > θt−1
                              ∗    − c ≥ (≤)U θt∗ , θt−1
                                                     ∗ , α , β, z if and only if x ≤ (≥) X (θ ∗ , α ) and
                                                          t                       t            t   t
therefore it is indeed optimal to attack for xt < x∗t and not to attack for xt > x∗t .

    Proof of Lemma 2. Part (i) follows directly by inspecting U.
                         ¡                  ¢
    For (ii), note that U θ∗ , θt−1
                                ∗ , α , β, z < U (θ ∗ , −∞, α , β, z) for all θ ∗ (since θ ∗
                                     t                       t                            t−1 > −∞) and
that U (θ∗ , −∞, αt , β, z) = U st (θ∗ , αt , β, z) is strictly decreasing in θ∗ (since αt ≥ β 2 / (2π)). It
               ¡                  ¢
follows that U θ∗ , θt−1
                      ∗ , α , β, z < 0 for all θ ∗ ≥ θ
                            t
                                                         bt , which gives the result.
                         ∗
    For (iii), take any θt−1 > θ∞ . Note that for all θ∗ ∈ [θt−1
                                                             ∗ , 1], lim        ∗
                                                                        α→∞ U (θ , −∞, α, β, z) =
θ∞ − θ∗ < 0. Since U (θ∗ , −∞, α, β, z) is continuous in θ∗ and [θt−1
                                                                  ∗ , 1] is compact, it follows that

there exists α such that, for any α > α, U (θ∗ , −∞, α, β, z) < 0 for all θ∗ ∈ [θt−1∗ , 1]. Moreover, for
         ¡                ¢                                  ¡ ∗ ∗            ¢
all α, U θ∗ , θt−1
               ∗ , α, β, z = −c < 0 for θ ≤ θ ∗                                        ∗
                                               t−1 and U θ , θt−1 , α, β, z < U (θ , −∞, α, β, z) for
                                            ¡                   ¢
θ∗ > θt−1
       ∗ . It follows that, for any α > α, U θ ∗ , θ ∗ , α, β, z < 0 for all θ ∗ and therefore (6) admits
                                                    t−1
no solution.

                                                      22
                             ∗
                                                          ¡                ¢
    For (iv), take any θt−1      < θ∞ . Since limα→∞ U θ∗ , θt−1∗ , α, β, z = θ − θ ∗ > 0 for any θ ∗ ∈
                                                                               ∞
                                ¡ ∗        ¢                                   ¡                  ¢
(θt−1 , θ∞ ), there exist θ ∈ θt−1 , θ∞ and α such that, for any α > α, U θ0 , θt−1
  ∗                        0                                                         ∗ , α, β, z > 0. By
                       ¡                  ¢                                   ¡ ∗ ∗              ¢
the continuity of U θ∗ , θt−1  ∗ , α, β, z in θ ∗ and the fact that lim ∗
                                                                        θ →1 U θ , θt−1 , α, β, z = −c, it
follows then that (6) admits a solution for αt > α.
                                       ∗ , α
    Finally, consider (v). Fix t ≥ 2, θt−2                                                ∗
                                             t−1 , β, and z (where we use the convention θ0 =
−∞) and suppose that θt−1    ∗    is the highest solution to (6) for period t − 1, which means that
 ¡ ∗ ∗                  ¢
U θ , θt−2 , αt−1 , β, z < 0 for all θ∗ > θt−1
                                           ∗ . This, together with the properties that U (θ ∗ , θ , α, β, z)
                                                                                                 −1
is non-increasing in θ−1 , continuous in θ∗ , and equal to −c for θ∗ ≤ θ−1 , implies that there ex-
                          ¡                    ¢
ists ∆ > 0 such that U θ∗ , θt−1∗ ,α                          ∗
                                     t−1 , β, z < −∆ for all θ ∈ [0, 1]. Furthermore, by continu-
ity of U in (θ∗ , α) , there exists α > αt−1 such that U (θ∗ , ·, α, ·) is uniformly continuous over
                                                                                   ¡                 ¢
[0, 1] × [αt−1 , α]. This also implies that there exists α ∈ (αt−1 , α) such that U θ∗ , θt−1
                                                                                          ∗ , α, β, z < 0

for all α ∈ [αt−1 , α) and all θ∗ ∈ [0, 1], which proves that (6) admits no solution in any period τ > t
for which ατ < α.

Lemma A1 There exist thresholds z ≤ z ≤ z such that: θ̂t ≤ θ̂1 for all t if z ≤ z; θ̂1 ≤ (≥) θ∞ if
and only z ≥ (≤) z; and θ̂t < θ∞ for all t if and only if z > z. These thresholds satisfy z = z = z
when c ≤ 1/2 and z ≤ z < z when c > 1/2.
                         ¡           ¢
   Proof. For any α ≥ α1 ≥ β 2 / (2π) , let θ̂ = θ̂ (α, β, z) be the unique solution to U (θ̂, −∞, α, β, z) =
0 (i.e., the static equilibrium threshold) and
                                              √      √
                            z̃ (α, β) ≡ θ∞ + α+β−β
                                                     α −1
                                                      Φ (θ∞ ) ,
                                          ³ √           ´
                                             α    −1
                            ẑ (α, β) ≡ Φ  √
                                            α+β
                                                             1
                                                Φ (θ∞ ) + √α+β  Φ−1 (θ∞ ) .

The threshold z̃ (α, β) is defined by U (θ∞ , −∞, α, β, z̃ (α, β)) = 0 and is such that θ̂ ≥ (≤) θ∞ if
and only if z ≤ (≥) z̃. The threshold ẑ (α, β) , on the other hand, is defined so that ∂ θ̂/∂α ≥ (≤) 0
if and only if z ≥ (≤) ẑ. To simplify notation, we henceforth suppress the dependence of θ̂ on (β, z)
and of z̃ and ẑ on β.
    First, consider c = 1/2, in which case ẑ (α) = z̃ (α) = 1/2 for all α. When z < 1/2, θ̂ (α) > θ∞
and ∂ θ̂/∂α < 0 for all α ≥ α1 and therefore θ̂1 ≥ θ̂t > θ∞ for all t. When instead z = 1/2,
θ̂ (α) = θ∞ for any α ≥ α1 , and therefore θ̂1 = θ̂t = θ∞ for all t. Finally, when z > 1/2, for any
α ≥ α1 , θ̂ (α) < θ∞ and ∂ θ̂/∂α > 0, and hence θ̂1 ≤ θ̂t < θ∞ for all t. The result thus holds with
z = z = z = 1/2.
    Next, consider c < 1/2, in which case z̃ (α) and ẑ (α) are both decreasing in α, satisfy ẑ (α) >
z̃ (α) > θ∞ for all α, and converge to θ∞ as α → ∞. When z ≤ θ∞ , then clearly z < z̃ (α) < ẑ (α)
for all α and therefore θ̂ (α) is always higher than θ∞ and decreasing in α, which implies that
θ̂1 ≥ θ̂t > θ∞ for all t. When z ∈ (θ∞ , z̃ (α1 )), there are α00 > α0 > α1 such that z̃ (α0 ) = ẑ (α00 ) = z.
For α ∈ [α1 , α0 ), θ̂ (α) is higher than θ∞ and decreases with α. As soon as α ∈ (α0 , α00 ), θ̂ (α)
becomes lower than θ∞ and continues to decrease with α. Once α ≥ α00 , θ̂ (α) starts increasing with

                                                      23
α, but never exceeds θ∞ . Hence, θ̂1 > θ∞ and θ̂1 ≥ θ̂t for all t. When z = z̃ (α1 ) , θ̂1 = θ∞ ≥ θ̂t for
all t. Finally, when z > z̃ (α1 ) , θ̂ (α) < θ∞ for all α, and therefore θ̂t < θ∞ for all t. We conclude
that the result holds for c < 1/2 with z = z = z = z̃ (α1 ) .

       Finally, consider c > 1/2, in which case ẑ (α) and z̃ (α) are both increasing in α, satisfy
ẑ (α) < z̃ (α) < θ∞ , and converge to θ∞ as α → ∞.When z ≤ ẑ (α1 ) , then clearly z < ẑ (α) < z̃ (α)
for all α > α1 and therefore θ̂ (α) is always higher than θ∞ and decreasing in α, which implies
that θ̂1 ≥ θ̂t > θ∞ for all t. When z ∈ (ẑ (α1 ) , z̃ (α1 )), there is α0 > α1 such ẑ (α0 ) = z. For
α ∈ (α1 , α0 ), θ̂ (α) is higher than θ∞ and increasing in α, whereas for α > α0 , θ̂ (α) decreases
with α, converging to θ∞ from above. It follows that maxt≥1 θ̂t ≥ θ̂1 > θ∞ . When z = z̃ (α1 ) ,
maxt≥1 θ̂t ≥ θ̂1 = θ∞ . When z ∈ (z̃ (α1 ) , θ∞ ), there are α00 > α0 > α1 such that z̃ (α0 ) = ẑ (α00 ) = z.
For α ∈ (α1 , α0 ), θ̂ (α) is lower than θ∞ and increasing in α. For α ∈ (α0 , α00 ), θ̂ (α) is higher than
θ∞ and increases with α. And for α > α00 , θ̂ (α) decreases with α and asymptotes to θ∞ from above.
Hence, maxt≥1 θ̂t > θ∞ > θ̂1 . Finally, when z ≥ θ∞ , then clearly z > z̃ (α) > ẑ (α) for all α and
therefore θ̂ (α) is always lower than θ∞ , increases with α, and asymptotes θ∞ from below. Hence,
θ̂1 ≤ θ̂t < θ∞ for all t. We conclude that the result holds for c > 1/2 with z = ẑ (α1 ), z = z̃ (α1 ) ,
and z = θ∞ .

                                        ¡       ¢                                     t−1
Lemma A2 For any δ ≥ 0 and any t ≥ 2, Vt x̄t ; δ is continuous in x̄t for any x̄t ∈ R     × R,
and similarly V1 (x̄1 ; δ) is continuous in x̄1 for any x̄1 ∈ R.15

                                                                                                     ¡   ¢
    Proof. Consider first δ = 0, in which case V1 (x̄; 0) ≡ U (θ1 (x̄) , −∞, α1 , β, z) and Vt x̄t ; 0 ≡
  ¡               ¡     ¢           ¢
U θt (x̄t ) , θt−1 x̄t−1 , αt , β, z for t ≥ 2. Note that, for all t, θt (x̄t ) is continuous in x̄t ∈ R and
                                                                                     ¡ ¢
takes values in [0, 1]. Since the max operator is continuous, it follows that θt x̄t ≡ maxτ ≤t {θτ (x̄τ )}
                                 t
is also continuous in x̄t ∈ R and takes values in [0, 1]. Furthermore, U (θ, −∞, α, β, z) is continuous
                                                                                                            ¡       ¢
in θ ∈ [0, 1] and U (θ, θ−1 , α, β, z) is continuous in (θ, θ−1 ) ∈ [0, 1]2 . It follows that, for all t, Vt x̄t ; 0
                       t
is continuous in R .

       Consider next δ > 0. To simplify notation, we henceforth suppress the dependence of pt ,
vt and Vt on δ whenever there is no risk of confusion. For all t ≥ 1, the function pt (θ; x̄t ) =


  15                                  t                                                       t
       Continuity can be extended in R as follows. For any function f : A → R, where A ⊆ R and t ≥ 1, we say that
f is continuous over A if and only if, for any xt ∈ A and any ε > 0, there exists η > 0 such that, for any x̃t ∈ A such
that for all τ ≤ t: (a) |x̃τ − xτ | < η if xτ ∈ R; (b) x̃τ < −1/η if xτ = −∞; (c) x̃τ > 1/η, if xτ = +∞, the following
                  ¡ ¢                ¡ ¢       ¡ ¢               ¡ ¢                 ¡ ¢                  ¡ ¢
is true: (a’) if f xt ∈ R, then |f x̃t − f xt | < ε; (b’) if f xt = −∞, then f x̃t < −1/ε; (c’) if f xt = +∞,
        ¡ t¢
then f x̃ > 1/ε.
                                                                                                                     t
  Note that, if f : A → R, g : B → R, and q : C → R are continuous, respectively, in A, B and C, where A ⊆ R ,
      k                           2                                                ¡     ¢    ¡ ¡ ¢ ¡ ¢¢
B ⊆ R , and f (A) × g (B) ⊆ C ⊆ R , then the function w : A × B → R defined by w xt , xk = q f xt , g xk is
continuous in A × B.


                                                          24
    ¡£ ¡√           ¢     ¤ ¢
F     Φ αt (x̄t − θ) − θ /δ is continuous in (θ, x̄t ) ∈ R2 and strictly decreasing in θ. For t ≥ 2,
                                   ¡√               ¢ ¡                  ¢
              ¡       t−1
                           ¢      φ αt (x − θ) ψt θ; x̄t−1 , δ
          ψt θ|x; x̄ , δ = R +∞ ¡√                     ¢
                               −∞ φ     αt (x − θ0 ) ψt (θ0 ; x̄t−1 , δ) dθ0
                                                                 ³√          ³               ´´
                                                                                    αt x+βz
                                  Πt−1
                                    s=1 [1  − ps  (θ;  x̄ s )] φ    αt +   β  θ −    αt +β
                             =R                                   ³√          ³               ´´      .
                                +∞ t−1               0 ; x̄ )] φ                 0 − αt x+βz        0
                               −∞ Π s=1  [1 − p s (θ        s        α t +  β  θ        αt +β    dθ

                                                                                                                                t−1
The p.d.f. ψt — and similarly the c.d.f. Ψt — is thus continuous in θ ∈ R and (x, x̄t−1 ) ∈ R×R . It
                ¡             ¢  R +∞               ¡              ¢
follows that vt x; x̄t−1 , x̄t = −∞ pt (θ; x̄t ) dΨt θ|x; x̄t−1 , δ − c is continuous in (x, x̄t−1 , x̄t ) ∈
      t−1                                         ¡         ¢        ¡          ¢
R×R ×R.16 It is then immediate that Vt x̄t−1 , x̄t = vt x̄t ; x̄t−1 , x̄t is also continuous in
                     t−1
(x̄t−1 , x̄t ) ∈ R         ×R. Similarly, for t = 1, v1 (x; x̄1 ) is continuous in (x, x̄1 ) ∈ R2 and therefore
V1 (x̄1 ) is continuous in x̄1 ∈ R.

         Proof of Proposition 3. (To simplify notation, we again suppress the dependence of pt , vt
and Vt on δ whenever this does not create confusion.)
    Suﬃciency. Consider a sequence {x̄t (δ)}∞   t=1 that satisfies conditions (ii) and (iii) in the
                                     ¡    t
                                            ¢
proposition. The monotonicity of vt x; x̄ with respect to x (see proof of Lemma A2 above)
                                              t    ¡      ¢         ¡ ¢
guarantees that, for any x ∈ R and any x̄t ∈ R , vt x; x̄t ≥ (≤) Vt x̄t if and only if x ≤ (≥) x̄t .
It follows that the strategies defined by (i) − (iii) constitute a monotone equilibrium.
         Necessity. Conversely, suppose that {at (·)}∞
                                                     t=1 is a monotone equilibrium. Since in any such
equilibrium the measure of agents attacking in every period is decreasing in θ, the probability
of regime change is also decreasing in θ. Then, by standard representation theorems (Milgrom,
1981), the expected payoﬀ from attacking is decreasing in xt , implying that agents must follow
                                                                                         ¡ t¢
cut-oﬀ strategies. For {x̄t }∞
                             t=1 to be equilibrium cutoﬀs, it must be that, for all t, Vt x̄  = 0 if
                    ¡ t¢                          ¡ t¢
−∞ < x̄t < +∞, Vt x̄ ≤ 0 if x̄t = −∞, and Vt x̄ ≥ 0 if x̄t = +∞.
     We next show that, in any equilibrium, x̄t < +∞ for all t ≥ 1 and x̄1 > −∞. Indeed, if
                                      ¡          ¢                                          t−1
x̄t = +∞, in which case pt (θ; +∞) = F 1δ (1 − θ) , then, for any t ≥ 2, (x, x̄t−1 ) ∈ R × R , and
θ0 ∈ R,
                            Z   +∞
  ¡             ¢                        ¡1             ¢ ¡               ¢
vt x; x̄t−1 , +∞ =                   F       δ   (1 − θ) ψt θ|x; x̄t−1 , δ dθ − c
                              −∞
                            Z  θ0                                                Z   +∞
                                        ¡1          ¢ ¡               ¢                       ¡1          ¢ ¡               ¢
                       =            F    δ   (1 − θ) ψt θ|x; x̄t−1 , δ dθ +               F    δ   (1 − θ) ψt θ|x; x̄t−1 , δ dθ − c
                              −∞                                                  θ0
                           ¡                ¢   ¡ ¡        ¢¢ £      ¡                ¢¤
                       ≤ Ψt θ0 |x; x̄t−1 , δ + F 1δ 1 − θ0     1 − Ψt θ0 |x; x̄t−1 , δ − c,
    16
                    ¡     ¢                              R1
    Note that vt x; x̄t can also be written as 0 Fp (y; x, x̄t )dy, where Fp (y; x, x̄t ) is the (probability) measure of θ
                                                                                        ¡                           ¢
for which p(θ; x̄t ) > y, that is, Fp (y; x, x̄t ) = 0 if y = 1 and Fp (y; x, x̄t ) = Ψt p−1 (y; x̄t ) |x; x̄t−1 , δ if y ∈ [0, 1), where
p−1 (y; x̄t ) denotes the inverse of p(θ; x̄t ) with respect to θ. The continuities of p and Ψt then imply that Fp (y; x, x̄t )
                                         t−1
is continuous in (x, x̄t ) ∈ R × R
                               × R, for any y ∈ [0, 1]. Since Fp (y; ·) is also bounded from above by 1, from the
                                              R1
Dominated Convergence Theorem, it follows that 0 Fp (y; x, x̄t )dy is also continuous in (x, x̄t ).


                                                                    25
        ¡                ¢ R θ0  ¡              ¢
where Ψt θ0 |x; x̄t−1 , δ = −∞ ψt θ|x; x̄t−1 , δ dθ. Furthermore, since the knowledge that the sta-
tus quo survived past attacks causes a first-order-stochastic-dominance change in posterior beliefs,17
   ¡               ¢     ³√        ³              ´´                        ³√        ³              ´´
Ψt θ0 |x; x̄t−1 , δ ≤ Φ      αt + β θ0 − ααt x+βz
                                             t +β
                                                    . Along with lim x→+∞ Φ   α t + β  θ 0 − αt x+βz
                                                                                               αt +β    =
                                   ¡              ¢      ¡         ¢
0, this implies that limx→+∞ vt x; x̄t−1 , +∞ ≤ F 1δ (1 − θ0 ) − c. Since the latter is true for any
                                                        ¡         ¢
θ0 ∈ R, it is also true for θ0 → +∞, in which case F 1δ (1 − θ0 ) → 0. Together with the fact that vt is
                                                      ¡        ¢              ¡              ¢
bounded from below by −c, this implies that V x̄t−1 , +∞ = limx→+∞ vt x; x̄t−1 , +∞ = −c < 0
and hence x̄t = +∞ can not be part of any equilibrium. A similar argument rules out x̄1 = +∞.
Finally, suppose x̄1 = −∞. Then, for any x ∈ R and any θ0 ∈ R,
                          Z +∞
                                 ¡       ¢                   ¡     ¢ ¡ ¡    ¢¢
             v1 (x; −∞) =      F 1δ (−θ) ψ1 (θ|x) dθ − c ≥ Ψ1 θ0 |x F 1δ −θ0 − c,
                                       −∞
                          R θ0                                                                            ¡1          ¢
where Ψ1 (θ0 |x) =         −∞ ψ1 (θ|x) dθ,       and therefore limx→−∞ v1 (x; −∞) ≥ F                       δ   (−θ0 ) − c. Since this
is true also for θ0 → −∞, and since v1 is bounded from above by 1 − c, we have that V1 (−∞) =
limx→−∞ v1 (x; −∞) = 1 − c > 0, implying that x̄1 = −∞ can not be part of an equilibrium.
       We conclude that (i) − (iii) necessarily hold in any monotone equilibrium.
       Existence.         For any δ > 0, the monotonicity of v1 (x; x̄1 ) in x̄1 along with its continuity in
x for any x̄1 and the fact that limx→−∞ v1 (x, −∞) > 0 > limx→+∞ v1 (x, +∞), implies that there
exist x0 , x00 ∈ R such that V1 (x0 ) ≥ v1 (x0 , −∞) > 0 > v1 (x00 , +∞) ≥ V1 (x00 ) . The continuity of
V1 (x̄1 ) in x̄1 then ensures existence of a solution x̄1 (δ) ∈ (x0 , x00 ) to V1 (x̄1 ; δ) = 0.
     Next, consider t ≥ 2. For any given x̄t−1 , a similar argument as above ensures the existence
                             ¡        ¢      ¡             ¢
of x00 ∈ R such that Vt x̄t−1 , x00 ≤ vt x00 , x̄t−1 , +∞ < 0. Moreover, either there also exists
                       ¡          ¢            ¡        ¢
x0 ∈ R such that Vt x̄t−1 , x0 ≥ 0, or Vt x̄t−1 , x̄t < 0 for all x̄t ∈ R. In the former case, the
                 ¡          ¢                                                              ¡           ¢
continuity of Vt x̄t−1 , x̄t in x̄t ensures the existence of x̄t ∈ (x0 , x00 ) such that Vt x̄t−1 , x̄t = 0.
                      ¡              ¢     ¡          ¢      ¡       ¢
In the latter case, vt x; x̄t−1 , −∞ ≤ vt x; x̄t−1 , x = Vt x̄t−1 , x < 0 for any x ∈ R and therefore
                   ¡           ¢                 ¡            ¢
at x̄t = −∞, Vt x̄t−1 , −∞ ≡ limx→−∞ vt x; x̄t−1 , −∞ ≤ 0. We conclude that there exists a
sequence {x̄t (δ)}∞
                  t=0 that satisfies conditions (ii) and (iii) in the proposition.

    Proof of Theorem 2. We start by establishing pointwise convergence of Vt as δ → 0. For
                 ¡           ¢   t−1
any t ≥ 2 and any x̄t−1 , x̄t ∈ R    × R, by (7) and (8), we have that18
                                        Z   +∞
             ¡               ¢                                      ¡                 ¢        ¡                          ¢
       lim Vt x̄t−1 , x̄t ; δ = lim              pt (θ; x̄t , δ) dΨt θ|x̄t ; x̄t−1 , δ − c = Ψt θt (x̄t ) |x̄t ; x̄t−1 , 0 − c
       δ→0                         δ→0 −∞
                                    ¡                ¡     ¢           ¢    ¡               ¢
                                 = U θt (x̄t ) ; θt−1 x̄t−1 , αt , β, z ≡ Vt x̄t−1 , x̄t ; 0 .
                                                                    ¡              ¢ √        ³√      ³                                 ´´
  17                                                                                                                          αt x+βz
       This can be seen by noting that the ratio of the densities ψt θ|x; x̄t−1 , δ / αt + βφ   αt + β θ −                     αt +β
                                                                                                                                             is
increasing in θ.
  18
                                                                                                    ¡                          ¢
     For δ > 0, let Fp (y; x̄t , δ) be as in footnote 16. Similarly, for δ = 0, Fp (y; x̄t , 0) = Ψt θt (x̄t ) |x̄t ; x̄t−1 , 0 if y ∈ [0, 1)
                                                                                                                                  t−1
and Fp (y; x̄t , 0) = 0 if y = 1. Since Fp is bounded from above by 1 and, for any y ∈ [0, 1] and any x̄t ∈ R  × R,
         t                t
                                                                                                 R +∞        t
Fp (y; x̄ , δ) → Fp (y; x̄ , 0) as δ → 0, from standard Dominated Convergence Theorems, limδ→0 0 Fp (y; x̄ , δ)dy =
R +∞                               R +∞
 0
      limδ→0 Fp (y; x̄t , δ)dy = 0 Fp (y; x̄t , 0)dy, which gives the result.


                                                                    26
Similarly, for any x̄1 ∈ R, by (7),

                 lim V1 (x̄1 ; δ) = Ψ1 (θ1 (x̄1 ) |x̄1 ) − c = U (θ1 (x̄1 ) ; −∞, α1 , β, z) ≡ V1 (x̄1 ; 0) .
                δ→0

    We now prove the result by induction. To simplify the notation, for all t ≥ 1,we henceforth let
  ¡ t¢     ¡      ¢
Ut x̄ ≡ Vt x̄t ; 0 for the unperturbed game (δ = 0) and reserve the use of Vt for the perturbed
games (δ > 0).
        Consider first T = 1 and fix an arbitrary ε > 0. From the strict monotonicity of U1 (x̄1 ),19

                                            U1 (x∗1 − ε) > 0 > U1 (x∗1 + ε) .

By the convergence of V1 to U1 as δ → 0, we can find δ1 (ε) > 0 such that, for any δ < δ1 (ε) ,

                                         V1 (x∗1 − ε; δ) > 0 > V1 (x∗1 + ε; δ) .

From the continuity of V1 (x̄1 ; δ) in x̄1 for any δ > 0, it follows that there exists a solution x̄1 (δ)
to V1 (x1 ; δ) = 0 such that x∗1 − ε < x̄1 (δ) < x∗1 + ε. Following the same steps as in the proof of
existence in Proposition 3, we can then construct an equilibrium {x̄t (δ)}∞
                                                                          t=1 for Γ (δ) such that
|x̄1 (δ) − x∗1 | < ε. This proves the result for T = 1.
        Consider next an arbitrary T ≥ 2, fix ε > 0, and suppose the result holds for T − 1.
    Take first any equilibrium of Γ(0) such that x∗T > −∞. By the (local) strict monotonicity of UT
                                                              ¡          ¢
around x∗T implied by the assumption that x∗T ∈  / arg maxx UT x∗T −1 , x , there exists εT < ε such
that either
                           ¡                 ¢        ¡                 ¢
                         UT x∗T −1 , x∗T − εT > 0 > UT x∗T −1 , x∗T + εT ,
      ¡                ¢           ¡               ¢
or UT x∗T −1 , x∗T − εT < 0 < UT x∗T −1 , x∗T + εT . Without loss of generality, assume the first
                                                                                   ¡        ¢
case — the argument for the other case is identical. From the continuity of UT xT −1 , xT in
              T −1
xT −1 ∈ R            and the fact that the result holds for T − 1, there exists some ε0T ∈ (0, εT ) such that,
for any δ < δ (ε0T , T − 1), there is a sequence x̄T −1 (δ) satisfying the following three conditions:20
        [C1] for all t ≤ T − 1, either x̄t (δ) = −∞ and Vt (x̄τ (δ)) ≤ 0, or x̄t ∈ R and Vτ (x̄τ (δ) ; δ) = 0;
   [C2] for all t ≤ T − 1, |x∗t − x̄t (δ)| < ε0T < ε if x∗t ∈ R, and x̄t (δ) < −1/ε0T < −1/ε if x∗t = −∞;
                         ¡                      ¢             ¡                  ¢
   [C3] in period T, UT x̄T −1 (δ), x∗T − εT > 0 > UT x̄T −1 (δ) , x∗T + εT .
                                  ¡           ¢        ¡          ¢          ¡        ¢   T −1
Next, by the convergence of VT xT −1 , xT to UT xT −1 , xT for any xT −1 , xT ∈ R               × R, there
exists δT ∈ (0, δ (ε0T , T − 1)) such that, for any δ < δT , there is x̄T −1 (δ) that satisfies [C1]-[C2] and
such that:
  19
                                                                                                                   √
       This follows from the the monotonicity of U (θ; −∞, α1 , β, z) in θ — which in turn is implied by α1 ≥ β 2 / 2π —
and the monotonicity of θ1 (x̄1 ) in x̄1 .
  20
     Continuity of U implies existence of ε0T such that that [C3] holds for any x̄T −1 (δ) that satisfies [C2]; that the
result holds for T − 1 then ensures that, for any δ < δ (ε0T , T − 1) , there exists x̄T −1 (δ) that satisfies both [C1] and
[C2].


                                                             27
                            ¡                      ¢           ¡                      ¢
    [C30 ] in period T, VT x̄T −1 (δ), x∗T − εT ; δ > 0 > VT x̄T −1 (δ) , x∗T + εT ; δ .
                                     ¡         ¢
But then, by the continuity of VT xT −1 , xT in xT , for the same x̄T −1 (δ), there exists an x̄T (δ) ∈ R,
                                                ¡                   ¢
with |x∗T − x̄T (δ)| < εT < ε, that solves VT x̄T −1 (δ), x̄T (δ); δ = 0.
                                                                                             ¡          ¢
    Next, take any equilibrium of Γ(0) such that x∗T = −∞. Recall that, for any t ≥ 2, Ut x∗t−1 , xt =
                                                                  ¡     ¢
−c < 0 for all xt < x̃t , where x̃t > −∞ solves θt (x̃t ) = θt−1 x∗t−1 ≡ maxτ ≤t−1 θτ (x∗τ ) . Pick some
                                                               ¡         ¢
x0T ∈ (−∞, min{−1/ε, x̃T }). From the continuity of UT xT −1 , xT in xT −1 and the fact that the
result holds for T − 1, there exists some ε0 ∈ (0, ε) such that, for any δ < δ (ε0 , T − 1)), there is a
sequence x̄T −1 (δ) which satisfies conditions [C1]-[C2] above (replacing ε0T with ε0 ) and such that:
             ¡              ¢
    [C4] UT x̄T −1 (δ) , x0T < 0.
By the pointwise convergence of VT to UT , there also exists a δT ∈ (0, δ (ε0 , T − 1))) such that, for
any δ < δT , there is x̄T −1 (δ) that satisfies [C1]-[C2] and such that:
             ¡                    ¢
    [C40 ] VT x̄T −1 (δ) , x0T ; δ < 0.
                                                                           ¡                    ¢
If, for the same x̄T −1 (δ), there exists an x00T ∈ (−∞, x0T ) such that VT x̄T −1 (δ), x00T ; δ ≥ 0, then,
                           ¡         ¢
by the continuity of VT xT −1 , xT in xT ∈ R, there is also an x̄T (δ) ∈ R, with x00T < x̄T (δ) <
                             ¡                    ¢                   ¡               ¢
x0T < −1/ε, such that VT x̄T −1 (δ), x̄T (δ) ; δ = 0. If instead VT x̄T −1 (δ), xT ; δ < 0 for all xT ∈
                                             ¡              ¢
(−∞, x0T ), then x̄T (δ) = −∞ satisfies VT x̄T −1 (δ), −∞ ≤ 0.21
       Finally, recall that (6) admits at most two solutions in every t and therefore the set of xT ∗ that
can be part of an equilibrium of Γ (0) is finite. Hence, there is δ (ε, T ) ∈ (0, δ (ε, T − 1)) such that,
                                                                                                ¡        ¢
for any δ < δ (ε, T ) and every equilibrium {x∗t }∞t=1 of Γ (0) for which xt ∈
                                                                              ∗ / arg max U xt−1∗ , x
                                                                                            x t
for all t ≤ T, there exists x̄T (δ) such that, for all t ≤ T : if x∗t ∈ R, then |x̄t (δ) − x∗t | < ε
        ¡         ¢                                                  ¡     ¢
and Vt x̄t (δ) ; δ = 0; and if x∗t = −∞, then x̄t (δ) < −1/ε and Vt x̄t (δ) ≤ 0. Using the same
arguments as for the proof of existence in Proposition 3, x̄T (δ) is part of an equilibrium {x̄t (δ)}∞
                                                                                                     t=1
for Γ (δ) , which completes the proof.

       Proof of Proposition 4. Apart from a notational adjustment — namely the dependence of
U in period t on (βt , zt ) and of (x∗t , θt∗ ) on z t — the proof follows exactly the same steps as in the
model with only private information, and is thus omitted for brevity.

       Proof of Theorem 3. Consider first t = 1. For any (α1 , β1 , z1 ) , U (θ∗ , −∞, α1 , β1 , z1 ) is
continuous in θ∗ ∈ [0, 1] with U (0, −∞, ·) = 1 − c and U (1, −∞, ·) = −c. Hence a solution
θ1∗ (z1 ) to U (θ1∗ , −∞, α1 , β1 , z1 ) = 0 always exists.22 Next, consider any t ≥ 2 and note that,
                                                      ¡
             ∗ , α , β ) and any θ ∗ ∈ (θ ∗ , 1), U θ ∗ , θ ∗ , α , β , z
                                                                          ¢
for any (θt−1       t t                      t−1             t−1 t t t is strictly decreasing in zt and
U (θ∗ , ·, zt ) → 1 − c > 0 as zt → −∞, implying that necessarily maxθ∗ ∈[θ−1 ,1] U (θ∗ , ·, zt ) > 0
for zt suﬃciently low. Furthermore, since U (θ∗ , ·, zt ) is continuous in θ∗ ∈ [θt−1
                                                                                  ∗ , 1] for any z ,
                                                                                                  t
             ¡ ∗ ∗      ¢                                   ∗      ∗
and since U θ , θt−1 , · → −c monotonically for any θ ∈ [θt−1 , 1] as zt → +∞, from stan-
  21
       This follows from the same argument used in the proof of Proposition 3.
  22
       Note that the function θ1∗ (·) is unique if and only if α1 ≥ β12 /2π. Hence for α1 < β12 /2π, the game trivially admits
multiple equilibria even if T = 1.


                                                              28
                                                             ¡              ¢
dard Monotone Convergence Theorems, the function U θ∗ , θt−1      ∗ , ·, z
                                                                           t converges uniformly to −c
                                                 ¡                 ¢
as zt → +∞, implying that maxθ∗ ∈[θ−1 ,1] U θ∗ , θt−1  ∗ ,α ,β ,z
                                                            t t t < 0 for zt suﬃciently high. The
                                                                                  ¡ ∗          ¢
strict monotonicity of U in zt then guarantees that there exists a finite z θt−1      , αt , βt such that
                 ¡                   ¢                                 ¡            ¢
maxθ∗ ∈[θ−1 ,1] U θ∗ , θt−1
                        ∗ , α , β , z ≥ (≤) 0 if and only if z ≤ (≥) z θ ∗ , α , β , which also implies
                             t t t                                        t−1   t t
                                                                            ¡           ¢
that (9) admits a solution θt∗ (z t ) > θt−1
                                         ∗ (z t−1 ) if and only if z ≤ z θ ∗ , α , β . The following
                                                                     t        t−1   t t
is then an equilibrium: for t = 1, θ1∗ (z1 ) is any solution to U (θ1∗ , −∞, α1 , β1 , z1 ) = 0; for all
                                                           ¡                             ¢
t ∈ {2, ..., T }, θt∗ (z t ) = max({θt−1
                                     ∗ (z t−1 )} ∪ {θ ∗ : U θ ∗ , θ ∗ (z t−1 ), α , β , z = 0}. Note that, in this
                                                                   t−1           t t t
                                                                       ¡              ¢          ¡ ¢
equilibrium, at any t ≥ 2, θt∗ (z t ) > θt−1
                                           ∗ (z t−1 ) for all z ≤ z θ ∗ , α , β . Since θ ∗ z t = θ ∗ (z ) for
                                                                 t        t−1    t t           t        1 1
all z t and all t is also an equilibrium, we conclude that the game admits multiple equilibria for any
{αt , βt }Tt=1 and any T ≥ 2.




References

 [1] Angeletos, George-Marios, Christian Hellwig, and Alessandro Pavan (2003) “Coordination and
     Policy Traps,” working paper, MIT/UCLA/Northwestern.

 [2] Atkeson, Andrew (2000), “Discussion on Morris and Shin,” NBER Macroeconomics Annual.

 [3] Carlsson, Hans, and Eric van Damme (1993), “Global Games and Equilibrium Selection,”
     Econometrica 61, 5, 989-1018.

 [4] Chamley, Christophe (1999), “Coordinating Regime Switches,” Quarterly Journal of Eco-
     nomics 114, 3, 869-905.

 [5] Chari, V.V., and Patrick Kehoe (2003), “Hot Money,” Journal of Political Economy 111,
     1262-1292.

 [6] Corsetti, Giancarlo, Bernardo Guimaraes and Nouriel Roubini, (2004), “International Lending
     of Last Resort and Moral Hazard: A Model of IMF’s Catalytic Finance,” working paper,
     University of Rome.

 [7] Dasgupta, Amil (2002), “Coordination, Learning and Delay,” working paper, London School
     of Economics.

 [8] Edmond, Chris (2003), “Information and the Limits to Autocracy,” working paper, UCLA.

 [9] Frankel, David, and Ady Pauzner (2000), “Resolving Indeterminacy in Dynamic Settings: The
     Role of Shocks,” Quarterly Journal of Economics 115, 283-304.

                                                       29
[10] Giannitsarou, Chryssi, and Flavio Toxvaerd (2003), “Recursive Global Games,” working paper,
    Universidade Nova de Lisboa and Hebrew University of Jerusalem.

[11] Goldstein, Itay (2002), “Strategic Complementarities and the Twin Crises,” working paper,
    Duke University.

[12] Goldstein, Itay, and Ady Pauzner (2000), “Demand Deposit Contracts and the Probability of
    bank Runs,” working paper, Duke University and Tel Aviv University.

[13] Goldstein, Itay, and Ady Pauzner (2001), “Contagion of Self-Fulfilling Financial Crises due
    to Diversification of Investment Portfolios,” working paper, Duke University and Tel Aviv
    University.

[14] Heidhues, Paul, and Nicolas Melissas (2003), “Equilibria in a Dynamic Global Game: The Role
    of Cohort Eﬀects”, working paper, WZB Berlin and University of Leicester.

[15] Levin, Jonathan (2001), “A Note on Global Games with Overlapping Generations,” working
    paper, Stanford University.

[16] Milgrom, Paul (1981), “Good News and Bad News: Representation Theorems and Applica-
    tions,” Bell Journal of Economics 12, 380-391.

[17] Morris, Stephen, and Hyun Song Shin (1998), “Unique Equilibrium in a Model of Self-Fulfilling
    Currency Attacks,” American Economic Review, 88, 3, 587-597.

[18] Morris, Stephen and Hyun Song Shin (1999), “A Theory of the Onset of Currency Attacks,” in
    Agenor, Vines and Weber, eds., Asian Financial Crisis: Causes, Contagion and Consequences,
    Cambridge, UK: Cambridge University Press.

[19] Morris, Stephen and Hyun Song Shin (2000), “Rethinking Multiple Equilibria in Macroeco-
    nomics,” NBER Macro Annual.

[20] Morris, Stephen and Hyun Song Shin (2001), “Global Games - Theory and Applications,” in M.
    Dewatripont, L. Hansen, and S. Turnovsky, eds., Advances in Economics and Econometrics
    (8th World Congress of the Econometric Society), Cambridge, UK: Cambridge University
    Press.

[21] Morris, Stephen and Hyun Song Shin (2004), “Coordination Risk and the Price of Debt,”
    European Economic Review 48, 133-153.

[22] Rochet, Jean-Charles and Xavier Vives (2004), “Coordination Failures and the Lender of Last
    Resort: Was Bagehot Right After All?,” working paper, University of Toulouse.


                                               30
