                                 NBER WORKING PAPER SERIES




              HOSPITAL COMPETITION, MANAGED CARE AND MORTALITY
                AFTER HOSPITALIZATION FOR MEDICAL CONDITIONS:
                         EVIDENCE FROM THREE STATES

                                            José J. Escarce
                                            Arvind K. Jain
                                          Jeannette Rogowski

                                         Working Paper 12335
                                 http://www.nber.org/papers/w12335


                       NATIONAL BUREAU OF ECONOMIC RESEARCH
                                1050 Massachusetts Avenue
                                  Cambridge, MA 02138
                                       June 2006




This research was funded by grant number P01 HS10770-01 from the Agency for Healthcare Research and
Quality. We would like to thank Randy Hirscher for expert programming assistance, Elaine Quiter for project
management, and Kate Lee for administrative assistance. The views expressed herein are those of the
author(s) and do not necessarily reflect the views of the National Bureau of Economic Research.

©2006 by José J. Escarce, Arvind K. Jain and Jeannette Rogowski. All rights reserved. Short sections of
text, not to exceed two paragraphs, may be quoted without explicit permission provided that full credit,
including © notice, is given to the source.
Hospital Competition, Managed Care and Mortality After Hospitalization for Medical
Conditions: Evidence From Three States
José J. Escarce, Arvind K. Jain and Jeannette Rogowski
NBER Working Paper No. 12335
June 2006
JEL No. I1

                                            ABSTRACT

This study assessed the effect of hospital competition and HMO penetration on mortality after
hospitalization for six medical conditions in California, New York, and Wisconsin. We used linked
hospital discharge and vital statistics data to study adults hospitalized for myocardial infarction, hip
fracture, stroke, gastrointestinal hemorrhage, congestive heart failure, or diabetes. We estimated
logistic regression models with death within 30 days of admission as the dependent variable and
hospital competition, HMO penetration, and hospital and patient characteristics as explanatory
variables. Higher hospital competition was associated with lower mortality in California and New
York, but not Wisconsin. In addition, higher HMO penetration was associated with lower mortality
in California, but higher mortality in New York. In the context of the study states’ history with
managed care, these findings suggest that hospitals in highly competitive markets compete on quality
even in the absence of mature managed care markets. The findings also underscore the need to
consider geographic effects in studies of market structure and hospital quality.

José J. Escarce
Division of General Internal Medicine
Health Services Research
911 Broxton Plaza
Box 951736
Los Angeles, CA 90024
escarce@rand.org

Jeannette Rogowski
Department of Health Systems and Policy
University of Medicine and Dentistry of
New Jersey (UMDNJ)
335 George Street, Suite 2200
New Brunswick, NJ 08903
and NBER
rogowsje@umdnj.edu
                                            BACKGROUND

       Over the past two decades the structure of the U.S. health care industry has changed

dramatically. In particular, the growth of managed care—especially health maintenance

organizations (HMOs)—has led to the introduction of price competition among health care

providers. Numerous studies have assessed the effects of changes in health care market structure

on health care system performance. Studies of the hospital sector have confirmed that managed

care has led to the intensification of price competition among hospitals (e.g., Feldman et al.

1990), and that price competition has resulted in lower rates of cost growth, lower prices and

price-cost margins, and changes in the adoption and use of technology (e.g., Zwanziger and

Melnick 1988; Robinson 1991; Gaskin and Hadley 1997; Melnick et al. 1992; Keeler, Melnick,

and Zwanziger 1999; Baker and Phibbs 2002; Heidenreich et al. 2002; Bundorf et al. 2004).

However, the effects of changes in hospital market structure on the quality of care provided by

hospitals is less well understood. Only a handful of studies have addressed this issue and the

findings have not been consistent.

       The literature provides mixed evidence on the effects of hospital competition and

managed care penetration on the quality of hospital care. In the earliest study, based on data

from the early 1980s, Shortell and Hughes (1988) found that in-hospital mortality rates for 16

clinical conditions were higher in market areas with higher HMO penetration, but the number of

competing hospitals in a market area was unassociated with mortality. More recently, Kessler

and McClellan (2000) studied 1-year mortality for Medicare patients with acute myocardial

infarction (AMI) in the 1980s and 1990s. They found that higher hospital competition was

associated with decreased mortality, especially after 1990. HMO penetration was not associated




                                                                                                  3
with mortality, but the beneficial effects of hospital competition were stronger in high

penetration market areas. By contrast, Mukamel, Zwanziger, and Tomaszewski (2001), using

data from the 1990s, found no effects of hospital competition on 30-day mortality for Medicare

patients with a variety of conditions, but higher HMO penetration was associated with lower

mortality.

       In a study based on hospital discharge data from 16 states in the 1990s, Sari (2002)

examined the effects of hospital competition and HMO penetration on the rates of in-hospital

mortality following common elective procedures, selected in-hospital complications, and

inappropriate surgery. They found that higher hospital competition and higher HMO penetration

were associated with lower rates of wound infections, iatrogenic complications, and

inappropriate surgery. Shen (2003) found that faster growth in non-Medicare HMO penetration

increased 7-day, 30-day, and 90-day mortality for Medicare patients with AMI, but did not affect

longer-term mortality.

       While the five studies reviewed in the preceding paragraphs considered competition

globally, for all patients in a market, a recent study by Gowrisankaran and Town (2003) took a

different approach by assuming that hospitals compete for HMO and Medicare patients

separately. The investigators used data for Southern California in the early 1990s to study in-

hospital mortality for pneumonia and 30-day mortality for AMI. They found that competition

for HMO patients was associated with lower mortality, whereas competition for Medicare

patients was associated with higher mortality.

       There are several potential reasons for the differences in findings across existing studies.

Some of the differences may be attributable to differences in the time periods studied. The

effects of hospital competition and managed care on hospital quality may have evolved over time




                                                                                                      4
as hospitals adapted to the new regime of price competition. Methodological differences across

studies, including differences in measures of hospital quality or hospital competition, may

contribute to differences in findings as well. For example, since hospitals in more competitive

market areas and in areas with higher HMO penetration have shorter lengths of stay, and since

shorter length of stay may shift deaths from the hospital to the period following discharge (Baker

et al. 2002), use of in-hospital mortality (or complication rates) as the measure of quality may

lead to bias toward finding that higher hospital competition and HMO penetration are associated

with higher quality. The only studies that have been able to use mortality within a fixed time

interval as the quality measure are those that focus on Medicare patients. Last, the effects of

hospital competition and managed care may vary across geographic areas depending on the

maturity of managed care markets or other factors. No study has directly addressed this

possibility.

        The goal of this study is to assess the effect of hospital competition and HMO penetration

on hospital quality of care for six medical conditions, contrasting the findings for three states:

California, New York, and Wisconsin. As shown in Figure 1, these states differ in their history

and experience with HMOs. California, the prototypical example of a state with mature

managed care markets, has had among the highest levels of HMO penetration since the early

1980s. HMO penetration in Wisconsin grew early, nearly equaling the level in California by

1985, but has since plateaued. New York had very low HMO penetration until about 1990, when

penetration began to rise and eventually surpassed the level in Wisconsin. Our study is based on

data for these three states between 1994 and 1999.




                                                                                                     5
                                         NEW CONTRIBUTION

       Our study contributes to the literature on hospital market structure and the quality of

hospital care in three main ways. First, by linking hospital discharge and vital statistics data, we

are able to use 30-day mortality as the quality measure while including all patients in the

analysis, not just Medicare patients. Second, we use more recent data than prior studies. Finally,

and most important, we examine the experience of three states that differ in their history with

managed care and in the maturity of their managed care markets. Thus we assess the importance

of considering state-specific effects when studying the effects of managed care penetration and

hospital competition on hospital quality.



                                CONCEPTUAL FRAMEWORK


       Hospital markets have evolved rapidly over the past two decades. In the 1970s, health

insurance consisted of fee-for-service plans that allowed their insured members to use any

hospital and paid for hospital care on a cost-reimbursement basis. Cost-based payment led

hospitals to compete through the services, amenities, and convenience they offered rather than

price. Under this form of nonprice competition, often called the “medical arms race,” hospitals

in more competitive markets had higher costs (Joskow 1980; Robinson and Luft 1985).

       There are no studies of the impact of nonprice competition on the quality of hospital care.

However, one study of hospital choice that used data from the early 1980s found that patients

with a range of medical and surgical conditions were more likely to use hospitals having lower

in-patient mortality, other things equal (Luft et al., 1989). This suggests that in the days of the

“medical arms race” hospitals could compete for patients by offering higher quality of care.




                                                                                                      6
       Changes in the types of health insurance plans and in hospital payment beginning in the

early 1980s led to dramatic changes in the nature of competition among hospitals. Rapid

escalation in hospital costs led to the introduction of a prospective payment system for hospitals

by Medicare, reducing incentives for hospitals to increase costs. More important, the emergence

and rapid growth of managed care plans, especially HMOs, were enormously consequential.

Managed care plans bargained with hospitals to obtain price discounts and selectively contracted

with some of them to create networks of hospitals that would provide care to their insured

members. Selective contracting by managed care plans introduced price competition into

hospital markets and began to erode the “medical arms race” model of competition (e.g.,

Feldman et al. 1990). Of note, unique among the three study states, New York had an all-payer,

prospective rate-setting system for hospitals until 1997. However, New York’s system allowed

HMOs to negotiate lower prices with hospitals beginning in 1988 (McDonough 1997).

       Documented effects of price competition among hospitals include lower rates of hospital

cost growth and lower rates of use of costly services and technologies (e.g., Zwanziger and

Melnick 1988; Robinson 1991; Gaskin and Hadley 1997; Baker and Phibbs 2002; Heidenreich et

al. 2002; Bundorf et al. 2004). Therefore, price competition, left unchecked, might be expected

to adversely affect hospital quality of care by inducing hospitals to skimp on the resources used

to care for patients. However, there is considerable indirect evidence that HMOs may have

fostered quality competition among hospitals as well, by making quality a factor in their

contracting decisions, at least in mature managed care markets like those in California.

       The first line of indirect evidence comes from interviews and surveys of HMO executives

in California, who report that they consider information on quality when choosing hospitals for

contracts, even if the information is based on surrogate quality measures (Schulman et al. 1997;




                                                                                                     7
Rainwater and Romano 2003). Notably, Schulman at al. (1997) found that the use of quality

information was infrequent in less mature managed care markets in Florida and Pennsylvania.

The second line of evidence comes from studies that have assessed quality of care in hospitals

used by large numbers of HMO patients compared with hospitals used by large numbers of

patients with fee-for-service insurance. Escarce et al. (1999) found that HMO patients who

received coronary artery bypass surgery were more likely than their peers with fee-for-service

coverage to use low-mortality hospitals in California, but not in Florida. Erickson et al. (2000)

found that patients in New York with managed care insurance were less likely than fee-for-

service patients to use low-mortality hospitals for coronary artery bypass surgery. The final line

of evidence comes from an econometric study of the determinants of contracts between HMOs

and hospitals for bypass surgery, which found that HMOs are more likely to have contracts with

hospitals that have low mortality rates, other things equal (Gaskin et al. 2002).

       This discussion suggests that the effects of hospital competition and HMO penetration on

the quality of hospital care are theoretically ambiguous. Although price competition might be

expected to affect hospital quality adversely, quality competition would tend to offset this effect.

Thus the net impact of hospital competition and HMO penetration on hospital quality is likely to

depend on the relative strength of these counterbalancing influences. The discussion also

suggests that the relative strength of price and quality competition may hinge on the maturity of

managed care markets, with quality competition being strongest in the most mature markets.




                                                                                                    8
                                    DATA AND METHODS

Data and Study Sample

       The main source of data for this study consisted of linked hospital discharge and vital

statistics data for three states: New York (1995-1999), Wisconsin (1994-1999) and California

(1994-1999). (Linked data for 1994 were unavailable for New York.) The hospital discharge

data contained detailed information on all discharges from short-term general hospitals in these

states during the period in question, including admitting hospital; source of admission; patient

age, sex, race/ethnicity, and zip code of residence; principal diagnosis and secondary diagnoses

(up to 24 in California, 14 in New York, and 8 in Wisconsin); principal procedure secondary

procedures (up to 24 in California, 14 in New York, and 5 in Wisconsin); and type of health

insurance. The vital statistics data contained information on all deaths in these states during the

period in question.

       We identified adult residents of the study states who were admitted to hospitals in

metropolitan areas from the community or from nursing homes for acute myocardial infarction

(AMI), hip fracture (HIP), stroke (CVA), gastrointestinal hemorrhage (GIH), congestive heart

failure (CHF), or diabetes mellitus (DM). We chose these six conditions because at least one

study of geographic variation in hospital admission rates found that each was a low variation

condition (e.g., Wennberg, McPherson, and Caper 1984; Gittlesohn and Powe 1995; McMahon,

Wolf, and Tedeschi 1989; Chassin et al. 1986). In the framework developed by Wennberg

(1987), low variation conditions tend to be those in which the criteria for hospitalizing patients

are narrowly defined and for which there is a relatively high degree of professional consensus

regarding the need for hospital admission. We wished to assess quality of care for conditions

with these characteristics because hospital competition and HMO penetration may influence




                                                                                                      9
admission decisions for conditions in which hospital admission is discretionary. Thus, for

discretionary conditions, hospital competition and HMO penetration are more likely to be

correlated with unmeasured severity of illness, which may lead to biased estimates of their

effects on health outcomes. Nonetheless, there are differences in the degree of consensus

regarding the need for hospital admission even among the six study conditions. Whereas most

clinicians agree that all patients with AMI, HIP, or CVA and most patients with GIH require

hospitalization, admission decisions for CHF and DM are more discretionary. We excluded

patients who lived in other states because vital statistics data are more likely to record deaths for

state residents. We excluded admissions to hospitals in nonmetropolitan areas because we did

not have data on HMO penetration.

       We refined the study sample further in four ways. First, we excluded admissions for

certain clinical variants of the study conditions to ensure more clinically homogenous samples or

samples with a high likelihood of needing hospital admission. For example, we excluded HIP

admissions where the fracture was due to primary or metastatic bone cancer or to major multiple

trauma because these cases are very different from typical fractures, and we excluded GIH

admissions where the hemorrhage was due to esophagitis or a Mallory-Weiss tear because these

cases generally do not require admission.

       Second, we included only first admissions in an “episode of care,” defined as admissions

where another admission for the same condition had not occurred within the preceding 90 days.

For CHF, in particular, two or more admissions often occurred in close succession. Third, for

California, we included only admissions that began between April 1, 1994 and November 30,

1999; for Wisconsin, we included admissions that began between April 1, 1994 and December

31, 1999; and for New York, we included admissions that began between April 1, 1995 and




                                                                                                   10
December 31, 1999. We excluded admissions in the first quarter of the first year of data for each

state so we could identify first admissions in an episode of care. In addition, we excluded

admissions in December 1999 for California so we could assess 30-day mortality (see below)

without censoring, because the California vital statistics data only included deaths through 1999.

(The Wisconsin and New York vital statistics data included deaths through 2000.) Fourth, for

each study condition, we excluded admissions to hospitals that had fewer than 25 admissions for

that condition during the period of the study.

        The final study sample consisted of N=1,321,531 patients in California, N=876,704

patients in New York, and N=200,872 patients in Wisconsin. These admissions were to 363

different hospitals in California, 190 in New York, and 61 in Wisconsin. The study hospitals

were located in 25 different metropolitan areas in California, 13 in New York, and 13 in

Wisconsin.

        Other data sources used in the study were the American Hospital Association Annual

Surveys of Hospitals, Medicare Cost Reports, and Medicare PPS Impact Files for 1994-1999.



Empirical Analyses

        The measure of hospital quality in the study was 30-day mortality. We assessed the

effect of hospital competition and HMO penetration on quality by estimating admission-level

logistic regression models for each study condition within each state, using death within 30 days

of admission as the dependent variable and hospital competition, HMO penetration, hospital

characteristics1 and patient severity measures as explanatory variables.


1
 We used the characteristics of the hospital to which the patient was initially admitted even if the patient was
subsequently transferred to a different hospital (e.g., Kessler and McClellan 2000; Gowrisankaran and Town 2003).
Transfer rates were low for all study conditions except AMI (for California: AMI, 22.0 percent; HIP, 1.6. percent;
CVA, 3.4 percent; GIH, 1.6 percent; CHF, 3.4 percent; and DM, 1.4 percent; for New York: AMI, 26.4 percent;


                                                                                                                11
         The key explanatory variables in the models were hospital competition and HMO

penetration. We assessed the degree of competition facing each hospital using the predicted 75

percent and 90 percent radii for the hospital, obtained from Gresenz, Rogowski, and Escarce

(2004), to define the hospital’s local market area.2 After identifying all the other hospitals in

each hospital’s local market area, we derived the following competition measures: (1) a

competition index calculated as one minus the Herfindahl index based on bed shares, and (2) the

square root of the number of hospitals. We used one minus the Herfindahl index based on the 90

percent radius in our main analyses, and conducted sensitivity analyses using the alternate

measures. HMO penetration in each metropolitan area was measured as the fraction of the

population enrolled in an HMO, obtained from the InterStudy Regional Market Analysis

database for 1994-1999.

         The hospital characteristics included in the models were teaching status, categorized as

none, minor, or major based on the intern- and resident-to-bed ratio;3 ownership, categorized as

public (i.e., city or county-owned), private nonprofit, or private for-profit;4 and bed size,

categorized as less than 100 beds, 100-199 beds, 200-399 beds, or 400 or more beds.


HIP, 3.1 percent; CVA, 2.6 percent; GIH, 1.0 percent; CHF, 3.7 percent; and DM, 0.9 percent; for Wisconsin: AMI,
12.3 percent; HIP, 2.0 percent; CVA, 3.2 percent; GIH, 1.2 percent; CHF, 2.6 percent; and DM, 1.2 percent). In
effect, our approach holds the admitting hospital responsible for making transfers that would improve patient
outcomes.
2
  Briefly, we used hospital discharge data for nine states in 1997 to determine, for each short-term general hospital
in those states, the distance from the hospital to patient zip codes required to account for 75 percent and 90 percent
of the admissions to the hospital. We then developed a regression model for the 75 and 90 percent radii as functions
of hospital and market area characteristics, and we used the estimated coefficients to predict the radii for every
metropolitan hospital in the U.S. (For details, see Gresenz, Rogowski, and Escarce [2004].)
3
  Teaching hospitals were those with any interns or residents, and major teaching hospitals were those with more
than 0.25 interns and residents per bed. Data on interns and residents were obtained from Medicare Cost Reports.
4
 District hospitals in California are tax supported, but they resemble private nonprofit hospitals in most other ways.
Because there are few district hospitals in metropolitan areas, we included them in the nonprofit category. All
hospitals in Wisconsin were private nonprofits except for one public hospital, so we did not include ownership in the
Wisconsin models.



                                                                                                                   12
        To control for differences in patient severity, we also included a variety of severity

measures as covariates in the regression models, including patient age, sex, whether the patient

was admitted from a nursing home, chronic comorbidities, and a set of condition-specific

measures for each study condition. The chronic comorbidities used in the analyses were the

conditions identified by Iezzoni et al. (1994) as conditions that are nearly always present prior to

hospital admission; hence they are extremely unlikely to represent complications due to poor

care. They included primary cancer with a poor prognosis, metastatic cancer, chronic pulmonary

disease, coronary artery disease, congestive heart failure, peripheral vascular disease, severe

chronic liver disease, diabetes mellitus with end-organ damage, chronic renal failure, nutritional

deficiencies, dementia, and functional impairment.5 Examples of the condition-specific

measures for AMI include indicators for the location of the infarction and for the presence of

complete heart block; for CVA, indicators for hemorrhagic stroke and for different types of

ischemic stroke; for GIH, indicators for the source of the bleeding, such as esophageal varices,

different types of peptic ulcer with or without perforation or obstruction, arteriovenous

malformations, and diverticulosis; and for DM, indicators for the type of diabetes (type 1 or type

2), for the presence of ketoacidosis and nonketotic coma, and for different end-organ

complications.6 Finally, the models included indicator variables for year of admission.




5
 Elixhauser et al. (1998) developed a more comprehensive list of comorbidities. However, this list includes
conditions, such as hypertension, paralysis, obesity, and uncomplicated diabetes, that have been found to be
underreported in hospital discharge data, especially for patients who die (Romano and Mark 1994; Iezzoni et al.
1992; Iezzoni et al. 1994).
6
  To test the performance of these severity measures, we estimated logistic regression models for each study
condition using death within 30 days as the dependent variable and the severity measures, alone, as explanatory
variables. The c-statistics for these models ranged from 0.75 to 0.82 (with the exception of 0.66 to 0.69 for CHF),
indicating excellent discrimination. Additionally, comparisons of predicted and observed mortality across deciles of
risk showed good calibration.



                                                                                                                  13
       Standard errors were corrected for clustering of admissions within hospitals using a

Huber-White sandwich estimator. We converted the odds ratios from the logistic regression

models to approximate relative risks using the method described by Zhang and Yu (1998).



                                           RESULTS

Descriptive Data

       Table 1 reports 30-day mortality for the six study conditions, by state. Mortality was

lowest for DM and highest for CVA and AMI in every state. Comparing states, mortality rates

were highest in Wisconsin, intermediate in California, and lowest in New York.

       Patients in Wisconsin were slightly older than patients in the other states (data not

shown). Thus 71.8% of Wisconsin patients were 65 years or older across all the study

conditions, compared with 69.7% of patients in each of California and New York, and 18.8% of

Wisconsin patients were 85 years or older, compared with 17.3% of California patients and

18.4% of New York patients. The percentage of women patients across the study conditions

ranged from 51.3% in California, to 51.7% in Wisconsin, to 54.0% in New York. Patients in

Wisconsin averaged 1.02 chronic comorbidities, compared with 1.00 for patients in California

and 0.98 for patients in New York. However, patients in California were more likely than those

in Wisconsin or New York to be admitted to the hospital from a nursing home (4.7%, 1.3%, and

2.4%, respectively).

       Table 2 reports the characteristics of the hospitals that contributed admissions to the

study sample in each state. The competition index (calculated as one minus the Herfindahl

index) based on the 90 percent radius averaged 0.79 across hospitals in California, 0.72 in New

York, and 0.68 in Wisconsin. On average, hospitals in California had 19.8 hospitals within their




                                                                                                 14
90 percent radius, compared with 28.0 hospitals for hospitals in New York and 8.0 hospitals for

hospitals in Wisconsin. The competition measures based on the 75 percent radius exhibited

similar patterns across the three states. The average HMO penetration in the metropolitan areas

where the study hospitals were located was 0.43 in California, 0.34 in New York, and 0.32 in

Wisconsin.

       There were large differences across the study states in hospital ownership (Table 2).

Hospitals in California were much more likely to be for-profit (27.0%) than hospitals in New

York (5.4%), and Wisconsin had no for-profit hospitals. By contrast, hospitals in New York

were more likely to be public (9.7%) than hospitals in California (5.9%) or Wisconsin (1.5%).

The teaching status of hospitals also differed across states. Only three in ten hospitals in

California had teaching programs, compared with half in New York and Wisconsin. On the

other hand, the proportion of hospitals categorized as major teaching hospitals was much larger

in New York (28.5%) than either California (7.6%) or Wisconsin (5.3%). The study states

differed in the distribution of hospital size as well. Wisconsin had the highest fraction of small

hospitals with fewer than 100 beds, while New York had the highest fraction of very large

hospitals with 400 or more beds.



Regression Results

       Tables 3a-3c report the findings of our main analyses regarding the effects of hospital

competition, HMO penetration, and hospital characteristics on 30-day mortality for the study

conditions in California, New York, and Wisconsin, respectively. We found that hospital

competition was associated with lower mortality rates in California and New York. In

California, five conditions had significantly lower mortality in hospitals that faced greater




                                                                                                 15
competition: HIP (relative risk [RR]=0.75, p<0.01), CVA (RR=0.71, p<0.001), GIH (RR=0.83,

p<0.05), CHF (RR=0.88, p<0.10), and DM (RR=0.82, p<0.01). In New York, three conditions

had significantly lower mortality in hospitals that faced more competition: AMI (RR=0.85,

p<0.01), GIH (RR=0.86, p<0.10), and DM (RR=0.86, p<0.10). The point estimates for the other

conditions in both states were consistent with a protective effect of competition, but these

estimates did not achieve statistical significance.7            Hospital competition was unassociated with

mortality in Wisconsin.

         The relative risks summarized in the preceding paragraph are consistent with clinically

significant effects of hospital competition on mortality. For example, other things equal, a

California hospital at the 10th percentile of the competition index (one minus the Herfindahl

index based on the 90 percent radius) had a 30-day mortality rate of 7.1% for HIP, compared

with 6.2% in a hospital at the 90th percentile of the index. The corresponding figures for other

conditions were 18.4% and 15.6% for CVA, 6.2% and 5.6% for GIH, 9.0% and 8.4% for CHF,

and 3.9% and 3.2% for DM. Similarly, other things equal, a New York hospital at the 10th

percentile of the competition index had a 30-day mortality rate of 14.3% for AMI, compared

with 12.2% in a hospital at the 90th percentile of the index. The corresponding figures for other

conditions were 6.6% and 5.7% for GIH, and 3.2% and 2.7% for DM.

         The effects of HMO penetration differed strikingly across the study states (Tables 3a-3c).

In California, higher HMO penetration reduced mortality for GIH (RR=0.76, p<0.05) and CHF

(RR=0.78, p<0.01), and the point estimates for most of the remaining conditions were consistent

7
  Kessler and McClellan (2000) and Gowrisankaran and Town (2003) have argued that measures of hospital
competition based on patient flows may be endogenous to hospital quality, since hospitals with higher quality may
draw patients from longer distances. We based our competition measures on predicted rather than observed radii, as
described earlier, in order to avoid endogeneity, and we tested whether this strategy worked by estimating additional
logistic models for 30-day mortality that included the hospital’s predicted radius as an explanatory variable. The
coefficient of the predicted radius was close to zero for all the study conditions in all states, and the coefficients of
hospital competition did not change appreciably. Moreover, the statistical significance of the findings for
competition was strengthened in California and only slightly weakened in New York.


                                                                                                                      16
with a protective effect of HMO penetration, although these estimates did not achieve statistical

significance. Similarly, in Wisconsin, higher HMO penetration reduced mortality for CHF

(RR=0.66, p<0.01), and the point estimates for four of the five remaining conditions were

consistent with a protective effect of HMO penetration. By contrast, in New York, higher HMO

penetration was associated with higher mortality for HIP (RR=1.54, p<0.001), CVA (RR=1.33,

p<0.01), GIH (RR=1.54, p<0.01), and CHF (RR=1.43, p<0.01). Further, the point estimates for

AMI and DM suggested a harmful effect of HMO penetration as well, but these estimates were

not significant.

        Because the estimated effects of hospital competition and HMO penetration were

qualitatively similar for the six study conditions within each state (Tables 3a-3c), we estimated a

model for each state where we pooled all the conditions and included interactions between

condition and all the explanatory variables except competition and penetration. These analyses

found significant protective effects of hospital competition in California (OR=0.80, p<0.001) and

New York (OR=0.89, p<0.05), but not Wisconsin (OR=1.02, p>0.05). The pooled analyses also

found significant protective effects of HMO penetration in California (OR=0.86, p<0.05) and

Wisconsin (O=0.78, p<0.05). However, in New York, higher HMO penetration was associated

with higher mortality (OR=1.39, p<0.001).

        In addition, to assess whether the protective effect of hospital competition was greater in

metropolitan areas with high HMO penetration, we estimated models where we again pooled all

the study conditions but this time included an interaction between hospital competition and an

indicator variable for metropolitan areas in the top half of the distribution of HMO penetration

for each state. These analyses found a significant protective effect of hospital competition in

both high and low penetration metropolitan areas in California, but the protective effect of




                                                                                                   17
competition was greater in high penetration areas (RR=0.81, p<0.001, in high penetration areas;

RR=0.91, p<0.10, in low penetration areas; p<0.001 for test of difference in odds ratios). The

protective effect of hospital competition did not vary by HMO penetration in New York.

       Other hospital characteristics were also associated with mortality for medical conditions

(Tables 3a-3c), although the precise findings varied across the study states. Public hospitals in

California had higher mortality than private nonprofit hospitals for AMI and lower mortality for

CHF and DM, while public hospitals in New York had higher mortality for CVA. For-profit

hospitals in California had higher mortality for AMI and lower mortality for CVA, CHF and

DM, whereas for-profit hospitals in New York had lower mortality for HIP and CVA. In

California, major teaching hospitals had higher mortality than non-teaching hospitals for CVA,

GIH, and DM. By contrast, major teaching hospitals in New York had lower mortality than non-

teaching hospitals for CVA, CHF, and DM, and major teaching hospitals in Wisconsin had lower

mortality for DM. In California, large hospitals of 400 beds or more tended to have lower

mortality than small hospitals with fewer than 100 beds. Large hospitals in New York had

higher mortality than small hospitals for GIH and CHF, whereas in Wisconsin the effect of

hospital size on mortality was mixed.



Alternate Measures of Hospital Competition

       We explored the robustness of our findings for hospital competition using three alternate

competition measures: the competition index based on the 75 radius and the square root of the

number of hospitals based on both the 90 percent and 75 percent radii. As shown in Table 4, the

finding of protective effects of hospital competition in California and New York was robust. In

California, AMI was the only study condition for which higher competition did not reduce




                                                                                                    18
mortality. In New York, every study condition exhibited a protective effect of hospital

competition for at least one competition measure, although within condition the level of

statistical significance varied across measures. We found no evidence that hospital competition

affected mortality in Wisconsin irrespective of the competition measure used. Our findings

regarding the effects of HMO penetration on mortality did not change as we varied the measure

of hospital competition (data not shown).



Effect of Hospital Competition on Medicare Versus Non-Medicare Patients

        To assess whether the effect of hospital competition mortality differed for Medicare and

non-Medicare patients (Gowrisankaran and Town, 2003), we estimated models for 30-day

mortality that included the appropriate interaction terms. In California, the effect of competition

differed only for AMI. Higher competition reduced mortality for non-Medicare patients with

AMI (RR=0.89, p<0.10), but not for Medicare patients. In New York, the effect of competition

differed for four study conditions. Thus higher competition reduced mortality for non-Medicare

patients with HIP (RR=0.79, p<0.05), CVA (RR=0.87, p<0.05), CHF (RR=0.88, p<0.10), and

DM (RR=0.80, p<0.05), but not for Medicare patients with those conditions. For all other study

conditions, higher competition had the same effect (or lack thereof) on both Medicare and non-

Medicare patients. In no case did higher competition lead to higher mortality for Medicare

patients.



Additional Sensitivity Analyses

        We conducted additional sensitivity analyses to further assess the robustness of our

results. First, hospital discharge data have been criticized for lacking the clinical detail necessary




                                                                                                   19
to capture illness severity adequately enough to assess hospital quality of care (e.g., Pine et al.

1997; Hannan et al. 1992). Therefore, we reestimated the models in our main analyses including

an indicator for uninsured patients and an indicator for patients with insurance coverage from

Medicaid or an indigent program under the rationale that these categories may capture

unobserved dimensions of health status (e.g., Parkerson et al. 2005; Hadley 2003). The findings

for hospital competition and HMO penetration in Tables 3a-3c were unchanged.

       Second, due to the limited number of metropolitan areas in each study state, and because

we were concerned that HMO penetration could be endogenous to hospital quality, we estimated

models for 30-day mortality where we replaced the HMO penetration variable with metropolitan-

area fixed effects. The findings for hospital competition were unchanged.

       Third, because the New York City metropolitan area accounted for a large share of

hospital admissions in the state of New York (one-third to two-fifths across conditions), and

because some observers believe that the hospital market in New York City is atypical (Salit,

Fass, and Nowak 2002), we repeated the analyses for New York excluding admissions to

hospitals in New York City. The findings for hospital competition and HMO penetration were

again unchanged.

       Fourth, because New York did not fully abolish hospital rate-setting until 1997, we

estimated models to test for differences in the effects of hospital competition and HMO

penetration between 1995-1996 and 1997-1999. We did not find appreciable differences.

       Finally, we estimated models with 90-day and 180-day mortality, rather than 30-day

mortality, as the outcome. As Table 5 shows, the effects of hospital competition and HMO

penetration on 90-day and 180-day mortality were similar to their effects on 30-day mortality,




                                                                                                      20
although the effects of competition were slightly attenuated in the analyses of 180-day mortality

in California.




                                          DISCUSSION

       This study examined the effects of hospital competition and HMO penetration on the

quality of hospital care for six medical conditions in California, New York, and Wisconsin. We

found that hospitals in California and New York that faced a higher degree of competition

generally had lower mortality rates within 30 days of hospital admission. Specifically, higher

hospital competition led to lower mortality for five of the six study conditions in California and

all six conditions in New York, although significance levels varied depending on the competition

measure used. Analyses where we pooled the six study conditions also found protective effects

of competition in California and New York. By contrast, hospital competition was unassociated

with mortality in Wisconsin. Our findings regarding hospital competition were robust to a wide

range of sensitivity analyses in which we employed alternate measures of hospital competition

and varied the explanatory variables in the regression models. Similarly, analyses using 90-day

or 180-day mortality as the outcome, rather than 30-day mortality, found beneficial effects of

hospital competition in California and New York but not Wisconsin. In contrast to

Gowrisankaran and Town (2003), we did not find that higher competition was associated with

higher mortality for Medicare patients.

        The study also found that higher HMO penetration was associated with lower mortality

for gastrointestinal hemorrhage and congestive heart failure in California and for congestive

heart failure in Wisconsin, and the analyses where we pooled the six study conditions found a




                                                                                                 21
beneficial effect of higher HMO penetration in California and Wisconsin as well. Moreover,

when we included an interaction between hospital competition and HMO penetration in the

regression models, we found that the protective effect of competition in California was stronger

in metropolitan areas with high penetration. By contrast, in New York higher HMO penetration

was associated with a substantial increase in mortality for four of the six study conditions and in

the pooled analyses. We interpret our results for HMO penetration with caution due to the fact

that penetration was measured at the level of metropolitan areas and each study state only had

between 13 and 25 metropolitan areas. The small numbers of observations on HMO penetration,

especially in New York and Wisconsin, coupled with the concern that HMO penetration could be

endogenous to hospital quality, argue for regarding these results as suggestive rather than

conclusive. Nonetheless, the difference across states in the findings for penetration is striking.

       The results of this study are consistent with the thesis that hospitals competed on “true”

quality of care—i.e., processes and outcomes of care—rather than just on price or amenities in

California and New York, but not in Wisconsin. This observation raises two questions. First,

what is the source of the divergent results for California and New York, on one hand, compared

with Wisconsin, on the other? Although we cannot be certain, one possibility is that the effects

of hospital competition on quality of care emerge only at high levels of competition. As shown

in Table 2, hospitals in Wisconsin typically competed with many fewer hospitals than hospitals

in either California or New York.

       Second, and more important, do our results regarding the effects of hospital competition

on hospital quality have anything to do with managed care? Our finding that in California

hospital competition had a stronger beneficial effect on mortality in metropolitan areas with high

HMO penetration suggests that HMOs in that state fostered quality competition among hospitals




                                                                                                     22
and that they were at least partly responsible for the competition effects on quality that we found.

This interpretation is consistent with what is known about the maturity of managed care markets

in California and with the indirect evidence, reviewed earlier, that HMOs in California have

made hospital quality a factor in their contracting decisions. It is also consistent with our finding

that higher HMO penetration, per se, was associated with lower mortality in California. A

substantial presence in a market area of HMOs that take quality into account in contracting and

that induce hospitals to compete on quality would be expected to lead to overall improvements in

the quality of care in the area.

        On the other hand, our finding that in New York the beneficial effect of hospital

competition on mortality was the same in high and low HMO penetration areas, coupled with the

finding that higher HMO penetration in a metropolitan area was associated with higher mortality,

suggests that HMOs in New York may not have played a prominent role in promoting quality

competition among hospitals. This interpretation is consistent with the observation that HMOs

in New York did not begin to grow rapidly until the 1990s, and that hospital markets were not

fully deregulated until 1997. It is also consistent with Erickson et al.’s (2000) finding that

managed care patients in New York were less likely than fee-for-service patients to use low-

mortality hospitals for coronary artery bypass surgery, which suggests that managed care

organizations did not emphasize quality in hospital contracting. Rather, the findings for New

York raise the possibility that competition on “true” quality of care was a component of the

medical arms race model of hospital competition that prevailed in New York prior to the rapid

growth of managed care. Notably, studies have found that patients with fee-for-service

insurance are more likely to use hospitals with low mortality than hospitals with high mortality,

other things equal (e.g., Luft et al. 1989; Escarce et al. 1999), which gives hospitals a reason to




                                                                                                      23
compete on quality even when individual patients and their physicians, and not managed care

organizations, are making the choices.

       Additional findings of our study addressed to the effects on quality of hospital ownership,

teaching status, and bed size. Several studies have found similar or worse outcomes in public

hospitals compared with private hospitals (e.g., Shapiro et al. 1994; Kuhn et al. 1994).

Therefore, the finding of lower mortality for congestive heart failure in diabetes in public

hospitals in California was unexpected. To investigate this finding, we compared the

characteristics of patients admitted to public and private hospitals in California. We found that

compared with patients admitted to private hospitals, those admitted to public hospitals were

much younger, had fewer co-morbidities, and had substantially lower predicted probabilities of

death for all the study conditions. If our severity measures failed to capture all the differences in

illness severity between public and private hospital patients, the finding of lower mortality for

congestive heart failure and diabetes in public hospitals could reflect unobserved differences in

severity.

       The finding that major teaching hospitals in California had higher mortality for three

conditions was also unexpected. Several studies have reported better quality of care and lower

mortality in major teaching hospitals compared with other hospitals (e.g., Keeler et al. 1992;

Rosenthal et al. 1997; Ayanian and Weissman 2002). On the other hand, reports developed by

California’s Office of Statewide Health Planning and Development (OSHPD) on hospital quality

of care for myocardial infarction and pneumonia in California are not consistent with published

studies. For myocardial infarction, major teaching hospitals in California were more likely than

other hospitals in metropolitan areas to be both low-mortality and high-mortality outliers

(OSHPD 2002). For pneumonia, major teaching hospitals were less likely than other hospitals to




                                                                                                    24
be low-mortality outliers but more likely to be high-mortality outliers (OSHPD 2004). Our

findings regarding teaching status and 30-day mortality in New York and Wisconsin were

consistent with the published literature.

       A noteworthy strength of our study is that we employed linked hospital discharge and

vital statistics data, which enabled us to use 30-day mortality, rather than in-hospital mortality, as

the measure of quality of care for all patients. Previous studies that used mortality within a fixed

time interval after hospital admission as the quality measure were limited to Medicare patients

(e.g., Kessler and McClellan 2000; Mukamel, Zwanziger, and Tomaszewski 2001; Shen 2003).

Using in-hospital mortality to assess quality may lead to biased estimates of the effects of market

structure on quality because market structure may affect hospital length of stay and,

consequently, the likelihood of dying in the hospital (e.g., Baker et al. 2002). An additional

strength is that we examined mortality for six medical conditions that vary in the degree of

professional consensus regarding the need for hospitalization, including several for which there

is a great deal of consensus. Further, our focus on a small number of conditions enabled us to

include a variety of carefully selected, condition-specific severity measures in our regression

models.

       Our study also has several limitations. First, discharge data are inherently limited in their

ability to capture patient severity, since they lack clinical detail such as laboratory and

physiologic data (e.g., Pine et al. 1997). Although we used multiple and detailed condition-

specific measures to assess severity, we cannot rule out the possibility that the limitations of

discharge data influenced our findings.

       Second, radius-based measures of hospital competition have been criticized because all

hospitals inside the radius count equally whereas hospitals just outside the radius do not count at




                                                                                                   25
all. We addressed this concern by using competition measures based on two different radii—the

75 percent and 90 percent radii—which in practice led to sizable differences in the number of

hospitals that contributed to the competition measures. Our results did not change appreciably

based on the choice of radius. Radius-based competition measures have also been criticized for

being endogenous, but we addressed this concern by using predicted, rather than observed, radii.

       Third, the small number of metropolitan areas in each study state precludes drawing

definitive conclusions about the impact of HMO penetration on hospital quality of care.

Nonetheless, the divergence in the findings for penetration across the three states lends support

to the notion that the effect of managed care on quality may vary geographically, possibly

depending on characteristics of the managed care market. The results for New York, in

particular, call for additional research into the circumstances where managed care may lead to

lower hospital quality. In addition, our study did not address the influence of hospital market

structure on quality in nonmetropolitan areas.

       Fourth, because our study did not assess the impact of hospital competition on costs, the

implications of our findings for the welfare effects of competition are uncertain. In particular,

we don’t know whether competition reduces hospital costs in a state with few competition

hospitals, such as Wisconsin, to the same degree as in California.

       To conclude, this study provides robust evidence that hospital competition can lead to

higher quality of care for a range of medical conditions, at least in states like California and New

York where hospitals typically compete with many other hospitals. However, the findings of the

study also suggest that quality competition among hospitals may not require the presence of

managed care. In particular, the results for New York raise the possibility that quality

competition may be a feature of competitive hospital markets irrespective of the characteristics




                                                                                                    26
of managed care markets. The study findings also suggest that the influence of managed care on

hospital quality may vary across states. Taken together, our results underscore the need to

consider state-specific effects in studies of health care markets and quality of care. Given the

“backlash” against managed care, studies to assess the conditions under which hospitals compete

on quality even in the absence of mature managed care markets warrant particular attention.




                                                                                                   27
                                       REFERENCES

Ayanian, J.Z., and J.S. Weissman. 2002. “Teaching Hospitals and Quality of Care: A Review

of the Literature.” The Milbank Quarterly 80 (3): 569-93.



Baker, D.W., D. Einstadter, C.L. Thomas, S.S. Husak, N.H. Gordon, and R.D. Cebul. 2002.

“Mortality Trends During a Program that Publicly Reported Hospital Performance.” Medical

Care 40 (10): 879-90.



Baker, L.C., and C.S. Phibbs. 2002. “Managed Care, Technology Adoption, and Health Care:

The Adoption of Neonatal Intensive Care.” The RAND Journal of Economics 33 (3): 524-48.



Bundorf, M.K., K.A. Schulman, J.A. Stafford, D. Gaskin, J.G. Jollis, and J.J. Escarce. 2004.

“Impact of Managed Care on the Treatment, Costs, and Outcomes of Fee-for-Service Medicare

Patients with Acute Myocardial Infarction.” Health Services Research 39 (1): 131-52.



Chassin, M.R., R.H. Brook, R.E. Park, J. Keesey, A. Fink, J. Kosecoff, K. Kahn, N. Merrick, and

D.H. Solomon. 1986. “Variations in the Use of Medical and Surgical Services by the Medicare

Population.” New England Journal of Medicine 314 (5): 285-90.



Elixhauser, A., C. Steiner, D.R. Harris, and R.M. Coffey. 1998. “Comorbidity Measures for

Use with Administrative Data.” Medical Care 36 (1): 8-27.




                                                                                               28
Erickson, L.C., D.F. Torchiana, E.C. Schneider, J.W. Newburger, and E.L. Hannan. 2000. “The

Relationship between Managed Care Insurance and Use of Lower-Mortality Hospitals for CABG

Surgery.” Journal of the American Medical Association 283 (15): 1976-82.



Escarce, J.J., R.L. Van Horn, M.V. Pauly, S.V. Williams, J.A. Shea, and W. Chen. 1999.

“Health Maintenance Organizations and Hospital Quality for Coronary Artery Bypass Surgery.”

Medical Care Research and Review 56 (3): 340-62.



Feldman, R., H.C. Chan, J. Kralewski, B. Dowd, and J. Shapiro. 1990. “Effects of HMOs on the

Creation of Competitive Markets for Hospital Services.” Journal of Health Economics 9 (2):

207-22.



Gaskin, D.J., and J. Hadley. 1997. “The Impact of HMO Penetration on the Rate of Hospital

Cost Inflation, 1985-1993.” Inquiry 34 (3): 205-16.



Gaskin, D.J., J.J. Escarce, K. Schulman, and J. Hadley. 2002. “The Determinants of HMOs’

Contracting with Hospitals for Bypass Surgery.” Health Services Research 37 (4): 963-84.



Gittelsohn, A., and N.R. Powe. 1995. “Small Area Variations in Health Care Delivery in

Maryland.” Health Services Research 30 (2): 295-317.



Gowrisankaran, G., and R.J. Town. 2003. “Competition, Payers and Hospital Quality.” Health

Services Research 38 (6, part 1): 1403-21.




                                                                                             29
Gresenz, C.R., J. Rogowski, and J.J. Escarce. 2004. “Updated Variable-Radius Measures of

Hospital Competition.” Health Services Research 39 (2): 417-30.



Hadley, J. 2003. “Sicker and Poorer—the Consequences of Being Uninsured: A Review of the

Research on the Relationship Between Health Insurance, Medical Care Use, Health, Work, and

Income.” Medical Care Research and Review 60 (2) Suppl: 3S-75S.



Hannan, E.L., H. Kilburn Jr., M.L. Lindsey, and R. Lewis. 1992. “Clinical Versus

Administrative Data Bases for CABG Surgery. Does it Matter?” Medical Care 30 (10): 892-

907.



Heidenreich, P.A., M. McClellan, C. Frances, and L.C. Baker. 2002. “The Relation between

Managed Care Market Share and the Treatment of Elderly Fee-for-Service Patients with

Myocardial Infarction.” The American Journal of Medicine 112 (3): 176-82.



Iezzoni, L.I., T. Heeren, S.M. Foley, J. Daley, J. Hughes, and G.A. Coffman. 1994. “Chronic

Conditions and Risk of In-Hospital Death.” Health Services Research 29 (4): 435-60.



Iezzoni, L.I., S.M. Foley, J. Daley, J. Hughes, E.S. Fisher, and T. Heeren. 1992.

“Comorbidities, Complications, and Coding Bias. Does the Number of Diagnosis Codes Matter

in Predicting In-Hospital Mortality?” The Journal of the American Medical Association 267

(16): 2197-203.




                                                                                              30
Joskow, P.L. 1980. “The Effects of Competition and Regulation on Hospital Bed Supply and

the Reservation Quality of the Hospital.” The Bell Journal of Economics 11 (2): 421-47.



Keeler, E.B., L.V. Rubenstein, K.L. Kahn, D. Draper, E.R. Harrison, M.J. McGinty, W.H.

Rogers, and R.H. Brook. 1992. “Hospital Characteristics and Quality of Care.” The Journal of

the American Medical Association 268 (13): 1709-14.



Keeler, E.B., G. Melnick, and J. Zwanziger. 1999. “The Changing Effects of Competition on

Non-Profit and For-Profit Hospital Pricing Behavior.” Journal of Health Economics 18 (1): 69-

86.



Kessler, D.P., and M.B. McClellan. 2000. “Is Hospital Competition Socially Wasteful?” The

Quarterly Journal of Economics 115 (4): 577-615.



Kuhn, E.M., A.J. Hartz, H. Krakauer, R.C. Bailey, A.A. Rimm. 1994. “The Relationship of

Hospital Ownership and Teaching Status to 30- and 180-Day Adjusted Mortality Rates.”

Medical Care 32 (11): 1098-108.



McDonough, J.E. 1997. “Tracking The Demise of State Hospital Rate Setting.” Health Affairs

16 (1): 142-49.




                                                                                            31
McMahon Jr., L.F., R.A. Wolfe, P.J. Tedeschi. 1989. “Variation in Hospital Admissions among

Small Areas. A Comparison of Maine and Michigan.” Medical Care 27 (6): 623-31.



Melnick, G.A., J. Zwanziger, A. Bamezai, and R. Pattison. 1992. “The Effects of Market

Structure and Bargaining Position on Hospital Prices.” Journal of Health Economics 11 (3):

217-33.



Mukamel, D.B., J. Zwanziger, and K.J. Tomaszewski. 2001. “HMO Penetration, Competition,

and Risk-Adjusted Hospital Mortality.” Health Services Research 36 (6 part 1): 1019-35.



OSHPD Hospital Outcomes Center. 2004. Report on Hospital Outcomes for Community-

Acquired Pneumonia in California, 1999-2001. Sacramento, California: Healthcare Quality and

Analysis Division, California Office of Statewide Health Planning and Development. February.



OSHPD Healthcare Quality and Analysis Division. 2002. Report on Heart Attack Outcomes in

California 1996-1998, Volume 1: User’s Guide. Sacramento, CA: California Office of

Statewide Health Planning and Development. February.



Parkerson, G.R. Jr., W.E. Hammond, J.L. Michener, K.S. Yarnall, and J.L. Johnson. 2005.

“Risk Classification of Adult Primary Care Patients by Self-Reported Quality of Life.” Medical

Care 43 (2): 189-93.




                                                                                             32
Pine, M., M. Noriusis, B. Jones, and G.E. Rosenthal. 1997. “Predictions of Hospital Mortality

Rates: A Comparison of Data Sources.” Annals of Internal Medicine 126 (5): 347-54.



Rainwater, J.A., and P.S. Romano. 2003. “What Data do California HMOs Use to Select

Hospitals for Contracting?” The American Journal of Managed Care 9 (8): 553-61.



Romano, P.S., and D.H. Mark. 1994. “Bias in the Coding of Hospital Discharge Data and Its

Implications for Quality Assessment.” Medical Care 32 (1): 81-90.



Romano, P.S. and R. Mutter. 2004. “The Evolving Science of Quality Measurement for

Hospitals: Implications for Studies of Competition and Consolidation.” International Journal of

Health Care Finance and Economics 4 (2): 131-57.



Robinson, J.C. 1991. “HMO Market Penetration and Hospital Cost Inflation in California.”

The Journal of the American Medical Association 266 (19) 2719-23.



Robinson, J. C., and H. S. Luft. 1985. “The Impact of Hospital Market Structure on Patient

Volume, Average Length of Stay, and the Cost of Care.” Journal of Health Economics 4 (4):

333-56.



Rosenthal, G.E., D.L. Harper, L.M. Quinn, and G.S. Cooper. 1997. “Severity-Adjusted

Mortality and Length of Stay in Teaching and Nonteaching Hospitals. Results of a Regional

Study.” The Journal of the American Medical Association 278 (6): 485-90.




                                                                                             33
Salit, S., S. Fass, and M. Nowak. 2002. “Out of the Frying Pan: New York City Hospitals in an

Age of Deregulation.” Health Affairs 21 (1): 127-39.



Sari, N. 2002. “Do Competition and Managed Care Improve Quality?” Health Economics 11

(7): 571-84.

Schulman, K.A., L.E. Rubenstein, D.M. Seils, M. Harris, J. Hadley, and J.J. Escarce. 1997.

“Quality Assessment in Contracting for Tertiary Care Services by HMOs: A Case Study of

Three Markets.” The Joint Commission Journal on Quality Improvement 23 (2): 117-27.



Shapiro, M.F., R.E. Park, J. Keesey, and R.H. Brook. 1994. “The Effect of Alternative Case-

Mix Adjustments on Mortality Differences Between Municipal and Voluntary Hospitals in New

York City.” Health Services Research 29 (1): 95-112.



Shen, Y.C. 2003. “The Effect of Financial Pressure on the Quality of Care in Hospitals.”

Journal of Health Economics 22 (2): 243-69.



Shortell, S.M., and E.F. Hughes. 1988. The Effects of Regulation, Competition, and Ownership

on Mortality Rates among Hospital Inpatients. The New England Journal of Medicine 318 (17):

1100-7.




                                                                                              34
Wennberg, J.E., K. McPherson, and P. Caper. 1984. “Will Payment Based on Diagnosis-

Related Groups Control Hospital Costs?” The New England Journal of Medicine 311 (5): 295-

300.



Wennberg, J.E. 1987. “Population Illness Rates Do Not Explain Population Hospitalization

Rates. A Comment on Mark Blumberg’s Thesis that Morbidity Adjusters are Needed to

Interpret Small Area Variations.” Medical Care 25 (4): 354-9.



Young, G.J., J.F. Burgess Jr., and D. Valley. 2002. “Competition among Hospitals for HMO

Business: Effect of Price and Nonprice Attributes.” Health Services Research 37 (5): 1267-89.



Zhang, M.B., and K.F. Yu. 1998. “What’s the Relative Risk? A Method for Correcting the

Odds Ratio in Cohort Studies of Common Outcomes. Journal of the American Medical

Association 280(19): 1690-1691.



Zwanziger, J., and G.A. Melnick. 1988. “The Effects of Hospital Competition and the Medicare

PPS Program on Hospital Cost Behavior in California.” Journal of Health Economics 7 (4):

301-20.




                                                                                            35
                                      Figure 1. HMO Penetration in Three Study States

                                60
Percent of Population in HMOs




                                50

                                40
                                                                                        California
                                30                                                      New York
                                                                                        Wisconsin
                                20

                                10

                                0
                                     1980'   1985'    1990'    1995'    2000'
                                                      Year




                                                                                                     36
Table 1: Thirty-Day Mortality for Study Conditions, By State.

                        AMI       HIP     CVA      GIH      CHF       DM
California
    30-day Mortality    13.2%   6.3%    16.0%   5.7%    8.5%    3.3%
    N                  227,446 129,944 237,248 216,443 355,613 154,837

New York
   30-day Mortality     12.5%     5.7%   15.3%   5.8%    8.0%    2.8%
   N                   153,970   75,567 134,016 121,733 262,844 128,574

Wisconsin
   30-day Mortality    13.3%      7.2%    17.1%     6.0%    10.8%     3.3%
   N                   37,693    21,810   34,037   29,011   55,475   22,846




                                                                              37
Table 2: Descriptive Data: Hospital Competition, HMO Penetration, and Other Hospital
Characteristics in Three States

                                                 Percentage or Mean (SD)
                                   California        New York         Wisconsin
Hospital Competition
 90% Radius Measures
   1 - Herfindahl Index            0.79 (0.25)      0.72 (0.31)      0.68 (0.29)
   Number of Hospitals             19.8 (25.6)      28.0 (44.4)      8.0 (7.7)
 75% Radius Measures
   1- Herfindahl                   0.61 (0.33)      0.57 (0.37)      0.51 (0.30)
   Number of Hospitals             7.3 (11.1)       12.4 (22.7)      3.3 (4.0)

HMO Penetration                    0.43 (0.13)      0.34 (0.14)      0.32 (0.13)

Hospital Characteristics
 Hospital Ownership
       Nonprofit                   67.1%            84.9%            98.5%
       Public                      5.9%             9.7%             1.5%
       For profit                  27.0%            5.4%             ---
 Teaching Status
       No                          70.3%            46.6%            52.5%
       Minor                       22.1%            24.9%            42.2%
       Major                       7.6%             28.5%            5.3%
 Hospital Bed Size
       <100 beds                   25.5%            11.7%            32.8%
       100-199 beds                36.0%            22.3%            30.8%
       200-399 beds                32.1%            34.3%            28.5%
       400+ beds                   6.4%             31.7%            7.9%




                                                                                       38
Table 3a: Regression Results: Effects of Hospital Competition, HMO Penetration, and
Hospital Characteristics on 30-Day Mortality for Six Medical Conditions in California.


                               AMI          HIP        CVA         GIH         CHF          DM
                              Relative    Relative    Relative    Relative    Relative    Relative
Explanatory Variable            Risk        Risk        Risk        Risk        Risk        Risk
Hospital Competition         0.93        0.75***     0.71***     0.83**      0.88*       0.82*
(1-Herfindahl, 90% radius)
                             0.91        0.87        0.98        0.76**      0.78***     0.93
HMO Penetration

Hospital Ownership
   Non-Profit (excluded)     1.00        1.00        1.00        1.00        1.00        1.00
   Public                    1.35***     0.98        1.06        1.08        0.87*       0.70***
   For Profit                1.08**      1.05        0.92**      0.98        0.93**      0.85***

Teaching Status
   No (excluded)             1.00        1.00        1.00        1.00        1.00        1.00
   Minor                     0.99        1.07*       1.04        0.99        1.01        1.10*
   Major                     0.93        1.05        1.12**      1.19***     0.96        1.15*

Hospital Bed Size
   <100 Beds (excluded)      1.00        1.00        1.00        1.00        1.00        1.00
   100-199 Beds              0.97        1.01        0.98        1.05        1.03        0.99
    200-399 Beds             0.94*       1.02        0.92*       1.05        1.00        0.91
    400+ Beds                0.90**      0.94        0.89*       0.94        0.85***     0.72***

Notes: Statistical significance is indicated as follows: *p<0.10, **p<0.05, ***p<0.01.
The regression models included patient severity measures and year indicators.




                                                                                                     39
Table 3b: Regression Results: Effects of Hospital Competition, HMO Penetration, and
Hospital Characteristics on 30-Day Mortality for Six Medical Conditions in New York.


                               AMI          HIP        CVA         GIH         CHF          DM
                              Relative    Relative    Relative    Relative    Relative    Relative
Explanatory Variable            Risk        Risk        Risk        Risk        Risk        Risk
Hospital Competition         0.85***     0.91        0.92        0.86*       0.94        0.86*
(1-Herfindahl, 90% radius)
                             1.20        1.54***     1.33***     1.54***     1.43***     1.13
HMO Penetration

Hospital Ownership
   Non-Profit (excluded)     1.00        1.00        1.00        1.00        1.00        1.00
   Public                    1.03        1.00        1.36***     1.13        0.95        0.97
   For Profit                0.98        0.61***     0.90*       0.88        0.94        0.90

Teaching Status
   No (excluded)             1.00        1.00        1.00        1.00        1.00        1.00
   Minor                     1.03        0.98        1.03        1.00        0.99        1.03
   Major                     0.98        0.91        0.89**      0.98        0.82***     0.81**

Hospital Bed Size
   <100 Beds (excluded)      1.00        1.00        1.00        1.00        1.00        1.00
   100-199 Beds              0.98        0.94        1.01        1.06        1.05        0.95
    200-399 Beds             1.02        0.99        0.94        1.14        1.09        0.97
    400+ Beds                1.06        0.93        0.99        1.20*       1.12*       1.08

Notes: Statistical significance is indicated as follows: *p<0.10, **p<0.05, ***p<0.01.
The regression models included patient severity measures and year indicators.




                                                                                                     40
Table 3c: Regression Results: Effects of Hospital Competition, HMO Penetration, and
Hospital Characteristics on 30-Day Mortality for Six Medical Conditions in Wisconsin.


                               AMI          HIP        CVA         GIH         CHF          DM
                              Relative    Relative    Relative    Relative    Relative    Relative
Explanatory Variable            Risk        Risk        Risk        Risk        Risk        Risk
Hospital Competition         1.06        0.98        0.90        0.94        1.12        1.02
(1-Herfindahl, 90% radius)
                             0.78        1.03        0.95        0.78        0.66***     0.76
HMO Penetration

Teaching Status
   No (excluded)             1.00        1.00        1.00        1.00        1.00        1.00
   Minor                     0.95        0.98        1.04        0.98        1.10*       0.95
   Major                     1.20*       1.03        1.07        0.95        0.87*       0.55**

Hospital Bed Size
   <100 Beds (excluded)      1.00        1.00        1.00        1.00        1.00        1.00
   100-199 Beds              1.15        0.94        0.91        1.18*       0.90        0.99
    200-399 Beds             1.20*       0.93        0.85**      1.15        0.83**      0.91
    400+ Beds                1.27**      0.86        0.85**      1.24*       0.84*       0.85

Notes: Statistical significance is indicated as follows: *p<0.10, **p<0.05, ***p<0.01.
The regression models included patient severity measures and year indicators. However, the
models for Wisconsin did not include hospital ownership.




                                                                                                     41
  Table 4: Regression Results: Effects of Hospital Competition Using Alternate Measures of
  Competition, By State.


                             AMI        HIP        CVA        GIH        CHF        DM
State/                      Relative   Relative   Relative   Relative   Relative   Relative
Competition Measure          Risk       Risk       Risk       Risk       Risk       Risk

California

  90% Radius Measures
    1-Herfindahl Index      0.93       0.75***    0.71***    0.83**     0.88*      0.82*
    Number of Hospitals     0.99       0.97***    0.96***    0.98***    0.96***    0.97***


  75% Radius Measures
    1-Herfindahl Index      1.02       0.87**     0.77***    0.94       0.89**     0.92
    Number of Hospitals     0.99       0.95***    0.93***    0.97***    0.94***    0.96***

New York

  90% Radius Measures
    1-Herfindahl Index      0.85***    0.91       0.92       0.86*      0.94       0.86*
    Number of Hospitals     0.97***    0.99*      0.97***    0.97***    1.00       1.00


  75% Radius Measures
    1-Herfindahl Index      0.90*      0.92       0.94       0.87**     0.89**     0.83**
    Number of Hospitals     0.96***    0.97***    0.97***    0.95***    0.99       0.98

Wisconsin

  90% Radius Measures
    1-Herfindahl Index      1.06       0.98       0.90       0.94       1.12       1.02
    Number of Hospitals     1.01       1.01       0.99       0.95       0.98       0.97


  75% Radius Measures
    1-Herfindahl Index      1.11       1.17       0.94       1.10       0.96       1.01
    Number of Hospitals     1.04       1.04       1.00       1.02       0.96*      1.00

  Notes: Statistical significance is indicated as follows: *p<0.10, **p<0.05, ***p<0.01.
  The regression models included HMO penetration, hospital ownership (except in Wisconsin),
  teaching status, bed size, patient severity measures, and year indicators.




                                                                                              42
Table 5: Regression Results: Effects of Hospital Competition and HMO Penetration 90-
Day and 180-Day Mortality for Six Medical Conditions, By State.


                                  AMI        HIP        CVA        GIH        CHF        DM
State/Outcome/                   Relative   Relative   Relative   Relative   Relative   Relative
Competition Measure               Risk       Risk       Risk       Risk       Risk       Risk

California

  90-Day Mortality
    Hospital Competition         0.93       0.84**     0.75***    0.89*      0.90*      0.84*
    (1-Herfindahl, 90% radius)
    HMO Penetration              0.92       0.93       1.01       0.83**     0.81***    1.00

  180-Day Mortality
    Hospital Competition         0.95       0.87**     0.77***    0.93       0.94       0.91
    (1-Herfindahl, 90% radius)
    HMO Penetration              0.91       0.91       1.03       0.80***    0.85***    1.03

New York

  90-Day Mortality
    Hospital Competition         0.83***    0.89*      0.90*      0.82**     0.93       0.91
    (1-Herfindahl, 90% radius)
    HMO Penetration              1.27**     1.47***    1.21**     1.36**     1.42***    1.42*

  180-Day Mortality
    Hospital Competition         0.86***    0.89**     0.91*      0.85***    0.96       0.90
    (1-Herfindahl, 90% radius)
    HMO Penetration              1.29***    1.43***    1.18**     1.24*      1.38***    1.39**

Wisconsin

  90-Day Mortality
    Hospital Competition         1.09       1.03       0.95       1.00       1.07       0.90
    (1-Herfindahl, 90% radius)
    HMO Penetration              0.72       0.93       0.95       0.81       0.80       0.63

  180-Day Mortality
    Hospital Competition         1.09       1.03       0.98       0.97       1.07       1.07
    (1-Herfindahl, 90% radius)
    HMO Penetration              0.65*      0.99       0.96       0.77       0.78*      0.66

Notes: Statistical significance is indicated as follows: *p<0.10, **p<0.05, ***p<0.01.
The regression models included hospital ownership (except in Wisconsin), teaching status, bed
size, patient severity measures, and year indicators.


                                                                                                 43
