                              NBER WORKING PAPER SERIES




              INFORMATIONAL FRICTIONS AND PRACTICE VARIATION:
                   EVIDENCE FROM PHYSICIANS IN TRAINING

                                       David C. Chan, Jr

                                      Working Paper 21855
                              http://www.nber.org/papers/w21855


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                                    January 2016




Previously circulated as "Uncertainty, Tacit Knowledge, and Practice Variation: Evidence from
Physicians in Training." I am grateful to David Cutler, Joe Doyle, Bob Gibbons, and Jon Gruber
for their guidance on this project from an early stage. I also thank Achyuta Adhvaryu, Daron
Acemoglu, Leila Agha, David Autor, Daniel Barron, David Bates, Amitabh Chandra, Wes
Cohen, Michael Dickstein, Amy Finkelstein, Emir Kamenica, Pat Kline, Jon Kolstad, Eddie
Lazear, Frank Levy, Grant Miller, David Molitor, Jon Skinner, Doug Staiger, Chris Walters, and
seminar audiences at Arizona, ASHEcon, Carnegie Mellon, Case Western Reserve University,
Chicago Booth, Cornell Weill, Duke, Johns Hopkins, Maryland, MIT, NBER (Organizational
Economics), North Carolina, Paris School of Economics, Queen’s University, Rice, Stanford,
Tulane, and WEAI for helpful comments. Joel Katz and Amy Miller provided invaluable context
to the data. Samuel Arenberg, Atul Gupta, and Natalie Nguyen provided excellent research
assistance. I acknowledge support from the NBER Health and Aging Fellowship, under the
National Institute of Aging Grant Number T32-AG000186; the Charles A. King Trust
Postdoctoral Fellowship, the Medical Foundation; and the Agency for Healthcare Research and
Quality Ruth L. Kirschstein Individual Postdoctoral Fellowship 1-F32-HS021044-01. The views
expressed herein are those of the author and do not necessarily reflect the views of the National
Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2016 by David C. Chan, Jr. All rights reserved. Short sections of text, not to exceed two
paragraphs, may be quoted without explicit permission provided that full credit, including ©
notice, is given to the source.
Informational Frictions and Practice Variation: Evidence from Physicians in Training
David C. Chan, Jr
NBER Working Paper No. 21855
January 2016, Revised November 2016
JEL No. D20,D83,I10,L23,L84,M11,M53,M54

                                         ABSTRACT

Substantial practice variation across physicians for seemingly similar patients remains an
unresolved puzzle. This paper studies physicians in training to explore the behavioral foundations
of practice variation. A discontinuity in the formation of teams reveals a large contribution of
relative experience in the size of practice variation. Among the same physician trainees,
convergence towards a common practice differs by practice environment, with more convergence
in specialist-driven services. Rich trainee characteristics and training histories, including the
practice styles of prior supervising physicians, explain little if any variation. These findings
suggest a major role for informational frictions in the origins of practice variation.


David C. Chan, Jr
Center for Health Policy and
Center for Primary Care and Outcomes Research
117 Encina Commons
Stanford, CA 94305
and NBER
david.c.chan@stanford.edu
1    Introduction

    There exists large variation in health care spending in the United States. Much of the extensive

literature on this subject has focused on how care varies across regions, understandably because

of unobserved patient sorting within regions to hospitals and physicians.1 However, very little is

known about the behavioral foundations of variation from individual agents. Using quasi-random

assignment of patients to teams of physicians in training (“housestaﬀ”) at a large academic hospital,

this paper aims to describe the evolution of practice variation among internal medicine housestaﬀ

in order to shed light on the behavioral foundations underlying practice variation.

    While this study is necessarily limited to within an organization, it is well-suited to assess the

behavioral foundations of practice variation in two respects. First, while the state of the art in the

area-level variations literature is making progress in separating causes into two broad categories of

patient-specific “demand” factors and place-specific “supply” factors (Finkelstein et al., 2016), this

study holds fixed demand factors (by patient random assignment) as well as institutional supply

factors (e.g., financial incentives, capital endowments, market structure, and culture). This allows

me to focus instead on the sources of variation across agents within an institution, which is intuitively

important but not well understood. Second, residency training is a promising setting to study the

dynamics of physician practice variation, as it is perhaps the most formative period in physicians’

careers, when trainees begin with very little prior clinical experience and engage in intensive training

in a controlled environment. This allows me to track, with detailed patient-care and administrative

data, the evolution of variation among housestaﬀ as they transition to diﬀerent team roles and

rotate among diﬀerent practice environments.

    I first demonstrate clinically significant variation attributable to housestaﬀ who are quasi-

randomly assigned patients. Assignment of patients to housestaﬀ within the same organization

has causal eﬀects on daily total spending, daily test spending, length of stay, and 30-day readmis-

sions, and even 30-day mortality. While much of the regional variations literature has found no

correlation between spending and outcomes (e.g., Fisher et al., 2003a,b), I find that housestaﬀ who

spend more have better outcomes, a finding consistent with more recent evidence by Doyle et al.
   1
     See, e.g., Skinner (2012) for a recent review of the literature, which dates at least to Wennberg and Gittelsohn
(1973) in the US and Glover (1938) in the UK.




                                                         1
(2015), which studies quasi-random variation in patient assignment across hospitals. Although as-

sociations between spending and mortality are imprecise, reassigning patients from 10th-percentile

to 90th-percentile housestaﬀ in the spending distribution would also lower readmissions by a 2.5

percentage points, eliminating about a fifth of readmissions. Accounting for correlations between

spending and outcomes implies variation in eﬃciency across housestaﬀ that is 12% to 60% smaller

than variation in spending.

   Next, in a stylized framework with learning and team decisions, I conceptually show that practice

variation does not necessarily decrease with experience. Rather, as physicians gain more precise

beliefs about practicing medicine, they may also gain greater influence so that their beliefs count

more in team decisions. I empirically examine this concept of influence within teams by exploiting

a mechanical discontinuity in housestaﬀ roles: Since patients are cared for by a team comprised of

a first-year “intern” and a second- or third-year “resident,” the relative experience of a housestaﬀ

changes discontinuously across the one-year mark. This separates the eﬀect of influence from time-

varying but plausibly continuous characteristics of the index housestaﬀ, such as skills and cumulative

learning. The standard deviation of spending eﬀects across housestaﬀ discontinuously increases from

approximately a 20% diﬀerence in costs among year-end interns to a 70% diﬀerence in costs among

beginning residents.

   I investigate learning through the evolution of practice variation in terms of both persistence

and convergence. Practice patterns become increasingly persistent within housestaﬀ, even if they

show little convergence overall. However, convergence in practice diﬀers significantly across practice

environments. Resident practices converge in specialist-driven services – cardiology and oncology

– eliminating much of the variation by the end of residency, while the same residents show no

convergence when practicing in general medicine. One plausible explanation for the diﬀerential

learning towards a common practice is the greater existence and use of explicit medical knowledge

in specialist services. However, at a minimum, this finding shows the eﬀect of the environment on

the development of practice variation, holding the agents who learn fixed. This diﬀerence between

specialist- and generalist-driven services is highly significant with systematic placebo tests random-

izing service-block identities, and this diﬀerence holds when matching patients based on formally

coded diagnoses.

   Finally, as a benchmark to the above results, I quantify practice variation predictable by hous-

                                                  2
estaﬀ characteristics and prior observable training experiences, using the following: (a) detailed

housestaﬀ characteristics from confidential residency selection and administrative data (e.g., test

scores, rank-list positions, honors); (b) precommitted career choices in which housestaﬀ with dif-

ferent future plans are required to have the same initial training in internal medicine; and (c)

histories of training experiences (e.g., whether the housestaﬀ recently trained with a high-spending

supervising physician) that are as good as randomly assigned. Housestaﬀ characteristics predict

in aggregate only a small portion of the large underlying spending variation. When using LASSO

to avoid overfitting due to the large number of characteristics relative to the number of housestaﬀ,

the sole predictive characteristic is male sex, which predicts 4% less spending among residents,

whereas the standard deviation of practice variation among residents is at least 15 times greater.

Similarly, housestaﬀ tenure does not significantly shift mean levels of spending or other outcomes

(e.g., readmission and mortality), and a wide variety of training experiences have no true predictive

power.

       Together, these findings are most supportive of informational frictions as a major mechanism

sustaining practice variation, in the following sense: The importance of relative influence is consis-

tent with knowledge gained through experience but not easily passed from senior agents to junior

agents.2 Further, the degree of convergence as housestaﬀ learn diﬀers across practice environments,

holding the housestaﬀ fixed. These information-based mechanisms of influence and learning are

an order of magnitude more relevant to practice variation than intrinsic heterogeneity, to the ex-

tent that any of it is correlated to detailed physician characteristics related to skill and preferences.

These findings, based on 3.2 million orders tracking physicians as they train, provide complementary

evidence to surveyed physician beliefs (Cutler et al., 2013), especially when much of what physicians

do may arise from knowledge, beliefs, or habits that are not easily elicited by asking them.

       At least since Arrow (1963), informational frictions in medical care have been well-known, and

at least since Polanyi (1966), tacit knowledge – “knowledge,” possibly including beliefs or habits,

that is diﬃcult to communicate – has been considered a significant barrier in the standardization

of decisions and routines across workers (Nelson and Winter, 1982; Autor et al., 2003). However,
   2
    In Appendix A-3, I discuss how this idea is consistent with possibility of social authority or hierarchy. Authority
as a function of knowledge, even when used to describe a profession independent of any individual’s knowledge, is
explored in detail by Starr (2008), who documents the rise of the medical profession as specialized scientific knowledge
expanded.



                                                           3
tacit knowledge has not received much consideration in the economics literature as a behavioral

foundation for practice variation in health care, possibly because it is inherently diﬃcult to measure

and more generally due to a lack of micro-level data to document and follow significant variation in

a controlled environment.3 Indeed, perhaps the most surprising finding of this study is the size and

persistence of variation across housestaﬀ despite being observed in selective and intensive training.

The evidence of informational frictions as a foundation for practice variation in this homogeneous

environment is in some sense a lower bound for informational frictions across institutions and among

physicians who are not actively training.

        The remaining organization of this paper is as follows. Section 2 describes the institutional

setting; Section 3 describes the data. Section 4 presents a first look at meaningful variation across

housestaﬀ in several outcomes. Section 5 discusses variation across the discontinuity of relative

experience, and Section 6 discusses convergence (or the lack thereof) in diﬀerent environments.

Section 7 describes results on the predictive power of housestaﬀ characteristics and experience on

outcomes. Section 8 discusses policy implications and concludes.


2        Institutional Setting

2.1       Medical Care by Physicians in Training

        Since the Flexner Report in 1910, medical training has largely become standardized across the

US (Flexner, 1910; Cooke et al., 2006). Each patient is cared for by a team of a first-year housestaﬀ

(“intern”) and a second- or third-year housestaﬀ (“resident”). Residents are usually assigned to two

interns at a time and therefore are responsible for twice the number of patients. As a result, span

of control considerations argue for more control by interns over their patients than residents do,

as interns can devote more attention to each patient. There are no other formal distinctions in

decision rights or job responsibilities between interns and residents, including legal or regulatory

ones, but residents are expected to know more and often engage in higher-level decision-making in

patient care. These housestaﬀ teams are supervised by “attending” physicians and operate within a
    3
    See Cutler (2010) and Skinner (2012) for thoughtful reviews on potential causes of practice variation. Much of
the conventional wisdom focuses on a lack of competition across firms, due for instance to health insurance and lack
of quality measurement. The evidence in this paper would suggest that the issue goes beyond measuring “quality” and
that for large areas of medicine, there is a lack of agreement on what constitutes best practices for a given patient.




                                                          4
broader practice environment, which includes other health care workers (e.g., consulting physicians,

pharmacists, and nurses), as well as institutional rules for deciding and implementing care.

       Housestaﬀ from diﬀerent programs and diﬀerent “tracks” within a program work together on

the same clinical services. For example, a sizeable number of interns only plan to spend one year

in the internal medicine residency (“preliminary” interns, as opposed to the standard “categorical”

interns), subsequently proceeding to other residency programs, such as anesthesiology, radiology,

or dermatology.4 These plans are committed to prior to starting the internal medicine residency.

In addition, medical housestaﬀ from another hospital and obstetrics-gynecology and emergency

medicine housestaﬀ from the same hospital work alongside housestaﬀ from the main residency

program in the same teams and on the same services.

       Housestaﬀ schedules are arranged a year in advance to satisfy hospital programmatic require-

ments and broader regulations. Rotations include intensive care unit (ICU), outpatient, research,

subspecialty (mostly outpatient) electives, and ward blocks. This study focuses on inpatient ward

rotations, which are comprised of cardiology, oncology, and general medicine services. Per residency

administration, preferences are not collected about rotations, and assignment does not consider

housestaﬀ characteristics, although housestaﬀ on certain tracks may be unavailable during certain

times due to programmatic diﬀerences.5 Scheduling does not consider the teams of intern, resident,

and attending physicians that will be formed as a result. In fact, attending schedules are done

independently, and neither housestaﬀ nor attending scheduling is aware of each other’s results in

advance.

       Patients arriving at the hospital are assigned to interns and residents by algorithm, which

distributes patients in a rotation among housestaﬀ that are “on-call” and have not reached the

maximum number of patients. Patients who remain admitted for more than one day may also be

mechanically transferred between housestaﬀ changing rotations. When a housestaﬀ replaces another

one, she assumes the care of the entire list of patients from the other housestaﬀ. Because housestaﬀ

blocks are generally two weeks in length and staggered for interns and residents, it is not uncommon
   4
     In addition, tracks within a residency program include primary care, “short tracks” to fellowship training, research
tracks such as genetics, and medicine-pediatrics or medicine-psychiatry combined programs.
   5
     Housestaﬀ are allowed to express preferences about vacation days, although these vacation days are few, about
two weeks per year. Senior residents (third-year residents) may also express more general preferences about the
timing of non-clinical blocks, such as research electives. For interns, schedules are assigned even prior to their arrival
from medical school.



                                                            5
for a patient to experience a change in either an intern or a resident.

2.2     Medical Knowledge

      Inpatient medical care is comprised of three services at this institution: cardiology, oncology,

and general medicine. This organization represents the most common configuration of inpatient care

across academic hospitals in the US. Of the 24 residency programs ranked by US News & World

Report and shown in Table A-2, 22 and 19 programs have dedicated cardiology and oncology services,

respectively. Gastroenterology, represented at 6 programs, is the next most common subspecialty

service. A similar relationship among subspecialties exists in the universe of internal medicine

programs recognized by ACGME (Table A-3). Specialist-driven services by definition are staﬀed by

specialist attending physicians, who have several more years of training after internal medicine. In

contrast, generalists are responsible for patients on general medicine services, who may optionally

consult a specialist if they deem it helpful.

      In recent decades, by important measures, medical knowledge has progressed in cardiology and

oncology to a greater extent than for other diseases.6 Table A-4 shows the number of original

research articles appearing in the New England Journal of Medicine in the last ten years according

to key disease specialty or subspecialty. Oncology and cardiology research papers are the most

numerous by a substantial margin. Table A-5 reports current research funding by National Institute

of Health (NIH) Institute or Center. Although Institutes often lump disease categories, the National

Cancer Institute (NCI) with current funding of $6.7 billion and the National Heart, Lung, and Blood

Institute (NHBLI) with current funding of $3.6 billion occupy the first and third positions for funding

out of a list of 27 Institutes and Centers.

      In this sense cardiology and oncology care have stronger “best practices” than other subspe-

cialties of internal medicine. Diﬀerences in best practices can aﬀect variation in two ways. First,

strong best practices, embedded in attending physicians, ancillary staﬀ, and institutional rules,

constrain variation in housestaﬀ decisions even if these housestaﬀ have not yet fully internalized all

information available at the institution. Second, environments with stronger best practices will be

more conducive to learning. The fact that physicians need further subspecialty training to assume
  6
   The production and use of knowledge is in turn driven by government, academic, and industry priorities. For
example, in some locations and in the past, tuberculosis wards were common but cease to exist today.




                                                      6
primary responsibility for cardiology and oncology patients, but not to treat pneumonia, may also

reflect a larger body of knowledge used to care for these patients.7


3        Data

        This study uses data collected from several sources. First, I observe the identities of each physi-

cian on the clinical team – the intern, resident, and attending physician – for each patient on an

internal medicine ward service and for each day in the hospital. Over five years, I observe data for

48,185 admissions, equivalent to 220,117 patient-day observations. Corresponding to these admis-

sions are 724 unique interns, 410 unique residents, and 540 unique attendings. Of the housestaﬀ, 516

interns and 347 residents are from the same-hospital internal medicine residency, with the remainder

visiting from another residency program within the same hospital or from the other hospital. There

is no unplanned attrition across years of residency.8

        Detailed residency application information for each housestaﬀ includes demographics, medical

school, USMLE test scores, membership in the Alpha Omega Alpha (AOA) medical honors society,

other degrees, and position on the residency rank list. USMLE test scores represent a standardized

measure of resident knowledge and ability. Position on the residency rank list represents desirability

to the residency program, according to both criteria that I observe and those assessed during

the interview and potential recruitment process. Finally, I observe precommitted career “tracks”

for each housestaﬀ physician, including special tracks (e.g., primary care, genetics), the standard

“categorical” internal medicine track, and tracks into another residency such as anesthesiology,

dermatology, psychiatry, or radiology after a preliminary intern year.

        I use scheduling data and past matches with supervising attending physicians and other houses-

taﬀ to impute housesetaﬀ experience over time. As described in Section 2, housestaﬀ do not choose

most of their learning experiences, at least in terms of their clinical rotations and in what order,

peers and supervising physicians, and patients seen on the wards. Table 1 shows that interns and
    7
     Several observers have noted that the increasing length of training in medicine seems to related to the growing
role of scientific knowledge and technology in medicine (Ludmerer, 1988; Starr, 2008). For example, prior to the
beginning of the 20th century, practitioners could become doctors in a matter of weeks. Although the first American
residency was started at Johns Hopkins in 1889, teaching hospitals and residencies only grew to prominence in the
1920s, when suﬃcient technological knowledge (and, to a degree, urbanization) shifted care from patients’ homes to
hospitals.
   8
     In two cases, interns with hardship or illness in the family were allowed to redo intern year.




                                                         7
residents, respectively, with high or low spending eﬀects are exposed to similar types of patients and

are equally likely to be assigned to high- or low-spending coworkers and attendings. In Appendix

A-1, I present more formal analyses on conditional random assignment of housestaﬀ physicians;

I cannot reject the null that housestaﬀ identities are jointly unrelated to patients types or other

training experiences.

       Patient demographic information includes age, sex, race, and language. Clnical information

derives primarily from billing data, in which I observe International Classification of Diseases,

Ninth Revision, (ICD-9) codes and Diagnostic-related Group (DRG) weights. I use these codes to

construct 29 Elixhauser comorbidity dummies and Charlson comorbidity indices (Charlson et al.,

1987; Elixhauser et al., 1998). I also observe the identity of the admitting service (e.g., “Heart Failure

Team 1”), which categorizes patients that are admitted for similar reasons (e.g., heart failure).9

       For each patient-day, I observe total cost information, aggregated within 30 billing departments

such as blood bank, various laboratory, nursing, nutrition, pharmacy, physical therapy, radiology.

I also observed more detailed cost information specific to each of 3.2 million physician orders in

laboratory and radiology (e.g., CT, MRI, nuclear medicine, ultrasound). Admission and discharge

data allow me to impute length of stay in days and readmission rates. Finally, dates of death

are provided via linkages with social security vital statistics data. While I study variation across

housestaﬀ in each of the outcome measures of daily total costs, daily test costs, length of stay,

readmissions, and mortality in Section 4, for most of the paper I focus on daily test costs (a)

because they are most closely controlled by housestaﬀ, (b) because daily outcomes linked to a

large number of physician orders allow for greater precision in measuring variation, and (c) because

they capture variation in diagnostic approaches, the heart of medical decision-making, including

in situations in which very little is known about patients.10 The distribution of daily test costs is

heavily right-skewed. I censor daily test cost observations greater than $800, which comprise 3% of
   9
      These admitting services are more narrowly defined than the broad categories of cardiology, oncology, and general
medicine. However, even within specific admitting service, attendings may have diﬀerent types of patients (e.g., a
vertically integrated HMO admits to the same service as the hospital’s own attendings). Therefore, without hand-
coding attendings to practice groups and conditioning on these groups, patients are not quasi-randomly assigned
to attendings. Still, as described above, housestaﬀ are quasi-randomly assigned to patients, other housestaﬀ, and
attendings.
   10
      Medical spending has been the focus of much of the literature on practice variation (Fisher et al., 2003a,b) and
is a key policy focus in its own right (Anderson et al., 2005). Test spending has particularly received increasing
attention as the relative cost of tests has risen and now comprises a significant proportion of overall costs (Schroeder
et al., 1974; Iwashyna et al., 2011).



                                                           8
the data; the resulting distribution is shown in Figure A-5.11 The mean daily test cost is $124, while

the median is $49 and the 90th percentile is $337. These daily costs aggregate to overall admission

tests costs with a mean of $714.


4         Variation across Housestaﬀ

         I first examine variation attributable to housestaﬀ, specifically residents, in each of the following

outcomes: log total spending on day of admission, log test spending on day of admission, log

length of stay, 30-day readmission, and 30-day mortality. I specify each outcome Yajkt – indexed by

admission a, time t, resident j, and attending k – and use a random eﬀects framework to estimate

variation attributable to housestaﬀ, while conditioning on patient-admission characteristics Xa (see

Section 3), time categories Tt for month-year combination and day of the week, and attending

identities:

                                         Yajkt = g (PY (Xa , Tt , k)) + ξj + εajkt .                      (1)

The object of interest in this specification is an estimate of the variation in ξj , accounting for

sampling error and patient characteristics, time period, and identities of (non-randomly assigned)

attending physicians. PY (Xa , Tt , k) is a linear projection of outcomes Yajkt onto Xa , Tt , and k,

using only within-housestaﬀ variation, g (·) is a potentially flexible transformation of the projection,

ξj is a resident random eﬀect possibly correlated with PY (Xa , Tt , k), and εajkt is an error term

that is normal for log spending and log length of stay or logistic for binary outcomes of readmission

and mortality. For binary outcomes, Yajkt is a latent variable that determines the observed binary

outcome Ỹajkt = 1 (Yajkt > 0).

         As a simple benchmark of variation in diﬀerent outcomes, this exercise treats practice variation

as fixed over time within residents, in contrast to the fuller statistical model in Sections 5 and 6

that nonparametrically allows for drift over time. Naturally, the time-invariant variation estimated

in this section will be lower than the variation across housestaﬀ within smaller time intervals that

I investigate in later sections.

         Although patients are conditionally as good as randomly assigned to housestaﬀ (Appendix A-1),

random assignment does not hold across time categories and admitting services. This motivates a
    11
         Results in this paper are robust to this censoring.



                                                               9
treatment of resident eﬀects that allows for correlation with PY (Xa , Tt , k). I thus separate ξj into

a correlated component uj and an uncorrelated component vj :


                                                   ξj = uj + vj ,


where Corr (uj , PY (Xa , Tt , k)) ̸= 0 and Corr (vj , PY (Xa , Tt , k)) = 0. I restrict comparisons across

housestaﬀ to the uncorrelated component, vj , for two reasons. First, comparing housestaﬀ with

diﬀerent average PY (Xa , Tt , k) is less likely to be valid because patients are not randomly assigned

between these housestaﬀ. Second, uj is mechanically correlated across diﬀerent outcome measures

by the correlation between uj and patient observed and unobserved characteristics captured by

PY (Xa , Tt , k).12 Given this setup, which I describe in more detail in Appendix A-2, I calculate

empirical Bayes predictions v̂j (Searle et al., 1992) for each resident in each of the outcome measures.

       Figure 1 shows distributions of resident eﬀects in each outcome measure. Within the same

institution and set of housestaﬀ, reassigning patients from the 10th-percentile- to the 90th-percentile-

v̂j resident (among residents exposed to patients with the same PY (Xa , Tt , k) on average) increases

respective outcomes of total spending on admission, test spending on admission, and length of stay

by about 20%. In dollar terms, respective reassignment from the 10th to 90th percentile resident

increases total spending on admission from $1,022 to $1,245, and test spending on admission from

$135 to $164.13 Reassignment according to length of stay increases length of stay from 3.64 days

to 4.35 days. Reassignment from the 10th to 90th percentile according to 30-day readmissions and

30-day mortality increases these events from 9.6% to 16.4%, and from 5.1% to 10.3%, respectively.

       Figure 2 shows correlations between resident eﬀects in spending and clinical outcomes. Con-

sistent with Doyle et al. (2015), which measures correlations between hospital eﬀects on spending

and outcomes, identified by random arrivals of patients by ambulance to hospitals, I find a similar
  12
     Standard approaches (e.g., Abowd et al., 2008) to correlated random eﬀects will mechanically assign uj based
on PY (Xa , Tt , k) and therefore induce correlation in uj between diﬀerent outcome measures driven by projections
of patient types onto outcomes. For example, patients in the bone marrow transplant service are more resource-
intensive patients and also more likely to die. Comparing housestaﬀ who spent more and less time on the bone
marrow transplant service would thus induce a correlation in uj between spending and mortality.
  13
     Variation in spending on admission is less than variation in spending on all days, even when controlling for
day of stay. This indicates that spending on the first day, even though it is generally higher, is less variable in log
terms. I show results for variation in daily spending in Table 4 (Section 7), although that table and Figure 1 are
not directly comparable since the former states variation in terms of the standard deviation of the directly estimated
random eﬀect distribution while the latter states variation in terms of shrunken empirical Bayes predictions v̂j . I
focus on variation on day of admission in this section in order to assess the relationship between resident eﬀects on
admission-level outcomes and daily-level outcomes.


                                                          10
positive relationship between spending and clinical outcomes across residents. Residents who spend

more either in total or by testing have fewer 30-day readmissions. Reassigning patients from the

10th to 90th percentile of v̂j according to total spending would reduce readmissions by 2.5 per-

centage points, or eliminate about a fifth of readmissions. The relationship between spending and

mortality is slightly negative but small and statistically insignificant. These relationships imply

smaller variation in eﬃciency, as much as 12% to 60% smaller, than variation in spending across

housestaﬀ.14


5         Influence

         This section examines the eﬀect of relative influence in teams on the variation of housestaﬀ

eﬀects. In Appendix A-3, I introduce a simple conceptual framework to consider decision-making

in teams under uncertainty. While details are in the appendix, the intuition is straightforward: in

a team environment under uncertainty, decisions will aggregate information from diﬀerent agents’

prior beliefs, and this aggregation depends on both the means of the priors as well as relative

precisions of the priors. While agents learning from common data and underlying truth should

converge to the same practices when making decisions individually, the information-aggregation

feature of team decisions, which can be thought of as a foundation for influence, gives rise to the

possibility that an agent’s eﬀect on variation may increase even as she learns.

         To estimate the importance of influence in practice variation in a team environment, I exploit

the discontinuous change in roles at the end of the first year of training. In particular, a housestaﬀ

near the end of the first year still has at least one year less experience than the other teammate,

while the same housestaﬀ at the beginning of the second year has one year more experience than

the other teammate. This allows me to focus on a discontinuous change in relative influence, while

holding everything else fixed about the index housestaﬀ that is plausibly continuous. The institu-

tional setting of residency has the dual advantages of no diﬀerences in formal roles that mechanically
    14
    Assessing optimal spending or quantifying variation in eﬃciency is not the focus of this paper. However, a
back-of-the-envelope calculation would imply that relative to variation in total spending, accounting for the negative
relationship between readmission eﬀects and spending eﬀects (coeﬃcient of -0.125) would reduce the variation by
12.5%. Further using the point estimate on mortality reductions (coeﬃcient of -0.0136), average admission cost of
$7,050, $50,000 for the value of a life year (e.g., Cutler et al., 2013), and an assumed life-expectancy of 5 years
in the event of not dying within 30 days (e.g., Alter et al., 2012), reduces the variation in eﬃciency by another
(5 × $50, 000 × 0.0136) /$7, 050 = 48.2%.




                                                         11
increase resident influence and no unobserved selection into senior roles.15 Nevertheless, the “influ-

ence eﬀect” may still be considered a reduced-form combination of (a) true diﬀerences in the relative

quality of information for a given housestaﬀ at the discontinuity and (b) perceived diﬀerences that

can include things like hierarchy and prestige due to seniority in medicine. As discussed in Appendix

A-3, the latter phenomenon of hierarchy can be thought of as consistent with the framework of team

decision-making under uncertainty, in which informational frictions prevent agents from objectively

knowing or even communicating each other’s true informational content.

     For a patient being treated on day t of admission a by intern i, resident j, and attending k, I

specify log daily test costs as


                                                              τ (i,t)      τ (j,t)
                                  Yaijkt = Xa β + Tt η + ξi             + ξj         + ζk + νa + εaijkt .          (2)


Equation (2) includes patient and admissions characteristics Xa , and a set of time categories Tt for

month-year combination, day of the week, and day of service relative to the admission day. I allow

for attending fixed eﬀects, ζk .16

     The parameters of interest in Equation (8) characterize distributions of time-varying random
             τ (i,t)          τ (j,t)
eﬀects, ξi             and ξj           for intern i and resident j, respectively, at discrete tenure interval τ (·, t)

that is function of the housestaﬀ and time. In Appendix A-3, I explain how this additive but time-

varying specification can be based on a team-theoretic framework of Bayesian decision-making.
 τ (i,t)           τ (j,t)
ξi         and ξj            is constant within each tenure interval and housestaﬀ, but for this analysis I

impose no structure across tenure intervals for the same housestaﬀ. As described in Appendix A-5,

I employ a method akin to restricted maximum likelihood (REML) and similar to an approach

by Chetty et al. (2014) that allows random eﬀects to be correlated with fixed covariates without
                                                                                                       τ (·)
further modeling of the correlation. Tenure-specific standard deviations of ξh∈{i,j} are then directly

and jointly estimated by maximum likelihood. These empirical estimates of practice variation are
  15
     Moreover, as mentioned in Section 2, two interns are usually assigned to a resident, and as a result, interns
have more per patient clinical interactions and greater control over orders. These institutional facts suggest that, if
information were equal, interns should have more influence than residents in the care of a given patient. As such,
an observed increase in influence at the first-year mark may be viewed as a lower bound of the eﬀect of more precise
information on influence.
  16
     Physician practice patterns have been found to be quite stable in the existing literature, which motivates fixed
eﬀects that are time-invariant (Epstein and Nicholson, 2009; Molitor, 2016). I do not focus on practice variation
among attending physicians for two practical reasons: First, unlike housestaﬀ physicians, they are not randomly
assigned patients. Second, they are only variably observed in the data, with many attendings working only a few
weeks a year.


                                                                  12
unbiased even in finite samples.17 Finally, in some specifications I allow for shocks at the admission

level, νa , allowing some patients, even controlling for patient observables, to randomly result in

more test costs than others.

         Figure 3 presents results for the estimated standard deviations of the distributions of housestaﬀ

eﬀects within each tenure interval τ . In my baseline specification, I consider non-overlapping tenure

intervals that are 60 days in length for the first two years of residency, and 120 days in length for

the third year, since third-year housestaﬀ have fewer inpatient days.18 I find large and significant

variation in housestaﬀ eﬀects during all intervals of time. A standard-deviation increase in the
                    τ (i,t)
intern eﬀect, ξi              , increases test spending by about 20%. A standard-deviation increase in the
                      τ (j,t)
resident eﬀect, ξj              , increases spending by about 70%. In comparison, the standard deviation for

admission-level eﬀects, νa , is 40%; including or omitting admission-level random eﬀects does not

significantly alter results. Given the large qualitative heterogeneity across patients in inpatient care,

it is notable that residents alone are responsible for more variation in spending than unobserved

patient characteristics.

         Physician eﬀects are determined by both individual beliefs and relative influence. However,

under the assumption that housestaﬀ beliefs are continuous over time, the discontinuity at the

one-year tenure mark identifies the change in influence due to a discontinuous increase in relative

tenure, from being at least one year less experienced to being one year more experienced than

the teammate. The change in spending-eﬀect variation indeed is highly discontinuous, tripling in

standard deviation across the one-year tenure mark. This implies a large eﬀect of relative influence

on the size of physician spending variation.


6         Learning: Persistence and Convergence

         In this section, I examine housestaﬀ learning, based on two main sources of evidence. First,

I study the serial correlation of housestaﬀ eﬀects across adjacent time periods, as a measure of
    17                                                                τ (·)
     It is well-known that in finite samples fixed eﬀect estimates of ξh∈{i,j} would include measurement error and
therefore would have a distribution with greater variance than the underlying distribution of true eﬀects. However,
because I necessarily specify two sets of eﬀects, one for the intern and the other for the resident, there are two
complications to the standard Bayesian shrinkage procedure (e.g., Morris, 1983) which result in biased estimates of
the distribution that I confirm in simulations. This is discussed further in Appendix A-5.
  18
     I observe approximately half as many patient-days for housestaﬀ in the third year, because third-year housestaﬀ
spend more time in research and electives than in the first two years of training.




                                                          13
persistence. Because correlation should be invariant to changes in scale, it measures persistence in

a way that is conceptually distinct from changes in influence. Increasing persistence reflects that

physicians are settling on choices similar to their past choices in a way that sets them apart other

physicians.19

    Second, I study the convergence of housestaﬀ eﬀects with tenure, separately in the diﬀerent

practice environments of specialist and generalist services. Convergence – defined as a decrease

in the variation of housestaﬀ eﬀects with tenure – implies that housestaﬀ become more like one

another in their eﬀects and is a more direct test of learning to practice a common standard or “best

practice.” A lack of convergence requires not only that housestaﬀ do not learn to practice a common

standard but also that their practice styles remain distinctive from one another. A greater degree of

convergence in one environment over another may suggest more learning toward a common practice.

At a minimum, it provides evidence that the practice environment, holding the agents fixed, may

determine the dynamics of practice variation over time.

6.1    Persistence

    I study the serial correlation across estimated housestaﬀ eﬀects across tenure intervals. The

model for housestaﬀ eﬀects remains specified in Equation (2), but the estimation procedure now

includes two periods and specifies a parameter in the variance-covariance matrix of housestaﬀ-tenure

eﬀects that allows for this correlation. Details are described in Appendix A-5.2. This procedure can

yield estimates of the correlation between eﬀects in any two tenure periods, but I am particularly

interested in the serial correlation between two adjacent periods.

    Figure 4 shows correlation estimates between each tenure interval and the previous interval.

Estimates are less precise than the standard deviation across housestaﬀ eﬀects within each tenure

period (Figure 3).20 The overall lower precision is not surprising given that correlation estimates
  19
     In the conceptual framework in Section A-3, particularly in Equation (A-8), this persistence may be most literally
thought of as persistence of beliefs mh . The development of persistent but heterogeneous practices is consistent
with housestaﬀ ceasing to learn a common practice. However, unchanging heterogeneity alone may also represent
heterogeneous preferences or skills. These two sources can be separated somewhat by the time course of correlation
(e.g., high correlation from the beginning suggests intrinsic heterogeneity). I explore intrinsic heterogeneity further
in Section 7.
  20
     This figure additionally shows results based on a Bayesian refinement, discussed in Appendix A-6, that also uses
correlations between non-adjacent periods. Results and similar with or without the refinement. This perhaps reflects
a general consistency in estimation correlations both between adjacent periods and between non-adjacent periods.
Alternatively, Proposition A-4 in Appendix A-6 also states that the informativeness of these auxiliary correlations
can be low if they are close to 0.



                                                          14
require observing the same housestaﬀ across diﬀerent periods. It is also important to have a suf-

ficient number of observations per housestaﬀ in each period, for a suﬃcient number of housestaﬀ,

because the correlation depends on the relative values of eﬀects across housestaﬀ both within period

and across periods. By contrast, measuring the standard deviation across housestaﬀ eﬀects only

requires more than one observation per housestaﬀ within period in order to decompose the variance

components due to housestaﬀ and patient-days.

     Nonetheless, central estimates are all above 0 and are generally increasing with tenure. That

is, a higher-spending housestaﬀ is always more likely than not to be higher-spending in the next

period. Many of the central estimates are economically significant, using correlations estimated by

Chetty et al. (2014) for teacher value-added as a reference. At the same time, the upper limit of

the 95% credible interval of the Bayesian posterior rules out extremely high serial correlations for

almost all of the tenure periods. Only one of the fourteen periods has an upper limit greater than

0.70. This suggests that some non-trivial learning continues to occur throughout training and is

inconsistent with pure intrinsic heterogeneity as the sole explanation for practice style variation. I

will explore intrinsic heterogeneity correlated with rich observable characteristics further in Section

7.

6.2    Convergence

     In order to assess convergence across practice environments, I estimate Equation (2) for each of

the three ward services of cardiology, oncology, and general medicine. As in Section 5, this yields

the standard deviation of housestaﬀ eﬀect distributions by tenure, now separately for each of the

ward services. In Figure 5, I show each of these profiles of housestaﬀ-eﬀect variation over tenure for

cardiology, oncology, and general medicine. Housestaﬀ eﬀects significantly converge in cardiology

and oncology, but for the same residents, there is no evidence of convergence in their practice

patterns in general medicine. The standard deviation of spending variation steadily declines from

85% in cardiology and 75% in oncology, at the beginning of second year (as residents), to 37% in

cardiology and 53% in oncology by the end of training.

     Merging cardiology and oncology services into a single “specialist service,” I quantify a rate of

convergence in spending eﬀects among residents of about a 16% percentage-point decrease in the

standard deviation of housestaﬀ eﬀects per year. In other words, given a standard deviation of


                                                  15
74% at the beginning of the second year (when interns become residents), this is equivalent to a

relative decrease of 43% of this standard deviation over the next two years.21 Randomizing over

10,000 placebo combinations of housestaﬀ-service-months (of about 1.27×10970 combinations) yields

a range of placebo convergence estimates of [−0.073, 0.085], suggesting that the actual estimate

−0.160 is extremely significant (see Figure 6). Details are given in Appendix A-7.

6.2.1      Decomposing Experience Leading to Convergence


       Using variation in the order of housestaﬀ training experiences, I explore the contribution of

general versus specific experience on cardiology or oncology in determining convergence in these

respective services. This distinction is informative for understanding the pathways through which

learning takes place for the care of patients on these services, for example distinguishing the in-

formation being learned (routines for cardiology patients) vs. the teachers per se (cardiologists).

Convergence according to specific experience suggests that learning occurs via direct experience

with patients and attending physicians on the respective cardiology and oncology services. Con-

vergence according to general experience could still be consistent with greater learning towards

common practice for patients in specialist-driven services, but that this learning may also occur via

experiences outside of these services.

       In order to separate general from specific experience, I exploit variation in the order of housestaﬀ

training across services. I decompose the set of observations into subsets representing deciles of

specific experience “orthogonal” to general experience, and vice versa. I construct linear boundaries

between subsets as linear quantile regressions of specific experience (i.e., number of days on service

s that resident j has had by day t, τs (j, t)) on general experience (i.e., days of tenure τ (j, t)), and

vice versa, over housestaﬀ-day observations in service s. Figure 8 shows the variation in specific and

general experience, for cardiology and oncology, with overlaid decile boundaries. This representation

of experience is most informative when there is large variation in training experiences (i.e., specific

experience is not perfectly predicted by general experience).22
  21
     The standard deviation during the first tenure period of the second year is 69%, but the linearized projection of
the trend over the next two years implies a standard deviation of 74% for this tenure period.
  22
     Intuitively, measures that are strongly positively correlated will result in a large proportion of overlapping obser-
vations in sets but in reverse order, e.g., a large proportion of observations in the first-decile set of one measure being
in the last-decile set of the other measure. This therefore will bias finding convergence with increasing deciles in both
measures, regardless of arbitrary actual positive eﬀects of both measures on convergence. Of course, if measures are
perfectly correlated, then defining orthogonal deciles will be impossible.



                                                            16
       I then estimate the distribution of resident-tenure eﬀects in Equation (2) for each orthogonal

decile of specific experience or general experience.23 Figure 9 shows plots of estimated resident

eﬀect standard deviations using observations in each of these deciles. Practice in cardiology shows

clear reductions in variation along increasing deciles of general and specific experience. Results for

oncology are less clear; convergence perhaps is stronger with increases in general experience. These

results decompose convergence in the specialist-driven services into two mechanisms. First, at least

for cardiology, convergence specifically occurs via experience on the same service. Second, general

experience, independent of time spent on cardiology or oncology rotations, also fosters adoption

of the best practices for patients on the specialty services. For example, managing cardiovascular

disease in outpatient, emergency department, and general inpatient settings, trainees may learn

more about how to handle patients with well-defined cardiovascular disease on inpatient cardiology

wards. This pathway is consistent with knowledge spillovers (albeit asymmetric ones) across internal

medicine services.

6.2.2      Best Practices as Encoded by Organization


       Given convergence with general experience, it is natural to ask whether convergence reflecting

stronger best practices can be predicted by coded diagnoses. First, I explore whether convergence

may occur in cardiology and oncology because these services have a higher concentration of diagnoses

by constructing pseudo-services within general medicine that include the three most common Major

Diagnostic Categories (MDC) of circulatory, respiratory, and digestive (see Table A-6 for summary

statistics). I find no diﬀerence in convergence between these pseudo-services (Figure A-7). Relatedly,

there is no greater convergence in care for patients with more common diagnostic codes within service

(Figure A-8).

       Second, I examine whether stronger best practices can be identified by specific diagnoses, linked

to published guidelines in the national guideline repository maintained by the US Agency for Health-

care Research and Quality (guidelines.gov). Roughly half of the diagnoses coded in all services

are linked to a published guideline. As shown in Figure A-9, there is no diﬀerence in practice

convergence, within service, for patients with and without diagnoses linked to guidelines. This null
                                                           ′                                   ′
  23
    As before, I impose no relationship between ξhτ and ξhτ for τ ̸= τ ′ , but because ξhτ and ξhτ may now both be in
                                                                                                   ′
the same estimation sample (i.e., in the same orthogonal decile), I explicitly consider ξhτ and ξhτ as separate random
eﬀects.


                                                         17
finding suggests that guideline existence is an imperfect representation of true best practices, and

that coded diagnoses, despite their potential richness and widespread use as the foundation for re-

imbursement (and research), are an imperfect measure of care-relevant patient conditions. Finally,

I replicate 97% of the diagnostic-code makeup of the cardiology service using patients from general

medicine, by selecting patients with ICD-9 codes in common with cardiology and weighting them

appropriately. I find no convergence in these patients from general medicine but with diagnostic

codes in common with cardiology (Figure 7).

         These findings are consistent with the complexity of information not only in characterizing best

practices but in identifying the patients themselves for which best practices are applicable. Although

it may be surprising that potentially rich administrative diagnostic codes are uninformative for

predicting convergence, closer examination reveals that codes used in practice are quite coarse. For

example, the most common formal diagnosis in both cardiology and general medicine is “Chest

pain, not otherwise specified.” 24 Further, the strong diﬀerence in convergence between specialist

and generalist services suggests that much more information is used in assigning patients in practice,

and that this assignment is meaningful.


7         Housestaﬀ Characteristics and Experience

         In Sections 5 and 6, I show that practice variation depends to a large degree on team roles and

the practice environment, despite a fixed cohort of housestaﬀ with broadly similar experiences in the

same training program. This suggests that information-based mechanisms are important drivers of

practice variation. Given the traditional emphasis on human capital and intrinsic heterogeneity (e.g.,

ability) (e.g., Doyle et al., 2010; Fox and Smeets, 2011; Bartel et al., 2014), a natural comparison is

to examine predicted diﬀerences in spending according to housestaﬀ characteristics and experience.

I use rich data on housestaﬀ characteristics and quasi-experimental variation in training experiences

to address this question in detail, and I find that mean eﬀects of numerous housestaﬀ characteristics

and measures of experience are either insignificant or an order of magnitude less important than

the mechanisms of relative influence and potential convergence. This suggests that traditional

concepts of intrinsic heterogeneity and human capital are less valuable predictors than informational
    24
    Table A-7 illustrates this further by listing the 15 most common diagnoses in each service, as well as whether
there exists a guideline for each of the listed ICD-9 codes.



                                                       18
mechanisms in understanding variation in health care practice.

7.1       Housestaﬀ Characteristics

       In the same training program, I observe predetermined and unusually detailed characteristics

that are likely correlated with diﬀerences in preferences and abilities.25 For example, USMLE

scores directly measure medical knowledge as a medical student; position on the residency rank

lists reflects overall desirability; and residency tracks reflect important career decisions and lifestyle

preferences, such as a decision to become a radiologist rather than a primary care physician. In

addition to housestaﬀ in the main residency program, I observe both interns and residents from

an internal medicine residency based in another hospital. For these outside-hospital housestaﬀ, I

can evaluate the eﬀect of their presence on medical teams. This eﬀect includes both diﬀerences in

selection into the diﬀerent program and in training experiences across the programs (the outside

residency is nationally recognized but lower ranked, and the outside hospital is known to be more

cost-conscious).

       Separately for each of these characteristics, and for interns and residents, I assess the relationship

these characteristics and daily test spending in regressions of this type:


                         Yaijkt = αm Characteristic m
                                                    h + Xa β + Tt η + ζ−hk + εaijkt ,                              (3)


                     h equals 1 if housestaﬀ h ∈ {i, j} had characteristic (or made track choice) m
where Characteristic m

prior to starting residency, and ζ−hk is a fixed eﬀect for the other housestaﬀ −h and attending k.26

The coeﬃcient of interest is αm , which is the causal eﬀect of a patient being assigned to a housestaﬀ

with characteristic m, includes eﬀects that may be directly related to m as well as eﬀects due to

any unobserved traits correlated with m.

       I also evaluate the combined predictive eﬀect of housestaﬀ characteristics in two steps. First, I

regress outcomes on all direct housestaﬀ characteristics, with continuous characteristics like position
  25
     Previous studies have investigated the eﬀect of coarse measures of observable physician characteristics (e.g.,
gender) and training experiences (e.g., place of medical school or residency) in a single regression (e.g., Epstein and
Nicholson, 2009). A challenge with this approach is that housestaﬀ may select into diﬀerent experiences. However,
these studies have also been unable to find any significant predictors of physician practice styles.
  26
     In principle, I could include housestaﬀ characteristics as mean shifters in the baseline random eﬀects model in
Equation (2). However, since characteristics are generally insignificant predictors of variation, results of (residual)
variation attributable to housestaﬀ are unchanged.




                                                          19
on rank list entered linearly, along with the other admission and time regressors in Equation (3):

                                 ∑
                      Yaijkt =       αm Characteristic m
                                                       h + Xa β + Tt η + ζ−hk + εaijkt .                       (4)
                                 m

                                                             ∑                      m
This yields a predicted score Zh for each housestaﬀ h, Zh =    m α̂m Characteristic h , which I
                        √
normalize to Z̃h = Zh / Var (Zh ) with standard deviation 1. Similar to Equation (3), I then

regress daily test spending on this normalized score:


                                 Yaijkt = αZ̃h + Xa β + Tt η + ζ−hk + εaijkt .                                 (5)


       Finally, I evaluate Equation (3) more flexibly by allowing splines of continuous characteristics

and two-way interactions between characteristics, while assuming an “approximately sparse” model

and using LASSO to select for significant characteristics (e.g., Belloni et al., 2014). This approach

guards against overfitting in finite data when the number of potential characteristics becomes large.

In total, excluding collinear characteristics, I consider 36 and 32 direct characteristics for interns and

residents, respectively, and 285 and 308 two-way interactions, as potential regressors in Equation

(3).

       Table 2 shows results for Equation (5) and a subset of results for Equation (3). Considering

characteristics individually in Equation (3), only two characteristics are statistically significant:

male sex and high USMLE test score. Male interns have 2% lower daily spending costs, significant

at the 10% level; male residents have 4% lower daily spending costs, significant at the 5% level. A

high USMLE score predicts 3% lower daily spending, significant at the 10% level, for residents. Table

2 also considers the mean eﬀect of having housestaﬀ from the other residency program, an eﬀect that

could be due to selection (i.e., intrinsic heterogeneity) or diﬀerences in learning experiences across

the two programs. While other-program interns do not have significantly diﬀerent mean spending

eﬀects, other-program residents spend 17% less, but the latter is only significant at the 10% level

because of relatively few housestaﬀ from the other program.27
  27
     Doyle et al. (2010) study teams of housestaﬀ from two diﬀerent programs in a single academic hospital and find
that teams from the more prestigious program incur fewer costs. This contrasts with my finding that housestaﬀ from
a less prestigious program (the “other” program) incur fewer costs. In Doyle et al. (2010), housestaﬀ from diﬀerent
programs are separated into diﬀerent teams, while in this setting they are intermingled. A further finding of this
study is that the diﬀerence between the two programs increases as housestaﬀ gain more experience, which could be
consistent with either greater influence or learned diﬀerences between the two programs, but not solely consistent



                                                        20
    A standard-deviation change in the overall predictive score changes costs by about 2% for both

interns and residents. By comparison, using the same characteristics to predict whether a housestaﬀ

was ranked in the upper half on the residency program’s rank list (excluding rank as a character-

istic) yields a predictive score that with one standard deviation changes the probability of being

highly ranked by about 20%. LASSO selected no intern characteristic as significant and selected

only resident male sex as significant. In this sense, the overall predictive score is likely to be an

overestimate of variation due to intrinsic heterogeneity.

    Overall, these results show that intrinsic heterogeneity, to the extent that it is correlated with

any of the rich pre-residency characteristics and choices I observe, explains relatively little compared

to the size of variation that depends on influence and learning. The single characteristic selected by

LASSO, male sex, has a larger eﬀect for residents than for interns. Note that the increasing eﬀect

of an intrinsic characteristic moving from role of intern to resident is consistent with the the idea

of increasing influence with relative experience and inconsistent with intrinsic heterogeneity alone.

7.2     Housestaﬀ Experience

    I consider several measures of experience including days on ward service, patients seen, and

supervising physicians for a given housestaﬀ prior to a patient encounter. For each of these measures,

I estimate a regression of the form

                     (                                        )
                                 m                   m
      Yaijkt   = αm 1 Experience h,τ (h,t)−1 < Medianτ (h,t)−1 + Xa β + Tt η + ζh + ζ−hk + εaijkt ,   (6)


where the coeﬃcient of interest αm is on whether the measure Experience m
                                                                        h,τ (h,t)−1 is above median,

where both the measure and the median are calculated using observations before the tenure period

associated with the index observation. I also consider service-specific measures, Experience ms
                                                                                             h,τ (h,t)−1 ,

calculated using observations within service s (e.g., the number of patients seen on cardiology ser-

vice) and evaluated against a service-specific median. Patient characteristics Xa and time indicators

Tt are the same as used in previous regressions. In my baseline specification, I control for the identi-

ties of the housestaﬀ as ζh and the peer-attending combination as ζ−hk separately, although whether

I include ζh at all or include a fixed eﬀect for intern-resident-attending ζijk does not qualitatively
with intrinsic heterogeneity.



                                                      21
influence results, consistent with random assignment of housestaﬀ to patients and peers (Appendix

A-1). Results from Equation (6) are shown in Table 3 and are broadly insignificant. A LASSO

implementation that jointly considers a larger number of summary experience measures in early or

more recent months relative to the patient encounter, as well as two-way interactions between these

measures, (112 and 288 variables for interns and residents, respectively) also fails to select any of

these measures as significant.

         I also consider the eﬀect of resident tenure on outcomes of test daily spending, total daily

spending, length of stay, 30-day readmissions, and 30-day mortality for each of the ward services.

Because I also control for month-year interactions, I study this as the eﬀect of having a third-year

housestaﬀ, as opposed to having a second-year housestaﬀ, as the resident:


                         Yaijkt = α1 (τ (j, t) > 2 years) + Xa β + Tt η + ζik + εaijkt .                       (7)


The coeﬃcient α is small and insignificant for all of these outcomes. Table 4 lists results along with

counterfactuals for switching to a resident one standard deviation above or below in housestaﬀ-eﬀect

distribution for the relevant outcome.

         Overall, these results indicate that summary measures of housestaﬀ experience are also poor

predictors of practice and outcomes, especially relative to the large variation across housestaﬀ. In

this setting with the distinctive advantage that housestaﬀ are as good as randomly assigned to

training experiences, I am able to reject that formal diﬀerences in training are responsible for any

significant subsequent variation in housestaﬀ behavior. This fails to support the “schools of thought”

view of practice variation, at least within an organization with largely uniform training experiences

but nonetheless large practice variation.28 Rather, it is consistent with the view, as previously

suggested in Section 6.2.2, that summary measures of experience, even with (administratively) rich

data, are likely to be impractical representations of the lessons to be learned via specific experiences.


8         Discussion and Conclusion

         Persistent variation in health care production has been widely noted in policy discussions.29
    28
     Molitor (2016) reaches a similar conclusion in a panel examination of physicians who move across areas and do
not show any longer term adjustment in practice styles.
  29
     For example, it is well-known that President Barack Obama paid special attention to this fact during US health


                                                        22
However, the behavioral foundations of such variation in medical care, and indeed in closely related

variation in other industries (e.g., Syverson, 2011), remain poorly understood. This paper shows

significant practice variation concentrated in the hands of certain physicians, but that the extent

of practice variation for the same set of physicians depends on the team structure of decision-

making and the practice environment. Suggestive of informational frictions, the channels of influence

and convergence (or lack thereof) appear to be much larger than the contributions of intrinsic

heterogeneity or practice styles inherited from supervising physicians (i.e., “schools of thought”).

    This study’s findings are derived from a single, large academic institution and are therefore

limited in scope. Nonetheless, this limitation to a relatively homogeneous set of physicians in a

constant setting is likely to present a lower bound to the variation (and informational frictions) that

may exist (a) across more heterogeneous agents, (b) across settings, and (c) among physicians that

are no longer in residency training. This “lower bound” variation that I find in this study is still large

by any measure of small-area variation in the Dartmouth Atlas.30 Although intrinsic heterogeneity

in providers could also be greater across areas, previous studies also suggest a limited role in using

provider characteristics to explain variation (Epstein and Nicholson, 2009), and I further provide

new evidence, to my knowledge, that systematic practice diﬀerences between physicians in diﬀerent

future specialties are much smaller than the magnitude of variation among the same set of physicians

across roles or practice environments.

    While this paper presents a novel empirical look at the role of informational frictions in the

evolution of medical practice variation, its findings are consistent with original thinking and evi-

dence in the practice variation literature. It has long been suspected that practice variation arises

because of a lack of consensus on how medical technology should be used. In early research, Jack

Wennberg and colleagues indeed document larger variation in surgical procedures where there is

more disagreement (Wennberg et al., 1980; McPherson et al., 1982; Wennberg et al., 1982). This
care reform leading to the Aﬀordable Care Act (e.g., Pear, 2009). An article about health care spending variation
by Atul Gawande in 2009 in the New Yorker was dubbed by David Brooks of the New York Times as the most
influential essay of the year. The existence of medical spending variation has led influential policymakers, such as
Peter Orszag, to conclude that $700 billion (or over 30%) of health care spending could simply be eliminated without
any ill eﬀects and has led some to propose penalizing areas with higher-than-average per capita spending (see, e.g.,
Roy, 2010, and Jauhar, 2014, in the popular press for references to these suggestions and “contrarian views” against
them).
  30
     For example, the coeﬃcient of variation (or the standard deviation divided by the mean) in price- and
demographic-adjusted spending across Hospital Referral Regions (HRRs) is approximately 13% in 2014, according to
this link, accessed in October 2016.



                                                        23
view accords more generally with Polanyi’s (1958) thesis that knowledge is diﬃcult to communicate

and therefore highly personal. As Nelson and Winter (1982) observe, there is a connection between

the tacit nature of knowledge across individuals and the transferrability of practices or “routines”

across organizations, and Gibbons and Henderson (2012) discuss how this translates to persistent

performance diﬀerences across seemingly similar enterprises, in which managers may fail to perceive,

understand, or implement solutions to problems due to these frictions.

   The notion that practice variation is a symptom of informational frictions is relevant for policy

and welfare considerations. It is notable that, despite seemingly widespread agreement among

policymakers that variation should be eliminated, definitive agreement about the set of decisions

for specific patient cases is rare, even for the most common or straightforward cases. Simply

setting benchmarks for spending (or any other simple summary statistic) provides little guidance

for physicians on how to actually care for patients, and it is possible that practice patterns may be

optimized within provider for his or her tacit knowledge, developed over years, in a way similar to

variation across regions shown by Chandra and Staiger (2007). The standard route of generating

medical knowledge via clinical trials would only be partially helpful if any given piece of knowledge

must be integrated and clinical practice is nuanced. To some extent, informational frictions are

fundamentally a product of limitations, in medicine and in other jobs with discretion, in what

can be observed and prespecified by algorithm. Technologies or organizational structures, such

as those used in “continuous quality improvement” in high-performing institutions (McCarthy and

Blumenthal, 2006), that aim to transmit knowledge of actual treatment decisions across decision-

makers may be a promising area of future research on practice variation.



References

Abowd, John M., Francis Kramarz, and Simon Woodcock, “Econometric Analyses of Linked

  Employer-Employee Data,” in Laszio Matyas and Patrick Sevestre, eds., The Econometrics of

  Panel Data, number 46. In ‘Advanced Studies in Theoretical and Applied Econometrics.’, Springer

  Berlin Heidelberg, January 2008, pp. 727–760.

Acemoglu, Daron, Victor Chernozhukov, and Muhamet Yildiz, “Learning and Disagree-

  ment in an Uncertain World,” Working Paper 12648, National Bureau of Economic Research

                                                 24
  October 2006.

Alchian, Armen A. and Harold Demsetz, “Production, information costs, and economic orga-

  nization,” The American Economic Review, 1972, 62 (5), 777–795.

Alter, David A., Dennis T. Ko, Jack V. Tu, Therese A. Stukel, Douglas S. Lee, Andreas

  Laupacis, Alice Chong, and Peter C. Austin, “The Average Lifespan of Patients Discharged

  from Hospital with Heart Failure,” Journal of General Internal Medicine, September 2012, 27 (9),

  1171–1179.

Anderson, G. F., P. S. Hussey, B. K. Frogner, and H. R. Waters, “Health spending in the

  United States and the rest of the industrialized world,” Health Aﬀairs, 2005, 24 (4), 903–914.

Arrow, Kenneth J., “Uncertainty and the Welfare Economics of Medical Care,” The American

  Economic Review, December 1963, 53 (5), 941–973.

Autor, David H., Frank Levy, and Richard J. Murnane, “The Skill Content of Recent Tech-

  nological Change: An Empirical Exploration,” The Quarterly Journal of Economics, November

  2003, 118 (4), 1279–1333.

Bartel, Ann P., Nancy Beaulieu, Ciaran Phibbs, and Patricia W. Stone, “Human Capital

  and Productivity in a Team Environment: Evidence from the Healthcare Sector,” American

  Economic Journal: Applied Economics, April 2014, 6 (2), 231–259.

Bartling, Bjorn, Ernst Fehr, and Holger Herz, “The Intrinsic Value of Decision Rights,”

  Econometrica, November 2014, 82 (6), 2005–2039.

Bates, Douglas, Martin Machler, Ben Bolker, and Steve Walker, “Fitting Linear Mixed-

  Eﬀects Models using lme4,” Journal of Statistical Software, October 2015, 67 (1), 1–48. arXiv:

  1406.5823.

Belloni, Alexandre, Victor Chernozhukov, and Christian Hansen, “High-Dimensional

  Methods and Inference on Structural and Treatment Eﬀects,” Journal of Economic Perspectives,

  May 2014, 28 (2), 29–50.




                                                25
Caplin, Andrew and Mark Dean, “Revealed Preference, Rational Inattention, and Costly In-

  formation Acquisition,” American Economic Review, July 2015, 105 (7), 2183–2203.

Chamberlain, Gary, “Panel Data,” in Zvi Griliches and M.D. Intrilligator, eds., Handbook of

  Econometrics, Vol. Chapter 22, Amsterdam: North Holland, 1984, pp. 1248–1318.

Chandra, A. and D. O. Staiger, “Productivity spillovers in healthcare: evidence from the

  treatment of heart attacks,” The Journal of Political Economy, 2007, 115 (1), 103–140.

Charlson, Mary E., Peter Pompei, Kathy L. Ales, and C. Ronald MacKenzie, “A new

  method of classifying prognostic comorbidity in longitudinal studies: Development and valida-

  tion,” Journal of Chronic Diseases, 1987, 40 (5), 373–383.

Chetty, Raj, John N. Friedman, and Jonah E. Rockoﬀ, “Measuring the Impacts of Teachers

  I: Evaluating Bias in Teacher Value-Added Estimates,” American Economic Review, 2014, 104

  (9), 2593–2632.

Cooke, Molly, David M. Irby, William Sullivan, and Kenneth M. Ludmerer, “American

  Medical Education 100 Years after the Flexner Report,” New England Journal of Medicine, 2006,

  355 (13), 1339–1344.

Csikszentmihalyi, Mihaly, Flow: The Psychology of Optimal Experience, Harper & Row, 1990.

Cutler, David, “Where Are the Health Care Entrepreneurs?,” Issues in Science and Technology,

  2010, 27 (1), 49–56.

  , Jonathan Skinner, Ariel Dora Stern, and David Wennberg, “Physician Beliefs and

  Patient Preferences: A New Look at Regional Variation in Health Care Spending,” Working

  Paper 19320, National Bureau of Economic Research August 2013.

Cyert, Richard and James March, A Behavioral Theory of the Firm, Oxford: Blackwell, 1963.

Doyle, Joseph J., John A. Graves, Jonathan Gruber, and Samuel Kleiner, “Measuring

  Returns to Hospital Care: Evidence from Ambulance Referral Patterns,” Journal of Political

  Economy, February 2015, 123 (1), 170–214.



                                                26
  , S. M. Ewer, and T. H. Wagner, “Returns to physician human capital: Evidence from

  patients randomized to physician teams,” Journal of Health Economics, 2010, 29 (6), 866–882.

Elixhauser, Anne, Claudia Steiner, D. Robert Harris, and Rosanna M. Coﬀey, “Comor-

  bidity Measures for Use with Administrative Data,” Medical Care, January 1998, 36 (1), 8–27.

Ellison, G. and D. Fudenberg, “Rules of thumb for social learning,” Journal of Political Economy,

  1993, 101 (4), 612–643.

Epstein, A. J. and S. Nicholson, “The formation and evolution of physician treatment styles:

  an application to cesarean sections,” Journal of Health Economics, 2009, 28 (6), 1126–1140.

Finkelstein, Amy, Matthew Gentzkow, and Heidi Williams, “Sources of Geographic Varia-

  tion in Health Care: Evidence from Patient Migration,” Quarterly Journal of Economics, 2016,

  Forthcoming.

Fisher, Elliott S., David E. Wennberg, Therese A. Stukel, Daniel J. Gottlieb, F. L.

  Lucas, and Etoile L. Pinder, “The Implications of Regional Variations in Medicare Spending.

  Part 1: The Content, Quality, and Accessibility of Care,” Annals of Internal Medicine, February

  2003, 138 (4), 273–287.

  ,   ,   ,    ,   , and    , “The Implications of Regional Variations in Medicare Spending. Part 2:

  Health Outcomes and Satisfaction with Care,” Annals of Internal Medicine, February 2003, 138

  (4), 288–298.

Flexner, Abraham, Medical education in the United States and Canada: a report to the Carnegie

  Foundation for the Advancement of Teaching, Carnegie Foundation for the Advancement of Teach-

  ing, 1910.

Fox, Jeremy T. and Valerie Smeets, “Does Input Quality Drive Measured Diﬀerences in Firm

  Productivity?,” International Economic Review, November 2011, 52 (4), 961–989.

Garicano, Luis, “Hierarchies and the Organization of Knowledge in Production,” Journal of Po-

  litical Economy, October 2000, 108 (5), 874–904.




                                                 27
   and Esteban Rossi-Hansberg, “Organization and Inequality in a Knowledge Economy,” The

  Quarterly Journal of Economics, November 2006, 121 (4), 1383–1435.

Gawande, Atul, “The Cost Conundrum,” The New Yorker, June 2009.

Gibbons, Robert and Rebecca Henderson, “What do managers do? Exploring persistent per-

  formance diﬀerences among seemingly similar enterprises,” in Robert Gibbons and John Roberts,

  eds., The Handbook of Organizational Economics, Princeton, NJ: Princeton University Press,

  2012, pp. 680–732.

Gilks, W. R. and P. Wild, “Adaptive Rejection Sampling for Gibbs Sampling,” Applied Statistics,

  1992, 41 (2), 337.

Glover, Allison, “The Incidence of Tonsillectomy in School Children,” Proceedings of the Royal

  Society of Medicine, August 1938, 31 (10), 1219–1236.

Iwashyna, T. J., A. Fuld, D. A. Asch, and L. M. Bellini, “The impact of residents, interns, and

  attendings on inpatient laboratory ordering patterns: A report from one university’s hospitalist

  service,” Academic Medicine, 2011, 86 (1), 139.

Jacob, Brian A. and Lars Lefgren, “What Do Parents Value in Education? An Empirical

  Investigation of Parents’ Revealed Preferences for Teachers,” The Quarterly Journal of Economics,

  November 2007, 122 (4), 1603–1637.

Jauhar, Sandeep, “Don’t Homogenize Health Care,” The New York Times, December 2014.

Kane, Thomas J. and Douglas O. Staiger, “Volatility in School Test Scores: Implications

  for Test-Based Accountability Systems,” in David Grissmer and Helen F. Ladd, eds., Brook-

  ings Papers on Education Policy, Washington, DC: Brookings Institution Press, January 2002,

  pp. 235–283.

Ludmerer, Kenneth M., Learning to Heal: The Development of American Medical Education,

  Perseus Books Group, January 1988.

McCarthy, D. and D. Blumenthal, “Stories from the sharp end: case studies in safety improve-

  ment,” Milbank Quarterly, 2006, 84 (1), 165–200.

                                                28
McPherson, Klim, John E. Wennberg, Ole B. Hovind, and Peter Cliﬀord, “Small-Area

  Variations in the Use of Common Surgical Procedures: An International Comparison of New

  England, England, and Norway,” New England Journal of Medicine, November 1982, 307 (21),

  1310–1314.

Molitor, David, “The evolution of physician practice styles: Evidence from cardiologist migration,”

  Technical Report 22478, National Bureau of Economic Research 2016.

Morris, Carl N., “Parametric Empirical Bayes Inference: Theory and Applications,” Journal of

  the American Statistical Association, March 1983, 78 (381), 47–55.

Nelson, Richard R. and Sidney G. Winter, An Evolutionary Theory of Economic Change,

  Harvard University Press, 1982.

Patterson, H. D. and R. Thompson, “Recovery of inter-block information when block sizes are

  unequal,” Biometrika, December 1971, 58 (3), 545–554.

Pear, Robert, “Health Care Spending Disparities Stir a Fight,” The New York Times, June 2009.

Polanyi, Michael, Personal Knowledge: Towards a Post-Critical Philosophy, University of Chicago

  Press, 1958.

  , The Tacit Dimension, New York: Doubleday Press, 1966.

Prendergast, Canice, “A Theory of Yes Men,” The American Economic Review, September 1993,

  83 (4), 757–770.

Radner, Roy, “The Organization of Decentralized Information Processing,” Econometrica, 1993,

  61 (5), 1109–46.

Rogerson, Richard, Robert Shimer, and Randall Wright, “Search-Theoretic Models of the

  Labor Market: A Survey,” Journal of Economic Literature, December 2005, 43 (4), 959–988.

Roy, Avik, “The Dartmouth Atlas and Obamacare,” National Review, June 2010.

Scharfstein, David S. and Jeremy C. Stein, “Herd Behavior and Investment,” The American

  Economic Review, June 1990, 80 (3), 465–479.


                                                29
Schroeder, S. A., A. Schliftman, and T. E. Piemme, “Variation among physicians in use of

  laboratory tests: relation to quality of care,” Medical Care, 1974, 12 (8), 709–713.

Searle, S. R., G. Casella, and C. E. McCulloch, Variance Components, Wiley New York,

  1992.

Skinner, Jonathan, “Causes and Consequences of Regional Variations in Healthcare,” in Mark V

  Pauly, Thomas G McGuire, and Pedro Barros, eds., Handbook of Health Economics, Vol. 2, San

  Francisco: Elsevier, 2012, pp. 49–93.

Starr, Paul, The Social Transformation Of American Medicine: The Rise Of A Sovereign Profes-

  sion And The Making Of A Vast Industry, Basic Books, August 2008.

Syverson, Chad, “What Determines Productivity?,” Journal of Economic Literature, June 2011,

  49 (2), 326–365.

Wennberg, J. and A. Gittelsohn, “Small area variations in health care delivery,” Science, 1973,

  182 (4117), 1102–1108.

Wennberg, J. E., J. P. Bunker, and B. Barnes, “The need for assessing the outcome of

  common medical practices,” Annual Review of Public Health, 1980, 1, 277–295.

Wennberg, John E., Benjamin A. Barnes, and Michael Zubkoﬀ, “Professional uncertainty

  and the problem of supplier-induced demand,” Social Science & Medicine, January 1982, 16 (7),

  811–824.




                                                 30
                                        Figure 1: Distributions of Resident Eﬀects



                       6     A: Spending on Admission                                        B: Length of Stay




                                                                                  6
                       4




                                                                                  4
             Density




                                                                        Density
                       2




                                                                                  2
                       0




                                                                                  0
                            -.3   -.2     -.1    0      .1    .2                       -.2    -.1     0        .1   .2
                                        Resident effect                                         Resident effect


                                   C: Readmission                                               D: Mortality
                       15




                                                                                  20
                                                                                  15
                       10
             Density




                                                                        Density
                                                                         10
                       5




                                                                                  5
                       0




                                                                                  0




                            .05    .1     .15     .2         .25                       0      .05     .1     .15    .2
                                  Resident Pr(outcome)                                       Resident Pr(outcome)




Note: This figure shows distributions of empirical Bayes predictions (BLUPs) of resident random eﬀects
for outcomes of spending on day of admission (Panel A), length of stay (Panel B), 30-day readmission
(Panel C), and 30-day mortality (Panel D). Random eﬀects are modeled according to Equation (1), allowing
for correlation with patient and admission characteristics, time categories, and attending identities. The
empirical Bayes predictions are of the component of the random eﬀects that is orthogonal to a projection of
these characteristics onto the outcome. More details are described in Section 4 and Appendix A-2. Random
eﬀects are represented directly on the x-axis for continuous outcomes of (log) spending and (log) length of stay
in Panels A and B, while they are transformed into probabilities for the average patient for binary outcomes
of readmission and mortality in Panels C and D. Panel A shows distributions for both total spending (solid
line) and test spending (dashed line). The vertical gray lines represent 10th and 90th percentiles of the
distribution (total spending in Panel A); because BLUPs are shrunken 10th and 90th percentiles are less
dispersed than implied by standard deviations of the random eﬀects distributions (Table 4).



                                                                   31
                                   Figure 2: Eﬀects on Spending and Clinical Outcomes



                             A: Readmit, Total Spending                                             B: Death, Total Spending
                   .2




                                                                                         .2
                      .15




                                                                                            .15
             Pr(outcome)




                                                                                   Pr(outcome)
                                                                                   .1
             .1




                                                                                         .05
                   .05




                                                      Coeff = -.125 (.0169)                                                Coeff = -.0136 (.0142)

                            -.3         -.2     -.1    0      .1        .2                        -.3         -.2     -.1    0      .1        .2
                                              Resident effect                                                       Resident effect


                             C: Readmit, Test Spending                                                  D: Death, Test Spending
                   .2




                                                                                         .2
                      .15




                                                                                            .15
             Pr(outcome)




                                                                                   Pr(outcome)
             .1




                                                                                   .1
                   .05




                                                                                         .05




                                                      Coeff = -.102 (.0175)                                                Coeff = -.0131 (.0143)

                                  -.2         -.1    0        .1        .2                              -.2         -.1    0        .1        .2
                                              Resident effect                                                       Resident effect




Note: This figure shows the relationship between empirical Bayes predictions of resident random eﬀects
for spending and for clinical outcomes. Each panel is a binned scatterplot of average random eﬀects for
spending within vigintiles on the x-axis and the corresponding random eﬀects clinical outcomes among the
same residents in the spending vigintile on the y-axis. Clinical outcome random eﬀects are transformed into
probabilities for the average patient, as in Figure 1. The figure considers two measures of spending: total
spending on day of admission (Panels A and B) and test spending on day of admission (Panels C and D).
Two clinical outcomes are 30-day readmissions (Panels A and C) and 30-day mortality (Panels B and D).
Regression lines are also plotted, with y-coordinates of the lines transformed to probabilities for the average
patient by a logistic transformation. Coeﬃcients (and standard errors in parentheses) correspond to a linear
regression fit of the transformed clinical probabilities on spending random eﬀects. More details on how the
random eﬀects are calculated are described in Section 4 and Appendix A-2.



                                                                              32
            Figure 3: Standard Deviation of Housestaﬀ Random Eﬀects by Tenure
                               1            .8
               Std. dev. (log dollar costs)
                      .4       .2
                               0  .6




                                                 0   120   240   360   480     600   720   840   960   1080
                                                                       Days tenure



Note: This figure shows the standard deviation in a random eﬀects model of log daily test costs shown in
Equation (2) at each non-overlapping two-month tenure interval. Point estimates are shown as connected
dots; 95% confidence intervals are shown as dashed lines. The model controls for patient and admission
observable characteristics, time dummies (month-year interactions, day of the week), and attending identities
(as fixed eﬀects). Patient characteristics include demographics, Elixhauser indices, Charlson comorbidity
scores, and DRG weights. Admission characteristics include the admitting service (e.g., “Heart Failure Team
1”). Housestaﬀ prior to one year in tenure are interns and become residents after one year in tenure; a
vertical line denotes the one-year tenure mark.




                                                                        33
            Figure 4: Serial Correlation of Housestaﬀ Random Eﬀects over Tenure
                            1
                Correlation coefficient
                 0          -.5     .5




                                          90   210   330   450     570       690   810   930   1050
                                                              Day of residency



Note: This figure shows the serial correlation between random eﬀects within housestaﬀ in a given tenure
period and the previous tenure period. Hollow dots show directly estimated correlations from maximum
likelihood of data from the two tenure periods (details in Appendix A-5.2). Solid dots show posterior
correlations from a Bayesian refinement procedure that includes both the directly estimated correlation and
information from other correlations between non-adjacent periods (details in Appendix A-6). The dashed
lines are the 95% credible interval for the posterior correlations. The 95% confidence interval for the directly
estimated correlations are slightly larger but otherwise similar and are omitted from this figure for simplicity.
The random eﬀect model of log daily test costs is first estimated as in Equation (2), as described in the
notes for Figure 3. Housestaﬀ prior to one year in tenure are interns and become residents after one year in
tenure; a vertical line denotes the one-year tenure mark.




                                                                 34
                                                                    Figure 5: Housestaﬀ-eﬀect Variation by Tenure in Each Service



                                                               Cardiology                                                    Oncology                                                  General Medicine




                                                   .8
                                                                                                                 .8
                                                                                                                                                                              .8




                                           .6
                                                                                                         .6
                                                                                                                                                                      .6




                                  .4
                                                                                                .4
                                                                                                                                                             .4




35
                         .2
                                                                                       .2
                                                                                                                                                    .2




                      Std. dev. (log dollar costs)
                                                                                    Std. dev. (log dollar costs)
                                                                                                                                                 Std. dev. (log dollar costs)




                                      0
                                                                                                    0
                                                                                                                                                                 0




                                                        0   200 400 600 800 1000                                      0   200 400 600 800 1000                                     0   200 400 600 800 1000
                                                               Days tenure                                                   Days tenure                                                  Days tenure




     Note: Similar to Figure 3, this figure shows the standard deviation in a random eﬀects model, as in Equation (2), of log daily test costs at each
     non-overlapping two-month tenure interval but for each service of cardiology, oncology, and general medicine. Controls are the same as those listed
     in the caption for Figure 3. Housestaﬀ prior to one year in tenure are interns and become residents after one year in tenure; vertical lines denote the
     one-year tenure mark.
            Figure 6: Systematic Placebo Tests for Specialist-service Convergence
               500
               400
               300
               200
               100
               0




                     -.2      -.15         -.1        -.05         0           .05         .1

                                     Frequency histogram             Kernel smoothed




Note: This figure shows 10,000 random placebo tests for convergence in the specialist services. Merging
cardiology and oncology yields an actual estimate of -0.160, or a 16% percentage point decrease per year
in the standard deviation of spending eﬀects of residents over the two years of the resident role, shown by
the vertical line. In each of 10,000 placebo tests, I randomize combinations of housestaﬀ-month-service to a
placebo specialist service, matching the number of housestaﬀ-month-services assigned to specialist services
in each month of tenure. I estimate the same random eﬀects model of log daily test costs shown in Equation
(2) for the placebo specialist service and estimate the rate of placebo convergence using estimated housestaﬀ
eﬀects in this placebo specialist service. Estimates for convergence are shown as a frequency histogram with
a kernel-smoothed overlay.




                                                     36
                                                           Figure 7: Pseudo-cardiology Service



                                                               A: Pseudo-cardiology by ICD-9 Codes



                                           10
                                           8
                            Log frequency
                              4       6    2
                                           0




                                                           0         100          200          300          400
                                                                              Frequency rank


                                                                  B: Housestaff-effect Variation
                                                      .8
                            Std. dev. (log dollar costs)
                                .2      .40    .6




                                                           0      200        400       600       800       1000
                                                                               Days tenure

                                                                   Pseudo-cardiology           Cardiology
                                                                                               General medicine




Note: This figure shows the construction of a pseudo-cardiology service by ICD-9 codes (Panel A) and
housetaﬀ-eﬀect variation by tenure in this service (Panel B). This service is constructed from general medicine
observations, matching ICD-9 codes observed in cardiology. This procedure covers 97% of observations in
the actual cardiology service. Panel A shows ICD-9 codes ranked by frequency in cardiology; gray bars
represent ICD-9 codes matched with observations in general medicine. Eight of 410 ICD-9 codes have only
one observation and are therefore not shown with a non-zero log frequency. Panel B shows the standard
deviation of housestaﬀ eﬀects by tenure for actual services of cardiology (short-dashed line) and general
medicine (long-dashed line), and for a pseudo-cardiology service (dot and solid line) comprised of patients
in general medicine but matching ICD-9 code primary diagnoses in cardiology. Estimation of Equation (2)
includes admission-intern random eﬀects to normalize higher variance in the number of patients per intern
in the pseudo-cardiology service (thus results are slightly diﬀerent than in Figure 5, for example. Housestaﬀ
prior to one year in tenure are interns and become residents after one year in tenure; vertical lines denote
the one-year tenure mark.




                                                                                 37
              Figure 8: Orthogonal Quantiles of General and Specific Experience



                                                     A: Cardiology

                                   150                                               1,000


                                                                                     800
                         Days on cardiology
                                      100




                                                                                     600


                                                                                     400
                          50




                                                                                     200


                                                                                     0
                                   0




                                               0   200      400        600    800
                                                   Days tenure as resident


                                                       B: Oncology
                                   100




                                                                                         900
                                                                                         800
                                          80




                                                                                         700
                         Days on oncology




                                                                                         600
                                   60




                                                                                         500
                                                                                         400
                            40




                                                                                         300
                                                                                         200
                                   20




                                                                                         100
                                                                                         0
                                   0




                                               0   200       400        600    800
                                                    Days tenure as resident




Note: This figure shows orthogonal deciles of general and specific experience in cardiology (Panel A) and
oncology (Panel B), as described in Section 6.2.1. Days on cardiology (i.e., cardiology wards and coronary
care units, including at aﬃliated hospitals) are considered specific experience for cardiology; days on oncology
(i.e., oncology wards and bone marrow transplant service) are considered specific experience for oncology.
Overall tenure as a resident is considered general experience. Numbers of observations in each 10 × 10 day
bin are shown as densities. Quintile (rather than decile) boundaries are plotted for visual simplicity: Short-
dashed lines illustrate orthogonal quintiles of general experience; long-dashed lines illustrate orthogonal
quintiles of specific experience.




                                                                  38
      Figure 9: Convergence by Orthogonal Deciles of General and Specific Experience



                                            A: Cardiology                                                       B: Oncology
                        1




                                                                                           1
         Std. dev. (log dollar costs)




                                                                            Std. dev. (log dollar costs)
                                 .8




                                                                                                    .8
                      .6




                                                                                         .6
           .4




                                                                              .4
                        .2




                                                                                           .2




                                        2    4        6       8   10                                       2    4        6       8   10
                                            Decile experience                                                  Decile experience




Note: This figure plots the standard deviation of resident spending eﬀects estimated by Equation (2),
but decomposing experience into deciles of general and specific components, as described in Section 6.2.1.
Controls are the same as those listed in the caption for Figure 3. Each estimation sample is defined by an
“orthogonal decile” of general (solid dots) or specific (hollow dots) experience, which are deciles of general
(or specific) experience orthogonal to linear quantile predictions based on specific (general) experience. The
set of observations comprising each decile is illustrated in Figure 8. Panel A shows results in cardiology;
Panel B shows results in oncology. See notes in Figure 8 for how general and specific experience are defined.




                                                                       39
                            Table 1: Exogenous Assignment for Housestaﬀ with Above or Below Average Spending


                                                                     Interns                                     Residents
                                                          Below-median       Above-median             Below-median     Above-median
                                                          test spending      test spending            test spending     test spending
                       Patient characteristics
                                                               62.11               62.13                  62.07                62.15
                          Age
                                                              (16.90)             (16.86)                (16.82)              (16.93)
                                                               0.484               0.482                  0.489                0.478
                          Male
                                                              (0.500)             (0.500)                (0.500)              (0.500)
                                                               0.706               0.703                  0.708                0.702
                          White race
                                                              (0.455)             (0.457)                (0.455)              (0.457)
                                                               0.161               0.159                  0.157                0.162
                          Black race
                                                              (0.367)             (0.365)                (0.364)              (0.368)
                          Charlson comorbidity                  2.87                2.87                   2.84                 2.90




40
                          index                                (2.79)              (2.79)                 (2.77)               (2.81)
                          Diagnostic-related                    1.25                1.25                   1.27                 1.24
                          Group (DRG) weight                   (0.86)              (0.84)                 (0.85)               (0.84)

                       Supervising physicians
                         Above-median-spending                 0.500               0.500
                                                                                                           N/A                 N/A
                         residents                            (0.501)             (0.501)
                         Above-median-spending                 0.503               0.502                  0.501                0.502
                         attendings                           (0.501)             (0.501)                (0.501)              (0.501)

     Note: This table shows evidence of exogenous assignment for housestaﬀ with below-median or above-median averaged spending eﬀects. Average
     spending eﬀects, not conditioning by tenure, are estimated as fixed eﬀects by a regression of log test spending on patient characteristics and physician
     (intern, resident, and attending) identities. Lower- and higher-spending interns are identified by their fixed eﬀect relative to the median fixed eﬀect.
     For each of these groups of interns, this table shows average patient characteristics and spending eﬀects for supervising physicians. Averages are
     shown with standard deviations in parentheses.
                    Table 2: Eﬀect of Housestaﬀ Characteristics on Spending


                                                         Log daily test costs
                                        (1)          (2)         (3)           (4)               (5)
                                                    High       Highly         Other            Overall
                                       Male
                                                   USMLE       ranked        hospital           score
     Panel A: Interns
       Eﬀect of housestaﬀ             -0.021        -0.003         0.011          0.007        0.019
       with characteristic           (0.012)       (0.013)        (0.018)        (0.025)      (0.006)
       Observations                  186,694       185,497        131,418        220,074      190,640
       Adjusted R2                     0.166         0.166         0.166          0.165        0.165
       Sample characteristic
                                      0.596          0.258          0.234         0.055         N/A
       mean

     Panel B: Residents
       Eﬀect of housestaﬀ             -0.039        -0.013         0.002          -0.169       0.022
       with characteristic           (0.016)       (0.020)        (0.028)        (0.095)      (0.008)
       Observations                  206,802       199,715        129,508        220,074      206,802
       Adjusted R2                     0.180         0.180         0.178           0.178       0.180
       Sample characteristic
                                      0.564          0.235          0.213         0.060         N/A
       mean

Note: This table reports results for some regressions of the eﬀect of indicators of some housestaﬀ char-
acteristics, including other hospital status, and a normalized predictive score (with standard deviation 1)
based on all observed housestaﬀ characteristics. Panel A shows results for interns; Panel B shows results for
residents. Columns (1) to (4) are regressions of the form in Equation (3), where the coeﬃcient of interest
is on an indicator for a group of housestaﬀ identified by either pre-residency characteristics or whether the
housestaﬀ is from the other academic hospital. The eﬀect of many other characteristics of interest (or groups)
were estimated as insignificant and omitted from this table for brevity. Column (5) is reports results for
Equation (5), where the regressor of interest is a normalized predictive score based on age, sex, minority
status, housestaﬀ track, rank on matching rank list, USMLE score, medical school rank in US News & World
Report, indicators for whether the medical school is foreign or “rare,” AOA medical honor society mem-
bership, and additional degrees at time of residency matriculation. By comparison, a predictive score for
being highly ranked (in the top 50 rank positions) based on the same characteristics (except rank) changes
the probability of being highly ranked by about 20% for both interns and residents. All models control for
patient and admission characteristics, time dummies, and fixed eﬀects for attending and the other housestaﬀ
on the team (e.g., the resident is controlled for if the group is specific to the intern). Standard errors are
clustered by admission.




                                                     41
                       Table 3: Eﬀect of Housestaﬀ Experience on Spending


                                                           Log daily test costs
                                        (1)           (2)          (3)          (4)               (5)
                                      Number       Number of Number of Attending               Attending
                                      of days       patients   attendings spending             spending
     Panel A: Interns
       Eﬀect of housestaﬀ
                                       -0.004         -0.016         -0.017        -0.009        0.014
       with measure above
                                      (0.016)        (0.016)        (0.016)       (0.013)       (0.058)
       median
       Observations                   182,166       182,166         182,166       155,762       129,863
       Adjusted R2                     0.172         0.172           0.172         0.170         0.192

     Panel B: Residents
       Eﬀect of housestaﬀ
                                       -0.034         -0.050         -0.20         0.040         -0.025
       with measure above
                                      (0.035)        (0.030)        (0.039)       (0.036)       (0.054)
       median
       Observations                   200,276       200,276         200,276       182,329       174,834
       Adjusted R2                     0.181         0.181           0.181         0.181         0.187

     Measure and median
                                         Y              Y              Y             N             Y
     within service

Note: This table reports results for some regressions of the eﬀect of indicators of housestaﬀ experience. Panel
A shows results for interns; Panel B shows results for residents. Regressions are of the form in Equation (3),
where the coeﬃcient of interest is on an indicator for a group of housestaﬀ identified whether their measure
(e.g., number of days) is above the median within a 60-day tenure interval (across all housestaﬀ). The
relevant tenure interval is the tenure interval before the one related to the day of the index admission. All
columns except for (4) represent measures and medians that are calculated within service (e.g., number of
days is calculated separately for a housestaﬀ within cardiology, oncology, and general medicine and compared
to medians similarly calculated within service). Columns (4) and (5) feature a measure of attending spending,
which is the average cumulative eﬀect of attending physicians who worked with the housestaﬀ of interest up
to the last prior tenure interval. Attending “eﬀects” are calculated by a random eﬀects method that adjusts
for finite-sample bias; since patients are not as good as randomly assigned to attending physicians, these
eﬀects do not have a strict causal interpretation at the level of the attending physician. Other specifications
(e.g., calculating all measures across services, or not conditioning on housestaﬀ identity) were similarly
estimated as insignificant and omitted from this table for brevity. All models control for patient and admission
characteristics, time dummies, and fixed eﬀects for attending and the other housestaﬀ on the team (e.g., the
resident is controlled for if the group is specific to the intern). Standard errors are clustered by admission.




                                                      42
                                     Table 4: Mean Eﬀect of Resident Tenure and Variation across Residents


                                                                     (1)             (2)              (3)             (4)             (5)
                                                                  Daily log       Daily log
                                                                                                 Log length         30-day         30-day
                                                                    test            total
                                                                                                   of stay         readmit        mortality
                                                                  spending        spending
                  Mean resident tenure eﬀect regression
                                                                    0.0057          0.0035          0.0072          0.0028          0.0002
                     Third-year resident
                                                                   (0.0070)        (0.0042)        (0.0060)        (0.0038)        (0.0027)
                     Observations                                  219,727         219,727          48,175          47,874          48,175
                     Adjusted R2                                    0.138            0.087           0.271           0.046           0.193

                  Counterfactual outcomes (none are log)
                    Mean outcome                                   $123.75        $1,279.57         3.996           0.124           0.071




43
                                                                   $124.45        $1,284.07         4.024           0.127           0.071
                     Third-year resident
                                                                   ($0.87)          ($5.35)        (0.024)         (0.004)         (0.003)
                                                                   $210.81        $1,563.90         4.346           0.168           0.107
                     1 s.d. increase in resident eﬀect
                                                                   ($4.08)         ($11.62)        (0.019)         (0.003)         (0.003)
                                                                   $72.64         $1,046.93         3.674           0.091           0.047
                     1 s.d. decrease in resident eﬀect
                                                                   ($1.40)          ($7.77)        (0.016)         (0.003)         (0.002)

     Note: In the top panel, this table reports results of regressions of various outcomes on having a third-year (as opposed to a second-year resident), as
     defined by Equation (7). Total spending includes imputed costs, such as physician and nurse salaries and operating costs. The third-year coeﬃcient
     is insignificant in all of the models. In the bottom panel, mean (non-logged) outcomes are reported, a counterfactual for having a third-year resident
     (assuming that a second-year resident was previously responsible for the mean outcome), and counterfactuals for switching the resident for another
     one who has a spending eﬀect one standard deviation higher or lower in the relevant outcomes. Distributional counterfactuals are generated by
     random-eﬀect models, discussed in Appendix A-2. The random eﬀect models are linear for daily log spending and log length of stay; they are logistic
     for readmissions and mortality. Random-eﬀect models are estimated for the entire sample, assuming constant spending eﬀects within the two years
     in the role of resident. Therefore, variation in spending eﬀects is less than in baseline Equation (2) which allows tenure-specific spending eﬀects.
     Standard errors are shown in parentheses.
Appendix (for Online Publication per Referees / Editor)

A-1         Quasi-random Assignment
This appendix presents two sets of randomization tests for exogenous assignment, complementing
evidence in Table 1. Section A-1.1 presents results regarding the assignment of patients to housestaﬀ.
Section A-1.2 presents the assignment of housestaﬀ to supervising physicians.

A-1.1        Assignment of Patients to Housestaﬀ
First, I test for the joint significance of housestaﬀ identities in regressions of this form:

                        Xa = Tt η + µs (a ∈ Service s ) + ζiτ <T + ζjτ >T + ζk + εaijtk ,                    (A-1)

where Xa is some patient characteristic or linear combination of patient characteristics for the
patient at a unique admission a at time t, being cared for by intern i, resident j, and attending
k on the day of admission. Tt is a set of time categories, including the day of the week and the
month-year interaction; µs is a fixed eﬀect that corresponds to the admitting service s (e.g., “heart
failure service” or “oncology service”). ζiτ <T , ζjτ >T , and ζk are fixed eﬀects for the intern i, resident
j, and attending k, respectively. For simplicity, I do not impose any relationship between the fixed
eﬀect of a housestaﬀ as an intern and the fixed (eﬀect of the)same housestaﬀ as a resident. I then
test for the joint significance of the fixed eﬀects ζiτ <T , ζjτ >T .
                                                                        i∈I,j∈J
   In column (1)
               ( of Table A-1,
                            )  I show F -statistics and the corresponding p-values for the null
                 τ <T  τ >T
hypothesis that ζi , ζj            = 0. I perform the regression (A-1) separately each of the
                                   i∈I,j∈J
following patient characteristics Xa as a dependent variable: patient age, a dummy for male sex, and
a dummy for white race.31 I also perform (A-1) using as dependent variables the linear prediction
of log admission test spending based on patient age, race, and gender. I fail to find joint statistical
significance for any of these tests.
       Second, I test for the significance of housestaﬀ characteristics in regressions of this form:

                        Xa = Tt η + µs (a ∈ Service s ) + γ1 Zi + γ2 Zj + ζk + εaijkt .                      (A-2)

Equation (A-2) is similar to Equation (A-1), except for the use of a vector of housestaﬀ characteris-
tics Zi and Zj for intern i and resident j, respectively, to test whether certain types of residents are
more likely to be assigned certain types of patients. Housestaﬀ characteristics include the following:
position on the rank list; USMLE Step 1 score; sex; age at the start of training; and dummies
for foreign medical school, rare medical school, AOA honor society membership, PhD or another
graduate degree, and racial minority.
  31
    I do not test for balance in patient diagnoses, because these are discovered and coded by physicians potentially
endogenous. Including or excluding them in the baseline specification of Equation (2) does not qualitatively aﬀect
results.



                                                       A-1
       Columns (2) and (3) of Table A-1 show F -statistics and the corresponding p-values for the null
hypothesis that (γ1 , γ2 ) = 0. Column (2) includes all housestaﬀ characteristics in Zh ; column (3)
excludes position on the rank list, since this information is missing for a sizeable proportion of
housestaﬀ. Patient characteristics for dependent variables in (A-2) are the same as in (A-1). Again,
I fail to find joint significance for any of these tests.
       Third, I compare the distribution of patient age and the predicted test costs across patients
admitted to interns and residents with high or low test spending eﬀects, which previously I estimate
in a regression of this form:

                              Yaijkt = Xa β + Tt η + ζiτ <T + ζjτ >T + ζk + εaijkt ,                             (A-3)

where Yaijkt is log test spending, Xa is a set of admission characteristics as described in Section
3, Tt is a set of time categories, and intern, resident, and attending fixed eﬀects denoted similarly
as in Equation (A-1). Figure A-2 shows kernel density plots of the age distributions for patients
assigned to interns and residents, respectively, each of which compare housestaﬀ with practice styles
above and below the mean. Figure A-3 plotting the distribution of predicted spending for patients
assigned to housestaﬀ with above- or below-mean spending practice styles. There is essentially no
diﬀerence across the distribution of age or predicted spending for patients assigned to housestaﬀ
with high or low spending practice styles. Kolmogorov-Smirnov statistics cannot reject the null that
the underlying distributions are diﬀerent.

A-1.2       Assignment of Housestaﬀ to Other Providers
To test whether certain types housestaﬀ are more likely to be assigned to certain types of housestaﬀ
and attending physicians, I perform the following regressions:

                                                       1−r
                                           ζ̂hr = γh ζ̂−h  + γk ζ̂k + εijka ,                                    (A-4)

where r ≡ 1 (τ > T ) is an indicator for whether the fixed eﬀect for housestaﬀ h was calculated
while h was an intern (r = 0) or a resident (r = 1). As in Equation (A-1), I assume no relationship
between ζ̂hτ <T and ζ̂hτ >T . Each observation in Equation (A-4) corresponds to an admission a, but
where error terms are clustered at the level of the intern-resident-attending team, since there are
multiple observations for a given team. ζˆk is the estimated fixed eﬀect for attending k.32 Estimates
for γh and γk are small, insignificant, and even slightly negative.
       Second, I perform a similar exercise as in the previous subsection, in which I plot the dis-
tribution of estimated attending fixed eﬀects working with housestaﬀ with above- or below-mean
spending practice styles. In Figure A-4, the practice-style distribution for attendings is similar
  32                                                                                                      (0)   (1)
    I use two approaches to get around the reflection problem due to the first-stage joint estimation of ζi , ζj , and
ζk (Manski, 1993). First, I perform (A-4) using “jack-knife” estimates of fixed eﬀects, in which I exclude observations
                                  (r)                           (1−r)
with −h and k to compute the ζˆh estimate that I use with ζ̂−h and ζ̂k . Second, I use the approach by Mas and
Moretti (2009), in which I include nuissance parameters in the first stage to absorb team fixed eﬀects for (i, j, k).



                                                         A-2
for those assigned to high- vs. low-spending housestaﬀ. As for distributions of patient charac-
teristics in Appendix A-1.1, diﬀerences in the distributions are not qualitatively significant, and
Kolmogorov-Smirnov statistics cannot reject the null that these distributions are diﬀerent, at least
when clustering at the level of the intern-resident-attending team.


A-2         Time-Fixed Practice Variation
This appendix discusses in more detail the approach I take in Section 4, where I estimate practice
variation attributable to residents in several outcome measures. Unlike the fuller statistical model
in Appendix A-5, used in Sections 5 and 6, I focus on variation due to the resident and consider
this variation to be fixed over time. However, this approach allows for both continuous and binary
outcomes, whereas the model in Appendix A-5 is restricted to continuous outcomes.
       Consider an outcome Yaijkt observed for admission a at time t under intern i, resident j, and
attending k. In the first step, I calculate a linear projection of the outcome PY (Xa , Tt , k) using
patient-admission characteristics Xa , a vector of time categories Tt , and the attending identity k,
using only within-housestaﬀ variation. That is, I estimate the regression

                                    Yaijkt = Xa β + Tt η + ζk + νij + εaijkt ,

and calculate PY (Xa , Tt , k) = Xa β̂ + Tt η̂ + ζ̂k . This linear projection is easy to calculate and
avoids incidental parameter problems in nonlinear models for binary outcomes.
       Unlike the approach in Appendix A-5, I cannot simply diﬀerence PY (Xa , Tt , k) from Yaijkt
and estimate a model restricted maximum likelihood (REML) model, because Yaijkt may be a
binary variable. I therefore estimate a random eﬀects model that controls for patient-admission
characteristics, time categories, and attending identities via this linear projection:

                                    Yajkt = g (PY (Xa , Tt , k)) + ξj + εajkt ,                                  (A-5)

omitting i in the subscript for the outcome. g (·) is a potentially flexible nonlinear function that
may be used if Yajkt is a binary outcome determined by a nonlinear model.33 ξj is a resident eﬀect,
and εajkt is an independent error term that is normal for continuous outcomes of log spending and
log length of stay and logistic for binary outcomes of readmission and mortality.
       Because I control for PY (Xa , Tt , k) directly in Equation (A-5), I need to explicitly allow for
correlations between ξj and PY (Xa , Tt , k). I allow for this in a correlated random eﬀects approach
(Abowd et al., 2008) by considering two components of ξj – uj that is correlated with PY (Xa , Tt , k),
and vj that is uncorrelated with uj and PY (Xa , Tt , k) – and by modeling uj as a projection of the
  33
    I operationalize g (·) as a linear function of cubic splines. Results are insensitive to whether I allow for
g (PY (Xa , Tt , k)) or simply take the projection linearly as γPY (Xa , Tt , k). In my baseline results, I use the lat-
ter approach.




                                                         A-3
empirical expectation of PY (Xa , Tt , k) conditional on j. Define this empirical expectation as
                                                ∑
                                                    1 (j (a) = j) PY (Xa , Tt , k)
                                     P̂Y |j =            ∑                         ,
                                                            1 (j (a) = j)

where 1 (j (a) = j) is an indicator for whether an admission a, for which there exists a projection
PY (Xa , Tt , k), is associated with resident j. I then estimate Equation (A-5) as

                                Yajkt = g (PY (Xa , Tt , k)) + δ P̂Y |j + vj + εajkt .                              (A-6)

The term δ P̂Y |j absorbs the component uj .34 In applications of correlated random eﬀects that
are interested in
               ( the )   variance of ξj , both components uj and vj are used in this calculation, i.e.,
d           d                d (vj ). However, part of Section 4 aims to compare the eﬀects on diﬀer-
Var (ξj ) = Var δ̂ P̂Y |j + Var
ent outcomes among residents who are as good as randomly assigned patients. Therefore, I focus
on empirical Bayes predictions of vj formed by estimates of (A-6) (Searle et al., 1992). This exer-
cise compares resident eﬀects that are orthogonal to projections of average patient characteristics,
time categories, and attending identities, and more closely approximates the conditional random
assignment design that one obtains under the REML approach in Sections 5 and 6 (Appendix A-5).


A-3       Conceptual Framework of Team Decisions
A-3.1      Influence in Team Decisions
Consider a simple team-theoretic environment of decision-making (e.g., Cyert and March, 1963;
Radner, 1993; Garicano, 2000), in which team members use the information they have to make the
best decision for caring for a particular patient.35 The team must take an action a to match an
unknown state θ, and will receive utility

                                                u (a; θ) = − (θ − a)2 .                                             (A-7)

    The team responsible for the care of a patient is comprised of two housestaﬀ agents, a first-year
“intern” i and a second- or third-year “resident” j. These two agents also operate within a practice
environment, including other supervising (“attending”) and consulting physicians, institutional rules
(e.g., they are required to get consultant approval to order expensive tests in certain cases), and
known standards of practice at the institution and more broadly.
    The intern has a normal prior subjective distribution of θ, with mean mi and precision gi ,
   34
      I also consider versions of Equation (A-6) that allow for cubic splines of δ P̂Y |j , and results are robust to these
nonlinear transformations.
   35
      Although the experimental literature has shown that agents may have intrinsic utility for influence (Bartling et
al., 2014), I abstract from heterogeneous preferences or specialization at the individual physician level to highlight
the simple mechanism that more-experienced agents should have greater influence in the absence of moral hazard.
However, the intuition should follow in more complicated settings as long as there is a common component to the
decision that is agreed upon by both agents, and there is incomplete information about that component.



                                                           A-4
dropping reference to time for simplicity. The resident also has a normal subjective distribution of
θ, with mean mj and precision gj . Finally, I model the practice environment by another “prior”
with mean 0 and precision G. If agents h ∈ {i, j} can communicate (mh , gh ) and know G, the
utility-maximizing action is
                                                       gi mi + gj mj
                                                a∗ =                 .                                          (A-8)
                                                       gi + gj + G
This framework illustrates that the “best guess” or mean of each housestaﬀ’s belief is weighted by
a factor akin to influence on the team and within the practice environment, gh / (gh + g−h + G).
    The more precise her signal is relative to her teammate and the practice environment, the
greater her influence will be. Because teams are always comprised of an intern and a resident,
when a housestaﬀ’s tenure passes the one-year mark, she will be assigned to a teammate who has
one year less experience than her, while she previously worked with a teammate who had at least
one year more experience. This discontinuous decrease in g−h results in a discontinuous increase
in her influence (and the variation in medical care attributable to newly minted residents relative
to seasoned interns), even if mh and gh are continuous across time. With respect to the practice
environment, a housestaﬀ’s influence will be lower in a tighter practice environment with higher
G. At the extreme, if care were dictated by attending physicians or guidelines, there should be no
variation attributable to housestaﬀ.

A-3.2      Learning and Convergence
Next consider convergence due to learning, or the process by which housestaﬀ beliefs change over
time. The key intuition is that the rate of learning may depend on the the amount and accessibility
of knowledge to be learned, because learning requires accessing outside knowledge and incorporating
it to future clinical practice.36 This intuition appeals to a broad literature on search theory (see
e.g., Rogerson et al. 2005, for a review), which allows physician learning to slow down or stop
if the search costs of learning exceed the benefits.37 I model this in reduced-form as a precision
function gh = g (τ ; K) that depends on the tenure τ (or experience) of housestaﬀ h and implicitly
on the practice environment K in which the housestaﬀ learns. Under classical Bayesian learning,
the distribution of subjective means mh conditional on tenure τ has mean 0 and standard deviation
g (τ ; K)−1/2 .
  36
     Although θ is known perfectly ex post in the setup in Section A-3.1, one may consider θ to be imperfectly observed
(e.g., observed with some noise), imperfectly remembered, or most importantly imperfectly informative for future
patients, who will be diﬀerent, in the absence of devoting some cost to learning.
  37
     See Caplin and Dean (2015) for a broader discussion of rational decision-making under knowledge constraints
and information cost functions. An alternative formulation by Acemoglu et al. (2006) allows for a lack of asymptotic
agreement if there is suﬃcient uncertainty in the subjective distributions that map signals onto underlying parameters.
Also, Ellison and Fudenberg (1993) show that, under social learning, there will be less convergence if agents observe
greater diversity in choices made. In this section I am agnostic about the mechanism of learning, except that agents
increase the precision of their beliefs with experience. One intriguing possibility, that seems consistent with some
of the numerical results in Appendix A-4, is that housestaﬀ learn more as residents because they get feedback on
decisions that they influence, an idea explored in psychology (Csikszentmihalyi, 1990).




                                                         A-5
       Thus, restating Equation (A-8) as

                                                        g i mi     gj mj
                                 a∗ = a∗i + a∗j =              +            ,                                 (A-9)
                                                    gi + gj + G gi + gj + G

the standard deviation σ (τ ; K) of experience-specific housestaﬀ eﬀects a∗h,τ can be stated as

                                                           g (τ ; K)1/2
                                   σ (τ ; K) =                                ,                              (A-10)
                                                 g (τ ; K) + g (τ + ∆; K) + G

where the index cohort {h} has tenure τ and the cohort {−h} of the other team member has tenure
τ + ∆, where ∆ may be positive or negative. At time t relative to the beginning of the academic
year, intern tenure is t, and resident tenure is t + T or t + 2T , where T is one year, for second- or
third-year residents, respectively.
       Define convergence as a reduction in σ (τ ; K) with time, i.e., as ∂σ (τ ; K) /∂τ < 0 within academic
years. Unlike in settings where there is a single decision-maker and G = 0, g ′ (τ ) > 0 is not suﬃcient
for convergence. First, convergence in variation attributable to a decision-maker is muted when that
decision-maker’s influence is limited. Second, as long as influence is limited (i.e., there are other
agents with information), increasing g (τ ) may primarily increase influence and therefore even widen
variation. I explore these implications further and provide numerical examples in Appendix A-4.

A-3.3        Tacit Knowledge and Hierarchy
One reason why learning can only increase with tenure is that knowledge cannot be costlessly
passed from senior to junior housestaﬀ. That is, knowledge is tacit, or equivalently, there are
informational frictions in the transfer of knowledge that can have important implications for practice
variation, even with identical preferences and no systematic diﬀerences in experiences (i.e., “schools
of thought”) across agents in the same cohort. A natural extension of this is that agents h ∈ {i, j}
cannot fully communicate their beliefs, in particular gh , even in the specific case of the decision
at hand. This leads to the idea of hierarchies, in which agents may simply weight mh based on
characteristics of h such as tenure or perceived expertise that are imperfectly correlated with gh .
       This particularly applies to hierarchies in which there is no asymmetric decision rights or formal
mechanism for one agent to reward or punish another.38 In this sense, hierarchies are analogous to
directives within a firm as discussed by Alchian and Demsetz (1972): They are not defined by “some
superior authoritarian directive or disciplinary power,” but rather they arise endogenously given the
underlying information structure and production process, and given the need to settle on a routine
that is most likely to yield eﬃcient outcomes. Of note, absent learning and tacit knowledge, Garicano
  38
     Another explanation for why subordinate agents contribute less information about θ than managers do involves
moral hazard, outside of the team-theoretic framework: Agents exert private eﬀort to gather information, managers
are principals who incentivize agents to exert eﬀort but only can assess this by gauging m̂i relative to mj , where
j is now the principal, and agents can observe mj (Scharfstein and Stein, 1990; Prendergast, 1993). However, in
this and many other settings, senior team members (i.e., residents) are not principals and cannot provide incentives.
Only attending physicians perform housestaﬀ evaluations, with only weak career implications. If attending physicians
assess intern eﬀort by comparing m̂i to mj , this must still be founded upon learning, in which gj > gi .


                                                        A-6
(2000) and Garicano and Rossi-Hansberg (2006) predict “management by exception” under which
managers with larger spans of control (i.e., the resident, who is assigned to two interns) should have
less influence over average daily decisions. The prediction here does not contradict their important
insight but highlights an additional mechanism, due to learning, in which senior agents can have
greater influence under tacit knowledge.


A-4      Variation over Time under Example Learning Parameters
This appendix further explores the implications of the conceptual framework in Section A-3, in which
decision-making is modeled in a team-theoretic environment, along a continuous action space, for
two agents with normal priors. While this framework is not meant to be taken literally (e.g., actions
may not be continuous, decision-making may not be strictly team-theoretic), this appendix provides
further intuition and numerical examples in this framework for how learning could lead to persistent
practice variation.

A-4.1     Analytical Evaluation
Consider the standard deviation of experience-specific housestaﬀ eﬀects a∗h,τ , originally stated in
Equation (A-10):

                                                     g (τ )1/2
                                    σ (τ ) =                        ,                             (A-11)
                                             g (τ ) + g (τ + ∆) + G
omiting reference to the learning environment K for brevity. σ (τ ) can be thought of a profile of
practice variation across housestaﬀ over diﬀerent tenure periods, akin to the profiles empirically
estimated in the paper (e.g., Figure 3). g (τ ) is the precision of a housestaﬀ’s subjective prior, given
that the housestaﬀ has tenure τ , and can be thought of as related to learning over τ : Greater g (·)
reflects greater knowledge; greater g ′ (·) reflects faster learning. In the standard case, assume that
g ′ (·) > 0, i.e., there is no “forgetting.” ∆ is the tenure diﬀerence between housestaﬀ of tenure τ
and other housestaﬀ whom this group works with. Finally, recall that G reflects the strength of the
external practice environment, or the precision of the “prior” that includes attending physicians and
institutional rules, which I will refer to as the “external prior.”
   A few observations about practice variation and learning can be made. First, note that the scale
and the shape of the practice variation profiles can be separately rationalized.

Proposition A-1. Consider a practice variation profile, σ (τ ), that exists under a learning profile
g (τ ) and external prior G. Then κσ (τ ) also exists for any constant κ.

Proof. The learning profile g (τ ) /κ2 and external prior G/κ2 yield the desired practice variation
profile κσ (τ ) under Equation (A-11).

   Scaling both the learning profile and the external prior by a constant preserves the “influence”
that each agent has relative to each other and to the external practice environment. However, vari-

                                                   A-7
ation across agents in their mean beliefs will be increased (or decreased) as they all have subjective
prior distributions smaller (or greater) precisions.
   Next, consider the discontinuity in practice variation across the one- and two-year tenure marks.
Recall that at the beginning of the academic year in June, new interns (first-year housestaﬀ) arrive,
and experienced interns proceed to the role of resident. Housestaﬀ train for a total of three years,
so that in June there are both residents with one year of training and two years of training.

Proposition A-2. Define σ (T − ) ≡ limτ →T − σ (τ ), and σ (T + ) ≡ limτ →T + σ (τ ); similarly define
σ (2T − ) ≡ limτ →2T − σ (τ ), and σ (T + ) ≡ limτ →2T + σ (τ ). Then

                                              σ (2T + )   σ (T + )
                                                        >          > 1.
                                              σ (2T − )   σ (T − )

Proof. Consider the conservative case that interns only work with second-year residents in their last
month. Then
                                          σ (T + )   g (T ) + g (2T ) + G
                                                   =                      ,
                                          σ (T − )    g (T ) + g (0) + G
   and
                                         σ (2T + )   g (2T ) + g (T ) + G
                                               −
                                                   =                      .
                                         σ (2T )     g (2T ) + g (0) + G
   Since g (·) is monotonically increasing, g (0) < g (T ) < g (2T ), which yields our result.

   Because there is a change in the tenure of the other housestaﬀ as new interns arrive at the
beginning of each academic year, there is in principle a discontinuous increase in influence (and
therefore practice variation) at the beginning of each year. However, the increase at τh = T is
always larger than the increase at τh = 2T for two reasons, both related to the monotonic increase
in precision with tenure: First, housestaﬀ at τh = T have less precise subjective priors than those at
τh = 2T , so any decrease in the relative tenure of their peer housestaﬀ increases their influence by
more. Second, the decrease in the relative tenure of the peer is greater at τh = T (from τ−h = 2T to
τ−h = 0) than at τh = 2T (from τ−h = T to τ−h = 0). I will show below in the numerical examples
that, within this framework, this diﬀerence in the discontinuous increases at τh = T and at τh = 2T
can be quite large, and that the discontinuity at τh = 2T can be quite trivial. Of course, there
are other reasons for a negligible discontinuity at τh = 2T , including discrete decisions and rules of
thumb, such as titles of “resident” and “intern” meaning more than actual tenure within titles.
   Finally, consider the derivative of variation with respect to tenure:

                               −1/2 ′
                       1
                       2 g (τ )    g (τ ) (g (τ )   + g (τ + ∆) + G) − g (τ )1/2 (g ′ (τ ) + g ′ (τ + ∆))
          σ ′ (τ ) =                                                                                        .
                                                    (g (τ ) + g (τ + ∆) + G)2

Focusing on the numerator to determine the sign of σ ′ (τ ), I arrive at the following necessary and
suﬃcient condition for convergence (i.e., σ ′ (τ ) < 0):

                                                              g ′ (τ )
                         σ ′ (τ ) < 0 ⇔ g (τ ) >                             (g (τ + ∆) + G) .                  (A-12)
                                                     2g ′ (τ + ∆) + g ′ (τ )

                                                           A-8
This condition highlights that convergence is not supported at all τ under all learning profiles g (τ ).
In particular, if the precision of the index housestaﬀ’s subjective prior g (τ ) is less than the combined
precision of the peer’s subjective prior g (τ + ∆) and the external practice environment’s precision
G, then convergence may not be supported, particularly if g ′ (τ ) is large relative to g ′ (τ + ∆). The
intuition for this is related to influence. For small g (τ ) relative to g (τ + ∆) + G, the housestaﬀ
has relatively low influence, and increases in g (τ ) may increase variation primarily by increasing
influence. This is especially true if most of the learning occurs in the index housestaﬀ’s cohort as
opposed to the peer’s cohort, or g ′ (τ ) ≫ g ′ (τ + ∆), because learning by the peer reduces influence.
However, regardless of the size of g ′ (τ ), a suﬃcient condition for convergence is g (τ ) > g (τ + ∆)+G.
Given that g (·) is monotonically increasing, this suggests that convergence is more likely with
residents than with interns.
      In order to make further observations, I consider a piecewise linear function for the learning
profile g (τ ).

Proposition A-3. Assume that g (τ ) takes a piecewise linear form, such that

                             g (τ ) = k0 + k1 min (τ, T ) + k2 max (τ − T, 0) .                   (A-13)

For any g (τ ) that satisfies the form (A-13), conditional on some ∆ > 0 (i.e., τ < T ), there exists a
              ∗
unique point τ∆>0 such that σ ′ (τ ) > 0 for all τ < τ∆>0
                                                      ∗   , and σ ′ (τ ) < 0 for all τ > τ∆>0
                                                                                          ∗   . Similarly,
                                                                       ∗
conditional on some ∆ < 0 (i.e., τ > T ), there exists a unique point τ∆<0 such that σ ′ (τ ) > 0 for
         ∗
all τ < τ∆<0 , and σ ′ (τ ) < 0 for all τ > τ∆<0
                                             ∗                              ∗
                                                 . The specific forms that τ∆>0      ∗
                                                                                and τ∆<0 take are

                              ∗          G + k1 T + k2 (∆ − T ) − 2k0 k2 /k1
                             τ∆>0 =                                          ;                    (A-14)
                                                      k1 + k2
                              ∗          G + k1 ∆ − 2k1 (k0 + k1 T ) /k2
                             τ∆<0 =                                      + T.                     (A-15)
                                                    k1 + k2

Proof. State the convergence condition in Equation (A-12) as a criterion function G (τ ; ∆) in which
convergence occurs if and only if G (τ ; ∆) > 0:

                                      (                       )
                    G (τ ; ∆) = g (τ ) 2g ′ (τ + ∆) + g ′ (τ ) − g ′ (τ ) (g (τ + ∆) + G) ,

      Under any g (τ ) of the form (A-13), G (τ ; ∆) is monotonically increasing in τ , which implies a
                       ∗ ; ∆) = 0 conditional on ∆. To arrive at the specific functions that τ ∗
single solution to G (τ∆                                                                      ∆>0 and
 ∗
τ∆<0                                                                    ∗ ; ∆) = 0 and solve for
     take in Equations (A-14) and (A-15), plug Equation (A-13) into G (τ∆
 ∗.
τ∆
                 ∗
      Note that τ∆>0 in Equation (A-14) may be less than 0 or greater than T . In the former case,
there is convergence for all τ ∈ [0, T ] (the entire intern year); in the latter case, there is divergence
                                                   ∗
(variation is increasing) for all τ ∈ [0, T ]. If τ∆>0 ∈ (0, T ), then variation in practice styles first
increases then decreases. Similarly, practice variation may be increasing over the tenure period as



                                                     A-9
a resident τ ∈ [T, 3T ], decreasing over the entire period, or first increasing then decreasing.39 As
noted above, and by comparing (A-14) and (A-15), convergence is more likely and occurs earlier
during the period as resident than during the period as intern.

A-4.2        Numerical Examples
Figure A-1 presents a few numerical examples of variation profiles under diﬀerent learning profiles
described by functions of the piecewise linear form in Equation (A-13). The three parameters of
interest are k0 , or the precision of subjective beliefs before starting training; ki , or the rate of increase
in the precision during intern year; and kj , or the rate of increase during the subsequent two years
as a resident. I normalize the scale of time with T = 1, so that ki and kj also represent increases in
the precision per year, and the precision of beliefs at the end of training is g (3T ) = k0 + ki + 2kj .
I also normalize G = 1, so that whether precisions of beliefs are greater than the precision of the
external prior simply depends on whether they are greater or less than 1. Given Proposition A-1,
I consider this normalization as only relevant for the scale of the variation profile, since any scale
keeping the same shape over the overall variation profile σ (τ ) can be implemented by multiplying
k0 , ki , kj , and G by some constant.
       I discuss each panel of Figure A-1 in turn:

       • Panel A considers equal k0 = ki = kj = 0.2, which are relatively small compared to G = 1. The
         result is broadly non-convergence, as greater experience primarily results in greater influence
         against a relatively strong external practice environment. The discontinuity in variation is
         significantly larger at t = T than at t = 2T . Variation increases in intern year and decreases
         but only slightly in the next to years as resident.

       • Panel B imposes no resident learning (kj = 0) and presents the limiting case in which dis-
         continuous increases in variation at t = T and t = 2T are the same. Variation is still at
         least as big during the two years as resident as during the year as intern, driven by influence.
         Variation seems relatively constant over training.

       • Panel C generates a similar variation profile as in Panel B with a non-zero kj by increasing
         the ratios of k0 and ki to kj . The scale of variation is smaller than in Panel B, which reflects
         that precision in housestaﬀ beliefs are now larger. A rescaled version with smaller precisions
         (and smaller G) would reveal larger relative increases in variation at the discontinuities.

       • Panel D examines increasing ki relative to k0 , so that more learning occurs in the first year of
         training as opposed to knowledge possessed before starting training. Influence more obviously
         increases in the first year, and increases in variation are sharper at the discontinuities, since
         intern experience matters more. Note that working with a resident is equivalent with working
         with a end-of-year intern, and increases in variation at τ = T and τ = 2T are the same (as in
         Panel B).
  39                                               ∗     ∗
       This is ensured even across τ = 2T because τ−T > τ−2T .


                                                        A-10
       • Panel E asserts that most of the learning occurs during the role as resident. There is much
         greater variation across residents than across interns, and the discontinuous increase in vari-
         ation is much larger at τ = T , while the increase is negligible at τ = 2T . There is significant
         convergence during the two years as resident.

       • Panel F is similar to panel E but shows less convergence during role as resident. The ratio
         of learning as intern to learning as resident (ki /kj ) is similar, but learning during training
         is reduced relative to knowledge gained prior to training (k0 ) and to the external practice
         environment (G).


A-5         Statistical Model of Housestaﬀ Eﬀects
In this appendix, I introduce a statistical model to estimate the standard deviation σ (τ ) of housestaﬀ
eﬀects a∗h,τ in discrete tenure period τ and the correlation ρ (τ1 , τ2 ) between housestaﬀ eﬀects a∗h,τ1
and a∗h,τ2 in two discrete periods τ1 and τ2 . Random assignment of patients to housestaﬀ, conditional
on time categories, allows me to estimate housestaﬀ eﬀects.40 Finite observations per housestaﬀ-
period means that eﬀects will be estimated with error, which implies that standard deviations of
unshrunken eﬀects will overstate the true σ (τ ). Further, correlations of estimates â∗h,τ1 and â∗h,τ2
will be generally understate true correlations, and comparing the relative magnitudes of correlations
between two pairs of periods will be invalid.
       Standard Bayesian shrinkage procedures to adjust for finite-sample overestimates of σ (τ ) (e.g.,
Morris, 1983),41 however, deal with a single eﬀect entering the right-hand side of each observation.
In this setting, I must deal with two eﬀects – one for the intern and one for the resident – for which I
want to estimate distributions. Having two sets of eﬀects results in two complicating issues: First, it
is possible that all housestaﬀ may not form a single connected set, so eﬀects must be first demeaned
within connected set. Second, more importantly, shrinking one set of eﬀects requires a relatively
precise mean to shrink toward; this requirement is violated because the eﬀects of the other set are
equally problematic, which results in biased estimates of the underlying distribution. Even without
this complication, Bayesian shrinkage does not resolve the issue of biased estimates of ρ (τ1 , τ2 ),
since errors in estimates of a∗h,τ1 and a∗h,τ2 are not eliminated but only shrunken.42
       I therefore adopt a random eﬀects approach in which I simulaneously estimate both distributions
of intern and resident eﬀects by maximum likelihood. First, similar in spirit to Chetty et al. (2014)
and closely related to the idea of restricted maximum likelihood (REML) (Patterson and Thompson,
  40
     I do not strictly require conditional random assignment of patients to housestaﬀ if I use patients that are shared
by multiple interns or residents due to lengths of stay spanning scheduling shifts. However, I do not rely on this in
my baseline specification, in order to use more of the data.
  41
     Recent examples of papers that have used this procedure include Kane and Staiger (2002), Jacob and Lefgren
(2007), and ?.
  42
     Chetty et al. (2014) develop a method of moments approach of predicting unbiased teacher eﬀects that accounts
for drift in eﬀects over time and actually estimates the covariance between eﬀects in diﬀerent periods. However, a
crucial assumption they make is that eﬀects follow a stationary process, which is obviously not true among housestaﬀ
because of both learning and influence.



                                                        A-11
                                                         (                   )
1971), I create the diﬀerenced outcome Ỹaijkt = Yaijkt − Xa β̂ + Tt η̂ + ζ̂k , where β̂, η̂, and ζ̂k are
estimated by using variation within housestaﬀ pairs and discrete tenure[ periods. This] allows random
housestaﬀ eﬀects to be correlated with Xa , Tt , and ζk . Note that E Ỹaijkt |a, k, t = 0 for all a, k,
                                                         43

and t. In practice, given quasi-random assignment of attending physicians and patients to housestaﬀ,
conditional on schedules, I am only concerned with correlations between housestaﬀ eﬀects and Tt ,
but diﬀerencing out projections due to Xa and ζk simplifies computation and avoids the incidental
parameters problem in the later maximum-likelihood stage. In the next two subsections I will
describe in turn how I calculate σ (τ ) and ρ (τ1 , τ2 ). In simulated data (not shown), I confirm that
Bayesian shrinkage results in inaccurate estimates of these moments and that the statistical method
outlined in this appendix yield close estimates of the true moments of the data generating process,
regardless of the number of observations per intern or residents.

A-5.1      Standard Deviation of Housestaﬀ Eﬀects
To estimate σ (τ ), I specify a crossed random eﬀects model for each set of days comprising a
housestaﬀ tenure period τ ,
                                                             τ +∆
                                            Ỹaijkt = ξhτ + ξ−h   + εaijkt ,                                       (A-16)

using observations for which τ (h, t) = τ . In other specifications, I consider a random eﬀect model
that allows for unobserved heterogeneity in patients:

                                                          τ +∆
                                         Ỹaijkt = ξhτ + ξ−h   + νa + εaijkt ,                                     (A-17)

where νa is an admission eﬀect.44 Because housestaﬀ are assigned conditionally randomly to each
                              τ +∆                                                             τ +∆
other and to patients, ξhτ , ξ−h   , and νai are uncorrelated with each other. Assuming ξhτ , ξ−h   , and
νa are normally distributed, their standard deviations σξ,τ , σξ,τ +∆ , and σν are estimated by the
standard maximum-likelihood method.
    Equations (A-16) and (A-17) can be stated in vector form:

                                                     Ỹ = Zu + ε,                                                  (A-18)

where Ỹ is the n × 1 vector of diﬀerenced outcomes, Z is a selection matrix, and u is a stacked
vector of random eﬀects.
    Let Nh be the number of housestaﬀ with tenure τ and N−h be the corresponding peers observed
in the sample. Then in the case that (A-18) represents (A-16), Z is an n × (Nτ + Nτ +∆ ) selection
matrix for housestaﬀ with tenure τ and their peers, and u is an (Nτ + Nτ +∆ ) × 1 stacked vector of
  43
     An alternative albeit slightly more involved approach involves estimating “correlated random eﬀects,” as described
by Chamberlain (1984) and Abowd et al. (2008).
  44
     This specification requires the use of sparse matrices for estimation. In specifications without the use of sparse
matrices, I nest this eﬀect within interns, i.e., I include νai as an intern-admission eﬀect. While it is easier to estimate
a specification with νai , I will describe this specification for ease of explication. In practice, results are materially
unaﬀected by whether I use νa or νai , or in fact whether I include an admission-related eﬀect at all.




                                                           A-12
housestaﬀ and peer random eﬀects. The variance-covariance matrix of u is diagonal:
                                               [                                ]
                                                    2 I
                                                   σξ,τ               0
                                                        Nh
                              Var u = G =                         2
                                                                                    .
                                                         0       σξ,τ +∆ IN−h


   Similarly, in the case that (A-18) represents (A-17), Z is an n × (Nτ + N + Na ) selection matrix
for intern i, resident j, and admission a, and u is an (Ni + Nj + Na ) × 1 stacked vector of intern,
resident, and admission random eﬀects, where Na is additionally the number of admissions in the
sample. The diagonal variance-covariance matrix of u is
                                            2 I
                                                                                        
                                            σξ,τ Nh               0             0
                                                                                       
                          Var u = G =             0          2
                                                             σξ,τ +∆ IN−h       0       .
                                                   0              0         σν2 INa

   Using the definition V = ZGZ′ + σε2 In , the log likelihood function under either of the above
specifications is
                                    1{                                 }
                             L=−      n log (2π) + log |V| + Ỹ′ V−1 Ỹ .                        (A-19)
                                    2
I thus estimate (A-16) or (A-17) by maximum likelihood, for each τ separately. Although each
estimation yields results for both σξ,τ and σξ,τ +∆ , the parameter of interest for a given τ is σξ,τ ≡
σ (τ ). Note that for τ corresponding to interns, the peer housestaﬀ are residents who may have
                                                                  τ +∆
tenure one or two years greater than τ , and the distribution of ξ−h   should not be interpreted as
tenure-specific. For τ corresponding to residents, σξ,τ +∆ is estimated for only part of the sample of
interns working with residents of tenure τ .

A-5.2     Correlation of Housestaﬀ Eﬀects
To estimate ρ (τ1 , τ2 ), I augment models in (A-16) and (A-17) to account for two separate tenure
periods τ1 and τ2 across which housestaﬀ eﬀects may be correlated. Although I observe each
housestaﬀ across their entire training, I only observe a subset of these housestaﬀ in each 60-day
or 120-day tenure period, and the number of housestaﬀ observed in two diﬀerent tenure periods
is even smaller. Because housestaﬀ that I do not observe in both τ1 and τ2 do not contribute to
the estimate of ρ (τ1 , τ2 ), I only include in the estimation sample observations associated with a
housestaﬀ observed in both tenure periods.
   Specifically, in place of Equation (A-16), I consider

                                               τ (h,t)      τ +∆
                                   Ỹaijkt = ξh          + ξ−h   + εaijkt ,                      (A-20)

which features the function τ (h, t) ∈ {τ1 , τ2 }. This specifies that eﬀects of housestaﬀ in the tenure
periods of interest (τ1 and τ2 ) may be drawn from two separate distributions depending on the
tenure period τ1 or τ2 corresponding to observation t, while eﬀects of the peer housestaﬀ (with



                                                       A-13
tenure τ + ∆) are pooled into a single distribution. The analog for Equation (A-17) is

                                            τ (h,t)         τ +∆
                                 Ỹaijkt = ξh            + ξ−h   + νa + εaijkt .                  (A-21)

   As above, both (A-20) and (A-21) can be written in the vector form of (A-18). When representing
(A-20) as (A-18), the selection matrix Z is of size n×(2Nτ + Nτ +∆ ) , since it now maps observations
onto one of two random eﬀects of the index housestaﬀ h, depending if τ (h, t) = τ1 or τ (h, t) = τ2 .
The stacked vector of random eﬀects u is similarly of size (2Nτ + Nτ +∆ )×1. The variance-covariance
matrix of u is                                       [                          ]
                                                          Gτ           0
                                 Var u = G =                      2
                                                                                    ,
                                                             0   σξ,τ +∆ IN−h

where Gτ is a 2Nτ × 2Nτ block-diagonal matrix of the form
                                                                        
                                                    A        0   ···  0
                                                                     .. 
                                                                      . 
                                                   0        A           
                                     Gτ =                               ,
                                                   ..           ..
                                                                    . 0 
                                                    .                   
                                                    0        ··· 0 A

with each block being the 2 × 2 variance-covariance matrix A of random eﬀects within housestaﬀ
and across tenure periods:                  [            ]
                                                ξhτ1
                                      Var                    = A, for all h.
                                                ξhτ2

   Representing (A-21) as (A-18) is a similar exercise. The selection matrix Z is of size n ×
(2Nτ + Nτ +∆ + Na ), and the vector of random eﬀects u is of size (2Nτ + Nτ +∆ + Na ) × 1. The
variance-covariance matrix of u is
                                                                                       
                                                    Gτ            0             0
                                                                                       
                             Var u = G =  0                  2
                                                             σξ,τ +∆ IN−h       0       ,
                                                    0             0         σv2 INa

where Gτ is the same as before.
   The log likelihood is the same as in Equation (A-19), but using revised definitions of G that allow
for covariance between random eﬀects of the same housestaﬀ across tenure periods. The correlation
parameter of interest ρ (τ1 , τ2 ) is estimated from Â and is constrained to be between −1 and 1.
Standard errors of the correlation estimate are calculated by a likelihood ratio test comparing the
likelihood of models fit while holding the correlation fixed but varying all other parameters with the
globally optimal fit (i.e., they do not depend on any assumption about the distribution of ρ̂ (τ1 , τ2 )).




                                                         A-14
A-6         Bayesian Refinement of Serial Correlation Estimates
Appendix A-5.2, describes a procedure to estimate the correlation between housestaﬀ eﬀects in any
two tenure periods. While I am most interested in evaluating how serial correlation between two
adjacent periods changes through training, there is valuable information in the correlation between
non-adjacent periods that relates to these parameters of interest. This is particularly the case
since I only observe a subset of housestaﬀ practicing in any given pair of periods. The eﬃcient
method of incorporating all of this information would be to jointly estimate all correlations at once,
but given the computational burden of estimating a crossed random eﬀects model and the large
number of observations in the full sample, I am required to keep the specification simple and sample
restricted.45
       Given this, I develop a methodology to refine estimates of the correlation between housestaﬀ
eﬀects in adjacent periods based on estimates of other correlations between eﬀects in non-adjacent
periods. To be more notationally concrete, assume that τ is an integer from 1 (the first tenure period)
to τmax = 15 (the last tenure period), and denote the set T = {1, . . . , τmax }. In this approach, I
first infer prior distributions of ρ (τ, τ + 1) based on other correlations from non-adjacent periods
and then use these prior distributions and the maximum-likelihood estimate ρ̂ (τ, τ + 1) described
in Appendix A-5.2 to compute a posterior distribution.
       The first step is to use estimates of correlations between non-adjacent periods as information on
a correlation ρ (τ, τ + 1) for some τ . The insight here is that if, for some τ ′ ∈
                                                                                  / {τ, τ + 1}, correlations
ρ (τ, τ ′ ) and ρ (τ + 1, τ ′ ) are known, then this information would place bounds on admissible values
of ρ (τ, τ + 1).

Proposition A-4. Consider random variables X, Y , and Z, such that Corr (X, Y ) = γ and
Corr (Y, Z) = φ. Then Corr (X, Z) satisfies
                          √                                                √
                   γφ −       (1 − γ 2 ) (1 − φ)2 ≤ Corr (Y, Z) ≤ γφ +         (1 − γ 2 ) (1 − φ2 ).

Proof. Without loss of generality, assume that E [X] = E [Y ] = E [Y ] = 0 and Var (X) = Var (Y ) =
Var (Z) = 1. If these conditions do not hold, we can renormalize the random variables without
changing the correlation between them. Consider the projection of Z on X and Y :

                                              Z = αX + βY + U,                                               (A-22)

where Corr (X, U ) = 0 and Corr (Y, U ) = 0. In addition, consider the projection of Y on X:

                                                  Y = γX + V,                                                (A-23)
  45
     Many crossed random eﬀects models without any correlation parameters were computationally feasible until a
few years ago when sparse matrix methods became available, which some statistical packages such as Stata have yet
to incorporate. With 15 periods, the fully specified model would have 105 correlations to estimate jointly. The fully
specified model Further, computational issues are considered important even for “moderately large” datasets, defined
as having between 10,000 to 100,000 observations (Bates et al., 2015), while the full dataset of this study has more
than 200,000 patient-day observations.


                                                       A-15
where Corr (X, V ) = 0. Observe that the coeﬃcient on X in this projection is indeed γ: Corr (X, Y ) =
Corr (X, γX + V ) = γCorr (X, X) = γ. Next, substituting (A-23) into (A-22) gives

                                           Z = (α + βγ) X + U + BV.                               (A-24)

Therefore, Corr (X, Z) = Corr (X, (α + βγ) X + U + BV ) = α + βγ since Corr (X, U ) = 0 and
Corr (X, V ) = 0. Hence, we have φ = α + βγ, or equivalently, α = φ − βγ.
      Now we are ready to bound Corr (Y, Z) = 0:

             Corr (Y, Z) = Corr (γX + V, (α + βγ) X + U + BV ) = γ (α + βγ) + βVar (V ) ,

using Corr (V, U ) = Corr (Y − γX, U ) = 0, since Corr (X, U ) = Corr (Y, U ) = 0. In addition, the
variance of V can be found from (A-23):

                                                 1 = γ 2 + Var (V ) .

Hence,
                                                           (       )
                               Corr (Y, Z) = γ (α + βγ) + β 1 − γ 2 = αγ + β.                     (A-25)

Substituting α = φ − βγ derived above gives
                                                             (       )
                                         Corr (Y, Z) = φγ + β 1 − γ 2 .

      Since γ and φ are fixed, we only need to bound β to bound Corr (Y, Z). We will use (A-24),
which can be written as
                                                Z = φX + U + βV,

since φ = α + βγ. So taking the variance of both sides,

                                         1 = φ2 + Var (U ) + β 2 Var (V ) .

We have prviously seen that Var (V ) = 1 − γ 2 , and we know that Var (U ) ≥ 0. Thus,
                                                          √
                                                              1 − φ2
                                                  |β| ≤              .
                                                              1 − γ2

Substitiuting this inequality into (A-25) produces our result.46

      Proposition A-4 would produce sharp bounds for ρ (τ, τ + 1) if ρ (τ, τ ′ ) and ρ (τ + 1, τ ′ ), for
some τ ′ ∈
         / {τ, τ + 1}, were known with certainty (and at least one of these correlations is nonzero).
However, in practice, both ρ (τ, τ ′ ) and ρ (τ + 1, τ ′ ) will also be estimated with error. I therefore
create prior distributions that generally cover the entire support to create “prior distributions” of
 46
      I am grateful to Denis Chetverikov for showing me this result.



                                                          A-16
ρ (τ, τ + 1), given data between τ and τ ′ and between τ + 1 and τ ′ .
    These prior distributions and the subsequent Bayesian refinement process will be in a trans-
formed inverse hyperbolic tangent space, which conveniently transforms some correlation ρ ∈ [−1, 1]
to ρ̃ = tanh−1 ρ ∈ (−∞, ∞). I characterize estimates of ρ (τ, τ ′ ) and ρ (τ + 1, τ ′ ) as normal distribu-
tions in this transformed space. In particular, let ρ̂0.5 (τ, τ ′ ) denote the maximum-likelihood central
estimate, and let ρ̂0.025 (τ, τ ′ ) and ρ̂0.975 (τ, τ ′ ) denote the respective 95% lower and upper confi-
dence limits of ρ (τ, τ ′ ), as described in Appendix A-5.2. Then switching to a Bayesian framework,
I consider ρ̃ (τ, τ ′ ) as a normally distributed random variable with density:
                                                                (      (      ) (        ))
                                             fρ̃(τ,τ ′ ) (x) = ϕ x − µ̃ τ, τ ′ /σ̃ τ, τ ′ ,                              (A-26)

where ϕ (·) is the normal probability density function and
                                      (      )              (      )
                                    µ̃ τ, τ ′ = tanh−1 ρ̂0.5 τ, τ ′ ;
                                      (      )  tanh−1 ρ̂0.975 (τ, τ ′ ) − tanh−1 ρ̂0.025 (τ, τ ′ )
                                    σ̃ τ, τ ′ =                                                     .
                                                                    2 · 1.96

    Now consider the bounds on ρ (τ, τ + 1) implied by ρ (τ, τ ′ ) and ρ (τ + 1, τ ′ ) from Proposition
A-4. With some abuse of notation, define the lower and upper “bounds,” respectively, as
                                                                      √(                      )(                    )
               (                ′
                                    )        (  ) (          )
      ρ   LB
                   τ, τ + 1|τ           = ρ τ, τ ρ τ + 1, τ ′ −
                                                  ′
                                                                           1 − ρ (τ, τ ′ )2     1 − ρ (τ + 1, τ ′ )2 , and
                                                                      √(                      )(                    )
               (                ′
                                    )        (  ) (          )
      ρ   UB
                   τ, τ + 1|τ           = ρ τ, τ ρ τ + 1, τ ′ +
                                                  ′
                                                                           1 − ρ (τ, τ ′ )2     1 − ρ (τ + 1, τ ′ )2 .

Because both ρ (τ, τ ′ ) and ρ (τ + 1, τ ′ ) are estimated with error, I use the central estimates of
these correlations, ρ̂0.5 (τ, τ ′ ) and ρ̂0.5 (τ + 1, τ ′ ), to calculate ρ̂LB             ′        UB             ′
                                                                            0.5 (τ, τ + 1|τ ) and ρ̂0.5 (τ, τ + 1|τ ).
I then transform these to µ̃LB (τ, τ + 1|τ ′ ) and µ̃U B (τ, τ + 1|τ ′ ) via the inverse hyperbolic tan-
gent. In order to compute σ̃ LB (τ, τ + 1|τ ′ ) and σ̃ U B (τ, τ + 1|τ ′ ), I use the delta method, assuming
that Cov (ρ̂ (τ, τ ′ ) , ρ̂ (τ + 1, τ ′ )) = 0.47 I construct a “prior distribution” from the parameters of
                                                              (        )      ((        )     )
ρ̃LB (τ, τ + 1|τ ′ ) and ρ̃U B (τ, τ + 1|τ ′ ). Note that Pr ρ̃LB < x = Φ x − µ̃LB /σ̃ LB , where Φ (·)
is the normal cumulative distribution function, and where I have omitted the argument (τ, τ + 1|τ ′ )
                             (         )     ((       )       )
for simplicity. Similarly, Pr ρ̃U B > x = Φ x − µ̃U B /σ̃ U B . If ρ̃LB and ρ̃U B were known with
certainty (i.e., σ̃ LB = σ̃ U B = 0), then this prior distribution would have a very simple probability
density function:
                                                 
                                                 1, x ∈ [ρ̃LB (τ, τ + 1|τ ′ ) , ρ̃U B (τ, τ + 1|τ ′ )]
                          fρ̃(τ,τ +1|τ ′ ) (x) ∝                                                        .
                                                 0, otherwise

  47
     This covariance is unknown because I estimate ρ (τ, τ ′ ) and ρ (τ + 1, τ ′ ) separately. In order to estimate the
covariance, I would need to estimate them jointly, but of course in such a model, I would also estimate ρ (τ, τ + 1).
Therefore, bounds would not be necessary with such an approach. The main diﬃculty with this approach is compu-
tational feasibility.



                                                                 A-17
In the presence of uncertainty, I elaborate this density function to
                                                ((
                                               Φ x − µ̃LB ) /σ̃ LB ) ,   x ≤ xc
                        fρ̃(τ,τ +1|τ ′ ) (x) ∝       ((          )      )         ,                       (A-27)
                                               1 − Φ x − µ̃U B /σ̃ U B , x > x
                                                                                c

          (                         ) (              )
where xc = σ̃ LB µ̃U B + σ̃ U B µ̃LB / σ̃ LB + σ̃ U B is chosen to ensure that fρ̃(τ,τ +1|τ ′ ) (x) is contin-
uous.
    I am now at a point where I can state the posterior distribution, which I denote as fρ̃(τ,τ +1|T )
as a function of the maximum likelihood estimate in (A-26) and the prior distributions in (A-27):
                                                                     ∏
                        fρ̃(τ,τ +1|T ) (x) ∝ fρ̃(τ,τ +1) (x) ·                   fρ̃(τ,τ +1|τ ′ ) (x) .   (A-28)
                                                                 τ ′ ∈{τ,τ
                                                                     /     +1}


It can be shown that this function is log-concave. Thus, I am conveniently able to evaluate mo-
ments of the posterior distribution, including its mean and 95% credible interval using adaptive
rejection sampling (Gilks and Wild, 1992). I finally transform these moments back to the domain of
[−1, 1] with the hyperbolic tangent function in order to present them as estimates of the correlation
ρ (τ, τ + 1|T ).


A-7       Systematic Placebo Tests
I consider the statistical significance for convergence in the specialist services (i.e., cardiology and
oncology) relative to general medicine by performing the following thought experiment. If there is
no diﬀerence in true convergence between specialist and generalist services, then randomly assigning
actual months for each resident on either specialist or generalist services to a placebo specialist or
generalist service should result in similar convergence in these placebo services over time for a large
proportion of these placebo tests. On the other hand, if very few of these placebo tests result in
convergence similar to that observed in the actual specialist services, then this suggests statistical
significance.
    I implement these placebo tests as follows:

   1. Defining a service as either “specialist” or “generalist,” count the number of residents in a
        specialist service during each month t. Call this number Ntspec . The proportion of residents
        in cardiology, oncology, and general medicine during each month us shown in Figure A-6.

   2. For each resident-month-service block of observations in each month t, randomly choose Ntspec
        blocks and designate observations belonging to these blocks as pseudo-specialist service ob-
        servations.

   3. Using pseudo-specialist service observations, estimate the standard deviation in resident spend-
        ing distribution, as described in Appendix A-5, for each 60-day tenure period within two years
        of tenure and each 120-day tenure period in the third year.

                                                       A-18
  4. Estimate the rate of convergence by regressing σ̂ξ,τ on the midpoint in days tenure of a tenure
      period τ (e.g., the first 60-day tenure period has a midpoint of 30 days tenure), for tenure
      periods after intern year, weighting by the number of patient-days during each tenure period.
      The yearly rate of convergence is the coeﬃcient on days tenure multiplied by 365.

  5. Repeat for 10,000 times steps 2 to 4, collecting the yearly rate of convergence for each run.

The number of possible placebo tests in the procedure above is quite large. For example, con-
sider a representative month in which there are 30 resident-month blocks in the specialist service
(Ntspec = 30) out of a total of 55 resident-month-service blocks (Nt = 55). The number of random
combinations in that month alone, such that we assign exactly 30 resident-month-service blocks to
the pseudo-specialist service is

                                                       55!
                        Combinations for t =                     = 3.09 × 1015 .
                                                30! × (55 − 30)!

Performing this calculation for each of the 62 months in the data and multiplying together yields a
total number of combinations of 1.27 × 10970 .


A-8      Additional Results
In this appendix, I describe the following additional appendix tables and figures:

   • Figure A-1 shows numerical examples of variation profiles of the standard deviation of houses-
      taﬀ eﬀects over tenure, depending on the underlying learning function, in which the precision
      of subjective priors is parameterized as a piecewise linear of tenure, g (τ ), as discussed in
      Appendix A-4.

   • Figure A-2 shows distributions of age of patients assigned to high- and low-spending interns
      and residents.

   • Figure A-3 shows distributions of predicted spending (based on patient age, race, and sex)
      assigned to high- and low-spending interns and residents.

   • Figure A-4 shows distributions of attending spending eﬀects for attendings assigned to high-
      and low-spending interns and residents.

   • Figure A-5 shows the distribution of test costs across patient-days.

   • Figure A-6 describes the number of observations in terms of patient-days and residents on
      service for each service across months.

   • Figure A-7 shows variation in housestaﬀ eﬀects by tenure for two pseudo-services constructed
      from the general medicine service. These pseudo-services are constructed by Major Diagnostic
      Categories (MDCs), separating highly diagnosis-concentrated MDCs into one pseudo-service

                                                 A-19
  and leaving the remaining MDCs in the other. The purpose of this is to test the idea that
  convergence results from more concentrated services. Table A-6 describes summary statistics
  of both the actual services (cardiology, oncology, and general medicine), as well as these two
  pseudo-services.

• Figure A-8 shows variation in housestaﬀ eﬀects by tenure, dividing patients in each service by
  whether they have a primary ICD-9 code (administrative code for diagnosis) that is more or
  less common than the median observation in each service.

• Figure A-9 shows variation in housestaﬀ eﬀects by tenure, dividing patients in each service
  by whether there exists a published guideline for a patient’s primary ICD-9 code. Guidelines
  and their linkages to ICD-9 codes are collected from the national guideline repository at
  guidelines.gov.

• Table A-1 presents F -statistics testing for the joint significance housestaﬀ identities and hous-
  estaﬀ characteristics, as described by Equations (A-1) and (A-2) and in Appendix A-1.

• Table A-2 lists core rotations in the top 24 recognized internal residency programs, as a
  measure of the organization of medical care in academic hospitals.

• Table A-3 presents the number of core rotations in the universe of US internal medicine
  residencies, according to the American Council for Graduate Medical Education (ACGME).

• Table A-4 presents the number research papers in the last ten years in the New England
  Journal of Medicine, as a measure of major research activity in diﬀerent specialties.

• Table A-5 presents the amount of research funding by National Institutes of Health (NIH)
  Institute or Center,a s a measure of prioritized major research activity in diﬀerent specialties.

• Table A-6 presents summary statistics for patients admitted to the three ward services (car-
  diology, oncology, and general medicine), as well as the two pseudo-services constructed from
  general medicine. Numbers of admissions, MDCs, and ICD-9 coces are also presented, as well
  as the concentration of MDCs and ICD-9 codes within each service.

• Table A-7 lists the top 15 ICD-9 codes in each service, as well as whether there exists a
  guideline linked to that diagnostic code in the guidelines.gov national repository.




                                             A-20
                                        Figure A-1: Numerical Examples of Variation Profiles



                                                   A: k0 = .2, ki = .2, kj = .2                                              B: k0 = .2, ki = .2, kj = 0
                                          .5




                                                                                                                    .5
                     Std. dev. of effects




                                                                                               Std. dev. of effects
                                     .4




                                                                                                               .4
                               .3




                                                                                                         .3
                         .2




                                                                                                   .2
                   .1




                                                                                             .1
                                               0           1        2             3                                      0          1        2             3
                                                          Years tenure                                                             Years tenure


                                                    C: k0 = 5, ki = 5, kj = 1                                                D: k0 = .2, ki = 5, kj = 0
                                          .5




                                                                                                                    .5
                     Std. dev. of effects




                                                                                               Std. dev. of effects
                                     .4




                                                                                                               .4
                               .3




                                                                                                         .3
                         .2




                                                                                                   .2
                   .1




                                                                                             .1




                                               0           1        2             3                                      0          1        2             3
                                                          Years tenure                                                             Years tenure


                                                   E: k0 = .1, ki = 1, kj = 6                                                F: k0 = .1, ki = .2, kj = 1
                                          .5




                                                                                                                    .5
                     Std. dev. of effects




                                                                                               Std. dev. of effects
                                     .4




                                                                                                               .4
                               .3




                                                                                                         .3
                         .2




                                                                                                   .2
                   .1




                                                                                             .1




                                               0           1        2             3                                      0          1        2             3
                                                          Years tenure                                                             Years tenure




Note: This figure shows variation profiles of the expected standard deviation of housestaﬀ eﬀects over
tenure, σ (τ ), diﬀering by the underlying profile of learning over tenure. Learning is parameterized as a
piecewise linear function g (τ ) that describes how the precision of subjective priors increases over tenure. In
particular, this figure considers piecewise linear functions of the form (A-13), parameterized by k0 , ki , and
kj . Each panel considers a diﬀerent set of parameters of g (τ ). Given g (τ ), I calculate the expected standard
deviation of housestaﬀ eﬀects over tenure using Equation (A-11). I assume that interns are equally likely to
work with second-year residents and third-year residents. These profiles are discussed further in Appendix
A-4.




                                                                                      A-21
                    Figure A-2: Patients Age by Housesetaﬀ Spending Eﬀect



                                            A: Distribution by Intern Spending Effect
                              .025
                              .02
                        .01 .015
                         Density
                              .005
                              0




                                       20           40         60         80            100
                                                           Patient age

                                                   Above mean             Below mean



                                        B: Distribution by Resident Spending Effect
                              .02
                                .015
                        Density
                        .01   .005
                              0




                                       20           40         60         80            100
                                                           Patient age

                                                   Above mean             Below mean




Note: This figure shows the distribution of the age of patients assigned to interns with above- or below-
average spending eﬀects (Panel A) and residents with above- or below-average spending eﬀects (Panel B).
Housestaﬀ spending eﬀects, not conditioning by tenure, are estimated by Equation (A-3) as fixed eﬀects by
a regression of log test spending on patient characteristics and physician (intern, resident, and attending)
identities. Kolmogorov-Smirnov statistics testing for the diﬀerence in distributions yield p-values of 0.995
and 0.635 for interns (Panel A) and residents (Panel B), respectively.




                                                           A-22
        Figure A-3: Demographics-predicted Spending by Housestaﬀ Spending Eﬀect



                                          A: Distribution by Intern Spending Effect

                            20
                            15
                         Density
                           10
                            5
                            0




                                   5.7       5.8       5.9          6        6.1        6.2
                                                     Predicted test spending

                                                   Above mean              Below mean



                                         B: Distribution by Resident Spending Effect
                            20
                            15
                         Density
                           10
                            5
                            0




                                   5.7       5.8       5.9          6        6.1        6.2
                                                     Predicted test spending

                                                   Above mean              Below mean




Note: This figure shows the distribution of predicted test spending (based on patient age, race, and gender)
for patients assigned interns with above- or below-average spending eﬀects (Panel A) and residents with
above- or below-average spending eﬀects (Panel B). Housestaﬀ spending eﬀects, not conditioning by tenure,
are estimated by Equation (A-3) as fixed eﬀects by a regression of log test spending on patient characteristics
and physician (intern, resident, and attending) identities. Kolmogorov-Smirnov statistics testing for the
diﬀerence in distributions yield p-values of 0.892 and 0.447 for interns (Panel A) and residents (Panel B),
respectively.




                                                          A-23
           Figure A-4: Attendings Spending Eﬀects by Housestaﬀ Spending Eﬀect



                                        A: Distribution by Intern Spending Effect
                           2
                           1.5
                        Density
                          1.5
                           0




                                  -2         -1             0               1            2
                                                     Attending fixed effect

                                                  Above mean                Below mean



                                       B: Distribution by Resident Spending Effect
                           2
                           1.5
                        Density
                          1.5
                           0




                                  -2         -1             0               1            2
                                                     Attending fixed effect

                                                  Above mean                Below mean




Note: This figure shows the distribution of spending fixed eﬀects for attendings assigned to interns with
above- or below-average spending eﬀects (Panel A) and residents with above- or below-average spending
eﬀects (Panel B). Housestaﬀ and attending spending eﬀects, not conditioning by tenure, are estimated by
Equation (A-3) as fixed eﬀects by a regression of log test spending on patient characteristics and physi-
cian (intern, resident, and attending) identities. Kolmogorov-Smirnov statistics testing for the diﬀerence in
distributions yield p-values of 0.443 and 0.069 for interns (Panel A) and residents (Panel B), respectively.




                                                         A-24
                                    Figure A-5: Distribution of Daily Test Spending
                         .015
                         .01
               Density
                         .005
                         0




                                0             200            400          600           800
                                                          Test costs



Note: This figure shows the density daily test costs. The distribution is shown up to $800 per day.




                                                         A-25
             Figure A-6: Service Days and Residents on Ward Services over Time



                                  .5                    A: Patient-days
                        Percent service days
                             .3   .2  .4




                                      2005m6   2006m6   2007m6   2008m6    2009m6   2010m6
                                                             Month

                                                          MED             CAR
                                                                          ONC



                                                         B: Residents
                                  .6   .5
                        Percent residents
                          .3     .4
                                  .2




                                      2005m6   2006m6   2007m6   2008m6    2009m6   2010m6
                                                             Month

                                                          MED             CAR
                                                                          ONC




Note: This figure shows the percentage of patient-days (Panel A) and residents on service (Panel B) during
each month in the data for each service of general medicine, cardiology, and oncology. Residents may be
counted in more than one service if they spent time in more than one service in the same month.




                                                           A-26
                                    Figure A-7: Housestaﬀ-eﬀect Variation by Tenure in Pseudo-services



                                            A: MED1 (CAR, PULM, GI)                                                    B: MED2 (All Other)
                        .8




                                                                                                  .8
         Std. dev. (log dollar costs)




                                                                                   Std. dev. (log dollar costs)
                                .6




                                                                                                          .6
                      .4




                                                                                                .4
           .2




                                                                                     .2
                        0




                                                                                                  0




                                        0    200   400   600   800   1000                                         0   200   400   600   800   1000
                                                   Days tenure                                                              Days tenure




Note: This figure shows the standard deviation of test-spending eﬀects over housestaﬀ tenure in two pseudo-
services formed from general medicine admissions. These pseudo-services are meant to create a diﬀerence
in diagnostic concentration. MED1 includes the most common Major Diagnostic Categories (MDCs) of
“Circulatory System” (MDC 5), “Respiratory System” (MDC 4), and “Digestive System” (MDC 6), roughly
equivalent to cardiology, pulmonology, and gastroenterology; MED2 includes all other MDCs. Summary
statistics for these two pseudo-services are given in Table A-6. The random eﬀects model is still Equation
(2), estimated at non-overlapping two-month tenure intervals. 95% confidence intervals are omitted for
simplicity. Controls are the same as those listed in the caption for Figure 3. Housestaﬀ prior to one year in
tenure are interns and become residents after one year in tenure; a vertical line denotes the one-year tenure
mark.




                                                                            A-27
                                                          Figure A-8: Housestaﬀ-eﬀect Variation in Each Service by ICD-9 Code Frequency



                                                             Cardiology                                                 Oncology                                               General Medicine




                                      .8
                                                                                                 .8
                                                                                                                                                           .8




                                             .6
                                                                                                        .6
                                                                                                                                                                  .6




                                    .4
                                                                                               .4
                                                                                                                                                         .4




A-28
                          .2
                                                                                     .2
                                                                                                                                               .2




                       Std. dev. (log dollar costs)
                                                                                  Std. dev. (log dollar costs)
                                                                                                                                            Std. dev. (log dollar costs)




                                      0
                                                                                                 0
                                                                                                                                                           0




                                                      0   200 400 600 800 1000                                   0   200 400 600 800 1000                                  0   200 400 600 800 1000
                                                             Days tenure                                                Days tenure                                               Days tenure




       Note: This figure shows the standard deviation in a random eﬀects model, as in Equation (2), of log daily test costs at each non-overlapping tenure
       interval but for each service and for relatively common (within service) ICD-9 diagnostic codes (solid dots) and uncommon diagnoses (hollow dots).
       Controls are the same as those listed in the caption for Figure 3. Housestaﬀ prior to one year in tenure are interns and become residents after one
       year in tenure; vertical lines denote the one-year tenure mark.
                                                              Figure A-9: Housestaﬀ-eﬀect Variation in Each Service by Guideline Existence



                                                                 Cardiology                                                    Oncology                                                  General Medicine




                                                     .8
                                                                                                                   .8
                                                                                                                                                                                .8




                                             .6
                                                                                                           .6
                                                                                                                                                                        .6




                                    .4
                                                                                                  .4
                                                                                                                                                               .4




A-29
                           .2
                                                                                         .2
                                                                                                                                                      .2




                        Std. dev. (log dollar costs)
                                                                                      Std. dev. (log dollar costs)
                                                                                                                                                   Std. dev. (log dollar costs)




                                        0
                                                                                                      0
                                                                                                                                                                   0




                                                          0   200 400 600 800 1000                                      0   200 400 600 800 1000                                     0   200 400 600 800 1000
                                                                 Days tenure                                                   Days tenure                                                  Days tenure




       Note: This figure shows the standard deviation in a random eﬀects model, as in Equation (2), of log daily test costs at each non-overlapping tenure
       interval but for each service and for diagnoses with (solid dots) and without (hollow dots) published guidelines. Controls are the same as those listed
       in the caption for Figure 3. Housestaﬀ prior to one year in tenure are interns and become residents after one year in tenure; vertical lines denote the
       one-year tenure mark.
                                   Table A-1: Tests of Joint Significance of Housestaﬀ Identities and Characteristics


                                                                                    Independent variables
                                                Housestaﬀ identities                          Housestaﬀ characteristics
                   Patient characteristic                (1)                              (2)                              (3)
                                               F (1055, 46364) = 0.98            F (20, 16069) = 0.68            F (18, 37494) = 0.79
                             Age
                                                     p = 0.655                         p = 0.848                        p = 0.711
                                               F (1055, 46364) = 1.01            F (20, 16069) = 1.18                F (18, 37494) = 1.26
                             Male
                                                     p = 0.389                        p = 0.256                           p = 0.201
                                               F (1055, 46364) = 1.02            F (20, 16069) = 0.79                F (18, 37494) = 0.92
                            White




A-30
                                                     p = 0.356                        p = 0.734                           p = 0.558
                                               F (1055, 46364) = 0.98            F (20, 16069) = 0.79                F (18, 37494) = 1.08
                     Predicted spending
                                                     p = 0.685                        p = 0.731                           p = 0.368
       Note: This table reports tests of joint significance corresponding to Equations (A-1) and (A-2). Column (1) corresponds to Equation (A-1); columns
       (2) and (3) correspond to (A-2). Column (2) includes all housestaﬀ characteristics: housestaﬀ’s position on the rank list; USMLE Step 1 score; sex;
       age at the start of training; and dummies for whether the housestaﬀ graduated from a foreign medical school, whether he graduated from a rare
       medical school, whether he graduated from medical school as a member of the AOA honor society, whether he has a PhD or another graduate degree,
       and whether he is a racial minority. Column (3) includes all housestaﬀ characteristics except for position on the rank list. Rows correspond to diﬀerent
       patient characteristics as the dependent variable of the regression equation; the last row is predicted test spending using patient demographics (age,
       sex, and race). F -statistics and p-values are reported for each joint test.
                                   Table A-2: Core Rotations for Most Recognized Internal Medicine Residencies


                                                                                                Ward rotations
               Residency program                              MED        CAR         ONC        GI      PULM         RENAL          ID      RHEUM
               Massachusetts General Hospital                  3
               Johns Hopkins University                        3           3           3
               Brigham and Women’s Hospital                    3           3           3
               University of California, San Francisco         3           3                      3
               Mayo Clinic                                     3           3           3          3          3           3          3
               Duke University Hospital                        3           3           3                     3
               Washington University                           3           3           3
               University of Pennsylvania                      3           3           3
               New York Presbyterian (Columbia)                3           3           3                                            3
               Northwestern University                         3           3           3          3
               University of Michigan                          3           3           3          3          3
               University of Washington                        3           3           3
               University of Texas Southwestern                3           3
               Cleveland Clinic                                3           3           3          3                      3




A-31
               Mount Sinai Hospital                            3
               Stanford University                             3           3           3
               Vanderbilt University                           3           3           3
               New York Presbyterian (Cornell)                 3           3           3                                                        3
               University of Chicago                           3           3           3
               Emory University                                3           3
               UCLA Medical Center                             3           3          3
               Beth Israel Deaconess Medical Center            3           3          3
               Yale-New Haven Medical Center                   3           3          3           3                      3          3
               New York University                             3           3          3
               Total Counts (out of 24)                        24          22         19          6           3          3           3          1

       Note: This table shows core ward organ-based medical rotations for the 24 highly recognized internal medicine residency programs reported by
       US News & World Report, ordered by nominations in a survey of internists and residency program directors. The identities of core rotations were
       obtained by browsing each residency program’s website. Abbreviations: general medicine (MED), cardiology (CAR), hematology/oncology (ONC),
       gastroenterology (including liver) (GI), pulmonary (PULM), nephrology (RENAL), infectious disease (ID), and rheumatology (RHEUM). I exclude
       rotations in palliative care and geriatrics, as these are not traditional organ-based subspecialties, and in neurology, as it is a specialty outside of
       internal medicine. Total counts are shown in the last row.
           Table A-3: Core Rotations in Universe of Internal Medicine Residencies


                  Ward Rotations                                         Program count
                  General Medicine (MED)                                      310
                  Cardiology (CAR)                                            131
                  Hematology / Oncology (ONC)                                  85
                  Nephrology (RENAL)                                           34
                  Gastroenterology, including Hepatology (GI)                  28
                  Pulmonology (PULM)                                           27
                  Infectious Disease (ID)                                      22
                  Rheumatology (RHEUM)                                          7
                  Endocrinology (ENDO)                                          3

Note: This table shows core ward medical rotations in the universe of internal medicine residency programs
accredited by the American Council for Graduate Medical Education (ACGME), accessed at www.acgme.org.
Of the 345 programs listed in the website, 310 programs had curricula detailing core ward rotations. Core
ward rotations are defined as required rotations on ward services.




        Table A-4: New England Journal of Medicine Research Articles by Specialty


                 Specialty / subspecialty         Internal medicine         Article count
                 Hematology / Oncology                    Y                      596
                 Cardiology                               Y                      562
                 Genetics                                 N                      476
                 Infectious Disease                       Y                      453
                 Pulmonary / Critical Care                Y                      329
                 Pediatrics                               N                      285
                 Endocrinology                            Y                      283
                 Gastroenterology                         Y                      257
                 Neurology / Neurosurgery                 N                      245
                 Surgery                                  N                      228
                 Primary Care / Hospitalist               Y                      179
                 Nephrology                               Y                      158

Note: This table reports the number of research papers appearing in the last ten years in the New England
Journal of Medicine, by specialty or subspecialty as categorized by the journal. Specialties or subspecialties
are also categorized as being within internal medicine or not. A training path in clinical genetics is possible
from internal medicine, but genetics can also be pursued from pediatrics, obstetrics-gynecology, and other
specialties. The New England Journal of Medicine has the highest impact factor, 51.7, out of all medical
journals; only five other medical journals have double-digit impact factors, with the second-highest of 39.1
belonging to the Lancet, and the third-highest of 30.0 belonging to the Journal of the American Medical
Association. Articles counted as research papers are “scientific reports of the results of original clinical
research.” Other categories, as defined at http://www.nejm.org/page/author-center/article-types, include
reviews, clinical cases, perspective, commentary, and other.



                                                    A-32
 Table A-5: Research Funding by National Institutes of Health (NIH) Institute or Center


                                                                         Grants       Funding
              NIH Institute or Center
                                                                          open       (millions)
              National Cancer Institute (NCI)                            9,872         $6,670
              National Institute of Allergy and Infectious
                                                                         7,271         $5,433
              Diseases (NIAID)
              National Heart, Lung, and Blood Institute
                                                                         6,294         $3,591
              (NHLBI)
              National Institute of General Medical Sciences
                                                                         6,268         $2,614
              (NIGMS)
              National Institute of Diabetes and Digestive
                                                                         4,971         $2,397
              And Kidney Diseases (NIDDK)
              Eunice Kennedy Shriver National Institute of
                                                                         3,295         $1,814
              Child Health & Human Development (NICHD)
              National Institute of Neurological Disorders
                                                                         4,639         $1,753
              And Stroke (NINDS)
              National Institute of Mental Health (NIMH)                 3,650         $1,500
              National Institute on Drug Abuse (NIDA)                    2,809         $1,229
              National Institute on Aging (NIA)                          2,749         $1,220
              National Institute of Environmental Health
                                                                         1,504         $1,091
              Sciences (NIEHS)
              Oﬃce of the Director (OD)                                   820           $756
              National Eye Institute (NEI)                               1,798          $733
              National Human Genome Research Institute
                                                                          623           $627
              (NHGRI)
              13 Other Institutes and Centers                            8,564         $4,259

Note: This table lists the top fourteen Institutes and Centers of the National Institutes of Health (NIH),
ordered by current funding as defined by funds to currently open grants. Grants open and current funding
(in millions of dollars) are both listed. For brevity, the thirteen other Institutes and Centers are not listed
individually but are aggregated in the last line.




                                                    A-33
                                                     Table A-6: Ward Service Summary Statistics


                                                                        Actual services                      Pseudo-services
                                                               CAR          ONC            MED              MED1        MED2
                        Mean admission characteristics
                          Patient age                         63.71          59.25          62.79            64.76         60.67
                          DRG weight                          2.44            2.24           1.69             1.64          1.75
                          Test costs                         $613.61        $855.38        $687.18          $634.70       $743.75
                          All costs                         $9,703.80      $7,544.00      $5,303.48        $5,071.63     $5,553.42
                          Length of stay (days)               3.89            4.69           3.66             3.47          3.87
                          30-day readmission                  0.089          0.218          0.090            0.089         0.091
                          30-day mortality                    0.031          0.175          0.034            0.032         0.036
                        Observations




A-34
                          Admission count                     12,485        22,711         12,989           11,784         10,927
                          MDC count                             23            24             23               3              21
                          ICD-9 count                          440           1101           623              602            897
                        Concentration
                          MDC HHI                              0.740         0.117          0.103            0.347          0.101
                          ICD-9 HHI                            0.055         0.019          0.025            0.038          0.013

       Note: This table shows summary statistics for actual services – cardiology (CAR), oncology (ONC), and general medicine (MED) – and for “pseudo-
       services” formed based on Major Diagnostic Categories (MDC) from the general medicine service. The pseudo-service MED1 includes “Circulatory
       System” (MDC 5), “Respiratory System” (MDC 4), and “Digestive System” (MDC 6); MED2 includes all other MDCs. Summary statistics include
       mean admission characteristics (patient age, DRG weight) and outcomes (costs, length of stay, readmission, and mortality), counts (Numbers of
       admissions, MDCs, and ICD-9 codes), and Herfindahl-Hirschman Indices (HHI).
                                                      Table A-7: Top Diagnostic Codes by Service


                        Cardiology                                           Oncology                                     General Medicine
         ICD-9      Description                             ICD-9      Description                            ICD-9      Description
                                                                       Malignant neoplasm of
         786.50     Chest pain NOS                          162.9                                             786.50     Chest pain NOS
                                                                       bronchus/lung NOS
                                                                       Other lymphoma unspecified
          428.0     Congestive heart failure NOS            202.80                                             780.2     Syncope and collapse
                                                                       site
                    Acute myocardial infarction                        Malignant neoplasm of breast
         410.90                                             174.9                                               486      Pneumonia, organism NOS
                    NOS                                                NOS
                    Chronic ischemic heart disease                     Malignant neoplasm of soft                        Gastrointestinal hemorrhage
          414.9                                             171.9                                              578.9
                    NOS                                                tissue NOS                                        NOS
                    Intermediate coronary                              Multiple myeloma without
          411.1                                            203.00                                             786.09     Respiratory abnormality NEC
                    syndrome                                           remission
                                                                                                                         Abdominal pain unspecified
         427.31     Atrial fibrillation                     780.6      Fever                                  789.00
                                                                                                                         site
                    Paroxysmal ventricular
          427.1                                             183.0      Malignant neoplasm of ovary             428.0     Congestive heart failure NOS
                    tachycardia
                                                                       Malignant neoplasm of colon                       Acute myocardial infarction
          428.9     Heart failure NOS                       153.9                                             410.90




A-35
                                                                       NOS                                               NOS
          780.2     Syncope and collapse                   276.51      Dehydration                             577.0     Acute pancreatitis
                                                                       Acute myeloid leukemia                            Chronic airway obstruction
          425.4     Primary cardiomyopathy NEC              205.00                                              496
                                                                       without remission                                 NEC
                                                                       Malignant neoplasm of
         786.09     Respiratory abnormality NEC             157.9                                             276.51     Dehydration
                                                                       pancreas NOS
                                                                                                                         Nonpsychotic mental disorder
         427.89     Cardiac dysrhythmias NEC                 486       Pneumonia, organism NOS                 300.9
                                                                                                                         NOS
                    Malfunctioning cardiac                             Malignant neoplasm of
         996.00                                              185                                               682.9     Cellulitis NOS
                    device/graft NOS                                   prostate
                                                                       Abdominal pain unspecified
         427.32     Atrial flutter                         789.00                                              599.0     Urinary tract infection NOS
                                                                       site
                                                                       Malignant neoplasm of
          413.9     Angina pectoris NEC/NOS                 150.9                                              285.9     Anemia NOS
                                                                       esophagus NOS


       Note: This table lists the top 15 primary admission diagnoses, by ICD-9 codes, in order of descending frequency, for each of the ward services of
       cardiology, oncology, and general medicine. Italicized ICD-9 codes denote codes that are linked to guidelines on guidelines.gov. “NOS” = “Not
       Otherwise Specified”; “NEC” = “Not Elsewhere Classified.”
