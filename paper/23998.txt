                             NBER WORKING PAPER SERIES




        A NOTE ON VARIANCE DECOMPOSITION WITH LOCAL PROJECTIONS

                                    Yuriy Gorodnichenko
                                      Byoungchan Lee

                                     Working Paper 23998
                             http://www.nber.org/papers/w23998


                    NATIONAL BUREAU OF ECONOMIC RESEARCH
                             1050 Massachusetts Avenue
                               Cambridge, MA 02138
                                  November 2017




We thank Oscar Jorda and Mikkel Plagborg-Møller for comments on an earlier version of the
paper. The views expressed herein are those of the authors and do not necessarily reflect the
views of the National Bureau of Economic Research.˛

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2017 by Yuriy Gorodnichenko and Byoungchan Lee. All rights reserved. Short sections of text,
not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including © notice, is given to the source.
A Note on Variance Decomposition with Local Projections
Yuriy Gorodnichenko and Byoungchan Lee
NBER Working Paper No. 23998
November 2017
JEL No. C53,E37,E47

                                       ABSTRACT

We propose and study properties of several estimators of variance decomposition in the local-
projections framework. We find for empirically relevant sample sizes that, after being bias
corrected with bootstrap, our estimators perform well in simulations. We also illustrate the
workings of our estimators empirically for monetary policy and productivity shocks.


Yuriy Gorodnichenko
Department of Economics
530 Evans Hall #3880
University of California, Berkeley
Berkeley, CA 94720-3880
and IZA
and also NBER
ygorodni@econ.berkeley.edu

Byoungchan Lee
University of California, Berkeley
Department of Economics
Berkeley, CA
bc1105@berkeley.edu
    I. Introduction
Macroeconomists have been long interested in estimating dynamic responses of output, inflation and
other aggregates to structural shocks. While many analyses use vector autoregressions (VARs) or
dynamic stochastic general equilibrium (DSGE) models to construct estimated responses, an
increasing number of researchers focus on a single structural shock and employ single-equation
methods to study the dynamic responses. This approach allows concentrating on well-identified
shocks and leaving other sources of variation unspecified. In addition, these approaches often impose
no restrictions on the shape of the impulse response function. As a result, the local projections method
(Jordà 2005, Stock and Watson 2007) has gained prominence in applied macroeconomic research.
        The properties of impulse responses estimated with these methods are well studied (see
e.g. Coibion 2012) but little is known about how one can estimate quantitative significance of
shocks in the single-equation framework. Specifically, the vast majority of studies using single-
equation approaches do not report variance decomposition for the variable of interest and hence
one does not know if a given shock accounts for a large share of variation for the variable. 1 This
practice contrasts sharply with the nearly universal convention to report variance decompositions
in VARs and DSGE models. In this paper, we propose several methods to construct variance
decomposition in the local projection framework.
        We show that local projections lead to a simple and intuitive way to assess the contribution
of identified shocks to variation at different horizons. However, there are several options to
implement this insight. While the details of implementation do not matter in large samples, we
observe heterogeneity in the performance of various options in small, empirically relevant samples.
To illustrate the properties of various methods, we use several data generating processes which cover
main profiles of variance decompositions documented in previous works. We show that estimated
contributions to variation may be biased in small samples and one should use bootstrap to correct
for possible biases in the local projections’ estimates of variation decompositions. We also
demonstrate how our method works in settings with multiple identified shocks. We illustrate the
performance of our method using actual data and commonly used identified shocks as well as data
simulated according to the Smets and Wouters (2007) DSGE model. Our work is concurrent and



1
 Coibion et al. (2017) is among the very few papers reporting variance decomposition in the local projection method.
More precisely, if we use definitions of Plagborg-Møller and Wolf (2017), the object of our analysis is forecast
variance ratio.

                                                                                                                  1
complementary to Plagborg-Møller and Wolf (2017) who provide set-identified variance
decompositions in the local projections framework.
          The rest of the paper is structured as follows. Section II lays out a basic setting to derive
the estimators. Section III presents simulation results for bivariate and multivariate settings.
Section IV provide an application of our estimators to estimate the contribution of monetary policy
and productivity shocks to variation of output and inflation in the local projections framework.
Section V concludes.

    II. Basics of variance decomposition
Consider a generic setup encountered in studies using local projections. Let 𝑦𝑦𝑡𝑡 be an endogenous
variable of interest. We assume that variation in 𝑦𝑦𝑡𝑡 has two components: an identified white-noise
shocks series 𝑥𝑥𝑡𝑡 with mean zero and variance 𝜎𝜎𝑥𝑥2 and the “rest” captured by series 𝑧𝑧𝑡𝑡 so that
          𝑦𝑦𝑡𝑡 = ∑∞
                  𝑖𝑖=0 𝜓𝜓𝑥𝑥,𝑖𝑖 𝑥𝑥𝑡𝑡−𝑖𝑖 + 𝑧𝑧𝑡𝑡 = 𝜓𝜓𝑥𝑥 (𝐿𝐿)𝑥𝑥𝑡𝑡 + 𝑧𝑧𝑡𝑡 .                                                   (1)
We are interested in estimating coefficients in the lag polynomial 𝜓𝜓𝑥𝑥 (𝐿𝐿) which provides us with the
impulse response function of variable 𝑦𝑦𝑡𝑡 to shock 𝑥𝑥𝑡𝑡 . We make only a few assumptions about
properties of 𝑥𝑥𝑡𝑡 and 𝑧𝑧𝑡𝑡 . Specifically, we assume that 𝑧𝑧𝑡𝑡 admits an integrated 𝑀𝑀𝑀𝑀(∞) representation,
          Δ𝑧𝑧𝑡𝑡 = 𝑔𝑔𝑦𝑦 + 𝜓𝜓𝑒𝑒 (𝐿𝐿)𝑒𝑒𝑡𝑡                                                                                  (2)
where 𝑒𝑒𝑡𝑡 is a zero-mean white noise series with variance 𝜎𝜎𝑒𝑒2 . Following the conventions of local
projection applications, we assume that 𝑥𝑥𝑡𝑡 and 𝑒𝑒𝑡𝑡 are uncorrelated and that ∑∞      2
                                                                                 𝑖𝑖=0 𝜓𝜓𝑥𝑥,𝑖𝑖 < ∞ and

∑∞      2
 𝑖𝑖=0 𝜓𝜓𝑒𝑒,𝑖𝑖 < ∞ . Without loss of generality we set 𝜓𝜓𝑒𝑒,0 = 1 . We assume that {(𝑥𝑥𝑡𝑡 , Δ𝑦𝑦𝑡𝑡 ): 𝑡𝑡 =

1, … , 𝑇𝑇 } is observable.
          Forecast error for h-period ahead value of the endogenous variable is given by
          𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 ≡ 𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡+ℎ|𝑡𝑡−1 = (𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 ) − 𝐸𝐸[𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 |Ω𝑡𝑡−1 ]
where 𝑦𝑦𝑡𝑡+ℎ|𝑡𝑡−1 ≡ 𝐸𝐸[𝑦𝑦𝑡𝑡+ℎ |Ω𝑡𝑡−1 ] is the prediction of 𝑦𝑦𝑡𝑡+ℎ given information set Ω𝑡𝑡−1 ≡
{Δ𝑦𝑦𝑡𝑡−1 , 𝑥𝑥𝑡𝑡−1 , Δ𝑦𝑦𝑡𝑡−2 , 𝑥𝑥𝑡𝑡−2 , … }. We can decompose forecast error due to innovations in 𝑥𝑥𝑡𝑡 and other
sources of variation as follows 2
          𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 = 𝜓𝜓𝑥𝑥,0 𝑥𝑥𝑡𝑡+ℎ + ⋯ + 𝜓𝜓𝑥𝑥,ℎ 𝑥𝑥𝑡𝑡 + 𝑣𝑣𝑡𝑡+ℎ|𝑡𝑡−1 .                                                       (3)


2
  If 𝜓𝜓𝑒𝑒 (𝐿𝐿) is invertible, 𝑣𝑣𝑡𝑡+ℎ|𝑡𝑡−1 is equal to 𝜓𝜓𝑒𝑒,0 𝑒𝑒𝑡𝑡+ℎ + ⋯ + �𝜓𝜓𝑒𝑒,0 + ⋯ + 𝜓𝜓𝑒𝑒,ℎ �𝑒𝑒𝑡𝑡 . This representation in 𝑒𝑒𝑡𝑡 ’s is
obtained, because 𝑒𝑒𝑡𝑡 ∈ Ω𝑡𝑡 . See Appendix A for details. Note that we do not need invertibility of 𝜓𝜓𝑒𝑒 (𝐿𝐿) to construct
the contribution of 𝑥𝑥𝑡𝑡 to variability in 𝑦𝑦𝑡𝑡 . Intuitively, we only need an estimate of either 𝑉𝑉𝑉𝑉𝑉𝑉�𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 � in equations
(4) and (4’), or 𝑉𝑉𝑉𝑉𝑉𝑉�𝑣𝑣𝑡𝑡+ℎ|𝑡𝑡−1 � in equation (4’’) which does not require us separating 𝜓𝜓𝑒𝑒 (𝐿𝐿) and 𝑒𝑒𝑡𝑡 .

                                                                                                                                      2
Following Sims (1980), we can define the population share of variance explained by the future
innovations in 𝑥𝑥𝑡𝑡 to the total variations in 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 :
                𝑉𝑉𝑉𝑉𝑉𝑉�𝜓𝜓𝑥𝑥,0 𝑥𝑥𝑡𝑡+ℎ + ⋯ + 𝜓𝜓𝑥𝑥,ℎ 𝑥𝑥𝑡𝑡 �
        𝑠𝑠ℎ =                                                                                       (4)
                         𝑉𝑉𝑉𝑉𝑉𝑉�𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 �
                  ℎ      2
                �∑𝑖𝑖=0 𝜓𝜓𝑥𝑥,𝑖𝑖 �𝜎𝜎𝑥𝑥2
            =                                                                                       (4′)
                𝑉𝑉𝑉𝑉𝑉𝑉�𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 �
                            �∑ℎ𝑖𝑖=0 𝜓𝜓𝑥𝑥,𝑖𝑖
                                      2
                                            �𝜎𝜎𝑥𝑥2
            =                                                     .                                  (4′′ )
                �∑ℎ𝑖𝑖=0 𝜓𝜓𝑥𝑥,𝑖𝑖
                          2
                                �𝜎𝜎𝑥𝑥2   + 𝑉𝑉𝑉𝑉𝑉𝑉�𝑣𝑣𝑡𝑡+ℎ|𝑡𝑡−1 �
Equation (4) demonstrates that we have several options for estimating 𝑠𝑠ℎ and these options vary
in their reliance on imposing parametric structure. In what follows, we propose and evaluate
several methods to estimate 𝑠𝑠ℎ .

 A. 𝑅𝑅2 method
Let 𝑋𝑋𝑡𝑡ℎ = (𝑥𝑥𝑡𝑡+ℎ , … , 𝑥𝑥𝑡𝑡 )′. It can be shown with some algebra that equation (4) can be written as
                                                            −1
              𝐶𝐶𝐶𝐶𝐶𝐶�𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 , 𝑋𝑋𝑡𝑡ℎ ��𝑉𝑉𝑉𝑉𝑉𝑉�𝑋𝑋𝑡𝑡ℎ �� 𝐶𝐶𝐶𝐶𝐶𝐶(𝑋𝑋𝑡𝑡ℎ , 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 )
        𝑠𝑠ℎ =                                                                           .                 (5)
                                         𝑉𝑉𝑉𝑉𝑉𝑉(𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 )
This quantity can be understood as an 𝑅𝑅2 of the population projection of 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 on 𝑋𝑋𝑡𝑡ℎ , or
probability limit of sample 𝑅𝑅2 . This observation suggests a natural estimator for 𝑠𝑠ℎ . First, the
forecast errors for each horizon ℎ are estimated using local projections. Second, forecast error for
horizon ℎ at time 𝑡𝑡 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 is regressed on shocks 𝑥𝑥 that happen between 𝑡𝑡 and 𝑡𝑡 + ℎ. The 𝑅𝑅2 in
this regression is an estimate of 𝑠𝑠ℎ .
        More precisely, the estimated forecast error 𝑓𝑓̂𝑡𝑡+ℎ|𝑡𝑡−1 is the residual of the following
regression:
                                     𝐿𝐿𝑦𝑦                  𝐿𝐿𝑥𝑥

      𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 = 𝑐𝑐ℎ +       � 𝛾𝛾𝑖𝑖ℎ    Δ𝑦𝑦𝑡𝑡−𝑖𝑖 + � 𝛽𝛽𝑖𝑖ℎ 𝑥𝑥𝑡𝑡−𝑖𝑖 + 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 ,           (6)
                                    𝑖𝑖=1                   𝑖𝑖=1
                                                                                    ℎ
which is an approximation to 𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 = 𝑐𝑐ℎ + ∑∞                     ∞
                                                      𝑖𝑖=1 𝛾𝛾𝑖𝑖 Δ𝑦𝑦𝑡𝑡−𝑖𝑖 + ∑𝑖𝑖=1 𝛽𝛽𝑖𝑖 𝑥𝑥𝑡𝑡−𝑖𝑖 + 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 in

population. Then we run the following regression and calculate its 𝑅𝑅2 :
        𝑓𝑓̂𝑡𝑡+ℎ|𝑡𝑡−1 = 𝛼𝛼𝑥𝑥,0 𝑥𝑥𝑡𝑡+ℎ + ⋯ + 𝛼𝛼𝑥𝑥,ℎ 𝑥𝑥𝑡𝑡 + 𝑣𝑣�𝑡𝑡+ℎ|𝑡𝑡−1 .                            (7)
Thus, our first estimator is 𝑠𝑠̂ℎ𝑅𝑅2 = 𝑅𝑅2 which, by construction, is between 0 and 1. Note that 𝛼𝛼𝑥𝑥,𝑖𝑖 in
equation (7) corresponds to 𝜓𝜓𝑥𝑥,𝑖𝑖 in equation (1). Because 𝑓𝑓̂𝑡𝑡+ℎ|𝑡𝑡−1 in equation (7) is a residual of
an OLS regression with the intercept in equation (6) and 𝑥𝑥𝑡𝑡 is assumed to be zero mean, an
                                                                                                                3
intercept term in equation (7) is not required. Moreover, the population mean of both 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 and
𝑋𝑋𝑡𝑡ℎ are zeros, so both centered and non-centered 𝑅𝑅2 ’s are the same in population. We report results
for the non-centered 𝑅𝑅2 , but properties are similar when we use the centered 𝑅𝑅2 . The following
proposition derives the asymptotic distribution of the estimator.


                                                                                                                   ′
Proposition        1.     Suppose            𝑓𝑓ℎ = �𝑓𝑓𝑇𝑇|𝑇𝑇−ℎ−1 , 𝑓𝑓𝑇𝑇−1|𝑇𝑇−ℎ−2 , … , 𝑓𝑓𝐿𝐿𝑚𝑚𝑚𝑚𝑚𝑚+ℎ+1 |𝐿𝐿𝑚𝑚𝑚𝑚𝑚𝑚 �       and   𝑋𝑋ℎ =
   ℎ        ℎ                    ′
�𝑋𝑋𝑇𝑇−ℎ , 𝑋𝑋𝑇𝑇−1 , … , 𝑋𝑋𝐿𝐿ℎ𝑚𝑚𝑚𝑚𝑚𝑚+1 � for all ℎ ≥ 0 where 𝐿𝐿𝑚𝑚𝑚𝑚𝑚𝑚 = max�𝐿𝐿𝑥𝑥 , 𝐿𝐿𝑦𝑦 � . Then the 𝑅𝑅2 of the
regression of 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 on 𝑋𝑋𝑡𝑡ℎ , given by �𝑓𝑓ℎ′ 𝑃𝑃𝑋𝑋ℎ 𝑓𝑓ℎ �/(𝑓𝑓ℎ′ 𝑓𝑓ℎ ) where 𝑃𝑃𝑋𝑋ℎ = 𝑋𝑋ℎ (𝑋𝑋ℎ′ 𝑋𝑋ℎ )−1 𝑋𝑋ℎ′ , has the
following asymptotic distribution for some 𝑉𝑉ℎ,𝑅𝑅2 :

                                              𝑓𝑓ℎ′ 𝑃𝑃𝑋𝑋ℎ 𝑓𝑓ℎ         𝑑𝑑
                                     √𝑇𝑇 �           ′       − 𝑠𝑠ℎ � → 𝒩𝒩�0,        𝑉𝑉ℎ,𝑅𝑅2 �.
                                                 𝑓𝑓ℎ 𝑓𝑓ℎ

Proof. See Appendix B1.

In practice, we may plug the estimated forecast errors from equation (6) in the place of 𝑓𝑓ℎ .
Appendix B1 contains details of implementation. Note that, instead of using shocks 𝑥𝑥𝑡𝑡 , … , 𝑥𝑥𝑡𝑡+ℎ in
equation (7), one may want to use residuals from projecting 𝑥𝑥𝑡𝑡 , … , 𝑥𝑥𝑡𝑡+ℎ on lags of 𝑥𝑥𝑡𝑡 and Δ𝑦𝑦𝑡𝑡 from
equation (6) to guarantee that one does not use forecastable movements in 𝑥𝑥𝑡𝑡 , … , 𝑥𝑥𝑡𝑡+ℎ to account
for variation in 𝑓𝑓̂𝑡𝑡+ℎ|𝑡𝑡−1 . In practice, however, shocks 𝑥𝑥𝑡𝑡 are constructed in ways to ensure that 𝑥𝑥𝑡𝑡
is not predictable by lags of macroeconomic variables. As a result, we find in our simulations and
applications that purifying structural shocks make little difference. Relatedly, one may implement
this estimator by augmenting equation (6) with shocks 𝑥𝑥𝑡𝑡 , … , 𝑥𝑥𝑡𝑡+ℎ and calculating partial R2. This
insight also justifies using 𝑓𝑓̂𝑡𝑡+ℎ|𝑡𝑡−1 instead of 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 in Proposition 1.

 B. Local projection based methods
The 𝑅𝑅2 approach requires estimation of two regressions for each horizon (first, construct forecast
errors; second, compute the contribution of shocks 𝑥𝑥 between 𝑡𝑡 and 𝑡𝑡 + ℎ). However, one can
estimate variance decomposition from the local projection directly. Following Jordà (2005), we
can estimate 𝜓𝜓𝑥𝑥,ℎ from the following equation:
                                      𝐿𝐿𝑦𝑦                        𝐿𝐿𝑥𝑥

         𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 = 𝑐𝑐ℎLP + � 𝛾𝛾𝑖𝑖ℎ,𝐿𝐿𝐿𝐿 Δ𝑦𝑦𝑡𝑡−𝑖𝑖 + � 𝛽𝛽𝑖𝑖ℎ,𝐿𝐿𝐿𝐿 𝑥𝑥𝑡𝑡−𝑖𝑖 + 𝑟𝑟𝑡𝑡+ℎ|𝑡𝑡−1                          (8)
                                     𝑖𝑖=1                        𝑖𝑖=0

                                                                                                                                4
where 𝛽𝛽̂0ℎ,𝐿𝐿𝐿𝐿 is an estimate of 𝜓𝜓𝑥𝑥,ℎ . Since we can estimate 𝜎𝜎𝑥𝑥2 directly from 𝑥𝑥𝑡𝑡 , we can calculate
�∑ℎ𝑖𝑖=0 𝜓𝜓𝑥𝑥,𝑖𝑖
          2
                �𝜎𝜎𝑥𝑥2 in the numerator of equation (4’). To compute the denominator in equation (4’), we
note that the residual in equation (8) can be related to the forecast error 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 in equation (6).

For example, 𝑓𝑓̂𝑡𝑡|𝑡𝑡−1 = 𝛽𝛽̂00,𝐿𝐿𝐿𝐿 𝑥𝑥𝑡𝑡 + 𝑟𝑟̂𝑡𝑡|𝑡𝑡−1 , that is, a part of forecast error 𝑓𝑓𝑡𝑡|𝑡𝑡−1 is explained by shock
𝑥𝑥 happening at time 𝑡𝑡 which is now included as one of the regressors in equation (8). In a similar
spirit, we can use equation (3) to compute 𝑓𝑓̂𝑡𝑡+ℎ|𝑡𝑡−1 = 𝛽𝛽̂0ℎ,𝐿𝐿𝐿𝐿 𝑥𝑥𝑡𝑡 + 𝑟𝑟̂𝑡𝑡+ℎ|𝑡𝑡−1 . With these estimates of
                               � (𝑓𝑓̂𝑡𝑡+ℎ|𝑡𝑡−1 ) where 𝑉𝑉𝑉𝑉𝑉𝑉
𝑓𝑓̂𝑡𝑡+ℎ|𝑡𝑡−1 , we can compute 𝑉𝑉𝑉𝑉𝑉𝑉                    � (⋅) denotes a sample variance. Using these

insights, we define a local projection estimator of variance decomposition “LPA” as
                                                 2
                            �∑ℎ𝑖𝑖=0�𝛽𝛽̂0𝑖𝑖,𝐿𝐿𝐿𝐿 � � 𝜎𝜎�𝑥𝑥2
          𝑠𝑠ℎ𝐿𝐿𝐿𝐿𝐿𝐿 =                                                                                               (9)
                         � �𝛽𝛽̂0ℎ,𝐿𝐿𝐿𝐿 𝑥𝑥𝑡𝑡 + 𝑟𝑟̂𝑡𝑡+ℎ|𝑡𝑡−1 �
                        𝑉𝑉𝑉𝑉𝑉𝑉
                � (𝑥𝑥𝑡𝑡 ).
where 𝜎𝜎�𝑥𝑥2 ≡ 𝑉𝑉𝑉𝑉𝑉𝑉
          Although simple, LPA estimator does not guarantee that in small samples the estimated 𝑠𝑠ℎ
is between 0 and 1. A simple solution to this issue is to split the denominator into variation due to
𝑥𝑥 and due to 𝑣𝑣 so that �∑ℎ𝑖𝑖=0 𝜓𝜓𝑥𝑥,𝑖𝑖
                                   2
                                         �𝜎𝜎𝑥𝑥2 appears in both the numerator and denominator as in equation
(4’’). Note that
          𝑣𝑣�𝑡𝑡+ℎ|𝑡𝑡−1 = 𝑓𝑓̂𝑡𝑡+ℎ|𝑡𝑡−1 − 𝛽𝛽̂0ℎ,𝐿𝐿𝐿𝐿 𝑥𝑥𝑡𝑡 − 𝛽𝛽̂0ℎ−1,𝐿𝐿𝐿𝐿 𝑥𝑥𝑡𝑡+1 − ⋯ − 𝛽𝛽̂00,𝐿𝐿𝐿𝐿 𝑥𝑥𝑡𝑡+ℎ

                          = 𝑟𝑟̂𝑡𝑡+ℎ|𝑡𝑡−1 − 𝛽𝛽̂0ℎ−1,𝐿𝐿𝐿𝐿 𝑥𝑥𝑡𝑡+1 − ⋯ − 𝛽𝛽̂00,𝐿𝐿𝐿𝐿 𝑥𝑥𝑡𝑡+ℎ
so that
                                                                                                                              2
                               � �𝑟𝑟̂𝑡𝑡+ℎ|𝑡𝑡−1 − 𝛽𝛽̂0ℎ−1,𝐿𝐿𝐿𝐿 𝑥𝑥𝑡𝑡+1 − ⋯ − 𝛽𝛽̂00,𝐿𝐿𝐿𝐿 𝑥𝑥𝑡𝑡+ℎ � + ∑ℎ𝑖𝑖=0�𝛽𝛽̂0𝑖𝑖,𝐿𝐿𝐿𝐿 � 𝜎𝜎�𝑥𝑥2
           � �𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 � = 𝑉𝑉𝑉𝑉𝑉𝑉
          𝑉𝑉𝑉𝑉𝑉𝑉
which we use to define another local projection estimator of variance decomposition “LPB”:
                                                                                    2
                                                               �∑ℎ𝑖𝑖=0�𝛽𝛽̂0𝑖𝑖,𝐿𝐿𝐿𝐿 � � 𝜎𝜎�𝑥𝑥2
           𝑠𝑠ℎ𝐿𝐿𝐿𝐿𝐿𝐿 =                      2                                                                             .       (9′)
                         ∑ℎ𝑖𝑖=0�𝛽𝛽̂0𝑖𝑖,𝐿𝐿𝐿𝐿 � 𝜎𝜎�𝑥𝑥2 + 𝑉𝑉𝑉𝑉𝑉𝑉
                                                        � �𝑟𝑟̂𝑡𝑡+ℎ|𝑡𝑡−1 − 𝛽𝛽̂0ℎ−1,𝐿𝐿𝐿𝐿 𝑥𝑥𝑡𝑡+1 − ⋯ − 𝛽𝛽̂00,𝐿𝐿𝐿𝐿 𝑥𝑥𝑡𝑡+ℎ �

Using tools from Proposition 1, we can derive the asymptotic distribution of the LPA and LPB
estimators.


Proposition 2. The local projections based estimators when 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 is observable have the
following asymptotic distributions for some 𝑉𝑉ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 and 𝑉𝑉ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 :




                                                                                                                                         5
                                                        2
                                   ∑ℎ𝑖𝑖=0�𝛽𝛽̂0𝑖𝑖,𝐿𝐿𝐿𝐿 � 𝜎𝜎�𝑥𝑥2         𝑑𝑑
                             √𝑇𝑇 �                             − 𝑠𝑠ℎ � → 𝒩𝒩�0, 𝑉𝑉ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 �,   and
                                    � (𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 )
                                   𝑉𝑉𝑉𝑉𝑉𝑉
                                                            2
                                        ∑ℎ𝑖𝑖=0�𝛽𝛽̂0𝑖𝑖,𝐿𝐿𝐿𝐿 � 𝜎𝜎�𝑥𝑥2                             𝑑𝑑
       √𝑇𝑇 �                    2                                                       − 𝑠𝑠ℎ � → 𝒩𝒩�0,       𝑉𝑉ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 �.
            ∑ℎ𝑖𝑖=0�𝛽𝛽̂0𝑖𝑖,𝐿𝐿𝐿𝐿 � 𝜎𝜎�𝑥𝑥2 + 𝑉𝑉𝑉𝑉𝑉𝑉
                                           � �𝑟𝑟𝑡𝑡+ℎ|𝑡𝑡−1 − ∑ℎ−1  ̂ 𝑖𝑖,𝐿𝐿𝐿𝐿 𝑥𝑥𝑡𝑡+ℎ−𝑖𝑖 �
                                                                 𝛽𝛽
                                                             𝑖𝑖=0 0

Proof. See Appendix B2.

    C. Small-sample refinements
To correct for potential small-sample biases in the estimates of 𝑠𝑠ℎ and to enhance coverage rates for
confidence bands, we bootstrap 𝑠𝑠̂ℎ𝑅𝑅2 , 𝑠𝑠̂ℎ𝐿𝐿𝐿𝐿𝐿𝐿 , and 𝑠𝑠̂ℎ𝐿𝐿𝐿𝐿𝐿𝐿 using an estimated VAR model which includes
two variables {𝑥𝑥𝑡𝑡 , Δ𝑦𝑦𝑡𝑡 }. While our implementation of bootstrap is aimed to remove potential biases,
alternative implementations may also refine asymptotic inference. Details on how bootstrap is
implemented are relegated to Appendix E.

    D. Extension
While our analysis has focused on the bivariate case, the framework can be easily generalized to
include more controls in equation (6):
                               𝐿𝐿𝑥𝑥                  𝐿𝐿𝐶𝐶

         𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 =    � 𝛽𝛽𝑖𝑖ℎ                  ′
                                        𝑥𝑥𝑡𝑡−𝑖𝑖 + � 𝐶𝐶𝑡𝑡−𝑖𝑖 𝛤𝛤𝑖𝑖ℎ + 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1                                           (10)
                              𝑖𝑖=1                  𝑖𝑖=1

where 𝐶𝐶𝑡𝑡 is the vector of control variables which may include structural shocks other than 𝑥𝑥𝑡𝑡 . In the
base case, 𝐶𝐶𝑡𝑡 consists only of Δ𝑦𝑦𝑡𝑡 . Note that for VAR-based bootstrap, one has to include 𝑥𝑥𝑡𝑡 and all
variables in 𝐶𝐶𝑡𝑡 to simulate data. 3 Similar adjustments are also possible for LPA and LPB methods.
         One should bear in mind that, although including or excluding 𝐶𝐶𝑡𝑡 or changing the
composition of variables in 𝐶𝐶𝑡𝑡 should make little difference of impulse responses estimated with
local projections (provided 𝑥𝑥 is uncorrelated with other shocks), what goes in 𝐶𝐶𝑡𝑡 is potentially
important for variance decomposition. Intuitively, by including more controls in 𝐶𝐶𝑡𝑡 , we (weakly)
reduce the size of the forecast error (that is, information set Ω𝑡𝑡 expands) and hence the amount of
variation to be explained shrinks. In other words, the regressand in equation (7) and therefore 𝑠𝑠ℎ


3
  As the number of variables in 𝐶𝐶𝑡𝑡 increases, the number of parameters in the VAR increases rapidly. When 𝐶𝐶𝑡𝑡 is a large
vector, or when a VAR is not a good representation of the DGP for control variables, VAR-based bootstrap might not be
an appealing option. In such a case, one may correct for biases by simulating asymptotic distribution of primitive quantities
in (4) such as 𝜓𝜓�𝑥𝑥,𝑖𝑖 , 𝜎𝜎�𝑥𝑥2 , and 𝑉𝑉𝑉𝑉𝑉𝑉
                                        � �𝑣𝑣�𝑡𝑡+ℎ|𝑡𝑡−1 �. By considering 𝑠𝑠ℎ as a non-linear function of those parameters, such
simulations would detect biases due to the non-linearity. See Appendix B for implementation and E and F for the results.

                                                                                                                              6
change with a change in the list of variables included in 𝐶𝐶𝑡𝑡 . Thus, one should not be surprised to
observe that the share of variation explained by 𝑥𝑥 may be sensitive to changes in 𝐶𝐶𝑡𝑡 .

III. Simulations
This section presents two sets of simulations. The first set shows results for the baseline bivariate
case and studies the performances of the three estimators for various profiles of contribution of 𝑥𝑥
to variance of 𝑦𝑦 at different horizons. The second set uses the estimated Smets and Wouters (2007)
model to investigate the performance in a setting with many control variables.
       For each data generating process (DGP), we simulate data 2,000 times. When we employ
bootstrap to correct for biases, the number of bootstrap replications is set to B=2,000. As a
benchmark, we report results based on a corresponding VAR. This benchmark corresponds to the
practice of including shocks into VARs directly (e.g., Basu et al. 2006, Ramey 2011, Barakchian
and Crowe 2013, Romer and Romer 2004, 2010). We choose the Hannan-Quinn information
criterion (HQIC) as our benchmark criterion to determine the number of lags in VAR. To make
VAR and LP models comparable, we use HQIC number of lags in the VAR to set 𝐿𝐿𝑥𝑥 and 𝐿𝐿𝑦𝑦 .
Results are similar when we use AIC instead of HQIC.
       The sample size for simulated data is 𝑇𝑇 = 160. Results for other sample sizes are reported
in Appendices E and F. Standard errors are computed as the standard deviation of estimates across
                                                                                          𝑠𝑠̂ ℎ −𝑠𝑠ℎ
bootstrapped samples. The coverage rates are calculated as Pr ��                                          �� ≤ 1.65.
                                                                                         𝑠𝑠.𝑒𝑒.(𝑠𝑠̂ ℎ )


   A. Bivariate Data Generating Processes
We study three DGPs to cover different shapes of 𝑠𝑠ℎ . The basic structure is as follows:
       𝑦𝑦𝑡𝑡 = 𝜓𝜓𝑥𝑥 (𝐿𝐿)𝑥𝑥𝑡𝑡 + 𝑧𝑧𝑡𝑡
       𝑧𝑧𝑡𝑡 = 𝑝𝑝𝑡𝑡 + 𝑎𝑎𝑡𝑡 ,
                                                        𝑝𝑝             𝑝𝑝
       �Δ𝑝𝑝𝑡𝑡 − 𝑔𝑔𝑦𝑦 � = 𝜌𝜌𝑝𝑝 �Δ𝑝𝑝𝑡𝑡−1 − 𝑔𝑔𝑦𝑦 � + 𝑒𝑒𝑡𝑡 ,            𝑒𝑒𝑡𝑡 ~ 𝑖𝑖𝑖𝑖𝑖𝑖 𝑁𝑁�0, 𝜎𝜎𝑝𝑝2 �,
       𝑎𝑎𝑡𝑡 = 𝜌𝜌𝑎𝑎 𝑎𝑎𝑡𝑡−1 + 𝑒𝑒𝑡𝑡𝑎𝑎 , 𝑒𝑒𝑡𝑡𝑎𝑎 ~ 𝑖𝑖𝑖𝑖𝑖𝑖 𝑁𝑁(0, 𝜎𝜎𝑎𝑎2 ),
                              2 ),
       𝑥𝑥𝑡𝑡 ~ 𝑖𝑖𝑖𝑖𝑖𝑖 𝑁𝑁(0, 𝜎𝜎𝑥𝑥
             𝑝𝑝
where 𝑥𝑥𝑡𝑡 , 𝑒𝑒𝑡𝑡 and 𝑒𝑒𝑡𝑡𝑎𝑎 are mutually independent, 𝑝𝑝𝑡𝑡 and 𝑎𝑎𝑡𝑡 are permanent and transitory
components of 𝑧𝑧𝑡𝑡 . Appendix C derives the population 𝑀𝑀𝑀𝑀(∞) representation of Δ𝑧𝑧𝑡𝑡 .




                                                                                                                       7
         DGP1 is characterized by hump-shaped 𝜓𝜓𝑥𝑥 and 𝑠𝑠ℎ . We assume that 𝜓𝜓𝑥𝑥 (𝐿𝐿)𝑥𝑥𝑡𝑡 follows an
𝑀𝑀𝑀𝑀(100) process with the maximum response set to 3 after 8 periods. 4 DGP2 has a strong
response of 𝑦𝑦 to 𝑥𝑥 only in the short-run and thus the shape of 𝑠𝑠ℎ is downward-sloping. Finally,
DGP3 assumes that 𝜓𝜓𝑥𝑥 (𝐿𝐿) has a unit root so that 𝑥𝑥 has persistent effects on 𝑦𝑦 and the shape of 𝑠𝑠ℎ
is upward-sloping. Table 1 reports parameter values for each DGP. Figure 1 plots true impulse
responses of 𝑦𝑦 to 𝑥𝑥 (Panel A) and the contribution of 𝑥𝑥 to variation in 𝑦𝑦 (Panel B).
         For DGP1, we find (Table 2) that local projections capture the hump-shaped impulse
response correctly but 𝑠𝑠 𝑅𝑅2 , 𝑠𝑠 𝐿𝐿𝐿𝐿𝐿𝐿 and 𝑠𝑠 𝐿𝐿𝐿𝐿𝐿𝐿 fail to match the hump-share dynamics of 𝑠𝑠ℎ . 𝑠𝑠 𝑅𝑅2 , 𝑠𝑠 𝐿𝐿𝐿𝐿𝐿𝐿
and 𝑠𝑠 𝐿𝐿𝐿𝐿𝐿𝐿 tend to monotonically increase with the horizon. The VAR misses the hump both in the
impulse response and variance decomposition as HQIC selects too few lags (on average the
number of lags is 1.27). Confidence bands yield poor coverage rates. This performance reflects
the fact that, by construction, shock 𝑥𝑥 contributes zero variation in 𝑦𝑦 for this DGP at short
horizons. Since 𝑠𝑠ℎ is between zero and one, we effectively have estimates close to the boundary
and, therefore, standard methods are likely to fail. While bootstrap appears to provide some
improvement (e.g., the bias at long horizons when 𝑥𝑥 accounts for a larger share of variance in 𝑦𝑦 is
corrected) 5, it does not perform consistently better because the parameter is at the boundary. When
we allow 𝑥𝑥 to explain 5 percent or more of the variation in 𝑦𝑦 at short horizons, bootstrap brings
coverage rates close to nominal (results are available upon request). Note that, although VAR is
strongly biased, the VAR estimates tend to have smaller variance so that the root mean squared
error (RMSE) is similar in magnitude to RMSE of the 𝑠𝑠 𝑅𝑅2 , 𝑠𝑠 𝐿𝐿𝐿𝐿𝐿𝐿 and 𝑠𝑠 𝐿𝐿𝐿𝐿𝐿𝐿 estimators. Finally, we
observe that the 𝑠𝑠 𝑅𝑅2 , 𝑠𝑠 𝐿𝐿𝐿𝐿𝐿𝐿 and 𝑠𝑠 𝐿𝐿𝐿𝐿𝐿𝐿 estimators have similar performance.
         Because DGP2 permits an exact, finite-order VAR representation, 6 VAR has good
properties in terms of bias, RMSE and coverage rates (Table 3). The local projections recover the
share of the impulse response correct, but the estimates of contribution of 𝑥𝑥 to variance of 𝑦𝑦 again
overstate the contribution at long horizons. Bootstrap can correct this bias. Given that VAR nests




4
  This value and pattern is motivated by a 3 percent response of real GDP to a 100bp monetary policy shock estimated
in Coibion (2012).
5
  The bias can be further reduced by using higher values of 𝐿𝐿𝑥𝑥 and 𝐿𝐿𝑦𝑦 by reducing errors in 𝑓𝑓̂𝑡𝑡+ℎ|𝑡𝑡−1 due to the
truncation.
                                                                                                      𝑝𝑝
6
  Given the parameter values in Table 1, Δ𝑦𝑦𝑡𝑡 = 𝑔𝑔𝑦𝑦 + (1 − 𝐿𝐿)(1 − 0.9𝐿𝐿)−1 𝑥𝑥𝑡𝑡 + (1 − 0.9𝐿𝐿)−1 𝑒𝑒𝑡𝑡 . By pre-multiplying
                                                                       𝑝𝑝
(1 − 0.9𝐿𝐿), we have Δ𝑦𝑦𝑡𝑡 = 0.1𝑔𝑔𝑦𝑦 + 0.9Δ𝑦𝑦𝑡𝑡−1 − 𝑥𝑥𝑡𝑡−1 + 𝑥𝑥𝑡𝑡 + 𝑒𝑒𝑡𝑡 .

                                                                                                                          8
the DGP and that VAR is more parsimonious than local projections, VAR has a better performance
than the 𝑠𝑠 𝑅𝑅2 , 𝑠𝑠 𝐿𝐿𝐿𝐿𝐿𝐿 and 𝑠𝑠 𝐿𝐿𝐿𝐿𝐿𝐿 estimators.
          Because 𝑥𝑥 has long-lasting effects on 𝑦𝑦 in DGP3, the VAR underestimates the responses at
long horizons in small samples. Impulse responses estimated with local projections perform better
but also exhibit a downward bias at long horizons. In a similar spirit, 𝑠𝑠̂ℎ shows a strong downward
bias for VAR and a smaller, but still considerable bias for the 𝑠𝑠 𝑅𝑅2 , 𝑠𝑠 𝐿𝐿𝐿𝐿𝐿𝐿 and 𝑠𝑠 𝐿𝐿𝐿𝐿𝐿𝐿 estimators (this is
the case even after we use bootstrap to correct for possible biases). This performance reflects the fact
that HQIC chooses a low number of lags (1.34 lags on average across simulations). As a result,
VARs used to simulate bootstrap samples fail to capture the degree of persistence in the data. To
demonstrate the importance of the lag order, we report results (Table 4) when we use VAR(5) and
VAR(10) for bootstrap. As the number of lags increases, we observe some improvement but these
enhancements are achieved at the price of higher variance in the estimates. These results suggest that
one may want to overfit VAR for persistent processes at the bootstrap stage.
          In summary, we find for small samples that the 𝑠𝑠 𝑅𝑅2 , 𝑠𝑠 𝐿𝐿𝐿𝐿𝐿𝐿 and 𝑠𝑠 𝐿𝐿𝐿𝐿𝐿𝐿 estimators perform
reasonably well across the DGPs and that bootstrap helps to improve the estimators’ properties. In
addition, there is relatively little difference between the 𝑠𝑠 𝑅𝑅2 , 𝑠𝑠 𝐿𝐿𝐿𝐿𝐿𝐿 and 𝑠𝑠 𝐿𝐿𝐿𝐿𝐿𝐿 estimators. In contrast,
VARs that include structural shock 𝑥𝑥 tend to perform poorly when a DGP is not nested in a small-
order VAR.

     B. Smets-Wouters model
While the bivariate DGPs provide important insights about how the 𝑅𝑅2 , 𝐿𝐿𝐿𝐿𝐿𝐿 and 𝐿𝐿𝐿𝐿𝐿𝐿 estimators
perform, researchers face potentially more complex DGPs and often have more information in
practice. In this section, we use the Smets and Wouters (2007) model to study performance of our
estimators in an environment with multiple shocks and many control variables.
          As discussed above, different information sets determine different population 𝑠𝑠ℎ . In the
simulations, we assume that the researcher is interested in explaining variation in output and that
the researcher observes output growth rate, inflation, federal funds rate, and monetary policy
shocks. 7 This choice of variables is motivated by the popularity of small VARs which include


7
  For this information set, we construct the true variance decomposition using a stationary Kalman filter similar to the
method in Appendix C. We also tried various combinations of shocks and endogenous variables and found similar
results. Figures for inflation and results with large samples are in Appendix F. Note that monetary policy shocks are
nearly invertible in the Smets-Wouters model (see Wolf (2017) for more details). While this may be a problem if we

                                                                                                                      9
output, inflation and a policy rate to study effects of monetary policy on the economy. In this
exercise, the shock is ordered first because the Smets-Wouters model allows contemporaneous
responses of macroeconomic variables to policy shocks. When estimating impulse responses using
local projections, we augment equation (8) with inflation and federal funds rate as controls.
         We find (Figure 2) that local projections correctly recover the response of output to
monetary policy shocks, while a low order VAR (lag length is chosen with HQIC) fails to capture
the transitory effect of monetary shocks on output. Consistent with our bivariate analysis, 𝑠𝑠̂ℎ𝑅𝑅2 ,
𝑠𝑠̂ℎ𝐿𝐿𝐿𝐿𝐿𝐿 and 𝑠𝑠̂ℎ𝐿𝐿𝐿𝐿𝐿𝐿 increase with the horizons while the true 𝑠𝑠ℎ exhibits hump-shaped dynamics. 𝑠𝑠ℎ
estimated with a VAR also fails to capture the true dynamics as 𝑠𝑠̂ℎ flattens out after about ℎ = 5.
Similar to our results in the previous section, we find that bias correction helps 𝑠𝑠̂ℎ𝑅𝑅2 , 𝑠𝑠̂ℎ𝐿𝐿𝐿𝐿𝐿𝐿 and 𝑠𝑠̂ℎ𝐿𝐿𝐿𝐿𝐿𝐿
to recover the true hump-shaped profile of 𝑠𝑠ℎ . Coverage rates (after bias correction) are 10
percentage points lower their nominal values at short horizons (ℎ ≤ 5) but the coverage rates are
close to nominal at longer horizons. Again, although VAR estimates of 𝑠𝑠ℎ are strongly biased, the
variance of estimates is low so that RMSE is broadly similar cross methods. We conclude that our
proposed methods to estimate variance decomposition work well in more complex settings.

IV. Application
To illustrate the properties our estimators, we use two structural shocks identified in the literature.
The first shock is the monetary policy innovation identified as in Romer and Romer (2004) and
extended in Coibion et al. (2017). The second shock is the total factor productivity (TFP) shock
identified as in Fernald (2014). 8 The correlation between the shocks is -0.059. Our objective is to
quantify the contribution of these shocks to variation of output and inflation. The sample covers
1969Q1-2007Q4 which excludes the period of binding zero lower bound. The set of variables for
local projections includes inflation (annualized growth rate of GDP deflator, i.e. 400Δln(𝑃𝑃𝑡𝑡 )),
annual GDP growth rate (400Δ ln(𝑌𝑌𝑡𝑡 )), federal funds rate, and the two-shock series. We set 𝐿𝐿𝐶𝐶 =
𝐿𝐿𝑥𝑥 = 4 in equation (10) and add control variables similarly when estimating impulse responses. In
the benchmark VAR, we have all five variables and allow four lags. 9

use shocks identified and recovered from a DSGE model, the spirit of our exercise is to assume that we have access
to other information (as in e.g. Romer and Romer (2004)) so that we can observe monetary policy shocks directly.
8
  When we use empirically identified shocks, measurement errors might be an issue. Given measurement errors, we
show that asymptotic biases of our estimators are negative in Appendix D. Therefore, results here can be understood
as conservative estimates. In addition, shocks are often estimated and thus are generated regressors, but if the
researcher is interested in testing the null of no response then there is no need to adjust inference (Pagan 1984).
9
  The ordering of shocks in the VAR is TFP shock, output growth rate, inflation, monetary policy shock, fed funds rate.

                                                                                                                    10
          Consistent with previous studies, we find (Figures 3 and 4) that a contractionary monetary
policy shocks lowers output and prices, and that a positive TFP shock raises output and lowers prices.
Impulse responses estimated with VAR and local projections are similar. VAR estimates for variance
decomposition suggest that each of the shocks accounts for approximately 10 percent of variation in
output. According to the VAR estimates, monetary policy shocks account for approximately 25
percent of variation in inflation at long horizons and little variation at short horizons while the
contribution of TFP shocks is generally small. Bias correction makes no material difference for the
variance decomposition estimates for all cases but one: the bias-corrected estimate of the contribution
of monetary policy shocks to variation of inflation at long horizons is reduced to about 10 percent.
          Local projections estimate that the contribution of the two shocks to variation of output is
approximately twice as large as the contribution in VAR estimates. Consistent with simulations,
bias correction tends to generate lower contributions but generally the magnitudes are similar.
Specifically, when we use the 𝑠𝑠 𝑅𝑅2 estimator, monetary policy shocks account for approximately
20 percent of variation in output according to local projection estimates (25 percent without bias
correction) and approximately 10 percent according to VAR estimates. While the 𝐿𝐿𝐿𝐿𝐿𝐿 estimator
yields similar results, the 𝐿𝐿𝐿𝐿𝐿𝐿 estimator assigns a much larger role to the monetary policy shocks.
This pattern reflects the fact that 𝑠𝑠̂ℎ𝐿𝐿𝐿𝐿𝐿𝐿 may be greater than 1 in finite samples. Also, note that, in
contrast to the profile of 𝑠𝑠ℎ estimated with VAR for output (which is generally flat after ℎ = 5),
𝑠𝑠̂ℎ𝑅𝑅2 , 𝑠𝑠̂ℎ𝐿𝐿𝐿𝐿𝐴𝐴 and 𝑠𝑠̂ℎ𝐿𝐿𝐿𝐿𝐿𝐿 have richer dynamics.
          In a similar spirit, the contribution of TFP and monetary policy shocks to variation in
inflation is much greater according to our local-projections estimates. The difference is particularly
large for monetary shocks: 𝑠𝑠̂ℎ𝑅𝑅2 and 𝑠𝑠̂ℎ𝐿𝐿𝐿𝐿𝐿𝐿 are close to 40 percent (after bias correction) and 𝑠𝑠̂ℎ𝑉𝑉𝑉𝑉𝑉𝑉 is
about 10 percent at long horizons. Again, 𝑠𝑠̂ℎ𝐿𝐿𝐿𝐿𝐿𝐿 estimates an even greater contribution of monetary
shocks and confidence intervals are much wider for 𝑠𝑠̂ 𝐿𝐿𝐿𝐿𝐿𝐿 than for 𝑠𝑠̂ 𝐿𝐿𝐿𝐿𝐿𝐿 or 𝑠𝑠̂ 𝑅𝑅2 . Again, this stems
from the fact that 𝑠𝑠̂ℎ𝐿𝐿𝐿𝐿𝐿𝐿 may be greater than 1 in finite samples.


V. Concluding remarks
Single-equation methods can offer flexibility and parsimony that many economists seek. The
increasing popularity of these methods, specifically the local projections, calls for further
development of these tools. An important limitation for practitioners using this framework has
been a lack of simple tools to assess quantitative significance of a given set of shocks, that is, the


                                                                                                                11
contribution of the shocks to variance of the variable of interest. We propose several methods to
provide such a metric. In a series of simulation exercises, we document that these methods have
good small-sample properties. We also show that conventional approaches to assess the
quantitative significance of two popular structural shocks (monetary policy shocks and total factor
productivity shocks) could have been understated the importance of these two shocks.


References
Barakchian, S. Mahdi, and Christopher Crowe, 2013. “Monetary policy matters: Evidence from
       new shocks data,” Journal of Monetary Economics, 60(8): 950-966.
Basu, Susanto, John G. Fernald, and Miles S. Kimball, 2006. “Are Technology Improvements
       Contractionary?” American Economic Review, 96(5): 1418–1448.
Coibion, Olivier, 2012. “Are the Effects of Monetary Policy Shocks Big or Small?” American
       Economic Journal: Macroeconomics, 4(2): 1–32.
Coibion, Olivier, Yuriy Gorodnichenko, Lorenz Kueng, and John Silvia, 2017. “Innocent Bystanders?
       Monetary policy and inequality,” Journal of Monetary Economics, 88(C): 70–89.
Fernald, John, 2014. “A Quarterly, Utilization-Adjusted Series on Total Factor Productivity,”
       Working Paper 2012-19.
Jordà, Oscar, 2005. “Estimation and Inference of Impulse Responses by Local Projections,”
       American Economic Review, 95(1): 161–182.
Pagan, Adrian, 1984. “Econometric Issues in the Analysis of Regressions with Generated
       Regressors,” International Economic Review, 25(1): 221-247.
Plagborg-Møller, Mikkel, and Christian K. Wolf, 2017. “Instrumental Variable Identification of
       Dynamic Variance Decompositions,” manuscript.
Ramey, Valerie A., 2011. “Identifying Government Spending Shocks: It's all in the Timing,”
       Quarterly Journal of Economics, 126(1): 1–50.
Romer, Christina D., and David H. Romer, 2010. “The Macroeconomic Effects of Tax Changes:
       Estimates Based on a New Measure of Fiscal Shocks,” American Economic Review,
       100(3): 763-801.
Romer, Christina, D., and David H. Romer, 2004. “A New Measure of Monetary Shocks:
       Derivation and Implications,” American Economic Review, 94(4): 1055-1084.
Sims, Christopher A., 1980. “Macroeconomics and reality.” Econometrica, 48(1): 1-48.
Smets, Frank, and Rafael Wouters, 2007. “Shocks and frictions in US business cycles: A Bayesian
       DSGE approach,” American Economic Review, 97(3): 586-606.
Stock, James, and Mark Watson, 2007. “Why Has U.S. Inflation Become Harder to Forecast?”
       Journal of Money, Banking and Credit, 39(1): 3–33.
Wolf, Christian K., 2017. “Masquerading Shocks in Sign-Restricted VARs,” manuscript.




                                                                                                12
       Table 1. Parameter values for data generating processes (DGPs) used in simulations.

                     𝜓𝜓𝑥𝑥 (𝐿𝐿)            𝜎𝜎𝑥𝑥      𝑔𝑔𝑦𝑦      𝜌𝜌𝑝𝑝       𝜎𝜎𝑝𝑝      𝜌𝜌𝑎𝑎      𝜎𝜎𝑎𝑎
DGP1             Hump-shaped               1        0.5       0.9       0.5        0.9        3
DGP2             (1 − 0.9L)−1              3        0.5       0.9       1.5         -         -
DGP3        (1 − L)−1 (1 − 0.9L)−1         1        0.5       0.5         2        0.9        3




                                                                                                    13
                                        Table 2. Simulation results for DGP 1.

                                                                                 Horizon ℎ
                                                      0          4          8            12   16     20

Impulse response
   True                                             0.00       1.39       3.00         2.06   0.88   0.29
   Local projections                                0.00       1.36       2.99         2.03   0.85   0.29
   VAR(HQIC)                                        0.00       0.18       0.26         0.27   0.27   0.27

Variance decomposition
   True                                             0.00       0.04       0.19         0.21   0.18   0.14
   Average estimate
      R2                                            0.01       0.06       0.20         0.25   0.26   0.27
      LP A                                          0.01       0.04       0.18         0.23   0.23   0.23
      LP B                                          0.01       0.04       0.17         0.22   0.21   0.21
      VAR(HQIC)                                     0.01       0.02       0.02         0.03   0.03   0.03

   Root mean squared error
      R2                                            0.01       0.05       0.11         0.16   0.19   0.22
      LP A                                          0.01       0.04       0.11         0.15   0.18   0.20
      LP B                                          0.01       0.04       0.10         0.14   0.15   0.15
      VAR(HQIC)                                     0.01       0.03       0.17         0.20   0.16   0.14

   Coverage (90 % level) (asymptotic)
      R2                                            1.00       0.94       0.74         0.71   0.75   0.73
      LP A                                          1.00       0.94       0.53         0.57   0.74   0.80
      LP B                                          1.00       0.93       0.53         0.55   0.70   0.78
      VAR(HQIC)                                     1.00       0.57       0.06         0.05   0.07   0.09

Variance decomposition (bias corrected, VAR(HQIC))
   True                                       0.00             0.04       0.19         0.21   0.18   0.14
   Average estimate
      R2                                      0.00             0.02       0.13         0.16   0.13   0.11
      LP A                                    0.00             0.02       0.14         0.17   0.16   0.14
      LP B                                    0.00             0.02       0.14         0.17   0.15   0.13
      VAR(HQIC)                               0.00             0.00       0.01         0.02   0.02   0.02

   Root mean squared error
      R2                                            0.01       0.05       0.13         0.16   0.17   0.18
      LP A                                          0.01       0.04       0.12         0.16   0.17   0.18
      LP B                                          0.01       0.04       0.12         0.14   0.15   0.15
      VAR(HQIC)                                     0.01       0.04       0.19         0.21   0.18   0.15

   Coverage (90 % level)
      R2                                            1.00       0.93       0.59         0.61   0.67   0.79
      LP A                                          1.00       0.82       0.45         0.49   0.59   0.79
      LP B                                          1.00       0.81       0.46         0.47   0.57   0.73
      VAR(HQIC)                                     1.00       0.41       0.05         0.05   0.06   0.08




                                                                                                            14
                                        Table 3. Simulation results for DGP 2

                                                                                Horizon ℎ
                                                     0          4          8            12   16     20

Impulse response
   True                                             3.00       1.97       1.29        0.85   0.56   0.36
   Local projections                                2.99       1.88       1.18        0.71   0.43   0.22
   VAR(HQIC)                                        2.96       1.98       1.40        1.04   0.82   0.67

Variance decomposition
   True                                             0.80       0.25       0.10        0.05   0.03   0.02
   Average estimate
      R2                                            0.79       0.27       0.15        0.14   0.15   0.18
      LP A                                          0.80       0.27       0.13        0.10   0.09   0.09
      LP B                                          0.79       0.26       0.13        0.09   0.09   0.09
      VAR(HQIC)                                     0.80       0.27       0.13        0.08   0.06   0.05

   Root mean squared error
      R2                                            0.03       0.11       0.12        0.14   0.17   0.21
      LP A                                          0.03       0.09       0.08        0.08   0.09   0.11
      LP B                                          0.03       0.08       0.07        0.08   0.09   0.10
      VAR(HQIC)                                     0.03       0.08       0.07        0.06   0.05   0.05

   Coverage (90 % level) (asymptotic)
      R2                                            0.92       0.87       0.92        0.89   0.85   0.80
      LP A                                          0.93       0.90       0.94        0.95   0.93   0.93
      LP B                                          0.90       0.88       0.93        0.94   0.92   0.90
      VAR(HQIC)                                     0.90       0.88       0.91        0.97   0.99   0.99

Variance decomposition (bias corrected, VAR(HQIC))
   True                                       0.80             0.25       0.10        0.05   0.03   0.02
   Average estimate
      R2                                      0.81             0.25       0.09        0.04   0.01   0.00
      LP A                                    0.79             0.25       0.10        0.05   0.03   0.02
      LP B                                    0.81             0.25       0.10        0.05   0.03   0.02
      VAR(HQIC)                               0.80             0.25       0.10        0.05   0.03   0.02

   Root mean squared error
      R2                                            0.03       0.10       0.09        0.09   0.11   0.13
      LP A                                          0.03       0.08       0.07        0.07   0.07   0.08
      LP B                                          0.03       0.08       0.07        0.07   0.07   0.08
      VAR(HQIC)                                     0.03       0.08       0.06        0.05   0.04   0.04

   Coverage (90 % level)
      R2                                            0.91       0.90       0.97        0.98   0.98   0.97
      LP A                                          0.93       0.88       0.91        0.98   0.97   0.97
      LP B                                          0.89       0.83       0.89        0.97   0.97   0.96
      VAR(HQIC)                                     0.89       0.88       0.89        0.92   0.99   1.00




                                                                                                           15
                       Table 4. Simulation results for DGP 3 with alternative lag orders in VARs.

                                                                                   Horizon ℎ
                                                         0          4          8           12       16     20

Impulse response
   True                                                 1.00       4.10       6.13       7.46       8.33   8.91
   Local projections                                    0.99       3.96       5.78       6.86       7.44   7.66
   VAR(5)                                               0.93       3.74       4.76       5.01       5.10   5.14
   VAR(10)                                              0.92       3.65       5.34       6.05       6.17   6.23

Variance decomposition (bias corrected, VAR(5))
   True                                                 0.06       0.29       0.47       0.58       0.65   0.70
   Average estimate
      R2                                                0.06       0.26       0.41       0.50       0.55   0.58
      LP A                                              0.05       0.24       0.38       0.48       0.54   0.58
      LP B                                              0.06       0.25       0.40       0.49       0.54   0.57
      VAR(5)                                            0.06       0.24       0.33       0.36       0.38   0.39

   Root mean squared error
      R2                                                0.04       0.11       0.16       0.19       0.21   0.23
      LP A                                              0.04       0.11       0.17       0.21       0.25   0.28
      LP B                                              0.04       0.11       0.16       0.19       0.20   0.22
      VAR(5)                                            0.04       0.11       0.19       0.26       0.31   0.34

   Coverage (90 % level) (asymptotic)
      R2                                                0.77       0.80       0.80       0.81       0.82   0.83
      LP A                                              0.85       0.83       0.82       0.83       0.84   0.85
      LP B                                              0.84       0.79       0.78       0.78       0.79   0.80
      VAR(5)                                            0.83       0.78       0.66       0.51       0.40   0.33

Variance decomposition (bias corrected, VAR(10))
   True                                                 0.06       0.29       0.47       0.58       0.65   0.70
   Average estimate
      R2                                                0.07       0.30       0.47       0.57       0.63   0.66
      LP A                                              0.05       0.23       0.37       0.47       0.52   0.55
      LP B                                              0.05       0.27       0.44       0.54       0.60   0.63
      VAR(10)                                           0.06       0.27       0.42       0.50       0.54   0.56

   Root mean squared error
      R2                                                0.05       0.12       0.16       0.19       0.21   0.22
      LP A                                              0.04       0.12       0.17       0.21       0.25   0.29
      LP B                                              0.04       0.12       0.16       0.18       0.20   0.21
      VAR(10)                                           0.04       0.11       0.15       0.19       0.21   0.23

   Coverage (90 % level)
      R2                                                0.72       0.76       0.78       0.80       0.82   0.83
      LP A                                              0.87       0.87       0.89       0.90       0.91   0.92
      LP B                                              0.85       0.77       0.75       0.76       0.78   0.79
      VAR(10)                                           0.83       0.83       0.81       0.79       0.77   0.74




                                                                                                                  16
                   Figure 1. Population impulse responses and variance decomposition for each DGP




Notes: the left panel shows the impulse response functions for three bivariate data generating processes (DGPs). The right
panel shows the contribution of the identified shock to variation of an outcome variable for the DGPs.




                                                                                                                       17
                          Figure 2: Smets and Wouters (2007) model, real GDP and monetary policy shock, T = 160.
                               Impulse Response                                             Variance Decomposition
                  1                                                        0.2




        0.5                                                             0.15




                  0                                                        0.1




      -0.5                                                              0.05




             -1                                                                  0

                      0            5                10   15     20                    0                   5             10   15   20




Variance Decomposition, Bias-Corrected                                               Coverage Probability of 90% C.I.
        0.2                                                                      1




     0.15



                                                                           0.8

        0.1




     0.05
                                                                           0.6




                  0

                      0            5                10   15     20                    0                   5             10   15   20




                                         Root MSE
     0.15




        0.1




     0.05




                  0

                      0            5                10   15     20




                                                                                                                                       18
                                          Figure 3 Real GDP. 1969:Q1-2007:Q4.

              Impulse Response, VAR                                               Impulse Response, LP
   5                                                            10



   0                                                             0



  -5                                                           -10
       0        5           10            15         20              0            5            10           15    20

           Variance Decomposition, VAR                            Variance Decomposition, VAR, bias-corrected
0.6                                                            0.6

0.4                                                            0.4

0.2                                                            0.2

   0                                                             0

-0.2                                                          -0.2
       0        5           10            15         20              0            5            10           15    20

            Variance Decomposition, R2                               Variance Decomposition, R2, bias-corrected
0.6                                                            0.6

0.4                                                            0.4

0.2                                                            0.2

   0                                                             0

-0.2                                                          -0.2
       0        5           10            15         20              0            5            10           15    20

           Variance Decomposition, LP A                           Variance Decomposition, LP A, bias-corrected
0.6                                                            0.6

0.4                                                            0.4

0.2                                                            0.2

   0                                                             0

-0.2                                                          -0.2
       0        5           10            15         20              0            5            10           15    20

           Variance Decomposition, LP B                           Variance Decomposition, LP B, bias-corrected
0.6                                                            0.6

0.4                                                            0.4

0.2                                                            0.2

   0                                                             0

-0.2                                                          -0.2
       0        5           10            15         20              0            5            10           15    20


                                  TFP          TFP 90% CB            MP         MP 90% CB




                                                                                                                       19
                                          Figure 4. Inflation. 1969:Q1-2007:Q4.

              Impulse Response, VAR                                                 Impulse Response, LP
0.5                                                                2



   0                                                               0



-0.5                                                              -2
       0        5           10            15          20               0            5            10           15    20

           Variance Decomposition, VAR                             Variance Decomposition, VAR, bias-corrected

0.6                                                              0.6
0.4                                                              0.4
0.2                                                              0.2
   0                                                               0
-0.2                                                            -0.2
       0        5           10            15          20               0            5            10           15    20

            Variance Decomposition, R2                                 Variance Decomposition, R2, bias-corrected

0.6                                                              0.6
0.4                                                              0.4
0.2                                                              0.2
   0                                                               0
-0.2                                                            -0.2
       0        5           10            15          20               0            5            10           15    20

           Variance Decomposition, LP A                            Variance Decomposition, LP A, bias-corrected

0.6                                                              0.6
0.4                                                              0.4
0.2                                                              0.2
   0                                                               0
-0.2                                                            -0.2
       0        5           10            15          20               0            5            10           15    20

           Variance Decomposition, LP B                             Variance Decomposition, LP B, bias-corrected
0.8                                                              0.8
0.6                                                              0.6
0.4                                                              0.4
0.2                                                              0.2
   0                                                               0
-0.2                                                            -0.2
       0        5           10            15          20               0            5            10           15    20


                                    TFP           TFP 90% CB               MP        MP 90% CB




                                                                                                                         20
                          APPENDIX FOR



A NOTE ON VARIANCE DECOMPOSITION WITH LOCAL
                PROJECTIONS


      Yuriy Gorodnichenko                      Byoungchan Lee
University of California – Berkeley   University of California – Berkeley
            and NBER




                                                                       1
Appendix A. Identification of 𝑒𝑒𝑡𝑡
In Section II, we derive the ℎ-period ahead forecast error as following:
                        𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 = 𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡+ℎ|𝑡𝑡−1 = (𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 ) − 𝐸𝐸[𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 |Ω𝑡𝑡−1 ]
                                                  = 𝜓𝜓𝑥𝑥,𝑜𝑜 𝑥𝑥𝑡𝑡+ℎ + ⋯ + 𝜓𝜓𝑥𝑥,ℎ 𝑥𝑥𝑡𝑡 + 𝑣𝑣𝑡𝑡+ℎ|𝑡𝑡−1
where 𝑦𝑦𝑡𝑡+ℎ|𝑡𝑡−1 ≡ 𝐸𝐸[𝑦𝑦𝑡𝑡+ℎ |Ω𝑡𝑡−1 ] and Ω𝑡𝑡−1 = {Δ𝑦𝑦𝑡𝑡−1 , 𝑥𝑥𝑡𝑡−1 , Δ𝑦𝑦𝑡𝑡−2 , 𝑥𝑥𝑡𝑡−2 , … }. In the footnote 2, we
argue that given invertibility of 𝜓𝜓𝑒𝑒 (𝐿𝐿), 𝑣𝑣𝑡𝑡+ℎ|𝑡𝑡−1 = 𝜓𝜓𝑒𝑒,0 𝑒𝑒𝑡𝑡+ℎ + ⋯ + �𝜓𝜓𝑒𝑒,0 + ⋯ + 𝜓𝜓𝑒𝑒,ℎ �𝑒𝑒𝑡𝑡 .
             There is a technically subtle issue that the above forecast error seems to be based on the
information set Ω𝑡𝑡−1 ∪ {𝑒𝑒𝑡𝑡−1 , … }, not the set of observables Ω𝑡𝑡−1 . Thus, we need to prove that
knowing 𝑒𝑒𝑡𝑡 is redundant, once we have Ω𝑡𝑡 . In other words, {𝑒𝑒𝑡𝑡−1 , 𝑒𝑒𝑡𝑡−2 , … } ⊂
𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐�𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠(Ω𝑡𝑡−1 )�.
             Let’s assume that we have only Ω𝑡𝑡 . Following the idea of Jordà (2005), 𝜓𝜓𝑥𝑥,ℎ is identified
     𝐶𝐶𝐶𝐶𝐶𝐶(𝑦𝑦𝑡𝑡 −𝑦𝑦𝑡𝑡−ℎ−1 , 𝑥𝑥𝑡𝑡−ℎ )
as                                      for all ℎ. This implies that Δ𝑧𝑧𝑡𝑡 is identified, because
                 𝑉𝑉𝑉𝑉𝑉𝑉(𝑥𝑥𝑡𝑡 )

                                                        Δ𝑧𝑧𝑡𝑡 = Δ𝑦𝑦𝑡𝑡 − (1 − 𝐿𝐿)𝜓𝜓𝑥𝑥 (𝐿𝐿)𝑥𝑥𝑡𝑡 .
The drift term of 𝑧𝑧𝑡𝑡 is also easily identified because 𝑔𝑔𝑦𝑦 = 𝐸𝐸[Δ𝑧𝑧𝑡𝑡 ] = 𝐸𝐸[Δ𝑦𝑦𝑡𝑡 ], where 𝐸𝐸[⋅] is the
unconditional expectation operator. Therefore,
                                         𝑤𝑤𝑡𝑡 ≡ 𝜓𝜓𝑒𝑒 (𝐿𝐿)𝑒𝑒𝑡𝑡 = Δ𝑧𝑧𝑡𝑡 − 𝑔𝑔𝑦𝑦 ∈ closure�span(Ω𝑡𝑡 )�.
             Finally, it follows from the uniqueness of the Wold decomposition 1 that
                                               𝑒𝑒𝑡𝑡 = 𝑤𝑤𝑡𝑡 − 𝑃𝑃𝑟𝑟𝑟𝑟𝑟𝑟𝑟𝑟𝑟𝑟𝑟𝑟𝑟𝑟𝑟𝑟𝑟𝑟(𝑤𝑤𝑡𝑡 |𝑤𝑤𝑡𝑡−1 , 𝑤𝑤𝑡𝑡−2 , … )
                    𝐶𝐶𝐶𝐶𝐶𝐶(𝑤𝑤𝑡𝑡 −𝑤𝑤𝑡𝑡−ℎ−1 ,𝑒𝑒𝑡𝑡−ℎ )
and 𝜓𝜓𝑒𝑒,ℎ =                                          for all ℎ, where 𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃(𝑎𝑎|𝐴𝐴) is defined by the orthogonal
                              𝑉𝑉𝑉𝑉𝑉𝑉(𝑒𝑒𝑡𝑡 )

projection of a vector 𝑎𝑎 in a Hibert space to a closed subspace generated by a set of vectors 𝐴𝐴,
𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐�span(𝐴𝐴)� .              2
                                              Therefore, {𝑒𝑒𝑡𝑡 , 𝑒𝑒𝑡𝑡−1 , … } ⊂ 𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐�𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠(Ω𝑡𝑡 )� , and specifically,
𝐸𝐸[𝑦𝑦𝑡𝑡+ℎ |Ω𝑡𝑡−1 ] = E[𝑦𝑦𝑡𝑡+ℎ |Ω𝑡𝑡−1 ∪ {𝑒𝑒𝑡𝑡−1 , 𝑒𝑒𝑡𝑡−2 , … }].
             This result illustrates how we can back out 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 in practice. First, we consider 𝑦𝑦𝑡𝑡+ℎ −
𝑦𝑦𝑡𝑡−1 :
y𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 = 𝜓𝜓𝑥𝑥,0 𝑥𝑥𝑡𝑡+ℎ + 𝜓𝜓𝑥𝑥,1 𝑥𝑥𝑡𝑡+ℎ−1 + ⋯ + 𝜓𝜓𝑥𝑥,ℎ 𝑥𝑥𝑡𝑡 + [(𝑆𝑆 ∗ )ℎ+1 − 𝐼𝐼]𝜓𝜓𝑥𝑥 (𝐿𝐿)𝑥𝑥𝑡𝑡−1 + 𝑧𝑧𝑡𝑡+ℎ − 𝑧𝑧𝑡𝑡−1 ,




1
    See Brockwell and Davis (1991) for details.
2
    See Conway (1990) for details on projections.

                                                                                                                                2
where 𝑆𝑆 ∗ is the adjoint operator of the unilateral shift on 𝑙𝑙2 (𝑁𝑁) and 𝐼𝐼 is the identity operator. In
other words,
              𝑆𝑆(𝜓𝜓0 , 𝜓𝜓1 , … ) = (0, 𝜓𝜓0 , 𝜓𝜓1 , … ),   𝑎𝑎𝑎𝑎𝑎𝑎     𝑆𝑆 ∗ (𝜓𝜓0 , 𝜓𝜓1 , … ) = (𝜓𝜓1 , 𝜓𝜓2 , … ).
        For simple notations, we additionally assume that ∑∞
                                                           j=0 𝑗𝑗 ⋅ �𝜓𝜓𝑒𝑒,𝑗𝑗 � < ∞. This condition holds

for any stationary ARMA processes. By applying the Beveridge-Nelson decomposition, we obtain
the followings:
            𝑧𝑧𝑡𝑡 = Δ𝑧𝑧𝑡𝑡 + ⋯ + Δ𝑧𝑧1 + 𝑧𝑧0 = 𝑔𝑔𝑦𝑦 ⋅ 𝑡𝑡 + 𝜓𝜓𝑒𝑒 (1) ⋅ (𝑒𝑒𝑡𝑡 + ⋯ + 𝑒𝑒1 ) + 𝜁𝜁𝑡𝑡 − 𝜁𝜁0 + 𝑧𝑧0 ,
                                         ∞ �                 ���                                        ���
where 𝜓𝜓𝑒𝑒 (1) = ∑∞                                                                               ∞
                  𝑗𝑗=0 𝜓𝜓𝑒𝑒,𝑗𝑗 , 𝜁𝜁𝑡𝑡 = ∑𝑗𝑗=0 𝜓𝜓𝑗𝑗 𝑒𝑒𝑡𝑡−𝑗𝑗 , 𝜓𝜓𝚥𝚥 = −(𝜓𝜓𝑗𝑗+1 + 𝜓𝜓𝑗𝑗+2 + ⋯ ), and ∑𝑗𝑗=0 |𝜓𝜓𝚥𝚥 | < ∞.

Thus, we can rewrite 𝑧𝑧𝑡𝑡+ℎ − 𝑧𝑧𝑡𝑡−1 by 𝜓𝜓𝑒𝑒 (1) ⋅ (𝑒𝑒𝑡𝑡+ℎ + ⋯ + 𝑒𝑒𝑡𝑡 ) + 𝜁𝜁𝑡𝑡+ℎ − 𝜁𝜁𝑡𝑡−1 . 3 Finally,
            𝐸𝐸(𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 |Ω𝑡𝑡−1 ) = �𝜓𝜓𝑥𝑥,ℎ+1 − 𝜓𝜓𝑥𝑥,0 �𝑥𝑥𝑡𝑡−1 + �𝜓𝜓𝑥𝑥,ℎ+2 − 𝜓𝜓𝑥𝑥,1 �𝑥𝑥𝑡𝑡−2 + ⋯ +
                                               𝐸𝐸(𝜁𝜁𝑡𝑡+ℎ − 𝜁𝜁𝑡𝑡−1 |Ω𝑡𝑡−1 ).
        This illustrates what we actually do when we try to estimate the forecast errors by taking
residuals after regressing 𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 on Δ𝑦𝑦𝑡𝑡−1 , 𝑥𝑥𝑡𝑡−1 and their lagged values. In the regression,
𝑥𝑥𝑡𝑡−1 and its lagged values control for two things. First thing to be captured is the component
directly related to {𝑥𝑥𝑡𝑡−1 } through 𝜓𝜓𝑥𝑥 (𝐿𝐿) , which is [(𝑆𝑆 ∗ )ℎ+1 − 𝐼𝐼]𝜓𝜓𝑥𝑥 (𝐿𝐿)𝑥𝑥𝑡𝑡−1 = �𝜓𝜓𝑥𝑥,ℎ+1 −
𝜓𝜓𝑥𝑥,0 �𝑥𝑥𝑡𝑡−1 + �𝜓𝜓𝑥𝑥,ℎ+2 − 𝜓𝜓𝑥𝑥,1 �𝑥𝑥𝑡𝑡−2 + ⋯ in the above expression. Moreover, (1 − 𝐿𝐿)𝜓𝜓𝑥𝑥 (𝐿𝐿)𝑥𝑥𝑡𝑡−1 in
Δ𝑦𝑦𝑡𝑡−1 is also controlled, generating 𝑤𝑤𝑡𝑡−1 = 𝜓𝜓𝑒𝑒 (𝐿𝐿)𝑒𝑒𝑡𝑡−1 . A closed subspace generated by 𝑤𝑤𝑡𝑡−1 and
its lagged values will be the same as that by 𝑒𝑒𝑡𝑡−1 , 𝑒𝑒𝑡𝑡−2 , …. Finally, this part of the projection will
control for 𝐸𝐸(𝜁𝜁𝑡𝑡+ℎ − 𝜁𝜁𝑡𝑡−1 |Ω𝑡𝑡−1 ) because 𝜁𝜁𝑡𝑡−1 is a limit of linear combinations of {𝑒𝑒𝑡𝑡−1 , 𝑒𝑒𝑡𝑡−2 , … }.
This completes purification of the 𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 to 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 .




3
 Of course, we can proceed without the additional assumption. In that case, notations become messy because
everything should be written in terms of 𝑒𝑒𝑡𝑡 ’s instead of 𝜁𝜁𝑡𝑡+ℎ − 𝜁𝜁𝑡𝑡−1 .

                                                                                                                 3
Appendix B1. Proof of Proposition 1 and implementation detail
                                                                                                                                       ′
Proposition              1.          Suppose         𝑓𝑓ℎ = �𝑓𝑓𝑇𝑇|𝑇𝑇−ℎ−1 , 𝑓𝑓𝑇𝑇−1|𝑇𝑇−ℎ−2 , … , 𝑓𝑓𝐿𝐿𝑚𝑚𝑚𝑚𝑚𝑚+ℎ+1 |𝐿𝐿𝑚𝑚𝑚𝑚𝑚𝑚 �                   and   𝑋𝑋ℎ =
   ℎ        ℎ                              ′
�𝑋𝑋𝑇𝑇−ℎ , 𝑋𝑋𝑇𝑇−1 , … , 𝑋𝑋𝐿𝐿ℎ𝑚𝑚𝑚𝑚𝑚𝑚+1 � for all ℎ ≥ 0 where 𝐿𝐿𝑚𝑚𝑚𝑚𝑚𝑚 = max�𝐿𝐿𝑥𝑥 , 𝐿𝐿𝑦𝑦 � . Then the 𝑅𝑅2 of the
regression of 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 on 𝑋𝑋𝑡𝑡ℎ , given by �𝑓𝑓ℎ′ 𝑃𝑃𝑋𝑋ℎ 𝑓𝑓ℎ �/(𝑓𝑓ℎ′ 𝑓𝑓ℎ ) where 𝑃𝑃𝑋𝑋ℎ = 𝑋𝑋ℎ (𝑋𝑋ℎ′ 𝑋𝑋ℎ )−1 𝑋𝑋ℎ′ , has the
following asymptotic distribution for some 𝑉𝑉ℎ,𝑅𝑅2 :
                                                     𝑓𝑓ℎ′ 𝑃𝑃𝑋𝑋ℎ 𝑓𝑓ℎ         𝑑𝑑
                                                √𝑇𝑇 � ′             − 𝑠𝑠ℎ � → 𝒩𝒩�0,                𝑉𝑉ℎ,𝑅𝑅2 �.
                                                        𝑓𝑓ℎ 𝑓𝑓ℎ
Proof. Although 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 is a time 𝑡𝑡 + ℎ variable, not time 𝑡𝑡, we can proceed without loss of
validity of the results below by considering the moment conditions below as time 𝑡𝑡 + ℎ conditions,
not 𝑡𝑡. We use this notation instead of 𝑓𝑓𝑡𝑡|𝑡𝑡−ℎ−1 for consistency of the presentation.
                       ′       ′       ′
          Let 𝜃𝜃0 = �𝜃𝜃1,0 , 𝜃𝜃2,0 , 𝜃𝜃3,0 �′ where
                                                             𝑋𝑋𝑡𝑡ℎ = (𝑥𝑥𝑡𝑡+ℎ , … , 𝑥𝑥𝑡𝑡 )′ ,
                                                          −1                                                                       ′
                           𝜃𝜃1,0 = �𝐸𝐸[𝑋𝑋𝑡𝑡ℎ 𝑋𝑋𝑡𝑡ℎ ′]� �𝐸𝐸�𝑋𝑋𝑡𝑡ℎ 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 �� = �𝜓𝜓𝑥𝑥,0 , 𝜓𝜓𝑥𝑥,1 , … , 𝜓𝜓𝑥𝑥,ℎ � ,
                                                     𝜃𝜃2,0 = 𝐸𝐸�𝑋𝑋𝑡𝑡ℎ 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 � = 𝜃𝜃1,0 𝜎𝜎𝑥𝑥2 ,
                                                                       2               2
                                                         𝜃𝜃3,0 = 𝐸𝐸�𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 � ≡ 𝜎𝜎𝑓𝑓,ℎ .
                                                                        ′
We define the method of moments estimator 𝜃𝜃� = �𝜃𝜃�1′ , 𝜃𝜃�2′ , 𝜃𝜃�3′ � as following:
                                                                                      𝑋𝑋ℎ′ 𝑓𝑓ℎ                         𝑓𝑓ℎ′ 𝑓𝑓ℎ
                                     𝜃𝜃�1 = (𝑋𝑋ℎ′ 𝑋𝑋ℎ )−1 (𝑋𝑋ℎ′ 𝑓𝑓ℎ ),       𝜃𝜃�2 =            ,         𝜃𝜃�3 =
                                                                                        𝑇𝑇ℎ                              𝑇𝑇ℎ
                                                                                                         𝑓𝑓ℎ′ 𝑃𝑃𝑋𝑋ℎ 𝑓𝑓ℎ
where 𝑇𝑇ℎ = 𝑇𝑇 − (𝐿𝐿𝑚𝑚𝑚𝑚𝑚𝑚 + 1) . It follows that 𝑠𝑠ℎ = 𝜉𝜉(𝜃𝜃0 ) and                                                         = 𝜉𝜉�𝜃𝜃�� where 𝜉𝜉(𝜃𝜃) =
                                                                                                            𝑓𝑓ℎ′ 𝑓𝑓ℎ

                         𝜃𝜃2′ 𝜃𝜃1
𝜉𝜉(𝜃𝜃1 , 𝜃𝜃2 , 𝜃𝜃3 ) =              . Therefore, we first derive the asymptotic distribution of √𝑇𝑇�𝜃𝜃� − 𝜃𝜃0 � and then
                           𝜃𝜃3

apply the delta method.
          To begin, we consider the moment conditions that 𝐸𝐸�𝑔𝑔�𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 , 𝑋𝑋𝑡𝑡ℎ , 𝜃𝜃�� = 0 where
                                                                                                                         ′
                                                                                 𝑋𝑋𝑡𝑡ℎ �𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 − �𝑋𝑋𝑡𝑡ℎ � 𝜃𝜃1 �
                            𝑔𝑔𝑡𝑡+ℎ (𝜃𝜃) ≡ 𝑔𝑔�𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 , 𝑋𝑋𝑡𝑡ℎ , 𝜃𝜃� = �              𝑋𝑋𝑡𝑡ℎ 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 − 𝜃𝜃2                   �.
                                                                                              2
                                                                                           𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1    − 𝜃𝜃3
It is clear that the conditions are satisfied only when 𝜃𝜃 = 𝜃𝜃0 and the system is just-identified. As
shown by Hansen (1982), we know that


                                                                                                                                                    4
                                                                 𝑑𝑑
                                          √𝑇𝑇�𝜃𝜃� − 𝜃𝜃0 � → 𝒩𝒩(0,                    𝐺𝐺 −1 Ω(𝐺𝐺 ′ )−1 )
where 𝐺𝐺 = 𝐸𝐸[∇θ 𝑔𝑔𝑡𝑡+ℎ (𝜃𝜃0 )] and Ω = ∑∞
                                         𝑙𝑙=−∞ Γ(𝑙𝑙) and Γ(𝑙𝑙) is the autocovariance of 𝑔𝑔𝑡𝑡+ℎ (𝜃𝜃0 ) at lag
                                                                                                         ′
𝑙𝑙. With some algebra, we can show that 𝐺𝐺 = −𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑 �𝐸𝐸 �𝑋𝑋𝑡𝑡ℎ �𝑋𝑋𝑡𝑡ℎ � � , 𝐼𝐼ℎ+2 � where 𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑(𝐴𝐴, 𝐵𝐵) is the

block diagonal matrix whose diagonal components are 𝐴𝐴 and 𝐵𝐵 in order.
                                                                                  𝜕𝜕𝜕𝜕(𝜃𝜃0 )         1          ′       ′
           Regarding the delta method, we define Δ ≡                                           =             �𝜃𝜃2,0 , 𝜃𝜃1,0 , −𝑠𝑠ℎ �. Combining the
                                                                                    𝜕𝜕𝜃𝜃′           𝜃𝜃3,0

above derivations, and being explicit about the fact that the moment conditions 𝑔𝑔𝑡𝑡+ℎ (⋅) are for the
𝑅𝑅2 approach at horizon ℎ, we have the desired result.
                                               𝑓𝑓ℎ′ 𝑃𝑃𝑋𝑋ℎ 𝑓𝑓ℎ         𝑑𝑑
                                          √𝑇𝑇 � ′             − 𝑠𝑠ℎ � → 𝒩𝒩�0,                       𝑉𝑉ℎ,𝑅𝑅2 �
                                                  𝑓𝑓ℎ 𝑓𝑓ℎ
                                                                     ′−1                            −1
                         where 𝑉𝑉ℎ,𝑅𝑅2 = Δℎ,𝑅𝑅2 �𝐺𝐺ℎ,𝑅𝑅2 � Ωℎ,𝑅𝑅2 �𝐺𝐺ℎ,𝑅𝑅 2� Δ′ℎ,𝑅𝑅2 .                                                □


Implementation. We discuss how to implement Proposition 1. First of all, we use 𝑓𝑓̂𝑡𝑡+ℎ|𝑡𝑡−1
obtained from Equation (6) instead of 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 in practice, because 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 is not observable.
                                                             ′
Then 𝑓𝑓̂ℎ = �𝑓𝑓̂𝑇𝑇|𝑇𝑇−ℎ−1 , … , 𝑓𝑓̂𝐿𝐿𝑚𝑚𝑚𝑚𝑚𝑚+ℎ+1 |𝐿𝐿𝑚𝑚𝑚𝑚𝑚𝑚 � , and 𝑠𝑠̂ℎ𝑅𝑅2 is given by �𝑓𝑓̂ℎ′ 𝑃𝑃𝑋𝑋ℎ 𝑓𝑓̂ℎ �/(𝑓𝑓̂ℎ′ 𝑓𝑓̂ℎ ).
           We also need to estimate 𝑉𝑉ℎ,𝑅𝑅2 because it depends on the population parameters. Let’s
                                                                                                                                          ′
begin with Δℎ,𝑅𝑅2 . A practically feasible estimator of 𝜃𝜃 we use is 𝜃𝜃� = �𝜃𝜃�1′ , 𝜃𝜃�2′ , 𝜃𝜃�3′ � where
                                                                                      𝑋𝑋ℎ′ 𝑓𝑓̂ℎ                        𝑓𝑓̂ℎ′ 𝑓𝑓̂ℎ
                              𝜃𝜃�1 = (𝑋𝑋ℎ′ 𝑋𝑋ℎ )−1 �𝑋𝑋ℎ′ 𝑓𝑓̂ℎ �,            𝜃𝜃�2 =              ,             𝜃𝜃�3 =              .
                                                                                        𝑇𝑇ℎ                               𝑇𝑇ℎ
                                                               ��
                                                          𝜕𝜕𝜕𝜕�𝜃𝜃           1
                                 �ℎ,𝑅𝑅2 ≡
A natural estimator of Δℎ,𝑅𝑅2 is Δ                                    =    �   �𝜃𝜃�2′ , 𝜃𝜃�1′ , −𝑠𝑠̂ℎ𝑅𝑅2 �.   The last element is based on a
                                                           𝜕𝜕𝜃𝜃′           𝜃𝜃3

bias-corrected estimates instead of 𝜉𝜉�𝜃𝜃� � because we find that this specification provides better
performances in simulations. 4 How to obtain the bias-corrected estimator 𝑠𝑠̂ℎ𝑅𝑅2 in this set-up will be
discussed later.
                                                             ′
           We next turn to 𝐺𝐺 = −𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑 �𝐸𝐸 �𝑋𝑋𝑡𝑡ℎ �𝑋𝑋𝑡𝑡ℎ � � , 𝐼𝐼ℎ+2 �. It can be easily estimated by 𝐺𝐺�ℎ,𝑅𝑅2 =
                                                                                      ′
−𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑(𝑋𝑋ℎ′ 𝑋𝑋ℎ /𝑇𝑇ℎ , 𝐼𝐼ℎ+2 ) = −𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑 �∑𝑇𝑇−ℎ              ℎ     ℎ
                                                𝑡𝑡=𝐿𝐿𝑚𝑚𝑚𝑚𝑚𝑚 +1 𝑋𝑋𝑡𝑡 �𝑋𝑋𝑡𝑡 � /𝑇𝑇ℎ , 𝐼𝐼ℎ+2 �.

           It remains to estimate Ωℎ,𝑅𝑅2 = ∑∞
                                            𝑙𝑙=−∞ Γ(𝑙𝑙) where Γ(𝑙𝑙) is the autocovariance of 𝑔𝑔𝑡𝑡 (𝜃𝜃0 ) at

lag 𝑙𝑙. We use the pre-whitening procedure following Andrews and Monahan (1992) to avoid


4
    Results are available upon requests.

                                                                                                                                                 5
underestimation problem of the long-run variance of 𝑔𝑔𝑡𝑡+ℎ (𝜃𝜃0 ). To that end, we define a 2ℎ + 3
dimensional vector 𝑍𝑍𝑡𝑡+ℎ as following:
                                                                               ′
                                                 𝑋𝑋𝑡𝑡ℎ �𝑓𝑓̂𝑡𝑡+ℎ|𝑡𝑡−1 − �𝑋𝑋𝑡𝑡ℎ � 𝜃𝜃�1 �
                                      𝑍𝑍𝑡𝑡+ℎ   ≡⎛       𝑋𝑋 ℎ 𝑓𝑓̂       − 𝜃𝜃�
                                                              𝑡𝑡 𝑡𝑡+ℎ|𝑡𝑡−1            2
                                                                                       ⎞.

                                                   ⎝          𝑓𝑓̂𝑡𝑡+ℎ|𝑡𝑡−1
                                                                  2
                                                                           −   𝜃𝜃�3          ⎠
                                                                                                  1
It is worth noting that the sample average of 𝑍𝑍𝑡𝑡 is a zero vector, i.e.                               ∑𝑇𝑇−ℎ
                                                                                                         𝑡𝑡=𝐿𝐿𝑚𝑚𝑚𝑚𝑚𝑚 +1 𝑍𝑍𝑡𝑡 = 0 given the
                                                                                                  𝑇𝑇ℎ

definition of 𝜃𝜃� . To whiten the series, we use a VAR(1) that 𝑍𝑍𝑡𝑡 = 𝐴𝐴𝑍𝑍𝑡𝑡−1 + 𝑈𝑈𝑡𝑡 . The estimated
autoregressive matrix and the residual are denoted by 𝐴𝐴̂ and 𝑈𝑈
                                                              �𝑡𝑡 . Then we estimate the long-run
            �𝑡𝑡 by applying the method suggested by Newey and West (1987) with the Bartlett kernel
variance of 𝑈𝑈
                  �𝐿𝐿 +2 , … , 𝑈𝑈
to the residuals �𝑈𝑈           �𝑇𝑇−ℎ �. Specifically, the estimated long-run variance is given by
                     𝑚𝑚𝑚𝑚𝑚𝑚

                                         1                                  𝐿𝐿𝑁𝑁𝑁𝑁
            � �𝑈𝑈
          𝐿𝐿𝐿𝐿𝐿𝐿 �𝑡𝑡 � = Γ�𝑈𝑈,0 +              �Γ�𝑈𝑈,1 + Γ�𝑈𝑈,−1 � + ⋯ +           �Γ�        + Γ�𝑈𝑈,−𝐿𝐿𝑁𝑁𝑁𝑁 �
                                    𝐿𝐿𝑁𝑁𝑁𝑁 + 1                           𝐿𝐿𝑁𝑁𝑁𝑁 + 1 𝑈𝑈,𝐿𝐿𝑁𝑁𝑁𝑁
where Γ�𝑈𝑈,𝑙𝑙 is the estimated autocovariance matrix of 𝑈𝑈𝑡𝑡 at lag 𝑙𝑙. We use a simple rule suggested
by Stock and Watson (2011) to select the number of autocovariance matrices to be included in the
                                                                                  1/3          � ℎ,𝑅𝑅2
estimation. Following the rule, 𝐿𝐿𝑁𝑁𝑁𝑁 + 1 is the closest natural number of 0.75𝑇𝑇ℎ . Finally, Ω
                             −1
is obtained by �𝐼𝐼2ℎ+3 − 𝐴𝐴̂� 𝐿𝐿𝐿𝐿𝐿𝐿
                                � �𝑈𝑈�𝑡𝑡 ��𝐼𝐼2ℎ+3 − 𝐴𝐴̂′ �−1 .

        In sum, the asymptotic standard error of 𝑠𝑠̂ℎ𝑅𝑅2 is given by
                                                    1
                         [𝑠𝑠. 𝑒𝑒. (𝑠𝑠̂ℎ𝑅𝑅2 )]2 =       �ℎ,𝑅𝑅2 �𝐺𝐺�ℎ,𝑅𝑅2 �−1 Ω
                                                       Δ                    � ℎ,𝑅𝑅2 �𝐺𝐺� ′ 2 �−1 Δ
                                                                                                 �′ 2
                                                                                        ℎ,𝑅𝑅      ℎ,𝑅𝑅
                                                   𝑇𝑇ℎ
                                                                  1 ′ ′
                                              �ℎ,𝑅𝑅2 =
                                        where Δ                      �𝜃𝜃�2 , 𝜃𝜃�1 , −𝑠𝑠̂ℎ𝑅𝑅2 �,
                                                                  �
                                                                 𝜃𝜃3
                                                                     𝑋𝑋ℎ′ 𝑋𝑋ℎ
                                           𝐺𝐺�ℎ,𝑅𝑅2 = −𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑 �             , 𝐼𝐼ℎ+1 �,
                                                                       𝑇𝑇ℎ
                             � ℎ,𝑅𝑅2 = �𝐼𝐼2ℎ+3 − 𝐴𝐴̂�−1 𝐿𝐿𝐿𝐿𝐿𝐿
                             Ω                            � �𝑈𝑈�𝑡𝑡 ��𝐼𝐼2ℎ+3 − 𝐴𝐴̂′ �−1 .


Bias-correction. We conjecture that most of the finite sample bias is due to the non-linear
transformation 𝜉𝜉(⋅), not estimation of 𝜃𝜃. Note that 𝜃𝜃 consists of projection coefficients of 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 on
𝑋𝑋𝑡𝑡ℎ , covariance between 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 and 𝑋𝑋𝑡𝑡ℎ , and variance of 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 . Estimation of all three quantities
are rather standard, and significant biases regarding the method of moments estimator have not been
reported. Below we suggest a method to capture biases originating from 𝜉𝜉(⋅) in small samples.

                                                                                                                                        6
                                        𝑑𝑑
       Because √𝑇𝑇�𝜃𝜃� − 𝜃𝜃0 � → 𝒩𝒩(0,                   𝐺𝐺 −1 Ω(𝐺𝐺 ′ )−1 ) , we can approximate the asymptotic
                                                                     −1
variance of the feasible estimator 𝜃𝜃� by
                                                     1
                                                          �𝐺𝐺�ℎ,𝑅𝑅2 � Ω � ℎ,𝑅𝑅2 �𝐺𝐺� ′ 2 �−1 . We simulate 𝜃𝜃 𝑏𝑏 for 𝐵𝐵 times
                                                    𝑇𝑇ℎ                             ℎ,𝑅𝑅

from the following normal distribution:
                                                           1             −1
                              𝜃𝜃 𝑏𝑏 ∼ 𝒩𝒩 �𝜃𝜃� ,               �𝐺𝐺�ℎ,𝑅𝑅2 � Ω � ℎ,𝑅𝑅2 �𝐺𝐺� ′ 2 �−1 �.
                                                          𝑇𝑇ℎ                           ℎ,𝑅𝑅


       We discard cases with 𝜃𝜃3𝑏𝑏 ≤ 0 while drawing 𝜃𝜃 𝑏𝑏 ’s, because 𝜃𝜃3 = 𝑉𝑉𝑉𝑉𝑉𝑉�𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 �. Then
the bias is estimated by
                                                                                                  𝐵𝐵
                                    �������                                   �������      1
                   𝑏𝑏𝑏𝑏𝑏𝑏𝑠𝑠ℎ𝑅𝑅2   ≡ 𝜉𝜉(𝜃𝜃            � �,
                                          𝑏𝑏 ) − 𝜉𝜉�𝜃𝜃          where         𝜉𝜉(𝜃𝜃 𝑏𝑏 ) ≡    � 𝜉𝜉(𝜃𝜃 𝑏𝑏 ).
                                                                                           𝐵𝐵
                                                                                             𝑏𝑏=1

       Finally, the bias-corrected estimator is given by
                                                                                    �������
                                    𝑠𝑠̂ℎ𝑅𝑅2 = 𝜉𝜉�𝜃𝜃� � − 𝑏𝑏𝑏𝑏𝑏𝑏𝑠𝑠ℎ𝑅𝑅2 = 2𝜉𝜉�𝜃𝜃� � − 𝜉𝜉(𝜃𝜃 𝑏𝑏 ).




                                                                                                                           7
Appendix B2. Proof of Proposition 2 and implementation details
Proposition 2. The local projections based estimators when 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 is observable have the
following asymptotic distributions for some 𝑉𝑉ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 and 𝑉𝑉ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 :
                                                              2
                                        ∑ℎ𝑖𝑖=0�𝛽𝛽̂0𝑖𝑖,𝐿𝐿𝐿𝐿 � 𝜎𝜎�𝑥𝑥2         𝑑𝑑
                                  √𝑇𝑇 �                             − 𝑠𝑠ℎ � → 𝒩𝒩�0, 𝑉𝑉ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 �,                      and
                                         � (𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 )
                                        𝑉𝑉𝑉𝑉𝑉𝑉
                                                                  2
                                             ∑ℎ𝑖𝑖=0�𝛽𝛽̂0𝑖𝑖,𝐿𝐿𝐿𝐿 � 𝜎𝜎�𝑥𝑥2                                                𝑑𝑑
      √𝑇𝑇 �                    2                                                          − 𝑠𝑠ℎ � → 𝒩𝒩�0,                     𝑉𝑉ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 �
           ∑ℎ𝑖𝑖=0�𝛽𝛽̂0𝑖𝑖,𝐿𝐿𝐿𝐿 � 𝜎𝜎�𝑥𝑥2 + 𝑉𝑉𝑉𝑉𝑉𝑉
                                          � �𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 − ∑ℎ𝑖𝑖=0 𝛽𝛽̂0𝑖𝑖,𝐿𝐿𝐿𝐿 𝑥𝑥𝑡𝑡+ℎ−𝑖𝑖 �

Proof. Similar to Proposition 1, the moment conditions below should be understood as time 𝑡𝑡 + ℎ
conditions, not time 𝑡𝑡.
    (i)          LP-A estimator
We first derive the joint distribution of 𝜓𝜓�𝑥𝑥,𝑖𝑖 ’s, 𝜎𝜎�𝑥𝑥2 , and 𝜎𝜎�𝑓𝑓,ℎ
                                                                        2      � �𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 �. Then we will use the
                                                                            ≡ 𝑉𝑉𝑉𝑉𝑉𝑉
delta method to find 𝑉𝑉ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 .
           To begin, we describe the moment conditions for the local projections for 𝜓𝜓�𝑥𝑥,𝑖𝑖 ’s. We run
the following OLS regression and take the coefficient on 𝑥𝑥𝑡𝑡 :
          𝑦𝑦𝑡𝑡+𝑖𝑖 − 𝑦𝑦𝑡𝑡−1 = 𝛽𝛽0𝑖𝑖 𝑥𝑥𝑡𝑡 + ⋯ + 𝛽𝛽𝐽𝐽𝑖𝑖𝐿𝐿𝐿𝐿 𝑥𝑥𝑡𝑡−𝐽𝐽𝐿𝐿𝐿𝐿 + 𝛾𝛾1𝑖𝑖 Δ𝑦𝑦𝑡𝑡−1 + ⋯ + 𝛾𝛾𝐼𝐼𝑖𝑖𝐿𝐿𝐿𝐿 Δ𝑦𝑦𝑡𝑡−𝐼𝐼𝐿𝐿𝐿𝐿 + 𝑐𝑐𝑖𝑖 + 𝑟𝑟𝑡𝑡+𝑖𝑖|𝑡𝑡−1

for all 𝑖𝑖 = 0,1, … , ℎ. In the above representation, 𝛽𝛽0𝑖𝑖 = 𝜓𝜓𝑥𝑥,𝑖𝑖 . For a simple notation, we rewrite the
above equation by
                                                           𝑝𝑝𝑖𝑖,𝑡𝑡 = 𝑞𝑞𝑡𝑡′ Β𝑖𝑖 + 𝑟𝑟𝑡𝑡+𝑖𝑖|𝑡𝑡−1
                                                    where 𝑝𝑝𝑖𝑖,𝑡𝑡 = 𝑦𝑦𝑡𝑡+𝑖𝑖 − 𝑦𝑦𝑡𝑡−1 ,
                                                                                                                   ′
                                        𝑞𝑞𝑡𝑡 = �1, 𝑥𝑥𝑡𝑡 , … , 𝑥𝑥𝑡𝑡−𝐽𝐽𝐿𝐿𝐿𝐿 , Δ𝑦𝑦𝑡𝑡−1 , … , Δ𝑦𝑦𝑡𝑡−𝐼𝐼𝐿𝐿𝐿𝐿 � ,
                                                                                                             ′
                                               Β𝑖𝑖 = �𝑐𝑐𝑖𝑖 , 𝛽𝛽0𝑖𝑖 , … , 𝛽𝛽𝐽𝐽𝑖𝑖𝐿𝐿𝐿𝐿 , 𝛾𝛾1𝑖𝑖 , … , 𝛾𝛾𝐼𝐼𝑖𝑖𝐿𝐿𝐿𝐿 � .
                       � 𝑖𝑖 becomes the method of moments estimator of the following moment
Then the OLS estimator Β
conditions that
                                                        𝐸𝐸�𝑞𝑞𝑡𝑡 �𝑝𝑝𝑖𝑖,𝑡𝑡 − 𝑞𝑞𝑡𝑡′ Β𝑖𝑖 �� = 0.
Also, 𝜓𝜓�𝑥𝑥,𝑖𝑖 is given by 𝜄𝜄1′ Β
                                � 𝑖𝑖 where 𝜄𝜄1 is a 𝐼𝐼 𝐿𝐿𝐿𝐿 + 𝐽𝐽𝐿𝐿𝐿𝐿 + 2 dimensional vector whose first element is

one and the others are zero.




                                                                                                                                             8
                                                                                                  2
        To study all parameters required simultaneously, we let 𝜃𝜃0 = �Β0′ , … , Βℎ′ , 𝜎𝜎𝑥𝑥2 , 𝜎𝜎𝑓𝑓,ℎ �′ where
   2
𝜎𝜎𝑓𝑓,ℎ ≡ 𝑉𝑉𝑉𝑉𝑉𝑉�𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 �. We use the moment conditions such that 𝐸𝐸[𝑔𝑔𝑡𝑡+ℎ (𝜃𝜃0 )] = 0 where 𝑔𝑔𝑡𝑡+ℎ (𝜃𝜃0 )
is given as following:
                                                       𝑞𝑞𝑡𝑡 �𝑝𝑝0,𝑡𝑡 − 𝑞𝑞𝑡𝑡′ Β0 �
                                                     ⎛              ⋮            ⎞
                                                                          ′
                                     𝑔𝑔𝑡𝑡+ℎ (𝜃𝜃0 ) = ⎜ 𝑡𝑡 ℎ,𝑡𝑡 𝑞𝑞𝑡𝑡 Βℎ �⎟.
                                                      𝑞𝑞   �𝑝𝑝      −
                                                     ⎜                           ⎟
                                                              𝑥𝑥𝑡𝑡2 − 𝜎𝜎𝑥𝑥2
                                                           2                 2
                                                     ⎝ 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 − 𝜎𝜎𝑓𝑓,ℎ ⎠
We define 𝑔𝑔𝑡𝑡+ℎ (𝜃𝜃) similarly. It is clear that it is a just-identified system. Similar to the proof of
Proposition 1, we know that
                                                    𝑑𝑑
                                 √𝑇𝑇�𝜃𝜃� − 𝜃𝜃0 � → 𝒩𝒩(0,               𝐺𝐺 −1 Ω(𝐺𝐺 ′ )−1 )
where 𝐺𝐺 = 𝐸𝐸[∇θ 𝑔𝑔𝑡𝑡+ℎ (𝜃𝜃0 )] and Ω = ∑∞
                                         𝑙𝑙=−∞ Γ(𝑙𝑙) and Γ(𝑙𝑙) is the autocovariance of 𝑔𝑔𝑡𝑡+ℎ (𝜃𝜃0 ) at lag

𝑙𝑙. With some algebra, we can show that
                                                  𝐼𝐼   ⊗ 𝑞𝑞𝑡𝑡 𝑞𝑞𝑡𝑡′             0
                                        𝐺𝐺 = −𝐸𝐸 � ℎ+1                             �
                                                       0                       𝐼𝐼2
where ⊗ is the Kronecker’s product.
        A transformation 𝜉𝜉 is required to connect 𝜃𝜃 with 𝑠𝑠ℎ . We define
                                                             ∑ℎ𝑖𝑖=0(𝜄𝜄1′ Β𝑖𝑖 )2 𝜎𝜎𝑥𝑥2
                                      𝜉𝜉(𝜃𝜃0 ) = 𝑠𝑠ℎ =                   2            .
                                                                    𝜎𝜎𝑓𝑓,ℎ
𝜉𝜉(𝜃𝜃) is also defined similarly.
                                                                𝜕𝜕𝜕𝜕(𝜃𝜃0 )
        Regarding the delta method, we need Δ ≡                           . With some algebra, we show that
                                                                  𝜕𝜕𝜃𝜃′
                                                                                 ′
                                                     2𝜓𝜓𝑥𝑥,0 𝜎𝜎𝑥𝑥2 𝜄𝜄1
                                                   ⎛       ⋮
                                                                2 ⎞
                                              1 ⎜ 𝑥𝑥,ℎ 𝜎𝜎𝑥𝑥 𝜄𝜄1 ⎟
                                                     2𝜓𝜓
                                          Δ= 2 ⎜ ℎ                     ⎟.
                                            𝜎𝜎𝑓𝑓,ℎ
                                                   ⎜ � 𝜓𝜓𝑥𝑥,𝑖𝑖 2 ⎟

                                                              𝑖𝑖=0
                                                         ⎝       −𝑠𝑠ℎ        ⎠
        Combining the above derivations, and being explicit about the fact that the moment
conditions 𝑔𝑔𝑡𝑡+ℎ (⋅) are for the LP-A approach at horizon ℎ, we have the desired result.
                                                   2
                                  ∑ℎ𝑖𝑖=0�𝜓𝜓�𝑥𝑥,𝑖𝑖 � 𝜎𝜎�𝑥𝑥2         𝑑𝑑
                            √𝑇𝑇 �                          − 𝑠𝑠ℎ � → 𝒩𝒩�0,                𝑉𝑉ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 �.
                                   � �𝑓𝑓̂𝑡𝑡+ℎ|𝑡𝑡−1 �
                                  𝑉𝑉𝑉𝑉𝑉𝑉



                                                                                                              9
                                                                    −1     ′                     −1
                   where 𝑉𝑉ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 = Δℎ,𝐿𝐿𝐿𝐿𝐿𝐿 �𝐺𝐺ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 � Ωℎ,𝐿𝐿𝐿𝐿𝐿𝐿 �𝐺𝐺ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 � Δ′ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 .                 □


     (ii)      LP-B estimator
            The joint distribution of 𝜓𝜓�𝑥𝑥,𝑖𝑖 ’s is obtained similarly. To study all parameters required
simultaneously,            we       let         𝜃𝜃0 = �Β0′ , … , Βℎ′ , 𝜎𝜎𝑥𝑥2 , 𝜎𝜎𝑣𝑣,ℎ
                                                                                  2
                                                                                      �′          where      2
                                                                                                          𝜎𝜎𝑣𝑣,ℎ ≡ 𝑉𝑉𝑉𝑉𝑉𝑉�𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 −
∑ℎ𝑖𝑖=0 𝜓𝜓𝑥𝑥,𝑖𝑖 𝑥𝑥𝑡𝑡+ℎ−𝑖𝑖 �. We use the moment conditions such that 𝐸𝐸[𝑔𝑔𝑡𝑡+ℎ (𝜃𝜃0 )] = 0 where 𝑔𝑔𝑡𝑡+ℎ (𝜃𝜃0 ) is
given as following:
                                                                     𝑞𝑞𝑡𝑡 �𝑝𝑝0,𝑡𝑡 − 𝑞𝑞𝑡𝑡′ Β0 �
                                        ⎛                                         ⋮       ⎞
                                        ⎜                            𝑞𝑞𝑡𝑡 �𝑝𝑝ℎ,𝑡𝑡 − 𝑞𝑞𝑡𝑡′ Βℎ �
                                                                                          ⎟
                                  (𝜃𝜃
                            𝑔𝑔𝑡𝑡+ℎ 0 =) ⎜                                   𝑥𝑥𝑡𝑡2 − 𝜎𝜎𝑥𝑥2 ⎟.
                                        ⎜                                       2         ⎟
                                        ⎜                 ℎ                               ⎟
                                                                                      2
                                         �𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 − �(𝜄𝜄1′ Β𝑖𝑖 ) 𝑥𝑥𝑡𝑡+ℎ−𝑖𝑖 � − 𝜎𝜎𝑣𝑣,ℎ
                                        ⎝               𝑖𝑖=0                              ⎠
We define 𝑔𝑔𝑡𝑡+ℎ (𝜃𝜃) similarly. It is clear that it is a just-identified system. In such a case, the method
of moments estimator 𝜃𝜃� can be understood as a two-step estimator. It first find Β
                                                                                  � 𝑖𝑖 ’s using the OLS
                                                                                                 2
moment conditions and then plug the estimates into the remaining conditions. Then 𝜎𝜎�𝑥𝑥2 and 𝜎𝜎�𝑣𝑣,ℎ
                  � 𝑖𝑖 ’s. It is worth noting that this is the same procedure we follow when we define
are derived given Β
𝑠𝑠̂ℎ𝐿𝐿𝐿𝐿𝐿𝐿 . The only difference is that we are using here 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 instead of its estimate.
            Similar to the proof of Proposition 1, we know that
                                                               𝑑𝑑
                                       √𝑇𝑇�𝜃𝜃� − 𝜃𝜃0 � → 𝒩𝒩(0,                  𝐺𝐺 −1 Ω(𝐺𝐺 ′ )−1 )
where 𝐺𝐺 = 𝐸𝐸[∇θ 𝑔𝑔𝑡𝑡+ℎ (𝜃𝜃0 )] and Ω = ∑∞
                                         𝑙𝑙=−∞ Γ(𝑙𝑙) and Γ(𝑙𝑙) is the autocovariance of 𝑔𝑔𝑡𝑡+ℎ (𝜃𝜃0 ) at lag

𝑙𝑙. With some algebra, we can show that

                                                                    𝐼𝐼ℎ+1 ⊗ 𝑞𝑞𝑡𝑡 𝑞𝑞𝑡𝑡′                 0
                                     ⎛                                                               � ⎞
                            𝐺𝐺 = −𝐸𝐸 ⎜                                                                    ⎟
                                     ⎜                  0                  ⋯           0
                                                                                                     � ⎟
                                              2𝑣𝑣𝑡𝑡+ℎ|𝑡𝑡−1 𝑥𝑥𝑡𝑡+ℎ 𝜄𝜄1′     ⋯ 2𝑣𝑣𝑡𝑡+ℎ|𝑡𝑡−1 𝑥𝑥𝑡𝑡+1 𝜄𝜄1′ 𝐼𝐼2
                                          ⎝                                                               ⎠
where ⊗ is the Kronecker’s product. For the bottom left part, we use the fact that 𝜄𝜄1′ Β𝑖𝑖 = 𝜓𝜓𝑥𝑥,𝑖𝑖 and
𝑣𝑣𝑡𝑡+ℎ|𝑡𝑡−1 = 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 − ∑ℎ𝑖𝑖=0 𝜓𝜓𝑥𝑥,𝑖𝑖 𝑥𝑥𝑡𝑡+ℎ−𝑖𝑖       .        Because        𝑣𝑣𝑡𝑡+ℎ|𝑡𝑡−1 = 𝜓𝜓𝑒𝑒,0 𝑒𝑒𝑡𝑡+ℎ + ⋯ + �𝜓𝜓𝑒𝑒,0 + ⋯ +
𝜓𝜓𝑒𝑒,ℎ �𝑒𝑒𝑡𝑡 is orthogonal to {𝑥𝑥𝑡𝑡 }, the bottom left block of 𝐺𝐺 becomes a zero matrix.


                                                                                                                                    10
         A transformation 𝜉𝜉 is required to connect 𝜃𝜃 with 𝑠𝑠ℎ . We define
                                                                             ∑ℎ𝑖𝑖=0(𝜄𝜄1′ Β𝑖𝑖 )2 𝜎𝜎𝑥𝑥2
                                                𝜉𝜉(𝜃𝜃0 ) = 𝑠𝑠ℎ =                                      2 .
                                                                        ∑ℎ𝑖𝑖=0(𝜄𝜄1′ Β𝑖𝑖 )2 𝜎𝜎𝑥𝑥2 + 𝜎𝜎𝑣𝑣,ℎ
𝜉𝜉(𝜃𝜃) is also defined similarly.
                                                                                     𝜕𝜕𝜕𝜕(𝜃𝜃0 )                                      2
         Regarding the delta method, we need Δ ≡                                                . For a simple notation, we write 𝜎𝜎𝑓𝑓,ℎ ≡
                                                                                       𝜕𝜕𝜃𝜃′

𝑉𝑉𝑉𝑉𝑉𝑉�𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 � = ∑ℎ𝑖𝑖=0 𝜓𝜓𝑥𝑥,𝑖𝑖
                                2                2
                                      𝜎𝜎𝑥𝑥2 + 𝜎𝜎𝑣𝑣,ℎ . With some algebra, we show that
                                                                                                      ′
                                                                 2𝜓𝜓𝑥𝑥,0 𝜎𝜎𝑥𝑥2 𝜄𝜄1
                                                               ⎛       ⋮           ⎞
                                                                            2
                                                       1 − 𝑠𝑠ℎ ⎜ 2𝜓𝜓𝑥𝑥,ℎ 𝜎𝜎𝑥𝑥 𝜄𝜄1 ⎟
                                                     Δ= 2 ⎜        ℎ               ⎟.
                                                        𝜎𝜎𝑓𝑓,ℎ ⎜           2       ⎟
                                                               ⎜ � 𝜓𝜓𝑥𝑥,𝑖𝑖 ⎟
                                                                                  𝑖𝑖=0
                                                                        ⎝−𝑠𝑠ℎ /(1 − 𝑠𝑠ℎ )⎠
         Combining the above derivations, and being explicit about the fact that the moment
conditions 𝑔𝑔𝑡𝑡+ℎ (⋅) are for the LPB approach at horizon ℎ, we have the desired result.
                                                                  2
                                               ∑ℎ𝑖𝑖=0�𝛽𝛽̂0𝑖𝑖,𝐿𝐿𝐿𝐿 � 𝜎𝜎�𝑥𝑥2                                         𝑑𝑑
       √𝑇𝑇 �                       2                                                                       − 𝑠𝑠ℎ � → 𝒩𝒩�0,       𝑉𝑉ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 �.
               ∑ℎ𝑖𝑖=0�𝛽𝛽̂0𝑖𝑖,𝐿𝐿𝐿𝐿 � 𝜎𝜎�𝑥𝑥2      � �𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 − ∑ℎ𝑖𝑖=0 𝛽𝛽̂0𝑖𝑖,𝐿𝐿𝐿𝐿 𝑥𝑥𝑡𝑡+ℎ−𝑖𝑖 �
                                             + 𝑉𝑉𝑉𝑉𝑉𝑉
                                                                         −1 ′                          −1
                    where 𝑉𝑉ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 = Δℎ,𝐿𝐿𝐿𝐿𝐿𝐿 �𝐺𝐺ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 � Ωℎ,𝐿𝐿𝐿𝐿𝐿𝐿 �𝐺𝐺ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 � Δ′ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 .                          □


Joint inference. In the below, we explain how to obtain joint distribution of the LP-B estimator
(𝑠𝑠̂0𝐿𝐿𝐿𝐿𝐿𝐿 , 𝑠𝑠̂1𝐿𝐿𝐿𝐿𝐿𝐿 , … , 𝑠𝑠̂𝐻𝐻𝐿𝐿𝐿𝐿𝐿𝐿 )′ . Results for the LP-A estimator can be obtained similarly.
                                                            𝐽𝐽𝐽𝐽𝐽𝐽𝐽𝐽𝐽𝐽
         We consider augmented moment conditions that 𝐸𝐸�𝑔𝑔𝑡𝑡+𝐻𝐻 (𝜃𝜃0 )� = 0 where 𝜃𝜃0 =
(Β0′ , … , Β𝐻𝐻
            ′               2
               , 𝜎𝜎𝑥𝑥2 , 𝜎𝜎𝑣𝑣,0          2
                                , … , 𝜎𝜎𝑣𝑣,𝐻𝐻 )′ is a (𝐻𝐻 + 1) ∗ (𝐼𝐼 𝐿𝐿𝐿𝐿 + 𝐽𝐽𝐿𝐿𝐿𝐿 + 3) + 1 dimensional vector, and
                                                                              𝑞𝑞𝑡𝑡 �𝑝𝑝0,𝑡𝑡 − 𝑞𝑞𝑡𝑡′ Β0 �
                                                  ⎛                                        ⋮                            ⎞
                                                  ⎜                          𝑞𝑞𝑡𝑡 �𝑝𝑝𝐻𝐻,𝑡𝑡 − 𝑞𝑞𝑡𝑡′ Β𝐻𝐻 �                ⎟
                                                  ⎜                                  𝑥𝑥𝑡𝑡2 − 𝜎𝜎𝑥𝑥2                      ⎟
                                                  ⎜                              0                         2            ⎟
                                 𝐽𝐽𝐽𝐽𝐽𝐽𝐽𝐽𝐽𝐽
                              𝑔𝑔𝑡𝑡+𝐻𝐻 0 = ⎜ (𝜃𝜃 )
                                                              �𝑓𝑓𝑡𝑡|𝑡𝑡−1 − �(𝜄𝜄1′ Β𝑖𝑖 ) 𝑥𝑥𝑡𝑡−𝑖𝑖 � − 𝜎𝜎𝑣𝑣,0
                                                                                                       2                ⎟.
                                                  ⎜                                                                     ⎟
                                                  ⎜                            𝑖𝑖=0                                     ⎟
                                                  ⎜                                         ⋮                           ⎟
                                                                                𝐻𝐻                             2
                                                  ⎜                                                                     ⎟
                                                          �𝑓𝑓𝑡𝑡+𝐻𝐻|𝑡𝑡−1 − �(𝜄𝜄1′ Β𝑖𝑖 ) 𝑥𝑥𝑡𝑡+𝐻𝐻−𝑖𝑖 � − 𝜎𝜎𝑣𝑣,𝐻𝐻
                                                                                                         2

                                                      ⎝                        𝑖𝑖=0                                     ⎠

                                                                                                                                                 11
Then it is straightforward to extend Proposition 2 to the joint distribution of (𝑠𝑠̂0𝐿𝐿𝐿𝐿 , 𝑠𝑠̂1𝐿𝐿𝐿𝐿 , … , 𝑠𝑠̂𝐻𝐻𝐿𝐿𝐿𝐿 )′ . In
practice, both 𝐼𝐼 𝐿𝐿𝐿𝐿 and 𝐽𝐽𝐿𝐿𝐿𝐿 should be small not to make (𝐻𝐻 + 1) ∗ (𝐼𝐼 𝐿𝐿𝐿𝐿 + 𝐽𝐽𝐿𝐿𝐿𝐿 + 3) + 1 too large
relative to available sample sizes.


Implementation. We discuss how to implement Proposition 2. In the below, we focus on the LP-
B estimator. Again, the LP-A estimator can be implemented in a similar way.
             First of all, we use 𝑓𝑓̂𝑡𝑡+ℎ|𝑡𝑡−1 from Equation (6) instead of 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 in practice.
             We also need to estimate 𝑉𝑉ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 because it depends on population parameters. Let’s begin
with Gℎ,𝐿𝐿𝐿𝐿𝐿𝐿 = −𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑(𝐼𝐼ℎ+1 ⊗ 𝐸𝐸[𝑞𝑞𝑡𝑡 𝑞𝑞𝑡𝑡′ ], 𝐼𝐼2 ). It is natural to have
                                                                                              𝑇𝑇−ℎ
                                                                           1
                                       𝐺𝐺�ℎ,𝐿𝐿𝐿𝐿𝐿𝐿   = −𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑 �𝐼𝐼ℎ+1 ⊗                     �         𝑞𝑞𝑡𝑡 𝑞𝑞𝑡𝑡 ′ , 𝐼𝐼2 �.
                                                                          𝑇𝑇ℎ
                                                                                       𝑡𝑡=𝐿𝐿𝑚𝑚𝑚𝑚𝑚𝑚 +1

                                                                                             2 ′
             The feasible estimator of 𝜃𝜃 is denoted by 𝜃𝜃� ≡ �Β
                                                               � 0′ , … , Β
                                                                          �ℎ′ , 𝜎𝜎�𝑥𝑥2 , 𝜎𝜎�𝑣𝑣,ℎ � where 𝜎𝜎�𝑥𝑥2 =
1                                    1                                                                      2
                             2
     ∑𝑇𝑇𝑡𝑡=1 𝑥𝑥𝑡𝑡2 , and 𝜎𝜎�𝑣𝑣,ℎ =         ∑𝑇𝑇−ℎ            ̂             ℎ      ′�
                                            𝑡𝑡=𝐿𝐿𝑚𝑚𝑚𝑚𝑚𝑚+1 �𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 − ∑𝑖𝑖=0 𝜄𝜄1 Β𝑖𝑖 𝑥𝑥𝑡𝑡+ℎ−𝑖𝑖 � . We define (𝐻𝐻 + 1) ∗ (𝐼𝐼
                                                                                                    5                         𝐿𝐿𝐿𝐿
                                                                                                                                   +
𝑇𝑇                                   𝑇𝑇ℎ

𝐽𝐽𝐿𝐿𝐿𝐿 + 2) + 2 dimensional vector 𝑍𝑍𝑡𝑡+ℎ as following:
                                                                        𝑞𝑞𝑡𝑡 �𝑝𝑝0,𝑡𝑡 − 𝑞𝑞𝑡𝑡′ Β�0�
                                                ⎛                                    ⋮              ⎞
                                                ⎜                       𝑞𝑞𝑡𝑡 �𝑝𝑝ℎ,𝑡𝑡 − 𝑞𝑞𝑡𝑡′ Β�ℎ �  ⎟
                                     𝑍𝑍𝑡𝑡+ℎ    ≡⎜                              𝑥𝑥𝑡𝑡2 − 𝜎𝜎�𝑥𝑥2       ⎟.
                                                ⎜                                        2          ⎟
                                                ⎜                  ℎ                                ⎟
                                                 �𝑓𝑓̂𝑡𝑡+ℎ|𝑡𝑡−1 − ��𝜄𝜄1′ Β
                                                                        �𝑖𝑖 � 𝑥𝑥𝑡𝑡+ℎ−𝑖𝑖 � − 𝜎𝜎�𝑣𝑣,ℎ
                                                                                                2

                                                ⎝                𝑖𝑖=0                               ⎠
     � ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 is obtained by applying the Newey-West estimator to 𝑍𝑍𝑡𝑡+ℎ with pre-whitening
Then Ω
similar to Proposition 1.
             It remains to estimate Δℎ,𝐿𝐿𝐿𝐿𝐿𝐿 . It is straightforward to define
                                                                                                                    ′
                                                                                      2𝜓𝜓�𝑥𝑥,0 𝜎𝜎�𝑥𝑥2 𝜄𝜄1
                                                                              ⎛              ⋮                  ⎞
                                                           1   − 𝑠𝑠̂ℎ𝐿𝐿𝐿𝐿𝐿𝐿   ⎜       2𝜓𝜓�𝑥𝑥,ℎ 𝜎𝜎�𝑥𝑥2 𝜄𝜄1       ⎟
                                             �ℎ.𝐿𝐿𝐿𝐿𝐿𝐿 =
                                             Δ                                ⎜           ℎ                     ⎟
                                                                   2
                                                               𝜎𝜎�𝑓𝑓,ℎ        ⎜                                 ⎟
                                                                              ⎜         � 𝜓𝜓�𝑥𝑥,𝑖𝑖
                                                                                             2
                                                                                                                ⎟
                                                                                        𝑖𝑖=0
                                                                              ⎝−𝑠𝑠̂ℎ𝐿𝐿𝐿𝐿𝐿𝐿 /(1 − 𝑠𝑠̂ℎ𝐿𝐿𝐿𝐿𝐿𝐿 )⎠

5
     The denominator 𝑇𝑇ℎ ight be adjusted according to the degrees of freedom without affecting the asymptotics.

                                                                                                                                 12
                   1
          2
where 𝜎𝜎�𝑓𝑓,ℎ =         ∑𝑇𝑇−ℎ            ̂2                                         𝐿𝐿𝐿𝐿𝐿𝐿
                         𝑡𝑡=𝐿𝐿𝑚𝑚𝑚𝑚𝑚𝑚 +1 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 . We plug the bias-corrected 𝑠𝑠̂ℎ      in the place of 𝑠𝑠ℎ . How to
                  𝑇𝑇ℎ

obtain a bias-corrected estimator 𝑠𝑠̂ℎ𝐿𝐿𝐿𝐿𝐿𝐿 in this set-up will be discussed later.
                 �ℎ.𝐿𝐿𝐿𝐿𝐿𝐿 , the standard error of 𝑠𝑠̂ℎ𝐿𝐿𝐿𝐿𝐿𝐿 is given as following:
           Given Δ
                                                      1
                        [𝑠𝑠. 𝑒𝑒. (𝑠𝑠̂ℎ𝐿𝐿𝐿𝐿𝐿𝐿 )]2 =       �ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 �𝐺𝐺�ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 �−1 Ω
                                                         Δ                          � ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 �𝐺𝐺�ℎ,𝐿𝐿𝐿𝐿𝐿𝐿
                                                                                                   ′         −1 ′
                                                                                                            � Δ�ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 .
                                                     𝑇𝑇ℎ


Bias-correction. Similar to discussion regarding Proposition 1, we conjecture that most of the
finite sample bias is due to the non-linear transformation 𝜉𝜉(⋅).
           We     approximate            the     asymptotic             variance         of     the      feasible       estimator 𝜃𝜃� by
1                   −1                          −1
      �𝐺𝐺�ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 � Ω � ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 �𝐺𝐺�ℎ,𝐿𝐿𝐿𝐿𝐿𝐿
                                      ′
                                               � . Then we simulate 𝜃𝜃 𝑏𝑏 for 𝐵𝐵 times from the following normal
𝑇𝑇ℎ

distribution:
                                                              1                −1                          −1
                                 𝜃𝜃 𝑏𝑏 ∼ 𝒩𝒩 �𝜃𝜃� ,               �𝐺𝐺�ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 � Ω � ℎ,𝐿𝐿𝐿𝐿𝐿𝐿 �𝐺𝐺�ℎ,𝐿𝐿𝐿𝐿𝐿𝐿
                                                                                                 ′
                                                                                                          � �.
                                                             𝑇𝑇ℎ
                                                       2
           We drop cases when simulated 𝜎𝜎�𝑥𝑥2 and 𝜎𝜎�𝑣𝑣,ℎ are negative. The bias is estimated by
                                                                                                          𝐵𝐵
                                         �������                                       �������      1
                         𝑏𝑏𝑏𝑏𝑏𝑏𝑠𝑠ℎ𝐿𝐿𝐿𝐿 ≡ 𝜉𝜉(𝜃𝜃            � �,
                                               𝑏𝑏 ) − 𝜉𝜉�𝜃𝜃             where          𝜉𝜉(𝜃𝜃 𝑏𝑏 ) ≡    � 𝜉𝜉(𝜃𝜃 𝑏𝑏 ).
                                                                                                    𝐵𝐵
                                                                                                         𝑏𝑏=1

           Finally, the bias-corrected estimator is given by
                                                                                          �������
                                        𝑠𝑠̂ℎ𝐿𝐿𝐿𝐿 = 𝜉𝜉�𝜃𝜃� � − 𝑏𝑏𝑏𝑏𝑏𝑏𝑠𝑠ℎ𝐿𝐿𝐿𝐿 = 2𝜉𝜉�𝜃𝜃� � − 𝜉𝜉(𝜃𝜃 𝑏𝑏 ).




                                                                                                                                     13
Appendix C. Finding a MA(∞) representation for a process driven by
multiple underlying shocks
Suppose the following data generating process as in Section II. In this section, we explain how an
infinite-order MA representation driven by a single white noise process is obtained for the residual
process Δ𝑝𝑝𝑡𝑡 + Δ𝑎𝑎𝑡𝑡 .
                                              𝑦𝑦𝑡𝑡 = 𝜓𝜓𝑥𝑥 (𝐿𝐿)𝑥𝑥𝑡𝑡 + 𝑧𝑧𝑡𝑡            where              𝑧𝑧𝑡𝑡 = 𝑝𝑝𝑡𝑡 + 𝑎𝑎𝑡𝑡 ,
                                                                                                   𝑝𝑝           𝑝𝑝
                                �Δ𝑝𝑝𝑡𝑡 − 𝑔𝑔𝑦𝑦 � = 𝜌𝜌𝑝𝑝 �Δ𝑝𝑝𝑡𝑡−1 − 𝑔𝑔𝑦𝑦 � + 𝜎𝜎𝑝𝑝 𝑒𝑒𝑡𝑡 ,                        𝑒𝑒𝑡𝑡 ~ 𝑖𝑖𝑖𝑖𝑖𝑖 𝑁𝑁(0,1),
                                                𝑎𝑎𝑡𝑡 = 𝜌𝜌𝑎𝑎 𝑎𝑎𝑡𝑡−1 + 𝜎𝜎𝑎𝑎 𝑒𝑒𝑡𝑡𝑎𝑎 ,              𝑒𝑒𝑡𝑡𝑎𝑎 ~ 𝑖𝑖𝑖𝑖𝑖𝑖 𝑁𝑁(0,1),
                                                                             𝑝𝑝
                       𝑥𝑥𝑡𝑡 ~ 𝑖𝑖𝑖𝑖𝑖𝑖 𝑁𝑁(0, 𝜎𝜎𝑥𝑥2 ),         and {𝑥𝑥𝑡𝑡 }, �𝑒𝑒𝑡𝑡 � and {𝑒𝑒𝑡𝑡𝑎𝑎 } are mutually independent.
             We first show why having a representation 𝑔𝑔𝑦𝑦 + 𝜓𝜓𝑒𝑒 (𝐿𝐿)𝑒𝑒𝑡𝑡 of Δ𝑝𝑝𝑡𝑡 + Δ𝑎𝑎𝑡𝑡 is needed. When
                                                                                        �t =
all three shocks are in the information set, then the corresponding forecast error with Ω
                  𝑝𝑝
{𝑥𝑥𝑡𝑡 , Δ𝑦𝑦𝑡𝑡 , 𝑒𝑒𝑡𝑡 , 𝑒𝑒𝑡𝑡𝑎𝑎 , … } is
                                  𝑓𝑓̃𝑡𝑡+ℎ|𝑡𝑡−1 = 𝑦𝑦𝑡𝑡+ℎ − E�𝑦𝑦𝑡𝑡+ℎ |Ω
                                                                    � 𝑡𝑡−1 � = 𝜓𝜓𝑥𝑥,0 𝑥𝑥𝑡𝑡+ℎ + ⋯ + 𝜓𝜓𝑥𝑥,ℎ 𝑥𝑥𝑡𝑡
                                         𝑝𝑝                            𝑝𝑝                                                           𝑝𝑝
                               +𝜎𝜎𝑝𝑝 𝑒𝑒𝑡𝑡+ℎ + �1 + 𝜌𝜌𝑝𝑝 �𝜎𝜎𝑝𝑝 𝑒𝑒𝑡𝑡+ℎ−1 + ⋯ + �1 + 𝜌𝜌𝑝𝑝 + ⋯ + 𝜌𝜌𝑝𝑝ℎ �𝜎𝜎𝑝𝑝 𝑒𝑒𝑡𝑡
                                                           𝑎𝑎                 𝑎𝑎
                                                  +𝜎𝜎𝑎𝑎 𝑒𝑒𝑡𝑡+ℎ + 𝜌𝜌𝑎𝑎 𝜎𝜎𝑎𝑎 𝑒𝑒𝑡𝑡+ℎ−1 + ⋯ + 𝜌𝜌𝑎𝑎ℎ 𝜎𝜎𝑎𝑎 𝑒𝑒𝑡𝑡𝑎𝑎 .
Then
                                                                            �∑ℎ𝑖𝑖=0 𝜓𝜓𝑥𝑥,𝑖𝑖
                                                                                      2
                                                                                            � 𝜎𝜎𝑥𝑥2
                                   𝑠𝑠̃ℎ =                                                               2                       .
                                                                                         𝑗𝑗
                                              �∑ℎ𝑖𝑖=0 𝜓𝜓𝑥𝑥,𝑖𝑖
                                                        2
                                                              � 𝜎𝜎𝑥𝑥2 + ∑ℎ𝑖𝑖=0�∑𝑖𝑖𝑗𝑗=0 𝜌𝜌𝑝𝑝 � 𝜎𝜎𝑝𝑝2 + ∑ℎ𝑖𝑖=0 𝜌𝜌𝑎𝑎2𝑖𝑖 𝜎𝜎𝑎𝑎2
             However, what we estimate in the simulations using Δ𝑦𝑦𝑡𝑡 and 𝑥𝑥𝑡𝑡 is 𝑠𝑠ℎ , not 𝑠𝑠̃ℎ . It is because
                                                   � 𝑡𝑡 . Because Ω𝑡𝑡 is coarser than Ω
our information set is Ω𝑡𝑡 , not the augmented one Ω                                  � 𝑡𝑡 , 𝑠𝑠ℎ ≤ 𝑠𝑠̃ℎ . To
obtain the true value of 𝑠𝑠ℎ , we need 𝜓𝜓𝑒𝑒 (𝐿𝐿) and 𝜎𝜎𝑒𝑒 .
             We use a stationary Kalman filter (Hamilton (1994), pp.391-394) to that end. We cast the
above process in a form of state-space representation.
State equation:
                                                                   𝑠𝑠𝑡𝑡 = 𝐹𝐹𝑠𝑠𝑡𝑡−1 + 𝐵𝐵𝐵𝐵𝑡𝑡 ,
                                                    where             𝑠𝑠𝑡𝑡 = (𝛥𝛥𝑝𝑝𝑡𝑡 − 𝑔𝑔𝑦𝑦 , 𝛥𝛥𝑎𝑎𝑡𝑡 , 𝑒𝑒𝑡𝑡𝑎𝑎 )′,
                                                                              𝑝𝑝            ′
                                                                𝑢𝑢𝑡𝑡 = �𝑒𝑒𝑡𝑡 , 𝑒𝑒𝑡𝑡𝑎𝑎 � ~(0, 𝐼𝐼),
                                                                   𝜌𝜌𝑝𝑝               0          0
                                                                F=�0                 𝜌𝜌𝑎𝑎       −𝜎𝜎𝑎𝑎 �,
                                                                    0                 0          0
                                                                                                                                         14
                                                        𝜎𝜎𝑝𝑝       0
                                                     B=�0         𝜎𝜎𝑎𝑎 �.
                                                         0         1
Measurement equation: Δ𝑧𝑧𝑡𝑡 = 𝑔𝑔𝑦𝑦 + 𝐻𝐻 ′ 𝑠𝑠𝑡𝑡               where          𝐻𝐻 = (1,1,0)′ .
         By defining 𝑄𝑄 = 𝐵𝐵𝐵𝐵𝐵𝐵′ = 𝐵𝐵𝐵𝐵′ and 𝑅𝑅 = 0, the stationary 𝑃𝑃 and 𝐾𝐾 are obtained from the
matrix equation (13.5.3) and (13.5.4) on Hamilton (1994).
                                   𝑃𝑃 = 𝐹𝐹[𝑃𝑃 − 𝑃𝑃𝑃𝑃(𝐻𝐻 ′ 𝑃𝑃𝑃𝑃 + 𝑅𝑅)−1 𝐻𝐻 ′ 𝑃𝑃]𝐹𝐹 ′ + 𝑄𝑄,
                                              𝐾𝐾 = 𝐹𝐹𝐹𝐹𝐹𝐹(𝐻𝐻 ′ 𝑃𝑃𝑃𝑃 + 𝑅𝑅)−1 .
This is a discrete time algebraic Riccati equation for 𝑃𝑃 which can be solved numerically. Then
deriving 𝐾𝐾 is straightforward from the second equation. Given 𝐾𝐾, it is known that
    Δ𝑧𝑧𝑡𝑡 = 𝑔𝑔𝑦𝑦 + (𝐼𝐼 + 𝐻𝐻 ′ (𝐼𝐼 − 𝐹𝐹𝐹𝐹)−1 𝐾𝐾𝐾𝐾)𝑒𝑒𝑡𝑡 ,      𝑒𝑒𝑡𝑡 ~𝑊𝑊𝑊𝑊(𝜎𝜎𝑒𝑒2 ),     and      𝜎𝜎𝑒𝑒 = √𝐻𝐻 ′ 𝑃𝑃𝑃𝑃 + 𝑅𝑅.
         To convert (𝐼𝐼 + 𝐻𝐻 ′ (𝐼𝐼 − 𝐹𝐹𝐹𝐹)−1 𝐾𝐾𝐾𝐾) into 𝜓𝜓𝑒𝑒 (𝐿𝐿), we use the identity that (𝐼𝐼 − 𝐹𝐹𝐹𝐹)−1 = 𝐼𝐼 +
𝐹𝐹𝐹𝐹 + 𝐹𝐹 2 𝐿𝐿2 + ⋯. Note all three eigenvalues of 𝐹𝐹, 𝜌𝜌𝑝𝑝 , 𝜌𝜌𝑎𝑎 and 0, are less than one in absolute values.
         Given the MA representation of Δ𝑧𝑧𝑡𝑡 , we can find 𝑠𝑠ℎ accordingly.
         In Section III.B, the model of Smets and Wouters (2007) is analyzed. We find the 𝑠𝑠ℎ under
the assumed information set in a similar way.




                                                                                                                        15
Appendix D. Unobservable Shocks and Measurement Errors
In some cases, an estimated structural shock is only a part of the true shock that can be identified
with high confidences. For example, unexplained innovations in the Federal Funds Rates from
Romer and Romer (2004) may be a part of the entire change in the monetary policy including
changes in members on the board of governors, change in institutional details, or regime shifts as
in the Volcker periods. Similarly, legislative tax changes identified from narratives by Romer and
Romer (2010) would be understood as a part of the whole fiscal policy shocks affecting the U.S.
economy. The measurement error is yet another potential issue. It is unavoidable in practical
studies, especially when shocks are generated from narratives like Ramey (2011) and Romer and
Romer (2010). In this section, we show that our approach can still provide interesting and
meaningful quantities, because the estimates can be understood as a conservative estimate of the
‘true’ estimates available only when all hidden confounding factors are observable.
              We decompose the true shock into two components 𝑥𝑥𝑡𝑡 = 𝑥𝑥𝑡𝑡𝑜𝑜 + 𝑥𝑥𝑡𝑡𝑢𝑢 . The superscript o means
observable, and u unobservable. We understand the vector process of two components has a
representation as
                                                            𝜎𝜎𝑜𝑜                   0
                                                𝑥𝑥𝑡𝑡𝑜𝑜
                                               � 𝑢𝑢 � = �                                    � 𝛿𝛿𝑡𝑡 ,
                                                𝑥𝑥𝑡𝑡     𝜌𝜌𝑜𝑜,𝑢𝑢 𝜎𝜎𝑢𝑢            2 𝜎𝜎
                                                                          �1 − 𝜌𝜌𝑜𝑜,𝑢𝑢 𝑢𝑢

                                                                           1/2                            1/2
where              𝛿𝛿𝑡𝑡 ~ 𝑤𝑤𝑤𝑤(𝐼𝐼2 ), 𝛿𝛿𝑡𝑡 ⊥ 𝑒𝑒𝑡𝑡 , 𝜎𝜎𝑜𝑜 = �𝑉𝑉𝑉𝑉𝑉𝑉(𝑥𝑥𝑡𝑡𝑜𝑜 )�     , 𝜎𝜎𝑢𝑢 = �𝑉𝑉𝑉𝑉𝑟𝑟(𝑥𝑥𝑡𝑡𝑢𝑢 )�     ,   and   𝜌𝜌𝑜𝑜,𝑢𝑢 =
𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐(𝑥𝑥𝑡𝑡𝑜𝑜 , 𝑥𝑥𝑡𝑡𝑢𝑢 ).
              Three different situations are possible for the sign of correlation between two components,
(1) 𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐(𝑥𝑥𝑡𝑡𝑜𝑜 , 𝑥𝑥𝑡𝑡𝑢𝑢 ) = 0: they are orthogonal, (2) 𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐(𝑥𝑥𝑡𝑡𝑜𝑜 , 𝑥𝑥𝑡𝑡𝑢𝑢 ) > 0: this might be the case when we
are able to observe only some parts of the true shock, and (3) 𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐(𝑥𝑥𝑡𝑡𝑜𝑜 , 𝑥𝑥𝑡𝑡𝑢𝑢 ) < 0: the presence of
measurement error 𝑚𝑚𝑡𝑡 might impose such a correlation structure, since 𝑥𝑥𝑡𝑡𝑜𝑜 = 𝑥𝑥𝑡𝑡 + 𝑚𝑚𝑡𝑡 , and 𝑥𝑥𝑡𝑡𝑢𝑢 =
−𝑚𝑚𝑡𝑡 . Narrative approaches might be exposed to such a concern.
              Our claim is that the suggested estimators have a negative asymptotic bias, regardless of
the sign of correlation between two components. 6 The population variance share can be written as
a fraction of the amount explained by the innovations in {𝑥𝑥𝑡𝑡 } to the variance of forecast error, 𝑠𝑠ℎ =



6
 All of our estimators have the same probability limit. So, the discussion in this section applies to R2, LP-A, and
LP-B estimators.

                                                                                                                               16
    ∑ℎ      2       2
     𝑖𝑖=0 𝜓𝜓𝑥𝑥,𝑖𝑖 𝜎𝜎𝑥𝑥
                         . We argue that there are (1) a positive asymptotic bias for the denominator, and (2) a
𝑉𝑉𝑉𝑉𝑉𝑉(𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 )

negative asymptotic bias for the numerator when we apply our method to {𝑥𝑥𝑡𝑡𝑜𝑜 } only while ignoring
the existence of {𝑥𝑥𝑡𝑡𝑢𝑢 }. Therefore, the estimated share can be understood as a conservative estimate
for the population quantity with the full information about {𝑥𝑥𝑡𝑡𝑜𝑜 } and {𝑥𝑥𝑡𝑡𝑢𝑢 }.
                Let’s start with the denominator. The first problem we encounter is about recovering the
forecast errors. It will be proven that the estimated forecast error without information on {𝑥𝑥𝑡𝑡𝑢𝑢 } will
have larger variances than the ‘true’ forecast error 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 . With the full information, we can back
out the forecast error as a difference between 𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 and its projected values on the
                                                          𝑜𝑜       𝑢𝑢                 𝑜𝑜       𝑢𝑢
information set at time 𝑡𝑡 − 1 where Ω𝑡𝑡−1 = {Δ𝑦𝑦𝑡𝑡−1 , 𝑥𝑥𝑡𝑡−1 , 𝑥𝑥𝑡𝑡−1 , Δ𝑦𝑦𝑡𝑡−2 , 𝑥𝑥𝑡𝑡−2 , 𝑥𝑥𝑡𝑡−2 , … } as
                                        𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 = 𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 − 𝐸𝐸(𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 |Ω𝑡𝑡−1 )
where the latter conditional expectation is the projection of 𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 on the closed subspace
spanned by Ω𝑡𝑡−1 . However, an econometrician has only Ω𝑒𝑒𝑡𝑡−1 = {𝑥𝑥𝑡𝑡−1
                                                                    𝑜𝑜                  𝑜𝑜
                                                                         , 𝛥𝛥𝑦𝑦𝑡𝑡−1 , 𝑥𝑥𝑡𝑡−2 , 𝛥𝛥𝑦𝑦𝑡𝑡−2 , … }. It is
evident that Ω𝑒𝑒𝑡𝑡 ⊂ Ω𝑡𝑡 . We define the closed subspaces spanned by variables in each information set as
                                                      𝑉𝑉𝑡𝑡 = 𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐(𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠(Ω𝑡𝑡 ) ),
                                                      𝑉𝑉𝑡𝑡𝑒𝑒 = 𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐�𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠(Ω𝑒𝑒𝑡𝑡 )�.
                We now compare the true forecast errors and identifiable ones to econometricians having
Ω𝑒𝑒𝑡𝑡−1 . By using a notation of 𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑡𝑡𝑡𝑡𝑡𝑡𝑡𝑡(𝑠𝑠|𝑆𝑆) to denote the population least square projection of
the element s on the closed subspace 𝑆𝑆, we can rewrite 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 as
𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 = 𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 − 𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃(𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 |𝑉𝑉𝑡𝑡−1 ) = 𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃(𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 |(𝑉𝑉𝑡𝑡−1 )⊥ )
where 𝑉𝑉𝑡𝑡⊥ is the orthogonal complement of 𝑉𝑉𝑡𝑡 .
                                                                          𝑒𝑒
                On the other hand, the econometrician’s forecast error 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 is given by
                   𝑒𝑒                                                                    𝑒𝑒 )                    𝑒𝑒
                𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 = 𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 − 𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃(𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 |𝑉𝑉𝑡𝑡−1  = 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 + 𝑟𝑟𝑡𝑡+ℎ|𝑡𝑡−1
                     𝑒𝑒                                                                                                   𝑒𝑒 ).
where             𝑟𝑟𝑡𝑡+ℎ|𝑡𝑡−1 ≡ 𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒𝑒(𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 |𝑉𝑉𝑡𝑡−1 ) − 𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃(𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 |𝑉𝑉𝑡𝑡−1
                                                               𝑒𝑒
                It is worth to mention that 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 and 𝑟𝑟𝑡𝑡+ℎ|𝑡𝑡−1 are orthogonal, because the first term is an
                                                                          𝑒𝑒
element of (𝑉𝑉𝑡𝑡−1 )⊥ , and the second of 𝑉𝑉𝑡𝑡−1 . 7 Therefore, 𝑉𝑉𝑉𝑉𝑉𝑉�𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 � = 𝑉𝑉𝑉𝑉𝑉𝑉�𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 � +



7
  This result is in fact due to a decomposition of the entire vector space, V, into a direct sum of three mutually
                                                         𝑒𝑒                       𝑒𝑒 )⊥ )
orthogonal closed subspaces as V = 𝑉𝑉𝑡𝑡−1                     ⊕ (𝑉𝑉𝑡𝑡−1 ∩ (𝑉𝑉𝑡𝑡−1          ⊕ (𝑉𝑉 ∩ (𝑉𝑉𝑡𝑡−1 )⊥ ), where the symbol ‘⊕’ means a
direct sum. From the representation, it directly follows that 𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 = 𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃(𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 |𝑉𝑉) =
                                         𝑒𝑒 )                                                      𝑒𝑒 )⊥ )
𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃(𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 |𝑉𝑉𝑡𝑡−1  + 𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃(𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 |𝑉𝑉𝑡𝑡−1 ∩ (𝑉𝑉𝑡𝑡−1     +

                                                                                                                                         17
          𝑒𝑒
𝑉𝑉𝑉𝑉𝑉𝑉�𝑟𝑟𝑡𝑡+ℎ|𝑡𝑡−1 � ≥ 𝑉𝑉𝑉𝑉𝑉𝑉�𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 �. Also, the equality holds only when 𝑥𝑥𝑡𝑡𝑢𝑢 and its lagged values have
                                                  𝑒𝑒
no additional power in explaining 𝑦𝑦𝑡𝑡+ℎ given 𝑉𝑉𝑡𝑡−1 implying 𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃(𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 |𝑉𝑉𝑡𝑡−1 ) =
                                         𝑒𝑒 ).
𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃(𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 |𝑉𝑉𝑡𝑡−1   This is not true except for some uninteresting special situations
such as 𝜓𝜓𝑥𝑥 (𝐿𝐿) = 0 or 𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐(𝑥𝑥𝑡𝑡𝑜𝑜 , 𝑥𝑥𝑡𝑡𝑢𝑢 ) = ±1.
             The second step is to show the econometrician’s numerator converges to a values less than
the true numerator in probability. The true numerator is ∑ℎ𝑖𝑖=0 𝜓𝜓𝑥𝑥,𝑖𝑖
                                                                  2
                                                                        𝜎𝜎𝑥𝑥2 as before. Defining 𝑋𝑋𝑡𝑡ℎ =
(𝑥𝑥𝑡𝑡+ℎ , … , 𝑥𝑥𝑡𝑡 )′ , we can write it as following:
                                                                   ′                 ′ −1
                                          𝐸𝐸�𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 ⋅ 𝑋𝑋𝑡𝑡ℎ �𝐸𝐸�𝑋𝑋𝑡𝑡ℎ 𝑋𝑋𝑡𝑡ℎ � 𝐸𝐸�𝑋𝑋𝑡𝑡ℎ ⋅ 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 �
                                                                       ′
                                   ′ −1                                                  ′                   ′ −1
             = �𝐸𝐸�𝑋𝑋𝑡𝑡ℎ 𝑋𝑋𝑡𝑡ℎ � 𝐸𝐸�𝑋𝑋𝑡𝑡ℎ ⋅ 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 �� �𝐸𝐸�𝑋𝑋𝑡𝑡ℎ 𝑋𝑋𝑡𝑡ℎ �� �𝐸𝐸�𝑋𝑋𝑡𝑡ℎ 𝑋𝑋𝑡𝑡ℎ � 𝐸𝐸�𝑋𝑋𝑡𝑡ℎ ⋅ 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 ��.

The term inside the last square bracket is a vector of population regression coefficients of 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1
                                                                                                                            ′
on 𝑋𝑋𝑡𝑡ℎ . By the specification, we know that it is equal to Ψ ℎ = �𝜓𝜓𝑥𝑥,0 , … , 𝜓𝜓𝑥𝑥,ℎ � .
                                                                                                                                              𝑒𝑒
             Now            we             investigate             the         econometrician’s                 numerator              𝐸𝐸 �𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 ⋅
      ′                         ′ −1
𝑋𝑋𝑡𝑡ℎ,𝑒𝑒 � 𝐸𝐸 �𝑋𝑋𝑡𝑡ℎ,𝑒𝑒 𝑋𝑋𝑡𝑡ℎ,𝑒𝑒 �        𝐸𝐸�𝑋𝑋𝑡𝑡ℎ,𝑒𝑒 ⋅ 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1
                                                           𝑒𝑒
                                                                    � where 𝑋𝑋𝑡𝑡ℎ,𝑒𝑒 = (𝑥𝑥𝑡𝑡+ℎ
                                                                                          𝑜𝑜                                𝑒𝑒
                                                                                               , … , 𝑥𝑥𝑡𝑡𝑜𝑜 )′ . Because 𝑟𝑟𝑡𝑡+ℎ|𝑡𝑡−1 =
                                                                           𝑒𝑒 )⊥ )
𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑐𝑐𝑡𝑡𝑡𝑡𝑡𝑡𝑡𝑡( 𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃(𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 |𝑉𝑉𝑡𝑡−1 ) | (𝑉𝑉𝑡𝑡−1           𝑒𝑒 )⊥
                                                                                   ∈ (𝑉𝑉𝑡𝑡−1                        ,       𝐸𝐸�𝑋𝑋𝑡𝑡ℎ,𝑒𝑒 ⋅ 𝑓𝑓𝑡𝑡+𝑡𝑡|𝑡𝑡−1
                                                                                                                                             𝑒𝑒
                                                                                                                                                       �=

𝐸𝐸�𝑋𝑋𝑡𝑡ℎ,𝑒𝑒 ⋅ 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 �. The corresponding projection coefficient is

                               ′ −1                                                  𝐶𝐶𝐶𝐶𝐶𝐶(𝑥𝑥𝑡𝑡𝑜𝑜 , 𝑥𝑥𝑡𝑡𝑢𝑢 )   �𝜎𝜎𝑜𝑜 + 𝜌𝜌𝑜𝑜,𝑢𝑢 ⋅ 𝜎𝜎𝑢𝑢 � ℎ
          𝐸𝐸 �𝑋𝑋𝑡𝑡ℎ,𝑒𝑒 𝑋𝑋𝑡𝑡ℎ,𝑒𝑒 �       𝐸𝐸�𝑋𝑋𝑡𝑡ℎ,𝑒𝑒 ⋅ 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 � = �1 +                          𝑜𝑜 ) � Ψ =
                                                                                                              ℎ
                                                                                                                                        Ψ .
                                                                                        𝑉𝑉𝑉𝑉𝑉𝑉(𝑥𝑥𝑡𝑡                     𝜎𝜎𝑜𝑜
We used the fact that 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 = ∑ℎ𝑖𝑖=0 𝜓𝜓𝑥𝑥,𝑖𝑖 𝑥𝑥𝑡𝑡+ℎ−𝑖𝑖 + ∑ℎ𝑖𝑖=0 ∑𝑖𝑖𝑗𝑗=0(𝜓𝜓𝑒𝑒.𝑗𝑗 ) 𝑒𝑒𝑡𝑡+ℎ−𝑖𝑖 .
             Finally, the econometrician’s numerator becomes
                              −1                                   ′
                          ′                                                              ′                          ′ −1
  �𝐸𝐸 �𝑋𝑋𝑡𝑡ℎ,𝑒𝑒   𝑋𝑋𝑡𝑡ℎ,𝑒𝑒 �        𝐸𝐸�𝑋𝑋𝑡𝑡ℎ,𝑒𝑒   ⋅ 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 �� �𝐸𝐸 �𝑋𝑋𝑡𝑡ℎ,𝑒𝑒 𝑋𝑋𝑡𝑡ℎ,𝑒𝑒 �� �𝐸𝐸 �𝑋𝑋𝑡𝑡ℎ,𝑒𝑒 𝑋𝑋𝑡𝑡ℎ,𝑒𝑒 �      𝐸𝐸�𝑋𝑋𝑡𝑡ℎ,𝑒𝑒 ⋅ 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 ��
                                                                                                       ℎ
                �𝜎𝜎𝑜𝑜 + 𝜌𝜌𝑜𝑜,𝑢𝑢 ⋅ 𝜎𝜎𝑢𝑢 � ℎ ′            �𝜎𝜎𝑜𝑜 + 𝜌𝜌𝑜𝑜,𝑢𝑢 ⋅ 𝜎𝜎𝑢𝑢 � ℎ       2                             2
              =                         𝛹𝛹 ⋅ 𝜎𝜎𝑜𝑜2 𝐼𝐼 ⋅                         𝛹𝛹 = � 𝜓𝜓𝑥𝑥,𝑖𝑖 �𝜎𝜎𝑜𝑜 + 𝜌𝜌𝑜𝑜,𝑢𝑢 ⋅ 𝜎𝜎𝑢𝑢 � .
                        𝜎𝜎𝑜𝑜                                    𝜎𝜎𝑜𝑜
                                                                                                      𝑖𝑖=0

Thus, any asymptotic bias in the numerators are from the differences between 𝜎𝜎𝑥𝑥2 and
                          2                                                      2
�𝜎𝜎𝑜𝑜 + 𝜌𝜌𝑜𝑜,𝑢𝑢 ⋅ 𝜎𝜎𝑢𝑢 � . Because 𝜎𝜎𝑥𝑥2 − �𝜎𝜎𝑜𝑜 + 𝜌𝜌𝑜𝑜,𝑢𝑢 ⋅ 𝜎𝜎𝑢𝑢 � = �1 − 𝜌𝜌𝑜𝑜,𝑢𝑢
                                                                             2
                                                                                   �𝜎𝜎𝑢𝑢2 ,



                                                                                                   𝑒𝑒 )      𝑒𝑒
𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃(𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 |𝑉𝑉 ∩ (𝑉𝑉𝑡𝑡−1 )⊥ ) = 𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃𝑃(𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 |𝑉𝑉𝑡𝑡−1  + 𝑟𝑟𝑡𝑡+ℎ|𝑡𝑡−1 + 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 , and the last three
terms are mutually orthogonal.

                                                                                                                                                      18
                                                             ′                 ′ −1
                                  𝐸𝐸�𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 ⋅ 𝑋𝑋𝑡𝑡ℎ �𝐸𝐸�𝑋𝑋𝑡𝑡ℎ 𝑋𝑋𝑡𝑡ℎ � 𝐸𝐸�𝑋𝑋𝑡𝑡ℎ ⋅ 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 �
                                                                                                         ℎ
                                       ′                         ′ −1
                  𝑒𝑒
         = 𝐸𝐸 �𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1 ⋅   𝑋𝑋𝑡𝑡ℎ,𝑒𝑒 � 𝐸𝐸 �𝑋𝑋𝑡𝑡ℎ,𝑒𝑒   𝑋𝑋𝑡𝑡ℎ,𝑒𝑒 �     𝐸𝐸�𝑋𝑋𝑡𝑡ℎ,𝑒𝑒        𝑒𝑒
                                                                                      ⋅ 𝑓𝑓𝑡𝑡+ℎ|𝑡𝑡−1         2
                                                                                                    � + � 𝜓𝜓𝑥𝑥,𝑖𝑖        2
                                                                                                                  �1 − 𝜌𝜌𝑜𝑜,𝑢𝑢 �𝜎𝜎𝑢𝑢2 .
                                                                                                        𝑖𝑖=0

          As claimed, the econometrician’s numerator is asymptotically less and denominator is
asymptotically greater than their full information counterparts. Thus, we have a negative
asymptotic bias. So, we can understand our method as a conservative estimator for the true 𝑠𝑠ℎ .
Moreover, the size of bias becomes small when the observed and unobserved parts are highly
correlated, or variance of the unobserved parts is small. In such a case, both biases for the
                      𝑒𝑒
denominator 𝑉𝑉𝑉𝑉𝑉𝑉�𝑟𝑟𝑡𝑡+ℎ|𝑡𝑡−1 �, and the numerator ∑ℎ𝑖𝑖=0 𝜓𝜓𝑥𝑥,𝑖𝑖
                                                             2            2
                                                                   �1 − 𝜌𝜌𝑜𝑜,𝑢𝑢 �𝜎𝜎𝑢𝑢2 are small. 8




8
  In the above, we assume that 𝑥𝑥𝑡𝑡𝑜𝑜 and 𝑥𝑥𝑡𝑡𝑢𝑢 have the sample impulse response polynomial 𝜓𝜓𝑥𝑥 (𝐿𝐿) for simplicity. Instead,
we may consider 𝜓𝜓𝑥𝑥𝑜𝑜 (𝐿𝐿)𝑥𝑥𝑡𝑡𝑜𝑜 + 𝜓𝜓𝑥𝑥𝑢𝑢 (𝐿𝐿)𝑥𝑥𝑡𝑡𝑢𝑢 . This does not change our result, and the above derivations admit a straight-
forward extension to the general case. In such a case, the difference between two numerators becomes
         𝑢𝑢 2
∑ℎ𝑖𝑖=0�𝜓𝜓𝑥𝑥,𝑖𝑖          2
               � �1 − 𝜌𝜌𝑜𝑜,𝑢𝑢 �𝜎𝜎𝑢𝑢2 . Therefore, we can conclude that if the unobservable component has a less contribution to
the endogenous variable than the observable component, the bias in the numerator would be small.

                                                                                                                                          19
Appendix E. Supplementary Figures for Univariate Simulations

Details on VAR-based Bootstrap
We first choose 𝐿𝐿𝑉𝑉𝑉𝑉𝑉𝑉 using the HQIC. VAR models for (𝑥𝑥𝑡𝑡 , Δ𝑦𝑦𝑡𝑡 )′ are estimated for different lag
lengths between 1 and 10. The information criterion is given by
                                                               2𝑘𝑘 log(log(𝑇𝑇))
                                          log(𝑑𝑑𝑑𝑑𝑑𝑑(𝑉𝑉)) +
                                                                      𝑇𝑇
where 𝑉𝑉 is the estimated variance matrix of the reduced-form residual process, 𝑘𝑘 is the number of
parameters, in this bi-variate case, 4 times lag length, and 𝑇𝑇 is the sample size. For a fair comparison,
we adjust the initial observation across 𝐿𝐿𝑉𝑉𝑉𝑉𝑉𝑉 and make the effective sample sizes same. Once it is
selected as a minimizer of the HQIC, both 𝐿𝐿𝑥𝑥 and 𝐿𝐿𝑦𝑦 are set to 𝐿𝐿𝑉𝑉𝑉𝑉𝑉𝑉 .
         We use the estimated 𝑉𝑉𝑉𝑉𝑉𝑉(𝐿𝐿𝑉𝑉𝑉𝑉𝑉𝑉 ) model to bootstrap. First of all, we randomly choose 𝑡𝑡
                                                                                   ′
between 1 and 𝑇𝑇 − 𝐿𝐿𝑉𝑉𝑉𝑉𝑉𝑉 . Then (𝑥𝑥𝑡𝑡 , Δ𝑦𝑦𝑡𝑡 )′ , … , �𝑥𝑥𝑡𝑡+𝐿𝐿𝑉𝑉𝑉𝑉𝑉𝑉 , Δ𝑦𝑦𝑡𝑡+𝐿𝐿𝑉𝑉𝑉𝑉𝑉𝑉 � are used as an initial condition
when simulating the bootstrapped time series.
         Second, we randomly draw the reduced form residuals with replacement. Using the
estimated model with the above initial conditions and shuffled residuals, artificial data points are
generated. The first 𝑇𝑇𝐵𝐵𝐵𝐵𝐵𝐵𝐵𝐵𝐵𝐵 number of observations are discarded as burn-in. 𝑇𝑇𝐵𝐵𝐵𝐵𝐵𝐵𝐵𝐵𝐵𝐵𝐵𝐵 = 100 in all
simulations.
         We apply our estimators to the bootstrapped time series obtaining 𝑠𝑠̂ℎ𝑅𝑅2,𝑏𝑏 , 𝑠𝑠̂ℎ𝐿𝐿𝐿𝐿𝐿𝐿,𝑏𝑏 , and 𝑠𝑠̂ℎ𝐿𝐿𝐿𝐿𝐿𝐿,𝑏𝑏
for 𝑏𝑏 = 1, … , 2000. Given 𝑠𝑠̂ℎ𝑉𝑉𝑉𝑉𝑉𝑉 obtained from the estimated 𝑉𝑉𝑉𝑉𝑉𝑉(𝐿𝐿𝑉𝑉𝑉𝑉𝑉𝑉 ) model, the biases for
local projection-based estimators are obtained by
                                                      𝐵𝐵
                                                  1
                                                     � 𝑠𝑠̂ℎ𝑚𝑚,𝑏𝑏 − 𝑠𝑠̂ℎ𝑉𝑉𝑉𝑉𝑉𝑉
                                                  𝐵𝐵
                                                     𝑏𝑏=1

for 𝑚𝑚 = 𝑅𝑅2, 𝐿𝐿𝐿𝐿𝐿𝐿, and 𝐿𝐿𝐿𝐿𝐿𝐿.
         For other details regarding simulations, see Section III.




                                                                                                                         20
How to read the legend:
   1. Impulse response
       -   The 90% bands are based on 5% and 95% quantiles of estimates across 2,000
           replications.


   2. Variance decomposition, Coverage probability, and Root MSE
   -   ‘R2-VAR’ means the bias-corrected R2 estimator by bootstrapping an estimated VAR
       model. Its standard error is the standard deviation across bootstrap estimates.
   -   ‘R2-Sim’ uses the method discussed in Appendix B. The coverage probability is based
       on the asymptotic standard error with pre-whitening as discussed in Appendix B.
   -   ‘R2’ denotes for the estimator without any finite sample correction. It uses the same
       standard error as ‘R2-VAR.’
   -   ‘LP A/B-VAR’, ‘LP A/B-Sim’, ‘LP A/B’, ‘VAR-VAR’, and ‘VAR’ are defined
       similarly.




                                                                                               21
DGP 1, T = 160.




                  22
DGP1, T = 500.




                 23
DGP2, T = 160.




                 24
DGP2, T= 500.




                25
DGP3, T = 160, VAR(HQIC).




                            26
DGP3, T = 160, VAR(5).




                         27
DGP3, T = 160, VAR(10).




                          28
DGP3, T = 500, VAR(HQIC).




                            29
Appendix F. Supplementary Figures for Multivariate Simulations

For details regarding simulations, see Section III.
How to read the legend:
   1. Impulse response
       -   The 90% bands are based on 5% and 95% quantiles of estimates across 2,000
           replications.


   2. Variance decomposition, Coverage probability, and Root MSE
       -   ‘R2-VAR’ means the bias-corrected R2 estimator by bootstrapping an estimated VAR
           model. Its standard error is the standard deviation across bootstrap estimates.
       -    ‘R2-Sim’ uses the method discussed in Appendix B. The coverage probability is
           based on the asymptotic standard error with pre-whitening as discussed in Appendix
           B.
       -    ‘R2’ denotes for the estimator without any finite sample correction. It uses the same
           standard error as ‘R2-VAR.’
       -   ‘LP A/B-VAR’, ‘LP A/B-Sim’, ‘LP A/B’, ‘VAR-VAR’, and ‘VAR’ are defined
           similarly.




                                                                                                30
Real GDP and monetary policy shock, T = 160




                                              31
Real GDP and monetary policy shock, T = 500.




                                               32
Price inflation and monetary policy shock, T = 160




                                                     33
Price inflation and monetary policy shock, T = 500.




                                                      34
Appendix G. Applications to Real GDP and Inflation
For the LP method, we use different local projections for bias-correction depending on whether
the estimated VAR or simulations are used. For example, suppose that 𝑥𝑥𝑡𝑡 is the monetary policy
shock, and 𝑦𝑦𝑡𝑡 is the real GDP. When we bootstrap the estimated VAR, the following local
projection is estimated to have bootstrap impulse responses.
                                                                     3
                     b
                   𝑦𝑦𝑡𝑡+ℎ   −     b
                                𝑦𝑦𝑡𝑡−1   = 𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐 + � 𝛽𝛽𝑖𝑖ℎ 𝑥𝑥𝑡𝑡−𝑖𝑖
                                                                        b
                                                                              + 𝐶𝐶0,1 ⋅ 𝑇𝑇𝑇𝑇𝑇𝑇𝑡𝑡𝑏𝑏 + 𝐶𝐶0,2 ⋅ 𝑜𝑜𝑜𝑜𝑜𝑜𝑜𝑜𝑜𝑜𝑜𝑜 𝑔𝑔𝑔𝑔𝑔𝑔𝑔𝑔𝑔𝑔ℎ𝑏𝑏𝑡𝑡
                                                                   𝑖𝑖=0
                                                                                    3
                                                                                       𝑏𝑏      ′
                                            + 𝐶𝐶0,3 ⋅   𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖b𝑡𝑡   + ��𝐶𝐶𝑡𝑡−𝑖𝑖 � 𝛤𝛤𝑖𝑖ℎ + 𝑟𝑟𝑡𝑡+ℎ|𝑡𝑡−1
                                                                                                         𝑏𝑏
                                                                                                                  ,
                                                                                   𝑖𝑖=1

where 𝐶𝐶𝑡𝑡 includes 𝑇𝑇𝑇𝑇𝑃𝑃𝑡𝑡 , 𝑜𝑜𝑜𝑜𝑜𝑜𝑜𝑜𝑜𝑜𝑜𝑜 𝑔𝑔𝑔𝑔𝑔𝑔𝑔𝑔𝑔𝑔ℎ𝑡𝑡 , 𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑛𝑛𝑡𝑡 and 𝑓𝑓𝑓𝑓𝑓𝑓𝑓𝑓𝑓𝑓𝑓𝑓𝑓𝑓 𝑓𝑓𝑓𝑓𝑓𝑓𝑓𝑓𝑓𝑓 𝑟𝑟𝑟𝑟𝑟𝑟𝑒𝑒𝑡𝑡 . It corresponds
to VAR(4) with the vector of TFP, output growth, inflation, monetary policy shock, and federal
funds rate.
           On the other hand, we cannot include many variables when we need asymptotic (joint)
variance estimated. In this case, the following regression is estimated.
      b        b
    𝑦𝑦𝑡𝑡+ℎ − 𝑦𝑦𝑡𝑡−1 = 𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐 + 𝛽𝛽0ℎ 𝑥𝑥𝑡𝑡b + 𝐶𝐶0,1 ⋅ 𝑇𝑇𝑇𝑇𝑇𝑇𝑡𝑡𝑏𝑏 + 𝐶𝐶0,2 ⋅ 𝑜𝑜𝑜𝑜𝑜𝑜𝑜𝑜𝑜𝑜𝑜𝑜 𝑔𝑔𝑔𝑔𝑔𝑔𝑔𝑔𝑔𝑔ℎ𝑏𝑏𝑡𝑡 + 𝐶𝐶0,3 ⋅ 𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑎𝑎𝑡𝑡𝑡𝑡𝑡𝑡𝑡𝑡b𝑡𝑡
                                 𝑏𝑏
                            + 𝑟𝑟𝑡𝑡+ℎ|𝑡𝑡−1 .
In a similar logic, it corresponds to VAR(1) with the same ordering. Therefore, we preserve the
assumed ordering of variables in both cases.
           When 𝑥𝑥𝑡𝑡 is 𝑇𝑇𝑇𝑇𝑃𝑃𝑡𝑡 , 𝑥𝑥𝑡𝑡 is the only time t variables on the right-hand side making it consistent
to the ordering.
           Figures below show the results for simulation based bias-corrections. Results are similar
to VAR-based ones.




                                                                                                                                                  35
1969:Q1-2007:Q4. Real GDP.


                        Impulse Response, VAR                                       Impulse Response, LP
          5                                                     10



          0                                                       0



         -5                                                    -10
              0           5           10             15   20          0             5             10          15   20

                  Variance Decomposition, VAR-VAR
        0.6
                                                                                            TFP
        0.4
                                                                                            TFP 90% CB
        0.2
                                                                                            MP
          0                                                                                 MP 90% CB

       -0.2
              0           5           10             15   20

                   Variance Decomposition, R2-VAR                         Variance Decomposition, R2-Simulation
        0.6                                                    0.6

        0.4                                                    0.4

        0.2                                                    0.2

          0                                                       0

       -0.2                                                    -0.2
              0           5          10              15   20          0             5             10          15   20

                  Variance Decomposition, LP-A-VAR                    Variance Decomposition, LP-A-Simulation
        0.6                                                    0.6

        0.4                                                    0.4

        0.2                                                    0.2

          0                                                       0

       -0.2                                                    -0.2
              0           5          10              15   20          0             5             10          15   20

                  Variance Decomposition, LP-B-VAR                    Variance Decomposition, LP-B-Simulation
        0.6                                                    0.6

        0.4                                                    0.4

        0.2                                                    0.2

          0                                                       0

       -0.2                                                    -0.2
              0           5          10              15   20          0             5             10          15   20




                                                                                                                        36
1969:Q1-2007:Q4, Inflation.


                         Impulse Response, VAR                                       Impulse Response, LP
         0.5                                                       2



           0                                                       0



        -0.5                                                      -2
               0           5           10             15   20          0             5              10         15   20

                   Variance Decomposition, VAR-VAR
         0.8
         0.6
                                                                                              TFP
         0.4
                                                                                              TFP 90% CB
         0.2
                                                                                              MP
           0
                                                                                              MP 90% CB
        -0.2
               0           5           10             15   20

                    Variance Decomposition, R2-VAR                         Variance Decomposition, R2-Simulation
         0.8                                                    0.8
         0.6                                                    0.6
         0.4                                                    0.4
         0.2                                                    0.2
           0                                                       0
        -0.2                                                    -0.2
               0           5           10             15   20          0             5              10         15   20

                   Variance Decomposition, LP-A-VAR                    Variance Decomposition, LP-A-Simulation
         0.8                                                    0.8
         0.6                                                    0.6
         0.4                                                    0.4
         0.2                                                    0.2
           0                                                       0
        -0.2                                                    -0.2
               0           5          10              15   20          0             5              10         15   20

                   Variance Decomposition, LP-B-VAR                    Variance Decomposition, LP-B-Simulation
         0.8                                                    0.8
         0.6                                                    0.6
         0.4                                                    0.4
         0.2                                                    0.2
           0                                                       0
        -0.2                                                    -0.2
               0           5          10              15   20          0             5              10         15   20




                                                                                                                         37
References
Andrews, Donald W.K., and J. Christopher Monahan, 1992. "An improved heteroskedasticity and
       autocorrelation consistent covariance matrix estimator." Econometrica, 60(4): 953-966.
Brockwell, Peter J., and Richard A. Davis, 1991, Time series: theory and methods. Springer
       Science & Business Media.
Conway, John B., 1990. A course in functional analysis. Vol. 96. Springer Science & Business
       Media.
Hamilton, James D., 1994. Time series analysis. Princeton: Princeton university press.
Hansen, Lars Peter, 1982. "Large sample properties of generalized method of moments
       estimators." Econometrica, 50(4): 1029-1054.
Jordà, Oscar, 2005. “Estimation and Inference of Impulse Responses by Local Projections,”
       American Economic Review, 95(1): 161–182.
Ramey, Valerie A., 2011. "Identifying Government Spending Shocks: It's all in the Timing,"
       Quarterly Journal of Economics, 126(1): 1–50.
Romer, Christina, D., and David H. Romer, 2004. "A New Measure of Monetary Shocks:
       Derivation and Implications," American Economic Review, 94(4): 1055-1084.
Romer, Christina D., and David H. Romer, 2010. "The Macroeconomic Effects of Tax Changes:
       Estimates Based on a New Measure of Fiscal Shocks," American Economic Review,
       100(3): 763-801.
Stock, James H., and Mark W. Watson, 2011. Introduction to Econometrics, 3/E. Boston:
       Addison Wesley.
Whitney K. Newey and Kenneth D. West, 1987. "A Simple, Positive Semi-Definite,
       Heteroskedasticity        and        Autocorrelation        Consistent        Covariance
       Matrix." Econometrica, 55(3): 703-708.




                                                                                                38
