                                NBER WORKING PAPER SERIES




           MAXIMUM LIKELIHOOD ESTIMATION OF THE EQUITY PREMIUM

                                          Efstathios Avdis
                                         Jessica A. Wachter

                                        Working Paper 19684
                                http://www.nber.org/papers/w19684


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                    November 2013




We are grateful to Kenneth Ahern, John Campbell, John Cochrane, Frank Diebold, Greg Duffee, Ian
Dew- Becker, Adlai Fisher, Robert Hall, Soohun Kim, Ilaria Piatti, Jonathan Wright, Motohiro Yogo
and seminar participants at the University of Alberta, the Wharton School, the NBER Forecasting
& Empirical Methods Workshop, the SFS Cavalcade, the SoFiE Conference and the EFA Conference
for helpful comments. The views expressed herein are those of the authors and do not necessarily reflect
the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2013 by Efstathios Avdis and Jessica A. Wachter. All rights reserved. Short sections of text, not
to exceed two paragraphs, may be quoted without explicit permission provided that full credit, including
© notice, is given to the source.
Maximum likelihood estimation of the equity premium
Efstathios Avdis and Jessica A. Wachter
NBER Working Paper No. 19684
November 2013, Revised September 2015
JEL No. C32,C58,G11,G12

                                              ABSTRACT

The equity premium, namely the expected return on the aggregate stock market less the government
bill rate, is of central importance to the portfolio allocation of individuals, to the investment decisions
of firms, and to model calibration and testing. This quantity is usually estimated from the sample average
excess return. We propose an alternative estimator, based on maximum likelihood, that takes into account
information contained in dividends and prices. Applied to the postwar sample, our method leads to
an economically significant reduction from 6.4% to 5.1%. Simulation results show that our method
produces tighter estimates under a range of specifications.


Efstathios Avdis
University of Alberta
3-30B Business
Edmonton, AB
Canada T6G 2R6
avdis@ualberta.ca

Jessica A. Wachter
Department of Finance
2300 SH-DH
The Wharton School
University of Pennsylvania
3620 Locust Walk
Philadelphia, PA 19104
and NBER
jwachter@wharton.upenn.edu
1         Introduction
The equity premium, namely the expected return on equities less the risk-
free rate, is an important economic quantity for many reasons. It is an input
into the decision process of individual investors as they determine their asset
allocation between stocks and bonds. It is also a part of cost-of-capital calcu-
lations and thus investment decisions by firms. Finally, financial economists
use it to calibrate and to test, both formally and informally, models of asset
pricing and of the macroeconomy.1
        The equity premium is usually estimated by taking the sample mean of
stock returns and subtracting a measure of the riskfree rate such as the average
Treasury Bill return. As is well known (Merton, 1980), it is difficult to estimate
the mean of a stochastic process. If one is computing the sample average, a
tighter estimate can be obtained only by extending the data series in time
which has the disadvantage that the data are potentially less relevant to the
present day.
        Given the challenge in estimating sample means, it is not surprising that
a number of studies investigate how to estimate the equity premium using
techniques other than taking the sample average. These include making use of
survey evidence (Claus and Thomas, 2001; Graham and Harvey, 2005; Welch,
2000), data on the cross section (Polk, Thompson, and Vuolteenaho, 2006),
and data on stock return volatility (Pástor and Stambaugh, 2001). The branch
of the literature most closely related to our work uses the accounting identity
that links prices, dividends, and returns (Blanchard, 1993; Constantinides,
2002; Fama and French, 2002; Donaldson, Kamstra, and Kramer, 2010). The
idea is simple in principle, but the implementation is inherently complicated by
    1
        See, for example, the classic paper of Mehra and Prescott (1985), and surveys such
as Kocherlakota (1996), Campbell (2003), Mehra and Prescott (2003), DeLong and Magin
(2009).




                                              1
the fact that the formula for returns is additive, while incorporating estimates
of future dividend growth requires multi-year discount rates which are multi-
plicative.2 As DeLong and Magin (2009) discuss in a survey of the literature,
it is not clear why such methods would necessarily improve the estimation of
the equity premium.
       In this paper, we propose a method of estimating the equity premium that
incorporates additional information contained in the time series of prices and
dividends in a simple and econometrically-motivated way. Like the papers
above, our work relies on a long-run relation between prices, returns and divi-
dends. However, our implementation is quite different, and grows directly out
of maximum likelihood estimation of autoregressive processes. First, we show
that our method yields an economically significant difference in the estimation
of the equity premium. Taking the sample average of monthly log returns
and subtracting the monthly log return on the Treasury bill over the postwar
period implies a monthly equity premium of 0.43%. Our maximum likelihood
approach implies an equity premium of 0.32%. In annual terms, these translate
to 5.2% and 3.9% respectively. Assuming that returns are approximately log-
normally distributed, we can also derive implications for the equity premium
computed in levels: in monthly terms the sample average implies an equity
premium of 0.53%, or 6.37% per annum, while maximum likelihood implies an
equity premium of 0.42% per month, or 5.06% per annum.
       Besides showing that our method yields economically significant differ-
ences, we also perform a Monte Carlo experiment to demonstrate that, in
finite samples and under a number of different assumptions on the data gener-
ating process, the maximum likelihood method is substantially less noisy than
the sample average. For example, under our benchmark simulation, the sam-
   2
       Fama and French (2002) have a relatively simple implementation in which they replace
price appreciation by dividend growth in the expected return equation. We will discuss their
paper in more detail in what follows.




                                              2
ple average has a standard error of 0.089%, while our estimator has a standard
error of only 0.050%.
   Further, we derive formulas that give the intuition for our results. Max-
imum likelihood allows additional information to be extracted from the time
series of the dividend-price ratio. This additional information implies that
shocks to the dividend-price ratio have on average been negative. In contrast,
ordinary least squares (OLS) implies that the shocks are zero on average by
definition. Because shocks to the dividend-price ratio are negatively corre-
lated with shocks to returns, our results imply that shocks to returns must
have been positive over the time period. Thus maximum likelihood implies an
equity premium that is below the sample average. Not surprisingly, given this
intuition, we show by Monte Carlo simulations that the effect of our procedure
is stronger, the more persistent the predictor variable.
   The remainder of our paper proceeds as follows. Section 2 describes our
statistical model and estimation procedure. Section 3 describes our results.
Section 4 describes the intuition for our efficiency results and how these re-
sults depend on the parameters of the data generating process. Section 5 shows
the applicability of our procedure under alternative data generating processes.
First, we show how to adapt our procedure to account for conditional het-
eroskedasticity. Second, we consider the performance of our estimation proce-
dure from Section 2 when the likelihood function is mis-specified in important
ways. Third, we consider the implications of structural breaks for our analysis.
Section 6 concludes.




                                       3
2         Statistical Model and Estimation

2.1         Statistical model
Let Rt+1 denote net returns on an equity index between t and t + 1, and Rf,t+1
denote net riskfree returns between t and t + 1. We let rt+1 = log(1 + Rt+1 ) −
log(1 + Rf,t+1 ). Let xt denote the log of the dividend-price ratio. We assume

                               rt+1 − µr = β(xt − µx ) + ut+1                              (1a)
                               xt+1 − µx = θ(xt − µx ) + vt+1 ,                           (1b)

where, conditional on (r1 , . . . , rt , x0 , . . . , xt ), the vector of shocks [ut+1 , vt+1 ]>
is normally distributed with zero mean and covariance matrix
                                           
                                      2
                                    σu σuv
                             Σ=            .
                                          2
                                    σuv σv
We assume that the dividend-price ratio follows a stationary process, namely,
that θ < 1; later we discuss the implications of relaxing this assumption.
Note that our assumptions on the shocks imply that µr is the equity premium
and that µx is the mean of xt . While we focus on the case that the shocks
are normally distributed and iid, we also explore robustness to alternative
distributional assumptions.
        Equations (1a) and (1b) for the return and predictor processes are standard
in the literature. Indeed, the equation for returns is equivalent to the ordi-
nary least squares regression that has been a focus of measuring predictability
in stock returns for almost 30 years (Keim and Stambaugh, 1986; Fama and
French, 1989). We have simply rearranged the parameters so that the mean
excess return µr appears explicitly. The stationary first-order autoregression
for xt is standard in settings where modeling xt is necessary, e.g. understanding
long-horizon returns or the statistical properties of estimators for β.3 Indeed,
    3
        See for example Campbell and Viceira (1999), Barberis (2000), Fama and French (2002),
Lewellen (2004), Cochrane (2008), Van Binsbergen and Koijen (2010).



                                               4
most leading economic models imply that xt is stationary (e.g. Bansal and
Yaron, 2004; Campbell and Cochrane, 1999). A large and sophisticated liter-
ature uses this setting to explore the bias and size distortions in estimation
of β, treating other parameters, including µr , as “nuisance” parameters.4 Our
work differs from this literature in that µr is not a nuisance parameter but
rather the focus of our study.


2.2       Estimation procedure
We estimate the parameters µr , µx , β, θ, σu2 , σv2 and σuv by maximum like-
lihood. The assumption on the shocks implies that, conditional on the first
observation x0 , the likelihood function is given by

  p (r1 , . . . , rT ; x1 , . . . , xT |µr , µx , β, θ, Σ, x0 ) =
                                    (                T               T              T
                                                                                         !)
                                                 2 X                             2 X
                         T               1    σ                 σ uv
                                                                     X         σ
              |2πΣ|− 2 exp −                     v
                                                        u2 − 2          ut vt + u     v2    . (2)
                                         2 |Σ| t=1 t            |Σ| t=1        |Σ| t=1 t

Maximizing this likelihood function is equivalent to running ordinary least
squares regression. Not surprisingly, maximizing the above requires choosing
means and predictive coefficients to minimize the sum of squares of ut and vt .
       This likelihood function, however, ignores the information contained in the
initial draw x0 . For this reason, studies have proposed a likelihood function
that incorporates the first observation (Box and Tiao, 1973; Poirier, 1978),
   4
       See for example Bekaert, Hodrick, and Marshall (1997), Campbell and Yogo (2006),
Nelson and Kim (1993), and Stambaugh (1999) for discussions on the bias in estimation of
β and Cavanagh, Elliott, and Stock (1995), Elliott and Stock (1994), Jansson and Moreira
(2006), Torous, Valkanov, and Yan (2004) and Ferson, Sarkissian, and Simin (2003) for
discussion of size. Campbell (2006) surveys this literature. There is a connection between
estimation of the mean and of the predictive coefficient, in that the bias in β arises from the
bias in θ (Stambaugh, 1999), which ultimately arises from the need to estimate µx (Andrews,
1993).




                                               5
assuming that it is a draw from the stationary distribution. In our case, the
stationary distribution of x0 is normal with mean µx and variance
                                                   σv2
                                         σx2 =          ,
                                                 1 − θ2
(Hamilton, 1994). The resulting likelihood function is

  p (r1 , . . . , rT ; x0 , . . . , xT |µr , µx , β, θ, Σ) =
                                                    (                  2 )
                                           − 1           1   x 0  − µ x
                                  2πσx2 2 exp −
                                         
                                                                             ×
                                                         2       σx
                                    (                T                 T              T
                                                                                           !)
                       − T2              1 σv2 X 2               σuv X           σu2 X 2
              |2πΣ| exp −                               u −2             ut vt +        v     . (3)
                                         2 |Σ| t=1 t             |Σ| t=1         |Σ| t=1 t
We follow Box and Tiao in referring to (2) as the conditional likelihood and
(3) as the exact likelihood. Recent work that makes use of the exact likelihood
in predictive regressions includes Stambaugh (1999) and Wachter and Waru-
sawitharana (2009, 2012), who focus on estimation of the predictive coefficient
β.5 Other previous studies have focused on the effect of incorporating this
first term (referred to as the initial condition) on unit root tests (Elliott, 1999;
Müller and Elliott, 2003).6
       We derive the values of µr , µx , β, θ, σu2 , σv2 and σuv that maximize the
likelihood (3) by solving a set of first-order conditions. We give closed-form
expressions for each maximum likelihood estimate in Appendix A. Our so-
lution amounts to solving a polynomial for the autoregressive coefficient θ,
after which the solution of every other parameter unravels easily. Because
our method does not require numerical optimization, it is computationally ex-
pedient. In what follows, we refer to this procedure as maximum likelihood
   5
       Wachter and Warusawitharana (2009, 2012) use Bayesian methods rather than maxi-
mum likelihood.
  6
    We could extend our results to multiple predictor variables (Kelly and Pruitt (2013), for
example, allow multiple valuation ratios to predict returns), though to keep this manuscript
of manageable size, we do not do so here. The likelihood function in (3) admits a general-
ization to multiple predictors, as can be found in Hamilton (1994).



                                                 6
estimation (MLE) even when we examine cases in which it is mis-specified.
Depending on the context, we may also refer to it as our benchmark proce-
dure.
       In this paper, we compare estimating the equity premium using maximum
likelihood versus the sample mean.7 Given that our goal is to estimate µr ,
which is a parameter determining the marginal distribution of returns, why
might it be beneficial to jointly estimate a process for returns and for the
dividend-price ratio? Here, we give a general answer to this question, and go
further into specifics in Section 4. First, a standard result in econometrics says
that maximum likelihood, assuming that the specification is correct, provides
the most efficient estimates of the parameters, that is, the estimates with the
(weakly) smallest asymptotic standard errors (Amemiya, 1985). Furthermore,
in large samples, and assuming no mis-specification, introducing more data
makes inference more reliable rather than less. Thus the value of µr that max-
imizes the likelihood function (3) should be (asymptotically) more efficient
than the sample mean because it is a maximum likelihood estimator and be-
cause it incorporates more data than a simpler likelihood function based only
on the unconditional distribution of the return rt .
       This reasoning holds asymptotically as the sample size grows large. Several
practical considerations might be expected to work against this reasoning in
finite samples. First, one might ask whether maximum likelihood delivers a
substantively different, and more reliable, estimator than the sample mean.
The asymptotic results say only that maximum likelihood is better (or, tech-
nically, at least as good), but the difference may be negligible. Second, even
if there is an improvement in asymptotic efficiency for maximum likelihood, it
   7
       Another point of comparison is the estimate of the mean return from the conditional
likelihood (2). Simulation results show that this estimator is less efficient than both the
estimator from the exact likelihood and the sample mean. Additional information in regards
to this estimator is available from the authors upon request.




                                             7
could easily be outweighed in practice by the need to estimate a more compli-
cated system. Finally, estimation of the equity premium by the sample mean
does not require specification of the predictor process. Mis-specification in the
process for dividend-price ratio could outweigh the benefits from maximum
likelihood. These questions motivate the analysis that follows.


2.3    Data
We calculate maximum likelihood estimates of the parameters in our predictive
system for the excess return of the value-weighted market portfolio from CRSP.
Recall that our object of interest is rt , the logarithm of the gross return in
excess of the riskfree asset: rt = log(1 + Rt ) − log(1 + Rtf ). We take Rt to
be the monthly net return of the value-weighted market portfolio and Rtf to
be the monthly net return of the 30-day Treasury Bill. We use the standard
construction for the dividend-price ratio that eliminates seasonality, namely,
we divide a monthly dividend series (constructed by summing over dividend
payouts over the current month and previous eleven months) by the price.



3     Results

3.1    Point estimates
Table 1 reports estimates of the parameters of our statistical model given in
(1). We report estimates for the 1927-2011 sample and for the 1953-2011
postwar subsample. For the postwar subsample, the equity premium from
MLE is 0.322% in monthly terms and 3.86% per annum. In contrast, the
sample average (given under the column labeled “OLS”) is 0.433% in monthly
terms, or 5.20% per annum. The annualized difference is 133 basis points.
Applying MLE to the 1927–2011 sample yields an estimated mean of 4.69%
per annum, 88 basis points lower than the sample average.


                                       8
       Table 1 also reports results for maximum likelihood estimation of the pre-
dictive coefficient β, the autoregressive coefficient θ, and the standard devi-
ations and correlation between the shocks. The estimation of the standard
deviations and correlation are nearly identical across the two methods, not
surprisingly, because these can be estimated precisely in monthly data. Esti-
mates for the average value of the predictor variable, the predictive coefficient
and the autoregressive coefficient are noticeably different. The estimate for the
average of the predictor variable is lower for maximum likelihood estimation
(MLE) than for OLS in both samples. The difference in the postwar data is 4
basis points, an order of magnitude smaller than the difference in the estimate
of the equity premium. Nonetheless, the two results are closely related, as we
will discuss in what follows.


3.2        Efficiency
We now return to the question of efficiency. We ask, does our maximum
likelihood procedure reduce estimation noise in finite samples? We simulate
10,000 samples of excess returns and predictor variables, each of length equal
to the data. Namely, we simulate from (1), setting parameter values equal
to their maximum likelihood estimates, and, for each sample, initializing x
using a draw from the stationary distribution. For each simulated sample, we
calculate sample averages, OLS estimates and maximum likelihood estimates,
generating a distribution of these estimates over the 10,000 paths.8
       Table 2 (Panel A) reports the means, standard deviations, and the 5th,
50th, and 95th percentile values of a simulation calibrated using the postwar
sample. While the sample average of the excess return has a standard devi-
   8
       In every sample, both actual and artificial, we have been able to find a unique solution
to the first order conditions such that θ is real and between -1 and 1. Given this value for θ,
there is a unique solution for the other parameters. See Appendix A for further discussion
of the polynomial for θ.



                                                9
ation of 0.089, the maximum likelihood estimate has a standard deviation of
only 0.050 (unless stated otherwise, units are in monthly percentage terms).
9
    Besides lower standard deviations, the maximum likelihood estimates also
have a tighter distribution. For example, the 95th percentile value for the
sample mean of returns is 0.47, while the 95th percentile value for the maxi-
mum likelihood estimate is 0.40 (in monthly terms, the value of the maximum
likelihood estimate is 0.32). The 5th percentile is 0.18 for the sample average
but 0.24 for the maximum likelihood estimate.
        Table 2 also shows that the maximum likelihood estimate of the mean of the
predictor has a lower standard deviation and tighter confidence intervals than
the sample average, though the difference is much less pronounced. Similarly,
the maximum likelihood estimate of the regression coefficient β also has a
smaller standard deviation and confidence intervals than the OLS estimate,
though again, the differences for these parameters between MLE and OLS are
not large. The results in this table show that, in terms of the parameters of
this system at least, the equity premium is unique in the improvement offered
by maximum likelihood. This is in part due to the fact that estimation of
first moments is more difficult than that of second moments in the time series
(Merton, 1980). However, the result that the mean of returns is affected more
than the mean of the predictor shows that this is not all that is going on. We
return to this issue in Section 4.
        Figure 1 provides another view of the difference between the sample mean
and the maximum likelihood estimate of the equity premium. The solid line
shows the probability density of the maximum likelihood estimates while the
dashed line shows the probability density of the sample mean.10 The data gen-
    9
        Table A.1 shows an economically significant decline in standard deviation for the long
sample as well: the standard deviation falls from 0.080 to 0.058. It is noteworthy that our
results still hold in the longer sample, indicating that our method has value even when there
is a large amount of data available to estimate the sample mean.
   10
      Both densities are computed non-parametrically and smoothed by a normal kernel.



                                               10
erating process is calibrated to the postwar period, assuming the parameters
estimated using maximum likelihood (unless otherwise stated, all simulations
that follow assume this calibration). The distribution of the maximum likeli-
hood estimate is visibly more concentrated around the true value of the equity
premium, and the tails of this distribution fall well under the tails of the distri-
bution of sample means.11 For the remainder of the paper, we refer to this data
generating process, namely (1) with parameters given by maximum likelihood
estimates from the postwar sample, as our benchmark case. Unless otherwise
specified, we simulate samples of length equal to the postwar sample in the
data (707 months).
       It is well known that OLS estimates of predictive coefficients can be biased
(Stambaugh, 1999). Panel A of Table 2 replicates this result: the “true”
value of the predictive coefficient β in the simulated data is 0.69, however, the
mean OLS value from the simulated samples is 1.28. That is, OLS estimates
the predictive coefficient to be much higher than the true value, and thus
the predictive relation to be stronger. The bias in the predictive coefficient
is associated with bias in the autoregressive coefficient on the dividend-price
ratio. The true value of θ in the simulated data is 0.993, but the mean OLS
value is 0.987. Maximum likelihood reduces the bias somewhat: the mean
maximum likelihood estimate of β is 1.24 as opposed to 1.28, but it does not
eliminate it. Note that the estimates of the equity premium are not biased;
the mean for both maximum likelihood and the sample average is close to the
population value.
       These results suggest that 0.69 is probably not a good estimate of β, and
  11
       In Table 2, we used coefficients estimated by maximum likelihood to evaluate whether
MLE is more efficient than OLS. Perhaps it is not surprising that MLE delivers better esti-
mates, if we use the maximum likelihood estimates themselves in the simulation. However,
Table A.3 shows nearly identical results from setting the parameters equal to their sample
means and OLS estimates. We perform more extensive robustness checks in Section 5.




                                             11
likewise, 0.993 is likely not to be a good estimate of θ. Does the superior
performance of maximum likelihood continue to hold if these estimates are
corrected for bias? We turn to this question next. We repeat the exercise
described above, but instead of using the maximum likelihood estimates, we
adjust the values of β and θ so that the mean computed across the simulated
samples matches the observed value in the data. The results are given in
Panel B. This adjustment lowers β and increases θ, but does not change the
maximum likelihood estimate of the equity premium. If anything, adjusting
for biases shows that we are being conservative in how much more efficient our
method of estimating the equity premium is in comparison to using the sample
average. The sample average has a standard deviation of 0.138, while the
standard deviation of the maximum likelihood estimate if 0.072. Namely, after
accounting for biases, maximum likelihood gives an equity premium estimate
with standard deviation that is about half of the standard deviation of the
sample mean excess return.12 We will refer to this as our benchmark case with
bias-correction.


3.3        The equity premium in levels
So far we have defined the equity premium in terms of log returns. However,
our result is also indicative of a lower equity premium using return levels. For
simplicity, assume that the log returns log (1 + Rt ) are normally distributed.
Then
                                                           1
              E[Rt ] = E elog(1+Rt ) − 1 = eE[log(1+Rt )]+ 2 Var(log(1+Rt )) − 1.
                                   


Using the definition of the excess log return, E [log(1 + Rt )] = E[rt ]+E[log(1+
Rtf )], so the above implies that
                                                f    1
             E[Rt − Rtf ] = eE[rt ] eE [log(1+Rt )]+ 2 Var(log(1+Rt )) − 1 − E[Rtf ].
  12
       Table A.2 shows results under bias correction and fat-tailed shocks. Our results are
virtually unchanged.



                                               12
Our maximum likelihood method provides an estimate of E[rt ] and all other
quantities above can be easily calculated using sample moments. Taking the
sample mean of the series Rt − Rtf for the period 1953-2011 yields a risk
premium that is 0.530% per month, or 6.37% per annum. On the other hand,
using the above calculation and our maximum likelihood estimate of the mean
of rt gives an estimate of E[Rt − Rtf ] of 0.422% per month, or 5.06% per
annum.13 Thus our estimate of the risk premium in return levels is 131 basis
lower than taking the sample average, in line with our results for log returns.


3.4       Comparison with Fama and French (2002)
Fama and French (2002) also propose an estimator that takes the time series
of the dividend-price ratio into account in estimating the mean return. Noting
the following return identity:
                                           Dt    Pt − Pt−1
                                Rt =           +           ,
                                          Pt−1      Pt−1
and taking the expectation:
                                                       
                                     Dt         Pt − Pt−1
                         E[Rt ] = E        +E               ,
                                    Pt−1           Pt−1
they propose replacing the capital gain term E[(Pt −Pt−1 )/Pt−1 ] with dividend
growth E[(Dt − Dt−1 )/Dt−1 ]. They argue that, because prices and dividends
are cointegrated, their mean growth rates should be the same. They find that
the resulting expected return is less than half the sample average, namely
4.74% rather than 9.62%.
       While their argument seems intuitive, a closer look reveals a problem. Let
Xt = Dt /Pt , and let lower-case letters denote natural logs. Then

                           dt+1 − dt = xt+1 − xt + pt+1 − pt .                      (4)
  13
       In the data, in monthly terms for the period 1953-2011, the sample mean of Rt is
0.918%, the sample mean of Rtf is 0.387%, the sample mean of log(1 + Rtf ) is 0.386% and
the variance of log(1 + Rt ) is 0.194%.



                                              13
Because Xt is stationary, E[xt+1 − xt ] = 0 and it is indeed the case that

                                E[dt+1 − dt ] = E[pt+1 − pt ].                               (5)

However, exponentiating (4) and subtracting 1 implies
                                Dt+1 − Dt   Xt+1 Pt+1
                                          =           − 1.                                   (6)
                                   Dt        X t Pt
That is, stationarity of Xt implies (5), but not E[(Pt − Pt−1 )/Pt−1 ] = E[(Dt −
Dt−1 )/Dt−1 ]. Namely it does not imply that the average level growth rates are
equal.
   For expected growth rates to be equal in levels, (6) shows that it must be
               h           i     h      i
the case that E XXt+1
                   t
                      Pt+1
                       Pt
                             = E   Pt+1
                                    Pt
                                         . It seems unlikely that there are general
conditions under which this holds. Note that it follows from E[log(Xt+1 /Xt )] =
0 and Jensen’s inequality that E[Xt+1 /Xt ] > 1.14 This implies that the es-
timator proposed by Fama and French (2002) is inconsistent for the equity
premium, and thus it is not necessary (or possible) to evaluate efficiency.
       Nonetheless, our results show that assuming cointegration of prices and
dividends can be very informative for estimation of the mean return.15 Indeed,
the intuition that we will develop in the next section is closely related to
  14
       Indeed, if we assume that growth rates of dividends and prices are log-normal, a neces-
sary and sufficient condition for equality of expected (level) growth rates is that the variances
of the log growth rates are equal:

                                Var(dt+1 − dt ) = Var(pt+1 − pt ).                           (7)

To see this, note that (5), combined with log-normality, implies that
                                                     
                       Dt+1 − 1 Var(dt+1 −dt )      Pt+1 − 1 Var(pt+1 −pt )
                   E           e 2             =E         e 2               .
                        Dt                           Pt

If (7) holds, then the second terms on the right and left hand side cancel, yielding the result.
This is a knife-edge result in which the variance of the log dividend-price ratio xt and the
covariance of xt with log price changes cancel out. However, it is well-known that prices are
more volatile than dividends (Shiller, 1981).
 15
    This point is also made by Constantinides (2002), who suggests adjusting the mean



                                               14
that conjectured by Fama and French (2002): The sample average of realized
returns is “too high” because shocks to discount rates (proxied for by the
dividend-price ratio) were negative on average over the sample period.



4     Discussion

4.1     Source of the gain in efficiency
What determines the difference between the maximum likelihood estimate
of the equity premium and the sample average of excess returns? Let µ̂r
denote the maximum likelihood estimate of the equity premium and µ̂x the
maximum likelihood estimate of the mean of the dividend-price ratio. Given
these estimates, we can define a time series of shocks ût and v̂t as follows:

                             ût = rt − µ̂r − β̂(xt−1 − µ̂x )                          (8a)
                             v̂t = xt − µ̂x − θ̂(xt−1 − µ̂x ).                         (8b)

By definition, then,
                           T          T              T
                        1X         1X             1X
                  µ̂r =       rt −       ût − β̂       (xt−1 − µ̂x ).                  (9)
                        T t=1      T t=1          T t=1

As (9) shows, there are two reasons why the maximum likelihood estimate of
the mean, µ̂r , might differ from the sample mean T1 Tt=1 rt . The first is that
                                                    P

the shocks ût may not average to zero over the sample. The second, which
depends on return predictability, is that the average value of xt might differ
from µ̂x .
    It turns out that only the first of these effects is quantitatively important
for our sample. For the period January 1953 to December 2001, the sample
return by the difference in the valuation ratio between the first and last observation. Con-
stantinides derives conditions such that the resulting estimator has lower variance than the
mean return.



                                            15
           1
                PT                                                      PT
average    T     t=1   ût is equal to 0.1382% per month, while β̂ T1      t=1 (xt−1   − µ̂x )
is −0.0278% per month. The difference in the maximum likelihood estimate
and the sample mean thus ultimately comes down to the interpretation of the
shocks ût . To understand the behavior of these shocks, we will argue it is
necessary to understand the behavior of the shocks v̂t . And, to understand
v̂t , it is necessary to understand why the maximum likelihood estimate of the
mean of xt differs from the sample mean.


4.1.1      Estimation of the mean of the predictor variable

To build intuition, we consider a simpler problem in which the true value of
the autocorrelation coefficient θ is known. We show in Appendix A that the
first-order condition in the exact likelihood function with respect to µx implies
                                                          T
                     (1 + θ)                   1         X
        µ̂x =                    x0 +                        (xt − θxt−1 ).             (10)
                1 + θ + (1 − θ)T      (1 + θ) + (1 − θ)T t=1

We can rearrange (1b) as follows:

                               xt+1 − θxt = (1 − θ)µx + vt+1 .

Summing over t and solving for µx implies that
                                   T                             T
                            1 1X                          1     X
                     µx =             (xt − θxt−1 ) −               vt ,                (11)
                          1 − θ T t=1                 T (1 − θ) t=1

where the shocks vt are defined using the mean µx and the autocorrelation θ.
   Consider the conditional maximum likelihood estimate of µx , the estimate
that arises from maximizing the conditional likelihood (2). We will call this
µ̂cx . Note that this is also equal to the OLS estimate of µx , which arises from
estimating the intercept (1 − θ)µx in the regression equation

                               xt+1 = (1 − θ)µx + θxt + vt+1




                                             16
and dividing by 1 − θ. The conditional maximum likelihood estimate of µx is
determined by the requirement that the shocks vt average to zero. Therefore,
it follows from (11) that
                                                T
                                         1 1X
                              µ̂cx   =             (xt − θxt−1 ).
                                       1 − θ T t=1
Substituting back into (10) implies
                               (1 + θ)               (1 − θ)T
                  µ̂x =                    x0 +                   µ̂c .
                          1 + θ + (1 − θ)T      (1 + θ) + (1 − θ)T x
Multiplying and dividing by 1 − θ implies a more intuitive formula:
                               1 − θ2                  (1 − θ)2 T
                 µ̂x =                       x 0 +                    µ̂c .               (12)
                         1 − θ2 + (1 − θ)2 T       1 − θ2 + (1 − θ)2 T x
Equation 12 shows that the exact maximum likelihood estimate is a weighted
average of the first observation and the conditional maximum likelihood esti-
mate. The weights are determined by the precision of each estimate. Recall
that
                                          σv2
                                               
                            x0 ∼ N 0,             .
                                        1 − θ2
Also, because the shocks vt are independent, we have that
                               T
                                                  σv2
                                                        
                        1     X
                                  vt ∼ N 0,                .
                    T (1 − θ) t=1             T (1 − θ)2
Therefore T (1 − θ)2 can be viewed as proportional to the precision of the
conditional maximum likelihood estimate, just as 1 − θ2 can be viewed as pro-
portional to the precision of x0 . Note that when θ = 0, there is no persistence
and the weight on x0 is 1/(T + 1), its appropriate weight if all the observa-
tions were independent. At the other extreme, as θ approaches 1, less and less
information is conveyed by the shocks vt and the “estimate” of µ̂x approaches
x0 .16
  16
       We cannot use (12) to obtain our maximum likelihood estimate because θ is not known
(more precisely, the conditional and exact maximum likelihood estimates of θ will differ).
Because of the need to estimate θ, the conditional likelihood estimator for µx is much less
efficient than the exact likelihood estimator; a fact that is not apparent from these equations.



                                                17
   While (12) rests on the assumption that θ is known, we can nevertheless
use it to qualitatively understand the effect of including the first observation.
Because of the information contained in x0 , we can conclude that the last T
observations of the predictor variable are not entirely representative of values
of the predictor variable in population. Namely, the values of the predictor
variable for the last T observations are lower, on average, than they would be
in a representative sample. It follows that the predictor variable must have
declined over the sample period. Thus the shocks vt do not average to zero, as
OLS (conditional maximum likelihood) would imply, but rather, they average
to a negative value.
   Figure 2 shows the historical time series of the dividend-price ratio, with
the starting value in bold, and a horizontal line representing the mean. Given
the appearance of this figure, the conclusion that the dividend-price ratio has
been subject to shocks that are negative on average does not seem surprising.


4.1.2   Estimation of the equity premium

We now return to the problem of estimating the equity premium. Equation 9
shows that the average shock T1 Tt=1 ût plays an important role in explaining
                               P

the difference between the maximum likelihood estimate of the equity premium
and the sample mean return. In traditional OLS estimation, these shocks
must, by definition, average to zero. When the shocks are computed using the
(exact) maximum likelihood estimate, however, they may not.
   To understand the properties of the average shocks to returns, we note that
the first-order condition for estimation of µ̂r implies
                               T               T
                            1X         σ̂uv 1 X
                                  ût = 2         v̂t .                     (13)
                            T t=1       σ̂v T t=1

This is analogous to a result of Stambaugh (1999), in which the averages of the
error terms are replaced by the deviation of β and of θ from the true means.



                                        18
Equation 13 implies a connection between the average value of the shocks to
the predictor variable and the average value of the shocks to returns. As the
previous section shows, MLE implies that the average shock to the predictor
variable is negative in our sample. Because shocks to returns are negatively
correlated with shocks to the predictor variable, the average shock to returns
is positive.17 Note that this result operates purely through the correlation of
the shocks, and is not related to predictability.18
       Based on this intuition, we can label the terms in (9) as follows:
                         T                 T                    T
                      1X                1X                   1X
              µ̂r =         rt    −           ût    −     β̂      (xt−1 − µ̂x ) .        (14)
                      T t=1             T t=1                T t=1
                                        | {z }             |        {z        }
                                  Correlated shock term      Predictability term

As discussed above, the correlated shock term accounts for more than 100%
of the difference between the sample mean and the maximum likelihood es-
timate of the equity premium, and is an order of magnitude larger than the
predictability term. Our argument above can be extended to show why these
terms tend to have opposite signs. When the correlated shock term is posi-
tive (as is the case in our data), shocks to the dividend-price ratio must be
negative over the sample. The estimated mean of the predictor variable will
therefore be above the sample mean, and the predictability term will be neg-
ative. Figure A.2 shows that indeed these terms tend to have opposite signs
in the simulated data.19
  17
       This point is related to the result that longer time series can help estimate parameters
determined by shorter time series, as long as the shocks are correlated (Stambaugh, 1997;
Singleton, 2006; Lynch and Wachter, 2013). Here, the time series for the predictor is slightly
longer than the time series of the return. Despite the small difference in the lengths of the
data, the structure of the problem implies that the effect of including the full predictor
variable series is very strong.
  18
     Ultimately, however, there may be a connection in that variation in the equity premium
is the main driver of variation in the dividend-price ratio and thus the reason why the shocks
are negatively correlated.
  19
     There is a small opposing effect on the sign of the predictability term. Note that the



                                               19
   This section has explained the difference between the sample mean and
the maximum likelihood estimate of the equity premium by appealing to the
difference between the sample mean and the maximum likelihood estimate of
the mean of the predictor variable. However, Table 1 shows that the differ-
ence between the sample mean of excess returns and the maximum likelihood
estimate of the equity premium is many times that of the difference between
the two estimates of the mean of the predictor variable. Moreover, Table 2
shows that the difference in efficiency for returns is also much greater than the
difference in efficiency for the predictor variable. How is it then that the dif-
ference in the estimates for the mean of the predictor variable could be driving
the results? Equation 13 offers an explanation. Shocks to returns are far more
volatile than shocks to the predictor variable. The term σ̂uv /σ̂v2 is about −100
in the data. What seems like only a small increase in information concerning
the shocks to the predictor variable translates to quite a lot of information
concerning returns.


4.2     Properties of the maximum likelihood estimator
In this section we investigate the properties of the maximum likelihood esti-
mator, and, in particular, how the variance of the estimator depends on the
persistence of the predictor variable, the amount of predictability, and the
correlation between the shocks to the predictor and the shocks to returns.


4.2.1    Variance of the estimator as a function of the persistence

The theoretical discussion in the previous section suggests that the persistence
θ is an important determinant of the increase in efficiency from maximum
sample mean in this term only sums over the first T − 1 observations. If the predictor
has been falling over the sample, this partial sum will lie above the sample mean, though
probably below the maximum likelihood estimate of the mean.




                                           20
likelihood. Figure 3 shows the standard deviation of estimators of the mean of
the predictor variable (µx ) in Panel A and of estimators of the equity premium
(µr ) in Panel B as functions of θ. Other parameters are set equal to their
benchmark values, adjusted for bias in the case of β. For each value of θ, we
simulate 10,000 samples.
   Panel A shows that the standard deviation of both the sample mean and
MLE of µx are increasing in θ. This is not surprising; holding all else equal,
an increase in the persistence of θ makes the observations on the predictor
variable more alike, thus decreasing their information content. The standard
deviation of the sample mean is larger than the standard deviation of the
maximum likelihood estimate, indicating that our results above do not depend
on a specific value of θ. Moreover, the improvement in efficiency increases
as θ grows larger. Consistent with the results in Table 2, the size of the
improvement is small.
   Panel B shows the standard deviation of estimators of µr . In contrast
to the case of µx , the relation between the standard deviation and θ is non-
monotonic for both the sample mean of excess returns and the maximum
likelihood estimate of the equity premium. For values of θ below about 0.998,
the standard deviations of the estimates are decreasing in θ, while for values
of θ above this number they are increasing. This result is surprising given the
result in Panel A. As θ increases, any given sample contains less information
about the predictor variable, and thus about returns. One might expect that
the standard deviation of estimators of the mean return would follow the same
pattern as in Panel A. Indeed, this is the case for part of the parameter space,
namely when the persistence of the predictor variable is very close to one.
   However, an increase in θ has two opposing effects on the variance of the
estimators of the equity premium. On the one hand, an increase in θ decreases
the information content of the predictor variable series, and thus of the return
series, as described above. On the other hand, for a given β, an increase in θ



                                      21
raises the R2 in the return regression. Because innovations to the predictable
part of returns are negatively correlated with innovations to the unpredictable
part of returns, an increase in θ increases mean reversion (this can be seen
directly from the expressions for the autocovariance of returns in Appendix B).
   This increase in mean reversion has consequences for estimation of the eq-
uity premium. Intuitively, if in a given sample there is a sequence of unusually
high returns, this will tend to be followed by unusually low returns. Thus
a sequence of unusually high observations or unusually low observations are
less likely to dominate in any given sample, and so the sample average will
be more stable than it would be if returns were iid (see Appendix C). Be-
cause the sample mean is simply the scaled long-horizon return, our result is
related to the fact that mean reversion reduces the variability of long-horizon
returns relative to short-horizon returns. For θ sufficiently large, the reduc-
tion in information from the greater autocorrelation does dominate the effect
of mean-reversion, and the variance of both the sample mean and the maxi-
mum likelihood estimate increase. In the limit as θ approaches one, returns
become non-stationary and the sample mean has infinite variance.
   Panel B of Figure 3 also shows that MLE is more efficient than the sample
mean for any value of θ. The benefit of using maximum likelihood increases
with θ. Indeed, while the standard deviation of the sample mean falls from 0.14
to 0.12 as θ goes from 0.980 to 0.995, the maximum likelihood estimate falls
further, from 0.14 to 0.06. It appears that the benefits from mean reversion
and from maximum likelihood reinforce each other.


4.2.2   Variance of estimator under alternative parameter assump-
        tions

The previous section established the importance of the persistence of the
dividend-price ratio in the precision gains from maximum likelihood. In this
section we focus on the two aspects of joint return and dividend-price ratio


                                      22
process that affect how information about the distribution of the dividend-
price ratio affects inference concerning returns: the predictive coefficient β
and the correlation of the shocks ρuv .
   We first consider the role of predictability. In the historical sample, pre-
dictability works against us in finding a lower equity premium. Indeed, as (9)
shows, the difference between the maximum likelihood estimator can be de-
composed into a term originating from non-zero shocks, and a term originating
from predictability. More than 100% of our result comes from the correlated
shock term; in other words the predictability term works against us. Without
the predictability term, our equity premium would be 0.29% per month rather
than 0.32%.
   This result is not surprising given that the intuition in Section 4.1 points
to negative ρuv rather than positive β as the source of our gains. If this is
correct, we should be able to document efficiency gains in simulations where
the predictive coefficient is reduced or eliminated entirely. Indeed, Table 2
shows that if we bias-correct β and θ, the efficiency gains are even larger than
when parameters are set to the maximum likelihood estimates. In this section,
we take this analysis a step further, and set β exactly to zero. We repeat the
exercise from Section 4.2.1, calculating the standard deviation of the estimates
across different values of θ. When we repeat the estimation, we do not impose
β = 0, which will work against us in finding efficiency gains.
   Panel C of Figure 3 shows the results. First, because returns are iid, the
standard deviation of the sample mean is independent of θ and is a horizontal
line on the graph. The standard deviation of the maximum likelihood estimate
is, however, decreasing in θ. As θ increases, the information contained in the
first data point carries more weight. Thus the estimator is better able to
identify the average sign of the shocks to the dividend-price ratio and thus
to expected returns. Consider, for example, an autocorrelation of 0.998 (the
bias-corrected value in Panel B of Table 2). As Panel C shows, the standard



                                          23
deviation of the MLE estimator is 0.12 while the standard deviation of the
sample mean is 0.17, or nearly 50% greater.20 Thus neither the reduction in
the equity premium that we observe in the historical sample, nor the efficiency
of the maximum likelihood estimator depend on the predictability of returns.
       So far we have shown how changes in the persistence, and changes in the
predictability of returns impact the efficiency of our estimates. In particular,
the efficiency of our estimates does not depend on return predictability. On
what, then, does it depend? The above discussion suggests that it depends,
critically, on the correlation between shocks to the dividend-price ratio and
to returns, because this is how the information from the dividend-price ratio
regression finds its way into the return regression. We look at this issue specif-
ically in Panel D of Figure 3, where we set the correlation between the shocks
to equal zero. In this figure, returns are no longer iid, which explains why the
standard deviation of the sample mean estimate rises as θ increases. On other
hand, though there is return predictability, the lack of correlation implies that
there is no mean reversion in returns, so the increase is monotonic, as opposed
to what we saw in Panel B.21 Most importantly, this figure shows zero, or neg-
ligible, efficiency improvements from MLE. In fact, for all but extremely high
values of θ, MLE performs very slightly worse than the sample mean, perhaps
because it relies on biased estimates of predictability.22 This exercise has little
empirical relevance as the correlation between returns and the dividend-price
  20
       Wachter and Warusawitharana (2015) show in a Bayesian setting that, if one holds
a belief that there is no predictability, the posterior distribution for the autoregressive
coefficient shifts upward towards unity. Cochrane (2008) makes an analogous point using
frequentist methods.
   21
      However, if the equity premium were indeed varying over time, one would expect return
innovations to be negatively correlated with realized returns (Pastor and Stambaugh, 2009).
  22
     Though the data generating process assumes bias-corrected estimates, MLE will still
find values of β that are high relative to the values specified in the simulation. This will
hurt its finite-sample performance.




                                            24
ratio is reliably estimated to be strongly negative.23 Nonetheless, it is a stark
illustration of the conditions under which our efficiency gains break down.



5        Estimation under Alternative Data Gener-
         ating Processes
This section shows the applicability of our procedure under alternative data
generating processes. Section 5.1 shows how to adapt our procedure to cap-
ture conditional heteroskedasticity in returns and in the predictor variable.
Section 5.1 and Section 5.2 consider the performance of our benchmark pro-
cedure when confronted with data generating processes that depart from the
stationary homoskedastic case in important ways. Our aim is to map out
cases where mis-specification overwhelms the gains from introducing data on
the dividend-price ratio, and when it does not. Finally, Section 5.3 analysis
the consequences of structural breaks for our results.


5.1        Conditional Heteroskedasticity
As is well-known, stock returns exhibit time-varying volatility (French, Schw-
ert, and Stambaugh, 1987; Bollerslev, Chou, and Kroner, 1992). In this section
we generalize our estimation method to take this into account. Because of our
focus on maximum likelihood, a natural approach is to use the GARCH model
of Bollerslev (1986). We will refer to this method as GARCH-MLE, and, for
consistency, continue to refer to the method described in Section 2 as MLE.
We ask three questions: (1) Do we still find a lower equity premium when we
apply GARCH-MLE to the data? (2) Is GARCH-MLE efficient in small sam-
  23
       It does suggest, however, that including data on predictor variables that have low per-
sistence and/or low realized correlations with returns will not impact estimates of the equity
premium nearly to the extent of the dividend-price ratio.




                                               25
ples? (3) If we simulate data characterized by time-varying volatility and apply
(homoskedastic, and therefore mis-specified) MLE, do we still find efficiency
gains?
       While the traditional GARCH model is typically applied to return data
alone, our method closely relies on estimation of a bivariate process with cor-
related shocks. Allowing for time-varying volatility of returns but not of the
dividend-price ratio seems artificial and unnecessarily restrictive. Following
Bollerslev (1990), who estimates a GARCH model on exchange rates, we con-
sider two correlated GARCH(1,1) processes. We assume

                                rt+1 − µr = β(xt − µx ) + ut+1                        (15a)
                             xt+1 − µx = θ(xt − µx ) + vt+1 ,                         (15b)

where, conditional on information available up to and including time t,
                                                            
                                   2
          ut+1                   σu,t+1       ρuv σu,t+1 σv,t+1
               ∼ N 0,                                        ,    (15c)
                                                     2
          vt+1              ρuv σu,t+1 σv,t+1      σv,t+1

with

                                  2
                                 σu,t+1 = ωu + αu u2t + δu σu,t
                                                            2
                                                                ,                     (15d)
                                   2
                                  σv,t+1 = ωv + αv vt2 + δv σv,t
                                                             2
                                                                 .                    (15e)

We assume initial conditions

                                       2           ωu
                                      σu,1 =               ,
                                               1 − αu − δu
                                       2           ωv
                                      σv,1   =             .
                                               1 − αv − δv
                 ωu               ωv                                             2
Note that      1−αu −δu
                          and   1−αv −δv
                                           represent the unconditional means of σu,t and
 2                   24
σv,t respectively.        The bivariate GARCH(1,1) log-likelihood function is there-
  24
       Applying the law of iterated expectations, we find Eu2t = E[Et−1 u2t ] = Eσu,t
                                                                                  2
                                                                                      . The
result for σu follows under stationarity by taking the expectation of the left and right hand
sides of (15d), and the same argument works for σv .



                                                 26
fore

  l(r1 , . . . , rT ; x1 , . . . , xT |µr , µx , β, θ, ωu , αu , δu , αv , δv , ρuv , x0 ) =
                                                                                                   
      T                                                      T          2                        2
    X                                                1      X
                                                                  ut + 2ρuv q ut vt + vt  .
           log (1 − ρ2uv )σu,t      2   2
                                           
                                       σv,t   +         2              2                        2
     t=1
                                                 1 − ρuv t=2 σu,t                        σ2 σ2 σv,t
                                                                                u,t v,t

                                                                                                  (16)

       This likelihood function conditions on x0 , and thus is the GARCH analogue
of the conditional maximum likelihood function (2). However, unlike in the
homoskedastic case, there is no analytical expression for the unconditional dis-
tribution of x0 (Diebold and Schuermann, 2000).25 For this reason, we adopt
a two-stage method that allows us both to estimate conditional heteroskedas-
ticity, and to take into account the initial observation on the dividend-price
ratio. While this represents a departure from “pure” maximum likelihood, it
nonetheless allows us to consistently and efficiently estimate parameters.
       We proceed as follows. First, we maximize the function (16) across the full
  25
       In principle we could capture this distribution by simulating from the conditional bivari-
ate GARCH(1,1) over a long-period of time. To integrate this method into our optimization
would not be easy however; for each function evaluation in our numerical optimization, we
would need to simulate this distribution with enough accuracy to capture subtle effects of,
say, the autoregressive coefficient θ along with the GARCH parameters. This would be
challenging given that the parameter range of interest implies that xt is highly persistent.
We would then need to repeat the procedure thousands of times in our Monte Carlo sim-
ulations. It is hard to see the benefits (in terms of finite-sample efficiency gains) that this
procedure would have over the more computationally feasible procedure that we do adopt.




                                                 27
set of parameters. We then maximize

 l(r1 , . . . , rT ; x0 , . . . , xT |µr , µx , β, θ, ωu , αu , δu , αv , δv , ρuv ) =
                                                         (x0 − µx )2
                                                  
                                  ωv
                                                                         (1 − αv − δv ) 1 − θ2
                                                                                               
         log                                    2
                                                      +
                   (1 − αv − δv ) (1 − θ )                     ωv
                                                                                                 
     T                                                      T          2                        2
   X                                                1      X
                                                                 ut + 2ρuv q ut vt + vt  ,
          log (1 − ρ2uv )σu,t      2   2
                                          
 +                                    σv,t   +         2              2                         2
    t=1
                                                1 − ρuv t=1 σu,t                      σ2 σ2  σv,t
                                                                              u,t v,t

                                                                                                (17)

where we fix the estimates of ωu , αu , δu , ωv , αv , δv and ρuv from the first
stage, and obtain new estimates of µr , µx , β and θ. The first two terms on the
right hand side of (17) represents a density for the initial observation x0 . This
density, which is normal with standard deviation E[σv,t ]/(1 − θ2 ), represents
an approximation to the true unknown density. By performing the estimation
in two stages, we can make sure that the mis-specification in the second stage
doesn’t contaminate our GARCH estimation. Indeed, the GARCH estimation
we perform in the first stage is the standard one in the literature. As mentioned
above, we refer to this procedure as GARCH-MLE.
   We report estimates in Table A.4.                  Similarly to previous studies (e.g.
French, Schwert, and Stambaugh (1987)), we find that return volatility is
moderately persistent, with a monthly autocorrelation of 0.72. Volatility of
the dividend-price ratio is somewhat more persistent, with a monthly auto-
correlation of 0.89. The average conditional volatilities of ut and vt are nearly
identical to the unconditional volatilities in our benchmark case. Most im-
portantly, given the focus of this study, the average equity premium is very
close to what we found in our benchmark estimation: 0.335% per month, as
opposed to 0.322%. The sample mean is 0.433% per month. Thus the finding
of a lower equity premium is robust to time-varying volatility, which answers
the first question we pose in the introduction to this section.
   We now move on to the question of efficiency. We simulate 10,000 samples


                                                28
from the process (15) using parameter values estimated by GARCH-MLE. We
consider the performance of OLS (where we report sample means for the equity
premium and the dividend-price ratio), the benchmark MLE procedure, and
GARCH-MLE. Table 3 reports the means, standard deviations, and the 5th,
50th, and 95th percentiles of each parameter estimate.26 We find that both
MLE and GARCH-MLE are more efficient than the sample mean, and they
are both about as efficient as each other. The efficiency gains are similar to
what we see when the data generating process is homoskedastic (Table 2).
We conclude that our estimation works well in the presence of time-varying
volatility, both when we consider a method that explicitly takes time-varying
volatility into account, and when we consider a (mis-specified) method that
does not.


5.2       Non-stationarities in the dividend-price ratio
The previous section shows that our method works equally well for a bivariate
GARCH(1,1) model as for our benchmark homoskedastic model. This may be
because our method essentially translates information from long-run changes in
the dividend-price ratio to information about returns. These long-run changes
are sufficiently large that short-term volatility fluctuations do not alter their
interpretations. Here, and in the sections that follow, we consider alternative
models that have the potential to dramatically alter the interpretation of the
time series of the dividend-price ratio, and thus the model’s results for the
equity premium. As in Section 4.2.2 where we set the correlation between
shocks to the dividend-yield and returns to be zero, our aim is to “turn off” the
gains from our method. However, in that case, a zero correlation was clearly
counterfactual. Here, we consider models which, at least on a purely statistical
 26
      For the volatility parameters σu and σv , we report the square root of the unconditional
          2        2
means of σu,t and σv,t for GARCH-MLE.




                                              29
level, could account for the data. To focus on our main mechanism, we consider
homoskedastic returns; however, the results of the previous section strongly
suggest that these findings are also robust to conditional heteroskedasticity.


5.2.1       The random walk model

Given the observed high autocorrelation of the dividend-price ratio, a natural
extension is to consider a random walk. One immediate question that we face
in assuming a random walk is the role of the predictive coefficient β. If the
dividend-price ratio were to follow a random walk, and if β were nonzero,
then the equity premium would be undefined. That is, excess stock returns,
which would be non-stationary in this case, would not possess an unconditional
mean. Any method, including the sample mean and our maximum likelihood
procedure would give meaningless results. For this reason, when we consider
a non-stationary dividend-price ratio (in this and in the subsequent section),
we assume β = 0.
       We therefore simulate 10,000 artificial samples from the process

                                    rt+1 − µr = ut+1
                                         xt+1 = xt + vt+1 .

For each sample, we then apply our benchmark maximum likelihood procedure,
as well as OLS regression.27 For parameters µr and µx (this is a parameter
in the estimation, not in the data generating process), we compare our max-
imum likelihood results with the sample means. Our benchmark maximum
  27
       In our previous simulations, we initialize x0 using a draw from the stationary distribu-
tion. Clearly this is not possible in this case. We report simulation results with x0 set equal
to its value in the data, but we have obtained identical results from randomizing over x0 .
Other parameters are as follows: µr equals to its benchmark maximum likelihood estimate,
σu the standard deviation of returns, σv the standard deviation of differences in the log
dividend-price ratio, and ρuv to the correlation between returns and differences in the log
dividend-price ratio.



                                               30
likelihood procedure is mis-specified because it assumes stationarity and al-
lows for predictability. Of course assumptions of OLS are also violated, as
discussed above.
   Table 4 shows the results. Maximum likelihood still estimates the equity
premium without bias, as shown by the fact that the average estimate of µr is
exactly equal to the true value from the simulation. As previously discussed,
the predictive coefficient and the autoregressive coefficient are biased upward
and downward respectively, and this is clearly shown in the table. As a result,
maximum likelihood still identifies a positive β and a stationary dividend-price
ratio, even though these are not the characteristics of the data generating
process.
   Besides correctly estimating the equity premium, maximum likelihood leads
to significant gains in efficiency, even relative to our benchmark case. The stan-
dard deviation of the maximum likelihood estimate is only 30% of the standard
deviation of the sample mean. The spread between the fifth and ninety-fifth
percentile also falls by a factor greater than three. In this case, our estima-
tion method does not pick up the non-stationarity in the dividend-price ratio
(nor does OLS). However, the intuition of Section 4 still holds in this limiting
case, and the model successfully estimates the equity premium with increased
precision.


5.2.2      Predictor with Time Trend

The previous section shows that our method can still be effective under a
random-walk model for the dividend-price ratio. What about other forms of
non-stationarity? Using the intuition from Section 4, we can reason backwards
to find a model seems particularly likely to cause problems for our estimation
method. Such a model would lead our method to conclude that the average
shock is non-zero more often than it is.
   These considerations lead us to consider a time trend in the dividend-price


                                       31
ratio. As in the case of the random walk model, we set β equal to zero so the
equity premium is still well-defined. We therefore consider

                      rt+1 − µr = ut+1                                     (18a)
                      xt+1 − µx = ∆ + θ(xt − µx ) + vt+1 ,                 (18b)

where ∆ denotes the time trend. We consider a calibration of (18) that both
fits the data, and represents a worst-case scenario from the point of view of our
method. With the exceptions of ∆ and β, we set the parameters to equal those
of our benchmark calibration. We then set ∆ so that the in-sample average of
shocks to the dividend-price ratio is exactly zero. Because Tt=1 v̂t in the data
                                                           P

is −1.051, and because the length of the sample is 707 months, this implies a
value of ∆ of −0.1487%.
   We simulate 10,000 samples from (18). For each of these we compute OLS
and find the sample mean of the predictor variable and of the equity premium.
We also run our benchmark maximum likelihood estimation, which is highly
mis-specified in this case. For consistency, we continue to refer to this as
maximum likelihood.
   Results are shown in Table 5. Unlike in the case of the random walk, in
this case mis-specification has serious consequences for the estimation of the
equity premium. Whereas the sample mean finds, on average, the correct
value, maximum likelihood finds a lower value: 0280% versus 0.322%. The
maximum likelihood estimator has a lower standard error, but this doesn’t
matter because it is in fact an inconsistent estimator for the equity premium.
   Why does the maximum likelihood estimator fail in this case? Consider
first the estimation of the process for xt . The true mean of xt is undefined.
However, in every sample there will be an observed mean. This sample mean
will be on average lower than the true value of µx because the time trend
lowers the level of the dividend-price ratio. The MLE will be slightly higher
than the sample mean because it will correct for what it sees as an unusual


                                       32
series of shocks. However, what appears to be an unusual series of shocks is
in fact the time trend.
       Now consider the estimation of the equity premium. Unlike the mean of xt ,
the equity premium is well-defined because we have set β to equal zero. This
is why the sample mean finds the correct answer. The maximum likelihood
estimator, however, uses information from the predictor variable equation,
information that is, in this case, incorrect. This information indicates that,
on average, shocks have been positive to returns over each sample period, and
thus it is necessary to adjust the equity premium downward.
       While it would probably be nearly impossible to reject this time-trend
model on purely statistical grounds, it seems unappealing from the point of
view of economics. It implies that market participants would have known
in advance about the decrease in the dividend-price ratio over the post-war
sample, which is hard to believe. Not surprisingly given this basic intuition,
equilibrium models of the asset prices tend to imply not (18), but rather the
autoregressive process (1b), at least as an approximation.28


5.3       Structural Breaks
So far, we have assumed that a single process characterizes returns and the
dividend-price ratio over the postwar period. Studies including Pástor and
Stambaugh (2001), Lettau and Van Nieuwerburgh (2008) and Pettenuzzo and
Timmermann (2011) argue that this period has been characterized by a struc-
tural break. The presence of a structural break could have several implications
for our findings. Recall that the reason for our lower point estimate of the eq-
uity premium is the decline in the dividend-price ratio over the sample period.
In a limiting case, where this decline is due entirely to a structural break, then
  28
       Hansen, Heaton, and Li (2008) also present an example where a time-trend model
for valuation ratios creates problems for interpretation of statistical findings. They argue
similarly that the time trend model is an implausible description on economic grounds.



                                            33
our finding of a lower equity premium could completely disappear because the
dividend-price ratio would no longer be declining over each sub-sample. As a
related point, a structural break could make it less likely that we would find
efficiency gains because, while the relevant sample size would be smaller, the
persistence of the dividend-price ratio would be smaller as well.
   To evaluate the effects, we use the framework of Lettau and Van Nieuwer-
burgh (2008), whose model is most similar to the one we consider. Lettau and
van Nieuwerburgh find evidence for a structural break in the dividend-price
ratio in 1994. Accordingly, we re-estimate our model on each sub-period. The
results are reported in Table 6. This table shows that maximum likelihood
still leads to substantially lower point estimates as compared with the sample
mean. Consider first the 1953–1994 subperiod. This subperiod is characterized
by relatively high returns, as indicated by a sample mean of 0.439%, slightly
higher than our full sample average. However, this period is characterized by a
striking decline in the dividend-price ratio, a fact that is largely undiminished
by breaking the sample in 1994 (see Figure 2). Our model thus attributes
the high observed equity premium to an unusual series of shocks rather than
a high true mean. The point estimate for the equity premium, at 0.315%, is
lower than the point estimate for the full sample.
   For the second sub-period, from 1995-2011, observed returns were lower,
leading to a sample mean of 0.411%. Again, the dividend-price ratio de-
clined over this sub-sample, so the maximum likelihood estimate is lower than
the sample mean, at 0.336%. Thus maximum likelihood continues to have a
substantial effect on the equity premium estimate, despite the presence of a
structural break.
   We now turn to the question of efficiency. Panel A1 of Table 7 shows sim-
ulation results when the parameters and the length of each fictitious sample
are set to match the 1953–1994 subsample. We still do find efficiency gains,
but they are indeed smaller than in our benchmark case. The standard error



                                       34
on the equity premium falls from 0.086 for the sample mean to 0.062 for max-
imum likelihood (in comparison, for our benchmark case, the sample mean
had a standard error of 0.089 and the maximum likelihood estimate had a
standard error of 0.050). Panel A1 also reveals the extent of the bias in the
predictive and autoregressive coefficients. The mean estimate of β is substan-
tially higher than its true value, and the mean of θ is substantially lower. This
bias was also apparent in our benchmark case discussed in Section 3.2, but
it is more substantial because of the reduction in sample size. Motivated by
these results, we also consider a bias-corrected simulation, where, as before,
we choose the true values of the parameters so that the mean in simulation
matches the observed point estimates. As Panel A2 shows, the efficiency gain
from maximum likelihood is almost as large as for our benchmark simulation
when we correct for bias. The reason is that θ is higher than in Panel A1
(though it is still below the full-sample estimate), and the sample size is lower.
   We repeat this analysis for the 1995–2011 subsample, with results shown
in Panel B. Panel B1 shows the results without the bias correction. In this
case, because the sample size is so short, we still see efficiency gains despite the
relatively low value of the autocorrelation. We also attempt a bias correction
in Panel B2. Our results indicate the difficulties of inference over short time
periods in the presence of persistent regressors. Even if we set the predictive
coefficient to zero and the autocorrelation to 0.999, we are unable to quite
match the values in the data (though we come close). Under this calibration,
a short sample, combined with a high degree of persistence implies that the
standard errors for maximum likelihood are less than half as large as for the
sample mean. In other words, our efficiency gains are larger than even in the
full sample.
   To summarize, because a structural break does not entirely explain the
decline in the price-dividend ratio, our method still produces substantially
lower estimates of the equity premium than the sample mean, even when we



                                        35
take a structural break into account. Moreover, our efficiency gains are the
same or larger than in our benchmark case.



6     Conclusion
A large literature has grown up around the empirical quantity known as the
equity premium, in part because of its significance for evaluating models in
macro-finance (Mehra and Prescott (1985)) and in part because of its prac-
tical significance as indicated by discussions in popular classics on investing
(e.g. Siegel (1994), Malkiel (2003)) and in undergraduate and masters’ level
textbooks.
    Estimation of the equity premium is almost always accomplished by taking
sample means. The implicit assumption is that the period in question con-
tains a representative sample of returns. We show that it is possible to relax
this assumption, and obtain a better estimate of the premium, by bringing
additional information to bear on the problem, specifically the information
contained separately in prices and dividends.
    We show that the time series behavior of prices, dividends and returns,
suggests that shocks to returns have been unusually positive over the post-war
period. Thus the sample average will overstate the equity premium. We show
that this intuition can be formalized with the standard econometric technique
of maximum likelihood. Applying maximum likelihood rather than taking the
sample average leads to an economically significant reduction in the equity
premium of 1.3 percentage points from 6.4% to 5.1%. Furthermore, Monte
Carlo experiments indicate that the small-sample noise is greatly reduced.
    Our method differs from the sample mean in that we require assumptions
on the data generating process for the dividend-price ratio. We have shown
that our findings are robust to a wide range of variations in these assumptions.
Specifically, it is not necessary for returns to be homoskedastic, or even for the



                                       36
dividend-price ratio to be stationary. We also show that our method works well
in the presence of structural breaks. The main conclusion from our findings
is that the generous risk compensation offered by equities over the postwar
sample may in part be an artifact of that period, and may not be a reliable
guide to what investors will experience going forward.




                                     37
References
Amemiya, Takeshi, 1985, Advanced Econometrics. (Harvard University Press
  Cambridge, MA).

Andrews, Donald W. K., 1993, Exactly median-unbiased estimation of first
  order autoregressive/unit root models, Econometrica 61, 139–165.

Bansal, Ravi, and Amir Yaron, 2004, Risks for the long-run: A potential
  resolution of asset pricing puzzles, Journal of Finance 59, 1481–1509.

Barberis, Nicholas, 2000, Investing for the long run when returns are pre-
  dictable, Journal of Finance 55, 225–264.

Bekaert, Geert, Robert J. Hodrick, and David A. Marshall, 1997, On biases in
  tests of the expectations hypothesis of the term structure of interest rates,
  Journal of Financial Economics 44, 309–348.

Blanchard, Olivier J., 1993, Movements in the Equity Premium, Brookings
  Papers on Economic Activity 1993, 75–138.

Bollerslev, Tim, 1986, Generalized autoregressive conditional heteroskedastic-
  ity, Journal of Econometrics 31, 307–327.

Bollerslev, Tim, 1990, Modelling the Coherence in Short-Run Nominal Ex-
  change Rates: A Multivariate Generalized ARCH Model, The Review of
  Economics and Statistics 72, pp. 498–505.

Bollerslev, Tim, Ray Y. Chou, and Kenneth F. Kroner, 1992, {ARCH} mod-
  eling in finance: A review of the theory and empirical evidence, Journal of
  Econometrics 52, 5 – 59.

Box, George E.P., and George C. Tiao, 1973, Bayesian Inference in Statistical
  Analysis. (Addison-Wesley Pub. Co. Reading, MA).


                                      38
Campbell, John Y., 2003, Consumption-based asset pricing, in G. Constan-
  tinides, M. Harris, and R. Stulz, eds.: Handbook of the Economics of Fi-
  nance, vol. 1b (Elsevier Science, North-Holland ).

Campbell, John Y., 2006, Household Finance, Journal of Finance 61, 1553 –
  1604.

Campbell, John Y., and John H. Cochrane, 1999, By force of habit: A
  consumption-based explanation of aggregate stock market behavior, Journal
  of Political Economy 107, 205–251.

Campbell, John Y., and Luis M. Viceira, 1999, Consumption and portfolio de-
  cisions when expected returns are time-varying, Quarterly Journal of Eco-
  nomics 114, 433–495.

Campbell, John Y., and Motohiro Yogo, 2006, Efficient tests of stock return
  predictability, Journal of Financial Economics 81, 27–60.

Cavanagh, Christopher L., Graham Elliott, and James H. Stock, 1995, Infer-
  ence in models with nearly integrated regressors, Econometric Theory 11,
  1131–1147.

Claus, James, and Jacob Thomas, 2001, Equity Premia as Low as Three Per-
  cent? Evidence from Analysts’ Earnings Forecasts for Domestic and Inter-
  national Stock Markets, The Journal of Finance 56, 1629–1666.

Cochrane, John H., 2008, The Dog That Did Not Bark: A Defense of Return
  Predictability, The Review of Financial Studies 21, 1533–1575.

Constantinides, George M., 2002, Rational Asset Prices, The Journal of Fi-
  nance 57, 1567–1591.




                                       39
DeLong, J. Bradford, and Konstantin Magin, 2009, The U.S. Equity Return
  Premium: Past, Present, and Future, The Journal of Economic Perspectives
  23, 193–208.

Diebold, Francis X., and Til Schuermann, 2000, Exact maximum likelihood es-
  timation of observation-driven econometric models, in M. Weeks R.S. Mari-
  ano, and T. Schuermann, eds.: Simulation-Based Inference in Econometrics:
  Methods and Applications (Cambridge University Press, ).

Donaldson, R. Glen, Mark J. Kamstra, and Lisa A. Kramer, 2010, Estimating
  the equity premium, Journal of Financial and Quantitative Analysis 45,
  813–846.

Elliott, Graham, 1999, Efficient Tests for a Unit Root When the Initial Ob-
  servation is Drawn from Its Unconditional Distribution, International Eco-
  nomic Review 40, 767–783.

Elliott, Graham, and James H Stock, 1994, Inference in Time Series Regression
  When the Order of Integration of a Regressor Is Unknown, Econometric
  Theory 10, 672–700.

Fama, Eugene F., and Kenneth R. French, 1989, Business conditions and
  expected returns on stocks and bonds, Journal of Financial Economics 25,
  23–49.

Fama, Eugene F., and Kenneth R. French, 2002, The Equity Premium, The
  Journal of Finance 57, pp. 637–659.

Ferson, Wayne E., Sergei Sarkissian, and Timothy T. Simin, 2003, Spurious
  regressions in financial economics?, Journal of Finance 58, 1393–1413.

French, Kenneth R., G. William Schwert, and Robert F. Stambaugh, 1987,
  Expected stock returns and volatility, Journal of Financial Economics 19,
  3–29.


                                     40
Graham, John R., and Campbell R. Harvey, 2005, The long-run equity risk
  premium, Finance Research Letters 2, 185–194.

Hamilton, J. D., 1994, Time Series Analysis. (Oxford University Press Prince-
  ton, NJ).

Hansen, Lars Peter, John C. Heaton, and Nan Li, 2008, Consumption strikes
  back? Measuring long run risk, Journal of Political Economy 116, 260–302.

Jansson, Michael, and Marcelo J. Moreira, 2006, Optimal Inference in Regres-
  sion Models with Nearly Integrated Regressors, Econometrica 74, 681–714.

Keim, Donald B., and Robert F. Stambaugh, 1986, Predicting returns in the
  stock and bond markets, Journal of Financial Economics 17, 357–390.

Kelly, Bryan, and Seth Pruitt, 2013, Market expectations in the cross-section
  of present values, The Journal of Finance 68, 1721–1756.

Kocherlakota, Narayana R., 1996, The Equity Premium: It’s Still a Puzzle,
  Journal of Economic Literature 34, 42–71.

Lettau, Martin, and Stijn Van Nieuwerburgh, 2008, Reconciling the return
  predictability evidence, Review of Financial Studies 21, 1607–1652.

Lettau, Martin, and Jessica A. Wachter, 2007, Why is long-horizon equity
  less risky? A duration-based explanation of the value premium, Journal of
  Finance 62, 55–92.

Lewellen, Jonathan, 2004, Predicting returns with financial ratios, Journal of
  Financial Economics 74, 209–235.

Lynch, Anthony W., and Jessica A. Wachter, 2013, Using Samples of Unequal
  Length in Generalized Method of Moments Estimation, Journal of Financial
  and Quantitative Analysis 48, 277–307.



                                     41
Malkiel, Burton Gordon, 2003, A random walk down Wall Street. (W. W. Nor-
  ton and Company, Inc. New York, NY).

Mehra, Rajnish, and Edward Prescott, 1985, The equity premium puzzle,
  Journal of Monetary Economics 15, 145–161.

Mehra, Rajnish, and Edward C. Prescott, 2003, The equity premium in retro-
  spect, in G. M. Constantinides, M. Harris, and R. M. Stulz, eds.: Handbook
  of the Economics of Finance (Elsevier, North-Holland ).

Merton, Robert C., 1980, On estimating the expected return on the market:
  An exploratory investigation, Journal of Financial Economics 8, 323–361.

Müller, Ulrich K., and Graham Elliott, 2003, Tests for Unit Roots and the
  Initial Condition, Econometrica 71, 1269–1286.

Nelson, C. R., and M. J. Kim, 1993, Predictable stock returns: The role of
  small sample bias, Journal of Finance 48, 641–661.

Pástor, Ľuboš, and Robert F. Stambaugh, 2001, The Equity Premium and
  Structural Breaks, The Journal of Finance 56, 1207–1239.

Pastor, Lubos, and Robert F. Stambaugh, 2009, Predictive systems: Living
  with imperfect predictors, Journal of Finance 64, 1583 – 1628.

Pettenuzzo, Davide, and Allan Timmermann, 2011, Predictability of stock re-
  turns and asset allocation under structural breaks, Journal of Econometrics
  164, 60–78.

Poirier, Dale J., 1978, The effect of the first observation in regression models
  with first-order autoregressive disturbances, Journal of the Royal Statistical
  Society, Series C, Applied Statistics 27, 67–68.




                                      42
Polk, Christopher, Samuel Thompson, and Tuomo Vuolteenaho, 2006, Cross-
  sectional forecasts of the equity premium, Journal of Financial Economics
  81, 101–141.

Shiller, Robert J., 1981, Do stock prices move too much to be justified by
  subsequent changes in dividends?, American Economic Review 71, 421–436.

Siegel, Jeremy J., 1994, Stocks for the long run: a guide to selecting markets
  for long-term growth. (Irwin Burr Ridge, IL).

Singleton, Kenneth, 2006, Empirical dynamic asset pricing: Model specifica-
  tion and econometric assessment. (Princeton University Press Princeton,
  NJ).

Stambaugh, Robert F., 1997, Analyzing investments whose histories differ in
  length, Journal of Financial Economics 45, 285–331.

Stambaugh, Robert F., 1999, Predictive regressions, Journal of Financial Eco-
  nomics 54, 375–421.

Torous, Walter, Rossen Valkanov, and Shu Yan, 2004, On predicting stock
  returns with nearly integrated explanatory variables, Journal of Business
  77, 937–966.

Van Binsbergen, Jules H., and Ralph S. J. Koijen, 2010, Predictive regressions:
  A present-value approach, The Journal of Finance 65, 1439–1471.

Wachter, Jessica A., and Missaka Warusawitharana, 2009, Predictable returns
  and asset allocation: Should a skeptical investor time the market?, Journal
  of Econometrics 148, 162–178.

Wachter, Jessica A., and Missaka Warusawitharana, 2015, What is the chance
  that the equity premium varies over time? Evidence from regressions on the
  dividend-price ratio, Journal of Econometrics 186, 74–93.


                                      43
Welch, Ivo, 2000, Views of Financial Economists on the Equity Premium and
  on Professional Controversies, The Journal of Business 73, 501–537.




                                    44
                      Table 1: Maximum Likelihood and OLS Estimates


                                1953–2011            1927–2011
                               OLS     MLE          OLS     MLE


                        µr     0.433       0.322    0.464    0.391
                        µx    −3.545      −3.504   −3.374   −3.383
                        β      0.828       0.686    0.623    0.650
                        θ      0.992       0.993    0.992    0.991
                        σu     4.414       4.416    5.466    5.464
                        σv     0.046       0.046    0.057    0.057
                        ρuv   −0.961      −0.961   −0.953   −0.953


Notes: Estimates of

                              rt+1 − µr    = β(xt − µx ) + ut+1
                              xt+1 − µx    = θ(xt − µx ) + vt+1 ,

where ut and vt are Gaussian and iid over time with standard deviations σu and σv and
correlation ρuv . rt is the continuously-compounded CRSP return minus the 30-day Treasury
Bill return and xt is the log of the dividend-price ratio. Data are monthly. Means and
standard deviations of returns are in percentage terms. Under the OLS columns, parameters
are estimated by ordinary least squares, except for µr and µx , which are equal to the sample
averages of excess returns and the log dividend-price ratio respectively. Under the MLE
columns, parameters are estimated using maximum likelihood.




                                              45
                  Table 2: Small-sample distribution of estimated parameters


      True Value        Method        Mean    Std. Dev.            5%      50 %    95 %

                  Panel A: DGP calibrated to maximum likelihood estimates
                        Sample        0.322        0.089     0.175       0.322      0.467
µr        0.322
                         MLE          0.323        0.050     0.241       0.324      0.404
                        Sample       −3.508        0.231    −3.894      −3.507     −3.126
µx      −3.504
                         MLE         −3.508        0.221    −3.875      −3.507     −3.145
                         OLS          1.284        0.699     0.420       1.145      2.639
β         0.686
                         MLE          1.243        0.670     0.440       1.103      2.541
                         OLS          0.987        0.007     0.973       0.988      0.996
θ         0.993
                         MLE          0.987        0.007     0.974       0.989      0.996
                         OLS          4.408        0.119     4.213       4.408      4.603
σu        4.416
                         MLE          4.406        0.119     4.211       4.406      4.600
                         OLS          0.046        0.001     0.044       0.046      0.048
σv        0.046
                         MLE          0.046        0.001     0.044       0.046      0.048
                         OLS         −0.961        0.003    −0.965      −0.961     −0.956
ρuv     −0.961
                         MLE         −0.961        0.003    −0.965      −0.961     −0.956
                     Panel B: DGP calibrated to bias-corrected estimates
                        Sample        0.324        0.138     0.097       0.327      0.546
µr        0.322
                         MLE          0.322        0.072     0.205       0.323      0.441
                        Sample       −3.510        0.582    −4.464      −3.512     −2.567
µx      −3.504
                         MLE         −3.510        0.557    −4.425      −3.506     −2.601
                         OLS          0.750        0.643    −0.009       0.610      1.989
β         0.090
                         MLE          0.686        0.601     0.036       0.528      1.881
                         OLS          0.991        0.007     0.978       0.992      0.999
θ         0.998
                         MLE          0.992        0.006     0.979       0.993      0.998
                         OLS          4.417        0.118     4.223       4.416      4.611
σu        4.424
                         MLE          4.417        0.118     4.225       4.416      4.612
                         OLS          0.046        0.001     0.044       0.046      0.048
σv        0.046
                         MLE          0.046        0.001     0.044       0.046      0.048
                         OLS         −0.961        0.003    −0.965      −0.961     −0.956
ρuv     −0.961
                         MLE         −0.961        0.003    −0.965      −0.961     −0.956
Notes: We simulate 10,000 monthly samples from the data generating process (DGP)

                              rt+1 − µr   = β(xt − µx ) + ut+1
                              xt+1 − µx   = θ(xt − µx ) + vt+1 ,

where ut and vt are Gaussian and iid over time with standard deviations σu and σv and
correlation ρuv . The sample length is as in postwar data. In Panel A parameters are set
to their maximum likelihood estimates. In Panel B parameters are set to their maximum
likelihood estimates with θ and β adjusted for bias. We conduct maximum likelihood esti-
mation (MLE) for each sample path. As a comparison, we take sample means to estimate
µr and µx (Sample) and use ordinary least squares to estimate the slope coefficients and
the variance and correlations of the residuals (OLS). The table reports the means, standard
deviations, and 5th, 50th, and 95th percentile values across simulations.

                                              46
     Table 3: Small-sample distribution of estimators under conditional heteroskedasticity


       True Value         Method           Mean Std. Dev.            5%      50 %    95 %

                        Sample             0.335    0.088           0.190    0.335     0.478
µr         0.335         MLE               0.335    0.049           0.253    0.335     0.415
                      GARCH-MLE            0.335    0.049           0.252    0.335     0.414
                        Sample            −3.570    0.225       −3.945      −3.570   −3.204
µx       −3.569          MLE              −3.571    0.214       −3.926      −3.572   −3.222
                      GARCH-MLE           −3.571    0.214       −3.922      −3.571   −3.224
                         OLS               1.288    0.694           0.425    1.156     2.621
β          0.689         MLE               1.244    0.668           0.436    1.103     2.554
                      GARCH-MLE            1.236    0.664           0.436    1.100     2.531
                         OLS               0.987    0.007           0.973    0.988     0.996
θ          0.993         MLE               0.987    0.007           0.974    0.989     0.996
                      GARCH-MLE            0.987    0.007           0.974    0.989     0.996
                         OLS               4.343    0.131           4.128    4.341     4.565
σu         4.351         MLE               4.342    0.131           4.126    4.340     4.563
                      GARCH-MLE            4.341    0.133           4.125    4.339     4.566
                         OLS               0.045    0.001           0.043    0.045     0.047
σv         0.045         MLE               0.045    0.001           0.043    0.045     0.047
                      GARCH-MLE            0.045    0.001           0.043    0.045     0.047
                         OLS              −0.959    0.003       −0.964      −0.959   −0.954
ρuv      −0.959          MLE              −0.959    0.003       −0.964      −0.959   −0.954
                      GARCH-MLE           −0.959    0.003       −0.964      −0.960   −0.954

Notes: We simulate 10,000 monthly data samples from

                              rt+1 − µr    = β(xt − µx ) + ut+1
                              xt+1 − µx    = θ(xt − µx ) + vt+1 ,

where ut and
         p vt follow GARCH processes with conditional correlation ρuv . The parameter
σu equals E[σut2 ] and similarly for σ . Parameters are set equal to estimates from GARCH-
                                      v
MLE as described in Section 5.1. For each sample path, we estimate parameters by OLS
(and report sample means for µr and µx ), by MLE (assuming homoskedastic shocks), and
by GARCH-MLE.




                                              47
Table 4: Small-sample distribution of estimators when the dividend-price ratio follows a
random walk


       True Value      Method        Mean    Std. Dev.           5%      50 %     95 %

                       Sample       0.325        0.166      0.050       0.327      0.599
µr        0.322
                        MLE         0.322        0.047      0.246       0.323      0.401
                       Sample      −2.988        0.699     −4.130      −2.996     −1.845
µx      undefined
                        MLE        −2.986        0.637     −4.006      −2.997     −1.971
                        OLS         0.710        0.608      0.005       0.571      1.883
β         0
                        MLE         0.629        0.562      0.062       0.467      1.729
                        OLS         0.992        0.006      0.980       0.994      1.000
θ         1.000
                        MLE         0.993        0.006      0.981       0.995      0.999
                        OLS         4.413        0.117      4.221       4.414      4.605
σu        4.423
                        MLE         4.415        0.117      4.223       4.417      4.607
                        OLS         0.046        0.001      0.044       0.046      0.048
σv        0.046
                        MLE         0.046        0.001      0.044       0.046      0.048
                        OLS        −0.962        0.003     −0.967      −0.962     −0.957
ρuv     −0.962
                        MLE        −0.962        0.003     −0.967      −0.962     −0.957

Notes: We simulate 10,000 monthly data samples from

                                  rt+1 − µr = ut+1
                                       xt+1 = xt + vt+1

where ut and vt are Gaussian and iid over time with correlation ρuv . For each sample path
we conduct (mis-specified) maximum likelihood estimation (MLE) of

                            rt+1 − µr   = β(xt − µx ) + ut+1
                            xt+1 − µx   = θ(xt − µx ) + vt+1 .

For comparison, we take sample means to estimate µr and µx (Sample) and use ordinary
least squares to estimate the slope coefficients and the variance and correlations of the
residuals (OLS). The table reports the means, standard deviations, and 5th, 50th, and 95th
percentile values across simulations.




                                            48
Table 5: Small-sample distribution of estimators when the dividend-price ratio has a time
trend


        True Value    Method        Mean    Std. Dev.            5%      50 %     95 %

                      Sample       0.322        0.168       0.044       0.321       0.599
µr          0.322
                       MLE         0.280        0.145       0.044       0.280       0.516
                      Sample      −3.682        0.234      −4.066      −3.682      −3.292
µx        −3.504
                       MLE        −3.663        0.223      −4.028      −3.661      −3.296
                       OLS         0.590        0.684      −0.255       0.460       1.880
β           0
                       MLE         0.514        0.660      −0.270       0.375       1.756
                       OLS         0.987        0.007       0.974       0.988       0.996
θ           0.993
                       MLE         0.988        0.007       0.975       0.989       0.996
                       OLS         4.410        0.117       4.219       4.410       4.602
σu          4.416
                       MLE         4.409        0.117       4.218       4.410       4.601
                       OLS         0.046        0.001       0.044       0.046       0.048
σv          0.046
                       MLE         0.046        0.001       0.044       0.046       0.048
                       OLS        −0.961        0.003      −0.965      −0.961      −0.956
ρuv       −0.961
                       MLE        −0.961        0.003      −0.965      −0.961      −0.956

Notes: We simulate 10,000 monthly data samples from

                           rt+1 − µr = ut+1
                           xt+1 − µx = ∆ + θ(xt − µx ) + vt+1

where ut and vt are Gaussian and iid over time with correlation ρuv . We set µr , µx , θ,
σu , σv and ρuv to their benchmark maximum likelihood estimates (Table 1) and ∆ to the
                     PT
mean residual (1/T ) t=1 v̂t = −0.14868. For each sample path we conduct (mis-specified)
maximum likelihood estimation (MLE) of

                            rt+1 − µr   = β(xt − µx ) + ut+1
                            xt+1 − µx   = θ(xt − µx ) + vt+1 .

For comparison, we take sample means to estimate µr and µx (Sample) and use ordinary
least squares to estimate the slope coefficients and the variance and correlations of the
residuals (OLS). The table reports the means, standard deviations, and 5th, 50th, and 95th
percentile values across simulations.




                                           49
                              Table 6: Sub-sample estimates


                                1953–1994           1995–2011
                               OLS     MLE         OLS     MLE


                       µr     0.439       0.315    0.411    0.336
                       µx    −3.342      −3.337   −4.048   −3.955
                       β      2.538       2.186    2.614    1.968
                       θ      0.977       0.981    0.972    0.979
                       σu     4.205       4.210    4.840    4.842
                       σv     0.043       0.043    0.051    0.051
                       ρuv   −0.967      −0.967   −0.948   −0.949


Notes: Estimates of

                             rt+1 − µr    = β(xt − µx ) + ut+1
                             xt+1 − µx    = θ(xt − µx ) + vt+1 ,

where ut and vt are Gaussian and iid over time with correlation ρuv . rt is the continuously-
compounded CRSP return minus the 30-day Treasury Bill return and xt is the log of the
dividend-price ratio. Two monthly data samples are considered: 1953–1994 and 1995–2011.
Means and standard deviations of returns are in percentage terms. Under the OLS columns,
parameters are estimated by ordinary least squares, except for µr and µx , which are equal
to the sample averages of excess returns and the log dividend-price ratio respectively. Under
the MLE columns, parameters are estimated using maximum likelihood.




                                             50
Table 7: Small-sample distribution of estimators in simulations calibrated to subsamples
from Table 6


     True Value      Method        Mean    Std. Dev.         5%         50 %      95%

                     Panel A1: DGP calibrated to 1953–1994 period
                     Sample       0.315         0.086     0.176        0.315       0.457
µr       0.315
                      MLE         0.316         0.062     0.214        0.315       0.417
                     Sample      −3.336         0.097    −3.494       −3.337      −3.179
µx     −3.337
                      MLE        −3.336         0.093    −3.488       −3.337      −3.183
β        2.186        MLE         2.983         1.133     1.518        2.776       5.122
θ        0.981        MLE         0.973         0.012     0.951        0.975       0.988
           Panel A2: DGP calibrated to 1953–1994 period with bias correction
                     Sample       0.315         0.115     0.125        0.314       0.504
µr       0.315
                      MLE         0.315         0.080     0.184        0.315       0.447
                     Sample      −3.336         0.166    −3.610       −3.337      −3.061
µx     −3.337
                      MLE        −3.336         0.158    −3.595       −3.336      −3.074
β        1.400        MLE         2.185         0.961     1.007        1.983       4.066
θ        0.990        MLE         0.981         0.010     0.962        0.983       0.993
                     Panel B1: DGP calibrated to 1995–2011 period
                     Sample       0.333         0.187     0.028        0.332       0.639
µr       0.336
                      MLE         0.334         0.110     0.153        0.335       0.516
                     Sample      −3.952         0.145    −4.194       −3.951      −3.712
µx     −3.955
                      MLE        −3.953         0.139    −4.183       −3.952      −3.721
β        1.968        MLE         3.841         2.220     1.158        3.358       8.071
θ        0.979        MLE         0.958         0.024     0.913        0.963       0.986
           Panel B2: DGP calibrated to 1995–2011 period with bias correction
                     Sample       0.331         0.339    −0.232        0.336       0.891
µr       0.336
                      MLE         0.332         0.152     0.083        0.332       0.582
                     Sample      −3.941         1.091    −5.741       −3.949      −2.161
µx     −3.955
                      MLE        −3.941         1.079    −5.733       −3.952      −2.175
β        0            MLE         2.109         1.877     0.136        1.620       5.831
θ        0.999        MLE         0.976         0.020     0.937        0.981       0.996

Notes: We simulate 10,000 monthly samples from the data generating process (DGP)

                           rt+1 − µr   = β(xt − µx ) + ut+1
                           xt+1 − µx   = θ(xt − µx ) + vt+1 ,

where ut and vt are Gaussian and iid over time with correlation ρuv . In Panel A, sample
length and paramaters are for the 1953–1994 subsample, without bias correction (A1) and
with bias correction (A2). In Panel B is constructed similarly for the 1995-2011 sample,
except that here the bias-correction is partial. For each sample path, we conduct maximum
likelihood estimation (MLE) and, for comparison, take sample means to find µr and µx
(Sample). The table reports the means, standard deviations, and 5th, 50th, and 95th
percentile values across simulations.


                                           51
                                                       8
                                                       7                           MLE
                                                       6
                                                       5
                Density


                                                       4
                                                       3
                                                       2                             Sample Mean

                                                       1
                                                       0
                                                              0         0.2       0.4       0.6    0.8
                                                                  Equity premium (monthly units)

Figure 1: Densities of the estimators of the equity premium in repeated samples of length
equal to the postwar data. The solid line shows the density of the maximum likelihood
estimate while the dashed line shows the density of the sample mean.
               Logarithm of the dividend-price ratio




                                                        −3



                                                       −3.5



                                                        −4



                                                       −4.5

                                                           Jan53 Jan63 Jan73 Jan83 Jan93 Jan03
                                                                             Month

Figure 2: The logarithm of the dividend-price ratio over the period January 1953 to De-
cember 2011 (the postwar sample). The dotted line indicates the mean, and the black dot
the initial value.




                                                                              52
               Panel A: Mean of the log dividend-price ratio                    Panel B: Equity premium, benchmark



                      0.8
                                                                              0.2
Standard deviation




                      0.6                                                    0.15
                                                                                                           Sample

                      0.4
                                                                              0.1
                      0.2                                                                                  MLE
                                                                             0.05
                       0.98     0.985       0.99       0.995        1          0.98      0.985      0.99       0.995       1

                     Panel C: Equity premium, no predictability              Panel D: Equity premium, uncorrelated shocks



                      0.2                                                     0.3
Standard deviation




                     0.15                                                    0.25


                      0.1                                                     0.2


                     0.05                                                    0.15
                       0.98     0.985       0.99     0.995          1          0.98      0.985      0.99     0.995         1
                                         Persistence                                             Persistence

                        Figure 3: Standard deviation of estimators of the mean of the log-dividend price ratio
                        (Panel A) and of the equity premium (Panels B–D). Estimators are the sample mean (dots)
                        and maximum likelihood (crosses). For each value of the autocorrelation θ, we simulate
                        10,000 monthly samples and calculate the standard deviation of estimates across samples.
                        Parameters other than θ are set equal to their maximum likelihood estimates with the
                        following exceptions. In Panel B, the predictive coefficient is bias-corrected. In Panel C,
                        the predictive coefficient is set equal to zero. In Panel D, the predictive coefficient is bias-
                        corrected and the correlation of the shocks is set equal to zero.




                                                                        53
Appendix

A     Derivation of the Maximum Likelihood Estimators
We denote the maximum likelihood estimate of parameter q as q̂. Here we derive
the estimators for µr , µx , β, θ, σu2 , σv2 and σuv . We note in particular that σ̂u2 is
the estimator of σu2 , not the square of the estimator of σu , and similarly for σ̂v2 .
Maximizing the exact log likelihood function is the same as minimizing the function
L:

                                                                   1 − θ2
  L(β, θ, µr , µx , σuv , σu , σv ) = log(σv2 ) − log(1 − θ2 ) +          (x0 − µx )2
                                                                     σv2
                                                       T            T            T
                                                   σv2 X 2      σuv X        σ2 X 2
                                + T log(|Σ|) +           ut − 2       ut vt + u    vt ,
                                                   |Σ|          |Σ|          |Σ|
                                                        t=1               t=1           t=1

                       2 . The first-order conditions arise from setting the following
where |Σ| = σu2 σv2 − σuv
partial derivatives of the likelihood function to zero:
                    T                       T
            ∂   σ2 X                    σuv X
      0=      L= v    ut (µx − xt−1 ) −       (µx − xt−1 )vt                              (A.1a)
           ∂β   |Σ|                     |Σ|
                         t=1                            t=1
         ∂       θ        (x0 − µx )2
      0=    L=        − θ
         ∂θ    1 − θ2         σv2
                                            T                       T
                                        σuv X                   σu2 X
                                      −       ut (µx − xt−1 ) +       vt (µx − xt−1 )
                                        |Σ|                     |Σ|
                                            t=1                           t=1
                                                                                         (A.1b)
                     T          T
           ∂     σ2 X       σuv X
     0=       L=− v    ut +       vt                                                      (A.1c)
          ∂µr    |Σ|        |Σ|
                          t=1              t=1
           ∂      1     − θ2
     0=       L=−       (x0 − µx )
          ∂µx       σv2
                                T           T                         T
                            σv2 X       σuv X                     σ2 X
                        +         βut −       (βvt − (1 − θ)ut ) − u    (1 − θ)vt
                            |Σ|         |Σ|                       |Σ|
                                t=1               t=1                            t=1
                                                                                         (A.1d)
           ∂          2σuv
     0=        L = −T
          ∂σuv         |Σ|




                                                  54
                                     T                      T                   T
                             σuv σv2 X 2      σu2 σv2 + σuv
                                                         2 X            σuv σu2 X 2
                          +2           ut − 2                 ut vt + 2           vt
                              |Σ|2                 |Σ|2                  |Σ|2
                                        t=1                      t=1              t=1
                                                                                       (A.1e)
                              T                T             T
          ∂         σv2   σv4 X 2      σuv σv2 X          2 X
                                                        σuv
    0=        L = T     −       ut + 2           u v
                                                  t t −        vt2                     (A.1f)
         ∂σu2       |Σ| |Σ|2            |Σ|2            |Σ|2
                                  t=1                   t=1              t=1



          ∂       1       σu2                        1
    0=        L =     + T     − (1 − θ2 )(x0 − µx )2 4
         ∂σv2     σv2     |Σ|                       σv
                                                2 XT                T             T
                                              σuv     2     σuv σu2 X         σu4 X 2
                                        −            ut + 2           u v
                                                                       t t −        vt .
                                              |Σ|2           |Σ|2            |Σ|2
                                                  t=1              t=1           t=1
                                                                                       (A.1g)

   Define the residuals

                             ût = rt − µ̂r − β̂(xt−1 − µ̂x )

                             v̂t = xt − µ̂x − θ̂(xt−1 − µ̂x ).

We now outline the algebra that allows us to solve these first-order conditions.


Step 1: Express µ̂x in terms of θ̂ and the data.

Combining the first-order conditions (A.1c) and (A.1d) gives
                              T
                              X                
                                    v̂t = 1 + θ̂ (µ̂x − x0 ) ,                          (A.2)
                              t=1

which we can write as
                                          P             
                              1 + θ̂ x0 + Tt=1 xt − θ̂xt−1
                        µ̂x =                            .                          (A.3)
                                     1 + θ̂ + 1 − θ̂ T


Step 2: Express the covariance matrix in terms of µ̂x , θ̂, µ̂r , β̂ and
the data.

The first-order conditions (A.1e), (A.1f) and (A.1g) give the relations




                                                 55
                                                                                              2       T
                                 σ̂uv                                                  σ̂uv             X
                     T σ̂u2   = − 2 σ̂uv + (1 − θ̂2 )(x0 − µ̂x )2                                   +         û2t ,        (A.4)
                                  σ̂v                                                   σ̂v2
                                                                                                        t=1
                                                               T
                                                               X
            (T + 1)σ̂v2 = (1 − θ̂2 )(x0 − µ̂x )2 +                       v̂t2 ,                                             (A.5)
                                                               t=1
                            PT
                     σ̂uv        ût v̂t
                        2
                          = Pt=1
                              T
                                         .                                                                                  (A.6)
                      σ̂v     t=1 v̂t
                                     2



Step 3: Solve for θ̂ in terms of the data. This also gives µ̂x and σ̂v2
in terms of the data.

Combining the first-order conditions (A.1a) and (A.1b) gives
                              T
                              X                                     θ̂
                      0=            (µ̂x − xt−1 )v̂t + σ̂v2                  − θ̂(x0 − µ̂x )2 .                             (A.7)
                              t=1                             1 − θ̂2

Here µ̂x and v̂t are functions of only θ̂ and the data, so if we combine (A.7) and
(A.5) we can get an equation for θ̂:
                               T                                          T
                               X                               θ̂         X
                0 = (T + 1)          (µ̂x − xt−1 )v̂t +                           v̂t2 − T θ̂(x0 − µ̂x )2 .
                               t=1                         1 − θ̂2         t=1

Because we require that −1 < θ̂ < 1, we can multiply this by
                                                               2                  
                                        (T + 1) − (T − 1)θ̂                1 − θ̂2

and rearrange to obtain


                                      T         T −1
                                                                                           !2
                                X         X
                             2
  0 = T θ̂ − 1 (T + 1) 1 − θ̂ + 2θ̂     xt − θ̂      xt
                                                              t=0                 t=1
                                                   T         T −1
                                                                                                        !
                                               X         X
                    + (T + 1) − (T − 1)θ̂ θ̂ − 1     xt − θ̂      xt
                                                                            t=0                t=1
                                T −1                                                  T                  T −1
            "                                 !                                                                        !#
                                X                                                   X                  X
       × 2T θ̂(1 + θ̂)                   xt       − (T + 1) + (T − 1)θ̂                         xt +             xt
                                 t=1                                                      t=0            t=1
                                                               2
                                          + (T + 1) − (T − 1)θ̂



                                                         56
                                 T −1                                               T                   T
  "                                           !                                                                 #
                             X                                                X                   X
× θ̂        1 − θ̂2 T + 1               x2t       + θ̂2 (T − 1) − (T + 1)                xt xt−1 + θ̂         x2t .
                                 t=1                                               t=1                  t=0

This is a fifth-order polynomial in θ̂ where the coefficients are determined by the
sample. As a consequence, it is very hard to establish analytical results on existence
and uniqueness of solutions that would be accepted as estimators of θ. Nevertheless,
in lengthy experimentation and simulation runs we have always found that this
polynomial only has one root within the unit circle of the complex plane and that
this root is real. Therefore this root is a valid MLE of θ. Given this solution for θ̂,
(A.3) gives the estimator for µx and (A.5) gives the estimator for σv2 .


Step 4: Solve for µ̂r and β̂ in terms of the data. This also gives the
solution for σ̂uv and σ̂u2 .

The first-order condition (A.1c) gives
                                               T                     T
                                               X               σ̂uv X
                                                     ût =             v̂t .                                   (A.8)
                                                                σ̂v2
                                               t=1                  t=1

Combining this with the first-order condition (A.1a) yields

                                                           σ̂uv             
                                     β̂ = β OLS +                 θ̂ − θ OLS
                                                                               ,                               (A.9)
                                                            σ̂v2

where
                                                                 T             T                      T
                                                           "                                   !                 !#
                                1                              1X            1X                     1X
θOLS =                                                2           xt−1 xt −     xt−1                   xs
                                                               T             T                      T
                PT               P
            1         2           1 T
            T    t=1 xt−1 −      T      t=1 xt−1                  t=1               t=1                  s=1


is the OLS coefficient of regressing xt on xt−1 and
                                                 T               T              T
                                            "                            !            !#
  OLS                   1                     1X              1X             1X
β     = P                                2         xt−1 rt −       xt−1   −       rs
                                              T               T              T
                         P
         1  T     2       1    T
        T       x
            t=1 t−1   −   T    t=1 x t−1        t=1             t=1            s=1


is the OLS coefficient of regressing rt on xt−1 .
      Equations (A.6), (A.8) and (A.9) constitute a system of three equations in the
                                     σ̂uv
three unknowns µ̂r , β̂ and           σ̂v2
                                           .   The solution is




                                                             57
                    T                   T
                 "                                         !
                1 1X                  1X                          F − β OLS H
          µ̂r =       rt −                xt − µ̂x
                J T                   T                        1 + (θ̂ − θOLS )H
                          t=1             t=1
                                          T
                                                               !                          #
                                      1   X                      β OLS (1 + θ̂H) − θOLS F
                                  −             xt−1 − µ̂x                                          (A.10)
                                      T                             1 + (θ̂ − θOLS )H
                                          t=1
                  β OLS + (θ̂ − θOLS )F              (θ̂ − θOLS )G
           β̂ =                                 −                       µ̂r                         (A.11)
                    1 + (θ̂ − θOLS )H     1 + (θ̂ − θOLS )H
        σ̂uv         F −β   OLS H              G
                =                    −                   µ̂r ,                                      (A.12)
         σ̂v2     1 + (θ̂ − θOLS )H    1 + (θ̂ − θOLS )H

where
                                                  T                             T
                                            "                                                  !#
                                 G              1X                            1X
         J =1−                                      xt − µ̂x − θOLS               xt−1 − µ̂x
                       1 + (θ̂ − θOLS )H        T                             T
                                                    t=1                         t=1
                 PT
                        rt v̂t
         F = Pt=1
               T           2
                     t=1 v̂t
                  PT
                         v̂t
         G = PTt=1
                        2
                  t=1 v̂t
                 PT
                  t=1 (xt−1 − µ̂x )v̂t
        H=           PT                .
                              v̂ 2
                          t=1    t

Expressions (A.10) and (A.11) provide the estimators for µr and β because they
depend only on the data and µ̂x and θ̂, which we have already expressed in terms of
the data. Finally, (A.12) gives the estimator the estimator of σuv via (A.5), which
further yields the estimator of σu2 via (A.4).


B     Mean Reversion in Returns
Consider the effect of a series of shocks on excess returns (in this subsection, we will
assume, for expositional reasons, that the mean excess return is zero):

                                   rt = βxt−1 + ut

                                 rt+1 = βθxt−1 + βvt + ut+1

                                 rt+2 = βθ2 xt−1 + βθvt + βvt+1 + ut+2




                                                          58
and so on. Thus, for k ≥ 1, the autocovariance of returns is given by

                      Cov (rt , rt+k ) = θk β 2 Var(xt ) + θk−1 βσuv ,           (B.1)

where Var(xt ) = σv2 /(1−θ2 ). An increase in θ increases the variance of the predictor
variable. In the absence of covariance between the shocks u and v, this effect would
increase the autocovariance of returns through the term θk β 2 Var(xt ). However,
because u and v are negatively correlated, the second term in (B.1), θk−1 βσuv is also
negative. We show below that this second term dominates the first for all positive
values of θ up until a critical value, at which point the first comes to dominate.
    Assume θ > 0, β > 0 and σuv < 0, as we estimate the case to be in our data.
Substituting in Var(xt ) = σv2 /(1 − θ2 ), multiplying by (1 − θ2 ) > 0 and dividing
through by θk−1 β > 0 shows that the autocovariance of returns is negative whenever

                              −σuv θ2 + βσv2 θ + σuv < 0.

The left-hand side is a quadratic polynomial in θ with a positive leading coefficient.
As a result, whenever this polynomial has two real roots in θ, the entire expression
is negative if and only if θ lies in between those roots. Indeed, the polynomial has
two real roots because its discriminant equals β 2 σv4 +4σuv
                                                          2 > 0. Let θ be the smaller
                                                                      1

of the two roots and let θ2 be the larger one, that is,
                                          p
                                 −βσv2 + β 2 σv4 + 4σuv 2
                            θ2 =                          .
                                          −2σuv
Under our assumptions it is straightforward to prove that θ1 < −1 and −1 < θ2 < 1,
so the only possible change of sign of the return autocovariance happens at θ2 . In
particular, Cov (rt , rt+k ) < 0 whenever θ < θ2 and Cov (rt , rt+k ) > 0 whenever
θ > θ2 .


C     The Variance of the Sample Mean Return
By definition
                    T                     T                         T
                                                          !
                  1X                    1X                        1X
                      rt = µr + β           xt−1 − µx         +       ut ,
                  T                     T                         T
                    t=1                    t=1                      t=1



                                            59
thus
            T                                T                        T
                     !                                 !                     !
          1X                    2          1X                       1X
  Var         rt          = β Var              xt−1         + Var       ut
          T                                T                        T
             t=1                              t=1                    t=1
                                                                               T          T
                                                                                                 !
                                                                             1X         1X
                                                                + 2βCov          xt−1 ,     ut       .
                                                                             T          T
                                                                                 t=1       t=1

The variance of the average predictor is available and it depends on θ. The variance
of the average residual does not depend on θ. Finally, the covariance of the average
predictor and the average predictor depends on θ and ρuv . It is not a trivial quantity
because even though ut is uncorrelated with xt−1 , it is correlated with xt via vt
whenever ρuv 6= 0 and thus it is also correlated with xt+1 , xt+2 , . . . , xT −1 whenever
θ 6= 0.
    In particular,
                                  T
                                              !
                                1X                     1
                         Var        ut            = σu2 ,
                                T                      T
                                     t=1
                                 T
                                              !
                                      σv2                      2 θ(θT − 1)
                                                                        
                               1X            1        θ
               Var                =xt−1          1+2       + 2               ,
                               T    1 − θ2 T         1−θ      T (1 − θ)2
                        t=1
               T            T
                                !
                                                   1 θT − 1
                                                            
             1X         1X                1 1
       Cov       xt−1 ,       ut = σuv           + 2           ,
             T          T                 T 1 − θ T (1 − θ)2
                   t=1               t=1

so that
            T
                     !
                                                         2
                                                            
          1X                1         2       σuv    2 σv
  Var         rt          =          σu + 2β      +β
          T                 T                1−θ      1 − θ2
             t=1
                                                                      1 − θT           σv2
                                                                                                
                                                                1
                                                              − 2 2β              βθ        + σuv .
                                                               T     (1 − θ)2        1 − θ2

    It follows that
                       T
                                    !
                                                         2
                                                                           
                     1X                   1     2     2 σv         σuv       1
             Var         rt             =      σu + β      2
                                                             + 2β        +O     .
                     T                    T            1−θ        1−θ        T2
                          t=1

The term σu2 + β 2 σv2 /(1 − θ2 ) measures the contribution of the return shocks and
the predictor to the variability of the sample-mean return. The term βσuv /(1 − θ)
measures the contribution of the covariance of the return shocks and the predictor



                                                        60
shocks to the variability of the sample-mean return. The former term increases as
θ increases, which says that the sample-mean return is more variable because the
predictor is more variable. At the same time, the latter term becomes more negative
as θ increases, so that in fact the overall variability of the sample-mean return can
decrease.




                                         61
   Table A.1: Small-sample distribution of estimators: calibration to 1927–2011 sample


            True Value   Method      Mean Std. Dev.        5%       50 %      95 %

                         Sample     0.390    0.080       0.258     0.389     0.522
      µr      0.391
                          MLE       0.391    0.058       0.295     0.390     0.485
                         Sample    −3.383    0.196      −3.710    −3.385    −3.063
      µx     −3.383
                          MLE      −3.384    0.190      −3.701    −3.384    −3.074
                          OLS       1.039    0.547       0.336     0.941     2.063
      β       0.650
                          MLE       1.018    0.530       0.345     0.923     2.007
                          OLS       0.987    0.006       0.976     0.988     0.995
      θ       0.991
                          MLE       0.987    0.006       0.977     0.989     0.994
                          OLS       5.460    0.119       5.265     5.459     5.655
      σu      5.464
                          MLE       5.458    0.119       5.263     5.458     5.653
                          OLS       0.057    0.001       0.055     0.057     0.059
      σv      0.057
                          MLE       0.057    0.001       0.055     0.057     0.059
                          OLS      −0.953    0.003      −0.958    −0.953    −0.948
      ρuv    −0.953
                          MLE      −0.953    0.003      −0.958    −0.953    −0.948

Notes: We simulate 10,000 monthly samples from

                            rt+1 − µr   = β(xt − µx ) + ut+1
                            xt+1 − µx   = θ(xt − µx ) + vt+1 ,

where ut and vt are Gaussian and iid over time with standard deviations σu and σv and
correlation ρuv . The sample length is set to match the 1927–2011 sample, and parameters are
set to their maximum likelihood estimates over this period. We conduct maximum likelihood
estimation (MLE) for each sample path. As a comparison, we take sample means to estimate
µr and µx (Sample) and use ordinary least squares to estimate the slope coefficients and
the variance and correlations of the residuals (OLS). The table reports the means, standard
deviations, and 5th, 50th, and 95th percentile values across simulations.




                                            62
           Table A.2: Small-sample distribution of estimators: t-distributed shocks
             True Value    Method      Mean Std. Dev.          5%       50 %      95 %

                           Sample      0.323    0.138       0.098      0.320     0.552
       µr       0.322
                            MLE        0.322    0.072       0.204      0.322     0.440
                           Sample     −3.504    0.578      −4.454     −3.498    −2.543
       µx     −3.504
                            MLE       −3.504    0.549      −4.404     −3.498    −2.589
                            OLS        0.746    0.634      −0.007      0.601     1.947
       β        0.090
                            MLE        0.683    0.594       0.040      0.533     1.836
                            OLS        0.991    0.007       0.978      0.993     0.999
       θ        0.998
                            MLE        0.992    0.006       0.980      0.993     0.998
                            OLS        4.419    0.185       4.136      4.411     4.727
       σu       4.430
                            MLE        4.419    0.185       4.136      4.410     4.727
                            OLS        0.046    0.002       0.043      0.045     0.049
       σv       0.046
                            MLE        0.046    0.002       0.043      0.045     0.049
                            OLS       −0.961    0.004      −0.967     −0.961    −0.954
       ρuv    −0.961
                            MLE       −0.961    0.004      −0.967     −0.961    −0.954

Notes: We simulate 10,000 monthly samples from

                              rt+1 − µr   = β(xt − µx ) + ut+1
                              xt+1 − µx   = θ(xt − µx ) + vt+1 ,

where [ut , vt ] has a bivariate t-distribution. The sample length is as in postwar data. Param-
eters are set to their maximum likelihood estimates (assuming normally distributed shocks)
where β and θ are adjusted for bias. We conduct benchmark maximum likelihood estimation
(MLE) for each sample path (this assumes normality and is therefore mis-specified). As a
comparison, we take sample means to estimate µr and µx (Sample) and use ordinary least
squares to estimate the slope coefficients and the variance and correlations of the residuals
(OLS). The table reports the means, standard deviations, and 5th, 50th, and 95th percentile
values across simulations. We set the degrees of freedom for the t-distribution to 5.96. This
matches the average kurtosis of the estimated residuals for returns and the dividend-price
ratio, and takes into account that the kurtosis is downward biased.




                                               63
    Table A.3: Small-sample distribution of estimators: Calibration to OLS estimates


             True Value    Method     Mean Std. Dev.         5%      50 %      95 %

                          Panel A: January 1953 to December 2011
                           Sample    0.432    0.082       0.297     0.431     0.565
       µr      0.433
                            MLE      0.432    0.049       0.352     0.432     0.513
                           Sample   −3.550    0.192      −3.865    −3.551    −3.232
       µx     −3.545
                            MLE     −3.550    0.184      −3.854    −3.552    −3.242
                            OLS      1.414    0.715       0.512     1.276     2.801
       β       0.828
                            MLE      1.372    0.689       0.515     1.241     2.675
                            OLS      0.986    0.007       0.971     0.987     0.995
       θ       0.992
                            MLE      0.986    0.007       0.972     0.988     0.995
                            OLS      4.410    0.118       4.215     4.410     4.603
       σu      4.414
                            MLE      4.408    0.118       4.214     4.408     4.601
                            OLS      0.046    0.001       0.044     0.046     0.048
       σv      0.046
                            MLE      0.046    0.001       0.044     0.046     0.048
                            OLS     −0.961    0.003      −0.965    −0.961    −0.956
       ρuv    −0.961
                            MLE     −0.961    0.003      −0.965    −0.961    −0.956
                          Panel B: January 1927 to December 2011
                           Sample    0.463    0.082       0.326     0.462     0.596
       µr      0.464
                            MLE      0.464    0.058       0.367     0.463     0.560
                           Sample   −3.373    0.200      −3.702    −3.373    −3.044
       µx     −3.374
                            MLE     −3.373    0.194      −3.690    −3.374    −3.054
                            OLS      1.019    0.543       0.322     0.925     2.051
       β       0.623
                            MLE      0.995    0.527       0.329     0.903     1.983
                            OLS      0.987    0.006       0.976     0.988     0.995
       θ       0.992
                            MLE      0.988    0.006       0.977     0.989     0.995
                            OLS      5.465    0.121       5.269     5.463     5.668
       σu      5.466
                            MLE      5.463    0.121       5.268     5.461     5.666
                            OLS      0.057    0.001       0.055     0.057     0.059
       σv      0.057
                            MLE      0.057    0.001       0.055     0.057     0.059
                            OLS     −0.953    0.003      −0.958    −0.953    −0.948
       ρuv    −0.953
                            MLE     −0.953    0.003      −0.958    −0.953    −0.948

Notes: We simulate 10,000 monthly samples from

                             rt+1 − µr   = β(xt − µx ) + ut+1
                             xt+1 − µx   = θ(xt − µx ) + vt+1 ,

where ut and vt are Gaussian and iid over time with standard deviations σu and σv and
correlation ρuv . The sample length is as in postwar data. Parameters are set to their OLS
estimates. We conduct maximum likelihood estimation (MLE) for each sample path. As a
comparison, we take sample means to estimate µr and µx (Sample) and use ordinary least
squares to estimate the slope coefficients and the variance and correlations of the residuals
(OLS). The table reports the means, standard deviations, and 5th, 50th, and 95th percentile
values across simulations.                   64
         Table A.4: Estimation of a predictive regression with heteroskedasticity


               Panel A:                       Panel B:                    Panel C:
         Means and coefficients         Volatility parameters         Covariance matrix

         µr    0.335                    ωu    4.763                   σu∗    4.351
         µx   −3.569                    αu    0.029                   σv∗    0.045
         β     0.688                    δu    0.719                   ρuv   −0.959
         θ     0.993                    ωv    1.855 × 10−4
                                        αv    0.016
                                        δv    0.892

Notes: We estimate the bivariate process

                             rt+1 − µr       = β(xt − µx ) + ut+1
                             xt+1 − µx       = θ(xt − µx ) + vt+1 ,

where, conditional on information available up to and including time t,
                                           2
                                                                    
                  ut+1                   σu,t+1       ρuv σu,t+1 σv,t+1
                          ∼ N 0,                             2             ,
                  vt+1              ρuv σu,t+1 σv,t+1      σv,t+1

and
                                 2
                                σu,t+1 = ωu + αu u2t + δu σu,t
                                                           2
                                                               ,
                                   2
                                  σv,t+1 = ωv + αv vt2 + δv σv,t
                                                             2
                                                                 .

Here, rt is the continuously compounded return on the value-weighted CRSP portfolio in
excess of the return on the 30-day Treasury Bill and xt is the log of p
                                                                      the dividend-price ratio.
Starredpparameters are implied by other estimates, namely σu∗ = ωu /(1 − αu − δu ) and
σv∗ = ωv /(1 − αv − δv ). Parameters are estimated using a two-stage process by which
the means and coefficients (Panel A) are treated as fixed and the volatility parameters
(Panels B and C) are estimated using conditional maximum likelihood in the first stage,
and the volatility parameters are treated as fixed, while the means and coefficients are re-
estimated in the second stage. Data are monthly, from January 1953 to December 2011.
Means and standard deviations of returns are in percentage terms.




                                                65
                                      1000


                                       800
                   Frequency

                                       600


                                       400


                                       200


                                         0
                                                0.94        0.96         0.98           1
                                                           Root of θ polynomial

Figure A.1: Histogram of maximum likelihood estimates of θ, the autocorrelation of the
dividend-price ratio from simulated data. We simulate 10,000 monthly data samples from
(1) with length and parameters as in the postwar data series.




                                       0.3

                                       0.2
                Predictability term




                                       0.1

                                        0

                                      −0.1

                                      −0.2

                                      −0.3
                                             −0.3   −0.2   −0.1     0     0.1     0.2       0.3
                                                            Correlated shock

Figure A.2: We simulate 10,000 monthly data samples from (1) with length and parameters
as in the postwar data series. The figure shows the joint distribution of the predictability
          PT                                                PT
term β̂ T1 t=1 (xt−1 −µ̂x ) and the correlated shock term T1 t=1 ût that sum to the difference
between the maximum likelihood estimate and the sample mean.




                                                                66
