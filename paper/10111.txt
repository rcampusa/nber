                                 NBER WORKING PAPER SERIES




              A TALE OF TWO TIME SCALES: DETERMINING INTEGRATED
                  VOLATILITY WITH NOISY HIGH-FREQUENCY DATA

                                              Lan Zhang
                                            Per A. Mykland
                                           Yacine Ait-Sahalia

                                         Working Paper 10111
                                 http://www.nber.org/papers/w10111


                       NATIONAL BUREAU OF ECONOMIC RESEARCH
                                1050 Massachusetts Avenue
                                  Cambridge, MA 02138
                                     November 2003




We gratefully acknowledge the support of the National Science Foundation under grants DMS-0204639
(Zhang and Mykland) and SBR-0111140 (Aït-Sahalia). The views expressed herein are those of the authors
and not necessarily those of the National Bureau of Economic Research.

©2003 by Lan Zhang, Per A. Mykland, and Yacine Ait-Sahalia. All rights reserved. Short sections of text,
not to exceed two paragraphs, may be quoted without explicit permission provided that full credit, including
© notice, is given to the source.
A Tale of Two Time Scales: Determining Integrated Volatility with Noisy High Frequency Data
Lan Zhang, Per A. Mykland, and Yacine Ait-Sahalia
NBER Working Paper No. 10111
November 2003
JEL No. C32, G12

                                           ABSTRACT

It is a common practice in finance to estimate volatility from the sum of frequently-sampled squared

returns. However market microstructure poses challenges to this estimation approach, as evidenced

by recent empirical studies in finance. This work attempts to lay out theoretical grounds that

reconcile continuous-time modeling and discrete-time samples. We propose an estimation approach

that takes advantage of the rich sources in tick-by-tick data while preserving the continuous-time

assumption on the underlying returns. Under our framework, it becomes clear why and where the

"usual" volatility estimator fails when the returns are sampled at the highest frequency.

Lan Zhang
Department of Statistics
Carnegie Mellon University
Pittsburgh, PA 15213
lzhang@stat.cmu.edu

Per A. Mykland
Department of Statistics
The University of Chicago
Chicago, IL 60637
mykland@galton.uchicago.edu

Yacine Ait-Sahalia
Bendheim Center for Finance
Princeton University
Princeton, NJ 08544-1021
and NBER
yacine@princeton.edu
A Tale of Two Time Scales: Determining Integrated Volatility                                          2


1    INTRODUCTION

In the analysis of high frequency …nancial data, a major problem concerns the nonparametric
determination of the volatility of an asset return process. A common practice is to estimate volatility
from the sum of the frequently-sampled squared returns. Though this approach is justi…ed under
the assumption of a continuous stochastic model in an idealized world, it meets the challenge
from market microstructure in real applications. We argue that this customary way of estimating
volatility is ‡awed in that it overlooks observation error. The usual mechanism for dealing with the
problem is to throw away some data, by sampling less frequently or constructing “time-aggregated”
returns from the underlying high frequency asset prices. We propose here a statistically sounder
device. Our device is model-free, it takes advantage of the rich sources in tick-by-tick data, and to a
great extend it corrects the e¤ect of the microstructure noise on volatility estimation. In the course
of constructing our estimator, it becomes clear why and where the “usual”volatility estimator fails
when the returns are sampled at high frequency.

   Our interest lies in using high frequency intraday data to estimate the integrated volatility over
some time periods. To …x the ideas, let fSt g denote the price process of a security, and suppose
the log-return process fXt g, where Xt = log St , follows an Itô process
                                               Xt =   t dt   +   t dBt                              (1)
where Bt is a standard Brownian motion. Typically, 2t ; the instantaneous variance (or di¤usion
coe¢ cient) of the return process fXt g; will be stochastic. The parameter of interest is the integrated
                                                               RT         RT
(cumulative) volatility over one or successive time periods, 0 1 2t dt , T12 2t dt; .... A natural way
to estimate the cumulative volatility over, say, a single time interval from 0 to T , is to use the sum
of squared incremental returns,
                                    X                      Z T
                                        (Xti+1 Xti )2           2
                                                                t dt;                                (2)
                                     ti                            0
                                                                                          P
where the Xti ’s are all the observations of the return process in [0; T ]. The estimator ti (Xti+1
Xti )2 is commonly used and generally called “realized volatility” or “realized variance.” For a
sample of the recent literature in integrated volatility, see Hull and White (1987), Jacod and Protter
(1998), Gallant, Hsu, and Tauchen (1999), Chernov and Ghysels (2000), Gloter (2000), Andersen,
Bollerslev, Diebold, and Labys (2001), Barndor¤-Nielsen and Shephard (2001), Mykland and Zhang
(2002) and others.

   Under model (1), the approximation in (2) is justi…ed by theoretical results in stochastic
processes which state that                           Z T
                                 X
                            plim   (Xti+1 Xti )2 =       2
                                                         t dt;                            (3)
                                          ti                             0

as the sampling frequency increases. In other words, the estimation error of the realized volatility
diminishes. According to (3), realized volatility computed from the highest frequency data ought
                                         RT
to provide the best possible estimate for 0 2t dt the integrated volatility.
A Tale of Two Time Scales: Determining Integrated Volatility                                        3


    However, this is not the general viewpoint from the …nance literature. It is generally held there
that the returns process Xt should not be sampled too often, regardless of the fact that the asset
prices can often be observed with extremely high frequency, such as several times per second. It has
been found empirically that the estimator is not robust when the sampling interval is quite small.
Issues including bigger bias in the estimate and non-robustness to changes in sampling interval have
been reported (see e.g., Brown (1990), Campbell, Lo, and MacKinlay (1997), Bai, Russell, and Tiao
(2000)). The main explanation for this phenomenon is a vast array of issues collectively known
as market microstructure, such as, but not limited to, the existence of the bid-ask spread: see
Aït-Sahalia, Mykland, and Zhang (2003) for a description of these phenomena and their grounding
in the vast theoretical literature describing the frictions inherent in the trading process. When
prices are sampled at …ner intervals, microstructure issues become more pronounced. It is then
suggested that the bias induced by market microstructure e¤ects makes the most …nely sampled
data unusable for the calculation, and many authors prefer to sample over longer time horizons to
obtain reasonable estimates. The length of the the typical choices in the literature is ad hoc and
ranges from 5 to 30 minutes for exchange rate data, for instance.

    This approach to handling the data poses a conundrum from the statistical point of view. We
argue here that sampling over longer horizon merely reduces the impact of microstructure, rather
than quantifying and correcting its e¤ect for volatility estimation. And it goes against the grain
to throw away data. On the other hand, market microstructure may pose so many problems that
subsampling is the only way out.

    In this paper we analyze the trade o¤s involved in the choice of sampling frequency and develop
a method to estimate integrated volatility in such a way as to lessen this con‡ict. Our contention
in the following is that the contamination due to market microstructure is, to …rst order, the same
as what statisticians usually call “observation error”. We shall incorporate the observation error
into the estimating procedure for integrated volatility. In other words, we shall suppose that the
return process as observed at the sampling times is of the form

                                             Yti = Xti +   ti :                                   (4)

Here Xt is a latent true, or e¢ cient, return process, and the 0ti s are independent noise around the
true return. A similar structure was used in the parametric context where t = is constant by
Aït-Sahalia, Mykland, and Zhang (2003). In that paper, due to the parametric nature of volatility,
we proposed likelihood-based corrections for market microstructure.

    We show in Section 2.2 that, if the data have a structure of the form (4), ignoring microstructure
noise would have a devastating e¤ect on the use of the realized volatility. Instead of (2), one gets
                             X
                                      (Yti+1 Yti )2 = 2nV ar( ) + Op (n1=2 )                       (5)
                          ti ;ti+1 2[0;T ]

where the errors ti ’s are i.i.d. with mean 0, and n is the number of sampling intervals over [0; T ].
As we will show, ignoring market microstructure noise in the context of stochastic volatility leads to
A Tale of Two Time Scales: Determining Integrated Volatility                                         4


an even more dangerous situation than when is constant and T ! 1: The results from equation
(5) suggest that the realized volatility does not estimate the true integrated volatility, but rather
the variance of the contamination noise. In fact, we will show that the true integrated volatility,
which is Op (1), is even dwarfed by the magnitude of the asymptotically Gaussian Op (n1=2 ) term in
(5).

    Of course, the model (4) may also not be correct. When made the basis of inference, it could still
occur that one does not wish to sample as frequently as the data would permit. It may, however,
make it possible to use substantially larger amounts of data than what would be possible under
(2). Subsampling-based schemes can be made to incorporate all the data.

    In seeking to create an inference procedure under measurement error, we have sought to draw
some lessons from the empirical practice that one should not use all the data, while at the same
time not violating basic statistical principles. Our procedure estimates parameters at two di¤erent
frequencies of sampling, and then by cancellation removes the e¤ect of the 0 s to the required order.
We show in Section 4 that this leads to a variance-variance trade-o¤ between the e¤ect in (5) and
an e¤ect due to the sampling frequencies.

    The theory, including asymptotic distributions, is developed in Section 2-4 for the case of one
time period [0; T ]. The multi-period problem is treated in Section 5. Section 6 discusses how to
estimate the asymptotic variance for equidistant sampling. And Section 7 discusses what to do if
one really wants to use the customary realized volatility, sampled at high frequency despite the
presence of microstructure noise.



2     ANALYSIS OF THE “REALIZED VOLATILITY”

2.1   Set-up

To spell out the model above, we let Y be the logarithm of the transaction price, which is observed
at times 0 = t0 ; t1 ; ; tn = T . We assume that at these times, Y is related to a latent true price
X (also in logarithm scale) through equation (4). The latent price X is given in (1). The noise ti
satis…es the following assumption,

                   ti   i:i:d: with E   ti   = 0; and V ar(   ti )   = : Also   ?
                                                                                ? X process        (6)

where ?? denotes independence between two random quantities. Our modeling as in (4) does not
require that t exists for every t, in other words, our interest in the noise is only at the observation
times ti ’s.

   For the moment, we focus on determining the integrated volatility of X for the entire time
period [0; T ]. This is also known as the continuous quadratic variation < X; X > of X. In other
A Tale of Two Time Scales: Determining Integrated Volatility                                            5


words,                                                   Z       T
                                                                     2
                                           < X; X >T =               t dt                             (7)
                                                             0


     To describe succinctly the realized volatility, we use the notion of observed quadratic variation
[ ; ] . Given the grid G = ft0 ; :::; tn g, the observed quadratic variation for a generic process Z is
                                                       X
                                             [Z; Z]t =     ( Zti )2                                    (8)
                                                    ti+1 t

where Zti = Zti+1 Zti . We shall later have occasion to vary the grid G. Quadratic covariations
are similarly de…ned (see e.g., Karatzas and Shreve (1991) for more details on quadratic variations.)

    Our interest is to assess how well the realized volatility, [Y; Y ]T , approximates the integrated
volatility < X; X >T of the true returns process. In our asymptotic considerations, we shall always
assume that the number of observations in [0; T ] goes to in…nity, and also that the maximum
distance in time between two observations goes to zero:

                                          max   ti ! 0 as n ! 1                                       (9)
                                            i



2.2   The Realized Volatility: An Estimator of the Spread of the Noise?

Under the additive model Yti = Xti + ti , the realized volatility based on the observed returns Yti
now has the form
                             [Y; Y ]T = [X; X]T + 2[X; ]T + [ ; ]T :
This gives the conditional mean and variance of [Y; Y ]T , given the process of latent true prices X.
As derived in the Appendix,

                              E([Y; Y ]T j X process) = [X; X]T + 2n ;                               (10)

under assumption (6) and the de…nition of [ ; ] in (8). Similarly,
                                                                            4
                             V ar([Y; Y ]T j X process) = 4nE                   + Op (1);            (11)

subject to condition (6) and E    4    < 1, for all i. The exact expression for the variance is given in
                                  ti
Appendix A.1.

    Following the discussion in Appendix A.2, it is also the case that as n ! 1, the distribution
of n 1=2 ([Y; Y ]T 2n ) becomes normal conditionally on the X process, with mean 0 and variance
4E 4 .

   Equations (10) and (11) suggest that in the discrete world where microstructure e¤ects are
unfortunately present, realized volatility [Y; Y ]T is not a reliable estimator for the true variation
A Tale of Two Time Scales: Determining Integrated Volatility                                         6


[X; X]T of the returns. For large n, realized volatility could have little to do with the true returns.
As seen in (10), [Y; Y ]T has a positive bias whose magnitude increases linearly with the sample
size n. If one really wants to live with this bias – which we do not recommend – and use the
customary realized volatility as a measure of variation, the above provides theoretical evidence for
not sampling too often (see Section 7 for a formal analysis).

    Interestingly, apart from revealing the biased nature of [Y; Y ]T at high frequency, our analysis
also delivers an estimator for the spread of the noise term. In other words, the realized volatility
[Y; Y ]T yields a consistent and asymptotically normal estimator of noise spread , namely ^ =
 1
2n [Y; Y ]T . We have, for a …xed true return process X,

                               n1=2 (^    ) ! N (0; E 4 ); as n ! 1;                              (12)

see Theorem A.1 in the Appendix.



3     SAMPLING SPARSELY WHILE USING ALL THE DATA:
      ANALYSIS IN THE MULTIPLE GRID CASE

3.1   Multiple Grids and Su¢ ciency

We have argued in the previous section that one can indeed bene…t from using infrequently sampled
data. And yet, one of the most basic lessons of statistics is that one should not do this. We present
here two ways of tackling the problem. Both are based on selecting a number of subgrids of the
original grid of observation times, G = ft0 ; :::; tn g, and then averaging the estimators derived from
the subgrids. The principle is that to the extent that there is a bene…t to subsampling, this bene…t
can now be retained, while the variation of the estimator can be lessened by the averaging. The
bene…t of the averaging is clear from su¢ ciency considerations, and many statisticians would say
that subsampling without subsequent averaging is inferentially incorrect.

    In the following, we …rst introduce a set of notations, and then turn to studying the realized
volatility in the multi-grid context. In Section 4, we show how to explicitly estimate the model (4)
by using a combination of the single grid G and the multiple grids.


3.2   Notation for the Multiple Grids

We speci…cally suppose that the total grid G, G = ft0 ; :::; tn g as before, is partitioned into K
non-overlapping subgrids G (k) , k = 1; :::; K, in other words,

                          G = [K
                               k=1 G
                                     (k)
                                         where G (k) \ G (l) = ; when k 6= l:
A Tale of Two Time Scales: Determining Integrated Volatility                                          7


For most purposes, the natural way to select the k th subgrid G (k) is to start with tk     1   and then
pick every Kth sample point after that, until T . That is to say that

                              G (k) = (tk     1 ; tk 1+K ; tk 1+2K ;      ; tk   1+nk K )

for k = 1;    ; K, and nk is the integer making tk 1+nk K the last element in G (k) . We shall refer to
this as regular allocation of sample points to subgrids.

     Whether the allocation is regular or not, we let nk be such that the subgrid G (k) has nk + 1
elements. As before, the number of elements in the total grid G is n + 1. More general schemes for
allocating sample points to grids can also be used, subject to the restrictions in Theorem A.1 in
Appendix A.2. The realized volatility based on all observation points G, so far denoted [Y; Y ]T , will
                                          (all)
now for clarity be written as [Y; Y ]T . Meanwhile, if one uses only the subsampled observations
                                                                   (k)
Yt , t 2 G (k) , the realized volatility will be denoted as [Y; Y ]T . It has the form
                                             (k)
                                                    X
                                      [Y; Y ]T =           (Ytj;+ Ytj )2 :
                                                    tj ;tj;+ 2G (k)


where, if ti 2 G (k) , then ti;   and ti;+ denote respectively the preceding and following elements in
G (k) .
                                      (all)
    A natural competitor to [Y; Y ]T          is then given by
                                                               K
                                                 (avg)       1 X        (k)
                                       [Y; Y ]T          =       [Y; Y ]T ;                         (13)
                                                             K
                                                                 k=1

and this is the statistic we analyze in the following.

    As before, we …x T and use only the observations within the time period [0; T ]. Asymptotics
will still be under (9) and under
                                   as n ! 1; n=K ! 1:                                      (14)
In general, the nk need not be the same across k. We de…ne
                                            K
                                          1 X      n                   K +1
                                       n=     nk =                          :                       (15)
                                          K                            K
                                                   k=1



3.3    Error Due to the Noise

Recall that we are interested in determining the integrated volatility < X; X >T , or quadratic
variation, of the true but unobservable returns. As an intermediate step, we study in this subsection
                                                 (avg)                     (avg)
how well the “pooled” realized volatility [Y; Y ]T     approximates [X; X]T      , where the latter is
the “pooled”true integrated volatility when X is considered only on the discrete time scale. [X; X]
has the form given in equation (8).
A Tale of Two Time Scales: Determining Integrated Volatility                                                 8


   From (10) and (13),
                                      (avg)                                (avg)
                            E([Y; Y ]T        j X process) = [X; X]T                 + 2n :             (16)

Also, since f t ; t 2 G (k) g are independent for di¤erent k,
                                                               K
                            (avg)                           1 X              (k)
                 V ar([Y; Y ]T      j X process) =               V ar([Y; Y ]T jX process)
                                                            K2
                                                                 k=1
                                                                 XK
                                                            1                    4
                                                        =               nk 4E        + Remainder,
                                                            K2
                                                                 k=1
                                                              n     4            1
                                                        = 4     E       + Op (     )                    (17)
                                                              K                  K
in the same way as in (11). The order of the remainder follows as in the single grid case, see (A.3)
in the Appendix.
                                                                                                    (avg)
    By Theorem A.1 in Appendix A.2, the conditional asymptotics for the estimator [Y; Y ]T                  are
as follows

Theorem 1. Suppose X is an Itô process of form (1). Suppose Y is related to X through model
(4), and that (6) is satis…ed with E 4 < 1. Also suppose that ti and ti+1 are not in the same
subgrid for any i. Under assumption (14), as n ! 1
                     r
                       K          (avg)       (avg)      L
                                                             p
                          ([Y; Y ]T     [X; X]T     2 n) ! 2 E 4 Z (avg) ;                (18)
                        n
                                              (avg)
conditional on the X process, where Z                 is standard normal.


   This can be compared with the result which is stated below in equation (48) in Section 7.
              (avg)                                                                         (avg)
Notice that Z       in (18) is almost never the same as Z in (48), in particular, Cov(Z ; Z       )=
      2    4
V ar( )=E , based on the proof in Theorem A.1 in the Appendix.
                                                                                                        (avg)
   In comparison to the realized volatility using the full grid G, the aggregated estimator [Y; Y ]T
provides an improvement in that both the asymptotic bias and variance are of smaller order of n.
Cf. equations (10) and (11) in the preceding section. We shall use this in Section 4, and also in
Section 7 below.


                                                                            (avg)
3.4    Error Due to the Discretization E¤ect: [X; X]T                                   < X; X >T

In this subsection, we study the impact of the time discretization. In other words, we investigate
                       (avg)
the deviation of [X; X]T     from the integrated volatility < X; X >T of the true process. Denote
A Tale of Two Time Scales: Determining Integrated Volatility                                                        9


the discretization e¤ect as DT , where
                                                            (avg)
                               Dt = [X; X]t                         < X; X >t
                                                K
                                                X
                                           1                          (k)
                                    =                       ([X; X]t          < X; X >t )                       (19)
                                           K
                                                k=1

with                                                          X
                                          (k)
                                 [X; X]t        =                          (Xti ;+   Xti )2                     (20)
                                                    ti 2G (k) :ti;+    t

We consider in the following the asymptotics of DT . The problem is similar to that of …nding the
               (all)
limit of [X; X]T     < X; X >T , cf. equation (49) below. This present case, however, is more
complicated due to the multiple grids.

   We suppose in the following that the sampling points are allocated to subgrids as described by
equation (A.20) in Appendix A.3. In particular, this covers the regular allocation, as de…ned in
Section 3.2. We also assume that
                                                     1
                                      max j ti j = O( ):                                     (21)
                                         i           n

   De…ne the weight function
                                    K
                                8n X                (l)         1             (k)  (l)  1
                        hi =          [ti           ti +          ti ][f#k : ti > ti g + ]                      (22)
                               T K3                             2                       2
                                    l=1

In the case where the ti are equidistant, and under regular allocation of points to subgrids,                ti =   t,
and so all the hi are equal, and
                    2                                                      2K(2K      1)(2K + 1)  8
           hi =         t(1 + 32 + ::: + (2K                  1)2 ) =                            = + o(1):      (23)
                   tK 3                                                              3K 3         3
More generally, assumptions (21) and (A.20) assure that

                                                    sup hi = O(1):                                              (24)
                                                        i


   We take < D; D >T to be the quadratic variation of Dt when viewed as a continuous time
process (19). This gives the best approximation to the variance of DT .

   We show the following results in Appendix A.3.
Theorem 2. Suppose X is an Itô process of the form (1), with drift coe¢ cient t and di¤ usion
coe¢ cient t , both continuous almost surely. Assume (21) and (A.20). Then the quadratic variation
of DT is approximately
                                                  TK 2          K
                                   < D; D >T =         n + op (   )                           (25)
                                                   n            n
where                                     X
                                   2
                                   n =        hi (< X; X >0ti )2 ti :                         (26)
                                                    i
A Tale of Two Time Scales: Determining Integrated Volatility                                           10


   In particular, DT = Op ((K=n)1=2 ). From this, we shall derive a variance-variance trade-o¤
between the two e¤ects that have been discussed –noise and discretization.

   First, however, we discuss the asymptotic law of DT . Stable convergence is discussed at the
end of this section.

Theorem 3. Assume the conditions of Theorem 2, and also that
                                                    2   P       2
                                                    n   !                                          (27)

Also assume Condition E in Appendix A.3. Then
                                                                L
                                        DT =(K=n)1=2 ! Z;                                          (28)

where Z is standard normal, and independent of the data. The convergence in law is stable.


   In other words, DT =(K=n)1=2 can be taken to be asymptotically mixed normal “N (0;          2 ).”


   For most of our discussion, it is most convenient to suppose (27), and this is satis…ed in many
cases. For example, when the ti are equidistant, and under regular allocation of points to subgrids,
                                                 Z
                                          2   8 T 4
                                            =          dt;                                     (29)
                                              3 0 t

following (23). One does not need to rely on (27); we argue in Appendix A.3 that without this
condition, one can take DT =(K=n)1=2 to be approximately N (0; 2n ). For estimation of 2 or 2n ,
see Section 6 below.

    Finally, stable convergence (Rényi (1963), Aldous and Eagleson (1978), Chapter 3 of Hall and
Heyde (1980)) means for our purposes that the left hand side of (28) converges to the right hand
side jointly with the X process, and that Z is independent of X. This is slightly weaker than
convergence conditional on X, but serves the same function of permitting the incorporation of
conditionality-type phenomena into arguments and conclusions, cf. the following sections.


3.5   Combining the Two Sources of Error

We can now combine the two error terms arising from discretization and from the observation noise,
respectively. It follows from Theorems 1 and 3 that

                                   (avg)                                        L
                             [Y; Y ]T          < X; X >T            2 n             Ztotal ;       (30)

where Ztotal is a standard normal random variable independent of the X process, and

                                           2        n       4       T   2
                                               =4     E         +           :                      (31)
                                                    K               n
A Tale of Two Time Scales: Determining Integrated Volatility                                           11

                    L
Here, the symbol “ ” means that when multiplied by a suitable factor, the convergence is in law
(and stable, by the preceding results): see also the proof of Theorem 4 in the next section.

    It is easily seen that if one takes K = cn2=3 , both components in 2 will be present in the limit,
                                                                    (avg)
otherwise one of them will dominate. Based on (30), [Y; Y ]T              is yet a biased estimator of the
quadratic variation < X; X >T of the true return process. In particular, the bias 2 n still increases
with the number of the sub-samples. One can recognize that, as far as the asymptotic bias is
                    (avg)                                     (all)
concerned, [Y; Y ]T       is a better estimator than [Y; Y ]T , since n        n, suggesting that the bias
                                       (avg)
in the subsampled estimator [Y; Y ]T         increases in a slower pace than the full-sampled estimator.
One can also construct a bias-adjusted estimator from (30), and this further development would
involve the higher order analysis between the bias and the subsampled estimator. We show the
methodology of bias correction in Section 4.



4     ESTIMATION FOR THE MODEL WITH MEASUREMENT
      ERROR: COMBINING TWO SAMPLING FREQUENCIES

4.1   The Estimator: Main Result

In previous sections, we have seen that the multigrid estimator [Y; Y ](avg) is yet another biased
estimator of the true integrated volatility < X; X >. In this section we improve the multigrid
estimator by adopting bias adjustment.

   To access the bias, one utilizes the full grid. As mentioned from equation (12) in single-grid
case (Section 2), can be consistently approximated by
                                                 1        (all)
                                           ^=      [Y; Y ]T :                                         (32)
                                                2n

Hence the bias of [Y; Y ](avg) can be consistently estimated by 2n^. A bias-adjusted estimator for
< X; X > can thus be obtained by
                                                         (avg)
                                    <\
                                     X; X >T = [Y; Y ]T            2^n:                               (33)


   To study the asymptotic behavior of < \
                                         X; X >T , note …rst that under the conditions of Theorem
A.1 in Appendix A.2
            1=2                                              1=2
        K                              (avg)            K                 (avg)         (avg)
                  <\
                   X; X >T      [X; X]T          =                 [Y; Y ]T       [X; X]T       2 n
        n                                               n
                                                      2(K n)1=2 (^        )
                                                 L
                                                 ! N (0; 8 2 );                                       (34)
A Tale of Two Time Scales: Determining Integrated Volatility                                                 12


where the convergence in law is conditional on X.

    We can now combine this with the results of Section 3.4 to determine the optimal choice of K
as n ! 1:
                                                      (avg)       (avg)
      <\
       X; X >T      < X; X >T     = (< \
                                       X; X >T [X; X]T ) + ([X; X]T                           < X; X >T )
                                              !
                                        n1=2
                                  = Op          + Op n 1=2 :                                                (35)
                                        K 1=2

The error is minimized by equating the two terms on the right hand side of (35), yielding that the
                                 (avg)
optimal sampling step for [Y; Y ]T     is K = O(n2=3 ). The right hand side of (35) then has order
Op (n 1=6 ).

   In particular, if we take
                                            K = cn2=3 ;                                                     (36)
we …nd the limit in (35), as follows.

Theorem 4. Suppose X is an Itô process of form (1), and assume the conditions of Theorem 3 in
Section 3.4. Suppose Y is related to X through model (4), and that (6) is satis…ed with E 2 < 1.
Also suppose that ti and ti+1 is not in the same subgrid for any i. Under assumption (36),
                                                    L                              p
               n1=6 < \
                      X; X >T       < X; X >T       ! N (0; 8c          2 2
                                                                              )+       T N (0; c)
                                                                  2 2              1=2
                                                    =       8c          + c 2T           N (0; 1);          (37)

where the convergence is stable in law (see Section 3.4).


   Proof of Theorem 4. Note that the …rst normal distribution comes from equation (34) and
the second from Theorem 3 in Section 3.4. The two normal distributions are independent since
the convergence of the …rst term in (35) is conditional of the X process, which is why they can
be amalgamated as stated. The requirement that E 4 < 1 (Theorem A.1 in the appendix) is not
                                                          (1)
needed since only a law of large number is required for MT (see the proof of that theorem) when
considering the di¤erence in (34) above. This …nishes the proof.

    The estimation of the asymptotic spread s2 = 8c 2 2 +c 2 T of < \
                                                                    X; X >T is deferred to Section
6 below. Also, note that, by Theorem A.1 and the same methods as in Appendix A.2, a consistent
estimator of the asymptotic variance of ^ is given by
                                         1 X
                                             ( Yti )4     3^2 :                                             (38)
                                        2n
                                            i
A Tale of Two Time Scales: Determining Integrated Volatility                                                            13


4.2   Properties of < \
                      X; X >T : Optimal Sampling, and Bias Adjustment

To further pin down the optimal sampling frequency K one can minimize the expected asymptotic
variance in (37) to obtain
                                                    1=3
                                              16 2
                                       c=                                                (39)
                                             T E 2
which can be consistently estimated from data in past time periods (before time t0 = 0), using ^ and
an estimator of 2 , cf. Section 6. As mentioned in Section 3.4, 2 can be taken to be independent
of K so long as one allocates sampling points to grids regularly, as de…ned in Section 3.2. Hence
one can choose c, and so also K, based on past data.
Example 1. If 2t is constant, and for equidistant sampling and regular allocation to grids,                         2   =
8 4
3   T , and the asymptotic variance in equation (37) is

                                        2 2                                 8
                                   8c         + c 2 T = 8c           2 2
                                                                           + c         4
                                                                                           T2
                                                                            3
and the optimal choice of c becomes
                                                                          1=3
                                                         6 2
                                              copt =                            :                                   (40)
                                                         T2 4
In this case, the asymptotic variance is
                                                       1=3             4=3
                                               4(6 2 )       (   2
                                                                     T)         :

    One can also, of course, estimate c to minimize the actual asymptotic variance in (37) from data
in the current time period (0 t T ). It is beyond the scope of this paper to consider whether
such a device for selecting the frequency has any impact on our asymptotic results.

   In addition to large sample arguments, one can study < \   X; X >T from a “smallish” sample
point of view. We argue in the following that one can apply a bias type adjustment to get
                                              (adj)              n         1
                                 <\
                                  X; X >T             = 1                      <\
                                                                                X; X >T :                           (41)
                                                                 n

    The di¤erence from the estimator in (33) is of order Op (n=n) = Op (K 1 ), and thus the two
estimators behave the same to the asymptotic order that we consider. The estimator (41), however,
has the appeal of being, in a certain way, “unbiased”, as follows. Consider all estimators of the
form
                                        (adj)           (avg)
                               <\X; X >T      = a[Y; Y ]T     2b^n;
then, from (10) and (16),
                       (adj)                                         (avg)                       n       (all)
          E(< \
              X; X >T          jX process) = a([X; X]T                         + 2n )           b ([X; X]T + 2n )
                                                                                                 n
                                                                 (avg)               n      (all)
                                               = a[X; X]T                           b [X; X]T + 2(a       b)n :
                                                                                     n
A Tale of Two Time Scales: Determining Integrated Volatility                                                           14


It is natural to choose a = b to completely remove the e¤ect of . Also, following Section 3.4, both
       (avg)            (all)
[X; X]T      and [X; X]T are asymptotically unbiased estimators of < X; X >T . Hence one can
argue that one should take a(1 n=n) = 1, yielding (41).

    Similarly, an adjusted estimator of        is given by
                                      1                         (all)                (avg)
                              ^(adj) = (n      n)    1
                                                         [Y; Y ]T              [Y; Y ]T         ;                     (42)
                                      2
                                                                                       (all)                  (avg)
which satis…es that E(^(adj) jX process ) = + 12 (n n) 1 [X; X]T        [X; X]T    , and is there-
fore unbiased to high order. As for the asymptotic distribution, One can see from Theorem A.1 in
the Appendix that

                        ^(adj)        = (^          )(1 + O(K         1
                                                                          )) + Op (Kn          3=2
                                                                                                     )
                                                              1=2          1                        3=2
                                      = ^        + Op (n             K         )) + Op (Kn                )
                                                              5=6
                                      = ^        + Op (n             )

from (36). It follows that n1=2 (^        ) and n1=2 (^(adj)              ) have the same asymptotic distribution.



5    MULTIPLE PERIOD INFERENCE

For a given family A = fG (k) ; k = 1;       ; Kg, we denote by

                                      \                      (avg)       n
                                    < X; X >t = [Y; Y ]t                   [Y; Y ]t                                   (43)
                                                                         n
                              P                            (avg)          P             (k)
where, as usual, [Y; Y ]t =      ti+1 t  Yt2i and [Y; Y ]t           = K1 K  k=1 [Y; Y ]t , with

                                          (k)
                                                    X
                                   [Y; Y ]t =                       (Yti ;+      Yti )2 :
                                                ti 2G (k) :ti;+ t

In order to estimate < X; X > for several discrete time periods, say [0; T1 ], [T1 ; T2 ],    , [T   ; T ],
                                                                                           R Tm M 2 1 M
where M is …xed, this amounts to estimating < X; X >Tm             < X; X >Tm 1 = Tm 1 u du, for
m = 1;     ; M , and the obvious estimator is < \
                                                X; X >T      <\ X; X >T
                                                                      m
                                                                                .               m 1


    To carry out the asymptotics, let nm be the number of points in the mth time segment, and
                         2=3                                   1=6
similarly let Km = cm nm , where cm is a constant. Then fnm (< \    X; X >Tm < \ X; X >Tm 1
R Tm    2 du); m = 1;                                  2 2       2           1=2
 Tm 1 u                  ; M g converge stably to f(8cm    + cm m (Tm Tm 1 )) Zm g, where the
Zm are i.i.d. standard normals, independent of the underlying process, and 2m is the limit 2
(Theorem 3) for time period m. In the case of equidistant ti and regular allocation of sample
                        RT
points to grids, 2m = 38 Tmm 1 4u du.

    In other words, the one period asymptotics generalizes straightforwardly to the multiperiod
                                                    R Tm
case. This is because < \
                        X; X >Tm < \  X; X >Tm 1            2
                                                     Tm 1 u du has, to …rst order, a martingale
structure. This can be seen from the Appendix.
A Tale of Two Time Scales: Determining Integrated Volatility                                                               15


    An advantage of our proposed estimator is that if ti has di¤erent variance in di¤erent time
segments, say V ar( ti ) = m for ti 2 (Tm 1 ; Tm ], then both consistency and asymptotic (mixed)
normality continue to hold, provided that one replaces by m . This adds a measure of robustness
to the procedure. If one were convinced that is the same across time segments, an alternative
estimator has the form
                                         (avg)     1                  1       (all)
                    <\  X; X >t = [Y; Y ]t       ( #fti+1 tg 1) [Y; Y ]t :                        (44)
                                                  K                  n
                                             R Tm
The errors < \
             X; X >Tm < \    X; X >Tm 1              2
                                               Tm 1 u du, however, are in this case not asymptotically
independent. Note that for T = Tm , both candidates (43) and (44) for < \       X; X >t coincide with
the quantity in (33).



6    DETERMINING THE ASYMPTOTIC VARIANCE

In the one period case, the main goal is to …nd the spread s2 = 8c 2 2 + c 2 T , cf. (36)-(37). The
multigrid case is a straightforward generalization, as indicated in Section 5.

    Here, we shall only be concerned with the case where the points ti are equally spaced ( ti = t),
and are regularly allocated to the grids A1 = fG (k) ; k = 1;   ; K1 g. The more general case where
the sampling intervals are irregular, and proof of the method, is treated in Zhang and Mykland
(2003). A richer set of ingredients are required to …nd the spread than just to estimate < \   X; X >T .
To implement the estimator, create an additional family A2 = fG     (k;i) ; k = 1;  ; K1 ; i = 1;   ; Ig
of grids where G (k;i) contains every i-th point of G (k) . We assume that K1        c1 n2=3 . The new
family then consists of K2 c2 n2=3 grids, where c2 = c1 I.
                                                                                                                          m
   In addition, we need a division of the time line into segments (Tm                          1 ; ; Tm ],   where Tm =   M T.
For the purposes of this discussion, M is large but …nite.

    We now get an initial estimator of spread as
                      M
                      X                                                                                             2
                                      K1                     K1                         K2                    K2
        s^20 = n1=3         <\
                             X; X >Tm      <\
                                            X; X >Tm                1
                                                                           (< \
                                                                              X; X >Tm         <\
                                                                                                X; X >Tm 1 )
                      m=1

where < X; X >K i
              t is the estimator (43) using grid family i, i = 1; 2.

    Using the discussion in Section 5, one can see that

                                                     s^20        s20 ;                                                    (45)

where, for c1 6= c2 (I 6= 1),
                                                                                1=2    1=2 2
                            s20 = 8 2 (c1 2 + c2 2          c1 1 c2 1 ) + (c1          c2 ) T          2

                                                                                         2
                                = 8 2 c1 2 (1 + I    2
                                                             I     1
                                                                       ) + c1 (I 1=2   1) T    2
                                                                                                   :                      (46)
A Tale of Two Time Scales: Determining Integrated Volatility                                            16


In (45), the symbol    means …rst convergence in law as n ! 1, and then a limit in probability
as M ! 1. Since can be estimated by ^ = [Y; Y ](all) =2n, one can put hats on s20 , 2 , and 2 in
(46) to obtain an estimator of 2 . Similarly,
                             0                                     1
                                           2        2      1 1
                                      c(c    +  c        c   c   )              c
                  s2 = 8 2 @c 2          1        2       1 2
                                                           2
                                                                   A+                     s20
                                              1=2      1=2                 1=2     1=2 2
                                           (c1        c2 )              (c1       c2 )
                                                           !
                                        I 2 I 1+1                    c        1
                      = 8 c 2 cc1 3                    2
                                                               2
                                                                 +                    2
                                                                                   2 s0 ;     (47)
                                          (I 1=2     1)             c1 (I 1=2   1)

where c    Kn   2=3   where K is the number of grids used originally to estimate < X; X >T .

    Normally, one would take c1 = c. Hence an estimator s^2 can be found from s^20 and ^. When
c1 = c, we argue that the optimal choice is I = 3 or 4, as follows. The coe¢ cients in (47) become
                                                                  2
                                  coe (s20 ) = (I 1=2       1)
                                                                           2
                                  coe ( 2 ) = 8c     2
                                                         (I 1=2       1)       f (I)

where f (I) = I 2I 1=2 I 2 + I 1 . For I                 2, f (I) is increasing, and f (I) crosses 0 for I
between 3 and 4. These, therefore, are the two integer values of I which give the lowest ratio of
coe ( 2 )=coe (s20 ). Using I = 3 or 4, therefore, would maximally insulate against ^2 dominating
over s^20 . This is desirable as s^20 is the estimator of carrying the information about 2 . Numerical
values for the coe¢ cients are given in Table 1. If c is such that ^2 still overwhelms s^20 , then a choice
of c1 6= c should be considered.


       Table 1. Coe¢ cients of ^2 and s^2 when c1 = c
     I                   coe (s20 )                               coe ( 2 )
     3                     1:866                                   3:611c 2
     4                     1:000                                  1:5000c 2




7    THE BENEFITS OF SAMPLING SPARSELY

In the above, we have constructed a method to directly estimate the integrated volatility of the
process X, by combining di¤erent sampling frequencies. If one really insists, however, one can
pretend that the noise term is so negligible that one can ignore it. In the following, we discuss
whether this approach can possibly have at least some merit.
A Tale of Two Time Scales: Determining Integrated Volatility                                          17


7.1   The Single Grid Case

In Section 2, we argued that the realized volatility estimates the wrong quantity. This problem
only gets worse when observations are sampled more frequently. Its …nancial interpretation boils
down to market micro-structure, measured by in (4). As the data record is sampled …nely, the
change in true returns gets smaller while the microstructure noise, such as bid-ask spread and
transaction cost, remains at the same magnitude. In other words, when the sampling frequency
is extremely high, the observed ‡uctuation in the returns process is more heavily contaminated
by microstructure noise and becomes less representative of the true variation < X; X >T of the
returns. Along this line of discussion, the broad opinion in …nancial applications is not to sample
too often, at least when using realized volatility. We now discuss how this can be viewed in the
context of the model (4) with stochastic volatility.

   Intuitively, suppose that is small. It could formally be taken to tend to zero as n ! 1, along
with E 4 . The asymptotic normality in Section 2.2 then takes the form
                                            L                     p
                                [Y; Y ]T         [X; X]T + 2 n + 2 nE 4 Z ;                          (48)
                   L
where the symbol “ ”is used in a similar way to that of Section 3.5. Here Z is standard normal, the
subscript indicates that the randomness comes from the noise, or the deviation of the observables
Y from the true process X. The convergence in law is conditional on the X process.

   Following Rootzen (1980), Jacod and Protter (1998) and Mykland and Zhang (2002), and under
the conditions stated in these papers, one can show that
                                                           Z    T                   1=2
                  n    1=2                             L               0     4
                             ([X; X]T      < X; X >T ) !            2H (t)   t dt         Zdiscr ;   (49)
                  T                                         0

stably in law (see the end of Section 3.4). Zdiscr is standard normal random variable, the subscript
indicates that the randomness is due to the discretization e¤ect in [X; X]T when evaluating <
X; X >T . H(t) is the asymptotic quadratic variation of time, as discussed in Mykland and Zhang
(2002). In the case of equidistant observations which we consider here, t0 = ::: = tn 1 = t
and H 0 (t) = 1. Again the convergence is in law, and it is stable, cf. the end of Section 3.4. Since
the 0 s are independent of the X process, Z is independent of Zdiscr .

   For small , one now has a chance at estimating < X; X >T . It follows from (48)-(49) that
                                             L
                                [Y; Y ]T         < X; X >T +2 n + Ztotal ;                           (50)

in the sense of stable convergence, where Ztotal is standard normal, and where the variance has the
form                                                 Z
                                    2             T T
                                      = 4nE 4 +          2H 0 (t) 4t dt                        (51)
                                                  n 0
A Tale of Two Time Scales: Determining Integrated Volatility                                                                          18


    Seen from this angle, there is scope for using the realized volatility [Y; Y ] to estimate < X; X >.
It is achieved with bias 2 n, but the bias goes down if one uses fewer observations. This, then, is
consistent with the practice in empirical …nance.

   As can be seen from (51), there is, however, a trade-o¤ between sampling too often and sampling
too rarely, as in the constant case. Consider again the situation where the observation times are
equidistant, so that H 0 (t) = 1 independently of the sampling frequency. It is then natural to
minimize the mean squared error
                                        M SE = (2 n)2 + 2 ;                                   (52)
which means that one should choose n to satisfy @M SE=@n                                           0, in other words,
                                                                 Z       T
                                                            T
                               8 2 n + 4E          4
                                                                             2H 0 (t)       4
                                                                                            t dt      0:                             (53)
                                                            n2       0

To solve for n, we suppose as mentioned above that                                       ! 0 as n ! 1, and we suppose that
E 4 =(E 2 )2 is of order O(1). Thus
                                                                             Z   T
                                1   E 4                          2T
                            n3 + n2                                                  2H 0 (t)      4
                                                                                                   t dt    0:                        (54)
                                2 (E 2 )2                            8       0

Hence, …nally,
                                         Z   T                           1=3
                             2=3     T                 0     4                                2=3
                      n=                         2H (t)      t dt                + o(               ) as            ! 0:             (55)
                                     8   0


    The equation (55) is the formal statement saying that one can sample more frequently when the
error spread is small. Note that to …rst order, the …nal trade-o¤ is between the bias 2vn and the
variance due to discretization. The e¤ect of the variance associated with Z is of lower order when
comparing n and . It should be emphasized that (55) is a feasible way of choosing n. One can
                                                                                     RT
estimate using all the data following the procedure in Section 2.2. The integral 0 2H 0 (t) 4t dt
can be estimated by the methods discussed in Section 6 below. For a general procedure, see Zhang
and Mykland (2003).

   We can do better, however, than using the “realized volatility”, as we shall see in the following.


7.2   The Multiple Grid Case

Following the development in Section 3, one can go to the multi-grid case and search for an optimal
frequency n for subsampling to balance the coexistence of the bias and the variance in (30). To
                                        (avg)
reduce the mean squared error of [Y; Y ]T , we set @M SE=@ n = 0. From (31)-(30), bias = 2 n
and 2 = 4 Kn
             E 4 + Tn 2 , then

                                                           n                 T                             T
            M SE = bias2 +     2
                                   = 4 2 n2 + 4              E   4
                                                                     +               2
                                                                                         = 4 2 n2 +             2
                                                                                                                    to …rst order;
                                                           K                 n                             n
A Tale of Two Time Scales: Determining Integrated Volatility                                        19


thus the optimal n satis…es that
                                                      2   1=3
                                                  T
                                          n =         2
                                                                :                                 (56)
                                                  8
                                          (avg)
Therefore, assuming the estimator [Y; Y ]T    is adopted, one could bene…t from a minimum MSE
if one subsamples n data in an equidistant fashion. In other words, all n observations can be used
if one uses K , K      n=n , subgrids. This is in contrast to the drawback of using all the data in
the single grid case. The subsampling coupled with aggregation brings out the advantage of using
the entire data. Of course, for the asymptotics to work, we need 2 ! 0.

    Our recommendation, however, is to use the methods in Sections 4 -6.



8    CONCLUSION

In this work, we have quanti…ed and corrected the e¤ect of noise on the nonparametric assessment
of integrated volatility. In the setting of high frequency data, the usual …nancial practice is to use
sparse sampling, in other words, throwing away most of the available data. We have argued that
this is caused by not incorporating the noise in the model. While it is statistically unsound to
throw away data, we have shown that it is possible to build on this practice to construct estimators
that make statistical sense.

    Speci…cally, we have found that the usual realized volatility mainly estimates the magnitude of
the noise term rather than anything to do with volatility. An approach that is built on separating
the observations into multiple “grids” lessens this problem. We found that the best results can
be obtained by combining the usual (“single grid”) realized volatility with the multiple grid based
device. This gives an estimator which is approximately unbiased, and we have also shown how to
assess the (random) variance of this estimator. Most of the development is in the context of …nding
the integrated volatility over one time period; at the end, we extend this to multiple periods. Also,
in the case where the noise can be taken to be almost negligible, we provide a way of optimizing the
sampling frequency if one wishes to use the classical “realized volatility”or its multi-grid extension.

    One important message of the paper: Any time one has an impulse to sample sparsely, one can
always do better with a multi-grid method. No matter what the model is, no matter what quantity
is being estimated.



APPENDIX: PROOFS OF RESULTS
                                            P       P            P
When the total grid G is considered, we use ni=11 ,   ti+1 T and    ti 2G interchangeably in the
following proofs. And we write jX to indicate expressions that are conditional on the entire X
process.
A Tale of Two Time Scales: Determining Integrated Volatility                                                                                                                             20


A.1     Variance of [Y; Y ]T Given the X Process

We here calculate explicitly the variance in equation (11), from which the stated approximation
follows. The explicit remainder term is also used for equation (17).

   Let a partition of [0; T ] be 0 = t0                 t1                               tn = T . Under assumption (6),
                                                       X
          V ar([Y; Y ]T jX) = V ar[                              ( Yti )2 jX]
                                                      ti+1 T
                                                  X                                                        X
                                     =                 V ar[( Yti )2 jX] + 2                                       Cov[( Yti 1 )2 ; ( Yti )2 jX]
                                              ti+1 T                                                   ti+1 T
                                              |                 {z                        }        |                                  {z                            }
                                                                IT                                                                IIT

since   Yti =         Xti +     ti   is 1-dependent given X process.
                      V ar[( Yti )2 jX] =                  4(    Yti jX) + 2[V ar( Yti jX)]2
                                                       +4[E( Yti jX)]2 V ar( Yti jX)
                                                       +4E( Yti jX)                       3(       Yti jX)
                                                                                                            2
                                                  =        4(        ti )     + 2[V ar(                ti )]     + 4( Xti )2 V ar(                 ti )

                                                       +4( Xti )                   3(     ti );        under Assumption 6
                                                  = 2       4(   )+8               2
                                                                                     + 8( Xti )2
since 3 (                            0s                                                                                                                                              2
               ti )   = 0. The            are the cumulants of the relevant order. So, IT = n 2                                                            4(       )+8                     +
8 [X; X]T .

   Similarly, for the covariance,
  Cov[( Yti 1 )2 ; ( Yti )2 jX] = Cov[(                              ti     1   )2 ; (         2
                                                                                           ti ) ]      + 4( Xti 1 )( Xti )Cov(                            ti    1   ;         ti )
                                                                                                                    2                                                    2
                                                    +2( Xti 1 )Cov[                           ti   1   ;(        ti )   ] + 2( Xti )Cov[(                  ti       1   ) ;          ti ]
                                                                          2
                                           =          4(   )+2                     4( Xti 1 )( Xti )                     2(   )                                                 (A.1)
                                                      2( Xti )                3(   ) + 2( Xti 1 )                  3(    )
because   1(    ) = 0,     2(   ) = V ar( ) = E( 2 ),                         3(   ) = E 3 , and                   4(   ) = E( 4 )           3 2.

   Thus, assuming the coe¢ cients in (A.1)
                        IIT     = 2(n              1)( 4 ( ) + 2 2 )
                                                   X
                                          8            ( Xti 1 )( Xti )                                4    3(   )( Xtn           1        Xt0 )
                                                  ti+1 T


   Amalgamating the two expressions one obtains
               V ar([Y; Y ]T jX) = n 2                   ) + 8 2 + 8 [X; X]T + 2(n 1)( 4 ( ) + 2 2 )
                                                           4(
                                                        X
                                                      8   ( Xti 1 )( Xti ) 4 3 ( )( Xtn 1    Xt0 )
                                                           4
                                          = 4nE                 + Rn ;                                                                                                          (A.2)
A Tale of Two Time Scales: Determining Integrated Volatility                                                                             21


where the remainder term Rn satis…es

                   jRn j         8 [X; X]T + 2( 4 ( ) + 2 2 )
                                      X
                                 +8 j    ( Xti 1 )j( Xti )j + 4j                      3(   )j(j Xtn 1 j + j Xt0 j)
                                 16 [X; X]T + 2(            4(    ) + 2 2 ) + 2j           3(    )j(2 + [X; X]T )                      (A.3)

by the Cauchy-Schwarz inequality and since jxj                            (1 + x2 )=2.
                                                                                                                  (avg)
   Since [X; X]T = Op (1), (11) follows. Similarly, (17) follows since [X; X]T                                             = Op (1).


A.2    Relevant Central Limit Theorem

Lemma A.1. Suppose X is an Itô process. Suppose Y is related to X through model (4). Then
under assumption (6) and de…nitions (8) and (13),
         (all)         (all)                              (avg)                  (avg)                  (avg)
   [Y; Y ]T      = [ ; ]T      + Op (1), and [Y; Y ]T                  = [ ; ]T           + [X; X]T             + Op ( p1K )


Proof of Lemma A.1

(a) The one grid case:
                                         (all)                  (all)             (all)                 (all)
                                 [Y; Y ]T         = [X; X]T              + [ ; ]T         + 2[X; ]T                                    (A.4)

We show:
                                                                (all) 2
                                             E ([X; ]T                 ) jX       = Op (1)                                             (A.5)

and in particular
                                                                 (all)
                                                     [X; ]T               = Op (1)                                                     (A.6)
To see (A.5):
                                          n
                                          X1
                             (all)
                      [X;   ]T       =            ( Xti )(         ti )
                                          i=0
                                          n
                                          X1                              n
                                                                          X1
                                     =            ( Xti )       ti+1             ( Xti )    ti
                                          i=0                              i=0
                                          n
                                          X1
                                     =            ( Xti     1            Xti )   ti   +    Xtn     1   tn       Xt0   t0
                                            i=1
A Tale of Two Time Scales: Determining Integrated Volatility                                                                                  22

                (all)
Since E([X; ]T          jX) = 0 and     ti   i.i.d. for di¤erent ti , we get

                              (all) 2                                     (all)
                 E ([X; ]T        ) jX          = V ar([X; ]T                     jX)
                                                         n
                                                         X1
                                                =        [         ( Xti     1          Xti )2 +         Xt2n    1
                                                                                                                     +    Xt20 ]
                                                             i=1
                                                                                   n
                                                                                   X1
                                                = 2 [X; X]T                  2            ( Xti 1 )( Xti )
                                                                                    i=1
                                                       4 [X; X]T                                                                         (A.7)

by the Cauchy-Schwarz Inequality, from which and from [X; X](all) being of order Op (1), (A.5)
follows. Hence (A.6) follows by the Markov Inequality.

(b) The multiple grid case:

   Notice that
                                                              (avg)                (avg)                 (avg)
                              [Y; Y ](avg) = [X; X]T                    + [ ; ]T           + 2[X; ]T                                     (A.8)
                                                                                                                 (avg)
(A.8) strictly follows from model (4) and the de…nitions of grids and [ ; ]t                                             , see Section 3.2.

   We need to show:
                                                             (avg) 2                    1
                                               E([X; ]T                 jX) = Op (        )                                              (A.9)
                                                                                        K
in particular
                                                             (avg)               1
                                                 [X; ]T                = Op (         ):                                                (A.10)
                                                                                K 1=2
                 (avg)                       (avg) 2
and V ar([X; ]T          jX) = E[([X; ]T          ) j X]:
                                                 (avg)
   To show (A.9), note that E([X; ]T                     jX) = 0,

                                             (avg) 2                                       (avg)
                              E[([X; ]T          ) j X] = V ar([X; ]T                              jX)
                                                                            K
                                                                         1 X            (k)
                                                                   =          V ar([X; ]T jX)
                                                                         K2
                                                                              k=1
                                                                         4       (avg)       1
                                                                           [X; X]T     = Op ( )
                                                                         K                   K
where the second equality follows from the disjointness of di¤erent grids as well as ?? X . The
                                                                                          (avg)
inequality follows from the same argument as in (A.7). Then the order follows since [X; X]T     =
Op (1): see the method in Mykland and Zhang (2002) if one wants a rigorous development for the
                (avg)
order of [X; X]T .

Theorem A.1. Suppose X is an Itô process of form (1). Suppose Y is related to X through model
(4), and that (6) is satis…ed with E 4 < 1. Also suppose that ti and ti+1 is not in the same subgrid
A Tale of Two Time Scales: Determining Integrated Volatility                                                                                          23

                                                  p           q
                                                                          (avg)                                                          (avg)
for any i. Under assumption (14), as n ! 1, ( n(^           ); Kn ([Y; Y ]T                                                      [X; X]T            2 n))
converges in law to a bivariate normal, with mean 0 and covariance matrix
                                                            !
                                         E 4      2V ar( 2 )
                                                                                                                                                 (A.11)
                                       2V ar( 2 )   4E 4
conditional on X process. where the limiting random variable is independent of the X process.

Proof of Theorem A.1:

        By Lemma A.1, need the distribution of [ ; ](avg) and [ ; ](all) .

        First, we explore the convergence of
                                  1
                                 p [ ; ](all)
                                          T                        2 n; [ ; ]T
                                                                                 (avg)
                                                                                         K          2 nK                                         (A.12)
                                   n
Recall that all the sampling points t0 ; t1     ; tn are within [0; T ]. We use G to denote the time
points in the full sampling, as in the single grid. G (k) denotes the subsamplings from k th grid.

        As before, if ti 2 G (k) , then ti; and ti;+ are, respectively, the previous and next element in G (k) .
 ti ;    = 0 for ti = min G (k) and ti ;+ = 0 for ti = max G (k) .

        Set
                                                       (1)          1 X 2
                                                  MT           =   p         ( ti            )
                                                                     n
                                                                       ti 2G
                                                       (2)          1 X
                                                  MT           =   p          ti ti      1                                                       (A.13)
                                                                     n
                                                                         ti 2G
                                                                       K
                                                   (3)              1 X X
                                                  MT           =   p                         ti ti ;
                                                                     n
                                                                         k=1 ti 2G
                                                                         (k)

                                                                         (1)      (2)         (3)
We …rst …nd the asymptotic distribution of (MT ; MT ; MT ) using the martingale central limit
theorem, and then we use the result to …nd the limit of (A.12).
                           (1)       (2)   (3)
     Note that (MT ; MT ; MT ) are the end points of martingales with respect to …ltration Fi =
  ( tj ; j i; Xt ; all t). We now derive its (discrete-time) predictable quadratic variation < M (l) ; M (k) >,
l; k = 1; 2; 3. (Discrete time predictable quadratic variations are only used in this proof, and are
di¤erent from the continuous time quadratic variations in (7)).
                                 1X
         < M (1) ; M (1) >T =            V ar( 2ti     j Fti 1 ) = V ar( 2 )
                                 n
                                   ti 2G
                                 1 X                                  X
         < M (2) ; M (2) >T =            V ar( ti ti 1 j Fti 1 ) =          2
                                                                            ti 1 =
                                                                                   2
                                                                                     + op (1)
                                 n                                 n
                                               ti 2G                                          ti 2G
                                               K
                                               X       X                                                   K
                                                                                                           X X
               (3)        (3)              1                                                                               2         2
          <M         ;M         >T    =                        V ar(   ti ti;    j Fti 1 ) =                               ti;   =       + op (1)
                                           n                                                           n
                                               k=1 ti 2G (k)                                               k=1 ti 2G (k)
A Tale of Two Time Scales: Determining Integrated Volatility                                                                                                                  24


by the law of large numbers.

   Similarly, for the predictable quadratic covariations,
                                      1X                                                                                     31
                                                                                                                                  X
  < M (1) ; M (2) >T            =        Cov(               2
                                                            ti            ;        ti ti       1   j Fti 1 ) = E                              ti   1   = op (1)
                                      n                                                                                      n
                                          ti 2G                                                                                   ti 2G
                                          K
                                          X        X                                                                                           K
                                                                                                                                               X X
                                      1                                                                                                31
  < M (1) ; M (3) >T            =                           Cov(           2
                                                                           ti           ;          ti ti;        j Fti 1 ) = E                                   ti;   = op (1)
                                      n                                                                                                   n
                                          k=1 ti   2G (k)                                                                                      k=1 ti   2G (k)
                                          K
                                          X        X
                                      1
  < M (2) ; M (3) >T            =                           Cov(           ti ti       1   ;       ti ti;        j Fti 1 )
                                      n
                                          k=1 ti 2G (k)
                                          K
                                          X X
                                =                               ti   1    ti;       = op (1)
                                      n
                                          k=1 ti 2G (k)

since ti+1 is not in the same grid as ti .

   Since the ti ’s are i.i.d. and E 4ti < 1, the conditional Lindeberg conditions are satis…ed. Hence
by the martingale CLT (see condition 3.1, p. 58 of Hall and Heyde (1980)), (M (1) ; M (2) ; M (3) ) are
asymptotically normal, with covariance matrix as the asymptotic value of < M (l) ; M (k) >. In
other words, asymptotically, (M (1) ; M (2) ; M (3) ) are independent normal with respective variances
V ar( ), 2 , and 2 .

   Returning to (A.12),
                                                       X                                                                                           X
              [ ; ](all)            2n        = 2                (   2
                                                                     ti              )+(            2
                                                                                                    t0           )+(    2
                                                                                                                        tn         )      2              ti ti   1
                                                      i6=0;n                                                                                   ti >0
                                                 p
                                              = 2 n(M (1)                           M (2) ) + Op (1)                                                                      (A.14)

Meanwhile:
                                                                         X                                              2
                  [ ; ](k)          2nk           =                                                (     ti ;+      ti )      2nk
                                                      ti 2G (k) ; ti 6=max G (k)
                                                             X
                                                                              2                            2                           2
                                                  = 2                    (    ti               )       (   min G (k)
                                                                                                                             )     (   max G (k)
                                                                                                                                                             )            (A.15)
                                                        ti   2G (k)
                                                                     X
                                                            2                      ti ti ;
                                                                ti 2G (k)

where nk + 1 is the total number of sampling points in G (k) .

   Hence,
          (avg)                           p                                                         p
     [ ; ]T       K           2n K =          n(2M (1)               2M (3) )                  R = 2 n(M (1)                      M (3) ) + Op (K 1=2 );                  (A.16)
            PK        h                                                               i
since R =                 (   2               )+(      2                             ) satisfying ER2 = V ar(R)                                        4KV ar( 2 ):
              k=1             min G (k)                max G (k)
A Tale of Two Time Scales: Determining Integrated Volatility                                                         25


    Since n 1 K ! 0, and since the error terms in (A.14) and (A.15) are uniformly integrable, it
follows that
                        (A:12) = 2(M (1) M (2) ; M (1) M (3) ) + op (1)                  (A.17)

   Hence, (A.12) is also asymptotically normal with covariance matrix
                                                            !
                                      4E 4       4 Var( 2 )
                                                              :
                                      4 Var( 2 ) 4E 4


   By Lemma A.1, and as n       1K     ! 0,
                     1
                    p [Y; Y ](all)
                             T           2 n; K([Y; Y ]T
                                                              (avg)
                                                                         [X; X]T
                                                                                   (avg)
                                                                                           2 n) jX
                      n
is asymptotically normal,
                                                                    !                              !
                  (all)
            [Y; Y ]T     2 n                                                       M (1)   M (2)
      p1                                                      jX         =2                            + op (1)
                   (avg)                        (avg)
        n
            [Y; Y ]T K 2 nK             [X; X]T         K                          M (1)   M (3)
                                                                                                           !!     (A.18)
                                                               L                    E 4    Var( 2 )
                                                                ! 2N          0;
                                                                                    Var( ) E 4
                                                                                        2



   Since                                                                 r
                                1        (all)     K                         K
                            ^=    [Y; Y ]T     and p =                         (1 + o(1));                        (A.19)
                               2n                   n                        n
Theorem A.1 follows.


A.3    Asymptotics of DT

For transparency of notation, we take t = T =n, in other words, the average of the ti . For given
                  (k)                                                        (k)
s 2 [0; T ], let s be the closest point on grid G (k) smaller than s, i.e., s = maxfu s : u 2 G (k) g.
                                         (k)
In particular, for grid points ti , let ti be the closest point on the grid G (k) smaller than ti , i.e.,
 (k)                                            (k)       (k)
ti = maxfu ti : u 2 G (k) g. Observe that ti = (ti ) .

   We do not assume regular allocation of sample points to subgrids, but instead that
                                        K
                                        X               (k)        (l)
                                 max          f#k : ti        > ti g2 = O(K 3 ):                                  (A.20)
                                   i
                                        l=1

                   (k)    (l)                                                                              (l)
Note that f#k : ti > ti g is the number of points in the total grid G between ti and ti . The
requirement (A.20) is satis…ed under regular allocation of sample points to subgrids, as de…ned in
Section 3.2, in other words, G (l) = ftl 1 ; tK+l 1 ; :::g.
A Tale of Two Time Scales: Determining Integrated Volatility                                                                       26


Proof of Theorem 2. Rewrite
                                         (avg)
                DT   = [X; X]T                          < X; X >T
                                 K
                                 X
                             1                              (k)
                     =                    ([X; X]T                 < X; X >T )
                             K
                                 k=1
                                 XK              X                    Z   ti+1
                             1
                     =                                            2              (Xs        Xti )dXs by Itô’s formula
                             K                                        ti
                                 k=1 fti ;ti;+ 2G (k) g
                             Z             K
                                     T
                                         1 X
                     = 2                     (Xs                  Xs(k) )dXs
                                 0       K
                                           k=1

                                                                                        1   PK
Denote the integrand as Zs . We can write Zs = Xs                                       K     k=1 Xs(k)


   Following the arguments in Mykland and Zhang (2002), the quadratic variation of DT is
                                                    Z       T
                  < D; D >T              = 4                    Zs2 d < X; X >s
                                                    0
                                                    Z       T
                                                                              K
                                         = 4                    < Z; Z >s d < X; X >s +op (
                                                                                 )
                                              0                                n
                                             Z T
                                                                               K
                                         = 4     < Z; Z >s < X; X >0s ds + op ( )
                                              0                                 n
                                                 Z
                                             X i+1  t
                                                                                    K
                                         = 4          < Z; Z >s < X; X >0s ds + op ( );
                                                  ti                                n
                                                        i

where the sum is over all (except the last) observation points ti . To calculate the integrand, note
that for ti s < ti+1 ,
                                K K
                             1 XX
< Z; Z >s < X; X >0s =              (< X; X >s                                     < X; X >s(k) ^s(l) ) < X; X >0s
                             K2
                                         k=1 l=1
                                         XK
                             1                                                                            (k)      (l)
                         =                     (< X; X >s                   < X; X >s(l) )(2f#k : s             > s g + 1) < X; X >0s
                             K2
                                         l=1
                                         XK
                             1                              (l)                   (k)        (l)                            K
                         =                     (s           ti )(2f#k : ti              > ti g + 1)(< X; X >0ti )2 + op (     );
                             K2                                                                                             n
                                         l=1
A Tale of Two Time Scales: Determining Integrated Volatility                                                                     27

            (l)         (l)
since the s       = ti as s varies over the relevant time interval [ti ; ti+1 ). Hence
              Z     ti+1
                              < Z; Z >s < X; X >0s ds
                   ti
                     K Z ti+1
                  1 X                        (l)                     (k)       (l)                             K
        =                     (s           ti )ds (2f#k : ti               > ti g + 1)(< X; X >0ti )2 + op (      )
                  K2    ti                                                                                     n2
                        l=1
                        XK
                  1              1 2               (l)                       (k)      (l)                              K
        =                          t + (ti         ti ) ti (2f#k : ti              > ti g + 1)(< X; X >0ti )2 + op (      )
                  K2             2 i                                                                                   n2
                        l=1
                  1                               K
        =           tKhi (< X; X >0ti )2 ti + op ( 2 )
                  4                               n
where the hi are de…ned by (22). Hence, since the error term above is uniform in i (in probability),
                                                              X                                   K
                                  < D; D >T =            tK       hi (< X; X >0ti )2 ti + op (      )                         (A.21)
                                                                                                  n
                                                              i

thus showing Theorem 2.

   We now proceed to the asymptotic distribution of DT . We …rst state a technical condition on
the …ltration (Ft )0 t T to which Xt and t (but not the 0 s) are assumed to be adapted.

    Condition E (Description of the …ltration): There is a continuous multidimensional P -local
martingale X = (X (1) ;  ; X (p) ), any p, so that Ft is the smallest sigma-…eld containing (Xs ; s
t) and N , where N contains all the null sets in (Xs ; s T ).

   For example, X can be a collection of Brownian motions.

    Proof of Theorem 3. One shows by methods similar to those in the proof of Theorem 2 that
if L is any martingale adapted to the …ltration generated by X , then
                                                          1
                                               sup j         < D; L >t j !p 0;                                                (A.22)
                                                    t     tK
The stable convergence with respect to the …ltration (Ft )0 t T then follows in view of Rootzen
(1980) or Jacod and Protter (1998). This ends the proof of Theorem 3.

    Finally, in the case where 2 does not converge, one can still use the mixed normal with variance
 2 . This is because every subsequence of 2 has a further subsequence which does converge in
 n                                            n
probability to some 2 in probability, and hence for which the assumption (27) in Theorem 3 would
be satis…ed.

   The reason for this is that one can de…ne the distribution function of a …nite measure by
                                                X
                                       Gn (t) =      h i ti                                (A.23)
                                                                    ti+1 t
A Tale of Two Time Scales: Determining Integrated Volatility                                            28


Since Gn (t) T supi hi , it follows from (24) that the sequence Gn is weakly compact in the sense
of weak convergence (see Helly’s Theorem, e.g. Billingsley (1995) p. 336). For any convergent
subsequence Gn ! G, we then get that
                              Z   T                                  Z   T
                      2
                      n   =           (< X; X   >0t )2 dGn (t)   !           (< X; X >0t )2 dG(t):   (A.24)
                              0                                      0

almost surely, since be have assumed < X; X >0t to be a continuous function of t. One then de…nes
 2 to be the (subsequence dependent) right hand side of (A.24).


   To proceed further with the asymptotics, continue the subsequence from above, and note that
                                               Z t
                          1
                              < D; D >t            (< X; X >0s )2 dGn (s)
                           tK                   0
                                               Z t
                                          !        (< X; X >0s )2 dG(s)
                                                             0

to conclude.




REFERENCES
Aït-Sahalia, Y., Mykland, P. A., and Zhang, L. (2003), “How Often to Sample a Continuous-Time
  Process in the Presence of Market Microstructure Noise,” Tech. rep., Princeton University.

Aldous, D. J. and Eagleson, G. K. (1978), “On Mixing and Stability of Limit Theorems,” Annals
  of Probability, 6, 325–331.

Andersen, T. G., Bollerslev, T., Diebold, F. X., and Labys, P. (2001), “The Distribution of Exchange
 Rate Realized Volatility,” Journal of the American Statistical Association, 96, 42–55.

Bai, X., Russell, J. R., and Tiao, G. C. (2000), “Beyond Merton’s Utopia I: E¤ects of Non-Normality
  and Dependence on the Precision of Variance Estimates Using High Frequency Financial Data,”
  Tech. rep., University of Chicago.

Barndor¤-Nielsen, O. E. and Shephard, N. (2001), “Non-Gaussian Ornstein-Uhlenbeck-Based Mod-
  els And Some Of Their Uses In Financial Economics,” Journal of Royal Statistical Society, B,
  63, 167–241.

Billingsley, P. (1995), Probability and Measure, New York: Wiley, 3rd ed.

Brown, S. J. (1990), “Estimating Volatility,” in Financial Options: From Theory to Practice, eds.
  Figlewski, S., Silber, W., and Subrahmanyam, M., Homewood, IL: Business One-Irwin, pp. 516–
  537.

Campbell, J. Y., Lo, A. W., and MacKinlay, A. C. (1997), The Econometrics of Financial Markets,
  Princeton, NJ: Princeton University Press.
A Tale of Two Time Scales: Determining Integrated Volatility                                   29


Chernov, M. and Ghysels, E. (2000), “A Study Towards a Uni…ed Approach to the Joint Estimation
  of Objective and Risk Neutral Measures for the Purpose of Options Valuation,” Journal of
  Financial Economics, 57, 407–458.

Gallant, A. R., Hsu, C.-T., and Tauchen, G. T. (1999), “Using Daily Range Data to Calibrate
 Volatility Di¤usions and Extract the Forward Integrated Variance,” The Review of Economics
 and Statistics, 81, 617–631.

Gloter, A. (2000), “Estimation des Paramètres d’une Di¤usion Cachée,” Ph.D. thesis, Université
  de Marne-la-Vallée.

Hall, P. and Heyde, C. C. (1980), Martingale Limit Theory and Its Application, Boston: Academic
 Press.

Hull, J. and White, A. (1987), “The Pricing of Options on Assets with Stochastic Volatilities,”
 Journal of Finance, 42, 281–300.

Jacod, J. and Protter, P. (1998), “Asymptotic Error Distributions for the Euler Method for Sto-
  chastic Di¤erential Equations,” Annals of Probability, 26, 267–307.

Karatzas, I. and Shreve, S. E. (1991), Brownian Motion and Stochastic Calculus, New York:
 Springer-Verlag.

Mykland, P. A. and Zhang, L. (2002), “ANOVA for Di¤usions,” Tech. rep., The University of
 Chicago, Department of Statistics.

Rényi, A. (1963), “On Stable Sequences of Events,” Sankyā Series A, 25, 293–302.

Rootzen, H. (1980), “Limit Distributions for the Error in Approximations of Stochastic Integrals,”
  Annals of Probability, 8, 241–251.

Zhang, L. and Mykland, P. A. (2003), “Interval Estimation for the Variability of a Contaminated
  Ito Process,” Tech. rep., Carnegie-Mellon University, Department of Statistics.
