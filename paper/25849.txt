                              NBER WORKING PAPER SERIES




                      EMPLOYMENT DISCRIMINATION AGAINST
                    INDIGENOUS PEOPLES IN THE UNITED STATES:
                       EVIDENCE FROM A FIELD EXPERIMENT

                                        Patrick Button
                                       Brigham Walker

                                      Working Paper 25849
                              http://www.nber.org/papers/w25849


                    NATIONAL BUREAU OF ECONOMIC RESEARCH
                             1050 Massachusetts Avenue
                               Cambridge, MA 02138
                                    May 2019




We are thankful for internal grant support from the Murphy Institute, CELT, NCI, the Duren
Professorship, the Kurzius Family Professorship, and the COR Research Fellowship. We also
thank the National Institutes of Health via a postdoctoral training grant for Patrick Button
(5T32AG000244-23) which funded his research at the RAND Corporation. The views expressed
are our own and not those of any funders. We thank Cathy Balfe, Danell Benguigui, Connor
Crowley, Olivia Frazer, Natalie George, Emmarose Glaser, Ilan Gressel, Jason Housman,
Jennifer Kallenburg, Kendall Knuth, Keenan Lang-Backe, Julia Levy, Adam Majewski, Ethan
May, Shea McGrinder, Chris Pennanen, Sam Rich, Claudia Shi, Jinlong Shi, Piper Serra, Hunter
Spires, Alec Stewart, Savannah Strachan, Tiantian Tang, and Aubrey Wang for excellent research
assistance and comments. We also thank Randall Akee, Peter Blair, Ian Burn, Nanneh Chehras,
Donna Feir, Joanna Lahey, Miriam Jorgensen, David Neumark, David Phillips, and anonymous
referees for helpful comments and discussions. We received helpful feedback from seminar and
conference participants at the AEA, Auburn, the Bush School at TAMU, IZA/SOLE, URegina,
SOFI, the SSS, Tulane, UVic, and the Hoover Institute. This study was approved by Tulane
University’s IRB (#16-910329UE, #1085352-TU, #2018-477-TU). The views expressed herein
are those of the authors and do not necessarily reflect the views of the National Bureau of
Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2019 by Patrick Button and Brigham Walker. All rights reserved. Short sections of text, not to
exceed two paragraphs, may be quoted without explicit permission provided that full credit,
including © notice, is given to the source.
Employment Discrimination against Indigenous Peoples in the United States: Evidence from
a Field Experiment
Patrick Button and Brigham Walker
NBER Working Paper No. 25849
May 2019
JEL No. C93,J15,J7

                                           ABSTRACT

We conducted a resume correspondence experiment to measure discrimination in hiring faced by
Indigenous Peoples in the United States (Native Americans, Alaska Natives, and Native
Hawaiians). We sent employers realistic 13,516 resumes for common jobs (retail sales, kitchen
staff, server, janitor, and security) in 11 cities and compared callback rates. We signaled
Indigenous status in one of four different ways. We almost never find any differences in callback
rates, regardless of the context. These findings hold after numerous robustness checks, although
our checks and discussions raise multiple concerns that are relevant to audit studies generally.


Patrick Button
Department of Economics
Tulane University
6823 St. Charles Avenue
New Orleans, LA 70118
and NBER
pbutton@tulane.edu

Brigham Walker
Department of Economics
Tulane University
bwalker6@tulane.edu




A data appendix is available at
http://www.nber.org/data-appendix/w25849
A randomized controlled trials registry entry is available at
https://www.socialscienceregistry.org/trials/2299
                                                  Introduction

         Indigenous Peoples1 in North America faced perpetual injustices throughout history. A

summary2 includes, but is not limited to, the colonization, annexation, and military occupation of

Hawaii (Silva 2004; Sai 2008), genocide (Thornton 1987), massacres (e.g., Wounded Knee, Brown

2007), forced relocation (e.g., the “Trail of Tears”) and isolation in Indian reservations (Foreman

1972), disenfranchisement (Wolfley 1991), the slaughter of the bison (Feir, Gillezeau, and Jones

2017), and the forcible assimilation of Indigenous children through Indian boarding schools (Feir

2016b, 2016a; Adams 1995).

         These injustices extend to contemporary racial disparities, which are some of the largest.

Among racial and ethnic minorities, American Indians and Alaska Natives (AIANs) have the

lowest employment-to-population ratio (54.6%, with 59.9% for whites), the highest

unemployment rate (9.9%, with 4.6% for whites) (U.S. Bureau of Labor Statistics 2016), and they

earn significantly less income (median income of $35,060 in 2010, compared to $50,046 for the

nation as a whole) (U.S. Census Bureau, 2015). These disparities are less stark for NHPIs as they

have the highest employment-to-population ratio (62.8%); though, this reflects a stronger economy

in Hawaii. Even absent this, unemployment rates are still higher for NHPIs relative to whites

(5.7%, versus 4.6%) (U.S. Bureau of Labor Statistics 2016). Poverty rates among those who

identify as AIAN alone (NHPI) are nearly double (1.5 times) the rates of those in the general

population (U.S. Census Bureau, 2015; WHIAAPI 2010). For NHPIs, this is These disparities are

even more substantial for the 22% of AIANs who reside or used to reside on one of the 326 federal


1
  The term Indigenous Peoples refers to those who lived in North America before colonization. Indigenous Peoples
in the United States encompass a broad group including Native Americans (of which there are at least 566 identified
tribal groups in the United States), Alaska Natives, and Native Hawaiians and other Pacific Islanders. In this paper,
we use Indigenous Peoples to refer to the broad group of those who are Native American or Alaska Native (titled
American Indian or Alaska Native, AIAN, in the U.S. Census), or Native Hawaiian (titled Native Hawaiian and
other Pacific Islanders, NHPI, in the U.S. Census.)
2
  See Nabokov (1999) for a more detailed historical summary.

                                                          2
or state Indian reservations (U.S. Census Bureau 2015; Gitter and Reagan 2002; Taylor and Kalt

2005) or on Alaska Native Statistical Areas (U.S. Census Bureau 2011).3 These disparities are only

becoming more relevant as Indigenous populations grow.4

        Several factors could contribute to these disparities, such as differences in education,

geography (especially Indian reservations), and the intergenerational legacy of colonialism.5

Another possible explanation is employment discrimination. Survey evidence suggests that

Indigenous Peoples face employment discrimination6 and there are negative stereotypes against

Indigenous Peoples that may lead to employment discrimination.7 However, we are only aware of

one peer-reviewed study that attempted to quantify employment discrimination against Indigenous

Peoples in the United States (Hurst 1997).8 Hurst (1997) decomposed the AIAN-white earnings

gap using the Oaxaca-Blinder decomposition method. Hurst (1997) found that, while observable

factors such as education and geography explain a large part of the gap (e.g., 87% of the earning




3
  Native Americans living on tribal lands were 10.1% more likely to live in poverty (Collett, Limb, and Shafer,
2016).
4
  According to the 2010 Census, 5.2 million people identified as AIAN, alone or in combination (Norris, Vines, and
Hoeffel, 2012) and 1.2 million people identified as Native Hawaiian or Other Pacific Islander (NHPI), alone or in
combination (Hixson, Hepler, and Kim, 2012). The AIAN population is projected to grow to 8.6 million by 2050
(U.S. Census Bureau, 2015) and the NHPI population is also experiencing relatively rapid growth (Hixson, Hepler,
and Kim 2012).
5
  Research on how historical mistreatment of Indigenous Peoples has led to current disparities includes Feir (2016a,
2016b), Adams (1995), and Feir, Gillezeau, and Jones (2017).
6
  In a survey of 342 Native American adults in the United States, 31% of respondents believed that they were
discriminated against because they were Native American when applying for jobs (NPR, Harvard T.H. Chan School
of Public Health, and Robert Wood Johnson Foundation 2017). See also https://www.justice.gov/opa/pr/justice-
department-sues-south-dakota-state-agency-discrimination-against-native-american-job (accessed May. 1, 2016).
7
  Stereotypes, especially in the media, are that Native Americans are “savages” or “noble savages” (they are
spiritual, wise, and have traditional beliefs and cultural traditions) (McLaurin 2012; Riverwind 2007). The
stereotypes most closely connected with employment are that Native Americans are lazy, less interested in work,
less educated or skilled, and rely on government handouts (Riverwind 2007; Schmidt 2007; Tan, Fujioka, and Lucht
1997; James et al. 1994). There is also the perception that Native Americans are more likely to suffer from
alcoholism (Riverwind 2007; Tan, Fujioka, and Lucht 1997). For a broader discussion, see James et al. (1994).
8
  Research on discrimination against Indigenous people is somewhat more common for Canada (e.g., Kuhn and
Sweetman 2002; Krishna and Ravi 2011; Feir 2013) and Australia (e.g., Booth, Leigh, and Varganova, 2012). Many
discrimination studies focus on the United States, but they are all on other disadvantaged groups. See Neumark
(2018) for a review of the experimental studies. Austin (2013) suggests that a resume-correspondence study of our
nature for discrimination against Native Americans would be useful (pp. 25).

                                                         3
gap between those who identify as AIAN alone versus white alone), there is “still a substantial

unexplained differential in earnings between the various categories of Indians and non-Indians.”

(p. 805).

        Quantifying employment discrimination against Indigenous Peoples is essential to inform

policies to reduce these large economic disparities. If there is little discrimination, then disparities

are primarily caused by factors other than employment discrimination like differences in

education, which policy-makers could then target directly. However, if there is significant

discrimination, then this suggests that supply-side policy measures like education or skills training9

may be less effective at closing this gap. In this case, stronger discrimination laws, or stronger

enforcement of them, could be more helpful, as could efforts that seek to reduce discriminatory

attitudes or behaviors or our abilities to act upon them.

        To quantify whether discrimination is behind these economic disparities, we conducted a

field experiment of hiring discrimination—more specifically, a resume correspondence study—

sending job applications to job openings. Field experiments such as ours are the preferred method

of estimating employment discrimination because they can hold all factors other than minority

status constant (Neumark 2018; Bertrand and Duflo 2017; Gaddis 2018) which is not the case for

studies that use survey data (e.g., Hurst, 1997).

        In our field experiment, job applications are identical on average but are either signaled to

be white or Indigenous (Native American, Alaska Native, or Native Hawaiian). Our general

approach follows previous studies of this nature (e.g., Pager, 2003; Bertrand and Mullainathan,




9
 For example, the Bureau of Indian Affairs’ (BIA) Financial Assistance and Social Services (FASS) program
(https://www.benefits.gov/benefits/benefit-details/801), the Native American Vocational and Technical Education
Program (NAVTEP) (…/756), the U.S. Department of Labor’s Division of Indian and Native American Program
(DINAP) (…/81), the Indian Higher Education Grant Program (…/796), and the U.S. Department of the Interior’s
Job Placement and Training Program (…/797) (all accessed June 30, 2018).

                                                        4
2004; Lahey, 2008; Neumark, Burn, and Button, 2019) by estimating hiring discrimination by

comparing interview offer rates (“callbacks”) by race. Since signaling Indigenous status is not

straightforward, we use four different methods: first names for some Native Hawaiian applications,

last names for some Native American applicants of Navajo ancestry, listing an Indigenous

language along with English as mother tongues in a language section on the resume, or by

mentioning Indigenous status in the description of a volunteer experience, mirroring Tilcsik

(2011), Ameri et al. (2018), and Namingit, Blankenau, and Schwab (2017).

         We also quantify whether there is additional bias against Native Americans from Indian

reservations. Employers may have negative perceptions of these reservations, as poverty rates

there are higher (Collett, Limb, and Shafer 2016), economic conditions are worse (Gitter and

Reagan 2002; Taylor and Kalt 2005; Akee and Taylor 2014) (Gitter and Reagan 2002; Taylor and

Kalt 2005), and educational quality can be lower (DeVoe, Darling-Churchill, and Snyder, 2008).10

Estimating this potential bias has important implications given increased migration over time from

Indian Reservations to urban centers (e.g., Snipp 1997, Pickering, 2000). Bias may be an additional

friction in the ability of Native Americans to successfully migrate to urban centers.

         Our large-scale field experiment, based on 13,516 job applications in 11 cities and five

occupations, shows no evidence of discrimination in callbacks against Indigenous Peoples. This

holds even when we analyze the data separately by occupation, occupation-and-gender, and by

city. Our estimates of no discrimination differ from the majority of similar field experiments of

hiring discrimination that find discrimination against the minority group (Neumark 2018; Baert




10
  As noted above, Native Americans living on tribal lands were 10.1% more likely to live in poverty compared to
those in rural areas (Collett, Limb, and Shafer, 2016). The per capita income of American Indians on reservations is
less than half the US average (Akee and Taylor 2014). We provide some details on the prevalence of Native
Americans presently living on or near a reservation in Online Appendix Table I1.

                                                         5
2018). We similarly find no differences based on how we signal Indigenous status and no

additional bias against Native Americans who lived on an Indian Reservation.

           We conduct an extensive battery of robustness checks, including adjusting for the variance

of unobservables (Neumark 2012; Neumark and Rich 2018) . We also carefully put our results in

context and compare them to the previous literature. We conduct a complementary Oaxaca-Blinder

decomposition of gaps in earnings, unemployment rates, and unemployment duration, to explore

how our results compare to non-experimental estimates of discrimination and to determine what

observable factors may be behind these disparities in economic outcomes.

           These checks and discussions suggest that our results are, in most cases, not due to choices

in our experimental design, but they do shed light on concerns such as economic cycles and the

saliency of audit study signals, which affect the interpretation of this and previous audit studies

more broadly and should be considered by future researchers. We also propose a larger battery of

robustness checks that those doing audit studies should consider, regardless of the results of their

experiment.



                                            Field Experiment Design

           In this section, we summarize how we designed our field experiment. We discuss issues

such as our pre-analysis plan, how we signaled race, how we constructed the resumes, which jobs

we targeted, and which cities we picked. Our goal was to design the field experiment to be as

externally valid as possible, and we aim in this section to be transparent in our design, especially

as our choices and discussion may be helpful to others designing these experiments. Additional

details on the design of our field experiment are in Online Appendix A.11



11
     The online appendix is available at http://www.patrickbutton.com/research.

                                                           6
         To briefly summarize the general experimental design, we sent two applications in a

random order to each job in retail sales, server, kitchen staff, janitor, and security. One application

was from an Indigenous applicant (Native American, Native Hawaiian, or Alaska Native), with

the Indigenous status signaled in four possible ways (volunteer experience, language, first name,

last name). The other application was from a non-Indigenous (white) applicant that had no minority

signals. All applicants had a high school diploma and relevant work experience in the occupation,

with resumes constructed partly from publicly-posted resumes on Indeed.com. We applied to jobs

in 11 cities: Albuquerque, Anchorage, Billings, Chicago, Honolulu, Houston, Los Angeles, New

York, Oklahoma City, Phoenix, and Sioux Falls. We measured discrimination by comparing

callback rates – interview offers or other positive responses – by race. Figure 1 provides a diagram

that summarizes our resumes and approach.

Pre-Analysis Plan

         Before putting this experiment into the field, we filed a pre-analysis plan and registered it

with the American Economic Association’s Randomized Control Trial Registry.12 The goal was

to pre-specify any variables, models, sample sizes, or decisions to prevent data mining or p-

hacking while simultaneously avoiding tying our hands too much in ways that would negatively

affect our ability to conduct this research later (see Olken 2015 and Lahey and Beasley 2018). We

discuss this pre-analysis plan in greater detail in Online Appendix B.13




12
   Few audit studies of discrimination are registered yet registering randomized control trials in other fields is
standard. For our registered trial, see https://www.socialscienceregistry.org/trials/2299 (accessed December 26,
2017).
13
   We also explain a few minor deviations that we made to our analysis relative to the pre-analysis plan, although
these minor deviations do not affect the results.

                                                          7
     Figure 1 – Example of Pairs of Applicants for Jobs in Phoenix with Navajo Applicants




Notes: We always sent the A-B pair when the Indigenous applicant was Native Hawaiian or Alaska Native as type C
is not possible for these groups. For pair with a Native American applicant, half of the jobs get the A-B pair, and the
other half get the A-C pair. Half the A-C pairs have Job 3 for type C be a job on the Indian reservation while the
other half have the equivalent job in the local city as in type A.

Signaling Indigenous Status

         Indigenous people in the United States belong to numerous different tribal groups (the

federal government recognizes 567 tribal nations National Congress of American Indians (2017)).

Consequently, it is not possible to study all tribal groups.14 Also, racial signals must be carefully

chosen to be appropriate for each tribal group. Further, there is no obvious way to signal

Indigenous status, and different possibilities have strengths and weaknesses. Names are most



14
   Given that we wanted to vary Indian reservation upbringing, for Native American applicants, we selected from
tribal nations with reservations for their tribal affiliation. We then selected the tribal nations associated with the
reservations we ultimately chose, as discussed later.

                                                            8
  externally valid way to signal race, since names always need to be included, but names could be a

  weak signal or could signal socioeconomic status in addition to race (Fryer and Levitt 2004;

  Barlow and Lahey 2018; Gaddis 2017a, 2017b). On the other hand, disclosing minority status

  through work or volunteer experience (e.g., Tilcsik 2011; Ameri et al. 2018; Namingit, Blankenau,

  and Schwab 2017) may be a stronger signal but may be less externally valid since minority groups

  may prefer not to signal group affiliation to avoid potential discrimination.

           We used four possible ways to signal that the job applicant is Indigenous: volunteer

  experience, languages spoken, first names for Native Hawaiians, and last names for Native

  Americans of Navajo ancestry. We present our matching of possible signals to Indigenous groups

  in Table 1 and explain these assignment decisions below (sample resumes are in Online Appendix

  H). We also test the robustness of our results to signal type in our robustness section and in Online

  Appendix D. We the test the saliency of our signals through surveys, discussed later and presented

  in greater detail in Online Appendix E and Online Appendix F.

              Table 1 – Summary of Possible Racial Signals by Indigenous Group
                        Possible Signals of Indigenous Status
                                                                        Indian Reservation
Indigenous Group   Volunteer                       First     Last            Possible
                                   Language
                   Experience                     Name      Name
Navajo                  X        X (Navajo)                   X   X (Navajo Nation)
Apache                  X        X (Apache)                       X (Fort Apache or San Carlos)
Blackfeet               X                                         X (Blackfeet)
Tohono O’odham          X        X (Pima)                         X (Tohono O’odham)
Oglala Lakota           X        X (Lakota)                       X (Pine Ridge)
Osage                   X                                         X (Osage)
Alaska Native           X        X (Yup’ik)
Native Hawaiian         X        X (Hawaiian)       X
  Notes: The language signal is not possible for Blackfeet or Osage because Indigenous language use for those tribes is
  not sufficiently common (see Online Appendix Table A1).

           Volunteer experience as an Indigenous signal.

           Volunteer and work experience have been used before to signal minority status. Tilcsik

  (2011) and others signal sexual orientation through volunteer experience with a lesbian, gay,

                                                           9
bisexual, and transgender (LGBT) or gay or lesbian group. Ameri et al. (2018) signal disability

partly through a relevant volunteer experience as an accountant at a fictional disability group.

Namingit, Blankenau, and Schwab (2017) disclose an illness-related gap in employment history

partly through a volunteer experience (Cancer survivor’s group) on a resume.

        We follow a similar approach by using volunteer experience as one way to signal race. We

used volunteer experience as a youth mentor with the Big Brothers and Big Sisters (BBBS) of

America to signal race. In this volunteer experience, it is typical for “Bigs” to be matched with

“Littles” based on race or other socioeconomic factors to improve mentorship. We list this in a

volunteer experience section with a title such as “Youth Mentor,” and a description such as: “I

mentored youth in my [Native American/Native Hawaiian/Alaska Native] community. I worked

with youth on social skills, academics, and understanding our [Native American/Native

Hawaiian/Alaska Native] culture.” For an example, see the example resumes presented in Online

Appendix H.

        A concern with using a volunteer experience to signal race is that this experience could be

valuable to employers, independent of the racial signal.15 To control for this, all resumes,

regardless of race or signals used listed a volunteer experience. For the white resume in a pair

where the Indigenous resume has the volunteer signal, the white resume has a volunteer experience

either at a local Boys & Girls Club or at a local food bank. For any resume pair where the

Indigenous applicant does not signal through volunteer experience, then one resume chosen at

random gets the BBBS volunteer experience without a mention of race, and the other resume gets




15
  However, similarly-constructed resume experiments did not find that the addition of similar volunteer experiences
improved callback rates (Neumark, Burn, and Button, 2019).

                                                        10
either Boys & Girls Club or food bank.16 Thus, we can directly identify the effect of the BBBS

experience, relative to the control volunteer experiences, separately from its use as a racial signal.

However, we find no differences in callback rates by type of volunteer experience.

         Language as an Indigenous signal.

         We found few audit-correspondence studies of discrimination that used language as a

signal of minority status.17 The American Community Survey codes 169 AIAN languages, plus

Hawaiian and Hawaiian Pidgin. While most Indigenous people primarily speak English,

Indigenous languages are somewhat common: 26.8% of AIANs spoke a language other than

English at home in 2014, compared to 21.2% nationally (U.S. Census Bureau 2015). Among those

who identified as NHPI alone and were born in the United States, 30.3% spoke a language other

than English at home (U.S. Census Bureau 2014). Since it is rare for non-Indigenous people to

speak an Indigenous language, especially as a native speaker, this makes for a robust racial signal.

We thus used Indigenous languages to signal Indigenous status in some cases for most (but not all)

of the tribal groups since Indigenous language use varies by tribal group.18 Table 1 presents the

languages that we selected for each Indigenous group, and Online Appendix A presents our

analysis of Census data to determine the frequency of each Indigenous language and thus to what

extent signaling through language is appropriate.19


16
   When this volunteer experience was listed on the resume and was not used to signal race, it was listed in a
volunteer experience section with a title such as “Youth Mentor” and the description such as “I mentor youth in my
community. I work with youth on social skills, academics, and community engagement.”
17
   One example may be Oreopolous (2011) to some extent. Also, another study suggests that it would be a
possibility. Behaghel, Crépon, and Barbanchon (2015) study the effect of randomly anonymizing resumes received
by employers on outcomes for minority workers. While they do not construct “tester” resumes as in a typical audit-
correspondence study, they note that language often signals race, ethnicity, or nationality on actual resumes.
18
   We did not use language to signal Indigenous status for individuals from the Osage or Blackfeet tribes since
Indigenous language use by these tribes is very low.
19
   We used two approaches to determine which languages are spoken by which tribal groups. The first was to
ascertain the languages historically spoken by the tribe. The second was to determine which Indigenous languages
were spoken by individuals who live on the Indian reservations associated with the tribe. While not all individuals
from a tribe live on a reservation, this was the only data-driven approach for us to investigate language use by the
tribal group.

                                                         11
        It is unclear how employers would view this signal. The ability to speak an Indigenous

language may be seen positively by employers, either because the language could be used on the

job (though this is rare) or because it is a signal of general ability.20 On the other hand, speaking

an Indigenous language may signal that the applicant is “more” Indigenous, either culturally or by

ancestry, which may be disliked by discriminatory employers. It may also signal that the applicant

has worse English skills even if it is made clear, as we do on the resumes, that the applicant speaks

both languages natively.

        To investigate this, we added the Irish Gaelic language as a control language to 10% of the

white resumes. We added the Irish Gaelic language which, like Indigenous languages, is

uncommonly-used in the United States. It is also one that is unlikely to signal that the applicant

might have worse English skills since English is nearly universal in Ireland. While this control is

imperfect, we find no difference in callback rates between resumes with an Indigenous language

or Irish Gaelic or between resumes with Irish Gaelic and resumes with no other languages listed.

        First name as an Indigenous signal (Native Hawaiian only).

        We signaled race through first names for some Native Hawaiian applicants only. To

determine possible first name, we first considered names within the top 100 baby names from

Social Security records for the state of Hawaii in order to get a list of common first names only.21

We then investigated which of these popular names were Native-Hawaiian, using various

sources.22 We settled on three male names: Kekoa, Ikaika, and Keoni, and one female name: Maile.


20
   For example, employers may see people that speak a second language (Indigenous or not) as of greater ability
because it is difficult to learn a second language. Alternatively, employers may see individuals who learn a second
language at home as more productive for other reasons (e.g., they were raised by more active parents).
21
   We first queried the United States Social Security Administration’s “Popular Names by State” database for the
state of Hawaii (https://www.ssa.gov/cgi-bin/namesbystate.cgi, accessed November 8, 2016). We considered names
in the top 100 names for boys or girls born in 1985-1987 (corresponding to around age 30, the approximate age of
our applicants).
22
   These sources were “allbabynames.net” (see, e.g., http://www.allbabynames.net/index.php?query=Kekoa),
http://babynames.allparenting.com/US/States/Hawaii_A_Baby_Name_Paradise/,

                                                        12
When using the first name as a racial signal, we randomly assigned one of these names, conditional

on gender. We did not use first names to signal race for Alaska Natives or Native Americans

because there was little information on first names for these populations.23

         Last name as an Indigenous signal (Native American, Navajo, only).

         To find Indigenous-specific last names, we use tabulations from the 2000 Census of the

racial composition of each last name.24 Unfortunately, these data also do not include information

on NHPI individuals, so we can only use this data to determine names for AIAN individuals. We

used this data and other sources on the ancestry of names to select four names of Navajo origin:

Begay, Yazzie, Benally, and Tsosie. These are among the most common last names that are almost

exclusively held by individuals who identify as AIAN alone. Online Appendix A provides more

details of our process for selecting these names.

         We also considered the possibility of assigning some Native American last names that were

perhaps stronger signals (e.g., Sittingbull, Whitebear). However, these names are rare.25 These

names are also difficult to assign appropriately to tribal groups. Further, we had concerns that the

names, especially the very rare ones that did not appear in the Census data, signaled stereotypical




https://en.wiktionary.org/wiki/Appendix:Hawaiian_given_names,
http://www.behindthename.com/names/usage/hawaiian, and http://www.alohafriends.com/names_traditional.html
(all accessed November 13, 2016). All names appear in each source, except Maile does not appear for the last
source.
23
   For example, there is no Census or Social Security Administration tabulation of first names by race as there is for
last names (Tzioumis 2018) and there is little information that suggests that Native American or Alaska Native first
names are sufficiently common. Furthermore, no Alaska Native-specific names appear in the Social Security
database in Alaska for the years 1985-1987.
24
   The tabulations provide a list of 151,671 last names. For each last name, there is an estimate of the number of
people per 100,000 people with this last name and the proportion of people with this name that reported each race.
See http://www2.census.gov/topics/genealogy/2000surnames/names.zip (accessed June 25, 2016).
25
   For example, “Whiteagle” only occurred for 0.16 people per 100,000 people, and “(Fast/Yellow/White)horse”
only occurred for 0.14 people per 100,000 people, each. Even summing over all these names that were perhaps more
salient, they were not sufficiently frequent.

                                                         13
tropes of Native Americans from popular media (McLaurin 2012; Tan, Fujioka, and Lucht 1997).26

That said, these sort of names would have been a stronger signal of Indigenous status, an issue

what may have affected our results, which we discuss later.

         Assigning racial signals.

         Table 1 summarizes which of the signals we used as options for each tribal or Indigenous

group. We allocated Indigenous signals as follows. For Navajo and Native Hawaiian applicants,

where three signals were possible, we assigned signals with the following probabilities: Name only

(30%), Language only (25%), Volunteer only (25%), Name and Language (5%), Name and

Volunteer (5%), Language and Volunteer (5%), and all three (5%). For Alaska Native, Apache,

Tohono O’odham, and Oglala Lakota applicants, where language and volunteer were possible, we

assigned signals with the following probabilities: Language only (40%), Volunteer only (40%),

and both (20%). For Osage and Blackfeet applicants, only the volunteer signal was possible.

Assigning more than one signal allowed to test whether discrimination increased when saliency,

through having multiple signals, was higher.

Indian Reservation Upbringing

         We assigned half of the Native American applicants an upbringing on an Indian reservation

rather than in the city. We signaled this through having graduated from a high school on an Indian

reservation, rather than a local high school. We considered seven Indian reservations, as shown in

Table 1. These fall within the top ten most populous reservations (Norris et al., 2012). We used

one to three high schools per reservation, depending on availability. We specifically chose high

schools with names that were a clear signal that the high school was on an Indian reservation. We



26
  A referee brought up a helpful point that testing “stereotypical” names is useful to inform if those names lead to
discrimination. The referee mentioned that there has been concern about passing along such names to children for
fear that they would face discrimination.

                                                          14
also specified the location of the high school as “City, Reservation Name, State” to ensure the

saliency of this signal. For the white, Native Hawaiian, and Alaska Native resumes, and the other

half of the Native American resumes without an Indian reservation upbringing, we assigned one

of two to four high schools local to the city (from Neumark, Burn, and Button, 2019, and Neumark,

Burn, Button, and Chehras, 2018).27

         For half of the Indigenous applicants with an Indian reservation upbringing, we also had

their first job out of high school (the least recent job, Job 3, as in Figure 1) listed on the resume as

having been on the reservation, while the others had a local job. In addition to strengthening the

reservation signal, this on-reservation work experience is realistic for many Indigenous people

who grew up on an Indian reservation and later migrated to a city. Since we randomized the

addition of this on-reservation work experience, we can identify whether this has any independent

effect beyond the location of the high school. A typical entry-level job on a reservation that was

also common off a reservation, according to publicly posted resumes on Indeed.com, was a cashier

at a grocery store. Thus, for pairs of applicants where we sent Native American applicants, we set

Job 3 (see Figure 1) for both resumes to be a cashier at a grocery store, with the store location

either being on the reservation or in the local city. All subsequent jobs are in the targeted

occupation. Thus, the only change when we included this reservation job was the location of Job

3.

         Employers may prefer local or non-rural applicants, which challenges our ability to identify

differential treatment by Indian Reservation upbringing. We investigate this by randomly

assigning a rural upbringing to white resumes in pairs where we sent a Native American resume.

We added a high school in a small town to 25% of these white resumes, and then in half of these


27
  These schools are ones that have been around for a while and that do not signal any race or ethnicity (e.g., no
historically Black schools).

                                                         15
we also assigned a Job 3 location in that same rural town, mirroring the reservation job.28 Adding

reservation signals may also increase the likelihood that the employer detects that the applicant is

Native American. We attempted to control for this by sometimes assigning Indigenous applicants

to have more than one racial signal to see if this affects results (it does not).

Cities

         We focused on cities where more Indigenous Peoples live to get estimates of discrimination

that better reflect their experiences. We applied for jobs in eight of the ten cities with the most

people who identify as AIAN (Norris, Vines, and Hoeffel 2012). These are, in decreasing order of

AIAN population: New York, Los Angeles, Phoenix, Oklahoma City, Anchorage, Albuquerque,

Chicago, and Houston.29 We then added two additional smaller cities with a larger proportion who

are AIAN: Billings and Sioux Falls. Billings and Sioux Falls are also noteworthy because these

cities are near a few Indian reservations of interest (e.g., Pine Ridge).30

         To study discrimination against Native Hawaiians, we applied to jobs in Honolulu, the city

with the most Native Hawaiians. We also applied for some jobs in Los Angeles with Native

Hawaiian applicants, as Los Angeles is the most common mainland city for Native Hawaiians to

live in (Hixson, Hepler, and Kim 2012).


28
   We specifically chose these small towns to match with each reservation such that both the reservation and small
towns were about an equal distance from the city (see Online Appendix Table A2).
29
   We excluded cities from within states already represented. Those excluded were Tulsa (rank of 6) since it is
similar to Oklahoma City (rank of 4) and San Antonio (rank of 10) since it is similar to Houston (rank of 9). We
note that it would have been useful to study rural areas nearby reservations as well, as discrimination could be more
severe there. However, there are not job boards than can be feasibly used in those areas. We had difficulty getting a
large enough sample size even in “larger” cities such as Sioux Falls and Billings.
30
   The Pine Ridge Indian Reservation is notable because of its extremely high poverty rates and its many other
challenges. See, e.g., Pickering (2000) and media coverage such as
https://www.cnn.com/videos/politics/2017/05/26/pine-ridge-indian-reservation-forgotten-americans-orig-js.cnn
(accessed January 22, 2019). We note that there are numerous reservations that are closer to the cities we test. We
decided to focus on more populous reservations, but in an alternative approach we could have focused on
reservations that were very close by, even if they were small. The distance between the city and the reservation
could matter as could the size of the reservation. Despite these tradeoffs, we do not find discrimination regardless of
reservation upbringing.


                                                          16
Occupations

         We chose common occupational categories where there were many jobs posted online that

usually allowed applications by email and were common for applicants of about age 30. Tables 2

and 3 show the popularity of our selected occupations and these tables present statistics on the race

and gender of those in each occupation, based on the Current Population Survey (CPS).31 The most

popular occupations differed significantly by gender, and much less by race.32 Accordingly, we

settled on jobs in five broad occupations: retail sales, kitchen staff, server, janitors, and security

guards.33   34
                 We used male and female applicants for all occupations except security guard as

women infrequently hold that position.

Education

         All applicants had a high school diploma only. We focused on this group for a few reasons.




31
   For this analysis of CPS data, we use an age range of 25 to 35, we define “white” as “white only,” and we define
AIAN (NHPI) as “AIAN (NHPI) alone or in combination.” See Online Appendix A for additional details. This
appendix also has expanded tables (Online Appendix Tables A3 and A4) showing similar statistics for other
occupations, allowing a comparison of our selected occupations to other popular occupations.
32
   Of the 38 most popular occupations for white men (Online Appendix Table A3) and white women (Online
Appendix Table A4), only 13 appear on both lists. For men, 25 of the 38 most popular occupations for AIAN men
(18 for NHPI men) are also in the top 38 for white men. This is 27 (23) for AIAN women (NHPI women), compared
to the list of 38 for white women.
33
   We note that other occupations that we did not select were also feasible. We chose security instead of drivers
since driver jobs are commonly moving to companies like Uber and Lyft and because we already had the inputs to
make security resumes from a previous study (Neumark, Burn, and Button, 2019). We also found security
interesting to study given the relatively higher concentration of Indigenous men. We opted for server and kitchen
staff over customer service because customer service has some overlap with retail sales, which we had already
included. While we could have applied for administrative and secretarial positions as in Neumark, Burn, and Button
(2019), we decided to avoid doing so since the applications to those jobs in that study elicited many spam responses
that made data collection less accurate and more time-consuming. This occupation was also only common for
women.
34
   We group the occupational categories from the CPS into broader occupations, to match the job postings, as
follows: retail sales (corresponding to retail salespersons; cashiers; counter and rental clerks; sales representatives,
services, all other; and sales and related workers, all others, in the Census occupational classification), kitchen staff
(cooks; food preparation workers; dishwashers; combined food preparation and serving workers, including fast food;
counter attendants, cafeteria, food concession, and coffee shops; food servers, non-restaurant; and dining room and
cafeteria attendants and bartender helpers), server (waiters and waitresses; bartenders; and hosts and hostesses,
restaurant, lounge, and coffee shop), janitors (janitors and building cleaners and grounds maintenance workers), and
security guards (security guards and gaming surveillance officers).

                                                           17
   First, it is much less common for Indigenous Peoples to have a post-secondary education.35

   Second, advanced degrees are usually not required in our selected occupations. Third, we wanted

   to focus on somewhat less-educated individuals who might be closer to the margins of poverty.36

                 Table 2 – Frequency of our Selected Occupations for Men, by Race
                                                        Proportion of Entire Race Ratio to White
                    Occupation (Rank)
                                                         White AIAN NHPI AIAN NHPI
Retail salespersons 41-2031 (#5)                        2.18% 0.83% 0.46% 0.0119 0.0020
Grounds maintenance workers 37-3010 (#6)                2.06% 2.36% 2.11% 0.0359 0.0097
Cooks 35-2010 (#9)                                      1.65% 3.73% 2.51% 0.0707 0.0144
Janitors and building cleaners 31-201X (#10)            1.49% 1.68% 2.00% 0.0355 0.0128
Waiters and waitresses 35-3031 (#24)                    0.94% 0.57% 0.08% 0.0189 0.0008
Cashiers 41-2010 (#31)                                  0.84% 1.26% 0.50% 0.0469 0.0056
Security Guards and Gaming Surveillance Officers (#37) 0.74% 1.44% 2.74% 0.0614 0.0353
   Notes: Data come from all months of the 2015 Current Population Survey. Estimates are weighted using population
   weights. Occupations are ranked based on the decreasing share of white men that have this occupation out of all white
   men. White corresponds to those who report that they are white only, while AIAN (NHPI) correspond to those who
   report AIAN (NHPI) either alone or in combination with another race. Our sample includes those aged 25 to 35 only.
   Ratio to white presents the number of AIAN (NHPI) individuals in the occupation for each white individual. See
   Online Appendix A and Online Appendix Table A3 for a larger table with other occupations.

                  Table 3 – Frequency of our Selected Occupations for Women, by Race
                                                       Proportion of Entire Race Ratio to White
                      Occupation (Rank)
                                                       White AIAN NHPI AIAN NHPI
        Cashiers 41-2010 (#4)                          2.65% 3.30% 3.25% 0.0503 0.0113
        Waiters and waitresses 35-3031 (#5)            2.65% 0.80% 0.47% 0.0122 0.0016
        Retail salespersons 41-2031 (#8)               2.00% 1.94% 1.50% 0.0391 0.0069
        Cooks 35-2010 (#27)                            1.00% 1.11% 1.81% 0.0449 0.0167
        Bartenders 35-3011 (#34)                       0.81% 0.32% 0.86% 0.0161 0.0098
        Janitors and building cleaners 31-201X (#38)   0.75% 0.40% 1.03% 0.0217 0.0127
   Notes: See the notes to Table 2. Occupations are ranked based on the decreasing share of white women that have this
   occupation out of all white women. See Online Appendix A and Online Appendix Table A4 for a larger table with
   other occupations.




   35
      According to data from the Current Population Survey, 33.2% of those who identify as white only and non-
   Hispanic have at least a bachelor’s degree, while this is only 15.2% (22.3%) for those who identify as AIAN alone
   (NHPI alone) (see Online Appendix Table G1.).
   36
      While it is possible to create resumes for applicants without a high school diploma, almost all jobs require this or
   a GED. Assigning a GED is also possible, but these are also not particularly common, and we wanted to focus our
   statistical power on detecting the effects of race.

                                                             18
Job Histories

         We modeled our resume design and descriptions off real publicly-posted resumes from

Indeed.com. This improved the external validity of our experiment. We randomly assigned three

jobs with matching job descriptions from a list of twelve possible jobs per city and occupation

combination. The employer, job title, and address were taken from actual resumes or collected

from active businesses. We randomly generated job tenure distributions, conditional on all three

jobs spanning high school graduation to near the present.37 All applicants within each pair were

either both employed with 25% probability or both unemployed (as of the month before the job

application) with 75% probability.38 Since kitchen staff jobs are very heterogeneous, covering

experienced cooks down to entry-level dishwashers, we created separate resumes for cooks and

more entry-level positions (e.g., food preparation, fast-food, dishwasher).39

Age and Names

         We set the age of all applicants to be approximately 29 to 31, via a high school graduation

year of either 2004 or 2005, randomly chosen (we applied for jobs in 2017). We used first names

that were common for those of this age based on common baby names taken from Social Security

data.40 For last names, we randomly assigned one of the last names used in Neumark, Burn, and

Button (2019) who used names from Social Security Administration tabulations of popular last

names by birth year.




37
   We randomly set the transition period between jobs to be the same month, one month later, two months later, or
three months later, all with equal probability.
38
   During the field experiment, every month we moved the ending date of the most recent job forward one month so
that unemployment durations did not lengthen during the experiment.
39
   While we pool all these kitchen staff jobs together in our analysis, our results are the same if we analyze cook jobs
separately from the others. These results are available upon request.
40
   See https://www.ssa.gov/oact/babynames/#andht=1 (accessed May 20, 2016). We borrowed the list of names from
Neumark, Burn, and Button (2019).

                                                          19
Residential Addresses, Phone Numbers, and Email Addresses

         Within each set of applications sent in response to an ad, all applications were from

different residential addresses, which were randomly assigned. We used addresses from Neumark,

Burn, and Button (2019) and Neumark et al. (forthcoming).41 We assigned each of our applicants

a unique email address and one of 88 different phone numbers.42



                                                 Collecting Data

Pairing Resumes to Send to Job Ads

         After creating the final resumes, we combined them into pairs to apply to each job (see

Figure 1). Each pair always had one white and one Indigenous applicant. The tribal group of the

Indigenous applicants depended on the city in which we applied. Table 4 presents our allocations.

All other resume characteristics were randomized with replacement except the following: first and

last names, resume template styles, addresses, email address domain, employers listed in the job

history, exact phrasing describing skills or jobs on the resume or cover letter, and the specific

volunteer experience. This was to ensure that the resumes were sufficiently differentiated.




41
   These addresses were selected carefully to ensure that they did not signal a race or ethnicity other than white, did
not signal a particular age (e.g., no senior living complexes), and were not likely to send an unusual signal (positive
or negative) about the socioeconomic status of the applicant. These addresses also were not too far from the central
business district(s) in the metro areas.
42
   We purchased enough phone numbers to assign unique numbers to bins of job applicants defined by city, race
(white or Indigenous), and occupation (retail sales, server, kitchen staff, janitor, and security, with janitor and
security pooled into one set of numbers). This resulted in 88 unique phone numbers. With all of these numbers and
other matching methods (further discussed in Online Appendix A), it was highly unlikely that we could not assign a
response to an applicant.

                                                          20
                                Table 4 – Applicant Types Sent by City
City                  Applicant Types Sent
Albuquerque           White (A), Navajo (60%)/Apache (40%) (B or C, 50% probability each)
Anchorage             White (A), Alaska Native (B)
Billings              White (A), Blackfeet (B or C, 50% probability each)
                      White (A), Navajo (25%)/Apache (15%)/Blackfeet (15%)/Osage (15%)/Tohono
Chicago
                      O’odham (15%)/Oglala Lakota (15%) (B or C, 50% probability each)
Honolulu              White (A), Native Hawaiian (B)
Houston               See Chicago
                      White (A), Native Hawaiian (B) (25%) or
                      White (A), Navajo (18.75%)/Apache (11.25%)/Blackfeet (11.25%)/Osage
Los Angeles
                      (11.25%)/Tohono O’odham (11.25%)/Oglala Lakota (11.25%) (B or C, 50%
                      probability each)
New York              See Chicago
Oklahoma City White (A), Osage (B or C, 50% probability each)
                      White (A), Navajo (40%)/Apache (20%)/Tohono O’odham (40%) (B or C, 50%
Phoenix
                      probability each)
Sioux Falls           White (A), Oglala Lakota (B or C, 50% probability each)
Notes: Two applications, one Indigenous and one white, were sent in random order to each job ad. A, B, and C refer
to the resume types presented in Figure 1, where A is always a white applicant, B is always an Indigenous application
who grew up in the urban center, and C is always a Native American applicant who grew up on an Indian reservation.



Sample Size

           In our pre-analysis plan,43 we conducted a power analysis to determine how many

observations would be necessary to detect meaningful differences in callback rates between

Indigenous and white applicants. Based on previous studies, we decided that we wanted to have

the power to detect at least a three-percentage point difference in the callback rate. Based on our

calculations, we anticipated needing to apply to 4,211 jobs (8,422 applications). We ultimately

decided to collect more data (13,516 total applications) to have the power to detect differences

smaller than three percentage points and to detect other mediators of discrimination with more

precision (e.g., reservation upbringing, geography, gender, and occupation). We followed our


43
     See Online Appendix B and https://www.socialscienceregistry.org/trials/2299 (accessed December 26, 2017).

                                                         21
commitment in our pre-analysis plan to do our principal analysis both with the ultimate sample

size (13,516) and with 8,422 applications. Our results are similar either way (see Online Appendix

Table B1).

Identifying Job Ads

         We identified viable jobs to apply for using a common job-posting website.44 The jobs

needed to fit the correct description for our occupational categories, be for non-manager or non-

supervisor roles, and not require in-person applications, inquiries by phone, or application through

an external website. We ignored job ads that required documents that we did not prepare (e.g.,

headshots or salary history) or required skills,45 training, or education that our resumes did not

have. We applied for jobs between March 2017 and December 2017.

Emailing Applications

         We used a different email subject line, opening, body, closing, and signature order for each

application in a pair to ensure that applicants from the same pair were not perceived as related. We

based some of these scripts on examples and advice from job search experts.46 The content of our

emails mirrored cover letters, and we followed the standard practice for these jobs of including

this content in the body of the email (requests for separate cover letters were rare).

Coding Employer Responses

         We coded employer responses as positive (e.g., “Please call to schedule an interview”),

ambiguous (e.g., “We reviewed your application and have a few questions”), or negative (e.g.,

“We have filled the position”). To avoid having to classify the heterogeneous ambiguous responses



44
   We discuss the process that our research assistants followed in detail in Online Appendix A.
45
   We also ignored job ads that required a quality element (e.g., a skill) that was part of the vector of randomized
quality features that we added to the resumes to correct for the variance of unobservables issue. See Online
Appendix C for more details.
46
   See https://www.thebalance.com/writing-a-letter-of-application-for-employment-2061570 (viewed August 20,
2016).

                                                          22
through a subjective process, we follow others (e.g., Neumark, Burn, and Button, 2019) and treat

only positive and ambiguous responses as callbacks, but our results are robust to using strict

interview requests only (see Online Appendix Table D5).



                                       Data Analysis Methodology

        We started by testing how callback rates differed by Indigenous status, then explored how

any possible discrimination varied by Indigenous group, Indian reservation upbringing,

occupation, gender, or by city. We then conducted a battery of robustness checks, including testing

how our discrimination estimates varied by the Indigenous signal(s) we used.

Callback Rates by Indigenous Status and Indian Reservation Upbringing

        We first assessed callback rates by race without regression controls. For this analysis, we

computed raw callback rates by race and used an exact Fisher test (two-sided) to test whether

callback differences were statistically significantly different by race. First, we pooled all

Indigenous groups together to test for a difference between white and Indigenous applicants. Then

we compared Native American, Alaska Native, Native Hawaiian, and white applicants separately.

        We then moved to a regression model and controlled for other resume features to improve

precision and to test the sensitivity of the results to the inclusion of control variables. More

importantly, we added controls for city to account for how we sent different types of resumes

(Indigenous status, Indian reservations, rural upbringing controls) by city. In this regression, we

also investigated whether discrimination against Native Americans differed if they had an

upbringing on an Indian reservation. Our regression is:47


47
  In our pre-analysis plan, we originally committed to using a probit model. However, we became aware that it was
more common to use a linear probability model due to issues with coefficients on interaction terms in non-linear
models (Ai and Norton 2003; Greene 2010). Our probit results are similar and we present them in Online Appendix
Table D1.

                                                       23
       𝐶𝑎𝑙𝑙𝑏𝑎𝑐𝑘𝑖 = 𝛽0 + 𝛽1 𝑁𝐴𝑖 + 𝛽2 𝑁𝐴𝑖 ∗ 𝑅𝑒𝑠𝑒𝑟𝑣𝑎𝑡𝑖𝑜𝑛𝑖
                                                                                                                    [1]
                         + 𝛽3 𝑁𝐴𝑖 ∗ 𝑅𝑒𝑠𝑒𝑟𝑣𝑎𝑡𝑖𝑜𝑛𝑖 ∗ 𝑅𝑒𝑠𝑒𝑟𝑣𝑎𝑡𝑖𝑜𝑛 𝐽𝑜𝑏𝑖 + 𝛽4 𝐴𝑁𝑖 + 𝛽5 𝑁𝐻𝑖

                         + 𝛽6 𝑅𝑢𝑟𝑎𝑙𝑖 + 𝛽7 𝑅𝑢𝑟𝑎𝑙𝑖 ∗ 𝑅𝑢𝑟𝑎𝑙 𝐽𝑜𝑏𝑖 + 𝐶𝑜𝑛𝑡𝑟𝑜𝑙𝑠𝑖 𝛽8 + 𝜀𝑖

where i indexes each application, NA is an indicator variable for being Native American, AN is an

indicator variable for being Alaska Native, NH is an indicator variable for being Native Hawaiian,

Reservation is an indicator variable for being a Native American applicant who grew up on an

Indian Reservation, Reservation Job is an indicator variable for being a Native American applicant

who grew up on an Indian Reservation and their oldest job listed on the resume (first job out of

high school) was on the reservation, Rural is an indicator variable for being a white applicant who

grew up in a rural area, and Rural Job is an indicator variable for being a white applicant who grew

up in a rural town and their oldest job was in the rural town. White is the excluded racial category,

so all estimates reflect callback differences relative to white applicants. Controls is a vector of

resume controls. We used three versions: (1) no resume controls (to match the raw tabulations),

(2) regular controls48 (the default for all our analysis), and (3) full controls, which includes

additional controls49 on top of the regular controls.

         Following Neumark, Burn, and Button (2019), we cluster our standard errors on the

resume. There may also be random influences at the level of the job ad, which would suggest

clustering on the job, or multi-way clustering on the job and the resume simultaneously (Cameron,

Gelbach, and Miller 2011). The difficulty with clustering on the job is that we cannot match all


48
   The regular controls are indicator variables for employment status, resumes skills (Spanish, no typos in cover
letter, better cover letter, and two occupation-specific skills), occupation, gender, resume sending order, volunteer
experience, and city.
49
   The additional controls included in full controls are graduation year (we randomize between two years), the start
month of the oldest job (job 3), the gap (in months) between job 3 and job 2, the gap between job 2 and 1, the
duration of the volunteer experience (in months), and indicator variables for the naming structure for the resume, the
version of the e-mail script, the formatting of the e-mail, the structure of the subject line in the e-mail, the opening
greeting in the e-mail, the structure of the e-mail, the structure of the e-mail signature, the domain of the e-mail
address, the voicemail greeting.

                                                          24
responses perfectly to job ads, leading to a restricted sample.50 However, our results are unchanged

regardless of how we cluster our standard errors (see Online Appendix Table D2).

         After conducting this primary analysis, we then conduct regressions to analyze callback

rates for Indigenous Peoples, compared to whites, separately by occupation, occupation and

gender, and by city. In these and all subsequent analysis we use the regular controls.



                                                       Results

Effects by Race and Indian Reservation Upbringing

         Table 5 presents the raw callback rates by race. The callback rates were nearly identical for

whites and Indigenous Peoples at 19.8% and 20.1%, respectively. By subgroup, the callback rates

were 19.6% for Native Americans, 21.3% for Native Hawaiians, and 25.5% for Alaska Natives.

Exact Fisher tests (two-sided) find that Alaska Natives had a statistically significantly higher

callback rate compared to both whites and Native Americans (both at 5% level).51 However, these

estimates do not control for city-specific callback rates, and higher callback rates for all applicants

in Anchorage almost certainly explain these results.52




50
   Since we assign multiple applicants the same phone number, we are sometimes not able to match a voicemail
response to a specific job even if we can match it to a specific resume because the voicemail is sparse on details
(e.g., applicant name, company) that would typically facilitate a match. In all, there were only 33 responses that we
were unable to match.
51
   This test treats the observations as independent. Our regression analyses that follow clustered our standard errors
so as not to assume independence.
52
   The callback rate for white applicants in Anchorage was 24.8%, and this was much lower for whites in the entire
sample (19.8%).

                                                          25
                   Table 5 – Mean Callback Differences by Indigenous Status
                  Callback:                                    No          Yes         Total
                  White                             80.2%                 19.8%
                                                   (5,421)               (1,337)       6,758
                  Indigenous                        79.9%                 20.1%
                                                   (5,397)               (1,361)       6,758
                      Native American               80.4%                 19.6%
                                                   (4,187)               (1,018)       5,205
                      Native Hawaiian               78.7%                 21.3%
                                                   (1,000)                (271)        1,271
                      Alaska Native                 74.5%                 25.5%
                                                    (210)                  (72)         282
                  Total                             80.0%                 20.0%
                                                  (10,818)               (2,698)      13,516
                  Test of independence (p-value): White                    N.A.        N.H.
                  White                                        …            …            …
                  Native American                            0.763          …            …
                  Native Hawaiian                            0.165        0.132          …
                  Alaska Native                              0.022        0.017        0.153
       Notes: The p-values reported for the tests of independence are from Fisher’s exact test (two-sided).

       In Table 6 we estimate regressions, following Equation [1], to determine callback

differences by race. The results without controls (column (1)) show again that Alaska Natives have

a statistically significantly higher callback rate compared to whites. However, adding the regular

controls (column (2)), which includes city fixed effects, removes this difference. In the regression

with regular controls, our preferred and default specification, Native American applicants (without

a reservation upbringing) have only a 0.4 percentage point lower callback rate, but this is not

statistically significant. Alaska Natives (Native Hawaiians) have a 0.5 percentage point higher (0.3

percentage point lower) callback rate, but this is again not statistically significant.




                                                       26
           Table 6 – Callback Estimates by Race and Indian Reservation Upbringing
                                                              No               Regular               Full
                                                           Controls            Controls           Controls
                                                              (1)                 (2)                (3)
          Native American                                     -0.011            -0.004             -0.005
                                                             (0.010)           (0.009)            (0.009)
          … x Reservation                                      0.000            -0.000             -0.000
                                                             (0.015)           (0.012)            (0.012)
          … x Reservation x Reservation Job                    0.022             0.006              0.005
                                                             (0.020)           (0.016)            (0.016)
          Alaska Native                                      0.052**             0.005              0.003
                                                             (0.026)           (0.035)            (0.035)
          Native Hawaiian                                      0.012            -0.003             -0.002
                                                             (0.013)           (0.013)            (0.013)
          Non-Reservation Rural                             -0.038**            -0.016             -0.015
                                                             (0.016)           (0.013)            (0.013)
          … x Rural Job                                        0.018             0.002              0.002
                                                             (0.023)           (0.018)            (0.018)
                 Callback Rate for White:                                       19.8%
Notes: N=13,516. Standard errors are computed based on clustering at the resume level. Significantly different from
zero at 1-percent level (***), 5-percent level (**) or 10-percent level (*). The regular controls are indicator variables
for employment status, added quality features (Spanish, no typos in the cover letter, better cover letter, and two
occupation-specific skills), occupation, gender, resume sending order, volunteer experience, and city. The full controls
include the regular controls plus the graduation year (we randomize between two years), the start month of the oldest
job (job 3), the gap (in months) between job 3 and job 2, the gap between job 2 and 1, the duration of the volunteer
experience (in months), and indicator variables for the naming structure for the resume, the version of the e-mail script,
the formatting of the e-mail, the structure of the subject line in the e-mail, the opening greeting in the e-mail, the
structure of the e-mail, the structure of the e-mail signature, the domain of the e-mail address, the voicemail greeting.

         After adding controls, such as city fixed effects (column (2)), the callback rates are identical

for Native Americans with and without a reservation upbringing. Callback rates are 0.6 percentage

points higher for those who worked on the Indian reservation, compared to those who just went to

high school on the reservation, but this is again not statistically significant. All these near zero or

small estimates are robust to the inclusion of the full set of controls (column (3)). Therefore, these

regression estimates show no evidence of discrimination.




                                                           27
Effects by Occupation and Gender

        Table 7 presents the results by occupation. For all occupations except security, the callback

rates are nearly identical for Indigenous and white applicants. 53 For security we see a 1.1

percentage point higher callback rate for Indigenous applicants, but this is again statistically

insignificant.

                          Table 7 – Discrimination Estimates by Occupation
             Indigenous                  Estimate            Callback Rate for Whites           N
             … x Retail                   0.004                       17.3%                   2,926
                                         (0.013)
             … x Server                   -0.001                       16.4%                  2,774
                                         (0.013)
             … x Kitchen                  -0.006                       22.2%                  4,858
                                         (0.012)
             … x Janitor                  -0.001                       16.8%                  1,652
                                         (0.016)
             … x Security                  0.011                       27.4%                  1,306
                                         (0.022)
Notes: N=13,516. See the notes to Table 6. Different from zero at 1-percent level (***), 5-percent level (**) or 10-
percent level (*). Regressions use the “Regular Controls” from Table 6 (Column (2)).

        Table 8 presents results by occupation and gender. The estimates show no differential

treatment of Indigenous men compared to white men. We find a strong preference for female

applicants for server positions, a 6.5 percentage point higher callback rate for white women

compared to white men (who have a callback rate of 13.3%). Similarly, and as found in previous

work (e.g., Neumark, Burn, and Button, 2019; Neumark et al. forthcoming), we find a preference

for women in retail sales: a 3.7 percentage point higher callback rate for white women compared

to white men (who have a callback rate of 16.3%).




53
  These results, available upon request, are similar if Native Americans, Native Hawaiians, and Alaska Natives are
analyzed separately.

                                                        28
                  Table 8 – Discrimination Estimates by Occupation and Gender
                                                                        Indigenous x          Callback Rate for
                           Indigenous                Female
                                                                           Female                White Men
 … x Retail                    0.006                0.037**                 -0.003                 16.3%
                             (0.017)                (0.018)                (0.025)
 … x Server                   -0.002               0.065***                  0.002                   13.3%
                             (0.016)                (0.017)                (0.024)
 … x Kitchen                  -0.007                 0.000                   0.001                   21.5%
                             (0.014)                (0.015)                (0.021)
 … x Janitor                   0.003                 -0.012                 -0.008                   17.7%
                             (0.021)                (0.022)                (0.031)
 … x Security                  0.011                                                                 27.4%
                                                       N/A                    N/A
                             (0.022)
Notes: N=13,516. See the notes to Table 6. Different from zero at 1-percent level (***), 5-percent level (**) or 10-
percent level (*). Regressions use the “Regular Controls” from Table 6 (Column (2)). Note that we did not send female
applicants to security jobs.

Effects by City

         Table 9 shows results by city. Again, there are largely no differential results.54 Callback

differences are within two percentage points for all cities except Phoenix (Albuquerque) where

Indigenous applicants have a 4.1 percentage point higher (3.7 percentage point lower) callback

rate. Only the estimate for Phoenix is statistically significant, but only at the 10% level.55




54
   We also ran an additional regression but with additional three-way interactions between NA, Reservation, city, to
see if the effects of reservation upbringing also varied by city. The results, presented in Online Appendix Table D12,
show no differences by city.
55
   Although with 11 cities, we would expect about one city, on average, to have a significant estimate at the 10%
level even absent any actual effects.

                                                         29
                              Table 9 – Discrimination Estimates by City
                       Indigenous                                  Estimate           N
                       … x Albuquerque                              -0.037           700
                                                                   (0.029)
                       … x Anchorage (AK Native)                     0.005           564
                                                                   (0.035)
                       … x Billings                                  0.012           212
                                                                   (0.062)
                       … x Chicago                                  -0.009          1,466
                                                                   (0.018)
                       … x Honolulu (Native HI)                      0.002          2,034
                                                                   (0.016)
                       … x Houston                                  -0.002          1,112
                                                                   (0.024)
                       … x Los Angeles (Native Am.)                 -0.001          1,866
                                                                   (0.014)
                       … x Los Angeles (Native HI)                  -0.014           440
                                                                   (0.019)
                       … x New York                                 -0.011          2,758
                                                                   (0.011)
                       … x Oklahoma City                             0.018           616
                                                                   (0.033)
                       … x Phoenix                                  0.041*          1,526
                                                                   (0.023)
                       … x Sioux Falls                              -0.004           154
                                                                   (0.078)
Notes: N=13,516. See the notes to Table 6. Different from zero at 1-percent level (***), 5-percent level (**) or 10-
percent level (*). Regressions use the “Regular Controls” from Table 6 (Column (2)).




                                                        30
                    Robustness Checks and Putting our Results in Context

       We discuss numerous additional robustness checks and considerations to convince the

reader that our results are generally not due to errors or choices in our experimental design or

analysis. Our broader discussion and battery of checks highlighted below brings attention to the

limitations of our experiment, but also to the limitations of other studies. We emphasize that these

checks would be useful for others to do, regardless of the outcome of their studies. We also hope

that this broader discussion puts our results in the proper context, and makes clear what we learn,

and still do not know, about discrimination faced by Indigenous Peoples in the United States.

Estimates by Indigenous Signal Type

       To explore whether our results differed based on the four ways we signal Indigenous status

(volunteer experience, language, Native Hawaiian first name, and Navajo last name), we analyzed

callback rates by Indigenous signal type as follows:

 𝐶𝑎𝑙𝑙𝑏𝑎𝑐𝑘𝑖 = 𝛽0 + 𝛽1 𝑉𝑜𝑙𝑢𝑛𝑡𝑒𝑒𝑟 𝑂𝑛𝑙𝑦𝑖 + 𝛽2 𝐿𝑎𝑛𝑔𝑢𝑎𝑔𝑒 𝑂𝑛𝑙𝑦𝑖 + 𝛽3 𝐹𝑖𝑟𝑠𝑡 𝑁𝑎𝑚𝑒 𝑂𝑛𝑙𝑦𝑖
                                                                                                 [2]
                 + 𝛽4 𝐿𝑎𝑠𝑡 𝑁𝑎𝑚𝑒 𝑂𝑛𝑙𝑦𝑖 + 𝛽5 𝑇𝑤𝑜 𝑆𝑖𝑔𝑛𝑎𝑙𝑠𝑖 + 𝛽6 𝑇ℎ𝑟𝑒𝑒 𝑆𝑖𝑔𝑛𝑎𝑙𝑠𝑖

                 + 𝛽12 𝐵𝑜𝑦𝑠&𝐺𝑖𝑟𝑙𝑠𝑖 + 𝛽12 𝐹𝑜𝑜𝑑𝐵𝑎𝑛𝑘𝑖 + 𝛽12𝐺𝑎𝑒𝑙𝑖𝑐𝑖 + 𝐶𝑜𝑛𝑡𝑟𝑜𝑙𝑠𝑖 𝛽13 + 𝜀𝑖

where Volunteer Only is an indicator variable for being an Indigenous applicant with the volunteer

(Big Brothers & Big Sisters) signal only, Language Only is an indicator variable for being an

Indigenous applicant with the language signal only, First Name Only is an indicator variable for

being a Native Hawaiian applicant with the first name signal only, Last Name Only is an indicator

variable for being a Native American applicant of Navajo ancestry with a Navajo last name only,

Two (Three) Signals is an indicator variable for any combinations of two (three) signals, Boys &

Girls is an indicator variable for having the Boys & Girls Club control volunteer experience, Food




                                                31
Bank is an indicator variable for having the food bank control volunteer experience,56 and Gaelic

is an indicator variable for having the Irish Gaelic control language.57

         Table 10 presents the estimates by signal type, from Equation [2]. The results do not differ

by the signal. For Indigenous applicants who have the volunteer signal only, the callback rate is

0.6 percentage points lower, but this is statistically insignificant (standard error of 1.0). The

estimates on the controls for volunteer experiences are also statistically insignificant, which

suggests that regardless of which control volunteer experience is used (Boys & Girls Club, Food

Bank, Big Brothers Big Sisters without Indigenous signal), there is no difference in callback rates.

                  Table 10 – Discrimination Estimates by Indigenous Signal Type
                   Indigenous                                              Estimate         N
                   … x Volunteer Only                                         -0.006        3,029
                                                                             (0.010)
                   … x Language Only                                          0.006         1,723
                                                                             (0.010)
                   … x First Name (Native Hawaiian) Only                      -0.017          475
                                                                             (0.018)
                   … x Last Name (Navajo) Only                                -0.007          222
                                                                             (0.026)
                   … x Two Signals                                            0.003           823
                                                                             (0.015)
                   … x Three Signals                                          0.038           92
                                                                             (0.037)
                   Boys & Girls Club (Volunteer Control)                      -0.007        3,298
                                                                             (0.009)
                   Food Bank (Volunteer Control)                              -0.006        3,460
                                                                             (0.009)
                   Irish Gaelic (Language Control)                            -0.017          831
                                                                             (0.013)
Notes: N=13,516 for the entire sample, and N in the table is the number of resumes with that feature. See the notes to
Table 6. Different from zero at 1-percent level (***), 5-percent level (**) or 10-percent level (*). Regressions use the
“Regular Controls” from Table 6 (Column (2)). The excluded volunteer control is Big Brothers Big Sisters without
the racial signal.


56
   The excluded category is the Big Brothers & Big Sisters control volunteer experience, which is added randomly to
one of the resumes in pairs where the Indigenous applicant does not use the volunteer signal.
57
   We also replaced the single First Name and Last Name variables with indicator variables for each possible Native
Hawaiian first name (Maile, Kekoa, Ikaika, and Keoni) and each possible Navajo last name (Begay, Tsosie, Benally,
Yazzie). This was to see if the results differ by the randomly chosen name, which was not the case. These results are
available upon request.

                                                          32
       Results are similar for the language signal. For Indigenous applicants who have the

language signal only, the callback rate difference is also small (0.6 percentage points higher). The

control for the Indigenous language (Irish Gaelic) is statistically insignificant but is larger and

negative (a 1.7 percentage point lower callback rate).

       The estimates with two or three signals are positive but again statistically insignificant.

These estimates are imprecise, however, for three signals, given that most resumes had only one

or two signals. Thus, there is no evidence to support that having multiple signals decreases the

callback rate. The fact that there is no difference in callback rates by Indian reservation upbringing

is further evidence that our discrimination estimates do not vary by signal type or by saliency.

Saliency of Signals

       A key question in any correspondence study is whether the tested subjects detected and

correctly interpreted the signal(s) of minority status. Usually this is just assumed to be the case.

We are only aware of a few studies that carefully test for saliency and interpretation of signals

(Kroft, Notowidigdo, and Lange, 2013; Lahey and Oxley, 2018). If the signal is not detected, or is

only detected sometimes, then results are attenuated towards zero. If the signal is interpreted

differently than intended (e.g., a different minority is assumed, or the signal also conveys

socioeconomic status) then the results may not reflect what the experimenters expect to test (Fryer

and Levitt, 2004; Gaddis, 2017; Barlow and Lahey, 2018). We use four different signals in our

study (volunteer experience, language, Native Hawaiian first name, and Navajo last name).

Despite our results not differing by signal type, or when more than one signal is used (Table 10),

it still may be the case that each signal has different levels of saliency. To investigate this, we

fielded two surveys, both described in more detail in Online Appendix E (“resume survey”) and

Online Appendix F (“names survey”).



                                                 33
        First, we fielded the resume survey, a survey similar to Kroft, Notowidigdo, and Lange

(2013). Specifically, we asked individuals on Amazon Mechanical Turk to read one of the resumes

from our study and to consider the candidate for a job position in the relevant occupation. We then

asked the subjects to recall characteristics of the applicant (race or ethnicity, languages spoken,

age, education, employment status). We included surveys showing resumes without signals (white)

or with some combination of signals for either Native American or Native Hawaiian applicants.

We included respondents from both a national sample and separately an Arizona and New Mexico

only sample for the Navajo resumes given that relatively more Indigenous Peoples live in those

states.58

        More details and results from this resume survey are in Online Appendix E. To summarize,

the white resumes (no signals) are usually identified as white (86.8% of the time). However,

resumes with a Native American (Native Hawaiian) signal were detected as AIAN (NHPI) at rates

between 18.8% to 74.2% (26.4% to 82.0%).59 More specifically, the Navajo last name only signal

is very weak (18.8%) compared to the language signal only (32.4%) or the volunteer signal only

(37.2%), which are stronger, but still not strong. Saliency is significantly higher when using more

than one signal, ranging from 58.0% for Navajo last name and volunteer experience to 74.2% for

Navajo last name and Navajo language listed. Looking just at respondents in Arizona and New

Mexico, the probability that applicants were identified correctly as AIAN was significantly higher,

ranging from 58.3% (Navajo last name only) to 76.7% (Navajo last name and Navajo language

listed). Saliency for the Native Hawaiian resumes is 26.4% for first name only, 82.0% for language


58
   The additional surveys in Arizona and New Mexico were for two reasons. First, oversampling those two states
more closely aligns our survey sample with our experiment sample. Second, we can explore how saliency differs
when exposure to Indigenous Peoples is higher.
59
   For Native American resumes, conditional on not guessing AIAN, the most common guess was white.
Interestingly, a non-trivial proportion of respondents (12.9% to 15.8%) indicated that they thought the Native
American individual was instead NHPI when signal(s) other than Navajo last name were used (columns (4), (5), and
(8)). In these cases, they identified the applicant as Indigenous but of the wrong racial or tribal group.

                                                      34
only, and 75.0% for volunteer and language. We would expect these saliency rates to be even

higher in a Hawaii-only sample relative to this national sample.

         For comparison, and following Kroft, Notowidigdo, and Lange (2013), we also measured

the saliency of other aspects of the resume that are often used to signal minority status or other

essential resumes features. We measured the saliency of gender, age, highest completed education,

employment status (employed vs. unemployed), duration of the last job held, and whether a second

language was listed. Across all tested resumes, survey respondents correctly identified gender

71.4% of the time,60 highest completed education 86.4% of the time, employment status 68.3% of

the time, and correctly recalled whether there was a second language on the resume 75.3% of the

time. As for age (duration of the last job held), the mean of identified minus actual was -1.60 years

(-0.90 years), with a standard deviation of 4.69 years (3.15 years). These results suggest that other

signals range from having only moderate strength (e.g., employment status) to being reasonably

strong, but were not always detected (e.g., highest completed education).

         We learn two things from all these results of the resume survey. First, our signal

combinations are occasionally detected more often than other resume features, where saliency may

be assumed to be obvious (e.g., employment status, 68.3% saliency). This suggests that one should

never assume that signals will always be detected. Researchers should generally test for the

saliency of their signals and discuss how this effects their results. Second, our signals on average

are less salient than other resume features so our results could be attenuated.

         This attenuation concern prompted us to explore further how our results vary by signal

type, going beyond our analysis by signal type in Table 10. Since the saliency of the Navajo last

name signal only was low, mostly outside Arizona and New Mexico, we conducted three


60
  We calculate this using a sample of the first names that strongly signal gender (i.e., no ambiguous names like Pat,
Casey, or Taylor) and generally signal that the individual is white.

                                                         35
additional robustness checks where we: (1) recoded those with Navajo last names as the only signal

as “white”; (2) controlled for resumes with the Navajo last name only with a separate indicator

variable; and (3) re-estimated Equation [2] (like in Table 10) but recoded the signals as if the

Navajo last name signal did not exist. As shown in Online Appendix Tables D3 and D4 these tests

again do not change our results.

       Despite this Navajo last name signal being particularly weak, more-so outside of Arizona

and New Mexico, we learn from this survey and our experimental results that individuals with

these names are only sometimes going to be perceived as Indigenous and do not face hiring

discrimination at the callback stage just based on their name. This is not the case for the vast

majority of other minorities as the numerous studies using other minority names find

discrimination (Neumark 2018; Baert 2018).

       We also learn from this that it is essential to test the names used to ensure that they signal

what is intended. Here we echo concerns in recent work that carefully explores how names signal

race, ethnicity, and socioeconomic status finding that individual names may not signal what

researchers assume and specific names can drive results in unexpected ways (Barlow and Lahey

2018; Gaddis 2017b, 2017a). We tested the names we used in the resume survey, discussed earlier.

We also fielded a second survey on Amazon Mechanical Turk specifically on our Navajo last

names, similar to how Gaddis (2017a, 2017b) tests names. We simply showed those surveyed a

name (e.g., Daniel Begay, Emily Adams) and asked them to indicate to which race they thought

that individual belonged.

       We present more details and full results from both surveys in Online Appendix E (resume

survey) and Online Appendix F (names survey). For example, in the names survey, out of the

Navajo last names, saliency was highest for Tsosie (47.1% nationally thought this person was



                                                36
AIAN and 70.0% in Arizona and New Mexico only), followed by Yazzie (12.5%, 28.6%), Begay

(10.0%, 35%), and Benally (5.7%, 15%).61              62
                                                           We also learn from both surveys that individuals

perceive Indigenous Peoples to be more likely to have been born outside the United States – an

odd result, but one seen in other research including using the Native Implicit Association Test

(Native IAT).63

Statistical Power

         A possible reason generally for a lack of statistically significant results is low power, but

this is not a problem we face for our main results. As discussed earlier, we have significantly more

observations than our power analysis required, and we have the seventh largest sample size relative

to the other 113 resume-correspondence studies of hiring discrimination summarized in Baert

(2018) and Neumark (2018).64 Our standard errors, in many cases, are also precise enough to rule

out large amounts of discrimination in our main results, suggesting that even if there is differential

treatment, it is uncommon.65 Of course, our results are not precise enough to rule out discrimination



61
   The saliency of the names in the names survey is higher than in the resume survey, likely because the resume
survey showed resumes instead of just names, so recall was lower. Imperfect recall may also explain why
individuals do not always remember less controversial signals like employment status.
62
   For Native Hawaiian first names in the resume survey, using a national sample, the most salient name was Keoni
(58% NHPI) followed by Ikaika (24%), Kekoa (14%), and Maile (10%), suggesting that most names were not
salient to Americans in general. Due to issues with Amazon Mechanical Turk, we were unable to conduct this
survey using a sample of Hawaii residents only. We would expect saliency of these names to be significantly higher
in Hawaii, and, that they would be higher for the names survey (see footnote above).
63
   See
https://implicit.harvard.edu/implicit/Launch?study=/user/demo.us/demo.nativeamer.0002/nativeamdemo.expt.xml
(accessed July 1, 2018). In the names survey, those with white names are seen as having been born in the United
States 92.1% of the time in the national sample (96.0% of the time in the Arizona and New Mexico sample), relative
to 64.8% for those with Navajo last names (72.3% in the Arizona and New Mexico sample.).
64
   The studies with more job applications than us are: Neumark, Burn, and Button, (2019); Agan and Starr (2018);
López Bóo, Rossi, and Urzúa (2013); Maurer-Fazio (2012); Maurer-Fazio and Lei (2015); and Zhou, Zhang, and
Song (2013). Our records of the sample sizes (applications sent, unique jobs) for each study are available upon
request.
65
   For example, in Table 6, our preferred estimate (column (2)) for Native American is a 0.4 percentage point
decrease in the callback rate, with a standard error of 0.9 percentage points. The 95% confidence interval is -2.2 to
1.4 percentage points. So even this upper bound of discrimination, a 2.2 percentage point lower callback rate, is not
particularly large relative to the baseline callback rate for white applicants (19.8%) and importantly is not
statistically significant.

                                                           37
in every circumstance. For example, we cannot rule out discrimination in small cities or town, such

as Billings and Sioux Falls, and other comparisons that involves small cells (e.g., Navajo last name

signal) are underpowered.

The “Heckman-Siegelman Critique” and the Neumark (2012) Correction

         Audit and correspondence studies, especially resume-correspondence studies like ours,

could face the “Heckman-Siegelman critique” (Heckman, 1998; Heckman and Siegelman, 1993).

This critique holds that while these studies control for average differences in observable

characteristics (information included in the job application), discrimination estimates can still be

biased, in either direction, through differences in the variance of unobservable characteristics.

Neumark (2012) shows how this can occur using a model of hiring decisions, and Neumark and

Rich (2016) show that about half of the resume-correspondence studies they evaluated were biased

because of this issue. We discuss this issue in more detail, including with a formal model, and test

for this bias in Online Appendix C.

         To summarize, we correct for this possible bias by randomly adding quality features66 to

the applications. As discussed in Neumark (2012) and Online Appendix C, these quality features

shift the probability of a callback, allowing us to identify to what extent differences in the variance

of unobservables between white and Indigenous applicants lead to bias in our original estimates.

We find no evidence of bias in our main results due to the variance of unobservables issue. The

estimated variances of unobservables are nearly equal for white and Indigenous applicants for the




66
  Half of the application pairs are made to be “higher quality”, and these higher-quality applications get four out of
the five possible quality features: Spanish as a second language, a more detailed cover letter that summarizes
employment experiences, a lack of typos in the cover letter, and two occupational-specific skills. See Online
Appendix C for additional details.

                                                          38
combined analysis (all occupations) and each occupation separately.67 Thus, our lack of estimated

discrimination is robust to this critique.

Do Callbacks Capture Hiring Discrimination?

         Since resume-correspondence studies quantify hiring discrimination by comparing

callbacks, there is the recurring question of whether callbacks truly measure hiring discrimination.

Many others discuss this issue (e.g., Neumark, Burn, and Button, 2019; Booth, Leigh, and

Varganova 2012). There are many reasons to believe that callbacks capture a significant share of

hiring discrimination. At the interview offer stage, is it far less likely that discrimination can be

detected or enforced, relative to later when company personnel systems may have more detailed

records of applicants (Neumark, Burn, and Button, 2019). At the callback stage, employers are

also more likely to make quick decisions and fall victim to implicit bias (Bertrand et al. 2005;

Rooth 2010). Audit studies that have actors and actresses go to interviews, and thus can observe

job offers too, show that 75% to 90% of discrimination occurs at the callback stage (Bendick,

Brown, and Wall 1999).68

         On the other hand, the share of discrimination that occurs after the callback phase (at or

after the interview) could vary by the minority group and by the saliency of the minority status on

the resume. Where minority status is more salient (e.g., gender, commonly-understood race or

ethnicity-specific names), then discrimination at this stage is more possible. In sum, we argue that

we are capturing a stage where a significant proportion of hiring discrimination (if it exists) usually




67
   Our most significant difference in the variance of unobservables occurs for kitchen jobs, suggesting that whites
have a slightly higher variance of unobservables. This suggests a negative bias in the estimate, rather than a positive
bias. However, there is no statistically significant difference between these variables and applying the Neumark
(2012) correction does not change the results in all our cases.
68
   See discussion of International Labor Organization (ILO) studies of ethnic discrimination in Riach and Rich
(2002).

                                                          39
occurs, but, like other studies, we cannot claim to capture all of hiring discrimination. Future work

on discrimination beyond the callback stage would be useful.69

Population and Occupation Weighting

         We attempted to apply for all eligible job openings that met our criteria in each city and

occupation. Since our main estimates are unweighted, this means we oversampled populous cities.

What would generate more population-representative results for Indigenous Peoples would be to

weight the estimates by city so that they reflect the population distribution of Indigenous Peoples

across these cities.70 Similarly, we can weight by the frequency of occupations according to the

CPS data in case our sample of jobs by occupation differs significantly from the national data. We

can also weight by both. In Online Appendix D, we discuss how we construct these weights, and

we present our main results, from Table 6, under different types of weighting (Indigenous

population in the city, occupational popularity, and both) (see Online Appendix Table D9). Our

results are unaffected by how we weight the data.

Choice of Occupations and Type of Jobs

         We chose common occupations for those around age 30. These positions do skew more

low-skilled or lower-experience relative to some other possible occupations, although this is a

broader concern facing resume-correspondence studies in general (Neumark 2018; Baert 2018).

Were our chosen occupations ones that do not have discrimination? Numerous studies also used

retail sales, server, and kitchen staff positions and found discrimination. Neumark, Burn, and

Button (2016, 2019) also apply for janitor and security jobs and find some evidence of




69
   For example, a referee shared with us that there is anecdotal evidence that some Native Americans have
experienced discrimination at the interview stage depending on their skin color or how “white” they appear.
70
   We are only aware of one other paper, Neumark et al. (2018), who also discuss the issue of weighting in audit
studies.

                                                         40
discrimination, although these results are not robust to other considerations.71 Therefore, we are

not convinced, given this prior work using our same occupations, that our selected occupations

just happened to be ones where discrimination does not occur in general.

         Would discrimination be more common or less common in our chosen occupations relative

to alternatives? For a few reasons, we argue that discrimination is more likely in our occupations

and jobs relative to others. Research suggests that there is more discrimination in low-skilled

positions (Helleseter, Kuhn, and Shen 2014; Kuhn and Shen 2013). Similarly, smaller firms, which

are more likely to use the job board we used,72 are less likely to have Human Resources

departments and are less likely to be covered by Title VII of the Civil Rights Act, which applies

to firms with at least 15 employees.

         On the other hand, Sociology research suggests that individuals sometimes “type” jobs as

being more suitable for individuals of certain races or genders (Kaufman 2002). While we found

no research on this typing for Indigenous Peoples, we do not think that Indigenous Peoples are

typed into retail sales or server positions. In these occupations, there is a significant amount of

customer interaction such that customer discrimination may cause a preference for whites. Typing,

however, may be relevant for kitchen staff, janitor, and security jobs. For kitchen staff, there is the

potential notion that people of color are more likely to be “back of the house” (kitchen) than “front

of the house” (servers, hosts, bartenders) staff, and this manifests in the CPS data.73 However,

discrimination does not appear to vary by occupation (Tables 7 and 8), suggesting that this concern



71
   Some studies other than Neumark, Burn, and Button (2016, 2019) also used janitor and security positions, but
these jobs were generally included in a larger pool of jobs that were analyzed, so it is hard to determine what the
estimates were for these occupations specifically.
72
   Larger companies are more likely to have their own applications processes that do not allow them to be included
in most resume-correspondence studies such as ours, even if they post on common job boards.
73
   Using the data from Tables 2 and 3, the ratio of waiters and waitresses to cooks for white men (women) is 0.57
(2.65). These ratios are much lower for AIAN men (0.15), AIAN women (0.72), NHPI men (0.03), and NHPI
women (0.26).

                                                         41
did not affect our results. A related issue is that typing could vary by city based on the size of the

Hispanic population, as certain jobs may be typed as more or less “Hispanic”.74 In Online

Appendix Table D10 we show estimates of the relative size of the Hispanic population in each

occupation-city-gender combination. We used this information to re-estimate our main results

(Table 6, Column (2)) excluding occupation-city-gender combinations where Hispanics

outnumber whites. Our results are unchanged.75

Timing of the Study and Labor Market Tightness

         Discrimination could occur more often when economic conditions are worse (Neumark

and Button 2014; Johnston and Lordan 2016; Baert et al. 2015; Kroft, Notowidigdo, and Lange

2013). Therefore, resume-correspondence studies could generate larger (smaller) discrimination

estimates during a downturn (a boom) in labor markets. We compare the timing of our study to all

other resume-correspondence or employment audit studies conducted in the United States that

were listed in the summary tables in either Baert (2018) or Neumark (2018)’s reviews of the

literature. Online Appendix Table D11 presents the timing of data collection in each study and the

national, seasonally-adjusted unemployment rates during that time.

         This table shows that our study was during a time with lower unemployment rates (16th to

24th percentile of the seasonally-adjusted rate from 1948 to 2018).76 This percentile range of our

unemployment rates overlaps with the ranges of Pager (2003) (23rd to 56th percentile) and

Kleykamp (2009) (21st to 35th), both which find statistically significant effects, although their



74
   We thank Randall Akee, and others, for raising this helpful point.
75
   These results are available upon request.
76
   We collected data from March 2017 to December 2017, where the seasonally-adjusted national unemployment
rate ranged from 4.1 to 4.4 percent. Compared to the national, seasonally-adjusted, unemployment rate estimates
from all months from January 1948 to October 2018, our unemployment rates fall into the 16th to the 24th percentile
(the median unemployment rate is 5.6, the 10th percentile is 3.8, and the 90th percentile is 7.9). We calculated this
using Bureau of Labor Statistics data from series LNS14000000 (accessed November 23, 2018, from
https://data.bls.gov/timeseries/lns14000000). Our data and calculations are available upon request.

                                                         42
signals of minority status may have been stronger (e.g., criminal records). The unemployment rates

during our study were not as extreme as over a third of the other studies which occurred during the

Great Recession, where unemployment rates reached record highs.77

         While better economic conditions at the time of our study could have made our

discrimination estimates smaller, it is not yet clear from the literature to what extent economic

cycles affect discrimination in callbacks. We do argue that more work needs to be done to

determine how economic cycles affect discrimination, especially considering many studies being

case studies of the Great Recession, which may not reflect normal economic times.

Oaxaca-Blinder Decomposition of Earnings and Unemployment Gaps

         Our field experiment shows no evidence of discrimination, suggesting that the significant

disparities in economic outcomes between Indigenous Peoples and whites are more likely due to

factors other than discrimination. To explore this further, we also conduct an Oaxaca-Blinder

decomposition (Oaxaca and Ransom 1994), similar to Hurst (1997) and Feir (2013), using monthly

IPUMS-CPS data from 2010 to 2017 (Flood et al., 2015). We used the “oaxaca” Stata command

outlined in Sinning, Hahn, and Bauer (2008) to decompose gaps in earnings into an explained

portion, explained by observable factors such as education, occupation, and geography, and into

an unexplained (residual) portion, which could reflect unemployment discrimination. We expand

on prior wage decomposition studies (e.g., (Hurst 1997; Feir 2013; Baldwin and Choe 2014; Kruse

et al. 2018; Krishna and Ravi 2011; Kuhn and Sweetman 2002) by also decomposing gaps in




77
  Of the 21 studies, eight have a percentile range that includes at least the 90th percentile of unemployment rates, if
not higher (Jacquemet and Yannelis 2012; Bailey, Wallace, and Wright 2013; Wright et al. 2013; Decker et al. 2015;
Nunley et al. 2015; Gaddis 2015; Hipes et al. 2016; Farber, Silverman, and von Wachter 2017). We argue that many
of these studies are just case studies of the Great Recession and may not tell us about discrimination in general.

                                                          43
unemployment rates and unemployment durations, given that these are more directly related to the

callback discrimination we estimate in our field experiment.78

         Our Oaxaca-Blinder decomposition is a useful complement to our experiment as it allows

us to see whether discrimination might occur outside the context of our field experiment. It also

allows us to determine which factors explain the disparities in economic outcomes that we see in

the raw data, with the caveat that the Oaxaca-Blinder decomposition is not the preferred way to

measure discrimination since it cannot control for all factors other than race, unlike an experiment.

         We discuss the methodology for our Oaxaca-Blinder decomposition in-depth and present

more detailed results in Online Appendix G, with results summarized in Tables 11 (AIAN) and 12

(NHPI). To summarize, we find that for those who identify as AIAN alone compared to non-

Hispanic white alone,79 most of the raw gap in hourly wages (a 15.6% gap) is explained by lower

educational levels and lower-paying occupations, leading to a small unexplained gap (1.2%).80 For

NHPIs, the raw gap in hourly wages is smaller (9.1%) and is explained by education and

occupations but is offset by differences in the state of residence, whereby Native Hawaiians are

more likely to live in Hawaii, where earnings are higher. In net, there is a slightly larger

unexplained gap (4.2%). This suggests the potential for minimal amounts of wage discrimination

against AIANs and the potential for some wage discrimination against NHPIs.



78
   Discrimination in hiring directly leads to a lower arrival rate of job offers, with lower arrival rates being
mechanically linked in job search theory models to both higher unemployment rates and longer unemployment rates,
so long as reservation wages do not adjust completely to offset these effects, which is unlikely (Cahuc, Carcillo, and
Zylberberg 2014). Exploring gaps in earnings, however, measures wage discrimination rather than hiring
discrimination when occupation fixed effects are included. When these are not included, then the discrimination
estimates (“unexplained”) from an Oaxaca-Blinder decomposition do capture some hiring discrimination if hiring
discrimination manifests as different eventual occupations, but then this analysis cannot control for occupational
choices, outside of discrimination, that create differences.
79
   Results are similar using AIAN alone or in combination, and results using NHPI alone or in combination are also
similar to the results for NHPI alone (see Online Appendix Tables G2, G3, and G4).
80
   For comparison, prior studies have found the unexplained gap in log earnings to be 13% for single-ancestry
Native Americans and 26.5% for single-ancestry Alaska Natives (Hurst, 1997), and among Aboriginal Peoples in
Canada, the unexplained gaps was 11 to 16% in 2005(Feir, 2013).

                                                         44
          Table 11 – Oaxaca-Blinder Decomposition Estimates (AIANs vs. Whites)
                                                 Unemployment     Unemployment
                             Log Hourly Wage
                                                      Rates      Duration in Weeks
      Total Difference       -0.145*** (0.006) 0.045*** (0.001)  -1.705*** (0.502)
      Explained              -0.133*** (0.006) 0.003*** (0.000)  -3.313*** (0.263)
                Occupation -0.072*** (0.005)   0.013*** (0.000)  0.495*** (0.156)
                  Education -0.053*** (0.002)   0.007*** (0.000) 1.330*** (0.081)
                       State 0.017*** (0.001)  0.001*** (0.000)  -1.086*** (0.081)
                   Hispanic -0.014*** (0.001) -0.019*** (0.000) -2.466*** (0.120)
                        Age -0.010*** (0.001) -0.000*** (0.000) -2.744*** (0.173)
                    Married -0.006*** (0.000)  0.003*** (0.000)  0.503*** (0.080)
                    Gender 0.005*** (0.001)     -0.000** (0.000)  0.088** (0.041)
               Metro Status -0.003*** (0.000)  0.000*** (0.000)  -0.074*** (0.025)
                 Experience   0.003** (0.001)  -0.001*** (0.000) 1.226*** (0.114)
             Survey Timing    0.001** (0.001)  -0.000*** (0.000) -0.304*** (0.100)
                   Children -0.000** (0.000)   0.000*** (0.000)  -0.282*** (0.035)
      Unexplained            -0.012*** (0.003) 0.043*** (0.000)  1.609*** (0.410)
                White Mean         $19.13             0.037            30.11
               Observations       239,981           2,186,764           81,543
Notes: Data from IPUMS-CPS monthly data from 2010-2017 (Flood et al., 2005). Statistically significantly different
from at 1-percent level (***), 5-percent level (**) or 10-percent level (*). Robust standard errors are in parentheses.
AIANs include only those who identify as AIAN alone. Results including AIAN in combination are similar and are
presented in Online Appendix Tables G2, G3, and G4. Hourly wage is determined as either the hourly wage for
those paid hourly and not top-coded, or the hourly wage is estimated by dividing weekly earnings by the usual hours
worked. Estimates are weighted using population weights.

            Table 12 – Oaxaca-Blinder Decomposition Estimates (NHPIs vs. Whites)
                                                 Unemployment
                                                                    Unemployment
                             Log Hourly Wage          Rates
                                                                  Duration in Weeks
      Total Difference               -0.087*** (0.012)          0.017*** (0.001)            -2.876** (1.383)
      Explained                      -0.046*** (0.011)          0.010*** (0.001)              0.010 (0.646)
                Occupation           -0.053*** (0.007)          0.009*** (0.001)              0.068 (0.308)
                   Hispanic           -0.010* (0.006)           -0.005*** (0.000)            0.731* (0.396)
                  Education          -0.026*** (0.003)          0.004*** (0.000)           0.858*** (0.165)
                    Married          -0.002*** (0.001)          0.002*** (0.000)           -0.434*** (0.151)
                       State         0.049*** (0.003)           0.002*** (0.000)            0.694*** (0.138)
                 Experience            0.000 (0.003)            -0.001*** (0.000)           1.647*** (0.228)
               Metro Status          0.008*** (0.001)           -0.000*** (0.000)          0.260*** (0.035)
                        Age          -0.018*** (0.004)          0.000*** (0.000)           -3.461*** (0.344)
                   Children            -0.000 (0.000)           0.000*** (0.000)           -0.295*** (0.058)
             Survey Timing           0.003*** (0.001)             -0.000 (0.000)              0.151 (0.215)
                    Gender           0.005*** (0.002)             -0.000 (0.000)            -0.209** (0.082)
      Unexplained                    -0.041*** (0.012)          0.007*** (0.001)            -2.887** (1.219)
                White Mean                 $19.13                     0.037                       30.11
               Observations               237,105                   2,167,445                     79,036
Notes: See notes to Table 11. Statistically significantly different from at 1-percent level (***), 5-percent level (**)
or 10-percent level (*). NHPIs include those who identify as NHPI alone. Results including NHPI in combination
are similar and are presented in Online Appendix Tables G2, G3, and G4.



                                                           45
         For unemployment rates, the raw gap of a 4.5 percentage point higher unemployment rate

for AIAN alone is almost entirely unexplained (4.3 percentage points unexplained). For NHPI, the

raw gap is smaller (1.7 percentage points) but is partially explained (0.7 percentage points left

unexplained). However, for unemployment durations, the evidence differs for AIAN and NHPI

individuals. Both AIAN and NHPI individuals have negative raw gaps, suggesting shorter

unemployment durations (1.7 weeks shorter for AIAN alone, 2.9 weeks shorter for NHPI alone).

After the decomposition, there is a positive unexplained portion for AIAN: unemployment

durations that are 1.6 weeks longer for AIANs.81 In contrast, the duration for NHPI is entirely

unchanged and unexplained in the decomposition. These unemployment results for AIANs point

consistently towards potential hiring discrimination while the results for NHPI are unclear.

        There are two possible explanations for why our Oaxaca-Blinder results, namely for

AIANs and for unemployment rates and duration, differ from the results of our field experiment.

First, there is the standard criticism that unexplained gaps in Oaxaca-Blinder decompositions are

not necessarily evidence of discrimination, but instead show an upper-bound to discrimination

(hence potential discrimination). This is because it is not possible to use survey data to control for

all differences to make Indigenous and non-Indigenous Peoples identical in all aspects other than

race, as can be done in the field experiment (Neumark 2018; Bertrand and Duflo 2017). Thus,

uncontrolled differences other than discrimination could explain these unexplained gaps. The most

relevant uncontrolled difference would be differences in reservation wages.

        Conversely, it is possible that hiring discrimination does exist and is picked up by this

decomposition, but it is missed entirely by the field experiment. As discussed, our field experiment


81
  This flip from a raw gap in favor of AIANs to an unexplained disparity occurs primarily from controlling for
differences in age and Hispanic ancestry.

                                                        46
is only a case study: discrimination among common occupations (retail sales, server, kitchen staff,

janitor, and security) in 11 cities for applicants who have only a high school education and are of

about age 30. While we argue that discrimination is more likely to occur in low-skilled occupations

and for the small employers that are more likely to be included in our sample, we cannot entirely

rule out that there could be discrimination in other occupations or contexts.

         To better understand whether the results from our Oaxaca-Blinder decompositions reflect

potential discrimination outside of our case study, we re-ran our decompositions where we

restricted the sample to include only observations that better aligned with our experiment.82 Our

results, available upon request, are relatively unchanged in these restricted samples, suggesting

that contexts outside our field experiment are not driving the potential discrimination we see in the

Oaxaca-Blinder decompositions. We see it is far more likely that the unexplained higher

unemployment rates (and durations for AIAN) reflect uncontrolled factors rather than hiring

discrimination existing in general and missed by our experiment. However, a more thorough

analysis, similar to Hurst (1997), Feir (2013), Kuhn and Sweetman (2002), or Krishna and Ravi

(2011), would be helpful but is beyond the scope of this paper.



                                                   Conclusion

         Our results from a large-scale field experiment of hiring discrimination where we sent

13,516 job applications of on-average identical applicants who were either Indigenous or white to

jobs as retail salespersons, servers, kitchen staff, janitors, or security guards show a lack of

discrimination at the callback stage, in net, against Indigenous Peoples. We also do not find bias




82
  Specifically, we restricted our sample to individuals in our age range who are high school graduates in the
occupations and states that we tested.

                                                         47
against Native American applicants from Indian reservations. We do not find discrimination even

when we estimate separately by city, occupation, or occupation and gender.

        Our results are robust in several ways, including to the inclusion or exclusion of controls,

to how we signal Indigenous status (volunteer, language, name), to the Neumark (2012) correction

for potential bias from the variance of unobservables, to how the regressions are weighted, to how

callbacks are coded, and to how we cluster our standard errors. We discuss how our results could

be affected by several factors, such as better economic conditions at the time of the experiment

(but this is rather uncertain), the ways in which we signal Indigenous status, the saliency of our

signals of Indigenous status, or a lack of statistical power in a few circumstances. We also argue

that our choice of occupations and the type of jobs or employers we tested was unlikely to have

generated our result of no discrimination, but we again emphasize that we cannot rule out

discrimination in all occupations or all contexts.

        We learn quite a bit about audit study methodology from this paper. First, it is unclear to

what extent macroeconomic cycles affect discrimination, and thus future work on this topic would

help us both understand the mechanisms of discrimination and help us interpret the results of

previous work and this paper. Second, we learn from this paper and other recent work (Gaddis

2017a, 2017b; Barlow and Lahey 2018) that it is crucial to test for how salient the signal of

minority status is, and to test for how the signal is perceived. Audit studies may not be capturing

what the researchers think it is. Third, we propose several additional robustness checks that should

be considered, such as weighting. While our lack of results prompted us to dig further into if our

results were a true “zero”, we believe these robustness checks are important to conduct regardless

of the result.




                                                 48
        Our results suggest that the significant economic disparities faced by Indigenous Peoples

have little to do with discrimination and more to do with other factors, such as differences in

education. Directly addressing these inequalities could help alleviate these inequalities. Since we

find little evidence of discrimination, it is less likely that supply-side investments in Indigenous

peoples or communities (e.g., education and job training) will have their impacts frustrated by

discriminatory employers. Determining which policies best help narrow economic disparities

would be fruitful, especially given the shortage of economics research on Indigenous Peoples (Feir

and Hancock 2016).

         This study is one of the first, and few, to explore the extent to which Indigenous Peoples

face discrimination. Future work can explore this in many ways. First, our case studies cannot rule

out discrimination in all occupations or all cities, so future researchers could continue to investigate

whether discrimination occurs in other circumstances that we were not able to study. Second,

discrimination can occur more broadly, as shown in experimental audit studies of discrimination

in health care (e.g. Sharma, Mitra, and Stano 2015), in housing (e.g., Hanson and Hawley 2011;

Hanson et al. 2016), in access to local government services (e.g., Giulietti, Tonin, and

Vlassopoulos 2017), and in political representation (e.g., Butler and Broockman 2011). While

there are a few non-experimental studies that uncover disparities or suggest discrimination against

Indigenous Peoples in these other contexts such as in policing (Gorsuch and Rho, forthcoming),

access to credit (Jorgensen and Akee 2017), in housing and institutionalization (Feir and Akee

2018), and in business and economic development (Akee and Jorgensen 2014), more research is

needed to fully understand to what extent Indigenous Peoples face discrimination more broadly.




                                                  49
                                        References

Adams, David Wallace. 1995. Education for Extinction: American Indians and the Boarding
     School Experience, 1875-1928. Lawrence, KS: University Press of Kansas.
Agan, Amanda, and Sonja Starr. 2018. “Ban the Box, Criminal Records, and Statistical
     Discrimination: A Field Experiment.” The Quarterly Journal of Economics 131 (1): 191–
     235. https://doi.org/10.1093/qje/qjx028.Advance.
Ai, Chunrong, and Edward C Norton. 2003. “Interaction Terms in Logit and Probit Models.”
     Economics Letters 80 (1): 123–29. https://doi.org/10.1016/S0165-1765(03)00032-6.
Akee, Randall K. Q., and Miriam Jorgensen. 2014. “Property Institutions and Business
     Investment on American Indian Reservations.” Regional Science and Urban Economics 46
     (1): 116–25. https://doi.org/10.1016/j.regsciurbeco.2014.04.001.
Akee, Randall K. Q., and Jonathan B Taylor. 2014. Social and Economic Change on American
     Indian Reservations A Databook of the US Censuses and the American Community Survey
     Social and Economic Change on American Indian Reservations A Databook of the US
     Censuses and the American Community Survey.
Ameri, Mason, Lisa Schur, Meera Adya, F. Scott Bentley, Patrick McKay, and Douglas Kruse.
     2018. “The Disability Employment Puzzle: A Field Experiment on Employer Hiring
     Behavior.” ILR Review 71 (2): 329–64. https://doi.org/10.1177/0019793917717474.
Austin, Algernon. 2013. “Native Americans and Jobs: The Challenge and the Promise.”
     Washington, DC: Economic Policy Institute Briefing Paper #370.
Baert, Stijn. 2018. “Hiring Discrimination: An Overview of (Almost) All Correspondence
     Experiments Since 2005.” In Audit Studies: Behind the Scenes with Theory, Method, and
     Nuance, edited by S. Michael Gaddis, 63–77. New York: Springer.
Baert, Stijn, Bart Cockx, Niels Gheyle, and Cora Vandamme. 2015. “Is There Less
     Discrimination in Occupations Where Recruitment Is Difficult?” ILR Review 68 (3): 467–
     500. https://doi.org/10.1177/0019793915570873.
Bailey, John, Michael Wallace, and Bradley Wright. 2013. “Are Gay Men and Lesbians
     Discriminated Against When Applying for Jobs? A Four-City, Internet-Based Field
     Experiment.” Journal of Homosexuality 60 (6): 873–94.
     https://doi.org/10.1080/00918369.2013.774860.
Baldwin, Marjorie L., and Chung Choe. 2014. “Wage Discrimination Against Workers with
     Sensory Disabilities.” Industrial Relations 53 (1): 101–24.
     https://doi.org/10.1111/irel.12048.
Barlow, Rose M., and Joanna N. Lahey. 2018. “Is Lacey Black?: Intersecting Perceptions of
     Racial Minority Status and Social Class.” Social Science Quarterly 99 (5): 1680–98.
     https://doi.org/https://doi.org/10.1111/ssqu.12529.
Behaghel, Luc, Bruno Crépon, and Thomas Le Barbanchon. 2015. “Unintended Effects of
     Anonymous Résumés.” American Economic Journal: Applied Economics 7 (3): 1–27.
     https://doi.org/10.1257/app.20140185.
Bendick, Marc, L E Brown, and K Wall. 1999. “No Foot in the Door: An Experimental Study of
     Employment Discrimination against Older Workers.” Journal of Aging & Social Policy 10:
     5–23. https://doi.org/10.1300/J031v10n04_02.
Bertrand, Marianne, and Esther Duflo. 2017. “Field Experiments on Discrimination.” In
     Handbook of Economic Field Experiments, edited by Abhijit Vinayak Banerjee and Esther
     Duflo, 309–93. Elsevier. https://doi.org/10.1017/CBO9781107415324.004.


                                            50
Bertrand, Marianne, and Sendhil Mullainathan. 2004. “Are Emily and Greg More Employable
      Than Lakisha and Jamal? A Field Experiment on Labor Market Discrimination.” American
      Economic Review 94 (4): 991–1013. https://doi.org/10.1257/0002828042002561.
Bertrand, Marianne, Sendhil Mullainathan, Dolly Chugh, and Sendhil Mullainathan. 2005.
      “Implicit Discrimination.” American Economic Review 95 (2): 94–98.
Booth, Alison L., Andrew Leigh, and Elena Varganova. 2012. “Does Ethnic Discrimination Vary
      Across Minority Groups? Evidence from a Field Experiment.” Oxford Bulletin of
      Economics and Statistics 74 (4): 547–73. https://doi.org/10.1111/j.1468-0084.2011.00664.x.
Brown, Dee. 2007. Bury My Heart at Wounded Knee: An Indian History of the American West.
      New York: Macmillan.
Butler, Daniel M., and David E. Broockman. 2011. “Do Politicians Racially Discriminate
      Against Constituents? A Field Experiment on State Legislators.” American Journal of
      Political Science 55 (3): 463–77.
Cahuc, Pierre, Stephane L. Carcillo, and André Zylberberg. 2014. Labor Economics. Second Edi.
      Vol. 43. Cambridge, MA: MIT Press.
Cameron, A. Colin, Jonah B. Gelbach, and Douglas L. Miller. 2011. “Robust Inference With
      Multiway Clustering.” Journal of Business & Economic Statistics 29 (2): 238–49.
      https://doi.org/10.1198/jbes.2010.07136.
Collett, Tess, Gordon E. Limb, and Kevin Shafer. 2016. “Effects of Native American
      Geographical Location and Marital Status on Poverty.” Journal of Sociology and Social
      Welfare 43 (1): 37–54.
Decker, Scott H., Natalie Ortiz, Cassia Spohn, and Eric Hedberg. 2015. “Criminal Stigma, Race,
      and Ethnicity: The Consequences of Imprisonment for Employment.” Journal of Criminal
      Justice 43 (2): 108–21. https://doi.org/10.1016/j.jcrimjus.2015.02.002.
DeVoe, Jill Fleury, Kristen E. Darling-Churchill, and Thomas D. Snyder. 2008. “Status and
      Trends in the Education of American Indians and Alaska Natives: 2008.” Washington, DC:
      U.S. Department of Education Report NCES 2008-084.
      http://nces.ed.gov/pubsearch/pubsinfo.asp?pubid=2008084.
Farber, Henry S, Dan Silverman, and Till M Von Wachter. 2017. “Factors Determining
      Callbacks to Job Applications by the Unemployed: An Audit Study.” RSF: The Russell
      Sage Foundation Journal of the Social Sciences 3 (3): 168–201.
      https://doi.org/10.7758/RSF.2017.3.3.08.
Feir, Donna. 2013. “Size, Structure, and Change: Exploring the Sources of Aboriginal Earnings
      Gaps in 1995 and 2005.” Canadian Public Policy 39 (2): 309–34.
      https://doi.org/10.3138/CPP.39.2.309.
———. 2016a. “The Intergenerational Effect of Forcible Assimilation Policy on School
      Performance.” International Indigenous Policy Journal 7 (3): 1–44.
———. 2016b. “The Long Term Effects of Forcible Assimilation Policy: The Case of Indian
      Boarding Schools.” Canadian Journal of Economics 49 (2): 433–80.
Feir, Donna, and Randall K. Q. Akee. 2018. “Estimating Institutionalization and Homelessness
      for Status First Nations in Canada: A Method and Implications.” International Indigenous
      Policy Journal 9 (4).
      https://www.uvic.ca/socialsciences/economics/assets/docs/discussion/DDP1801.pdf.
Feir, Donna, Rob Gillezeau, and Maggie Jones. 2017. “The Slaughter of the Bison and Reversal
      of Fortunes on the Great Plains.” Working Paper.
Feir, Donna, and Robert Hancock. 2016. “Answering the Call: A Guide Reconciliation for


                                              51
     Quantitative Social Scientists.” Canadian Public Policy 42 (3): 350–65.
Foreman, Grant. 1972. Indian Removal: The Emigration of the Five Civilized Tribes of Indians.
     Civilization of the American Indian Series ; v. 2.
Fryer, Roland G. Jr., and Steven D. Levitt. 2004. “The Causes and Consequences of
     Distinctively Black Names.” Quarterly Journal of Economics 119 (3): 767–805.
     https://doi.org/10.1093/qje/qjt005.Advance.
Gaddis, S. Michael. 2015. “Discrimination in the Credential Society: An Audit Study of Race
     and College Selectivity in the Labor Market.” Social Forces 93 (4): 1451–59.
     https://doi.org/10.1093/sf/sou111.
———. 2017a. “How Black Are Lakisha and Jamal? Racial Perceptions from Names Used in
     Correspondence Audit Studies.” Sociological Science 4: 469–89.
     https://doi.org/10.15195/v4.a19.
———. 2017b. “Racial/Ethnic Perceptions from Hispanic Names: Selecting Names to Test for
     Discrimination.” Socius 3: 1–11. https://doi.org/10.2139/ssrn.2975829.
———. 2018. “An Introduction to Audit Studies in the Social Sciences.” In Audit Studies:
     Behind the Scenes with Theory, Method, and Nuance, edited by S. Michael Gaddis. New
     York: Springer.
Gitter, Robert J, and Patricia B Reagan. 2002. “Reservation Wages: An Analysis of the Effects
     of Reservations on Employment of American Indian Men.” American Economic Review 92
     (4): 1160–68.
Giulietti, Corrado, Mirco Tonin, and Michael Vlassopoulos. 2019. “Racial Discrimination in
     Local Public Services: A Field Experiment in the US.” Journal of the European Economic
     Association 17 (1): 165–204. https://doi.org/10.1093/jeea/jvx045.
Gorsuch, Marina Mileo, and Deborah Rho. n.d. “Police Stops and Searches of Native Americans:
     The Roles of Race, Place, and Gender.” Forthcoming in International Indigenous Policy
     Journal.
Greene, William. 2010. “Testing Hypotheses about Interaction Terms in Nonlinear Models.”
     Economics Letters 107 (2): 291–96. https://doi.org/10.1016/j.econlet.2010.02.014.
Hanson, Andrew, and Zackary Hawley. 2011. “Do Landlords Discriminate in the Rental Housing
     Market? Evidence from an Internet Field Experiment in US Cities.” Journal of Urban
     Economics 70: 99–114. https://doi.org/10.1016/j.jue.2011.02.003.
Hanson, Andrew, Zackary Hawley, Hal Martin, and Bo Liu. 2016. “Discrimination in Mortgage
     Lending: Evidence from a Correspondence Experiment.” Journal of Urban Economics 92:
     48–65. https://doi.org/10.1016/j.jue.2015.12.004.
Heckman, James J., and Peter Siegelman. 1993. “The Urban Institute Audit Studies: Their
     Methods and Findings.” In Clear and Convincing Evidence: Measurement of
     Discrimination in America, edited by Micheal Fix and Raymond Struyk. Washington, DC:
     The Urban Institute.
Heckman, James J. 1998. “Detecting Discrimination.” Journal of Economic Perspectives 12 (2):
     101–16.
Helleseter, Miguel Delgado, Peter Kuhn, and Kailing Shen. 2014. “Employers’ Age and Gender
     Preferences: Direct Evidence from Four Job Boards.” Working Paper.
Hipes, Crosby, Jeffrey Lucas, Jo C Phelan, and Richard C White. 2016. “The Stigma of Mental
     Illness in the Labor Market.” Social Science Research 56: 16–25.
     https://doi.org/10.1016/j.ssresearch.2015.12.001.
Hixson, Lindsay, Bradford B. Hepler, and Myung Ouk Kim. 2012. “The Native Hawaiian and


                                             52
     Other Pacific Islander Population: 2010.” Washington, DC: US Census Bureau - 2010
     Census Briefs. http://www.census.gov/prod/cen2010/briefs/c2010br-12.pdf.
Hurst, Michael. 1997. “The Determinants of Earnings Differentials for Indigenous Americans:
     Human Capital, Location, or Discrimination?” The Quarterly Review of Economics and
     Finance 37 (4): 787–807.
Jacquemet, Nicolas, and Constantine Yannelis. 2012. “Indiscriminate Discrimination: A
     Correspondence Test for Ethnic Homophily in the Chicago Labor Market.” Labour
     Economics 19 (6): 824–32. https://doi.org/10.1016/j.labeco.2012.08.004.
James, Keith, Willie Wolf, Chris Lovato, and Steve Byers. 1994. “Barriers to Workplace
     Advancement Experienced by Native Americans.” Report to the U.S. Department of Labor,
     Glass Ceiling Commission. http://digitalcommons.ilr.cornell.edu/key_workplace.
Johnston, David W., and Grace Lordan. 2016. “Racial Prejudice and Labour Market Penalties
     During Economic Downturns.” European Economic Review 84: 57–75.
     https://doi.org/10.1016/j.euroecorev.2015.07.011.
Jorgensen, Miriam, and Randall K. Q. Akee. 2017. “Access to Capital and Credit in Native
     Communities: A Data Review.” Tuscon.
Kaufman, Robert L. 2002. “Assessing Alternative Perspectives on Race and Sex Employment
     Segregation.” American Sociological Review 67 (4): 547–72.
Kleykamp, Meredith. 2009. “A Great Place to Start? The Effect of Prior Military Service on
     Hiring.” Armed Forces & Society 35 (2): 266–85.
Krishna, Pendakur, and Pendakur Ravi. 2011. “Aboriginal Income Disparity in Canada.”
     Canadian Public Policy 37 (1): 61–83. https://muse.jhu.edu/article/429086.
Kroft, Kory, Matthew J Notowidigdo, and Fabian Lange. 2013. “Duration Dependence and
     Labor Market Conditions: Evidence from a Field Experiment.” Quarterly Journal of
     Economics 128 (3): 1123–67. https://doi.org/10.1093/qje/qjt015.
Kruse, Douglas, Lisa Schur, Sean Rogers, and Mason Ameri. 2018. “Why Do Workers with
     Disabilities Earn Less? Occupational Job Requirements and Disability Discrimination.”
     British Journal of Industrial Relations 56 (4): 798–834. https://doi.org/10.1111/bjir.12257.
Kuhn, Peter, and Kailing Shen. 2013. “Gender Discrimination in Job Ads: Evidence from
     China.” The Quarterly Journal of Economics 128 (1): 287–336.
     https://doi.org/10.1093/qje/qjs046.
Kuhn, Peter, and Arthur Sweetman. 2002. “Aboriginals as Unwilling Immigrants: Contact,
     Assimilation and Labour Market Outcomes.” Journal of Population Economics 15 (2): 331–
     55. https://doi.org/10.1007/s001480100083.
Lahey, Joanna N. 2008. “Age, Women, and Hiring: An Experimental Study.” Journal of Human
     Resources 43 (1): 30–56. https://doi.org/10.1353/jhr.2008.0026.
Lahey, Joanna N., and Ryan Beasley. 2018. “Technical Aspects of Correspondence Studies.” In
     Audit Studies: Behind the Scenes with Theory, Method, and Nuance, edited by S. Michael
     Gaddis, 81–101. New York: Springer.
Lahey, Joanna N., and Douglas R. Oxley. 2018. “Discrimination at the Intersection of Age, Race,
     and Gender: Evidence from a Lab-in-the-Field Experiment.” NBER Working Paper 25357.
López Bóo, Florencia, Martín A. Rossi, and Sergio S. Urzúa. 2013. “The Labor Market Return to
     an Attractive Face: Evidence from a Field Experiment.” Economics Letters 118 (1): 170–72.
     https://doi.org/10.1016/j.econlet.2012.10.016.
Maurer-Fazio, Margaret. 2012. “Ethnic Discrimination in China’s Internet Job Board Labor
     Market.” IZA Journal of Migration 1 (12): 1–24. https://doi.org/10.1186/2193-9039-1-12.


                                               53
Maurer-Fazio, Margaret, and Lei Lei. 2015. “‘As Rare as a Panda’: How Facial Attractiveness,
     Gender, and Occupation Affect Interview Callbacks at Chinese Firms.” International
     Journal of Manpower 36 (1): 68–85. https://doi.org/10.1108/IJM-12-2014-0258.
McLaurin, Virginia A. 2012. “Stereotypes of Contemporary Native American Indian Characters
     in Recent Popular Media.” University of Massachusetts Amherst.
Nabokov, Peter. 1999. Native American Testimony: A Chronicle of Indian-White Relations from
     Prophecy to the Present, 1492-2000. Revised, S. Penguin Books.
Namingit, Sheryll, William Blankenau, and Benjamin Schwab. 2017. “Sick and Tell: A Field
     Experiment Analyzing the Effects of an Illness-Related Employment Gap on the Callback
     Rate.”
National Congress of American Indians. 2017. “Tribal Nations and the United States: An
     Introduction.”
     http://www.ncai.org/tribalnations/introduction/Tribal_Nations_and_the_United_States_An_
     Introduction-web-.pdf.
Neumark, David. 2012. “Detecting Discrimination in Audit and Correspondence Studies.”
     Journal of Human Resources 47 (4): 1128–57. https://doi.org/10.1353/jhr.2012.0032.
———. 2018. “Experimental Research on Labor Market Discrimination.” Journal of Economic
     Literature 56 (3): 799–866. https://doi.org/https://doi.org/10.1257/jel.20161309.
Neumark, David, Ian Burn, and Patrick Button. 2016. “Experimental Age Discrimination
     Evidence and the Heckman Critique.” American Economic Review 106 (5): 303–8.
     https://doi.org/10.1257/aer.p20161008.
———. 2019. “Is It Harder for Older Workers to Find Jobs? New and Improved Evidence from
     a Field Experiment.” Journal of Political Economy 127 (2): 922–70.
     https://doi.org/https://doi.org/10.1086/701029.
Neumark, David, Ian Burn, Patrick Button, and Nanneh Chehras. n.d. “Do State Laws Protecting
     Older Workers from Discrimination Reduce Age Discrimination in Hiring? Evidence from
     a Field Experiment.” Forthcoming in the Journal of Law and Economics.
Neumark, David, and Patrick Button. 2014. “Did Age Discrimination Protections Help Older
     Workers Weather the Great Recession?” Journal of Policy Analysis and Management 33
     (4): 566–601. https://doi.org/https://doi.org/10.1002/pam.21762.
Neumark, David, and Judith Rich. 2018. “Do Field Experiments on Labor and Housing Markets
     Overstate Discrimination? Re-Examination of the Evidence.” ILR Review 72 (1): 223–52.
     https://doi.org/https://doi.org/10.1177/0019793918759665.
Norris, Tina, Paula L. Vines, and Elizabeth M. Hoeffel. 2012. “The American Indian and Alaska
     Native Population: 2010.” Washington, DC: US Census Bureau - 2010 Census Briefs.
NPR, Harvard T.H. Chan School of Public Health, and Robert Wood Johnson Foundation. 2017.
     “Discrimination in America: Experiences and Views of Native Americans.”
     https://www.rwjf.org/content/dam/farm/reports/surveys_and_polls/2017/rwjf441402.
Nunley, John M., Adam Pugh, Nicholas Romero, and R. Alan Seals. 2015. “Racial
     Discrimination in the Labor Market for Recent College Graduates: Evidence from a Field
     Experiment.” The B.E. Journal of Economic Analysis & Policy 15 (3): 1093–1125.
     https://doi.org/10.1515/bejeap-2014-0082.
Oaxaca, Ronald L., and Michael R Ransom. 1994. “On Discrimination and the Decomposition of
     Wage Differentials.” Journal of Econometrics 61 (1): 5–21. https://doi.org/10.1016/0304-
     4076(94)90074-4.
Olken, Benjamin A. 2015. “Promises and Perils of Pre-Analysis Plans.” Journal of Economic


                                             54
     Perspectives 29 (3): 61–80.
Oreopoulos, Philip. 2011. “Why Do Skilled Immigrants Struggle in the Labor Market? A Field
     Experiment with Thirteen Thousand Resumes.” American Economic Journal: Economic
     Policy 3 (4): 148–71.
Pager, Devah. 2003. “The Mark of a Criminal Record.” American Journal of Sociology 108 (5):
     937–75. https://doi.org/10.1086/374403.
Pickering, Kathleen. 2000. “Alternative Economic Strategies in Low-Income Rural
     Communities: TANF, Labor Migration, and the Case of the Pine Ridge Indian
     Reservation.” Rural Sociology 65 (1): 148–67. https://doi.org/10.1111/j.1549-
     0831.2000.tb00347.x.
Riach, Peter A., and Judith Rich. 2002. “Field Experiments of Discrimination in the Market
     Place.” The Economic Journal 112 (November): F480–518. https://doi.org/10.1111/1468-
     0297.00080.
Riverwind, Joseph. 2007. “The Basic Indian Stereotypes.” Blue Corn Comics. 2007.
     http://www.bluecorncomics.com/stbasics.htm.
Rooth, Dan-Olof. 2010. “Automatic Associations and Discrimination in Hiring: Real World
     Evidence.” Labour Economics 17 (3): 523–34.
     https://doi.org/10.1016/j.labeco.2009.04.005.
Sai, David Keanu. 2008. “The American Occupation of the Hawaiian Kingdom: Beginning the
     Transition from Occupied to Restored State.”
Schmidt, Robert. 2007. “Indians as Welfare Recipients.” Blue Corn Comics. 2007.
     http://www.bluecorncomics.com/welfare.htm.
Sharma, Rajiv, Arnab Mitra, and Miron Stano. 2015. “Insurance, Race/Ethnicity, and Sex in the
     Search for a New Physician.” Economics Letters 137: 150–53.
     https://doi.org/10.1016/j.econlet.2015.11.005.
Silva, Noenoe K. 2004. Aloha Betrayed: Native Hawaiian Resistance to American Colonialism.
     Durham, NC: Duke University Press.
Sinning, Mathias, Markus Hahn, and Thomas K. Bauer. 2008. “The Blinder–Oaxaca
     Decomposition for Nonlinear Regression Models.” The Stata Journal 8 (4): 480–92.
     http://ideas.repec.org/a/tsj/stataj/v7y2007i4p465-506.html.
Tan, Alexis, Yuki Fujioka, and Nancy Lucht. 1997. “Native American Stereotypes, TV
     Portrayals, and Personal Contact.” Journalism and Mass Communication Quarterly 74 (2):
     265–84.
Taylor, Jonathan B., and Joseph P. Kalt. 2005. American Indians on Reservations: A Databook
     of Socioeconomic Change Between the 1990 and 2000 Censuses.
     http://hpaied.org/sites/default/files/publications/AmericanIndiansonReservationsADatabook
     ofSocioeconomicChange.pdf.
Thornton, Russell. 1987. American Indian Holocaust and Survival: A Population History since
     1492. The Civilization of the American Indian Series. Norman, OK: University of
     Oklahoma Press. https://doi.org/10.1002/1520.
Tilcsik, András. 2011. “Pride and Prejudice: Employment Discrimination against Openly Gay
     Men in the United States.” American Journal of Sociology 117 (2): 586–626.
     https://doi.org/10.1086/661653.
Tzioumis, Kostas. 2018. “Demographic Aspects of First Names.” Scientific Data, no. 180025: 1–
     9. https://doi.org/10.1038/sdata.2018.25.
U.S. Bureau of Labor Statistics. 2016. “Labor Force Characteristics by Race and Ethnicity,


                                             55
     2015.” Washington, DC: U.S. Bureau of Labor Statistics BLS Report 1062.
U.S. Census Bureau. 2011. “Facts and Features: American Indian and Alaska Native Heritage
     Month: November 2011.” 2011.
     https://www.census.gov/newsroom/releases/archives/facts_for_features_special_editions/cb
     11-ff22.html.
———. 2014. “S1601 - Language Spoken at Home - 2010-2014 American Community Survey
     5-Year Estimates.” American Factfinder. 2014.
———. 2015. “Facts and Features: American Indian and Alaska Native Heritage Month:
     November 2015.” 2015. https://www.census.gov/newsroom/facts-for-features/2015/cb15-
     ff22.html.
White House Initiative on Asian Americans & Pacific Islanders (WHIAAPI). 2010. “Fact Sheet:
     What You Should Know About Native Hawaiians and Pacific Islanders (NHPI’S).”
     Washington, DC. http://www2.ed.gov/about/inits/list/asian-americans-initiative/what-you-
     should-know.pdf%0A.
Wolfley, Jeanette. 1991. “Jim Crow, Indian Style : The Disenfranchisement of Native
     Americans.” American Indian Law Review 16 (1): 167–202.
Wright, Bradley R. E., Michael Wallace, John Bailey, and Allen Hyde. 2013. “Religious
     Affiliation and Hiring Discrimination in New England: A Field Experiment.” Research in
     Social Stratification and Mobility 34: 111–26. https://doi.org/10.1177/2329496514524541.
Zhou, Xiangyi, Jie Zhang, and Xuetao Song. 2013. “Gender Discrimination in Hiring: Evidence
     from 19,130 Resumes in China.” Ssrn, no. 28: 1–36. https://doi.org/10.2139/ssrn.2195840.




                                             56
