                 NBER WORKING PAPER SERIES




      SOME CONVERGENCE PROPERTIES OF BROYDEN'S METHOD



                      David M. Gay


                  Working Paper No. 175




COMPUTER RESEARCH CENTER FOR ECONOMICS AND MANAGEMENT SCIENCE
         National Bureau of Economic Research, Inc.
                    575 Technology Square
               Cambridge, Massachusetts 02139


                         July 1977


                         Preliminary
NBER working papers are distributed informally and in limited
numbers.

This report has not undergone the review accorded official
NBER publications; in particular, it has not yet been sub-
mitted for approval by the Board of Directors.

'NBER Computer Research Center. Research supported in part
 by National Science Foundation Grant MCS76-0032' to the
 National Bureau of Economic Research, Inc.
                      Abstract

In 1965 Broyden introduced a family of algorithms called

(rank-one) quasi—New-ton methods for iteratively solving sys-
tems of nonlinear equations. We show that when any member
of this family is applied to an nxn nonsingular system of

linear equations and direct-prediction steps are taken
every second iteration, then the solution is found in at

most 2n steps. Specializing to the particular family mem-
ber known as Broydents (good) method, we use this result to

show that Broyden's method enjoys local 2n-step Q-quadratic
convergence on nonlinear problems.
                        Contents




1.   Introduction .                          1

2.   Finite Termination on Linear Systems    3


3. Local 2n-Step Q-Quadratic Convergence
    of Broyden's Method                      9

4. Concluding Remarks                       14

5. References                               16
                                   —1—



1. Introduction
     In 1965 Broyden [1965] introduced a family of algorithms
called quasi-Newton methods for solving systems of nonlinear

equations, i.e. ,      for   finding x* e ]Rn such that f(x*)      0,

where f; JR" ÷ ]R" is differentiable. Broyden proposed a modified

form of Newton's method in which an approximation H to the

inverse of the true Jacobian matrix f(x) is used and updated
after each step. This leads to an iteration of the form
x.
 1+1
         x. -
          1      11 1
                X.H.f(x.),     where the steplength A.
                                                     1
                                                       is chosen to

promote   convergence. In what follows we shall usually restrict our

attention to direct prediction methods, i.e., A.            1 as in

Newton's method. By analogy with the DFP method [Davidon,
1959; Fletcher a       Powell,   1963] for unconstrained minimization,
and by considering what is desirable when f is linear, Broy-
den proposed updating H. in such a way that the quasi-Newton

equation H1÷1 [fx±÷1 -
                                 f(x±)]
                                            x1÷1 -   x holds. Since
new information is picked up in only one direction each step,

Broyden suggested obtaining H+1 from H. by means of a
rank 1 update, i.e., by adding a matrix of rank 1 to H1.
This leads to the following iterative procedure.


          Choose nonsingular H0 e flXfl and x0 c 3R.
          Fork 0,1,2, ...            let
(1.la)          5k     _Hkf(xk);
(l.lb)                   Xk +
                xk+l
(1.lc)          31k    f(xk+l) —   f(xk);
                                       —2—




(l.ld)            If          0 then
(1.le)                          else choose Vk c ]RrI   such that VYk
(l.lf)                          and VH'Sk 0
(l.lg)                          and let Hk+l H + (sk      -
                                                              HkYk)v
       Because of (l.lf) and the Sherman-Morrison [l9Z9] formula,

Hk+l is nonsingular whenever Hk is, so induction shows that
Hk is nonsingular for all k, whence Sk              0   only if f(xk)           0.

       Broyden's [1965] method (sometimes called his first or

good method) results from choosing vk             Hksk/(skHkyk) in (l.le)
-- and is defined for                  0 only so long as SHkYk          0 and
         0.                   second or bad method results from choosing
Syk
              T
                       when         0 and is defined so long as
Vk
              0
YkHk5k
       Broyden has shown that his (first) method converges

locally at least linearly on nonlinear problems [1971] and at

least R-superlinearly on linear problems [1970]. Later,
Broyden, Dennis, and Morg [1973] showed that both Broyden's

good and his bad method converge locally at least Q-super-

linearly. More and Trangenstein [1976] subsequently proved
that "locally" could be replaced by "globally" when a modified
form of Broyden's method is applied to linear systems of equa-

tions. In Section 2 of this paper we show that when any form
of (1.1), including Broyden's good and bad methods (so long as

they are defined), is applied to a system of linear equations

f(x)     Ax - b        in which A c ]RF1<1 is nonsingular, then the

iteration converges in at most 2n steps (i.e., x5               x   =   A   b
                                       —3—




for all j > 2n).           We show further that this result also holds
when some nonunit steps are allowed (Sk                     XkHkf(xk), with

Ak      0, 1). Specializing to Broydens good method, we show
in Section 3 that this method enjoys local 2n-step Q-quadratic

convergence on nonlinear problems. Section                     presents some
concluding remarks.

2.   Finite Termination on Linear Systems

        In this section we show that Algorithm (1.1) converges

in at most 2n steps when applied to an f representing a
nonsingular system of linear equations: f(x)                     Ax -   b,   where

A nxn b £          lRnl,    and A is nonsingular. This follows as
an easy corollary to the following lemma, which holds even if
A is singular. The notation [ci used below denotes the
greatest integer less than or equal to a c ]R, while for non-
zero u, v        ]RrI, the notation u                v means that u         Xv for
some real A        0.



Lemma 2.1
        If A c             and Algorithm (1.1) is applied to f(x) E Ax               -   b

with the result that                   f(xk) and               are linearly inde-

pendent, then for 1 <          j   <   L(k+i)/2J,
(2.1)      (AHk_2j÷l)'fk_2j+l 0 <            i   <   j,   are linearly independent.


Proof: Since k-l Ask_i                    _AHklfkl, this is easily seen
to hold for j           1. Assume it true for j                m <   L(k+l)/2J.
Note that 2m <       k-i,     whence k-2m-i > 0.             Also note from

(l.la,b,c,d) that y.               0 =>      y11 0, ° k—l               0     >
                                                —4—




'k-2m-l
                    0. Now
s
    k-2m
           -H k-2my k-2m                 -H    f
                                           k-2m k-2m
                                                             +Hk-2mAMk-2m fk-2m
                                         -H
                                              k-2m
                                                     (I—AHk-2m)fk-2m           so

AHic2m+i                AHk2(I - CI            -
                                                   AHk2]fk2V2).               Moreover,

                             -
k-2m+l                             k2mk2m              Since

0 <    i   < m,     are linearly independent by the induction hypothesis
(2.1), we see by the two preceeding equations and induction on
      that there exist               y          (dependent on k and m) such that

(ARk 2m+l                2m+l            (I_AHk_2m)[(AHk_2m)' +
                                                                           .(AHk21fk2
for 0 <
      —         —       m,       whence (I - AH                                       <
                                               k-2m )(AH k-2m )'f k-2m         ,    0 —   —

are linearly independent. But                          (I -
                                                               AHk    2yk2l 0 by
(l.le,g), so k-2m-l _AHk2mlfk2ml and (AHk2ffl)'f2m
o <    I   <   m, are linearly independent. As before, we see that
there exist                        (dependent on k and m) such that

                                  (I -
(AHk2)'fk2                               AHk           [(AHk2 l +
                                                         +
                                                                     i,i(AHk_2m_l)jfk_2m_l
for 0 <         I   <   m,       whence we readily see that (AHk2ml)'fk2ml

o <   I    <   m+1,      are linearly independent. Thus (2.1) holds for

j     m+l, and the lemma follows by induction. I

Theorem 2.2: If f(x)                       Ax - b       and A c             is nonsingular,
then Algorithm (1.1) converges in at most 2n steps (i.e.,

2n 0).
                                              —5—




Proof: As noted above, Hk is nonsingular for all k; since
A is nonsingular, we thus see that if f22 is nonzero,
then the same is true of s                               -H       f        and
                                          2n—2                2n—2 2n—2

'2n-2 AS22. If f1 0, then necessarily 2-2
SO 2n2            0 and Lemma 2.1 implies that f21 2n-2
(since otherwise ]R would contain n+l linearly independent
vectors). Since s22 H21Y22 H21A522 by (l.le,g),
we have y22 As22 AH21y22 and hence
f
    2n—l
           AH 2n—l f2ri—l   ,     so

f f2n-1 +A2n-lf -AH2n—l 2n—l 0.
    2n                                 2n—1
                                                               f


           Theorem 2.2 leaves several questions unanswered, such as
whether a full 2n steps may actually be required. Computer
runs suggest for small values of n that Broydents good and
bad methods may both require a full 2n steps. As we shall
now see, it is possible for arbitrary n and nonsingular A
to choose H, f, and the                        Vk in (l.le) so that Algorithm
(1.1) requires a full 2n steps. This is the content of
Theorem 2.L., proof of which requires the following lemma.

Lemma 2.3: In Algorithm (1.1), if                                  0, vy1 0, and
Rank(I -             n-l, then Rank(I - AHk+l)                            n-l.
              AHk)

Proof: I -
                 AHk+l
                                I -
                                       AHk(I
                                                -   [I   -
                                                              AHk]fkv)
                                (I -
                                        AHk)(I + AHkfkv)
                                (I -                -
                                        AHk)(I
                                              —6—




It suffices to show that (I -                                      0 whenever u is
                                                   AHk+i)u
linearly independent of                            Now Rank(I -                           n-i and
                                                                            AFIk)
(I -
          AHk)Yk          0, so (I -                      0 whenever w is linearly
                                              AHk)W
                                               T               T
                                                         k"k
•
independent of kl• But vk(I -                                           0, so for

w      (I -
                ykv)U, we have vw 0, while vYkl 0 by
assumption. Thus w is linearly independent of
whence (I -                            (I -               0. •
                       AHk+l)u                AHk)W

Theorem        2.4.:    If I - AH0            is nonsingular, if (AH)'f,

o   <i     <   n-i,    are linearly independent, if vfk                                   0 and

vHk'sk           0 for k > 0,             and if VYkl 0 for k > 1,
then Algorithm (1.1) requires a full 2n steps to converge.

Proof: As in the proof of Lemma 2.1, we find
(2.2a)                        (I -
                 k+l                 AHk)fk,
(2.2b)                               _(vfk)(I - AHk)(AHk)fk,                        and
                 AHk+lfk+l

(2.2c)                                  _(vfk)(I -                                   +     E
                 (AHk÷l)1fk÷l                                 AHk)[(AHk)'                      (AHk)1fk
for             1.     In particular, since vf0                        0,     I -              is non-
                                                                                         AH0

singular, and (AH0)1f0, 0 <                    i   <   n-l,     are linearly independent,
we see for j              1    that

(2.3a)           (AH21)1f21 0 <                          n-j,      are linearly independent.

Moreover, since I - AH1                        (I -     AH)(I      -
                                                                        y0v),             we see for

j     1     that

(2.3b)           Rank(I —                      n—l.
                               AH2.1)
                                              —7—




Suppose (2.3) holds for 5                      k <   n.    Since 2kl _AH2klf2kl,
we see from (2.2) and (2.3a) that 2k-i and (AH2k)'f2k,

o   <i   <   n-k-i,    are linearly independent. But
(I -
       AH2)21   0, while Rank(I - H2k) n-i by (2.3b)
and Lemma 2.3, so 2kl spans the null space of I - AH2k

and (I - AH2k)(AH2k)'f2k,                     0 <         n-k-i,   must be linearly

independent (since otherwise 2k1 were a linear combination
of (AH2k)'f2k, 0 <                i   <   n-k-i).    From (2.2) it follows that

(2.3a) holds for j                    k+l, while (2.3b) holds for j                  k+l

by Lemma 2.3. Thus (2.3) holds by induction for 1 <                          j   <   n.
In particular, f1 0, whence Algorithm (1.1) runs a full
2n steps before converging. I

       Another question that Theorem 2.2 leaves unanswered is
what happens when a step-length parameter is introduced, i.e.,

when step (l.la) is replaced by Sk                           AkHkfk For
         0, 1,     (2.2) becomes
Ak

(2.)              (AHk+l)'fk+l
                                            (I -
                                                    AHk) AHk)' +
                                                                     E   (AHk)]fk +

                                               +
                                                     i,ok
i.e., multiples of k are added to the right-hand sides of
(2.2). Thus the proof of Lemma 2.1 is unaffected if

Ak21 1, 1 <                 m <       L(k+i)/2J;      it seems essential only that

             1.    More generally, we see from (2.Ll.) that if
Xk2m
                      0 <             m,    are linearly independent, then the
                                —8—




set {(AHk)1fk I 0 < i < m+1} must contain at least m+l

linearly independent vectors, whence (AHk)1fk 0 < i <
must be linearly independent (since if (AHk)fk were dependent

on (AHk)1fk 0 < I < j, for some j < m, then (AHk)fk

could be expressed as linear combinations of these same vectors

for all       > j). Hence the proof of Lemma 2.1 may be modified

to obtain

Theorem 2.5: If Algorithm (1.1) is applied to a linear function

f(x)      Ax - b   with A c ]Rnl>(11 nonsingular and (l.la) replaced

by                           0), and if there are integers k.,
       5k   XkHkfk (Xk
o —< i —< n, such that ko       -l and X k.     1 with
                                            1

k.>k.
 i— i-i+2 for 1<i<ri,
                — —   then fk
                              n
                                                0.
       Theorem 2.'-i. is readily generalized to allow X2k    1,

o < k < n. Whether a further generalization along the lines

of Theorem 2.5 is possible remains an open question.
                                                     —9—



3        Local 2n-Step Q-Quadratic Convergence of Broyden's Method
         We now restrict our attention to the direct-prediction

version of Eroyden's (good) method. This amounts toAlgo—

rithm (1.1) with Vk                             HkTsk/(skTHkyk). With this Vk,        it   is

well known (and easily seen from the Sherman-Morrison [19L49]

formula)           that if                      is nonsingular and Sk Hkyk       0, then
Hk÷l
    —l
              Hk
                   —l   +
                             k            —1         T      T
                                      Hk sk)sk /(sk sk). We shall find it some-
what more convenient to restate the direct—prediction Broyden's

method in terms of B Hk. Thus for k                                        0, 1, 2,
we are dealing with the following iteration (in which




(3.la) s kk
(3.lh)                                +
                                 Xk        Sk
(3.lc) k k+l —
(3.ld) If skBkyk                                0 then k±l =        + (   - Bksk)sk/(sksk)
(3.le)                                            else Bk+l      Bk.


          In what follows,                           =          denotes the Euclidean
                                            T
vector norm                 lxii          (x x)          or the corresponding induced

matrix norm. We may now state the main result of this section:

Theorem 3.1: Suppose f: n -]R is differentiable with
                             1
f(x)      -   f(y)           ff'(y +            T(x-y))(x-y)dT,    that f(x*)     0 with
                             0

A   E    f'(x*)         nonsingular, and that the Jacobian matrix f' j
                                              —10—



Lipschitz continuous at x*, i.e., for some constant A
and all x sufficiently close to x,

(3.2)       f' (x) -           f' (x <        A       -
                                                          x.
           Then there exist y, , >                         0        such that if


(3.3) x_4 <                          and B- A <
           then    the. iterates produced by Algorithm (3.1) satisfy

(3.)                       -
                               x     <            -


           for   all Q >            0.

Proof: From (3.2) and the proofs of Theorems 3.2 and 14.3 of

[Broyden, Dennis, & Mor, 1973], there exist ,c >                                   0    with
  < l/(LIA'II)                 such that if (3.3) holds, then

(3. 5)
            Xk+l
                       -                 Xk
                                              -   x
(3.6)       Bk - A              <   2,
(3.7)                           <



(3.8)

and sBy 0 only if                             x*. Fix 9 and let h                  -
                                                                                       x*jI:
we must show that there is a y independent of 9 such that

IIx+2 -     x      <       yh2.

         Consider the sequences ' x2,                          ..   . , x2   of vectors and


     B2,
                   2 of matrices generated from                                    x and
                                                       —11—




B         B by (3.1) with f(x) replaced by f(x)                                           A(x -

i.e., k                       xk), Sk              Bkfk, Xk+l           Xk
                                                                                +
                                                                                    Sk,
      =
          k+1
                      -
                          k        Ask and
                                                   -
(3.9)
                      B±1          Bk +                 Bkskk/ksk)
for Sk                O    with Bk+l = Bk
                                                               Sk
                                                                       0.       Similarly to (3.6)
and (3.8), we have


                      k A <                        and

(3.11)                         <



          W' s:w by ii.iuction that there ex.Ltt ',
(independent              of ) such that
(3.12a)                        -                                       nd
                                       BI! II+5II          y1.h
(3.12b)
                      Ilx+ - xii
for       0<j<2n.
          Since B                  B
                                       0    and x =      0,
                                                           x (3.12) holds for j =                     0

with      -               2 0   0.               Suppose it holds for j    k. To
              ,   0         , =
establish             (3.12b) for            j      k+1, we first note that


                      IIS+k
                               -
                                       Sk        Bkf÷k Bf
(3.13)                                           IIBII IIBkII IIB+k - BkM IIf+kII                 +


                                                                            -
                                                    +
                                                           Ii1II t'+k
Now       +k -            k [fx+k -                     f(xj+k)1
                                                                   +
                                                                       Lx÷k
                                                                                      -
                                                                                           xk)l
                                                  —12—




and (3.2) and (3.5) imply
               A
            - f(x+k)M                     Lf* + T[XL+k_X*]) -
                                                                                      ft(x*)1(x_x*)dT
                                                                 1
                                  <                     —
                                                            x*II /lIX2.+k
                                                                             —
                                                                                 xITdT
                                                        -   x*112 <

while for
               '3,k        tIAIIy2k,

IJf(x+k) -     xk)II              hAil ilX+k - Xkil                       13,kh       by (3.12b), so

(3.13), (3.8),        (3.11),             and (3.12a) imply

(3.1k)                -
                               skIl

                                                  +
                                                        All(X        +
where ,k lA'iI2y1 ,k                                                     213k), which,
along with (3.12b) for j                               k, gives (3.12b) for j                k+1
with                              +
         12,k+1     12,k
       It remains to show that (3.lL) and (3.12a) for j                                        k

imply (3.12a) for j                       k+1. If 5+k                     0 or Sk         0, then
                                              A
either +k+1 0 or                                            0, whence the reasoning above

                                              <   (     +   3,k+l together with (3.6)
(3.1LI.) shows        if                      —
and (3.10), this shows for 15k+1                                             +
                                                                                 23k+1 that
!IB+k+l - Bk+lii '1i+k+11'                             YSk+1h2. On the other hand, if
                                      A
both     5+k       0 and Sk                        0     (as we henceforth assume), then

in view of (3.ld), (3.9),                         and (3.7), we need only show that

                                                        T        T
(3.15)       +k -               B+ks+k)sj+k/(s÷ks+k)
                                                                                  -



                           -              -
                                                  A A AT ATA
                                                  Bksk)sk/(sksk)            II+kII        16,kh,
                                                        —13—




for then (3.12a) holds for j                                    k+l with
                                                                                         1
11,k+1        max{y5 k+1' 11,k +                                        Let Ak           ff'(xL+k+ T5+k)dT,
                                                                                         0
                                                                A
so that                      Aks,+k. Since                                Ash, we have the follow-
                   .+k

bound on LHS(3.15), the left-hand side of (3.15):

                                                               T           T
        LHS(3.15)                (Ak_Bj+k)s+ks+k/(sj+ks+k) -

                                                    -           '    "T          ATr     II   1       II

                                                             (ABk)sksk/(sksk)JI               fV&+kl
(3.16)                                              -                                T         T
                         <
                             [(A-A)          (B+k_Bk)]s+ks+k/(sj+k +k )lI hf                                II
                                                                                                                 II +



                             +                        T      - AT .TA
                                     (A_Bk)[sj+ks+k/(sj÷ks+k) 5ksk/(sksk)
                                 1
Now IlAk — All           <
                                 fhlf'(xj+k
                                 0
                                                         +   TSZ+k) —          f(x*)IldT
                                                    + Ts+k —            x*hJdT
                                     0

                         <                      —
                                                     x'Il
by (3.2) and (3.5), while jfIl                                 <               by (3.2), (3.5), and the
                                                                    y7h
definition of h, where
                                                    17         hAll +     X5/2.      Because of (3.5),

                                   T    T
            and the fact that Is÷ksj+k/(s+ks+k)l
(3.7),                                                                                            1, we thus
find IhAk - All          <   Xh          and

        -                                                                  <                      From (3.12a)
                                                             '1f+k11
for j         k,     we thus find that the first term in the right-
hand side (RHS) of (3.16) is bounded by (Ày7 +
                                           A                                     A
                                                                                              ylk)h.       By

(3.10)      and (3.6), lA —                Bk!1     tli+kH
                                                                        hA —
                                                                                 Bk1! IlBj+ks÷kll .        18IlS.Il
where               llAIl         +      26).       Moreover,
                                                —1t—



                                                                             A
       T          AAT
 S+kS+k -         SkSk             -        _______       S+k         -     Sk                   +
 4+kS+k           SkSk                      I! S+kIJ     IIS+kIl           liSkil
                                                                            A

                                                +       _______       —     6k              Sk
                                                       IIS.+kI!            IIskIJ       IkkII

                                                                  -
                                   <    2
                                            +k" S+kII                     Sk/ Sk        )
                                       [2/Ils÷I](s÷k
                                                           -
                                                               Sk)
                                                                      +
                                                                          [(IlI     -


                                   <                - Sk/+k.
Because of (3.lq.), we therefore conclude that the second
term in RHS(3.16) is bounded by Y8Ykh2, so (3.15) holds
with ' 6
           ,.   Xy.7
                       +
                           .L.,_
                                       + Ly0y   . Thus     (3.12a) holds for                 j       k+l,
and by induction we see that (3.12) holds for                                       j        2n. But

X2n x           by Theorem 2.2, so (3J4) holds with '                                       11,2n       I

      We    could use the same techniques to prove a similar

result for Broyden's bad method, i.e., Vk
(l.2e). At the time of this writing, it remains an open
question whether a similar result holds for Broyden's method

with projected updates [Gay F Schnabel, 1977].

4.   Concluding        Remarks

     Theorem 2.2 came as quite a surprise to a number of us
who had confidently shared the belief that Broyden's method

did not enjoy finite termination on linear problems. Among
other things, this theorem should serve to still the criticism

that Broyden [1970, p. 377] had in mind when he wrote, "Thus
                             —15—




Broyden's algorithm will not solve linear systems in a finite
number of steps and this has been held to be a disadvantage
of the method."

       Theorem 3.1 is one interesting consequence of Theorem 2.2:

Broyden's method with unit step lengths enjoys local 2n-step
Q-quadratic convergence and hence has an R-order of (local)

convergence of at least 21/(2n) (see §9.2 of [Ortega S Rhein-

boldt, 1970]). This result nicely complements that of
[Broyden, Dennis, S More, 1973], which establishes the local

Q—superlinear convergence of Broyden's method. The Q-super-
linear convergence assures that eventually more progress is

made in the current iteration than in the previous one, while

the 2n-step Q-quadratic convergence assures a definite amount

of progress at intervals of no more than 2n iterations.

       Theorem 2.14 suggests that Broyden's good (or bad) method
often converges no faster than 2n-step Q—quadratically and

hence has an R-order of exactly 21/(2n)     If so, then we may
extend the comparison of asymptotic efficiencies in §6 of

[Brent, 1973] to include Broyden's method. According to
Brent's definition, Broyden's method would have efficiency

E(B)     (1og22)/(2n), the lowest of the methods compared. Of

course, this says little for practical applications, where
the bulk of execution time is consumed in finding the region

of fast local convergence and where the simple measure of

work (i.e., the number of equivalent function evaluations)

that Brent used may not suffice. Moreover, if (as we suspect)
                              —16—




a result similar to Theorem 3.1 holds for Broyden's method

with projected updates [Gay      Schnabel, 1977], then this
version of Broyden's method often enjoys (n+1)-step Q-quadra-
tic convergence, which gives it efficiency E(P) =
                                                      (log22)/(n+l),
the same as for the finite-difference Newton's method.


Acknowledgment

     The author thanks John E. Dennis, Jr. both for helpful

comments on a draft of this paper and for suggesting that

Theorem 2.2 would probably imply the local 2n-step Q-quadratic

convergence of the direct-prediction Broyden's method on

nonlinear problems.


5.   References


Brent, R.P. (1973), "Some Efficient Algorithms for Solving
          Systems of Nonlinear Equations", SIAM J. Numer.
           Anal. 10, pp. 327-3.
Broyden, C.G. (1965), "A Class of Methods for Solving Non-
          linear Simultaneous Equations", Math. Comput. 19,
          pp. 577—593.

Broyden, C.G. (1970), "The Convergence of Single-Rank Quasi-
          Newton Methods", Math. Comput. 2'i., pp. 365-382.
Broyden, C.G. (1971), "The Convergence of an Algorithm for
          Solving Sparse Nonlinear Systems", Math. Comput. 25,
           pp. 285—29Lf.

Broyden, C.C.; Dennis, J.E.; a More, J.J. (1973), "On the
          Local and Superlinear Convergence of Quasi-Newton
          Methods", J. Inst. Math. Appi. 12, pp. 223-25.
Davidon, W.C. (1959), "Variable Metric Method for Minimiza-
          tion", Argonne National Labs. report ANL-5990 Rev.

Fletcher, R.; a Powell, M.J.D. (1963), "A Rapidly Convergent
          Descent Method for Minimization", Comput. J. 6,
          pp. 163—168.
                           —17—




Gay, D.M.; F Schnabel, R.B. (1977), "Solving Systems of
          Nonlinear Equations by Broyden's Method with Pro-.
          jected Updates", NBER Working Paper No. 169.
Mor, J.J.; & Trangenstein, J.A. (1976), "On the Global
          Convergence of Broyden's Method", Math. Comput. 30,
          pp. 523_5140.

Ortega, J.M.; & Rheinboldt, W.C. (1970), Iterative Solution
          of Nonlinear Equations in Several Variables,
          Academic Press, New York.

Sherman, J.; & Morrison, W.J. (1949), "Adjustment of an
          Inverse Matrix Corresponding to Changes in the
          Elements of a Given Column or a Given Row of the
          Original Matrix", Ann. !4ath. Statist. 20, p. 621.
