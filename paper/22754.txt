                              NBER WORKING PAPER SERIES




             CAN ONLINE DELIVERY INCREASE ACCESS TO EDUCATION?

                                        Joshua Goodman
                                          Julia Melkers
                                         Amanda Pallais

                                      Working Paper 22754
                              http://www.nber.org/papers/w22754


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                          October 2016, revised September 2017




We thank Zvi Galil, Alan Glass, Michael Terrazas, and David White for supporting this research,
explaining how OMSCS and its admissions process works, and sharing data. For helpful
comments, we thank David Autor and Lawrence Katz, as well as seminar participants at Harvard,
MIT, Columbia, University of Mannheim, CESifo, UIUC, University of Connecticut, University
of Virginia, Louisiana State University, NYU, Stanford, Carleton, APPAM and AEFP. Carlos
Paez, Melanie Rucinski and Tianlong Xu provided excellent research assistance. The views
expressed herein are those of the authors and do not necessarily reflect the views of the National
Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2016 by Joshua Goodman, Julia Melkers, and Amanda Pallais. All rights reserved. Short
sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including © notice, is given to the source.
Can Online Delivery Increase Access to Education?
Joshua Goodman, Julia Melkers, and Amanda Pallais
NBER Working Paper No. 22754
October 2016, revised September 2017
JEL No. I20,I23,J2,J24

                                         ABSTRACT

Though online technology has generated excitement about its potential to increase access to
education, most research has focused on comparing student performance across online and in-
person formats. We provide the first evidence that online education affects the number of people
pursuing education. We study the Georgia Institute of Technology’s Online M.S. in Computer
Science, the earliest model to combine the inexpensive nature of online education with a highly-
ranked degree program. Regression discontinuity estimates exploiting an admissions threshold
unknown to applicants show that access to this online option substantially increases overall
enrollment in education, expanding the pool of students rather than substituting for existing
educational options. Demand for the online option is driven by mid-career Americans. By
satisfying large, previously unmet demand for mid-career training, this single program will boost
annual production of American computer science master’s degrees by about seven percent. More
generally, these results suggest that low-cost, high-quality online options may open opportunities
for populations who would not otherwise pursue education.

Joshua Goodman                                  Amanda Pallais
Harvard Kennedy School                          Department of Economics
79 JFK Street                                   Harvard University
Cambridge, MA 02138                             Littauer Center
and NBER                                        Cambridge, MA 02138
joshua_goodman@hks.harvard.edu                  and NBER
                                                apallais@fas.harvard.edu
Julia Melkers
School of Public Policy
Georgia Institute of Technology
685 Cherry Street Atlanta, GA 30332
julia.melkers@pubpolicy.gatech.edu
1       Introduction
Online coursework has been heralded as potentially transformative for higher education, possibly
lowering costs of delivery and increasing access for disadvantaged students. From 2002 through
2012, the number of online bachelor’s degrees awarded rose from 4,000 to 75,000, or five percent
of all U.S. bachelor’s degrees issued that year (Deming et al., 2015). The federal government
estimates that 27 percent of college students were taking at least one course online as of 2013, the
most recent year for which data exists.1 Though online education is increasingly prevalent, we
know relatively little about the longer run implications of the existence of this new form of human
capital development (McPherson and Bacow, 2015).
        This paper provides the first evidence on whether online education can improve access to edu-
cation, a key question in evaluating online education’s overall impact. Does online education sim-
ply substitute for in-person education or can it instead expand access to students who would not
otherwise have enrolled in an educational program? Existing research largely compares student
performance in online and in-person classes, often by randomly assigning students to one format
or the other conditional on already having enrolled. The online format generally leads to worse
learning outcomes (Joyce et al., 2015; Alpert et al., 2016; Krieg and Henson, 2016), particularly for
academically weaker students such as those in community colleges (Xu and Jaggars, 2014) and
for-profit colleges (Bettinger et al., 2017). In some settings, students do equally well across both
formats, raising the possibility that the online format may nonetheless be a cost effective delivery
mechanism (Figlio et al., 2013; Bowen et al., 2014).
        Though the body of research on the pedagogical efficacy of the online format is growing, no
prior research on online education has addressed whether the existence of online options increases
the number of people obtaining education. This is in part because the ubiquity of such options
makes it difficult to construct convincing counterfactuals. Understanding the impact of online
education depends, however, on whether online classes replace in-person classes or generate ad-
ditional human capital investment.
        We provide evidence on this by examining the earliest educational model to combine the in-
expensive nature of online education with a degree program from a highly-ranked institution.
Specifically, we study the new Online Master of Science in Computer Science (OMSCS) offered
by the Georgia Institute of Technology (Georgia Tech) and developed in partnership with Udac-
ity and AT&T. In spring 2014, Georgia Tech’s Computer Science Department, which is regularly
ranked in the top ten in the United States, started enrolling students in a fully online version of its
highly regarded master’s degree. The online degree costs about $7,000, less than one-sixth of the
$45,000 out-of-state students pay for Georgia Tech’s in-person computer science master’s degree
(MSCS). Program price and admissions criteria were set in part to attract a much larger number
    1
    See Table 311.15 of the 2014 Digest of Education Statistics, published by the U.S. Department of Education’s Na-
tional Center for Education Statistics.


                                                         1
of students than the in-person program without compromising the quality of the degree.
   Importantly, the degree OMSCS students earn is not labeled “online” and is in name fully
equivalent to the in-person degree. As a result, the reputation and labor market value of Georgia
Tech’s in-person degree now at least partially depend on the extent to which Georgia Tech can
ensure that the quality of its graduates does not differ substantially across the two formats. In
an attempt to address the quality concerns that online education raises, Georgia Tech designed
OMSCS such that its courses are online versions of the same courses in-person students take,
designed by the same faculty teaching those courses, and graded using the same standards.
   We first document where demand for this model of online education comes from by comparing
the online and in-person applicant pools, as both programs lead to the same degree but through
different formats. We find large demand for the online program, which is now the nation’s largest
master’s degree program in computer science. Importantly, there is nearly no overlap between the
applicant pools to these two programs, with few individuals applying to both. The average in-
person applicant is a 24-year old non-American recently out of college, whereas the average online
applicant is a 34-year old mid-career American. Eighty percent of those admitted to the online
program accept those offers and enroll, suggesting few find compelling alternative educational
options. Large demand from a mid-career population uninterested in its in-person equivalent and
a high matriculation rate both suggest the online program is drawing in students who would not
otherwise enroll elsewhere.
   Next, we rigorously estimate whether this online option expands access to education for stu-
dents who would not otherwise enroll, thus increasing the number of students participating in
higher education. To do so, we utilize quasi-random variation in admission to OMSCS to deter-
mine the extent to which access to the online option substitutes for enrollment in other programs.
We exploit the fact that capacity constraints for the first applicant cohort led to the program’s
admission officer reading applications in descending order of undergraduate GPA until he had
identified about 500 applicants to which immediate admission was offered. As a result, such offers
were made only to those with a GPA of at least 3.26, a threshold that was arbitrary and unknown
to applicants. The officer eventually read all of the applications and some of those below the
threshold were offered deferred admission. A regression discontinuity design shows this admis-
sions process created at the threshold a roughly 20 percentage point difference in the probability
of admission to the online program.
   With National Student Clearinghouse data that tracks enrollment in any U.S. formal higher
education, we use a regression discontinuity design to compare enrollment outcomes for appli-
cants just above and below that threshold, two groups who differ only in their access to this online
option. We find a roughly 20 percentage point difference in the probability of eventually enrolling
in the online program, the magnitude of which suggests that roughly all of the marginal admits




                                                 2
ultimately matriculate.2 Importantly, we show that very few applicants to OMSCS enroll in other,
non-OMSCS programs. Those just below the admission threshold are no more likely to enroll
elsewhere than those just above it, implying that access to the online program does not substitute
for other educational options. Such access thus substantially increases the number of students
enrolling at all. The higher education market appears to have been failing to meet demand for this
online option.
       To assess whether OMSCS substituted for informal educational options such as MOOCs or
professional certification programs, we surveyed applicants to the first OMSCS cohort three and
a half years after the start of program. While almost three-quarters of applicants had undertaken
informal training in the interim, the average time spent in non-degree training was small relative
to the time a degree program requires. Using our regression discontinuity design, we find no
evidence that OMSCS substituted for non-degree options. Combining time spent on formal and
informal education, we find that access to OMSCS had a large and significant impact on total
training.
       Early evidence also suggests that this online program is delivering a relatively high-quality
educational experience. To test whether students pursuing the degree online were finishing their
courses with as much knowledge as those pursuing it in person, Georgia Tech blindly graded fi-
nal exams for online and in-person students taking the same course from the same instructor. The
online students slightly outperformed the in-person students (Goel and Joyner, 2016).3 OMSCS
students are also persisting at rates substantially higher than students in nearly all MOOCs and
higher than in many online degree programs. Among those students who started OMSCS in 2014,
62 percent remain enrolled two years later, apparently on track to complete their degrees. This is
very likely a lower bound on completion rates given that over 25 percent of students who take a
semester off from the program re-enroll in subsequent semesters. Given the nearly 1,200 Amer-
icans enrolling each year in OMSCS and assuming only those 62 percent graduate, this implies
production of at least 725 new American computer science master’s degrees holders annually.
Roughly 11,000 Americans earn their master’s degree in computer science each year, implying
that this single program will boost annual national production of American compute science mas-
ter’s degrees by about seven percent.
       That OMSCS appears to be filling a gap in the higher education market may explain why the
announcement of the program in 2013 garnered such extensive media attention. OMSCS was
described as the first large-scale program offered by a highly-ranked department, priced much
lower than its in-person equivalent and culminating in a prestigious graduate degree. Prior mod-
   2
     The difference in OMSCS enrollment at the discontinuity is not due to differential likelihood of enrolling in OMSCS
conditional on admission. On both sides of the discontinuity, 80 percent of admitted students enroll in the program.
   3
     We lack baseline measures of student skill that would allow us to distinguish the hypothesis that online delivery
was as pedagogically effective as in-person delivery from the hypothesis that online students started from a higher
knowledge base than in-person students. We also lack data that would allow us to determine OMSCS’ impact on
earnings and other labor market outcomes.


                                                           3
els of online education had involved highly-ranked institutions offering online degrees as costly
as their in-person equivalents, lower-ranked institutions offering inexpensive degrees with low
labor market returns (Deming et al., 2016), or free massive online open courses (MOOCs) with
unclear returns and very high attrition rates (Perna et al., 2013; Banerjee and Duflo, 2014). Because
OMSCS’ price-quality pairing had not been previously seen in online education, the New York
Times declared that this model meant “disruption may be approaching.”4 President Obama men-
tioned OMSCS in an August 2013 speech on college affordability and again in March 2015 while
visiting Georgia Tech, describing the program as a model for “innovative ways to increase value”
in higher education.5
      Features of OMSCS made possible only by online technology appear central to demand for this
educational option. We surveyed OMSCS applicants about the program features that were most
important in their decision to apply. The four most important options all related to geographic
and temporal flexibility: the lack of need to commute or relocate, the flexibility of coursework and
time commitments, and general convenience. We view this extreme flexibility as unique to online
education. Asynchronous online education allows students to learn material and complete as-
signments on a schedule they can customize around their family- and job-related time constraints.
Distance learning allows students to access education without the need to commute or relocate
themselves or their families. Many applicants also valued OMSCS’s low cost, though fewer than
valued its flexibility. While lower costs are not a feature of all online education, economies of scale
allow online classes to cost less per student. Unlimited by geography, scheduling, or classroom
size, online classes can be much larger than in-person classes. Moreover, while there are large up-
front costs of creating online content, such content can be reused so that cost is spread over even
more students.
      Online models combining a low cost with a credential from a highly-ranked university appear
to be growing in importance. In spring of 2016, inspired in part by OMSCS, the University of
Illinois at Urbana-Champaign (UIUC) began enrolling students in its “iMBA” program, a fully
online version of its highly-regarded MBA. The degree costs about $22,000, roughly one-third the
cost of the in-person MBA offered by UIUC and similarly-ranked institutions. UIUC also has a
new an online master’s program in data science that will cost just over $19,000. Yale University is
currently developing a fully online version of its Master of Medical Science degree for physician
assistants. In the fall of 2016, over a dozen highly ranked universities affiliated with the EdX
consortium started by Harvard and MIT announced plans to offer micro-master’s degrees. Such
degrees will be open to any student willing to pay a total of roughly $1,000 for exam proctoring
at the end of each course and will consist of between one-quarter and one-half of the courses in a
traditional version of each degree. Examples of such degrees include supply chain management
  4
    T. Lewin (2013), “Master’s Degree Is New Frontier of Study Online” New York Times, August 17.
  5
    B. Obama (2015), “Remarks by the President Announcing Student Aid Bill of Rights.” March 10
https://www.whitehouse.gov/the-press-office/2015/03/10/remarks-president-announcing-student-aid-bill-rights.


                                                     4
from MIT, artificial intelligence from Columbia University, and social work from the University of
Michigan at Ann Arbor.6 That more highly-ranked institutions appear to be entering the market
for inexpensive online degrees suggests our results may be increasingly relevant to the future of
online education.
          The remainder of the paper proceeds as follows. In Section 2, we describe the OMSCS pro-
gram in more detail, the available data, and our survey, while in Section 3 we present descriptive
statistics on applicants to the in-person and online programs. We present regression discontinuity
estimates of the impact of access to online education on formal and informal enrollment in Section
4. Finally, Section 5, we discuss the implications of our findings. We argue that the single program
studied here will likely increase the number of Americans earning computer science master’s de-
grees by about seven percent. We also discuss the external validity of these findings, as well as
concerns about the quality of education delivered by the online program.


2          Context and Data
2.1         The OMSCS Degree Program

OMSCS courses are offered through a platform designed by Udacity, one of the largest providers
of massive open online courses.7 To earn their degree, OMSCS students must complete 10 courses,
specializing in either computational perception and robotics, computing systems, interactive in-
telligence, or machine learning. Students who have taken two foundational courses can take up
to three classes per semester, while other students can take only two at a time. The typical stu-
dent takes one or two courses each semester, so that expected time to graduation is six to seven
semesters, which can include summer terms. In order to maintain educational quality, the online
courses use similar assignments and grading standards as their in-person counterparts. Consis-
tent with the OMSCS degree being at least nominally equivalent to the in-person degree, OMSCS
is accredited because the accreditor considers it equivalent to the in-person program.
          Though deadlines for submitting assignments are the same as the in-person courses, one major
difference is that all lecture-watching and other learning experiences are asynchronous, meaning
that there is no fixed time during which a student must be online. All content is posted at the
start of the semester so that students may proceed at a pace of their choosing. Students sched-
ule their exams within a specified window and are monitored to guard against cheating. Most
interaction happens in online forums where students post questions and receive answers from fel-
low students, teaching assistants, or faculty members. Faculty members interact with students in
online office hours, though online forums are typically run by the head teaching assistant. Feed-
      6
          J. Young (2016), “Online Micro-Master’s Programs Extend Their Reach” Chronicle of Higher Education, September
20.
      7
    To create the OMSCS program, Georgia Tech partnered with Udacity and AT&T, the latter of which provided start-
up funding.


                                                             5
back on assignments comes from teaching assistants, many of whom are current MSCS or OMSCS
students and each of whom serves approximately 50 students.8
       AT&T provided roughly $4,000,000 in start-up funds to supplement GA Tech’s own initial in-
vestment. Much of that funded production of the roughly 30 courses OMSCS offers, each of which
initially cost about $300,000 to produce, though production costs have since dropped to under
$200,000. Such costs reflect the fact that OMSCS does not record and re-broadcast in-person lec-
tures as some online courses do, but instead produces original videos and other materials for each
course. Individual faculty members are paid $20,000 for initially creating a course and $10,000
each time they teach the course, which many of them continue to do. In 2015, OMSCS had net
revenues of about $2,000,000 and by fall 2016 had returned the Computer Science Department’s
initial investment in the program.
       To make OMSCS accessible to a wider range of applicants than its in-person counterpart, its
admissions website describes as “preferred qualifications” having a B.A. in computer science or a
related field with an undergraduate GPA of 3.0 or higher.9 Such qualifications do not guarantee
admission and, as the website notes, “applicants who do not meet these criteria will be evaluated
on a case-by-case basis.” The admissions website to the in-person program describes a GPA of
3.0 as a “desirable minimum” and notes that “most candidates score higher.” MSCS also requires
submission of GRE scores, which OMSCS does not. Whereas MSCS has one cohort of applicants
each year who apply to start in the fall, OMSCS has two applicant cohorts each year as students
can begin their coursework in either the fall or the spring. The first OMSCS enrollees began their
coursework in the spring of 2014.


2.2      Data

We have data from Georgia Tech’s Computer Science Department on all applicants to OMSCS’s
first six cohorts, who started their courses in spring 2014, fall 2014, spring 2015, fall 2015, spring
2016, and fall 2016. We also have data on four cohorts of applicants to MSCS, those applying to
start classes in each fall from 2013 through 2016. For each applicant, we have basic self-reported
demographic information including age, gender, race/ethnicity, and citizenship. Applicants also
report their postsecondary educational history, including the name of each college attended, their
GPA at that college, and the field and type of any degree earned. Applicants report the name of
their employer if employed at the time of application. We also observe whether a given applicant
was ever admitted to or enrolled in OMSCS or MSCS.
   8
      One teaching assistant is not human. Professor Ashok Goel, who teaches a course entitled “Knowledge Based Arti-
ficial Intelligence,” created a virtual teaching assistant named Jill, based on artificial intelligence technologies adapted
from IBM’s Watson platform. Jill regularly answered students’ questions and was only revealed to them as virtual late
in the semester.
    9
      As we describe below, our regression discontinuity analysis uses a different GPA cutoff that affected the probability
of admission but was unknown to applicants.




                                                             6
         We merge all applicants’ data to the National Student Clearinghouse (NSC), an organization
that tracks enrollment at post-secondary institutions throughout the United States. The NSC iden-
tifies which, if any, institution a student is enrolled in at any moment in time, allowing us to track
the educational trajectories of students who enroll in Georgia Tech and other institutions.10 NSC
coverage rates for undergraduates in Georgia are around 95 percent and generally above 90 per-
cent in other states (Dynarski et al., 2015). Though less is known about graduate student coverage
rates, we show that a very high fraction of MSCS applicants are observed enrolling in institutions
other than Georgia Tech, suggesting widespread coverage of master’s degree students. Impor-
tantly, we do observe many for-profit and nonprofit institutions that primarily offer online course-
work, such as the University of Phoenix and Western Governor’s University. We supplement this
with data from the National Science Foundation on the full population of students earning com-
puter science master’s degrees in the United States in 2013, the most recent year available.
         Because the NSC data contain information only on enrollment in formal higher education
degree programs, we conducted an online survey on other forms of training that would not be
captured by such data. The survey was sent in July 2017 by e-mail to all spring 2014 OMSCS
applicants, asking them about their experiences from the time they first applied to OMSCS. Re-
spondents were asked whether, since January 2014, they had participated in any form of training
in computing or computer science that was not part of a formal graduate degree program and,
if so, how many hours they had spent on such training. They were given the option to indicate
participation in professional certification programs (such as Microsoft Certifications), coding boot
camps (such as General Assembly), massive online open courses, and other forms of training
that they could specify. Respondents indicating they were employed in January 2014 were asked
whether that employer would have been willing to subsidize participation in OMSCS, other grad-
uate degree programs, and training not leading to a graduate degree. Finally, respondents were
asked to indicate how important various OMSCS characteristics were in their decision to apply.11


3         Descriptive Comparison of Applicant Pools
To document where demand for OMSCS comes from, we describe the characteristics of the OM-
SCS applicant pool and compare them to the characteristics of the MSCS applicant pool. Because
both programs culminate in the same nominal degree, we view such a comparison as controlling
for the degree sought. As such, we argue that differences in the applicant pools between these
programs are largely due to differences in the programs’ costs and methods of curriculum deliv-
ery.
         Demand for the online program is large, as seen in panel A of Table 1. OMSCS attracts over
3,400 applicants annually, about twice as many as its in-person equivalent. This is not due simply
    10
         Though the NSC also records degree completion, it is too early to measure this.
    11
         For specific wording of the survey questions, see Appendix A.


                                                               7
to large pent-up demand, as the most recent applicant cohort is larger than all but the first cohort,
which contained many AT&T employees.12 OMSCS admits 61 percent of those applicants, almost
five times the 13 percent admission rate for the in-person program. OMSCS is thus less selective
and more open than its in-person counterpart, as program designers intended.
       Eighty percent of those admitted to the online program enroll, so that each year nearly 1,700
students begin a computer science master’s degree through OMSCS, more than 10 times as many
who begin a degree through MSCS. This makes OMSCS the largest computer science master’s
degree program in the United States, and possibly the world. By way of comparison, the NSF
estimates that U.S. institutions issued about 21,000 computer science master’s degrees in 2013. If
all OMSCS enrollees were to complete their degrees, OMSCS would be responsible for the pro-
duction of eight percent of all computer science master’s degrees in the country. The nearly 1,200
annual American enrollees in OMSCS would represent over ten percent of all Americans earning
such degrees.
       Two descriptive facts suggest that demand for the online program comes from a different pop-
ulation than demand for the in-person program. First, in our data, fewer than 0.2 percent of the
nearly 18,000 applicants to either program applied to both programs, suggesting that students
view these programs as distinct educational products. Second, as panel B in Table 1 shows, the
applicant pools to the two programs look very different, particularly in terms of nationality and
age.13
       The online program attracts a much more American demographic than does the in-person
program. About 70 percent of the online applicants are U.S. citizens, compared to 8 percent of
in-person applicants. Figure 1 shows the distribution of citizenship across the two pools. The
vast majority of in-person applicants are citizens of India (nearly 70 percent) or China (nearly 20
percent). After admissions and enrollment decisions, the fraction of in-person enrollees who are
U.S. citizens rises to 26 percent. Even so, over half of that student body are Indian or Chinese citi-
zens. Panel B shows that fewer than 10 percent of applicants to the online program are Indian or
Chinese citizens, proportions that do not change substantially with admissions and enrollment de-
cisions. That international applicants show stronger demand for the in-person program suggests
such students may value the opportunity to be physically present in the U.S., which admission
to an online program does not grant.14 That over 70 percent of online program enrollees are U.S.
citizens makes that pool substantially more American than the national pool of those completing
computer science master’s degrees, of whom 52 percent are U.S. citizens.
       The online program attracts a substantially older demographic than does the in-person pro-
  12
     See columns 1-6 of Table A.1.
  13
     Table A.1 shows the characteristics of individual cohorts of applicants. None of the demographic facts highlighted
here change substantially over the observed time period.
  14
     Low international awareness of OMSCS’ existence may explain a small portion of their proportionally stronger
demand for the in-person program, as Table A.1 shows that the international composition of the applicant pool has
very slowly increased over time, perhaps because such awareness has increased.


                                                          8
gram. Online applicants are on average 34 years old, compared to an average age of 24 for in-
person applicants. Figure 2 shows the age distribution of applicants to the two programs. Over 75
percent of in-person applicants are 25 years old or younger and over 95 percent are 30 or younger.
Nearly no one older than 30 applies to the in-person program. The opposite is true of the online
program. Only 10 percent of online applicants are 25 or younger and fewer than 30 percent are
between 25 and 30. The majority of applicants are over 30 years old, with substantial representa-
tion of those in their 40s and 50s. This remains true if the sample is limited to those admitted or to
those who enroll.
    Whereas the in-person program attracts applicants straight out of college or early in their ca-
reers, the online program attracts an older population largely in the middle of their careers. Nearly
ninety percent of online applicants list a current employer, relative to under 50 percent of in-person
applicants.15 Table 2 shows more detail about online applicants’ employment, listing the top 25
employers represented in their applications. Because of its corporate sponsorship of the develop-
ment of OMSCS, AT&T is by far the largest such employer.16 Well-represented in the list are tech-
nology giants (Microsoft, Google, Amazon, Apple), military branches (Air Force, Army, Navy),
defense contractors (Lockheed Martin, Raytheon, Northrop Grumman, Boeing), and financial and
consulting firms (Bank of America, Accenture). Such firms, with more than 25 employees apply-
ing to OMSCS, comprise less than one-fourth of the applicant pool. Firms with 2 to 25 applicants
comprise one-fifth of the applicant pool. Remarkably, nearly half of applicants to OMSCS appear
to be the only employee from their firms applying to the program, suggesting that demand for
such training is widespread and not simply concentrated among a few large firms.
    The online and in-person applicant and enrollee pools look fairly similar in terms of gender
and race, particularly when the sample is limited to U.S. citizens. Only 13 percent of U.S. cit-
izen online applicants are female, a proportion quite similar to the percentage in the in-person
program.17 Among U.S. citizens, the online applicant pool is 64 percent white, 17 percent black
or Hispanic, and 15 percent Asian, proportions roughly similar to the in-person applicant pool.
There is little evidence of differential gender or racial diversity by program type. Other forms of
diversity, such as socioeconomic status and academic skill, are hard to evaluate because our appli-
cation data contain no information on family background and no objective measures of academic
skill that are comparable across the two applicants pools.18
    We can, however, use characteristics of applicants’ undergraduate institutions as proxies for
applicants’ family backgrounds and academic skills. To do so, we use data from the Integrated
  15
     Employment information is missing for the 2013 MSCS applicants, so the 50 percent figure is based on 2014-16
MSCS applicants.
  16
     As seen in Table A.1, this is driven largely by the first cohort of applicants, of whom 23 percent were from AT&T.
That proportion drops to fewer than 10 percent in subsequent cohorts. None of the demographic facts discussed here
change meaningfully when AT&T employees are removed from the sample.
  17
     Among all applicants, the in-person program has a higher proportion of female applicants due to the fact that
Indian and Chinese applicants are more likely to be female than are American applicants.
  18
     Unlike the in-person program, the online program does not require applicants to submit GRE scores.


                                                          9
Postsecondary Education Data System (IPEDS) to characterize applicants by the U.S. colleges they
attended.19 Table 3 shows clear differences across the two applicant pools. Online applicants come
from colleges where the average student’s SAT math score is 30 points, or about 0.2 standard devi-
ations, lower than students from in-person applicants’ colleges. Online applicants’ colleges have
a higher proportion of low income students, as well as a substantially lower six-year graduation
rate. Differences among admitted students and enrollees are of similar magnitude. This suggests
that the online program attracts applicants who are from more economically disadvantaged back-
grounds and who are academically weaker on average than their in-person counterparts. Online
applicants also have a more diverse set of college majors, as they are much less likely than in-
person applicants to have majored in computer science. Instead, they are more likely to have
majored in engineering, mathematics, physical sciences, and even social sciences and humanities.
    Our online survey of spring 2014 OMSCS applicants reveals preferences consistent with the
appeal of online education to those whose jobs, families or residential situations do not allow for
enrollment in traditional programs. Table 4 shows the survey had a 38 percent response rate.20 The
survey, presented in Appendix A, listed a number of features of the OMSCS program. For each,
respondents were asked to rate its importance in their decision to apply to OMSCS. Panel B lists
program characteristics in descending order of the fraction of respondents describing the given
characteristic as “extremely important.” The top four characteristics all relate to the geographic or
temporal flexibility that an asynchronous, fully online program provides, with 69 percent valuing
the lack of need to commute or relocate to attend and 65 percent valuing the program’s flexible
time commitments.21 The cost and Georgia Tech’s reputation are the next most valued charac-
teristics, with 53 percent of respondents citing them as extremely important and 85 to 90 percent
citing them as important or extremely important. Skill development was cited as extremely im-
portant by just under half of applicants, while only 19 percent of applicants appear to have valued
professional networks the program might impart.
    Panel C shows that 63 percent said their employer would subsidize OMSCS and a nearly iden-
tical proportion would have subsidized other degrees or non-degree training, suggesting differen-
tial employer-based support of OMSCS can not explain its appeal relative to other options. Older
workers’ employers are 12-15 percentage points more likely to subsidize training, the only sub-
   19
      We use IPEDS data from 2005, roughly the average year of college graduation for online applicants. Our results are
not sensitive to this choice given how slowly college characteristics change over time. We are able to link 67 percent of
OMSCS applicants and 11 percent of MSCS applicants to colleges in IPEDS. For both programs, we can link 88 percent
of U.S. citizen applicants to their colleges.
   20
      As shown in Table A.2, survey respondents and non-respondents are quite similar in terms of gender, country of
residence and college major. Respondents were more likely to be white, were slightly older and were slightly more
likely to be employed than non-respondents. Respondents overwhelmingly report having been employed in January
2014 (91 percent), at a rate that nearly identical to that reported on the official applications. As Figure A.1 shows,
applicants with GPAs just above the admissions threshold were insignificantly slightly more likely to respond than
those with GPAs just below the threshold.
   21
      If we consider the fraction of respondents indicating a characteristic was important or extremely important in their
decision to apply, the top four characteristics are the same, with over 90% choosing each.


                                                           10
stantial survey difference by applicant age.22
    Participating in non-degree training is common among OMSCS applicants but the number of
hours they spend doing such training is dwarfed by the hours spent in formal degree-based pro-
grams. Panel D of Table 4 shows that 72 percent of respondents report having participated in some
type of non-degree training between January 2014, when they applied to OMSCS, and July 2017,
when the survey was administered. Respondents report having spent an average of 111 hours
in such non-degree training over three and a half years, half of which comes from MOOCs.23 To
compare this to time spent in formal graduate degree programs, we use the NSC data to compute
the number of semesters during which respondents were formally enrolled, assume that each
semester is 13 weeks long, and take as our best estimate of time spent OMSCS’ suggestion that the
typical student will “spend roughly 18 hours per week on coursework.”24 Doing so shows that
the average respondent spent nearly 800 hours on degree-based programs, so that non-degree
training represents only 12 percent of the total time spent on training.
    The descriptive comparison of the two applicant pools thus provides three pieces of evidence
that together are consistent with the possibility that OMSCS represents a new educational product
for which there is currently no close substitute in the higher education market. First, though
the two programs culminate in the same degree, there is nearly no overlap in the populations
interested in these educational options. The typical applicant to the in-person program is a 24-
year old recent college graduate from India, whereas the typical applicant to the online program
is a 34-year old currently-employed American. Second, demand from Americans for the online
version of the program is large, with well over 10 times more American applicants to OMSCS
than to MSCS. Third, eighty percent of those admitted to the online program accept those offers
and enroll, suggesting that relatively few such admits find alternative higher education options
compelling. Survey evidence suggests both that the flexibility enabled by online technology is
central to OMSCS’ appeal and that non-degree training, though common, occupies much less of
applicants’ time than does formal graduate education. Large demand for OMSCS from a mid-
career population uninterested in its in-person equivalent and the high enrollment rate among
admits both suggest that OMSCS provides an educational pathway for which there has previously
been no compelling, competing alternative. To strengthen the case for this argument, we turn to
a second empirical strategy that focuses on causal inference and complements the descriptive
analysis above.
   22
      That older applicants’ employers are more willing to subsidize training is fully statistically explained by the fact
that older workers have larger employers. Controlling for the number of applicants from a given employer largely
eliminates the raw difference observed by age in panel C.
   23
      Over one-fourth of the non-degree training hours come from “other” experience. Of respondents who listed specific
experiences, most appeared to be referring to informal coursework or certification.
   24
      This number is taken from OMSCS’ FAQ, accessed on August 10, 2017 at http://www.omscs.gatech.edu/
prospective-students/faq. We use OMSCS’ figure because, as we show below, few applicants enroll anywhere
other than OMSCS.




                                                           11
4     The Impact of Online Access on Educational Trajectories
4.1     Regression Discontinuity Design

Our goal is to determine whether the existence of an online option alters applicants’ educational
trajectories. If not for access to such an option, would its applicants pursue other educational op-
tions? Or does the online option lack close substitutes in the current higher education market? The
difficulty in answering this question is that applicants admitted to OMSCS are generally academ-
ically stronger than and differ along other dimensions from those denied admission. Comparing
the subsequent educational trajectories of these two groups of students would confound the im-
pact of online access with the impact of underlying academic skills and other characteristics.
      We solve this problem by identifying an exogenous source of variation in the probability that
an applicant had access to the online option. In particular, though OMSCS admitted a wider
range of students in later cohorts, the program decided to somewhat constrain the number of
students admitted to the very first cohort in spring 2014. OMSCS did this to ensure that any
challenges inherent in starting a new program would not be compounded by an overly large
enrollment total. The chief admissions officer therefore read applications in descending order of
undergraduate GPA and offered immediate admission only to the first 500 or so applications he
read that he deemed admissible. As a result, only applicants with an undergraduate GPA of 3.26
or higher were eligible for admission in spring 2014.
      The admissions officer ultimately read all applications and some students both below and
above the 3.26 threshold were made offers of deferred admission. Such students were allowed to
enroll in summer 2014, fall 2014 or spring 2015. The admissions data we have can not distinguish
between students made offers of admission for spring 2014 and those who were offered deferred
admission. We therefore measure enrollment outcomes as of fall 2016, well beyond the point at
which all spring 2014 applicants would have had to enroll if admitted or would have had time
to apply to and enroll in other institutions if rejected. We focus on the probability that a given
student received any admission offer, regardless of its timing.
      The GPA threshold thus represents an exogenous source of variation in whether a given stu-
dent was offered admission to OMSCS. We use the threshold to implement a regression disconti-
nuity design (RD) that compares the educational trajectories of applicants just above and below
that threshold. Such students should be nearly identical in terms of academic skills, as measured
by GPA, as well as other characteristics. They should differ only in their access to the online
option. We estimate the impact of having a GPA above the admissions threshold on enrollment
outcomes of the first applicant cohort through the following baseline specification:

              Enrolledi = β0 + β1 Admissiblei + β2 GP Ai + β3 Admissiblei × GP Ai + i .         (1)

      Here, Enrolled indicates enrollment status in OMSCS or other programs for applicant i, Admissible

                                                 12
indicates the applicant is above the GPA threshold and GP A measures his distance from that
threshold in GPA points. In this local linear regression, the two GPA variables model the relation-
ship between GPA and college outcomes as linear, with the interaction term allowing that slope to
vary on either side of the threshold. The coefficient on Admissible thus measures the difference in
OMSCS enrollment probability between applicants just above and just below that threshold. This
specification generates intent-to-treat estimates of the impact of increased access to OMSCS.
   Using the same basic specification, we also generate instrumental variables estimates of the
impact of admission on enrollment, where admission is instrumented with having an immediately
admissible GPA. Specifically, we estimate the first stage equation

           Admittedi = α0 + α1 Admissiblei + α2 GP Ai + α3 Admissiblei × GP Ai + i .            (2)

where Admitted indicates eventual admission to OMSCS. We then use predicted values of Admitted
to estimate a second stage of the form

                                   d i + γ2 GP Ai + γ3 Admissiblei × GP Ai + i .
             Enrolledi = γ0 + γ1 Admitted                                                        (3)

This yields estimates of the impact of OMSCS admission on enrollment choices for compliers at the
margin, namely those students for whom the threshold itself altered their probability of eventual
admission. We think of this as a matriculation rate for such applicants.
   Following Lee and Card (2008), our baseline specifications for all of these estimates cluster
standard errors by distance from the GPA threshold because GPA is a fairly discrete variable, with
many students reporting values that are multiples of 0.1 or 0.25. To improve precision, we include
demographic controls for gender, race/ethnicity, citizenship, age, employment and college major.
Optimal bandwidths, as suggested both by Imbens and Kalyanaraman (2012) and Calonico et al.
(2014), are between 0.3 and 0.5 GPA points for all outcomes. We treat 0.5 GPA points as our default
bandwidth but show that our results are robust to use of smaller and larger bandwidths, as well
as to exclusion of demographic controls.
   Validity of our RD estimates requires that students not systematically manipulate which side
of the GPA threshold they fall on. Though they do self-report GPAs, two facts suggest little scope
for manipulation. First, applicants were required to submit transcripts and thus knew that their
self-reported GPAs might be checked against officially reported ones. Second, applicants had no
knowledge that a GPA of 3.26 would play any role in the admissions process, a fact that was
decided only after all applications had been submitted. The only GPA criterion publicized was
that a GPA of 3.0 or higher was preferred, though applicants with lower GPAs could be admitted.
It thus seems highly unlikely that there could be differential sorting across the 3.26 threshold. We
confirm this in two ways.
   First, as suggested by McCrary (2008), we show in Figure A.2 that the density of students just


                                                13
above the threshold looks similar to the density just below. Multiples of 0.1, as well as 3.0 and 4.0,
are particularly common, but there is no clear difference in the distribution of GPAs around the el-
igibility threshold. Formal tests show no evidence that GPAs just above 3.26 are over-represented
relative to GPAs just below 3.26, suggesting no obvious manipulation by students. Second, we
confirm that observable covariates are balanced across the threshold by running the specification
in Equation 1 using such covariates as outcomes. Table A.3 shows the results of these covariate
balance tests, using a variety of bandwidths. There is no practically or statistically significant
evidence of differential sorting across the threshold in terms of gender, race, citizenship, age, em-
ployment, or college major. The balance of density and covariates at the threshold suggest that
students on either side of the threshold are similar along both observed and unobservable dimen-
sions. Our regression discontinuity coefficients should therefore provide unbiased estimates of
the impact of online access on educational trajectories.


4.2      Causal Estimates

We first document how the GPA threshold affected the probability of admission to OMSCS. The re-
lationship between GPA and the probability of being offered admission, seen in Panel A of Figure
3, shows a clear discontinuity. The first stage estimates in column 1 of Table 5 suggest that those
just above the GPA threshold were about 20 percentage points more likely to be admitted to the
online program than their counterparts with slightly lower GPAs. This difference represents the
extent to which the GPA threshold generated exogenous variation in access to the online option.
       Importantly, access to the online program generates enrollment in that program. We define
OMSCS enrollment as a student having enrolled in at least one semester by fall 2016.25 At that
point, all immediate and deferred admissions offers would have expired, and applicants would
have had the opportunity to apply to and enroll in other, competing degree programs. Panel B of
Figure 3 shows the fraction of applicants who ever enrolled in OMSCS. The graphical evidence, as
well as the estimates in column 2 of Table 5, suggest that threshold-based admissibility increases
enrollment in the online option by slightly more than 20 percentage points. This implies that
roughly all of the marginal applicants admitted because of the GPA threshold accepted the offer
of admission and enrolled. Instrumental variables estimates, shown in column 3, confirm that the
matriculation rate of such students is close in magnitude and statistically indistinguishable from
100 percent. These applicants appear not to have competing options that would cause them to
decline their admissions offer.
       Importantly, though admission affects enrollment, admission timing does not appear to. Fig-
ure A.4 shows OMSCS enrollment rates as a function of GPA, for the sub-sample of applicants
  25
    The relationship between spring 2014 enrollment and GPA in Figure A.3 is consistent with the requirement of a
GPA of at least 3.26 for immediate admission. Only four applicants below the GPA threshold appear to have enrolled
in OMSCS in spring 2014.



                                                       14
offered admission. Those above the threshold were largely given immediate offers and those be-
low deferred offers, yet at the threshold there is no clear difference in the probability of enrolling in
OMSCS, conditional on admission. The point estimate of the discontinuity is close to zero and sta-
tistically insignificant whether we use our default bandwidth of 0.5 or the Imbens-Kalyanaraman
optimal bandwith of 0.3.
   Examination of enrollment in other programs confirms that OMSCS has no close substitutes.
Panel A of Figure 4 shows the fraction of OMSCS applicants who enrolled in other, non-OMSCS
programs by fall 2016. We include any non-OMSCS degree program, regardless of field of study.
The overall levels of such enrollment are quite low, with fewer than 20 percent of those just below
the threshold enrolling elsewhere. The few alternatives chosen by such applicants are rarely the
more prestigious competitors of MSCS, such as Carnegie Mellon or University of Southern Califor-
nia, but are instead lower-ranked online programs from institutions such as DeVry University or
Arizona State University. This is in contrast to MSCS applicants, many hundreds of whom choose
those prestigious competitors over Georgia Tech. Panel B shows that over 50 percent of MSCS
applicants enroll in alternative U.S. programs, a fraction that rises to 65 percent when considering
just U.S. applicants to the in-person program. Those interested in the online program appear to
have fewer competing alternatives than those interested in the in-person program.
   In addition to the low overall rate of online program applicants enrolling in alternatives to
OMSCS, there is also no visually apparent discontinuity in non-OMSCS enrollment, with columns
4 and 5 of Table 5 showing statistically insignificant point estimates close to zero. If access to
OMSCS were substituting for other in-person programs, we would expect to see a clear drop in
enrollment elsewhere to the right of the GPA threshold. Though our regression discontinuity
estimates are generated by those at a particular point in the GPA distribution, it is worth noting
that those with much higher or lower GPAs also do not appear to enroll in non-OMSCS options.
This suggests the market is not providing appealing alternatives for a wide range of students for
whom OMSCS is appealing. In contrast, most MSCS applicants with lower and higher GPAs find
suitable alternatives in which to enroll.
   Access to the online option therefore increases the number of people pursuing education at
all. We see this in Figure 5, which shows the fraction of applicants enrolling in any formal higher
education. There is a large, clear discontinuity at the admissions threshold, with estimates from
column 6 of Table 5 suggesting that admissibility to the online program increases enrollment in
formal higher education by about 20 percentage points. The instrumental variables estimates in
column 7 imply that roughly 100 percent of the marginal admits to OMSCS represent new entrants
into formal higher education. Access to this online option thus increases the number of people
pursuing education.
   We perform a number of robustness checks to confirm that our estimates are not sensitive
to our specification choices. The first two rows of Table 5 show that inclusion of demographic



                                                   15
controls improves the precision of our estimates, but does not meaningfully alter their magnitude.
The remaining rows of the table show that our point estimates are robust to a fairly wide set of
bandwidths, including those close to the optimal bandwidths mentioned previously. To check
that our estimated discontinuities in admission, OMSCS enrollment and overall enrollment are
not driven by spurious features of the data, we test for placebo discontinuities by running our
baseline regression specification placing the admissions threshold at GPA values other than 3.26.
The resulting coefficients are shown in panel A of Figures A.5, A.6 and A.7. In all cases, the
actual threshold of 3.26 generates the largest discontinuity and the only one that is positive and
statistically significant.
      One other potential concern is that the location of the threshold was endogenous to the qual-
ity of the applicant pool in that part of the GPA distribution. If students with a 3.26 GPA were
of particularly high quality and thus ended the admissions process by using up the program’s
final capacity, then our estimates might be biased by correlations between such quality and en-
rollment decisions. To test whether such endogenous threshold location is generating bias, panel
B of Figures A.5, A.6 and A.7 show estimated discontinuities from donut hole RD specifications
that exclude observations close to the threshold. The resulting coefficients are, if anything, slightly
larger, suggesting that our estimates are not driven by observations very close to the threshold.
      As a final check, we explore heterogeneity in enrollment impacts of online access in Table 6.
Limiting the sample to non-AT&T employees has little effect on our point estimates, suggesting
that our results are not driven by this potentially unusual subset of applicants. Limiting the sam-
ple to U.S. citizens has similarly little effect. Subsequent rows separate the sample by age, gender
and race. The main takeaway from these estimates is that there is no subgroup of applicants for
whom access to OMSCS substitutes for enrollment in other formal degree programs. None of
the point estimates in columns 4 and 5 are significantly negative. The result is that, for all sub-
groups for whom the threshold clearly generates variation in access to OMSCS, such access clearly
increases overall enrollment in higher education.


4.3     Non-Degree Training

Having shown that OMSCS does not substitute for enrollment in other graduate degree programs,
we use the survey to explore how it affects informal training. The first column of Table 7 shows
the impact of passing the admissions threshold on the survey response rate, while Figure A.1 plots
the response rate by GPA. Although both suggest that students with GPAs above the admissions
threshold have higher response rates, these differences are small and insignificant, suggesting that
selection into the survey sample is unlikely to generate substantial bias.
      Table 7 utilizes the regression discontinuity design to determine the impact of access to OMSCS
on informal training. There is no evidence that access to OMSCS reduces hours spent on non-
degree training. Our point estimates, while small and insignificant, suggest that access to OMSCS


                                                  16
actually increases informal education, with some specifications showing OMSCS admissibility
causes marginally significant increases in time spent on professional certification programs and
coding boot camps. Figure 6 graphically depicts our results for all types of non-degree training
combined, while Figure A.8 shows the results for different types of training separately.
    Table 7, Column 7 shows that, unsurprisingly, admission to OMSCS substantially increases
the number of hours spent on degree-based training. These estimates use the assumption that
students spend 18 hours per week on classwork each semester that they are enrolled in a degree
program (Georgia Tech’s estimate for the workload in OMSCS). Under this assumption, we find
that admission to OMSCS increases degree training by 1400-1900 hours over the three and a half
year period in question. Because the number of hours spent on non-degree training is so small
relative to degree training, estimated impacts of OMSCS admission on total training hours are
similar to those spent on degree training. Figure 7 shows the jump in total hours of training at
the admission threshold graphically, while Table A.4 explores the robustness of these results to
different assumptions about the hours spent in different types of degree training. Regardless of
the assumption we make, we find that access to OMSCS has a large and significant impact on total
training.


5   Discussion and Conclusion
Our descriptive evidence shows large demand for the first low-cost online degree offered by a
highly-ranked institution. Applicant pools to the online and in-person versions of this degree
program show almost no overlap in individuals or in demographic characteristics. Unlike its
in-person equivalent, the online option generates demand largely from mid-career Americans.
Large demand from older, employed individuals is consistent with the idea that the geographic
and temporal flexibility of the online option are critical to its appeal. Online education can provide
mid-career training without forcing individuals to quit their jobs or move to locations with appro-
priate educational institutions. Relatively low demand for the online option from non-Americans
is consistent with the value of in-person programs stemming at least partially from physical access
to U.S. social networks and labor markets.
    Our causal evidence shows that this online option expands access to education and does not
substitute for other informal training. Eighty percent of those accepted by OMSCS enroll. The vast
majority of applicants denied access do not pursue any form of further formal education. Most
importantly, gaining access to the online option does not decrease the extent to which students
enroll in other educational programs or non-degree training. This is the first rigorous evidence
that we know of showing an online degree program can increase educational attainment, implying
that the higher education market had previously been failing to meet demand for this particular
bundle of program characteristics.


                                                 17
       This model of online education thus has the potential to substantially increase the national
stock of computer science human capital. OMSCS enrolls about 1,170 Americans annually. Though
it is too early to measure completion rates, NSC data on the 2014 OMSCS enrollees suggest that
at least 62 percent are still enrolled at least two years after they begin the program and thus ap-
parently on track to graduate. The actual fraction who will graduate may be substantially higher
than that, given that the flexible nature of the program and mid-career students’ busy professional
and family lives makes persistence somewhat difficult to measure. For example, over 25 percent
of students who take a fall or spring semester off appear to re-enroll in the subsequent spring or
fall semester. Persistence to graduation could therefore be as high as 90 percent.26 Conservatively,
if only 62 percent of enrollees graduate, OMSCS will annually produce about 725 American com-
puter science master’s degree recipients. According to IPEDS’ Completion Survey, about 11,000
American citizens earned a master’s degree in computer science in 2013, the most recent year
data is available. This implies that OMSCS will generate a seven percent increase in the national
production of such degrees. If 90 percent of enrollees graduate, OMSCS will increase such produc-
tion by 10 percent. Either way, the program will produce a substantial fraction of such computer
science human capital.
       We conclude with two questions raised by this research. The first concerns external validity.
To what extent will the conclusions drawn from this particular online program apply to other
populations and subjects? It seems likely, for example, that mid-career training in other fields
might be amenable to this model. For example, the University of Illinois’ modeling of two degrees
on OMSCS (an MBA and a data science master’s) and the recent rise of “micro-master’s” programs
suggests that other institutions believe there are untapped markets in such training. Whether
such low-cost, high-quality models can make inroads in undergraduate or secondary education
remains to be seen.
       The second question concerns the quality of the education that this online option provides.
How large are the learning and labor market impacts of this online degree and how do they com-
pare to that of the in-person equivalent? Comparing the undergraduate colleges attended by
OMSCS and MSCS students suggests that OMSCS students are, on average, somewhat weaker
academically than their in-person counterparts. Nonetheless, comparisons of student achieve-
ment across the online and in-person formats suggests that OMSCS students finish their courses
with at least as much knowledge as their in-person counterparts (Goel and Joyner, 2016). We
hope to explore in subsequent work the extent to which the OMSCS degree is valued by the labor
market and whether and how it affects career advancement. Whether the labor market perceives
OMSCS graduates as similar in quality to their in-person counterparts will have implications for
the impact of such models on the postsecondary sector more generally (Hoxby, 2014).



  26
       By comparison, about 95 percent of MSCS students graduate within two years.


                                                          18
References
Alpert, W. T., K. A. Couch, and O. R. Harmon (2016). A randomized assessment of online learning.
  American Economic Review 106(5), 378–82.

Banerjee, A. V. and E. Duflo (2014). (Dis) organization and success in an economics MOOC. The
  American Economic Review 104(5), 514–518.

Bettinger, E. P., L. Fox, S. Loeb, and E. S. Taylor (2017). Virtual classrooms: How online college
  courses affect student success. American Economic Review 107(9), 2855–75.

Bowen, W. G., M. M. Chingos, K. A. Lack, and T. I. Nygren (2014). Interactive learning online at
  public universities: Evidence from a six-campus randomized trial. Journal of Policy Analysis and
  Management 33(1), 94–111.

Calonico, S., M. D. Cattaneo, and R. Titiunik (2014). Robust nonparametric confidence intervals
  for regression-discontinuity designs. Econometrica 82(6), 2295–2326.

Deming, D. J., C. Goldin, L. F. Katz, and N. Yuchtman (2015). Can online learning bend the higher
 education cost curve? The American Economic Review 105(5), 496–501.

Deming, D. J., N. Yuchtman, A. Abulafi, C. Goldin, and L. F. Katz (2016). The value of post-
 secondary credentials in the labor market: An experimental study. The American Economic Re-
 view 106(3), 778–806.

Dynarski, S. M., S. W. Hemelt, and J. M. Hyman (2015). The missing manual: Using National
 Student Clearinghouse data to track postsecondary outcomes. Educational Evaluation and Policy
 Analysis 37(1 suppl), 53S–79S.

Figlio, D., M. Rush, and L. Yin (2013). Is it live or is it internet? Experimental estimates of the
  effects of online instruction on student learning. Journal of Labor Economics 31(4), 763–784.

Goel, A. and D. Joyner (2016). An experiment in teaching cognitive systems online. International
 Journal for Scholarship of Technology Enhanced Learning 1(1).

Hoxby, C. M. (2014). The economics of online postsecondary education: MOOCs, nonselective
 education, and highly selective education. The American Economic Review 104(5), 528–533.

Imbens, G. and K. Kalyanaraman (2012). Optimal bandwidth choice for the regression disconti-
  nuity estimator. The Review of economic studies 79(3), 933–959.

Joyce, T., S. Crockett, D. A. Jaeger, O. Altindag, and S. D. O’Connell (2015). Does classroom time
  matter? Economics of Education Review 46, 64–77.

Krieg, J. M. and S. E. Henson (2016). The educational impact of online learning: How do university
  students perform in subsequent courses? Education Finance and Policy 11(4), 426–448.

Lee, D. S. and D. Card (2008). Regression discontinuity inference with specification error. Journal
  of Econometrics 142(2), 655–674.



                                                19
McCrary, J. (2008). Manipulation of the running variable in the regression discontinuity design: A
 density test. Journal of Econometrics 142(2), 698–714.

McPherson, M. S. and L. S. Bacow (2015). Online higher education: Beyond the hype cycle. The
 Journal of Economic Perspectives 29(4), 135–153.

Perna, L., A. Ruby, R. Boruch, N. Wang, J. Scull, C. Evans, and S. Ahmad (2013). The life cycle of a
  million mooc users. In MOOC Research Initiative Conference, pp. 5–6.

Xu, D. and S. S. Jaggars (2014). Performance gaps between online and face-to-face courses: Differ-
  ences across types of students and academic subject areas. The Journal of Higher Education 85(5),
  633–659.




                                                20
                Figure 1: Citizenship of In-Person and Online Program Applicants




           80                (A) In-Person Program Applicants
                                                                             Applied
                                                                             Admitted
                                                                             Enrolled
           60
           40
           20
           0




                       USA               India           China             Other


                               (B) Online Program Applicants
           80




                                                                             Applied
                                                                             Admitted
                                                                             Enrolled
           60
           40
           20
           0




                       USA               India           China             Other


Notes: Panels A and B show the distribution of citizenship of applicants to the in-person and
online programs respectively. Panel A includes all 2013-16 in-person program applicants. Panel B
includes all 2014-16 online program applicants. From left to right, the three bars show the fraction
of applicants, admitted students, and enrolled students from each country.



                                                 21
               Figure 2: Age Distribution of In-Person and Online Program Applicants




                                (A) In-Person Program Applicants
                      .8
                      .6
           Fraction

                      .4
                      .2
                      0




                           20    25     30     35      40    45     50     55     60

                                                     Age



                                  (B) Online Program Applicants
                      .3
                      .2
           Fraction

                      .1
                      0




                           20    25     30     35      40    45     50     55     60

                                                     Age


Notes: Panels A and B show the age distribution of applicants to the in-person and online pro-
grams respectively. Panel A includes all 2013-16 in-person program applicants. Panel B includes
all 2014-16 online program applicants. The 75 applicants with ages below twenty or above sixty
are rounded to those values for this figure.



                                                22
                                         Figure 3: Access to and Enrollment in the Online Program




                                                          (A) Online Admission
                                    .8
                                    .7
           Admitted to OMSCS
                                    .6
                                    .5
                                    .4
                                    .3
                                    .2
                                    .1
                                    0




                                         2.5                          3.26                          4
                                                                      GPA


                                                          (B) Online Enrollment
                                    .8
                                    .7
           Ever Enrolled in OMSCS
                                    .6
                                    .5
                                    .4
                                    .3
                                    .2
                                    .1
                                    0




                                         2.5                          3.26                          4
                                                                      GPA


Notes: The above figure shows as a function of college GPA the fraction of spring 2014 online
program applicants who were admitted (panel A) and who enrolled in the online program by fall
2016 (panel B). The graph is limited to those with GPAs between 2.5 and 4.0. The dots shown
come from binning the data in intervals of 0.05 from the threshold, with dot size proportional to
the number of applicants in each bin. Also shown are fitted lines from a local linear regression
discontinuity model using a bandwidth of 0.5, so that not all points shown are used to compute
such predictions.
                                               23
                                                                                    Figure 4: Enrollment in Other Programs




                                                                                       (A) Online Program Applicants
                                             0 .1 .2 .3 .4 .5 .6 .7 .8 .9 1
           Enrolled in Non-GA Tech Program




                                                                              2.5                       3.26                 4
                                                                                                        GPA


                                                                                     (B) In-Person Program Applicants
                                             0 .1 .2 .3 .4 .5 .6 .7 .8 .9 1
           Enrolled in Non-GA Tech Program




                                                                              2.5                       3.26                 4
                                                                                                        GPA


Notes: The above figure shows as a function of college GPA the fraction of spring 2014 online
program applicants (panel A) and fall 2013 and 2014 in-person program applicants (panel B) who
by fall 2016 had enrolled in any formal non-Georgia Tech program, regardless of field of study. The
graph is limited to those with GPAs between 2.5 and 4.0. The dots shown come from binning the
data in intervals of 0.05 from the threshold, with dot size proportional to the number of applicants
in each bin. Also shown in panel A are fitted lines from a local linear regression discontinuity
model using a bandwidth of 0.5, so that not all points shown are used to compute such predictions.
                                                  24
                                     Figure 5: Enrollment in Any Degree Program

               .8
               .7
     Enrolled in Any Program
  .4        .5 .3     .6




                               2.5                         3.26                                4
                                                           GPA

Notes: The above figure shows as a function of college GPA the fraction of spring 2014 online
program applicants who by fall 2016 had enrolled in any program, OMSCS or otherwise. The
graph is limited to those with GPAs between 2.5 and 4.0. The dots shown come from binning the
data in intervals of 0.05 from the threshold, with dot size proportional to the number of applicants
in each bin. Also shown are fitted lines from a local linear regression discontinuity model using a
bandwidth of 0.5, so that not all points shown are used to compute such predictions.




                                                        25
                                             Figure 6: Hours of Non-Degree Training

                                 200
  Hours of non-degree training
                                 0




                                       2.5                       3.26                        4
                                                                 GPA

Notes: The above figure shows as a function of college GPA the total number of hours respondents
to the July 2017 survey report having spent in non-degree training since January 2014. The graph
is limited to those with GPAs between 2.5 and 4.0. The dots shown come from binning the data
in intervals of 0.05 from the threshold, with dot size proportional to the number of applicants in
each bin. Also shown are fitted lines from a local linear regression discontinuity model using a
bandwidth of 0.5, so that not all points shown are used to compute such predictions.




                                                              26
                                        Figure 7: Total Hours of Training
                          1,400
  Hours of all training
                          200




                                  2.5                    3.26                               4
                                                         GPA

Notes: The above figure shows as a function of college GPA the total number of hours respondents
to the July 2017 survey spent on all training since January 2014. Degree training hours come
from assuming an 18-hour per week commitment for 13 weeks during each semester enrolled
according to the NSC data. All training hours add to that the non-degree training hours reported
by respondents. The graph is limited to those with GPAs between 2.5 and 4.0. The dots shown
come from binning the data in intervals of 0.05 from the threshold, with dot size proportional to
the number of applicants in each bin. Also shown are fitted lines from a local linear regression
discontinuity model using a bandwidth of 0.5, so that not all points shown are used to compute
such predictions.




                                                       27
                      Table 1: Characteristics of Program Applicants and Enrollees

                                                          All                                       US
                                          Online      In-person        NSF          Online      In-person        NSF
                                           (1)            (2)          (3)           (4)            (5)          (6)
(A) Application and enrollment
Degrees awarded                                                      20,983                                    10,948
Number applied (annualized)                3,410         1,851                       2,407         141
Number admitted (annualized)               2,075          233                        1,462          68
Number enrolled (annualized)               1,663          120                        1,169          33
Admission rate                              0.61          0.13                       0.61          0.48
Enrollment rate                             0.49          0.06                       0.49          0.24

(B) Applicant characteristics
U.S. citizen                                0.71         0.08
Age                                         33.8         23.9                         34.7         25.1
Employed                                    0.87         0.49                         0.90         0.41
White                                       0.50         0.06                         0.64         0.54
Black or Hispanic                           0.16         0.02                         0.17         0.15
Asian                                       0.31         0.91                         0.15         0.27
Female                                      0.15         0.25                         0.13         0.17
Computer science major                      0.37         0.63                         0.40         0.52

(C) Enrollee characteristics
U.S. citizen                                0.70         0.28          0.52
Age                                         32.4         24.1                         33.0         25.8
Employed                                    0.89         0.42                         0.92         0.41
White                                       0.51         0.23                         0.67         0.61          0.54
Black or Hispanic                           0.12         0.06                         0.12         0.14          0.18
Asian                                       0.33         0.70                         0.17         0.20          0.14
Female                                      0.13         0.30          0.27           0.11         0.17          0.26
Computer science major                      0.42         0.62                         0.46         0.56
 Notes: Data in columns 1 and 4 come from all 2014-16 online program applicants. Data in columns 2 and and 5
 come from all 2013-16 in-person program applicants. Column 3 describes those who completed computer science
 master’s degrees in the US in 2013 and comes from 2013 IPEDS Completion Survey, accessed through the NSF’s
 WebCASPAR site. Columns 1-3 include all individuals, while columns 4-6 limit the sample to American citizens.
 For comparability, the numbers in columns 1, 2, 4 and 5 of panel A are scaled to be annual. In panel A, the enrollment
 rate is calculated as the fraction of applicants who enrolled.




                                                          28
                  Table 2: Distribution of Employers for Online Program Applicants

Listed                                           Number of                 Percentage               Cumulative
employer                                         applicants                  of total               percentage
AT&T                                                 1,062                    10.44                     10.44
Microsoft                                             105                     1.03                      11.47
Intel                                                  99                      0.97                     12.44
IBM                                                    94                      0.92                     13.36
U.S. Air Force                                         90                      0.88                     14.24
Google                                                 78                      0.77                     15.01
U.S. Army                                              68                      0.67                     15.68
United Parcel Service                                  66                      0.65                     16.33
Lockheed Martin                                        63                      0.62                     16.95
Amazon                                                 59                      0.58                     17.53
Cisco Systems                                          58                      0.57                      18.1
Oracle                                                 56                      0.55                     18.65
General Motors                                         51                      0.50                     19.15
Boeing                                                 47                      0.46                     19.61
General Electric                                       47                      0.46                     20.07
Raytheon                                               46                      0.45                     20.52
Northrop Grumman                                       43                      0.42                     20.94
Hewlett-Packard                                        40                      0.39                     21.33
Accenture                                              39                      0.38                     21.71
Apple                                                  33                      0.32                     22.03
Bank of America                                        31                      0.30                     22.33
J.P. Morgan Chase                                      29                      0.29                     22.62
U.S. Navy                                              28                      0.28                     22.90
Booz Allen Hamilton                                    26                      0.26                     23.16
Capital One                                            26                      0.26                     23.42

Employers with 2-25 applicants                       1,930                    18.97                     42.39
Employers with 1 applicant                           4,473                    43.97                     86.36

No employer listed                                   1,385                    13.62                      100
 Notes: Shown above are the top 25 employers listed by all 2014-16 online program applicants, as well as the total
 number of applicants from employers with 2-25 applicants, from employers with only one applicant, and with no
 employer listed.




                                                        29
                     Table 3: Applicants’ Undergraduate College Characteristics
                                    Applicants                      Admits                      Enrollees
                                 Online In-person              Online In-person             Online In-person
SAT math score                     649          679             655           692             657          692
Fraction low income                0.23         0.20            0.22          0.17            0.22         0.17
Six-year graduation rate           0.61         0.70            0.62          0.73            0.63         0.71

N                                 6,882         800             4,316         341            3,449         170
Notes: Shown above are the means of undergraduate college characteristics for all online and in-person program ap-
plicants, admits, and enrollees, as derived from the 2005 wave of IPEDS. All differences between the two programs
are statistically significant at the one percent level. The sample includes only students whose listed undergraduate
colleges were found in IPEDS. SAT math scores are the 75th percentile of the incoming freshman distribution. The
fraction of students classified as low income is measured by the proportion receiving federal grant aid.




                                                        30
                              Table 4: OMSCS Applicant Survey Responses

                                                             All                 Age≤35                  Age>35
                                                             (1)                   (2)                     (3)
(A) Response rate
Responded to survey                                         0.38                   0.36                     0.40
N                                                          2,419                  1,218                    1,201
(B) Important program features
No need to commute or relocate                               0.69                  0.70                     0.69
Flexible time commitments                                    0.65                  0.64                     0.67
Convenience                                                  0.62                  0.60                     0.63
Flexible coursework schedule                                 0.60                  0.60                     0.59
Cost                                                         0.53                  0.54                     0.51
Reputation of Georgia Tech                                   0.53                  0.51                     0.54
Challenge, skill development                                 0.47                  0.47                     0.47
Professional network                                         0.19                  0.15                     0.22
N                                                            876                   419                      457
(C) Employer would subsidize
OMSCS                                                        0.63                  0.55                     0.70
Other graduate degrees                                       0.61                  0.55                     0.67
Non-degree training                                          0.59                  0.52                     0.65
N                                                            723                   337                      386
(D) Hours of training
Did any type of non-degree training                         0.71                    0.68                    0.74
Hours of non-degree training                              111.25                  105.67                  116.29
Hours of MOOCs                                             57.20                   55.72                   58.53
Hours of professional certification                        16.63                   13.60                   19.37
Hours of coding boot camp                                   6.33                    8.65                    4.24
Hours of other types                                       31.09                   27.69                   34.15
Hours of degree training (estimated)                      796.07                  861.30                  737.20
Hours of all training (estimated)                         907.32                  966.96                  853.49
N                                                           898                     426                     472
 Notes: Listed above are mean values of survey responses from spring 2014 OMSCS applicants. The sample in each
 panel consists of respondents who gave valid answers to all questions in that panel. Panel B lists in descending
 order the fraction of respondents who described a given program feature as extremely important in their decision
 to apply to OMSCS. Panel C refers to the willingness of one’s January 2014 employer to subsidize training. Panel D
 refers to non-degree training conducted from January 2014 through July 2017. Degree training hours are estimated
 from NSC data by assuming each semester enrolled requires 18 training hours per week for 13 weeks.




                                                        31
                    Table 5: Access to OMSCS and Enrollment in Higher Education

                           Admitted        Enrolled OMSCS           Enrolled elsewhere        Enrolled anywhere
                             (FS)           (RF)     (IV)            (RF)       (IV)           (RF)       (IV)
                              (1)            (2)      (3)             (4)        (5)            (6)        (7)
(A) BW=0.7
Admissible                   0.178∗∗∗     0.194∗∗∗     1.090∗∗∗      0.007        0.038       0.177∗∗∗     0.998∗∗∗
                              (0.062)      (0.051)      (0.214)     (0.037)      (0.213)       (0.038)      (0.305)

(B) BW=0.7, controls
Admissible                   0.189∗∗∗     0.201∗∗∗     1.063∗∗∗      0.002        0.011       0.180∗∗∗     0.951∗∗∗
                              (0.052)      (0.040)      (0.189)     (0.034)      (0.180)       (0.036)      (0.256)

(C) BW=0.5, controls
Admissible                   0.187∗∗∗     0.212∗∗∗     1.136∗∗∗      0.046        0.245       0.223∗∗∗     1.196∗∗∗
                              (0.066)      (0.048)      (0.257)     (0.043)      (0.283)       (0.042)      (0.402)

(D) BW=0.3, controls
Admissible                   0.218∗∗∗     0.227∗∗∗     1.043∗∗∗      0.063        0.288       0.235∗∗∗     1.079∗∗∗
                              (0.081)      (0.068)      (0.240)     (0.054)      (0.321)       (0.053)      (0.377)

Control mean                   0.41          0.36                    0.18                       0.51
 Notes: Heteroskedasticity-robust standard errors clustered by GPA are in parentheses (* p<.10 ** p<.05 *** p<.01).
 Each regression discontinuity estimate in columns 1, 2, 4 and 6 comes from a local linear model that regresses
 an indicator for an admission or enrollment outcome on an indicator for being above the GPA threshold of 3.26,
 distance from that threshold, and the interaction of the two. Columns 3, 5 and 7 contain instrumental variables
 estimates of the impact of admission on enrollment, where admission has been instrumented with being above the
 threshold. The sample includes all spring 2014 applicants to OMSCS whose GPA is within the listed bandwidth.
 The top row includes no controls, while the remaining rows control for gender, race/ethnicity, citizenship, age,
 employment and college major. Enrollment is measured by fall 2016. The sample size in panels A and B is 1,706, in
 panel C is 1,365, in panel D is 926 and in panel E ranges from 1,051 to 1,293. Listed below each column is the mean
 of the outcome for those 0.01-0.10 GPA points below the threshold.




                                                         32
               Table 6: Heterogeneity in Enrollment Impacts of Access to Online Option

                        Admitted        Enrolled OMSCS           Enrolled elsewhere          Enrolled anywhere
                          (FS)           (RF)     (IV)            (RF)        (IV)            (RF)       (IV)
                           (1)            (2)      (3)             (4)         (5)             (6)        (7)
Excluding AT&T           0.225∗∗∗      0.265∗∗∗     1.178∗∗∗      0.036         0.158       0.260∗∗∗      1.154∗∗∗
                          (0.078)       (0.058)      (0.248)     (0.052)       (0.263)       (0.051)       (0.372)
N                          1,062         1,062        1,062       1,062         1,062         1,062         1,062

U.S. citizen              0.157∗∗      0.217∗∗∗     1.381∗∗∗      0.009         0.055       0.204∗∗∗       1.299∗∗
                          (0.071)       (0.054)      (0.416)     (0.049)       (0.327)       (0.050)       (0.560)
N                          1,193         1,193        1,193       1,193         1,193         1,193         1,193

Age ≥ 35                 0.309∗∗∗      0.300∗∗∗     0.970∗∗∗     -0.050         -0.161      0.221∗∗∗      0.716∗∗∗
                          (0.070)       (0.069)      (0.125)     (0.064)       (0.200)       (0.070)       (0.200)
N                           668           668          668         668           668           668           668

Age < 35                   0.082        0.154∗∗       1.866      0.109∗∗        1.323       0.213∗∗∗        2.580
                          (0.088)       (0.072)      (1.501)     (0.051)       (1.807)       (0.069)       (2.530)
N                           697           697          697         697           697           697           697

Male                      0.161∗∗      0.216∗∗∗     1.340∗∗∗      0.010         0.065       0.195∗∗∗       1.212∗∗
                          (0.071)       (0.051)      (0.399)     (0.053)       (0.346)       (0.051)       (0.554)
N                          1,184         1,184        1,184       1,184         1,184         1,184         1,184

Female                    0.362∗∗        0.206       0.570∗∗     0.197∗         0.545        0.347∗∗       0.959∗∗
                          (0.140)       (0.130)      (0.252)     (0.112)       (0.416)       (0.139)       (0.386)
N                           181           181          181         181           181           181           181

White or Asian           0.218∗∗∗      0.256∗∗∗     1.172∗∗∗      0.018         0.081       0.247∗∗∗      1.130∗∗∗
                          (0.069)       (0.053)      (0.221)     (0.048)       (0.234)       (0.048)       (0.331)
N                          1,067         1,067        1,067       1,067         1,067         1,067         1,067

Black or Hispanic          0.040         0.000        0.007      0.202∗∗        4.998         0.068         1.695
                          (0.114)       (0.115)      (2.845)     (0.100)      (14.541)       (0.123)       (4.429)
N                           243           243          243         243           243           243           243


 Notes: Heteroskedasticity-robust standard errors clustered by GPA are in parentheses (* p<.10 ** p<.05 *** p<.01).
 Each regression discontinuity estimate in columns 1-4 comes from a local linear model that regresses an indicator
 for an admission or enrollment outcome on an indicator for being above the GPA threshold of 3.26, distance from
 that threshold, and the interaction of the two. Columns 5 and 6 contain instrumental variables estimates of the
 impact of admission on enrollment, where admission has been instrumented with being above the threshold. The
 sample includes all spring 2014 applicants to OMSCS whose GPA is within 0.5 of the admissions threshold and who
 belong to the listed subgroup. All regressions control for the gender, race, geography, age, employment and college
 major variables listed in Table A.1. Enrollment is measured by fall 2016.




                                                         33
                                                  Table 7: Access to OMSCS and Non-Degree Training

                                  Responded                       Hours spent on non-degree training                                  Hours spent on
                                      to                Any                       Prof.      Boot                  Other           Degree          All
                                    survey              type        MOOC          cert.     camp                   type           training      training
                                      (1)                (2)          (3)          (4)        (5)                   (6)              (7)           (8)
     (A) BW=0.7
     Admissible (RF)                  0.022            13.810           -4.816        9.195         15.131∗        -5.701        293.456∗∗        307.266∗∗
                                     (0.053)          (27.790)        (18.027)       (10.048)        (7.832)      (11.765)        (124.258)        (124.258)
     Admitted (IV)                    0.125            89.007          -31.041        59.266         97.524       -36.742        1891.409∗∗       1980.416∗∗
                                     (0.289)         (190.079)       (118.099)       (74.870)       (71.952)      (73.584)        (807.888)        (862.136)
     N                                1706              649              649           649             649          649              649              649
     (B) BW=0.7, controls
     Admissible (RF)                  0.032             7.057           -8.230         7.842        15.080∗        -7.636        285.524∗∗        292.581∗∗
                                     (0.053)          (28.169)        (18.459)        (9.844)        (7.660)      (12.555)        (121.105)        (123.066)
     Admitted (IV)                    0.170            45.913          -53.543        51.021         98.113       -49.678        1857.621∗∗       1903.534∗∗
                                     (0.278)         (185.739)       (123.844)       (69.355)       (66.988)      (80.885)        (721.949)        (759.458)
     N                                1706               649             649            649            649          649              649              649
     (C) BW=0.5, controls




34
     Admissible (RF)                  0.048            18.604           -3.135       19.679∗         11.028        -8.969         294.394∗∗       312.998∗∗
                                     (0.062)          (30.779)        (21.518)       (11.141)        (7.766)      (13.803)        (147.483)        (151.729)
     Admitted (IV)                    0.256            97.548          -16.436       103.185         57.827       -47.027        1543.630∗∗       1641.178∗∗
                                     (0.325)         (168.093)       (114.243)       (77.112)       (50.738)      (71.786)        (631.961)        (677.440)
     N                                1365              512              512           512             512          512              512              512
     (D) BW=0.3, controls
     Admissible (RF)                  0.048            37.644          -1.620         29.172         11.471        -1.380         349.310∗         386.954∗
                                     (0.087)          (34.869)        (25.604)       (18.014)       (10.762)      (14.749)        (189.433)        (197.774)
     Admitted (IV)                    0.222           153.477          -6.603        118.937         46.769        -5.626        1424.155∗∗       1577.632∗∗
                                     (0.394)         (160.518)       (104.836)       (96.131)       (50.495)      (59.917)        (623.471)        (690.736)
     N                                 926              346             346            346            346           346              346              346

     Control mean                      0.37             89.00          44.88           7.85           1.08          35.19          670.50            759.50
      Notes: Heteroskedasticity-robust standard errors clustered by GPA are in parentheses (* p<.10 ** p<.05 *** p<.01). The regression discontinuity estimate
      in the top row of each panel comes from a local linear model that regresses the listed outcome on an indicator for being above the GPA threshold of 3.26,
      distance from that threshold, and the interaction of the two. The bottom row of each panel contains instrumental variables estimates of the impact of
      admission on the listed outcome, where admission has been instrumented with being above the threshold. The sample includes all spring 2014 applicants
      to OMSCS whose GPA is within the listed bandwidth and who had valid survey responses. Outcomes refer to total hours spent on training from January
      2014 through July 2017. The top panel includes no controls, while the remaining rows control for gender, race/ethnicity, citizenship, age, employment
      and college major. Listed below each column is the mean of the outcome for those 0.01-0.10 GPA points below the threshold.
A     Online Survey
We sent a web-based survey through Qualtrics to all spring 2014 OMSCS applicants, via the e-
mail addresses they had listed on their applications. All but two percent of those e-mail addresses
still appeared to be active. The survey opened on July 19, 2017. Non-respondents were sent
weekly reminders until the survey closed on August 7, 2017. Respondents were provided with
a unique link to the survey and were allowed to respond only once. The survey contained two
sections. In the first section, questions addressed respondents’ informal education in computing.
The second section of the survey asked respondents to indicate their reasons for applying to the
OMSCS program.

A.1   Survey Questions
A few years ago, you applied to Georgia Tech’s Online M.S. in Computer Science. As part of a research
study we are conducting on graduate computing education, we would like to ask you a few questions about
your experiences since then. The following questions ask about your training OUTSIDE of Georgia Tech’s
Online M.S. in Computer Science.

    • Since January 2014, have you taken any of the following types of computer science/computing
      training outside of a master’s degree program? (Yes/No/Don’t recall)

        – Professional certification programs in computing (such as Microsoft Certified Systems
          Engineer)
        – Coding boot camps (such as General Assembly)
        – Massive open online courses on computing or coding (through, for example, Coursera,
          Udacity or EdX)
        – Other

    • Approximately how many total hours did you spend in the following courses that you
      named from January 2014 until now?

        – Professional certification programs in computing (such as Microsoft Certified Systems
          Engineer)
        – Coding boot camps (such as General Assembly)
        – Massive open online courses on computing or coding (through, for example, Coursera,
          Udacity or EdX)
        – Other(please list the other course(s) here)

    • In January 2014, were you:

        – Working for a company, government, or non-profit
        – Self-employed
        – Unemployed
        – Don’t recall

                                                  35
• (If respondents indicated they were “Working for a company, government, or non-profit”)
  Whether or not you enrolled in any course, to the best of your recollection, was your em-
  ployer in 2014 willing to help pay for at least a part of the cost of your enrollment in any of
  the following? (Yes/No/Don’t recall)

     – Georgia Tech’s Online M.S. in Computer Science
     – A graduate degree program other than Georgia Tech’s Online M.S. in Computer Science
     – Other training or certification, not leading to a formal master’s degree

• How important were the following in your decision to apply for the Online Master’s of Com-
  puting Program at Georgia Tech? (Not at all important / Somewhat important / Important
  / Extremely important)

     – Convenience
     – Cost
     – Overall reputation of Georgia Tech
     – Reputation of the Computing Program at Georgia Tech
     – Academic challenge and skill development
     – Access to computing resources
     – No need to commute or relocate
     – Flexible time commitments
     – Flexible coursework schedule
     – Opportunities to build my professional network




                                             36
                                     Figure A.1: Survey Response Rates

                        0.56
  Responded to survey
                        0.21




                               2.5                    3.26                                   4
                                                      GPA

Notes: The above figure shows as a function of college GPA the fraction of spring 2014 online
program applicants who responded to the July 2017 survey on non-degree training. The graph
is limited to those with GPAs between 2.5 and 4.0. The dots shown come from binning the data
in intervals of 0.05 from the threshold, with dot size proportional to the number of applicants in
each bin. Also shown are fitted lines from a local linear regression discontinuity model using a
bandwidth of 0.5, so that not all points shown are used to compute such predictions.




                                                    37
                                       Figure A.2: GPA Distribution, Online Program Applicants




                                75
         Number of Applicants
                                50
                                25
                                0




                                     2.5                  3           3.26     3.5               4
                                                                      GPA

Notes: The above figure shows the number of spring 2014 online program applicants with a given
GPA, limiting the graph to those with GPAs between 2.5 and 4.0.




                                                                 38
                                           Figure A.3: Immediate Enrollment in the Online Program

                  .5
  Enrolled in OMSCS in Spring 2014
    .1         .2 0    .3       .4




                                     2.5                               3.26                         4
                                                                       GPA

Notes: The above figure shows as a function of college GPA the fraction of spring 2014 online
program applicants who enrolled in the online program in spring 2014. The graph is limited to
those with GPAs between 2.5 and 4.0. The dots shown come from binning the data in intervals of
0.05 from the threshold, with dot size proportional to the number of applicants in each bin. Also
shown are fitted lines from a local linear regression discontinuity model using a bandwidth of 0.5,
so that not all points shown are used to compute such predictions.




                                                                    39
                   Figure A.4: Enrollment in the Online Program, Conditional on Admission




                     1         .9
         Ever Enrolled in OMSCS
         .7          .8
                     .6




                                    2.5               3.26                                  4
                                                      GPA

Notes: The above figure shows as a function of college GPA the fraction of spring 2014 online
program applicants who were admitted and who enrolled in the online program by fall 2016. The
graph is limited to those with GPAs between 2.5 and 4.0. The dots shown come from binning the
data in intervals of 0.05 from the threshold, with dot size proportional to the number of applicants
in each bin. Also shown are fitted lines from a local linear regression discontinuity model using a
bandwidth of 0.5, so that not all points shown are used to compute such predictions.




                                                    40
          Figure A.5: Placebo and Donut Hole Tests: Admission to the Online Program




                                                                    (A) Placebo RD
                                       .4
                                       .3
             Estimated Discontinuity
                                       .2
                                       .1
                                       0
                                       -.1
                                       -.2
                                       -.3




                                             2.86   2.96    3.06     3.16        3.26    3.36   3.46    3.56    3.66
                                                              Placebo Admissions Threshold


                                                                   (B) Donut Hole RD
                                       .4
             Estimated Discontinuity
                                       .3
                                       .2
                                       .1
                                       0




                                                0          0.01       0.02              0.03     0.04          0.05
                                                              Size of Donut Hole (GPA points)


Notes: The outcome in all regressions shown is admission to the online program, for spring 2014
online program applicants. Panel A shows estimated discontinuities from regression specifica-
tions that assume the admissions threshold is at the listed GPA value, using a bandwidth of 0.5
GPA points and including demographic controls. Panel B shows estimated discontinuities from
regression specifications that assume the correct threshold of 3.26, that use a bandwidth of 0.5 GPA
points and include demographic controls, but that exclude applicants whose GPAs are within the
listed distance of the threshold. Vertical lines indicate 95% confidence intervals.

                                                                            41
                                        Figure A.6: Placebo and Donut Hole Tests: Online Enrollment




                                                                   (A) Placebo RD
                                      .4
                                      .3
            Estimated Discontinuity
                                      .2
                                      .1
                                      0
                                      -.1
                                      -.2
                                      -.3




                                            2.86   2.96    3.06     3.16        3.26    3.36   3.46    3.56    3.66
                                                             Placebo Admissions Threshold


                                                                  (B) Donut Hole RD
                                      .4
            Estimated Discontinuity
                                      .3
                                      .2
                                      .1
                                      0




                                               0          0.01       0.02              0.03     0.04          0.05
                                                             Size of Donut Hole (GPA points)


Notes: The outcome in all regressions shown is enrollment in the online program by fall 2016, for
spring 2014 online program applicants. Panel A shows estimated discontinuities from regression
specifications that assume the admissions threshold is at the listed GPA value, using a bandwidth
of 0.5 GPA points and including demographic controls. Panel B shows estimated discontinuities
from regression specifications that assume the correct threshold of 3.26, that use a bandwidth of
0.5 GPA points and include demographic controls, but that exclude applicants whose GPAs are
within the listed distance of the threshold. Vertical lines indicate 95% confidence intervals.

                                                                           42
                                      Figure A.7: Placebo and Donut Hole Tests: Enrollment Anywhere




                                                                   (A) Placebo RD
                                      .4
                                      .3
            Estimated Discontinuity
                                      .2
                                      .1
                                      0
                                      -.1
                                      -.2
                                      -.3




                                            2.86   2.96    3.06     3.16        3.26    3.36   3.46    3.56    3.66
                                                             Placebo Admissions Threshold


                                                                  (B) Donut Hole RD
                                      .4
            Estimated Discontinuity
                                      .3
                                      .2
                                      .1
                                      0




                                               0          0.01       0.02              0.03     0.04          0.05
                                                             Size of Donut Hole (GPA points)


Notes: The outcome in all regressions shown is enrollment in any degree program by fall 2016, for
spring 2014 online program applicants. Panel A shows estimated discontinuities from regression
specifications that assume the admissions threshold is at the listed GPA value, using a bandwidth
of 0.5 GPA points and including demographic controls. Panel B shows estimated discontinuities
from regression specifications that assume the correct threshold of 3.26, that use a bandwidth of
0.5 GPA points and include demographic controls, but that exclude applicants whose GPAs are
within the listed distance of the threshold. Vertical lines indicate 95% confidence intervals.

                                                                           43
                                     Figure A.8: Hours of Non-Degree Training, by Type



                                    (A) MOOCs                                                  (B) Professional certifications
                       120




                                                                                       120
   Hours of training




                                                                   Hours of training
                                                                                       0
                       0




                             2.5        3.26              4                                  2.5             3.26                4
                                        GPA                                                                 GPA


                                   (C) Boot camps                                            (D) Other non-degree programs
                       120




                                                                                       120
   Hours of training




                                                                   Hours of training
                       0




                                                                                       0




                             2.5        3.26              4                                  2.5            3.26                 4
                                        GPA                                                                 GPA


Notes: The above figure shows as a function of college GPA the number of hours respondents
to the July 2017 survey report spending in various forms of non-degree training since January
2014. The graph is limited to those with GPAs between 2.5 and 4.0. The dots shown come from
binning the data in intervals of 0.05 from the threshold, with dot size proportional to the number
of applicants in each bin. Also shown are fitted lines from a local linear regression discontinuity
model using a bandwidth of 0.5, so that not all points shown are used to compute such predictions.




                                                              44
                 Table A.1: OMSCS and MSCS Applicant Characteristics by Cohort

                                         Applicants to OMSCS                           Applicants to MSCS
                              Feb.    Aug. Feb. Aug. Feb.                 Aug.     Aug. Aug. Aug. Aug.
                              2014    2014 2015 2015 2016                 2016     2013 2014 2015 2016
                               (1)     (2)    (3)     (4)  (5)             (6)      (7)    (8)     (9)  (10)
(A) Gender, race
Male                          0.86     0.86     0.86     0.84     0.84     0.84    0.76     0.75     0.75     0.75
White                         0.54     0.55     0.50     0.43     0.47     0.47    0.08     0.08     0.05     0.05
Black, Hispanic               0.18     0.14     0.16     0.16     0.16     0.12    0.02     0.03     0.02     0.02
Asian                         0.24     0.28     0.31     0.37     0.34     0.38    0.90     0.88     0.93     0.93
(B) Geography
Georgia resident              0.14     0.14     0.13     0.14     0.15     0.11    0.04     0.03     0.02     0.02
US resident                   0.91     0.88     0.90     0.72     0.77     0.73    0.11     0.13     0.09     0.10
US citizen                    0.78     0.73     0.71     0.64     0.68     0.65    0.09     0.10     0.06     0.07
US permanent resident         0.07     0.07     0.09     0.06     0.08     0.08    0.01     0.01     0.01     0.02
Foreign citizen               0.15     0.20     0.21     0.29     0.24     0.27    0.90     0.89     0.93     0.91
(C) Age, employment
Age                          36.72    33.87    34.00    32.23    33.17    31.53    23.66    24.07    23.82    23.86
Employed                      0.91     0.90     0.88    0.81      0.86     0.83      .      0.50     0.49      0.48
Employed by AT&T             0.23      0.09     0.06    0.05      0.08     0.04      .       0.00    0.00      0.00
(D) College major
Computer science              0.43     0.37     0.35     0.36     0.34     0.34    0.66     0.62     0.64     0.61
Engineering                   0.27     0.28     0.29     0.30     0.31     0.32    0.26     0.29     0.30     0.30
Other                         0.30     0.35     0.36     0.34     0.35     0.34    0.08     0.08     0.06     0.09
(E) Admission
Admitted to GA Tech           0.48     0.62     0.59     0.66     0.69     0.68    0.13     0.16     0.13     0.09
Enrolled in GA Tech           0.40     0.49     0.52     0.48     0.55     0.53    0.07     0.07     0.07     0.05

Number applied               2,419    1,633    1,386    1,472    1,347    1,972    1,379    1,749    1,925    2,350
Number admitted              1,150    1,018     821      965      933     1,338     185      279      247      221
Number enrolled               969      801      718      702      745     1,054     101      117      142      120
 Notes: Listed above are mean values of key variables for applicants to the OMSCS program in columns 1-6 and the
 MSCS program in columns 7-10.




                                                       45
                            Table A.2: Characteristics of Survey Respondents

                              All                                                                       p-value
                          spring 2014                                                                     from
                            OMSCS               Survey               Survey                             t-test of
                           applicants        respondents         non-respondents           (2)-(3)       (2)=(3)
                              (1)                 (2)                   (3)                  (4)           (5)
Female                        0.137              0.138                  0.136               0.001         0.923
White                         0.539              0.620                  0.489               0.131         0.000
Asian                         0.237              0.187                  0.268              -0.081         0.000
Black or Hispanic             0.183              0.153                  0.201              -0.048         0.003
Resides in USA                0.912              0.913                  0.912               0.000         0.978
Majored in CS                 0.428              0.447                  0.416               0.031         0.138
Age                            36.7               37.6                   36.2                1.4          0.047
Employed                      0.914              0.932                  0.903               0.029         0.013

N                             2,419               915                   1,504
 Notes: Column 1 shows mean characteristics of all spring 2014 applicants to the OMSCS program. Columns 2 and
 3 separate the sample by whether a given applicant responded to the online survey on informal training. Columns
 4 and 5 show differences between characteristics of respondents and non-respondents, as well as the p-value from
 a t-test of that difference.




                                                         46
                                      Table A.3: Covariate Balance Tests

                                                 Black or        U.S.                                      Majored
                         Male        Asian       Hispanic       citizen        Age        Employed          in CS
                          (1)         (2)           (3)           (4)          (5)          (6)               (7)
(A) BW = 0.7
Admissible GPA           0.035      0.056∗        -0.026        -0.037       -1.341         -0.004          -0.074
                        (0.030)     (0.029)       (0.029)       (0.031)      (1.062)        (0.022)         (0.062)
N                        1,706       1,706         1,706         1,706        1,706          1,706           1,706

(B) BW = 0.5
Admissible GPA           0.031       0.050        -0.024        -0.035       -1.929         -0.003          -0.113
                        (0.035)     (0.033)       (0.033)       (0.034)      (1.223)        (0.027)         (0.073)
N                        1,365       1,365         1,365         1,365        1,365          1,365           1,365

(C) BW = 0.3
Admissible GPA           -0.002     0.075∗        -0.026        -0.069       -2.215         -0.018          -0.128
                        (0.049)     (0.040)       (0.038)       (0.044)      (1.596)        (0.035)         (0.098)
N                         926         926           926           926          926            926             926

Control mean             0.86         0.13          0.20          0.88        37.13           0.91            0.50
 Notes: Heteroskedasticity-robust standard errors clustered by GPA are in parentheses (* p<.10 ** p<.05 *** p<.01).
 Each regression discontinuity estimate comes from a local linear model that regresses the covariate listed on an
 indicator for being above the GPA threshold, distance from that threshold, and the interaction of the two.The sample
 includes all spring 2014 applicants to OMSCS whose GPA is within the listed bandwidth. Listed below each column
 is the mean of the covariate for those 0.01-0.10 GPA points below the threshold.




                                                           47
                               Table A.4: Hours of Degree and All Training

                                             Hours of degree training                 Hours of all training
Assume hrs/wk for OMSCS =                    18        18          9                18        18           9
Assume hrs/wk for other deg =                18        36         18                18        36          18
                                             (1)       (2)        (3)               (4)       (5)         (6)
(A) BW=0.7
Admissible (RF)                             293∗∗      308∗∗         154∗∗         307∗∗        322∗∗       168∗∗
                                            (124)       (143)         (71)         (124)        (146)        (77)
Admitted (IV)                              1891∗∗      1987∗∗        994∗∗        1980∗∗       2076∗∗       1083∗
                                            (808)       (979)        (489)         (862)       (1045)       (570)
N                                            649         649          649           649          649         649
(B) BW=0.7, controls
Admissible (RF)                             286∗∗      312∗∗         156∗∗         293∗∗       319∗∗       163∗∗
                                            (121)       (143)          (71)        (123)        (147)        (78)
Admitted (IV)                              1858∗∗      2030∗∗        1015∗∗       1904∗∗       2076∗∗      1061∗∗
                                            (722)       (900)         (450)        (759)        (950)       (516)
N                                            649         649           649          649          649         649
(C) BW=0.5, controls
Admissible (RF)                             294∗∗      360∗∗         180∗∗         313∗∗       379∗∗       199∗∗
                                            (147)       (172)         (86)         (152)        (179)        (95)
Admitted (IV)                              1544∗∗      1890∗∗        945∗∗        1641∗∗       1987∗∗      1042∗∗
                                            (632)       (849)        (425)         (677)        (908)       (496)
N                                            512         512          512           512          512         512
(D) BW=0.3, controls
Admissible (RF)                             349∗        412∗         206∗          387∗         450∗        244∗
                                            (189)       (219)        (110)         (198)        (230)       (122)
Admitted (IV)                              1424∗∗      1680∗∗        840∗∗        1578∗∗       1833∗∗       993∗
                                            (623)       (817)        (408)         (691)        (895)       (496)
N                                            346         346          346           346          346         346

Control mean                                671          792          396           760         881          485
 Notes: Heteroskedasticity-robust standard errors clustered by GPA are in parentheses (* p<.10 ** p<.05 *** p<.01).
 The regression discontinuity estimate in the top row of each panel comes from a local linear model that regresses
 the listed outcome on an indicator for being above the GPA threshold of 3.26, distance from that threshold, and
 the interaction of the two. The bottom row of each panel contains instrumental variables estimates of the impact
 of admission on the listed outcome, where admission has been instrumented with being above the threshold. The
 sample includes all spring 2014 applicants to OMSCS whose GPA is within the listed bandwidth and who had
 valid survey responses. Outcomes refer to total hours spent on training from January 2014 through July 2017.
 The top panel includes no controls, while the remaining rows control for gender, race/ethnicity, citizenship, age,
 employment and college major. Listed below each column is the mean of the outcome for those 0.01-0.10 GPA
 points below the threshold.




                                                        48
