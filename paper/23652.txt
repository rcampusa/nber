                              NBER WORKING PAPER SERIES




                    RATIONALLY INATTENTIVE BEHAVIOR:
             CHARACTERIZING AND GENERALIZING SHANNON ENTROPY

                                         Andrew Caplin
                                          Mark Dean
                                          John Leahy

                                       Working Paper 23652
                               http://www.nber.org/papers/w23652


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                                    August 2017




We thank Dirk Bergemann, Daniel Csaba, Henrique de Oliveira, Xavier Gabaix, Sen Geng,
Andrei Gomberg, Michael Magill, Daniel Martin, Filip Matejka, Alisdair McKay, Stephen
Morris, Efe Ok, and Michael Woodford for their constructive contributions. This paper builds on
the material contained in the working paper "The Behavioral Implications of Rational Inattention
with Shannon Entropy" by Andrew Caplin and Mark Dean [2013], and subsumes all common
parts. The views expressed herein are those of the authors and do not necessarily reflect the views
of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2017 by Andrew Caplin, Mark Dean, and John Leahy. All rights reserved. Short sections of
text, not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including © notice, is given to the source.
Rationally Inattentive Behavior: Characterizing and Generalizing Shannon Entropy
Andrew Caplin, Mark Dean, and John Leahy
NBER Working Paper No. 23652
August 2017
JEL No. D8,D83

                                         ABSTRACT

We provide a full behavioral characterization of the standard Shannon model of rational
inattention. The key axiom is "Invariance under Compression", which identifies this model as
capturing an ideal form of attention-constrained choice. We introduce tractable generalizations
that allow for many of the known behavioral violations from this ideal, including asymmetries
and complementarities in learning, context effects, and low responsiveness to incentives. We
provide an even more general method of recovering attention costs from behavioral data. The
data set in which we characterize all behavioral patterns is "state dependent" stochastic choice
data.

Andrew Caplin                                  John Leahy
Department of Economics                        Gerald R. Ford School of Public Policy
New York University                            University of Michigan
19 W. 4th Street, 6th Floor                    3308 Weill Hall
New York, NY 10012                             735 S. State St. #3308
and NBER                                       Ann Arbor, MI 48109
andrew.caplin@nyu.edu                          and NBER
                                               jvleahy@umich.edu
Mark Dean
Columbia University
420 W 118th Street
New York, NY 10027
Mark.Dean@columbia.edu




An online appendix is available at http://www.nber.org/data-appendix/w23652
Rationally Inattentive Behavior: Characterizing and Generalizing
                        Shannon Entropy

                            Andrew Capliny, Mark Deanz, and John Leahyx

                                                   July 2017




                                                   Abstract

         We provide a full behavioral characterization of the standard Shannon model of rational
      inattention. The key axiom is “Invariance under Compression”, which identi…es this model as
      capturing an ideal form of attention-constrained choice. We introduce tractable generalizations
      that allow for many of the known behavioral violations from this ideal, including asymmetries
      and complementarities in learning, context e¤ects, and low responsiveness to incentives. We
      provide an even more general method of recovering attention costs from behavioral data. The
      data set in which we characterize all behavioral patterns is “state dependent” stochastic choice
      data.



1    Introduction

Understanding limits on private information has been central to economic analysis since the pio-
neering work of Hayek [1937, 1945]. While there are many models of information acquisition in
use (see Hellwig et al. [2012]), a major new route to such understanding was initiated by Sims
[1998, 2003], who introduced the theory of rational inattention. He considered the implications of
attention costs based on Shannon mutual information for macroeconomic dynamics. The ensuing
period has seen applications of the Shannon cost function to such diverse subjects as stochastic
choice (Matejka and McKay [2015]), investment decisions (Mondria [2010]), global games (Yang
[2015]), pricing decisions (Woodford [2009], Mackowiak and Wiederholt [2009], Martin [2017] and
Matµejka [2015]), dynamic learning (Steiner et al. [2015]) and social learning (Caplin et al. [2015]).
     One reason for the appeal of the Shannon cost function is analytic tractability. A second lies
is its connection to optimal coding (Shannon [1948], Sims [2003], Cover and Thomas [2012]). Yet
      We thank Dirk Bergemann, Daniel Csaba, Henrique de Oliveira, Xavier Gabaix, Sen Geng, Andrei Gomberg,
Michael Magill, Daniel Martin, Filip Matejka, Alisdair McKay, Stephen Morris, Efe Ok, and Michael Woodford for
their constructive contributions. This paper builds on the material contained in the working paper “The Behavioral
Implications of Rational Inattention with Shannon Entropy”by Andrew Caplin and Mark Dean [2013], and subsumes
all common parts.
    y
      Center for Experimental Social Science and Department of Economics, New York University. Email: an-
drew.caplin@nyu.edu
    z
      Department of Economics, Columbia University. Email: mark.dean@columbia.edu
    x
      Department of Economics, Universtity of Michigan and NBER. Email: jvleahy@umich.edu



                                                        1
these do not imply behavioral validity. Indeed it is now known that behavior often violates key
features of the Shannon model. These include: its implication that all states are equally easy to
identify and to discriminate among (see Dewan and Neligh [2017] for behavioral counterexamples);
the implied ‡exibility of response to payo¤ incentives (see Caplin and Dean [2013] for behavioral
counterexamples); and essential independence of behavior from event likelihoods (see Woodford
[2012] for behavioral counter examples).
    At this stage there are two related open questions. First, while various features of the behavior
associated with the Shannon model are known, there is as yet no full behavioral characterization.
What precisely are the behavioral characteristics of the Shannon model? Second, what workable
alternative models allow for the complex behavioral patterns identi…ed in practice?
    In this paper we address both questions. We provide a full behavioral characterization of
the Shannon model. This characterization pinpoints it as de…ning an “ideal” form of attention-
constrained choice, in which choices depend only on the probabilistic structure of payo¤s. We
also introduce two tractable generalizations that allow for many observed behavioral departures
from the Shannon model. The …rst involves Uniformly Posterior-Separable (UPS) models, in which
attention costs depend on the expectation of a general convex function of the posterior beliefs.
One particular example uses Tsallis entropy instead of Shannon entropy. UPS models allow for
such factors as: asymmetric costs of learning about distinct states; di¤ering perceptual distance
between distinct states; complementarities in learning about distinct states; and complex responses
to payo¤ incentives. Posterior-separable (PS) models are even more ‡exible as they allow the cost
of attention to depend on prior beliefs and hence vary from context to context. The tractability of
PS and UPS models derives from the fact that, as in the Shannon model, attention costs depend
on the expectation of a strictly convex function of posterior beliefs so that standard Lagrangian
optimization methods are available. These generalizations are already gaining traction in the
literature (see Caplin and Dean [2013], Gentzkow and Kamenica [2014], Steiner et al. [2015], Clark
[2016] and Morris and Strack [2017]).
   In addition to answering open questions, our analysis produces an unexpected bonus. We
provide a constructive method of recovering attention costs from behavioral data. This method is
both general and intuitively reasonable, resting as it does on standard balancing of marginal costs
and marginal utility.
    Our …rst result starts from behavioral patterns induced by a general UPS cost function and
identi…es additional restrictions that ensure that this function is of the Shannon form. UPS cost
functions are characterized by a general strictly convex function of posterior beliefs. The Shannon
model specializes to a particular one parameter family of such functions. Hence the gap between
the UPS model and the Shannon model can be analogized to that between a general strictly concave
utility function and Cobb-Douglas utility.
    Just as constancy of expenditure shares pins down the Cobb-Douglas form, we identify a single
behavioral axiom that de…nes the Shannon model. Invariance Under Compression (IUC) makes
choices invariant to changes in the underlying state space that do not impact the probabilistic
structure of payo¤s. In this sense, the Shannon model alone produces an idealized form of attention-
constrained behavior in which only payo¤ relevant information matters.
   Our remaining results establish necessary and su¢ cient conditions for a UPS representation.
They do this in three stages, with each stage being of independent interest. The …rst stage intro-
duces axioms for recoverability of the cost function. The second introduces additional axioms and


                                                 2
characterizes the PS model. The third adds one …nal axiom that specializes the PS to the UPS
model.
    With regard to recoverability, we show that the cost function is fully pinned down by three
behavioral axioms. The …rst two are necessary for existence of a rationalizing cost function of
any form: no improving action switches (NIAS: see Caplin and Martin [2015]) and no improving
attention cycles (NIAC; see Caplin and Dean [2015]). The …nal axiom requires “completeness” of
the behavioral data, in a sense to be made precise.
    The PS characterization relies mainly on a behavioral invariance axiom, Separability, that is
less restrictive than IUC. It enables one to replace any action in a given decision problem without
disturbing the behavior associated with common actions. There are also three axioms that address
technical issues in the representation.
    The UPS characterization rests on a third behavioral invariance property, Locally Invariant
Posteriors (LIP), intermediate in generality between Separability and IUC. LIP insists that behav-
ioral data derived from any given decision problem can be used to characterize data for a wide class
of related problems, subject to Bayesian consistency.
    Central to our approach is a particular speci…cation of the choice data available to an ideal
observer, such as an econometrician or economic theorist. One key feature is stochasticity. That
cognitive constraints produce stochasticity in choice has been a commonplace in psychometrics ever
since the pioneering perceptual experiments of Weber [1834] and the formal models of Thurstone
[1927] and Luce [1959]. Stochasticity is also a feature in all models of rational inattention which
focus on cognitively constrained updating. Yet standard stochastic choice data is fundamentally
inadequate to capture attention, since it does not measure the degree of match between behavior
and reality. As Block and Marschak [1960] (p. 98-99) presciently noted, the path forward in testing
theories of attention lies in data enrichment.
    The data set that we study is “state-dependent” stochastic choice (SDSC) data, as introduced
in Caplin and Martin [2015] and Caplin and Dean [2015]. This treats both the payo¤ determining
states of the world and the behavioral choice as observable. It rests on the idea that attentional
constraints do not apply to an ideal observer. While consumers may have di¢ culty assessing
whether or not sales tax is included in the price paid at the register, the econometrician knows
(Chetty et al. [2009]). The resulting data strongly re‡ects the match between perception and reality.
In fact our results show that SDSC data can capture the full behavioral footprint of attention costs,
in stark contrast with standard stochastic choice data.
    Our work is related to a growing recent literature aimed at understanding the behavioral im-
plications of models with limited attention. Notable recent contributions include Masatlioglu et al.
[2012], Manzini and Mariotti [2014], Oliveira et al. [2017] and Steiner and Stewart [2016]. More
speci…cally, there have been several recent papers which have used …rst order conditions to solve
the Shannon model (for example Stevens [2014], Matejka and McKay [2015], Steiner et al. [2015],
Caplin et al. [2016]). Unlike these papers, we provide a set of easily interpretable axioms which give
insight into the type of behavioral patterns that the Shannon model predicts. de Oliveira [2013]
considers the behavioral implications of the Shannon model, but for a data set which consists of
observed choices over di¤erent menus of alternatives. Instead, our work uses SDSC, and therefore
links in with the recent renewed interest in modelling random choice in general (e.g. Agranov and
Ortoleva [2015], Manzini and Mariotti [2016], Apesteguia and Ballester [2016]), and it’s relationship
to information acquisition in particular (e.g. Krajbich and Rangel [2011]).


                                                  3
    Section 2 de…nes attention strategies in analytically appropriate form, and introduces the var-
ious classes of attention cost functions. Section 3 establishes general applicability of Lagrangian
methods of identifying optimal strategies. Section 4 introduces SDSC data and links it to atten-
tion strategies. Section 5 introduces our IUC axiom and the associated characterization theorem.
Section 6 introduces the recoverability result. Our characterizations of the PS and UPS models
are in Section 7. Section 8 provides additional analyses concerning alternative formulations of the
representation theorems and the properties of our axioms. Section 9 relates our work to the existing
literature on attention. Section 10 concludes. Throughout the paper we present the main Theorems
and discuss informally why they are true. Formal proofs are in the Appendix.


2     Attention Strategies and Costs

2.1   Posterior-Based Attention Strategies

We consider a decision maker (DM) who faces a large class of decision problems related to an in…nite
(countable or uncountable) underlying set of conceivable states of the world and an uncountably
in…nite set of potentially available actions, A. In a given decision problem, the DM is endowed
with a prior with …nite support as well as a …nite set of available actions. The DM receives known
expected utility u(a; !) when action a 2 A is chosen in state ! 2 . We assume that A is rich
enough that values u(a; !) 2 R are unrestricted.


De…nition 1 Given 2 ( )             , ( ) f! 2 j (!) > 0g speci…es possible states (where
denote simple distributions over the space); ( ) = f 2 j ( )       ( )g possible posteriors; and
~ ( ) = f 2 ( )j ( ) = ( )g interior posteriors with precisely the same support as .


De…nition 2 A decision problem comprises a pair ( ; A) 2            A with A …nite. D is the set of
such decision problems.


   The central decision that we model concerns how much to learn. The DM decides this by
comparing the incremental improvement in decision quality associated with improved information
with the cost of incremental information. In formalizing the cost of learning, we will focus on the
outcome of the learning process and assign costs directly to each Bayes-consistent distribution of
posteriors, as in Caplin and Dean (2013). To this end, we de…ne an attention strategy in terms of
the resulting posteriors and their implications for choice.


De…nition 3 Given ( ; A) 2 D, the set of posterior-based attention strategies comprises all
simple probability distributions over posteriors and corresponding mixed action strategies,

                      ( ; A)   f = (Q ; q )jQ 2 Q( ), q : (Q ) !          (A)g ;

with A( )    A the chosen actions, and Q( ) the Bayes-consistent distributions,
                                                       X
                           Q( ) = fQ 2 ( ( ))j =              Q( )g:
                                                         2 (Q)




                                                 4
We de…ne corresponding unions ( ) and ; and also de…ne                           I(   )   ( ) as the set of inattentive
strategies such that (Q ) = .


    This posterior-based approach departs from the standard signal-based approach which speci…es
the cost of an available set of signals correlated with the true state of the world (see for example
Caplin and Dean [2015]). There are two key advantages of the posterior-based formulation. First,
our behavioral characterizations are more naturally stated in terms of posteriors. Second, this
formulation allows for several interesting generalizations of the Shannon cost function. Of course,
there is in general a mapping between signals and posteriors. We discuss in Section 8 why behavioral
results are independent of how strategies are formulated.
    Figure 1 illustrates the strategy  which we use as a running example. The underlying decision
problem consists of a prior with two states in its support, ( ) = f! 1 ; ! 2 g, each of which is equally
likely.1 The support of the strategy comprises two posteriors, (Q ) = a ; b :

                                           a         0:8           b       0:4
                                               =                       =              ;
                                                     0:2                   0:6

and speci…es Q ( a ) = 0:25 and Q ( b ) = 0:75. Actions a and b are chosen deterministically
from a and b respectively, q (aj a ) = q (bj b ) = 1.




                                                   Figure 1: Strategy

  1
      We use the notation
                                                                (! 1 )
                                                        =
                                                                (! 2 )
  to describe probability distributions.




                                                            5
2.2   Utility and Costs

The goal of the DM is to maximize prize-based expected utility (EU) net of additively separable
attention costs. Given 2 , prize based EU is computed in the standard manner,
                                    X X
                           U( )               Q ( )q (aj )u( ; a);
                                        2 (Q ) a2A

where u( ; a) is expected utility conditional on the posterior
                                               X
                                    u( ; a)           (!)u(a; !):                                  (1)
                                              !2 ( )

Attention costs for strategy 2 ( ) depend only on the distribution of posteriors Q 2 Q( ).
We assume that inattention is always possible, and normalize its cost to zero. We allow for the
possibility that some distributions of posteriors are infeasible by setting their costs to in…nity. For
example, there are interesting cases in which it is prohibitively costly to entirely rule out ex ante
possible states, so that it is infeasible to choose posteriors on the boundary of ( ).

De…nition 4 We de…ne F as the set of all priors and Bayes’ consistent posterior distributions,

                                   F = f( ; Q)j 2 ; Q 2 Q( )g:                                     (2)

We de…ne K as the set of all attention cost functions K : F ! R such that K( ; Q ) = 0 for
 2 I ( ).


2.3   The Shannon Cost Function

By far the best studied cost function that can be expressed directly in terms of priors and posteriors
is the Shannon function, in which the costs are linear in the mutual information between prior and
posteriors. It is standard that one Pcan compute mutual information by comparing the Shannon
entropy of the prior, H( ) =          !2 ( ) (!) ln (!), to the expected Shannon entropy of the
posteriors. In translating this into an attention cost function, note that what is costly is increasing
predictability, or reducing entropy. Given ( ; Q) 2 F, the Shannon attention cost function K S
with multiplicative factor > 0 is therefore speci…ed as,
                      2                                  3     2                             3
                         X                                        X
        K S ( ; Q)    4        Q( ) [ H( )] [ H( )]5 = 4                 Q( )H( ) + H( )5 :         (3)
                         2 (Q)                                   2 (Q)


    By way of illustration, consider attention strategy         from Figure 1. Figure 2 records the
probability of state ! 1 on the horizontal axis. The Figure re‡ects the fact that Shannon entropy is
strictly concave and symmetric around its maximized value at uniformity and that it is zero at the
end-points of the interval (since limx#0 x ln x = 0), at which it has unbounded derivative. Following
(3), we shift up the negative of the entropy function, which is strictly convex, to zero at the prior
of 0.5. The cost of strategy      is then found as the height of the chord joining the points on the
function corresponding to the two possible posterior likelihoods of ! 1 (0.4 and 0.8) as it passes over
the prior, as Figure 2 illustrates.

                                                     6
                                    Figure 2: Cost of Strategy


   Note that the Figure shows that all attentive strategies have strictly positive cost.


2.4   PS Cost Functions

The posterior-separable (PS) cost functions we study have the same form as (3), yet generalize the
underlying measure of disorder, or “entropy”, of the probability distribution over prior possible
states of the world. The only properties that are retained relate to the strict convexity of this
function and the speci…cation of inattention as feasible and free.

De…nition 5 An attention cost function is posterior-separable (PS), K 2 KP S ; if, given 2
 , there exists a strictly convex function T : ( ) ! R, real-valued on ~ ( ), such that, given
Q 2 Q( ),                                  X
                               K( ; Q) =      Q( )T ( ) T ( ),                             (4)
                                              2 (Q)

and such that the optimal posterior set ^ ( jK),
               ^ ( jK) = f 2 j9 ( ; A) 2 D and            2 ^ ( ; AjK) with     2 (Q )g;         (5)

is convex.

    To clarify …ne points in the de…nition, note that allowing T to take in…nite values for boundary
posteriors both covers various interesting forms of entropy (see section 8.3) and simpli…es our
behavioral characterization. Strict convexity in this case means that, given distinct posteriors
 1 , 2 at which T is real-valued (the set dom T in the notation of Rockafellar [1970] p. 23),

                         T (   1   + (1   )   2)   < T (   1)   + (1   )T (   2 );


                                                      7
all 2 (0; 1): hence dom T itself is a convex set. Our insistence that ^ ( jK) is also convex avoids
complications associated with possible non-existence of sub-di¤erentials on the boundary.2
    As noted in Section 9, functions of the PS form have featured in the literature on measures
of the information content of experiments following Blackwell [1951]. A straight forward result
with this functional form is that the strict convexity of T ensures that the corresponding measure
strictly respects the Blackwell partial ordering of information content (see Torgersen [1991]).
    In addition to allowing for general convex cost functions, note that this de…nition allows costs
to di¤er arbitrarily across priors, e.g. according to the cardinality of the state space. Subtraction
of T ( ) is a normalization which ensures that inattentive strategies are free as per the general
de…nition. Note that there are many di¤erent T functions that give rise to precisely the same cost
function. In particular, we show in the Appendix that K is invariant to a¢ ne transforms of T
(Lemma 4.3).


2.5    UPS Cost Functions

While the PS case allows for arbitrary dependence of the cost function on the prior, the Shannon
model does not exploit this freedom. Given distinct priors ; 0 2 , the function T ( ) and T 0 ( )
can be written in a manner that is independent of the prior. A …ne point relates to the possibly
in…nite costs of ruling out ex ante possible states. Note that even with Shannon cost functions, the
incremental cost of fully ruling out any prior possible state is unbounded at the margin. This means
that there is not full independence between the prior and the cost of the corresponding posterior.
However this dependence is limited. We can cover all such cases by insisting on a common T function
only for posteriors consistent with optimality.

De…nition 6 A PS cost function K 2 KP S is uniformly posterior-separable (UPS), K 2
KU P S , if there exists a strictly convex function T : ! R such that,
                                                X
                                    K( ; Q) =        Q( )T ( ) T ( ).            (6)
                                                   2 (Q)

                             ^ jK)
all ( ; Q) 2 F such that Q 2 Q(                Q( ) \      ( ^ ( jK)).

   Examples of cost functions which fall into the UPS category are those based on alternative
measures of entropy, such as that introduced by Tsallis [1988]. We discuss the relationship between
Tsallis and Shannon costs in Section 8.3.


3     PS Models, Optimal Strategies, and Lagrangians

In this section we identify optimal strategies using Lagrangian methods. We develop the geometric
intuition in the body of the text, with technical arguments in Appendix 1.
   2
     In general, the set of posteriors at which sub-di¤erentials exist (dom @T in the notation of Rockafellar [1970],
p. 227) need not be convex in particular contrived cases. Our results are most straight forward with ^ ( jK) convex,
which holds for all standard forms of entropy. While both are convex, note that ^ ( jK) may be a strict subset of
dom T . For example, the Shannon cost function is real-valued on the convex set ( ), while ^ ( jK S ) comprises
only interior posteriors, ^ ( jK S ) = ~ ( ).


                                                         8
3.1   Optimal Strategies

The value of strategy     2    ( ) is computed based on additive separability of prize utility and
attention costs.
                                      V ( ; jK)       U( )      K( ; Q ):
The value function and corresponding optimal strategies are then de…ned as:

                     V^ ( ; AjK)             sup      V ( ; jK);
                                         f 2 ( ;A)g
                                         n                                        o
                     ^ ( ; AjK)              2     ( ; A) jV ( ; jK) = V^ ( ; AjK) :


3.2   Net Utility

There are Lagrangian methods of characterizing optimal strategies in the PS model. Yet the fact
that costs can depend on the prior in the PS model gives rise to certain notational complexities.
Hence for expository purposes, we focus on the UPS case, noting at the end that the approach
generalizes to the PS case.
    The key geometric observation is that the value of any given strategy, modulo the normalizing
factor T ( ), can be decomposed into action speci…c net utilities, N a ( ),

                                         N a( )       u( ; a)    T ( ):                                         (7)
                              X
To con…rm, note that since          q (aj ) = 1 all     2 (Q ),
                              a2A
                                   X     X                                  X              X
      V ( ; jK) + T ( ) =                    Q ( )q (aj )u( ; a)                   Q ( )         q (aj )T ( )
                               2 (Q ) a2A                                 2 (Q )           a2A
                                   X     X
                          =                  Q ( )q (aj )N a ( ):
                               2 (Q ) a2A

Hence optimal strategies can be identi…ed as those that maximize the weighted averages of net
utilities.
    The net utility approach has simple geometric content. In Figure 3 we illustrate action-speci…c
net utilities in a simple two-state case with ( ) = f! 1 ; ! 2 g and (! 1 ) = 0:5. The probability of
state 1 is on the horizontal axis. The red, dashed line graphs T ( ) as a function of (! 1 ). The
green line represents the prize-based expected utility of an action a in which we have assumed that:
u(a; ! 1 ) = 1 and u(a; ! 2 ) = 0. To compute net utility we simply subtract the cost from the bene…t
(for clarity in the Figure we illustrate N a ( ) + T ( ) which allows us to see the tangency of net
costs with gross costs when = ). The result is the blue line in the Figure. Note that since net
utility is the di¤erence between a line and a strictly convex function, it is strictly concave.




                                                        9
                                 Figure 3: Net Utility of Action a:


    Figure 4 illustrates net utilities for a decision problem ( ; A) with two equiprobable states and
two actions, A = fa; bg. The second action is the mirror image of the …rst, with u(b; ! 1 ) = 0 and
u(b; ! 2 ) = 1. We illustrate in the Figure computation of the net utility of strategy . Precisely
as when computing the cost, the value is found by joining the points on the net utility function
corresponding to possible posteriors with a chord, and …nding the value of the chord as it passes
over the prior. Thinking of all such chords identi…es optimal strategies as de…ned by the posteriors
that support the highest chord passing over the prior. In Figure 4 posteriors ^ a and ^ b have this
property, and so form the support of an optimal strategy for this decision problem. Note that our
example strategy       is non-optimal, since the corresponding chord passes strictly below the top




                                                 10
chord.




                                Figure 4: Net Utility of Strategy



3.3      Lagrange Multipliers and the PS model

The shaded area in Figure 4 is the lower epigraph of the concavi…ed net utility function, de…ned as
the minimal concave function that majorizes all net utilities (Rockafellar [1970]). The applicability
of Lagrangian methods rests on the fact that the lower epigraph is always a convex set. This is
geometrically clear in the simple case illustrated in Figure 4, and applies quite generally. Indeed,
the same geometric approach works not only for UPS cost functions, but also for PS cost functions,
in which net utilities are speci…c to the prior. For PS cost functions, we …x the prior and again
de…ne action-speci…c net utilities as N a ( ),

                                     N a( )    u( ; a)   T ( ):                                  (8)

The key geometric observation is that one can still compute optimal strategies by appropriately
averaging these action and prior speci…c net utilities. Hence identical convex analytic methods
apply.
    The geometric approach in Figure 4 is completely general. There is one important point to
note in so generalizing, which derives from the adding up constraint on probabilities. Given this
constraint, Figure 4 represents a two-dimensional state space in one dimension. This transformation
is of great general value. Given 2 with j ( )j = J, we transform ( ) into the equivalent
subspace of RJ 1 . To simplify, we give all states distinct integer labels 1   j   J, and let J 1




                                                 11
denote the corresponding space of probability distributions:
                                      8                                9
                                      <             J
                                                    X1                 =
                               J 1
                                    =     2 RJ+ 1        (j)       1       ;                        (9)
                                      :                                ;
                                                        j=1

                 PJ   1
with (J) = 1        j=1   (j) left as implicit.
     In Appendix 2 we establish a “Lagrangian”lemma that shows that there is always a supporting
hyperplane to the lower epigraph of the convexi…ed net utility function (Lemma 2.6). The analytic
translation of this geometrically clear result is that optimal attention strategies are characterized by
Lagrange multipliers (j) conveying the change in net utility as each posterior (j) for 1 j J 1
is raised at the expense of reducing (J). The Lagrange multipliers de…ne the slope of the supporting
hyperplane at the optimum. All chosen actions have net utilities that lie on this hyperplane at
the corresponding chosen posterior, while no net utility function breaches the hyperplane for any
posterior.


Lagrangean Lemma: Given K 2 KP S and ( ; A) 2 D, 2 ^ ( ; AjK) if and only if 9 2 RJ                   1

    s.t.,
                        J
                        X1                               J
                                                         X1
                  a                              a0 0
                N ( )       (j) (j)       sup   N ( )        (j) 0 (j);
                                  j=1             a0 2A; 0 2 ( )               j=1

      all   2 ( ) and a 2 A, with equality if      2 (Q ) and q (aj ) > 0.


    Note that this lemma characterizes optimal strategies, and opens up standard methods of model
solution. In addition, it conveys important qualitative features of the behavior implied by PS and
UPS models. We return to this in later sections.


4     SDSC and Representations

In this section we introduce the data set and the sought after representations.


4.1   State Dependent Stochastic Choice Data

The key question in applied work on attention is the extent to which DMs internalize the actual
decision making environment in which they …nd themselves. Do they notice whether or not a sales
tax is included in the price paid at the register (Chetty et al. [2009])? Do they notice ‡uctuating
prices of the same good in a supermarket (Matµejka [2015])? Essentially all such situations can be
captured using the general model above, by appropriately specifying available actions, the various
factors (states of the world) that determine their payo¤s, and prior beliefs about how likely is each
such state.
    Our goal is to specify observable patterns in choice data that narrow down the theories of
inattentive choice. Before we begin, however, we must …rst specify exactly what sort of data is
su¢ cient for this task. An important …rst point is that standard stochastic choice data, in which one
only observes the unconditional likelihood of each choice, is fundamentally inadequate for capturing

                                                   12
attentional constraints. To see this, consider the two action decision problem illustrated in Figure
4. Note that the symmetry of the decision problem implies that the optimal strategy results in each
action being chosen equally often. In the particular strategy chosen, this re‡ects partial information.
Yet the same unconditional probabilities are also consistent with perfect information, with each
action chosen precisely when it is optimal. These probabilities are also consistent with completely
inattentive choice, with a fair coin ‡ipped to decide which action is taken. Unconditional choice
probabilities in no way re‡ect the extent to which behavioral patterns are impacted by reality. One
must also know how well the action suited reality.
    As …rst noted by Block and Marschak [1960] (p. 98-99), the way forward lies in realistically
enriching the ideal behavioral data available to an ideal observer (IO), such as an econometrician or
economic theorist, in which of costs of attention are to be identi…ed. The key to our data enrichment
is the observation that the information constraints that impact the DM do not apply to the IO.
For example, while the DM may have di¢ culty assessing whether or not a sales tax is included in
the purchase price or what the actual price of each good is in a supermarket, the IO with access
to the underlying reality does not. In de…ning our data, we therefore specify that the IO observes
both the state of the world as well as the action.
    In formal terms, our behavioral data set is state dependent stochastic choice (SDSC) data,
as in Caplin and Martin [2015] and Caplin and Dean [2015]. We specify both states and actions
as being fully observed by the IO. We further specify our IO as able to watch this DM facing
this same decision in…nitely often, with precisely this strategy used each time.3 For the IO to
treat repeated observations of the DM as deriving from the same decision problem implies that
the set of available actions, A, is the same. It requires also that the DM is seen as having the
same prior     over possible states of the world. We assume that the IO then observes the full
distribution of actual state realizations and action choices. In terms of interpreting the data as
revealing of patterns of attentional choice, we make the simplifying assumption that there are
common probability assessments between IO and DM. We call this “rational expectations” with
which it has spiritual commonalities.
    A key observation is that rationality of expectations enables the IO to infer the DM’s presumed
prior as the actual proportion of times each state is realized. We therefore treat the prior itself as
observable in specifying our behavioral data set in its most general form.


De…nition 7 Given ( ; A) 2 D, we de…ne state dependent stochastic choice (SDSC) data
as mapping from possible states to action probabilities,

                                       P( ; A)      fP :      ( )!    (A)g ;

with P (aj!) the probability of action a in state !. We de…ne P( ) as the union over all corre-
sponding decision problems and P [ 2 P( ).


    Implicit in this de…nition is the assumption that the expected utility function of the DM is part
of the data. One could readily replace this assumption with an enrichment of the data set that
allowed for utilities to be recovered from behavior, as discussed in Caplin and Dean [2015].4
   3
     In practice one might apply a model of this form to a population rather than an individual, as in the literature
on discrete choice following McFadden [2005].
   4
     One could replace the “Savage style”actions we use in this paper with “Anscombe-Aumann”acts that map states



                                                         13
    While only recently introduced in economics, SDSC data has a long and storied history in psy-
chometrics. The Weber-Fechner laws, which are based on corresponding data, identify regularities
in how well humans perceive objective di¤erences in the strength of various external stimuli.
    There are two key di¤erences between our approach and the standard psychometric approach.
First, we follow classical economic logic, so that the stimuli are levels of utility, or reward. Second,
we model perceptual e¤ort as chosen in light of potential rewards. Given this, we will show that
rich behavioral data has patterns in it that fully reveal costs of accurately recognizing external
reward stimuli.


4.2    From Strategy to Data

We illustrate in Figure 5 how seeing data on states and actions captures the behavioral imprint of
our running example, strategy . Given the assumed rationality of expectations, the subjective
probabilities of the DM agree with the data frequencies as seen by the IO. What the IO will then
see is a joint distribution of states and actions with precise probabilities determined by the prior,
the posteriors, and the mixed action strategy.




                                Figure 5: Data Generated by Strategy



    The fact that action a is chosen if and only if the DM receives a , and that Q ( a ) = 0:25
means that action a will be chosen 25% of the time (and b the remaining 75% of the time). Because
 a is associated with an 80% probability of ! (and a 20% probability of ! ), the resulting joint
                                               1                               2
probability of a and ! 1 is 20%. All other joint probabilities can be calculated in a similar way, as
shown in Figure 5. These joint probabilities can be converted into conditional probabilities using
Bayes’rule, giving the SDSC P associated with :

                                   P (aj! 1 ) = 0:4;        P (bj! 1 ) = 0:6;
                                   P (aj! 2 ) = 0:1;        P (bj! 2 ) = 0:9:
of the world to probability distributions over the prize space. Assuming the DM does maximize expected utility, u
could then be recovered by observing choices over degenerate acts (i.e. acts whose payo¤s are state independent).


                                                       14
    This method for generating data from strategies is more general. Following the logic of Figure 5,
we translate each strategy 2 ( ; A) into its observable counterpart in SDSC data, P , assuming
rational expectations. With this notation, note that P = P .

De…nition 8 Given 2 ( ; A) we de…ne the generated SDSC data P :                     ( )!   (A) and the
corresponding action choice probabilities P (a) on a 2 A( ) by:
                                             X
                                                  Q ( )q (aj ) (!)
                                             2 (Q )
                             P (aj!) =                                  ;
                                                          (!)
                                             X
                                 P (a) =              Q ( )q (aj ):
                                            2 (Q )



4.3   Choice Correspondence and Representations

In the idealized data set that we consider, SDSC data is available for all decision problems. As
indicated, and as in Caplin and Dean [2015], we assume that the IO knows all details of the decision
problem faced by the DM, which includes the prior and the payo¤s to all available actions. For
technical reasons, it simpli…es the statement of our representation theorems to imagine that the IO
sees a data set that is deep as well as broad. It speci…es for each decision problem a corresponding
set of qualifying SDSC functions - i.e. all such functions used by the DM in that decision problem.
Following Richter [1966], this is in the spirit of standard choice analysis based on a correspondence
mapping a choice set to a subset of suitable alternatives. C is the set of such data sets:

                             C     C : D ! 2P =;jC( ; A)        P( ; A) :

This level of arti…ciality turns out to be substantively irrelevant. We discuss in Section 8 how our
results extend to cases in which one sees only a selection from this data correspondence.
    We say that a data set C has a costly information representation based on a cost function K if
the observed SDSC data C( ; A) corresponding to each decision problem ( ; A) coincides with the
SDSC data P generated by optimal strategies 2 ^ ( ; AjK).

De…nition 9 Data set C 2 C has a costly information representation (CIR) based on K 2 K
if, for all ( ; A) 2 D,

                        C( ; A) = fP 2 Pj 2 ^ ( ; AjK)g           P^ ( ; AjK):

  1. It has a posterior-separable (PS) representation it is has a CIR K 2 KP S .
  2. It has a uniformly posterior-separable (PS) representation it is has a CIR K 2 KU P S .
  3. It has a Shannon representation if it has a CIR K = K S for             > 0.


4.4   The Revealed Strategy

Caplin and Dean [2015] show that, while there is a multiplicity of strategies that could have gen-
erated any SDSC data, there is always a unique least Blackwell informative strategy consistent

                                                 15
with the data. The …rst step in constructing this strategy is to identify with each chosen action a
the corresponding “revealed posterior” aP . This treats the action as chosen at one and only one
posterior which can be inferred from our behavioral data using Bayes’rule. Building on this, the
“revealed posterior-based strategy” is the least Blackwell informative strategy consistent with the
data. As such, it is the least costly for all our PS cost functions. It follows that for the class of
models we consider in this paper, optimality implies that the revealed attention strategy is used by
the DM in each decision problem.


       P 10 Given ( ; A) 2 D, P 2 P( ; A), and a 2 A, we de…ne revealed action probability
De…nition
P (a) = !2 ( ) (!)P (aj!). We de…ne A(P ) as the actions chosen with positive probability. If
a 2 A(P ) A, we de…ne also revealed posterior aP 2 ( )

                                                   a              (!)P (aj!)
                                                   P (!)      =              ;
                                                                    P (a)

with (P ) the union across a 2 A(P ). The revealed posterior-based attention strategy (P ) =
(QP ; qP ) 2 ( ; A)5 is de…ned by (QP ) = [a2A(P ) aP and:
                                                                    X
                                          QP ( ) =                                   P (a);
                                                              fa2A(P )j    a=    g
                                                                           P
                                                              (
                                                                  P (a)              a
                                                                  QP ( )    if       P    = ;
                                         qP (aj ) =                                  a
                                                                    0       if       P    6= :

   To illustrate construction of the revealed attention strategy, consider the data set P = P .
The revealed posterior associated with the choice of action a is,

                                   a               (! 1 )P (aj! 1 )   0:5 0:4
                                   P    (! 1 ) =                    =         = 0:8:
                                                       P (a)            0:25

Similarly
                               a                      b                                   b
                               P   (! 2 ) = 0:2;      P    (! 1 ) = 0:4; and              P    (! 2 ) = 0:6
We can then calculate the revealed strategy as involving
                                   a
                         QP (      P   ) = P (a) = (! 1 )P (aj! 1 ) + (! 2 )P (aj! 2 )
                                          = 0:5 (0:4 + 0:1) = 0:25:

Hence,
                                                          b
                                              QP (        P   ) = P (b) = 0:75;
Furthermore,
                                                      a                               b
                                             qP (aj   P       ) = 1 = qP (bj          P   ):

      Note in this case that           is in fact the revealed strategy associated with data set P            =P ,

                                                      = (P ) = (P ):

While this does not hold for arbitrary strategies, it is general for data observed in our representa-
  5
      See Appendix 1 for direct con…rmation that          (P ) 2 ( ; A).


                                                                  16
tions, as discussed in Caplin and Dean [2015]. Appendix 2 contains this result together with other
general results that link strategies revealed by data in costly information representations with the
SDSC data generated by optimal strategies.


5     Compression and the Shannon Model

Having introduced the key model elements and data-related de…nitions, we turn now to the results
themselves. In this section we start with a data set having a UPS representation and identify
additional behavioral restrictions that make this a Shannon representation. As the de…nitions
show, the UPS form allows for a general convex function T ( ), while Shannon restricts T ( ) to a
particular one parameter family, T ( ) = ln( ). This restriction on T implies many qualitative
restrictions on behavior. For example, there are strong symmetry properties, so that behavior
must indicate that all states individually are equally easy or di¢ cult to perceive. There are also
no complementarities, so that learning about one state makes it no easier (or more di¢ cult) to
learn about any separate state. There are also very strong smoothness properties and profound
quantitative restrictions e.g. in terms of the response to payo¤ changes.
    Our …rst theorem establishes that a single behavioral invariance axiom is enough to move us
from a UPS representation to a Shannon representation, hence conveying all of these particular
properties noted above and all others besides. This axiom insists that choices not change when
payo¤ equivalent states are “compressed” into a single state. In the remainder of the section we
…rst introduce this behavioral axiom intuitively. We then formalize it and state the main theorem.
Finally, we sketch the proof. The proof itself, which is involved, is in Appendix 5.


5.1   Basic Decision Problems and Basic Forms

What precisely does it mean to say that payo¤s alone matter? To specify, consider …rst decision
problems in which all states are distinct in terms of payo¤s, so that no two possible states have
identical payo¤s for all available actions. We call these “basic” decision problems.


De…nition 11 Given ( ; A) 2 D, a decision problem is basic, ( ; A) 2 B          D if, given ! 6= ! 0 2
 ( ), there exists a 2 A such that u(a; !) 6= u(a; ! 0 ).


   Consider now a non-basic decision problem with three possible states:      ( ) = f! 1 ; ! 2 ; ! 3 g and
two actions A = fa; bg. In this problem, states ! 1 and ! 2 are equivalent:

                                   u(a; ! 1 ) = 1, u(b; ! 1 ) = 0;
                                   u(a; ! 2 ) = 1, u(b; ! 2 ) = 0;
                                   u(a; ! 3 ) = 0, u(b; ! 3 ) = 1:

There are two obvious ways to shift all probability from the two equivalent states to one or the
other of them. One way is to set (! 1 ) = (! 1 ) + (! 2 ) and (! 2 ) = 0, with (! 3 ) = (! 3 ). The
alternative is to set ^ (! 2 ) = (! 1 ) + (! 2 ) and rule out state ! 1 . These priors associated with
these two “basic forms” of ( ; A) are illustrated in Figure 6.



                                                 17
                            Figure 6: Basic Forms of Decision Problem
                                              ( ; A)


We now provide the general technical de…nitions.


De…nition 12 We associate ( ; A) 2 D with a set of basic forms ( ; A) 2 B( ; A)                         B by:


  1. Partitioning ( ) into L basic sets                l(    )               comprising payo¤ equivalent states, so
                                                                  1 l L
     that, given ! 2 l ( ) and ! 0 2 m ( ),

                                   l = m i¤ u(a; !) = u(a; ! 0 ) all a 2 A:

  2. Labeling all possible states both by equivalence class and in order within each equivalence class:

                             ( ) = f! li jj1       i   I(l) = j        l
                                                                           ( )j and 1       l   Lg:

  3. Selecting {(l) 2 f1; ::; I(l)g all l and de…ning            ( ) = [L     l
                                                                        l=1 ! {(l) :

  4. De…ning     2 ( ) by setting
                                                   8
                                                   > I(l)
                                                   < X
                                                   >
                                                                 (! lj ) if i = {(l);
                                       (! li ) =                                        :
                                                   >
                                                   >   j=1
                                                   :         0 if i 6= {(l):

     Given {(l) 2 f1; ::; I(l)g on 1    l      L, we say ( ; A) 2 B( ; A) for {.




                                                        18
5.2   Invariance Under Compression

Note that there is no functional value for the DM in distinguishing between states that assign the
same payo¤ to all actions. Hence an ideally designed machine for encoding states would not waste
any of its scarce resources on this task. The stochastic structure of choice would not change if
distinct yet payo¤ equivalent states were “compressed” into a single state.
   Our Invariance under Compression axiom insists that patterns of choice are equivalent in all
decision problems with a common basic form.


Axiom A1 Invariance under Compression (IUC): Given ( ; A) 2 B( ; A) for {,

                         P 2 C( ; A) () 9P 2 C( ; A) s.t. P (aj! li ) = P (aj! l{(l) ),

      all 1   i   I(l); 1   l    L and a 2 A.


    We can illustrate the meaning of IUC using the example discussed above, in which the decision
problem ( ; A) is such that ( ) has two basic sets: f! 1 ; ! 2 g and f! 3 g. Note …rst that IUC
implies that, for any observed P 2 C( ; A) it must be the case that P (aj! 1 ) = P (aj! 2 ) for all
a 2 A: the DM must behave identically in any states that belong to the same basic set. Moreover,
behavior in ( ; A) must be similar to behavior in the basic version of the problem. For example,
given (! 1 ) = (! 1 ) + (! 2 ), P 2 C( ; A) if and only if P (aj! 1 ) = P (aj! 1 ) = P (aj! 2 ) for some
P 2 C( ; A) and all a 2 A. The fact that this also holds for the basic version of the problem in
which ^ (! 1 ) = (! 1 ) + (! 2 ) means furthermore that behavior in the two basic versions of the
problem must be the same: P 2 C( ; A) if and only if P (aj! 1 ) = P^ (aj! 2 ) for some P^ 2 C(^ ; A).
An immediate corollary is that, for any prior     such that (! 3 ) = (! 3 ) and ( )                ( ) it
must be the case that C( ; A) = C( ; A):
    The key result is that the Shannon cost function alone among UPS cost functions satis…es this
invariance axiom.


Theorem 1: Data set C 2 C with a UPS representation has a Shannon representation if and only
    if it satis…es IUC.


5.3   Necessity

That IUC is necessary for a Shannon representation follows directly from the posterior-based char-
acterization of the solution to the Shannon model. Caplin and Dean [2013] provide an “invariant
likelihood ratio”condition for optimality. This states that P 2 C( ; A) is consistent with optimality
for a cost function K S if and only if:


  1. Given a; b 2 A(P ),
                                     a (!)                b (!)
                                     P                    P
                                                 =                    all ! 2 ( ):                  (10)
                                exp(u(a; !)= )       exp(u(b; !)= )



                                                     19
  2. Given a 2 A(P ) and c 2 AnA(P ),
                                X              a (!)
                                               P
                                                             exp(u(c; !)= )   1:
                                        exp(u(a; !)= )
                               !2 ( )


   It is the fact that these conditions are invariant under the compression operation that establishes
IUC as necessary for a Shannon representation, as formalized in Appendix 5.


5.4     Guide to the Su¢ ciency Proof

While the necessity proof is straight forward, the su¢ ciency proof is not. Theorem 1 establishes that
IUC is profoundly powerful. It implies that, starting with behavior generated by a general strictly
convex function, IUC plus one attentive choice pins down behavior in all decision problems. This
follows since the attentive choice pins down the single parameter > 0 in the Shannon function,
leaving no more degrees of freedom.
    Given the vast distance that the proof must travel to rule out all other forms of the cost
function, it involves several stages that we elaborate on brie‡y here. The proof itself involves many
corresponding lemmas that provide details.
    One line of argument uses IUC to establish strong symmetry properties of the cost function:
here the argument is direct. Two other key aspects of the proof take up issues of smoothness
and functional form. In particular, there are strong di¤erentiability and additive separability
arguments. With these established, we identify a second order PDE that must be satis…ed
and that implies the Shannon form. The smoothness and separability arguments work in a …xed
state space of cardinality 4 or higher. The …nal step in the proof involves using IUC to link cost
functions across dimensions and to iterate down to dimensions below four. We brie‡y outline what
is accomplished in each stage, leaving the full treatment to the Appendix.


5.4.1    Symmetry

The …rst step in the proof is to introduce and demonstrate the powerful symmetry implications of
IUC. The de…nition of symmetry in beliefs is direct: 1 ; 2 2 are symmetric, 1         2 , if there
exists a bijection : ( 1 ) ! ( 2 ) such that, for all ! 2 ( 1 ),

                                           1 (!)   =   2(   (!)):

Correspondingly, the strictly convex function T :           ! R is symmetric if,

                                    1      2   =) T (   1)   =T(    2) :

A sequence of results establishes that IUC implies symmetry of the T function in a UPS represen-
tation (Lemma 5.7).


Symmetric Cost Lemma: GivenPC 2 C satisfying Axiom A1, any function T :                    ! R in a
   UPS representation K(Q) = (Q) Q ( ) T ( ) must be symmetric.



                                                   20
    Intuitively, Axiom A1 implies that relabeling the states cannot a¤ect choice. To see this consider
two basic decision problems ( 1 ; A1 ) and ( 2 ; A2 ) that are symmetric in the sense that 1 (!) =
 2 ( (!)) for each ! 2        ( 1 ) and such that, for each a 2 A1 , there exists b 2 A2 such that
u(a; !) = u(b; (!)) where the implied mapping between A1 and A2 is bijective. Now consider
a third problem ( 3 ; A3 ) which involves replicating ( 1 ; A1 ) and ( 2 ; A2 ) on a set of states ( 3 )
disjoint from ( 1 ) [ ( 2 ), and then consider the problem ( 31 + 32 + 23 ; A1 [ A2 [ A3 ). ( 1 ; A1 ),
( 2 ; A2 ); and ( 3 ; A3 ) are all basic versions of this last problem and therefore the SDSC data
generated by ( 1 ; A1 ) and ( 2 ; A2 ) is similar to the SDSC data generated by ( 3 ; A3 ) and hence
each is similar to the other. It is a small step from this observation to the Symmetric Cost Lemma.


5.4.2      Di¤erentiability

As noted above, much of the proof involves working within a …xed state space ~       of cardinality
J 4, with the states indexed by j. Recall that ~ comprise the interior posteriors with ( ) = ~
and we correspondingly let T~ be the restriction of T to ~ . By symmetry, the form of this function
depends only on the cardinality J.
    Given 2 ~ and any pair of states i 6= j we de…ne the one-sided derivative in direction ji, T~!
                                                                                                 ji
                                                                                                    ( ),
as the directional derivative associated with increasing the ith coordinate and equally reducing the
jth:
                                              T~( + (ei ej )) T~( )
                               T~!
                                 ji
                                    ( ) = lim                         ;
                                                    #0

where ek 2 RJ is the corresponding unit vector.6
    Since T~ is convex, we know that T~!  ji
                                             ( ) exists. We de…ne also the two-sided derivative in
              ~
direction ji, T(ji) , by:
                                              T~( + (ei ej )) T~( )
                            T~(ji) ( ) = lim                         :
                                                     !0

While in principle the two-sided derivative need not exist, we show that it always does (Lemma
5.32). The proof makes heavy use of results in Rockafellar [1970] and the profound structure
that IUC conveys. The proof is carried out in stages, interactively with the proof of full additive
separability, discussed further below.
    With T~(ji) ( ) existing always, we can de…ne cross directional derivatives of T~. Given 2 ~ and
any two pairs of states i 6= j and k 6= l, we de…ne the corresponding cross derivative of T~(ji) in
direction lk as the corresponding (two-sided) directional derivative,

                                                         T~(ji) ( + (ek     el ))   T~(ji) ( )
                                  T~(ji)(lk) ( ) = lim
                                                    !0

Again, we show that these cross-derivatives exist everywhere in ~ (Lemma 5.36).
  6
      This is de…ned in Rockafellar [1970] as the directional derivative of T~ at   in direction ei ej direction, T~0 ( jei ej )




                                                              21
5.4.3   Additive Separability

The proof of additive separability is staged and inter-leaved with the proof of di¤erentiability.
While we cannot in the text convey the full ‡avor of the additivity and di¤erentiability results, it
may be helpful to point out several key insights.
    The …rst observation is that the Lagrangian Lemma implies that there is a common hyper-
plane tangent to each of the net utility functions at each chosen posterior. This links directional
derivatives of the net utility function at distinct optimal posteriors (Lemma 5.11).


Equalization of Directional Derivatives: Suppose C 2 C has a UPS representation K, and
    consider ( ; A) 2 D and P 2 C( ; A) with a; b 2 A(P ) with f aP ; bP g ~ . Suppose that
    both T~(ji) ( P ) = T~(ji) ( P ), then
           a      a       b      b


                                                     a        a       b           b
                                                    N(ji) (   P)   = N(ji) (      P ):


    A second observation is that IUC places structure on the sets of posteriors that can be linked
by considering decision problems with equivalent states. In Figure 7, we illustrate this implication
of IUC with three states, but the intuition applies generally. Consider a decision problem with
three states (! 1 ; ! 2 ; ! 3 ) and two actions A = fa; bg, in which states ! 1 and ! 2 are equivalent.
Figure 7 displays the space of potential priors and posteriors. Suppose that 1 is the prior in the
basic problem in which all of the combined probability of ! 1 and ! 2 is assigned to ! 1 and 2 is
the prior in the case in which ! 2 receives all of the weight. Since 1 (! 1 ) = (! 2 ) the line segment
connecting these two priors is parallel to the segment connecting (1; 0; 0) and (0; 1; 0). The line
segment connecting 1 and 2 represents the set of potential priors for which,

                                            (! 1 ) + (! 2 ) =      1 (! 1 )   =   2 (! 2 );

so that (   1 ; A)   and (   2 ; A)   are basic versions of ( ; A).
    The above shows that, letting to be an arbitrary prior in this set, IUC places restrictions
on the relationship between the optimal posteriors for the problems ( ; A), ( 1 ; A) and ( 2 ; A)
(Lemma 5.12). Consider a . Bayes rule states that a (!) = P (aj!) (!)=P (a). IUC implies that
P (aj!) and P (a) are the same for all on the segment connecting 1 and 2 , including 1 and 2
themselves. This implies that as moves from 1 to 2 , a and b are always proportionate to .
It follows that a and b lie at the intersection of a line through and (0; 0; 1), the dashed grey
line in the …gure, and a line parallel to the segment connecting (1; 0; 0) and (0; 1; 0), the solid red
and blue lines in the …gures. a1 and b1 in the …gure denote the optimal posteriors for ( 1 ; A), and
  a and b the optimal posteriors for ( ; A).
  2       2                              2




                                                              22
                                 Figure 7: Implications of Compression


    These two observations when combined relate the derivatives of T~ at a and b in the Figure.
The Lagrangian Lemma implies that there is a hyperplane tangent to both N ( a ) and N ( b ).
Suppose that both T~(ij) ( a ) and T~(ij) ( b ) exist. Since prize-based expected utility is linear, the
di¤erence between T~(ji) ( a ) and T~(ji) ( b ) must equal u(a; ! i ) u(a; ! j ) u(b; ! i ) + u(b; ! j ). Since
shifts in from 1 to 2 , do not a¤ect prize based utility, T~(ji) ( a ) T~(ji) ( b ) must be independent
of whenever both derivatives exist (Lemma 5.13).
     Consider now two priors and ^ , each lying between 1 and 2 . The four posteriors a , b ,^ a ,
and ^ b form a trapezoid in the Figure. If T~ is di¤erentiable at all four points we would know that
T~(ji) ( a ) T~(ji) ( b ) = T~(ji) (^ a ) T~(ji) (^ b ). We show that in general (Lemma 5.17):

                                  T~!
                                    ji
                                       (   a
                                               )     T~!
                                                       ji
                                                          ( b ) = T~!
                                                                    ji
                                                                       (^ a )   T~!
                                                                                  ji
                                                                                     (^ b )               (11)

We do so by …nding pairs of di¤erentiable points that simultaneously converge to the four posteriors
 a , b ,^ a , and ^ b .


    Equation (11) is close to the rectangle condition for additive separability. To apply the rectangle
condition, we deform the simplex so that the trapezoid becomes a rectangle, and then return to
the simplex. This results in the following characterization of the directional derivative which we
state in terms of the dimension J since it requires J 4 (Lemma 5.21):

                                                       (1)
                          T~!
                            ji
                               ( )=A                                + B ( (2); :::; (J        1)) ;       (12)
                                                   (1) + (J)

for some A : R+ ! R and B : RJ 2 ! R; and all 2 i 6= j J 1. As (11) must hold for a range
                                           (1)
of (1) and (J) we can show that A (1)+        (J) must be constant (Lemma 5.22). Symmetry then
implies that, if T~! ( ) does not depend on (1) and (J), B cannot depend on any (k) other than
                  ji




                                                               23
 (i) and (j) (Lemma 5.24). Finally, we use the fact that T~(ji) ( ) = T~(ki) ( ) T~(kj) ( ) whenever
the latter are well de…ned to establish that there exists a function f on (0; 1) such that for all 2 ~
(Lemma 5.29):
                                     T~!
                                       ji
                                          ( ) = f ( (i)) f ( (j)):

This function is then used to show that the two-sided directional derivatives T~(ji) exist everywhere
(Lemma 5.36).


5.4.4   The Second Order PDE and Shannon Entropy

Consider again the problem in Figure 7. The Lagrangian Lemma implies that as we shift between
                                                         a    a          b    b
 1 and 2 , the resulting revealed posteriors satisfy N(ji) ( ( )) = N(ji) ( ( )). Setting (t) =
t 2 + (1 t) 1 , we can de…ne a (t) = a ( (t)) and b (t) = b ( (t)) to be the revealed posteriors
associated with (t). Given the twice di¤erentiability of T~, we have dt
                                                                     d    a ( a (t)) = d N b ( b (t)),
                                                                        N(ji)          dt (ji)
and, since ! 1 and ! 2 are redundant prized-based utility does not depend on t, so that
                                      d ~         a             d ~
                                        T (           (t)) =      T ( b (t)).
                                      dt (ji)                   dt (ji)
Finally, note that since a (t), (t), and b (t) all lie along a line through (0; 0; 1), a change in t
alters a proportionately more than b . It follows that
                                 a
                                     (1)T~(ji)(12) (   a
                                                           )=    b
                                                                     (1)T~(ji)(12) ( b ).

Since this equation holds for all (1), both sides must equal some constant                  J,   and, since T~(ji) ( ) =
f ( (i)) f ( (j)), we arrive at
                                          (1)f 0 ( (1)) = J :
A particular solution to this equation is       J
                                                ln x. Integrating once more yields the Shannon form:
                                                 X
                                          T~ = J       (j) ln( (j)):
                                                       j

Other solutions to these di¤erential equations can be rejected as either irrelevant (they sum to a
constant because the (j) sum to a constant), inconsistent with the dependence of T~(ji) on solely
on (i) and (j), or inconsistent with symmetry.


5.4.5   IUC and Universal Domain

The proof at this stage has three gaps. First, it applies only to interior posteriors. Second, there is
no tie between dimensions J 4. Third it does not cover lower dimensional cases. We show next
that IUC solves all of these.
    The …rst key observation is that, given J 4, all optimal strategies are precisely as if J applied
to all posteriors 2 with j ( )j = L           J. Note that, as a convex function, the costs are at
least as high as the limit of the costs on the boundary. This limit function is in fact the classical




                                                           24
Shannon entropy function,
                                                   L
                                                   X
                                               J
                                      T( )               (l) ln (l):
                                                   l=1

Even if costs take this minimum value, the known necessary and su¢ cient conditions for optimality
imply that no prior possible states are ever ruled out in an optimal strategies. Hence the behavioral
data is precisely as it would be if this function applied to all posteriors, even those that set some
prior possible states as impossible.
    The …nal part of the proof uses IUC to iterate down in dimension. To be precise, de…ne K J to
be the Shannon cost function with parameter J for J       4 as de…ned on all posteriors with that
state space or below,
                                  X
                    KJ ( )     J
                                       (j) ln (j); all 2 with j ( )j J:
                                  j2 ( )

The precise result we establish is that, given any decision problem ( ; A) 2 D with a prior of
cardinality one lower, j ( )j = J 1,

                        P 2 C( ; A) i¤ 9 2 ^ ( ; AjK J ) such that P = P .

Note that establishing this completes the proof of the theorem, since it directly implies that J =
 J 1 for J   4, where the Shannon form was already established, and that the Shannon form and
the corresponding parameter apply also to J = 3, then iteratively to J = 2, completing the logic.


6     Existence and Recoverability

As indicated in the introduction, our remaining results establish necessary and su¢ cient conditions
for a UPS representation. In this section we cover the …rst stage of this three stage process, by
introducing conditions that establish recoverability of the cost function.


6.1   NIAS, NIAC, and Completeness

Our general recoverability result rests on three axioms, all of which are necessary for a PS repre-
sentation of any kind, and indeed apply even more generally. Our …rst two axioms are required for
existence of any CIR. “No Improving Action Switches” (NIAS), due to Caplin and Martin [2015],
is based on utility being maximized at each posterior. It insists that all actions chosen maximize
expected utility at the corresponding posterior. “No Improving Attention Cycles”(NIAC), adapted
from Caplin and Dean [2015], rules out switching attention strategies across problems in a manner
that increases overall utility. It insists that attention strategies cannot be shu- ed between decision
problems in such a manner as to raise total utility across these decision problems.


Axiom A2 No Improving Action Switches (NIAS): Given ( ; A) 2 D and P 2 C( ; A),
                                                         a              a
                                    a 2 A(P ) =) u(      P ; a)   =u
                                                                   ^(   P ; A);




                                                   25
        where,
                                                  u
                                                  ^( ; A)        max u( ; a):                                    (13)
                                                                 a2A

Axiom A3 No Improving Attention Cycles (NIAC): Given                                     2   and a …nite set

                                                 f(A(m); P (m))g1          m M

        with ( ; A(m)) 2 D, P (m) 2 C( ; A(m)), and (A(1); P (1)) = (A(M ); P (M )),
                                M
                                X1                               M
                                                                 X1
                                      ^ ( ; A(m); P (m))
                                      U                                 ^ ( ; A(m); P (m + 1));
                                                                        U
                                m=1                              m=1

        where,                                                 X
                                           ^ ( ; A; P )
                                           U                            QP ( )^
                                                                              u( ; A):                           (14)
                                                               2 (P )


   Our third axiom insists that almost all posterior distributions satisfying Bayes’ rule can be
found in the data for some decision problem. The caveat relates to posteriors that entirely rule out
some ex ante possible states of the world. As indicated above, this never happens in the Shannon
model.
   To state this formally, we let C ( ) denote all revealed posteriors ever observed in any decision
problem with the given prior, and correspondingly QC ( ) as distributions over posteriors that are
observed in the data. We de…ne also C = [ 2 C ( ).


Axiom A4 Completeness: Given                    2 :

           1.    C(   ) contains all interior posteriors, ~ ( )            C(   ).
           2.    C(   ) is a convex set.
           3. If Q 2 Q( ) is such that        (Q)         C(   ) then Q 2 QC ( ).


6.2      Recoverability

The recoverability result rests on A2-A4 alone.


Theorem 2: Given C 2 C satisfying A2-A4, there exists a function K 2 K such that C( ; A)
    P^ ( ; AjK) all ( ; A) 2 D. This function is unique on ( ; Q) 2 F with Q 2 QC ( ).


    The proof has two key steps. The …rst establishes existence of a cost function K 2 K such that
C( ; A) P^ ( ; AjK) all ( ; A) 2 D based on NIAS and NIAC. This proof is essentially the same
as that of Caplin and Martin [2015] and Caplin and Dean [2015].7 The second is a constructive
proof that pins this function down deterministically. The second stage is worth sketching out, not
only because of its technical importance, but also because it underlies our characterization of PS
representations.
  7
      The richer data also leads us to change proof method, relying in this case on the work of Rochet [1987].


                                                           26
    The procedure for constructing the cost function involves application of the fundamental theo-
rem of calculus. Given 2 and Q 2 QC ( ), we …rst enumerate the possible posteriors n 2 (Q)
for 1 n N = j (Q)j and de…ne corresponding …xed probability weights Qn Q( n ). We then
construct a path from the prior to the set of posteriors by de…ning for each n a line
                                          n            n
                                          t   =t            + (1            t) ;

so that at t = 0 we have n0 = and at t = 1 we have n1 = n . For each t we consider the
distribution Qt in which each nt is selected with the same probability as n ,
                                                           n
                                              Qt (         t)   = Qn :

Note that this construction ensures that the weighted average of the posteriors always averages
back to the prior,         X                 X
                              Qt ( nt ) nt =   Qn [t n + (1 t) ] = ;
                             n                     n

so that Qt 2 Q( ).
    Since Qt 2 Q( ), A4 implies that Qt 2 QC ( ). Hence for every t 2 [0; 1], there exists a
decision problem ( ; At ) 2 D and observed data Pt 2 C( ; At ) that give rise to the corresponding
distribution of revealed posteriors QPt = Qt .

   Given any cost function K 2 K such that C( ; A) P^ ( ; AjK) all ( ; A) 2 D, we then show
that,
                                     K( ; Qt ) K(t):
is convex and continuous in t 2 [0; 1], and hence almost everywhere di¤erentiable in t with,
                                                           Z    1
                                         K(t) =                     K 0 (t)dt;                             (15)
                                                            0

where the integration is over points of di¤erentiability.
    Next we characterize K 0 (t). At any point t at which K(t) is di¤erentiable, we consider the
decision problem ( ; At ) for which Qt is globally, hence locally, optimal. Thinking of shifting
locally to a di¤erent posterior distribution Qs for s 2 (t    ; t + ) leads to a …rst-order condition,
                                            X
                                  K 0 (t) =   Qn ([ n      ] u(ant )):                            (16)
                                              n

where ant is any chosen action associated with nt 2 (Qt ) and where the dot product [               n   ] u(ant )
is de…ned by,                                 X
                          [ n     ] u(ant )        [ n (!)   (!)] u(ant ; !):
                                                  !2 ( )

Substituting (16) into (15) yields,
                                          X                                  Z     1
                                                       n        n
                              K( ; Q) =           Q [                   ]              u(ant )dt:
                                              n                                0




                                                           27
Note that, given ( ; Q) 2 F with Q 2 QC ( ); enumerating the support                 (Q) = f   n j1   n    Ng
and using the notation above, this cost function is of the form,
                                      X
                          K( ; Q)         Q( n )T C ( n ; Q) T C ( ; Q);
                                             n

where T C ( ; Q) = 0 and,
                                                                Z   1
                                 T C(   n
                                            ; Q)   [   n
                                                            ]           u(ant )dt:                        (17)
                                                                0

    There are three noteworthy aspects of the result. First, the variational logic re‡ects the economic
intuition that marginal utility of improved information should align with its marginal cost. If a
large change in payo¤s is required to induce a small change in the optimal posterior, learning is
costly on the margin. The second point is that many action sets produce the same distribution of
posteriors. For example one could shift up all payo¤s by a constant amount. What we know is
that (17) must be invariant to the particular action set that generates this posterior distribution.
In the particular case of adding a constant to all payo¤s, invariance follows because state by state
di¤erences between prior and posterior average to zero. What the general result tells us is that the
corresponding invariance is fully general once A2 through A4 are assumed.
    The third point of interest is that the cost function recovered in this general case has much
in common with PS cost functions. The key distinction is that T C ( n ; Q) depends not only on
the particular posterior n but also the full distribution of posteriors Q. Hence the computation
for a …xed posterior can be entirely di¤erent should the distribution of posteriors change. This
di¤erentiates it from the PS form, to which we now turn.


7     PS and UPS Representations

In this section we introduce axioms for PS and UPS representations.


7.1   Separability

As indicated above, the …rst key step in the PS proof is to rule out dependence of T C (              n ; Q)   in
(17) on the distribution of posteriors. Given 2 (Q) \ (Q0 ), we want to ensure that,

                                        T C ( ; Q) = T C ( ; Q0 ):

This requires an invariance axiom concerning data with shared revealed posteriors. We must be
able to …nd decision problems that produce both distributions using common actions at shared
posteriors. The logic of this axiom is demonstrated in Figure 8. Consider again the decision
problem ( ; fa; bg) of Figure 4. The optimal strategy for this decision problem involves the use of
posteriors ^ a and ^ b and so these posteriors would be revealed in the data. Our separability axiom
demands that for any arbitrary posterior ^ c , such that ^ b ; ^ c can be the support for an attention
strategy feasible from , there must exist a corresponding action c such that this pair of posteriors
are revealed in the SDSC data from ( ; fb; cg), with ^ b still the revealed posterior for action b (see
Figure 8a).


                                                       28
                      Figure 8a                                             Figure 8b



    The necessity of this axiom for our model is illustrated in Figure 8b. We begin with the
hyperplane which de…nes the optimal strategy in problem ( ; fa; bg) which is tangent to the net
utility function for action a at ^ a and action b at ^ b . Given the ability to shift and tilt the gross
utility line de…ned by the payo¤s, it is always possible to …nd an action c such that the resulting
gross utility function, when combined with the cost curve, gives a net utility function which is
tangent to the hyperplane precisely at ^ c . The Lagrangian Lemma then tell us that ^ b ; ^ c de…ne
the support of an optimal strategy in the resulting decision problem, and so must be observed in
the data for ( ; fb; cg) as required.
   This logic holds more generally, as stated in the following axiom.


Axiom A5 Separability: Given ( ; A(1)) 2 D, P (1) 2 C( ; A(1)), and Q2 2 QC ( ) with
     (QP (1) ) \ (Q2 ) 6= ;, there exists A(2) A and P (2) 2 C( ; A(2)) satisfying QP (2) = Q2
    such that qP (1) (aj ) = qP (2) (aj ) all 2 (QP (1) ) \ (Q2 ).


    The proof that Separability implies existence of function T such that T ( ) = T C ( ; Q) in
equation (17) for all Q 2 QC ( ) is straight forward. It involves standard linear algebra arguments
as well as our knowledge of the speci…c structure of the cost function for each …xed posterior
distribution as de…ned by (17).
    While the Separability axiom uses the existential quali…er, in the case of Shannon represen-
tations one can specify the precise change in actions needed to generate speci…ed changes in the
posteriors. This follows from the invariant likelihood ratio property speci…ed in equation (10). This
ratio is enough to pin down the action required in A(2) to generate any 2 (Q2 )= (QP (1) ) using
the posteriors in (QP (1) ) \ (Q2 ) and their associated actions.




                                                  29
7.2   Convexity Properties

With Separability, we have a rationalizing cost function of the PS form, but without the required
strict convexity. In the next stage of the proof we show that there is no loss of generality in assuming
the function to be weakly convex. In terms of rationality, there is no advantage to deliberately
throwing away information, so that, even if they were present, concave portions of the cost function
would never be acted on. This aspect of the proof is very much analogous to the result of Afriat
[1967] that concavity can be assumed of any utility function recovered from optimizing choice in a
linear budget set.
   While weak convexity is guaranteed, one cannot guarantee strict convexity without additional
assumptions. To this end we introduce a non-linearity axiom which insists that if one revealed
posterior is a mixture of two others, then the expected utilities cannot be correspondingly mixed.
This directly permits the further step from weak to strict convexity.

Axiom A6 Non-linearity: Given ( ; A) 2 D, P 2 C( ; A), and distinct a1 ; a2 ; a3 2 A(P ) with
     a1   a3
     P 6= P ,

                 a2       a1               a3           a2                 a1                       a3
                 P    =   P    + (1    )   P    =) u(   P ; a2 )   6= u(   P ; a2 )   + (1    )u(   P ; a3 ):



7.3   From Some to All Optima

With axioms A2 through A6, we are able to identify a PS cost function K 2 KP S that rationalizes
all observed data, so that C( ; A) P^ ( ; AjK). Two additional axioms are required to establish
that all optimal strategies are seen, C( ; A) = P^ ( ; AjK). We …rst impose a convexity property on
the data.

Axiom A7 Convexity: Given ( ; A) 2 D, Pl 2 C( ; A) for 1                          l      L, and probability weights
     (l) > 0, P 2 C( ; A), where,
                                                           L
                                                           X
                                            P (aj!)                (l)Pl (aj!):
                                                           l=1


   With this, we …rst show that an arbitrary optimal strategy can be decomposed (using an ap-
propriate mixture operation) into a set of such strategies (l) with linearly independent posteriors,
                                                     L
                                                     X
                                                 =           (l) (l):
                                                     l=1

Caratheodory’s theorem plays the key role in this part of the proof. We then show that this
mixture operation correspondingly mixes the data, so that if each of the data sets P (l) is observed,
                            XL
Convexity implies that P =       (l)P (l) must also be observed.
                                 l=1

   Our …nal axiom provides conditions ensuring that each data set P (l) with linearly independent
posteriors is indeed observed. A key observation in this stage concerns uniqueness of optimal

                                                        30
strategies. A uniqueness lemma ensures that any optimal strategy that uses linearly independent
posteriors is uniquely optimal provided all available actions are chosen. To apply this to strategy
 (l), we diminish the payo¤s to all actions that are unchosen in this strategy by an arbitrarily small
amount. This marginal change ensures that the uniqueness result applies to all correspondingly
perturbed decision problems, for each of which (l) is therefore uniquely optimal. Uniqueness of
optimal strategies in a PS representation implies that the corresponding SDSC data is observed.
    Our process of taking perturbations allows us to construct for each (l) a corresponding sequence
of action sets that converges to A in the limit in such a way that (l) is uniquely optimal, hence
observed in the data all the way to the limit. To use convergence of this sequence of decision
problems to make a conclusion on the limit problem itself requires a continuity axiom. Given 2
we de…ne a payo¤-based metric on the space of actions,
                                        0                                 11
                                                                               2
                                             X                            2A
                            d(a; a ) = @
                                  0
                                                  u(a; !)         0
                                                               u(a ; !)            :
                                         !2 ( )


Axiom A8 Continuity: Consider I     1 sequences of actions ai (m) with limm!1 ai (m) = ai
    for 1   i   I, and de…ne A(m) = [Ii=1 ai (m) and A = [Ii=1 ai . Then given    2   and
          1
    P 2 \m=1 C( ; A(m)),
                                A(P ) A =) P 2 C( ; A):

    This is a very weak condition concerning sequences of choice sets which converge pointwise and
which have a subset of actions which remain …xed. If, at every step in the sequence, the same
choice behavior is observed (which must therefore only involve choice amongst actions available in
all choice sets), then that behavior must also be observed in the limit. In light of our perturbation
method, this su¢ ces to establish that all data sets P (l) are observed in the original choice set.
To complete the proof, we apply the convexity result to show that the data P generated by the
original optimal strategy is also observed.


7.4   Existence and Simple Recovery

We summarize this discussion in the following theorem.

Theorem 3: Data set C 2 C has a PS representation if and only if it satis…es Axioms A2 through
    A8.

    Given a PS cost function, we show that there is a relatively simple way to recover it. Given
  2 and non-degenerate Q 2 QC ( ), Corollary 2 establishes existence of a choice set A such that
an inattentive strategy 2 I ( ; A) and a strategy = (Q ; q ) 2 ( ; A) with Q ( ) = Q ( )
are both optimal, hence have equal expected utility net of attention costs,

                                 U( )       U ( ) = K( ; Q)      K( ; )

By construction, the inattentive strategy is free, K( ; ) = 0, so that indi¤erence implies that
K( ; Q) is directly computable as the di¤erence in expected utility,

                                      K( ; Q) = U ( )         U ( ):

                                                   31
7.5   LIP and UPS Theorem

A single invariance axiom takes us from a PS to a UPS representation. Locally Invariant Posteriors
(LIP) conveys the idea that, given P 2 C( ; A), the resulting action-posterior pairs are invariant
to various changes in and A.
      First, if the prior changes to 0 such the posteriors revealed in ( ; A) are still feasible, then
they must still be observed in C( 0 ; A). The necessity of this condition is illustrated in Figure 9,
which again builds on the decision problem ( ; fa; bg) with = 0:5 and optimal posteriors ^ a and
^ b : Recall that these posteriors are identi…ed as supporting the highest chord above the prior .
Consider the prior 0 with 0 (! 1 ) = 0:3, and note that precisely the same posteriors support the
highest chord above this new prior as well, implying that they remain optimal and so must be
observed for decision problem ( 0 ; fa; bg).




                                       Figure 9: Locally Invariant Posteriors



   LIP also requires that, given P 2 C( ; A), if a new decision problem is de…ned by deleting some
available actions, then the remaining action-posterior pairs must be observed provided Bayesian
consistency is retained.
   The following formal de…nition captures both of these invariance properties.


Axiom A9 Locally Invariant Posteriors (LIP):X Consider ( ; A) 2 D, P 2 C( ; A), and
    probabilities (a) > 0 on A 0 A(P ) with   (a) = 1. De…ne P 0 2 P by A(P 0 ) = A0 ,
                       X                                       a2A0
      QP 0 ( ) =                      (a) and:
                   fa2A0 j   a=   g
                             P

                                                           (
                                                                 (a)
                                                                QP ( )  if aP = 0 ;
                                            qP 0 (aj ) =
                                                               qP 0 (aj ) = 0 else.


                                                           32
                                            !
                      X
     Then   P0   2C          (a)   a ; A0
                                   P            :
                      a2A0


    Our fourth theorem shows essentially that a data set with a PS representation has a UPS
representation if and only if it satis…es LIP. There is a caveat. For necessity of LIP (Axiom A9),
we insist on a link between the posteriors C ( 1 ) and C ( 2 ) for distinct priors. If prior 2 lies in
the convex hull of posteriors that are revealed posteriors from prior 1 , then these posteriors must
be observed from prior 2 also. We present a simple example in Appendix 4 in which this does not
hold. We de…ne regular data sets as those that have this property globally.


De…nition 13 Data set C is regular, C 2 C R C, if, given             1   2   and Q 2    ( (   1 ))   with
 (Q)    C ( 1 ),           X
                                                       C
                                 Q( ) = 2 =) (Q)         (           2 ):
                                   2 (   2)



    Note that the Shannon model generates a data set that is regular, as do other standard entropies.
It simpli…es our analysis without substantively amending our results to include regularity as a pre-
condition in the necessity proof.


Theorem 4: If C 2 C has a PS representation and satis…es LIP (Axiom A9), it has a UPS
    representation. If C 2 C R has a UPS representation then it satis…es LIP.


   The proof of theorem 4 is lengthy yet conceptually straight forward. It relies on the Lagrangian
Lemma and elementary linear algebra. It also relies on invariance of the cost function under a¢ ne
transforms of the strictly convex function T .
    Note that between them, theorems 1, 3, and 4 show that data set C 2 C has a Shannon
representation if and only if it satis…es Axioms A1 through A9. For the sake of completeness, we
establish this as Corollary 3 in Appendix 5.


8    Further Results

In this section we provide further results that expand on various features of our representation.
We …rst show how to obtain a representation when the IO observes only a single piece of SDSC
for each decision problem - i.e. a choice function rather than a choice correspondence. Second, we
describe the relationship between our model and the more traditional model of costly information
acquisition in which the DM chooses between information structures consisting of signals, rather
than probability distributions over posteriors. Finally we introduce Tsallis entropy (Tsallis [1988]),
an alternative formulation to that of Shannon which is of value in describing physical and social
systems (see Section 9.3). Costs based on Tsallis entropy fall in the UPS class but do not satisfy
IUC, as we demonstrate.




                                                    33
8.1   Choice Functions

To explore the application of our approach to choice functions, we let C F be the set of data sets in
which there is only one observation of SDSC data for each decision problem,

                             CF      C F : D ! PjC F ( ; A) 2 P( ; A) :

Given there will be multiple optima in some decision problems, there are several distinct forms
of representation that may be of interest. The most obvious approach captures observation of a
selection from the optimal choice correspondence.


De…nition 14 Data set C F 2 C F has a functional costly information representation (FCIR)
K 2 K if, for all ( ; A) 2 D,
                                    C F ( ; A) 2 P^ ( ; AjK):
It has a FPS/FUPS/F-Shannon representation if it is has an FCIR with K 2 KP S /KU P S /K = K S
for > 0.


    We can also consider the case in which the DM mixes among strategies when there are multiple
optima, meaning that the observed data falls in the convex hull of the data generated by optimal
strategies.


De…nition 15 Data set C F 2 C F has a mixed functional costly information representation
(MCIR) K 2 K if, for all ( ; A) 2 D,
                                                 n           o
                                C F ( ; A) 2 Conv P^ ( ; AjK) ;

It has a MPS/MUPS/M-Shannon representation if it is has an MCIR with K 2 KP S /KU P S /K =
K S for > 0.


   Our …rst observation is that a data set will have a FPS representation if and only if n
                                                                                         it has an MPS
                                                                                                    o
representation. This follows from the fact that, for the PS model, P ( ; AjK) = Conv P^ ( ; AjK) .
                                                                   ^
Thus we can concentrate on identifying conditions which allow for the former type of representation.
    The key to functional extensions of our approach is a recoverability result in the spirit of that
outlined in Section 6, whereby Axioms A2 through A4 alone are enough to uniquely pin down a
rationalizing cost function. In the case of a functional representation, we cannot guarantee that
all distributions over posteriors will be observed in the data. However, it is the case that all
distributions with linearly independent support will be observed, as all such strategies are uniquely
optimal in some decision problem if costs are posterior separable. It is therefore possible to uniquely
identify costs for all such attention strategies. Moreover, there is a unique way to extend this cost
function to all attention strategies in a manner consistent with posterior separability. If we de…ne
mixtures of posterior distributions as in Appendix 2,
                             L
                             X                       L
                                                     X
                        Q=         l Ql   , Q( ) =         (l)Ql ( ) all   2 (Q);
                             l=1                     l=1



                                                     34
posterior separability of costs implies that,
                                                L
                                                X
                                      Q    =          l Ql
                                                l=1
                                                              L
                                                              X
                                          ) K( ; Q) =               l K(   ; Ql ):
                                                              l=1


    Thus if a data set has a FPS representation then it is possible to uniquely identify those costs K
from the data.8 Having done so, one can then identify all SDSC which are consistent with optimal
behavior with respect to this cost function P^ ( ; AjK). Treating this as a data set, we can then
apply the relevant axioms: for an FPS P^ must satisfy Axioms A5-A8, for a FUPS it must also
satisfy Axiom A9 and for F-Shannon it must also satisfy Axiom A1. In this way we can construct
necessary and su¢ cient conditions for functional representations.


8.2    Costly Signal Acquisition

The standard approach to modeling optimal acquisition of costly information speci…es an informa-
tion structure, consisting of a joint distribution of signals and states. The DM chooses amongst
these structures, which are subject to some cost function (see for example Caplin and Dean [2015]).
A signal-based strategy comprises an information structure and a mixed action strategy mapping
signals to distributions over chosen actions. As is standard, and as we assume in our posterior-
based approach, costs depends only on the information structure, not the action strategy. The DM
faced with decision problem ( ; A) 2 D is modeled as choosing a signal-based strategy to maximize
expected utility net of information costs.
    The signal-based and posterior-based approaches are equivalent in the sense that a data set can
be rationalized by optimal choice of signal-based strategy if and only if it can be rationalized by
optimal choice of posterior-based strategies. To go from a CIR in our sense to a corresponding
cost function on information structures involves little more than identifying the signals with the
posteriors. The argument in the reverse direction involves identifying posteriors associated with
the various actions and correspondingly transforming the mixed strategy.
    While the data that is characterized is the same using our posterior-based formulation and the
standard signal-based formulation, there is a key distinction with regard to testability. Subjective
signals are observable only indirectly, through their impact on updating and thereby behavior.
From the viewpoint of choice-based analysis, the posterior-based approach has the advantage that
it by-passes unobservable signals.


8.3    Tsallis Entropy and Failures of IUC

The IUC property seems su¢ ciently reasonable as to be more widely true. To understand how IUC
fails for cost functions other than Shannon, we show how the condition fails for the class of cost
functions associated with entropy functions introduced by Tsallis [1988].
   8
     With regard to attention strategies with linearly dependent support, one can insist that these are only used when
optimal according to the recovered cost function.


                                                         35
       For   2 R,    6= 1; the Tsallis entropy of posterior 2 is de…ned by,
                                                   0              1
                                              1 @         X
                                 TS ( ) =            1       (!) A 2 R:
                                                 1
                                                                      !2 ( )

As      ! 1, Tsallis entropy heads in the limit to Shannon entropy, H( ).
    A key property of Tsallis entropy is that it is non-additive. Given two independent probability
distributions 1 and 2 , the entropy of the product distribution can be related to the entropy of
the marginal distributions,
                                 1     2               1                  2                     1            2
                      TS (                 ) = TS (        ) + TS (           ) + (1   )T S (       )T S (       ):

Shannon entropy ( = 1) is the special case of additivity.
   Given     2    it is simple to de…ne the Tsallis cost function for information structures with
 (Q)    ~ ( ) in a manner completely analogous to the Shannon model. Costs are related to the
expected Tsallis entropy of the posteriors less that of the prior, again with multiplicative factor
  > 0,                                     hX                          i
                          K T S ( ; Q) =         Q( )T S ( ) T S ( ) :

Recall that what is costly is reducing entropy so K T S is decreasing in the entropy of the posteriors.
K T S ( ; Q) is real-valued for all distributions Q 2 ( ( )).9
    This cost function is a member of the UPS class, and so the resulting behavior satis…es Axioms
A2-A9. However it violates IUC. Consider a problem ( ; A) and suppose that states ! 1 ; ! 2 2 ( )
are identical in payo¤ terms, so that, u(a; ! 1 ) = u(a; ! 2 ) for all a 2 A. Consider P 2 C( ; A) and
suppose without loss of generality that each action is chosen from one and only one posterior so
that QP ( aP ) = P (a). Now consider K T S ( ; QP ):
               X                       X                    a (!)     1        1        X                (!)          1   1
                                 a             a            P
                          QP (   P)            P (!)                                            (!)                           ;
             a2
                                                                     1                                                1
             P    (QP )               !2 ( )                                           !2 ( )


where we have pulled out multiplicative factor aP (!) to make explicit the relationship to a constant
                                                                                       P
elasticity function. Substituting using Bayes’rule, aP (!) = P (aj!)
                                                                 P (a)
                                                                       (!)
                                                                           and invoking ! P (aj!) = 1,
   9
      A subtle point is that there are cases in which an ex ante possible state may be ruled out, as when ( ) =
f! 1 ; ! 2 ; ! 3 g yet 2 (Q) has support ( ) = f! 1 ; ! 2 g. The above formula correctly deals with this case when when
  > 0 because the contribution of these terms to the sum is zero so that their exclusion is immaterial.
  Matters are slightly more complex when < 0. In this case there are in…nite costs to ruling out ex ante possible
states. This calls for care in specifying the Tsallis attention cost function. Given       2 , the corresponding cost
function is:                   ( hX                              i
                                        Q( )T S ( ) T S ( )           if ( ) = ( ) all 2 (Q);
                        KT S =
                                               1                    if ( ) 6= ( ) some 2 (Q).
   The need to depart from the standard speci…cation of Tsallis entropy in the above cases is due to what is essentially
a missing argument. The standard Tsallis entropy function makes no explicit reference to the prior. Yet the cost of
making an ex ante possible state impossible becomes unboundedly high at the margin when < 0, so that making
it free to entirely rule such a state out would be inappropriate.




                                                                36
leads to the following expression for Tsallis costs in terms of SDSC data:
                                                             "                                              #
                                   X X                         (P (aj!)=P (a))                     1
                                                                                                        1
                 TS
              K     ( ; QP ) =                  P (aj!) (!)
                                                                            1
                                       a2A(P ) !2 ( )
                                           X                    (!)     1   1
                                                    (!)
                                                                        1
                                         !2 ( )


    Now suppose that IUC holds so that P 2 C( ; A) implies P (aj! 1 ) = P (aj! 2 ) for all a 2 A. We
now focus on the part of this expression associated with a single action a 2 A and the two states
! 1 and ! 2 :
                                                          1                                                     1
                                 (P (aj! 1 )=P (a))            1                         (P (aj! 2 )=P (a))         1
             P (aj! 1 ) (! 1 )                                     + P (aj! 2 ) (! 2 )
                                                1         !                                             1
                                                1
                          (P (aj! 1 )=P (a))          1
         =     P (aj! 1 )                                     [ (! 1 ) + (! 2 ) ] :
                                         1

We now compare this to the cost that would be incurred if ! 1 and ! 2 were instead collapsed into the
single state ! 1 with prior probability (! 1 ) + (! 2 ). If, as speci…ed by IUC, the choice probabilities
remain P (aj! 1 )                                             !
                                      (P (aj! 1 )=P (a)) 1 1
                           P (aj! 1 )                           [ (! 1 ) + (! 2 )] :
                                                     1

   If < 1 then the decision maker …nds it more costly to learn about ! 1 and ! 2 separately than
together,
                             (! 1 ) + (! 2 ) > ( (! 1 ) + (! 2 )) :
If > 1, the opposite is the case. It is clear that these changes in the marginal cost of information
mean that the same P (aj! 1 ) cannot generally be optimal in the original problem and its basic form,
leading to a violation of IUC.
   Only if = 1 does the DM treat the two scenarios as equivalent. Recall that as ! 1, Tsallis
entropy approaches Shannon entropy. Shannon entropy is therefore the special case in which the
agent is indi¤erent between aggregating and separating states. This is the essence of the IUC
axiom. With Shannon, the cost of implementing P (aj!) rises proportionately with (!), whereas
with Tsallis entropy costs rise more than proportionately with (!) when > 1, and less than
proportionately when < 1: The implication is that when < 1, information is proportionately
cheaper in more likely states, so that an agent would appear to pay greater attention in such states.


9     Relation to the Literature

9.1   Existing Characterizations of the Shannon Model

Several recent papers have provided insights into the behavior implied by the Shannon model.
Matejka and McKay [2015] provide a generalized logit formula for optimal SDSC probabilities
P (aj!) in the Shannon model. Caplin and Dean [2013], Stevens [2014], and Caplin et al. [2016]


                                                              37
show that addition of appropriate complementary slackness conditions renders these necessary and
su¢ cient.
    While insightful, such conditions for optimality are not directly revealing of the behavioral
patterns that the model produces. In contrast, our analysis is of value in this regard. Indeed, many
of the tools we describe - such as the posterior based approach to optimal strategies in the Shannon
model and the geometry of net utility functions - have already proved useful in economic research
since their introduction in Caplin and Dean [2013] (see for example Caplin et al. [2015] and Martin
[2017]). For example, in the UPS case, LIP makes it relatively easy to derive comparative static
results as priors change.
    A more closely related analysis is that of de Oliveira [2013], who also axiomatizes a form of
decision making given a Shannon cost function. The key di¤erence is that de Oliveira [2013] places
axioms on preference orderings over menus, whereas we place axioms on choices as revealed in
SDSC data. There is therefore no obvious relationship between the axioms. One possible exception
is that IUC appears related to de Oliveira [2013]’s independence of orthogonal decision problem
(IODP) axiom. IODP involves indi¤erence between solving two decision problems with independent
payo¤s together or separately. We early on conjectured that we would need both IUC and IODP
to generate the Shannon form. We only later realized that IUC alone was su¢ cient. It is therefore
possible that IUC implies IODP. de Oliveira [2013] also does not consider generalizations of the
Shannon model.
    Pioneering work by Shannon [1948] and Khinchin [1957] provides direct axiomatizations of
Shannon entropy. These axiomatizations focus on properties of the measure of information itself,
rather than on how basing learning costs on them impacts optimal behavior. Axioms such as con-
tinuity, being maximal at uniformity, being invariant to zero probability events, and satisfaction of
additivity conditions are shown to imply the Shannon entropy function for probability distributions.
This work is therefore focussed on properties of measures of disorder, rather than understanding
the behavioral implications of associated attention cost functions.


9.2   Behavioral Evidence Against the Shannon Model

The use of the Shannon model is often justi…ed on information theoretic grounds (see for example
Sims [2003] and Matejka and McKay [2015]). In particular, mutual information is related to the rate
of information ‡ow needed to generate a given conditional distribution of signals given a distribution
of states, assuming optimal coding (see for example Cover and Thomas [2012] chapter 10). Yet the
experimental literature in economics and psychology establishes that there are important behavioral
reasons to look beyond that model.
    The most direct evidence derives from experiments that collect SDSC data to which the above
characterizations apply. This ‡edgling literature exhibits behavioral patterns that are inconsistent
with the Shannon model. One key problem relates to the elasticity of chosen posteriors to changes
in the underlying rewards. The Shannon model makes sharp and precise predictions about the
rate at which subjects improve their accuracy in response to improved incentives. A single decision
problem is enough to pin down the one parameter in the model and so the “expansion path”
of information acquisition in response to changed incentives. Caplin and Dean [2013] show that
the improvement in expected utility as the incentive to learn rises is signi…cantly lower than the
Shannon model predicts in a simple two state, two action set-up.


                                                 38
    A second behavioral limitation of the Shannon model is that it makes no allowance for perceptual
distance. Yet perceptual distance is critical in many every day decisions, as when good decisions
require the DM to di¤erentiate between alternative pricing schemes: it seems likely that prices
which are closer together will be harder to distinguish than those which are far apart. By way of
conceptual con…rmation, Dean and Neligh [2017] design an experiment with 100 balls on a screen,
of which a random number (between 40 and 60) are red, with the remainder blue. Subjects are
tasked with correctly identifying which color ball is in the majority. The Shannon model implies
that they must be just as good at the task when there are 51 red balls on the screen as when there
are 60, which is strongly rejected by the data.
   An earlier literature in psychology also demonstrates behavior that does not …t with the Shannon
model. Woodford [2012] discusses the experimental results of Shaw and Shaw [1977], in which a
subject brie‡y sees a signal which may appear at one of a number of locations on the screen.
Their task is to accurately reproduce the location of this brie‡y seen signal. According to the
Shannon cost function, the actual location, being payo¤ irrelevant, should also be irrelevant to task
performance. Yet in practice, performance is superior at locations that occur more frequently.


9.3   PS Models

UPS models were introduced in Caplin and Dean [2013]. They are rich enough to allow for many
of the behavioral …ndings that call the Shannon model into question. With regard to incentives,
Caplin and Dean [2013] develop a simple two parameter UPS model that generalizes the Shannon
model. They …nd that the additional degree of freedom leads to a signi…cantly better …t of the
data according to the Akaike Information Criterion. With regard to perceptual distance, while
rejecting the Shannon model, Dean and Neligh [2017] …nd (weak) support for LIP, and hence the
UPS model. Finally, note that while the results of Shaw and Shaw [1977] are inconsistent with
the Shannon model, they are consistent with the UPS model. In the Tsallis model with < 1, for
example, learning about unlikely states is proportionately more expensive than about likely states.
This produces a commensurately greater error rate, as in the experiment.
   Since their introduction, several papers have made use of UPS costs functions - see for example
Gentzkow and Kamenica [2014], Steiner et al. [2015], Clark [2016] and Morris and Strack [2017].
In part this is due to their ‡exibility in rationalizing behavior. It is also due in part to the fact
that UPS models make available familiar Lagrangian methods of optimization.
    The current paper is the …rst to introduce the more general class of PS cost function. As noted,
this allows the costs to vary depending on prior beliefs. We expect this additional ‡exibility also
to prove useful in understanding behavior and in economic modeling. Indeed alternative forms of
entropy have proven valuable in other disciplines. There are many settings in which the additional
‡exibility they allow for leads to a better ability to describe physical and social systems. Examples
include internet usage (Tellenbach et al. [2009]), machine learning (Maszczyk and Duch [2008]),
statistical mechanics (Lenzi et al. [2000]), and many other applications in physics (Beck [2009]).
See Gell-Mann and Tsallis [2004] for a review. In these cases, the additivity property of Shannon
entropy is found to be unhelpful in describing the phenomena of interest.
   Interestingly, the literature in information theory and on the design of experiments has also
focussed on PS cost functions. For example, the Blackwell-Sherman-Stein Theorem shows that
PS functions can be used to characterize the property of statistical su¢ ciency, and so provide


                                                 39
an alternative characterization of Blackwell’s theorem. The theorem states that an information
structure is statistically su¢ cient for 0 (i.e. Blackwell dominates 0 ) if and only if,
                               X                    X
                                     Q ( )T ( )         Q 0 ( )T ( );
                                   2 (Q )                       2 (Q 0 )

for every continuous, (weakly) convex T , where Q is the distribution over posteriors generated
by    (see for example Le Cam [1996]).   · 10 Torgersen [1991] further shows that the class of PS
cost functions can be characterized by properties of the costs themselves. Speci…cally, the (weakly
convex) PS class of cost function of information structures characterizes monotonicity in Blackwell
informativeness and linearity in a natural mixture operation.


9.4      Alternative Models of Limited Attention

Our work belongs to a recent literature which characterizes the behavior associated with models of
incomplete attention - see for example Masatlioglu et al. [2012], Manzini and Mariotti [2014] and
Steiner and Stewart [2016]. It is also related to signi…cant bodies of work on costly information
acquisition with very di¤erent forms of cost function. The most ubiquitous such model is search
theoretic, involving a …xed cost of uncovering each available option (e.g. Caplin et al. [2011]). Other
approaches include costly purchase of normal signals (Verrecchia [1982], Llosa and Venkateswaran
[2012] and Colombo et al. [2014] ) and “all or nothing” information costs (Reis [2006]). Even in
the rational inattention literature alternative cost functions have been provided. For example,
Paciello and Wiederholt [2014] consider costs that are convex in mutual information, while Sims
[2003] considers a model in which there is a hard constraint on the amount of mutual information
a DM can use. Inspired by the …ndings of Shaw and Shaw [1977], Woodford [2012] considers
a cost function which is linear in Shannon capacity, rather than Shannon mutual information.
Another ongoing body of work to which our modeling relates is the sparsity-based model of Gabaix
[2014]. This model is based on a distinct form of attention cost function involving …xed costs of
comprehending individual characteristics of options. The question of how these other cost functions
restrict behavior, and so how they di¤er from the PS class, remains open.


10       Concluding Remarks

Together our results provide necessary and su¢ cient conditions for cost functions of increasing
speci…city. Theorem 3 states that Axioms A2-A8 are necessary and su¢ cient for the existence
of a Posterior Separable attention cost function. In addition, given a Posterior Separable cost
function, Theorem 4 states that Locally Invariant Posteriors (Axiom A9) is necessary and su¢ cient
for the existence of a Uniformly Posterior Separable cost function. Finally, given a Uniformly
Posterior Separable cost function, Theorem 1 states that Invariance under Compression (Axiom
A1) is necessary and su¢ cient for the cost function to take the Shannon form. In addition, Theorem
2 states that Axioms A1-A3 are su¢ cient for there to exist a unique attention cost function that
represents the data.
 10
      We thank Daniel Csaba for pointing this out to us.




                                                           40
References
Sydney N. Afriat. The Construction of Utility Functions from Expenditure Data. International
  Economic Review, 8(1):67–77, 1967.

Marina Agranov and Pietro Ortoleva. Stochastic choice and preferences for randomization. Available
 at SSRN 2644784, 2015.

Jose Apesteguia and Miguel A Ballester. Single-crossing random utility models. 2016.

Christian Beck. Generalised information and entropy measures in physics. Contemporary Physics,
  50(4):495–510, 2009.

David Blackwell. Comparison of experiments. In Proceedings of the second Berkeley symposium on
  mathematical statistics and probability, volume 1, pages 93–102, 1951.

Henry David Block and Jacob Marschak. Contributions to Probability and Statistics, volume 2,
  chapter Random orderings and stochastic theories of responses, pages 97–132. Stanford University
  Press, 1960.

Andrew Caplin and Mark Dean. Behavioral implications of rational inattention with shannon
 entropy. NBER Working Papers 19318, National Bureau of Economic Research, Inc, August
 2013.

Andrew Caplin and Mark Dean. Revealed preference, rational inattention, and costly information
 acquisition. The American Economic Review, 105(7):2183–2203, 2015.

Andrew Caplin and Daniel Martin. A testable theory of imperfect perception. The Economic
 Journal, 125(582):184–202, 2015.

Andrew Caplin, Mark Dean, and Daniel Martin. Search and satis…cing. The American Economic
 Review, 101(7):2899–2922, 2011.

Andrew Caplin, John Leahy, and Filip Matµejka. Social learning and selective attention. Technical
 report, National Bureau of Economic Research, 2015.

Andrew Caplin, Mark Dean, and John Leahy. Rational inattention, optimal consideration sets and
 stochastic choice. 2016.

Raj Chetty, Adam Looney, and Kory Kroft. Salience and taxation: Theory and evidence. American
 Economic Review, 99(4):1145–1177, 2009.

Aubrey Clark. Contracts for information acquisition. 2016.

Luca Colombo, Gianluca Femminis, and Alessandro Pavan. Information acquisition and welfare.
  The Review of Economic Studies, 81:1438–1483, 2014.

Thomas M Cover and Joy A Thomas. Elements of information theory. John Wiley & Sons, 2012.

Henrique de Oliveira. Axiomatic foundations for entropic costs of attention. Mimeo, Northwestern
  University, 2013.

Mark Dean and Nathaniel Neligh. Experimental tests of rational inattention. 2017.


                                               41
Ambuj Dewan and Nathaniel Neligh. Estimating information cost functions in models of rational
 inattention. 2017.

Xavier Gabaix. A sparsity-based model of bounded rationality. The Quarterly Journal of Eco-
  nomics, 129(4):1661–1710, 2014.

Murray Gell-Mann and Constantino Tsallis. Nonextensive entropy: interdisciplinary applications.
 Oxford University Press, 2004.

Matthew Gentzkow and Emir Kamenica. Costly persuasion. The American Economic Review,
 104(5):457–462, 2014.

Friedrich August Hayek. Economics and knowledge. Economica, 4(13):33–54, 1937.

Friedrich August Hayek. The use of knowledge in society. The American economic review, pages
  519–530, 1945.

Christian Hellwig, Sebastian Kohls, and Laura Veldkamp. Information choice technologies. The
  American Economic Review, 102(3):35–40, 2012.

Akovlevich Khinchin. Mathematical Foundations of Information Theory, volume 434. Courier
  Corporation, 1957.

Ian Krajbich and Antonio Rangel. Multialternative drift-di¤usion model predicts the relationship
  between visual …xations and choice in value-based decisions. Proceedings of the National Academy
  of Sciences, 108(33):13852–13857, 2011.

L Le Cam. Comparison of experiments: A short review. Lecture Notes-Monograph Series, pages
  127–138, 1996.

EK Lenzi, RS Mendes, and LR Da Silva. Statistical mechanics based on renyi entropy. Physica A:
 Statistical Mechanics and its Applications, 280(3):337–345, 2000.

Luis Gonzalo Llosa and Venky Venkateswaran. E¢ ciency with endogenous information choice.
  Unpublished working paper. University of California at Los Angeles, New York University, 2012.

R. D. Luce. Individual Choice Behavior: A Theoretical Analysis. New York: Wiley, 1959.

Bartosz Mackowiak and Mirko Wiederholt. Optimal sticky prices under rational inattention. Amer-
  ican Economic Review, 99(3):769–803, June 2009.

Paola Manzini and Marco Mariotti. Stochastic choice and consideration sets. Econometrica,
  82(3):1153–1176, 2014.

Paola Manzini and Marco Mariotti. Dual random utility maximisation. 2016.

Daniel Martin. Strategic pricing with rational inattention to quality. Mimeo, New York University,
 2017.

Yusufcan Masatlioglu, Daisuke Nakajima, and Erkut Y Ozbay. Revealed attention. American
  Economic Review, 102(5):2183–2205, 2012.

Tomasz Maszczyk and W÷odzis÷aw Duch. Comparison of shannon, renyi and tsallis entropy used in
  decision trees. In International Conference on Arti…cial Intelligence and Soft Computing, pages
  643–651. Springer, 2008.

                                               42
Filip Matejka and Alisdair McKay. Rational inattention to discrete choices: A new foundation for
  the multinomial logit model. American Economic Review, 105(1):272–98, 2015.

Filip Matµejka. Rationally inattentive seller: Sales and discrete pricing. The Review of Economic
  Studies, 83(3):1156–1188, 2015.

Daniel McFadden. Revealed stochastic preference: A synthesis. Economic Theory, 26(2):245–264,
 2005.

Jordi Mondria. Portfolio choice, attention allocation, and price comovement. Journal of Economic
  Theory, 145(5):1837–1864, 2010.

Stephen Morris and Philipp Strack. The wald problem and the equivalence of sequential sampling
  and static information costs. 2017.

Henrique Oliveira, Tommaso Denti, Maximilian Mihm, and Kemal Ozbek. Rationally inattentive
  preferences and hidden information costs. Theoretical Economics, 12(2):621–654, 2017.

Luigi Paciello and Mirko Wiederholt. Exogenous information, endogenous information and optimal
  monetary policy. The Review of Economic Studies, 83:356–388, 2014.

Ricardo Reis. Inattentive producers. Review of Economic Studies, 73(3):793–821, 2006.

Marcel K Richter. Revealed preference theory. Econometrica: Journal of the Econometric Society,
 pages 635–645, 1966.

Jean-Charles Rochet. A necessary and su¢ cient condition for rationalizability in a quasi-linear
  context. Journal of Mathematical Economics, 16(2):191–200, April 1987.

R. Tyrrell Rockafellar. Convex Analysis. Princeton University Press, Princeton, 1970.

C. E. Shannon. A mathematical theory of communication.           Bell System Technical Journal,
  27(3):379–423, 1948.

M. L. Shaw and P. Shaw. Optimal allocation of cognitive resources to spatial locations. J Exp
 Psychol Hum Percept Perform, 3(2):201–211, May 1977.

Christopher A. Sims. Stickiness. Carnegie-Rochester Conference Series on Public Policy, 49(1):317–
  356, December 1998.

Christopher A. Sims. Implications of Rational Inattention. Journal of Monetary Economics,
  50(3):665–690, 2003.

Jakub Steiner and Colin Stewart. Perceiving prospects properly. American Economic Review, 2016.

Jakub Steiner, Colin Stewart, and Filip Matejka. Rational inattention dynamics: Inertia and delay
  in decision-making. Centre for Economic Policy Research, 2015.

Luminita Stevens. Coarse pricing policies. Available at SSRN 2544681, 2014.

Bernhard Tellenbach, Martin Burkhart, Didier Sornette, and Thomas Maillart. Beyond shannon:
  Characterizing internet tra¢ c with generalized entropy metrics. In International Conference on
  Passive and Active Network Measurement, pages 239–248. Springer, 2009.

Louis L Thurstone. A law of comparative judgment. Psychological review, 34(4):273, 1927.

                                               43
Erik Torgersen. Comparison of statistical experiments. Number 36. Cambridge University Press,
  1991.

Constantino Tsallis. Possible generalization of boltzmann-gibbs statistics. Journal of statistical
  physics, 52(1-2):479–487, 1988.

Robert Verrecchia. Information acquisition in a noisy rational expectations economy. Econometrica,
  50(6):1415–1430, 1982.

EH Weber. De tactu. Koehler, Leipzig, 1834.

Michael Woodford. Information constrained state dependent pricing. Journal of Monetary Eco-
 nomics, 56(S):S100–S124, 2009.

Michael Woodford. Inattentive valuation and reference-dependent choice. Mimeo, Columbia Uni-
 versity, 2012.

Ming Yang. Coordination with ‡exible information acquisition. Journal of Economic Theory,
 158:721–738, 2015.




                                               44
