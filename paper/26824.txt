                                NBER WORKING PAPER SERIES




                        A MODEL OF SCIENTIFIC COMMUNICATION

                                           Isaiah Andrews
                                          Jesse M. Shapiro

                                       Working Paper 26824
                                http://www.nber.org/papers/w26824


                          NATIONAL BUREAU OF ECNOMIC RESEARCH
                                  1050 Massachusetts Avenue
                                    Cambridge, MA 02138
                                        March 2020

The article previously circulated under the title "Statistical Reports for Remote Agents." We
acknowledge funding from the National Science Foundation under Grants No. 1654234 and 1949047,
the Sloan Research Fellowship, the Silverman (1968) Family Career Development Chair at MIT, and
the Eastman Professorship and Population Studies and Training Center at Brown University. Any
opinions, findings, and conclusions or recommendations expressed in this material are those of the
authors and do not necessarily reflect the views of the funding sources. We thank Glen Weyl for
contributions to this project in its early stages. Conversations with Matthew Gentzkow and Kevin M.
Murphy on related projects greatly influenced our thinking. For comments and helpful conversations,
we also thank Alberto Abadie, Tim Armstrong, Gary Chamberlain, Xiaohong Chen, Max Kasy, Elliot
Lipnowski, Adam McCloskey, Emily Oster, Mikkel Plagborg-Møller, Tomasz Strzalecki, and Neil
Thakral. The paper also bene ted from the comments of seminar and conference audiences at Brown
University, Harvard University, the Massachusetts Institute of Technology, the University of Chicago,
Boston College, Rice University, Texas A&M University, New York University, Columbia
University, the University of California Los Angeles, the University of Texas at Austin, Oxford
University, the Eitan Berglas School of Economics, the National Bureau of Economic Research, and from
comments by conference discussants Jann Spiess and James Heckman. We thank our dedicated
research assistants for their contributions to this project. We thank our dedicated research assistants
for their contributions to this project. The views expressed herein are those of the authors and do not
necessarily reflect the views of the National Bureau of Economic Research.

At least one co-author has disclosed a financial relationship of potential relevance for this research.
Further information is available online at http://www.nber.org/papers/w26824.ack

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2020 by Isaiah Andrews and Jesse M. Shapiro. All rights reserved. Short sections of text, not to
exceed two paragraphs, may be quoted without explicit permission provided that full credit, including
© notice, is given to the source.
A Model of Scientific Communication
Isaiah Andrews and Jesse M. Shapiro
NBER Working Paper No. 26824
March 2020, Revised in October 2020
JEL No. C18

                                         ABSTRACT

We propose a positive model of empirical science in which an analyst makes a report to an
audience after observing some data. Agents in the audience may differ in their beliefs or
objectives, and may therefore update or act differently following a given report. We contrast the
proposed model with a classical model of statistics in which the report directly determines the
payo . We identify settings in which the predictions of the proposed model differ from those of
the classical model, and seem to better match practice.


Isaiah Andrews
Department of Economics
Harvard University
Littauer M18
Cambridge, MA 02138
and NBER
iandrews@fas.harvard.edu

Jesse M. Shapiro
Economics Department
Box B
Brown University
Providence, RI 02912
and NBER
jesse_shapiro_1@brown.edu
1         Introduction
Statistical decision theory, following Wald (1950), is the dominant theory of optimality
in econometrics.1 The classical theory of point estimation, for instance, envisions an
analyst who estimates an unknown parameter based on some data. The performance
of the estimate is judged by its proximity to the true value of the parameter. This
judgment is formalized by treating the estimate as a decision that, along with the
parameter, determines a realized payoff or loss. For example, if the loss is taken to be
the square of the difference between the estimate and the parameter, then the expected
loss is the estimator's mean squared error, a standard measure of performance.
        Although many scientific situations seem well described by the classical model,
many others do not. Scientists often communicate their findings to a broad and diverse
audience, consisting of many different agents (e.g., practitioners, policymakers, other
scientists) with different opinions and objectives. These diverse agents may make
different decisions, or form different judgments, following a given scientific report. In
such cases, it is the beliefs and actions of these audience members which ultimately
matter for realized payoffs or losses.
        In this paper we propose an alternative, positive model of empirical science to cap-
ture scientific situations of this kind. In the proposed communication model, defined
in Section 2, the analyst makes a report to an audience based on some data. After
observing the analyst's report, but not the underlying data, each agent in the audi-
ence takes their optimal decision. Agents differ in their priors or loss functions, and
may therefore have different optimal decisions following a given report. A reporting
rule (specifying a distribution of reports for each realization of the data) induces an
expected loss for each agent, which we call the rule's communication risk.
        We compare the proposed communication model with a decision model in which
the analyst selects a decision that directly determines the loss for all agents. The
decision risk of a rule for a given agent is then the expected loss under the agent's prior
from taking the decision prescribed by the rule.2 The decision model generalizes the
classical frequentist model, and the decision model's implications coincide with those
    1
     See Lehmann and Casella (1998) for a textbook treatment of statistical decision theory and
Stoye (2012) and Manski (2019) for recent discussions of its relation to econometrics.
   2
     Decision risk is what Lehmann and Casella (1998, Chapter 4) call the Bayes risk.


                                               2
of the classical model in a particular sense. By contrast, we find that the implications
of the decision model can be very different from those of the communication model.
   Section 3 presents an example in which the communication and decision models
imply opposite dominance orderings of the same rules. In the example, the analyst
conducts a randomized controlled trial to assess the effect of a deworming medication
on the average body weight of children in a low-income country. Although deworm-
ing medication is known to (weakly) improve nutrition, sampling error means that
the treatment-control difference may be negative. Under quadratic loss, the deci-
sion model implies that all audience members prefer that the analyst censor negative
estimates at zero, since zero is closer to the (weakly positive) true effect than any neg-
ative number. Under the same loss, the communication model implies that censoring
discards potentially useful information (the more negative the estimate, the weaker
the evidence for a large positive effect), and has no corresponding benefit (agents can
incorporate censoring when determining their optimal decisions or estimates). Thus,
an uncensored rule dominates a censored one under the communication model, while
the reverse is true under the decision model. We claim, and illustrate by example,
that a scientist choosing a report for a research article would be unlikely to censor. We
also develop some general properties of the communication model that are suggested
by the example.
   Section 4 presents an example in which the communication and decision models
disagree in an even stronger sense. In this example, the analyst conducts a randomized
controlled trial to determine, from a finite set of options, the optimal treatment for
a medical condition. When all of the treatments show equally promising effects in
the trial, the decision model implies that it is optimal for the analyst to randomize
among the treatments. By contrast, under the communication model, randomization
discards the information that the treatments showed similar effects, which is useful
to an agent who has a prior or preference in favor of one of them. Thus, a rule
that reports that the trial was inconclusive dominates one that randomizes among
the treatments under the communication model, while the reverse is true under the
decision model. In fact, we show that any rule that is undominated (admissible)
under the decision model in this example must be dominated (inadmissible) under
the communication model, and vice versa. Again, we illustrate by example that the


                                            3
implications of the communication model seem to better match practice in at least
some situations, and we develop some general results suggested by the example in an
appendix.
       Section 5 looks beyond dominance comparisons to consider alternative ways of
selecting rules. One is to minimize weighted average risk which, under the decision
model, corresponds to selecting Bayes decision rules. If all agents receive positive
weight, then (under regularity conditions) weighted average risk inherits any ordering
implied by dominance, and the conflicts in the preceding examples stand. Another
way to select rules is to minimize the maximum risk over agents in the audience. Here
we find more agreement between the two models in the sense that if the class of beliefs
in the audience is convex, then (under regularity conditions) any rule that is minimax
in decision risk is minimax in communication risk. This finding establishes a sense in
which any rule that is robust for decision-making is also robust for communication.
       We illustrate both results in an example, based on GMM estimation, in which an
analyst needs to combine multiple potentially misspecified moments to learn about
a structural parameter of interest. We characterize, respectively, rules that minimize
weighted average decision risk and communication risk, and show how and why they
differ. We further derive minimax decision rules, show that they are not minimax
optimal for communication when the audience is non-convex, and discuss why they
become minimax optimal for communication when the audience is convex.
       Heterogeneity among agents plays a central role in our analysis. When agents are
homogeneous, the distinction between decision and communication risk is inconse-
quential, because a benevolent analyst can simply report the agents' optimal decision
given the data. When agents are instead heterogeneous, the distinction can be con-
sequential, because different agents may prefer different decisions (or estimates).
       We are not aware of past work that studies the ranking of rules based on com-
munication risk in a setting with heterogeneous agents. Raiffa and Schlaifer (1961),
Hildreth (1963), Sims (1982, 2007), and Geweke (1997, 1999), among others, consider
the problem of communicating statistical findings to diverse, Bayesian agents.3 Our
   3
     See also Efron (1986) and Poirier (1988). A related literature (e.g., Pratt 1965; Kwan 1999;
Abadie 2020; Abadie and Kasy 2019; Frankel and Kasy 2018) assesses the Bayesian interpretation
of frequentist inference. Another literature (e.g., Zhang et al. 2013; Jordan et al. 2018; Zhu
and Lafferty 2018) considers the problem of distributing statistical estimation and inference across


                                                 4
analysis is particularly related to that of Hildreth (1963) who studies, among other
topics, the properties of what we term communication risk in the single-agent setting.
Andrews et al. (2020) study the implications of communication risk for structural
estimation in economics (see also Andrews et al. 2017).
    Our setting is also related to the literature on comparisons of experiments follow-
ing Blackwell (1951, 1953), reviewed, for example, in Le Cam (1996) and Torgersen
(1991). What we term communication risk has previously appeared in this literature
(see for instance Example 1.4.5 in Torgersen 1991), but the primary focus has been on
properties (e.g., Blackwell's order) that hold for all possible beliefs and loss functions.
By contrast, we focus on the comparison between communication risk and decision
risk for a given loss function and class of priors. We formalize the connection to
sufficiency, which plays an important role in this literature, in Section 3.3.
    Our setting is broadly related to large literatures on strategic communication
(Crawford and Sobel 1982) and information design (Bergemann and Morris 2019).
As in Farrell and Gibbons (1989), the receivers (agents) in our setting are hetero-
geneous. As in Kamenica and Gentzkow (2011), the sender (analyst) in our setting
commits in advance to a reporting strategy. Unlike much of the literature on strate-
gic communication, our setting does not involve a conflict of interest between the
sender and the receivers, which Spiess (2018), Banerjee et al. (2020), and others have
recently considered in a statistical context.


2     Model
An analyst observes data X  X , for X a sample space. The distribution of X is
governed by the parameter   , X  F , for  a parameter space. The analyst
publicly commits to a rule c : X   (S ) that maps from realizations of the data X
to a distribution over reports s  S , for S a signal space. Let C denote the set of all
such rules, and with a slight abuse of notation let c (X )  S denote the realization
from a given rule c  C .
    The analyst's report c (X ) is transmitted to a set of agents indexed by a. Each
multiple machines when communication is costly. Brown (1975) considers a setting with a collection
of possible loss functions, while the literature on robust Bayesian decision theory (see e.g. Gilboa
and Schmeidler 1989; Stoye 2012) analyzes decision rules with respect to classes of priors.

                                                 5
agent a is identified with a prior a   () on the parameter space. We will call
the set A   () of such priors the audience. While we interpret the audience as
a collection of agents, our model can be interpreted as one in which there is a single
agent who possesses additional information unavailable to the analyst.4
        After receiving the analyst's report c (X ) each agent a takes a decision d  D  S ,
for D a decision space. A decision rule is a rule with range  (D) . Let B be the set of
all decision rules. The assumption that D is contained in S means that the analyst
is free to select any decision rule, B  C .
        After taking the decision d, the agent a realizes the loss L (d, )  0. The analyst
is benevolent and wishes to minimize the ex ante expected loss, or risk, of each
agent under the agent's own prior. We consider two notions of risk. The first, which
we call decision risk, is the expected loss to the agent from following the decision
recommended by the analyst's report. Formally, for c  B , the decision risk Ra (c) is

                                    Ra (c) = Ea [L (c (X ) , )] .

The second, which we call the communication risk, is the expected loss when each
agent updates their beliefs based on the analyst's report and then selects a decision
that is optimal under their updated beliefs. Formally, for c  C the communication
      
risk Ra (c) is
                              
                             Ra (c) = Ea inf Ea [L (d, ) |c (X )] .
                                             dD

        For given audience A and loss L (·, ·), we will call the model with rules B and risk
functions Ra (·) the decision model, and the model with rules C and risk functions
 
Ra (·) the communication model. The assumption that all agents share a common loss
function is without loss of generality, as a model with heterogeneous loss functions can
always be re-parameterized as one with a homogeneous loss and a richer parameter
.
        Both the decision model and the communication model evaluate the expected loss
with respect to the agent's own prior. The key difference between the decision model
and the communication model is that, under the decision model, the expected loss is
    4
    Under this interpretation, A is the set of posterior beliefs that the agent may hold after receiving
the additional information.


                                                   6
evaluated as if the agent is forced to adopt the decision recommended by the analyst's
report, whereas under the communication model, the expected loss is evaluated as if
each agent takes their optimal decision conditional on the analyst's report.
   If we take the audience A to be the set of point-mass priors on , i.e., the vertices
of  (), then the decision risk is the frequentist risk (Lehmann and Casella 1998,
equation 1.10), and the decision model coincides with the classical model. If we
instead take the audience A to be the set of all possible priors on , i.e.,  (),
then the decision model still selects the same rules as the classical model under many
standard optimality criteria (see Stoye 2012 for discussion). We therefore focus on
comparing the decision and communication models.
   The implications of the decision and communication models coincide if we take the
audience A to be a singleton with unique element a . In this case, under the decision
model the analyst will choose a rule c such that c (X ) minimizes Ea [L (d, ) |X ]
almost surely. Any such rule is also optimal under the communication model. If A
instead contains multiple priors this logic need not apply and, as we show below, the
two models can have quite different implications.


Interpretation of the Decision and Loss
We pause to highlight two ways to interpret the decision d  D and loss L (d, ).
One interpretation is that the decision d  D represents a real-world action whose
consequences are captured by L (d, ). For example, doctors may need to choose a
treatment, policymakers to set a tax, and scientists to decide on what experiment to
run next. On this interpretation, the decision model reflects a situation in which the
analyst makes a decision on behalf of all agents, or equivalently, all agents are bound
to take the decision recommended by the analyst. The communication model, by
contrast, reflects a situation in which each agent is free to take their optimal decision
given the information in the analyst's report.
   Another interpretation is that the decision d  D represents a best guess whose
departure from the truth is captured by L (d, ). This interpretation is evoked by
canonical losses, such as L (d, ) = (d - )2 , that increase in the distance between
the estimate and the parameter. On this interpretation, the decision model reflects



                                           7
a situation in which each agent evaluates the quality of the analyst's guess according
to the agent's prior. The communication model, by contrast, reflects a situation in
which each agent evaluates the quality of the agent's own best guess, as informed by
the analyst's report as well as the agent's prior.
    In many real-world situations the agents in the audience for a given scientific find-
ing will have diverse opinions and may therefore make different decisions, or form
different best guesses about an unknown parameter, after observing the same re-
port. The communication model better reflects such situations than does the decision
model. In other situations--for example, a government committee deciding on the
appropriate treatment to reimburse for a given diagnosis for all practitioners, or a
scientific committee deciding where next to point a telescope that will provide data
to many researchers--the decision model seems a better fit.


3     Conflict in Dominance Ordering
We will say that a rule c dominates another rule c under a given model if the rule
c achieves weakly lower risk for all agents in the audience and strictly lower risk for
some. In this section, we show by example that the decision and communication
models can imply opposite dominance orderings, in the sense that c dominates c in
the communication model but c dominates c in the decision model.


3.1    A Treatment Effect with a Sign Constraint
An analyst observes data on weight gain for a sample of children enrolled in a ran-
domized trial of deworming drugs (anthelmintic therapy). For the NC children in the
control group, weight gain Xi is distributed as Xi  N (C ,  2 ). For the NT children
in the treatment group, weight gain Xi is distributed as Xi  N (T ,  2 ) . Thus the
sample space is X = RNC +NT . We assume that weight gain is independent across
children so that the control group mean X C and treatment group mean X T follow

                                                     2
                         XC               C          NC
                                                          0
                                N               ,         2
                                                                  .
                         XT               T          0    NT




                                            8
The variance  2 and group sizes (NC , NT ) are commonly known. The average treat-
ment effect of deworming drugs on child weight is T - C . Suppose that this effect is
known a priori to be nonnegative, and in particular  = {(C , T )  R2 : T  C }.
   The audience consists of governments who must decide how much to subsidize (or
tax) deworming drugs. The governments face a loss L (d, ) = (d - (T - C ))2 for
d the per-unit subsidy, with d < 0 denoting a tax. The set of feasible decisions is
D = R. We assume that the audience A consists of the set of all distributions such
that T - C is a zero-truncated normal. All statements in this section continue to
apply when A =  ().
   Consider two decision rules, c and c , defined as

                    c (X ) = X T - X C , c (X ) = max {c (X ) , 0} .

The rule c reports the difference in means between the treatment and control groups.
The rule c censors this report at 0.

Claim 1. Rule c dominates rule c under the decision model. Rule c dominates rule
c under the communication model.

   Start with the decision model. Because all governments accept that T  C , a
tax on deworming drugs is never optimal. Yet, the rule c will sometimes recommend a
tax. Under the decision model, such a recommendation incurs an unnecessarily large
loss, because it is worse than recommending a neutral policy d = 0.
   Next consider the communication model. Although all governments accept that
T  C , in cases where X T - X C < 0 the realized value of X T - X C is nevertheless
informative about the true value of T - C . Intuitively, the lower is X T - X C ,
the stronger is the evidence for a small value of T - C . The rule c preserves this
information, whereas the rule c discards it. Even though every government's optimal
subsidy d is nonnegative, there is no benefit to the censoring in c , because each
government can simply censor its own decision d based on the information conveyed
by c.
   We can compare the implications of the decision and communication models to
observed practice in a situation similar to the example. Kruger et al. (1996) conducted
an early randomized controlled trial of the effect of deworming drugs on children's

                                           9
growth. A separate randomization was used to study the effect of iron-fortified soup.
Among children who received unfortified soup, those receiving deworming drugs had
a lower average growth over the intervention period (mean weight gain of 0.9kg,
n = 15) than those receiving a placebo treatment (mean weight gain of 1.0kg, n = 14;
see Table 4 of Kruger et al. 1996). Kruger et al. (1996) state that "[Positive effects on
weight gain] can be expected with reduction in diarrhoea, anorexia, malabsorption,
and iron loss caused by parasitic infection" (p. 10). In a later review of the literature,
Croke et al. (2016) state that "there is no scientific reason to believe that deworming
has negative side effects on weight" (p. 19).
       If we interpret these statements to mean that the average treatment effect is
known to be non-negative, then censoring the estimated treatment effect at 0 (i.e.,
reporting that the treatment and control groups experienced the same average weight
gain) would lead to an estimate strictly closer to the truth than the negative estimate
implied by the group means, and would therefore dominate in mean squared error.
However, Kruger et al. (1996) did not publish a censored estimate, nor did any of the
four studies that Croke et al. (2016) identify as implying negative point estimates of
the effect of deworming drugs on weight.5


3.2       Discussion
We have focused on a scenario where the audience consists of policymakers, so the loss
captures the value of setting the right policy. We may alternatively envision the loss
as capturing the scientific community's desire for a good guess of the true average
treatment effect. On this interpretation, a guess d < 0 is again unappealing from
   5
     Croke et al. (2016, Figure 2) identify 4 negative point estimates out of a total of 22 reviewed.
These 4 negative point estimates are from 4 distinct studies (including Kruger et al. 1996), out of a
total of 20 distinct studies reviewed. Donnen et al. (1998, Table 2) report the regression-adjusted
weight gains for a group treated with mebendazole and a control. They further report that the
treated group's gain is statistically significantly below that of the control group at all time horizons
considered. Croke et al. (2016, Figure 2) report a statistically significant effect on weight gain of
-0.45kg based on the data from Donnen et al. (1998). Miguel and Kremer (2004, Table V) report
treatment and control group means of standardized weight-for-age and a statistically insignificant
difference in means of -0.00 to rounding precision. Croke et al. (2016, Figure 2) report a statistically
insignificant effect on weight of -0.76kg based on the data from Miguel and Kremer (2004). Awasthi
et al. (2000, Table 1) report treatment and control group means of weight gain and report that
these are not statistically different. Croke et al. (2016, Figure 2) report a statistically insignificant
effect of -0.05kg based on the data from Awasthi et al. (2000).


                                                   10
the standpoint of decision risk (such a guess cannot be right), but may be appealing
from the standpoint of communication risk (because it conveys useful information
that agents can use in formulating their own guesses).
   We have focused on rules that have range D and are therefore decision rules. This
is natural under the decision model but is restrictive under the communication model.
To illustrate, suppose that S contains R2 and consider the rule c with

                                 c (X ) = X C , X T .

Claim 2. The rule c dominates the rule c under the communication model. The
rule c achieves weakly lower risk for all agents than does any other rule under the
communication model.

Because the rule c conveys more information than the rule c, it dominates the rule c
under the communication model. Moreover, because the statistic c (X ) is sufficient
for , rule c is weakly better than any other rule for any agent under the communi-
cation model. Interestingly, Kruger et al. (1996) report group means for the control
and treatment groups, and do not explicitly report the difference X T - X C .
   We have also focused on a situation in which the tension between the decision and
communication models arises due to an a priori constraint on the parameter space.
While illustrative, that is not the only situation in which the tension arises. Imagine,
for example, that the randomized controlled trial is run at J  3 sites j , each of which
                                          j   j
is associated with its own parameters j = C , T . We drop the sign constraints,
so that  = R2J , and take A to be the set of all distributions on  such that the
J -vector T - C is normally distributed. Agents in the audience must now choose a
                                                                                2
subsidy or tax for each site, so that D = RJ , and L (d, ) = d - (T - C )           for ·
the Euclidean norm. At each site the number of treatment and control units is equal
to N , which we continue to assume is commonly known along with the variance  2
of weight gain. Consider two estimators, cM and cJS defined as

                                                      J -2      2 2
       cM (X ) = X T - X C , cJS (X ) = max 1 -               2     , 0 cM (X ) .
                                                      M
                                                     c (X )      N

                                                                         j      j
where X T - X C is the J -vector of treatment-control differences X T - X C . The

                                          11
rule cM corresponds to the maximum likelihood estimator for the vector of average
treatment effects, while cJS is a positive-part James-Stein estimator.

Claim 3. Rule cJS dominates rule cM under the decision model. Rule cM dominates
rule cJS under the communication model.

   Classic results in statistics (James and Stein 1961; Baranchik 1970; Efron and
Morris 1973) imply that for any value of  the mean-squared error of rule cJS is
strictly lower than that of cM , implying that cJS dominates cM under the decision
model. At the same time, because cJS (X ) is a function of cM (X ), cM is at least as
good as cJS for any agent under the communication model. Moreover, because cJS
sometimes discards useful information (by mapping a range of X T - X C values to
zero), cM dominates cJS under the communication model.


3.3    Generalization
The examples in this section illustrate two general properties of dominance orderings
under the communication model. The first is that coarsening the analyst's report is
never desirable.

Proposition 1. Fix rules c, c  C . If the distribution of c (X ) |c (X ) , X is equal to
 (c (X )) for some  : S   (S ), then c achieves weakly lower risk than c for all
agents a  A under the communication model. If, further, there exists a  A for
whom c (X ) and c (X ) imply different optimal actions with positive probability,


           Pr arg min Ea [L (d, ) |c (X )]  arg min Ea [L (d, ) |c (X )] =    > 0,
           a     dD                           dD

                                    
where both minima are achieved and Ra (c) is finite, then c dominates c under the
communication model.

The conditions in the first part of Proposition 1 imply that c (X ) is a garbling of
c (X ), while the second part gives a sufficient condition for strict superiority of c for
a given loss function and prior. An important special case of garbling is when c (X )
can be written as a deterministic transformation of c (X ), as in the examples in this
section.

                                             12
    The second general property is that, following Blackwell (1951, 1953), it is optimal
for the analyst to report sufficient statistics when feasible.

Proposition 2. Fix a rule c  C . If c (X ) is sufficient for  under F , then c
achieves weakly lower risk than does any other rule for all agents a  A under the
communication model.

The statements about the communication model in Claims 1, 2, and 3 are corollaries
of Propositions 1 and 2.


4      Conflict in Admissibility
We will say that a rule c is admissible under a given model if no other rule dominates
c. Admissibility in the decision model corresponds to what Stoye (2012) terms -
admissibility. In this section, we give an example in which the sets of admissible rules
under the decision and communication models do not intersect.


4.1    Optimal Treatment Assignment
An analyst must make a clinical recommendation to an audience of physicians on the
basis of the available evidence. Say that each physician's goal is to achieve the best
average outcome for patients with each of a given set of attributes (e.g., diagnoses).
We suppose these attributes are discrete, as in Manski (2004), and study the problem
of recommending treatment to patients in a given attribute cell.
    Formally, denote the available treatments (e.g., medications) by t  {1, ..., T }
for T  2. Suppose that the analyst observes data from a trial where n  1 units
(e.g., patients) are randomly allocated to each treatment t, and that for each unit
i the analyst measures a binary outcome Yi (e.g., an indicator for the resolution
of symptoms). Let us further assume that patient outcomes are independent, so
it is without loss to represent the data for treatment t as a fraction of successes
       1
Xt  0, n , ..., 1 , with nXt following a binomial distribution. The sample space is
then
                                                       T
                                           1
                                  X =    0, , ..., 1       .
                                           n

                                           13
      The unknown parameter is (1 , ..., T ) where t denotes the success probability
for units assigned to treatment t. We assume each t lies in a nontrivial interval
                                                 T
0  (0, 1), so the parameter space is  = T
                                        0  (0, 1) . We take the audience to

consist of all possible priors A =  ().
      Each physician's decision consists of either picking a treatment t or declining to do
so. Formally we take the decision space to be D = {1, ..., T }{} where  corresponds
to not picking a treatment. The physician's objective is to pick the best treatment
which, following Manski (2004), we formalize by considering the regret loss
                                          
                                          -d + maxt t           if d = 
                              L (d, ) =                                   .
                                          max                   if d = 
                                             t t


Declining to pick a treatment yields greater loss than picking any given treatment
(e.g., because the patient cannot self-prescribe).
      Again consider two rules. The first rule, c , takes c (X ) = arg maxt Xt if the
argmax is unique and otherwise randomizes uniformly over arg maxt Xt . The second
rule, c                                                    ~ (X ) = c (X ) otherwise. As in
               ~ (X ) =  if arg maxt Xt = {1, ..., T } and c
      ~, takes c
Section 3, the comparison of these two rules reveals a conflict in dominance ordering
between the communication and decision models.

Claim 4. Rule c dominates rule c
                               ~ under the decision model. Rule c
                                                                ~ dominates rule
c under the communication model.

      Start with the decision model. The rule c is a special case of what Manski (2004)
terms the "conditional empirical success" rule, and is related to the empirical wel-
fare maximization procedures studied by Kitagawa and Tetenov (2018) and Athey
and Wager (forthcoming). Classical decision-theoretic results for selection problems
(Lehmann 1966; Eaton 1967) imply that the rule c minimizes decision risk uni-
formly over A =  () among rules that are invariant with respect to permutations
of the treatments, and that c is an optimal decision rule for any agent a with a
permutation-invariant prior.6 By contrast, because the rule c
                                                            ~ sometimes fails to make
a recommendation, thus choosing the bad decision d = , the rule c
                                                                ~ is not an optimal
decision rule for any agent a  A.
  6
      The results of Stoye (2009) further imply that c is a minimax decision rule in the case of T = 2.

                                                   14
   Next consider the communication model. Any agent can construct c (X ) given
~ (X ) for any X  X . Proposition 1 therefore implies that rule c
c                                                               ~ achieves weakly
lower risk than rule c . Note, however, that c
                                             ~ (X ) cannot be constructed from c (X ),
because c (X ) does not inform the agent when there has been a tie. Intuitively, this
results in a loss of useful information for an agent a whose prior is such that they
prefer to follow the rule c only when the data are informative about the optimal
                                                               ~ dominates c under
treatment. For this reason, Proposition 1 further implies that c
the communication model.
   In fact, the tension between the decision and communication models is stronger
than what is captured by Claim 4. Because d =  is a bad decision, any rule that
sometimes recommends it is inadmissible in decision risk. But because the decision
space is too small to convey the full data, T + 1 = |D| < |X | = (n + 1)T , and distinct
realizations of the data imply distinct optimal actions for some agent, any rule that
does not sometimes report c (X ) =  is inadmissible in communication risk.
Claim 5. There exists no rule c that is admissible under both the decision model and
the communication model.
We prove Claim 5 as a consequence of a more general result for situations with finite
decision and sample spaces. Loosely, if (i) there is a decision that is always unappeal-
ing and (ii) the decision space is too small to convey the actionable information in
the data, then there exists no rule that is feasible and admissible in both the decision
model and the communication model.
   In practice, analysts in situations like the one we have modeled sometimes ex-
press their ignorance rather than choosing a concrete recommendation at random.
UpToDate is a private publisher that synthesizes medical research into clinical rec-
ommendations. As in the communication model, readers of these recommendations
include practitioners who are free to make different clinical decisions. On the choice
among selective serotonin reuptake inhibitors (SSRIs) to treat unipolar major depres-
sion in adults, UpToDate says, "Given the lack of clear superiority in efficacy among
antidepressants, selecting a drug is based on other factors, such as ... patient prefer-
ence or expectations" (Simon 2019). Such a report seems more similar to c
                                                                        ~ than to
c , and thus more consistent with the predictions of the communication model than
with the predictions of the decision model.

                                          15
4.2      Discussion
The example illustrates a tension between the decision and communication models
that arises when the data are completely uninformative. Reporting that findings
are inconclusive arises in many situations like the one illustrated by the UpToDate
quote. Online Appendix A extends the analysis to demonstrate a case in which the
communication model favors reporting  even when the data are informative, provided
the amount of information in the data is small in comparison to the audience's priors.
    Claim 5 holds for any signal space S containing D. Indeed, it seems plausible that
an analyst concerned with communication risk might wish to convey more than simply
"I don't know." The UpToDate article that we quote above, for example, discusses
the evidence before stating its conclusion, noting that some evidence in favor of a
particular selection of SSRIs failed to replicate in a second meta-analysis, and that
"randomized trials have found no evidence that one antidepressant [SSRI] is superior
in preventing relapse or recurrence" (Simon 2019).
    The conclusion of Claim 5 also holds if we restrict D to contain only the feasible
treatments {1, ..., T }, provided that the signal space S contains at least one element
that is not in {1, ..., T }. Intuitively, in this case the rule c
                                                                ~ is simply infeasible under the
decision model, but remains superior to the (feasible) rule c under the communication
model.


5     Additional Optimality Criteria
In this section we look beyond dominance comparisons to consider two other opti-
mality criteria: optimality in weighted average risk, and minimaxity. To derive our
results, we impose the following regularity conditions.

Assumption 1. There exists a  -finite measure  which dominates F for all   .
The loss function L (d, ) is nonnegative and lower semicontinuous in d for all   .

The existence of a dominating measure is a weak condition that holds in all of our
examples. Likewise, the loss functions in our examples are continuous in d, which
implies lower semicontinuity.


                                              16
Assumption 2. The decision space is a subset of Euclidean space, D  Rq for q
finite, and is closed. Moreover, either (i) D is bounded or (ii) lim    d    L (d, ) = 
for all .

Assumption 2 holds in all of our examples. See Assumption 3 in the Appendix for a
weaker condition sufficient for our results.


5.1      Weighted Average Risk
Let  be a distribution on A and define

                    (c) =        Ra (c) d (a) ,  (c) =
                                                              
                                                             Ra (c) d (a)
                             A                           A


to be the weighted average decision and communication risk of rule c, respectively.
Any rule c  B that minimizes weighted average decision risk  (c) is a Bayes decision
rule (e.g., Lehmann and Casella 1998, p. 6; Robert 2007, p. 63). Bayes decision rules
have strong optimality properties in the classical setting.7
      For given weights  , weighted average risk defines a complete ordering on the set
of rules, whereas dominance and admissibility define only partial orderings. These
orderings are closely related.

Proposition 3. Suppose Assumptions 1 and 2 hold. If, under a given model, rule c
dominates rule c , and the risk function for c is bounded and continuous in a, then
c has strictly lower weighted average risk than c with respect to any weights  with
full support on A. If the risk functions for all rules are bounded and continuous in a,
then any rule that minimizes weighted average risk with respect to full-support weights
 is admissible.

Intuitively, if c dominates c , then at least one agent a is worse off under c than under
c , and no agent is better off. As long as  puts weight on agents in a neighborhood of
a, and agents in that neighborhood have risk similar to a's, c will be strictly preferred
to c under weighted average risk.
  7
    In particular, Complete Class Theorems show that in many cases any rule that cannot be
expressed as Bayes is dominated by one that can be.



                                            17
      An implication of Proposition 3 is that if there is a conflict in dominance ordering
(as in Section 3) or a conflict in admissibility (as in Section 4) between the commu-
nication and decision models, then (under the given conditions) there is a conflict
in the ordering of weighted average risks with respect to full-support weights. The
following corollary illustrates for the case of a conflict in admissibility.

Corollary 1. Suppose that decision and communication risk are bounded and con-
tinuous in a for all c  B . If there is no rule that is admissible under both the
decision and communication models, then any rule c that minimizes weighted average
risk for some full-support weights  under the decision model is inadmissible, and
does not minimize weighted average risk under any full-support weights   , under the
communication model.

Under the conditions of Corollary 1, any Bayes decision rule based on full-support
weights  is inadmissible for communication, and does not minimize weighted average
communication risk for any full-support weights, including weights   =  .


5.2      Maximum Risk
We will say that a rule c is minimax under a given model if it minimizes the maximum
risk possible under the set of priors in the audience. Formally, rule c is minimax if

                     Ra (c ) = inf sup Ra (c) , Ra
                                                 
                                                   (c ) = inf sup Ra
                                                                   
                                                                     (c)
                               cB aA                      cC aA


under the decision and communication models, respectively. Since we evaluate perfor-
mance with respect to a class of priors, minimaxity in the decision model corresponds
to robust Bayes optimality (also called -minimaxity ­ see, e.g., Gilboa and Schmei-
dler 1989; Stoye 2012).
      The max-min inequality implies that inf cB supaA Ra (c)  supaA inf cB Ra (c).
If the reverse is true, so that inf cB supaA Ra (c) = supaA inf cB Ra (c), we will say
that a minimax theorem holds under the decision model.8

  8
    Viewing the decision model as a zero-sum game between the analyst and nature, a minimax
theorem holds if and only if this game has a value (von Neumann and Morgenstern 1944).



                                             18
Theorem 1. If a minimax theorem holds under the decision model, then any rule
c that is minimax under the decision model is minimax under the communication
model.

Proof. By the definitions of decision and communication risk, for all a  A, inf c B Ra (c )
                            
 Ra (c) for all c  C , and Ra (c)  Ra (c) for all c  B . By the first inequality and the
                                                                            
max-min inequality, supaA inf cB Ra (c)  supaA inf cC Ra (c)  inf cC supaA Ra (c).
                                             
Since Ra (c)  Ra (c), however, inf cC supaA Ra (c)  inf cB supaA Ra (c). If a mini-
                                                                            
max theorem holds under the decision model, this implies that inf cC supaA Ra (c) =
inf cB supaA Ra (c), and any rule c with Ra (c ) = inf cB supaA Ra (c) must also
have Ra (c ) = inf cC supaA Ra
                             
                               (c) and therefore be minimax under the communica-
tion model.

Thus if a minimax theorem holds under the decision model, there is no conflict be-
tween the decision and communication models when the analyst seeks to minimize
maximum risk.
   Theorem 1 holds for all S  D. Hence, for minimax communication, there is no
gain from enlarging the signal space beyond D, or in communicating information other
than a recommended decision, provided a minimax theorem holds. The literature has
derived minimax rules in a wide range of frequentist decision problems, and Theorem 1
implies that these will also be minimax communication rules for the maximal audience
A =  (), provided a minimax theorem holds. Theorem 1 also implies that robust
Bayes decision rules with respect to a class of priors A are robust communication
rules with respect to the same class of priors, provided a minimax theorem holds.
   The next proposition, proved in the appendix as a consequence of a more general
result building on arguments from Strasser (1985), gives sufficient conditions for a
minimax theorem to hold. To state the proposition, we say that A is convex if for
any a, a  A and any   (0, 1),  · a + (1 - ) · a  A.

Proposition 4. Suppose Assumptions 1 and 2 hold. If the audience A is convex,
then a minimax theorem holds under the decision model, and there exists a minimax
rule c .

Convexity of A holds for the maximal audience A =  (), as well as for the classes
of priors studied in Gilboa and Schmeidler (1989). We next discuss an example that

                                           19
illustrates the differences between minimizing weighted average risk and minimizing
maximum risk, and also highlights the role played by convexity of A in Proposition
4.


5.3     Combining Multiple Moments
An analyst observes k moments X  Rk and is interested in a scalar parameter  . An
                                                                    ) = X - G
economic model imposed by the analyst implies a moment function g (~         ~,
for G a known, nonrandom k -vector. Under the analyst's model the moment g ( )
has mean 0 at the true value of  . The economic model may be misspecified, however,
so that the true mean of g ( ) is given by ( ,  ), where (,  ) are nuisance parameters
with dim ( ) + dim ( ) = k . Thus  = (, ,  ). We formalize the idea that  is the
parameter of interest by taking D = R and L (d, ) = (d -  )2 .
     We further assume that

                              g ( )  N ( ,  ) ,  2 · Ik

where  2 > 0 is a commonly known variance and Ik is the identity matrix. Armstrong
and Koles´
         ar (2020), among others, describe conditions under which Gaussian models
of this kind approximate GMM settings with local misspecification.
     All agents a  A believe that  follows a multivariate normal distribution with
  ( ,  ) and   N (0, 2
                      ) for  > 0. Agents are concerned about misspecification,

and each agent a believes that  = a and   N 0, 2
                                                · Idim( ) for   0. Thus,

agents are certain, but may disagree, about the extent of misspecification of the first
dim ( ) moments, and are uncertain, in a commonly-agreed way, about the extent of
misspecification of the remaining dim ( ) moments.
     We will consider an audience A and weights  such that beliefs about  follow
a  N 0, 2
         · Idim( ) under  , for  > 0. Under such weights we can charac-

terize rules that minimize weighted average risk under both the decision and com-
munication models. Towards such a characterization, decompose X =             X , X
and G =      G , G     conformably with ( ,  ) and assume that G , G = 0. Let
               -1
^ =      G G        G X be the maximum likelihood estimate (absent misspecifica-
tion) based on the first dim ( ) moments, and define ^ analogously. Note that

                                          20
           2                                   -1
      |) = 
Var (^       =  2 ·  for  = G G                     , and likewise for ^ .

Claim 6. Any rule c that minimizes weighted average risk under the decision model
takes
                                        2            -1                         -1
                                          + 2
                                                          ·^ + 2
                                                                 + 2
                                                                                     ·^
           c (X ) = c (^
                        , ^ ) =                              -1                      -1
                                        -2 +  2 + 2 
                                                                  + 2 + 2 
                                                                         

almost surely. One rule c that minimizes weighted average risk under the communi-

cation model takes

                                              -2      2               -1
                                                 ·^ +   + 2
                                                                           ·^
                c    (X ) =   c   (^
                                    , ^ ) =                                -1   .
                                              -2 +  -2 +  2 + 2 
                                                               


The rule c does not minimize weighted average risk under the communication model,
and the rule c does not minimize weighted average risk under the decision model.

Moreover, no other rule achieves strictly lower communication risk than c for any

agent.

   Both c (^
            , ^ ) and c (^
                          , ^ ) are weighted averages of the prior mean (i.e., 0)
and the maximum likelihood estimates (^
                                       , ^ ). The weighted averages differ in the
weight they place on ^ , the maximum likelihood estimate based on the block of
moments about which the agents disagree. Each agent a is confident that the bias
                       -1
of ^ for  is G G            G a . Under the decision model, disagreement about the
magnitude of the bias translates into a larger expected distance between ^ and  .
Under the communication model, such disagreement is irrelevant, because each agent
a can readily compute their posterior mean

                                                          -2        -1
                                                             G G         G a
            Ea [ |c     , 
                      (^  ^ )] =    c   (^
                                          , ^ ) -                                    -1
                                                    -2 +  -2 +  2 + 2 
                                                                     


that adjusts c   , 
               (^  ^ ) for the bias in ^ . As a result, c (^
                                                            , ^ ) places more weight
on ^ than does c (^
                   , ^ ). And because Ea [ |c (^
                                                , ^ )] coincides with agent a's
posterior mean Ea [ |X ] based on the full data, no communication rule can be better
than c from the agent's point of view.

   In the limit taking disagreement to zero,   0, the two rules coincide, whereas
in the limit taking disagreement to infinity,   , c (^
                                                      , ^ ) places no weight on

                                               21
^ , and c
          (^
            , ^ ) is unaffected. By contrast, the rules c and c are similar in how

they treat agents' uncertainty about  , and in the limit as    both rules place
no weight on ^ . Thus, the decision and communication models both predict that the
analyst will down-weight moments about whose validity the audience is very uncer-
tain. In contrast to the communication model, however, the decision model further
predicts that the analyst will down-weight moments about whose misspecification
audience members disagree, even if each audience member is certain in their belief.
   In practice analysts frequently choose from among a large set of potentially mis-
specified moments when estimating economic models. Nakamura and Steinsson (2018)
advocate estimating structural models of the macroeconomy by targeting "identified
moments" that correspond to direct estimates of causal effects (see also Dridi et al.
2007). Nakamura and Steinsson (2018) argue that, although the assumptions jus-
tifying the causal interpretation of identified moments "are typically controversial,"
these moments are sensitive to a relatively narrow range of modeling assumptions.
By contrast, other moments one could target, for example unconditional means and
variances, are likely to be sensitive to the specification of many different aspects of
the model. Targeting identified moments may therefore allow audience members to
form more precise beliefs about the likely impact of misspecification on the analyst's
estimate. In this sense the recommendation to target identified moments, in pref-
erence to moments whose behavior under misspecification is harder to assess, seems
more consistent with the predictions of the communication model than with those of
the decision model.
   It is also possible to characterize minimax rules in this example.

Claim 7. Any rule c
                   that is minimax under the decision model takes

                                               2         -1
                                                 + 2
                                                              ·^
                      c
                       (X ) = c
                               (^
                                 , ^ ) =                       -1
                                            -2 +  2 + 2 
                                                       


almost surely, and therefore coincides with c in the limit as   . The rule c
                                                                            is
not minimax under the communication model.

   Because any decision rule that puts weight on ^ can be arbitrarily bad for suffi-
ciently large a , the rule c
                            puts no weight on ^ . Ignoring ^ is unappealing under the

                                          22
communication model, however, because ^ is informative about  , and as discussed
above agents can account for the bias in ^ in formulating their optimal decision, no
matter how large is a .
       Proposition 4 does not apply in this setting because the audience A is not convex.
If we replace the audience A with its convex hull, then by Proposition 4 and Theorem
1, c
    is a minimax rule under the communication model. Intuitively, convexifying
the audience means that if there exist agents a and a who disagree about  , there
exists a third agent a who puts equal weight on the two beliefs. Convexity thus
turns disagreement about how to interpret ^ into uncertainty, and so implies that
minimax communication rules should put no weight on ^ . This illustrates the role
of the convexity restriction on A in Proposition 4.

Discussion

Under the communication model, rule c is more appealing than rule c because

agents can adjust for the bias in ^ when forming their own decisions or judgments.
To make the appropriate adjustment, agents need to know the weight that c (^
                                                                            , ^ )
places on ^. Andrews et al. (2020) discuss the situation where weights are data-
dependent, in which case it is appealing (from the standpoint of communication risk)
for the analyst to report the weights to the audience.
       Under the communication model, the rule c (^
                                                   , ^ ) is as good, for any agent,
as having access to the full data X .9 This property of the example depends on the
assumption that all agents have the same prior variance for . In situations with more
heterogeneity in agents' beliefs, there need not be a low-dimensional sufficient statistic.
Online Appendix B considers a setting where each component of g ( ) is subject to
an additional disturbance, on which agents have mean-zero Gaussian priors with
potentially different prior variances. In this case, any coarsening of the data increases
risk for some agent, and an analyst concerned with communication risk in such a
setting might be expected to report X to the audience. DellaVigna (2018) advocates
reporting the moments X as good practice when estimating structural models in
behavioral economics. Online Appendix B shows that, as the size of the additional
   9
    In particular, c (^
                       , ^ ) is marginally sufficient for  with respect to A in the sense of Raiffa
and Schlaifer (1961).


                                                23
disturbance becomes small, c (^
                               , ^ ) achieves communication risk arbitrarily close
to that from observing X . If there are communication constraints (say because k is
large or some data must remain confidential), c (^
                                                  , ^ ) therefore remains appealing
under the communication model.


6     Conclusions
We propose a model of scientific communication in which the analyst's report is
designed to convey useful information to the agents in the audience, rather than, as in
a classical model of statistics, to make a good decision or guess on these agents' behalf.
We exhibit settings in which the proposed model predicts very different reporting
rules from the classical model. We argue that, in some practical situations similar to
these settings, scientists' reports appear more consistent with the predictions of the
proposed model than with the predictions of the classical model.

Proofs of Claims

Proof of Claim 1. To see that c dominates c under the decision model, note that
Pra {c (X ) < 0} > 0 for all a  A, and

             Ea [L (c (X ) , ) |c (X ) < 0] > Ea L c (X ) ,  |c (X ) < 0 ,

while the two rules achieve the same loss when c (X )  0. Dominance in the decision
model follows immediately.
    For dominance in the communication model consider an agent with a N (µ, 1)
prior on T - C , truncated at zero. This agent's posterior on T - C after observing
                                   ~ -2                  -1                                 2       2
c (X ) = d is a N     1
                       -2
                    1+~
                          µ   +    
                                  1+~ -2
                                         d, (1   +~ -2 )      truncated at zero, for ~2 =   NT
                                                                                                  
                                                                                                 +NC
                                                                                                     .
This agent's optimal decision is thus a strictly increasing function of c (X ). Since
c (X ) is a non-invertible transformation of c (X ) , and arg mindD Ea [L (d, ) |c (X )]
                                                                 ~< 0
is a singleton by strict convexity of the loss, for almost every d

                                     ~  arg min Ea [L (d, ) |c (X ) = 0] = .
        arg min Ea L (d, ) |c (X ) = d
          dD                                          dD




                                                    24
Proposition 1 thus implies that c dominates c in the communication model.

Proof of Claim 2. For the first part of the claim, consider an agent with a dog-
matic prior that C = 0 with probability one. Suppose further that this agent has
a N (µ, 1) prior on T . This agent's posterior on the average treatment effect after
                                              -2
            ¯C , X
                 ¯ T will be a N   1         ~T    ¯          -2 -1
observing X                      1+~
                                     -2 µ +
                                              
                                            1+~ -2 XT , 1 + ~ T     distribution trun-
                                       T          T
                          2
                          
                    2
cated at zero, for ~T  =N  T
                             . Hence, this agent's optimal action is a strictly increasing
transformation of X ¯ T . Under the agent's prior, however, c (X ) is equal to X   ¯ T plus
standard normal noise, so the agent cannot implement this optimal action based on
observing c (X ) alone. Proposition 1 thus implies that c dominates c under the
communication model.
   The second part of the claim is immediate from Proposition 2.

Proof of Claim 3. The first part of the claim follows from standard results on
the positive-part James-Stein estimator (see e.g. Efron and Morris 1973). For the
second part of the claim, consider an agent with a N (µ, IJ ) prior on the vector of
average treatment effects, and note that this agent's posterior mean is a one-to-one
                           ¯T - X
transformation of c (X ) = X     ¯ C . Hence, the conclusion follows from Proposition
1 by an argument similar to the proof of Claim 1.

Proof of Claim 4. Under the decision model, all agents a  A strictly prefer to
randomize uniformly over d  {1, ..., T } rather than taking d = . That c dominates
c
~ in the decision model follows immediately.
   For the second part of the claim, note that c
                                               ~ yields weakly smaller communication
risk for all agents than c by the first part of Proposition 1. To show strict inequality
for some agents, consider agents a for whom Ea [t | arg maxt Xt = {1, ..., T }] is non-
constant across t, while for all X arg maxt Ea [t |c (X )] = c (X ) . Any agent a with
a permutation-invariant prior has c (X )  arg maxt Ea [t |c (X )] , so we can find
agents a of the sort we desire by slightly perturbing such a prior. When arg maxt Xt =
{1, ..., T }, the decision taken by these agents is uniformly randomized under the rule
c , while under the rule c
                         ~ they are able to pick a decision they strictly prefer to uniform
randomization. Dominance in the communication model follows by Proposition 1.


                                            25
Definition 1. Suppose X is finite, and let P be the set of partitions of X , with generic
element P  P . Let P  denote the subset of P such that for every cell Xp  P  P  ,
each agent has at least one decision d  D that is optimal for every x  Xp . That is,


 P =     P P:       xXp arg min Ea [L (d, ) |X = x]        =  for all Xp  P, a  A .
                            dD


The effective size of the sample space X , denoted N (X , A), is the minimal size
of a partition in P  , N (X , A) = min {|P | : P  P  } .

Proposition 5. Suppose that D and X are finite, that L (d, ) is bounded, and that
there exists a decision d  D with L (d, )  L (d , ) for all    and some d  D,
with strict inequality for all   ~  . Suppose further that Pra  ~ > 0 for some
a  A, and that F has support X for all   . If N (X , A)  |D|, then any rule
c that is admissible in decision risk is inadmissible in communication risk and vice
versa.

Proof of Claim 5. We prove this result building on Proposition 5. First, note that
choosing d = 1 yields strictly lower loss than choosing d =  for all   , which
verifies the condition on the loss. Next, note that the effective size N (X ,  ()) of
the sample space is bounded below by the size N X , A    ~ for a restricted audience
~   (). Consider the audience consisting of only three agents, a0 , a1 , and a2 .
A
Agent a0 has a uniform prior on . This implies that t is independent of s for
all s = t. By the monotone likelihood ratio property of the binomial distribution,
provided arg maxt Xt is unique this agent strictly prefers to set d = arg maxt Xt . When
arg maxt Xt is not unique, by contrast, this agent strictly prefers d  arg maxt Xt to
d  arg maxt Xt , but is indifferent among d  arg maxt Xt .
   Note, next, that

                              f (X ; ) da ()
               a (|X ) =                       , Ea [|X ] =      da (|X )
                              f X;   ~ da    ~                
                           


for f (X ; ) the probability mass function of F , where F has full support for all
  . Hence, Ea [|X ] is continuous in a (for the L1 norm on A). Thus, there exists
an open neighborhood N (a0 ) around a0 such that all agents a  N (a0 ) strictly

                                           26
prefer to set d  arg maxt Xt to d  arg maxt Xt for all realizations of X . Within this
neighborhood, there is an agent a1 who strictly prefers d = 1 when arg maxt Xt =
{1, ..., T }, and an agent a2 who strictly prefers d = 2 conditional on the same event.
This immediately implies, however, that N X , A     ~  T + 1, since


      arg min Ea0 [L (d, ) |X ] , arg min Ea1 [L (d, ) |X ] , arg min Ea2 [L (d, ) |X ]
        dD                         dD                          dD

     
     (arg max Xt , arg max Xt , arg max Xt ) when arg max Xt is a singleton
             t            t            t                 t
   =                                                                         ,
     (arg max X , 1, 2)
             t t                             when arg maxt Xt = {1, ..., T }

where the right hand side takes T + 1 distinct values.

Proof of Claim 6. Note that  (c) = Ra (c) for a        ~ =       a  ~ d (a) for
                                                               A
all ~  . Hence, weighted average decision risk is simply the decision risk for the
agent with the weighted average prior, a . However, the rule c (X ) corresponds to
the posterior mean for this prior, and hence is the almost-surely unique optimal rule
in the decision model.
   For the communication model, by contrast, note that, as discussed in the main
text, Ea [ |c (^
                , ^ )] = Ea [ |X ] corresponds to agent a's posterior mean. Hence,
c (^
    , ^ ) allows all agents to obtain the same risk as if they observed the full data,
and so is optimal in the communication model. By contrast, for all agents a  A,
Vara (c   , 
        (^  ^ ) |c (^
                     , ^ )) > 0, so c (^
                                        , ^ ) has strictly lower weighted average risk
than c (^
         , ^ ) under the communication model.

Proof of Claim 7. Note that for all c, supaA Ra (c) = sup  (c) . Hence, to obtain
a minimax decision rule, we want to solve mincB sup  (c). Note, next, that the
decision risk of c
                  (^
                    , ^ ) is the same for all a  A, and that c
                                                              (^
                                                                , ^ ) corresponds
to a Bayes decision rule for an agent with an infinite-variance normal prior on  , and
                  2
independent N (0,   ) and N 0, 2
                                · Idim( ) priors on  and  , respectively. Denote

the corresponding (limit of) weights by   , and note that for all a  A,

                            Ra (c ) =  (c ) = min  (c) .
                                                    cB



                                             27
Since  (c ) =  (c ) for all  , it follows immediately that c
                                                            is a minimax decision
rule. Since the loss function is strictly convex, it is almost surely unique. Finally,
                                                                             -1
                                                                     (2 +2  ) · ^
building on the proof of Claim 6, note that Ea [ |c    (^  , ^ )] = -2           -1 for
                                                                     +( +  )
                                                                         2  2


all a, and that Ea (Ea [ |c
                           (^  , ^ )] - Ea [ |c (^
                                                  ,  ^ )])2 =  > 0 for a constant .
Hence c
       is not minimax under the communication model.

Proofs of Propositions

Proof of Proposition 1. For the first part of the proposition, under the garbling
condition, an agent who observes c (X ) can generate draws from the distribution of
c (X ) |c (X ) , X by applying  to the observed report c (X ) . This, however, implies
that Ea [L (d, ) |c (X ) , c (X )] = Ea [L (d, ) |c (X )], so


    Ra (c) = Ea inf Ea [L (d, ) |c (X )]  Ea inf Ea [L (d, ) |c (X )] = Ra (c ) .
                   dD                                dD


For the second part of the proposition, let us write E  X for the event that

              arg min Ea [L (d, ) |c (X )]  arg min Ea [L (d, ) |c (X )] = .
                dD                              dD


Note that Ea [L (d, ) |c (X ) , E ] = Ea [L (d, ) |c (X )] , and consider f : X  D
such that f (X ) lies in arg mindD Ea [L (d, ) |c (X )] almost surely. By definition,
Ea [L (f (X ) , ) - mindD Ea [L (d, ) |c (X )] |E ] > 0, so since


                 Ea L (f (X ) , ) - min Ea [L (d, ) |c (X )] |X \ E  0,
                                       dD


the result follows.

Proof of Proposition 2. Sufficiency of c (X ) implies that for any other report
c (X ) and any prior a, the distribution of |c (X ) , c (X ) is the same as that of |c (X ).
Hence, Ea [L (d, ) |c (X ) , c (X )] = Ea [L (d, ) |c (X )] , and the argument is the same
as in the first part of Proposition 1.

Assumption 3. Either (i) D is compact or (ii) D is locally compact with a countable
base, and {d : L (d, )  l} is compact for all l  R and   .

                                              28
Lemma 1. Under Assumption 1, Assumption 2 implies Assumption 3.

Proof of Lemma 1. Proved in Online Appendix C.

Lemma 2. Under Assumption 1, decision risk is lower semicontinuous in a for all
c  C . Under Assumptions 1 and 3, the same holds for communication risk.

Proof of Lemma 2. Proved in Online Appendix C.

Proof of Proposition 3. We discuss the argument for the decision model, while
the result for the communication model follows by the same argument. Lemma 2
implies that Ra (c ) is lower semicontinuous in a, while Ra (c) is continuous in a by
assumption. Hence, Ra (c ) - Ra (c) is lower semicontinuous. Dominance of c means
that {a : Ra (c ) - Ra (c) < 0} is empty, while {a : Ra (c ) - Ra (c) > 0} is nonempty,
and is open by lower semicontinuity. Since  has full support, this implies that

       (c ) -  (c) =           1 {Ra (c ) - Ra (c) > 0} (Ra (c ) - Ra (c)) d (a) > 0.
                           A


Since Ra (c) is bounded  (c) is finite, proving the first part of the proposition.
   For the second part of the proposition, suppose towards contradiction that the
rule c minimizes weighted average risk, but is dominated by another rule c . By the
above  (c) >  (c ) , which contradicts weighted average optimality of c.

Proof of Corollary 1. By Proposition 3, under the conditions of the corollary any
rule that minimizes weighted average risk with respect to full-support weights in a
given model is admissible in that model. Hence, if the set of admissible rules for the
decision and communication model do not overlap, weighted average risk optimality
in the decision model implies inadmissibility, and hence non-optimality in weighted
average risk for any full-support weights, in the communication model.

   The next lemma considers generalized decision functions. For H the space of
bounded continuous functions h : D  R, and M the set of bounded signed measures
on X , define the class of generalized decision functions G as the set of bilinear functions
g : H × M  R with (i) |g (h, µ)|  h                   µ 1 , (ii) g (h, µ)  0 if h  0 and

                                              29
µ  0, and (iii) g (1, µ) = µ         1   if µ  0. For c  B , let c (·; x) be the measure
on D implied by c (x), define gc (h, µ) =           X   D
                                                            h(d)dc (d; x) dµ (x), and note that
{gc : c  B}  G . Further, for        : D  R define W (g, , a) =          
                                                                            g (  , F ) da (), and
note that W (gc , L, a) = Ra (c) .

Lemma 3. (Extension of Lemma 46.1 in Strasser 1985) Suppose that L is bounded
and continuous. For every continuous f : A  R the following two statements are
equivalent: (i) there exists g  G such that f (a)  W (g, L, a) for all a  A, (ii)
  f (a) d (a)  inf       W (g, L, a) d (a) : g  G for every weight function  on A.

Proof of Lemma 3. Proved in Online Appendix C.

Corollary 2. (Extension of Corollary 46.2 in Strasser 1985) The conclusion of
Lemma 3 holds for any loss function L that is lower semicontinuous in d.

Proof of Corollary 2. Proved in Online Appendix C.

Proof of Proposition 4. As discussed in the text, we need only show that

                             inf sup Ra (c)  sup inf Ra (c) .
                             cB aA               aA cB


To do so, note that supaA inf cB Ra (c)  sup inf cB  (c) , and let f (a) be the
constant function equal to sup inf cB  (c) for all a. By construction             f (a) d (a) 
inf     W (g, L, a) d (a) : g  G for all  , so by Corollary 2 there exists g   G with
f (a)  W (g  , L, a) for all a  A.
      For case (i) in Assumption 3, Theorem 43.2 of Strasser (1985) implies that there
exists some c  B with gc (L, µ) = g  (L, µ) for all µ  0. For case (ii), Theorem
43.5 of Strasser (1985) implies that there exists c  B such that gc (L, µ)  g  (L, µ).
For these c , supaA Ra (c )  sup inf cB  (c) by construction. Since A is convex,
however, sup inf cB  (c) is equal to supaA inf cB Ra (c), so inf cB supaA Ra (c) 
supaA Ra (c )  supaA inf cB Ra (c) and c is a minimax rule under the decision
model.




                                               30
Proof of Proposition 5. We first argue that any rule c that is admissible in
decision risk must use the decision d with probability zero. Specifically, consider any
a with Pra    ~ > 0, and a rule c with Pr {c (X ) = d|X = x} > 0 for some x. By our

full support assumption Pra c (X ) = d|  ~        > 0, and conditional on   ~ the
rule c yields strictly higher expected loss than the rule c which chooses d whenever
c chooses d and agrees with c otherwise. By assumption c has weakly lower loss for
all parameter values   , ~ and so dominates c. Hence, any rule admissible in the
decision model must choose d with probability zero.
    We next show that any rule that chooses d with probability zero is inadmissible
in the communication model. Consider any such rule c ~, and for each d~  D define
X d ~ = x  X | Pr c           ~|X = x > 0 . If xX (d) arg min
                     ~ (X ) = d                                    Ea [L (d, ) |X = x]
                                                                   dD
                      
is nonempty for all d  D \ {d} and a  A, then we can show that N (X , A) 
|D| - 1. Hence, since N (X , A)  |D| , there exist d  D \ {d}, a  A such that
xX (d ) arg mindD Ea [L (d, ) |X = x] = . For d  arg mindD Ea [L (d, ) |c
                                                                        ~ (X ) = d ],
             ~  X (d ) and d  D such that
there exists x

                   Ea [L (d , ) |X = x
                                     ~] < Ea [L (d , ) |X = x
                                                            ~] .

Consider the rule c that is equal to c
                                     ~ except that it reports d when X = x
                                                                         ~. By
Proposition 1, c dominates c
                           ~ in communication risk.
   Hence, we have shown that any rule admissible in the decision model must choose
d with probability zero, while any rule that chooses d with probability zero is inad-
missible in the communication model.




References
Abadie, Alberto. 2020. Statistical non-significance in empirical economics. American
      Economic Review: Insights 2(2): 193-208.
Abadie, Alberto and Maximilian Kasy. 2019. Choosing among regularized estimators
      in empirical economics: The risk of machine learning. Review of Economics
      and Statistics 101(5): 743-762.
Andrews, Isaiah, Matthew Gentzkow, and Jesse M. Shapiro. 2017. Measuring the

                                          31
      sensitivity of parameter estimates to estimation moments. Quarterly Journal
      of Economics 132(4): 1553-1592.
Andrews, Isaiah, Matthew Gentzkow, and Jesse M. Shapiro. 2020. Transparency in
      structural research. Journal of Business and Economic Statistics.
Armstrong, Timothy B. and Michal Koles´   ar. 2020. Sensitivity analysis using approx-
      imate moment condition models. arXiv preprint arXiv:1808.07387. Accessed
      on August 26 2020 at
      <https://arxiv.org/abs/1808.07387v5>.
Awasthi, S., V. K. Pande, and R. H. Fletcher. 2000. Effectiveness and cost-effectiveness
      of albendazole in improving nutritional status of pre-school children in urban
      slums. Indian Pediatrics 37(1): 19-29.
Athey, Susan and Stefan Wager. Forthcoming. Policy learning with observational
      data. Econometrica.
Banerjee, Abhijit, Sylvain Chassang, Sergio Montero, and Erik Snowberg. 2020. A
      theory of experimenters: robustness, randomization, and balance. American
      Economic Review 110(4): 1206-1230.
Baranchik, A.J. 1970. A family of minimax estimators of the mean of a multivariate
      normal distribution. Annals of Mathematical Statistics 41(2): 642-645.
Bergemann, Dirk and Stephen Morris. 2019. Information design: A unified perspec-
      tive. Journal of Economic Literature 57(1): 44-95.
Blackwell, David. 1951. The comparison of experiments. In J. Neyman (ed.), Pro-
      ceedings of the Second Berkeley Symposium on Mathematical Statistics and
      Probability : 93-102. Berkeley: University of California Press.
Blackwell, David. 1953. Equivalent comparisons of experiments. Annals of Mathe-
      matical Statistics 24(2): 265-272.
Brown, Lawrence D. 1975. Estimation with incompletely specified loss functions
      (the case of several location parameters). Journal of the American Statistical
      Association 70(350): 417-427.
Crawford, Vincent P. and Joel Sobel. 1982. Strategic information transmission.
      Econometrica 50(6): 1431-1451.
Croke, Kevin, Joan Hamory Hicks, Eric Hsu, Michael Kremer, and Edward Miguel.
      2016. Does mass deworming affect child nutrition? Meta-analysis, cost-
      effectiveness, and statistical power. World Bank Policy Research Working
      Paper No. 7921.


                                          32
DellaVigna, Stefano. 2018. Structural behavioral economics. In D. Bernheim, S.
        DellaVigna, and D. Laibson (eds.), Handbook of Behavioral Economics: Ap-
        plications and Foundations 1: 613-723. Elsevier.
Donnen, Philippe, Daniel Brasseur, Mich`    ele Dramaix, Francoise Vertongen, Mweze
        Zihindula, Mbasha Muhamiriza, and Philippe Hennart. 1998. Vitamin A sup-
        plementation but not deworming improves growth of malnourished preschool
        children in eastern Zaire. Journal of Nutrition 128(8): 1320-1327.
Dridi, Ramdan, Alain Guay, and Eric Renault. 2007. Indirect inference and calibra-
        tion of dynamic stochastic general equilibrium models. Journal of Economet-
        rics 136(2): 397-430.
Eaton, Morris L. 1967. Some optimum properties of ranking procedures. The Annals
        of Mathematical Statistics 38(1): 124-137.
Efron, Bradley and Carl Morris. 1973. Stein's estimation rule and its competitors--an
        empirical Bayes approach. Journal of the American Statistical Association
        68(341): 117-130.
Efron, Bradley. 1986. Why isn't everyone a Bayesian? American Statistician 40(1):
        1-5.
Farrell, Joseph and Robert Gibbons. 1989. Cheap talk with two audiences. American
        Economic Review 79(5): 1214-1223.
Frankel, Alex and Maximilian Kasy. 2018. Which findings should be published?
        MetaArXiv Preprints 10.31222/osf.io/mbvz3. Accessed on September 2 2020
        at <https://osf.io/preprints/metaarxiv/mbvz3/>.
Geweke, John. 1997. Posterior simulators in econometrics. In D. M. Kreps and
        K. F. Wallis (eds.), Advances in Economics and Econometrics: Theory and
        Applications, Seventh World Congress 3: 128-165. Cambridge: Cambridge
        University Press.
Geweke, John. 1999. Using simulation methods for Bayesian econometric models:
        Inference, development, and communication. Econometric Reviews 18(1): 1-
        73.
Gilboa, Itzhak and David Schmeidler. 1989. Maxmin expected utility with non-
        unique prior. Journal of Mathematical Economics 18(2): 141-153.
Hildreth, Clifford. 1963. Bayesian statisticians and remote clients. Econometrica
        31(3): 422-438.
James, W. and Charles Stein. 1961. Estimation with quadratic loss. Proceedings of


                                         33
      the Fourth Berkeley Symposium on Mathematical Statistics and Probability 1:
      361-379.
Jordan, Michael I., Jason D. Lee, and Yung Yang. 2018. Communication-efficient dis-
      tributed statistical inference. Journal of the American Statistical Association
      114(526): 668-681.
Kamenica, Emir and Matthew Gentzkow. 2011. Bayesian persuasion. American
      Economic Review 101(6): 2590-2615.
Kitagawa, Toru and Aleksey Tetenov. 2018. Who should be treated? Empirical
      welfare maximization methods for treatment choice. Econometrica 86(2): 591-
      616.
Kremer, Michael and Edward Miguel. 2004. Worms: identifying impacts on education
      and health in the presence of treatment externalities. Econometrica 72(1):
      159-217.
Kruger, Marita, Chad J. Badenhorst, and Erna P. G. Mansvelt. 1996. Effects of iron
      fortification in a school feeding scheme and anthelmintic therapy on the iron
      status and growth of six- to eight-year-old schoolchildren. Food and Nutrition
      Bulletin 17(1): 1-11.
Kwan, Yum K. 1999. Asymptotic Bayesian analysis based on a limited information
      estimator. Journal of Econometrics 88(1): 99-121.
Le Cam, L. 1996. Comparison of experiments--A short review. In T. S. Ferguson,
      L. S. Shapley, and J. B. MacQueen (eds.), Statistics, Probability and Game
      Theory: Papers in Honor of David Blackwell : 127-138. Hayward: Institute of
      Mathematical Statistics.
Lehmann, E. L. 1966. On a theorem of Bahadur and Goodman. The Annals of
      Mathematical Statistics 37(1): 1-6.
Lehmann, E.L. and George Casella. 1998. Theory of Point Estimation. 2nd ed. New
      York: Springer-Verlag.
Manski, Charles F. 2004. Statistical treatment rules for heterogeneous populations.
      Econometrica 72(4): 1221-1246.
Manski, Charles F. 2019. Statistical inference for statistical decisions. arXiv preprint
      arXiv:1909.06853. Accessed on August 25 2020 at
      <https://arxiv.org/abs/1909.06853>.
Nakamura, Emi and J´   on Steinsson. 2018. Identification in macroeconomics. Journal
      of Economic Perspectives 32(3): 59-86.


                                          34
Poirier, Dale J. 1988. Frequentist and subjectivist perspectives on the problems of
       model building in economics. Journal of Economic Perspectives 2(1): 121-144.
Pratt, John W. 1965. Bayesian interpretation of standard inference statements. Jour-
       nal of the Royal Statistical Society, Series B (Methodological) 27(2): 169-203.
Raiffa, Howard and Robert Schlaifer. 1961. Applied Statistical Decision Theory.
       Boston: Division of Research, Graduate School of Business Administration,
       Harvard University.
Robert, Christian. 2007. The Bayesian Choice: From Decision-Theoretic Founda-
       tions to Computational Implementation. 2nd ed. New York: Springer-Verlag.
Simon, Gregory. 2019. Unipolar major depression in adults: choosing initial treat-
       ment. In D. Solomon (ed.), UpToDate. Accessed on September 19, 2019 at
       <https://www.uptodate.com/contents/unipolar-major-depression-in-adults-
       choosing-initial-treatment>.
Sims, Christopher A. 1982. Scientific standards in econometric modeling. In M.
       Hazewinkel and A. H. G. Rinnooy Kan (eds.), Current Developments in the
       Interface: Economics, Econometrics, Mathematics : 317-337. Holland: D Rei-
       del Publishing Company.
Sims, Christopher A. 2007. Bayesian methods in applied econometrics, or, why econo-
       metrics should always and everywhere be Bayesian. Slides from the Hotelling
       Lecture, presented June 29, 2007 at Duke University.
Spiess, Jann. 2018. Optimal estimation when researcher and social preferences are
       misaligned. Harvard University Working Paper. Accessed on December 27,
       2019 at <https://scholar.harvard.edu/files/spiess/files/alignedestimation.pdf>.
Stoye, J¨org. 2009. Minimax regret treatment choice with finite samples. Journal of
       Econometrics 151(1): 70-81.
Stoye, J¨org. 2012. New perspectives on statistical decisions under ambiguity. Annual
       Review of Economics 4: 257-282.
Strasser, Helmut. 1985. Mathematical Theory of Statistics: Statistical Experiments
       and Asymptotic Decision Theory (De Gruyter Studies in Mathematics 7).
       Berlin: Walter de Gruyter.
Torgersen, E. 1991. Comparison of Experiments. Encyclopedia of Mathematics and
       its Applications. 1st ed. Cambridge: Cambridge University Press.
von Neumann, John and Oskar Morgenstern. 1944. Theory of Games and Economic
       Behavior. Princeton: Princeton University Press.


                                         35
Wald, Abraham. 1950. Statistical Decision Functions. New York, NY: John Wiley
      & Sons.
Zhu, Yuancheng, and John Lafferty. 2018. Distributed nonparametric regression
      under communication constraints. Proceedings of the 35th International Con-
      ference on Machine Learning 80.
Zhang, Yuchen, John C. Duchi, Michael I. Jordan, and Martin J. Wainwright. 2013.
      Information-theoretic lower bounds for distributed statistical estimation with
      communication constraints. Advances in Neural Information Processing Sys-
      tems 26.




                                        36
                               Online Appendix for


            A Model of Scientific Communication
              Isaiah Andrews, Harvard University and NBER
              Jesse M. Shapiro, Brown University and NBER

                                     October 2020



A     Extension of Optimal Treatment
      Assignment Example
This section extends the analysis of optimal treatment assignment in Section 4 of
the main text to show that when agents have sufficiently informative priors, it may
be communication-preferred to report  even in some cases without exact ties. To
                                                        ¯   ().
develop these results we consider a restricted audience A
                                      ¯ and some non-empty set E  X ,
Claim 8. Suppose that for an audience A

                                                              ¯, X  E .
              arg max Ea [t |X ] = arg max Ea [t ] for all a  A                      (1)
                  t                    t


Then the rule c             ¯ (X ) = c (X ) when X  E and c
              ¯ which takes c                               ¯ (X ) =  when X  E
has weakly lower communication risk for all a  A¯ than does the rule c .


Claim 9. If in addition to the conditions of Claim 8, (i) {X : arg maxt Xt = {1, ..., T }}
E = , (ii) there exists a  A  ¯ with arg maxt Ea [t |c (X )] = c (X ) for all X , and (iii)
                                      ¯ dominates c in communication risk.
arg maxt Ea [t ] is a singleton, then c


Proof of Claim 8. Note that all agents have the option to choose d  arg maxt Ea [t ]
conditional on observing c ¯ (X ) = , while choosing d  arg maxt Ea [t |c
                                                                        ¯ (X )] condi-
tional on observing c¯ (X ) = . By the definition of E this yields a weakly lower
expected loss for agent a than choosing some d  arg maxt Ea [t |c (X )].

                                           37
Proof of Claim 9. If arg maxt Ea [t ] is a singleton for a given agent a and (1) holds,
then conditional on X  E agent a strictly prefers not to randomize their decision.
At the same time, since arg maxt Ea [t |c (X )] = c (X ), under the rule c this agent's
decision is random conditional on the data when

                      X  E  X : arg max Xt = {1, ..., T } .
                                          t


As above, since the agent is free to choose d = c¯ (X ) conditional on c
                                                                       ¯ (X ) =  and
d = arg maxt Ea [t ] conditional on c¯ (X ) = , we see that c¯ yields a strictly lower
communication risk for this agent. Since we have shown in the proof of Claim 8 that
¯ yields weakly lower communication risk than c for all a  A
c                                                             ¯, c
                                                                 ¯ dominates c .


B     Extension of Combining Multiple
      Moments Example
Building on Section 5.3 in the main text, now suppose that X = G + ( ,  ) +  + ,
where   N (0,  2 · Ik ) . As in the main text, the analyst observes X , while the
variance  2 > 0 is commonly known, and the loss is L (d, ) = (d -  )2 . The unknown
parameters are  = (, , ,  ). All agents a  A have N (0, 2    ) priors on  , dogmatic
                                               2
priors on  with Pra { = a } = 1, and N 0,  · Idim( ) priors on  independent of
.
     If each agent a believes that Pra { = 0} = 1, the analysis in this extension
coincides with that in Section 5.3. Instead, suppose that each agent a believes that
  N (0, Va ) for Va a positive semidefinite matrix, and that  is independent of
(, ,  ). To express agent a's posterior mean for  conditional on X under this
assumption, define

                                0     0                                -1
             a =  2 · Ik +                                2
                                                   + Va , ,a = G - 1
                                                                 a G        .
                                0 2
                                   · Idim( )


Agent a's posterior mean for  (and hence optimal decision) is

                                     1
                    ca (X ) =   -2
                                           G -
                                             a
                                               1
                                                 X - (a , 0 )    .
                                ,a   + -
                                       
                                         2




                                              38
     Further suppose that the set of Va matrices over the audience is given by V =
{Va : a  A} =  · p.s.d.   Rk×k :   1 , for · the Frobenius norm and  > 0.
Hence, as   0, the situation converges to that described in the main text.
     We first show that X is a minimal (marginally) sufficient statistic for  in this
setting. Note that since matrix inversion is a homoemorphism between {a : a  A}
and {-   1               -1
        a : a  A}, {a : a  A} has a nonempty interior. This implies, however,
that for any X, X ~  Rk with X = X    ~ , there exists a  A such that ca (X ) - ca X
                                                                                   ~ =
G -  1     ~
   a (X -X )
   ,a +-
   -2    2    = 0, i.e., for whom these two realizations of the data imply different
        
optimal decisions.
     We next show that the communication risk of c           (^
                                                               , ^ ) as described in the
main text approaches that of the optimal rule based on X as   0. Note that
-  1
  a is continuous in Va , so as Va  0, a
                                               -1
                                                    -    1                       a
                                                        0 , where V0 = 0, and c (X ) 
Ea [ |c (^ , ^ )] for each realization of X . The dominated convergence theorem thus
                                        
implies that as Va  0, Ra    (X )  Ra     (c ), as we aimed to show.




C     Proofs for Auxiliary Results
Proof of Lemma 1. Case (i) of Assumption 2 trivially implies case (i) of Assump-
tion 3. For case (ii), closed subsets of Euclidean spaces are locally compact, and lower
semi-continuity of L implies that {d : L (d, )  l} is closed for all l. Assumption 2
(ii) implies that {d : L (d, )  l} is bounded.

Proof of Lemma 2. Theorem 42.3 of Strasser (1985) establishes that G is convex,
and compact in the weak topology (i.e. the topology such that gk  g if and only
if gk (h, µ)  g (h, µ) for all (h, µ)  H × M). Let L (d) = L (d, ) . Since L (d, )
is lower semicontinuous in d for all , Lemma 47.2 of Strasser (1985) establishes that
g (L , µ) = sup L g ( , µ) for L the set of bounded, non-negative, and continuous
functions : D  R with  L . Note that g ( , µ) is continuous with respect to the
product of the weak topology on G and the L1 topology on M.
                   ~ to be the set of functions ~ with ~  L for all  and sup,d ~ (d)
      Next, define L
finite, and let W g, ~, a =   
                                 g ~ , F da () . W g, ~, a is lower semi-continuous
with respect to the product of the weak topology on G and the L1 topology on
A. Since G is compact in the weak topology, the theorem of the maximum implies


                                          39
that inf gG W g, ~, a is likewise lower semicontinuous on A (see Lemma 17.30 in
Aliprantis and Border, 2006).
     The supremum of a family of lower semicontinuous functions remains lower semi-
continuous, so both sup ~L        ~
                          ~ W g, , a and sup ~L
                                                               ~
                                                 ~ inf g G W g, , a are lower semi-

continuous in a. For the former, note that sup ~L     ~
                                                ~ W g, , a        = W (g, L, a) (again
by Lemma 47.2 of Strasser, 1985). For the latter, note that L~ is convex, while G is
convex and compact in the weak topology. W g, ~, a is lower semicontinuous in g
and continuous in ~ (for the uniform topology on L~). Hence, Sion's (1958) minimax
theorem (Corollary 3.3 in Sion 1958) implies that

             sup inf W g, ~, a = inf sup W g, ~, a = inf W (g, L, a) .
               ~ g G
              ~L                    g G ~ ~
                                         L
                                                          g G


Hence, inf gG W (g, L, a) is lower semicontinuous in a.
     To complete the proof, we need to relate these results back to attainable risk
functions. For decision risk, recall that {gc : c  B}  G and note that W (gc , L, a) =
Ra (c) , so we have proved lower semicontinuity of Ra in a.
     For communication risk, consider case (i) in Assumption 3. Theorem 43.2 of
Strasser (1985) implies that for each g  G , there exists some c  B with gc (h, µ) =
g (h, µ) for all µ  0 and all lower semicontinuous functions h that are bounded
from below. Hence, inf gG W (g, L, a) = inf cC W (gc , L, a). Next consider case (ii).
Theorem 43.5 of Strasser (1985) implies that for each g  G , there exists c  B
such that gc (h, µ)  g (h, µ) for all h with compact sublevel sets {d : h (d)  l}.
Hence, again inf cC W (gc , L, a) = inf gG W (g, L, a). However, inf cC W (gc , L, a) is
equal to the communication risk based on observing the full data, so the conclusion
is immediate by considering the special case where the data X are reduced to just
the analyst's report.

Proof of Lemma 3. That (i) implies (ii) is immediate. To show that (ii) implies
(i), note that Theorem 45.6 of Strasser (1985) (taking M1 = {f } and
M2 = {W (g, L, a) : g  G}) implies that for C (A) the set of continuous functions on
A, there exists some g~ in the closure of W = gG {g  ¯  C (A) : g
                                                                ¯  W (g, L, ·)} with
~  f . Theorem 42.3 of Strasser (1985) establishes that G is convex, and compact
g
in the weak topology. Hence, W is closed by Remark 45.4 of Strasser (1985), and
~  W . Thus, (ii) implies (i), and we have established equivalence.
g

                                          40
Proof of Corollary 2. That (i) implies (ii) is again immediate. To obtain (i) from
             ~ as in the proof of Lemma 2. Condition (ii) implies that f (a) d (a) 
(ii), define L
inf     W g, ~, a d (a) : g  G for all  and all ~  L   ~. Hence, by Lemma 3, for each
~ L  ~ the set g  G : W g, ~, a  f (a) for all a  A is nonempty. Note that this
set is decreasing as ~ increases pointwise, so since L is the pointwise upper bound of L
                                                                                       ~,
Cantor's intersection theorem implies that {g  G : W (g, L, a)  f (a) for all a  A}
is nonempty, which in turn implies (i).


References Not Appearing in Paper
Aliprantis, Charalambos D. and Kim C. Border. 2006. Infinite Dimensional Analysis:
       A Hitchhiker's Guide. Berlin: Springer-Verlag.
Sion, Maurice. 1958. On general minimax theorems. Pacific Journal of Mathematics
       8(1): 171-176.




                                           41
