                                 NBER WORKING PAPER SERIES




                                   BUILDING THE STOCK OF
                                  COLLEGE-EDUCATED LABOR

                                             Susan Dynarski

                                         Working Paper 11604
                                 http://www.nber.org/papers/w11604


                       NATIONAL BUREAU OF ECONOMIC RESEARCH
                                1050 Massachusetts Avenue
                                  Cambridge, MA 02138
                                     September 2005




Comments welcome: susan_dynarski @ harvard.edu. I am grateful to the Russell Sage Foundation and the
University of California at Los Angeles for funding. Betsy Kent, J.D. LaRock, Isabel Millan-Valdes and Juan
Saavedra provided excellent research assistance. Joe Doyle, Amy Finkelstein, Brian Jacob, Jeff Liebman,
Erzo Luttmer, Ben Olken, Cecilia Rouse, Sarah Turner and seminar participants at the Centre for the
Economics of Education, Dartmouth, Harvard, MIT, the National Bureau of Economic Research, the
University of California at Davis and the University of Michigan were generous with their helpful comments.
Any errors are my own. The views expressed herein are those of the author(s) and do not necessarily reflect
the views of the National Bureau of Economic Research.

©2005 by Susan Dynarski. All rights reserved. Short sections of text, not to exceed two paragraphs, may
be quoted without explicit permission provided that full credit, including © notice, is given to the source.
Building the Stock of College-Educated Labor
Susan Dynarski
NBER Working Paper No. 11604
September 2005
JEL No. I21, I22, I28

                                           ABSTRACT


Half of college students drop out before completing a degree. These low rates of college completion
among young people should be viewed in the context of slow future growth in the educated labor
force, as the well-educated baby boomers retire and new workers are drawn from populations with
historically low education levels. This paper establishes a causal link between college costs and the
share of workers with a college education. I exploit the introduction of two large tuition subsidy
programs, finding that they increase the share of the population that completes a college degree by
three percentage points. The effects are strongest among women, with white women increasing
degree receipt by 3.2 percentage points and the share of nonwhite women attempting or completing
any years of college increasing by six and seven percentage points, respectively. A cost-benefit
analysis indicates that tuition reduction can be a socially efficient method for increasing college
completion. However, even with the offer of free tuition, a large share of students continue to drop
out, suggesting that the direct costs of school are not the only impediment to college completion.


Susan Dynarski
Harvard University
Kennedy School of Government
79 JFK Street
Cambridge , MA 02138
and NBER
susan_dynarski@harvard.edu
I. Introduction

          College attendance has risen substantially over the past forty years. In 1968, 36 percent of 23-

year-olds had gone to college. By 2000, that figure had grown to 55 percent. Over the same period, the

share of young people with a college degree has risen relatively slowly. In 1968, the share of 23-year-

olds with a bachelor’s degree was 14 percent, while in 2000 it was 19 percent.1 As these figures make

clear, many young people enter college but drop out before completing a degree. In the 2000 Census, just

57 percent of those age 22 to 34 with any college experience had completed an associate’s or bachelor’s

degree. Thirteen percent of those who had attempted college had not completed even a year.2

          These low rates of college completion among young people should be viewed in the context of

slowed growth in the educated labor force, as the well-educated baby boomers retire and new workers are

drawn from populations with historically low education levels (Ellwood, 2001). This sluggish growth in

the stock of educated labor in the United States can be contrasted with much faster growth rates in other

nations. In 1991, only two countries (Canada and Finland) exceeded the United States in their shares of

young people with a college degree, and only by a couple of percentage points. By 2002, the picture had

changed dramatically. Thirteen countries have equaled or exceeded the benchmark achieved by the

United States in 1991 and four nations are now ahead of us, with Japan and Korea outstripping us by

more than ten percentage points (Organization for Economic Cooperation and Development, 2004).




1
 These figures, tabulated from the October Current Population Surveys of 1968-2000, are from Turner
(2003). The figures for 23-year-olds imply that the college dropout rate has risen sharply. Turner points
out that among 30-year-olds the dropout rate is, by contrast, quite flat. She concludes that while the
dropout rate is not rising the time it takes to complete college is lengthening. A consequence is that each
college entrant now spends fewer years working as a college graduate. That is, the lifetime supply of
college-educated labor provided by each college entrant is dropping over time.
2
    Author’s tabulations from the Public Use Microdata One-Percent Sample of the 2000 Census.


                                                       1
        Any major growth in the college-educated workforce will require an increase in college

completion, since very large gains in college entry are now behind us.3 There are several channels through

which policy might affect the completion margin. Sociologists have focused, in particular, on weak

connections between college dropouts, their peers and their teachers (Tinto, 1994). Another lever is

improved academic preparation in high school. This paper focuses on a third channel: college costs. A

small literature has shown that decreasing college costs substantially increases the college entry rate of

young people. By contrast, we know little about how costs affect college completion.4

        Theory does not unambiguously predict the impact of schooling costs on persistence through

college, even once we know the impact of college costs on college entry. In Manski’s framework (1989),

students learn about their academic skills when they enter college and, should they find them lacking,

drop out. Marginal decreases to college costs may induce students with low expectations of success to

undertake this experiment. An alternative (but not incompatible) story is that the marginal college student

may be credit-constrained. Relaxing credit constraints may then induce into college individuals with

better academic skills than the typical college student.

        Determining how schooling costs affect human capital investment is not straightforward, since

the costs faced by a potential student may well be correlated with unobserved determinants of her

educational attainment. This paper exploits the introduction of large scholarship programs in two

Southern states to identify the effect of college costs on college completion. During the 1990s, a dozen

states introduced large-scale merit aid programs. Arkansas started the trend in 1991, with Georgia


3
  Seventy percent of young high school graduates have some college experience in Census 2000. Among
high income families the rate is ninety percent (Ellwood and Kane, 2000). This is not meant to imply that
there is no room for improvement at margins other than college completion. A substantial share of
nonwhites and Hispanics have not attempted college, but this is largely driven by their low rate of high
school graduation.
4
 For analysis of the causal impact of college costs on attendance see Kane (1994), Dynarski (2000, 2003,
2004) and Seftor and Turner (2002). Dynarski (2002) reviews this literature. Bettinger (2004) and
Dynarski (2003) present suggestive evidence that financial aid has a causal impact on completed
schooling. Angrist (1993) and Bound and Turner (2002) show that veterans' educational benefits increase
completed schooling.


                                                      2
following suit in 1993. These programs waive tuition and fees for students who achieve a minimum GPA

in high school (typically 3.0), and maintain a minimum GPA in college (typically 2.5 to 3.0). These are

not scholarships for a tiny academic elite: nearly 60 percent of those graduating high school in Georgia

qualify for its merit scholarship.

        In previous work, I have shown that these programs have had a positive impact on college

attendance (Dynarski, 2000 and 2004). In those papers, data limitations prevented the estimation of the

effect of merit aid on college completion. These data limitations have been relaxed by the release of the

2000 decennial census micro-data. As of 2000, several cohorts who were exposed to the Arkansas and

Georgia programs were in their early twenties, the traditional age of college graduation. I use a treatment-

comparison research design to evaluate the effect of these programs on college completion rates. Cross-

cohort differences in college completion within the states provide the identifying variation in the analysis.

The identifying assumption is that any cross-cohort change in college completion in the treatment states,

relative to the control states, is due to the scholarship programs.

        To preview the results, I find a large and significant impact of college costs on degree receipt.

The scholarship programs appear to increase the share of young people with a college degree by three

percentage points. This is a substantial effect, especially given that in the treatment states just 27 percent

of the pre-program cohorts have a college degree. The effects are strongest among women, with white,

non-Hispanic women showing increases of 3.2 percentage points. The share of nonwhite and Hispanic

women attempting or completing any years of college increased by six and seven percentage points,

respectively.

        The identifying assumption, while ultimately untestable, is subjected to a series of plausibility

checks. A key threat to the internal validity of the estimates is any pre-program trend in college

completion in the treatment states relative to the comparison states (Meyer, 1995). A plausible scenario is

that Arkansas and Georgia began to build their human capital years before introducing the scholarship

programs, through increased investment in children’s education or by attracting skilled adults from other

states. In this scenario, these pre-existing trends could even cause the scholarship programs, with well-

                                                       3
educated parents in the treatment states demanding scholarships so as to reduce tuition costs for their

college-bound children. Both pre-existing trends and reverse causality would produce a spurious, positive

correlation between the scholarship programs and educational attainment.

        I address this critical set of concerns with several methods. First, throughout the analysis I assign

program eligibility based on state of birth rather than state of residence. Recent migration into the

treatment states by well-educated young workers and their families cannot, therefore, explain the results.5

Second, a visual inspection of the data shows a distinct break from trend in the schooling of the affected

cohorts. Third, I include in the regressions parametric and non-parametric controls for trends in education

at the level of the state of birth and state of residence.6 Fourth, I show that the program effects occur only

at educational margins plausibly affected by eligibility for the merit scholarships. Together, this set of

results provides strong support for the identifying assumption of the paper.

        My reduced-form estimation strategy cannot separately identify the effect of aid on entry and

persistence conditional on entry. I can, however, place fairly narrow bounds on the persistence effect. The

scholarship programs appear to increase by five to eleven percent the probability of persistence to degree

of those who would have entered college even in the absence of the programs.

        A cost-benefit analysis indicates that tuition reduction can be an effective and socially efficient

method for increasing college completion. However, this approach alone will not keep the bulk of

dropouts from leaving college. The programs studied in this paper drove to zero the direct costs of

schooling for many entering college students, yet even with this offer of free tuition a large share of

students continued to drop out of college. This suggests that the direct costs of college are not the only (or




5
 In fact, assigning eligibility based on residence yields small and insignificant results. This point is
discussed later in the paper.
6
 By bringing in data from the 1990 census, I also can control for the interaction of age effects with state
of birth, which in the cross-sectional analysis using the 2000 census is the source of identification of the
program effect. The point estimates are robust to this very strong test.


                                                       4
even the central) impediment to degree completion, and policymakers and researchers will need to

explore more avenues in order to increase the stock of college educated labor.7

        One promising avenue is improved preparation in primary and secondary school. At least two

studies provide firm evidence that early interventions can have an impact on postsecondary attainment.

Results in Krueger and Whitmore (2001) indicate that students randomly assigned to small classes in

early elementary school are more likely than students in a control group to take college entry exams (a

strong predictor of college entry). The Abcederian study, a randomized-controlled trial, has shown a

positive impact of intensive, early childhood interventions on post-secondary schooling (FPG Child

Development Institute, 2005). Another possible policy lever is improved institutional support for college

students, in the form of more counseling, better coordination of course schedules and easier credit

transfers between two-year and four-year colleges. While these interventions have been fielded, analyzed

and discussed extensively (e.g., Tinto, 1994), there is no credible evidence of their causal impact on

college completion.

        The paper is organized as follows. Section II provides a literature review and background on the

state subsidy programs that will be the subject of the analysis. Section III lays out the identification

strategy and describes the data. Section IV provides results and robustness checks. Section V explores

heterogeneity in the program’s impact. Section VI discusses the results and Section VII concludes.



                                               II. Background

        This section discusses the relevant economic literature and provides background on the programs

that will be the subject of the empirical analysis.


7
  This conclusion accords with Stinebrickner and Stinebrickner (2003), who show that the dropout rate
approaches fifty percent at Berea College, even though that school pays all costs (tuition, fees, books,
room and board) for all its students. Note that their evidence and mine do not rule out liquidity constraints
as an explanation for low college completion rates, since the direct cost of college is a fraction of its total
cost. Further, a conclusion that current tuition prices are not the main impediment to college completion
does not imply that substantially raising the price of college would not increase the dropout rate, since
there are likely non-linearities in the response to price.


                                                       5
College Costs and College Completion

          Financial aid plausibly affects several margins of behavior: college attendance, college entry, and

degree completion.8 Dozens of studies have examined the relationship between college costs and these

outcomes.9 Almost all are plagued by identification problems, with the analyses failing to control for

correlation between college costs and unobserved determinants of schooling outcomes.

          A handful of well-identified studies, however, has established a strong casual link between

schooling costs and college attendance. Dynarski (2003) finds that the elimination of the Social Security

student benefit program, which paid the college costs of the children of deceased parents, substantially

reduced the college attendance of the affected population. Studies which examine the Pell Grant, currently

the largest source of federal grant aid, produce somewhat mixed results: Hansen (1983) and Kane (1995)

found no effect of the introduction of the Pell on the college attendance rate of low-income recent high

school graduates, but recent work by Seftor and Turner (2002) has found a positive effect on the

attendance of slightly older youth. Most relevant to the current paper, Dynarski (2000, 2004) and Kane

(2003) find that large-scale state merit scholarship programs substantially increase the share of young

people attending college.

          The evidence on the effect of aid on college persistence and completion is comparatively thin.

Angrist (1993) and Bound and Turner (2002) show that veterans’ educational benefits increase completed

schooling. Dynarski (2003) finds that the elimination of the Social Security student benefit program

reduced the schooling of the affected population of two-thirds of a year, but this result is imprecisely

estimated. Bettinger (2004) uses regression-discontinuity methodology to examine the effect of the Pell

Grant on persistence rate of college entrants and finds a positive effect, but notes that his results are quite


8
 College attendance is a state variable, indicating that at a given point in time a person is enrolled in
college. Entry and completion are stock variables, indicating that a person has ever attended college or
has completed college, respectively.
9
    Leslie and Brinkman (1988) review these studies.


                                                       6
sensitive to specification. The contribution of the present paper is to provide estimates of the effect of

college costs on persistence and degree completion that are precisely estimated and robust to specification

and functional form.



State Merit Aid Programs

        Since the early Nineties, more than a dozen states have established broad-based merit aid

scholarships. While states have long awarded college scholarships based on academic performance in

high school, these programs have traditionally subsidized only the highest-performing students. For

example, New York gives a scholarship to each high school’s top scorer on the state Regents exam. The

academically-elite students who receive these scholarships are unlikely to alter their decisions to complete

a degree based on whether they receive the scholarship. By contrast, the new merit scholarships are open

to students with solid but not exemplary academic records. A dozen state merit aid programs have

eligibility criteria that are sufficiently lenient that at least thirty percent of high school seniors have grades

and test scores that qualify them for an award. Many of these students may be on the margin of

completing a college degree, and so these programs are a fruitful source of variation for examining this

particular outcome.

        Of the thirteen states with broad-based merit aid programs, nine are in the South (see Appendix

Table). In 1993, just two states, Arkansas and Georgia, had programs in place. By 2003, thirteen states

had introduced large merit aid programs. Most of this growth has occurred quite recently, with six

programs starting up since 1999. Many of the merit programs are too new to detect effects on college

completion in currently available data. The oldest programs, established in Arkansas in 1991 and in

Georgia in 1993, provide the identifying variation in the paper.10




10
  Despite the differences between the two programs that I detail below, I find that their effects on college
completion are virtually identical.


                                                        7
          The Arkansas program was proposed in January 1991 by then-Governor Bill Clinton. The

program was quickly approved by the legislature and was in place in time for the high school class of

1991 to be offered scholarships for their fall enrollment. Eligibility for the Arkansas scholarship requires

a 19 or above on the ACT, a score exceeded by 60 percent of test-takers nationwide and below the

Arkansas state average of 20.4. Eligibility also requires a cumulative high school GPA of 2.5 in a set of

core classes, a standard met by up to 60 percent of high school students nationwide.11 Continued receipt

of the scholarship requires a GPA of 2.5 in college and progress at the rate of at least 24 semester hours a

year.12 The scholarship is available for a maximum of four years of undergraduate study.

          At its inception the Arkansas program paid tuition and required fees up to $1,000 at public and

private colleges in Arkansas; this was raised to $1,500 in 1994 and $2,500 in 1997. Starting in 1994,

students received a bonus of $500 if their previous year’s college grades were 3.0 or above. In light of

prevailing tuition prices in Arkansas, these are generous subsidies. In 1994, tuition and required fees were

$2,200 at University of Arkansas at Fayetteville (the state’s flagship institution) and $1,110 at Arkansas

State University at Beebe.

          When the program was introduced, Arkansas limited eligibility for the scholarships to those with

family incomes below $35,000 (for a family with two children); this was raised to $40,000 in 1993 and to

$75,000 in 1999. These caps should be viewed in the context of Arkansas, where incomes are among the

lowest in the nation. Median household income was $27,000 and $32,000 in 1989 and 1999,

respectively.13



11
  Author’s calculations from the 1997 National Longitudinal Survey of Youth. This is the share of
students with a senior year GPA of at least 2.5, and so is likely an upper bound on the share of students
who achieve this GPA for their entire high school career.
12
     Typically, a bachelor’s degree requires 120 semester hours.
13
  After the last increase in the income cap, enrollment in the program soared. A state revenue shortfall
then led program administrators to suspend the program, which was funded by general revenues. This
period falls outside the main analysis of the paper, which focuses on age cohorts entering college in 1996
and earlier.


                                                      8
        Georgia’s HOPE (Helping Outstanding Pupils Educationally) program was proposed in early

1993 by then-Governor Zell Miller. This program, too, moved quickly from proposal to legislation, with

the high school class of 1993 eligible for the first scholarships. The program is funded by a lottery, also

established in 1993. The scholarship requires a 3.0 GPA in high school.14 Renewal of the scholarship

requires a 3.0 GPA in college, with GPAs calculated when students accumulate 30, 60, 90 and 120 credit

hours. Unlike the Arkansas program, there is no time limit on scholarship receipt, but funded credit hours

are limited to 150.15 While Arkansas’ scholarship is dollar-denominated, the Georgia scholarship covers

full tuition and fees at any Georgia public college or university. For Georgia private colleges and

universities, the scholarship pays a lump sum that was gradually raised from $1,000 in 1993 to $3,000 in

1995.

        Participation in HOPE during its first year was limited to those with family incomes below

$66,000. This income cap was raised to $100,000 in 1994 and eliminated in 1995. Until 2001, HOPE

scholarships were offset by other sources of aid. Low-income students faced higher transaction costs and

lower average HOPE scholarships than did upper-income students, since they were required to apply for

federal financial aid and their state scholarships were offset by any grants they received.16




14
  As of 2000, only high school courses in a core curriculum (math, science, English, etc.) can be counted
toward the qualifying GPA.
15
  Cornwell, Lee and Mustard (2004) argue that HOPE has led students to slow their progress through
college, opting for lighter courseloads in order to more easily meet the GPA requirement. Students bear
most of the cost of such a strategy, since it substantially increases the opportunity cost of a college degree.
If HOPE does slow progress through college, I will underestimate its effect on college completion, since
in my data the eligible cohorts are relatively young. In principle, I can estimate the effect of HOPE on
time-to-degree by calculating age-specific program effects. In practice, these age-specific effects cannot
be disentangled from year-specific effects induced by the aging of the program and multiple changes in
the program rules.
16
  Georgia education officials, concerned that students would forgo applying for federal aid once the
HOPE Scholarship was available, mandated that applicants from families with incomes lower than
$50,000 complete the four-page Free Application for Federal Student Aid (FAFSA), which requests
detailed income, expense, asset and tax information.


                                                      9
        Note that the structure of the public university scholarship in Georgia provides incentives for

schools to raise their prices in order to capture more scholarship funds. Countervailing pressure against

price increases is provided by the legislature and students ineligible for the scholarships. The paper’s

estimates capture the reduced-form effect of the merit scholarships, which includes any drop in

educational attainment among those ineligible for the scholarship but exposed to the price increases.

Given the generosity of the scholarships and the small increases in price documented in the literature, any

such offsetting effect is likely quite small.17

                                         III. Empirical Methodology

        The empirical strategy is straightforward. I use a treatment-comparison research design. States

that never introduce merit programs, or introduce them after the period under analysis, constitute the

comparison group. I test the sensitivity of the results to the choice of comparison states. Relative changes

in educational attainment in the states that introduce merit aid identify the effect of merit aid.

        The key variable of interest is a dummy variable, merit, that indicates whether an individual

would have been exposed to a merit aid program upon high school graduation. Treatment status is

determined by year and state of high school graduation. Those who graduated from high school in 1991

and after in the state of Arkansas were exposed to that state’s scholarship program. Those who graduated

before 1991 were not eligible; the program was not grandfathered. Similarly, those who graduated in

1993 and after in Georgia were exposed to that state’s scholarship program.

        The census provides neither state nor year of high school graduation. I use age at the time of the

census survey to assign the year of high school graduation, which I assume to occur at age 18. For

example, an individual who was 27 in April 2000 (when census data are collected) was 18 in April 1991,

and so is assigned to be a high school senior in 1991. This is an imperfect proxy, since in the spring of



17
  Dynarski (2000) shows that public tuition and fees rose slightly faster in Georgia than in the rest of the
US after HOPE once introduced, after lagging US tuition growth in the pre-program period. In a more
detailed analysis, Long (2004) also concludes that the HOPE program has placed upward pressure on
prices.


                                                      10
their senior year many high school students are 19.18 I also test using Current Population Survey data on

the age distribution of high school seniors to probabilistically assign the year of high school graduation

and, thereby, treatment status. This increases the point estimates by about ten percent.

        I use state of birth to assign state of high school attendance. For this purpose, state of birth is

preferred over state of residence because the latter may be endogenously determined by the treatment:

individuals may migrate to college and then settle in the state in which they go to school. However, a

drawback of using state of birth as a proxy for state of high school attendance is that about twenty percent

of high-school-age youth live outside their state of birth. This classification error will tend to bias the

estimates downward. In one specification, I use high-school-age respondents in the Census to estimate

transition probabilities between state of birth and state of residence. I apply this matrix to the analytical

sample in order to probabilistically assign the state of high school graduation and, thereby, treatment

status. This increases the point estimates by about twenty-five percent.



Sample Definition

        My main analytical sample consists of 22- to 34-year-olds in the 2000 census. The lower cutoff is

chosen because it is a traditional age of college-leaving, and so is a reasonable age at which to begin

measuring degree completion. The upper cutoff is more arbitrary, and is chosen to provide roughly equal

numbers of age cohorts graduating high school in the years preceding and following the introduction of

the programs. These age cohorts correspond to the high school classes of 1984 through 1996, assuming

students graduate at age 18.

        I limit the sample to those who currently live in, and were born in, the United States.19

Observations for which age, state of birth or completed education is imputed are dropped from the




18
  Information on quarter of birth would allow a more accurate assignment, but this variable is unavailable
in the 2000 Census.


                                                      11
analysis. Analyses that include the imputed values produce substantively similar results. I do not use the

census sample weights in the analysis. Use of the weights does not substantively alter the results.



Variable Definitions

          As of 1990, the Census does not collect data on years of schooling at the college level, instead

capturing information about degree completion. The relevant survey question is reproduced in the

Appendix Table 1. I will focus on whether an individual has earned any college degree, including a two-

year associate’s degree.20 Additional results will show the impact of the merit aid programs at every level

of education by estimating treatment effects for all sixteen categories of the education variable.

          Measures of race and ethnicity are included in some specifications. Mutually-exclusive indicator

variables define individuals as Hispanics of any race, Black non-Hispanics, white non-Hispanics, and

other non-Hispanics. Table 2 contains the means of the key variables, listed separately by the individual’s

state of birth - Arkansas, Georgia, the rest of the South, and the rest of the United States.21



Specification

          In the most parsimonious specification, I regress educational attainment against the treatment

dummy and a set of state of birth and age effects. I estimate the following equation using Ordinary Least

Squares:

          (1) yiab = β meritab + δ a + δ b + ε iab



19
  Mississippi’s program, introduced in 1996, is old enough to affect AA completion in 2000 but too
young to affect BA completion. To simplify the analysis I have removed Mississippi from the sample; its
inclusion does not alter the results substantially.
20
     This corresponds to values 12 and above of the census education variable.
21
  The Southern census region consists of the South Atlantic states (Delaware, Florida, Georgia,
Maryland, North Carolina, South Carolina, Virginia and West Virginia, plus the District of Columbia);
the East South Central states (Alabama, Kentucky, Mississippi and Tennessee); and the West South
Central states (Arkansas, Louisiana, Oklahoma and Texas).


                                                      12
Here, yiab is a measure of the completed education of person i of age a born in state b. δ b and δ a denote

state of birth and age fixed effects, respectively, and ε iab is an idiosyncratic error term. The identifying

assumption of this equation is that any relative increase across age cohorts in the schooling of those born

in merit aid states is attributable to the merit program itself. If the identifying assumption is correct, β is

the increase in education associated with exposure to a merit aid program.

        I will generally perform this regression in cell means measured at the level of state of birth and

age cohort:

        (2) yab = β meritab + δ a + δ b + ε ab

This approach produces estimates mathematically identical to those obtained in Equation (1), yet requires

little computational power. Further, as discussed later in the paper, performing the regression in grouped

means allows for a very simple calculation of consistent standard errors (See Bertrand, Duflo and

Mullainathan, 2004).



                                    IV. Results and Robustness Checks

        I begin with a visual inspection of the cell means that provide the identifying variation in the

paper. Figure 1A separately plots the probability of degree completion in Arkansas and the rest of the

United States, excluding Georgia. Since this is a single cross-section, the graph reflects both time and age

variation in education, with age effects dominating among the youngest cohorts. Education rises steadily

among those in their twenties. In the US, the share holding a college degree rises from 17.5 percent

among 22-year-olds to 37.7 percent among 29-year-olds.22 College completion is considerably lower in

Arkansas than in the US; among pre-program cohorts, the gap averages thirteen percentage points.

        The shape of the US age-education profile provides the counterfactual for Arkansas. Among the

pre-program age cohorts, Arkansas roughly tracks the US. The series is noisy but essentially flat for these


22
  Using multiple cross-sections, Turner (2004) documents that degree completion continues through the
twenties and into the early thirties.


                                                      13
cohorts, though the Arkansas series is (unsurprisingly) noisier than that of the US. With the first post-

program cohort there is a marked convergence in the two series, however. The gap between Arkansas and

the US narrows by more than seven percentage points between the two cohorts that straddle the

introduction of the scholarship. After this sharp convergence, Arkansas cohorts again roughly track their

US counterparts. During the post-program era, the gap between the US and Arkansas averages nine

percentage points. We see a similar dynamic at work in Georgia, shown in Figure 1B. The gap between

Georgia and the US is roughly nine percentage points among the pre-program cohorts. Starting with the

first post-program cohort, we see a convergence between the two series, with the gap closing to about five

percentage points.

        In both of these figures, the sharp divergence from trend in the first program year supports the

identifying assumption of the paper. In the regression analysis, I will explicitly test for this break from

trend by controlling for linear and quadratic trends in age at the state level.



Baseline Results and Statistical Inference

Table 3 presents the results of estimating Equation (1). The coefficient of 0.0298 in Column (1) suggests

that the merit programs increased the share of the population earning a college degree by 2.98 percentage

points. To give a sense of the magnitude of this estimate, note that the pre-program level of degree

completion was about 24 percent in Georgia and Arkansas.

        The heteroskedasticity-adjusted standard error is 0.82 percentage points. As discussed by

Bertrand, Duflo and Mullainathan (2004), standard errors in this context can be misleading for two

reasons: the treatment varies not across individuals but across age cohorts within states and there is likely

serial correlation in the error term across cohorts within states. The most straightforward solution is to

collapse the data into state-age means and re-run the estimating equation, adjusting the standard errors for

correlation within state of birth. Monte Carlo simulations in Bertrand, Duflo and Mullainathan (2004)

show that this approach produces hypothesis tests of the correct power. These results of this method are in

Column (2) of Table 3. The regression is weighted by the size of the population within each cell; the

                                                      14
slope coefficient is therefore identical to that obtained from the regression run in the micro data.23 The

standard error drops by more than half, to 0.40 percentage points.

        An alternative approach to inference in this context, again suggested by Bertrand, Duflo and

Mullainathan (2004), is to eliminate the time series variation in the data, which also eliminates the serial

correlation. If Arkansas and Georgia had introduced their programs in the same year, this would involve

grouping the means by state of birth and pre/post-program, then running the regression in these means.

The equivalent in the current context is to regress the outcome against state and year effects in the micro

data, form residuals, and for the treatment states only do a before/after comparison of the means of these

residuals, again weighted by the cell size. With this approach, the point estimate is 2.82 percentage points

and the standard error drops yet further, to 0.30 percentage points.

        These estimates of the standard errors are summarized in Table 4, along with several additional

approaches for estimating the standard errors in the microdata. With even the largest estimates of the

standard error I do not fail to reject the null. Looking across the table, we see that accounting for serial

correlation within states has a substantial impact on precision. The 95-percent confidence interval for the

program effect is four percentage points wide when unadjusted for serial correlation within states and one

to two percentage points wide when adjusted. Adjusting for serial correlation decreases standard errors in

this context because the error terms are weakly and negatively auto-correlated within each state of birth.

By contrast, the CPS wage data used in Bertrand et al. exhibit large and positive autocorrelation; thus,

adjusting for serial correlation in their context increases standard errors.24 In the remainder of the analysis,

I will estimate regressions in grouped means, with the standard errors then adjusted for autocorrelation

within states.



23
  If the regression is unweighted and, therefore, each state-age cohort given equal weight, the point
estimate is 3.2 percentage points.
24
  I regress the outcome variable on state-of-birth and age fixed effects and form residuals, thereby
isolating the variation that identifies the program effect. The first-, second- and third-order auto-
correlation coefficients for these residuals are 0.05, -0.02 and -0.03, respectively. The analogous
autocorrelations in Bertrand et al. are 0.51, 0.41 and 0.33.

                                                      15
State-Specific Labor Market Shocks

In the classic human capital model (Becker, 1994), educational attainment is a function not only of direct

costs but also of opportunity costs and returns to schooling. If the drop in direct costs that is the subject of

this analysis is correlated with shifts these other determinants of human capital, then the estimates

obtained so far may be biased. A tight labor market will increase the opportunity costs of college, which

in theory will tend to reduce the share of young people completing a degree.25 The same booming labor

market may also boost tax revenues and thereby render a state more willing to fund a merit aid program.

This would induce a negative correlation between the merit programs and college completion. Economic

conditions may also induce a positive correlation between merit programs and college completion: high

returns to college might induce parents to pressure politicians to fund scholarships, and will also tend to

keep people in school.

        To test whether labor market conditions are biasing the estimates, I add a set of control variables

to the basic specification. First, I control for the state unemployment rate, measured in the respondent’s

state of birth in the year in which he was 18 years old. This variable is intended to capture both

opportunity costs for the young person and the financial situation of his family. Second, I control for the

college wage premium among prime-wage workers, again measured in the respondent’s state of birth in

the year in which he was 18 years old.26 This is intended to capture the young person’s perceived returns

at the time he is making the decision to enroll in college. Third, I control for the size of the state-of-birth-

by-age cohort. This last variable may affect educational attainment through capacity constraints in

education (Bound and Turner, 2004). I allow the effect of all of these variables to vary with age, which



25
  A booming labor market may also boost the income of parents of college-age children, which in the
presence of liquidity constraints will tend to increase the share of young people completing a degree.
26
  I use 35- to 54-year-olds in the1984-96 March CPS to estimate these college premia. The premium is
defined as the difference between the mean log wages of year-round, full-time workers with exactly a
high school degree and a BA or above.


                                                       16
flexibly captures any changes over time in the effect of labor market conditions on schooling decisions.

Results are in Column (2) of Table 5.27 The unconditional estimate is reproduced in Column (1). After

controlling for these measures of labor market conditions the estimate drops imperceptibly, from 2.98 to

2.82, with little loss in precision. If the racial and ethnic composition of the program states is changing

over time relative to that of the comparison states, this would tend to bias the results, since race and

ethnicity are correlated with education. In the third column of the table, I therefore add additional controls

for race and ethnicity, as well these variables interacted with a sex dummy. Again, all of these variables

are interacted with age in order to allow their effect to vary flexibly over time. The estimated program

effect (Column (3)) is quite stable, at 2.63 percentage points, with a standard error of 0.53.



Robustness to Definition of Comparison States

        Labor market conditions and population characteristics may be shifting in unobserved ways in the

South relative to the rest of the country. Over the past few decades, relative income and education have

been rising in the South, suggesting that the rise in education estimated in the previous sections simply

reflects a broader convergence of the South with the rest of the country. If this is the case, then the US is

a poor counterfactual for Arkansas and Georgia, with the rest of the South forming a more appropriate

comparison group. I limit the sample to those with a Southern state of birth and re-estimate Equation (2).

The result is in Column (2) of Table 6. The estimate is quite stable at 2.78 percentage points, though the

standard error doubles to 0.79 percentage points.




27
  Mechanically, I control for these covariates as follows. I regress the merit dummy and outcome variable
against the covariates and form residuals. I collapse these residuals into cell means at the level of state of
birth and age and re-estimate Equation (2) with these cell means as the unit of observation. This will
produce the same point estimates as running Equation (1) in the microdata with covariates, with the
advantage of producing unbiased standard errors.


                                                      17
        In the next column, I define the sample as any state that had introduced a merit program by 2003;

this includes the non-Southern states of Michigan, Nevada and New Mexico. In this approach, the states

that ever introduce a merit program form their own comparison group and the program effect is identified

from the staggered timing of the programs’ introductions. The resulting estimate is 2.64, with a standard

error of 0.48 percentage points. In the last column, I again limit the sample to states that ever introduce a

merit scholarship but drop the non-Southern merit states from this analysis. The estimate is still positive

and significant but drops to 2.29 percentage points, with a standard error of 0.60 percentage points.



Falsification Exercise

        State of birth and state of residence are highly correlated. To make clear that the identification of

the program effect is driven by state of birth, rather than current state of residence, Table 7 shows the

results of re-estimating the equations with state of residence determining treatment status. That is, current

state of residence, rather than state of birth, is assumed to be the state in which a person graduated from

high school. These estimates are very small and statistically indistinguishable from zero: 0.39 and zero

percentage points when the entire US and the South, respectively, are used as the comparison groups.

        This result shows that the states with scholarship programs are not simply states to which the

well-educated are migrating. This strongly supports the identification strategy of the paper. In fact, since

the estimates of the paper indicate that the merit programs are inducing more young people to complete

college, the null results of Table 7 necessarily imply that either highly educated workers are migrating out

of merit states or relatively uneducated workers are migrating into the merit states. The scenario of an

inflow of uneducated workers is consistent with Moretti (2004). He shows that a college-educated

workforce generates positive wage externalities for both skilled and unskilled workers; through this

channel, a state with a growing share of college-educated workers could be a magnet for unskilled labor.

         Whether those induced to complete college remain in the state in which they are educated is

important from the state’s perspective: it is quite different to educate a college graduate and have her

leave than to have her stay and produce positive externalities. I do not explore migration in the present

                                                      18
paper, but instead focus on the efficacy of higher education policy in getting more people to complete

college, wherever those workers may take their human capital after graduation.



Underlying Trends in Educational Attainment

        I have so far controlled for observable differences between the treatment and comparison states.

Any unobserved differences between the treatment and comparison states that are fixed over time will be

absorbed by the state-of-birth fixed effects and will not bias the estimates. But any changes in the

populations and economies of Arkansas and Georgia that do not also occur in the comparison states are a

threat to the internal validity of the estimates. Since the industrial composition of the South has been

shifting substantially over the last several decades, and there has been a steady migration of the US

population southward, the assumption of fixed differences between the treatment and comparison states

may well be invalid.

        I informally evaluated this threat to validity with Figures 1A and 1B, which indicate a sharp break

for the affected cohorts. A more formal approach is to control parametrically for state-specific trends in

college completion. A typical method is to include linear time trends in the regression and identify the

program effect with deviations from those trends. Figures 1A and 1B make clear, however, that the

counterfactual trend is not linear, but rather quadratic. I test both the linear and quadratic functional

forms, as well as a non-parametric approach. As discussed below, all of these strategies return similar

results, with quite consistent point estimates but, in some cases, substantial loss of precision.

        I first add to the baseline regression a linear term in age, interacted with the state of birth

dummies:28

(3)      yab = β meritab + λb ageab + δ a + δ b + ε ab




28
  Conducting this exercise with means of the residuals, rather than unconditional means, does not alter
the results.


                                                         19
This specification allows each state to be on its own linear age trend in degree completion, with the

program effect identified by deviations from these trends. Results are in Column (2) of Table 8. For the

US sample, the point estimate drops from 2.98 to 2.21 percentage points and the standard error more than

triples, to 1.36. A similar pattern holds for the Southern census region, where the estimate drops from

2.78 to 2.45 percentage points and the standard error rises to 1.83. I next add the square of age, again

interacted with state of birth:

(4)      yab = β meritab + λb ageab + ηb ageab
                                            2
                                               + δ a + δ b + ε ab

As shown in Column (3), the estimate based on the US sample is essentially unchanged, while the

Southern sample estimate rises to 3.44 percentage points. The standard errors rise yet higher and the

estimates are not statistically significant.

        The approaches just discussed impose a functional form on the underlying trends. Including a

separate set of age effects for each geographic area, by contrast, allows the age-education profiles to take

whatever forms the data suggest. In Column (4), I add to the regression the interactions of age with the

nine census divisions of birth.29 Using either the US or Southern samples, the resulting estimate is 2.35

percentage points, with a standard error of about 1.5 percentage points, representing a small change in the

point estimate but a large loss in precision.

        While in a single cross-section I cannot control for the interaction of state of birth with age

effects and still identify the program effect, I can control for the interaction of state of residence with age.

With this approach, those who reside in their state of birth identify the state-specific age-education

profiles, while those who live outside of their state of birth identify the program effect. Results are in

Column (5). The estimates rise slightly and are statistically significant: 4.16 percentage points for the US

and 3.18 for the Southern sample.




29
  Arkansas and Georgia are in separate divisions, so separate counterfactual age profiles are estimated for
each of these treatment states.


                                                       20
           Note, however, that interstate migrants may have an unusual response to the merit programs.

Interstate mobility is highly correlated with education and income, so those who live outside their state of

birth may come from relatively advantaged backgrounds; while this does not bias the estimate it may limit

its generalizability. Ideally we could control for the interaction of state of birth with age, thereby

identifying an effect averaged over those who do and do not live within their state of birth. With data

from two points in time, we can include such controls while still identifying the program effect. I

therefore bring the 1990 census into the analysis, and add to the baseline specification state-of-birth-by-

age effect interactions, as well as all second-order interactions of census year, state of birth and age

effects:

(5)        yabt = β meritabt + δ a + δ b + δ t + δ ab + δ bt + δ at + ε ab

Equation (5) controls for state-specific changes between 1990 and 2000 in the rate of degree-holding

(through the interactions of census year and state of birth), as well as any changes over time in the shape

of the age-education profile that are common across the states (through the interaction of census year and

age). Finally, the specification controls for any state-of-birth-specific idiosyncrasies in the shape of the

age-education profile that are persistent over time (through the interaction of state of birth with age

effects). The program effect is identified by the triple interaction of state of birth, age dummies and

census year. Put differently, it is identified by changes between 1990 and 2000 in state-of-birth-specific

age-education profiles. Results are in Table 9. For both the US and South the estimates rise slightly, to

3.50 for the US sample and 3.32 for the South. Unsurprisingly, since this specification pushes the data

quite hard, the standard errors rise substantially, to about two percentage points.30 The stability of the

coefficients, however, is strongly supportive of the identification strategy of the paper.




30
 These standard errors are clustered at state of birth and census year, which is the unit of observation at
which we would be concerned about autocorrelation.


                                                              21
Accounting for Classification Error in Treatment Status

        The analysis has so far used state of birth and age to assign eligibility for a merit aid program,

with each individual imputed to be eligible with probability one or probability zero. There are two sources

of error in this method of assignment to treatment status. First, in the 2000 census, 24 percent of high

school students lived outside their state of birth. Assuming this rate has not changed substantially over

time, my assignment of eligibility for merit aid is incorrect for about 24 percent of the analytical sample.

Second, many students are younger or older than 18 in the spring of their senior year, typically ranging in

age from 17 to 19. For those high school seniors who were younger or older than 18 at the time a merit

program was introduced in their state, the paper has incorrectly imputed eligibility. In this section of the

paper I attempt to correct for both of these sources of error in the assignment of treatment status.

        I first address misclassification due to interstate migration. By using state of birth as a proxy for

state of high school attendance, I have so far ignored the information provided by current state of

residence. I therefore predict state of high school attendance with state of birth and use this predicted

value to assign treatment status. That is, I allow treatment status to be a probabilistic (rather than

deterministic) function of state of birth. To implement this strategy, I use high-school-age youth (15 to 17

years old) in the 2000 census to estimate a matrix of transition probabilities between state of birth and

state of high school attendance. In principle, this matrix could have 51 X 51 cells. However, since

attendance in only two states (Arkansas and Georgia) produces a treatment, it is more efficient to estimate

a matrix with dimension 51 X 2, corresponding to 51 states of birth and high school attendance in Georgia

or Arkansas.31 I apply this matrix to the older sample (22- to 34-year-olds) to yield predicted state of high

school attendance. The resulting predicted probabilities are used to define the treatment variable, which




31
  Specifically, I run OLS regressions of the following form, where i indexes individuals, b indexes state
of birth and I is an indicator variable:
I ( state of residence = AR)ib = δ b + ε ib
I ( state of residence = GA)ib = µb + vib


                                                      22
now ranges from zero to one. I then re-run Equation (2).32 Results are in Table 10. The estimate rises from

2.98 to 3.74 percentage points.

        This is quite close to the error-corrected estimate that would be appropriate if migration to and

from the merit states were random. Aigner (1973) and Freeman (1984) show that the relationship between

the true coefficient and that estimate in the presence of classification error is:

                 βˆ
(6)      β* =
                1− δ

where βˆ is the coefficient estimated in the presence of measurement error and δ is the degree of

classification error.33 Nationwide, 24 percent of high school seniors live outside their state of birth, so the

baseline estimate of 2.98 corresponds to a error-corrected estimate of 3.92 (=2.98 /0.76).

        I next account for measurement error in the year of high school graduation. I do so by allowing

treatment status to be a probabilistic function of age, using the 1989-91 School Enrollment Supplements

of the October CPS to estimate age-specific probabilities of being a high school senior for those age 16

through 24.34 I use these probabilities to impute for the analytical sample the probability of being a senior

in each of the years from 1984 through 2000. The resulting predicted probabilities are used to define the




32
  The treatment variable is now defined as the sum of the interactions of two predicted probabilities with
age dummies, e.g., for person of age a born in state b:

meritab = Prb (high school in AR) × I (a <=18 in 1991) + Prb (high school in GA) × I (a <=18 in 1993)

33
  This result may seem obvious, since classical measurement error is known to produce attenuation in
regression coefficients. However, measurement error in binary variables is non-classical: if a zero is
observed, the measurement error can only be non-negative and if a one is observed the measurement error
can only be non-positive. This violates the standard assumption that the measurement error is
uncorrelated with the truth.
34
  The questions needed to determine whether a person is enrolled for a high school senior are available
for these ages only. I constrain the sum of these probabilities to equal one, so that the estimate is corrected
only for the timing of when an age cohort was a high school senior. Allowing the probabilities to sum
than less than one would inflate the estimates by the inverse of the share of a birth cohort that attains the
senior year of high school.


                                                       23
treatment variable, which now ranges from zero to one, and the key estimating equation is re-run.35 The

resulting estimate is in Table 10, Row (3): 3.33 percentage points, with a standard error of 0.57

percentage points. Finally, in Row (4) I allow treatment status to be a probabilistic function of both state

of birth and age. This yields an estimated program effect of 4.21 percentage points, with a standard error

of 0.57.

           For simplicity of interpretation and exposition, in the remainder of the paper I will estimate

coefficients that are not adjusted for classification error. It should be kept in mind, however, that the

error-corrected estimates are twelve to forty percent higher than the uncorrected estimates.




                                     V. Heterogeneity in Program Effects

           The robustness checks of the previous section establish a strong case for causal interpretation of

the paper’s estimates. Estimates that control for observable characteristics and for underlying trends in

unobservable determinants of degree completion return quite similar results. So, too, do estimates that use

as the comparison group the entire US, the South alone, and states that ever introduce a merit aid

program. In every case, the estimates indicate that the merit aid programs increased the share of the

young, working age population receiving a college degree by three to four percentage points. Correcting

for mis-classification in treatment status increases the point estimate to 3.3 to 4.2. Having laid out the case

for causality in the estimated effects, in this section I identify the margins of behavior and populations

that respond most strongly to the scholarship programs.

           I start by examining how margins other than college degree completion react to the programs.

This exercise is of interest for two reasons. First, it is a check on the identification strategy, in that it



35
   The treatment dummy is now defined as the sum of the interactions of two predicted probabilities with
state of birth, e.g., for person of age a born in state b:

meritab =I b (born in Arkansas) × Pra (HS senior in 1991+) + I b (born in Georgia) × Pra (HS senior in 1993+)


                                                        24
allows us to confirm that there is no significant change in education at levels unaffected by the policy.

Second, it allows us to hypothesize about the marginal student whose behavior is affected by the program.

        I pinpoint changes in the full distribution of schooling using the methodology of the preceding

section. I create a set of indicator variables, each indicating that an individual’s level of education is

greater than or equal to schooling category j and create means of these variables for each state-of-birth by

age cohort:

(7)      yabj = E (educ ≥ j ) ab

I then estimate program effects ( β j ) for each of these j outcomes.

(8)      yabj = β j meritab + δ aj + δ bj + ε abj

These coefficients, along with their point-wise 95 percent confidence intervals, are plotted in Figure 2.

For reference, Table 11 lists the coefficients and their standard errors. Each point represents the estimated

program effect on the probability of being equal to or above that level of education. The point above AA,

for example, is 2.98. This estimate, seen throughout in the paper, is the impact of the program on the

probability of receiving an AA or above.

        For all pre-college outcomes, the estimates are close to zero. Ex ante, we might have expected an

effect of the programs upon high school graduation, since they both reward academic performance in high

school and increase the option value of graduating. 36 However, the results suggest that those whose

behavior is affected by these incentives (those close to having a B average in high school) are not at the

margin of dropping out of high school and therefore are unresponsive to this incentive.




36
   High school grades have risen in Georgia since its scholarship was introduced, which is consistent with
either increased effort in high school or grade inflation. Henry and Rubenstein (2002) document a steady
correlation between SAT scores and high school grades among entering Georgia college freshmen. They
argue that this unchanging relationship is evidence against grade inflation.


                                                      25
        The first positive and large estimate appears at the college entry margin, with a statistically

insignificant estimate of 1.59 percentage points.37 There is a yet larger (and significant) impact on

persistence through college, with the share completing at least some years of college rising by 1.94

percentage points. Relative to baseline, this is a large effect: in the 2000 census, 9 percent of this age

group had entered college without completing a single year. As discussed in detail in the previous section,

there is a statistically significant effect of 2.98 percentage points upon degree completion.

        There is also a statistically significant impact upon completing any education beyond the BA

(1.37 percentage points). This could indicate a weakness in the identification strategy, since the

scholarships only directly subsidize undergraduate study. There are several plausible explanations for a

program effect beyond the BA. First, courses taken at the baccalaureate level often count toward a

graduate degree, so completing a BA moves one closer to an MA. For example, accounting and nursing

students at Georgia Southern University concurrently earn bachelor’s and master’s degrees, with HOPE

paying for 150 credit hours of the combined course-load; the BA requires just 120 credit hours.38 More

generally, a simple model of human capital accumulation suggests that post-baccalaureate schooling

decisions will be a function of past schooling costs, implying that a college graduate who paid less for her




37
  In previous work with the Current Population Surveys, I have estimated a five to seven percentage
point impact of the merit programs on the contemporaneous college attendance rate of 18- to 19-year-olds
(Dynarski, 2000 and 2004). This result is not directly comparable to any of the present estimates, since
the attendance rate conflates two outcomes: entry and persistence conditional upon entry. Further, note
that the contemporaneous CPS attendance questions may capture short college spells forgotten by those
answering retrospective Census questions. Card and Lemieux (2001) note divergence between education
of cohorts as measured by Census and the CPS.
38
  State legislators, arguing that HOPE was not intended to pay for graduate school, have voted to limit to
127 the credit hours paid by the program (Salzer, 2005). A second HOPE provision, introduced in 1996,
encourages graduate study: the state forgives graduate student loans of those who teach in Georgia
elementary and secondary schools.


                                                      26
bachelor’s degree will be more willing to borrow for a master’s degree.39 Finally, in the presence of

liquidity constraints, a scholarship can lead students to work less and thereby complete their education

more quickly. In my data, I cannot rule out that the treated cohorts are simply completing their planned

degrees at a quicker pace. If this is the case, the programs’ effects on completed education will fade as the

treated cohorts age.40 However, even if the program effect completely dissipates as cohorts age, there will

still be a positive welfare impact of the scholarships, since education completed earlier in life yields more

years of private and social returns.

        I now turn to exploring heterogeneity across populations in the programs’ effects. Treatment

heterogeneity could be driven by a variety of factors that vary systematically across the population, such

as preparation in high school, labor market opportunities, returns to schooling, parental education and

liquidity constraints. I capture the reduced-form impact of all of these channels. I split the sample into

four mutually-exclusive groups: non-Hispanic white/Asian men, non-Hispanic white/Asian women,

Hispanic and nonwhite men, and Hispanic and nonwhite women, running Equation (2) separately for each

of these groups. The resulting coefficients, along with their point-wise 95 percent confidence intervals,

are plotted in Figures 3A through 3D.

        I find substantial heterogeneity in the effect of the scholarships, with the most striking effects for

women. Hispanic and nonwhite women are most responsive to the scholarships (Figure 3A), with their

college entry rate rising by 5.99 percentage points and their probability of completing at least some

college rising by 7.44 percentage points. They also exhibit large increases in their probability of receiving



39
   See Dynarski (2000) for the development of this model, which shows that future human capital
investment will depend on the cost of past investment if the price of debt rises with its level. There is
evidence that students and families face rising interest rates when borrowing for college. The cheapest
source of funds for most families is federally subsidized student loans, with housing equity the next
alternative. If housing equity has been exhausted, families can turn to unsubsidized federal loans. As a
last resort, families can turn to more expensive sources of funds, such as unsecured personal loans,
retirement savings and credit cards.
40
  In theory, I can test for fadeout of the program effect; in practice, it is difficult to discern such patterns
from random noise and year-specific changes in program generosity.


                                                       27
any college degree (3.46 percentage points). White, non-Hispanic women (Figure 3B) respond quite

strongly, as well, with their increases concentrated at completing any college degree (3.2 percentage

points) and completing a BA (2.3 percentage points). This group also exhibits somewhat smaller effects at

college entry (1.2 percentage points) and the completion at least a year of college (1.5 percentage points).

All of these estimates are highly significant.

        Program effects are relatively muted among white, non-Hispanic men (Figure 3C), but this

group’s probability of receiving a BA rises by respectable 1.93 percentage points. The results for

Hispanic and nonwhite men are mixed and noisy (Figure 3D). There are precisely-estimated increases in

the probability of completing any college degree and at least a BA (1.60 and 2.79 percentage points,

respectively), but there is also a large and insignificant drop in the probability that this group will

complete high school. This could indicate that instructional resources are being shifted away from

students on the margin of dropping out of high school, among which nonwhite and Hispanic men are

disproportionately represented, but this estimate is so imprecise that I hesitate to draw firm conclusions.

        I summarize the effects on degree completion in Table 12. For the entire sample, the effect is

concentrated on the BA margin: 2.52 percentage points, as compared to 0.46 for the AA margin. A

similar relationship holds for white, non-Hispanic women, for whom the BA outcome is more sensitive

than the AA (2.29 as compared to 0.87). Among nonwhite and Hispanic women, however, the AA margin

dominates: the estimated effect is 2.63 percentage points for the AA as compared to 0.82 for BA or

above. Among men, the estimated AA effect is negative, significantly so for nonwhites and Hispanics,

indicating that the subsidies are shifting this group from AA receipt toward BA completion.



                                                 VI. Discussion

        Together, these tables and figures provide strong evidence that the merit aid programs increased

the completed schooling of eligible youth. Merit aid is estimated to increase the college entry rate by 1.6

percentage points, the share who complete any years of college by 1.94 percentage points, and the share

who complete any college degree by 2.98 percentage points, and the share who complete a BA or above

                                                      28
by 2.52 percentage points. All but the first of these estimates are highly significant. All of these margins

are ones that are plausibly affected by the merit aid programs, which decrease the cost of both entering

and persisting through college.

        The program effects are much stronger for women than for men; the behavioral gap among

nonwhites is especially striking. The results accord with previous evidence on the relative elasticity of

male and female college attendance (Card and Lemieux, 2001). As the return to college has risen over

time, women have made far greater gains than men in college completion rates. Between the late 1980s

add the late 1990s, young women shot past their male peers in their college completion rate, with the

share of recent high school graduates with a BA rising from 21 to 31 percent for women and from 24 to

26 percent for men. The female advantage in college-going is particularly pronounced among

nonwhites.41 Nonwhite and Hispanic men are more likely than others to drop out of high school, be

incarcerated, or join the military, all of which will blunt the effect of any scholarship on this group’s

schooling decisions. Differential performance in high school explains gender differences in the effect of a

merit scholarship, in particular. Among members of the high school class of 1992 that went to college, 49

percent of women had a high school GPA of at least 3.0, while just 36 percent of their male peers

performed as well. If these achievement patterns held in Arkansas and Georgia, fewer male than female

high school graduates would have been eligible for the merit scholarships.



How Does Merit Aid Affect Persistence in College?

        I cannot separately identify the effect of merit aid on college entry and persistence conditional on

entry, because I cannot identify the marginal entrant. Instead, the paper has measured the reduced-form

impact of merit aid on completed schooling, which is the product of effects upon entry and persistence.

We can place informative bounds on the size of the persistence effect, however. One bound is formed by


41
  These statistics are for the high school classes of 1982 and 1992 and are drawn from High School and
Beyond and NELS88, respectively. See National Center for Education Statistics (2005). For discussion of
the gender gap in college see Jacob (2002).


                                                      29
assuming that none of those induced into college by the scholarships completes a degree. The other bound

is formed by assuming that all of those induced into college by the scholarships complete a degree. I

calculate these bounds below, using as inputs the estimated effects from Table 12 and the following data

for pre-program cohorts in the treatment states: 51.5 percent entered college and 26.7 percent completed a

degree, leading to a baseline persistence rate of 51.8 percent (=26.7/51.5).

        Scenario A: No student induced into college by the scholarship program completes a degree.
        In this case, all of the 2.98 percentage point increase in degree completion must be explained by
        increased persistence among those who would have entered college even in the absence of the
        scholarship. The merit programs are then estimated to have increased the degree completion rate
        to 29.7 percent (=26.7+2.98). The persistence rate is therefore calculated to rise by 5.2 percentage
        points to 57.0 percent (=29.7/51.5), or by about ten percent (=5.2/51.8).

        Scenario B: Every student induced into college by the scholarship program completes a degree.
        The programs are estimated to increase college entry by 1.6 percentage points. Thus, in this
        scenario, 1.38 percentage points (=2.98-1.6) of the increase in degree completion must be
        attributable to increased persistence of those who would have gone to college in the absence of
        the program. The program is estimated to increase their completion rate to 28.08 (=26.7+1.38)
        percent, which in turn implies an increase of 2.7 percentage point in persistence (from 51.8
        percent to 54.5 percent [=28.08/51.5]), or about five percent (=2.7/51.8).

The scholarship programs are therefore estimated to increase persistence to degree, conditional on college

entry, by 2.7 to 5.2 percentage points.42 Given a baseline persistence rate of 51.8 percent, this is

equivalent to a proportional increase of five to ten percent (or, equivalently, corresponds to a decrease in

the college dropout rate of six to twelve percent).

        Note that the paper’s estimates reflect any incentive effect of the scholarships on academic effort

in high school and college. They are therefore not directly comparable to estimates yielded from variation




42
  If we assume that marginal entrants persist at the same rate as pre-program college students, the implied
increase in the persistence rate for infra-marginal college entrants is 4.3 percentage points.


                                                      30
in price driven by, for example, Pell Grant eligibility.43 It is not clear whether the academic requirements

of the programs will tend to lead to larger or smaller college completion effects than a non-merit subsidy.

The merit programs’ academic requirements may push students to work harder in college, and thereby

make them more likely to succeed. This may make these programs particularly effective at increasing

degree receipt. Conversely, though, they may deny subsidies to many students who are on the margin of

completing a college degree, but whose grades are too low to maintain the scholarship. The programs

require a 2.75 to 3.0 GPA in college, well above the GPA required to graduate. This may make the

programs less effective in encouraging degree completion than one that is targeted at a lower point in the

distribution of academic achievement.



Cost-Benefit Analysis

        While the scholarships increase college entry and degree completion, it is still the case that most

of the scholarship funds go to people who would have entered or completed college anyway. Do the

private and social returns to the human capital created by the merit scholarships justify the outlay? In this

section, I discuss the possible benefits of the programs, delineate their costs, and calculate the social

welfare consequences of the merit scholarships under a variety of scenarios.

        A rich literature explores the private and social benefits of education. There is now extensive

evidence concerning the causal impact of a high school education on a variety of outcomes. High school

increases wages, extends life, increases civic participation, reduces crime and improves outcomes for the




43
   Bettinger (2004) uses a regression-discontinuity strategy to identify the effect of Pell Grant eligibility
on persistence, finding that a $1,000 increase in Pell Grant eligibility increases persistence between the
first and second years of college by two to four percentage points. Extrapolating Bettinger’s results to the
current context requires assuming that the effect of a scholarship is linear in its face value and that the
effect of a subsidy on the hazard of dropping out is constant across years of college. With these
assumptions, Bettinger’s estimate predicts that the merit aid program would increase the share completing
a BA by seven to fourteen percentage points, compared to the paper’s estimates of three to four
percentage points.


                                                      31
children of those constrained to stay in school.44 We have comparatively little information about the

corresponding returns to a college education.45 Plausibly, the private and social returns to college are

different from those of high school, so many of the existing estimates cannot be safely extrapolated.

While evidence indicates a high school education keeps people out of prison, college graduation is

unlikely to yield similar benefits. For the purposes of the current calculation, I take a conservative

approach and ignore all non-financial returns and externalities. This provides a lower bound on the social

benefits of the programs.

           The benefits are the sum of the marginal returns associated with attaining a given level of

schooling, weighted by the program’s causal impact on the probability that this level of schooling is

attained:


                                                       ∑β α
                                                         j
                                                                j       j


Here, β j is the effect of program on probability of attaining education level of j.46 α j is the lifetime

return to attaining schooling level j rather than schooling level j-1. These returns are calculated by

summing and discounting) the age-specific difference in the annual mean earnings of those with

schooling level j and j-1:47


                                                                y −y
                                                                    j              j −1
                                                       65
                                              αj =    ∑
                                                     a = j +6
                                                                    a

                                                                        r   a −1
                                                                                   a




44
  See Angrist and Krueger (1991) on wages; Lleras-Muney (2005) on health; Lochner and Moretti (2004)
on crime; Dee (2004) and Milligan, Moretti and Oreopoulos (2004) on civic participation; and
Oreopoulos, Page and Stevens (2003) on improved outcomes for children of high school graduates.
45
  Currie and Moretti (2003) and Moretti (2004) examine the impact of receiving a college education on
children’s health and others’ wages, respectively. Card (1995) estimates private wage returns using
distance to college as an instrument for a college education.
46
     Effects are essentially zero for levels of education lower than college entry, so they are ignored.
47
  While it appears that the program increased the population share with a master’s degree, I do not
include this as a program benefit in these calculations. Mechanically, I achieve this by excluding those
with education above a BA from the calculations of mean earnings.


                                                             32
To anchor the analysis, I assume that the marginal student earns the returns to education observed in the

cross section. These cross-sectional “returns” do not have a causal interpretation, since they include wage

differences driven by unobserved worker heterogeneity, but do provide a useful point of reference. Note

that these differences in annual earnings incorporate differences driven by both hourly wages and labor

supply. Both margins are plausibly affected by education.

        The costs consist of the scholarships, the excess burden induced by raising funds for the

scholarships, and the forgone earnings of those who stay in school longer because of the scholarships. I

first describe costs for those whose schooling attainment is not affected by the scholarship – that is, the

inframarginals. Opportunity costs of this group do not enter the social welfare calculation, as they would

have attended college in the absence of the program. I assume that the annual scholarship is $2,500. In

expectation, about 30 percent of a given age cohort will use this scholarship for at least one year of

college.48 Forty percent of those who use the scholarship as freshmen get the scholarship for a second

year; other students drop out or get grades too low to qualify. Three-quarters of those who receive the

scholarship the second year get it a third year, and two-thirds of those who get it the third year receive it

the fourth year. Just twenty percent of those who enter with a merit scholarship will both stay in school

and earn a GPA above 3.0 long enough to earn a BA.49 I use these hazards to calculate expected

scholarship costs for the inframarginals.

        For the marginals, the expected scholarship cost is a weighted sum of the estimated impact of the

program on attaining a given level of schooling and the marginal scholarship cost associated with moving

the student to that level of schooling:


48
  About 60 percent of the Census sample has gone to college. About half of recent high school graduates
entering college in 2001 had a GPA of 3.0 in high school (author’s calculations from Beginning
Postsecondary Students Survey), so about 30 percent (=0.6*0.5) of a given age cohort is expected to take
up the scholarship for at least a year.
49
  I have calculated these hazards using data on high school grades, college grades and persistence in the
2001 Beginning Postsecondary Students Survey. Administrative data from Georgia on the share
scholarship recipients who receive HOPE for multiple years yield hazards very similar to those predicted
by the BPS data.


                                                      33
                                                  ∑β S
                                                    j
                                                         j   j




For example, the education category about the AA (a two-year degree) is the BA. The marginal

scholarship cost for moving someone from an AA to a BA is then $2,500, for two years. The scholarship

costs are inflated in order to account for the deadweight loss induced by the taxes needed to raise the

revenue for the program. Gruber and Saez (2002) conclude that the elasticity of taxable income is 0.4;

given an average tax rate of 33 percent this corresponds to an marginal deadweight loss of taxation of

0.245.50 I use a real discount rate of four percent, which is appropriate given that I am not allowing for

any real wage growth.

        Given this set of assumptions, the present-discounted, per-person cost of offering the program to

an age cohort is about $1,700. Adding in the excess burden increases this cost to about $2,100.51 Eighty

percent of the scholarship funds flows to those whose schooling attainment is unaffected by the

program.52 All of the relevant opportunity costs are borne by the marginals. Across the entire cohort, they

average $2,000. All of the benefits are also produced by the marginals. Assuming that they face cross-

sectional returns to education, the expected lifetime returns (again, averaged over the entire cohort) are




50
  The Georgia scholarship is funded by a lottery, which as a revenue source will have a lower excess
burden than the income tax since players gain utility from playing and have some chance of winning. The
Arkansas program is funded from general revenues.
51
 Note that these are not per-student costs but per-person costs, averaged across the entire age cohort.
Many members of the cohort receive nothing, while relatively few receive the scholarship for four years.
52
   The scholarship is a transfer that can affect utility through a variety of channels, including increased
consumption. By ignoring any benefits that accrue through channels other than increased education, I
provide a lower bound on program benefits. The program’s internal rate of return would rise considerably
if these dollars were treated as a transfer rather than a cost.


                                                        34
$8,100. Benefits exceed costs by a factor of two. The internal rate of return implied by these figures is

7.9 percent, which easily exceeds any reasonable efficiency threshold.53

        A key assumption in this calculation is that marginals face the same rates of return as we observe

in the cross section. In this setting, theory does not unambiguously predict whether the marginal person

will have a return to schooling higher or lower these population values. If the scholarship loosens

liquidity constraints then her return may be higher, while if it simply reduces the price of college then her

return may be lower. Card (2001) notes that instrumental-variable estimates of the return to schooling are

typically higher than OLS estimates, which would suggest that the internal rate of return of 7.9 percent is

not overly optimistic. However, even if those whose schooling is increased by the scholarships earn

returns that are a third lower than those observed in the cross-section, the internal rate of return is 5.5

percent, while if they earn returns that are a third higher it is 9.7 percent. Note that all of these figures

represent lower bounds on the internal rate of return, as I have underestimated the benefits by ignoring

positive externalities to education and treating as a cost (rather than a transfer) the eighty percent of

scholarship dollars that go to students whose educational attainment is unaffected by the program.




                                               VII. Conclusion

        While the college attendance rate has risen sharply over time, the share of the population that has

completed college has stayed relatively flat. Given that a very high proportion of high school graduates

currently attempt college, large increases in the stock of college-educated labor will have to operate


53
  The above calculations may underestimate the program costs, in that the tuition and fees paid by the
scholarship do not represent the full public cost of educating a college student. Winston (1999) estimates
that roughly thirty percent of the average cost of educating a college student is covered by tuition and
fees, with the remainder covered by endowment income and government subsidies. This average figure
surely overstates the subsidy costs for marginal college graduates, for two reasons. First, the subsidy is
highest at selective institutions, which marginal students are not likely to attend. Second, marginal cost is
almost certainly below average cost for the moderate enrollment gains induced by the scholarship
programs. But even if we add the average subsidy (and its associated deadweight loss) to the costs of the
program, the internal rate of return is 6.8 percent.


                                                       35
through the intensive rather than the extensive margin, by adding more years to the schooling of those

who enter college rather than drawing more into postsecondary education. This paper has provided strong

evidence that subsidies to the direct costs of college are an effective tool for increasing college

completion and persistence.

        The results are robust to the inclusion of covariates, including measures of labor market demand

in state of birth when the college entry decision was being made. Nor does the inclusion of flexibly-

specified state-specific trends in education alter the conclusions. I find a large and significant impact of

these subsidies on both degree receipt and college entry. The results suggest that merit programs increase

college degree attainment by three to four percentage points. This is a substantial effect, given that the

baseline share of the affected population with a college degree was just 27 percent. The effects on

schooling are strongest among women, with white, non-Hispanic women increasing degree receipt by 3.8

percentage points and the share of Hispanic and nonwhite women attempting or completing any years of

college increasing by six and seven percentage points, respectively.

        While my reduced-form estimation strategy cannot separately identify the effect of aid on entry

and persistence, I estimate fairly narrow bounds on the persistence effect. The merit aid programs appear

to increase by five to eleven percent the probability of persistence to degree of those who would have

gone to college in the absence of a merit aid program – that is, of inframarginal college entrants. A simple

cost-benefit analysis concludes that the private benefits of the scholarship programs substantially

outweigh their costs, with a an internal rate of return to of five to ten percent.

        These results indicate that tuition policy can play a welfare-enhancing role in increasing the stock

of college-educated labor. But it should be emphasized that, for the bulk of college students, a scholarship

with very low transaction costs is not sufficient to get them to complete a degree. Even with the offer of

free tuition, a large share of students continue to drop out of college, suggesting that the direct costs of

school are not the only impediment to college completion. The results indicate that more than tuition

reduction will necessary in order to substantially increase the stock of college educated labor. Candidate



                                                       36
mechanisms are better preparation in elementary and secondary school, more intensive institutional

supports in college, and funding that extends beyond direct costs to opportunity costs.




                                                    37
                                              References


Angrist, Joshua (1993). “The Effect of Veterans Benefits on Education and Earnings.” Industrial and
        Labor Relations Review 46:4, 637-52.

Angrist, Joshua and Krueger, Alan (1991). “Does Compulsory School Attendance Affect Schooling and
        Earnings?” Quarterly Journal of Economics 106:4, pp. 979-1014.

Becker, Gary (1994). Human Capital. Chicago: University of Chicago Press.

Bertrand, Marianne, Esther Duflo and Sendhil Mullainathan (2004). “How Much Should We Trust
        Differences-in-Differences Estimates?” Quarterly Journal of Economics 119:1, pp. 249-275.

Bettinger, Eric (2004). “How Financial Aid Affects Persistence,” in Caroline Hoxby, ed., College
        Choices: The Economics of Where to Go, When to Go, and How To Pay for It. Chicago:
        University of Chicago Press.

Bound, John and Sarah Turner (2002). “Going to War and Going to College: Did World War II and the
       G.I. Bill Increase Educational Attainment for Returning Veterans?” Journal of Labor Economics.
       20 (4): 784-815.

Bound, John and Sarah Turner (2004). “Cohort Crowding: How Resources Affect Collegiate
       Attainment.” University of Michigan Population Studies Center, Research Report No. 04-557.

Card, David (1995). “Using Geographic Variation in College Proximity to Estimate the Return to
       Schooling,” in Aspects of Labour Market Behaviour: Essays in Honour of John Vanderkamp, ed.
       by Louis N. Christofides, E. Kenneth Grant, and Robert Swidinsky. Toronto: University of
       Toronto Press, pp. 201-222.

Card, David (2001). “Estimating the Return to Schooling: Progress on Some Persistent Econometric
       Problems.” Econometrica 69:5, pp. 1127-1160.

Card, David and Alan B. Krueger (1992). “Does School Quality Matter? Returns to Education and the
       Characteristics of Public Schools in the United States.” Journal of Political Economy 100:1, 1-40.

Card, David and Thomas Lemieux (2001). “Dropout and Enrollment Trends in the Postwar Period: What
       Went Wrong in the 1970s?” in Jonathan Gruber, ed., Risky Behavior among Youths: An
       Economic Analysis. Chicago: University of Chicago Press.

Cornwell, Christopher and David Mustard (2005). “Merit-Based Scholarships and Car Sales.”
      Unpublished manuscript, University of Georgia.

Cornwell, Christopher, David Mustard and Deepa Sridhar (2004). “The Enrollment Effects of Merit-
      Based Financial Aid: Evidence from Georgia’s HOPE Scholarship.” Unpublished manuscript,
      University of Georgia.

Cornwell, Christopher, Kyung Hee Lee and David Mustard (2004). “Student Responses to Merit
      Scholarship Retention Rules.” Unpublished manuscript, University of Georgia.




                                                   38
Currie, Janet and Enrico Moretti (2003). “Mother’s Education and the Intergenerational Transmission of
         Human Capital: Evidence from College Openings.” Quarterly Journal of Economics 118:4, pp.
         1495-1532.

Dee, Thomas (2004). “Are There Civic Returns to Education?” Journal of Public Economics 88:9, pp.
       1697-1720.

Dynarski, Susan (2000). “Hope for Whom? Financial Aid for the Middle Class and Its Impact on College
       Attendance.” National Tax Journal 53:3, 629-661.

Dynarski, Susan (2002). “The Behavioral and Distributional Implications of Aid for College.” American
       Economic Review 92:2, 279-285.

Dynarski, Susan (2003). “Does Aid Matter? Measuring the Effect of Student Aid on College Attendance
       and Completion.” American Economic Review 93:1, 279-288.

Dynarski, Susan (2004). “The New Merit Aid,” in Caroline Hoxby, ed., College Choices: The Economics
       of Where to Go, When to Go, and How To Pay for It. Chicago: University of Chicago Press.

Ellwood, David (2001). “The Sputtering Labor Force of the 21st Century: Can Social Policy Help?” in
       Alan Krueger and Robert Solow, eds., The Roaring Nineties: Can Full Employment Be
       Sustained? New York: Russell Sage.

Ellwood, David and Thomas Kane (2000). “Who is Getting a College Education? Family Background and
       the Growing Gaps in Enrollment,” in Sheldon Danziger and Jane Waldfogel, eds., Securing the
       Future. New York: Russell Sage.

FPG Child Development Institute, University of North Carolina (2005). “Early Learning, Later Success:
      The Abecedarian Study, Early Childhood Educational Intervention for Poor Children: Executive
      Summary.” http://www.fpg.unc.edu/~abc/summary.cfm Accessed July 14, 2005.

Gruber, Jonathan and Emmanuel Saez (2001). “The Elasticity of Taxable Income: Evidence and
        Implications.” Journal of Public Economics 84:1, pp. 1-32.

Henry, Gary and Ross Rubenstein (2002). “Paying for Grades: Impact of Merit-based Financial Aid on
       Educational Quality.” Journal of Policy Analysis and Management 21:1, pp. 93-109.

Healy, Patrick (1997). “HOPE Scholarships Transform the University of Georgia.” The Chronicle of
        Higher Education, November 7, p. A32.

Jacob, Brian (2002). “Where the Boys Aren’t: Non-cognitive Skills, Returns to School and the Gender
        Gap in Higher Education.” Economics of Education Review 21, pp. 589-98.

Kane, Thomas J. (1994). “College Entry by Blacks since 1970: The Role of College Costs, Family
       Background, and the Returns to Education.” Journal of Political Economy 102:5, 878-911.

Kane, Thomas J. (2003). “A Quasi-Experimental Estimate of the Impact of Financial Aid on College-
       Going.” National Bureau of Economic Research Working Paper 9703,

Krueger, Alan and Diane Whitmore (2001). “The Effect of Attending a Small Class in the Early Grades
       on College-test Taking and Middle School Test Results: Evidence from Project Star.” Economic
       Journal 111 (January), pp. 1-28.


                                                  39
Leslie, Larry and Paul Brinkman. 1988. The Economic Value of Higher Education. New York:
         Macmillan.

Lleras-Muney, Adriana (2005) “The Relationship between Education and Adult Mortality in the United
       States,” Review of Economic Studies 72:1.

Lochner, Lance and Enrico Moretti (2004), “The Effect of Education on Crime: Evidence from Prison
       Inmates, Arrests, and Self-Reports,” American Economic Review, 94:1 (March), pp. 155-189.

Long, Bridget (2004). “How do Financial Aid Policies affect Colleges? The Institutional Impact of the
       Georgia HOPE Scholarship.” Journal of Human Resources 39:3.

Meyer, Bruce (1995). “Natural and Quasi-Natural Experiments in Economics.” Journal of Business and
       Economic Statistics 12, 151–162.

Milligan, Kevin, Enrico Moretti, and Philip Oreopoulos (2004). “Does Education Improve Citizenship?
        Evidence from the U.S. and the U.K.” Journal of Public Economics 88:9-10.

Moretti, Enrico (2004). “Estimating the Social Return to Higher Education: Evidence from Longitudinal
        and Repeated Cross-Sectional Data.” Journal of Econometrics 121:1-2 pp. 175-212.

National Center for Education Statistics, US Department of Education (2005). “Gender Differences in
       Participation and Completion of Undergraduate Education and How They Have Changed Over
       Time.” Washington, DC: Government Printing Office.

Oreopoulos, Philip, Marianne Page and Ann Stevens (2003). “Does Human Capital Transfer from Parent
       to Child? The Intergenerational Effects of Compulsory Schooling.” Unpublished manuscript,
       University of Toronto.

Organization for Economic Cooperation and Development (2004). Education at Glance: OECD
       Indicators 2004. Paris: OECD.

Salzer, Patrick (2005). “House Votes to Limit HOPE to 127 Credits.” The Atlanta Journal Constitution,
        February 22.

Seftor, Neil and Turner, Sarah (2002). “Back to School: Federal Student Aid Policy and Adult College
        Enrollment.” Journal of Human Resources 37:2, 336-352.

Stinebrickner, Ralph and and Todd Stinebricker (2003). “Understanding Educational Outcomes of
        Students from Low-Income Families.” Journal of Human Resources 38:3, 591-617.

Tinto, Vincent (1994). Leaving College: Rethinking the Causes and Cures of Student Attrition. Chicago:
        University of Chicago Press.

Turner, Sarah E. (2004) “Going to College and Finishing College: Explaining Different Educational
        Outcomes,” in Caroline Hoxby, ed., College Choices: The Economics of Where to Go, When to
        Go, and How To Pay for It. Chicago: University of Chicago Press.

Winston, Gordon (1999). “Subsidies, Hierarchy and Peers: The Awkward Economics of Higher
       Education.” Journal of Economic Perspectives 13:1, pp. 13-36.




                                                   40
                                      Table 1
                     College Experience vs. College Completion
                                    Age 25-34
                              2000 Census, 1% Sample

                                                                        Share of College
                     % with Any     % with College     % with College
                                                                          Entrants Not
                      College          Degree             Degree
                                                                         Completing a
                     Experience      (AA or BA)            (BA)
                                                                            Degree


Black or Hispanic      60.8%             26.8%             18.8%             56%

White Non-Hispanic     71.4%             44.8%             35.4%             37%
                                                            Table 2
                                                Sample Means, by State of Birth
                                                      22- to 34-year olds
                                                   Census 2000, 1% Sample


                                                               Arkansas           Georgia       Rest of South       Rest of US



Any College Experience                                           0.495             0.517             0.551             0.606
Any College Degree                                               0.223             0.260             0.282             0.337
Associate's Degree Only                                          0.058             0.060             0.068             0.083
Bachelor's Degree or Above                                       0.165             0.200             0.214             0.254
Nonhispanic White or Asian                                       0.786             0.682             0.707             0.783
Unemployment Rate in State of Birth, at Age 18                   0.072             0.056             0.066             0.064
N                                                                3,467             9,225            97,321            332,347




Notes: Means are unweighted. Observations with imputed values of education, age or state of birth are dropped. Unemployment rate
is that of young people, from Bureau of Labor Statistics. Mississippi, which introduced a merit program in the middle of the period
under analysis, is dropped from the sample.
                                             Table 3
                                   OLS Estimates of Effect of
                        Merit Aid Programs on College Degree Attainment
                                 22- to 34-year-olds, 2000 Census


                                               US
                                              (1)                     (2)                      (3)
                                          Micro Data             Cell Means,              Cell Means,
                                                                Weighted by N ab          Unweighted



Merit Aid Program                            0.0298                  0.0298                  0.0324
                                            (0.0082)                (0.0040)                (0.0040)



Age Fixed Effects                               Y                       Y                       Y

State of Birth Fixed Effects                    Y                       Y                       Y

N                                            345,039                   650                     650
Mean of Y                                      0.33                    0.33                    0.33




Notes:
Micro regression: Heteroskedasticity-adjusted standard error in parentheses.
Cell-mean regressions: standard errors adjusted for correlation within state of birth. Regression in Column
(2) weighted by number of observations within the age-state of birth cell.
                                              Table 4
                                 Robustness of Statistical Inference



   (1)     I. Micro Data                                                                     0.0298
           Alternative approaches to computing standard error
   (2)     no adjustment for autocorrelation                                                (0.0082)
   (3)     arbitrary variance-covariance in error term, by state of birth                   (0.0038)
   (4)     arbitrary variance-covariance in error term, by state of birth & age             (0.0096)


   (5)     II. Unconditional Cell Means                                                      0.0298
           Alternative approaches to computing standard error
   (6)     no adjustment                                                                    (0.0104)
   (7)     arbitrary variance-covariance in error term, by state of birth                   (0.0040)


   (8)     III. Eliminate Time Series Variation                                              0.0282
   (9)     before/after comparison of treatment state residuals                             (0.0030)


Notes: All methods of estimating the standard errors account for heteroskedasticity.
I. Micro Data : Specification consists of degree regressed on merit dummy, state of birth fixed effects
and age fixed effects.
II. Unconditional Cell Means : Same as micro regression but data aggregated to state-of-birth by age
cells and regression weighted by cell size.
III. Eliminate Time Series Variation: In microdata, outcome and treatment dummy regressed on state
of birth and age fixed effects. Residuals aggregated to state-of-birth-by-age cells and these means (for
treatment states only) regressed against treatment dummy.
                                               Table 5
                       Control for Labor Market Characteristics & Demographics



                                                                        (1)            (2)            (3)

Merit Eligibility                                                     0.0298         0.0282         0.0263
                                                                     (0.0040)       (0.0042)       (0.0053)



Cohort Size, Unemployment Rate & College Premium                                       Y              Y

Sex, Race, Ethnicity                                                                                  Y




Notes: All covariates are interacted with age dummies. State-age mean residuals from regressions that
include the listed covariates are the unit of observation. Regressions are weighted by cell size and
standard errors are adjusted for correlation at the state level. Cohort size is measured in the 2000 census
for age cohort within each state of birth. Return to college is for state of birth in year individual was 18
and is calculated from the 1984-96 March CPS among 35-54-year-olds; see text for details.
                                                               Table 6
                                       Sensitivity of Results to Choice of Comparison States



                                                                                                                                 Southern States
                                                                                                      States that Ever
                                                                                                                                     that Ever
                                                        US                 Southern States            Introduce Merit
                                                                                                                                 Introduce Merit
                                                                                                            Aid
                                                                                                                                       Aid

                                                        (1)                        (2)                         (3)                        (4)
    Merit Aid Program                                0.0298                      0.0278                     0.0264                     0.0229
                                                    (0.0040)                    (0.0079)                   (0.0048)                   (0.0060)

    Age Fixed Effects                                    Y                          Y                          Y                           Y
    State of Birth Fixed Effects                         Y                          Y                          Y                           Y
    N                                                  650                         208                        156                        117

    Mean of Y                                          0.33                       0.28                        0.28                       0.27


Notes:
Micro regressions: standard errors adjusted for correlation within state of birth in parentheses; within state of birth and age in brackets.
Cell-mean regressions: weighted by cell size with standard errors adjusted for correlation within state of birth.
                                                 Table 7
                                         Falsification Exercise
                       Assignment of Treatment Status Based of State of Residence



                                                      US                                  South
                                             (1)                (2)                (3)               (4)
                                          State of          State of           State of           State of
                                           Birth           Residence            Birth            Residence
Merit Aid Program                         0.0298             0.0039             0.0278             0.0000
                                         (0.0040)           (0.0149)           (0.0079)           (0.0176)

Age Fixed Effects                             Y                  Y                 Y                  Y
State of Birth Fixed Effects                  Y                                    Y
State of Residence Fixed Effects                                 Y                                    Y
N                                           650                650                208               208

Note: Regressions are at the level of cell means (age by state of birth in Columns (1) and (3) and age by state
of residence in Columns (2) and (4)). Regressions weighted by cell size. Standard errors adjusted for
correlation within state of birth (1 and 3) or state of residence (2 and 4).
                                                                    Table 8
                                                               Robustness Check:
                                       Linear, Quadratic and Non-Parametric Controls for Underlying Trends


                                                                                                                 Census Division             State of Residence
                                                              State of Birth X Age Trends
                                                                                                                  X Age Effects                X Age Effects
                             Baseline
                                                           Linear                     Quadratic                 Nonparametric                Nonparametric

                                 (1)                          (2)                          (3)                          (4)                          (5)
  United States               0.0298                       0.0221                       0.0216                       0.0235                        0.0416
                             (0.0040)                     (0.0136)                     (0.0209)                     (0.0145)                      (0.0120)

      South                   0.0278                       0.0245                       0.0344                       0.0235                        0.0318
                             (0.0079)                     (0.0183)                     (0.0235)                     (0.0149)                      (0.0140)


Notes: Dependent variable is state-age mean of degree. Regressions are weighted by cell size and standard errors are adjusted for correlation at the state level.
All regressions include state-of-birth and age fixed effects. Specification in Column (2) includes a separate linear trend in age for each state of birth.
Specification in Column (3) includes a separate quadratic trend in age for each state of birth. Column (4) includes a full set of age-effect X division interactions.
Column (5) includes a full set of age-effect X state-of-residence interactions.
                                                      Table 9
                                                 Robustness Check:
                                   Non-Parametric Controls for Age, by State of Birth

                                                                      US                                           South

                                                           (1)                    (2)                    (3)                    (4)
                                                       Baseline              Control for              Baseline             Control for
                                                                           State-of-Birth X                              State-of-Birth X
                                                                                 Age                                           Age
                                                         2000               1990 & 2000                 2000               1990 & 2000

Program Effect                                           0.0298                 0.0350                 0.0278                 0.0332
                                                        (0.0040)               (0.0205)               (0.0079)               (0.0218)

Age Dummies X State of Birth                                                      Y                                              Y
Age Dummies X Census Year                                                         Y                                              Y
Census Year X State of Birth                                                      Y                                              Y


N                                                         650                   1,300                    208                    416


Notes: Standard errors adjusted for heteroskedasticity and correlation within state of birth and census year All regressions are weighted by
cell size and include state-of-birth and age fixed effects.
                                                  Table 10
                              Correct for Measurement Error in Treatment Status
                                           US Sample, 22-34-year-olds



                                                                                                   0.0298
    (1)     Baseline                                                                              (0.0040)


    (2)     Predict State in Which High School Senior                                              0.0374
                                                                                                  (0.0054)

    (3)     Predict Year in Which High School Senior                                               0.0333
                                                                                                  (0.0057)

    (4)     Predict State and Year in Which High School Senior                                     0.0421
                                                                                                  (0.0057)



Notes:

Row (1): Treatment status is a deterministic function of age and state of birth.
Individuals are assumed to attend high school in state of birth and be a high school senior at age 18.

Row (2): Treatment status is a deterministic function of age and a probabilistic function of state of birth.
High-school age (15- to 17-year-old) individuals in the 2000 census are used to estimate a transition matrix between
state of birth and state of residence. Matrix is used to estimate the probability of residence in a merit-aid state during
high school for the analytical sample.


Row (3): Treatment status is a probabilistic function of age and a deterministic function of state of birth.
1989-1991 School Enrollment Supplements of the October CPS are used to estimate age-specific probabilities of being
a high school senior among 16- to 24-year-olds. Separate probabilities are estimated by sex-race. These probabilities
are used to estimate the probability of being a senior in each of the years from 1984 through 2000 for the analytical
sample. The sum of these probabilities is constrained to equal one.

Row (4): Treatment status is a probabilistic function of age and a probabilistic function of state of birth.
Methods of both Row (2) and Row (3) are used to predict treatment status.
                                Table 11
                  Program Effect by Level of Education
                      22- to 34-year-olds, US born



Effect on probability that education is
                                            coefficient      se
greater than or equal to…
No schooling
Nursery to 4                                 -0.0014      (0.0003)
5-6                                          -0.0010      (0.0003)
7-8                                          -0.0014      (0.0006)
9                                             0.0015      (0.0007)
10                                           -0.0017      (0.0048)
11                                           -0.0056      (0.0050)
12, no diploma                               -0.0064      (0.0087)
12, diploma                                  -0.0059      (0.0056)
 < 1 year college                             0.0159      (0.0100)
some college, no degree                       0.0194      (0.0042)
AA                                            0.0298      (0.0040)
BA                                            0.0252      (0.0044)
MA                                            0.0137      (0.0047)
Prof Degree                                   0.0046      (0.0020)
PhD                                           0.0012      (0.0003)
                                    Table 12
           Heterogeneity in Treatment Effects By Race, Ethnicity and Sex
                                   US Sample


                                             (1)                (2)                (3)
                                        Any College             BA
                                                                                AA Only
                                          Degree             or above

Full Sample                                0.0298             0.0252             0.0046
                                          (0.0040)           (0.0044)           (0.0025)

White Non-Hispanic Women                   0.0316             0.0229             0.0087
                                          (0.0048)           (0.0050)           (0.0020)

Nonwhite and Hispanic Women                0.0346             0.0082             0.0263
                                          (0.0214)           (0.0138)           (0.0082)

White Non-Hispanic Men                     0.0158             0.0193            -0.0035
                                          (0.0092)           (0.0050)           (0.0093)

Nonwhite and Hispanic Men                  0.0160             0.0279            -0.0120
                                          (0.0034)           (0.0047)           (0.0028)


Notes: Each coefficient represents a separate regression. Dependent variable is state-age
mean of degree for specified group. Regressions are weighted by cell size and standard
errors are adjusted for correlation at the state level. All regressions include state-of-birth
and age fixed effects.
                              Figure 1A: Proportion Holding a College Degree,
                                        by Age Cohort, Census 2000
                                           Arkansas vs. Rest of US
                                     Line indicates last pre-program year
40%




30%




20%




                              Rest of US
10%
                              AR




0%
      1984 (34)


                  1985 (33)


                              1986 (32)


                                          1987 (31)


                                                      1988 (30)


                                                                  1989 (29)


                                                                              1990 (28)


                                                                                          1991 (27)


                                                                                                      1992 (26)


                                                                                                                  1993 (25)


                                                                                                                              1994 (24)


                                                                                                                                          1995 (23)


                                                                                                                                                      1996 (22)
                                             Year in Which Age 18 (Age in Census 2000)
                                             Figure 1B: Proportion Holding a College Degree,
                                                       by Age Cohort, 2000 Census
                                                           Georgia vs. Rest of US
                                                    Line indicates last pre-program year
40%




30%




20%




10%                                       Rest of US
                                          GA



0%
      1984 (34)


                  1985 (33)


                              1986 (32)


                                               1987 (31)


                                                                1988 (30)


                                                                            1989 (29)


                                                                                        1990 (28)


                                                                                                    1991 (27)


                                                                                                                1992 (26)


                                                                                                                            1993 (25)


                                                                                                                                        1994 (24)


                                                                                                                                                    1995 (23)


                                                                                                                                                                1996 (22)
                                                           Year in Which Age 18 (Age in Census 2000)
                                                           Figure 2
0.10
                                   Effect of Merit Aid of Full Distribution of Education
                                              Plotted is effect on Pr(Educ>=X)
0.08


0.06


0.04


0.02


0.00




                                                                                     < 1 year college
        Nursery to 4




                                                                                                                                                        PhD
                                                                                                        some college, no


                                                                                                                           AA


                                                                                                                                BA


                                                                                                                                     MA
                       5-6


                             7-8


                                      9


                                            10


                                                 11




                                                                                                                                          Prof Degree
                                                                       12, diploma
                                                      12, no diploma
-0.02




                                                                                                            degree
-0.04


-0.06


-0.08


-0.10
                                                      Figure 3A
                               Effect of Merit Aid of Full Distribution of Education
0.10                                      Plotted is effect on Pr(Educ>=X)
                                            Non-Hispanic White Women
0.08


0.06


0.04


0.02


0.00




                                                                                  < 1 year college
        Nursery to 4




                                                                                                                                                     PhD
                                                                                                                        AA


                                                                                                                             BA


                                                                                                                                  MA
                       5-6


                             7-8


                                   9


                                        10


                                             11




                                                                                                     some college, no




                                                                                                                                       Prof Degree
                                                                    12, diploma
                                                   12, no diploma
-0.02




                                                                                                         degree
-0.04


-0.06


-0.08


-0.10
                                                      Figure 3B
                               Effect of Merit Aid of Full Distribution of Education
0.10                                      Plotted is effect on Pr(Educ>=X)
                                          Hispanic and Nonwhite Women
0.08


0.06


0.04


0.02


0.00




                                                                                  < 1 year college
        Nursery to 4




                                                                                                                                                     PhD
                                                                                                                        AA


                                                                                                                             BA


                                                                                                                                  MA
                       5-6


                             7-8


                                   9


                                        10


                                             11




                                                                                                     some college, no




                                                                                                                                       Prof Degree
                                                                    12, diploma
                                                   12, no diploma
-0.02




                                                                                                         degree
-0.04


-0.06


-0.08


-0.10
                                                      Figure 3C
                               Effect of Merit Aid of Full Distribution of Education
0.10                                      Plotted is effect on Pr(Educ>=X)
                                              Non-Hispanic White Men
0.08


0.06


0.04


0.02


0.00




                                                                                  < 1 year college
        Nursery to 4




                                                                                                                                                     PhD
                                                                                                                        AA


                                                                                                                             BA


                                                                                                                                  MA
                       5-6


                             7-8


                                   9


                                        10


                                             11




                                                                                                     some college, no




                                                                                                                                       Prof Degree
                                                                    12, diploma
                                                   12, no diploma
-0.02




                                                                                                         degree
-0.04


-0.06


-0.08


-0.10
                                                      Figure 3D
                               Effect of Merit Aid of Full Distribution of Education
0.10                                      Plotted is effect on Pr(Educ>=X)
                                            Hispanic and Nonwhite Men
0.08


0.06


0.04


0.02


0.00




                                                                                  < 1 year college
        Nursery to 4




                                                                                                                                                     PhD
                                                                                                                        AA


                                                                                                                             BA


                                                                                                                                  MA
                       5-6


                             7-8


                                   9


                                        10


                                             11




                                                                                                     some college, no




                                                                                                                                       Prof Degree
                                                                    12, diploma
                                                   12, no diploma
-0.02




                                                                                                         degree
-0.04


-0.06


-0.08


-0.10
                                                       Appendix Table 1
                                                   State Merit Aid Programs




                                                                                                    Award
    State        Start                        Eligibility
                                                                                                 In-State Only
Arkansas         1991     initial: 2.5 GPA in HS core & 19 ACT                public: up to $2,500*
                          renew: 2.75 college GPA                             private: same
Florida          1997     initial: 3.0-3.5 HS GPA & 970-1270 SAT/20-28 public: 75-100% tuition/fees*
                          renew: 2.75-3.0 college GPA                         private: 75-100% avg public tuition/fees*
Georgia          1993     initial: 3.0 HS GPA                                 public: tuition/fees
                          renew: 3.0 college GPA                              private: $3,000
Kentucky         1999     initial: 2.5 HS GPA                                 public: $500-3,000*
                          renew: 2.5-3.0 college GPA                          private: same
Louisiana        1998     initial: 2.5-3.5 HS GPA & ACT > state mean          public: tuition/fees + $400-800*
                          renew: 2.3 college GPA                              private: avg public tuition/fees*
Maryland         2002     initial: 3.0 HS GPA in core                         2-yr school - $1,000
                          renew: 3.0 college GPA                              4-yr school - $3,000
Michigan         2000                                       th                in-state: $2,500 once
                          initial: level 2 of MEAP or 75 pctile of
                          renew: NA                                           out-of-state: $1,000 once
Mississippi      1996     initial: 2.5 GPA & 15 ACT                           fresh/soph: $500
                          renew: 2.5 college GPA                              jr/sr: $1,000
Nevada           2000     initial: 3.0 GPA & pass Nevada HS exam              public 4 yr: tuition/fees (max $2,500)
                          renew: 2.0 college GPA                              public 2-yr: tuition/fees (max $1,900)
New Mexico       1997                         st                              public: tuition/fees
                          initial: 2.5 GPA 1 semester of college
                          renew: 2.5 college GPA                              private: none
S. Carolina      1998     initial: 3.0 GPA & 1100 SAT/24 ACT                  2-yr school - $1,000
                          renew: 3.0 college GPA                              4-yr school - $2,000
Tennessee**      2003     initial:   3.0 college GPA or 890 SAT/19 ACT        2-yr school - $1,500 or tuition and fees
                          renew:     2.75 - 3.0 college GPA                   4-yr school - $3,000 or tuition and fees
W. Virginia      2002     initial: 3.0 HS GPA in core & 1000 SAT/21           public: tuition/fees
                          renew: 2.75-3.0 college GPA                         private: avg public tuition/fees

*award varies with test score or GPA
** Award valid at all institutions in the Southern Association of Schools and Colleges
                                                Appendix Table 2
                                   Census 2000 Educational Attainment Question


What is the highest degree or level of school this person has COMPLETED? Mark ONE box. If currently
enrolled, mark the previous grade or highest degree received.


01      No schooling completed
02      Nursery school to 4th grade
03      5th grade or 6th grade
04      7th grade or 8th grade
05      9th grade
06      10th grade
07      11th grade
08      12th grade, NO DIPLOMA
09      HIGH SCHOOL GRADUATE — high school DIPLOMA or the equivalent (for example: GED)
10      Some college credit, but less than 1 year
11      1 or more years of college, no degree
12      Associate degree (for example: AA, AS)

13      Bachelor’s degree (for example: BA, AB, BS)
14      Master’s degree (for example: MA, MS, MEng, MEd, MSW, MBA)
15      Professional degree (for example: MD, DDS, DVM, LLB, JD)
16      Doctorate degree (for example: PhD, EdD)
