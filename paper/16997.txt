                                 NBER WORKING PAPER SERIES




            QUANTILE REGRESSION WITH CENSORING AND ENDOGENEITY

                                         Victor Chernozhukov
                                          Iván Fernández-Val
                                         Amanda E. Kowalski

                                         Working Paper 16997
                                 http://www.nber.org/papers/w16997


                       NATIONAL BUREAU OF ECONOMIC RESEARCH
                                1050 Massachusetts Avenue
                                  Cambridge, MA 02138
                                       April 2011




We thank Denis Chetverikov and Sukjin Han for excellent comments and capable research assistance.
We are grateful to Richard Blundell for providing us the data for the empirical application. Stata software
to implement the methods developed in the paper is available in Amanda Kowalski's web site at
                   http://www.econ.yale.edu/ak669/research.html. We gratefully acknowledge research
support from the NSF. The views expressed herein are those of the authors and do not necessarily
reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2011 by Victor Chernozhukov, Iván Fernández-Val, and Amanda E. Kowalski. All rights reserved.
Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided
that full credit, including © notice, is given to the source.
Quantile Regression with Censoring and Endogeneity
Victor Chernozhukov, Iván Fernández-Val, and Amanda E. Kowalski
NBER Working Paper No. 16997
April 2011
JEL No. C14

                                               ABSTRACT

In this paper, we develop a new censored quantile instrumental variable (CQIV) estimator and describe
its properties and computation. The CQIV estimator combines Powell (1986) censored quantile regression
(CQR) to deal semiparametrically with censoring, with a control variable approach to incorporate
endogenous regressors. The CQIV estimator is obtained in two stages that are nonadditive in the unobservables.
The first stage estimates a nonadditive model with infinite dimensional parameters for the control
variable, such as a quantile or distribution regression model. The second stage estimates a nonadditive
censored quantile regression model for the response variable of interest, including the estimated control
variable to deal with endogeneity. For computation, we extend the algorithm for CQR developed by
Chernozhukov and Hong (2002) to incorporate the estimation of the control variable. We give generic
regularity conditions for asymptotic normality of the CQIV estimator and for the validity of resampling
methods to approximate its asymptotic distribution. We verify these conditions for quantile and distribution
regression estimation of the control variable. We illustrate the computation and applicability of the
CQIV estimator with numerical examples and an empirical application on estimation of Engel curves
for alcohol.


Victor Chernozhukov                                   Amanda E. Kowalski
Department of Economics                               Department of Economics
Massachusetts Institute of Technology                 Yale University
Cambridge, MA 02142                                   37 Hillhouse Avenue
vchern@mit.edu                                        Room 32, Box 208264
                                                      New Haven, CT 06520
Iván Fernández-Val                                    and NBER
Department of Economics                               amanda.kowalski@yale.edu
Boston University
270 Bay State Rd
Boston, MA 02215
ivanf@bu.edu
2

                                     1. Introduction

   Censoring and endogeneity are common problems in data analysis. For example, income
survey data are often top-coded and many economic variables such as hours worked, wages
and expenditure shares are naturally bounded from below by zero. Endogeneity is also an
ubiquitous phenomenon both in experimental studies due to partial noncompliance (Angrist,
Imbens, and Rubin, 1996), and in observational studies due to simultaneity (Koopmans
and Hood, 1953), measurement error (Frish, 1934), sample selection (Heckman, 1979) or
more generally to the presence of relevant omitted variables. Censoring and endogeneity
often come together. Thus, for example, we motivate our analysis with the estimation of
Engel curves for alcohol – the relationship between the share of expenditure on alcohol
and the household’s budget. For this commodity, more than 15% of the households in our
sample report zero expenditure, and economic theory suggests that total expenditure and
its composition are jointly determined in the consumption decision of the household. Either
censoring or endogeneity lead to inconsistency of traditional mean and quantile regression
estimators by inducing correlation between regressors and error terms. We introduce a
quantile regression estimator that deals with both problems and name this estimator the
censored quantile instrumental variable (CQIV) estimator.
   Our procedure deals with censoring semiparametrically through the conditional quantile
function following Powell (1986). This approach avoids the strong parametric assumptions
of traditional Tobit estimators. The key ingredient here is the equivariance property of
quantile functions to monotone transformations such as censoring. Powell’s censored quan-
tile regression estimator, however, has proven to be difficult to compute. We address this
problem using the computationally attractive algorithm of Chernozhukov and Hong (2002).
An additional advantage of focusing on the conditional quantile function is that we can cap-
ture nonadditive heterogeneity in the effects of the regressors across the distribution of the
response variable by computing CQIV at different quantiles (Koenker, 2005). The traditional
Tobit framework rules out this heterogeneity by imposing a location shift model.
  We deal with endogeneity using a control variable approach. The basic idea is to add a
variable to the regression such that, once we condition on this variable, regressors and error
terms become independent. This so-called control variable is usually unobservable and need
to be estimated in a first stage. Our main contribution here is to allow for semiparametric
models with infinite dimensional parameters and nonadditive error terms, such as quantile
regression and distribution regression, to model and estimate the first stage and back out the
control variable. This part of the analysis constitutes the main theoretical difficulty because
the first stage estimators do not live in spaces with nice entropic properties, unlike, for
example, in Andrews (1994) or Newey (1994). To overcome this problem, we develop a new
                                                                                             3

technique to derive asymptotic theory for two-stage procedures with plugged-in first stage
estimators that, while not living in Donsker spaces themselves, can be suitably approximated
by random functions that live in Donsker spaces. The CQIV estimator is therefore obtained
in two stages that are nonadditive in the unobservables. The first stage estimates the control
variable, whereas the second stage estimates a nonadditive censored quantile regression model
for the response variable of interest, including the estimated control variable to deal with
endogeneity.
   We analyze the theoretical properties of the CQIV estimator in large samples. Under suit-
                                      √
able regularity conditions, CQIV is n-consistent and has a normal limiting distribution.
We characterize the expression of the asymptotic variance. Although this expression can be
estimated using standard methods, we find it more convenient to use resampling methods
for inference. We focus on weighted bootstrap because it has practical advantages over non-
parametric bootstrap to deal with discrete regressors with small cell sizes (Ma and Kosorok,
2005, and Chen and Pouzo, 2009). We give regularity conditions for the consistency of
weighted bootstrap to approximate the distribution of the CQIV estimator. For our leading
cases of quantile and distribution regression estimation of the control variable, we provide
more primitive assumptions that verify the regularity conditions for asymptotic normality
and weighted bootstrap consistency. The verification of these conditions for quantile and
distribution regression estimators of the first stage is new to the best of our knowledge.
   The CQIV estimator is simple to compute using standard statistical software. We demon-
strate its implementation through Monte-Carlo simulations and an empirical application to
the estimation of Engel curves for alcohol. The results of the Monte-Carlo exercise demon-
strate that the performance of CQIV is comparable to that of Tobit IV in data generated
to satisfy the Tobit IV assumptions, and it outperforms Tobit IV under heteroskedasticity.
The results of the application to Engel curves demonstrate the importance of accounting for
endogeneity and censoring in real data. Another application of our CQIV estimator to the
estimation of the price elasticity of expenditure on medical care appears in Kowalski (2009).


1.1. Literature review. There is an extensive previous literature on the control variable
approach to deal with endogeneity in models without censoring. Hausman (1978) and
Wooldridge (2010) discussed parametric triangular linear and nonlinear models. Newey,
Powell, and Vella (1999) described the use of this approach in nonparametric triangular sys-
tems of equations for the conditional mean, but limited the analysis to models with additive
errors both in the first and the second stage. Lee (2007) set forth an estimation strategy
using a control variable approach for a triangular system of equations for conditional quan-
tiles with an additive nonparametric first stage. Imbens and Newey (2002, 2009) extended
the analysis to triangular nonseparable models with nonadditive error terms in both the
4

first and second stage. They focused on identification and nonparametric estimation rates
for average, quantile and policy effects. Our paper complements Imbens and Newey (2002,
2009) by providing inference methods and allowing for censoring. Chesher (2003) and Jun
(2009) considered local identification and semiparametric estimation of uncensored trian-
gular quantile regression models with a nonseparable control variable. Relative to CQIV,
these local methods impose less structure in the model at the cost of slower rates of con-
vergence in estimation. While the previous papers focused on triangular models, Blundell
and Matzkin (2010) have recently derived conditions for the existence of control variables
in nonseparable simultaneous equations models. We refer also to Matzkin (2007) for an
excellent comprehensive review of results on nonparametric identification of triangular and
simultaneous equations models.
   Our work is also closely related to Ma and Koenker (2006). They considered identifica-
tion and estimation of quantile effects without censoring using a parametric control variable.
Their parametric assumptions rule out the use of nonadditive models with infinite dimen-
sional parameters in the first stage, such as quantile and distribution regression models in
the first stage. In contrast, our approach is specifically designed to handle the latter, and
in doing so, it puts the first stage and second stage models on the equally flexible foot-
ing. Allowing for a nonadditive infinite dimensional control variable makes the analysis of
the asymptotic properties of our estimator very delicate and requires developing new proof
techniques. In particular, we need to deal with control variable estimators depending on
random functions that do not live in Donsker classes. We address this difficulty approx-
imating these functions with sufficient degree of accuracy by smoother functions that live
in Donsker classes. In the case of quantile and distribution regression, we carry out this
approximation by smoothing the empirical quantile regression and distribution regression
processes using third order kernels.
   For models with censoring, the literature is more sparse. Smith and Blundell (1986) pio-
neered the use of the control variable approach to estimate a triangular parametric additive
model for the conditional mean. More recently, Blundell and Powell (2007) proposed an
alternative censored quantile instrumental variable estimator that assumes additive errors in
the first stage. Our estimator allows for a more flexible nonadditive first stage specification.



1.2. Plan of the paper. The rest of the paper is organized as follows. In Section 2, we
present the CQIV model, and develop estimation and inference methods for the parameters of
interest of this model. In Section 3, we describe the associated computational algorithms and
present results from a Monte-Carlo simulation exercise. In Section 4, we present an empirical
application of CQIV to Engel curves. In Section 5, we provide conclusions and discuss
                                                                                                          5

potential empirical applications of CQIV. The proofs of the main results, and additional
details on the computational algorithms and numerical examples are given in the Appendix.

             2. Censored Quantile Instrumental Variable Regression

2.1. The Model. We consider the following triangular system of quantile equations:

                                       Y     = max(Y ∗ , C),                                          (2.1)
                                      Y ∗ = QY ∗ (U | D, W, V ),                                      (2.2)
                                      D = QD (V | W, Z).                                              (2.3)

In this system, Y ∗ is a continuous latent response variable, the observed variable Y is ob-
tained by censoring Y ∗ from below at the level determined by the variable C, D is the
continuous regressor of interest, W is a vector of covariates, possibly containing C, V is a
latent unobserved regressor that accounts for the possible endogeneity of D, and Z is a vec-
tor of “instrumental variables” excluded from (2.2).1 Further, u 7→ QY ∗ (u | D, W, V ) is the
conditional quantile function of Y ∗ given (D, W, V ); and v 7→ QD (v | W, Z) is the conditional
quantile function of the regressor D given (W, Z). Here, U is a Skorohod disturbance for Y
that satisfies the independence assumption

                                     U ∼ U (0, 1) | D, W, Z, V, C,

and V is a Skorohod disturbance for D that satisfies

                                           V ∼ U (0, 1) | W, Z, C.

In the last two equations, we make the assumption that the censoring variable C is inde-
pendent of the disturbances U and V . This variable can, in principle, be included in W . To
recover the conditional quantile function of the latent response variable in equation (2.2),
it is important to condition on an unobserved regressor V which plays the role of a “con-
trol variable.” Equation (2.3) allows us to recover this unobserved regressor as a residual
that explains movements in the variable D, conditional on the set of instruments and other
covariates.
  In the Engel curve application, Y is the expenditure share in alcohol, bounded from below
at C = 0, D is total expenditure on nondurables and services, W are household demographic
characteristics, and Z is labor income measured by the earnings of the head of the household.
Total expenditure is likely to be jointly determined with the budget composition in the
household’s allocation of income across consumption goods and leisure. Thus, households
1We   focus on left censored response variables without loss of generality. If Y is right censored at C, Y =
min(Y ∗ , C), the analysis of the paper applies without change to Ye = −Y , Ye ∗ = −Y ∗ , C    e = −C, and
                         e        e ∗ e
QYe ∗ = −QY , because Y = max(Y , C).
             ∗
6

with a high preference to consume “non-essential” goods such as alcohol tend to expend a
higher proportion of their incomes and therefore to have a higher expenditure. The control
variable V in this case is the marginal propensity to consume, measured by the household
ranking in the conditional distribution of expenditure given labor income and household
characteristics. This propensity captures unobserved preference variables that affect both the
level and composition of the budget. Under the conditions for a two stage budgeting decision
process (Gorman, 1959), where the household first divides income between consumption
and leisure/labor and then decide the consumption allocation, some sources of income can
provide plausible exogenous variation with respect to the budget shares. For example, if
preferences are weakly separable in consumption and leisure/labor, the consumption budget
shares do not depend on labor income given the consumption expenditure (see, e.g., Deaton
and Muellbauer, 1980). This justifies the use of labor income as an exclusion restriction.
   An example of a structural model that has the triangular representation (2.2)-(2.3) is the
following system of equations:

                                    Y ∗ = gY (D, W, ²),                                  (2.4)
                                     D = gD (W, Z, V ),                                  (2.5)

where gY and gD are increasing in their third arguments, and ² ∼ U (0, 1) and V ∼ U (0, 1)
independent of (W, Z, C). By the Skorohod representation for ², ² = Q² (U | V ) = g² (V, U ),
where U ∼ U (0, 1) independent of (D, W, Z, V, C). The corresponding conditional quantile
functions have the form of (2.2) and (2.3) with

                         QY ∗ (u | D, W, V ) = gY (D, W, g² (V, u)),
                             QD (v | W, Z) = gD (W, Z, v).

In the Engel curve application, we can interpret V as the marginal propensity to consume out
of labor income and U as the unobserved household preference to spend on alcohol relative
to households with the same characteristics W and marginal propensity to consume V .
  In the system of equations (2.1)–(2.3), the observed response variable has the quantile
representation

                   Y = QY (U | D, W, V, C) = max(QY ∗ (U | D, W, V ), C),                (2.6)

by the equivariance property of the quantiles to monotone transformations. For example,
the quantile function for the observed response in the system of equations (2.4)–(2.5) has
the form:
                     QY (u | D, W, V, C) = max{gY (D, W, g² (V, u)), C}.
                                                                                                 7

Whether the response of interest is the latent or observed variable depends on the source of
censoring (e.g., Wooldridge, 2010). When censoring is due to data limitations such as top-
coding, we are often interested in the conditional quantile function of the latent response
variable QY ∗ and marginal effects derived from this function. For example, in the system
(2.4)–(2.5) the marginal effect of the endogenous regressor D evaluated at (D, W, V, U ) =
(d, w, v, u) is
                          ∂d QY ∗ (u | d, w, v) = ∂d gY (d, w, g² (v, u)),
which corresponds to the ceteris paribus effect of a marginal change of D on the latent
response Y ∗ for individuals with (D, W, ²) = (d, w, g² (v, u)). When the censoring is due
to economic or behavioral reasons such are corner solutions, we are often interested in the
conditional quantile function of the observed response variable QY and marginal effects
derived from this function. For example, in the system (2.4)–(2.5) the marginal effect of the
endogenous regressor D evaluated at (D, W, V, U, C) = (d, w, v, u, c) is

              ∂d QY (u | d, w, v, c) = 1{gY (d, w, g² (v, u)) > c}∂d gY (d, w, g² (v, u)),

which corresponds to the ceteris paribus effect of a marginal change of D on the observed
response Y for individuals with (D, W, ², C) = (d, w, g² (v, u), c). Since either of the marginal
effects might depend on individual characteristics, average marginal effects or marginal effects
evaluated at interesting values are often reported.




2.2. Generic Estimation. To make estimation both practical and realistic, we impose a
flexible semiparametric restriction on the functional form of the conditional quantile function
in (2.2). In particular, we assume that

                        QY ∗ (u | D, W, V ) = X 0 β0 (u), X = x(D, W, V ),                   (2.7)

where x(D, W, V ) is a vector of transformations of the initial regressors (D, W, V ). The
transformations could be, for example, polynomial, trigonometric, B-spline or other basis
functions that have good approximating properties for economic problems. An important
property of this functional form is linearity in parameters, which is very convenient for
computation. The resulting conditional quantile function of the censored random variable

                                         Y = max(Y ∗ , C),

is given by
                             QY (u | D, W, V, C) = max(X 0 β0 (u), C).                       (2.8)
This is the standard functional form for the censored quantile regression (CQR) first derived
by Powell (1984) in the exogenous case.
8

   Given a random sample {Yi , Di , Wi , Zi , Ci }ni=1 , we form the estimator for the parameter
β0 (u) as
                                                n
                    b                      1 X b0                       b 0 β),
                   β(u) = arg min                   1(Si γ
                                                         b > ς)ρu (Yi − X i                 (2.9)
                               β∈Rdim(X) n
                                               i=1
where ρu (z) = (u − 1(z < 0))z is the asymmetric absolute loss function of Koenker and
Bassett (1978), X bi = x(Di , Wi , Vbi ), Sbi = s(X
                                                  bi , Ci ), s(X, C) is a vector of transformations
of (X, C), and Vbi is an estimator of Vi . This estimator adapts the algorithm for the CQR
estimator developed in Chernozhukov and Hong (2002) to deal with endogeneity. We call
the multiplier 1(Sbi0 γ
                      b > ς) the selector, as its purpose is to predict the subset of individuals
for which the probability of censoring is sufficiently low to permit using a linear – in place
of a censored linear – functional form for the conditional quantile. We formally state the
conditions on the selector in the next subsection. The estimator in (2.9) may be seen as a
computationally attractive approximation to Powell estimator applied to our case:
                                                      n
                                                   1X
                       βbp (u) = arg     min                          b 0 β, Ci )].
                                                         ρu [Yi − max(Xi
                                       β∈Rdim(X)   n i=1

   The CQIV estimator will be computed using an iterative procedure where each step will
take the form specified in equation (2.9). We start selecting the set of “quantile-uncensored”
observations for which the conditional quantile function is above the censoring point. We
implement this step by estimating the conditional probabilities of censoring using a flexible
binary choice model. Quantile-uncensored observations have probability of censoring lower
than the quantile index u. We estimate the linear part of the conditional quantile function,
Xi0 β0 (u), on the sample of quantile-uncensored observations by standard quantile regression.
Then, we update the set of quantile-uncensored observations by selecting those observations
with conditional quantile estimates that are above their censoring points and iterate. We
provide more practical implementation details in the next section.
   The control variable V can be estimated in several ways. Note that if QD (v | W, Z) is
invertible in v, the control variable has several equivalent representations:
                                                           Z 1
                                          −1
  V = ϑ0 (D, W, Z) ≡ FD (D | W, Z) ≡ QD (D | W, Z) ≡           1{QD (v | W, Z) ≤ D}dv. (2.10)
                                                                    0

For any estimator of FD (D | W, Z) or QD (V | W, Z), denoted by FbD (D | W, Z) or Q bD (V |
W, Z), based on any parametric or semi-parametric functional form, the resulting estimator
for the control variable is
                                                           Z 1
          b
     Vb = ϑ(D,                                b
               W, Z) ≡ FbD (D | W, Z) or Vb = ϑ(D, W, Z) ≡       bD (v | W, Z) ≤ D}dv.
                                                               1{Q
                                                                        0

 Here we consider several examples: in the classical additive location model, we have that
QD (v | W, Z) = R0 π0 + QV (v), where QV is a quantile function, and R = r(W, Z) is a vector
                                                                                                 9

collecting transformations of W and Z. The control variable is

                                     V = Q−1      0
                                          V (D − R π0 ),

which can be estimated by the empirical CDF of the least squares residuals. Chernozhukov,
Fernandez-Val and Melly (2009) developed asymptotic theory for this estimator. If D |
W, Z ∼ N (R0 π0 , σ 2 ), the control variable has the common parametric form V = Φ−1 ([D −
R0 π0 ]/σ), where Φ−1 denotes the quantile function of the standard normal distribution. This
control variable can be estimated by plugging in estimates of the regression coefficients and
residual variance.
  In a non-additive quantile regression model, we have that QD (v | W, Z) = R0 π0 (v), and
                                             Z 1
                              −1
                      V = QD (D | W, Z) =        1{R0 π0 (v) ≤ D}dv.
                                                          0

The estimator takes the form
                                         Z       1
                                  Vb =               1{R0 π
                                                          b(v) ≤ D}dv,                     (2.11)
                                             0

where π
      b(v) is the Koenker and Bassett (1978) quantile regression estimator and the integral
can be approximated numerically using a finite grid of quantiles. The use of the integral to
obtain a generalized inverse is convenient to avoid monotonicity problems in v 7→ R0 π
                                                                                     b(v) due
to misspecification or sampling error. Chernozhukov, Fernandez-Val, and Galichon (2010)
developed asymptotic theory for this estimator.
  We can also estimate ϑ0 using distribution regression. In this case we consider a semi-
parametric model for the conditional distribution of D to construct a control variable

                              V = FD (D | W, Z) = Λ(R0 π0 (D)),

where Λ is a probit or logit link function. The estimator takes the form

                                         Vb = Λ(R0 π
                                                   b(D)),

where πb(d) is the maximum likelihood estimator of π0 (d) at each d (see, e.g., Foresi and Per-
acchi, 1995, and Chernozhukov, Fernandez-Val and Melly, 2009). Chernozhukov, Fernandez-
Val and Melly (2009) developed asymptotic theory for this estimator.


2.3. Regularity Conditions for Estimation. In what follows, we shall use the following
notation. We let the random vector A = (Y, D, W, Z, C, X, V ) live on some probability
space (Ω0 , F0 , P ). Thus, the probability measure P determines the law of A or any of its
elements. We also let A1 , ..., An , i.i.d. copies of A, live on the complete probability space
(Ω, F, P), which contains the infinite product of (Ω0 , F0 , P ). Moreover, this probability space
can be suitably enriched to carry also the random weights that will appear in the weighted
10

bootstrap. The distinction between the two laws P and P is helpful to simplify the notation
in the proofs and in the analysis. Calligraphic letter such as Y and X denote the support
of Y and X; and YX denotes the joint support of (Y, X). Unless explicitly mentioned, all
functions appearing in the statements are assumed to be measurable.
     We now state formally the assumptions. The first assumption is our model.

Assumption 1 (Model). We have {Yi , Di , Wi , Zi , Ci }ni=1 , a sample of size n of independent
and identically distributed observations from the random vector (Y, D, W, Z, C) which obeys
the model assumptions stated in equations (2.7) - (2.10), i.e.

           QY (u | D, W, Z, V, C) = QY (u | X, C) = max(X 0 β0 (u), C), X = x(D, W, V ),
           V = ϑ0 (D, W, Z) ≡ FD (D | W, Z) ∼ U (0, 1) | W, Z.

  The second assumption imposes compactness and smoothness conditions. Compactness
can be relaxed at the cost of more complicated and cumbersome proofs, while the smoothness
conditions are fairly tight.

Assumption 2 (Compactness and smoothness). (a) The set YDWZCX is compact. (b)
The endogenous regressor D has a continuous conditional density fD (· | w, z) that is bounded
above by a constant uniformly in (w, z) ∈ WZ. (c) The random variable Y has a conditional
density fY (y | x, c) on (c, ∞) that is uniformly continuous in y ∈ (c, ∞) uniformly in (x, c) ∈
X C, and bounded above by a constant uniformly in (x, c) ∈ X C. (d) The derivative vector
∂v x(d, w, v) exists and its components are uniformly continuous in v ∈ [0, 1] uniformly in
(d, w) ∈ DW, and are bounded in absolute value by a constant, uniformly in (d, w, v) ∈
DWV.

  The following assumption is a high-level condition on the function-valued estimator of
the control variable. We assume that it has an asymptotic functional linear representation.
Moreover, this functional estimator, while not necessarily living in a Donsker class, can be
approximated by a random function that does live in a Donsker class. We will fully verify this
condition for the case of quantile regression and distribution regression under more primitive
conditions.

Assumption 3 (Estimator of the control variable). We have an estimator of the control
                          b
variable of the form Vb = ϑ(D, W, Z), such that uniformly over (d, w, z) ∈ DWZ, (a)
                                        X  n
       √
         b w, z) − ϑ0 (d, w, z)) = √1
      n(ϑ(d,                                `(Ai , d, w, z) + oP (1), EP [`(A, d, w, z)] = 0,
                                      n i=1
                                        P
where EP [`(A, D, W, Z)2 ] < ∞ and k √1n ni=1 `(Ai , ·)k∞ = OP (1), and (b)
                                              √
                                  e ∞ = oP (1/ n), for ϑe ∈ Υ,
                            kϑb − ϑk
                                                                                              11

where the entropy of the function class Υ is not too high, namely

                    log N (², Υ, k · k∞ ) . 1/(² log2 (1/²)), for all 0 < ² < 1.

   The following assumptions are on the selector. The first part is a high-level condition on
the estimator of the selector. The second part is a smoothness condition on the index that
defines the selector. We shall verify that the CQIV estimator can act as a legitimate selector
itself. Although the statement is involved, this condition can be easily satisfied as explained
below.

Assumption 4 (Selector). (a) The selection rule has the form

                                     1[s(x(D, W, Vb ), C)0 γ
                                                           b > ς],

                      b →P γ0 and, for some ²0 > 0,
for some ς > 0, where γ

                1[S 0 γ0 > ς/2] ≤ 1[X 0 β0 (u) > C + ²0 ] ≤ 1[X 0 β0 (u) > C] P -a.e.,

where S = s(X, V ) and 1[X 0 β0 (u) > C] ≡ 1[P (Y = C | Z, W, V ) < u]. (b) The set S
is compact. (c) The density of the random variable s(x(D, W, ϑ(D, W, Z)), C)0 γ exists and
is bounded above by a constant, uniformly in γ ∈ Γ and in ϑ ∈ Υ, where Γ is an open
neighborhood of γ0 and Υ is defined in Assumption 3. (d) The components of the derivative
vector ∂v s(x(d, w, v), c) are uniformly continuous at each v ∈ [0, 1], uniformly in (d, w, c) ∈
DWC, and are bounded in absolute value by a constant, uniformly in (d, w, v, c) ∈ DWVC.

  The next assumption is a sufficient condition to guarantee local identification of the pa-
                              √
rameter of interest as well as n-consistency and asymptotic normality of the estimator.

Assumption 5 (Identification and non-degeneracy). (a) The matrix

                       J(u) := EP [fY (X 0 β0 (u) | X, C)XX 0 1(S 0 γ0 > ς)]

is of full rank. (b) The matrix

                                    Λ(u) := VarP [f (A) + g(A) ],

is finite and is of full rank, where

                         f (A) := {1(Y < X 0 β0 (u)) − u}X1(S 0 γ0 > ς),

and, for Ẋ = ∂v x(D, W, v)|v=V ,
                                                                                     ¯
           g(A) := EP [fY (X 0 β0 (u) | X, C)X Ẋ 0 β0 (u)1(S 0 γ0 > ς)`(a, D, W, Z)]¯a=A .

  Assumption 4(a) requires the selector to find a subset of the quantile-censored observations,
whereas Assumption 5 requires the selector to find a nonempty subset. Given βb0 (u), an initial
consistent estimator of β0 (u), we can form the selector as 1[s(x(D, W, Vb ), C)0 γ
                                                                                  b > ς], where
12

                                            b = [βb0 (u)0 , −1]0 , and ς is a small fixed cut-off that
s(x(D, W, Vb ), C) = [x(D, W, Vb )0 , C]0 , γ
ensures that the selector is asymptotically conservative but nontrivial. To find βb0 (u), we use
a selector based on a flexible model for the probability of censoring. This model does not
need to be correctly specified under a mild separating hyperplane condition for the quantile-
uncensored observations (Chernozhukov and Hong, 2002). Alternatively, we can estimate a
fully nonparametric model for the censoring probabilities. We do not pursue this approach
to preserve the computational appeal of the CQIV estimator.

2.4. Main Estimation Results. The following result states that the CQIV estimator is
                                                √
consistent, converges to the true parameter at a n rate, and is normally distributed in large
samples.
Theorem 1 (Asymptotic distribution of CQIV). Under the stated assumptions
                 √
                      b − β0 (u)) →d N (0, J −1 (u)Λ(u)J −1 (u)).
                   n(β(u)

   We can estimate the variance-covariance matrix using standard methods and carry out
analytical inference based on the normal distribution. Estimators for the components of the
variance can be formed, e.g., following Powell (1991) and Koenker (2005). However, this
is not very convenient for practice due to the complicated form of these components and
the need to estimate conditional densities. Instead, we suggest using weighted bootstrap
(Chamberlain and Imbens, 2003, Ma and Kosorok, 2005, Chen and Pouzo, 2009) and prove
its validity in what follows.
   We focus on weighted bootstrap because it has practical advantages over nonparametric
bootstrap to deal with discrete regressors with small cell sizes and the proof of its consistency
is not overly complex, following the strategy set forth by Ma and Kosorok (2005). Moreover,
a particular version of the weighted bootstrap, with exponentials acting as weights, has a
nice Bayesian interpretation (Chamberlain and Imbens, 2003).
     To describe the weighted bootstrap procedure in our setting, we first introduce the “weights”.
Assumption 6 (Bootstrap weights). The weights (e1 , ..., en ) are i.i.d. draws from a random
variable e ≥ 0, with EP [e] = 1 and VarP [e] = 1, living on the probability space (Ω, F, P) and
are independent of the data {Yi , Di , Wi , Zi , Ci }ni=1 for all n.

Remark 1 (Bootstrap weights). The chief and recommended example of bootstrap weights
is given by e set to be the standard exponential random variable. Note that for other
positive random variables with EP [e] = 1 but VarP [e] > 1, we can take the transformation
ẽ = 1 + (e − 1)/VarP [e]1/2 , which satisfies ẽ ≥ 0, EP [ẽ] = 1, and VarP [ẽ] = 1.

  The weights act as sampling weights in the bootstrap procedure. In each repetition, we
draw a new set of weights (e1 , . . . , en ) and recompute the CQIV estimator in the weighted
                                                                                                        13

sample. We refer to the next section for practical details, and here we define the quantities
needed to verify the validity of this bootstrap scheme. Specifically, let Vbie denote the esti-
mator of the control variable for observation i in the weighted sample, such as the quantile
regression or distribution regression based estimators described in the next section. The
CQIV estimator in the weighted sample solves
                                                     n
                                                 1X
                     βbe (u) = arg     min                  γ 0 Sbie > ς)ρu (Yi − β 0 X
                                                       ei 1(b                         bie ),      (2.12)
                                     β∈Rdim(X)   n i=1

where Xb e = x(Di , Wi , Vb e ), Sbe = s(X
                                         b e , Ci ), and γ
                                                         b is a consistent estimator of the selector.
        i                  i       i      i
Note that we do not need to recompute γ         b in the weighted samples, which is convenient for
computation.
  We make the following assumptions about the estimator of the control variable in the
weighted sample.

Assumption 7 (Weighted estimator of control variable). Let (e1 , . . . , en ) be a sequence of
weights that satisfies Assumption 6. We have an estimator of the control variable of the form
Vb e = ϑbe (D, W, Z), such that uniformly over DWZ,
                                                 n
    √                                     1 X
     n(ϑbe (d, w, z) − ϑ0 (d, w, z)) = √         ei `(Ai , d, w, z) + oP (1), EP [`(A, d, w, z)] = 0,
                                           n i=1
                                              P
where EP [`(A, D, W, Z)2 ] < ∞ and k √1n ni=1 ei `(Ai , ·)k∞ = OP (1), and
                                                     √
                             kϑbe − ϑee k∞ = oP (1/ n), for ϑee ∈ Υ,

where the entropy of the function class Υ is not too high, namely

                     log N (², Υ, k · k∞ ) . 1/(² log2 (1/²)), for all 0 < ² < 1.

  Basically this is the same condition as Assumption 3 in the unweighted sample, and
therefore both can be verified using analogous arguments. Note also that the condition is
stated under the probability measure P, i.e. unconditionally on the data, which actually
simplifies verification. We give primitive conditions that verify this assumption for quantile
and distribution regression estimation of the control variable in the next section.
  The following result shows the consistency of weighted bootstrap to approximate the
asymptotic distribution of the CQIV estimator.

Theorem 2 (Weighted-bootstrap validity for CQIV). Under the stated assumptions, condi-
tionally on the data
                     √
                      n(βbe (u) − β(u))
                                  b     →d N (0, J −1 (u)Λ(u)J −1 (u)),

in probability under P.
14

  Note that the statement above formally means that the distance between the law of
√
  n(βbe (u)−β(u))
            b      conditional on the data and the law of the normal vector N (0, J −1 (u)Λ(u)J −1 (u)),
as measured by any metric that metrizes weak convergence, conveges in probability to zero.
More specifically,
                     √
             dBL {L[ n(βbe (u) − β(u))|data],
                                   b          L[N (0, J −1 (u)Λ(u)J −1 (u))]} →P 0,

where dBL denotes the bounded Lipshitz metric.
                                                                   √
  In practice, we approximate numerically the distribution of n(βbe (u) − β(u)) b     conditional
                                                                be
on the data by simulation. For b = 1, . . . , B, we compute βb (u) solving the problem (2.12)
with the data fixed and a set of weights (e1b , ..., enb ) randomly drawn for a distribution that
                                                                                     √
satisfies Assumption 6. By Theorem 2, we can use the empirical distribution of n(βbbe (u) −
b
β(u))  to make asymptotically valid inference on β0 (u) for large B.

2.5. Quantile and distribution regression estimation of the control variable. One
of the main contributions of this paper is to allow for quantile and distribution regression
estimation of the control variable. The difficulties here are multifold, since the control vari-
able depends on the infinite dimensional function π0 (·), and more importantly the estimated
version of this function, π
                          b(·), does not seem to lie in any class with good entropic properties.
We overcome these difficulties by demonstrating that the estimated function can be approx-
imated with sufficient degree of accuracy by a random function that lies in a class with good
entropic properties. To carry out this approximation, we smooth the empirical quantile re-
gression and distribution regression processes by third order kernels, after suitably extending
the processes to deal with boundary issues. Such kernels can be obtained by reproducing ker-
nel Hilbert space methods or via twicing kernel methods (Berlinet, 1993, and Newey, Hsieh,
and Robins, 2004). In the case of quantile regression, we also use results of the asymptotic
theory for rearrangement-related operators developed by Chernozhukov, Fernández-Val and
Galichon (2010). Moreover, all the previous arguments carry over weighted samples, which
is relevant for the bootstrap.

2.5.1. Quantile regression. We impose the following condition:

Assumption 8 (QR control variable). (a) The conditional quantile function of D given
(W, Z) follows the quantile regression model, i.e.,

                     QD (· | W, Z) = QD (· | R) = R0 π0 (·), R = r(W, Z),

where the coefficients v 7→ π0 (v) are three times continuously differentiable with uniformly
bounded derivatives, and R is compact; (b) The conditional density fD (· | R) is uniformly
bounded by a constant P -a.e., and is continuous at R0 π0 (v) uniformly in v ∈ (0, 1) P -a.e.
(c) The Gram matrix E[RR0 ] is finite and has full rank.
                                                                                                15

  For ρv (z) := (v − 1(z < 0))z, let
                                                         n
                             e                        1X
                           π
                           b (v) ∈ arg      min             ei ρv (Di − Ri0 π),
                                          π∈Rdim(R)   n i=1
where either ei = 1 for the      unweighted sample, to obtain the estimates; or ei is drawn from
a positive random variable       with unit mean and variance for the weighted sample, to obtain
bootstrap estimates. Then        set
                         Z                                     Z
             ϑ0 (d, r) =             0              be
                                 1{r π0 (v) ≤ d}dv; ϑ (d, r) =    1{r0 π
                                                                       be (v) ≤ d}dv.
                         (0,1)                                       (0,1)

  The following result verifies that our main high-level conditions for the control variable
estimator in Assumptions 3 and 7 hold under Assumption 8. The verification is done simul-
taneously for weighted and unweighted samples by including weights that can be equal to
the trivial unit weights, as mentioned above.

Theorem 3 (Validity of Assumptions 3 & 7 for QR). Suppose that Assumption 8 holds. (1)
We have that
                                       n
    √                              1 X
      n(ϑbe (d, r) − ϑ0 (d, r)) = √       ei `(Ai , d, r) + oP (1) Ã ∆e (d, r) in `∞ (DR),
                                    n i=1
                                                                                   −1
                    `(A, d, r) := fD (d | r)r0 EP [fD (R0 π0 (ϑ0 (d, r)) | R)RR0 ]      ×
                                       ×[1{D ≤ R0 π0 (ϑ0 (d, r))} − ϑ0 (d, r)]R,
                EP [`(A, d, r)] = 0, EP [`(A, D, R)2 ] < ∞,

where ∆e (d, r) is a Gaussian process with continuous paths and covariance function given
                      ˜ r̃)0 ]. (2) Moreover, there exists ϑee : DR 7→ [0, 1] that obeys the same
by EP [`(A, d, r)`(A, d,
                                                                                    √
first order representation, is close to ϑbe in the sense that kϑee − ϑbe k∞ = oP (1/ n), and, with
probability approaching one, belongs to a bounded function class Υ such that

                             log N (², Υ, k · k∞ ) . ²−1/2 , 0 < ² < 1.

Thus, Assumption 3 holds for the case ei = 1, and Assumption 7 holds for the case of ei
being drawn from a positive random variable with unit mean and variance as in Assumption
6. Thus, the results of Theorem 1 and 2 apply for the QR estimator of the control variable.


2.5.2. Distribution regression. We impose the following condition:

Assumption 9 (DR control variable). (a) The conditional distribution function of D given
(W, Z) follows the distribution regression model, i.e.,

                    FD (· | W, Z) = FD (· | R) = Λ(R0 π0 (·)), R = r(W, Z),
16

where Λ is either the probit or logit link function, the coefficients d 7→ π0 (d) are three times
continuously differentiable with uniformly bounded derivatives; (b) D and R are compact;
(c) The Gram matrix ERR0 has full rank.


     Let
                                         n
                                      1X
           be (d) ∈ arg
           π                min             ei {1(Di ≤ d) log Λ(Ri0 π) + 1(Di > d) log[1 − Λ(Ri0 π)]},
                          π∈Rdim(R)   n i=1
where either ei = 1 for the unweighted sample, to obtain the estimates; or ei is drawn from
a positive random variable with unit mean and variance for the weighted sample, to obtain
bootstrap estimates. Then set

                                  ϑ0 (d, r) = Λ(r0 π0 (d)); ϑbe (d, r) = Λ(r0 π
                                                                              be (d)).

  The following result verifies that our main high-level conditions for the control variable
estimator in Assumptions 3 and 7 hold under Assumption 9. The verification is done simul-
taneously for weighted and unweighted samples by including weights that can be equal to
the trivial unit weights.


Theorem 4 (Validity of Assumptions 3 & 7 for DR). Suppose that Assumption 9 holds. (1)
We have that
                                    n
  √
      b e                      1 X
    n(ϑ (d, r) − ϑ0 (d, r)) = √        ei `(Ai , d, r) + oP (1) Ã ∆e (d, r) in `∞ (DR),
                                n i=1
                                                   ·                                     ¸−1
                                   0         0               ∂Λ(R0 π0 (d))2            0
                `(A, d, r) := ∂Λ(r π0 (d))r EP                                      RR       ×
                                                     Λ(R0 π0 (d))[1 − Λ(R0 π0 (d))]
                                 1{D ≤ d} − Λ(R0 π0 (d))
                              ×      0                   0
                                                                  ∂Λ(R0 π0 (d))R,
                                Λ(R π0 (d))[1 − Λ(R π0 (d))]
                  EP [`(A, d, r)] = 0, EP [`(A, D, R)2 ] < ∞,

where ∆e (d, r) is a Gaussian process with continuous paths and covariance function given
                       ˜ r̃)0 ], and ∂Λ is the derivative of Λ. (2) Moreover, there exists ϑee :
by EP [`(A, d, r)`(A, d,
DR 7→ [0, 1] that obeys the same first order representation, is close to ϑbe in the sense that
                      √
kϑee − ϑbe k∞ = oP (1/ n) and, with probability approaching one, belongs to a bounded function
class Υ such that
                                log N (², Υ, k · k∞ ) . ²−1/2 , 0 < ² < 1.
Thus, Assumption 3 holds for the case ei = 1, and Assumption 7 holds for the case of ei
being drawn from a positive random variable with unit mean and variance as in Assumption
6. Thus, the results of Theorem 1 and 2 apply for the DR estimator of the control variable.
                                                                                               17

                     3. Computation and Numerical Examples

  This section describes the numerical algorithms to compute the CQIV estimator and
weighted bootstrap confidence intervals, and shows the results of a Monte Carlo numerical
example.

3.1. CQIV Algorithm. The algorithm to obtain CQIV estimates is similar to Chernozhukov
and Hong (2002). We add an initial step to estimate the control variable V . We name this
step as Step 0 to facilitate comparison with the Chernozhukov and Hong (2002) 3-Step CQR
algorithm.


Algorithm 1 (CQIV). For each desired quantile u, perform the following steps:

    0. Obtain an estimate of the control variable for each individual, Vbi , and construct X
                                                                                           bi =
       x(Di , Wi , Vbi ).
    1. Select a subset of quantile-uncensored observations, J0 , whose conditional quantile
       function is likely to be above the censoring point, namely select a subset of {i :
       Xi0 β0 (u) > C}. To find these observations, we note that X 0 β0 (u) > C is equivalent
       to P (Y > C | X, C) > 1 − u. Hence we predict the quantile-uncensored observations
       using a flexible binary choice model:

                        P (Y > C | X, C) = Λ(Si0 δ0 ), Si = s(Xi , Ci ),

       where Λ is a known link function, typically a probit or a logit. In estimation, we
       replace Si by Sbi = s(X
                             bi , Ci ). Then, we select the sample J0 according to the following
       criterion:
                                                 b > 1 − u + k0 }.
                                J0 = {i : Λ(Sbi0 δ)
    2. Estimate a standard quantile regression on the subsample defined by J0 :
                                               X
                         βb0 (u) = arg min                 bi0 β).
                                                  ρu (Yi − X                               (3.1)
                                        β∈Rdim(X)
                                                    i∈J0

       Next, using the predicted values, select another subset of quantile-uncensored obser-
       vations, J1 , from the full sample according to the following criterion:
                                          b 0 βb0 (u) > Ci + ς1 }.
                                J1 = {i : X                                                (3.2)
                                           i

    3. Estimate a standard quantile regression on the subsample defined by J1 . Formally,
       replace J0 by J1 in (3.1). The new estimates, βb1 (u), are the 3-Step CQIV coefficient
       estimates.
    4. (Optional) With the results from the previous step, select a new sample J2 replacing
       βb0 (u) by βb1 (u) in (3.2). Iterate this and the previous step a bounded number of times.
18

Remark 2 (Step 0). A simple additive strategy is to estimate the control variable using
the empirical CDF of the residuals from the first stage OLS regression of D on W and Z.
More flexible non-additive strategies based on quantile regression or distribution regression
are described in the previous section.

Remark 3 (Step 1). To predict the quantile-uncensored observations, a probit, logit, or any
other model that fits the data well can be used. Note that the model does not need to be
correctly specified; it suffices that it selects a nontrivial subset of observations with Xi0 β0 (u) >
Ci . To choose the value of k0 , it is advisable that a constant fraction of observations satisfying
       b > 1 − u are excluded from J0 for each quantile. To do so, set k0 as the q0 th quantile
Λ(Sbi0 δ)
          b conditional on Λ(Sb0 δ)
of Λ(Sbi0 δ)                        b > 1 − u, where q0 is a percentage (10% worked well in our
                                  i
simulation). The empirical value of k0 and the percentage of observations retained in J0 can
be computed as simple robustness diagnostic tests at each quantile.

Remark 4 (Step 2). To choose the cut-off ς1 , it is advisable that a constant fraction of
observations satisfying Xb 0 βb0 (u) > Ci are excluded from J1 for each quantile. To do so,
                           i
set ς1 to be the q1 th quantile of X  b 0 βb0 (u) − Ci conditional on X
                                                                      b 0 βb0 (u) > Ci , where q1 is a
                                       i                                i
percentage less than q0 (3% worked well in our simulation). In practice, it is desirable that
J0 ⊂ J1 . If this is not the case, we recommend altering q0 , q1 , or the specification of the
regression models. At each quantile, the empirical value of ς1 , the percentage of observations
from the full sample retained in J1 , the percentage of observations from J0 retained in J1 ,
and the number of observations in J1 but not in J0 can be computed as simple robustness
diagnostic tests. The estimator βb0 (u) is consistent but will be inefficient relative to the
estimator obtained in the subsequent step.

Remark 5 (Steps 1 and 2). In the notation of Assumption 4, the selector of Step 1 can be
expressed as 1(Sbi0 γ                     b = Sbi0 δb−Λ−1 (1−u) and ς0 = Λ−1 (1−u+k0 )−Λ−1 (1−u).
                     b > ς0 ), where Sbi0 γ
The selector of Step 2 can also be expressed as 1(Sbi0 γ         b > ς1 ), where Sbi = (X
                                                                                        bi0 , Ci )0 and
b = (βb0 (u)0 , −1)0 .
γ

Remark 6 (Steps 2, 3 and 4). Beginning with Step 2, each successive iteration of the
algorithm should yield estimates that come closer to minimizing the Powell objective func-
tion. As a simple robustness diagnostic test, we recommend computing the Powell objective
function using the full sample and the estimated coefficients after each iteration, starting
with Step 2. This diagnostic test is computationally straightforward because computing the
objective function for a given set of values is much simpler than maximizing it. In practice,
this test can be used to determine when to stop the CQIV algorithm for each quantile. If
the Powell objective function increases from Step s to Step s + 1 for s ≥ 2, estimates from
Step s can be retained as the coefficient estimates.
                                                                                                             19

3.2. Weighted Bootstrap Algorithm. We recommend obtaining confidence intervals through
a weighted bootstrap procedure, though analytical formulas can also be used. If the esti-
mation runs quickly on the desired sample, it is straightforward to rerun the entire CQIV
algorithm B times weighting all the steps by the bootstrap weights. To speed up the com-
putation, we propose a procedure that uses a one-step CQIV estimator in each bootstrap
repetition.

Algorithm 2 (Weighted bootstrap CQIV). For b = 1, . . . , B, repeat the following steps:

     1. Draw a set of weights (e1b , . . . , enb ) i.i.d from a random variable e that satisfies As-
        sumption 6. For example, we can draw the weights from a standard exponential
        distribution.
     2. Reestimate the control variable in the weighted sample, Vbibe = ϑbeb (Di , Wi , Zi ), and
        construct Xb e = x(Di , Wi , Vb e ).
                     ib                ib
     3. Estimate the weighted quantile regression:
                                                      X
                          βbbe (u) = arg min                                b e ),
                                                           eib ρu (Yi − β 0 X ib
                                            β∈Rdim(X)
                                                        i∈J1b

                            b 0X
         where J1b = {i : β(u)                       b
                                b e > Ci + ς1 }, and β(u) is a consistent estimator of β0 (u),
                                 ib
                                          b1
         e.g., the 3-stage CQIV estimator β (u).


Remark 7 (Step 2). The estimate of the control function ϑbeb can be obtained by weighted
least squares, weighted quantile regression, or weighted distribution regression.

Remark 8 (Step 3). A computationally less expensive alternative is to set J1b = J1 in all the
repetitions, where J1 is the subset of selected observations in Step 2 of the CQIV algorithm.

  We can construct an asymptotic (1−α)-confidence interval for a function of the parameter
                     gα/2 , gb1−α/2 ], where gbα is the sample α-quantile of [g(βb1e (u)), . . . , g(βbBe (u))].
vector g(β0 (u)) as [b
For example, the 0.025 and 0.975 quantiles of (βb1,k      e
                                                            (u), . . . , βbB,k
                                                                           e
                                                                               (u)) form a 95% asymptotic
confidence interval for the kth coefficient β0,k (u).

3.3. Monte-Carlo illustration. The goal of the following numerical example is to com-
pare the performance of CQIV relative to tobit IV and other quantile regression estimators
in finite samples. We generate data according to a normal design that satisfies the tobit
parametric assumptions and a design with heteroskedasticity in the first stage equation for
the endogenous regressor D that does not satisfy the tobit parametric assumptions. To
facilitate the comparison, in both designs we consider a location model for the response vari-
able Y ∗ , where the coefficients of the conditional expectation function and the conditional
quantile function are equal (other than the intercept), so that tobit and CQIV estimate the
20

same parameters. A comparison of the dispersion of the tobit estimates to the dispersion
of the CQIV estimates at each quantile in the first design serves to quantify the relative
efficiency of CQIV in a case where tobit IV can be expected to perform as well as possible.
The appendix provides a more detailed description of the designs.
  We consider two tobit estimators for comparison. Tobit-iv is the full information maxi-
mum likelihood estimator developed by Newey (1987), which is implemented in Stata with
the command ivtobit. Tobit-cmle is the conditional maximum likelihood tobit estimator
developed by Smith and Blundell (1986), which uses least squares residuals as a control vari-
able. For additional comparisons, we present results from the censored quantile regression
(cqr) estimator of Chernozhukov and Hong (2002), which does not address endogeneity; the
quantile instrumental variables estimator (qiv-ols) of Lee (2007) with parametric first and
second stage, which does not account for censoring; and the quantile regression (qr) estima-
tor of Koenker and Bassett (1978), which does not account for endogeneity nor censoring.
For CQIV we consider three different methods to estimate the control variable: cqiv-ols,
which uses least squares; cqiv-qr, which uses quantile regression; and cqiv-dr, which uses
probit distribution regression. The appendix also provides technical details for all CQIV
estimators, as well as diagnostic test results for the cqiv-ols estimator.
   We focus on the coefficient on the endogenous regressor D. We report mean bias and root
mean square error (rmse) for all the estimators at the {.05, .10, ..., .95} quantiles. For the
homoskedastic design, the bias results are reported in the upper panel of Figure 1 and the
rmse results are reported in the lower panel. In this figure, we see that tobit-cmle represents
a substantial improvement over tobit-iv in terms of mean bias and rmse. Even though
tobit-iv is theoretically efficient in this design, the CQIV estimators out-perform tobit-iv,
and compare well to tobit-cmle. The figure also demonstrates that the CQIV estimators
out-perform the other quantile estimators at all estimated quantiles. All of our qualitative
findings hold when we consider unreported alternative measures of bias and dispersion such
as median bias, interquartile range, and standard deviation.
   The similar performance of tobit-cmle and cqiv can be explained by the homoskedasticity
in the first stage of the design. Figure 2 reports mean bias and rmse results for the het-
eroskedastic design. Here cqiv-qr outperforms cqiv-ols and cqiv-dr at every quantile, which
is expected because cqiv-ols and cqiv-dr are both misspecified for the control variable. Cqiv-
dr has lower bias than cqiv-ols because it uses a more flexible specification for the control
variable. Cqiv-qr also outperforms all other quantile estimators. Most importantly, at every
quantile, cqiv-qr outperforms both tobit estimators, which are no longer consistent given
the heteroskedasticity in the design of the first stage. In summary, CQIV performs well
relative to tobit in a model that satisfies the parametric assumptions required for tobit-iv to
be efficient, and it outperforms tobit in a model with heteroskedasticy.
                                                                                                              21

                   4. Empirical Application: Engel Curve Estimation

   In this section, we apply the CQIV estimator to the estimation of Engel curves. The
Engel curve relationship describes how a household’s demand for a commodity changes as the
household’s expenditure increases. Lewbel (2006) provides a recent survey of the extensive
literature on Engel curve estimation. For comparability to the recent studies, we use data
from the 1995 U.K. Family Expenditure Survey (FES) as in Blundell, Chen, and Kristensen
(2007) and Imbens and Newey (2009). Following Blundell, Chen, and Kristensen (2007),
we restrict the sample to 1,655 married or cohabitating couples with two or fewer children,
in which the head of household is employed and between the ages of 20 and 55. The FES
collects data on household expenditure for different categories of commodities. We focus on
estimation of the Engel curve relationship for the alcohol category because 16% of families
in our data report zero expenditure on alcohol. Although zero expenditure on alcohol arises
as a corner solution outcome, and not from bottom coding, both types of censoring motivate
the use of censored estimators such as CQIV.
  Endogeneity in the estimation of Engel curves arises because the decision to consume a
particular category of commodity may occur simultaneously with the allocation of income
between consumption and savings. Following the literature, we rely on a two-stage budgeting
argument to justify the use of labor income as an instrument for expenditure. Specifically,
we estimate a quantile regression model in the first stage, where the logarithm of total
expenditure, D, is a function of the logarithm of gross earnings of the head of the household,
Z, and demographic household characteristics, W . The control variable, V , is obtained
using the CQIV-QR estimator in (2.11), where the integral is approximated by a grid of 100
quantiles. For comparison, we also obtained control variable estimates using least squares
and probit distribution regression. We do not report these comparison estimates because
the correlation between the different control variable estimates was virtually 1, and all the
methods resulted in very similar estimates in the second stage.
 In the second stage we focus on the following quantile specification for Engel curve esti-
mation:

            Yi = max(Xi0 β0 (Ui ), 0), Xi = (1, Di , Di2 , Wi , Φ−1 (Vi )), Ui v U (0, 1) | Xi ,

where Y is the observed share of total expenditure on alcohol censored at zero, W is a binary
household demographic variable that indicates whether the family has any children, and V
is the control variable. We define our binary demographic variable following Blundell, Chen
and Kristensen (2007).2

2Demographic   variables are important shifters of Engel curves. In recent literature, “shape invariant” specifi-
cations for demographic variable have become popular. For comparison with this literature, we also estimate
22

   To choose the specification, we rely on recent studies in Engel curve estimation. Thus,
following Blundell, Browning, and Crawford (2003) we impose separability between the con-
trol variable and other regressors. Hausman, Newey, and Powell (1995) and Banks, Blundell,
and Lewbel (1997) show that the quadratic specification in log-expenditure gives a better
fit than the linear specification used in earlier studies. In particular, Blundell, Duncan, and
Pendakur (1998) find that the quadratic specification gives a good approximation to the
shape of the Engel curve for alcohol. To check the robustness of the specification to the
linearity in the control variable, we also estimate specifications that include nonlinear terms
in the control variable. The results are very similar to the ones reported.
                                                     b for a variety of estimators. In addition
   Figure 3 reports the estimated coefficients u 7→ β(u)
to reporting results for CQIV with a quantile estimate of the control variable (cqiv), as in
the previous numerical examples, we report estimates from the censored quantile regression
(cqr) of Chernozhukov and Hong (2002), the quantile instrumental variables estimator with
a quantile regression estimate of the control variable (qiv) of Lee (2007), and the quantile
regression (qr) estimator of Koenker and Bassett (1978). We also estimate a model for
the conditional mean with the tobit-cmle of Smith and Blundell (1986) that incorporates a
least squares estimate of the control variable. The tobit-iv algorithm implemented in Stata
does not converge in this application. Given the level of censoring, we focus on conditional
quantiles above the .15 quantile.
   In the panels that depict the coefficients of expenditure and its square, the importance of
controlling for censoring is especially apparent. Comparison between the censored quantile
estimators (cqiv and cqr), plotted with thick light lines, and the uncensored quantile estima-
tors (qiv and qr), plotted with thin dark lines, demonstrates that the censoring attenuates
the uncorrected estimates toward zero at most quantiles in this application. In particular,
censoring appears very important at the lowest quantiles. Relative to the tobit-cmle estimate
of the conditional mean, cqiv provides a richer picture of the heterogenous effects of the vari-
ables. Comparison of the quantile estimators that account for endogeneity (cqiv and qiv),
plotted with solid lines, and those that do not (cqr and qr), plotted with dashed lines, shows
that endogeneity also influences the estimates, but the pattern is more difficult to interpret.
The estimates of the coefficient of the control variable indicate that the endogeneity problem
is more severe in the upper half of the distribution. This is consistent with a situation where
a strong preference to consume alcohol raises total household expenditure.
  Our quadratic quantile model is flexible in that it permits the expenditure elasticities to
vary across quantiles of the alcohol share and across the level of total expenditure. These

an unrestricted version of shape invariant specification in which we include a term for the interaction be-
tween the logarithm of expenditure and our demographic variable. The results from the shape invariant
specification are qualitatively similar but less precise than the ones reported in this application.
                                                                                                 23

quantile elasticities are related to the coefficients of the model by

                      ∂d QY (u | x) = 1{x0 β0 (u) > 0}{β01 (u) + 2β02 (u) d},

where β01 (u) and β02 (u) are the coefficients of D and D2 , respectively. Figure 4 reports point
and interval estimates of average quantile elasticities as a function of the quantile index u,
i.e., u 7→ EP [∂d QY (u | X)]. Here we see that accounting for endogeneity and censoring
also has important consequences for these economically relevant quantities. The difference
between the estimates is more pronounced along the endogeneity dimension than it is along
the censoring dimension. The right panel plots 95% pointwise confidence intervals for the
cqiv quantile elasticity estimates obtained by the weighted bootstrap method described in
Section 3 with standard exponential weights and B = 200 repetitions. Here we can see
that there is significant heterogeneity in the expenditure elasticity across quantiles. Thus,
alcohol passes from being a normal good for low quantiles to being an inferior good for high
quantiles. This heterogeneity is missed by conventional mean estimates of the elasticity.
  In Figure 5 we report families of Engel curves based on the cqiv coefficient estimates. We
predict the value of the alcohol share, Y , for a grid of values of log expenditure using the
cqiv coefficients at each quartile. The subfigures depict the Engel curves for each quartile of
the empirical values of the control variable, for individuals with and without kids, that is
                                                               b
                             d 7→ max{(1, d, d2 , w, Φ−1 (v))0 β(u), 0}

for (w, Φ−1 (v), u) evaluated at w ∈ {0, 1}, the quartiles of Vb for v, and u ∈ {0.25, 0.50, 0.75}.
Here we can see that controlling for censoring has an important effect on the shape of the
Engel curves even at the median. The families of Engel curves are fairly robust to the values
of the control variable, but the effect of children on alcohol shares is more pronounced. The
presence of children in the household produces a downward shift in the Engel curves at all
the levels of log-expenditure considered.




                                        5. Conclusion

  In this paper, we develop a new censored quantile instrumental variable estimator that
incorporates endogenous regressors using a control variable approach. Censoring and en-
dogeneity abound in empirical work, making the new estimator a valuable addition to the
applied econometrician’s toolkit. For example, Kowalski (2009) uses this estimator to ana-
lyze the price elasticity of expenditure on medical care across the quantiles of the expenditure
distribution, where censoring arises because of the decision to consume zero care and en-
dogeneity arises because marginal prices explicitly depend on expenditure. Since the new
24

estimator can be implemented using standard statistical software, it should prove useful to
applied researchers in many applications.


                                         Appendix A. Notation

   In what follows ϑ and γ denote generic values for the control function and the parameter
of the selector 1(Si0 γ > ς). It is convenient also to introduce some additional notation,
which will be extensively used in the proofs. Let Xi (ϑ) := x(Di , Wi , ϑ(Di , Wi , Zi )), Si (ϑ) :=
s(Xi (ϑ), Ci ), Ẋi (ϑ) := ∂v x(Di , Wi , v)|v=ϑ(Di ,Wi ,Zi ) , and Ṡi (ϑ) := ∂v s(Xi (v), Ci )|v=ϑ(Di ,Wi ,Zi ) .
When the previous functions are evaluated at the true values we use Xi = Xi (ϑ0 ), Si =
Si (ϑ0 ), Ẋi = Ẋi (ϑ0 ), and Ṡi = Ṡi (ϑ0 ). Also, let ϕu (z) := [1(z < 0) − u]. Recall that
A := (Y, D, W, Z, C, X, V ). For a function f : A 7→ R, we use kf k∞ = supa∈A |f (a)|; for a
K-vector of functions f : A 7→ RK , we use kf k∞ = supa∈A kf (a)k2 . We make functions in
Υ as well as estimates ϑb to take values in [0, 1], the support of the control variable V . This
allows us to simplify notation in what follows. We also adopt the standard notation in the
empirical process literature (see, e.g., van der Vaart, 1998),
                                                                     n
                                                                     X
                                                                −1
                                    En [f ] = En [f (A)] = n               f (Ai ),
                                                                     i=1

and                                                          n
                                                             X
                                                      −1/2
                          Gn [f ] = Gn [f (A)] = n             (f (Ai ) − EP [f (A)]).
                                                             i=1

When the function fb is estimated, the notation should interpreted as:

                                             Gn [fb ] = Gn [f ] |f =fb


                           Appendix B. Proof of Theorems 1 and 2
                                                                              √ b
B.1. Proof of Theorem 1. Step 1. This step shows that                          n(β(u) − β0 (u)) = OP (1).
     By Assumption 4 on the selector, for large enough n:
            b 0γ
        1{S(ϑ) b ≥ ς} ≤ 1{S 0 γ0 > ς − ²n } ≤ 1{S 0 γ0 > ς/2} ≤ 1{X 0 β0 (u) > C + ²0 } =: χ,

P -a.e., since
                        b 0γ
                     |S(ϑ) b − S 0 γ0 | ≤ ²n := LS (kϑb − ϑ0 k∞ + kb
                                                                   γ − γ0 k2 ) →P 0,
where LS := (k∂v sk∞ ∨ ksk∞ ) is a finite constant by assumption.
     Hence, with probability approaching one,
                      b
                      β(u) = arg       min                    b 0 β)1(S(ϑ)
                                                En [ρu (Y − X(ϑ)        b 0γ
                                                                           b > ς)χ],
                                    β∈Rdim(X)
                                                                                                 25

Due to convexity of the objective function, it suffices to show that for any ² > 0 there exists
a finite positive constant B² such that
                                µ                          ¶
                                      √ 0 h          i
                       lim inf P inf    nη En fbη,B² > 0 ≥ 1 − ²,                        (B.1)
                          n→∞          kηk2 =1

where                       n                        √ o
             b                     b 0                     b
             fη,B² (A) := ϕu Y − X(ϑ) (β0 (u) + B² η/ n) X(ϑ)1{S( b 0γ
                                                                 ϑ)  b > ς}χ.
Let
                              f (A) := ϕu {Y − X 0 β0 (u)} X1{S 0 γ0 > ς}.
Then uniformly in kηk2 = 1,
           √ 0                                             √ 0
            nη En [fbη,B² ] =            η 0 Gn [fbη,B² ] +  nη EP [fbη,B² ]
                                                                   √
                                =(1)     η 0 Gn [f ] + oP (1) + η 0 nEP [fbη,B² ]
                                =(2) η 0 Gn [f ] + oP (1) + η 0 J(u)ηB² + η 0 Gn [g] + oP (1)
                                =(3) OP (1) + oP (1) + η 0 J(u)ηB² + OP (1) + oP (1),
                                                                                         √
where relations (1) and (2) follow by Lemma 1 and Lemma 2 with βe = β0 (u) + B² η/ n,
                               e ∞ = oP (1/√n), ϑe ∈ Υ, kϑe − ϑ0 k∞ = OP (1/√n) and kβ0 (u) +
respectively, using that kϑb − ϑk
     √                       √
B² η/ n − β0 (u)k2 = O(1/ n); relation (3) holds by Chebyshev inequality. Since J(u) is
positive definite, with minimal eigenvalue bounded away from zero, the inequality (B.1)
follows by choosing B² as a sufficiently large constant.
  Step 2. In this step we show the main result. From the subgradient characterization of
the solution to the quantile regression problem we have
                 √     h i                                   √
                   nEn fb = δn ; kδn k2 ≤ dim(X) max kXi k2 / n = oP (1),          (B.2)
                                                              1≤i≤n

where                              n              o
                        fb(A) := ϕu Y − X(ϑ)
                                          b 0 β(u)
                                              b       b
                                                    X(ϑ)1{S( b 0γ
                                                            ϑ)  b > ς}χ.

  Therefore
                 √      h i              h i √          h i
      oP (1) =       nEn fb    =     Gn f + nEP fb
                                           b
                                                        √     h i
                              =(1)   Gn [f ] + oP (1) + nEP fb
                                                            √
                              =(2)                              b − β0 (u)) + Gn [g] + oP (1),
                                     Gn [f ] + oP (1) + J(u) n(β(u)

where relations (1) and (2) follow by Lemma 1 and Lemma 2 with βe = β(u),
                                                                    b     respectively,
             b   e            √     e      e              √          b
using that kϑ − ϑk∞ = oP (1/ n), ϑ ∈ Υ, kϑ − ϑk∞ = OP (1/ n) and kβ(u) − β0 (u)k2 =
      √
OP (1/ n).
26

     Therefore by invertibility of J(u),
                        √
                              b − β0 (u)) = −J(u)−1 Gn (f + g) + oP (1).
                          n(β(u)

By the Central Limit Theorem, Gn (f + g) →d N (0, VarP (f + g)), so that
                 √
                      b − β0 (u)) →d N (0, J(u)−1 VarP (f + g)J(u)−1 ).
                   n(β(u)

¤


                                                                         √ be
B.2. Proof of Theorem 2. Step 1. This step shows that                     n(β (u) − β0 (u)) = OP (1) under
the unconditional probability P.
     By Assumption 4 on the selector, with probability approaching one,

                   βbe (u) = arg     min       En [eρu (Y − X(ϑbe )0 β)1(S(ϑbe )0 γ
                                                                                  b > ς)χ],
                                   β∈Rdim(X)

where e is the random variable used in the weighted bootstrap, and χ = 1(X 0 β0 (u) > C + ²0 ).
Due to convexity of the objective function, it suffices to show that for any ² > 0 there exists
a finite positive constant B² such that
                                µ                          ¶
                                      √ 0 h e i
                       lim inf P inf            b
                                        nη En fη,B² > 0 ≥ 1 − ²,                         (B.3)
                          n→∞          kηk2 =1

where
                                  n                              √ o
           fbη,B
             e
                 ²
                   (A) := e · ϕ u   Y − X(ϑbe 0
                                             )  (β0 (u) + B ² η/  n) X(ϑbe )1{S(ϑbe )0 γ
                                                                                       b > ς}χ.

Let
                           f e (A) := e · ϕu {Y − X 0 β0 (u)} X1{S 0 γ0 > ς}.
Then uniformly in kηk2 = 1,
          √ 0                                              √ 0
            nη En [fbη,B
                     e
                         ²
                           ] =          η 0 Gn [fbη,B
                                                  e
                                                     ²
                                                       ]+    nη EP [fbη,B
                                                                      e
                                                                          ²
                                                                            ]
                                                                    √
                                =(1)    η 0 Gn [f e ] + oP (1) + η 0 nEP [fbη,B
                                                                              e
                                                                                ²
                                                                                  ]
                                =(2) η 0 Gn [f e ] + oP (1) + η 0 J(u)ηB² + η 0 Gn [g e ] + oP (1)
                                =(3) OP (1) + oP (1) + η 0 J(u)ηB² + OP (1) + oP (1),
                                                                                            √
where relations (1) and (2) follow by Lemma 1 and Lemma 2 with βe = β0 (u) + B² η/ n,
                                               √                                       √
respectively, using that kϑbe − ϑee k∞ = oP (1/ n), ϑee ∈ Υ, kϑee − ϑ0 k∞ = OP (1/ n) and
               √                      √
kβ0 (u) + B² η/ n − β0 (u)k2 = O(1/ n); relation (3) holds by Chebyshev inequality. Since
J(u) is positive definite, with minimal eigenvalue bounded away from zero, the inequality
(B.3) follows by choosing B² as a sufficiently large constant.
                                      √
  Step 2. In this step we show that n(βbe (u) − β0 (u)) = −J(u)−1 Gn (f e + g e ) + oP (1) under
the unconditional probability P.
                                                                                                       27

  From the subgradient characterization of the solution to the quantile regression problem
we have             h i
             √                                                 √
               nEn fbe = δne ; kδne k2 ≤ dim(X) max kei Xi k2 / n = oP (1),           (B.4)
                                                        1≤i≤n
where                           n               o
                 b
                 f (A) := e · ϕu Y − X(ϑ ) β (u) X(ϑbe )1{S(ϑbe )0 γ
                  e                    be 0 be
                                                                   b > ς}χ.

  Therefore
           √   h i                   h i √            h i
   oP (1) = nEn fbe        =     Gn fbe + nEP fbe
                                                      √     h i
                         =(1)    Gn [f e ] + oP (1) + nEP fbe
                                                          √
                         =(2)    Gn [f e ] + oP (1) + J(u) n(βbe (u) − β0 (u)) + Gn [g e ] + oP (1),

where relations (1) and (2) follow by Lemma 1 and Lemma 2 with βe = βbe (u), respectively,
                                 √                                  √
using that kϑbe − ϑee k∞ = oP (1/ n), ϑee ∈ Υ, kϑee − ϑ0 k∞ = OP (1/ n) and kβbe (u) − β0 (u)k2 =
      √
OP (1/ n).
  Therefore by invertibility of J(u),
                    √
                      n(βbe (u) − β0 (u)) = −J(u)−1 Gn (f e + g e ) + oP (1).
                                                                √
  Step 3. In this final step we establish the behavior of n(βbe (u) − β(u))  b     under Pe . Note
that Pe denotes the conditional probability measure, namely the probability measure induced
by draws of e1 , ..., en conditional on the data A1 , ..., An . By Step 2 of the proof of Theorem
1 and Step 2 of this proof, we have that under P:
√                                                   √
  n(βbe (u)−β0 (u)) = −J(u)−1 Gn (f e +g e )+oP (1), n(β(u)−β
                                                           b                     −1
                                                                   0 (u)) = −J(u) Gn (f +g)+oP (1).

Hence, under P
√
  n(βbe (u)−β(u))
            b     = −J(u)−1 Gn (f e −f +g e −g)+rn = −J(u)−1 Gn ((e−1)(f +g))+rn , rn = oP (1).

Note that it is also true that

                                  rn = oPe (1) in P-probability,

where the latter statement means that for every ² > 0, Pe (krn k2 > ²) →P 0. Indeed, this
follows from Markov inequality and by

                           EP [Pe (krn k2 > ²)] = P(krn k2 > ²) = o(1),

where the latter holds by the Law of Iterated Expectations and rn = oP (1).
28

  By the Conditional Multiplier Central Limit Theorem, e.g., Lemma 2.9.5 in van der Vaart
and Wellner (1996), we have that conditional on the data A1 , ..., An

               Gn ((e − 1)(f + g)) →d Z := N (0, VarP (f + g)), in P-probability,

where the statement means that for each z ∈ Rdim(X)

                           Pe (Gn ((e − 1)(f + g)) ≤ z) →P Pr(Z ≤ z).

Conclude that conditional on the data A1 , ..., An
         √
           n(βbe (u) − β(u))
                       b     →d N (0, J −1 (u)VarP (f + g)J −1 (u)), in P-probability,

where the statement means that for each z ∈ Rdim(X)
                       √
                   Pe ( n(βbe (u) − β(u))
                                    b     ≤ z) →P Pr(−J −1 (u)Z ≤ z).

¤



B.3. Lemma on Stochastic Equicontinuity.


Lemma 1 (Stochastic equicontinuity). Let e ≥ 0 be a positive random variable with unit
mean and finite variance that is independent of (Y, D, W, Z, X, V ), including as a special
case e = 1, and set, for A = (e, Y, D, W, Z, X, V ) and χ = 1(X 0 β0 (u) > C + ²0 ),

               f (A, ϑ, β, γ) := e · [1(Y ≤ X(ϑ)0 β) − u] · X(ϑ) · 1(S(ϑ)0 γ > ς) · χ.

Under the assumptions of the paper, the following relations are true.

     (a) Consider the set of functions

             F = {f (A, ϑ, β, γ)0 α : (ϑ, β) ∈ Υ0 × B, γ ∈ Γ, α ∈ Rdim(X) , kαk2 ≤ 1},

         where Γ is an open neighborhood of γ0 under the k · k2 metric, B is an open neigh-
         borhood of β0 (u) under the k · k2 metric, Υ0 is the intersection of Υ, defined in
         Assumption 3, with a small neighborhood of ϑ0 under the k · k∞ metric, which are
         chosen to be small enough so that:

                     |X(ϑ)0 β − X 0 β0 (u)| ≤ ²0 /2, P-a.e. ∀(ϑ, β) ∈ Υ0 × B,

         where ²0 is defined in Assumption 4. This class is P -Donsker with a square integrable
         envelope of the form e times a constant.
     (b) Moreover, if (ϑ, β, γ) → (ϑ0 , β0 (u), γ0 ) in the k · k∞ ∨ k · k2 ∨ k · k2 metric, then

                           kf (A, ϑ, β, γ) − f (A, ϑ0 , β0 (u), γ0 )kP,2 → 0.
                                                                                                  29

                       e β,
   (c) Hence for any (ϑ, eγ b) →P (ϑ0 , β0 (u), γ0 ) in the k · k∞ ∨ k · k2 ∨ k · k2 metric such that
       ϑe ∈ Υ0 ,
                               e β,
                     kGn f (A, ϑ, eγb) − Gn f (A, ϑ0 , β0 (u), γ0 )k2 →P 0.
                    b β,
   (d) For for any (ϑ, eγb) →P (ϑ0 , β0 (u), γ0 ) in the k · k∞ ∨ k · k2 ∨ k · k2 metric, so that
                                              √
                            kϑb − ϑk
                                  e ∞ = oP (1/ n), where ϑe ∈ Υ0 ,

       we have that
                                 b β,
                       kGn f (A, ϑ, eγb) − Gn f (A, ϑ0 , β0 (u), γ0 )k2 →P 0.



  Proof of Lemma 1. The proof is divided in proofs of each of the claims.
  Proof of Claim (a). The proof proceeds in several steps.
  Step 1. Here we bound the bracketing entropy for

                        I1 = {[1(Y ≤ X(ϑ)0 β) − u]χ : β ∈ B, ϑ ∈ Υ0 }.

For this purpose consider a mesh {ϑk } over Υ0 of k · k∞ width δ, and a mesh {βl } over B of
k · k2 width δ. A generic bracket over I1 takes the form

          [i01 , i11 ] = [{1(Y ≤ X(ϑk )0 βl − κδ) − u}χ, {1(Y ≤ X(ϑk )0 βl + κδ) − u}χ],

where κ = LX maxβ∈B kβk2 + LX , and LX := k∂v xk∞ ∨ kxk∞ .
   Note that this is a valid bracket for all elements of I1 induced by any ϑ located within δ
from ϑk and any β located within δ from βl , since

              |X(ϑ)0 β − X(ϑk )0 βl | ≤ |(X(ϑ) − X(ϑk ))0 β| + |X(ϑk )0 (β − βk )|
                                      ≤ LX δ max kβk2 + LX δ ≤ κδ,                             (B.5)
                                                β∈B

and the L2 (P ) size of this bracket is given by
                               p
             ki01 − i11 kP,2 ≤    EP [P {Y ∈ [X(ϑk )0 βl ± κδ] | D, W, Z, C, χ = 1}]
                               r
                             ≤    EP [ sup P {Y ∈ [y ± κδ] | X, C, χ = 1}]
                                      y∈(C+κδ,∞)
                             p
                           ≤  kfY (· | ·)k∞ 2κδ,


provided that 2κδ < ²0 /2. In order to derive this bound we use the condition |X(ϑ)0 β −
X 0 β0 (u)| ≤ ²0 /2, P -a.e. ∀(ϑ, β) ∈ Υ0 × B, so that conditional on χ = 1 we have that
X(ϑ)0 β > C + ²0 /2; and

 P {Y ∈ · | D, W, Z, C, χ = 1} = P {Y ∈ · | D, W, Z, V, C, χ = 1} = P {Y ∈ · | X, C, χ = 1},
30

because V = ϑ0 (D, W, Z) and the exclusion restriction for Z. Hence, conditional on X, C and
χ = 1, Y does not have point mass in the region [X(ϑk )0 βl ±κδ] ⊂ (C, ∞), and by assumption
the density of Y conditional on X, C is uniformly bounded over the region (C, ∞).
     It follows that

     log N[] (², I1 , L2 (P )) . log N (²2 , Υ0 , k · k∞ ) + log N (², B, k · k2 ) . 1/(²2 log2 ²) + log(1/²),

and so I1 is P-Donsker with a constant envelope.
     Step 2. Similarly to Step 1, it follows that

                             I2 = {X(ϑ)0 α : ϑ ∈ Υ0 , α ∈ Rdim(X) , kαk2 ≤ 1}

also obeys a similar bracketing entropy bound

                              log N[] (², I2 , L2 (P )) . 1/(²2 log2 ²) + log(1/²)

with a generic bracket taking the form [i02 , i12 ] = [X(ϑk )0 βl − κδ, X(ϑk )0 βl + κδ]. Hence, this
class is also P-Donsker with a constant envelope.
     Step 3. Here we bound the bracketing entropy for

                                   I3 = {1(S(ϑ)0 γ ≥ ς) : ϑ ∈ Υ0 , γ ∈ Γ}.

For this purpose consider the mesh {ϑk } over Υ0 of k · k∞ width δ, and a mesh {γl } over Γ
of k · k2 width δ. A generic bracket over I3 takes the form

                          [i03 , i13 ] = [1(S(ϑk )0 γl − κδ ≥ ς), 1(S(ϑk )0 γl + κδ ≥ ς)],

where κ = LS maxγ∈Γ kγk2 + LS , and LS := k∂v sk∞ ∨ ksk∞ .
   Note that this is a valid bracket for all elements of I3 induced by any ϑ located within δ
from ϑk and any γ located within δ from γl , since

                    |S(ϑ)0 γ − S(ϑk )0 γl | ≤ |(S(ϑ) − S(ϑk ))0 γ| + |S(ϑk )0 (γ − γk )|
                                             ≤ LS δ max kγk2 + LS δ ≤ κδ,                                 (B.6)
                                                        γ∈Γ

and the size of this bracket is given by
                                    p                           q
                     ki3 − i3 kP,2 ≤ P {|S(ϑk ) γl − ς| ≤ 2κδ} ≤ f¯S 2κδ,
                       0    1                  0


where f¯S is a constant representing the uniform upper bound on the density of random
variable S(ϑ)0 γ, where the uniformity is over ϑ ∈ Υ0 and γ ∈ Γ.
     It follows that

     log N[] (², I3 , L2 (P )) . log N (²2 , Υ0 , k · k∞ ) + log N (², Γ, k · k2 ) . 1/(²2 log2 ²) + log(1/²)
                                                                                                                  31

and so I3 is P-Donsker with a constant envelope.


  Step 4. In this step we verify the claim (a). Note that F = e · I1 · I2 · I3 . This class has a
square-integrable envelope under P.
  If we make a further assumption that the random variable e obeys EP |e|2+δ < ∞, for
δ > 0, then the class F is P-Donsker by the following argument. Note that the product
I1 · I2 · I3 of uniformly bounded classes is P-Donsker, e.g., by Theorem 2.10.6 of van der
Vaart and Wellner (1996). Under the stated assumption the final product of the random
variable e with the P-Donsker class remains to be P-Donsker by the Multiplier Donsker
Theorem, namely Theorem 2.9.2 in van der Vaart and Wellner (1996).
  It is also interesting to give a direct argument based on bracketing, which also requires the
somewhat weaker assumption of e ≥ 0 having finite variance. Indeed, our generic brackets
over F take the form
                                ·                                        ¸
                       0   1                   g h j               g h j
                     [f , f ] =      min 3 e i1 i2 i3 , max 3 e i1 i2 i3 .
                                     (g,h,j)∈{0,1}             (g,h,j)∈{0,1}

For example, if i01 , i02 , i03 ≥ 0, then f 0 = e i01 i02 i03 and f 1 = e i11 i12 i13 . Note that these are
valid brackets for all f that are induced by an element of I1 located in the bracket [i01 , i11 ],
an element of I2 located in the bracket [i02 , i12 ], and an element of I3 located in the bracket
[i03 , i13 ]. Using that the constructed brackets are uniformly bounded, by say k, the size of this
bracket is
                            p                                                                  p
           kf 0 − f 1 kP,2 ≤ EP e2 k 2 (ki01 − i11 kP,2 + ki02 − i12 kP,2 + ki03 − i13 kP,2 ) ≤ EP e2 k 2 3δ,

where we used the independence of random variable e from random vector A. Therefore,

   log N[] (², F, L2 (P )) . log N[] (², I1 , L2 (P )) + log N[] (², I2 , L2 (P )) + log N[] (², I3 , L2 (P )),

and the class is thus P-Donsker by the previous steps.
  Proof of Claim (b). The claim follows by the Dominated Convergence Theorem, since any
f ∈ F is dominated by a square-integrable envelope under P , and by the following three
facts:


    (1) in view of the relation such as (B.5), 1(Y ≤ X(ϑ)0 β)χ → 1(Y ≤ X 0 β0 (u))χ every-
        where, except for the set {A ∈ A : Y = X 0 β0 (u)} whose measure under P is zero by
        Y having a uniformly bounded density conditional on X, C;
    (2) in view of the relation such as (B.5), |X(ϑ)0 β − X 0 β0 (u)| → 0 everywhere;
    (3) in view of the relation such as (B.6), 1(S(ϑ)0 γ ≥ ς) → 1(S 0 γ0 ≥ ς) everywhere,
        except for the set {A ∈ A : S 0 γ0 = ς} whose measure under P is zero by S 0 γ0 having
        a bounded density.
32

   Proof of Claim (c). This claim follows from the asymptotic equicontinuity of the empirical
process (Gn [f ], f ∈ F ) under the L2 (P ) metric, and hence also with respect to the k · k∞ ∨
k · k2 ∨ k · k2 metric in view of Claim (b).
   Proof of Claim (d). It is convenient to set fb := f (A, ϑ,
                                                           b β,
                                                              eγb) and fe := f (A, ϑ,
                                                                                   e β,
                                                                                      eγb). Note
that
                                              √                  √
                            |Gn [fb − fe]| ≤ | nEn [fb − fe]| + | nEP (fb − fe)|                    (B.7)
                                             √            √
                                           .   nEn [ζb ] + nEP [ζb ]                                (B.8)
                                                         √
                                           . Gn [ζb ] + 2 nEP [ζb ],                                (B.9)

where |f | denote an application of absolute value to each element of the vector f , and ζb is
defined by the following relationship, which holds with with probability approaching one,

 |fb − fe| . |e| · kX(ϑ)
                      b − X(ϑ)k
                            e 2 + gb + b
                                       h . ζb := e · LX ∆n + gb + b
                                                                  h, ∆n ≥ kϑb − ϑk
                                                                                e ∞ , (B.10)

where LX = k∂v xk∞ ∨ kxk∞ , and, for some constant k,

       gb := e · 1{|Y − X(ϑ)  e ≤ k∆n }χ, and b
                          e 0 β|                            e 0γ
                                              h := e · 1{|S(ϑ) b − ς| ≤ k∆n },
               √
and ∆n = o(1/ n) is a deterministic sequence.
     Hence it suffices to show that the result follows from

                                           Gn [ζb ] = oP (1),                                      (B.11)

and
                                          √
                                           nEP [ζb ] = oP (1).                                     (B.12)

  Note that since ∆n → 0, with probability approaching one, gb and b
                                                                   h are elements of the
function classes

                 G = {e · 1(|Y − X(ϑ)0 β| ≤ k)χ : ϑ ∈ Υ0 , β ∈ B, k ∈ [0, ²0 /4]},
                 H = {e · 1(|S(ϑ)0 γ − ς| ≤ k) : ϑ ∈ Υ0 , γ ∈ Γ, k ∈ [0, 1]}.

By the argument similar to that in the proof of claim (a), we have that

            log N[] (², G, L2 (P )) . 1/(²2 log2 ²) and log N[] (², H, L2 (P )) . 1/(²2 log2 ²).
Hence these classes are P-Donsker with unit envelopes. Also note that
                          q                                       p
                kb
                 g kP,2 ≤  EP [e2 ] · P {|Y − X(ϑ)e 0 β|
                                                      e ≤ k∆n } ≤ 4kfY (· | ·)k∞ k∆n = o(1),       (B.13)
                          q                                      q
                kb
                 hkP,2          2           e 0
                         ≤ EP [e ] · P {|S(ϑ) γ b − ς| ≤ k∆n } ≤ 4f¯S k∆n = o(1),                  (B.14)

by the assumption on bounded densities and EP [e2 ] = 2.
                                                                                                       33

  Conclude that the relation (B.11) holds by (B.10), (B.13), (B.14), the P-Donskerity of the
empirical processes (Gn [h], h ∈ H) and (Gn [g], g ∈ G) and hence their asymptotic equiconti-
nuity under the k · kP,2 metric. Indeed, these properties imply
                                    b P,2 = o(1) ⇒ Gn [ζb ] = o(1).
                                   kζk

   To show (B.12) note that
                  √                     √
                         b . EP |e| · LX n∆n + kb
                    nEP |ζ|                     g kP,1 + kb
                                                          hkP,1 = o(1),
               √
since ∆n = o(1/ n), and
                                                                                    √
                                           e 0 β|
              g kP,1 ≤ EP |e| · P {|Y − X(ϑ)
             kb                                e ≤ k∆n } ≤ 2kkfY (· | ·)k∞ ∆n = o(1/ n)
                                                                          √
             kb                       e 0γ
              hkP,1 ≤ EP |e| · P {|S(ϑ)  b − ς| ≤ k∆n } ≤ 2k f¯S ∆n = o(1/ n),

by the assumption on bounded densities.




B.4. Lemma on Local Expansion.


Lemma 2 (Local expansion). Under the assumptions stated in the paper, for
       √
   δb = n(βe − β0 (u)) = OP (1); γ
                                 b = γ0 + oP (1);
               √                                √
    b w, z) = n(ϑ(d,
   ∆(d,             b w, z) − ϑ0 (d, w, z)) = n En [`(A, d, w, z)] + oP (1) in `∞ (DR),
     √
   k n En [`(A, ·)]k∞ = OP (1),

we have that
         √                                                   √
                        b 0 β}X(
           n EP 1{Y ≤ X(ϑ)  e    b
                                ϑ)1{S( b 0 γ ≥ ς}χ = J(u)δb + n En [g(A)] + oP (1),
                                      ϑ)

where
             Z
  g(A) =         B(a)`(A, d, r)dP (a, d, r), B(A) := fY (X 0 β0 (u)|X, C)X Ẋ 0 β0 (u)1(S 0 γ0 ≥ ς).


  Proof of Lemma 2. We have that with probability approaching one,
            b 0γ
        1{S(ϑ) b ≥ ς} ≤ 1{S 0 γ0 > ς − ²n } ≤ 1{S 0 γ0 > ς/2} ≤ 1{X 0 β0 (u) > C + ²0 } = χ,

P -a.e., by assumption on the selector since
                       b 0γ
                    |S(ϑ) b − S 0 γ0 | ≤ ²n := LS (kϑb − ϑ0 k∞ + kb
                                                                  γ − γ0 k2 ) →P 0,

where LS = (k∂v sk∞ ∨ ksk∞ ) is a finite constant by assumption.
34

     Hence uniformly in X such that X 0 β0 (u) > C + ²0 ,
                 √
                                 b 0 β}
                   nEP [1{Y ≤ X(ϑ)   e | D, W, Z, C]

                  = fY (X(ϑ̄X )0 β̄X | D, W, Z, C){X(ϑ̄X )0 δb + Ẋ(ϑ̄X )0 β̄X ∆(D,
                                                                               b    W, Z)}
                  = fY (X 0 β0 (u) | D, W, Z, C){X 0 δb + Ẋ 0 β0 (u)∆(D,
                                                                     b    W, Z)} + RX ,
                  = fY (X 0 β0 (u) | X, C){X 0 δb + Ẋ 0 β0 (u)∆(D,
                                                               b    W, Z)} + RX ,
                  R̄ =          sup             |RX | = oP (1),
                         {X:X 0 β0 (u)>C+²0 }

where ϑ̄X is on the line connecting ϑ0 and ϑb and β̄X is on the line connecting β0 (u) and β.
                                                                                           e
The first equality follows by the mean value expansion. The second equality follows by the
uniform continuity assumption of fY (· | X, C) uniformly in X, C, uniform continuity of X(·)
and Ẋ(·), and by kϑb − ϑ0 k∞ →P 0 and kβe − β0 (u)k2 →P 0. The third equality follows by

                     fY (· | D, W, Z, C) = fY (· | D, W, Z, V, C) = fY (· | X, C)

because V = ϑ0 (D, W, Z) and the exclusion restriction for Z.
  Since fY (· | ·) and the entries of X and Ẋ are bounded, and δb = OP (1) and k∆k
                                                                                 b ∞ = OP (1),
with probability approaching one
                           b 0 β)X(
                EP 1(Y ≤ X(ϑ)  e    b
                                    ϑ)1(S( b 0γ
                                          ϑ)  b ≥ ς)χ
                                                   b 0γ
                = EP [fY (X 0 β0 (u)|X, C)XX 0 1{S(ϑ) b ≥ ς}]δb
                                                          b 0γ
                +EP [fY (X 0 β0 (u)|X, C)X Ẋ 0 β0 (u)1{S(ϑ)       b
                                                             b ≥ ς}∆(D, W, Z)] + OP (R̄).     (B.15)

Furthermore since
                                     b 0γ
             EP |1(S 0 γ0 ≥ ς) − 1(S(ϑ) b ≥ ς)| ≤ EP [1(S 0 γ0 ∈ [ς ± ²n ])] . f¯S ²n →P 0,

where f¯S is a constant representing the uniform upper bound on the density of random
variable S 0 γ0 , the expression (B.15) is equal to

     J(u)δb + EP [fY (X 0 β0 (u)|X, C)X Ẋ 0 β0 (u)1(S 0 γ0 ≥ ς)∆(D,
                                                                b    W, Z)] + OP (f¯S ²n + R̄).
                  b w, z) = √n En [`(A, d, w, z)] + oP (1) and interchanging EP and En , we
Substituting in ∆(d,
obtain
                                                                      √
                                                        b
      EP [fY (X 0 β0 (u)|X, C)X Ẋ 0 β0 (u)1(S 0 γ0 ≥ ς)∆(D,  W, Z)] = n En [g(A)] + oP (1).

The claim of the lemma follows. ¤
                                                                                                   35

                             Appendix C. Proof of Theorem 3

  To show claim (1), we first note that by Chernozhukov, Fernández-Val and Melly (2009),
                                     n
        √                        1 X                                  −1
              π (v) − π0 (v)) = √
            n(b                         ei EP [fD (R0 π0 (v) | R)RR0 ] [v − 1{D ≤ R0 π0 (v)}]R.
                                  n i=1
By the Hadarmard differentiability of rearrangement-related operators in Chernozhukov,
Fernández-Val and Galichon (2010), the mapping π 7→ φπ from `∞ (0, 1)dim(R) to `∞ (DR)
defined by                             Z
                                 φπ (d, r) =           1{r0 π(v) ≤ d}dv
                                               (0,1)
is Hadamard differentiable at π = π0 , tangentially to the set of continuous directions, with
the derivative given by
                             φ̇π0 [h] = −fD (d | r)r0 h(ϑ0 (d, r)),
where ϑ0 (d, r) = φπ0 (d, r). Therefore by the Functional Delta Method (Theorem 20.8 in van
                                                  b r) = φπb (d, r),
der Vaart, 1998), we have that in `∞ (DR), for ϑ(d,
   √ b                                          P
     n(ϑ(d, r) − ϑ0 (d, r)) = −fD (d | r)r0 √1n ni=1 ei EP [fD (R0 π0 (ϑ0 (d, r)) | R)RR0 ]−1 ×
                                  ×[ϑ0 (d, r) − 1{D ≤ R0 π0 (ϑ0 (d, r))}]R + oP (1).
The claim (1) then follows immediately. Also for future reference, note that the result also
implies that
 √                                            √
     π (·) − π0 (·)) ⇒ Zπ in `∞ (0, 1), and r0 n(b
   n(b                                            π (·) − π0 (·)) ⇒ r0 Zπ in `∞ (R × (0, 1)),
                                                                                       (C.1)
where Zπ is a Gaussian process with continuous sample paths.
  The proof of claim (2) is divided in several steps:
                                                                            2
   Step 1. In this step we construct Υ and bound its entropy. Let CM          (0, 1) denote the class
of functions f : (0, 1) → R with all derivatives up to order 2 bounded by a constant M ,
including the zero order derivative. The covering entropy of this class is known to obey
           2                                                   dim(R) 2
log N (², CM (0, 1), k · k∞ ) . ²−1/2 . Hence also log N (², ×j=1 CM    (0, 1), k · k∞ ) . ²−1/2 . Next
construct for some small m > 0:
     ½Z                                                                                              ¾
                  0                                           dim(R) 2           0
Υ=           1{R π(v) ≤ D}dv : π = (π1 , ..., πdim(R) ) ∈ ×j=1 CM (0, 1), R ∂π(v) > m P -a.e. .
        (0,1)

Then for any π and π̄ obeying the conditions in the display and such that kπ − π̄k∞ ≤ δ,
                ¯Z                            Z                         ¯
                ¯                                                       ¯
                ¯             0
                         1{R π(v) ≤ D}dv −            1{R π̄(v) ≤ D}dv ¯¯
                                                         0
                ¯
                   (0,1)                        (0,1)
                    Z        n                                  o     1
                ≤           1 R0 π(v) − D ∈ [−kRk2 δ, kRk2 δ] dv . kRk2 δ . δ,
                      (0,1)                                          m
36

P -a.e., since the density of r0 π(V ), V ∼ U (0, 1), is bounded above by 1/m. We conclude
that
                                                    dim(R) 2
                 log N (², Υ, k · k∞ ) . log N (², ×j=1 CM   (0, 1), k · k∞ ) . ²−1/2 .

   Step 2. In this step we show that there exists ϑe ∈ Υ such that kϑe − ϑk     b ∞ = oP (1/√n).

     We first construct π
                        e such that
                 √                                           √
                   nkeπ−π bk∞ = oP (1),             and   max nkr0 (e
                                                                    π−π
                                                                      b)k∞ = oP (1),                    (C.2)
                                                           r∈R

                                                             dim(R)    2
where with probability approaching one, π
                                        e ∈ ×j=1                      CM (0, 1) and R0 ∂e
                                                                                        π (v) > m P -a.e., for
some M and some m > 0.
  We construct π e by smoothing π    b component by component. Let the components of π            b
be indexed by 1 ≤ j ≤ dim(R). Before smoothing, we need to extend π              bj outside (0, 1).
Start by extending the estimand π0j outside (0, 1) onto the ²-expansion (0, 1)² smoothly
so that the extended function is in the class C 3 . This is possible by first extending ∂ 3 π0j
smoothly and then integrating up to obtain lower order derivatives and the function. Then we
extend the estimator πbj to the outer region by simply setting π   bj (v) = π0j (v) over v ∈
                                                                                           / (0, 1).
                                              √
Note that the extended empirical process n(b      πj (v) − π0j (v)) remains to be stochastically
equicontinuous, since it vanishes asymptotically at the boundary of (0, 1). Then we construct
π
ej as the smoothed version of π bj , namely
                              Z
                    π
                    ej (v) =         π
                                     bj (z)[K((z − v)/h)/h]dz, v ∈ (0, 1),
                                    (0,1)²
                                            √                 √
where 0 ≤ h ≤ ² is bandwidth such that nh3 → 0 and nh2 → ∞; K : R → R is a third
order kernel with the properties: ∂ µ K are continuous on [−1, 1] and vanish outside of [−1, 1]
                R                 R
for µ = 0, 1, 2, K(z)dz = 1, and z µ K(z)dz = 0 for µ = 1, 2. Such kernel exists and can be
obtained by reproducing kernel Hilbert space methods or via twicing kernel transformations
(Berlinet, 1993, and Newey, Hsieh, and Robins, 2004). We then have
                           Z
   √                              √
     n(e
       πj (v) − π
                bj (v))  =           n[b
                                       πj (z) − π0j (z) − (b
                                                           πj (v) − π0j (v))][K([z − v]/h)/h]dz
                                (0,1)²
                                Z
                                             √
                            +                    n(π0j (z) − π0j (v))[K([z − v]/h)/h]dz.
                                    (0,1)²

The first term is bounded uniformly in v ∈ (0, 1) by ω(2h)kKk∞ →P 0 where
                                √
               ω(2h) = sup | n[b   πj (z) − π0j (z) − (b
                                                       πj (v) − π0j (v))]| →P 0.
                          |z−u|≤2h

The second term is bounded uniformly in v ∈ (0, 1), up to a constant, by
                                        Z
                       √    3         3
                                                       √
                         nk∂ π0j k∞ h     λ3 K(λ)dλ . nh3 → 0.
                                                                                                 37

This establishes the equivalence (C.2), in view of compactness of R.
  Next we show that k∂ 2 πej k∞ ≤ 2k∂ 2 π0j k∞ =: M with probability approaching 1. Note
that                               Z
            2           2
           ∂ πej (v) − ∂ π0j (v) =      bj (z)[∂ 2 K([z − v]/h)/h3 ]dz − ∂ 2 π0j (v),
                                        π
                                      (0,1)²
which can be decomposed into two pieces:
                            R
                 n−1/2 h−2 (0,1)² n1/2 (b
                                        πj (z) − π0j (z))[∂ 2 K([z − v]/h)/h]dz
                   R
                 + (0,1)² [∂ 2 K([z − v]/h)/h3 ]π0j (z)dz − ∂ 2 π0j (v).

The first piece is bounded uniformly in v ∈ (0, 1) by n−1/2 h−2 ω(2h)k∂ 2 Kk∞ → 0, while,
using the integration by parts, the second piece is equal to
                       Z
                            [∂ 2 π0j (z) − ∂ 2 π0j (v)][K([z − v]/h)/h]dz.
                          (0,1)²

This expression is bounded in absolute value by

                            kKk∞ sup |∂ 2 π0j (z) − ∂ 2 π0j (v)| → 0,
                                   |z−v|≤2h

by continuity of ∂ 2 π0j and compactness of (0, 1)² . Thus, we conclude that k∂ 2 π
                                                                                  ej −∂ 2 π0j k∞ →P
0, and we can also deduce similarly that k∂e     πj − ∂π0j k∞ →P 0, all uniformly in 1 ≤ j ≤
dim(R), since dim(R) is finite and fixed.
   Finally, since by Assumption 8(b) the conditional density is uniformly bounded above by
a constant, this implies that R0 ∂π0 (v) > k P -a.e., for some constant k > 0, and therefore we
also have that with probability approaching one, R0 ∂e    π (v) > k/2 =: m P -a.e.
  Next we construct
                                                Z
                          e r) = φπe (d, r) =
                          ϑ(d,                              1{r0 π
                                                                 e(v) ≤ d}dv.
                                                    (0,1)

Note that by construction ϑe ∈ Υ for some M with probability approaching one. It remains
                                         b
to show the first order equivalence with ϑ.
   By the Hadarmard differentiability for the mapping φπ stated earlier and by the functional
delta method (Theorem 20.8 in van der Vaart, 1998), ϑe and ϑb have the same first order
representation in `∞ (DR),
                       √                    √
                           e − ϑ0 (·)) = n(ϑ(·)
                         n(ϑ(·)                 b − ϑ0 (·)) + oP (1),
     √
i.e., nkϑe − ϑk
             b ∞ →P 0. ¤
38

                              Appendix D. Proof of Theorem 4

   Claim (1) follows from the results of Chernozhukov, Fernández-Val and Melly (2009). Also
for future reference, note that these results also imply that
   √                                            √
        π (·) − π0 (·)) ⇒ Zπ in `∞ (D), and r0 n(b
      n(b                                           π (·) − π0 (·)) ⇒ r0 Zπ in `∞ (RD), (D.1)

where Zπ is a Gaussian process with continuous sample paths.
     The proof of claim (2) is divided in several steps:
                                                                      2
   Step 1. In this step we construct Υ and bound its entropy. Let CM    (D) denote the class
of functions f : D → R with and all the derivatives up to order 2 bounded by a constant
M , including the zero order derivative. The covering entropy of this class is known to obey
        2
log(², CM (D), k · k∞ ) . ²−1/2 . Hence
                                        dim(R)    2
                                log(², ×j=1      CM (D), k · k∞ ) . ²−1/2 .

Next construct
                         n                                                            o
                                0                                      dim(R) 2
                   Υ = Λ(R π(D)) : π = (π1 , ..., πdim(R) ) ∈         ×j=1 CM   (D)       .

Then, for any π and π̄ obeying the condition in the definition of the preceding class such
that kπ − π̄k∞ ≤ δ,

                             |Λ(R0 π(D)) − Λ(R0 π̄(D))| ≤ k∂Λk∞ sup krk∞ δ.
                                                                         r∈R

We conclude that
                                                       dim(R)    2
                   log N (², Υ, k · k∞ ) . log N (², ×j=1       CM (D), k · k∞ ) . ²−1/2 .

                                                                           b ∞ = oP (1/√n).
     Step 2. In this step we show that there exists ϑe ∈ Υ such that kϑe − ϑk
     We first construct π
                        b and π
                              e such that,
                 √                                       √
                   nkeπ−π bk∞ = oP (1), and           max nkr0 (e
                                                                π−π
                                                                  b)k∞ = oP (1),              (D.2)
                                                      r∈R

                                                        dim(R)    2
where with probability approaching one, π
                                        e ∈ ×j=1                 CM (D), for some M .
   We construct π  e by smoothing π b component by component. Before smoothing, we extend
the estimand π0j outside D, onto the ²-expansion D² smoothly so that the extended function
is of class C 3 . This is possible by first extending the third derivative of π0j smoothly and
then integrating up to obtain lower order derivatives and the function. Then we extend π    bj
to the outer region by simply setting π   bj (d) = π0j (d) over d ∈
                                                                  / D. Note that the extended
         √
process n(b   πj (d) − π0j (d)) remains to be stochastically equicontinuous, since it vanishes
                                                                                             39

asymptotically at the boundary of D. Then we define the smoothed version of π
                                                                            bj as
                                Z
                       π
                       ej (d) =   π
                                  bj (z)[K((z − d)/h)/h]dz, d ∈ D,
                                    D²
                                             √                √
where 0 ≤ h ≤ ² is bandwidth such that nh3 → 0 and nh2 → ∞; K : R → R is a third
order kernel with the properties: ∂ µ K are continuous on [−1, 1] and vanish outside of [−1, 1]
                 R                     R
for µ = 0, 1, 2, K(z)dz = 1, and z µ K(z)dz = 0 for µ = 1, 2. Such kernel exists and
can be obtained by reproducing kernel Hilbert space methods or via twicing kernel methods
(Berlinet, 1993, and Newey, Hsieh, and Robins, 2004). We then have
                            Z
    √                            √
      n(e
        πj (d) − π
                 bj (d))  =        n[bπj (z) − π0j (z) − (b
                                                          πj (d) − π0j (d))][K([z − d]/h)/h]dz
                              D²
                              Z
                                  √
                           +         n(π0j (z) − π0j (d))[K([z − d]/h)/h]dz.
                                D²

The first term is bounded uniformly in d ∈ D by ω(2h)kKk∞ →P 0 where
                                √
               ω(2h) = sup | n[b   πj (z) − π0j (z) − (b
                                                       πj (d) − π0j (d))]| →P 0.
                         |z−u|≤2h

The second term is bounded uniformly in d ∈ D, up to a constant, by
                                        Z
                       √    3         3
                                                     √
                         nk∂ π0j k∞ h     λ3 K(λ)dλ . nh3 → 0.

This establishes the equivalence (D.2), in view of compactness of R.
  Next we show that k∂ 2 π ej k∞ ≤ 2k∂ 2 π0j k∞ := M with probability approaching 1. Note
that                                Z
             2           2
            ∂ πej (d) − ∂ π0j (d) =     bj (z)[∂ 2 K([z − d]/h)/h3 ]dz − ∂ 2 π0j (d),
                                        π
                                         D²
which can be decomposed into two pieces:
                          R
                 n−1/2 h−2 D² n1/2 (b
                                    πj (z) − π0j (z))[∂ 2 K([z − d]/h)/h]dz
                        R
                     + D² [∂ 2 K([z − d]/h)/h3 ]π0j (z)dz − ∂ 2 π0j (d).

The first piece is bounded uniformly in d ∈ D by n−1/2 h−2 ω(2h)k∂ 2 Kk∞ → 0, while, using
the integration by parts, the second piece is equal to
                        Z
                            [∂ 2 π0j (z) − ∂ 2 π0j (d)][K([z − d]/h)/h]dz,
                          D²

which converges to zero uniformly in d ∈ D by the uniform continuity of ∂ 2 π0j on D² and
by boundedness of the kernel function. Thus k∂ 2 π
                                                 ej − ∂ 2 π0j k∞ →P 0, and similarly conclude
that k∂eπj − ∂π0j k∞ →P 0, where convergence is uniform in 1 ≤ j ≤ dim(R), since dim(R) is
finite and fixed.
40

                     e d) = Λ(r0 π
   We then construct ϑ(r,          e(d)). Note that by the preceding arguments ϑe ∈ Υ
                                                                                 √
for some M with probability approaching one. Finally, the first order equivalence nkϑe −
b ∞ →P 0 follows immediately from (D.2), boundedness of k∂Λk∞ and compactness of R.
ϑk
¤




                          Appendix E. Monte Carlo designs

   For the homoskedastic design, we use the following parametric linear version of the system
of equations (2.4)–(2.5) to generate the observations:

                   D = π00 + π01 Z + π02 W + Φ−1 (V ),       V v U (0, 1),                (E.1)
                  Y ∗ = β00 + β01 D + β02 W + Φ−1 (²),      ² v U (0, 1),                 (E.2)

where Φ−1 denotes the quantile function of the standard normal distribution, and (Φ−1 (V ),
Φ−1 (²)) is jointly normal with correlation ρ0 . Though we can observe Y ∗ in the simulated
data, we artificially censor the data to observe

                 Y = max(Y ∗ , C) = max(β00 + β01 D + β02 W + Φ−1 (²), C).                (E.3)

From the properties of the multivariate normal distribution, Φ−1 (²) = ρ0 Φ−1 (V ) + (1 −
ρ20 )1/2 Φ−1 (U ), where U v U (0, 1). Using this expression, we can combine (E.1) and (E.3)
for an alternative formulation of the censored model in which the control term Vi is included
in the equation for the observed response:

     Y = max(Y ∗ , C) = max(β00 + β01 D + β02 W + ρ0 Φ−1 (V ) + (1 − ρ20 )1/2 Φ−1 (U ), C).

This formulation is useful because it indicates that when we include the control term in the
quantile function, its true coefficient is ρ0 .
   In our simulated data, we create extreme endogeneity by setting ρ0 = .9. We set π00 =
β00 = 0, and π01 = π02 = β01 = β02 = 1. We draw the disturbances [Φ−1 (V ), Φ−1 (²)] from a
bivariate normal distribution with zero means, unit variances and correlation ρ0 . We draw
Z from a standard normal distribution, and we generate W to be a log-normal random
variable that is censored from the right at its 95th percentile, qW . Formally, we draw Wf
from a standard normal distribution. We then calculate qW = QW (.95), which differs across
                                              f
replication samples. Next, we set W = min(eW , qW ). For comparative purposes, we set the
amount of censoring in the dependent variable to be comparable to that in Kowalski (2009).
Specifically, we set C = C = QY ∗ (.38) in each replication sample. We report results from
1,000 simulations with n = 1, 000.
                                                                                              41

   For the heteroskedastic design, we replace the first stage equation for D in (E.1) by the
following equation:

             D = π00 + π01 Z + π02 W + (π03 + π04 W )Φ−1 (V ),     V v U (0, 1)           (E.4)

where we set π03 = π04 = 1. The corresponding conditional quantile function is

                 QD (v | W, Z) = π00 + π01 Z + π02 W + (π03 + π04 W )Φ−1 (v),

and can be consistently estimated by quantile regression or other estimator for location-scale
shift models.


   Appendix F. CQIV Technical Details and Robustness Diagnostic Test

   For the OLS estimator of the control variable, we run an OLS first stage and retain
the predicted residuals from the OLS first stage as the control variable. For the quantile
estimator of the control variable, we run first stage quantile regressions at each quantile from
.01 to .99 in increments of .01. Next, for each observation, we compute the fraction of the
quantile estimates for which the predicted value of the endogenous variable is less than or
equal to the true value of the endogenous variable. We then evaluate the standard normal
quantile function at this value and retain the result as the estimate of the control variable.
In this way, the quantile estimate of the control variable allows for heteroskedasticity in the
first stage.
   For the distribution regression estimator of the control variable, we first create a matrix
n ∗ n of indicators, where n is the sample size. For each value of the endogenous variable
in the data set yj in columns, each row i gives if the log-expenditure of the individual i is
less or equal than yj (1(yi ≤ yj )). Second, for each column j of the matrix of indicators,
we run a probit regression of the column on the exogenous variables. Finally, the estimate
of the control variable for the observation i is the quantile function of the standard normal
evaluated at the predicted value for the probability of the observation i = j.
   In Table B1, we present the CQIV robustness diagnostic tests suggested in section 3 for
the CQIV estimator with an OLS estimate of the control variable. In our estimates, we
used a probit model in the first step, and we set q0 = 10 and q1 = 3. In practice, we do not
necessarily recommend reporting the diagnostics in Table B1, but we have included them here
for expositional purposes. In the top section of the table, we present diagnostics computed
after CQIV Step 1. At the 0.05 quantile, observations are retained in J0 if their predicted
probability of being uncensored exceeds 1−u+k0 = 1−.05+.0445 = .9945. Empirically, this
leaves 47.0% of the total sample in J0 in the median replication sample. In all statistics, the
variation across replication samples appears small. However, as intended by the algorithm,
there is meaningful variation across the estimated quantiles. As the estimated quantile
42

increases, the percentage of observations retained in J0 increases. From these diagnostics,
the CQIV estimator appears well-behaved in the sense that the percentage of observations
retained in J0 is never very close to 0 or 100.
  In the second section of Table B1, we present robustness test diagnostics computed after
CQIV Step 2. Observations are retained in J1 if the predicted Yi exceeds Ci + ς1 , where
the median value of Ci , as shown in the table, is 1.60, and the median value of ς1 at the
.05 quantile is 1.70. As desired, at each quantile, the percentage of observations retained in
J1 is smaller than the percentage of observations with predicted values above Ci but larger
than the percentage of observations retained in J0 . As shown in sections of the table labeled
“Percent J0 in J1 ” and “Count J1 not in J0 ” J0 is almost a proper subset of J1 .
   In the last section of Table B1, we report the value of the Powell objective function obtained
after CQIV Step 2 and CQIV Step 3. The last column shows that on average the final CQIV
step represents an improvement in the objective function in 36-51% of replication samples
across the estimated quantiles. In our CQIV simulation results, we report the results from
the third step. Researchers might prefer to select select results from the second or third step
based on the value of the objective function.
                                                                                                      43

                                            References
 [1] Andrews, Donald W. K. “Asymptotics for semiparametric econometric models via stochastic equicon-
     tinuity. ” Econometrica. 1994. 62 no. 1. pp 43-72.
 [2] Angrist, Joshua D., Imbens, Guido W., and Rubin, Donald B. “Identification of Causal Effects Using
     Instrumental Variables.” Journal of the American Statistical Association. 1996. 91. pp 444-455.
 [3] Banks, James, Blundell, Richard, and Lewbel, Arthur. “Quadratic Engel Curves and Consumer De-
     mand.” Review of Economics and Statistics. 1997. 79(4). pp 527-539.
 [4] Berlinet, Alain. “Hierarchies of higher order kernels.” Probability Theory and Related Fields. 1993.
     94(4). pp 489-504.
 [5] Blundell, Richard, Browning, Martin, and Crawford, Ian. “Nonparametric Engel Curves and Revealed
     Preference.” Econometrica. 2003. 71(1). pp 205-240.
 [6] Blundell, Richard, Chen, Xiaohong, and Kristensen, Dennis. “Semi-nonparametric IV Estimation of
     Shape-Invariant Engel Curves.” Econometrica. 2007. 75(6). pp. 1613-1669.
 [7] Blundell, Richard, and Matzkin, Rosa. “Conditions for the Existence of Control Functions in Nonsep-
     arable Simultaneous Equations Models.” CEMMAP Working Paper 28/10.
 [8] Blundell, Richard, Duncan, Alan, and Pendakur, Krishna. “Semiparametric Estimation and Consumer
     Demand.” Journal of Applied Econometrics. 1998. 13(5). pp. 435-461.
 [9] Blundell, Richard, and Powell, James. “Censored Regression Quantiles with Endogenous Regressors.”
     Journal of Econometrics. 2007. 141. pp. 65-83.
[10] Chamberlain, Gary, and Imbens, Guido. “Nonparametric applications of Bayesian inference.” Journal
     of Business and Economic Statistics. 2003. 21(1). pp. 12-18.
[11] Chen, Xiaohong, and Pouzo, Demian. “Efficient estimation of semiparametric conditional moment
     models with possibly nonsmooth residuals.” Journal of Econometrics. 2009. 152(1). pp. 46-60.
[12] Chernozhukov, Victor, Fernandez-Val, Ivan, and Galichon, Alfred. “Quantile and Probability Curves
     without Crossing.” Econometrica. 2010. 78(3, May) 1093-1125.
[13] Chernozhukov, Victor, Fernandez-Val, Ivan, and Melly, Blaise. “Inference on Counterfactual Distribu-
     tions.” MIT Department of Economics Working Paper. 08-16. 2009.
[14] Chernozhukov, Victor, and Hansen, Christian. “Instrumental variable quantile regression: A robust
     inference approach.” Journal of Econometrics. January 2008. 142(1). pp.379-398.
[15] Chernozhukov, Victor, and Hong, Han. “Three-Step Quantile Regression and Extramarital Affairs.”
     Journal of The American Statistical Association. September 2002. 97(459). pp. 872-882.
[16] Chesher, A. “Identification in Nonseparable Models.” Econometrica, 2003, 71(5), pp. 1405-1441.
[17] Deaton, Angus and Muelbauer, John. Economics and consumer behavior. Cambridge University Press.
     1980.
[18] Foresi, Silverio and Peracchi, Franco. “The Conditional Distribution of Excess Returns: An Empirical
     Analysis.” Journal of the American Statistical Association, 1995, 90(430), pp.451-466.
[19] Frisch, R. “Circulation Planning: : Proposal For a National Organization of a Commodity and Service
     Exchange.” Econometrica. 1934. 2(3), 258-336.
[20] Gorman, W.M. “Separable Utility and Aggregation.” Econometrica. 1959 27(3), 469-481.
[21] Hausman, Jerry A.“Specification Tests in Econometrics.” Econometrica. 1978. 46(6). pp. 1251-71.
[22] Hausman, Jerry, Newey, Whitney, and Powell, James. “Nonlinear Errors in Variables Estimation of
     Some Engel Curves.” Journal of Econometrics. 1995. 65. pp. 203-233.
44

[23] Heckman, James J. “Sample Selection Bias as a Specification Error” Econometrica. 1979. 47(1), 153-
     161.
[24] Imbens, Guido W., and Newey, Whitney K.. “Identification and Estimation of Triangular Simultaneous
     Equations Models without Additivity.”NBER Technical Working Paper 285. 2002.
[25] Imbens, Guido W., and Newey, Whitney K.. “Identification and Estimation of Triangular Simultaneous
     Equations Models without Additivity.”Econometrica. 2009. 77(5) 1481-1512.
[26] Jun, Sung Jae. “Local structural quantile effects in a model with a nonseparable control vari-
     able.”Journal of Econometrics. 2009. 151(1) 82-97.
[27] Koenker, Roger. Quantile Regression. Cambridge University Press. 2005.
[28] Koenker, Roger, and Bassett, Gilbert Jr. “Regression Quantiles.” Econometrica, 1978, 46(1), pp. 33-50.
[29] Koopmans, T.C. and Hood, W.C.. “The estimation of simultaneous linear economic relationships.”
     W.C. Hood and T.C. Koopmans, Editors, Studies in econometric method, Wiley, New York (1953).
[30] Kowalski, Amanda E. “Censored Quantile Instrumental Variable Estimates of the Price Elasticity of
     Expenditure on Medical Care.” NBER Working Paper 15085. 2009.
[31] Lee, Sokbae. “Endogeneity in quantile regression models: A control function approach.” Journal of
     Econometrics. 2007. 141, pp. 1131-1158.
[32] Lewbel, Arthur. “Entry for the New Palgrave Dictionary of Economics, 2nd Edition. ” Boston College.
     2006.
[33] Ma, Lingjie and Koenker, Roger. “Quantile regression methods for recursive structural equation mod-
     els.” Journal of Econometrics. 2006. 134(2). pp. 471-506.
[34] Ma, Shuangge, and Kosorok, Michael. “Robust semiparametric M-estimation and the weighted boot-
     strap.” Journal of Multivariate Analysis. 2005. 96(1). pp. 190-217.
[35] Matzkin, Rosa L. “Nonparametric Identification.”In Handbook of Econometrics, Vol. 6B, ed. by J.
     Heckman and E. Leamer. 2007. Amsterdam : Elsevier.
[36] Newey, Whitney K. “Efficient Estimation of Limited Dependent Variable Models with Endogenous
     Explanatory Variables.” Journal of Econometrics, 1987, 36, pp. 231-250.
[37] Newey, Whitney K. “The asymptotic variance of semiparametric estimators. ” Econometrica, 1994. 62
     no. 6. 1349-1382.
[38] Newey, Whitney K., Hsieh, Fushing, Robins, James M. “Twicing kernels and a small bias property of
     semiparametric estimators. ” Econometrica. 2004. 72(3). pp 947-962.
[39] Newey, Whitney K., Powell, James L., Vella, Francis. “Nonparametric Estimation of Triangular Simul-
     taneous Equations Models.” Econometrica. 1999. 67(3), 565-603.
[40] Powell, James L. “Censored Regression Quantiles.” Journal of Econometrics, 1986. 23. pp-143-155.
[41] Powell, James L. “Least absolute deviations estimation for the censored regression model.” Journal of
     Econometrics, 1984, 25(3), pp. 303-325.
[42] Powell, James L. “Chapter 14: Estimation of Monotonic Regression Models under Quantile Restric-
     tions.” Nonparametric and Semiparametric Methods in Econometrics and Statistics: Proceedings of the
     Fifth International Symposium in Economic Theory and Econometrics. 1991
[43] Smith, Richard J. and Blundell, Richard W. “An Exogeneity Test for a Simultaneous Equation Tobit
     Model with an Application to Labor Supply.” Econometrica, 1986, 54(3), pp. 679-685.
[44] van der Vaart. Asymptotic Statistics. Cambridge University Press. 1998.
[45] van der Vaart, A.W. and Wellner, Jon A. Weak convergence and empirical processes. Springer. 1996.
[46] Wooldridge, Jeffrey M. Econometric Analysis of Cross Section and Panel Data. MIT Press. Cambridge,
     MA. Second Edition. 2010.
                                                                                                                                                                           45




                                                                                 Bias in Coefficient of D


                      60




                      40




                      20
           Bias (%)




                       0




                      -20




                      -40




                      -60
                             0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95
                                                                                        Quantile

                            CQIV-OLS              CQIV-QR              CQIV-DR              QIV-OLS              CQR           QR            Tobit-IV         Tobit-CMLE




                                                                                 RMSE in Coefficient of D


                      60




                      50




                      40
           RMSE (%)




                      30




                      20




                      10




                       0
                             0.05   0.10   0.15   0.20   0.25   0.30   0.35   0.40   0.45   0.50   0.55   0.60   0.65   0.70   0.75   0.80   0.85   0.90   0.95
                                                                                        Quantile

                            CQIV-OLS              CQIV-QR              CQIV-DR              QIV-OLS              CQR           QR            Tobit-IV         Tobit-CMLE




Figure 1: Homoskedatic design: Mean bias and RMSE of Tobit and QR estimators. Results
obtained from 1,000 samples of size n = 1, 000.
46




                                                                                 Bias in Coefficient of D


                      60




                      40




                      20
           Bias (%)




                       0




                      -20




                      -40




                      -60
                             0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95
                                                                                        Quantile

                            CQIV-OLS              CQIV-QR              CQIV-DR              QIV-OLS              CQR           QR            Tobit-IV         Tobit-CMLE




                                                                                 RMSE in Coefficient of D


                      60




                      50




                      40
           RMSE (%)




                      30




                      20




                      10




                       0
                             0.05   0.10   0.15   0.20   0.25   0.30   0.35   0.40   0.45   0.50   0.55   0.60   0.65   0.70   0.75   0.80   0.85   0.90   0.95
                                                                                        Quantile

                            CQIV-OLS              CQIV-QR              CQIV-DR              QIV-OLS              CQR           QR            Tobit-IV         Tobit-CMLE




Figure 2: Heteroskedastic design: Mean bias and RMSE of Tobit and QR estimators. Results
obtained from 1,000 samples of size n = 1, 000.
                                                                                                                                                                                                                                                   47



                                   Coefficient of log expenditure                                                                                  Coefficient of log expenditure squared

0.8                                                                                                                       0


0.7
                                                                                                                     -0.01

0.6
                                                                                                                     -0.02
0.5


0.4                                                                                                                  -0.03


0.3
                                                                                                                     -0.04

0.2
                                                                                                                     -0.05
0.1

                                                                                                                     -0.06
  0


-0.1                                                                                                                 -0.07
       15    20        25     30   35      40     45        50     55     60   65    70        75        80    85   90        15    20        25        30     35   40      45        50     55   60     65        70        75    80   85    90
                                                  Quantile                                                                                                                       Quantile

                       CQIV                QIV                   Tobit-CMLE              CQR                   QR                              CQIV                  QIV                   Tobit-CMLE                   CQR              QR




                                           Coefficient of kids                                                                                               Coefficient of control variable


       0                                                                                                                  0.03



  -0.01                                                                                                                  0.025



  -0.02                                                                                                                   0.02



  -0.03                                                                                                                  0.015



  -0.04                                                                                                                   0.01



  -0.05                                                                                                                  0.005



  -0.06                                                                                                                        0



  -0.07                                                                                                                  -0.005
            15    20    25    30    35    40     45    50    55      60   65   70   75    80        85    90                       15    20        25    30    35   40     45    50    55    60   65    70    75        80    85   90
                                                      Quantile                                                                                                                  Quantile

                   CQIV                  QIV                Tobit-CMLE              CQR                       QR                                                CQIV                   QIV              Tobit-CMLE




                                                                        Figure 3: Coefficients of Engel Curves
                                                                                                                                                                                                                                                                                           48



                                                                                                                           Average Quantile Elasticities                                                                     95% Confidence Intervals for CQIV



                                                                                              0.04                                                                                               0.04




                                                                                              0.02                                                                                               0.02




                                                                                                 0                                                                                                  0




                                                                                              -0.02                                                                                              -0.02




exponentially distributed weights.
                                                                                              -0.04                                                                                              -0.04




                                                                                              -0.06                                                                                              -0.06




                                                                                              -0.08
                                                                                                                                                                                                 -0.08




                                                                                               -0.1
                                                                                                                                                                                                  -0.1




                                                                                              -0.12
                                                                                                                                                                                                 -0.12
                                                                                                      15   20   25     30    35   40    45   50    55    60   65    70   75   80      85    90
                                                                                                                                                                                                         15   20   25   30   35   40   45    50    55   60   65   70   75   80   85   90
                                                                                                                                             Quantile
                                                                                                                                                                                                                                            Quantile

                                                                                                                     CQR           QR             CQIV             QIV             Tobit-CMLE




elasticities. The intervals are obtained by weighted bootstrap with 200 replications and
Figure 4: Estimates and 95% pointwise confidence intervals for average quantile expenditure
                                                                                                                                                                              49



                    Kids, .25 quantile control variable                                              No kids, .25 quantile control variable

   0.14                                                                                  0.14


   0.12                                                                                  0.12


    0.1                                                                                   0.1


   0.08                                                                                  0.08


   0.06                                                                                  0.06


   0.04                                                                                  0.04


   0.02                                                                                  0.02


     0                                                                                     0
          4   4.2     4.4     4.6    4.8     5     5.2     5.4    5.6    5.8         6          4   4.2   4.4   4.6       4.8   5       5.2        5.4   5.6     5.8     6

                                    Log-expenditure                                                                      Log-expenditure




                    Kids, .50 quantile control variable                                              No kids, .50 quantile control variable

   0.14                                                                                  0.14


   0.12                                                                                  0.12


    0.1                                                                                   0.1


   0.08                                                                                  0.08


   0.06                                                                                  0.06


   0.04                                                                                  0.04


   0.02                                                                                  0.02

     0                                                                                      0
          4   4.2     4.4     4.6    4.8    5      5.2    5.4    5.6    5.8      6              4   4.2   4.4    4.6      4.8   5        5.2       5.4   5.6     5.8      6

                                    Log-expenditure                                                                      Log-expenditure



                    Kids, .75 quantile control variable                                              No kids, .75 quantile control variable

   0.14
                                                                                         0.14

   0.12
                                                                                         0.12

    0.1
                                                                                          0.1

   0.08
                                                                                         0.08

   0.06
                                                                                         0.06

   0.04
                                                                                         0.04

   0.02
                                                                                         0.02

     0
                                                                                           0
          4   4.2     4.4     4.6    4.8    5     5.2     5.4    5.6    5.8      6
                                                                                                4   4.2   4.4   4.6       4.8   5       5.2        5.4   5.6     5.8     6
                                    Log-expenditure
                                                                                                                         Log-expenditure
                    .25 quantile           .50 quantile           .75 quantile
                                                                                                          .25 quantile              .50 quantile               .75 quantile




Figure 5: Family of Engel curves: each panel plots Engel curves for the three quantiles of
alcohol share.
50


Table B1: CQIV Robustness Diagnostic Test Results
for CQIV with OLS Estimate of the Control Variable - Homoskedastic Design



     CQIV-OLS Step 1
                                    k0                               Percent J0
     Quantile        Median         Min          Max       Median       Min         Max
          0.05            0.04            0.04      0.05     47.20       43.30       50.30
            0.1           0.09            0.06      0.10     49.10       46.00       51.30
          0.25            0.20            0.15      0.24     52.20       50.50       53.70
            0.5           0.36            0.26      0.46     55.80       54.80       56.80
          0.75            0.43            0.29      0.58     59.40       57.70       61.10
            0.9           0.37            0.22      0.58     62.40       60.30       65.10
          0.95            0.30            0.18      0.54     64.20       61.40       67.50

     CQIV-OLS Step 2
                                      1                            Percent J1                  Percent Predicted Above C
     Quantile        Median         Min          Max       Median     Min         Max         Median      Min         Max
          0.05            1.70            1.45      2.01     50.70      46.70      54.90        52.30       48.20       56.70
            0.1           1.71            1.44      1.96     52.80      49.50      55.50        54.50       51.10       57.30
          0.25            1.71            1.46      1.98     56.30      53.60      58.70        58.10       55.30       60.60
            0.5           1.72            1.44      2.02     60.10      57.60      63.40        62.00       59.40       65.40
          0.75            1.73            1.47      1.99     64.00      61.20      66.80        66.00       63.10       68.90
            0.9           1.75            1.44      2.01     67.40      64.60      70.60        69.50       66.60       72.80
          0.95            1.76            1.49      2.02     69.30      65.60      72.80        71.50       67.70       75.10
                                    C                            Percent J0 in J1                 Count in J1 not in J0
     Quantile        Median         Min          Max       Median     Min         Max         Median      Min         Max
          0.05            1.60            1.33      1.85       100       97.7       100            36           0          81
            0.1           1.60            1.33      1.85       100       99.0       100            37           7          74
          0.25            1.60            1.33      1.85       100       99.6       100            40          15          68
            0.5           1.60            1.33      1.85       100       99.6       100            43          23          78
          0.75            1.60            1.33      1.85       100       99.7       100            47          17          74
            0.9           1.60            1.33      1.85       100       99.7       100            50          15          88
          0.95            1.60            1.33      1.85       100       99.1       100            51          16          97

     Comparison of Objective Functions
                              Objective Step 3                   Objective Step 2            Objective Step 3<Objective Step 2
     Quantile         Median         Min         Max       Median      Min          Max       Median                  Mean
          0.05             5058         4458       5674       5054       4400         5753             0                  0.44
            0.1            8939         7925       9946       8927       7888        10049             0                  0.47
          0.25            17292        15100      19839      17271      14741        20052             0                  0.44
            0.5           22859        18692      27022      22837      18306        27091             0                  0.45
          0.75            16073         9603      22872      15895       8737        22866             0                  0.42
            0.9           -1016        -9624       7150      -1047     -10834         9265             0                  0.45
          0.95           -13815       -24602      -2884     -14034     -27816        -1919             0                  0.44
     N=1,000, Replications=1,000
