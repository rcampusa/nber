                               NBER WORKING PAPER SERIES




     THE PROBLEM OF DATA QUALITY IN ANALYSES OF OPIOID REGULATION:
          THE CASE OF PRESCRIPTION DRUG MONITORING PROGRAMS

                                          Jill Horwitz
                                         Corey S. Davis
                                       Lynn S. McClelland
                                       Rebecca S. Fordon
                                          Ellen Meara

                                       Working Paper 24947
                               http://www.nber.org/papers/w24947


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                                    August 2018




The authors thank Chris Auld for helpful comments and Allison Borsheim and Joshua Parson for
research assistance. Supported by grants (P01AG019783 and U01AG046830) from the National
Institute on Aging. The views expressed herein are those of the authors and do not necessarily
reflect the views of the National Bureau of Economic Research.

At least one co-author has disclosed a financial relationship of potential relevance for this
research. Further information is available online at http://www.nber.org/papers/w24947.ack

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2018 by Jill Horwitz, Corey S. Davis, Lynn S. McClelland, Rebecca S. Fordon, and Ellen
Meara. All rights reserved. Short sections of text, not to exceed two paragraphs, may be quoted
without explicit permission provided that full credit, including © notice, is given to the source.
The Problem of Data Quality in Analyses of Opioid Regulation: The Case of Prescription
Drug Monitoring Programs
Jill Horwitz, Corey S. Davis, Lynn S. McClelland, Rebecca S. Fordon, and Ellen Meara
NBER Working Paper No. 24947
August 2018
JEL No. I1,I12,I18,K32,K42

                                          ABSTRACT

States, which have the primary legal role in regulating the prescribing and dispensing of
prescription medications, have created Prescription Drug Monitoring Programs (PDMP) to try to
reduce inappropriate prescribing, dispensing, and related harm. Research assessing whether these
interventions are effective has produced inconclusive and contradictory results. Here we examine
whether different data sources may have contributed to the varying results. Specifically, we: 1)
identify the decisions inherent in creating such a dataset; 2) discuss the public data sources used
by researchers in previous work; 3) develop and apply a detailed research protocol to create a
novel PDMP law dataset; and 4) to illustrate potential consequences of data choice, apply various
data sources to analyze the relationship between PDMP laws and prescribing and dispensing of
opioids among disabled Medicare beneficiaries. We find that our dates differ from those in
existing datasets, sometimes by many years. The regression analyses generated a twofold
difference in point estimates, as well as different signed estimates, depending on the data used.
We conclude that the lack of transparency about data assembly in existing datasets, differences
among dates by source, and the regression results raise concerns for PDMP researchers and
policymakers.

Jill Horwitz                                     Rebecca S. Fordon
University of California Los Angeles             UCLA School of Law
School of Law                                    385 Charles Young Drive East
Box 951476                                       Los Angeles, CA 90095
Los Angeles, CA 90095-1476                       fordon@law.ucla.edu
and NBER
horwitz@law.ucla.edu                             Ellen Meara
                                                 Dartmouth Institute for Health Policy
Corey S. Davis                                   and Clinical Practice
Network For Public Health Law                    WTRB 5th floor, #537
3701 Wilshire Blvd, Suite #750                   1 Medical Center Drive
Los Angeles, CA 90010                            Lebanon, NH 03766
davis@healthlaw.org                              and NBER
                                                 ellen.r.meara@dartmouth.edu
Lynn S. McClelland
UCLA School of Law
385 Charles Young Drive East
Los Angeles, CA 90095
mcclelland@law.ucla.edu
I.     INTRODUCTION

       Despite widespread attention in the media, by policy makers, and by states, the burden of

opioid-related harm in the United States continues to increase. Drug overdose, which cut short

the lives of more than 63,000 Americans in 2016, is now the leading cause of death for

Americans under age 50 and is the leading overall cause of accidental death, surpassing deaths

from traffic accidents (Centers for Disease Control, 2017). The majority of these deaths, over

42,000, involved opioids (Hedegaard and Minino, 2017). Although the causes of the crisis are

varied and complex, it is clear that opioid prescribing, which increased by over 300% from 1999

to 2015, contributed to this seemingly inexorable rise in preventable morbidity and mortality

(Guy et al 2017; Kunins 2013, Case and Deaton 2015). States, which have the primary legal role

in regulating the prescribing and dispensing of prescription drugs, have taken the lead in

attempting to reduce opioid-related harm. They have done so, in part, by creating Prescription

Drug Monitoring Programs (PDMPs), databases that collect information on certain medications

at the point of dispensing, and in most cases make those data available to authorized users (Davis

et al 2014).

       Over the past several years, researchers have been doing the critical work of assessing

whether these laws and the PDMPs they create have been effective at reducing inappropriate

prescribing, dispensing, and opioid-related health harms. To date, the results of these studies

have been inconclusive and sometimes contradictory (Davis et al 2017). There are a number of

potential reasons for these disparate findings, including that the studies measure somewhat

different outcomes and different populations and they often account only for a limited range of

policies (mainly PDMP implementation) when states implemented varied packages of laws

around the same time. Regardless, recent Federal legislation meant to combat the opioid crisis,



       3
such as the Comprehensive Addiction and Recovery Act of 2016 and the 21st Century Cures Act,

all include some funds targeting PDMPs. States will continue to seek best practice around

PDMPs as they spend scarce resources on their programs.

       Here we consider another explanation for the disparate findings among these studies. In

the vast majority of published PDMP studies, the researchers did not independently search for,

analyze, and code the relevant laws. Rather, they relied upon third-party information downloaded

from the websites of one or more organizations, sometimes coupled with ad-hoc outreach to

relevant states. The information gathered typically includes information such as the date each

state’s PDMP law was enacted and the date the PDMP became operational. However, the dates

reported by these public databases often differ, meaning that, at a minimum, results from a study

that relies on one data source may not be comparable to those from a study that used another.

Moreover, the source of the data published in the public databases themselves is often a black

box: None of the websites most commonly used in studies of PDMP effectiveness -- such as

those maintained by the National Alliance for Model State Drug Laws (NAMSDL) and The

Prescription Drug Abuse Policy System (PDAPS) -- provide publicly available detailed

information as to how the dates were determined. The dates used may be underspecified,

inconsistent, and potentially inaccurate measures of the relevant state laws, likely to yield

conflicting or unreliable results. This paper aims to illustrate the problem, and begin to remedy it

by identifying the parameters researchers must address when identifying the dates when states

enacted laws authorizing PDMPs as well as when those programs became operational, and

publishing a research protocol and sample database of relevant dates assembled by trained legal

researchers applying that protocol.




       4
       It is foreseeable that researchers will rely on publicly available databases as sources for

dates in PDMP studies, particularly when researchers before them have done so. Indeed, using

third party sources can be useful in protecting against unconscious researcher bias. However, the

websites relied on in the large and growing body of PDMP research typically do not provide

information on the definitions of “PDMP program” or other relevant measures, nor do they

explain the procedures by which start dates were determined. Therefore, the studies that rely on

the data in these public databases also lack such information. In addition, papers that utilize more

than one public source of legal information frequently fail to explain how conflicts across data

sources were resolved.

       The process of constructing a database of laws intended to reduce opioid-related harm

such as PDMP laws is complex. In fact, an entire burgeoning field – that of legal epidemiology –

is devoted to the appropriate use of law for research purposes (Ramanathan et al. 2017). In the

case of PDMPs, identifying the date that a law was “enacted,” what would seem to be a

straightforward concept, can be difficult. It is even less clear at what point a PDMP became

“operational” since these databases often phased in voluntary reporting of data, required

reporting of data, and different authorized users gained access to PDMPs at different times.

There are also differences in such foundational questions as what constitutes a PDMP at all.

       Here we consider how differences in the data sources used in existing PDMP research

may have led to varying conclusions regarding important opioid-related outcomes. More

specifically, we do four things: 1) identify the decisions a researcher must make to decide which

dates to use in a PDMP study; 2) discuss the major public data sources used by researchers

studying PDMPs, and, to the limited extent such information is available, summarize the

methodology used to construct them; 3) develop a detailed research protocol (Table 1) and apply



       5
it to create a new dataset of dates at which PDMP laws were enacted and became operational

(Table 2); and 4) as an illustration of the consequences of data choice, alternatively use the

various dates identified in Tables 1 and 2 in an analysis of the relationship between PDMP laws

and opioid prescription and dispensing patterns of opioids among disabled Medicare

beneficiaries using the sample from our previous work in Meara, et al., 2016 extended by two

years to 2014. Throughout we use the term law to include statutes, regulations, and associated

legal material.

       We draw several conclusions from our research. First, even experienced legal

researchers have difficulty creating consistent and reliable measures of PDMP law enactment

and operation dates. The complexity of the endeavor can be easily observed in our lengthy

research protocol (Table 1). Second, our dates differ a great deal from many of the publicly

available dates, sometimes by many years. Third, our tests of the data through regression

analyses generated a twofold difference in point estimates, as well as different signed estimates,

depending on the data set used. However, as with many other studies, our analyses are identified

by the small number of states that adopted laws during the study period. Not surprisingly,

therefore, despite large differences in the dates and in the point estimates across identical

regressions, the standard errors on our estimates are quite large. We were also unable to reject

the null hypotheses that the results were the same across the data in our limited test.

       Nonetheless, the lack of transparency about the methods by which data are assembled,

the differences among dates depending on the source of the data, and the large differences in the

point estimates raise serious for researchers and policymakers. At a minimum, more

transparency in the source of data and the protocol by which they were assembled is required.

II.    DEVELOPING A LEGAL DATABASE: KEY DECISIONS



       6
       a. What is a PDMP?

       Assembling even the most basic PDMP legal database requires making important

decisions. First, the researcher needs to answer a misleadingly simple question – What is a

PDMP? Do the “multiple copy prescription programs” that existed in approximately nine states

prior to 1992 (OIG 1992) where, typically, prescribers kept one copy of a prescription,

pharmacists kept another and sent a third to a state agency, qualify as a PDMP? Although these

programs did not have the capabilities of a modern, electronic system, one might believe that the

existence of an early triplicate program represented state attention to pharmaceutical misuse (and

therefore, shape the behavior of prescribers, dispensers, and patients), a problem in the state with

opioid use, or both. Indeed, some states with early programs had much slower growth in the use

of opioids compared with states creating programs after 2000. In fact, there is evidence that at

least some of them did affect prescribing decisions, leading to reductions in the prescription of

some controlled substances. (Sigler, et al., 1984; Weintraub, Singh, Byrne, Maharaj &

Guttmacher, 1991; Hartzema, et al., 1992; Simoni-Wastila, et al., 2004.)

       On the other hand, it may not make sense to treat such a program – like the one started in

the 1970s in New York or in the 1930s in California – the same way as modern prescription

tracking systems, as publicly available datasets often do. Perhaps the most potentially important

of these differences is that, although some of these states generated periodic reports based on

multiple copy prescription program data, none provided data to clinicians upon request. Where

data was accessible to outside entities, those entities were limited to authorized law enforcement

and regulatory agencies (OIG, 1992 at 10).

       If the researcher decides to define a PDMP as a modern electronic system, she must

identify which criteria qualify a system as “modern” and “electronic.” Many early electronic



       7
PDMPs required data to be sent only infrequently, such as monthly, and using methods that are

now outdated (e.g., mailed via media such as “computer diskette, or magnetic tape.”

Massachusetts 2004) Are such programs similar enough to a modern PDMP that they should be

counted? Or should the relevant factor be not the way data are submitted, but rather how they are

accessed? If one of the main goals of a PDMP is to improve clinician decision-making, perhaps

they should be counted only if and when they provide web-based access to prescribers or

dispensers? Again, there is not necessarily one right answer to these questions, but it is

important that they be considered.

       b. Enactment date

       Another related and perhaps equally important decision involves how to define the

enactment date to use. Using the earliest date at which any state law authorized a PDMP

(however defined) may be a reasonable choice if the researcher thinks that a benefit of the

database is in its signaling potential. But someone trained in legal research can find multiple

dates at which government acted or law became effective, most of which are available using

proprietary legal databases. For example, one can find the dates at which: (1) a bill authorizing

a PDMP was voted on by the state legislature; (2) where necessary, the governor signed the bill

into law; (3) a statute became effective by operation of law; and (4) the PDMP may or must be

implemented. In some states that last date passes with no evidence that a PDMP has been

established.

       In choosing the dates to list in the enactment database for this paper, three of us (all

lawyers with decades of legal research experience and many years of experience researching

controlled substance-related laws specifically) spent many hours considering which of these

dates to use. This is not a trivial decision, as these dates can sometimes differ by years and even



       8
shorter discrepancies frequently lead to a difference in the quarter that a law will be counted as

“enacted” in a research project based on quarterly outcome data.

       There are other reasonable choices to be made. However, it is critical that the choices are

transparent. For example, consider Arkansas’ act, which the legislature voted on in March 2011,

became effective in July 2011, but which states that the PDMP “shall become operational March

1, 2013, if full funding is available (emphasis added).” We use March 2013 as the enactment

date, with a notation regarding 2011, because it is clear from the statute that the program would

not be in effect, at the earliest, until 2013. This state also highlights another potential source of

divergent dates. Both NAMSDL and PDAPS use March 2011 as the enactment date, while we

use July 2011 for the secondary date because even though the law was approved in March 2011,

laws in Arkansas do not generally become effective until 90 days after the legislature adjourns.

In this case, the official effective date of the law, which we use, is July 27, 2011. We are not

claiming that our approach is necessarily better, but rather noting that these decisions – decisions

which are often entirely opaque - are important. When one is identifying the effectiveness of

laws by the quarter, even the difference between March and July in the same year matters.

       c. Operational Date

       In nearly all states the enactment dates do not correspond to the date the PDMP began

operations because the operation of the PDMP is dependent on funding being separately

authorized, regulations being issued, or other reasons. Therefore, the researcher may wish,

instead, to use the date the PDMP became “operational.” Contrary to our expectations beginning

this research, we found it easier to apply consistent rules in assembling the database of

operational dates. Nonetheless, it was still difficult to define “operational.” Does “operational”

mean the date that the PDMP began gathering information? The date it began requiring



       9
physicians or pharmacists to report data? The date it began gathering information via a particular

mechanism (such as via the internet)? The date it began making data readily available to certain

users, such as law enforcement agencies or clinicians? As with the definition of what makes a

PDMP and when the relevant legislation is enacted, there is not necessarily one right answer to

this question, but the choice made matters.

       Sometimes answers to these questions are in statutes, sometimes in related regulations,

and sometimes in the “frequently asked questions” sections of online PDMP guides or other

sources. Even if a skilled researcher has the expertise to interpret laws and access to all of the

sources necessary to do so, to complete even the simplest databases often requires contacting

state officials and finding the people who remember the history of their PDMP implementation.

Following the protocol discussed in Table 1, that is what we have done in assembling our

database of PDMP operational dates, which we define as the date the end user became able to

access PDMP data.

III.   PDMP ESTABLISHMENT/ENACTMENT AND OPERATIONAL DATES

       a. Public Sources

       Three publicly available sources have been used in PDMP studies. Here we discuss each

of them in turn. In addition, we have provided a Table with dates that each database reports for

PDMP statute enactment and operational dates, including the date at which a data collection

began. See Table 3.

       i.      The National Alliance for Model State Drug Laws (NAMSDL)

       NAMSDL is a nonprofit organization partially funded by the United States Department

of Justice that provides information to states on drug policies and law. NAMSDL is mentioned

as a data source in many papers regarding PDMPs. See, e.g., Bao et al. (2016), Deyo et al. 2013,



       10
Morgan, et al. (2012), Nam et al. (2017), Pardo (2017), Paulozzi, Kilbourne & Desai (2011),

Patrick et al. (2016), Simoni-Wastila & Qian (2012), and Dowell et al (2016).

       NAMSDL maintains a webpage, last updated in 2014, that includes a downloadable

report which lists PDMP “Date of Enactment,” “Date Collection Began,” and the “Date of User

Access” (NAMSDL, 2014). None of these terms are defined. According to the website,

“research is conducted using nationwide legal database software, individual state legislative

websites and direct communications with state PDMP representatives.” (NAMSDL, 2014)

Although dates are missing for some states in each list of dates, the Date of Enactment is most

complete (missing only Nebraska and Pennsylvania). Therefore, we use those dates in the

analyses below.

       ii.     The Prescription Drug Abuse Policy System (PDAPS)

       PDAPS is a project developed by a for-profit organization, Legal Science, LLC, in

collaboration with Temple University’s center for Health Law, Policy, and Practice. The project

is a built on The Policy Surveillance Program, a policy surveillance and legal mapping tool

funded by the Robert Wood Johnson Foundation. PDAPS is funded by the National Institute on

Drug Abuse to track key state laws related to prescription drug abuse. (One of us, Corey Davis,

serves, without compensation, on the expert advisory committee). PDAPS is mentioned as a

data source in many papers regarding PDMPs including Buchmueller and Carey (2018), Nam et

al. (2017), Pardo (2017), and Simoni-Wastila & Qian (2012).

       PDAPS operates a website with extensive data listings. One web page entitled “PDMP

Implementation Dates,” includes listings of dates (month, day, year) related to various aspects of

PDMPs (http://www.pdaps.org/datasets/pdmp-implementation-dates). According to the website,

these dates “were compiled through contact with PDMP administrators from each state program



       11
by Brandeis’ PDMP Training and Technical Assistance Center (TTAC).” In our analyses we use

data answering question 1.1, “When was the PDMP enabling legislation first enacted?” question

1.2, “When did the PDMP become operational?” and 1.3 “When did the PDMP first allow

authorized users to access the data?”

       In most but not all cases the dates on this webpage coincide with the dates listed on the

Brandeis TTAC website. We therefore also used a separate source of data from the PDAPS

website. In addition to the data from Brandeis, PDAPS conducted its own, independent review of

PDMP laws. We utilized two questions from this dataset, both of which roughly correspond to

our questions of interest: Question 1, “Does this state have laws authorizing access by a

professional to a PDMP system?” and Question 2: “Does this state have a law requiring

dispensers to report data to the PDMP?”

       iii.    The Prescription Drug Monitoring Program Training and Technical Assistance

               Center (TTAC)

       The Brandeis University TTAC “provides a comprehensive array of services, support,

resources, and strategies to PDMPs, federal partners and other stakeholders to further the efforts

and effectiveness of PDMPs in combating the misuse, abuse and diversion of prescription drugs”

(PDMP Assist, last checked June 7, 2018). The TTAC is mentioned as a data source in many

papers regarding PDMPs including Buchmueller and Carey (2018), Nam et al (2017), Powell et

al, (2016), and Patrick (2016).

       The TTAC “web site is funded through a grant from the Bureau of Justice Assistance,

Office of Justice Programs, U.S. Department of Justice.” The website includes a table that lists

the “Year PMP Legislation enacted” and “Year PMP Became Operational.” We were unable to

find anything on the site regarding the source of the primary information or the research methods



       12
used to collect it. Although many scholars cite the TTAC as the source of their data, no months

are reported that would allow a scholar to analyze data at a more precise time period than the

annual level (ttp://www.pdmpassist.org/content/pdmp-legislation-operational-dates ). In addition,

PDAPS states that it relies on TTAC data. Therefore, although a few of the dates in the PDAPS

and TTAC sites differ, we rely on PDAPS to represent the TTAC data and do not examine them

separately.

       b. Original Databases

       We constructed an original database of dates representing the month and year of PDMP

Enactment and Operation (See Table 2). We initially set out to define two sets of dates to

correspond with the dates available in the NAMSDL and PDAPS data, one based on enactment

of the legislation and another based on first operation of the PDMP. Because we could not apply

these broad definitions consistently across states, we report four sets of dates described below

and in Tables 1 and 2.

       First, a lawyer-librarian or a law student researcher supervised by a lawyer-librarian

established a date for each state applying the research protocol in Table 1. Second, the four

authors who are legal researchers on this project discussed each date and the supporting

evidence. In many cases, we required additional research, including phone calls to state

authorities, to establish a final date. This process took place during frequent meetings from

January through May 2018. A detailed report documenting all sources supporting our original

database is on file with the authors.

       In summary, we define the main enactment date – Enactment/Legislated Start Date Any

PDMP -- as the month and year in which a PDMP statute stated that dispensers or prescribers

would be first required to either a) send, via mail or fax, physical copies of written or filled



       13
prescriptions to a central database or b) send, via electronic methods, data regarding written or

dispensed prescriptions to a central database, whichever was earlier. (Table 1, Table 2 Column

1). This definition includes the older “triplicate” form systems. Because outcome data typically

only spans a decade or two at the most, unless it was straightforward to identify a start date that

occurred before January 1, 1990, we report the date as pre-1990.

        As explained in Table 1, for the paper-based programs we used the month and year that

the state first required that physical copies of prescriptions be sent to the relevant agency or

board in Table 2, Column 1. For programs that began as electronic systems we used the month

and year at which the relevant law that authorized the database stated that the PDMP must begin

operation. Therefore, if a statute was passed by the legislature and signed by a governor in June

2004 but the language of the statute required that the program begin by January 2005, we use the

latter date.

        We made the decision to use this later date, where relevant, rather than the date of

statutory enactment because we were mainly interested in when a provider would reasonably

understand the law to have practical effect. Indeed, in some cases, the statutes used authorizing

or aspirational language, stating that a state may or should if possible create a PDMP, language

that a provider would be unlikely to understand as binding. Second, the definition of enactment

date of statutes is difficult to identify because it differs by state. In some states, it is reasonable

to count the date at which a statute is passed by the legislature. In other states, one would use the

date the governor signed the bill. In still others, there are rules that a signed bill does not become

a law for a specified number of months. These and other differences make identifying a

consistent enactment date across states quite difficult. Others may make a different judgment,




        14
perhaps believing that press coverage of a legislature passing a bill regardless of content would

have a signaling effect that could change provider behavior.

       We include a second measure of enacted/legislated start dates for the eleven states with

statutes that indicated that the program start was contingent on receiving funding (Table 1,

Column 2). For those states, Column 1 includes the date at which that funding became available.

We made this choice because, for these states, the authorizing statute is more aspirational than

operative. No action could happen unless and until funds became available. Because neither

approach – using the date the act was passed or the approach we use -- is entirely satisfactory, we

include an additional column called Enactment/Legislated Start Date, Contingent on Funding.

Table 2, Column 2 lists the earlier date at which the statute was passed. Nonetheless, four of the

relevant states (GA, IA, ME, MD) received funding at the same time the statute indicated the

program would be effective if funding were received.

       We include a third measure of Enactment/Legislated Start Date to allow researchers to

have a complete set of statutory dates for only modern electronic programs. Because the older

paper programs and modern electronic programs differ a great deal, we provide an additional

column – Enactment/Legislated Start Date: Electronic -- for those states that had paper programs

and later transitioned to electronic programs. The date on which those transitions occurred are

displayed in Table 2, Column 3.

       Finally, we include a measure of the operational date of a PDMP which reflects the

month and year at which PDMP data became accessible to any party authorized to access it (e.g.,

physician or pharmacist) (Table 2, Column 4). Different programs allowed or required access to

physicians, pharmacists, members of law enforcement, or others. Therefore, the database may




       15
represent the date at which, for example, physicians in some states or pharmacists in another

were granted access.

       Some states operated pilot programs, allowing access to a small number of end users; we

report the date at which the full program became operational and not the earlier date at which the

pilot program began. We count a program as operational if the end user can access a database

directly through a computer, rather than through a phone call or fax.

IV.    METHODS FOR EMPIRICAL ANALYSES

       A. Data and Empirical Approach

       In addition to producing novel, transparent, and reproducible enactment and operational

dates, we test whether using different dates yields different results when measuring the

effectiveness of PDMPs on opioid-related outcomes. More specifically, we examine the

relationship between these different representations of whether and when a PDMP law was

enacted or a PDMP implemented and opioid outcomes among disabled Medicare beneficiaries.

       Using the same sample as in Meara et al., 2016 covering 2006-2012 with the addition of

data for 2013 and 2014, we examine Medicare beneficiaries from a 40 percent random sample of

Medicare beneficiaries 21 to 64 years of age, eligible for Medicare on the basis of disability,

alive, and continually enrolled in Medicare fee-for-service parts A, B, and D in a calendar year.

We excluded patients with cancer diagnoses, with end-stage renal disease, or who were receiving

hospice care to remove those likely to receive opioids for palliative care.

       Some of the publicly available datasets were missing data for some states. In our main

specifications we deleted those states from our analyses to make the results comparable and so

we could perform additional statistical tests across the models, leaving us with 34 states. In total

we observe over 6.1 million patient years. However, in sensitivity testing we performed the



       16
same analyses applying our original data (Table 1) to all forty-nine states with a PDMP

(excluding Missouri, which did not enact a PDMP law until 2017).



        We estimate the following Ordinary Least Squares regressions:

        Opioid Measureit = βo + β1PDMPit + β2Yeart + β3Stateit+ β4Xit                      (1)

        where the “Opioid Measure” for individual i in year t is alternatively one of two

outcomes. First we test the milligrams of morphine equivalents (MME) annually dispensed to a

beneficiary. Then, following Buchmueller et al. (2018), we estimate whether a patient filled any

opioid analgesic prescription in five or more pharmacies in a year. Models include a fixed effect,

Stateit, for the state of residence an individual, i, lives in at time t, and a fixed effect, Yeart, for

each year, and a vector Xit of patient characteristics. Patient characteristics include: sex, African-

American, other race (white is reference race group), Hispanic ethnicity, indicators for age (21-

29, 30-39, 40-49, 50-59, and 60 – 64), receipt of any Medicare Part D low income subsidy (as a

proxy for poverty), whether beneficiary was dually eligible for Medicaid, any diagnosis of

depression, a diagnosis of bipolar disorder, and a diagnosis of musculoskeletal disorder. We

include all opioids listed in Meara et al. (2016) as well as tramadol, which has been a schedule

IV controlled substance since 2014 and has typically been included in other papers describing

opioid prescribing.

        In these models, the coefficient of interest is β1, which describes the effect of having a

PDMP in a given state in a given year on our outcomes. To estimate β1, we use the various

measures of the date at which a state enacted a PDMP law or began operating a PDMP (see

Tables 1 and 2). The PDMP variable took on values of 0 in years before it was, depending on

the database used, enacted, operational, or accessible to users, values of 1 for each full year it



        17
was in place, and the share of months the PDMP was enacted, operational, or accessible for any

partial year. A PDMP enacted any time in July of 2007, for example, would have a value of .5

for 2007 and 1 thereafter. Where a database did not list a month, we coded the law as in place for

0.5 years for the first year of enactment, operation, or access.

V.     RESULTS

       a. Database Results

       As can be seen by comparing Table 1 (reporting the start dates we assembled applying

the protocol in Table 1) and Table 3 (reporting the start dates from publicly available databases),

there are large differences between our dates and publicly available dates. In many cases,

expertise interpreting statutes is required. For example, a few statutes, such as those in Arizona

and Nebraska, were enacted in jurisdictions in which the official enactment date is a specified

number of months after the legislature passes a bill or a governor signs it. In addition, decisions

of whether to round to a previous or next month or year when a day is provided as part of a date

can have large effects on estimates, particularly when research is organized at the quarterly level

and a limited number of years are used in samples. In some cases, the publicly available data do

not provide a month or any date at all. Sometimes, as is the case of some of NAMSDL’s

measures for Idaho, only a season is listed. In our empirical tests, because the dates came before

the study period, this had no effect, but it may well matter for other analyses.

       Although it can be hard to trace details, it is often important to do so. For example, many

statutes declare that a PDMP will be implemented contingent on funding. Sometimes funding

was contemporaneous with the statute enactment. But, as can be seen in Table 1, Column 3, in

many states that funding came later. In Washington, for example, the funding arrived four years

later. It may be more appropriate, therefore, to use the date funding was appropriated in this and



       18
similar cases. Moreover, a researcher who lists a date from a third-party source, without reading

the statute, would miss the fact that the statute itself does not give a start date at all; in fact, news

coverage shows the program was abandoned fully in 2008 due to budgetary issues and did not

launch until 2012, an important fact that would be missed. (Ho, 2008; Harshman, 2011; Farley,

2011)

        In addition, dates among publicly available databases also differ a great deal. For

example, consider that PDAPs uses the earliest paper systems as enactment and operational

dates, sometimes for very large states such as California, which it codes as 1938. NAMSDL,

conversely, lists California as enacting a PDMP in 2003. This divergence can have an important

effect, particularly as studies that rely on the PDAPS date might simply exclude California from

their analyses by coding it as having started before the study period.

        b. Quantitative Results

        As in Meara et al. (2016), in which we tested the relationship between various opioid

regulations and outcomes among the Medicare disabled population, we find no statistically

significant relationship between the enactment of a PDMP statute, operation of a PDMP

program, or first date of user access to an electronic PDMP and the annual MME dispensed to

disabled Medicare beneficiary between 2006 and 2014. (Table 4). However, what is of interest

for this analysis is the very large differences in the point estimates when data from the different

databases are used.

        The mean annual MME dispensed in a year in our population ranges from 5,290 in 2006

to a peak of 6,839 in 2010. In regression results, three of the four of the associations between

enactment of a PDMP and average annual MME dispensed per beneficiary are positive. Using

our own dates for enactment/legislated start date (Table 2, Column 1), the coefficient on the



        19
PDMP is only about one third (93.23 mgs morphine equivalent per year per beneficiary, Table 4,

Column 1) of the same coefficient using dates provided by the publicly available data. Using

PDAPs dates for enabling legislation (Table 3, Column 1), we find an increase of 274.6 MME

per year (Table 4, Column 3). Using NAMSDL’s dates for enactment of legislation (Table 3,

Column 4), we find an increase of 269.0 MME per year (Table 3, Column 4).

       These results are highly dependent on the type of system to be enacted, paper or

electronic. Using an alternative measure of enactment/legislated start date, one that restricts

enactment dates to modern electronic system (Table 2, combining Columns 1 and 3), we find a

decline in annual morphine equivalents dispensed of 71.52 MME associated with the variable

(Table 4, Column 2).

       Large differences in the estimates can also be seen when applying different sources

representing operational dates. Using our dates representing when a PDMP became operational

in terms of the end user being granted access to the database (Table 2, Column 4), we find an

effect of negative 69.77 MME annually (Table 4, Column 7) whereas the other databases identify

much smaller magnitudes. For example, PDAPS’ dates for when a PDMP became operational

(Table 3, Column 2) show an associated 13.24 mg decline (Table 4, Column 5) and for user

access (Table 3, Column 3) show an associated 40.96 mg decline (Table 4, Column 8). Similar

measures using NAMSDL’s dates (Table 3, Columns 5 and 6) show a 26.99 and 43.85 mg

decline respectively (Table 4, Columns 6 and 9).

       We also test the relationship between different PDMP start dates and the probability that

a beneficiary received opioids from five or more unique pharmacies in a year. Unlike the

estimates for mean MME dispensed, many of these results are statistically significant.




       20
Nonetheless, of primary interest to this analysis is the very large differences, both in magnitude

and sign, of the point estimates.

       The mean probability that a beneficiary obtained opioids at five or more pharmacies in a

year from 2006-2014 is 1.7 percent. In regression results, most associations between enactment

of a PDMP and this measure of a high number of pharmacies are positive and statistically

significant. Using our own dates for enactment/legislated start date (Table 2, Column 1), the

coefficient on enactment of a PDMP is just over a quarter of the same coefficients using similar

measures of enactment dates provided by the publicly available data. We find a 0.06 percentage

point increase in the probability a beneficiary received prescriptions from five or more

pharmacies (Table 5, Column 1), whereas using PDAPS’ dates for enabling legislation (Table 3,

Column 1), we find an increase of 0.211 percentage points (Table 5 column 3) and using

NAMSDL’s dates for enactment of legislation (Table 3, Column 4) we find an increase of 0.209

percentage point (Table 5, Column 4). These numbers represent increases of 3.5, 12.4, and 12.3

percent in the probability of dispenses at five or more pharmacies.

       However, like the results for annual MME dispensed, the estimated effect of PDMPs on

filling opioid prescriptions at multiple pharmacies are highly dependent on the definition of

PDMP date applied. Using our second measure of enactment, one that restricts enactment dates

to modern electronic system (Table 2, Columns 1 and 3), we find a statistically significant

decline of 0.062 percentage points (Table 5, Column 2) in the probability of dispenses at five or

more pharmacies, which represents a 3.6 percent decline associated with the intervention.

       Large differences in the estimates also can be seen when applying different sources

representing operational dates. Using our dates representing when a PDMP became operational

in terms of the end user being granted access to the database (Table 2, Column 4), we find a



       21
statistically significant decline of .068 percentage points (Table 5, Column 7) in the probability

of dispenses at five or more pharmacies, whereas the other databases identify much smaller

declines or increases, none of which are statistically significant. For example, PDAPS’ dates for

when a PDMP became operational (Table 3, Column 2) show an associated 0.012 percentage

point increase (Table 5, Column 5) and for user access (Table 3, Column 3) show an associated

0.029 percentage point decrease (Table 5, Column 8) in five or more pharmacies. Similar

measures using NAMSDL’s dates (Table 3, Columns 5 and 6) show a 0.0004 percentage point

increase and a .03 percentage point decrease respectively (Table 5, Columns 6 and 9).

VI.    DISCUSSION AND CONCLUSION

       Across multiple analyses, different sources of data and different definitions of start dates

yield very different results – sometimes by an order of magnitude. We suspect that some of the

differences among varying conclusions regarding whether PDMPs are effective can be explained

by the fact that different researchers have used different data sources. The large differences in

the point estimates seen in Tables 4 and 5 lend support to this view. Our results were based on a

sample including a limited number of years and, therefore, effects were identified upon a limited

number of states. Other studies will not be based on this same sample, and the results could well

be quite different. We repeated the models above on a sample of 49 states, excluding Missouri

which did not yet have a PDMP by the end of 2015.

       The specific estimates reported here are merely illustrative. We hope to draw more

general lessons. First, when state policy interventions such as the implementations of PDMPs

contain many facets or combinations of individual strategies, all of which evolve over time, it

can be difficult for researchers to create measures of the interventions even within a single state.

Creating such measures for fifty states over time raises an enormous challenge. Blank (2002)



       22
discussed similar difficulties in disentangling state approaches to welfare reform in the 1990s,

and the way these problems played out in evaluating welfare reform.

       Second, and likely our most important conclusion, is that in attempting to evaluate the

effects of legal policy, researchers must understand both how interventions work on the ground

and how they are represented in legal sources. They must have the expertise to read and interpret

laws accurately. To that end, we have presented a model of a research protocol that accounts for

some differences in types of PDMPs and applied it to generate a database of various enactment

and operational dates.

       Other researchers may reasonably make different choices than we did when deciding how

to code a state law or whether and how to use third party sources. That is to be expected. In all

cases, the desire to draw upon a seemingly objective source of legal dates must be weighed

against the appropriateness of a data source for the research question at hand. Nonetheless, it is

important to allow those who use research, including policymakers who base decisions on

research, to evaluate those choices. It is challenging to do so when researchers rely on sources

that do not make their research protocols available or do not report their own research methods.

       Although there is no one correct approach to measuring PDMP laws, regardless of the

study design, protocols need to be implemented consistently and transparently. Researchers

should acknowledge the limitations of any given decision. Overstating the benefits of an

ineffective program wastes scarce resources, while understating its benefits will slow action to

expand a successful effort. Given the stakes for so many lives, it is critical that this body of

research is based on transparent methods.




       23
VII.     REFERENCES

   Bao, Y,, Pan, Y., Taylor, A, Radakrishman, S., Luo, F., Pincus, H.A. & Schackman, B.R..

(2016). Prescription Drug Monitoring Programs Are Associated With Sustained Reductions In

Opioid Prescribing By Physicians. Health Affairs, 35(6), 1045-1051.

   Blank, Rebecca M. (2002). Evaluating Welfare Reform in the United States. J. of Econ Lit.,

v. 40, n.4, 1105-1166.

   Buchmueller, T.C. & Carey, C. (2018). The Effect of Prescription Drug Monitoring

Programs on Opioid Utilization in Medicare. Amer. J. Econ. J.: Econ Pol’y. 10(1), 77-112.

   Brandeis University Prescription Drug Monitoring Program Training and Technical

Assistance Center. (n.d.) PDMP Legislation & Operational Dates. Retrieved from

http://www.pdmpassist.org/content/pdmp-legislation-operational-dates

   Case, A. & Deaton, A. (2015). Rising Morbidity and Mortality in Midlife among White Non-

Hispanic Americans in the 21st Century. Proceedings of the Nat. Acad. Sciences. 112(49) 15078-

15083.

   Centers for Disease Control. (n.d.) 10 Leading Causes of Death by Age Group, United

States—2016. Retrieved from

https://www.cdc.gov/injury/wisqars/pdf/leading_causes_of_death_by_age_group_2016-508.pdf

   Centers for Disease Control. (n.d.) 10 Leading Causes of Injury Deaths by Age Group

Highlighting Unintentional Injury Deaths, United States—2016. Retrieved from

https://www.cdc.gov/injury/wisqars/pdf/leading_causes_of_injury_deaths_highlighting_unintenti

onal_injury_2016-508.pdf

   Centers for Disease Control. (2017) Underlying Cause of Death, 1999-2016 [Data file].

Retrieved from https://wonder.cdc.gov/controller/saved/D76/D15F907



         24
   Davis, C.S., Pierce, M., Dasgupta, N. (2014). Evolution and Convergence of State Laws

Governing Controlled Substance Prescription Monitoring Programs, 1998-2011. American

Journal of Public Health, 104(8), 1389-1395.

   Davis, C.S. (2017). Commentary on Pardo (2017) and Moyo et al. (2017): Much Still

Unknown about Prescription Drug Monitoring Programs. Addiction. 112(10),1797-1798.

   Deyo, R.A., Irvine, J.M., Millet, L.M., Beran, T., O’Kane, N., Wright, D.A. & McCarty, D..

(2013). Measures Such As Interstate Cooperation Would Improve The Efficacy Of Programs To

Track Controlled Drug Prescriptions. Health Affairs, 32(3), 603-613.

   Dowell, D., Arias, E., Kochanek, K., Anderson, R., Guy, G.P. Jr., Losby, J.L. & Baldwin, G.

(2017). Contribution of Opioid-Involved Poisoning to the Change in Life Expectancy in the

United States, 2000-2015. JAMA, 318(11), 1065-1067. (“Drug-poisoning deaths contributed a

loss of 0.28 years in life expectancy. Most of this loss (96%) was unintentional; 0.21 years were

lost to opioid-involved poisoning deaths.”)

   Dowell, D., Zhang, K., Noonan, R.K., Hockenberry J.M. (2016). Mandatory Provider

Review And Pain Clinic Laws Reduce The Amounts Of Opioids Prescribed And Overdose

Death Rates. Health Affairs, 35(10), 1876-1883.

   Farley, J. (2011, October 14). State to begin monitoring prescriptions for pain medication in

2012, Kitsap Sun. Retrieved from https://1.next.westlaw.com

   Guy, G.P. Jr., Zhang, K., Bohm, M.K., Losby, J., Lewis, B., Young, R… & Dowell, D.. Vital

signs: changes in opioid prescribing in the United States, 2006-2015. Morbidity and Mortality

Weekly Report (MMWR), 66(26), 697-704.

   Harshman, M. (2011, October 18). State to start monitoring prescriptions. Columbian, p. E.




       25
   Hartzema, A.G. (1992). Impact of Triplicate Prescription Program on Psychotropic

Prescribing Patterns in Long-Term Care Facilities. Annals of Pharmacotherapy, 26(4), 539-546.

   Hedegaard, H., Warner, M. & Miniño, A. (2017) Drug Overdose Deaths in the United States,

1999–2016. Retrieved from National Center for Health Statistics

https://www.cdc.gov/nchs/products/databriefs/db294.htm.

   Ho, V. (2008, December 11). Health Plans to be Pared, Two Potential Lifesavers Go. Seattle

Post-Intelligencer, p. A13.

   Kunins, H.V., Farley, T.A., & Dowell, D. (2013). Guidelines for opioid prescription: why

emergency physicians need support, Annals of Internal Medicine, 158(11), 841-842.

       Massachusetts, 105 Mass. Code Regs. 700.006(J)(1)(c) (2004) (current version at 105

Mass. Code Regs. 700.012(A)(5)).

       Meara, E., Horwitz, J.R., Powell, W., McClelland, L., Zhou, W., O'Malley, J., Morden,

N.E.. (2016). State Legal Restrictions and Prescription-Opioid Use among Disabled Adults. New

England J. Med., 375, 44-53.

   Morgan, L., Weaver, M., Sayeed, Z. & Orr, R. (2012). The Use of Prescription Monitoring

Programs to Reduce Opioid Diversion and Improve Patient Safety. Journal of Pain & Palliative

Care Pharmacotherapy, 27(1), 4-9.

   Nam, Y.H., Shea, D.G., Shi, Y. & Moran, J.R. (2017). State Prescription Drug Monitoring

Programs and Fatal Drug Overdoses. The American Journal of Managed Care, 23(5), 297-303.

   National Alliance for Model State Drug Laws. (2014). PDMP Dates of Operation. Retrieved

from http://www.namsdl.org/library/580225E9-E469-AFA9-50E7579C1D738E71/




       26
   Department of Health and Human Services Office of the Inspector General. (1992). Multiple

Copy Prescription Programs: State Experiences. Retrieved from

https://oig.hhs.gov/oei/reports/oei-12-91-00490.pdf

   Pardo, B. (2017). Do more robust prescription drug monitoring programs reduce prescription

opioid overdose? Addiction, 112(10), 1773-1783.

   Patrick, S.W., Fry, C.E., Jones T.F., & Buntin, M.B.. (2016). Implementation Of Prescription

Drug Monitoring Programs Associated With Reductions In Opioid-Related Death Rates. Health

Affairs, 35(7), 1324-1332.

   Prescription Drug Abuse Policy System. (2017, June 1). PDMP Implementation Dates.

Retrieved from http://www.pdaps.org/datasets/pdmp-implementation-dates

   Paulozzi, L.J., Kilbourne, E.M. & Desai, H.A. (2011). Prescription Drug Monitoring

Programs and Death Rates from Drug Overdose. Pain Medicine, 12(5), 747-754.

   Ramanathan, T., Hulkower, R., Holbrook, J. & Penn, M. (2017). Legal Epidemiology: The

Science of Law. The Journal of Law, Medicine & Ethics, 45(S1), 69-72.

   Sigler, K.A., Guernsey, B.G., Ingrim, N.B., Buesing, A.S., Hokanson, J.A., Galvan, E. &

Doutre, W.H. (1984). Effect of a triplicate prescription law on prescribing of Schedule II drugs.

American Journal of Health-System Pharmacy, 41(1), 108-111.

   Simoni-Wastila, L., Ross-Degnan, D., Mah, C., Gao, X., Brown, J., Cosler, L.E…Soumerai,

S.B. (2004). A retrospective data analysis of the impact of the New York triplicate prescription

program on benzodiazepine use in medicaid patients with chronic psychiatric and neurologic

disorders. Clinical Theraputics, 26(2), 322-336.

   Simoni-Wastila, L. & Qian, J. (2012). Inﬂuence of prescription monitoring programs on

analgesic utilization by an insured retiree population. Pharmacoepidemiology and Drug Safety,



       27
21, 1261-1268.

   Weintraub, M., Singh, S., Byrne, L., Maharaj, K. & Guttmacher, L. (1991). Consequences of

the 1989 New York State Triplicate Benzodiazepine Prescription Regulations. JAMA, 266(17),

2392-2397.




       28
Table 1: Research Protocol and Data Descriptions

As described in the text, we set out to define two sets of dates to correspond with the publicly
available dates – one based on enactment of the legislation and another based on when the
PDMP became operational. Because we could not apply these broad definitions consistently
across states, we report four sets of dates. The first three are related to the enactment/legislated
start date of the statute authorizing or requiring a PDMP. The fourth date reports when a modern,
electronic system became operational in terms of allowing an intended user to access the system.

I.     Enactment/Legislated Start Dates – Table 2, Columns 1 through 3.

       A.      Table 2, Column 1, Enactment Date/Legislated Start Date -- Any PDMP. This
       column contains the month and year that the legislation states dispensers or prescribers
       would be first required to either a) send, via mail or fax, physical copies of written or
       filled prescriptions to a central database or b) send, via electronic methods, data regarding
       written or dispensed prescriptions to a central database.
               A small number of states required copies of paper prescriptions to be sent to a
       central repository. For these states, we note the month and year that these statutes
       required copies of paper prescriptions to be sent in Table 2, Column 1. (NB: some states
       had required prescribers or dispensers to keep records of prescriptions but not send them
       to a central repository – we do not code those states as having a PDMP).
               For all other states, this column contains the month and year that a statute or
       regulation that authorized an electronic database to which information on dispensed
       prescriptions is required to be reported went into effect, subject to the following caveats:
               1.      If the statute is clear that the PDMP would not be required to exist until a
               date after the effective date of the statute, we note the date by which the PDMP is
               required to exist, not the effective date of the statute.
               2.      If the statute authorizes the PDMP contingent upon receipt of sufficient
               funding, we include the date that we find evidence that such funding was obtained
               by reaching outside the statute using the same protocol we used for determining
               the operational date as described below.

       B.      Table 2, Column 2, Enactment/Legislated Start Date – Contingent on Funding.
       For the eleven states in which the statute makes PDMP operation contingent on funding,
       we include the date at which the statute authorizing the development of a PDMP
       contingent on funding was enacted. This date is typically, although not always, earlier
       than the date the funding is received. We report this date because researchers may
       believe that the existence of a statute, even one that it inoperative, may influence provider
       behavior and because it may be useful in analyzing that question or in sensitivity
       analyses.




       29
       C.       Table 2, Column 3, Enactment/Legislated Start Date Electronic. For the twelve
       states, including some very large states, that had a paper-based system before they
       implemented an electronic system, we include an additional column listing the month and
       year that the state enacted (according to the definition above), a modern, electronic
       PDMP.
II.     Modern System Operational Date: These dates are meant to represent the month and
year that PDMP data became accessible to any user (e.g., physician, pharmacist, or member of
law enforcement) authorized by state law to receive it. Many programs began requiring reporting
before they began permitting or requiring prescribers, pharmacists, or others to query the
database. In these cases, we report the latter date, the date at which the database became
operational from the perspective of the end user. In addition, some states operated pilot
programs, allowing access to a small number of end users; we report the date at which the full
program became operational and not the earlier date at which the pilot program began. We count
a program as operational if the end user can access a database directly, rather than through a
phone call or fax because the latter are unlikely to allow the physician to access patient histories.
We determined this date from the following sources:
            a. State Statutes. Some statutes state a date by which the PDMP must be accessible
               to users. We used these dates as a starting point for our research, and confirmed
               these dates with or updated them from the additional sources listed in b-d below.
            b. Regulations.
            c. Subregulatory materials such as policy documents or manuals from the agency
               that operates the PDMP.
            d. Other sources, including but not limited to:
                    i. State government reports on the PDMPs (e.g., those listing start dates
                       and/or statistics on operations).
                   ii. Presentations by regulators (e.g., powerpoint presentations with summary
                       stats)
                  iii. Medical or Pharmacy Board Announcements
                  iv. FAQs and historical materials sections of the state PDMP website
                   v. Phone calls to relevant governing agency
                  vi. In rare cases, we rely on press reports. If there are conflicting press
                       reports, we make phone calls to the governing agency.




       30
Table 2: PDMP Enactment/Legislated Start and Operational Dates
                             (1)                   (2)                  (3)                (4)
                                             Enactment/
                      Enactment/                                 Enactment/       Modern System
                                          Legislated Start
                    Legislated Start                          Legislated Start   Operational/User
                                       Date: Contingent on
                        Date                                 Date: Electronic        Access
   Jurisdiction                              Funding
   Alabama              Nov-05                   Aug-04                                  Apr-06
   Alaska               Sep-08                                                            Jan-12
   Arizona              Sep-07                                                           Dec-08
   Arkansas             Mar-13                   Jul-11                                  May-13
   California          Pre-1990                                       Jan-05             Sep-09
   Colorado             Jun-05                                                           Feb-08
   Connecticut          Oct-06                                                            Jul-08
   Delaware             Sep-11                   Jul-10                                  Aug-12
   DC                   Feb-14                                                           Oct-16
   Florida              Dec-10                                                           Oct-11
   Georgia               Jul-11                  Jul-11                                  May-13
   Hawaii              Pre-1990                                       Dec-96             Feb-12
   Idaho               Pre-1990                                       Apr-00             Apr-08
   Illinois            Pre-1990                                       Apr-00             Dec-09
   Indiana             Pre-1990                                       Jul-07              Jul-07
   Iowa                 May-06                  May-06                                   Mar-09
   Kansas                Jul-08                                                          Apr-11
   Kentucky              Jul-98                                                           Jul-99
   Louisiana             Jul-06                                                           Jan-09
   Maine                Jan-04                   Jan-04                                   Jan-05
   Maryland             Oct-11                   Oct-11                                  Dec-13
   Massachusetts        Dec-92                                        Feb-13              Jan-11
   Michigan            Pre-1990                                       Jan-02              Jan-03
   Minnesota            Jan-09                   Jul-07                                  Apr-10
   Mississippi          Jun-06                                                            Jul-08
   Missouri              Jul-17
   Montana               Jul-11                                                          Oct-12
   Nebraska             Aug-11                                                            Jan-17
   Nevada               Jan-96                                                           Feb-11
   New Hampshire        Jun-12                                                           Oct-14
   New Jersey           Aug-09                                                            Jan-12
   New Mexico            Jul-04                                                          Aug-05
   New York            Pre-1990                                       Oct-06             Jun-13
   North Carolina       Jan-06                                                            Jul-07
   North Dakota         Dec-06                   Apr-05                                  Oct-08
   Ohio                 May-05                                                           Oct-06


        31
    Oklahoma                      Jan-91                                                                              Jul-06
    Oregon                         Jul-09                                                                             Sep-11
    Pennsylvania                 Pre-1990                                                  Jun-15                    Aug-16
    Rhode Island                 Pre-1990                                                  Aug-95                     Sep-12
    South Carolina                Jun-06                                                                              Feb-08
    South Dakota                  Mar-10                                                                             Mar-12
    Tennessee                     Jan-03                                                                              Jan-10
    Texas                         Aug-81                                                   Sep-99                    Aug-12
    Utah                           Jul-95                                                                             Jan-06
    Vermont                       Jun-08                        May-06                                                Jan-09
    Virginia                      Sep-03                                                                              Jun-06
    Washington                    Aug-11                        Jul-07                                                Jan-12
    West Virginia                 Jun-95                                                   Sep-02                    May-13
    Wisconsin                     Jun-10                                                                              Jun-13
      Wyoming                       Jul-03                                                                             Jul-13
Source: Data created by authors using protocol listed in Table 1 during the winter and spring 2018. A detailed
report of all sources consulted is on file with the authors.
Notes: All dates established according to research protocol detailed in Table 1. The Enactment Date Any PDMP
column lists the month and year each state required a dispenser or prescriber to report a written or filled prescription,
including paper submissions. For statutes that explicitly required a state to secure funding before requiring
reporting, we included the date at which the funding was secured as well as the earlier date at which the statute was
passed in a second column, the Contingent on Funding Enactment column. The Enactment Date Electronic column
lists the month and year that the state enacted a modern, electronic PDMP. The Modern System Operational Date
represents the month and year that PDMP data became accessible to any user (e.g., physician, pharmacist, or
member of law enforcement) authorized by state law to receive it.




         32
Table 3: Enactment and Operational Dates Publicly Available Sources
                 (1)             (2)             (3)              (4)             (5)               (6)
                 PDAPS           PDAPS           PDAPS            NAMSDL          NAMSDL            NAMSDL
                 Enabling                                                         Collection
                                                                  Enactment
Jurisdiction     Legislation     Operational     User Access                      Began             User Access
Alabama                May-05          Dec-05          Jun-07           May-04           Apr-06           Aug-07
Alaska                 Sep-08           Jul-11         Dec-11           Jun-08           Aug-11            Jan-12
Arizona                Sep-07          Sep-08          Nov-08            Jul-07          Oct-08           Dec-08
Arkansas               Mar-11          Feb-13          May-13           Mar-11           Mar-13           Mar-13
California             Dec-38          Dec-38                           Sep-03             1998              2009
Colorado               Jun-05          Jun-07          Feb-08           Jun-05            Jul-07          Feb-08
Connecticut            Jun-06          Jun-08                           Jun-06            Jul-08
Delaware                Jul-10         Feb-12          Aug-12            Jul-10          Mar-12           Aug-12
District of
Columbia               Feb-14                                           Feb-14
Florida                Jun-09          Aug-11            Oct-11         Jun-09           Sep-11           Oct-11
Georgia                May-11          Jun-13            Jun-13        May-11             Jul-13          Jul-13
Hawaii                 Dec-42          Dec-42                           Jun-96
Idaho                  Dec-66          Dec-66          May-99           Apr-00          fall 1997     spring 1998
Illinois               Dec-60          Dec-67                           Aug-99
Indiana                Dec-96          Dec-97                           Mar-06              1994            2007
Iowa                   May-06          Dec-08          Mar-09          May-06             Jan-09          Mar-09
Kansas                 Jun-08           Jan-11         Mar-11           Apr-08           Feb-11           Apr-11
Kentucky                Jul-98         Dec-98          Jun-99           Apr-98            Jan-99           Jul-99
Louisiana              Jun-06          Oct-08          Dec-08           Jun-06           Jun-08           Jan-09
Maine                  Jun-03          Jun-04          Dec-04           Jun-03            Jul-04          Jan-05
Maryland               May-11          Aug-13          Dec-13          May-11            Aug-13           Jan-14
Massachusetts          Dec-91          Dec-93                           Aug-10
Michigan               Dec-87          Dec-88                            Jan-02           Jan-03          Feb-03
Minnesota              Jun-07           Jan-10         Apr-10          May-07             Jan-10          Apr-10
Mississippi            Dec-04          Dec-04          Nov-05           Apr-06              2005          Dec-05
Missouri                                                            No program
Montana                Jun-11          Mar-12          Oct-12           Apr-11           Mar-12           Oct-12
Nebraska               Apr-11          Apr-11          Apr-11
Nevada                 Jun-95          Dec-96          Jun-97            Jul-95          Jan-97           Apr-97
New Hampshire          Jun-12          Sep-14          Oct-14           Jun-12           Oct-14           Oct-14
New Jersey              Jan-08         Aug-11           Jan-12           Jan-08          Sep-11            Jan-12
New Mexico              Jul-04         Dec-04           Jul-05           Jul-04          Jan-05           Aug-05
New York               Dec-71          Mar-73           Jan-10          Apr-73
North Carolina         Aug-05          Jun-07          Sep-07           Aug-05             Jul-07         Oct-07
North Dakota           Nov-05          Aug-07          Aug-07           Apr-07            Jan-07
Ohio                   May-05          Jun-06          Oct-06           Dec-04            Jan-06          Oct-06
Oklahoma               May-90          Dec-90                           May-90              1990           Jul-06
Oregon                  Jul-09         May-11          Aug-11            Jul-09           Jun-11          Sep-11
Pennsylvania           Dec-71          Dec-72

        33
 Rhode Island              Dec-77             Dec-78                            Nov-01
 South Carolina             Jun-06            Jan-08          Aug-08             Jun-06           Feb-08             Jun-08
 South Dakota              Mar-10             Dec-11          Feb-12            Mar-10            Dec-11             Mar-12
 Tennessee                 Dec-02            Nov-06           Dec-06            May-90
 Texas                     Aug-81             Dec-81          Dec-81             Jun-89
 Utah                      Dec-94             Dec-95          Dec-96             Jan-95           Jan-97             Jan-97
 Vermont                   May-06             Dec-08          Mar-09            May-06            Jan-09             Apr-09
 Virginia                  Apr-02            Aug-03           May-06            Apr-02            Jun-06             Jun-06
 Washington                  Jul-07           Oct-11           Jan-12           May-07            Oct-11             Jan-12
 West Virginia              Jun-95            Jun-95                            Mar-95
 Wisconsin                 May-10            Mar-13           May-13            May-10           May-13             May-13
 Wyoming                   Mar-03             Jun-04          Sep-04            Mar-03              2004               2004
Sources:      Data downloaded by authors between January and May 2018. Columns 2-4 are from the Prescription
Drug Abuse Policy System, http://pdaps.org/datasets/pdmp-implementation-dates (last checked April 26, 2018).
Column 2, Enabling Legislation, is from survey question 1.1 question – When was the PDMP enabling legislation
first enacted?. Column 3, Operational, is from survey question 1.2 When did the PDMP become operational?,
Column 4 User Access, is from survey question 1.3 When did the PDMP first allow authorized users to access the
data?. Dates in columns 5-7 are from the National Alliance for Model State Drug Laws, PMDP Dates of Operation
Report http://www.namsdl.org/library/580225E9-E469-AFA9-50E7579C1D738E71/ (last checked April 26, 2018).
Notes: Empty cells and cells with no month listed reflect the data as reported in the original sources. For cells in
which only a year was reported, we assigned the year a value of 0.5 in the regression analyses. Those cells for
which only a season was reported did not matter for the regression analyses since the years were before the study
periods.




         34
Table 4. Estimated Associations between Annual Morphine Equivalent Dispensed and PDMP Enactment and Operational
Dates from Various Sources, 2006-2014
                                  (1)            (2)            (3)            (4)        (5)              (6)           (7)             (8)               (9)
                                                                                       Operational – Collection or
                                      Enactment/Enabling/Legislated Start Dates                  Other                         Operational – User Access
                                            Horwitz et
                                            al.,                                                                     Horwitz et
                                            (electronic,  PDAPS                                      NAMSDL          al. Modern
                              Horwitz et al where         Enabling         NAMSDL      PDAPS         Collection      System          PDAPS 1.3      NAMSDL
VARIABLES                     (any PDMP ) applicable)     Legislation      Enactment   Operational   Began           Operational     User Access    User Access
 PDMP effect                  93.23          -71.52         274.6          269.0       -13.24         -26.99         -69.77          -40.96          -43.85
                              (150.2)        (204.9)        (193.1)        (193.5)     (198.8)        (217.1)        (205.7)         (208.8)         (206.6)
 Female                       -573.0***      -573.0***      -572.9***      -573.0***   -573.0***      -573.0***      -573.0***       -573.0***       -573.0***
                              (81.14)        (81.17)        (81.05)        (81.06)     (81.15)        (81.15)        (81.16)         (81.19)         (81.19)
 Black                        -3,571***      -3,571***      -3,571***      -3,571***   -3,571***      -3,571***      -3,571***       -3,571***       -3,571***
                              (368.7)        (368.8)        (368.5)        (368.5)     (368.8)        (368.8)        (368.8)         (368.7)         (368.7)
 Other Race                   -2,234***      -2,234***      -2,234***      -2,234***   -2,234***      -2,234***      -2,234***       -2,234***       -2,234***
                              (389.0)        (389.2)        (389.0)        (389.0)     (389.2)        (389.1)        (389.2)         (389.2)         (389.2)
 Hispanic                     -3,458***      -3,458***      -3,458***      -3,458***   -3,458***      -3,458***      -3,458***       -3,458***       -3,458***
                              (851.5)        (851.9)        (851.3)        (851.3)     (851.8)        (851.9)        (851.9)         (851.9)         (851.9)
 Part D low income subsidy    638.6***       638.9***       639.3***       639.3***    638.7***       638.7***       638.9***        638.8***        638.8***
                              (187.8)        (188.0)        (188.2)        (188.2)     (187.9)        (188.0)        (188.0)         (188.0)         (188.0)
 Dual eligible for Medicaid   -1,593***      -1,593***      -1,593***      -1,593***   -1,593***      -1,593***      -1,593***       -1,593***       -1,593***
                              (166.9)        (166.9)        (167.1)        (167.1)     (166.9)        (166.9)        (167.0)         (167.0)         (167.0)
 Depression dx                2,451***       2,450***       2,451***       2,451***    2,450***       2,450***       2,450***        2,450***        2,450***
                              (96.10)        (96.19)        (96.12)        (96.12)     (96.15)        (96.16)        (96.20)         (96.17)         (96.17)
 Bipolar diagnosis            -2,827***      -2,827***      -2,827***      -2,827***   -2,827***      -2,827***      -2,827***       -2,827***       -2,827***
                              (169.2)        (169.3)        (169.2)        (169.2)     (169.3)        (169.3)        (169.3)         (169.3)         (169.3)
 Musculoskeletal diagnosis    7,991***       7,991***       7,991***       7,991***    7,991***       7,991***       7,991***        7,991***        7,991***
                              (371.1)        (371.1)        (371.2)        (371.2)     (371.1)        (371.1)        (371.1)         (371.0)         (371.0)
 Constant                     182.0          235.5          96.71          102.1       226.5          229.9          234.5           231.3           231.7


         35
                                 (334.7)         (337.5)         (386.2)        (386.3)         (328.0)         (326.5)         (338.1)         (330.8)         (331.2)
  Observations                   6,142,826       6,142,826       6,142,826      6,142,826       6,142,826       6,142,826       6,142,826       6,142,826       6,142,826
  R-squared                        0.065          0.065             0.065          0.065            0.065          0.065           0.065            0.065        0.065
Source: Data are from a random 40 percent sample of all disabled Medicare beneficiaries, 2006-2014.
Notes: Cohorts by year included beneficiaries 21-64 years of age who were enrolled in fee-for-service Medicare Pars A, B, and D (inpatient, outpatient, and
prescriptions benefits) and were alive throughout the calendar year. They exclude patients with cancer diagnoses, end stage renal disease, or who were receiving
hospice care. We further restrict sample to 34 U.S. states with information from all three legal sources on enactment and operational dates (Table 3). Opioid
receipt is measured by Medicare prescription fills converted to morphine equivalents as in Meara et al. 2016, and summed into an annual measure of milligrams
morphine equivalent for each person-year. Models also included indicator variables for each year, 2007 through 2014, age (30-39, 40-49, 50-59, 60-64) with 21-
29 as reference. The standard errors shown are adjusted for correlation within states using Huber White Sandwich estimators.*** p<0.01, ** p<0.05, * p<0.1.
See Tables 1 and 2 for an explanation of column headings.




        36
Table 5. Estimated Associations between the Prevalence of Disabled Medicare Beneficiaries with Dispenses at 5 or more
Pharmacies and PDMP Enactment and Operational Dates, 2006-2014.
                                                             Enactment
                                 (1)              (2)              (3)              (4)            (5)            (6)           (7)              (8)              (9)
                                                                                                         NAMSDL         Modern
                                                        PDAPS            NAMSDL           PDAPS          Collection     System        PDAPS 1.3        NAMSDL Use
 VARIABLES            Any PDMP         Electronic       Enabling         Enactment        Operational    Began          Operational   User Access      Access
 PDMP effect (Prob
 beneficiary >= 5
 Pharm*100).          0.0578***        -0.0618***       0.211***         0.209***         0.0118         0.000366       -0.0676***    -0.0292          -0.0304
                      (0.0220)         (0.0209)         (0.0233)         (0.0234)         (0.00213)      (0.000215)     (0.0209)      (0.0211)         (0.0209)
 Female               0.000909***      0.000909***      0.000910***      0.000910***      0.000909***    0.000909***    0.000909***   0.000909***      0.000909***
                      (0.000109)       (0.000109)       (0.000109)       (0.000109)       (0.000109)     (0.000109)     (0.000109)    (0.000109)       (0.000109)
 Black race           -0.00263***      -0.00264***      -0.00263***      -0.00263***      -0.00263***    -0.00263***    -0.00264***   -0.00264***      -0.00264***
                      (0.000138)       (0.000138)       (0.000138)       (0.000138)       (0.000138)     (0.000138)     (0.000138)    (0.000138)       (0.000138)
 Asian, Native,
 Unknown              -0.00411***      -0.00411***      -0.00411***      -0.00411***      -0.00411***    -0.00411***    -0.00411***   -0.00411***      -0.00411***
                      (0.000335)       (0.000335)       (0.000335)       (0.000335)       (0.000335)     (0.000335)     (0.000335)    (0.000335)       (0.000335)
 Hispanic ethnicity   -0.00607***      -0.00607***      -0.00607***      -0.00607***      -0.00607***    -0.00607***    -0.00607***   -0.00607***      -0.00607***
                      (0.000262)       (0.000262)       (0.000262)       (0.000262)       (0.000262)     (0.000262)     (0.000262)    (0.000262)       (0.000262)
 Part D low income
 subsidy              0.00356***       0.00356***       0.00356***       0.00356***       0.00356***     0.00356***     0.00356***    0.00356***       0.00356***
                      (0.000207)       (0.000207)       (0.000207)       (0.000207)       (0.000207)     (0.000207)     (0.000207)    (0.000207)       (0.000207)
 Dual eligible for
 Medicaid             0.00100***       0.00100***       0.00100***       0.00100***       0.00100***     0.00100***     0.00100***    0.00100***       0.00100***
                      (0.000163)       (0.000163)       (0.000163)       (0.000163)       (0.000163)     (0.000163)     (0.000163)    (0.000163)       (0.000163)
 Depression dx        0.0180***        0.0180***        0.0180***        0.0180***        0.0180***      0.0180***      0.0180***     0.0180***        0.0180***
                      (0.000130)       (0.000130)       (0.000130)       (0.000130)       (0.000130)     (0.000130)     (0.000130)    (0.000130)       (0.000130)
 Bipolar diagnosis    0.00444***       0.00444***       0.00444***       0.00444***       0.00444***     0.00444***     0.00444***    0.00444***       0.00444***
                      (0.000216)       (0.000216)       (0.000216)       (0.000216)       (0.000216)     (0.000216)     (0.000216)    (0.000216)       (0.000216)
 Musculoskeletal
 diagnosis            0.0246***        0.0246***        0.0246***        0.0246***        0.0246***      0.0246***      0.0246***     0.0246***        0.0246***
                      (0.000117)       (0.000117)       (0.000117)       (0.000117)       (0.000117)     (0.000117)     (0.000117)    (0.000117)       (0.000117)


          37
 Constant                  -0.00819***       -0.00783***       -0.00890***       -0.00887***      -0.00797***      -0.00795***      -0.00782***     -0.00788***      -0.00788***
                           (0.000348)        (0.000337)        (0.000351)        (0.000351)       (0.000340)       (0.000340)       (0.000337)      (0.000338)       (0.000337)
 Observations               6,142,826        6,142,826          6,142,826          6,142,826        6,142,826        6,142,826        6,142,826         6,142,826    6,142,826
 R-squared                  0.017            0.017              0.017              0.017            0.017            0.017            0.017             0.017
Source: Data are from 40 percent sample of Medicare beneficiaries aged 21 to 64, 2006-2014.
Notes: Cohorts by year included beneficiaries 21-64 years of age who were enrolled in fee-for-service Medicare Pars A, B, and D (inpatient, outpatient, and
prescriptions benefits) and were alive throughout the calendar year. We further restrict sample to 34 U.S. states with information from all three legal sources on
enactment and operational dates (Table 1). Opioid receipt from more than 4 pharmacies is measured by Medicare payments for prescriptions filled in more than 4
pharmacies in a calendar year. Models also included indicator variables for each year, 2007 through 2014, age (30-39, 40-49, 50-59, 60-64) with 21-29 as
reference. The standard errors shown are adjusted for correlation within states using Huber White Sandwich estimators. *** p<0.01, ** p<0.05, * p<0.1.
See Tables 1 and 2 for an explanation of column headings.




         38
