                             NBER WORKING PAPER SERIES




                 NON-RANDOM EXPOSURE TO EXOGENOUS SHOCKS:
                         THEORY AND APPLICATIONS

                                       Kirill Borusyak
                                         Peter Hull

                                     Working Paper 27845
                             http://www.nber.org/papers/w27845


                    NATIONAL BUREAU OF ECONOMIC RESEARCH
                             1050 Massachusetts Avenue
                               Cambridge, MA 02138
                                  September 2020




We are grateful to Rodrigo Adão, Gabriel Ahlfeldt, Nate Baum-Snow, Vasco Carvalho, Gabriel
Chodorow-Reich, Dave Donaldson, Raffaella Giacomini, Paul Goldsmith- Pinkham, Richard
Hornbeck, Xavier Jaravel, Tetsuya Kaji, Vishal Kamat, Michal Kolesár, Aureo de Paula, Andrés
Rodríguez-Clare, Cyrus Samii, Ben Sommers, Chenzi Xu, and numerous seminar participants for
helpful comments. We thank Yatang Lin, as well as Molly Frean, Jonathan Gruber, and Ben
Sommers for sharing code and data. Ruixue Li, Elise Parrish, and Steven Shi provided
outstanding research assistance. The views expressed herein are those of the authors and do not
necessarily reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2020 by Kirill Borusyak and Peter Hull. All rights reserved. Short sections of text, not to
exceed two paragraphs, may be quoted without explicit permission provided that full credit,
including © notice, is given to the source.
Non-Random Exposure to Exogenous Shocks: Theory and Applications
Kirill Borusyak and Peter Hull
NBER Working Paper No. 27845
September 2020
JEL No. C21,C26,F14,I13,R40

                                           ABSTRACT

We develop new tools for causal inference in settings where exogenous shocks affect the
treatment status of multiple observations jointly, to different extents. In these settings researchers
may construct treatments or instruments that combine the shocks with predetermined measures of
shock exposure. Examples include measures of spillovers in social and transportation networks,
simulated eligibility instruments, and shift-share instruments. We show that leveraging the
exogeneity of shocks for identification generally requires a simple but nonstandard recentering,
derived from the specification of counterfactual shocks that might as well have been realized. We
further show how specification of counterfactual shocks can be used for finite-sample inference
and specification tests, and we characterize the recentered instruments that are asymptotically
efficient. We use this framework to estimate the employment effects of Chinese market access
growth due to high-speed rail construction and the insurance coverage effects of expanded
Medicaid eligibility.


Kirill Borusyak
Drayton House
30 Gordon Street
London
WC1H 0AX
United Kingdom
k.borusyak@ucl.ac.uk

Peter Hull
University of Chicago
5757 South University Avenue
Chicago, IL 60637
and NBER
hull@uchicago.edu




An appendix is available at http://www.nber.org/data-appendix/w27845
1     Introduction
To estimate causal effects or structural parameters, researchers often use regression procedures that
leverage the orthogonality of an unobserved residual  and an observed treatment or instrument
z . Such orthogonality has a strong justification when z is generated by a randomized controlled
trial (RCT) or a natural experiment that approximates an RCT, and when an appropriate exclusion
restriction holds. In conventional settings the experiment assigns one as-good-as-random shock to
each observation , which is used directly as an exogenous z .
    In some settings, however, exogenous shocks affect the treatment status of many observations
jointly, to different extents. For example, exogenous improvements to a transportation network may
differentially increase the market access of many cities, exogenous reforms to an entitlement program
may differentially expand the eligibility of many individuals, and exogenous changes in international
trade policy may differentially affect import competition in many labor markets. In such settings,
researchers may construct a z that combines a set of as-good-as-random shocks with some predeter-
mined measures of shock exposure. We will generically refer to such z as an instrument, although it
could also denote treatment in a reduced-form analysis. Typically the assumption of shock exogeneity
is viewed as sufficient for this constructed instrument to be orthogonal with  , perhaps conditional
on a set of observed controls.
    This paper establishes identification and inference challenges with z that combine exogenous
shocks and predetermined exposure, and proposes new solutions. We first show that a novel source
of omitted variables bias (OVB) may confound conventional regression approaches. The bias arises
from different observations receiving systematically different values of z because of their exposure
to shocks. For example, even when transportation upgrades are randomly selected in an RCT, more
central regions may see systematically larger increases in market access if they are closer to any
random set of upgrades. Identification of market access effects then fails if the more exposed regions
have systematically different unobservables, such as changes in local productivity or amenities.
    We propose a general solution to this OVB challenge based on specifying counterfactual shocks
that might as well have been realized. With this approach, the set of observed shocks is viewed as one
realization of some data-generating process--what we call the shock assignment process. A researcher
draws counterfactual shocks from this process, recomputes the instrument, and repeats many times.
Then, for each observation , the instrument is averaged across these draws to construct the expected
                                                                                   ~ = z - µ . We
instrument µ . Finally, µ is subtracted from z to obtain the recentered instrument z
show that this recentering is sufficient to purge the OVB that results from non-random shock exposure:
instrumenting with z
                   ~ identifies  , given a non-zero first stage. Intuitively, this instrumental variable
(IV) regression compares the outcomes of observations with higher-than-expected values of z , due
to the realized shocks, to those with lower-than-expected values. By construction this comparison is
driven only by the exogenous shock variation, and is therefore valid, even though z
                                                                                  ~ continues to vary


                                                   1
cross-sectionally because of differences in predetermined shock exposure. A closely related solution,
which isolates the same exogenous variation, is to include µ as a regression control.1
    Adjusting for the expected instrument is generally necessary for identification to follow just from
shock exogeneity, and not also from an implicit assumption of exogenous shock exposure. In con-
trast, conventional controls and fixed effects are only guaranteed to purge OVB (without restricting
unobservables) when they span the expected instrument--a condition that is difficult to assess when
counterfactual shocks are not specified.
    Counterfactual shocks can be specified to compute µ in several ways. When the shocks arise
from true randomization with a known protocol (whether controlled by the researcher or occurring
naturally), counterfactual shocks can be drawn according to this protocol. Otherwise, they can be
specified by plausible exchangeability assumptions, similar to those commonly imposed in observa-
tional data. For example, one might be comfortable assuming that entitlement program reforms could
as well be exchanged across certain states or that different railroad lines had an equal chance of being
selected for upgrade from a partially implemented transportation development plan. In these exam-
ples counterfactuals shocks can be drawn by randomly permuting states' policies or the construction
status of planned lines. Policy discontinuities, as commonly used in regression discontinuity designs,
can similarly yield local exchangeability of shocks and a measurable µ .
    We next show that problems with statistical inference in this setting can also be addressed by
specifying counterfactual shocks. Inference may be challenging when both observed and unobserved
shocks affect many observations jointly, as this may induce non-standard data dependencies with
observations "fuzzily clustered" by their common shock exposure. Conventional asymptotics that rely
on independence between most pairs of observations (for example, those from different clusters or
located at geographic or network distance above some threshold, as in Conley (1999) and Ogburn
et al. (2020)) can then fail. Our solution adapts principles of randomization inference (RI) via shock
counterfactuals. RI-based confidence intervals are exact under constant treatment effects, allow for
any correlation structure in the residuals, and are robust to weak instruments (Imbens and Rosenbaum
2005). RI is particularly attractive for placebo tests, where heterogeneous treatment effects are not a
problem, and yields new specification tests. To address the practical issue of choosing a powerful RI
test statistic, we use the fact that each statistic induces an estimator which rationalizes its observed
value as typical under the null (Hodges and Lehmann 1963; Rosenbaum 2002). We pick the RI statistic
that induces the recentered IV estimator, tightly linking our approach to estimation and inference.
    We complement our finite-sample framework for identification and inference with an asymptotic
analysis of consistency and efficiency. Recentered instruments yield consistent estimates and RI tests,
regardless of the correlation structure of the unobservables, so long as the observed shocks induce
   1 This solution can be represented as recentering the instrument and then taking out the µ -related variation from

the residual. Typically, controlling is therefore is weakly more efficient than just recentering in large samples, as would
be including any fixed set of predetermined controls after recentering.



                                                            2
sufficient cross-sectional variation in the instrument and treatment. We further characterize asymp-
totically efficient instrument constructions by extending the classical analysis of optimal IVs by Cham-
berlain (1987). The optimal instrument involves finding the best predictor of the endogenous variable
from exogenous shocks and endogenous exposure, recentering it, and then adjusting for the structural
residual's heteroskedasticity and dependence on shock exposure. While this instrument is typically
infeasible, it can guide the construction of powerful and feasible recentered instruments.2
    Our theoretical framework provides practical insights for a large number of empirical strategies. We
first illustrate the usefulness of expected instrument adjustment by estimating the local employment
effects of recent high-speed rail (HSR) development in China (Zheng and Kahn 2013; Lin 2017) via
the market access approach of Donaldson and Hornbeck (2016). Simple regressions of employment
growth on market access growth suggest a large and statistically significant effect. However, we find
this to be largely driven by systematic differences in a region's exposure to planned HSR lines, which
we construct by permuting lines that connect the same number of regions (a process that passes RI
specification tests). Chinese prefectures with higher-than-expected market access growth do not have
a significantly higher employment growth. We discuss how our approach relates to a long literature
estimating transportation upgrade effects (e.g. Baum-Snow (2007), Donaldson and Hornbeck (2016),
Donaldson (2018), Bartelme (2018), Ahlfeldt and Feddersen (2018), and Tsivanidis (2019)). We
contrast the challenges of strategically chosen transportation upgrades (Redding and Turner 2015)
with the less well-understood problem that regional exposure to exogenous upgrades may be unequal.
The latter problem can arise either because the geography of upgrades is not uniform or because the
effects of upgrades on measures like market access are heterogeneous.
    Second, we show how our framework can be used to boost the power of simulated policy eligibility
instruments (e.g., Currie and Gruber (1996a, 1996b), Cohodes et al. (2016), Cullen and Gruber (2000),
Gruber and Saez (2002), and East and Kuka (2015)). These instruments are used when individual
policy eligibility depends on both exogenous policies, e.g. at the state level, and non-random individual
characteristics. Simulated instruments isolate exogenous policy variation by not taking into account
individual heterogeneity in policy exposure. We propose to incorporate this endogenous variation but
appropriately recenter the instrument, yielding instruments that are valid under the same assumptions
but likely more powerful because they better predict the treatment. In an application estimating
Medicaid take-up and crowd-out effects from recent Affordable Care Act expansions, recentered IV
estimates have 60-70% smaller standard errors than conventional simulated IV estimates; we similarly
find dramatic and uniform power gains in calibrated Monte Carlo simulations.
    Third, we discuss how instrument recentering can be used to avoid OVB in regression estimates
of network spillovers (e.g. Miguel and Kremer (2004), Acemoglu et al. (2015), Jaravel et al. (2018),
    2 Adão et al. (2020) also follow Chamberlain (1987) in characterizing efficient instruments in a setting with interde-

pendence (specifically, in a model of spatial linkages). Our general characterization of efficient recentered instruments
differs from theirs by allowing for a complex data dependence structure, induced by common shocks, as well as the
endogeneity of shock exposure.


                                                            3
and Carvalho et al. (2020)) which may arise when nodes have systematically different exposure to
exogenous shocks because of their network position. Our solution applies even in settings with com-
plex specifications of spillover effects and shock assignment processes, where conventional regression
controls are generally insufficient. We also discuss how RI can be used to overcome difficult inference
challenges when spillovers are non-local.
   Fourth, we consider shift-share instruments: both traditional ones, which average a common set
of shocks with heterogeneous exposure weights (e.g., Bartik (1991), Blanchard and Katz (1992), Card
(2001), and Autor et al. (2013)), and a recent class of shift-share constructions that are nonlinear in the
shocks (e.g., Boustan et al. (2013), Berman et al. (2015), and Chodorow-Reich and Wieland (2020)).
This analysis builds on Borusyak et al. (2019), who first study identification with linear shift-share
instruments when shocks are exogenous but exposure is not. While they find that simple controls may
suffice to purge OVB, we show that recentering nonlinear shift-share IVs generally requires specifying
shock counterfactuals. We also show how this specification can be avoided, at a likely efficiency cost,
by replacing the nonlinear instrument with its first-order approximation, a linear shift-share IV. We
further illustrate how RI can be a useful mode of inference with shift-share instruments, even in the
linear case where asymptotic approaches have been proposed (Adão et al. 2019) but may suffer from
size distortions in finite samples. We find favorable properties of RI in Monte Carlo simulations based
on the "China shock" setting of Autor et al. (2013). RI has proper coverage even in simulations with
substantial treatment effect heterogeneity, where there is no theoretical guarantee. The simulated
power of RI tests furthermore dominates that of asymptotic tests which impose the null hypothesis
to achieve correct finite-sample size (Adão et al. 2019).
   We further discuss the implications of our framework for model-implied instruments (Adão et
al. 2020), instruments generated by centralized school assignment mechanisms (Abdulkadiroglu et
al. 2017; 2019), and instruments based on weather shocks (e.g. Gomez et al. (2007) and Madestam
et al. (2013)). We show how appropriate instrument recentering and randomization inference can be
used to relax various assumptions imposed in these settings.
   From an econometric perspective, the expected instrument can be seen as a generalization of
the propensity score of Rosenbaum and Rubin (1983). Conventional propensity scores are defined
in settings with randomly sampled data and a conditionally exogenous binary treatment. Earlier
generalizations have considered binary instruments (e.g. Abadie (2003)) and non-binary treatments
(e.g. Hirano and Imbens (2004)). Our setting accommodates these extensions but also allows for the
kinds of interdependent data that naturally arise when exogenous shocks jointly affect the treatment
of many observations. Adjusting for the non-random shock exposure, as captured by the expected
instrument, is furthermore relevant even when shocks are exogenous unconditionally.
   By formalizing the OVB problem and proposing the recentering solution, our paper relates to




                                                    4
specific settings where some of these issues have been previously discussed.3 In the linear shift-share
IV setting, Borusyak et al. (2019) show that instrument validity does not follow from exogeneity of
industry shocks when the sum of exposure shares underlying the instrument varies across observations.
We develop a general characterization of such OVB and a general solution based on expected instru-
ment adjustment. In the context of network spillovers, Aronow (2012) notes that random selection of
treatment units does not imply the randomization of network proximity to them. Aronow and Samii
(2017) propose a way to estimate spillover effects from discrete shocks that does not suffer from this
problem, via inverse propensity score weighting (see also Gerber and Green (2012, p. 261)).4 We
consider a broader class of network settings by imposing no restrictions on the support of the shocks,
develop regression-based estimators, and consider exact randomization-based inference.5
    Our use of randomization inference builds on a rich statistical literature dating back to Fisher
(1935) and reviewed in Lehmann and Romano (2006, Ch. 15). RI was originally proposed for ran-
domized control trials and has recently been used, for example, to test for network interference and
heterogeneous treatment effects (Aronow 2012; Athey et al. 2018b; Puelz et al. 2019; Ding et al. 2016).
RI has also been deployed in a range of non-experimental settings by, among others, Rosenbaum
(1984), Rosenbaum (2002), Bertrand et al. (2004), Imbens and Rosenbaum (2005), Ho and Imai
(2006), Abadie et al. (2010), Cattaneo et al. (2015), Dell and Olken (2018), Ganong and Jäger (2018),
Canay and Kamat (2018), and Shaikh and Toulis (2019). We apply RI to a broad class of settings
where random or as-good-as-random shocks affect many observations jointly but to different extents.
    Finally, our paper contributes to a growing literature on causal inference that focuses on the
assignment process of observed exogenous shocks (e.g. Lee (2008), Athey and Imbens (2018), Shaikh
and Toulis (2019), De Chaisemartin and Behaghel (2018)). This approach contrasts with alternative
identification strategies that adjust for the endogeneity in the expected structural residual, as in the
control functions approach of Heckman and Robb (1985) and difference-in-difference strategies (e.g.
Angrist and Pischke (2008, Ch. 5), De Chaisemartin and D'haultfoeuille (2020), Athey et al. (2018a)).
Leveraging the assignment process is most natural when the shocks are truly randomized. However,
the clarity of an experimental ideal and the implied specification tests make them appealing with
observational data, too. Specification of counterfactuals shocks can be viewed as a formalization of a
natural experiment--what DiNardo (2008) defines as a "serendipitous randomized trial"--in terms of
   3 Our recentering based on simulations is reminiscent of the "dartboard approach" of Ellison and Glaeser (1997), but

this connection is superficial as this paper corrects a biased descriptive statistic (a measure of spatial agglomeration)
rather than an instrument for causal effects.
   4 Aronow et al. (2020) distinguish between methods to estimate spillover effects that allow all units to interact while

imposing parametric structure (e.g., Manski (2013)) and those with unrestricted interactions among a small number of
node pairs (e.g., Hudgens and Halloran (2008)). Like Aronow and Samii (2017), we advance the former approach.
   5 There are further differences between the results of our paper and Aronow and Samii (2017). Our regression

approach generally captures a convex average of heterogeneous effects of a non-binary treatment under an appropriate
monotonicity condition (see Appendix A.4), but not necessarily the average causal effect estimated by Aronow and
Samii (2017). We obtain exact randomization-based inference by assuming constant treatment effects but allowing for
a general spillover structure, while Aronow and Samii (2017) construct asymptotically conservative confidence intervals
with unrestricted heterogeneity by assuming a small fraction of unit pairs are affected by the same shocks.




                                                            5
a particular randomization protocol.6
    The remainder of this paper is organized as follows. The next section motivates our analysis with
a stylized example of the identification and inference challenges in market access regressions. Section
3 develops our general framework and results on identification, inference, and asymptotic efficiency.
Section 4 discusses and illustrates practical implications of the framework. Section 5 concludes.



2     A Motivating Experimental Example
We begin with an idealized example where our framework applies most clearly: where exogenous
transportation shocks from an RCT are used to estimate the local effects of market access growth.
Market access is a statistic which captures the average cost of transportation from a region                  to other
regions of varying size (the exact formula is unimportant at this point). To estimate its effects we
consider a linear structural equation relating the growth of a regional outcome such as land value,
 log V , to the growth of market access  log M A :


                                            log V =   log M A +  ,                                                  (1)


where  captures unobserved shocks to local productivity and amenities occurring in region between
two periods. This equation can be derived from standard models of economic geography (e.g. Redding
and Venables (2004)), in which  is a structural elasticity. Equation (1) can also be interpreted
as a reduced-form causal model, in which  captures the effect of interventions that affect market
access (but not the residuals). For these reasons, equation (1), first proposed by Donaldson and
Hornbeck (2016), and its variants have become increasingly popular in estimating the regional effects
of transportation infrastructure upgrades (e.g. Bartelme (2018) and Tsivanidis (2019)).
    To illustrate the key insights of our framework we imagine estimating  by leveraging experimental
shocks to market access. Specifically, we imagine an RCT that changes transportation costs by
randomly selecting for construction a set of new roads that connect different regions; we assume that
other determinants of market access are held fixed. New roads affect  log M A for all regions (even
those not directly connected by new roads) to different extents, according to the known market access
formula. While we are not aware of actual experimental studies of market access, similar RCTs and
natural experiments have been previously analyzed. For example, Gonzalez-Navarro and Quintana-
Domeque (2016) study an RCT that paved streets in random neighborhoods across Mexico, while
Volpe Martincus and Blyde (2013) exploit random road disruptions in various parts of Chile due to an
    6 The term "natural experiment" is used in a variety of ways in social sciences; see Titiunik (2020) for a recent

discussion. While Titinuik argues that the key feature of natural experiments is the presence of an external factor that
affects treatment assignment, for us they are defined by the specification of counterfactuals for exogenous shocks. Our
results show how this definition yields novel methods for causal inference and specification tests, while for Titiunik
(2020) the utility of natural experiments is more limited--only to help justify certain identifying assumptions.




                                                           6
earthquake. Our hypothetical RCT can also serve as an experimental ideal for observational studies
of market access effects that leverage plausibly exogenous changes to transportation networks.
   At first glance, it may seem that the experimental variation in  log M A is sufficient to estimate 
by a simple linear regression. When new roads are selected at random, their construction is guaranteed
to be exogenous: i.e., independent from all local productivity and amenity shocks in  . Exogenous
transportation shocks are the only reason that  log M A is not identically zero across regions, since
market size and other determinants of transportation costs are held fixed in the RCT. We further
assume that the linear model (1) is correctly specified, such that the effects of the shocks on the
outcome are fully captured by the observed variation in  log M A .
   The first key insight of this paper is that even in this idealized experimental example, non-random
exposure to exogenous transportation shocks can generate omitted variable bias (OVB) in regres-
sion estimates of  . Intuitively, randomization of roads that affect market access is not the same
as randomization of market access. Even when new roads are placed randomly in space, some re-
gions will tend to see systematically higher market access growth because of their relative position in
the country's geography. This tendency can bias regression estimates of market access effects when
unobserved productivity and amenity shocks differ systematically in different areas. Formally, the
necessary orthogonality between  log M A and  can fail, even though the transportation shocks
underlying  log M A are independent of  .
   To see this OVB problem simply, consider a square island consisting of 64 equally-sized regions
with no initial connectivity, such that initial market access is identical for all regions. Suppose new
roads are constructed between regions completely at random: out of all potential roads connecting
adjacent regions, the RCT selects half for construction. One such draw from this experiment is
shown in Panel A of Figure 1, along with the resulting growth in market access.7 Expectedly, regions
that become connected by road tend to have higher  log M A . However, the figure reveals another
tendency: many of the regions with high market access growth are in the center of the island. This
concentration is not by chance. Panel B of Figure 1 shows that the average growth of market access
in each region, simulated across 1,000 counterfactual road networks drawn randomly from the same
assignment process (i.e. experimental protocol), is also higher in the center of the map. We label this
statistic µ , and it can be thought of as a region's "expected" market access prior to the realization
of exogenous shocks. The spatial pattern of µ indicates that more central regions are more exposed
to the RCT: no matter where random roads are built, central regions are more likely to be closer to
them and thus to see a larger increase in market access.
   Systematic differences in shock exposure, as captured by µ , can generate bias in ordinary least
  7 Market  access in period t = 1, 2 is here given by M A t =      - P where  kt is a function of distance and
                                                                  k kt k
connectivity in period t and Pk denotes region k's time-invariant market size (e.g., population). In this simplified
example Pkt = 1 is constant across regions and periods,  = 1, and  kt = 20.1d kt where d kt is the distance by road
from to k at time t (or infinity if there is no path).




                                                         7
                    Figure 1: Market Access Growth in the Motivating Example

                           A. Line Construction and Market Access Growth




                                                                       2.41
                                                                       2.14
                                                                       1.85
                                                                       1.58
                                                                       0.83




        B. Expected Market Access Growth                   C. Recentered Market Access Growth




                                             1.92
                                                                                                 0.5
                                             1.86                                                0.0
                                             1.75                                                -0.5
                                             1.47                                                -1.0
                                             1.39                                                -1.5




Notes: This figure illustrates the omitted variables bias problem and the recentering solution in the
simple market access example discussed in Section 2. Panel A shows a random draw of the railroad
construction experiment, with lines indicating connected regions and shading indicating corresponding
market access growth (computed as described in the text). Panel B shows average market access
growth over 1,000 such random draws. The shading in Panel C indicates the recentered market access
measure which subtracts expected market access in Panel B from realized market access in Panel A,
with the lines again indicating realized line construction.




                                                    8
squares (OLS) estimates of  . The OLS estimates come from a comparison of outcome growth be-
tween regions with high and low market access growth, which tend to be regions with high and low
µ , respectively. Expected market access growth is predetermined (with respect to the experimental
shocks) but need not be exogenous, and endogeneity of µ will generally bias the regression compar-
isons. In the simple example of Figure 1, OVB arises when unobserved productivity and amenity
shocks differ between the center and periphery of the map. For example, if rising sea levels reduce
amenity values near the edges of the island then central regions will tend to see both higher market
access growth and higher residuals, biasing OLS estimates of  upward.
    The second insight of this paper is that this identification challenge has an intuitive but non-
standard solution, based on the same knowledge of the shock assignment process that generated
Panel B of Figure 1. In this experimental setting, one can simulate market access growth across
counterfactual draws of the transportation upgrade RCT in order to compute each region's expected
                                                                      ~ =  log M A - µ ,
market access growth µ . One can then construct a recentered measure, z
which subtracts each region's expected growth from its observed growth. This z
                                                                             ~ can then be used to
instrument for  log M A in equation (1). IV estimation with the recentered measure compares regions
with market access growth that is higher than expected, because of the realization of exogenous shocks,
to regions with lower-than-expected market access growth. By construction, z
                                                                           ~ has no tendency to be
higher or lower in any predetermined group of regions and is thus uncorrelated with any productivity
or amenity shocks in  . In the simple example of Figure 1, observed market access growth is no
longer concentrated in the center of the map after recentering by µ (see Panel C).
    Adjusting for expected market access is generally necessary for identification of  to follow just from
the experimental transportation upgrades, and not also from an implicit assumption of exogenous µ .
We show in the next section that this adjustment can also be performed by controlling for µ in OLS
estimation of (1). Conventional controls and fixed effects similarly isolate experimental variation in
market access when they linearly span µ . Otherwise, controls may or may not purge OVB depending
on the properties of the unobservable, and there is no general guarantee.8 While in our simple example
controlling for geographic centrality would suffice, as it spans µ , this solution is very fragile. In general
µ depends in a complex way on the country's geography and the distribution of market size, as well
as the road assignment process. Appendix Figure A1, for instance, reproduces Figure 1 in a scenario
with unequal population. In this case expected market access growth exhibits complex patterns: µ is
high near the more populated regions (because the value of being connected to large markets is high),
low in the dense regions themselves (since for them internal market access is most important), and
remains low in the geographic periphery. Further complications arise when the map is not square,
when there are preexisting transportation networks, or when the potential set of roads selected by the
   8 Controlling for regional geography perfectly is of course not possible, as this would remove all variation in market

access growth. OVB is also not generally solved by using panel data: if roads tend to be built rather than destroyed,
expected market access grows over time and is thus not captured by region fixed effects. Indeed, equation (1) is already
written in differences and can be equivalently estimated in a panel with region fixed effects, with the same OVB problem.


                                                           9
RCT is concentrated in some parts of the country. Our solutions to OVB, based on drawing shock
counterfactuals to measure µ , continue to apply with these complications.
    The third insight of this paper is that problems with classic statistical inference on  can also
be overcome by simulating counterfactual transportation upgrades. The recentered market access
instrument is inherently correlated across regions because of the common exposure to experimental
shocks. Such spatial dependence may generate challenges for conventional asymptotic approaches to
inference that specify a geographic distance threshold after which observations of z
                                                                                   ~  are uncorrelated
(e.g., Conley (1999)). For the asymptotic approximation to hold this threshold should be sufficiently
small, which may be implausible with all regions exposed to all potential roads.9 We show in the next
section how classical methods of randomization inference can be applied to address such "exposure
clustering." RI confidence intervals have valid coverage in finite samples, regardless of the dependence
structure of z
             ~  . In the market access setting this procedure again leverages knowledge of the road
assignment process, and is again based on simulations of the experimental transportation upgrades.
Challenges of market access effect identification and inference in experimental settings can thus be
overcome in this unified way.
    In most settings, of course, transportation upgrades are not drawn uniformly on a map, their
assignment process is not known, and they may be placed strategically in violation of exogeneity. In
the next section we discuss how shock assignment processes may generally be specified, simulated,
and validated in observational data, provided the exogeneity of shocks is ex ante plausible. In Section
4.1 we apply this approach to a specific market access setting and relate it to existing approaches to
estimating transportation effects, with or without exogenous upgrades.



3     Identification, Inference, and Asymptotic Efficiency

3.1     Setting

We now develop a general econometric framework for settings with non-random exposure to exogenous
shocks. We suppose an outcome y and treatment x are observed for units                     = 1, . . . , L. Of interest
is a causal or structural parameter  relating treatment to outcomes by


                                                  y = x +  ,                                                      (2)


where  denotes an unobserved residual. Initially we assume y and x are both scalar and demeaned,
and that the effect of interest is linear. We discuss extensions to heterogeneous causal effects, additional
control variables, multiple treatments, and nonlinear outcome models in Section 3.6. Although we use
   9 As-good-as-random upgrades to long roads, for example, will tend to cause regions which are far apart in space to

"cluster" by their common market access growth. If the unobserved shocks in  also tend to propagate widely then
z
~  will tend to be correlated across long distances, invalidating spatially clustered standard errors.



                                                         10
a single index      for the observed units, our framework readily accommodates repeated cross-sections
and panel data.
    Importantly, in writing equation (2) we do not assume that the observations of (y , x ) are in-
dependently or identically distributed (iid ), as when arising from random sampling. This generality
allows for complex dependencies across           due to the common exposure to observed and unobserved
shocks. The lack of random sampling is also consistent with settings where the L units represent
a population--for example, all regions of a country--and conventional asymptotic frameworks are
inappropriate (Abadie et al. 2020).
    We suppose that to estimate  a researcher has constructed an instrument z which incorporates
variation from exogenous shocks, summarized by an N × 1 observed vector g . However the instrument
also incorporates additional predetermined variables which govern a unit's exposure to the shocks.
Collecting these additional observables in the set w, we write the instrument as


                                                   z = f (g ; w),                                                  (3)

                 L
where {f (·)}     =1   is a set of known non-stochastic functions. In the previous motivating example, g
contained information on transportation network upgrades and w summarized the regional popula-
tions; the f (·) functions combined g and w to form market access growth for each city                    according
                                                                                                          N
to a known formula. As another example, linear shift-share instruments set f (g ; w) =                    n=1   w n gn
where the w    n   are non-negative exposure share weights. We note that our framework allows x = z ,
in which case  is the reduced-form causal effect of the instrument (as in the motivating example).
    Equation (3) is very general, nesting many applied examples as we discuss in Section 4. Any
instrument that is measurable from a set of observed shocks g and other variables w can be described
in this way.10 Mapping the shocks into the instrument using some transformation f (·; w) is generally
necessary, for example, when the shocks are defined at a different "level" than the unit of observation
(e.g. industry shocks and regional data) or when shocks to one observation have spillover effects to
others. In some cases, such as the market access and linear shift-share examples, the instrument
specification may follow from a particular model for the treatment variable. In particular, when
   ~ (g, w, u) for a known f
x =f                       ~ (·) and some (possibly unobserved) endogenous shocks u, an instrument
                                                                                      ~ (g, w, 0). For
may be specified as the treatment prediction that shuts down these shocks: f (g, w) = f
now we take the choice of f (·) as given, addressing the question of which instrument constructions
may be more desirable in Section 3.5.
    Partitioning the determinants of z into a set of shocks g and other variables w allows us to formalize
the notion that some (but not all) sources of variation in the instrument are exogenous. In an RCT the
exogeneity of shocks can naturally arise from the experimental intervention. With observational data,
  10 Note that equation (3) does not contain a residual: it formalizes an algorithm for computing an instrument rather

than characterizing an economic relationship.



                                                         11
a researcher may appeal to an experimental ideal in which the shocks in g are as-good-as-randomly
assigned given predetermined variables in w, which are not exogenous. For example, in shift-share
designs it may be plausible that the industry-level shocks in g arise from a natural experiment but
that local industrial composition w is endogenous (Borusyak et al. 2019).
     We formalize shock exogeneity by the conditional independence of g from the residual vector
 = ( ) L=1 , given the other sources of instrument variation:


Assumption 1. (Shock exogeneity): g |w

This notion of shock exogeneity combines two conceptually distinct conditions. First, it imposes an
exclusion restriction: that the realization of shocks only affects the outcome of each unit via its treat-
ment x . This condition may be violated when the structural equation (2) is misspecified; for example,
when market access inadequately captures the local economic effects of new transportation.11 Second,
Assumption 1 requires the as-good-as-random assignment of shocks with respect to the unobserved
outcome determinants . This condition is satisfied when the shocks are fully randomly assigned, as
in an RCT: i.e., g  (, w). More generally, Assumption 1 allows w to contain variables that govern
the shock assignment process. We discuss how such conditioning is useful for specifying shock coun-
terfactuals in Section 3.3. The exclusion and as-good-as-random assignment assumptions are isolated
in Appendix A.4, which places our framework in a general potential outcomes model.
     We first consider identification of  from an instrumental variables regression of y on x , with
z as an instrument. Identification follows when the instrument z is relevant to the treatment
and orthogonal to the structural residual. In our non-iid setting, we formalize these conditions as
     1
E    L     zx    = 0 and



                              1                   1                     1
                          E          z     =E              zy    - E           zx      = 0,                       (4)
                              L                   L                     L

                                                                                   1                    1
implying that  is uniquely recoverable from the observable moments E               L     zy     and E   L      zx .
It is worth highlighting that full-data instrument orthogonality (4) combines two dimensions of vari-
ation: over the stochastic realizations of g , w, and , and across the cross-section of observations
    = 1, . . . , L. In the iid case it reduces to the more familiar condition E [z  ] = 0.
     When  is identified, a natural estimator is given by the solution to the sample analog of (4):

                                                       1
                                                  ^=L           zy
                                                    1              .                                              (5)
                                                       L        zx

This ^ is obtained by the sample IV regression of y on x , instrumenting by z . While our primary
  11 The shock exclusion restriction may follow from a particular economic model, as in Donaldson and Hornbeck (2016),

or be relaxed by including multiple treatments in x (e.g. allowing for both direct and spillover effects of the same
shocks, as in Miguel and Kremer (2004)).


                                                           12
focus is on identification and finite-sample inference, some of our theoretic results consider the asymp-
totic properties of such IV estimators. We establish these properties by considering a sequence of
data-generating processes, indexed by L, for the complete data (y, x, g, w). Consistency, for example,
               p
is defined as ^-
                 for L  , while asymptotic efficiency considers large-L approximations to the
            ^ We emphasize that this asymptotic sequence should be viewed as a way to approximate
variance of .
the finite-sample distribution of the IV estimators, rather than as a realistic description of the actual
sampling process for the data.12


3.2     Identification and Instrument Recentering

Our first result formalizes the omitted variables bias problem motivated in Section 2. We show that
the exogeneity of shocks underlying z is not enough to ensure identification of  , even if they are fully
randomly assigned. We then derive a simple but non-standard recentering of z that purges OVB in
this setting. We end this section with results on recentered IV consistency.
    As in the motivating market access example, identification under Assumption 1 can fail when
pre-determined exposure to the natural experiment is endogenous. While this exposure variation
is potentially high-dimensional, our first result shows that OVB is governed by a particular one-
dimensional confounder µ :

Lemma 1. Under Assumption 1,

                                            1                    1
                                       E           z      =E            µ      ,                                    (6)
                                            L                    L

where µ = E [f (g ; w) | w] defines the expected instrument. Thus  is not identified by the instrument
                1
z when E        L   µ      = 0.

            1                   1                                 1                           1
Proof. E    L       z    =E     L     E [f (g ; w) | w] = E       L      µ E [ | w ] = E      L      µ  . The first
and third equality follow from the law of iterated expectations, while the second equality follows by
Assumption 1 and the definition of µ .

Like in Section 2, the expected instrument µ captures the average value of z across different realiza-
tions of the shocks (here, conditional on w). Lemma 1 shows that the exogeneity of shocks makes z a
valid instrument if and only if µ is orthogonal to the residual  . Absent further assumptions on the
unobserved error, adjustment for µ is thus generally necessary to remove OVB. Note that adjustment
is generally necessary even if the shocks are unconditionally as-good-as-randomly assigned, i.e. when
g (, w) in Assumption 1.
   12 This is similar to how Bekker (1994) studies IV regressions with many instruments. As he writes, "the [asymptotic]

sequence is designed to make the asymptotic distribution fit the finite sample distribution better. It is completely
irrelevant whether or not further sampling will lead to samples conforming to this sequence" (p. 658).




                                                          13
    As the sole relevant confounder of z , our expected instrument generalizes the propensity score
of Rosenbaum and Rubin (1983). Propensity scores are typically defined for binary treatments (or
occasionally instruments, as in Abadie (2003)), while our regression-based correction applies to ar-
bitrary z . A more important distinction is that propensity scores are considered in iid settings, as
                                                         ~ (w ) = P r (x = 1 | w ) for w iid across
functions of observation-specific confounders: i.e., µ = µ
 . When w is low-dimensional, this obviates the need to specify the treatment assignment process
            ~ (·) can be non-parametrically estimated or flexible controls for w can simply be included
explicitly: µ
in the estimation equation. These solutions do not apply in our non-iid setup, where all components
of w may affect µ for each          and where the w  µ mapping may be observation-specific. In the
market access example, as explained in Section 2, it is not ex ante clear which features of the country's
geography, distribution of population, and preexisting transportation networks may suffice to span
the cross-sectional variation in µ even with fully random placement of transportation.
    When shock exposure is endogenous but Assumption 1 holds, Lemma 1 suggests a simple but
non-standard recentering of z that identifies  . In fact, a weaker notion of shock exogeneity suffices.
Consider:

Assumption 2. (Weak shock exogeneity):
(i) E [ | g, w] = E [ | w] almost surely for each .
(ii) E [ m | g, w] = E [ m | w] almost surely for each               and m.

Such mean and covariance independence of the residuals from the shocks is implied by Assumption 1
and will also be sufficient for some of our later asymptotic results. Here we use the first condition to
show that  is identified by an adjusted z
                                        ~ , given a non-zero first-stage:

                                                     ~ = z - µ . Then
Proposition 1. Suppose Assumption 2(i) holds and let z

                                                    1
                                                E          z
                                                           ~      = 0,                                              (7)
                                                    L

                                                                    1
such that  is identified by the instrument z
                                           ~ provided E             L      z
                                                                           ~x     is non-zero.

Proof. See Appendix C.1.

A recentered IV regression compares units with a higher-than-expected value of z , because of the
realization of the shocks, to units affected less than expected. The validity of z
                                                                                 ~ thus stems from the
exogeneity of shocks (specifically, Assumption 2(i)), even though it continues to vary cross-sectionally
due to heterogeneous shock exposure. First-stage relevance holds when the units with higher-than-
expected values of z have systematically different values of the treatment x .13
  13 Whenever the shocks induce some variation in treatment, there exist f (·) constructions such that the corresponding

recentered instrument satisfies the relevance condition. Formally, when Var [E [x | g, w] | w] is not almost-surely zero
at least for some , the recentered instrument constructed as z~ = E [x | g, w] - E [x | w] is relevant.



                                                          14
    A closely related regression-based solution to OVB is further implied by Lemma 1: including the
expected instrument µ as a control while using the original z as an instrument. This regression
yields the reduced-form and first-stage moments E            1
                                                             L     z y  and E       1
                                                                                    L     z x , where v  denotes
the cross-sectional projection of v on µ . Appendix C.1 shows that these moments also identify 
under Assumption 2(i).
    This result clarifies the role of conventional controls and fixed effects in purging OVB under our
assumptions: shock exogeneity is sufficient to identify  without recentering z or restricting unob-
servables only when the included controls linearly span µ . In panel data, for example, unit fixed
effects generally purge OVB only when the expected instrument is time-invariant, which generally
requires both the exposure w and the conditional distribution of shocks given w to be time-invariant.
While plausible in some applications, these conditions (in particular, stationarity of the shock distri-
bution) are quite restrictive. For instance, when roads tend to be built more than destroyed expected
market access will tend to grow over time. Similarly, when the average growth in Chinese imports
across manufacturing industries changes over time expected shift-share instruments that average those
shocks together (as in Autor et al. (2013)) will tend to be time-varying, even if the exposure shares
are held fixed.14
    Given identification of  , one may be interested in consistency of the recentered IV estimator
which uses z
           ~ as an instrument for x . Establishing consistency with our general asymptotic sequence
is non-trivial, as we cannot rely on conventional sampling-based arguments for iid data. Instead,
we show in Appendix A.2 how consistency is achieved given an asymptotic first stage, a substantive
assumption on the mutual cross-sectional dependence of z
                                                       ~ , and a weak regularity condition on the
residual  . In line with our general approach, we make no restriction on the mutual dependence
of residuals. Intuitively, the substantive assumption requires the recentered instrument construction
to well-differentiate observations by their exposure to the exogenous shocks, yielding a law of large
numbers that brings ^ close to  for large L. Lower-level conditions sufficient for this assumption are

also given in Appendix A.2.


3.3     Specifying Shock Counterfactuals

Our solution to the OVB challenge involves measuring the expected instrument, which typically
requires specifying counterfactual shocks that may well have occurred. Here we formalize this speci-
fication of the shock assignment process, and discuss general ways in which it may be accomplished.
We discuss and illustrate specific approaches in the context of various applied settings in Section 4.
    Formally, we denote the shock assignment process by the conditional distribution of g | w, which
  14 Borusyak et al. (2019) show that period fixed effects are also not enough in this scenario when the sum of exposure

shares (e.g. the lagged share of manufacturing employment in Autor et al. (2013)) varies across regions. When shocks
are iid within periods, the expected instrument is instead captured by the interaction between this sum of shares and
period indicators.




                                                          15
we write as G (g | w). When G (·) is known, the expected instrument µ =                          f ( ; w)dG( | w) is
measurable and can be used to purge OVB. To emphasize the importance of such knowledge, we state
it as an assumption:

Assumption 3. (Known assignment process): G (g | w) is known in the support of w.

      Specification of G(·) is straightforward when the shocks are actually determined by a known ran-
domization protocol, either overseen by the researcher herself or occurring naturally. Literal random-
ization of g given w implies both the exogeneity of shocks (i.e. Assumption 1, given shock exclusion)
and Assumption 3; the expected instrument may then be given either analytically or by simulating
and averaging across counterfactual randomizations. One might also leverage known discontinuities
in the policies that generate shocks by appealing to local randomization (Lee 2008).
      Absent true randomization or discontinuities, one might instead satisfy Assumptions 1 and 3 by
intuitive specifications of shock exchangeability given appropriate w. Suppose, for example, that
one assumes all permutations of g are equally likely to arise, as when the shocks gn are iid across
n. In this case G(g | w) is known to be uniform when w includes the permutation class (g ) =
{ (g ) |  (·)  N }, where N denotes the set of permutation operators  (·) on vectors of length N
(e.g. Lehmann and Romano 2006, p. 634). The marginal distribution of gn (conditionally on other
components of w) then need not be specified; the expected instrument is the average z across all
permutations of shocks, which serve as counterfactuals:

                                                  1
                                            µ =                 f ( (g ); w).                                         (8)
                                                  N!
                                                        (·)N


This µ is easy to compute (or approximate with a random set of permutations, when N is large).15
This scenario highlights the potentially dual role of w in our framework: as a means of satisfying
exogeneity (Assumption 1) and as a way to simplify the specification of shock counterfactuals (As-
sumption 3).16
      Similar expected instrument calculations follow under weaker shock exchangeability conditions.
When the gn are iid within, but not across, a set of known clusters, Assumption 3 is satisfied when the
class of within-cluster permutations is conditioned on and used to draw counterfactuals. Assignment
processes and exchangeability up to some unknown parameters can be accommodated, allowing for
example parameterized shock heteroskedasticity (see Section 3.6). Besides exchangeability, other
    15 Approximating µ is sufficient for identification because the recentered IV still identifies  in this case: i.e.
     1
E    L
          (f (g, w) - f ( (g ), w))  = 0 under Assumption 2(i), for any fixed or random  (·).
    16 A
       subtlety with Assumption 3 is that it requires the conditional distribution of g to be known in the full support
of w. In some cases this is not restrictive, such as with the exchangeability assumption discussed above. It is also
not restrictive if g  (,w), as when w contains predetermined variables and g arises from a truly random process or
natural event, since then G(g | w) does not depend on w. However, in other cases specifying the distribution of g | w
for counterfactual w may be challenging. In a transportation network setting where upgrades g are drawn randomly
from a predetermined plan w, it may be infeasible to specify the distribution of upgrades given any possible plan, or
even define the set of such plans, i.e. the support of w. In these situations our framework still directly applies viewing
w as non-stochastic.


                                                           16
symmetries in the joint shock distribution can also be used to construct valid counterfactuals (as we
illustrate in Section 4.4).
   We finally note that in observational data it is imperative to corroborate an ex ante argument for
Assumptions 1 and 3 by empirical tests. The next section shows that these assumptions yield testable
implications and a natural testing procedure.


3.4     Randomization Inference and Testing

We next discuss how specification of the shock assignment process can be used to construct valid
statistical tests and confidence intervals for  , following a long tradition of randomization inference
(Fisher 1935). Under constant effects the RI approach guarantees correct coverage in finite samples, of
both observations and shocks, even when the observations exhibit complex unobserved dependencies.
We focus on a particular type of RI tests which is tightly linked to our estimation approach and may
have favorable large-sample power. We then discuss how RI can be used to validate Assumptions 1
and 3, through exact falsification and specification tests.
   In general, RI tests and confidence intervals for  are based on a scalar test statistic T =
T (g, y - bx, w), where b is a candidate parameter value. Under the null hypothesis of  = b and
Assumption 1, the distribution of T = T (g, , w) conditional on  and w is implied by the shock
assignment process G(g | w). One may simulate this distribution, by redrawing (e.g., permuting)
the shocks in g and recomputing T . If the original value of T is far in the tails of the simulated
distribution, one has grounds to reject the null that  = b. Appendix A.1 formalizes this logic and
explains how inversion of these tests yields confidence interval for  by collecting all b that are not
rejected. These intervals have correct size, both conditionally on (, w) and unconditionally. Valid
RI confidence intervals can be obtained for any test statistic, although the the choice of T generally
affects the power against alternative hypotheses.17
   We address the practical issue of choosing a powerful randomization test statistic, and draw a tight
link between T and the recentered IV estimator ^, by building on the theory of Hodges and Lehmann

(1963). Specifically, we consider a T (g, y - bx, w) which ^ rationalizes as being typical under the null,

in the following sense:

Lemma 2. Let T = T (g, y - bx, w) and T  = T (g  , y - bx, w), where g  is distributed according
to G (· | w), independently of (g, x, y ), conditionally of w. Define the Hodges-Lehmann estimator as
the b  R that solve T = E [T  | y, x, w]. Then the recentered IV estimator is the Hodges-Lehmann
                                                  1
estimator associated with the statistic T =       L     (f (g, w) - µ ) (y - bx ).

Proof. See Appendix C.2.
 17 There  are no general results on the relative power of different RI statistics, although good power properties of
certain statistics have been established in some special contexts (Lehmann and Romano 2006, Section 15.2.2).




                                                         17
    This result shows that the recentered IV estimator of  equates the sample covariance between
                          ~ and implied residual y - bx with the expectation of its randomization
the recentered instrument z
distribution, satisfying our definition of a Hodges-Lehmann estimator.18 Notably, the same random-
ization tests, confidence intervals, and Hodges-Lehmann estimators are obtained from the statistic
                                                   1
based on the non-recentered instrument,            L      f (g, w) (y - bx ).19 In this sense, the RI approach
performs the recentering needed for identification of  automatically.
    Statistics chosen on the basis of Hodges-Lehmann estimators can inherit their power properties.
While we are not aware of existing general results, in Appendix A.2 we show that randomization tests
of Lemma 2 are generally consistent, in the sense of having power that asymptotically increases to
one for any fixed alternative, under the conditions which make the recentered IV estimator consistent.
This asymptotic result reinforces the tight connection between T and ^.20 We note, however, that

as in other settings (e.g. Abadie et al. 2010; Mackinnon and Webb 2020) the finite-sample validity
of RI may be most useful when the conditions for consistency are not met, such as when there are
few shocks with concentrated exposure (we discuss an example of such a setting in Section 4.3 and
illustrate good finite-sample power of RI for shift-share instruments with few shocks in Section 4.4).
    Randomization inference can also be used to perform falsification tests on our key Assumptions
1 and 3. Recentering implies a testable prediction that z
                                                        ~ is orthogonal to any variable r satisfying
g r | w, which holds for r that are either functions of w or some other observables thought to be
determined prior to (or independent of) the shocks g . To test this restriction, one may check that
                            1
the sample covariance       L     z
                                  ~ r is sufficiently close to zero by re-randomizing shocks and checking
that T is not in the tails of its conditional-on-(w, r) distribution. Multiple falsification tests, based
on a vector of predetermined variables R , can be combined by an appropriate RI procedure, e.g. by
                                                                       ~ on R .21
taking T to be the sample sum of squared fitted values from regressing z
    Falsification tests are useful in two ways. First, when r is a lagged outcome or another variable
thought to proxy for  , they provide an RI implementation of conventional placebo and covariate
balance tests of Assumption 1. While the use of RI for inference on causal effects may be complicated
by treatment effect heterogeneity, the sharp hypothesis of zero placebo effects is a natural null. Second,
   18 This definition follows Rosenbaum (2002) and Imbens and Rosenbaum (2005). The original definition in Hodges

and Lehmann (1963) is the value of  that maximizes the p-value of the randomization test. For two-sided confidence
interval this means equating T to its median, rather than its mean.
   19 This follows because recentering shifts both T and T  by the same value, 1    µ (y - bx ), which does not depend
                                                                               L
on g . Appendix C.2 further shows that the µ -controlled IV estimator is the Hodges-Lehmann estimator corresponding
                                           1
to the residualized covariance statistic L       z y  - bx .
   20 One might instead consider computing confidence intervals from the distribution of the recentered estimator itself

with re-randomized shocks g  . This idea fails in IV since the re-randomized instrument f (g  , w) - µ has a true
first-stage of zero. The distribution of reduced-form coefficients across re-randomized shocks is also not useful, except
for testing  = 0, as that distribution is centered around zero rather than  .
   21 Formally, this T = z ~ R (R R)-1 R z                                                                   1
                                            ~ can be seen as a quadratic form of the vector-valued statistic L      z
                                                                                                                    ~R ,
weighted by (R R)-1 , where R is the matrix collecting R and z      ~ is the vector collecting z
                                                                                               ~ . In applications we will
further exploit the observation that each coefficient in the regression of z ~ on R can be directly used as an RI test
                                                                                      1           , where here R denotes
statistic: by the Frisch-Waugh-Lovell theorem, the kth coefficient is proportional to L      z
                                                                                             ~ Rk               k
the vector of residuals from projecting the kth column of R on all other columns.




                                                           18
RI tests will generally have power to reject false specifications of the shock assignment process, i.e.
violations of Assumption 3, even when r does not proxy for  . For r = 1, for example (which is
trivially conditionally independent of g ), the test verifies that the sample mean of z is typical for the
realizations of the specified assignment process. Setting r = µ instead checks that the recentered
instrument is not correlated with the expected instrument that it is supposed to remove.


3.5     Asymptotic Efficiency

While any instrument f (g, w) can be made valid by appropriate recentering and used for valid
                                                                                                                        L
randomization inference, the choice of instrument construction from the set of possible {f (·)}                          =1

will generally matter for power. In Appendix A.3 we show that the following instrument minimizes
the asymptotic variance of recentered IV and maximizes the local power of RI-based tests, under
appropriate regularity conditions:

                                                      -1
                                    z  = E [ | w]          (E [x | g, w] - E [x | w]) .                                 (9)


This characterization extends the classic result of Chamberlain (1987) to our setting in showing how
exogenous shocks can be efficiently leveraged. Constructing such optimal instruments may not be
feasible in practice, and typically requires an economic model for both the dependence of treatment on
shocks and the endogeneity of exposure: E [x | g, w]] and E [ | w], respectively. Our characterization
nevertheless provides guidance for constructing recentered instruments, by showing what researchers
should strive for when choosing between alternative IV estimators.
    To build intuition for the optimal instrument, we establish the following Lemma:

             ~ = E [x | g, w] - E [x | w],  = E [ | w], and  = Var [ | w]. Then
Lemma 3. Let z


                                                 z  = -1 (~
                                                          z-^^ ) ,                                                    (10)

              -1 z
                 ~                                                                                            -1 
where ^=      -1                                         ~ on  (weighted by -1 ), and 
                      is the coefficient from projecting z                            ^=                    1+ -1  .


Proof. See Appendix C.3.

    Equation (10) permits an intuitive four-step description of the optimal instrument. First, one
takes the best predictor of treatment given by the shocks and predetermined variables, E [x | g, w].
Second, one recenters this predictor by E [x | w] to remove the potential OVB from non-random shock
exposure, obtaining z
                    ~. Third, one partially residualizes the recentered instrument on the predictable
component of the residual  .22 Finally, one adjusts for the residual variance , as in generalized least
  22 This residualization is partial (i.e. ^  [0, 1)) for the same reason as why, in the conventional panel data context,
the random effects estimator demeans the data within each unit only partially (e.g. Wooldridge 2002, p. 286). As with
unit-specific means in the panel setting,  is orthogonal to z   ~ in expectation and so provides an additional moment for
identifying  . We also note that if  is completely known, a more efficient but less robust instrument than (9) is available,


                                                             19
squares. While steps 1 and 4 follow the optimal instrument construction in Chamberlain (1987), steps
2 and 3 are new, stemming from the potential endogeneity of w.
    Predicting treatment from shocks and exposure (step 1) is trivial in reduced-form studies (since
E [x | g, w] = x for x = z = f (g, w)); otherwise it may be feasible when an economic model of
                                                 ~ (g, w, u) for a known f
treatment is available.23 Specifically, when x = f                       ~ (·) and a set of unobserved
                                                                    ~ (g, w, 0); that is, a treatment
shocks u, a reasonable stand-in for E [x | g, w] may be obtained by f
prediction which shuts down the role of unobserved shocks. This approach has been taken, for example,
by Bartelme (2018) in the market access setting (see also Berry et al. (1999) for the same idea in an
                                                      ~ (g, w, 0) with a first-order approximation,
entirely different context). One may also approximate f
resulting in a linear shift-share instrument we discuss in Section 4.4. Instrument recentering is then
generally necessary to isolate exogenous variation in shocks (step 2).
    The third and fourth steps in Lemma 3 may be more difficult to implement as they require
models of unobservables rather than the observed treatment. Practically, Step 3 calls to control
for predetermined variables which may be correlated with the residual, as including these controls
may approximate the projection of z
                                  ~ on  (by the Frisch-Waugh-Lovell theorem). By the logic of
Proposition 1 such controls are orthogonal to z
                                              ~ in expectation and will not weaken the first stage,
while their inclusion will generally improve efficiency by reducing the residual variance. Step 4 is a
more standard correction for heteroskedasticity and mutual correlation of residuals which is commonly
ignored in practice. We expect that performing the more feasible steps 1 and 2 alone will typically
improve power, although there is no guarantee (see Appendix B.3 for a counterexample discussed in
the context of the application in Section 4.2).


3.6     Extensions

Appendices A.4­A.8 extend our basic identification and inference results in several ways. Appendix
A.4 shows that in the presence of treatment effect heterogeneity the recentered IV estimator captures
a convex average of causal effects under an appropriate monotonicity condition, extending the con-
dition of Imbens and Angrist (1994) to this setting. This appendix further shows how a particular
reweighting of the recentered instrument--with weights given by the shock assignment process--can
yield identification of local average treatment effects in the traditional setting of a binary treatment
and instrument. Appendix A.5 shows how recentered IVs can be constructed when the shock assign-
ment process is only partially specified, allowing for a vector of unknown parameters which govern,
for example, how shocks vary systematically with observables. Valid finite-sample confidence intervals
can be obtained in this case by a two-step RI procedure (Berger and Boos 1994). Appendix A.6
which replaces y with y -  and  with  -  (by not adjusting x) and uses the original z . Since E [ -  | w] = 0,
instrument recentering that isolates variation in g but reduces power is unnecessary. However, this efficiency gain is
obtained at the cost of losing robustness to misspecification of the residual model.
  23 Obtaining E [x | g, w ] without a treatment model is challenging in our general non-iid setup, in contrast to other

settings where the first stage can be estimated non-parametrically (e.g. Newey (1990)).



                                                          20
shows how predetermined observables can be included as regression controls in our setting to reduce
residual variation and potentially increase power. Appendix A.7 discusses identification and inference
with multiple treatments or instruments. Finally, Appendix A.8 extends our framework to nonlinear
outcome models.



4     Practical Implications and Applications
We now show how our theoretic framework brings new practical insights to a variety of empirical
settings: to the estimation of transportation infrastructure effects (Section 4.1), effects of policy
eligibility with simulated instruments (Section 4.2), network spillover effects (Section 4.3), to linear
and nonlinear shift-share instruments (Section 4.4), and to other designs (Section 4.5). We illustrate
some of these insights with empirical applications, estimating market access effects of Chinese high-
speed rail and insurance coverage effects of Medicaid expansions, and with Monte Carlo simulations.


4.1    Effects of Transportation Infrastructure

We first apply our framework to estimate the effect of market access growth on Chinese regional
employment growth over 2007­2016, leveraging the construction of high-speed rail (HSR). We show
how counterfactual HSR networks can be specified, and how correcting for expected market access
growth can help purge OVB. We then provide a broader discussion of how our approach to estimating
transportation infrastructure effects relates to existing methods.


Application The recent construction of Chinese HSR over 2007­2016 gave China a network longer
than in all other countries combined (Lawrence et al. 2019). We first reproduce, with more recent data
and a correspondingly larger network, the finding of Lin (2017) that the HSR-driven growth of market
access strongly predicts local employment growth. We then propose and validate a specification of
counterfactual HSR maps based on planned but unbuilt lines. Recentering observed market access
growth by these counterfactuals reduces the estimated employment effect substantially, to the point
of statistical insignificance. Employment growth is instead strongly predicted by expected market
access: regions more exposed to potential HSR expansion tend to see faster employment growth.
    The Chinese HSR network mostly consists of dedicated passenger lines and has developed rapidly
since 2007. Construction was started by the Medium- and Long-Term Railway Plan in 2004; this plan
was later expanded in 2008 (as part of the stimulus package during the financial crisis) and again
in 2016 (Lawrence et al. 2019). Construction objectives included freeing up capacity on the existing
rail network (including freight lines) and supporting economic development by improved regional
connectivity (Lawrence et al. 2019; Ma 2011). While affordable fares make HSR popular for different
purposes, business travel is an important component of rail traffic, ranging between 28% and 62%,



                                                  21
depending on the line (Ollivier et al. 2014; Lawrence et al. 2019). The role of HSR extends beyond
directly connected regions, as passengers frequently transfer between HSR lines and between HSR and
traditional lines. An early analysis of Zheng and Kahn (2013) finds positive effects of HSR on housing
prices, while Lin (2017) similarly finds positive effects on regional employment.
    We analyze HSR-induced market access effects for 340 sub-province-level administrative divisions
in mainland China. We follow Potlogea and Cheng (2017) in referring to these units as prefectures:
although most are officially called "prefecture-level cities," they typically include multiple urban areas.
We measure market access in 2007 and 2016 by combining data on the development of the HSR network
and each prefecture's location and population (as measured in the 2000 census). A total of 83 HSR
lines opened between these years, with the first in 2008; a further 66 lines (which we refer to as
"planned") were completed or under construction as of April 2019.24 We compute a simple market
access measure in each prefecture                and year t based on the formula in Zheng and Kahn (2013):
MA t =       k   exp (-0.02   kt ) · Pk,2000 .   The summation is over all prefectures (including k = ), Pk,2000
denotes the predetermined population of prefecture k , and              kt   denotes predicted travel time between
regions    and k in year t (in minutes). Travel time predictions are based on the operational speed
of each HSR line as well as geographic distance, which proxies for the travel time by car or a low-
speed train. We relate market access growth, z = log M A              ,2016   - log M A   ,2007 ,   to the corresponding
growth in prefecture's urban employment y from the Chinese City Statistical Yearbooks. This yields
a set of 274 prefectures with non-missing outcome data; see Appendix B.1 for details on the sample
construction and market access measure. Panel A of Figure 2 shows the Chinese HSR network as of
the end of 2016, along with the implied growth of market access relative to 2007.
    Column 1 of Table 1 reports the coefficient from a simple regression of employment growth on
market access growth; Appendix Figure A3 visualizes this relationship.25 The estimated elasticity of
0.23 is quite large: given an average growth of market access of 0.54 log points, it implies a 12.4%
employment growth attributable to the HSR for an average prefecture--almost half of the 26.6%
average employment growth over this period. The estimate is also highly statistically significant using
the spatially-clustered standard errors of Conley (1999), echoing the findings of Lin (2017) (while not
being directly comparable due to our use of later years and a different specification).
    Panel A of Figure 2, however, gives immediate reason for caution against interpreting the OLS
coefficient as causal. Prefectures with high market access growth, which serve as the effective treatment
group, tend to be clustered in the main economic areas in the southeast of the country where HSR
lines are concentrated. Areas near major cities, such as Shanghai and Beijing, also tend to see high
   24 We define a line by a contiguous set of inter-prefecture HSR links that were proposed together and opened simulta-

neously. One experimental HSR line between Qinhuangdao and Shenyang opened in 2003. We include it in our market
access measure but focus on the majority of HSR-induced changes in the network and employment over 2007­2016.
   25 This regression can be viewed as a reduced-form of a hypothetical IV regression, in which the treatment variables

is a measure of market access that accounts for changing population. We focus on the reduced form here because of
data constraints: annual population is measured for all 340 prefectures only in the Census year of 2000. We discuss the
potential roles of controls below.



                                                            22
                  Figure 2: Chinese High Speed Rail and Market Access Growth

                     A. Completed Lines and Market Access Growth by 2016




                               B. All Completed and Planned Lines




Notes: Panel A of this figure shows the completed China high-speed rail network by the end of 2016,
with shading indicating market access growth relative to 2007. Panel B shows the network of all HSR
lines, including those planned but not yet completed as of 2016 (in red).




                                                23
       Table 1: Employment Effects of Market Access: Unadjusted and Recentered Estimates

                                        Unadjusted OLS        Recentered IV        Controlled OLS
                                              (1)                  (2)                   (3)

  Market Access Growth                       0.232                 0.036                 0.078
                                            (0.075)               (0.107)               (0.079)
                                                              [-0.161, 0.190]       [-0.087, 0.221]

  Expected Market Access Growth                                                         0.341
                                                                                       (0.096)

  Recentered                                  No                    Yes                  Yes
  Prefectures                                 274                   274                  274

Notes: This table reports coefficients from regressions of employment growth on market access growth
in Chinese prefectures from 2007­2016. Market access growth is unadjusted in column 1. In column
2 this treatment is instrumented by the market access growth recentered by permuting the opening
dates of HSR lines with the same number of links. Column 3 instead estimates an OLS regression
with recentered market access growth as treatment and controlling for expected market access growth
given by the same HSR counterfactuals. Standard errors which allow for linearly decaying spatial
correlation (up to a bandwidth of 500km) are reported in parentheses. 95% confidence intervals based
on the same HSR counterfactuals are reported in brackets.


market access growth as they are connected by the HSR network. A comparison between these
prefectures and the economic periphery may be confounded by the effects of unobserved policies, both
contemporaneous and historic, that differentially affected the economic center.
   Our solution is to view certain elements of the HSR network as realizations of a natural experiment.
We first formalize this view by specifying a set of counterfactual HSR networks and corroborate it
with appropriate falsification tests. We then appropriately recenter market access to ensure that the
regression leverages contrasts between actual and counterfactual realizations of the HSR assignment
process, and not other sources of cross-sectional variation in market access.
   Our specification of counterfactual upgrades exploits the heterogeneous timing of HSR construc-
tion. Specifically we permute the 2016 completion status of the built and planned lines, assuming
that the timing of line completion is conditionally as-good-as-random. Panel B of Figure 2 compares
the built and planned lines which form our counterfactuals. Planned lines tend to be concentrated in
the same areas of China as built lines, reinforcing the fact that (unlike in our motivating example in
Section 2) construction is not uniformly distributed in space. Although planned lines are of similar
length, they tend to connect more regions: the average number of cross-prefecture "links" is 3.31 and
2.45 for built and planned lines, respectively, with a statistically significant difference (p = 0.029).
To account for this difference we construct counterfactual upgrades by permuting 2016 completion
status only among lines with the same number of links. This procedure generates counterfactual HSR
maps that are visually similar to the actual 2016 network (see Appendix Figure A2 for an illustrative
example) and which isolate more plausibly exogenous variation. For example the main Beijing to


                                                    24
Shanghai HSR line, which has the greatest number of links, is always included in the counterfactuals.
    Table 2 validates this specification of the HSR assignment process by the RI tests described in
Section 3.4. We regress the resulting recentered market access measure (obtained from 999 coun-
terfactual maps) on a constant and several predetermined controls: a prefecture's expected market
access growth, distance to Beijing, latitude, and longitude. We report the resulting coefficients, along
with permutation p-values for individual coefficient significance and their joint significance. . The
test passes for all specifications and all but one individual coefficients. The first column, for example,
where only a constant is included, indicates that the average market access growth is very similar in
the actual and simulated samples; this test would fail if the government prioritized early construction
of the lines that generate more market access, even among those with the same number of links. We
note that while these results are suggestive of correct specification (i.e. we cannot reject Assump-
tion 3) they do not provide direct support of the exogeneity of HSR construction to the unobserved
determinants of employment (i.e. Assumption 1).26
    Figure 3 plots expected and recentered market access growth given by the conditional permutations
of built and unbuilt lines. The effect of recentering is apparent by contrasting the dark- and light-
shaded regions in Panel A of Figure 2 (indicating high and low market access growth) with the solid
and striped regions in Panel B of Figure 3 (indicating high and low recentered market access growth).
                                                               ~  0, reflecting the fact that expected
Recentering effectively removes western prefectures by setting z
market access growth in Panel A of 3 is similarly low. Recentering further removes some prefectures in
the east (such as Tianjin) which saw an as-expected increase in market access that would otherwise be
used to estimate the effect. At the same time, recentering provides a justification for retaining other
regional contrasts. Hohhot, for example, had a higher expected market access growth than Harbin,
due to the planned direct connection to Beijing. This connection was still under construction in 2016,
however, resulting in lower observed market access growth in Hohhot than in Harbin.
    Columns 2 and 3 of Table 1 show that adjusting for expected market access growth reduces the
estimated employment elasticity substantially, from 0.23 to 0.04 when we instrument by z
                                                                                       ~ or to
0.08 when we control for µ . This difference is explained by the fact that employment growth is
strongly predicted by expected market access growth: in column 3 we find a large coefficient on µ , of
0.34.27 Appendix Figure A4 illustrates these findings. Notably, neither of the two adjusted estimates
is statistically distinguishable from zero according to either Conley (1999) spatial-clustered standard
errors and permutation-based inference (which broadly agree in this setting). The apparently large
market access effect estimate in column 1 can thus be viewed as an artifact of non-random exposure
   26 While our specification tests pass for the 2007­2016 long difference, and are robust to using long differences ending

in 2014 or 2015, we have verified in unreported results that the same assignment process is rejected in specifications
which focus on earlier years of HSR development. Specifying a dynamic network formation process is a challenging
issue in general. We thus focus on the long difference for estimation.
   27 We use recentered (rather than unadjusted) market access growth as the treatment in column 3. This does not change

the estimate of  , but makes the coefficient on the expected instrument control more interpretable: the unadjusted effect
in Column 1 is then a weighted average of the two coefficients in column 3.



                                                            25
           Figure 3: Expected and Recentered Market Access Growth from Chinese HSR

                                A. Expected Market Access Growth




                               B. Recentered Market Access Growth




Notes: Panel A of this figure shows the variation in expected market access growth across Chinese
prefectures from 2007 to 2016, simulated by permuting the opening dates of lines with the same number
of links. Panel B plots the variation in recentered market access growth: the difference between the
market access growth shown in Panel A of Figure 2 and expected market access growth. The HSR
network as of 2016 is also shown in this panel.




                                                 26
  Table 2: HSR Assignment Process Specification Tests: Regressions of Recentered Market Access

                                        (1)              (2)              (3)               (4)              (5)

    Constant                          0.017           0.017            0.017             0.017            0.017
                                     {0.460}         {0.460}          {0.460}           {0.460}          {0.460}
    Expected MA Growth                               -0.101           -0.030            -0.193           -0.154
                                                     {0.260}          {0.797}           {0.032}          {0.094}
    Distance to Beijing                                                0.081                              0.036
                                                                      {0.278}                            {0.595}
    Latitude/100                                                                        -1.019           -0.800
                                                                                        {0.068}          {0.134}
    Longitude/100                                                                        0.739            0.748
                                                                                        {0.074}          {0.070}
    Joint p-value                    {0.461}          {0.382}          {0.352}          {0.189}          {0.227}

    Prefectures                        274              274               274              274              274

Notes: This table reports regression coefficients and permutation p-values for tests of correct specifica-
tion of the high-speed rail assignment process in the Chinese market access application. Coefficients
are from regressions of recentered market access growth (2007­2016) on different sets of predeter-
mined controls, where recentering is done by permuting the opening dates of lines with the same
number of links. All regressors are demeaned such that the constant in each regression captures
average recentered market access growth. Distance from Beijing is measured in 1,000km. Separate
permutation-based p-values for each regression coefficient are reported in curly brackets. Joint per-
mutation p-values are based on each regression's sum-of-square fitted values, as described in the text.


to the HSR natural experiment, as formalized by our assignment process.28


Discussion Our theoretical results provide a new general approach for estimating the effects of
transportation infrastructure upgrades, which remains challenging despite a long history in economics
(Redding and Turner 2015). Traditionally, these studies specified as treatment an indicator that region
  is connected to the network (e.g. Chandra and Thompson 2000; Michaels 2008) or a measure of
local connection intensity (e.g. Baum-Snow 2007; Duranton and Turner 2012). Modern approaches
often use more elaborate model-based market access measures (Donaldson and Hornbeck 2016), in
recognition of the fact that infrastructure upgrades can impact regions not directly connected to the
network. While many analyses of transportation shocks study local outcomes of individual regions,
some estimate the effects on bilateral outcomes, such as trade or migration between pairs of regions
or firms (Allen et al. 2019; Volpe Martincus and Blyde 2013).
    Our framework formalizes three distinct challenges with identifying such effects. The first is
strategic placement of infrastructure upgrades in anticipation of regional productivity or amenity
growth, a concern that is well-recognized in the literature (Redding and Turner 2015). When viewing
upgrades as our shocks g , strategic placement can be formalized by a dependence of g on  which
  28 Appendix Table A1 shows that these findings are robust to several alternative measures of employment. It also

reports the estimates of the effects of market access on total rail ridership (which may include HSR, traditional intercity
rail, and intracity lines). The coefficient decline due to recentering is not as large for this outcome, although the
estimates are too noisy to make conclusive claims.


                                                            27
violates shock exogeneity (i.e. Assumption 1). The transportation effects literature has devised several
remedies to this challenge, in particular by excluding major cities or other regions which directly affect
the placement of infrastructure (the "inconsequential place approach") or by using planned or historic
routes to instrument for the constructed railways. Our framework accommodates these solutions by
either limiting attention to inconsequential places (which changes the sample, and therefore ) or by
viewing planned or historic routes as the exogenous shocks (which changes g ).29
    When no assumption of upgrade exogeneity seems ex ante plausible, one can study market access
effects by leveraging the exogeneity of its other determinants. For example, Bartelme (2018) estimates
market access effects by leveraging exogenous shifters to market size and not transportation upgrades.
Our framework also applies to this strategy, with market size shifters collected in g . It is generally
difficult to obtain causal estimates without any exogeneity assumption placed on any shock to market
access.30 We therefore suppose that Assumption 1 holds for some g and , with the other determinants
of market access collected in w. For concreteness we suppose g captures some features of transportation
upgrades, as the alternative assumption of Bartelme (2018) is less standard.
    A second challenge that is less discussed in the transportation upgrade literature is that a cross-
sectional correlation between regional connectivity and unobservables is likely to arise from their
common dependence on regional geography. Even when upgrades are exogenous in the sense of
Assumption 1, they are unlikely to be uniformly assigned across regions. For example, if upgrades
are concentrated in more economically developed areas (as in our HSR application above), which
differ in their unobservables, an OVB problem may arise. Formally, E [ | w] and expected network
connectivity may covary across regions .
    A further third challenge arises with measures like market access, which respond to non-local
upgrade shocks and are defined by a non-linear formula. As discussed in Section 2, this can lead
to complex variation in expected market access growth even when exogenous upgrades are uniformly
distributed in space. This challenge highlights a novel tradeoff between traditional connectivity regres-
sions and the modern approach of Donaldson and Hornbeck (2016): although market access regressions
may better capture the non-local effects of transportation upgrades (and, as such, satisfy the exclusion
restriction in Assumption 1), they may also lead to more intricate OVB challenges.
    These two new challenges are not specific to connectivity and market access regressions. For
example Allen et al. (2019) study how migration between locations in the U.S. and Mexico depends
on a measure of difficulty of traveling between them, as affected by the wall constructed in some parts
   29 Other weakened versions of Assumption 1 are possible too, e.g. that  is conditionally independent of g for all
                                                                                                               n
potential lines n that do not cross region ; the market access instrument should then be constructed excluding those
lines (Lin 2017). We also note that these approaches may not suffice to remove all statistical dependence between g and
, for instance if productivity growth is correlated between the major and "inconsequential" regions and historic routes
affect current productivity growth in unobserved ways.
   30 Appendix A.9 illustrates this issue in a scenario where strategic choice of upgrades is the only problem (because

there are no other shocks and all relevant shock exposure is exogenous). Consistency of the estimator is obtained under
the "approximate" exogeneity of line placement--a nontrivial additional assumption.




                                                          28
of the border between the two countries. Even when new wall placement is not strategic, it is unlikely
to be uniformly distributed along a border (the second challenge). The effects of wall upgrades are
furthermore non-local, complicating OVB (the third challenge). One may expect, for instance, that
wall-induced changes in travel difficulty are correlated with the distance between locations (and thus
potentially with the error term): regardless of which sections of the wall are built, places far away
from the border will be affected less. This is because, when traveling between them, it is easier to
substitute away from newly blocked routes.
    Both of the new challenges raised by our framework are solved by specifying and simulating coun-
terfactual transportation network upgrades, which can be achieved in several ways. A first approach,
which we illustrated above, is to use predetermined upgrade plans and appeal to the randomness of
which subset of the plan materializes as of some date. This approach contrasts with the typical use of
upgrade plans in the literature, as instruments themselves (Redding and Turner 2015), which can relax
Assumption 1 but does not help with specifying shock counterfactuals.31 Our strategy for specifying
counterfactuals is instead similar to the use of accepted and rejected plans for new plant construction
in Greenstone et al. (2010), but in the transportation setting. Donaldson (2018) and Berger and Enflo
(2017) take a step in this direction, using planned but unbuilt railroads in a placebo exercise, as does
Lin (2017) by exploiting engineering problems that slowed down construction of certain lines in a
robustness check.
    A second approach to specifying counterfactuals is to model upgrades in terms of their engineering,
economic or political requirements and find alternative upgrades that satisfy these criteria. One
of the placebo analyses by Ahlfeldt and Feddersen (2018) follows this logic: they note that the
new railway line connected two major cities in Germany at distance around 160km and had three
intermediate stops. They then construct 1,000 random placebo lines that satisfy the same description.
One could also obtain engineering estimates of viable alternative routes for lines connecting major
cities, augmenting the inconsequential places approach with valid counterfactuals.32
    A third approach leverages known discontinuities in the policies determining network links, as in a
simpler regression discontinuity analysis. Campante and Yanagizawa-Drott (2018), for example, note
that cities just under 6,000 miles apart are distinctly more likely to have direct air links, relative to
cities just above that threshold. A local randomization view of such discontinuities (e.g., Lee (2008))
might motivate counterfactual networks that perturb links around the threshold.
    Finally, the assignment process for the shocks may sometimes be given by external (e.g. institu-
   31 Historical routes can be used in place of the plan if the researcher is willing to assume that some of them decayed

for random reasons while others continued to be in use. This again contrasts with the typical use of historical routes
(e.g. Duranton et al. (2013)). We note that if historic routes or plans are instead used to satisfy Assumption 1 then
counterfactual routes and plans need to be simulated to apply our approach.
   32 These approaches can be viewed as special cases of specifying a stochastic network formation model and simulating

it to construct counterfactuals. Other models of network formation (e.g., Chandrasekhar and Jackson 2014; Acemoglu
and Azar 2020) could similarly be used to study causal effects of network centrality in appropriate economic contexts
(see footnote 40). To our knowledge, this would be a novel use of such models.




                                                           29
tional or scientific) knowledge. For example, Volpe Martincus and Blyde (2013) leverage an earthquake
that blocked a large number of roads in Chile to estimate the effect of infrastructure downgrades on
trade patterns. Geological knowledge could be used in this case to specify the disruption locations of
counterfactual earthquakes and construct the expected instrument.
    Without specifying counterfactuals (or even assuming upgrade exogeneity) one may remove some
sources of OVB by including control variables, such as province fixed effects, geographic coordinates,
and pre-period characteristics of the local economy. The unobservables  which are not captured by
those controls should then be assumed orthogonal to the treatment variable. The case for such orthog-
onality can, however, be challenging to make for market access (or similar treatments) constructed
from many sources of variation. It may be untenable to assume that all of the treatment determinants
are orthogonal to the remaining variation in  , while the weaker assumption that such orthogonality
holds despite the endogeneity of some determinants of treatment appears hard to justify a priori.
    Relative to a conventional controlling approach, our framework for estimating transportation up-
grade effects offers two important advantages. First, by clarifying an experimental ideal it makes the
argument for market access exogeneity explicit and transparent and allows for a substantive debate
on whether the institutional features of the setting make such argument ex ante plausible. Second, it
yields additional tests: while pre-trend and balance tests are useful with any identification approach,
our framework offers new specification tests (as illustrated in the HSR setting above), with a new
mode of inference. Our approach also yields new robustness checks for a conventional controlling
strategy. If market access effects are identified without recentering, because the included controls
perfectly capture either the expected instrument or the endogenous features of shock exposure, then
the estimates should be robust to further controlling for expected market access growth constructed
with some reasonable counterfactuals.33


4.2     Simulated Eligibility Instruments

We next show how our framework yields more efficient instruments for estimating the effects of policy
eligibility, relative to the commonly employed simulated instrument approach of Currie and Gruber
(1996a, 1996b). Validity of our novel instruments arises from the same policy exogeneity assumptions
as for simulated instruments, but they attain power gains by incorporating endogenous (yet predictive)
variation in policy exposure and applying appropriate recentering. We first describe the general
approach, drawing on the optimal IV results of Section 3.5. We then illustrate the power gains in an
application estimating the take-up and crowd-out effects of Medicaid eligibility.
  33 Formally,                 1                   1
                 if either E   L
                                    | w = 0 or E
                                   z               L
                                                         | w = 0, where v
                                                                         denotes the in-sample residualization of
                                                              1
variable v on some functions of w used as controls, then E    L
                                                                z
                                                                ~                ~ = z - m (w) for a possibly incorrectly
                                                                       = 0 where z
specified expected instrument m(w).




                                                             30
General Approach We suppose that  captures the causal effect of eligibility x  {0, 1} of in-
dividual    for a public program (such as Medicaid or unemployment insurance) on some outcome y
(such as program takeup, health status, or educational attainment). Eligibility may be a complicated
function of regional, e.g. state-level, government policy and individual characteristics such as income
or family structure. While individual characteristics are likely correlated with the residual, making
x endogenous, we suppose that the state policies may be plausibly viewed as exogenous.
   In such settings Currie and Gruber (1996a, 1996b; henceforth CG) propose the use of simulated
instruments to isolate the exogenous policy variation.34 The CG instrument simulates, for each state,
the average eligibility of a nationally representative sample of individuals if they were to reside in
that state and be subject to its policies. These simulated eligibilities are then assigned to individuals
on the basis of their actual state of residence. In viewing the state policies as plausibly exogenous
shocks, we write g = (g1 , . . . , g50 ) with gn representing the eligibility policy of state n. To define the
CG instrument, we write h(gn ) for the simulated eligibility of the representative sample if they were
subject to policy gn .35 The CG instrument can then be written z CG = h(gs ), where s denotes the
state of residence of individual .
   Since the CG instrument is a function of state policies only, it is valid when those policies are
exogenous. Here we formalize the policy natural experiment by the row-exchangeability of g , con-
ditional on the collections of state residencies s and both observed individual demographics v and
unobserved .        This implies Assumption 1 and a conditionally uniform distribution of gn given
w = {s, v, (g )}, where (g ) again denotes the permutation class of g . The expected CG instru-
                                    1
ment µCG = E z CG | w =            50   n   h(gn ) is thus constant across individuals, so there is no OVB
               CG
from using z        . Statistical inference with z CG is also straightforward: when eligibility policies are
iid across states, conventional state-clustered standard errors are likely to suffice. Thus, the above
framework does not bring new insight to the use of conventional simulated instruments.
   Embedding the CG instrument in the framework of Section 3 instead shows how to construct
other valid instruments, based on the same natural experiment but leveraging additional sources of
variation. When all individual characteristics relevant to eligibility determination--such as income,
family structure, or employment status--are observed and contained in v , eligibility itself may be
written as a function of shocks and exposure measures: x = f (gs ; v ), where f (·) is a known mapping.
By simulating the average x across permutations of state policies, one can measure each individual's
                                               1
expected eligibility µ = E [x | w] =          50   n   f (gn ; v ) and either use it to form a recentered IV or
control for it in an OLS regression of y on x to purge OVB. This contrasts with the usual simulation in
CG's approach: rather than applying 's state policy to random individuals to construct an instrument
  34 For example, Currie and Gruber (1996a) write that their aim is "to achieve identification using only legislative

variation in Medicaid policy" (p. 445). We interpret this as positing exogenous variation in policies across states.
  35 For simplicity we view the h(·) function as non-stochastic, ignoring randomness of the representative sample. In

principle simulated instruments can be constructed from the entire national population.




                                                          31
for x , our approach applies random state policies to individual             to construct a control µ .36
    Alternative recentered IVs are likely to provide higher asymptotic power, per the discussion in
Section 3.5. Since E [x | g, w] = x , the recentered IV z
                                                        ~ = x - µ = E [x | g, w] - E [x | w] is
precisely the inner term of the optimal instrument in equation (9). To see intuitively why this z
                                                                                                ~ is
likely to yield power gains, consider the set of individuals who have the same eligibility under every
state's policy such that x = µ . The presence of such individuals is likely to weaken the first-stage
of the CG instrument, since they are unaffected by variation in z CG . The recentered IV estimator
effectively removes these inframarginal individuals, for whom z
                                                              ~ = 0.
    In Appendix A.10 we extend these insights by showing how more efficient instruments can be con-
structed when some individual determinants of eligibility are unobserved (as in Cohodes et al. (2016))
or endogenously respond to the state policies (as in East and Kuka (2015)). The results similarly
apply in settings where only some policy variation is exogenous, as our application next illustrates.
We further discuss in Appendix A.10 the advantages of our recentered IV relative to controlling for
individual characteristics flexibly, as is common in the related literature on the eligibility effects of
unemployment insurance (e.g., Cullen and Gruber 2000).


Application We illustrate our approach to simulated instruments by estimating the insurance cov-
erage effects of a partial expansion of U.S. Medicaid eligibility in 2014. We first estimate Medicaid
take-up and private insurance crowd-out effects from this expansion with a conventional simulated
instrument. We then show how significantly more precise estimates are obtained by a recentered IV
which leverages both state-wide shocks to eligibility policy and heterogeneity in individual exposure.
    Medicaid is the largest health insurance program in the U.S., covering around 29 million poor,
non-disabled adults. One of the goals of the 2009 Affordable Care Act (ACA) was to extend Medicaid
eligibility to all U.S. citizens and legal residents earning below 138% of the federal poverty line (FPL),
replacing older eligibility rules that were mostly stricter and varied widely across U.S. states. The
constitutionality of such an expansion was challenged (broadly along partisan lines), leading to a 2012
Supreme Court decision that made expansion at the discretion of individual state governors (National
Federation of Independent Business v. Sebelius, 567 U.S. 519). Subsequently, when most of the
principal pieces of the ACA took effect in January 2014, only 19 states enacted the federal Medicaid
expansion, among those 43 states that had not expanded under the ACA or had a universal 138%
FPL cutoff prior to 2014. The divide was partially along the party line: a minority (8 out of 30) of
states with Republican governors but a majority (11 out of 13) Democratic-controlled states eligible
for expansion in fact did so. We refer to the former 19 eligible states as having expanded Medicaid
under the ACA, with the remaining 24 denoted non-expansion states.37 Exact Medicaid eligibility
  36 Inference with the recentered IV z
                                      ~ = x - µ remains straightforward: z   ~  and z ~m m are uncorrelated for and
m in different states when policy shocks are independent, so conventional state-clustered standard errors remain valid.
  37 We follow Frean et al. (2017) in using the Kaiser Family Foundation State Action database to determine which

states adopted Medicaid expansions in each year; see https://web.archive.org/web/20150110162937/https://www.kff.



                                                          32
criteria continued to vary across states in 2014, with some expansion states raising eligibility beyond
the ACA's 138% FPL threshold and some non-expansion states partially raising eligibility though not
fully to the ACA threshold.
   A large and growing literature uses the 2014 partial Medicaid expansion to study effects of Medicaid
eligibility on a number of individual outcomes. Guth et al. (2020) summarizes this literature, which
overall suggests that more widespread eligibility increased access to and utilization of care, led to local
economic gains, and improved health outcomes. Some papers in this literature explicitly characterize
the state expansions as a natural experiment (e.g. Ghosh et al. (2019), Black et al. (2019)); many
describe them as exogenous and leverage difference-in-differences specifications comparing the outcome
trends of individuals in expansion and non-expansion states before and after 2014 (e.g. Hu et al. (2018),
Averett et al. (2019)). Notably, Frean et al. (2017) use simulated eligibility instruments in this context,
finding large Medicaid take-up effects and and little evidence of private insurance crowd-out, although
their analysis exploits ACA policy variation beyond Medicaid expansions. Overall there is mixed
evidence on crowd-out effects from the ACA expansions per se, with some studies finding relatively
large crowd-out (Leung and Mas 2018) and others finding small or inconclusive results (Kaestner et
al. (2017), Maclean and Saloner (2019)). Frean et al. (2017) also note a complication in interpreting
crowd-out effects during this period: the increased availability of direct-purchase private insurance
through new ACA marketplaces, which contrasts with the traditionally studied margin of crowd-out
from employer-sponsored plans (e.g. Cutler and Gruber 1996).
   Applying the Section 3 framework to this setting requires explicitly specifying counterfactual 2014
Medicaid expansions. Our baseline assumption is that a state's decision to expand is exchangeable
among Republican and Democratic-controlled states, while allowing states with different party control
to have different propensities to expand. Thus, all scenarios in which any 8 Republican and 11
Democratic states expanded are viewed as valid counterfactuals. We consider alternative assumptions
on the expansion assignment process in robustness checks below.
   Our data are drawn from the 2013 and 2014 American Community Surveys and capture a rep-
resentative 1% sample of non-disabled U.S. adults (ages 21-64) residing in the 43 states eligible for
expansion in 2014. This repeated cross-section includes information on insurance coverage (by Medi-
caid, ACA marketplaces, and employer-sponsored plans), household income and other demographics
potentially determining Medicaid eligibility, such as employment status and family structure. We
combine this main estimation sample with data from 2012 for falsification exercises; Appendix B.2
describes the sample construction in detail.
org/health-reform/state-indicator/state-activity-around-expanding-medicaid-under-the-affordable-care-act/ . States
which expanded coverage under the ACA or which had a universal 138% FPL cutoff prior to 2014 (and which are
excluded from our analysis) include California, Connecticut, the District of Columbia, Massachusetts, Minnesota, New
Jersey, Washington, and Vermont.




                                                        33
        We estimate take-up and crowd-out effects from second-stage specifications of the form


                                          y t = x t + s t + t + c t  +  t ,                                             (11)


where        indexes individuals, t indexes years (either 2013 or 2014), and s                t   specifies an individual's
state of residence in year t. The outcome y          t   is an indicator for a particular type of health insurance
coverage (Medicaid or private insurance), the treatment x                    t   is an indicator for Medicaid eligibility
under the year-t eligibility rules of 's state of residence, s and t denote state and year fixed effects,
and the vector c      t   includes time-varying controls (discussed below). Recognizing that eligibility is
likely endogenous in equation (11), we instrument it with two alternative IVs.
        We construct the simulated eligibility instrument consistently with our stance that only a state's
decision to expand Medicaid in 2014 as exogenous and not, for example, its prior level of generosity.
Hence this z CG
             t is constant in 2013 and in 2014 is solely determined by the expansion decision gs t 

{0, 1} of an individual's state of residence s t . Since the expansion shock is binary, the mapping from
gs t to z CG                                                                 CG
          t is inconsequential for its use an IV; we nevertheless construct z t in a manner consistent

with the original logic of Currie and Gruber (1996a); see Appendix B.2 for details. Because of the
state and year fixed effects in (11), this instrument produces the same estimate of  as would the
interaction of residing in an expansion state with the 2014 indicator. We include in the control vector
c   t   an indicator for residing in a Republican-controlled state, interacted with year, to match our
assumption of conditional exogeneity of expansion decisions within each governor's party.
        The alternative recentered IV also leverages conditionally exogenous variation in state Medicaid
expansion decisions while also incorporating individual heterogeneity to better predict Medicaid el-
igibility. We construct eligibility predictions z          t   = f (gs t ; v t ) by including in v     t   all individual de-
mographics that affect eligibility (household income, parental and employment status) as well as the
precise eligibility rules of the individual's state in 2013. This construction allows for a perfect pre-
diction of z    t   =x    t   in 2013; in 2014 we predict eligibility from state expansion decisions and prior
eligibility policy (again see Appendix B.2 for details).
        The expected instrument which corresponds to this z              t   is obtained by permuting expansion de-
cisions within Republican- and Democratic-controlled states. It defines a sample of "non-exposed"
individuals whose demographics and state of residence make them always or never eligible for Medi-
caid in 2014 despite the expansion decision and a set of "exposed" individuals for whom the expansion
shock is relevant. Per the discussion above, we drop non-exposed individuals from the 2014 sample
and, in keeping with the difference-in-difference structure, also drop individuals in 2013 whose individ-
ual characteristics would make them non-exposed in 2014. The remaining variation in µ t is absorbed
by the year-interacted state party indicator in c t , making instrument recentering unnecessary.
        Table 3 contrasts the predictiveness of the two instruments in first-stage regressions of Medicaid



                                                               34
                           Table 3: Medicaid Eligibility Effects: First-Stage Estimates

                                                   (1)                (2)               (3)

                        Simulated IV              0.851              0.032
                                                 (0.113)            (0.140)
                                              [0.567,1.115]     [-0.254,0.503]
                        Recentered IV                               0.817              0.972
                                                                   (0.171)            (0.015)
                                                                [0.397,1.162]      [0.941,1.014]

                        Partial R-Squared         0.022             0.113             0.894
                        Exposed Sample              N                 N                 Y
                        States                     43                43                43
                        Individuals             2,397,313         2,397,313          421,042

Notes: This table reports coefficients from first-stage regressions of Medicaid eligibility on the two
instruments described in the text: a simulated eligibility instrument and a recentered prediction of
Medicaid eligibility. Columns 1 and 2 estimate regressions in the full sample of individuals in 2013 or
2014, while column 3 restricts to the sample of individuals whose individual characteristics make them
exposed to the partial ACA Medicaid expansion in 2014. All regressions control for state and year
fixed effects and an indicator for Republican-controlled states interacted with year. State-clustered
SEs are reported in parentheses; 95% confidence intervals, obtained by a wild score bootstrap, are
reported in brackets. R-squared statistics partial out the fixed effects and controls.


eligibility x   t   on either z CG
                                t or z t , controlling for state and year fixed effects and the year-interacted

state party control. We report OLS coefficient estimates, state-clustered standard errors, and partial
R-squared statistics which measure the incremental predictiveness of the instruments given the fixed
effects and controls. To address finite-sample concerns with a relatively small number of state clusters,
we also report confidence intervals by a wild score bootstrap as suggested by Kline and Santos (2012).38
    The table shows that the recentered IV is much more predictive of actual Medicaid eligibility than
the simulated instrument. In column 1 we find that a one percentage point increase in simulated
Medicaid eligibility predicts a 0.85 percentage point increase in actual Medicaid eligibility. The par-
tial R-squared in this first-stage regression instrument is quite small, at 2.2 percent. Including the
recentered IV in column 2 increases the R-squared dramatically, to 11.3 percent; the coefficient on
the simulated instrument falls to an insignificant 0.03 while the coefficient on the recentered IV is
0.82. In Column 3 we restrict estimation to the "exposed" sample of individuals whose demographics
and state of residence make them marginal for the potential expansion of Medicaid eligibility in 2014.
Here we find that a one percentage point increase in the recentered IV predicts a 0.97 percentage
point increase in actual Medicaid eligibility. We also find a high partial R-squared, of 89.4 percent,
reflecting the fact that we have removed the part of the sample where eligibility is unaffected by the
state expansion decision.
    Table 4 shows that estimates of Medicaid take-up and private insurance crowd-out effects are
  38 This computationally efficient approach requires inverting bootstrapped test statistics, which generally makes con-
fidence intervals asymmetric around the IV point estimate.


                                                          35
                                         Table 4: Medicaid Eligibility Effects: Simulated and Recentered IV Estimates

                                                                                                               Has Employer-Sponsored
                                                 Has Medicaid                  Has Private Insurance
                                                                                                                     Insurance
                                        Simulated IV     Recentered IV    Simulated IV     Recentered IV     Simulated IV     Recentered IV
                                            (1)               (2)             (3)               (4)              (5)               (6)

                                                                                A. Baseline Controls
                     Eligibility             0.132            0.072          -0.048          -0.023               0.009          -0.009
                                            (0.028)          (0.010)          (0.023)         (0.007)            (0.014)          (0.005)
                                         [0.080,0.218]    [0.051,0.094]   [-0.109,0.010] [-0.039,-0.008]     [-0.035,0.053]   [-0.021,0.004]

                                                                           B. With Demographics x Post
                                             0.135            0.073          -0.050          -0.024               0.003          -0.008
36




                     Eligibility
                                            (0.029)          (0.010)          (0.022)         (0.007)            (0.013)          (0.005)
                                         [0.082,0.223]    [0.051,0.096]   [-0.114,-0.002] [-0.041,-0.008]    [-0.038,0.036]   [-0.020,0.005]

                     Exposed Sample           N                Y                N                 Y                N                Y
                     States                  43               43               43                43               43               43
                     Individuals          2,397,313         421,042         2,397,313          421,042         2,397,313         421,042

     Notes: This table reports coefficients from IV regressions of different measures of health insurance coverage on Medicaid eligibility, instrumented by
     one of the two instruments described in the text: a simulated eligibility instrument and a recentered prediction of Medicaid eligibility. Columns 1,
     3, and 5 estimate regressions in the full sample of individuals in 2013­2014, while columns 2, 4, and 6 restrict to the sample of individuals whose
     individual characteristics make them exposed to the partial ACA Medicaid expansion in 2014. All regressions control for state and year fixed effects
     and an indicator for Republican-controlled states interacted with year; the regressions in Panel B additionally control for deciles of household income,
     interacted with indicators for parental and work status and year. Conventional state-clustered SEs are reported in parentheses; 95% confidence
     intervals, obtained by a wild score bootstrap, are reported in brackets.
correspondingly much more precise when obtained with the recentered IV. Associated standard errors
and confidence interval lengths fall by around 60-70 percent when we replace z CG
                                                                               t with z t and restrict

estimation to the exposed sample. In columns 1 and 2 of Panel A we obtain a recentered IV confidence
interval of [0.05,0.09] for the take-up effect , relative to much wider a simulated instrument confidence
interval of [0.08,0.22]. For private insurance crowd-out, the respective confidence intervals in columns
3 and 4 are [-0.04,-0.01] and [-0.10,0.01]. Thus we can only reject the null hypothesis of no crowd-
out with 95% confidence when using the recentered IV. Importantly these columns include both the
conventional crowd-out margin of employer-sponsored insurance as well as the novel form of private
marketplace insurance introduced by the ACA. In columns 5 and 6 we focus on crowd-out of employer-
sponsored plans. Neither the simulated nor recentered IV yields statistically significant estimates at
the 95% level, though the latter is again much more precise.
   In economic terms, the recentered IV estimates in Panel A of Table 4 suggest a total private
insurance crowd-out rate of 30%, with a 7.2 percentage point increase in overall coverage offset by
a 2.3 percentage point decrease in private insurance coverage. This overall effect is similar to the
42% crowd-out that Leung and Mas (2018) find in applying a difference-in-differences specification to
the 2014 Medicaid expansion. However, like Frean et al. (2017), we find no statistically significant
evidence of employer-sponsored insurance crowd-out even with our more powerful recentered IV.
   Panel B of Table 4 shows that these substantive findings and apparent power gains are not driven by
the relatively simple regression specification. Adding flexible controls for the individual characteristics
which drive exposure to different eligibility policies (deciles of household income, interacted with indi-
cators for parental and work status and year) in c t leaves both the point estimates and the difference
in simulated IV and recentered IV standard errors and confidence interval lengths unchanged.
   We further analyze the robustness of this analysis in Appendix B.3. First, we validate our as-
sumption of expansion exogeneity with a placebo test that replaces 2014 outcomes with a comparable
cross-section from 2012. Although with the increased precision from the recentered IV we are able
to reject the null hypothesis of no pre-trends, Appendix Table A2 shows that the magnitude of the
placebo coefficient is small (around 0.01-0.02) regardless of the outcome and the instrument we use.
Second, we relax the key exogeneity assumption by allowing a state's decision to expand to depend
not only on the political party of their governor, but also on the state's median household income and
previous rate of Medicaid coverage. Appendix Table A3 shows that the estimated effects of eligibility
remain very similar across specifications. Third, we explore robustness to another implementation of
our approach: namely, using the recentered z     t   as the instrument without restricting to the exposed
sample. Appendix Table A4 shows that this approach only yields power gains when the additional
demographic controls (or an indicator for being in the exposed sample) are included in c t ; we dis-
cuss the combination of factors that drives this finding in Appendix B.3 and relate it to our general
efficiency theory of Section 3.5.



                                                      37
    Finally, we confirm large and uniform power gains from using the recentered IV in a Monte Carlo
study based on our baseline estimates. In this controlled environment the true causal effect and the
shock assignment process are known, allowing us to verify that recentered IV estimator is both close
to unbiased and significantly more efficient than the traditional simulated instrument approach. We
find, for example, that the minimum detectable effects of simulated IV (the smallest null hypotheses
which are rejected by a 0.05-size test with probability 0.8) are roughly three times larger than those
of the recentered IV (see Appendix Figures A5 and A6).


4.3     Network Spillovers

We now discuss the implications of our framework for identification and inference in spillover regres-
sions. In such settings the units         represent nodes in a network (of people, firms, regions, etc.), and
g captures shocks that are as-good-as-randomly assigned to them.39 The target parameter  denotes
the causal effect of a node-specific treatment x which captures the spillovers from g at node . For
example, one may be interested in the effects of an inventor's death on the future productivity of
her co-inventors (Jaravel et al. 2018), having a direct supplier or supplier's supplier hit by a natural
disaster on a firm's growth (Carvalho et al. 2020), or having more "dewormed" students at neighboring
schools on a student's test scores (Miguel and Kremer 2004).40 In bringing our framework to such
settings we maintain the assumption that the spillover treatment has been well-specified, in that it
captures all relevant channels by which the shocks affect a given node.41 Spillover regressions are
typically reduced-form, such that x is a function of the predetermined network structure in w and
the shocks g and z = x , but we also allow for IV regressions where treatment is affected by both g
and other shocks.
    Such spillover regressions may suffer from OVB when different nodes face systematically different
exposure to the exogenous shocks because of their network position. This exposure, summarized by
the expected instrument, depends on how the shocks are assigned and how z is constructed (e.g.,
whether it is nonlinear in the shocks). We first illustrate how these factors determine whether the
OVB can arise and whether it can be solved by conventional regression controls.
    For concreteness we center this discussion of OVB around a stylized version of Miguel and Kremer
(2004, henceforth MK), where z = x counts the number of dewormed students at schools within a
fixed radius from student 's school (excluding itself) and y is some health outcome. The deworming
shocks are generated by an RCT which as-good-as-randomly selected half of all schools for deworming.
   39 It is unimportant that the shocks are assigned to and the outcomes are observed for all nodes. Our framework

applies directly when, for instance, the shocks and the observations correspond to non-overlapping subsets of nodes.
   40 One can also consider settings in which x measures node 's network centrality itself, after a shock to the network

links. The market access measure we discuss in Sections 2 and 4.1 can be viewed as an example, capturing a region's
centrality in a transportation network.
   41 This exclusion restriction may follow from a particular model for peer effects, as in Manski (1993) and Manski

(2013), or a general equilibrium gravity model in the market access case. See Angrist (2014) for a discussion of potential
biases from misspecifying social interaction models in simpler settings.




                                                           38
Thus z can be written as a linear function of which students are experimentally dewormed (collected
in a binary vector g ) with coefficients determined by the pre-existing network of students and schools
(summarized in w). To simplify the discussion we abstract from other features of the actual MK
setting, including the fact that they estimate direct effects of deworming together with the spillover
effect; our framework is extended to such specifications with multiple treatments in Appendix A.7.
   The OVB issue is easy to see in this setting: students who live in denser areas will have system-
atically more dewormed neighbors, and dense areas may also have different unobserved determinants
of health. MK address this threat by controlling for the total number of eligible students in neigh-
boring schools, n . This is indeed what our approach recommends, provided all students have an
equal chance of being dewormed (a probability we denote by q ). The expected number of dewormed
neighbors µ = E [z | w] = qn is then proportional to n , so including this control purges OVB.42
   We now consider four deviations from the benchmark setup, in which conventional regression
controls are no longer sufficient to span the expected spillover treatment and purge OVB. First, there
may be a more complex shock assignment process. For example, stratified random assignment which
makes deworming more likely for some students or schools (depending on, for example, student gender
or school size) would make µ no longer proportional to n .
   Second, spillover effects may involve network weights. Suppose MK had instead specified the
spillover treatment as z =           nN   w n gn , where N is the set of 's neighbors and w           n   measures
the strength of the spillover from neighbor n's deworming status gn , for instance determined by how
frequently    and n interact.43 Then even in simple experimental designs, the expected instrument
equals µ =       nN    w   n   which need not be collinear with n : a person who interacts with neighbors
more will tend to be more affected by the deworming experiment even conditionally on the number
of neighbors. An example of this issue can be found in Acemoglu et al. (2015) where                       and n are
municipalities in Colombia and w          n   are inverse distance weights; here µ reflects the geographic
centrality of the region.
   Third, spillover treatments may be nonlinear in the network shocks. If, for example, MK had
studied the effects of having at least one treated neighbor, the appropriate µ control would have been
the student-specific probability of this event. Under simple randomization of deworming, this µ is a
nonlinear function of n and OVB may be purged by flexibly controlling for n . However this is no
longer the case with school-level randomization or more complex experimental protocols.
   Finally, spillovers may arise from shocks across the entire network, and not just from immediate
neighbors. Suppose MK had instead studied the effect of deworming spillovers given by the geographic
distance from the nearest dewormed school (which may be large for some schools). This non-local
specification of network spillovers makes µ inherently more complex: while in expectation the distance
  42 The n control would not be necessary if spillovers were instead specified as driven by the fraction of dewormed

neighbors. Under simple randomization all students would then have the same expected spillover treatment, µ = q .
  43 One can view such z as a special case of a shift-share instrument further discussed in Section 4.4 below. The

benchmark MK case is obtained with w n  1 [n  N ].


                                                        39
is smaller in dense areas, there is no simple measure that fully captures the expected distance to the
nearest dewormed school. This example is inspired by Carvalho et al. (2020) who study the effects
of network distance between firm            and the nearest firm located in the geographic area of a natural
                                  ohoku earthquake) in the firm-to-firm supplier network.44
disaster (specifically, the 2011 T¯
    In RCT settings like MK's the more intricate OVB challenges raised in each of these scenarios are
easily solved. A researcher can simply compute the expected spillover treatment by redrawing shocks
according to the randomization protocol, and appropriate adjust for it. With natural experiments
like that of Carvalho et al. (2020) institutional or scientific knowledge can help specify counterfactual
shocks, for instance by drawing on appropriate geological models of earthquake probabilities across
regions. With observational data counterfactual shocks can be specified by the partial exchangeability
of shocks, perhaps conditional on node-level observables. The approach of Jaravel et al. (2018),
for example, in which deceased and non-deceased co-inventors are matched based on age and other
characteristics, can be viewed as leveraging such an exchangeability assumption.
    Besides providing a solution to the OVB problem, our framework helps address well-known chal-
lenges of inference in network regressions. A conventional approach in the literature is to assume that
z  is uncorrelated beyond a small geographical or network distance (Conley (1999); see Acemoglu
et al. (2015) for a network example). This may work well when z captures local spillovers. However,
when both observed and unobserved shocks propagate further through the network conventional stan-
dard errors may be distorted. As usual, randomization inference is valid regardless of the correlation
structure of unobserved shocks, relying only on the correlation structure of the recentered instrument
that is implied by knowledge of the shock assignment process.
    An even more challenging problem that is solved by RI is when few shocks are observed in the
data, such as the single earthquake in Carvalho et al. (2020). A small number of shocks makes the
asymptotic approach inapplicable: even absent spillovers, it is generally impossible to consistently
estimate the effect of earthquakes if only one region is treated. The lack of consistency, however,
does not preclude informative inference provided shock counterfactuals are specified. For example,
if the true effect is zero, it is unlikely that unobserved shocks hit exactly the same region where the
earthquake randomly happened. RI-based confidence intervals capture this idea formally.


4.4     Linear and Nonlinear Shift-Share Instruments

We next consider instruments of the form z = f (g, w ), where w is a vector capturing the exposure
of observation to the set of shocks g (usually of the same dimensionality N ). Conventional shift-share
  44 Among firms with a given number of direct suppliers (a covariate Carvalho et al. (2020) control for), the probability

of having at least one supplier's supplier in the randomly assigned earthquake zone (i.e. at distance of two) still depends
on how connected its suppliers are. Nonlinearity of the network distance as a function of shocks makes this probability
also depend on the correlation structure of the shocks. Consider a firm for which the set of second-degree suppliers is
not very large but is geographically dispersed. This firm is much more likely to be affected by a shock hitting random
geographic areas (like an earthquake) than a shock hitting firms regardless of their geography.




                                                            40
instrument variables (SSIVs) set f (·) to take an exposure-weighted average of the shocks: typically
a regional instrument z is constructed from a set of industry shocks gn as z =                             n   w n gn , where
w   n   measures the industry's share (of, say, employment) in the region (e.g., Bartik (1991) and Autor
et al. (2013)). These instruments are often employed when the treatment variable can similarly be
represented as a share-weighted average x =             n      ~ n , where component x
                                                            w nx                     ~             n   = gn + u   n   includes
a potentially endogenous u n . More recently, the SSIV approach has inspired a number of nonlinear
instrument constructions for treatments that combine exogenous shocks with local shares in more
complex ways (e.g. Boustan et al. 2013; Berman et al. 2015; Chodorow-Reich and Wieland 2020).
    We first connect the Section 3 framework to the earlier work of Borusyak et al. (2019) in show-
ing that simple regression controls are typically enough to purge OVB when using linear shift-share
instruments, without specifying counterfactual shocks. We then present two sets of novel insights.
First, we formalize the class of nonlinear SSIVs and propose an approach to identification with them.
Explicit specification of counterfactual shocks is typically necessary for nonlinear SSIVs to be valid,
but linear approximations to such instruments may obviate this need at an efficiency cost. Second,
asymptotic inference is generally challenging in the nonlinear SSIV setting but valid randomization
inference based on shock counterfactuals is straightforward. Moreover, we find in Monte Carlo simu-
lations that in the linear SSIV case RI may serve as a useful complement to the existing asymptotic
approach of Adão et al. (2019). Throughout this analysis we follow Borusyak et al. (2019) in assuming
the shocks gn are as-good-as-randomly assigned while the exposure shares w                         n   may be endogenous
                                                                                                    45
(for example, if unobserved industry shocks affect regions via the same shares).


OVB with Linear SSIVs Borusyak et al. (2019) establish the validity of linear SSIVs under the
assumption of quasi-random shock assignment, formalized as equal conditional expectations of gn
across n, and that the exposure shares sum to one across n for each observation. When the second
assumption fails (what they label the "incomplete shares case"), they show how OVB is purged by
controlling for the sum of shares. They further show how simple quasi-random shock assignment
may be relaxed to allow the conditional expectation of gn to depend on shock-level observables, by
controlling for share-weighted averages of these potential confounders.
    In our general framework, these insights can be seen to follow from the linearity of the expected
shift-share instrument, since
                                       µ = E [z | w ] =           w n E [gn | w]                                         (12)
                                                              n

is an exposure-weighted average of the expected shocks E [gn | w]. When the expected shock is constant
(E [gn | w] =  for some ) and the exposure shares sum to one (                     n   w   n   = 1 for all ) the expected
  45 Our framework also nests the alternative linear SSIV framework of Goldsmith-Pinkham et al. (2020) in which

the shares are exogenous but shocks need not be. With shocks considered non-stochastic and with iid data, as in
Goldsmith-Pinkham et al. (2020), OVB does not arise as all observations are similarly exposed to the exogenous shares.
In Appendix A.9 we generalize this setup and show that identification requires additional assumptions when the shocks
are stochastic and endogenous.


                                                         41
instrument is also constant (µ = ) and no correction to the linear SSIV is needed to avoid OVB. In
the incomplete shares case where W =          n   w   n   varies, it is enough to linearly control for W since
µ = W . Under the weaker assumption of conditional random shock assignment, i.e. E [gn | w] =
qn  for some vector of observables qn , it is furthermore enough to control for the share-weighted sums
of confounders, Q =       n   s n qn , as they absorb µ = Q . The Section 3 framework also implies an
alternative solution to this general case: instead of controlling for Q one can recenter the shocks by
their conditional expectation. This follows because the recentered instrument is also a linear SSIV:


                                         ~ =z -µ =
                                         z                         w ng
                                                                      ~n ,                                 (13)
                                                               n


      ~n = gn - E [gn | w]. SSIV approaches which first residualize shocks on observables (e.g.,
where g
Greenstone et al. (2020)) may be interpreted as following this recentering logic.
   It is worth highlighting that the linearity of SSIV relaxes Assumption 3: the conditional expectation
E [gn | w] is the only moment of the shock assignment process that needs to be specified. Unmodeled
higher moments, such as shock heteroskedasticity and clustering, do not pose problems for instrument
recentering or controlling, as they might in the general case of nonlinear instrument constructions.


Nonlinear SSIVs The SSIV logic has recently been extended to cases where the treatment variable
can be represented as a nonlinear function of some predetermined exposure shares w and potentially
                                                               N
endogenous "shifts," i.e. x = f (~
                                 x , w ) for x    x n )n=1 . Chodorow-Reich and Wieland (2020), for
                                             ~ = (~
example, study the effects of a regional labor reallocation index x measuring the dispersion of local
industry growth rates x
                      ~   n   with initial industry employment shares w        n   as weights. If the researcher
observes an exogenous shifter gn for x
                                     ~ n , that is not observation-specific (i.e., measured nationally or
in other countries), an intuitive instrument can be constructed as z = f (g, w ), predicting x via
exogenous shocks and predetermined exposure. We believe this general formulation of such nonlinear
SSIVs is novel, while nesting several applied examples, including the predicted change in a regional
Gini coefficient in Boustan et al. (2013), the predicted share of migrants in Basso and Peri (2015),
and the predicted foreign demand instrument of Berman et al. (2015).
   Nonlinearity of f (·) generically leads to a challenging OVB problem. Even with fully exchangeable
shocks and "complete shares," where linear SSIV is valid without correction, the expected instrument
µ is a complex function of w . Moreover, unlike in the linear case, second and higher moments of the
shock assignment process may be relevant to the expected instrument and must generally be specified
for the appropriate recentering. Shock heteroskedasticity and clustering, in particular, are potentially
problematic for nonlinear SSIV.
   Our framework yields two solutions for OVB with nonlinear SSIVs, which give a likely tradeoff
between efficiency and robustness. A researcher may recenter a nonlinear z given a specification of
shock counterfactuals. Alternatively, she may take a first-order approximation of z around some fixed

                                                          42
                                                                                                                   f
vector of shocks g 0 (e.g., g 0 = 0) to obtain a linear SSIV of z
                                                                 =w
                                                                   g , for w
                                                                            =                                      g    g 0 , w . As before,
the linear instrument is valid when the shocks have a common mean and                                      n   w
                                                                                                                   n   is controlled for (or,
more generally, when the means of shocks depend linearly on some qn and                                            n   w
                                                                                                                        n qn is controlled
for). As an approximation to z the linear SSIV is likely to predict x less well and thus be less
efficient. On the other hand, its validity depends on correct specification of fewer moments of the
shock assignment process making it more robust. Such linear approximations have indeed motivated
SSIV instruments in the context of some economic models (e.g., Kovak (2013), Adão et al. (2019), and
Adão et al. (2020)) but the same logic applies generally, e.g. to predicted labor reallocation indices
and Gini coefficients.
    To make concrete the potential for OVB with nonlinear SSIVs, and our two solutions, we take
a stylized example of a popular instrument which could be called a "SSIV in logs" (e.g., Berman
                                                                      X 1
et al. 2015; Berthou et al. 2019; Costa et al. 2019). Suppose x = log X 0
                                                                          denotes the growth rate of
some regional variable which can be represented as a sum of industry components, X                                             t   =        ~
                                                                                                                                            X   nt .
                                                                                                                                        n

For example, X       t   may denote the total demand for a regional output that aggregates demand across
                                                                                                                           ~ n0
                                                                                                                           X
industries n. Then x can be rewritten as a nonlinear function of initial shares w                                  n   =   X 0     and regional
                             ~
                             X
growth rates x
             ~       n   =   ~
                             X
                                 n1
                                      , as x = log            n   w nx
                                                                     ~ n . Suppose that a researcher suspects endogeneity in
                                 n0

regional growth rates but observes an industry characteristic Gnt with plausibly exogenous growth
               Gn1
rates gn =     Gn0   that predict the x
                                      ~ n . This motivates a nonlinear SSIV:


                                                              z = log               w n gn .                                                 (14)
                                                                                n


    Although exogeneity of gn makes                           n    w n gn a valid instrument (after controlling for                     n   w n ),
the log transformation in equation (14) generally introduces OVB. This is because the log function
is concave, so the expected instrument µ = E [z | w] is systematically higher for regions where

    n   w n gn has a lower variance. In particular, regions with more diversified economies (i.e., with
w   n   more dispersed across n) will tend to have systematically higher z , while they may also have
systematically different unobservables. For example, diversification may make the local economy more
resilient to unobserved shocks, which would generate an upward bias in an IV estimator which takes
some measure of regional economic growth as an outcome.46
    Both of our solutions to OVB are quite intuitive for SSIVs in logs. One could recenter equation (14)
by the appropriate measure of diversification µ , which generally requires specifying and simulating
counterfactual shocks. Alternatively one may take a log-linear approximation around gn = 1, which
here yields an intuitive linear SSIV: z
                                       =                           n   w   n   log gn . Removing OVB from this instrument requires
   46 There is a further problem with the use of (14) in practice. In panel specifications with unit and period fixed

effects the instrument is commonly specified as z t = log    n
                                                               w n Gnt (e.g., Berman et al. 2015). In first differences
                                                                                                       w n Gn0
this corresponds to z = log               n
                                              w
                                              ~   n gn   where shares are reweighted, w
                                                                                      ~        n   =              .        These shares do not
                                                                                                         w n Gn 0
                                                                                                       n
align with the economic intuition behind the instrument construction and are likely to lead to a weaker first-stage. The
                                         Gnt
correct construction is z t = log  n
                                     w nG    .
                                                         n0




                                                                               43
only specifying (and appropriately controlling for) the expected log gn .47


Inference and Monte Carlo Simulations We finally discuss how our framework brings new tools
to SSIV inference. We are not aware of any general asymptotic theory for the nonlinear case (unless
restrictive independence assumptions are placed on the residuals), making RI an attractive approach
to inference. For the linear case we argue that RI may serve as a useful complement to the asymptotic
theory of Adão et al. (2019) .48
    The choice between RI and asymptotic approaches involves tradeoffs. An advantage of RI is its
validity even with relatively few or concentrated shocks, when the asymptotics approximation may
not be accurate. At the same time, RI requires specification of the shock assignment process, rather
than its first moment only, and thus assumptions of homoskedasticity (or a known parametric form
of heteroskedasticity, as in Appendix A.5), distribution symmetry, or similar conditions which are not
required for asymptotic exposure-robust inference. On other dimensions the two approaches are hard
to compare in general: they both require constant treatment effects (and their sensitivity to treatment
effect heterogeneity is not known), and their power may differ.49
    We therefore examine the power and robustness properties of RI in a Monte Carlo simulation.
Our simulation is based on the influential SSIV study by Autor et al. (2013), who estimate the
effects of import competition with China on U.S. local labor markets. The simulation process follows
Borusyak et al. (2019) in redrawing import competition shocks according to a wild bootstrap (to
preserve shock heteroskedasticity), holding fixed the exposure shares and estimated structural residuals
(see Appendix B.4 for details). We consider two asymptotic approaches to SSIV inference: the
conventional "exposure-robust" standard errors of Adão et al. (2019) (obtained via the equivalent
shock-level regression in Borusyak et al. (2019)) and a version designed for better finite-sample coverage
by imposing the null hypothesis. We contrast these approaches with an RI procedure based on
randomly flipping the signs of the simulated shocks, which leverages a known symmetry of the shock
distribution shape.
    Panel A of Figure 4 presents a simulated power curve for the main Autor et al. (2013) data-
generating process with 794 industry-by-period shocks (for 397 manufacturing SIC4 industries in two
periods). We plot simulated rejection rates for each of the three modes of inference across both a
  47 More robust linear SSIVs may more generally be obtained by taking the nonlinear transformation before averaging.

Derenoncourt (2019), for example, addresses a skewed distribution of shocks by taking the sample percentiles of a shift-
share instrument, yielding a nonlinear SSIV. Taking instead an exposure-weighted average of shock percentiles yields
a linear SSIV that is valid without recentering, provided these percentiles are as-good-as-randomly assigned and the
weights sum to one.
  48 Adão et al. (2019) consider an asymptotic sequence with many uncorrelated (or weakly correlated) shocks and

sufficiently dispersed exposure. Linearity of the instrument is indispensable for their results. This is clear from the
equivalence result in Borusyak et al. (2019), which shows that the Adão et al. (2019) standard errors can be obtained
from conventional calculations after transforming the data to the level of shocks. For nonlinear SSIV no such equivalence
generally exists, making it difficult to draw on conventional asymptotic theory.
  49 Adão et al. (2019) show that when treatment effects vary their standard errors are asymptotically conservative, but

this result only applies to reduced-form SSIV regressions under certain conditions on the exposure shares. We know of
no such guarantees in the IV case.



                                                           44
                         Figure 4: Simulated Size and Power of Alternative Shift-Share IV Inference Procedures

                           A. Many Shocks, Constant Effects                                                                               B. Few Shocks
                  1.00                                                                                             1.00




                  0.75                                                                                             0.75
 Rejection Rate




                                                                                                  Rejection Rate
                  0.50                                                                                             0.50




                  0.25                                                                                             0.25




                           5%                                                                                              5%
                  0.00                                                                                             0.00
                          -     -4           -2         0            2          4        +                                -     -4           -2         0            2          4        +
                                                   Coefficient                                                                                     Coefficient

                                     Exposure-robust        E-R, Null imposed       RI                                               Exposure-robust        E-R, Null imposed       RI


                                C. Effects Vary by Year                                                                   D. Effects Vary by Census Division
                  1.00                                                                                             1.00




                  0.75                                                                                             0.75
 Rejection Rate




                                                                                                  Rejection Rate




                  0.50                                                                                             0.50




                  0.25                                                                                             0.25



                           5%                                                                                              5%
                  0.00                                                                                             0.00
                          -     -4           -2         0            2          4        +                                -     -4           -2         0            2          4        +
                                                   Coefficient                                                                                     Coefficient

                                     Exposure-robust        E-R, Null imposed       RI                                               Exposure-robust        E-R, Null imposed       RI


Notes: This figure plots simulated power curves for different shift-share IV inference procedures. The
baseline data-generating process in Panel A comes from Autor et al. (2013), as described in Section
4.4 and Appendix B.4. In Panel B we reduce the number of industry shocks in each period from 397
to 20. In Panels C and D we specify a data-generating process with heterogeneous effects by period
or Census division. Exposure-robust tests are obtained from the equivalent shock-level regressions of
Borusyak et al. (2019). Hollow circles indicate the power at  = ±, approximated by  = ±1, 000.




                                                                                             45
true causal effect of  = 0 and a range of alternative hypotheses (normalized such that the SSIV
estimate in the data has  = 1). Consistent with Borusyak et al. (2019) we find that conventional
exposure-robust standard errors yield a mild overrejection of the nominal 5% level test (see their Table
C6, rows (b)), while the other two procedures exhibit no significant size distortions. Despite correct
coverage, power of the null-imposed asymptotic inference procedure is low, failing to reject arbitrarily
large values of  (i.e. yielding infinite 95% confidence intervals) over 20% of the time. In contrast the
RI procedure has power similar to that of conventional exposure-robust asymptotics, if a bit smaller.
   In Panel B of Figure 4 we consider a modified data-generating process with fewer shocks by
aggregating manufacturing industries to their SIC2 groups (yielding 20 shocks in each period), again
following Borusyak et al. (2019). The size of all three methods is similar to that in Panel A, with the
overrejection of conventional exposure-robust standard errors increasing slightly. Here the power of
RI is asymmetric: similar to that of conventional exposure-robust inference for negative values of 0 ,
but weaker for positive values. Still, it is again uniformly much stronger than that of the null-imposed
procedure which (approximately) shares the RI property of correct size.
   Finally, Panels C and D of Figure 4 explore robustness of the three methods to treatment effect
heterogeneity, either across the two periods (Panel C) or nine geographic regions (Census divisions,
Panel D), with the original 794 shocks. The data-generating process here is based on the heterogeneous
effects estimated in the Autor et al. (2013) data and demeaned in such a way that sets the median
SSIV estimate to zero to make coverage well-defined (see Appendix B.4 for details). Although there
is no theoretical guarantee for either RI nor the asymptotic approximations in this case, the results
are surprisingly similar to those in Panel A: RI coverage is correct and its power is close to that of
exposure-robust inference, while substantially exceeding that of the null-imposed version.


4.5    Other Settings

We conclude this section by discussing implications for model-implied optimal instruments (Adão et
al. 2020), instruments generated by centralized assignment mechanisms (Abdulkadiroglu et al. 2017;
2019), and instruments based on weather shocks (Gomez et al. 2007; Madestam et al. 2013). We
explain how our framework can relax certain restrictions for identification and suggest an alternative
basis for inference.
   Adão et al. (2020) develop a spatial general equilibrium model and propose a novel way to identify
its parameters. They assume that a researcher observes shifters g to some model's primitives, such as
trade costs. They then propose log-linearizing the model around the initial equilibrium to derive an
estimating equation for the changes in some regional outcome y , of


                                      y =       m   n   (w,  ) gn +  ,                             (15)
                                            n




                                                    46
where m     n   (w,  ) represents the general-equilibrium elasticity of y with respect to gn as a function
of predetermined equilibrium variables in w, and  captures unobserved shocks. Adão et al. (2020)
treat w as non-stochastic and impose exogeneity of the observed shifters by assuming50


                                                      E [ | g ] = 0.                                                   (16)


They then directly apply the classic efficiency result of Chamberlain (1987) to derive an optimal
"model-implied" generalized method of moments estimator of  .
    Our framework clarifies and permits a relaxation of an assumption that predetermined equilibrium
is exogenous, which Adão et al. (2020) implicitly make in this setting. The identification assumption
(16) is stronger than it might appear because the predetermined equilibrium variables in w are im-
plicitly conditioned on, and therefore treated as exogenous. To see this assumption clearly, note that
(16) implies E [ ] = 0 by the law of iterated expectations. While innocuous under iid -sampling,
this condition is strong in the interdependent economy, as it requires the unobserved shocks to be
on average the same for each region , regardless of the local characteristics in w like industry com-
position or migration shares.51 Our framework allows for a weaker assumption of E [ | g ] = E []
(Assumption 2(i)) without restricting E [ ] = 0, and therefore allows the predetermined equilibrium
to be endogenous; identification then follows from appropriate recentering. Since the treatment in
(15) is linear in shocks, recentering simply requires recentering gn by their conditional expectation
(as in Section 4.4; see also Appendix A.8 for a discussion of how the Section 3 framework is extended
to nonlinear equations). Our generalization of Chamberlain (1987) (similarly extended in Appendix
A.8) further shows how optimal recentered instruments can be constructed in this setting to allow for
both endogeneity of the predetermined equilibrium as well as potential non-iid ness of the unobserved
error  . As always, randomization inference can be used to account for unspecified error dependence.
    Next, our approach applies to settings in which instruments arise centralized assignment mecha-
nisms, such as those used to allocate public school seats to students. Abdulkadiroglu et al. (2017)
first show how centralized school assignments can be used as valid instruments when generated by
mechanisms satisfying the "equal treatment of equals" property, in which students with the same
school preferences and administrative priorities face the same assignment propensity. They use mar-
ket design theory to derive large-sample approximations to this assignment risk in deferred acceptance
mechanisms and further show how such assignment propensity scores can be simulated by redrawing
the randomized lottery numbers which break ties between students with the same preferences and
priorities. Abdulkadiroglu et al. (2019) extend this framework to mechanisms with discontinuities in
assignment rules (e.g. over scores from a school entrance exam) by showing how assignment risk can
  50 More  precisely, they use the property of their model that gn enter (15) via particular shift-share averages  = ( )L=1 ,
and assume E [ |  ] = 0. This detail does not affect our discussion of this setting.
  51 This point is more clearly seen in our framework, which views w as potentially stochastic and writes (16) as

E [ | g, w] = 0, which in turn implies E [ | w] = 0.



                                                             47
be derived from a local randomization approach.
    Our framework nests this setting by writing indicators for assignment of student to a given school
as z = f (g ; w), where (g ; w) partitions the inputs of a given assignment mechanism. The shock vector
g might for example contain the set of tie-breaking lottery numbers in a stochastic deferred acceptance
mechanism, with w containing the set of students' rankings over schools and administrative school
priorities. Our expected instrument µ would then coincide with the assignment propensity scores
defined in this literature.
    Our analysis offers two new insights to this setting. First, expected assignments may be generated
by simulating any mechanism with a random or locally random component g , whether or not it satisfies
equal treatment of equals. The validity of assignment instruments that recenter by or control for these
propensity scores arises simply from the exogenous variation in g . Second, valid finite-sample tests and
confidence intervals can also be obtained by simulating the mechanism. This RI approach accounts for
the inherent dependencies of school offers across students. It remains valid when potential outcomes
are not independent, as when applicants with similar school preferences and priorities are similar in
other unobserved ways, or are affected by common unobserved shocks.
    Finally, our approach applies to empirical designs leveraging spatial variation in weather, such
as rainfall on the days of elections and other political events. It is standard in this literature to
measure "normal weather" in each location as the average of historical data and then subtract it
from the actual weather (e.g. Gomez et al. 2007) or control for it (e.g. Madestam et al. 2013). These
two approaches to the OVB problem directly parallel our general solutions, given an assumption of
stationary weather. Our framework implies that this assumption is not important for identification:
any meteorological model that yields a weather distribution for the event days could similarly be used
for recentering. Further, randomization inference has not been applied in this context, while Lind
(2019) has shown that conventional modes of inference have severely distorted coverage because of the
spatial correlation in both weather and residuals. The only exception we are aware of is Madestam
et al. (2013), whose placebo test uses historical weather maps to preserve the correlation structure of
the data. Applying such simulations to construct confidence intervals for the actual estimates would
be in line with our general RI framework.



5     Conclusion
Many studies in economics construct treatments or instruments that combine exogenous shocks from
randomized or natural experiments with predetermined measures of shock exposure. We develop a
general econometric framework for such settings that allows for the possibility that shock exposure
is endogenous. Except in special cases, such endogeneity generates bias in conventional regression
estimators, while standard modes of statistical inference may also be invalid when observed and unob-



                                                   48
served shocks affect observations jointly. We show how these identification and inference problems can
be solved by specifying an assignment process for the exogenous shocks: namely, a set of counterfactual
shocks that might as well have been realized.
   This general framework has concrete implications for a large number of settings. First, we illustrate
the usefulness of specifying counterfactuals for new railroad construction when leveraging this variation
to estimate market access effects. Estimates of the effects of high-speed rail on local employment in
China are reduced to a statistical zero when adjusting for a region's expected market access growth.
Second, we show how our framework can be used to construct instruments which may be a more
powerful alternative to simulated eligibility IVs. Estimates of Medicaid take-up and crowd-out effects
are more than twice as precise when obtained by an instrument incorporating both as-good-as-random
policy variation and non-random individual exposure. Third, we provide Monte Carlo evidence that
randomization inference with linear shift-share IVs can be a valid and powerful alternative to more
traditional asymptotics. Finally, we show how our approach allows a researcher to make formal
identification arguments and conduct valid randomization inference with network spillover regressions,
nonlinear shift-share instruments, and in other settings.
   We conclude with a discussion of two important assumptions in our framework and avenues for
future research. First, while we show in Appendix A.4 that our solution to OVB applies under general
treatment effect heterogeneity, validity of the randomization inference procedure is only guaranteed
under constant effects. Valid inference with heterogeneous effects and interdependent data is a difficult
challenge, even in a more standard asymptotic approach (Adão et al. 2019), and the RI approach has
historically struggled to accommodate such heterogeneity. In simulations of shift-share IVs we do
not find that RI yields poor coverage and power under simple departures from constant effects. We
recommend that researchers run similar simulations in the context of their own applications.
   Second, specifying shock counterfactuals can be challenging in settings with no true randomiza-
tion. In the paper we illustrate how these challenges can be overcome in a variety of settings by
finding appropriate exchangeability of the shocks. For example, permuting the timing of railroad
upgrades within observably similar groups may yield a plausible set of counterfactuals for gauging the
potential for OVB. We also show how such specifications can be tested. We further consider some
partly-specified shock assignment processes in Appendix A.5; future research may yield more flexible
approaches.
   In our view, specifying shock counterfactuals has innate value in observational studies that claim
to leverage a natural experiment, understood as a serendipitous randomized trial (DiNardo 2008).
A virtue of randomized trials is that valid causal inference can be conducted without restricting
the unobserved residuals (e.g., potential outcomes in simple settings). In the settings we consider,
including with observational data, this property is only maintained when an expected instrument
adjustment is performed, which generally requires an explicit shock assignment process. Methods



                                                   49
that instead rely on properties of the structural residuals, such as a parallel trends assumption, are
instead referred to as quasi-experimental by DiNardo (2008). An instructive example can be found in
the setting of Redding and Sturm (2008) who study the effects of German reunification--­an event for
which parallel trends may plausibly hold while no obvious counterfactuals exist, and thus a natural
experiment may not be a fitting term. Generalizing our framework to augment specifications of shock
counterfactuals with plausible restrictions on the residual appears a fruitful area for future work and
may yield new "double-robust" identification results, in a sense similar to that of Arkhangelsky and
Imbens (2019).


References
Abadie, Alberto. 2003. Semiparametric instrumental variable estimation of treatment response mod-
    els, 113:231­263.
Abadie, Alberto, Susan Athey, Guido W. Imbens, and Jeffrey M. Wooldridge. 2020.
    "Sampling-based vs. Design-based Uncertainty in Regression Analysis." Econometrica 88:265­
    296.
Abadie, Alberto, Alexis Diamond, and Jens Hainmueller. 2010. "Synthetic control methods for
    comparative case studies: Estimating the effect of California's Tobacco control program." Journal
    of the American Statistical Association 105:493­505.
Abdulkadiroglu, Atila, Joshua D Angrist, Yusuke Narita, and Parag A. Pathak. 2019.
    "Breaking Ties: Regression Discontinuity Design Meets Market Design." Working Paper.
       . 2017. "Research Design Meets Market Design: Using Centralized Assignment for Impact
    Evaluation." Econometrica 85:1373­1432.
Acemoglu, Daron, and Pablo D. Azar. 2020. "Endogenous Production Networks." Econometrica
    88:33­82.
Acemoglu, Daron, Camilo García-Jimeno, and James A. Robinson. 2015. "State Capacity
    and Economic Development: A Network Approach." American Economic Review 105:2364­2409.
Adão, Rodrigo, Costas Arkolakis, and Federico Esposito. 2020. "General Equilibrium Indirect
    Effects in Space: Theory and Measurement." Working Paper.
Adão, Rodrigo, Michal Kolesár, and Eduardo Morales. 2019. "Shift-Share Designs: Theory
    and Inference." Quarterly Journal of Economics 134:1949­2010.
Ahlfeldt, Gabriel M., and Arne Feddersen. 2018. "From periphery to core: Measuring agglom-
    eration effects using high-speed rail." Journal of Economic Geography 18:355­390.
Allen, Treb, Caue Dobbin, and Melanie Morten. 2019. "Border Walls." Working Paper.
Angrist, Joshua D. 2014. "The perils of peer effects." Labour Economics 30:98­108.
Angrist, Joshua D., and JS Pischke. 2008. Mostly harmless econometrics: An empiricist's com-
    panion. Princeton University Press.
Arkhangelsky, Dmitry, and Guido W. Imbens. 2019. "Double-Robust Identification for Causal
    Panel Data Models."
Aronow, Peter M, Dean Eckles, Cyrus Samii, and Stephanie Zonszein. 2020. "Spillover
    Effects in Experimental Data." arXiv preprint.
Aronow, Peter M. 2012. "A General Method for Detecting Interference Between Units in Random-
    ized Experiments." Sociological Methods and Research 40:3­16.
Aronow, Peter M., and Cyrus Samii. 2017. "Estimating average causal effects under general in-
    terference, with application to a social network experiment." Annals of Applied Statistics 11:1912­
    1947.


                                                  50
Athey, Susan, Mohsen Bayati, Nikolay Doudchenko, Guido W. Imbens, and Khashayar
    Khosravi. 2018a. "Matrix Completion Methods for Causal Panel Data Models." NBER Working
    Paper 25132.
Athey, Susan, Dean Eckles, and Guido W. Imbens. 2018b. "Exact p-Values for Network Inter-
    ference." Journal of the American Statistical Association 113:230­240.
Athey, Susan, and Guido W. Imbens. 2018. "Design-based Analysis in Difference-In-Differences
    Settings with Staggered Adoption." Working Paper.
Autor, David H., David Dorn, and Gordon H. Hanson. 2013. "The China Syndrome: Local
    Labor Market Impacts of Import Competition in the United States." American Economic Review
    103:2121­2168.
Averett, Susan L, Julie K Smith, and Yang Wang. 2019. "Medicaid expansion and opioid
    deaths." Health Economics 28:1491­1496.
Bartelme, Dominick. 2018. "Trade Costs and Economic Geography: Evidence from the U.S."
Bartik, Timothy J. 1991. Who Benefits from State and Local Economic Development Policies? W.
    E. Upjohn Institute for Employment Research.
Basso, Gaetano, and Giovanni Peri. 2015. "The Association between Immigration and Labor
    Market Outcomes in the United States." Working Paper.
Baum-Snow, Nathaniel. 2007. "Did highways cause suburbanization?" Quarterly Journal of Eco-
    nomics 122:775­805.
Bekker, Paul A. 1994. "Alternative Approximations to the Distributions of Instrumental Variable
    Estimators." Econometrica 62:657.
Berger, Roger L., and Dennis D. Boos. 1994. "P values maximized over a confidence set for the
    nuisance parameter." Journal of the American Statistical Association 89:1012­1016.
Berger, Thor, and Kerstin Enflo. 2017. "Locomotives of local growth: The short- and long-term
    impact of railroads in Sweden." Journal of Urban Economics 98:124­138.
Berman, Nicolas, Antoine Berthou, and Jérôme Héricourt. 2015. "Export Dynamics and Sales
    at Home." Journal of International Economics 96:298­310.
Berry, Steven, James Levinsohn, and Ariel Pakes. 1999. "Voluntary Export Restraints on
    Automobiles : Evaluating a Trade Policy." American Economic Review 89:400­430.
Berthou, Antoine, John Jong-hyun Chung, Kalina Manova, and Charlotte Sandoz Dit
    Bragard. 2019. "Productivity, (Mis)allocation and Trade." Working Paper.
Bertrand, Marianne, Esther Duflo, and Sendhil Mullainathan. 2004. "How Much Should We
    Trust Differences-in-Differences Estimates?" The Quarterly Journal of Economics 119:249­275.
Black, Bernard, Alex Hollingworth, Leticia Nunes, and Kosali Simon. 2019. "The Effect of
    Health Insurance on Mortality: Power Analysis and What We Can Learn from the Affordable
    Care Act Coverage Expansions." NBER Working Paper 25568.
Blanchard, Olivier Jean, and Lawrence F. Katz. 1992. "Regional Evolutions." Brookings Papers
    on Economic Activity, 1­75.
Borusyak, Kirill, Peter Hull, and Xavier Jaravel. 2019. "Quasi-Experimental Shift-Share Re-
    search Designs." NBER Working Paper 24997.
Boustan, Leah, Fernando Ferreira, Hernan Winkler, and Eric M. Zolt. 2013. "The effect of
    rising income inequality on taxation and public expenditures: Evidence from U.S. Municipalities
    and school districts, 1970-2000." Review of Economics and Statistics 95:1291­1302.
Campante, Filipe, and David Yanagizawa-Drott. 2018. "Long-Range Growth: Economic Devel-
    opment in the Global Network of Air Links." Quarterly Journal of Economics 133:1395­1458.
Canay, Ivan A., and Vishal Kamat. 2018. "Approximate permutation tests and induced order
    statistics in the regression discontinuity design." Review of Economic Studies 85:1577­1608.
Card, David. 2001. "Immigrant Inflows, Native Outflows, and the Local Labor Market Impacts of
    Higher Immigration." Journal of Labor Economics 19:22­64.


                                                51
Carvalho, Vasco M., Makoto Nirei, Yukiko U. Saito, and Alireza Tahbaz-Salehi. 2020.
    "Supply Chain Disruptions: Evidence from the Great East Japan Earthquake." Working paper.
Cattaneo, Matias D., Brigham R. Frandsen, and Rocío Titiunik. 2015. "Randomization In-
    ference in the Regression Discontinuity Design: An Application to Party Advantages in the U.S.
    Senate." Journal of Causal Inference 3:1­24.
Chamberlain, Gary. 1987. "Asymptotic efficiency in estimation with conditional moment restric-
    tions." Journal of Econometrics 34:305­334.
Chandra, Amitabh, and Eric Thompson. 2000. "Does public infrastructure affect economic activ-
    ity? Evidence from the rural interstate highway system." Regional Science and Urban Economics
    30:457­490.
Chandrasekhar, Arun G, and Matthew O Jackson. 2014. "Tractable and Consistent Random
    Graph Models." NBER Working Paper 20276.
Chodorow-Reich, Gabriel, and Johannes Wieland. 2020. "Secular Labor Reallocation and Busi-
    ness Cycles." Journal of Political Economy.
Cohodes, Sarah R., Daniel S. Grossman, Samuel A. Kleiner, and Michael F. Lovenheim.
    2016. "The Effect of Child Health Insurance Access on Schooling: Evidence from Public Insurance
    Expansions." Journal of Human Resources 51:727­759.
Conley, T. G. 1999. "GMM estimation with cross sectional dependence." Journal of Econometrics
    92:1­45.
Costa, Rui, Swati Dhingra, and Stephen Machin. 2019. "Trade and Worker Deskilling." Working
    Paper.
Cullen, Julie Berry, and Jonathan Gruber. 2000. "Does Unemployment Insurance Crowd out
    Spousal Labor Supply?" Journal of Labor Economics 18:546­572.
Currie, Janet, and Jonathan Gruber. 1996a. "Health Insurance Eligibility, Utilization of Medical
    Care, and Child Health." The Quarterly Journal of Economics 111:431­466.
       . 1996b. "Saving Babies: The Efficacy and Cost of Recent Changes in the Medicaid Eligibility
    of Pregnant Women." Journal of Political Economy 104:1263­1296.
Cutler, David M., and Jonathan Gruber. 1996. "Does Public Insurance Crowd out Private
    Insurance?" The Quarterly Journal of Economics 111:391­430.
De Chaisemartin, Clement, and Luc Behaghel. 2018. "Estimating the Effect of Treatments
    Allocated by Randomized Waiting Lists." Working Paper.
De Chaisemartin, Clement, and Xavier D'haultfoeuille. 2020. "Two-way fixed effects estimators
    with heterogeneous treatment effects." American Economic Review 110:2964­2996.
Dell, Melissa, and Benjamin Olken. 2018. "The Development Effects of the Extractive Colonial
    Economy: The Dutch Cultivation System in Java." Working Paper.
Derenoncourt, Ellora. 2019. "Can you move to opportunity ? Evidence from the Great Migration."
    Working Paper.
DiNardo, John. 2008. "Natural Experiments and Quasi-Natural Experiments." In The New Palgrave
    Dictionary of Economics, 2nd editio, edited by Palgrave Macmillan. London: Palgrave Macmillan.
Ding, Peng, Avi Feller, and Luke Miratrix. 2016. "Randomization inference for treatment effect
    variation." Journal of the Royal Statistical Society. Series B: Statistical Methodology 78:655­671.
Donaldson, Dave. 2018. "Railroads of the Raj: Estimating the Impact of Transportation Infrastruc-
    ture." American Economic Review 108:899­934.
Donaldson, Dave, and Richard Hornbeck. 2016. "Railroads and American Economic Growth: A
    "Market Access" Approach." The Quarterly Journal of Economics 131:799­858.
Duranton, Gilles, Peter M. Morrow, and Matthew A. Turner. 2013. "Roads and trade: Evi-
    dence from the US." Review of Economic Studies 81:681­724.
Duranton, Gilles, and Matthew A Turner. 2012. "Urban Growth and Transportation." Review
    of Economic Studies 79:1407­1440.


                                                  52
East, Chloe N., and Elira Kuka. 2015. "Reexamining the consumption smoothing benefits of
     Unemployment Insurance." Journal of Public Economics 132:32­50.
Ellison, Glenn, and EL Glaeser. 1997. "Geographic concentration in US manufacturing industries:
     a dartboard approach." Journal of Political Economy 105:889­927.
Fisher, Ronald Aylmer. 1935. "The design of experiments."
Frean, Molly, Jonathan Gruber, and Benjamin D. Sommers. 2017. "Premium subsidies, the
     mandate, and Medicaid expansion: Coverage effects of the Affordable Care Act." Journal of Health
     Economics 53:72­86.
Ganong, Peter, and Simon Jäger. 2018. "A Permutation Test for the Regression Kink Design."
     Journal of the American Statistical Association 113:494­504.
Gerber, Alan S, and Donald P Green. 2012. Field experiments: Design, analysis, and interpre-
     tation. W. W. Norton & Company.
Ghosh, Ausmita, Kosali Simon, and Benjamin D Sommers. 2019. "The Effect of Health In-
     surance on Prescription Drug Use Among Low-Income Adults : Evidence from Recent Medicaid
     Expansions." Journal of Health Economics 63:64­80.
Goldsmith-Pinkham, Paul, Isaac Sorkin, and Henry Swift. 2020. "Bartik Instruments : What,
     When, Why, and How." American Economic Review 110:2586­2624.
Gomez, Brad T., Thomas G. Hansford, and George A. Krause. 2007. "The Republicans
     should pray for rain: Weather, turnout, and voting in U.S. presidential elections." Journal of
     Politics 69:649­663.
Gonzalez-Navarro, Marco, and Climent Quintana-Domeque. 2016. "Paving Streets for the
     Poor: Experimental Analysis of Infrastructure Effects." Review of Economics and Statistics 98:254­
     267.
Greenstone, Michael, Richard Hornbeck, and Enrico Moretti. 2010. "Identifying Agglomera-
     tion Spillovers: Evidence from Winners and Losers of Large Plant Openings." Journal of Political
     Economy 118:536­598.
Greenstone, Michael, Alexandre Mas, and Hoai-Luu Nguyen. 2020. "Do Credit Market Shocks
     Affect the Real Economy? Quasi-Experimental Evidence from the Great Recession and "Normal"
     Economic Times." American Economic Journal: Economic Policy 12:200­225.
Gruber, Jon, and Emmanuel Saez. 2002. "The elasticity of taxable income: Evidence and impli-
     cations." Journal of Public Economics 84:1­32.
Guth, Madeline, Rachel Garfield, and Robin Rudowitz. 2020. "The effects of medicaid expan-
     sion under the ACA: Updated Findings from a Literature Review." Kaiser Family Foundation
     37:944­950.
Heckman, James J., and Richard Robb. 1985. "Alternative methods for evaluating the impact
     of interventions. An overview." Journal of Econometrics 30:239­267.
Hirano, Keisuke, and Guido W. Imbens. 2004. "The Propensity Score with Continuous Treat-
     ments." Chap. Chapter 7 in Applied Bayesian Modeling and Causal Inference from Incomplete-
     Data Perspectives: An Essential Journey with Donald Rubin's Statistical Family, 73­84.
Ho, Daniel E., and Kosuke Imai. 2006. "Randomization inference with natural experiments: An
     analysis of ballot effects in the 2003 California recall election." Journal of the American Statistical
     Association 101:888­900.
Hodges, J.L. Jr., and Erich L Lehmann. 1963. "Estimates of Location Based on Rank Tests."
     The Annals of Mathematical Statistics 34:598­611.
Hu, Luojia, Robert Kaestner, Bhashkar Mazumder, Sarah Miller, and Ashley Wong. 2018.
     "The effect of the affordable care act Medicaid expansions on fi nancial wellbeing." Journal of
     Public Economics 163:99­112.
Hudgens, Michael G., and M. Elizabeth Halloran. 2008. "Toward causal inference with inter-
     ference." Journal of the American Statistical Association 103:832­842.


                                                    53
Imbens, Guido W., and Joshua D. Angrist. 1994. "Identification and Estimation of Local Average
    Treatment Effects." Econometrica 62:467.
Imbens, Guido W., and Paul R. Rosenbaum. 2005. "Robust, accurate confidence intervals with
    a weak instrument: quarter of birth and education." Journal of the Royal Statistical Society: Series
    A (Statistics in Society) 168 (January): 109­126.
Jaravel, Xavier, Neviana Petkova, and Alex Bell. 2018. "Team-Specific Capital and Innovation."
    American Economic Review 108:1034­1073.
Kaestner, Robert, Bowen Garrett, Jiajia Chen, Anuj Gangopadhyaya, and Caitlyn Flem-
    ing. 2017. "Effects of ACA Medicaid Expansions on Health Insurance Coverage and Labor Sup-
    ply." Journal of Policy Analysis and Management 36:608­642.
Kline, Patrick, and Andres Santos. 2012. "A Score Based Approach to Wild Bootstrap Inference."
    Journal of Econometric Methods 1:23­41.
Kovak, Brian K. 2013. "Regional effects of trade reform: What is the correct measure of liberaliza-
    tion?" American Economic Review 103:1960­1976.
Lawrence, Martha, Richard Bullock, and Ziming Liu. 2019. China's High-Speed Rail Develop-
    ment. Washington, D.C.: World Bank.
Lee, David S. 2008. "Randomized experiments from non-random selection in U.S. House elections."
    Journal of Econometrics 142:675­697.
Lehmann, Erich L, and Joseph P Romano. 2006. Testing statistical hypotheses. Springer Science
    & Business Media.
Leung, Pauline, and Alexandre Mas. 2018. "Employment Effects of the ACA Medicaid Expan-
    sions." Industrial Relations 57:206­234.
Lin, Yatang. 2017. "Travel costs and urban specialization patterns: Evidence from China's high
    speed railway system." Journal of Urban Economics 98:98­123.
Lind, Jo Thori. 2019. "Spurious weather effects." Journal of Regional Science 59:322­354.
Ma, Damien. 2011. "China's Long, Bumpy Road to High-Speed Rail." The Altantic.
Mackinnon, James G., and Matthew D. Webb. 2020. "Randomization Inference for Difference-
    in-Differences with Few Treated Clusters." Journal of Econometrics.
Maclean, Johanna Catherine, and Brendan Saloner. 2019. "The Effect of Public Insurance
    Expansions on Substance Use Disorder Treatment: Evidence from the Affordable Care Act."
    Journal of Policy Analysis and Management 38:366­393.
Madestam, Andreas, Daniel Shoag, Stan Veuger, and David Yanagizawa-Drott. 2013. "Do
    Political Protests Matter? Evidence from the Tea Party Movement." Quarterly Journal of Eco-
    nomics 128:1633­1685.
Manski, Charles F. 1993. "Identification of Endogenous Social Effects: The Reflection Problem."
    Review of Economic Studies 60:531­542.
       . 2013. "Identification of treatment response with social interactions." Econometrics Journal
    16:1­23.
Michaels, Guy. 2008. "The Effect of Trade on the Demand for Skill: Evidence from the Interstate
    Highway System." Review of Economics and Statistics 90:683­701.
Miguel, Edward, and Michael Kremer. 2004. "Worms: Identifying impacts on education and
    health in the presence of treatment externalities." Econometrica 72:159­217.
Newey, Whitney K. 1990. "Efficient Instrumental Variables Estimation of Nonlinear Models."
    Econometrica 58:809­837.
Ogburn, Elizabeth L., Oleg Sofrygin, Ivan Diaz, and Mark J. van der Laan. 2020. "Causal
    inference for social network data." arXiv preprint, 1­43.
Ollivier, Gerald, Richard Bullock, Ying Jin, and Nanyan Zhou. 2014. "High-Speed Railways
    in China: A Look at Traffic." China Transport Topics, 1­12.




                                                  54
Potlogea, Andrei, and Wenya Cheng. 2017. "Trade Liberalization and Economic Development:
    Evidence from China's WTO Accession." 2017 Meeting Papers.
Puelz, David, Guillaume Basse, Avi Feller, and Panos Toulis. 2019. "A Graph-Theoretic
    Approach to Randomization Tests of Causal Effects Under General Interference." arXiv preprint.
Redding, Stephen J., and Daniel M. Sturm. 2008. "The Costs of Remoteness : Evidence from
    German Division and Reunification." American Economic Review 98:1766­1797.
Redding, Stephen J., and Matthew A. Turner. 2015. "Transportation Costs and the Spatial
    Organization of Economic Activity." In Handbook of regional and urban economics, 1339­1398.
    Elsevier.
Redding, Stephen J., and Anthony J. Venables. 2004. "Economic geography and international
    inequality." Journal of International Economics 62:53­82.
Rosenbaum, Paul R, and Donald B Rubin. 1983. "The Central Role of the Propensity Score in
    Observational Studies for Causal Effects Paul R. Rosenbaum, Donald B. Rubin." 70:41­55.
Rosenbaum, Paul R. 1984. "Conditional permutation tests and the propensity score in observational
    studies." Journal of the American Statistical Association 79:565­574.
       . 2002. "Covariance adjustment in randomized experiments and observational studies." Statis-
    tical Science 17:286­327.
Shaikh, Azeem, and Panagiotis Toulis. 2019. "Randomization Tests in Observational Studies
    with Staggered Adoption of Treatment." Working Paper.
Titiunik, Rocío. 2020. "Natural Experiments." arXiv preprint.
Tsivanidis, Nick. 2019. "The Aggregate and Distributional Effects of Urban Transit Infrastructure:
    Evidence from Bogotá's TransMilenio." Working Paper.
Volpe Martincus, Christian, and Juan Blyde. 2013. "Shaky roads and trembling exports: As-
    sessing the trade effects of domestic infrastructure using a natural experiment." Journal of Inter-
    national Economics 90:148­161.
Wooldridge, Jeffrey M. 2002. "Econometric analysis of cross section and panel data MIT press."
    Cambridge, MA 108.
Zheng, Siqi, and Matthew E. Kahn. 2013. "China's bullet trains facilitate market integration and
    mitigate the cost of megacity growth." Proceedings of the National Academy of Sciences of the
    United States of America 110:1248­1253.




                                                  55
              Appendix to "Non-Random Exposure to
            Exogenous Shocks: Theory and Applications"
                                     Kirill Borusyak, UCL
                               Peter Hull, University of Chicago
Contents
A Theoretical Appendix                                                                                  57
  A.1 Randomization Inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .     57
  A.2 Consistency of Recentered IVs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .     58
  A.3 Asymptotic Efficiency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .     61
  A.4 Potential Outcomes and Heterogeneous Treatment Effects . . . . . . . . . . . . . . . .            62
  A.5 Assignment Processes with Unknown Parameters . . . . . . . . . . . . . . . . . . . . .            65
  A.6 Efficiency Controls . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   68
  A.7 Multiple Treatments and Instruments . . . . . . . . . . . . . . . . . . . . . . . . . . .         68
  A.8 Nonlinear Outcome Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .        71
  A.9 Identification with Exogenous Exposure . . . . . . . . . . . . . . . . . . . . . . . . . .        72
  A.10 Recentering in General Simulated Instrument Settings . . . . . . . . . . . . . . . . . .         74
  A.11 Recentering Helps with Consistency: An Example . . . . . . . . . . . . . . . . . . . .           75

B Empirical Appendix                                                                                    76
  B.1 Data for Section 4.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .    76
  B.2 Data for Section 4.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .    78
  B.3 Robustness Checks for Section 4.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . .       79
  B.4 Data for Section 4.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .    83

C Proofs of Propositions                                                                                84
  C.1 Proof of Proposition 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .    84
  C.2 Proof of Proposition 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .    85
  C.3 Proof of Proposition A4 and Lemma 3 . . . . . . . . . . . . . . . . . . . . . . . . . . .         86
  C.4 Proof of Proposition A1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .     88
  C.5 Proof of Proposition A2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .     88
  C.6 Proof of Proposition A3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .     91
  C.7 Proof of Proposition A5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .     93
  C.8 Proof of Propositions A6 and A7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .       94
  C.9 Proof of Proposition A8 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .     96
  C.10 Proof of Proposition A9 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .    96
  C.11 Proofs of Lemmas A2 and A3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .       97

Appendix Figures and Tables                                                                             98

                                                   56
