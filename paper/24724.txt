                             NBER WORKING PAPER SERIES




          PUBLIC CONTRACTING FOR PRIVATE INNOVATION:
 GOVERNMENT EXPERTISE, DECISION RIGHTS, AND PERFORMANCE OUTCOMES

                                       Joshua R. Bruce
                                    John M. de Figueiredo
                                      Brian S. Silverman

                                     Working Paper 24724
                             http://www.nber.org/papers/w24724


                    NATIONAL BUREAU OF ECONOMIC RESEARCH
                             1050 Massachusetts Avenue
                               Cambridge, MA 02138
                                    June 2018




We are grateful to Jean-Etienne de Bettignies, Robert Gibbons, Ricard Gil, Mitch Hoffman, Chris
McKenna, Arti Rai, Pablo Spiller, Jesper Sørensen, Giorgio Zanarone; seminar participants at
CUNEF, George Mason University, Queens University, Stanford University, and the University
of California, Berkeley; and attendees at the Society for Institutional and Organizational
Economics and Mack Institute/Wharton Technology & Innovation Conference, for comments on
previous drafts of this paper. This study is based upon work supported by the National Science
Foundation under Grants Numbers 1061600 and 1443014. The views expressed herein are those
of the authors and do not necessarily reflect the views of the National Bureau of Economic
Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2018 by Joshua R. Bruce, John M. de Figueiredo, and Brian S. Silverman. All rights reserved.
Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including © notice, is given to the source.
Public Contracting for Private Innovation: ¸˛Government Expertise, Decision Rights, and
Performance Outcomes
Joshua R. Bruce, John M. de Figueiredo, and Brian S. Silverman
NBER Working Paper No. 24724
June 2018
JEL No. H11,H57,L14,L24,L33,O32

                                         ABSTRACT

We examine how the U.S. Federal Government governs R&D contracts with private-sector firms.
The government chooses between two contractual forms: grants and cooperative agreements. The
latter provides the government substantially greater discretion over, and monitoring of, project
progress. Using novel data on R&D contracts and on the geo-location and technical expertise of
each government scientist over a 12-year period, we test implications from the organizational
economics and contracting literatures. We find that cooperative agreements are more likely to be
used for early-stage projects and those for which local government scientific personnel have
relevant technical expertise; in turn, cooperative agreements yield greater innovative output as
measured by patents, controlling for endogeneity of contract form. The results are consistent with
multi-task agency and transaction-cost approaches that emphasize decision rights and monitoring.


Joshua R. Bruce                                 Brian S. Silverman
Duke University                                 Rotman School of Management
Department of Sociology                         University of Toronto
417 Chapel Drive                                105 St. George Street
Box 90088                                       Toronto, Ontario M5S 3E6
Durham, NC 27708-0088                           CANADA
joshua.bruce@duke.edu                           silverman@rotman.utoronto.ca

John M. de Figueiredo
The Law School and Fuqua School
Duke University
210 Science Drive, Box 90360
Durham, NC 27708
and NBER
jdefig@duke.edu
INTRODUCTION

There is a vast literature documenting the solutions to contractual opportunism in agreements

between private firms. In principle, public-private contracting should be amenable to many of the

same solutions. However, in practice, contracting that involves the public sector is characterized

by strong rigidity (Moszoro, Spiller, and Stolorz, 2016), due both to political pressure from third

parties (Spiller and Moszoro, 2014) and more general bureaucratic structures (Moe, 1990).

Consequently, although many aspects of contract theory can inform public-private contracting,

the distinct characteristics of the public sector – which often preclude the use of several creative

contracting mechanisms implicated in such theories – suggest a more directed theoretical and

empirical approach is warranted to address the peculiarities of contracting in the governmental

setting.

           This paper examines public-private contracting in the specific setting of public

contracting for private innovation. Government entities frequently encourage the development of

specific types of innovations that are deemed necessary to achieve public aims. For example, in

2016 the U.S. federal government funded $148 billion in R&D (Hourihan and Parkes, 2015), at

least $30 billion of which was devoted to contracts for private innovation regarding specific

goals such as preclinical trials for new pharmaceutical drugs, studies of chemical toxicity in

water, and the development of systems on the Mars rover missions.1

           Contracting for innovation faces a central problem: when a client organization pays a

research firm to pursue a specific project, there is a risk that the research firm will divert the

payment to pursue its own interests. If the research project fails, it is difficult for the client

organization to distinguish between research-firm malfeasance and bad luck. This problem is


1
  Similarly, in 2012 the United Kingdom allocated £1.6B (18%) of its £8.7B government R&D budget to private
firms (National Audit Office, 2013).


                                                      2
exacerbated as the uncertainty surrounding the project increases. Organizational economists offer

several prescriptions to overcome this problem. However, virtually all of the proposed solutions

depend on substantial flexibility in contract design: judicious allocation of property rights

(Aghion and Tirole, 1994), menus of fixed fees and royalty payments (Hegde, 2014), appropriate

investments in equity (Oxley, 1997), or sophisticated contractual provisions to deal with a range

of contingencies that might arise (Reuer and Ariño, 2007). These solutions, however, are often

precluded by the rigidities of public-sector contracting, such as the need for standardized

contracts, the desire to prevent officeholders from self-dealing, the requirement for procedural

adherence and transparency by agencies and civil servants, the presence of public sector unions,

and the attempt to insulate the bureaucracy from the political pressures of third parties (Moszoro

et al., 2016). Given these constraints, how can public-private contracts for innovation overcome

contractual hazards in order to create value?

       We invoke and extend a solution that stems from recent analyses of privatization:

government retention of specific decision rights even while the private actor retains residual

control rights. Specifically, Hart et al.’s (1997) influential model of privatization predicts that

privatized services, for which the private provider owns residual control rights including decision

rights, will have lower costs but also lower quality than publicly-provided services. Yet

Williamson (1999) proposes that overlapping decision-making authority between the private

entity and public bureau may ameliorate quality degradation. Empirically, Cabral et al. (2010,

2013) find that privatized prisons in Brazil exhibit quality equivalent to that of publicly run

counterparts, attributing this to the presence at each private prison of a government supervisor, or

‘warden,’ whose job is to review and occasionally overrule decisions about those aspects of

operations that could adversely affect quality. This preserves quality as long as the government




                                                  3
warden is motivated to make good decisions.

       We extend this logic to make three predictions about public contracting for private

innovation. As contracting hazards increase due to project uncertainty, the government agency is

more likely to include an information exchange and decision-rights mechanism in the contract.

However, this mechanism will only be implemented if the government agency has employees

with the requisite subject-matter expertise to make effective and appropriate project decisions.

Finally, conditional on project uncertainty and government expertise, cooperative agreements

will be more successful at generating patented innovations (which are the explicit goal of such

projects) because of more effective monitoring of private-sector R&D efforts by the government.

       We test these predictions using a sample of more than 4,000 R&D contracts between U.S.

federal agencies and private firms. Similar to many countries, U.S. law generally restricts these

contracts to take one of two forms: a ‘grant,’ which affords the government no in-process

decision rights, and a ‘cooperative agreement,’ in which government employees have substantial

in-process decision rights. Using novel data on the technical expertise of government agency

personnel located in geographic proximity to the private firm’s R&D site, we find support for our

theoretical predictions. Notably, 1) earlier-stage projects (which are likely to entail greater

uncertainty) are more likely to be governed by cooperative agreements than by grants, 2)

agencies rely on cooperative agreements more readily when they have relevant technical

capabilities near the R&D site, 3) cooperative agreements perform better than grants in terms of

patents generated and the citations to these patents, and 4) although cooperative agreements

perform better than grants overall, those projects that were governed by grants would not have

been as productive as current cooperative agreements had they been organized as cooperative

agreements. We then consider a number of alternative theoretical explanations, econometric




                                                  4
specifications, and data measurements, and find the results are robust to these approaches.

        This study makes three contributions to the theoretical literature. First, whereas most

analyses of privatized services have focused on the in-house vs. privatization decision, we extend

the logic to consider variations in privatized governance based on different characteristics of

projects. Second, whereas recent literature on hybrid governance highlights the condition that the

government monitor must be willing to monitor effectively, we propose that, for projects that

rely on highly idiosyncratic knowledge, the monitor must be both willing and able – i.e., must

have the requisite skills to monitor and make good decisions. Third, this focus on requisite skills

extends the literature on government capabilities: whereas prior research on value creation in

public-private collaboration has tended to emphasize a government entity’s capabilities in

contracting (e.g., Klein et al., 2013), we extend this to consider how a government entity’s

technological capabilities and expertise influence the organization of privatized services.2

Through these contributions, we further flesh out the implications of Moszoro et al.’s (2016)

insights about rigidity in public-private contracting.

        The paper also makes an empirical contribution. We develop measures of government

innovative capabilities, based upon the specific technical expertise of government scientists,

engineers, doctors, and researchers as measured by 9.5 million person-year observations of

government personnel data. We then geo-locate those capabilities throughout the United States,

essentially creating a map of government capabilities along 59 expertise dimensions. To the best

of our knowledge, this is the first time that government capabilities have been measured in such

a microanalytic way.

        The paper proceeds as follows. In section 2, we analyze the public-sector challenge of


2
 Relatedly, Decarolis et al. (2018) examine public-private procurement contracting but focus on the competencies
of private firms rather than the public sector.


                                                        5
contracting effectively for R&D, ultimately generating predictions regarding the use of

government decision rights in contracts for innovation. Section 3 provides institutional detail on

the U.S. empirical setting. Section 4 introduces our data, model, and empirical strategy. Section 5

presents empirical results, and section 6 offers a brief discussion and conclusion.



CONTRACTING FOR RESEARCH – THE PRIVATE-PRIVATE VS. PUBLIC-

PRIVATE CONTEXT

The private-private context

The market for technology suffers from several well-documented defects (Arora and

Gambardella, 2010). The R&D process is commonly characterized by several features that create

contractual hazards, including uncertainty, noncontractible effort, tacit knowledge, and

appropriability concerns. Organizational economics theories generally agree that contracting

difficulties rise monotonically with these characteristics. Given such difficulties, scholars have

devoted substantial attention to explicating contractual mechanisms that private entities can use

to efficiently govern R&D transactions.

       Consider an example in which a pharmaceutical firm seeks to contract with a

biotechnology firm for R&D into a new drug. The client firm pays the research firm to conduct a

set of specified research tasks. But it is nearly impossible for the client firm to observe the effort

that the research firm’s employees actually devote to the tasks. R&D is an uncertain endeavor, so

if the research firm does not generate the desired innovation, it is difficult to tell whether this was

the result of insufficient effort or bad luck. Even when the innovation is developed, if transfer to

the client firm requires the provision of attendant tacit knowledge, then it is difficult to monitor

whether the researchers are making a good-faith effort to provide this knowledge (Hegde, 2014),




                                                  6
especially if either firm has latent concerns that proprietary knowledge outside the scope of the

contract will ‘leak’ to the other party during the course of the endeavor (Oxley and Wada, 2009).

         Given these challenges, how might the firms successfully govern their exchange? One

prescription is to judiciously assign property rights so as to elicit noncontractible effort as

effectively as is feasible (Aghion and Tirole, 1994; Grossman and Hart, 1986). Lerner and

Merges (1998) test this empirically by exploring the pattern of property-rights assignment in

R&D contracts between pharmaceutical companies and biotechnology firms. They find modest

evidence that these contracts do indeed assign more property rights to the biotech firm when

projects are earlier-stage (and hence are more uncertain and require more non-contractible effort

from the biotech firm). Lerner and Malmendier (2010) consider termination options that

distribute rights to R&D results when projects characterized by unobservable effort also generate

observable milestones, finding that such termination options also appear more frequently in

contracts for earlier-stage projects than in contracts for later-stage projects.3

         An alternative prescription is to implement a combination of fixed fees and royalty

payments to align the firms’ incentives. Since royalties depend on successful commercialization

of an innovation, they can provide a strong incentive to the research firm to both conduct the

requisite R&D and devote effort to transferring the results to the client firm (Xiao and Xu, 2012).

Although reliance on royalties shifts risk to the research firm, which in many models is more

risk-averse than the client firm, the benefits of incentive alignment outweigh the attendant costs

for sufficiently high levels of uncertainty and noncontractible effort. In a study of biomedical

invention, Hegde (2014) finds systematic patterns of complex royalty payments between



3
  A unilateral termination option for the client firm encourages the research firm to devote appropriate effort to the
project, while a termination fee set at an appropriate level discourages the client firm from strategically terminating
the project. This option can align incentives between client firm and research firm.


                                                           7
commercializing firms and inventors that are consistent with theoretical predictions.

       A third prescription is to judiciously use equity investments to align incentives, direct

effort, and protect knowledge (Pisano, 1990; Teece, 1986). While non-equity arrangements such

as licensing contracts will suffice for high-appropriability or low-tacit-knowledge research in the

presence of low uncertainty, equity joint ventures will be used to govern research agreements

with higher levels of contractual hazards (Oxley and Wada, 2009). Shared ownership of the

collaborative venture implies shared ownership of the attendant profits, thus aligning the firms’

incentives regarding success of the venture. Equity arrangements also provide formal monitoring

and, in particular, decision-making authority over the research effort (Reuer, Ariño, and

Mellewigt, 2006). These predictions have been borne out in specific industry settings (Sampson,

2004a) and multi-industry studies (Oxley, 1997). Going beyond the governance-choice decision,

Sampson (2004b) also finds that R&D alliances that are organized according to transaction-cost

precepts generate more patented innovations than those that are organized inappropriately.

       Finally, complex contractual provisions may be employed to coordinate and control effort

in the face of uncertainty. Contractual features such as contingency payments can elicit effort

and align incentives in contractual relationships, while provisions that specify responses to

potential contingencies can restrict opportunistic behavior (Argyres, Bercovitz, and Mayer, 2007;

Reuer and Ariño, 2007). Contractual clauses that thus effectively address hazards can

dramatically increase contractual effectiveness (Anderson and Dekker, 2005) and facilitate

resolution of disagreements (Lumineau and Malhotra, 2011). Alternatively, judicious assignment

of decision rights and monitoring provisions can dramatically influence the effectiveness of

incentives and the performance of the project (Arruñada, Garicano, and Vázquez, 2001; Athey

and Roberts, 2001; Reuer and Devarakonda, 2016).




                                                 8
         In general, then, contracting between private firms is frequently facilitated by a range of

governance mechanisms including judicious allocation of property rights, complex royalty

schemes, equity holdings, and/or sophisticated contingent contracts with attendant decision

rights. These mechanisms support a substantial market for technology both within and across

nations (Arora and Gambardella, 2010).



The public-private context

At first glance, one might expect that the above prescriptions are straightforwardly applicable to

public-private contracting. However, in many countries, strict rules and processes constrain the

form of public contracts for innovation. In the U.S., as in several other OECD countries,

government entities are prohibited from owning property rights in the resulting innovations,

paying royalties to the contracted firms, or taking equity in these firms. Strict contracting policies

also hinder attempts to craft project-specific contractual provisions.4 Thus, the most common

levers available to private-private contracts for research are unavailable in public-private

research contracts. These constraints reflect the stylized fact that public-sector contracts tend to

be far more rigid than their private-sector counterparts (Moszoro et al., 2016). This enduring

feature of public bureaucracy (Boyne, 2002) is often attributed to a desire to restrict public

agents’ ability to engage in self-dealing (Lan and Rainey, 1992); or, alternatively, to concerns

about political pressure from third parties (Spiller and Moszoro, 2014). This then leads to

processes in government which are procedurally onerous and substantively transparent, often

leading to inefficiency in the government by design (Moe, 1989). Because of these substantial

procedural requirements and limited resources for government contracting, the government tends


4
  For example, similar to the U.S., Canada’s federal contracts for R&D take the form of either grants or
‘contributions,’ which are largely analogous to U.S. cooperative agreements.


                                                          9
to favor standardized, rather than customized, contracts for many purposes, limiting the ability of

the government to employ specialized terms (Miller, 1955).

         This rigidity is manifest in Hart et al.’s (1997) incomplete-contract model of

privatization. In this model, a government actor chooses between delivering a service through in-

house provision or through a contract with a private provider. The service requires investment in

an asset and then operation using that asset. Of particular relevance, property rights over the

asset cannot be divided, but rest entirely with either the government or the firm, and payment to

the firm is limited to a fixed fee that can be renegotiated upward if the quality of the service is

increased. Given these blunt levers, the private firm has a strong incentive to lower the cost of

provision, even at the expense of quality, while an in-house provider has little incentive to

improve either cost or quality.5 Consequently, the authors predict that privatized services will

have lower costs but also lower quality than their publicly-provided counterparts. Levin and

Tadelis (2010) find that municipalities are less likely to outsource services for which quality is

important yet noncontractible, concluding that this is consistent with the Hart et al. (1997)

model. This provides a pessimistic assessment of the feasibility of public-private contracting for

innovation, given its reliance on noncontractible effort.

         Yet Cabral et al. (2010, 2013) find that privatized prisons in two Brazilian states exhibit

quality that is equal to or better than that of their publicly run counterparts, even while enjoying

lower costs. They propose that the key quality-protection mechanism is the appointment to each

private prison of a government ‘warden’ whose job is to monitor prison operation and ensure that

it adheres to specified minimum quality standards. As long as the warden remains committed to



5
 The private firm reaps the entire benefit from cost reduction, but only incurs a fraction of the benefit to quality
improvement because it must bargain with the government ex post for fee increases associated with improved
quality. The private firm thus ‘overinvests’ in cost reduction, yielding a socially suboptimal level of quality.


                                                           10
her task – i.e., she is not bribed by the private firm – then this ‘hybrid’ form of private operation

and public supervision appears to solve the problem of quality deterioration.6

        To the extent that public contracting for innovation is characterized by the constraints

embodied in the Hart et al. (1997) model, perhaps the sole available lever is the prospect of

government supervision of the research project, analogous to the government prison warden. Yet

one difference stands out in the innovation setting. Cabral et al. (2010, 2013) implicitly assume

that the government warden understands the causal mechanisms linking cost-reduction and

quality shading – in essence, she knows which actions by the private agent are good and which

are bad. However, evidence indicates that an organization’s possession of relevant technological

capability helps it appraise the value of external research (Cassiman and Veugelers, 2006): ‘[t]he

ability to evaluate…outside knowledge is largely a function of the level of prior related

knowledge’ (Cohen and Levinthal, 1990: 128).

        Indeed, precisely for this reason, an organization’s technological capability in a particular

sphere can influence its competence at contracting in that sphere. Mayer and Salomon (2006)

study an IT firm’s decisions to complete client projects with in-house or outsourced teams,

finding evidence that strong technological capability in, for example, mainframe technology

allows the firm to outsource on mainframe-related projects in the face of contractual hazards.

They conclude that the firm is better able to manage an external contract when it has

technological capabilities that enable it to anticipate problems and monitor outcomes. Building

on this idea, Argyres and Mayer (2007) propose that the technological (i.e., engineering)




6
  Although the Brazilian prison setting only allows comparison of public to private-hybrid prisons, it should be the
case that a purely private prison would have lower costs than the private-hybrid prison. Some of this would be due to
quality-shading efforts that are socially destructive. But some should be due to lower effort to invest in cost-
reduction by the private-hybrid, given that the warden may sometimes erroneously negate a valid cost-reduction
scheme.


                                                        11
expertise of a firm’s employees is particularly relevant to establishing effective interfirm

communication flows in research contracts. Thus, in the context of public contracting for

innovation, the government supervisor must have the requisite technological expertise to know

which actions are good and bad – in other words, if the supervisor is willing but not able to make

good decisions, then public supervision is a hindrance.

        In sum, extending the predictions concerning decision rights and monitoring above, we

expect to find two patterns in contract choice: research projects that are more uncertain in

outcome are more likely to be governed by contracts that afford greater public supervision (i.e.,

cooperative agreements), as are research projects for which the available public personnel have

relevant expertise. We further expect research projects governed according to the above precepts

will outperform those that are not in terms of innovative output.



GOVERNMENT CONTRACTING FOR RESEARCH: INSTITUTIONAL DETAILS

The U.S. federal government is composed of 381 agencies, which in turn are composed of 874

bureaus. Although formally overseen by the Executive Branch of the government, agencies

pursue their own research and development agendas, each determined by a variety of different

considerations. To meet their required objectives, bureaus often determine that specific research

endeavors would require expertise beyond that available within the Federal government.7 In such

cases, the bureau contracts with outside entities for the requisite research effort.

        The process begins when a bureau’s program office issues a call for research proposals,

or CFP (see ‘Appendix A: The Grant-Making Process’ for a detailed description of the CFP

process). The CFP outlines the motivation for the research project, the statutory authority for the


7
 McKenna (2006: 103-105) describes the government’s strategic decision, at the beginning of the U.S. space
program, to rely on external expertise rather than try to employ all necessary experts within NASA.


                                                       12
agency to conduct the research, a list of requirements, milestones, expectations, and objectives of

the project, a list of eligibility requirements for the private contractor, and a description of how

the project will be managed. The CFP may specify that the research will be conducted through a

grant, a cooperative agreement, or either. As Appendix A describes, the CFP process is virtually

identical across the two types of contracts. In both cases, all property rights resulting from the

contracted research are owned by the contracted entity while the U.S. government receives a

royalty-free license. This precludes the judicious allocation of property rights and the use of

royalty schemes to elicit effort.8 However, for the purposes of this study, there are three key

differences between the governance forms.

         The first difference is the degree of cooperative effort between the government agency

and private firm. As stipulated in the Federal Grant and Cooperative Agreement Act of 1977

(FGCAA) and the Code for Federal Regulation (CFR), grants do not provide for ‘substantial

involvement’ between government employees and the firm, whereas cooperative agreements do.9

This is reinforced by each agency’s own guidance documents. For example, Section 3 of the

NASA Grant and Cooperative Agreement Manual (2016: 3) notes that unlike a grant, a coopera-

tive agreement should be used if ‘substantial involvement is expected between the executive

agency and the…other recipient when carrying out the activity contemplated in the agreement.’10

         The second difference relates to the disparate pattern of decision rights assigned to


8
  Some Federal procurement agreements also involve R&D effort by the private vendor. In these agreements, called
‘contracts,’ the Federal government funds the vendor’s R&D as ‘work for hire’ and receives ownership of any
resulting patents. We exclude these from this study for two reasons: they are not designed to support significant
R&D; and their different (although still rigid) allocation of property rights would conflate the incentives affecting
contract performance.
9
  See ‘Implementation of the Federal Grants and Cooperative Agreements Act of 1977, Office of Management
Budget, August 18, 1978, Federal Register 43(161): 36860-36865. ‘Substantial involvement’ does not have a formal
regulatory definition, but it is described variously as entailing direction and redirection of the technical aspects of
the project as a whole; sharing responsibility with the firm for the management, control, direction, and performance
of the project.
10
   NASA Grant and Cooperative Agreement Manual, Revised September 16, 2016.


                                                         13
private firm and government. Grants typically allow the recipient firm’s principal investigator to

make virtually all key decisions during the research project, subject to compliance with Federal

regulations. In cooperative agreements, decision rights are more evenly distributed between

government and firm personnel. Daily decisions are often jointly determined by both parties. For

example, in a cooperative agreement between the National Cancer Institute (NCI) and

GlobeImmune, Inc. to develop yeast-based tarmogens for cancer immuno-therapy, the NCI and

GlobeImmune each had its own Principal Investigator. This role, as specified in the agreement,

was to be ‘person(s) designated by the Parties who will be responsible for the scientific conduct

of the Research Plan.’11

        Cooperative agreements also often provide the government with the right to terminate a

project before its official completion should the government’s principal decision-maker on the

project determine that its progress is not satisfactory. Indeed, the Department of Energy’s Model

Cooperative Agreement in Energy Efficiency and Renewable Energy contains not only regular

review meetings for the government, but also contains a section that grants the government

‘Go/No Go Decisions’ and decision-making authority at key milestones in the project.12 In

contrast, although the government can in principle decide to withhold subsequent funding

payments from an in-process grant, this tactic is cumbersome to implement and rarely employed.

        The third substantive difference between grants and cooperative agreements stems from

the decision-rights difference, and relates to the degree of information that passes between the

private firm and the government. Although a grant is awarded to a recipient firm through a




11
   ‘Preclinical and Clinical Development of GlobeImmune, Inc’s Proprietary Yeast-Based Tarmogens Expressing
Tumor-Associated Antigens for Cancer Immunotherapy,’ between the National Cancer Institute, NIH, and
GlobeImmune, Inc., signed 05/08/2008.
12
   ‘Model Cooperative Agreement,’ Contractual Term 7D. U.S. Department of Energy, Energy Efficiency and
Renewable Energy Program, 02/19/2013.


                                                     14
rigorous review process, during the project the recipient is only required to provide the agency

with periodic (often annual) reports of progress made on the grant’s objectives. After the project

is completed, the recipient has a finite amount of time (usually 90 days) to file a final report of

accomplishments.

        In cooperative agreements, the private firm is expected to provide information to the

government on a much more frequent basis. Given that decisions regarding project tasks are

sometimes made as frequently as daily, information must flow almost continuously to support

informed government decision-making. In those cases where government and private firm

scientists work closely together, this can occur informally through the collaborative effort. In

cases where this collaboration does not occur consistently, agreements stipulate formal

obligations to provide for communication. Thus, in contrast to research grants where researchers

provide information to the government at specified, infrequent intervals, cooperative agreements

stipulate more rapid communication and flow of information.

        For example, a cooperative agreement between the Department of Energy and Mascoma

Corporation, for a project to demonstrate feasibility of biorefining technology using plant

biomass, specified that ‘in order to adequately monitor project progress and provide technical

direction to the Recipient, DOE must [attend Mascoma Corporation] meetings, reviews and

tests.’ Presumably to protect against malfeasance, the cooperative agreement further noted,

‘[Mascoma Corporation] shall notify the DOE Project Officer of meetings, reviews, and tests in

sufficient time to permit DOE participation and provide all appropriate documentation for DOE

review.’13

        Overall, then, research grants and cooperative agreements represent discrete structural


13
   ‘Demonstration of Biorefinery Application,’ between the Mascoma Corporation and the Department of Energy,
signed 09/30/2008.


                                                      15
alternatives for R&D contracting between the U.S. Federal government and private firms. Grants

largely reflect canonical arms-length contracting, with little interaction during the research

project except for intermittent progress reports and with the research firm retaining almost

complete discretion over its allocation of effort. Cooperative agreements reflect contracting of

the type prescribed above to effectively manage contractual hazards, with the government

holding substantial monitoring authority and discretion over effort allocation and with the

requisite information flow and interaction between the parties.



DATA, MEASURES, AND EMPIRICAL STRATEGY

Data sources

To empirically test the predictions in this study, we employ data on the characteristics of U.S.

Federal Government research grants and cooperative agreements, characteristics of the

government bureau soliciting the project (notably the degree of relevant expertise in the local

bureau offices), characteristics of the firm performing the project, and measures of innovative

outcomes. We obtain this data from three sources.

       The first dataset contains information on the characteristics of agreements from

USASpending.gov. We downloaded all government grants and cooperative agreements (termed

‘assistance’ in the USASpending.gov nomenclature) executed between fiscal years 2000 and

2011. Each record contains information on the governance mechanism (grant or cooperative

agreement), the firm that received the funding, the principal location in which the organization

would perform the research (e.g., Cincinnati, Ohio), the agency or bureau of the government that

made the award (e.g., National Institute of Standards and Technology), the title and short




                                                 16
description of the project, and other details.14 Of particular relevance, project descriptions list a

set of activities necessary for the research project. We use records for only those organizations

categorized as businesses in the government agreement records.15 We also remove cases where

the funding agency was part of the Department of Defense or military due to data limitations.

         We employ a second dataset of granted U.S. patents, provided by PatentsView.org, to

measure patent generation. We download all U.S. patents with a ‘government interest’ indicated

in the patent application. Per U.S. regulations, patents that have any affiliation with a

government unit – including any funding from that unit – must include a government-interest

statement that acknowledges this affiliation. Government-interest statements refer to affiliated

grants and cooperative agreements by their unique ‘funding identification numbers.’ We then

conduct an exact match against the data in the USASpending database using the funding

identification numbers included in patent applications, thus identifying all patents that stipulated

an affiliation with any of the contracts in the sample. We ultimately identified 1,544 patents. Of

the 4,074 contracts in our sample, 508 (12.47%) led to at least one patent; 56 of these agreements

supported five patents or more. Separately, to create control variables as discussed below, we use

the PatentsView data to construct counts of aggregate patenting per year by each of the 383

private firms involved in any of the sample contracts.

         To identify the level of relevant expertise available in specific government bureau

offices, we rely on a third and relatively novel database from the U.S. Office of Personnel

Management’s (OPM) Central Personnel Data Files (CPDF). These records contain annual,




14
   A codebook for the federal assistance dataset is available at https://goo.gl/TW7QHY (last accessed February 17,
2017). To fill in some missing project descriptions, we searched the Federal Procurement Data System (FPDS) and
National Institutes of Health RePORTER system for federal award IDs matched to government-supported patents.
15
   To avoid any university affiliates misclassified as businesses, we also exclude records where the word ‘university’
appears in the organization name.


                                                         17
individual-level information on nearly all U.S. civil servants during the sample period (using

anonymous identifier codes), including information on work location, job title and occupation,

and research-related job functions.16 The CPDF allows us to measure the precise number of

government employees in each office of each Federal bureau who perform specific jobs. The

CPDF categorizes over 800 occupations into 59 occupational groups/families, as detailed in

OPM’s Handbook of Occupational Groups and Families.17 For example, the ‘Medical, Hospital,

Dental, and Pubic Health Group’ includes physician assistants, nurses, nurse assistants, and

doctors of dentistry, medicine, and osteopathy, among other related job titles. From these data,

we compute the number of personnel in each of the 59 occupational categories at every known

Federal work location in the US, geocoding each employee’s latitude and longitude. This

occupation-location data is further disaggregated to the bureau level (e.g., the NIH is a bureau of

the Department of Health and Human Services). Thus, we are able to identify how many of the

NIH’s employees in a particular location are in the Medical, Hospital, Dental, and Public Health

Group occupational category.

         Further, for each government employee who is involved in research-related activities,

broadly defined, the CPDF also includes a ‘functional research’ category, where the set of

categories includes research, development, testing and evaluation, construction, production,

installation, data collection, project management, and teaching. These classifications are created

by the National Science Foundation for OPM to describe the work that comprises the majority of

each research employee’s time. The ‘research’ function, for example, emphasizes early-stage

research – ‘systematic, critical, intensive investigation directed toward the development of new


16
   This dataset excludes the military, U.S. Post Office, and ‘sensitive’ agencies (colloquially known as ‘three-letter
agencies’) and occupations (such as U.S. Marshals). More than 70 percent of U.S. Federal Government employees
work outside the greater-DC metro area.
17
   Available at: https://www.opm.gov/fedclass/GShbkocc.pdf (last accessed February 14, 2017)


                                                          18
or fuller scientific knowledge of the subject studied’ – whereas the ‘testing and evaluation’

function emphasizes later stage ‘testing of equipment, materials, devices, components, systems

and methodologies under controlled conditions and the systematic evaluation of test data to

determine the degree of compliance of the test item with predetermined criteria and

requirements.18 We are thus able to identify how many of the NIH’s Medical, Hospital, Dental,

and Public Health Group personnel in any location are dedicated to early-stage research, how

many dedicated to development, and so on.

           With data from these three sources – USASpending, PatentsView, and the CPDF

database – we construct our variables.



Variables

Our first two predictions relate to the choice of governance for a research contract. The

dependent variable for testing these predictions is Coop Agreementj, which is a binary indicator

set equal to one if contract j was a cooperative agreement and zero if a grant. Our third prediction

relates to the innovative performance of research contracts. We employ five dependent variables

to test this prediction. Generates Patentj, is a binary indicator set equal to one if contract j

generated at least one patent and zero otherwise. NumPatentsj is a count of patents generated by

contract j. Citation-Weighted Patentsj, is the sum of the patents generated by contract j and the

subsequent citations to those patents. Citations/Patentj is constructed as Citation-Weighted

Patents/NumPatents. Citations/Patent/Yearj is constructed as Citation-Weighted

Patents/NumPatents divided by the number of years since contract j was signed.

           Governance. The main independent variables of interest predicting the choice of



18
     Office of Personnel Management (November 14, 2014). The Guide to Data Standards, Update 16, A159-A167.


                                                       19
governance are Early-Stage Personnelj, which proxies for high-uncertainty projects, and

Personnel Expertise Ratioj, which measures the ability of government personnel to provide

effective oversight on a project. For ease of explication, we discuss these in reverse order.

        Personnel Expertise Ratioj is defined as the proportion of occupational categories

required to conduct contract j that are available among geographically proximate client bureau

personnel. We measure this using a three-step procedure. First, for each of the 59 occupational

categories identified in the CPDF handbook, we create a list of distinct terms in the constituent

job titles.19 Next, we search for these terms in contract j’s project description. If a term from an

occupational category is found in the project description, then contract j is coded as requiring the

skills of that category. Thus, each contract is characterized as drawing on a subset of the 59

occupational skill sets, with the median contract requiring skills from eight occupational

categories, the mean contract requiring skills from 12.8 occupational categories, and the standard

deviation across all contracts at 15.8. Finally, for each contract j, we calculate the proportion of

requisite categories for which the sponsoring government bureau had at least one employee

within a 100-mile radius of the principal research location during the year that the contract was

signed.20 For example, if a project description signed in 2005 contained terms that occurred in

occupational categories x, y, and z, and the sponsoring government bureau had at least one

employee working in each of categories x and y that year within 100 miles of the research

location, then the Personnel Expertise Ratio for that contract would be 0.67. We predicted that

contracts are more likely to include monitoring/decision-rights provisions when the government




19
   For example, the term list for the ‘Medical, Hospital, Dental and Public Health Group’ includes terms such as
health, scienc*, medic*, physician, autopsy*, dietitian, nutritionist, diagnost*, radiolog*.
20
   We use a 100-mile radius for our core estimations because this roughly corresponds to the maximum distance that
one can drive twice in one workday (outbound and return) and still have time for a half-day meeting. We replicate
all estimations with alternative radii of 200, 300, 400, and 500 miles.


                                                       20
has personnel who are sufficiently expert to fulfill these duties effectively; consequently, we

expect the coefficient on Personnel Expertise Ratio to be positive.

       As noted above, we expect cooperative agreements will be favored for more uncertain

projects. We test this by using the functional research categories in the CPDF data to proxy for

the early-stage nature of a contract. Imagine that contract j’s project description contains words

that occur only in occupational category x and contract k’s project description contains words

that occur only in occupational category y. If the government employees in occupational

category x are clustered in the research function, while employees in occupational category y are

clustered in the development function, then contract j is likely to cover a more early-stage

research project than contract k.

       Given this, Early-Stage Personnelj is defined as the proportion of a bureau’s

geographically proximate employees in contract j’s requisite occupational categories who are

assigned to a research function. We measure this in a three-step process. We start with the list of

relevant occupational categories for contract j and identify client bureau personnel in those

categories within 100 miles of the location of work. We then calculate the percent of these

relevant employees who are also categorized in the research function. We predicted that

contracts are more likely to include monitoring/decision-rights provisions when the project

entails early-stage effort; consequently, we expect the coefficient on Early-Stage Personnel to be

positive.

       Performance. The main independent variable of interest in the innovative performance of

research contracts is the contractual form: Coop Agreement, defined above. We predicted that,

conditional on government personnel assigning contracts according to project uncertainty and

presence of relevant skills, cooperative agreements should outperform grants. Therefore, we




                                                21
expect the coefficient on Coop Agreement to be positive.

       Control variables. We include several additional variables to control for various project,

firm, bureau, and time-based characteristics. It is possible that projects with larger budgets or

more firm co-funding are more likely to fall under a particular governance form or generate

patents. We therefore include Federal Fundingj, defined as the dollar amount contributed by the

government to support contract j, as well as Firm/Total Fundingj, defined as the amount

contributed by the firm divided by total funding for contract j. Larger or higher-patenting firms

might be more likely to generate a patent from the contracted research and/or be differentially

likely to operate under a particular contractual form. To address this, we include Large Firmj,

which equals one if the firm is categorized by the government as a ‘large for-profit enterprise’ in

the research contract document and zero if it is coded as a ‘small business enterprise.’ We also

include Prior Patentsj, defined as the number of patent applications filed by the focal firm in the

year preceding the signing of contract j. Given the skew in Federal Funding, Firm/Total

Funding, and Prior Patents, we standardize each variable and use the z-scores rather than using

the raw values.

       A bureau’s choice of contractual form, and the performance of its contract, might be

affected by the degree to which its local office is managing several concurrent contracts. For a

cooperative agreement in particular, this could affect performance if government researchers

with relevant expertise are unable to devote as much attention and effort to contract j’s research

project as would be optimal. We include Coops Within 100 Milesj and Coops/Personnel Ratioj,

defined respectively as the number of in-process cooperative agreements within a 100-mile

radius of contract j’s principal research location and the ratio of these agreements to research

personnel in the local bureau. Note that the Coops/Personnel Ratio variable obliquely proxies for




                                                 22
the feasibility of coordination between government researchers and the focal firm; if the

government researchers are stretched too thin, then they will not be able to effectively monitor or

make decisions regarding contract j’s research project. Contracts undertaken in different years

might have different forms and outcomes due to temporal pressures on personnel; to address this

we include fiscal-year fixed effects. Finally, for roughly 31 percent of contracts, the project

description does not yield a link to any occupational categories, which precludes identifying

employees with relevant skills. In these instances, we set Personnel Expertise Ratio equal to 0.

To separate these from the qualitatively different instances in which contract j is linked to

occupational categories and the bureau has no relevant local personnel, we also include No

Expertisej, a binary variable set to one if contract j’s project description is not linked to any

occupational categories and to zero otherwise.21

           Table 1 provides summary statistics for our sample. As noted above, 12.5 percent of our

sample contracts generate at least one patent. Almost one-quarter of the contracts are cooperative

agreements. Slightly more than one-quarter of the contracts involve a large firm. The average

number of concurrent cooperative agreements managed by the local relevant bureau is nearly six,

which equates to nearly 0.5 agreements per local research employee. The average cooperative

agreement is five times as likely to generate a patent as the average grant, and is more likely to

entail early-stage effort. The average cooperative agreement is also more likely to be performed

by a large, high-patenting organization in conjunction with a bureau that has relevant local

expertise. Correlation matrices for the sample are provided in Table B1 of Appendix B.



                                           [TABLE 1 ABOUT HERE]



21
     We further address the issue of missing values in the Data section of Appendix B.


                                                           23
Empirical strategy

To appropriately estimate the models we employ a two-stage econometric technique that first

estimates the probability of selecting into a grant or cooperative agreement governance mode and

then estimates the effect of this cooperative agreement ‘treatment’ on patenting, using

information from the selection model to correct for the non-random nature of the treatment

model. The first stage provides a test for our governance predictions while the second stage

provides a test for our performance predictions.

       This estimation approach requires an instrumental variable for contract form in the first-

stage selection model. Our instrument is Personnel Expertise Ratio. As described above, when

there are fewer government research personnel with relevant expertise in the geographic area of a

research location, the government bureau is less able to accurately evaluate progress in the

research project. Thus, allocating decision rights and monitoring rights to the government will

provide little governance benefit and will merely impose bureaucracy costs on the project;

therefore, cooperative agreements will be negatively correlated with the number of

geographically proximate government personnel with relevant technical expertise. At the same

time, the presence of local government research personnel with expertise per se is unlikely to be

correlated with patenting, to the extent that firm and government scientists are effectively

substitutes in production. We address the robustness of this assumption in the Robustness Checks

section of Appendix B.

       One complication in our setting is that both selection and treatment models have

dichotomous dependent variables. Consequently, several conventional two-stage approaches are

inappropriate because they are only robust in linear settings (Chesher, 2010; Wooldridge, 2010).




                                                24
Our preferred method is the inverse probability weighting regression adjustment method

(IPWRA) (Angrist, 1998; Angrist and Pischke, 2009). Appendix B provides a more detailed

explanation of the IPWRA method, along with an assessment of its strengths and weaknesses. In

short, this method is appropriate when a researcher wants to estimate treatment effects from

observational data combining regression adjustment with inverse probability weighting. It is also

appropriate when the choice of treatment is endogenous (e.g., whether to use a cooperative

agreement or grant agreement) and there is a dichotomous variable in the second stage outcome

equation (e.g., whether an agreement yields a patent). Finally, it is attractive because it allows

both the treatment and control groups to have their own set of second-stage coefficients,

recognizing that those in each group may be differentially affected by the covariates.

        We believe that the IPWRA approach is the most relevant and most accurate statistical

approach for this research question and this data set. Nevertheless, we re-estimate the models

using alternative approaches, including the single stage (‘naïve’) probit, the two-stage least

squares linear probability model, the bivariate probit, the instrumental variables probit, and the

full-information-maximum-likelihood (FIML) approach with joint normality in the error terms. 22

The results of these robustness checks are reported in Appendix B. Virtually all results using

these methods are qualitatively identical to the results discussed in the next section.



EMPIRICAL RESULTS

The central results of this paper are reported in Table 2. Model 1 presents the first stage IPWRA

results that emanate from the governance predictions in the theory. Models 2A and 2B present



22
  All of these estimation approaches are appropriate conditional on the government funding a project. If one instead
assumes that the government decides among grant, cooperative agreement, and not funding the project at all, then a
multi-level treatment model would be appropriate. However, we cannot observe non-funded CFPs.


                                                        25
the second stage IPWRA results that arise from the contract performance predictions of the

theory. The first stage of this model includes all exogenous predictors as well as the instrument,

Personnel Expertise Ratio, which predicts selection into a cooperative agreement rather than a

grant. The second stage incorporates the inverse of the predicted probability of selection from the

first stage as a weight in the estimation as well as regression adjustment.



                                    [TABLE 2 ABOUT HERE]



       We begin with the first-stage results in Model 1, for which the dependent variable is

Coop Agreement. Of particular importance, the coefficient on Personnel Expertise Ratio is

positive, statistically significant (p = 0.000), and of substantial magnitude. Research contracts are

more likely to be organized as cooperative agreements when the sponsoring bureau has relevant

skills in its geographically proximate offices. The marginal effect of a bureau having personnel

in all relevant areas for a project leads to an 11 percent increase in the likelihood of a contract

being organized as a cooperative agreement rather than as a grant. This is also consistent with the

theoretical prediction that public-private contracts will be more likely to entail ongoing public

supervision when the public client possesses sufficient technical expertise to effectively exert its

supervisory responsibilities.

       Consistent with our prediction, the coefficient on Early-Stage Personnel in the first stage

is positive and significant (p = 0.000), indicating that earlier-stage projects are more likely to be

governed by cooperative agreements. If all the personnel with expertise in areas relevant to a

project’s required expertise work in early-stage research positions, an agreement is 16 percent

more likely to be organized cooperatively than if none of them does. Early-stage projects, which




                                                  26
are typically considered to be more uncertain and hence entail more unobservable effort, are thus

associated with high-monitoring, high-client-decision-rights governance.

       As for the control variables, contracts involving larger firms are more likely to be

organized as cooperative agreements. The amount of federal funding is not associated with

governance form, but the proportion of firm funding to total funding is positively associated with

cooperative agreements. Finally, projects that do not identify any areas of expertise were roughly

11 percent less likely to be organized as cooperative agreements, suggesting the government may

prefer arms-length financial support for narrowly-defined projects.

       We now turn to the second-stage results, for which the dependent variable is Generates

Patent. Model 2A presents the estimated coefficients for contracts that were governed as

cooperative agreements, while Model 2B presents these for contracts that were governed as

grants. Both second-stage models rely on the results from the first stage. We have converted the

coefficient on the treatment variable, Coop Agreement, to a marginal effect. Thus, the coefficient

on Coop Agreement in Model 2A reflects the marginal effect of being a cooperative agreement

vs. being governed by a grant, for those contracts that were actually governed by cooperative

agreement, while its counterpart in Model 2B reflects the effect of being a cooperative agreement

vs. a grant, for those contracts that were actually governed by grant. The coefficient in Model 2A

is 0.278, indicating that the average cooperative agreement in our sample was nearly 28 percent

more likely to generate a patent than it would have been if it were organized as a grant, holding

all other variables at the mean. In contrast, the coefficient in Model 2B is 0.083, indicating that

the average grant in our sample would have been eight percent more likely to generate a patent

had it been organized as a cooperative agreement. Put differently, consistent with our prediction,

cooperative agreements are associated with higher innovative output than are grants, controlling




                                                 27
for the other independent variables; this effect is more pronounced for contracts that actually

were organized as cooperative agreements than for contracts that actually were organized as

grants.

          In model 2A, several other variables influence the likelihood that a cooperative

agreement generates a patent. Of particular note, Coops/Personnel Ratio is negatively related to

Generates Patent; this is consistent with the notion that as a bureau’s scientific personnel gets

stretched thinly, they are less able to engage in smooth coordination of effort with firm

personnel, thus lowering research productivity. No coefficients on the control variables are

significant at conventional thresholds except for Prior Year Patents.

          Turning to Model 2B, which focuses on contracts that were organized as grants, the

coefficients on Large Firm and Firm/Total Funding are both positive and significant (p = 0.033

and p = 0.046, respectively). This indicates that larger organizations are more likely to generate

patents and, consistent with incentive theory, firms that have ‘skin in the game’ are also more

likely to generate patents.

          Taken together, the above results suggest that the presence or absence of relevant

expertise influences the governance of research contracts, such that cooperative agreements are

substantially more likely when the sponsoring government bureau has relevant skills in

geographically proximate offices. In addition, early-stage projects are more likely to be governed

as cooperative agreements. In turn, cooperative agreements are more likely than grants to

generate patents. Had the average cooperative agreement been governed as a grant, it would have

had a 28 percent lower probability of generating a patent. That said, those projects organized as

grants would not have enjoyed a comparable increase in probability of patent generation since

they are qualitatively different than the projects organized as cooperative agreements. Had the




                                                  28
average grant been governed as a cooperative agreement, it would have had an eight percent

higher probability (from a lower initial baseline) of generating a patent. 23



Extensions: The magnitude of innovative performance

The above estimation focuses on a binary measure of innovative performance—whether or not a

research contract generates at least one patent. It is possible that other measures of innovative

output will indicate different impacts of contract structure. As noted above, we constructed

alternative measures of innovative output, notably Num Patents, Citation-Weighted Patents,

Citations/Patent, and Citations/Patent/Year. Table 3 presents results for IPWRA estimation of

models with these four dependent variables. The Table only shows the second-stage results

because the first-stage results are identical to those of the IPWRA estimation in Table 2’s Model

1, by definition.



                                          [TABLE 3 ABOUT HERE]



         For each measure of innovative output, the coefficient on Coop Agreement is uniformly

positive and statistically significant (p = 0.000 in all models). In all four cases, this coefficient is

substantially higher for contracts that actually were governed by cooperative agreements than for

contracts that were governed by grants; the coefficient ranges from roughly five times larger to

as much as 15 times larger. (The largest differences occur because cooperative agreements


23
  This raises a question: If the average grant would enjoy a positive (albeit small) increase in probability of patent
generation if it were organized as a cooperative agreement, then why isn’t it governed by a cooperative agreement?
The negative coefficient on Coops/Personnel ratio implies that each cooperative agreement imposes a negative
externality on other geographically proximate cooperative agreements due to a congestion effect. Hence, for a wide
range of values, the modest bump in research productivity from converting a focal grant to cooperative agreement
will be offset by the declining productivity of nearby cooperative agreements. See Appendix B for a further
discussion of this point.


                                                          29
simultaneously generate more patents and more citations/patent, affecting Models 3–8.) This

consistent pattern of coefficient sign and magnitude matches the core results above. Because of

the extreme skewness of the dependent variables used in Table 3, we include in Appendix B the

coefficients on the second-stage Coop Agreement variable for identical models using logged

dependent variables (addressed as item seven in the robustness checks below and Table B8 in

Appendix B). The results for all eight models retain their sign and significance (p = 0.000 in all

models).



Robustness checks

There are several concerns that may arise from the specification and estimation strategies we

employ. They include: 1) sensitivity of results to the IPWRA approach or to the chosen

geographic radius for Personnel Expertise Ratio; 2) omitted variable bias related to temporal

variance, e.g., changes to the Federal budget thanks to the American Recovery and Reinvestment

Act of 2009 (ARRA, a.k.a. the Federal ‘stimulus package’); 3) unobserved heterogeneity at the

bureau level and/or firm level; 4) the empirical appropriateness of the instrumental variable; 5)

skewness of patenting and citation rates; 6) the possibility that the performance results reflect

more effective coordination between government and private sector scientists when they work on

cooperative agreements; and 7) unobserved heterogeneity in project quality assigned to grants

and cooperative agreements. We address in detail each of these concerns in appendices to the

paper; the first six concerns are addressed in the Robustness Checks section of Appendix B, and

the final concern is addressed in Appendix A. To summarize briefly: Across numerous

estimation methods and a wide range of geographic radii, the results illustrated in Table 2 remain

materially unchanged. Results also remain largely the same when a dummy variable to identify




                                                 30
ARRA contracts is included, when bureau and firm effects are included, and when logged

patenting and citations are used as dependent variables. Finally, after controlling for endogeneity

in contract choice to the best of our ability, the results remain qualitatively unchanged.



DISCUSSION AND CONCLUSION

Governments throughout the world spend tens of billions of dollars annually on contractually

sourced research. Yet the challenge of public contracting for private innovation, although of

substantial importance, is not well understood. In this paper, we shed light on this topic.

Conventional prescriptions from the ‘contracting for innovation’ literature do not apply

straightforwardly to government contracting because of restrictions that preclude the judicious

use of property rights, equity investment, royalty payments, or complex contractual provisions to

align parties’ incentives in the face of unobservable effort. Put differently, public contracting for

private innovation is an excellent setting in which to examine one particular mechanism to

induce effort: allocation of decision rights.

       We predict that public retention of decision rights is more likely to be used in the face of

high project uncertainty and when the available government personnel have project-relevant

technical expertise. We also predict that the use of monitoring and decision rights will positively

influence the likelihood that a project results in a patented innovation. We then test these

predictions with data on U.S. Federal government contracts for innovation by private firms,

which are generally constrained to take one of two forms: grants, in which the government

retains virtually no decision rights, and cooperative agreements, in which the government retains

ongoing decision rights and attendant monitoring rights.

       We find empirical support for the above predictions: cooperative agreements are more




                                                 31
likely to be used for early-stage projects than for later-stage projects, and cooperative agreements

are more likely to be used when local government personnel have relevant technical expertise.

Similarly, after accounting for endogeneity in governance choice due to project uncertainty and

personnel expertise, we find cooperative agreements are indeed associated with higher

innovative output than are grants. We interpret these results as evidence consistent with the idea

that a principal chooses to govern more-uncertain projects, where the problem of noncontractible

effort is higher, by retaining more decision rights and enforcing greater monitoring over the

project. However, when the principal lacks the relevant know-how to properly evaluate project

progress, it is preferable to leave decisions in the hands of the agent.

        These results contribute to our understanding of value creation involving public

organizations. Specifically, as public actors strive to generate valuable innovations to serve

government needs or more broadly enhance social welfare, this study’s insights may help these

actors overcome the constraints of contractual rigidities. More generally, these results contribute

to the literature on public contracting (Moszoro et al., 2016) and to the debate over management

of noncontractible quality for a privatized service (Hart et al., 1997; Williamson, 1999), notably

for ‘hybrid’ public management (Ménard, 2004; Rangan, Samii, and Van Wassenhove, 2006).

Whereas prior literature has identified the importance of incentives for the government overseer

of a hybrid (Cabral et al., 2010, 2013), this study highlights the importance of that overseer’s

ability to evaluate the effort of the private provider.

        At the broadest level, recent research on contractual governance has assessed the distinct

roles of coordination mechanisms vs. control mechanisms (Malhotra and Lumineau, 2011; Oxley

and Wada, 2009; Ryall and Sampson, 2009). For example, Lumineau and Malhotra (2011)

distinguish between contractual clauses that emphasize control and those that emphasize




                                                  32
coordination, and find that coordination-related clauses are associated with smoother functioning

of contracts in the face of interfirm friction. In a review of this literature, Lumineau (2017: 1561)

concludes that ‘a strong controlling focus may raise a constant policing…of the partner’s

performance…. Such a ‘carrot-and-stick’ approach with a strict oversight may create rigidity and

over-monitoring.’ Our study indicates that the relationship between rigidity and reliance on

control mechanisms may also flow in the opposite direction: in institutional contexts that impose

contractual rigidity, control mechanisms may be more feasible than coordination mechanisms.

       This study also makes an additional empirical contribution in developing a measure of

government personnel skills at a far more microanalytic level than has been done in the past. We

can thus measure the precise level of skills or capabilities, across 59 occupational categories and

19 functional areas, possessed by the personnel of a given U.S. government bureau at a precise

geographic level such as an office location, town, or any geographic radius. To the best of our

knowledge, no other measure of government technical expertise exists at such a level of

granularity. More generally, although the capabilities literature focuses theoretically on

capabilities with specific uses, data constraints have tended to restrict empirical measurement of

capabilities to features such as patenting productivity (e.g., Tortoriello, 2015) or prior experience

in a particular industry (e.g., Klepper and Simons, 2000).

       There are limitations to this study. First, we have excluded from our analysis pure

outsourcing arrangements, in which the government rather than the firm owns the property rights

to the innovation. It would be interesting to explore whether and how our theories and empirical

methods might apply to these very common arrangements. Second, our paper measures

innovative output as patents. One could imagine a situation where the government might value

other outputs, such as jobs, regional economic development, or a variety of political criteria.




                                                 33
Those aspects of a potential government utility function are outside the scope of this paper.

Third, we take contractual form as endogenously determined by the government, but without the

influence of firms who did not win. To the extent that non-winning applicants for innovation

contracts with the government influence contract form, our analysis will not capture that

influence. Finally, while our theoretical framework aspires to be universal, the empirical work is

particular to the institutional details and structure of government contracting for innovation in the

United States. We believe that exploring applications of the theory to other countries would be a

fruitful avenue for research.

       There exist a number of further unexplored questions in this vein. Does government

funding enable a firm to deepen its current expertise, or to broaden its technological portfolio and

capabilities? How do the human-capital capabilities of the government affect the effectiveness of

private sector research beyond patents? These questions are part of a vibrant avenue for future

research on innovation and appropriation at the nexus of the government and private-firm R&D.




                                                 34
                                       REFERENCES

Aghion P, Tirole J. 1994. The management of innovation. Quarterly Journal of Economics
    109(4): 1185–1209.
Anderson SW, Dekker HC. 2005. Management control for market transactions: The relation
    between transaction characteristics, incomplete contract design, and subsequent
    performance. Management Science 51(12): 1734–1752.
Angrist JD. 1998. Estimating the labor market impact of voluntary military service using social
    security data on military applicants. Econometrica 66(2): 249–288.
Angrist JD, Pischke J-S. 2009. Mostly Harmless Econometrics: An Empiricist’s Companion.
    Princeton University Press: Princeton.
Argyres N, Mayer KJ. 2007. Contract design as a firm capability: An integration of learning and
    transaction cost perspectives. Academy of Management Review 32(4): 1060–1077.
Argyres NS, Bercovitz J, Mayer KJ. 2007. Complementarity and evolution of contractual
    provisions: An empirical study of IT services contracts. Organization Science 18(1): 3–19.
Arora A, Gambardella A. 2010. Ideas for rent: An overview of markets for technology.
    Industrial and Corporate Change 19(3): 775–803.
Arruñada B, Garicano L, Vázquez L. 2001. Contractual allocation of decision rights and
    incentives: The case of automobile distribution. Journal of Law, Economics, & Organization
    17(1): 257–284.
Athey S, Roberts J. 2001. Organizational design: Decision rights and incentive contracts.
    American Economic Review 91(2): 200–205.
Boyne GA. 2002. Public and private management: What’s the difference? Journal of
    Management Studies 39(1): 97–122.
Cabral S, Lazzarini SG, de Azevedo PF. 2010. Private operation with public supervision:
    Evidence of hybrid modes of governance in prisons. Public Choice 145(1/2): 281–293.
Cabral S, Lazzarini SG, de Azevedo PF. 2013. Private entrepreneurs in public services: A
    longitudinal examination of outsourcing and statization of prisons. Strategic
    Entrepreneurship Journal 7(1): 6–25.
Cassiman B, Veugelers R. 2006. In search of complementarity in innovation strategy: Internal
    R&D and external knowledge acquisition. Management Science 52(1): 68–82.
Chesher A. 2010. Instrumental variable models for discrete outcomes. Econometrica 78(2): 575–
    601.
Cohen WM, Levinthal DA. 1990. Absorptive capacity: A new perspective on learning and
    innovation. Administrative Science Quarterly 35(1): 128–152.
Decarolis F, Giuffrida LM, Iossa E, Mollisi V, Spagnolo G. 2018. Bureaucratic Competence and
    Procurement Outcomes. Working Paper, National Bureau of Economic Research. Available
    at: http://www.nber.org/papers/w24201.
Grossman SJ, Hart OD. 1986. The costs and benefits of ownership: A theory of vertical and
    lateral integration. Journal of Political Economy 94(4): 691–719.
Hart O, Shleifer A, Vishny RW. 1997. The proper scope of government: Theory and an
    application to prisons. The Quarterly Journal of Economics 112(4): 1127–1161.
Hegde D. 2014. Tacit knowledge and the structure of license contracts: Evidence from the
    biomedical industry. Journal of Economics & Management Strategy 23(3): 568–600.




                                              35
Hourihan M, Parkes D. 2015, February 24. Federal R&D in the FY 2016 budget: An overview.
    American Association for the Advancement of Science. Available at:
    https://www.aaas.org/fy16budget/federal-rd-fy-2016-budget-overview [26 September 2017].
Klein PG, Mahoney JT, McGahan AM, Pitelis CN. 2013. Capabilities and strategic
    entrepreneurship in public organizations. Strategic Entrepreneurship Journal 7(1): 70–91.
Klepper S, Simons KL. 2000. The Making of an oligopoly: Firm survival and technological
    change in the evolution of the U.S. tire industry. Journal of Political Economy 108(4): 728–
    760.
Lan Z, Rainey HG. 1992. Goals, rules, and effectiveness in public, private, and hybrid
    organizations: More evidence on frequent assertions about differences. Journal of Public
    Administration Research and Theory: J-PART 2(1): 5–28.
Lerner J, Malmendier U. 2010. Contractibility and the design of research agreements. American
    Economic Review 100(1): 214–246.
Lerner J, Merges RP. 1998. The control of technology alliances: An empirical analysis of the
    biotechnology industry. The Journal of Industrial Economics 46(2): 125–156.
Levin J, Tadelis S. 2010. Contracting for government services: Theory and evidence from U.S.
    cities. The Journal of Industrial Economics 58(3): 507–541.
Lumineau F. 2017. How contracts influence trust and distrust. Journal of Management 43(5):
    1553–1577.
Lumineau F, Malhotra D. 2011. Shadow of the contract: How contract structure shapes interfirm
    dispute resolution. Strategic Management Journal 32(5): 532–555.
Malhotra D, Lumineau F. 2011. Trust and collaboration in the aftermath of conflict: The effects
    of contract structure. Academy of Management Journal 54(5): 981–998.
Mayer KJ, Salomon RM. 2006. Capabilities, contractual hazards, and governance: Integrating
    resource-based and transaction cost perspectives. Academy of Management Journal 49(5):
    942–959.
McKenna, C.D. 2006. The World's Newest Profession: Management Consulting in the Twentieth
    Century. Cambridge: Cambridge University Press.
Ménard C. 2004. The economics of hybrid organizations. Journal of Institutional and
    Theoretical Economics JITE 160(3): 345–376.
Miller AS. 1955. Government contracts and social control: A preliminary inquiry. Virginia Law
    Review 41(1): 27–58.
Moe TM. 1989. The politics of bureaucratic structure. In Can the Government Govern?
    Brookings Institution: Washington, D.C.: 267–329.
Moe TM. 1990. Political institutions: The neglected side of the story. Journal of Law,
    Economics, & Organization 6: 213–253.
Moszoro M, Spiller PT, Stolorz S. 2016. Rigidity of public contracts. Journal of Empirical Legal
    Studies 13(3): 396–427.
National Audit Office. 2013. Research and Development funding for science and technology in
    the UK. Memorandum for the House of Commons Science and Technology Committee,
    London.
Oxley JE. 1997. Appropriability hazards and governance in strategic alliances: A transaction cost
    approach. Journal of Law, Economics, & Organization 13(2): 387–409.
Oxley JE, Wada T. 2009. Alliance structure and the scope of knowledge transfer: Evidence from
    U.S.-Japan agreements. Management Science 55(4): 635–649.




                                               36
Pisano GP. 1990. The R&D Boundaries of the firm: An empirical analysis. Administrative
    Science Quarterly 35(1): 153–176.
Rangan S, Samii R, Van Wassenhove LN. 2006. Constructive partnerships: When alliances
    between private firms and public actors can enable creative strategies. Academy of
    Management Review 31(3): 738–751.
Reuer JJ, Ariño A. 2007. Strategic alliance contracts: Dimensions and determinants of
    contractual complexity. Strategic Management Journal 28(3): 313–330.
Reuer JJ, Ariño A, Mellewigt T. 2006. Entrepreneurial alliances as contractual forms. Journal of
    Business Venturing 21(3): 306–325.
Reuer JJ, Devarakonda SV. 2016. Mechanisms of hybrid governance: Administrative
    committees in non-equity alliances. Academy of Management Journal 59(2): 510–533.
Ryall MD, Sampson RC. 2009. Formal contracts in the presence of relational enforcement
    mechanisms: Evidence from technology development projects. Management Science 55(6):
    906–925.
Sampson RC. 2004a. Organizational choice in R&D alliances: Knowledge-based and transaction
    cost perspectives. Managerial and Decision Economics 25(6/7): 421–436.
Sampson RC. 2004b. The cost of misaligned governance in R&D alliances. Journal of Law,
    Economics, & Organization 20(2): 484–526.
Spiller PT, Moszoro M. 2014. Third-party opportunism and the theory of public contracts:
    Operationalization and applications. In The Manufacturing of Markets: Legal, Political and
    Economic Dynamics, Brousseau E, Glachant J-M (eds). Cambridge University Press: New
    York: 229–252.
Teece DJ. 1986. Profiting from technological innovation: Implications for integration,
    collaboration, licensing and public policy. Research Policy 15(6): 285–305.
Tortoriello M. 2015. The social underpinnings of absorptive capacity: The moderating effects of
    structural holes on innovation generation based on external knowledge. Strategic
    Management Journal 36(4): 586–597.
Williamson OE. 1999. Public and private bureaucracies: A transaction cost economics
    perspectives. Journal of Law, Economics, and Organization 15(1): 306–342.
Wooldridge JM. 2010. Econometric Analysis of Cross Section and Panel Data, 2nd ed. MIT
    Press: Cambridge, MA.
Xiao W, Xu Y. 2012. The impact of royalty contract revision in a multistage strategic R&D
    alliance. Management Science 58(12): 2251–2271.




                                               37
Table 1. Descriptive statistics for variables used in primary analysis

                                           All contracts                   Cooperative agreements only                  Grants only
                                            (N=4,074)                               (N=916)                              (N=3,158)
         Variable              Mean       S.D.     Min.       Max.       Mean    S.D.      Min.    Max.       Mean     S.D.     Min.    Max.

Generates Patent                0.125    0.330       0          1        0.326    0.469       0         1      0.066   0.249      0        1
Num. Patents Generated          0.322    1.963       0         59        1.096    3.964       0        59      0.097   0.439      0        6
Citation-Weighted Patents       1.815 23.513         0        1082       7.480    49.073      0       1082     0.172   1.817      0       61
Citations/Patent                0.496    3.607       0      100.333      1.793    7.050       0     100.333    0.120   1.323      0       61
Citations/Patent/Year           0.045    0.252       0       6.271       0.146    0.475       0      6.271     0.015   0.112      0     3.813
Coop Agreement                  0.225    0.418       0          1          1        0         1         1        0       0        0        0
Personnel Expertise Ratio       0.059    0.159       0          1        0.117    0.217       0         1      0.042   0.134      0        1
Early Stage Personnel           0.009    0.070       0          1        0.013    0.078       0         1      0.008   0.068      0        1
Federal Fundinga                  0        1      -2.331     31.400      0.214    1.342    -0.609    21.336   -0.062   0.871   -2.331   31.400
Firm/Total Fundinga               0        1      -0.354     4.101       0.870    1.546    -0.354    4.101    -0.252   0.561   -0.354   4.101
Large Firm                      0.268    0.443       0          1        0.750    0.433       0         1      0.128   0.334      0        1
Prior Year Patentsa               0        1      -0.316     16.323      0.483    1.392    -0.316    16.323   -0.140   0.801   -0.316   16.323
Coops/Personnel Ratio           0.459    1.839       0         25        1.093    2.917       0        24      0.275   1.322      0       25
Coops within 100 Miles          5.703 10.553         0         68        12.503   14.771      0        65      3.730   7.945      0       68
No Expertise                    0.312    0.463       0          1        0.084    0.278       0         1      0.378   0.485      0        1
Note. All variables calibrated to 100-mile distance.
a
  z-score standardized




                                                                          38
Table 2. Two-stage IPWRA probit estimation of patent generation


                                           First-stage
                                                              Second-stage models
                                             model
                                                            Model 2A         Model 2B
                                            Model 1        (subsample:      (subsample:
                                                             Coops)           Grants)
      Personnel Expertise Ratio (IV)        0.651**
                                            (0.165)
      Coop Agreement                                           0.278**         0.083**
                                                               (0.032)          (0.006)
      Early Stage Personnel                  1.007**            -3.660           0.700
                                             (0.275)           (2.155)          (0.385)
      Federal Funding                          0.038             0.046           0.061
                                             (0.035)           (0.046)          (0.035)
      Firm/Total Funding                     0.286**             0.077          0.148*
                                             (0.031)           (0.046)          (0.069)
      Prior Year Patents                       0.005          -0.171**          -0.025
                                             (0.024)           (0.058)          (0.066)
      Coops/Personnel Ratio                   -0.003           -0.090*          -0.079
                                             (0.014)           (0.046)          (0.048)
      Coops within 100 Miles                 0.018**             0.005           0.005
                                             (0.003)           (0.007)          (0.006)
      Large Firm                             1.270**             0.239          0.304*
                                             (0.068)           (0.154)          (0.152)
      No Expertise                          -0.663**             0.057          -0.152
                                             (0.090)           (0.284)          (0.152)
      Fiscal Year Fixed Effects                YES               YES             YES
      Note. N = 4,074 in Model 1, 916 in Model 2A, and 3,158 in Model 2B.
      Heteroskedasticity-robust standard errors are reported in parentheses. Models
      specified using 100-mile distance variables. Coefficients on Coop Agreement in
      Models 2A & 2B are interpreted as marginal effects; i.e., conditional on being a
      cooperative agreement or grant, respectively.
      * p < .05, ** p < .01




                                              39
  Table 3. Second-stage IPWRA results of patent generation and quality outcomes


                                                                                                                    Citations/
                          Num. patents generated    Citation-weighted patents       Citations/patent
                                                                                                                   patent/year
Variable                    Model 1      Model 2        Model 3  Model 4       Model 5       Model 6        Model 7         Model 8
                             Coops        Grants         Coops    Grants        Coops         Grants         Coops           Grants
Coop Agreement              0.666**      0.145**        4.516**  0.273**       1.506**       0.169**        0.121**         0.022**
                            (0.090)      (0.016)        (0.819)  (0.063)       (0.230)        (0.031)       (0.018)         (0.003)
Early Stage Personnel        -1.285        0.072        -6.281*    0.098       -1.699*          0.035       -0.160*           0.003
                            (0.663)      (0.121)        (2.976)  (0.268)       (0.803)        (0.098)       (0.077)         (0.014)
Federal Funding             0.208*        0.101*         0.781*    0.031         0.099         -0.006         0.011          -0.001
                            (0.098)      (0.040)        (0.394)  (0.035)       (0.059)        (0.010)       (0.008)         (0.002)
Firm/Total Funding            0.060       0.107*          1.184    0.148        -0.062          0.042         0.001           0.006
                            (0.064)      (0.046)        (0.632)  (0.173)       (0.112)        (0.060)       (0.010)         (0.009)
Prior Year Patents            0.174       -0.038          1.658   -0.167         0.029         -0.063        -0.004         -0.009*
                            (0.143)      (0.037)        (0.958)  (0.091)       (0.124)        (0.033)       (0.009)         (0.005)
Coops/Personnel Ratio         0.042      -0.054*          0.034   -0.050        -0.039         -0.014        -0.005          -0.002
                            (0.107)      (0.021)        (0.158)  (0.041)       (0.021)        (0.016)       (0.002)         (0.002)
Coops within 100 Miles       -0.009        0.003         -0.079   -0.008        -0.008         -0.003        -0.001          -0.000
                            (0.021)      (0.004)        (0.054)  (0.006)       (0.007)        (0.002)       (0.001)         (0.000)
Large Firm                    0.609       0.136*         -0.244   0.512*         0.291          0.204         0.033          0.032*
                            (0.320)      (0.059)        (1.133)  (0.257)       (0.210)        (0.115)       (0.021)         (0.015)
No Expertise                  0.481        0.031         -1.329   -0.099        -0.106         -0.069         0.012          -0.001
                            (0.381)      (0.036)        (1.247)  (0.135)       (0.245)        (0.085)       (0.031)         (0.006)
Year Fixed Effects            YES          YES            YES      YES           YES            YES           YES             YES
Note. N = 916 in odd-numbered models and 3,158 in even-numbered models. Heteroskedasticity-robust standard errors are reported in
parentheses. Models specified using 100-mile distance variables.
* p < .05, ** p < .01




                                                                 40
     APPENDIX A: THE PUBLIC CONTRACTING PROCESS FOR INNOVATION



       The public contracting process for innovation operates similarly for grants and for

cooperative agreements. The process unfolds as each government agency strives to accomplish

its research agenda, which itself is driven by the agency’s strategic plans, input from scientific

review boards, legislative mandates, and/or current exigencies. An agency is allocated funds

from Congress. Some of these funds are earmarked for specific research areas; the bulk are to be

allocated at the agency’s discretion. Given its agenda, the agency identifies a particular research

project of interest and posts a Request or Call for Proposals (CFP) to the public. The CFP usually

specifies the nature of the research, the desired deliverables, the general process for oversight,

and the anticipated maximum amount of the grant/cooperative agreement. Firms (and other

organizations) then submit proposals; coincidentally, the funding amount specified in almost all

submitted proposals is exactly the anticipated maximum amount in the CFP. The proposals are

then evaluated by agency personnel according to the criteria specified in the CFP, which includes

metrics on the ability of the proposed researchers to successfully meet the objectives of the CFP.

Agency personnel can choose to award a single project (to a single applicant), or multiple

projects (to multiple applicants) that work along different paths towards the same goals. In both

grants and cooperative agreements, the proposal must specify the researchers, equipment, and

facilities to be used. Although there can be some modest “revise and resubmit” interaction

around these proposals, they normally do not entail extended negotiation/lobbying between firm

and agency.

       Although there is little room for negotiation between firm and agency once a CFP is

released, it is possible that firms lobby the agency to encourage CFPs in certain broad areas of




                                                 41
research. (That said, the firm would still need to be awarded the proposal in a competitive

process.) Also, although these projects are intended to support an agency’s overall research

agenda, it is possible that agency researchers favor CFPs in certain fields because this allows

them to pursue their pet research. For the purposes of our study, the main question is: would such

distortions affect the governance or performance of research projects in a way that conflates our

results?

       For example, if innovative firms are influential and also prefer cooperative agreements,

then we might find that cooperative agreements yield more patenting than grants simply because

“better” firms are lobbying the agency for projects that will be governed as cooperative

agreements. We offer partial assurance here. Theoretically, if a firm is influential enough to

affect the subject matter of a CFP, one might expect that it is also influential enough to affect the

governance choice. Which governance form would a firm prefer – the grant, in which it has great

freedom to operate, or a cooperative agreement, in which it operates under the eye of

government personnel? Most theoretical lenses suggest that the firm would prefer the lower-

monitoring grant form. This would bias against the results that we find. Empirically, in a

robustness check that includes firm random effects, we find that cooperative agreements still

outperform grants at a level comparable to that of the main results. Although neither of these is

dispositive, it suggests that firm influence/preferences are not driving our results.

       Alternatively, if agency personnel prefer to govern research contracts as cooperative

agreements when the projects involve high-status firms or high-upside projects, then again we

might find that cooperative agreement generate more patents because “better” projects are set up

as cooperative agreements. As noted above, our robustness test with firm random effects

suggests that our main results are not driven by better firms. As for better projects, two questions




                                                 42
arise. Are better projects routed to cooperative agreements? Why doesn’t the agency permit all

research to be governed by cooperative agreements and credit claim over all innovation if then

funds?

         There are a number of reasons why this is an unlikely outcome, and that grants and

cooperative agreements are sorted appropriately based on government research contribution.

First, legislation specifies that cooperative agreements must have a “substantial” contribution by

the government agency. The contribution of the government in research must be specified in

writing in the proposal. This, in turn, requires researchers who are qualified to conduct the

research, which the government may not have. Thus, there are ex ante gates, before the research

begins, to ensure that substantial government cooperation is featured in the research. Second,

although there is no clear criteria in the legislation or regulations specifying how “substantial”

involvement is measured, government officials who merely claim collaboration when such

collaboration is lacking, risk running afoul of the law and becoming subject to severe penalties.

Auditing of researcher time certification, whistleblowing, and inspector general investigations

are all mechanisms by which such illegal behavior would be discovered. Third, in a career

concerns model, government officials are generally risk averse and extremely concerned about

downside outcomes. If a research project unravels and receives substantial negative press, the

researchers in the agency who are supposed to be (but are not really) engaged in the purported

collaborative agreement, will be found equally culpable of research failures as the researchers

who were engaged in the project, subjecting them to lower probabilities of promotion. The latter

two critiques might be remedied if the researchers had time to engage in each research project in

a significant way. However, researchers encounter time constraints to their involvement, as noted

in the paper. In fact, in Table 2, we control for the time effects by including a measure of the




                                                 43
number of collaborative agreements to the number of personnel. Overall, it is unlikely that

government researchers would have the incentive to classify projects as cooperative agreements

without their substantial contribution to the direction and content of the work.




Cited:

De Figueiredo JM, Silverman BS. 2007. How Does the Government (Want to) Fund Science?
    Politics, Lobbying and Academic Earmarks. In Science and the University, Stephan P,
    Ehrenberg RG (eds). University of Wisconsin Press: 36–51.
Hegde D, Mowery DC. 2008. Research Funding: Politics and Funding in the U.S. Public
    Biomedical R&D System. Science 322(5909): 1797–1798.




                                                44
            APPENDIX B: DATA, METHODS, AND ROBUSTNESS CHECKS




       This appendix provides additional details about the data and methods used in this study.

It then provides additional details about a series of robustness checks designed to further test our

predictions and to test alternative explanations. It is divided into three sections: Data, Methods,

and Robustness Checks.



Data

Correlation matrices

       The correlation matrices for our sample appear in Table B1.



Missing Project Descriptions

       As discussed in the text, 31.2% of funding agreements (i.e., 1,271 of 4,074) lack a match

with any of the 59 knowledge areas identified using OPM job titles. There are two reasons this

may be the case: (1) either there was text in the description field of a project’s record that did not

include any of the keywords used to identify subject matter expertise (24% of missing cases), or

(2) a description was entirely missing (76% of missing cases). When we initially downloaded the

agreement data from USASpending.gov, a considerable number of project descriptions were

missing. To address this, we searched the Federal Procurement Data System (FPDS;

www.fpds.gov) ATOM feed, a searchable Application Programming Interface (API) for

government spending records, for project descriptions based on the federal award ID number

included in the agreement records. We also searched the NIH RePORTER system




                                                 45
(https://projectreporter.nih.gov/), a similar system for several other agencies. While this

improved our data coverage, roughly 900 contracts continue to omit descriptions.

        In the analyses presented in the paper, we control for the lack of match to any of the 59

areas of expertise by including the dummy variable No Expertise (coded 1 for no match found),

but this does not discriminate between the two sources of non-matching discussed above. To

ensure that the type of non-matching does not materially affect the outcomes reported, we re-

estimated all models under two alternative specification: (1) including a second dummy variable

to indicate whether or not any text was included in the project description field from USA

spending; and (2) after dropping all cases without text in the description field. Under both

specifications, substantive results remain consistent with those reported in the main paper: for

example, the coefficient on Personnel Expertise Ratio in the first-stage = 0.618 and 0.617 in the

respective models (p < 0.001), and the marginal effect of Cooperative Agreement in the second

stage for contracts that are organized as cooperative agreements = 0.189 and 0.184, respectively

(p < 0.001).



Methods


Explanation of inverse probability weighted regression with adjustment (IPWRA)

        Here we outline the general approach to IPWRA.24 Consider each agreement that is

chosen for treatment, ! ∈ {0,1}. The potential outcome of the treatment is denoted as yt. As

researchers, we are interested in three parameters: the mean potential outcome, () = +(-) ); the

average treatment effect, /) = +(-) − -1 ); and the average treatment effect on the treated 2) =



24
  A more detailed discussion of the conceptual and mathematical underpinnings can be found in Greene (2012),
Cameron and Trivedi (2009), Imbens and Wooldridge (2009), and Angrist and Krueger (2001)..


                                                      46
+(-) − -1 |! = 1).25 To derive these values, we need to implement estimating equations for the

treatment equation and outcome equation. Estimating equations solve systems of equations to

computer the estimates of these parameter values, based on the functional forms for the probit. In

particular, if 4(5, !, 6) ) is the conditional mean for the outcome y conditional of covariates x and

treat level t, then + (7|5, !) = 4(5, !, 6) ) where 6) are the paremeters of the condition mean

model given the treatment model given the treatment t=1. For both of these equations, we use

probit models where the functional form for outcome model (see Stata 2014 Reference Manual).

           The estimators are derived through the estimating equations for the treatment model and

outcome model using quasi-maximum likelihood approaches. There are two general approaches

to solving these models. The first is regression adjustment methods. Regression adjustment

estimators estimate the effect parameters using the means of the observation-level predictions of

the condition means on the outcome. The second method, using inverse probability weighting,

develops estimators to determine the effect parameters using the means of the observed

outcomes weighted by their inverse probability of being treated. We incorporate both methods

using the inverse probability weighting with regression adjustment used by Cattaneo (2010) and

Cattaneo et al. (2013).

           These types of treatment models have additional attractive properties for our purposes.

First, they allow for different models predicting the treatment and outcome. Second, they are

econometrically identifiable from both functional form and instruments. In our case, we have an

instrument which is predictive of the choice of agreement form, but uncorrelated (except through

agreement form) with the probability of obtaining a patent. Third, these models are “double

robust.” This means that even if one of the treatment or outcome models is not fully specified,



25
     The no-treatment level is zero.


                                                   47
the estimates are still consistent. Fourth, they allow for different estimates of the variables of

interest in the treated and non-treated group. This would seem to be important as projects which

are selected into cooperative agreements may have different characteristics than those that are

chosen for grant agreements. The effect of each of the variables in the treatment equation may be

different in each circumstance.



Robustness Checks

Alternatives to the IPWRA method

       We argued above that the IPWRA method possesses numerous qualities that make it the

most appropriate statistical method for our research question and data. Nevertheless, to

demonstrate that the results are not an artifact of this statistical approach, we present results

using alternative econometric methods. Each model we discuss is successively closer to the type

of estimation procedure our data require. However, each entails tradeoffs that make them

second-best alternatives.

       We begin by considering single-stage, “naïve” probit models, both with and without year

fixed-effects, present in Table B2. In both models, Cooperative Agreement is positive as

expected (p = 0.000). These models are straightforward, but risk being misidentified due to

endogeneity between the treatment (agreement form) and outcome (patenting) variables. To

alleviate concerns over endogeneity, we next turn to alternative two-stage estimation methods,

more analogous to the IPWRA method we employ in the paper. These results are presented in

Table B3.

       The first two-stage candidate is two-stage least squares (2SLS) with instruments. This

estimation procedure linearizes the probability function in both the first stage and second stage.




                                                  48
However, when applied to binary outcome data, this method produces increasingly incorrect

parameter estimates as the probability mass moves away from the center of the probability

distribution (Wooldridge 2002). In our setting, the mean for the patent-creation probability

distribution is 0.13, indicating that the probability mass is beginning to get into the tails of the

probability distribution. Nevertheless, in Table B3, Model 1, we provide estimates for the both

stages of a two stage least squares (2SLS) linear probability model (LPM) estimation. The

coefficient on Coop Agreement becomes indistinguishable from zero. In the first-stage, the

coefficient on Personnel Expertise Ratio remains positive and significant (p = 0.001). We note

that the mean for cooperative agreement is 0.23, substantially closer to the center of the

probability distribution.

         A second approach is to use a two-stage probit model with instrumental variables. This

method cannot derive unbiased or consistent point estimation of coefficients except under a set

of very restrictive assumptions (Chesher, 2010). One solution to this problem is to linearize the

first stage of the regression and use instrumental-variables probit for the second stage.26 Of

course, linearizing the first stage is problematic, for the reasons noted above. Nevertheless,

Model 2 in Table B3 presents the results using this estimation procedure, following the three-

step approach outlined in Wooldridge (2010) and Adams et al. (2009). The instrument Personnel

Expertise Ratio, employed in a single-stage probit, is positive and significant (p = 0.000) in

predicting cooperative agreement adoption. The effect of Coop Agreement on patent generation

is positive and significant (p = 0.002).

         A third statistical approach is to use bivariate probit estimation. The bivariate probit



26
  The converse is infeasible; if one uses a probit estimation in the first stage and then OLS in second stage, then the
coefficients in the second stage will be incorrect. This is popularly known as the “forbidden regression” (Angrist and
Pischke, 2009: 109).


                                                          49
allows for correlation between the first- and second-stage error terms (Greene, 2012). Moreover,

similar to the IPWRA model, instruments in the first stage lead to a more precisely estimated

coefficient in the second stage. Although the bivariate probit also has several attractive features,

not least of which is that its statistical properties are well understood, it does have some

limitations. The relevant concern in our setting is that it assumes (i.e., forces) the treatment effect

to be equal across both the treated and untreated groups, providing only one set of second stage

coefficients (Lokshin and Sajaia, 2011). Model 3 presents results from a bivariate probit

estimation. Again, Personnel Expertise Ratio is positively related to cooperative agreement

selection, and again Coop Agreement is positively related to patent generation.

        A final emerging estimation technique for binary choice models with endogenous binary

regressors with instruments is to use FIML (Lokshin and Sajaia, 2011). This technique relies on

joint normality of the error terms in the treatment and outcome equations. Lokshin and Sajaia

(2011) show that, with good instruments in the first stage, this method produces estimated

coefficients that are very close to the true coefficients in Monte Carlo simulations. This method

also allows for the treatment effects to differ across the treated group and untreated group. Model

4 presents results of a FIML model, known as a “switch probit” in Stata parlance. Again,

Personnel Expertise Ratio is positively related to cooperative agreement selection, and again

Coop Agreement is positively related to patent generation.

        Overall, then, three out of four alternative two-stage empirical methods generate results

that are qualitatively similar to those of the IPWRA method. Given that the method that did not

replicate the results is also the least suitable for our data, we conclude that the core results of the

paper are generally robust to alternative estimation procedures.




                                                  50
Alternative cutoffs for geographic proximity

       Another potential concern regarding our analysis is that our results may depend on the

geographic range we consider when identifying relevant, local government personnel. Four of

our independent variables and our instrumental variable are all based on geographic proximity,

which necessitates an arbitrary decision regarding what distance is “proximate” – a day’s

roundtrip by a government scientist (4 hours of driving). We rely above on a radius of 100 miles

from the focal location of research work as the default distance – that is, the personnel counted as

potentially relevant to the agreement being carried out must work for the sponsoring agency

within 100 miles of the principal worksite indicated in the agreement. Perhaps 100 miles is an

overly stringent or optimistic threshold for collaborative work on a contract-research project. We

therefore re-estimate our primary model, the two-stage IPWRA probit reported in Models 2A

and 2B of Table 2 (main paper), using variables based on thresholds of 200, 300, 400, and 500

miles. The coefficients on Coop Agreement are presented in Table B4, along with the first-stage

coefficients on our instrumental variable in the selection model.

       In every model, the coefficient on Coop Agreement remains positive and significant (p =

0.000 in all models). The magnitudes of the coefficients remain relatively consistent, and close to

the increased probabilities of 27% for cooperative agreements and 8% for grants reported above.

The coefficient on the instrument, Personnel Expertise Ratio, retains similar magnitude

throughout all models. In unreported models, we also re-estimated the non-instrumented single-

stage probit model reported in Model 2 for 200-, 300-, 400-, and 500-mile specifications. Our

core result is robust against geographic manipulation in multiple model specification methods.




                                                51
Appropriateness of instrumental variable

       To be a valid instrument, Personnel Expertise Ratio must be correlated with the

endogenous regressor, Coop Agreement, and orthogonal to the error term in the main equation.

Table B5, Model 1 reports a single-stage probit model predicting patent generation with

coefficients converted to marginal effects, which is identical to Model 2 in Table B2 except that

it includes the instrument as an independent variable. The coefficients on all of the variables

common to the two models are little. Of particular importance, though, is that Personnel

Expertise Ratio exhibits no direct relationship with Generates Patent. Indeed, the BIC for Table

B5, Model 1 is slightly larger than the BIC for Table B2, Model 2, showing that including the

personnel expertise variable worsens model fit rather than improving it. In every two-stage

model specification reported in this paper, Personnel Expertise Ratio continues to be a positive

and significant predictor of Coop Agreement (p < 0.003 in all models).

       As discussed in the main paper, we elected to employ inverse-propensity weighted

regression adjustment (IPWRA) in our primary analysis to account for covariate imbalance.

IPWRA is a “doubly robust” estimation method, in that it gives “the analyst two chances to ‘get

it right’” (Morgan and Winship, 2015: 234). Furthermore, on the chance that agreement type

(cooperative versus grant) is endogenous to our main outcome variable (patent generation), we

include an instrument for selection into the cooperative agreement format – a continuous

measure of locally available government personnel in the relevant bureau with the relevant

expertise. Nevertheless, one might wonder what if any of our first-stage independent variables

are correlated with this instrument. Based on the correlations presented in Table B1, three right-

hand side variables are correlated above 0.3 with our instrument: No Expertise, Coops-to-

Personnel Ratio, and Early Stage Personnel.




                                                52
       As long as the instrument (Personnel Expertise Ratio) is not correlated with the errors of

our final outcome of concern (patent generation), it remains a valid instrument, known as a

“conditional instrumental variable” (Morgan and Winship, 2015: 298–299) in the presence of

correlation with other first-stage variables. The minimal correlation between the variables and

the lack relationship between Personnel Expertise Ratio and Generates Patent in Table B5

indicates this assumption is valid.

       However, we can model the data under the assumption of endogenous regressors for the

instrument in addition to a potentially endogenous treatment variable using an extended

regression models (ERMs). ERMs allow for multiple, simultaneous equations to be estimated

accounting for both endogenous treatment assignment and endogenous predictors of an

instrumental variable (Wooldridge, 2010). We fit a three-equation model using the same

functional setup as Table 2 in the main paper, but include an additional equation specifying that

Personnel Expertise Ratio be regressed on No Expertise, Coops-to-Personnel Ratio, and Early

Stage Personnel under the assumption of endogeneity; heteroscedasticity-robust standard errors

are included as an additional precaution. Results are reported in Table B6.

       Functionally, the results do not change. First, the instrument remains positive in

predicting treatment assignment (p = 0.000). Second, the treatment (cooperative agreement form)

remains a positive predictor of patent generation (p = 0.000). Furthermore, using Stata’s post-

estimation commands, we can estimate that the average treatment effect on the treated (ATET) is

a 28.2% increase in the likelihood of patent generation (p < .001), which is slightly larger than

the effect reported in Table 2 (main paper). Finally, the ERM method also evaluates error

correlations between dependent variables; important for our concerns is that the errors for




                                                53
personnel expertise are uncorrelated with patent generation, further supporting our use of this

variable as an instrument.



Temporal Variance

       Although there are multiple paths to analyzing the data, we opt for a strategy that

minimizes variation between observations (via inverse-probability weighting in the first stage of

our two-stage models) in order to achieve covariate balance between cooperative agreements and

grants. An alternative is to examine within-firm and/or time-period specific changes. We do this

in part in our current analyses by including fiscal year fixed effects in all primary analyses.

These year fixed effects capture variance due to government-wide or economy-wide events due

to the time period, such as the economic recession and government response in 2008-2009. In the

first-stage Model 1 (Table 2, main paper), the yearly coefficients are indeed negative during FYs

2008-2010, suggesting the government was more likely to issue grants over cooperative

agreements (which was the case throughout, shown by the higher proportion of agreements that

were grants).

       However, a major initiative of the federal government during this time was to stimulate

spending via the American Recovery and Reinvestment Act (ARRA). This stimulus package was

distributed over multiple fiscal years, and so might have effects not captured by year dummy

variables, in particular in the choice of issuing grants rather than cooperative agreements (i.e., the

ARRA could be an omitted variable in our first-stage, treatment-assignment model). While this

is not a concern as long as our covariate balance estimates are valid or as long as our

instrumental variable is valid, it is possible to determine if the ARRA had an effect in our data,

as agreement records indicate whether or not they were funding via the ARRA specifically. In




                                                 54
our sample, 291 agreements (7.14%) were flagged as stemming from the ARRA. Of those, 210

(72.16%) were cooperative agreements, rather than grants. Including a dummy variable (coded 1

if an agreement was supported by the ARRA) in the first and second stage models does not

materially affect any of our results, and is not statistically significant at a = 0.05 in predicting

agreement form (b = -0.239).



Bureau-Level Differences

        Another concern that may arise is that governmental units (“bureaus” in our discussion,

which correspond to the level of government just below agencies; e.g., the Centers for Disease

Control and Prevention is a bureau of the Health and Human Services agency) may influence

results in a manner not adequately captured without bureau fixed-effects. We are unable to use

bureau fixed-effects in our analysis because it introduces too much missing data. In the treatment

effects setup, models are fit separately (but relatedly) to the treatment and control conditions, so

if a bureau does not have sufficient coverage on all variables in both conditions, we do not

observe a sufficient number of both treatment and control cases in for each variable in our model

to accurately estimate a treatment effect under this specification. This is, fundamentally, the

problem of causal inference caused by missing data in non-experimental studies (Rosenbaum and

Rubin, 1983).

        One method for addressing causal concerns in the presence of missing and unbalanced

data is entropy balancing (Hainmueller, 2012; Hainmueller and Xu, 2013). Entropy balancing

overcomes observational differences in a manner similar to propensity score weighting, but with

increased flexibility and greater use of information. Important for our concerns, “Since the

entropy balancing weights vary smoothly across units, they also commonly retain more



                                                  55
information in the preprocessed data than other approaches” (Hainmueller and Xu, 2013: 2),

which is indeed the case in our analysis.

       We estimate entropy-balancing weights based on the first-stage covariates reported in

(main paper) Table 3, with the addition of indicators for each agency. This accounts for not only

the first-stage variables’ differences across grants and cooperative agreements, but also the

different likelihood of any bureau to use one form of support over the other. We lose 133 cases

for which entropy balancing was not possible (N = 3,941). Rather than estimating a two-stage

model, we then estimate a single-stage probit including these weights as probability weights.

Table D6 reports the results of this estimation, including the Personnel Expertise Ratio

instrument.

       There are several takeaways from Table B7. First, as in the paper, the coefficient for

cooperative agreements is positive and significant (p = 0.000), indicating that cooperative

agreement structure does enhance the likelihood of patent generation for those that were

cooperative agreements. The difference in predicted outcomes by support structure is a 21.5%

increase in the marginal likelihood that an agreement generates a patent, holding all other

variables at their mean value (this effect is equivalent to the average treatment effect, computed

using Stata’s ‘margins’ command). Furthermore, our instrument is not distinguishable from zero

in this model, which is equivalent to a second-stage regression in the two-stage least-squares

framework. This lends further support that it does not have a relationship to the final outcome, a

key concern in using it as an instrument.



Skew in patent and citation measures




                                                56
       It is well known that patenting and citation rates often are highly skewed. Our dependent

variable Generates Patent addresses this because it is a binary measure of at-least-one-patent.

Nevertheless, to explore whether our results for the other dependent variables, which are based

on patent and citation counts, are driven by skew, in Table B8 we re-estimate the basic models

using the natural logs of these dependent variables. The results are materially unchanged.



Heterogeneity in Scientist Coordination Across Grants and Cooperative Agreements

       As noted above, one alternative explanation for our predicted pattern of results is that

contract choice and innovative performance are both driven by government scientists’ ability to

collaborate with firm scientists. Specifically, when government personnel with relevant skills are

locally available, project tasks can entail greater collaboration; since federal policies stipulate

that high-collaboration endeavors be managed under cooperative-agreement contracts, then if

collaboration yields greater innovative output, cooperative agreements will be correlated with

innovative output as an artifact of collaborative activity. Although we cannot identify the specific

degree of collaboration that occurs in each research project, Coops-to-Personnel Ratio proxies

for the feasibility of collaboration by measuring the other demands on government researchers’

attention. The positive relationship between Coop Agreement and Generates Patent is unaffected

by inclusion of this proxy, thus indicating a salutary effect of cooperative-agreement governance

on innovative output beyond mere coordination in a project.



Firm Differences

       A final concern is that unobserved heterogeneity among firms may correlate with

performance of the contracts. We are unable to obtain convergence using firm fixed effects with




                                                  57
either IPWRA or entropy balancing due to sparseness of the data. We thus turn to random-effects

estimation, as this relaxes the model assumptions and makes fuller use of the data. A single-stage

random-effects model predicting patent generation is presented in Table B9. As in our primary

analysis, cooperative agreement increases the likelihood of patenting.

       An alternative form of time-varying heterogeneity across firms relates to firm experience

in contracting with the government. In Table B10 we re-estimate the probability that a contract is

governed as a cooperative agreement, controlling for the number of prior contracts the firm had

with the specific agency funding the focal contract (Model 1) or any agency (Model 2). We

further disaggregate this into prior grants and prior cooperative agreements in Models 3 and 4.

Models 1 and 2 indicate that contracts are more likely to be organized as grants the greater

number of prior contracts that a firm has had with the government. Models 3 and 4 show that a

firm’s current contract mode is likely to be similar to the mode of its prior contracts, suggesting

perhaps that there is a class of firm that is more likely to be awarded grants and another that is

more likely to be awarded cooperative agreements, or perhaps that agencies favor a modal form

that firm has experienced before. Of particular note, the inclusion of these variables does not

qualitatively change the magnitude of Personnel Expertise Ratio, and reduces the magnitude of

Early Stage Project by up to one-half in some models.




                                                 58
                                 References in Appendix B


Adams R, Almeida H, Ferreira D. 2009. Understanding the relationship between founder–CEOs
       and firm performance. Journal of Empirical Finance 16(1): 136–150.
Angrist JD, Krueger AB. 2001. Instrumental Variables and the Search for Identification: From
       Supply and Demand to Natural Experiments. The Journal of Economic Perspectives
       15(4): 69–85.
Angrist JD, Pischke J-S. 2009. Mostly harmless econometrics: an empiricist’s companion.
       Princeton University Press: Princeton.
Cameron AC, Trivedi PK. 2009. Microeconometrics using Stata. Stata Press: College Station,
       Texas.
Cattaneo MD. 2010. Efficient Semiparametric Estimation of Multi-valued Treatment Effects
       Under Ignorability. Journal of Econometrics 155(2): 138–154.
Cattaneo MD, Drukker DM, Holland AD. 2013. Estimation of multivalued treatment effects
       under conditional independence. Stata Journal 13(3): 407–450.
Chesher A. 2010. Instrumental Varaible Models for Discrete Outcomes. Econometrica 78(2):
       575–601.
Greene WH. 2012. Econometric analysis, 7th ed. Prentice Hall: Boston.
Hainmueller J. 2012. Entropy Balancing for Causal Effects: A Multivariate Reweighting Method
       to Produce Balanced Samples in Observational Studies. Political Analysis 20(1): 25–46.
Hainmueller J, Xu Y. 2013. Ebalance: A Stata Package for Entropy Balancing. Journal of
       Statistical Software 54(7): 1–18.
Imbens GW, Wooldridge JM. 2009. Recent Developments in the Econometrics of Program
       Evaluation. Journal of Economic Literature 47(1): 5–86.
Lokshin M, Sajaia Z. 2011. Impact of interventions on discrete outcomes: Maximum likelihood
       estimation of the binary choice models with binary endogenous regressors. Stata Journal
       11(3): 368–385.
Morgan SL, Winship C. 2015. Counterfactuals and Causal Inference: Methods and Principles
       for Social Research, 2nd ed. Cambridge University Press: New York.
Rosenbaum PR, Rubin DB. 1983. The Central Role of the Propensity Score in Observational
       Studies for Causal Effects. Biometrika 70(1): 41–55.
Wooldridge JM. 2010. Econometric analysis of cross section and panel data, 2nd ed. MIT Press:
       Cambridge, MA.




                                              59
                                                  Table B1: Correlation Matrices
Panel A: Spearman Correlation Matrix – All Agreements
Variable                       (1)      (2)       (3)     (4)           (5)      (6)      (7)      (8)      (9)    (10)    (11)
1. Generates Patent           1.000
2. Coop Agreement             0.329    1.000
3. Personnel Expertise Ratio  0.043    0.180     1.000
                   a
4. Federal Funding            0.179    0.189    -0.035    1.000
                        a
5. Firm/Total Funding         0.216    0.495     0.085    0.157         1.000
                      a
6. Prior Year Patents         0.102    0.390     0.121    0.046         0.300    1.000
7. Large Firm                 0.277    0.587     0.123    0.131         0.462    0.551    1.000
8. No Expertise              -0.171   -0.265    -0.358   -0.013        -0.137   -0.244   -0.248    1.000
9. Coops/Personnel Ratio      0.074    0.298     0.556   -0.053         0.147    0.184    0.271   -0.242   1.000
10. Early Stage Personnel     0.055    0.164     0.502    0.007         0.083    0.083    0.106   -0.235   0.284   1.000
11. Coops within 100 Miles    0.151    0.416     0.261   -0.021         0.271    0.289    0.346   -0.386   0.606   0.192   1.000

Panel B: Spearman Correlation Matrix – Cooperative Agreements Only
Variable                       (1)      (2)       (3)      (4)       (5)         (6)      (7)      (8)      (9)    (10)    (11)
1. Generates Patent           1.000
2. Coop Agreement               .        .
3. Personnel Expertise Ratio -0.102      .       1.000
                   a
4. Federal Funding            0.229      .      -0.132    1.000
                        a
5. Firm/Total Funding         0.035      .      -0.028    0.054     1.000
                      a
6. Prior Year Patents        -0.148      .      -0.022   -0.139     0.100        1.000
7. Large Firm                 0.133      .      -0.082    0.032     0.196        0.320    1.000
8. No Expertise              -0.010      .      -0.278   -0.090    -0.046        0.021   -0.061    1.000
9. Coops/Personnel Ratio     -0.153      .       0.229   -0.143    -0.077        0.039    0.048    0.039   1.000
10. Early Stage Personnel    -0.118      .       0.537   -0.051    -0.049       -0.010   -0.201   -0.153   0.043   1.000
11. Coops within 100 Miles   -0.096      .       0.031   -0.105     0.042        0.310    0.111    0.018   0.357   0.110   1.000



                                                                  60
                                              Table B1: Correlation Matrices (continued)


Spearman Correlation Matrix – Grants Only
Variable                       (1)      (2)        (3)      (4)          (5)     (6)       (7)     (8)      (9)    (10)    (11)
1. Generates Patent           1.000
2. Coop Agreement               .        .
3. Personnel Expertise Ratio  0.087      .        1.000
4. Federal Fundinga           0.065      .       -0.040    1.000
5. Firm/Total Fundinga        0.063      .        0.052    0.013        1.000
6. Prior Year Patentsa        0.033      .        0.091    0.021        0.137    1.000
7. Large Firm                 0.096      .        0.109    0.001        0.301    0.426    1.000
8. No Expertise              -0.134      .       -0.545    0.072        0.019   -0.189   -0.138    1.000
9. Coops/Personnel Ratio      0.088      .        0.469   -0.095        0.100    0.153    0.145   -0.357   1.000
10. Early Stage Personnel     0.091      .        0.495   -0.002        0.063    0.031    0.129   -0.230   0.185   1.000
11. Coops within 100 Miles    0.130      .        0.300   -0.114        0.137    0.182    0.174   -0.413   0.791   0.190   1.000


   a
       z-score standardized




                                                                   61
              Table B2: Single-Stage Probit Estimation
Variable                                        Model 1       Model 2
Cooperative Agreement                             0.705**       0.763**
                                                  (0.075)       (0.075)
Federal Funding                                   0.069**        0.061*
                                                  (0.026)       (0.026)
Firm/Total Funding                                 0.009          0.033
                                                  (0.026)       (0.027)
Prior Year Patents                                -0.075*       -0.064*
                                                  (0.031)       (0.028)
Coops/Personnel Ratio                            -0.051**      -0.054**
                                                  (0.019)       (0.019)
Coops within 100 Miles                             0.005         -0.002
                                                  (0.003)       (0.003)
Early Stage Personnel                              0.242          0.375
                                                  (0.377)       (0.378)
Large Firm                                        0.445**       0.462**
                                                  (0.075)       (0.077)
No Expertise                                     -0.472**      -0.254**
                                                  (0.075)       (0.095)
Fiscal Year Fixed Effects                           NO            YES
Observations                                       4074           4074
BIC                                              2662.019      2602.842
Pseudo R2                                          0.159          0.210
Note. Heteroskedasticity-robust standard errors are reported in
parentheses.
* p < .05, ** p < .01




                                  62
Table B3. Methodological Robustness Checks: Comparison of Two-Stage Estimation Procedures

                                                   First-Stage Models
                            Model 1    Model 2         Model 3            Model 4
Variable
                               2SLS    2S/3S IV        Bi-probit        Switch Probit
Personnel Expertise Ratio    0.160**    0.113**         0.673**            0.656**
 (Instrument)                (0.047)    (0.029)         (0.163)            (0.175)
Federal Funding                0.016      0.007           0.041              0.034
                             (0.012)    (0.006)         (0.035)            (0.034)
Firm/Total Funding           0.089**    0.050**         0.277**            0.289**
                             (0.008)    (0.005)         (0.030)            (0.032)
Prior Year Patents            -0.002      0.001           0.008             -0.001
                             (0.008)    (0.004)         (0.025)            (0.025)
Coops/Personnel Ratio         -0.001     -0.001          -0.002             -0.007
                             (0.004)    (0.002)         (0.014)            (0.014)
Coops within 100 Miles       0.006**    0.003**         0.017**            0.020**
                             (0.001)    (0.001)         (0.003)            (0.003)
Early Stage Personnel        0.186**    0.175**         1.033**            0.792**
                             (0.067)    (0.048)         (0.266)            (0.256)
Large Firm                   0.362**    0.324**         1.272**            1.280**
                             (0.021)    (0.021)         (0.068)            (0.066)
No Expertise                -0.128**   -0.111**        -0.663**           -0.634**
                             (0.017)    (0.014)         (0.088)            (0.083)
Fiscal Year Fixed Effects      YES        YES             YES                 NO

                                                  Second-Stage Models
                                                                   Model 4A     Model 4B
                            Model 1    Model 2        Model 3
                                                                 Switch Probit Switch Probit
                             2SLS      2S/3S IV       Bi-probit
                                                                     Coops        Grants
Coop Agreement                -0.118   1.726**         0.240**      0.281**      0.081**
                                                               a            b
                             (0.258)   (0.545)         (0.142)      (0.079)      (0.074)b
Federal Funding              0.026**     0.043          0.069*        0.070        0.059
                             (0.010)   (0.029)         (0.028)      (0.038)      (0.037)
Firm/Total Funding             0.035    -0.057         0.095**       -0.035        0.057
                             (0.025)   (0.060)         (0.026)      (0.074)      (0.075)
Prior Year Patents          -0.017**   -0.062*         -0.060*       -0.055       -0.090
                             (0.006)   (0.028)         (0.027)      (0.036)      (0.055)
Coops/Personnel Ratio       -0.014**   -0.051*        -0.053**     -0.067**       -0.014
                             (0.004)   (0.020)         (0.018)      (0.029)      (0.026)
Coops within 100 Miles         0.001    -0.008           0.002        0.001        0.005
                             (0.002)   (0.005)         (0.003)      (0.006)      (0.005)


                                            63
Early Stage Personnel                0.079          0.145          0.541          -2.039        0.772*
                                   (0.099)        (0.405)         (0.364)        (1.101)        (0.373)
Large Firm                          0.213*          0.067         0.745**          0.371         0.201
                                   (0.096)        (0.255)         (0.071)        (0.439)        (0.191)
No Expertise                        -0.053         -0.077        -0.391**          0.003       -0.260*
                                   (0.041)        (0.149)         (0.093)        (0.268)        (0.128)
Year Fixed Effects                   YES            YES             YES             NO            NO
Observations                         4,074          4,074            4,074                  4,074
Note. Heteroskedasticity-robust standard errors are reported in parentheses.
a
  t-statistic of difference in predicted probability of patent generation by agreement type
b
  t-statistic of difference in estimated treatment effect by agreement type
* p < .05, ** p < .01




                                                     64
             Table B4. Two-Stage IPWRA Probit Results, Sensitivity to Different Thresholds for Geographic Proximity
                                           (dependent variable: Generates Patent)

                               100 Miles              200 Miles              300 Miles              400 Miles              500 Miles

                          Co-ops       Grants    Co-ops       Grants    Co-ops       Grants     Co-ops      Grants     Co-ops      Grants
Coop Agreement            0.278**     0.083**    0.269**     0.085**    0.272**     0.083**     0.273**    0.084**     0.264**    0.085**
                          (0.032)     (0.006)    (0.031)     (0.006)    (0.029)     (0.006)     (0.029)    (0.006)     (0.028)    (0.007)

First-stage Personnel             0.651**               0.471**                 0.346**                0.572**                0.639**
 Expertise Instrument             (0.165)                (0.137)                 (0.123)                (0.109)               (0.109)
Note. Heteroskedasticity-robust standard errors are reported in parentheses. All independent variables from Table 2 are included in
estimation, but coefficients are not reported.
** p < .01




                                                                  65
 Table B5. Single-Stage Probit Estimation of Patent
Generation, With Instrument as Independent Variable

Variable                                Model 1

Coop Agreement                           0.125**
                                         (0.012)
Personnel Expertise Ratio                 -0.030
                                         (0.028)
Federal Funding                           0.010*
                                         (0.004)
Firm/Total Funding                         0.005
                                         (0.004)
Prior Year Patents                       -0.010*
                                         (0.005)
Coops/Personnel Ratio                   -0.009**
                                         (0.003)
Coops within 100 Miles                    -0.000
                                         (0.001)
Early Stage Personnel                      0.065
                                         (0.061)
Large Firm                               0.083**
                                         (0.015)
No Expertise                            -0.041**
                                         (0.013)
Year Fixed Effects                          Yes
N                                          4,074
          2
Pseudo R                                   0.211
BIC                                        2,610
Note. Heteroskedasticity-robust standard errors are
reported in parentheses.
* p < .05, ** p < .01




                           66
                    Table B6: Three-Equation Endogenous Treatment Extended Regression Model

    Model                                 Variable         Coefficient   Robust SE   z-statistic   p-value
                               Federal Funding                0.050        0.026        1.93        0.054
                               Firm/Total Funding            -0.018        0.035       -0.51        0.610
  Final-Stage Model
  (Predicting Patent




                               Prior Year Patents
   Generation = 1)




                                                             -0.061        0.028       -2.19        0.029
                               Coops/Personnel Ratio         -0.054        0.019       -2.79        0.005
                               Coops within 100 Miles        -0.005        0.004       -1.54        0.123
                               Early Stage Personnel          0.253        0.374        0.68        0.498
                               Large Firm                     0.241        0.120        2.01        0.045
                               No Expertise                  -0.154        0.103       -1.50        0.134
                               Coop Agreement                 1.330        0.253        5.26        0.000
  Treatment Assignment Model




                               Personnel Expertise Ratio      0.735        0.233        3.15       0.002
     (Predicting Cooperative




                               Federal Funding                0.036        0.035        1.04       0.300
                               Firm/Total Funding
         Agreement = 1)




                                                              0.291        0.033        8.96       0.000
                               Prior Year Patents             0.002        0.024        0.08       0.937
                               Coops/Personnel Ratio         -0.004        0.014       -0.28       0.777
                               Coops within 100 Miles         0.019        0.003        5.74       0.000
                               Early Stage Personnel          0.940        0.280        3.36       0.001
                               Large Firm                     1.267        0.068       18.66       0.000
                               No Expertise                  -0.650        0.093       -7.03       0.000

              Early Stage Personnel                           0.147        0.049        2.98       0.003
  Predicting
  Personnel
   Ratio IV




              Coops/Personnel Ratio                           0.003        0.001        2.84       0.005
              No Expertise                                   -0.082        0.004      -22.68       0.000
              Constant                                        0.082        0.004       22.34       0.000
Note. N = 4,074




                                                           67
Table B7: Entropy-Balanced Probit Estimation Predicting Patent Generation
Variable                       Coefficient Robust SE z-statistic p-value
Coop Agreement                    0.215      0.029      7.39      0.000
Personnel Expertise Ratio         0.029      0.071      0.41      0.684
Federal Funding                   0.019      0.005      4.11      0.000
Firm/Total Funding                0.031      0.012      2.63      0.008
Prior Year Patents               -0.023      0.015     -1.52      0.129
Coops/Personnel Ratio            -0.015      0.008     -1.92      0.055
Coops within 100 Miles            0.002      0.001      1.86      0.063
Early Stage Personnel             0.177      0.139      1.28      0.202
Large Firm                        0.004      0.045      0.09      0.930
No Expertise                     -0.048      0.038     -1.24      0.213
Note. Year fixed-effects included. N = 3,941




                                   68
          Table B8. Second-Stage IPWRA Results of Logged Patent Generation and Quality Outcomes
                                  Num. Patents       Citation-Weighted
                                                                             Citations/Patent       Citations//Year
                                   Generated               Patents
Variable                       Model 1 Model 2 Model 3 Model 4 Model 5 Model 6 Model 7 Model 8
Cooperative Agreement          0.293** 0.079** 0.459** 0.086** 0.352** 0.070** 0.082** 0.017**
                                (0.032)    (0.007)     (0.044)     (0.011)    (0.037)  (0.008)    (0.010)      (0.002)
Note. Heteroskedasticity-robust standard errors are reported in parentheses. Odd-number models report point estimates
for cooperative agreement analyses; even-number models report point estimates for grant analyses.
** p < .01




                                                          69
                                   Table B9:
Single-Stage Probit Predicting Patent Generation with Firm Random-Effects
Variable                       Coefficient Robust SE z-statistic        p-value
Coop Agreement                    0.192        0.020         9.46         0.000
Fed. Funding                      0.016        0.006         2.56         0.011
Firm-to-Total Funding             0.001        0.007         0.19         0.851
Prior Year Patents               -0.027        0.012        -2.21         0.027
Coops-to-Personnel Ratio         -0.004        0.005        -0.77         0.440
Coops within 100 Miles            0.000        0.001         0.16         0.873
Early Stage Personnel             0.075        0.123         0.61         0.539
No Expertise                     -0.067        0.025        -2.67         0.008
Note. Year fixed-effects included. 4,074 observations/383 groups. Coefficients are
predicted marginal effects.




                                       70
                                      Table B10:
     Probit Estimation of Cooperative Agreement = 1 with Prior Agreement Counts
                                          Model 1      Model 2       Model 3       Model 4
Personnel Expertise Ratio                 0.642**       0.636**      0.496**        0.501**
                                          (0.158)       (0.159)      (0.162)        (0.162)
Fed. Funding                                0.037       0.037*       0.040*         0.039*
                                          (0.020)       (0.020)      (0.020)        (0.020)
Firm-to-Total Funding                     0.255**       0.254**      0.237**        0.236**
                                          (0.027)       (0.027)      (0.027)        (0.027)
Prior Year Patents                          0.006         0.006       -0.026         -0.026
                                          (0.025)       (0.025)      (0.025)        (0.025)
Research Personnel Prop                    -0.133        -0.137       -0.091         -0.092
                                          (0.255)       (0.255)      (0.256)        (0.256)
Coops-to-Personnel Ratio                    0.005         0.006       -0.021         -0.021
                                          (0.013)       (0.013)      (0.013)        (0.013)
Coops within 100 Miles                    0.018**       0.018**      0.009**        0.010**
                                          (0.003)       (0.003)      (0.003)        (0.003)
Early Stage Personnel                     0.870*        0.853*         0.574          0.562
                                          (0.341)       (0.341)      (0.366)        (0.365)
Major Organization                        1.082**       1.075**      1.081**        1.064**
                                          (0.073)       (0.073)      (0.074)        (0.074)
No Expertise                             -0.457**      -0.457**     -0.463**       -0.461**
                                          (0.089)       (0.089)      (0.091)        (0.091)
Prior 1-Year Agency Contracts            -0.013**
                                          (0.002)
Prior 1-Year Contracts (Any Agency)                    -0.013**
                                                        (0.003)
Prior 1-Year Agency Grants                                          -0.026**
                                                                     (0.004)
Prior 1-Year Agency Coops                                            0.103**
                                                                     (0.013)
Prior 1-Year Grants (Any Agency)                                                    -0.026**
                                                                                     (0.004)
Prior 1-Year Coops (Any Agency)                                                      0.100**
                                                                                     (0.013)
Year Fixed Effects                            Yes          Yes           Yes           Yes
N = 3,724; only cases from 2001 onward used. Heteroskedasticity-robust standard errors are
reported in parentheses. Results are substantively unchanged by using a longer time window.
* p < .05, ** p < .01




                                              71
