                                 NBER WORKING PAPER SERIES




      ESTIMATING DYNAMIC DISCRETE CHOICE MODELS WITH HYPERBOLIC
      DISCOUNTING, WITH AN APPLICATION TO MAMMOGRAPHY DECISIONS

                                             Hanming Fang
                                              Yang Wang

                                         Working Paper 16438
                                 http://www.nber.org/papers/w16438


                       NATIONAL BUREAU OF ECONOMIC RESEARCH
                                1050 Massachusetts Avenue
                                  Cambridge, MA 02138
                                      October 2010




We would like to thank Peter Arcidiacono, Patrick Bayer, Han Hong, Joe Hotz, Edward Kung, Thierry
Magnac, Aprajit Mahajan, Ted O'Donoghue, Dan Silverman, Frank Sloan, Xun Tang and seminar/conference
participants at Cornell, AEA Meetings in San Francisco (2009) and Midwest Health Economics Conference
in Chicago (2010) for helpful comments and suggestions. The first draft of the paper (January 2009)
was completed when both authors were at Duke University. Fang gratefully acknowledges financial
support from NSF Grant SES 0844845. We are responsible for all remaining errors. The views expressed
herein are those of the authors and do not necessarily reflect the views of the National Bureau of Economic
Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2010 by Hanming Fang and Yang Wang. All rights reserved. Short sections of text, not to exceed
two paragraphs, may be quoted without explicit permission provided that full credit, including © notice,
is given to the source.
Estimating Dynamic Discrete Choice Models with Hyperbolic Discounting, with an Application
to Mammography Decisions
Hanming Fang and Yang Wang
NBER Working Paper No. 16438
October 2010
JEL No. C14,I1

                                            ABSTRACT

We extend the semi-parametric estimation method for dynamic discrete choice models using Hotz
and Miller's (1993) conditional choice probability (CCP) approach to the setting where individuals
may have hyperbolic discounting time preferences and may be naive about their time inconsistency.
We illustrate the proposed estimation method with an empirical application of adult women's decisions
to undertake mammography to evaluate the importance of present bias and naivety in the under-utilization
of this preventive health care. Our results show evidence for both present bias and naivety.


Hanming Fang
Department of Economics
University of Pennsylvania
3718 Locust Walk
Philadelphia, PA 19104
and NBER
hanming.fang@econ.upenn.edu

Yang Wang
Department of Economics
Lafayette College
213 Simon Center
Easton, PA 18042
wangy@lafayette.edu
1    Introduction

    Dynamic discrete choice models have been used to understand a wide range of economic be-
havior. The early dynamic discrete choice models that are empirically implemented tend to be
parametric;1 but recently, a growing list of authors have addressed the non- or semi-parametric
identification of dynamic discrete choice models. The earliest attempt in this regard is Hotz and
Miller (1993) which pioneered the approach of using conditional choice probabilities to infer about
choice-specific continuation values. Rust (1994a, 1994b) showed that the discount factor in stan-
dard dynamic discrete choice models are generically not identified; Magnac and Thesmar (2002)
expanded Rust’s non-identification results, and proposed exclusion restrictions that lead to the
identification of the standard discount factor.
    All of the above-mentioned literature model the impatience of the decision makers by assum-
ing that agents discount future streams of utility or profits exponentially over time. As is now well
known, exponential discounting is not just an analytically convenient assumption; without this
assumption, intertemporal marginal rates of substitution will change as time passes, and prefer-
ences will be time-inconsistent [see Strotz (1956, p.172)]. A recent theoretical literature has built
on the work of Strotz (1956) and others to explore the consequences of relaxing the standard as-
sumption of exponential discounting. Drawing both on experimental research and on common
intuition, economists have built models of quasi-hyperbolic discounting to capture the tendency
of decision makers to seize short-term rewards at the expense of long-term preferences.2 This lit-
erature studies the implications of time-inconsistent preferences, and their associated problems of
self-control, for a variety of economic choices and environments.3
    A small list of empirical papers that attempted to estimate dynamic models with hyperbolic
discounting time preferences have followed the parametric approach (Fang and Silverman 2009,
Laibson, Repetto and Tobacman 2007 and Paserman 2008).4 Fang and Silverman (2009) empiri-
    1
      The earliest formulation and estimation of parametric dynamic discrete choice models include Wolpin (1984) for
fertility choice, Miller (1984) for occupational choice, Pakes (1986) for patent renewal, and Rust (1987) for bus engine
replacement.
    2
      A body of experimental research, reviewed in Ainslie (1992) and Loewenstein and Elster (1992), indicates that
hyperbolic time discounting may parsimoniously explain some basic features of the intertemporal decision making
that are inconsistent with simple models with exponential discounting. Specifically, standard decision models with
exponential discounting are not easy to reconcile with commonly observed preference reversals: subjects choose the
larger and later of two prizes when both are distant in time, but prefer the smaller but earlier one as both prizes draw
nearer to the present (see Rubinstein 2003, however, for an alternative explanation of preference reversals).
    3
      For example, models of time-inconsistent preferences have been applied by Laibson (1997) and O’Donoghue and
Rabin (1999a,b) to consumption and savings; by Barro (1999) to growth; by Gruber and Koszegi (2001) to smoking de-
cisions; by Krusell, Kuruşçu, and Smith (2002) to optimal tax policy; by Carrillo and Mariotti (2000) to belief formation;
by Fang and Silverman (2004) to welfare program participation and labor supply of single mothers with dependent
children; and by Della Vigna and Paserman (2005) to job search.
    4
      Also related, Arcidiacono, Sieg and Sloan (2007) estimate a parametric forward-looking dynamic discrete choice
model of smoking and heavy drinking for late-middle age men in the Health and Retirement Studey (HRS) and find


                                                             1
cally implement a dynamic structural model of labor supply and welfare program participation
for never-married mothers with potentially time-inconsistent preferences. Using panel data on
the choices of single women with children from the National Longitudinal Survey of Youth (NLSY
1979), they provide estimates of the degree of time-inconsistency, and of its influence on the wel-
fare take-up decision. For the particular population of single mothers with dependent children,
they estimate the present bias factor and the standard discount factor to be 0.338 and 0.88 respec-
tively, implying a one-year ahead discount rate of 238%. Laibson, Repetto and Tobacman (2007)
use the Method of Simulated Moments (MSM) to estimate time preferences - both short and long
run discount rates – from a structural buffer stock consumption model that includes many realistic
features such as stochastic labor income, liquidity constraints, child and adult dependents, liquid
and illiquid assets, revolving credit and retirement. Under parametric assumptions on the model,
the model is identified from matching the model’s predictions of retirement wealth accumula-
tion, credit card borrowing and consumption-income co-movement with those observed in the
data. Their benchmark estimates imply a 48.5% short-term annualized discount rate and a 4.3%
long-term annualized discount rate. Paserman (2008) estimates the structural parameters of a job
search model with hyperbolic discounting and endogenous search effort, using data on duration
of unemployment spells and accepted wages from the NLSY 1979. Under parametric assumptions
of the model, identification of the hyperbolic discounting parameters comes from the variation in
the relative magnitude of unemployment duration and accepted wages. Indeed he finds that the
results are sensitive to the specific structure of the model and on the functional form assumption
for the distribution of offered wages. For low-wage workers, he rejects the exponential discount-
ing model and estimates a one-year discount rate of about 149%.5 Chung, Steenburgh and Sudhir
(2009) estimated a dynamic structural model of sales force response to a bonus-based compensa-
tion plan where the salesman might have hyperbolic discounting time preferences. Exploiting the
bonus-based compensation structure, they found some evidence consistent with present bias.
    None of the above papers allow for the possibility that a hyperbolic discounting decision-
maker may also be naive. More importantly, the identification of the present bias and standard
discount factors in these papers are often based on parametric assumptions imposed on the model.
To the best of our knowledge, it is not known whether dynamic discrete choice models with hy-
perbolic discounting preferences can be semi-parametrically identified using standard short-panel
that a forward-looking model fits the data (mainly the age profile for heavy-drinking and smoking) better than a my-
opic model. Their model assumes exponential discounting and thus does not incorporate the possibility that time
inconsistent preferences may play a role in the consumption of alcohol and cigarettes.
   5
     There are other inferential studies about discount rates that exploit specific clear-cut intertemporal trade-offs. For
example, Hausman (1979), and Warner and Pleeter (2001) estimate discount rates ranging from 0 to 89% depending on
the characteristics of the individual and intertemporal trade-offs at stake.




                                                            2
data that are typically used in these papers.6, 7
       In this paper, we consider a standard dynamic discrete choice model where decision makers
potentially exhibit hyperbolic discounting preferences in the form of a present-bias factor (𝛽), an
                                                                       ˜ [as in O’Donoghue and
exponential discounting factor (𝛿) and a potential naivety parameter (𝛽)
Rabin (1999a)], and examine the conditions under which the primitive parameters of the model,
including the three hyperbolic discounting time preference parameters, can be identified using
short-panel (two periods) data. We show that, if there exist exclusion variables that affect the tran-
sition probabilities of states over time but do not affect the decision-makers’ static payoff func-
tions, a condition similar to that in Magnac and Thesmar (2002) necessary for the identification
of dynamic discrete choice models with standard exponential discounting, then we can potentially
                                       ˜ and 𝛿.
identify all three discount factors 𝛽, 𝛽
       The intuition for why exclusion variables that affect the transition of state variables but not
static payoffs might provide source of identification for the discount factors can be described as
follows. Consider two decision-makers who share the same period-payoff relevant state variables
but differ only in the exclusion variables. Because the exclusion variables only affect the transition
of the payoff-relevant state variables, their effects on the choices in the current period will inform
us about the degree to which the agents discount the future. The intuition for why 𝛽, 𝛽    ˜ and 𝛿 can
be separately identified will be provided later in Section 3.2.
       We propose two estimation approaches that are intimately related to our identification argu-
ments. One approach is based on maximizing a pseudo-likelihood function and the other is based
on minimizing the estimated variation of the static payoff functions with respect to the exclusion
variables. Monte Carlo experiments show that both estimators perform well in large samples, but
in relatively small samples, the maximum pseudo-likelihood based estimator performs better. We
thus use maximum pseudo-likelihood based estimator in our empirical application.
       Our paper also represents an interesting intermediate case between the literature on estimating
dynamic discrete choice single-agent decision problems [see Miller (1984), Wolpin (1984), Pakes
(1986), Rust (1987), Hotz and Miller (1993) for early contributions and Rust (1994a, 1994b) and
Aguirregabiria and Mira (2007b) for surveys] and the more recent literature on estimating dy-
namic games [see Pakes and McGuire (1994), Pesendorfer and Schmidt-Dengler (2003), Pakes,
Ostrovsky and Berry (2007), Aguirregabiria and Mira (2007a), Bajari, Benkard and Levin (2007),
among others; and see Bajari, Hong and Nekipelov (2010) for a survey]. As is well-known, if an
agent has hyperbolic discounting time preferences, the outcome of her decision process can be
   6
      Fang and Silverman (2006) is an exception. They argue that exponential discounting and hyperbolic discounting
models are distinguishable, using an argument based on observed choice probabilities.
    7
      Mahajan and Tarozzi (2010) discuss how data about expectations regarding future behavior might be used to iden-
tify and estimate hyperbolic discounting parameters in their study of the adoption of insecticide treated nets.



                                                         3
considered as the equilibrium outcome of an intra-personal game with the players being the selves
of the same individual at different periods. There are two crucial differences, however, between the
intra-personal games we analyze for agents with time-inconsistent time preferences and those in
the existing dynamic games literature. The first difference is that in the intra-personal game case,
we do not observe the actions of all the players. More specifically, the outcomes – choices and the
evolutions of the state variables – we observe in the data are affected only by the current selves,
even though the current selves’ choices are impacted by their perception of future selves’ actions.
Secondly, the dynamic games literature [e.g. Bajari, Benkard and Levin 2007] may allow for the
different players to have different period-payoff functions, however, in our setting the payoffs
for the players – the current self and the future selves – differ only in time preferences; more-
over, under hyperbolic discounting, we are assuming a rather restricted form of time preference
differences between the players.
   We illustrate our identification argument and estimation method with an empirical applica-
tion of adult women’s decisions to undertake mammography to investigate the role of time incon-
sistent preferences in the under-utilization of this preventive care. We consider a simple model
where mammography can potentially lower the probability of death in the next two years and it
may also lower the probability of bad health conditional on surviving in two years; however, un-
dertaking mammography may involve immediate costs (most of which we would like to interpret
as psychological and physical costs instead of financial costs). For the purpose of identifying the
hyperbolic discounting preference parameters, we use several variables, including the indicator
for either the woman’s mother is still alive and/or whether she died at age greater than 70, as
the exclusion variables that do not enter the relevant instantaneous payoff function but affects the
transition probability of other instantaneous payoff-relevant state variables. Our estimates indi-
cate that individuals exhibit both present bias and naivety as 𝛽 and 𝛽˜ are estimated to be about
                                                                               ˜ > 𝛽). These sug-
0.72 and 0.99, respectively, suggesting both present bias (𝛽 < 1) and naivety (𝛽
gest that both present bias and naivety might have played an important role in the fact that nearly
25% of the women do not undertake mammography as advised by American Cancer Association,
which is universally regarded as a very cost effective way for early detection of breast cancer (see
Degnan et al. 1992).
   The remainder of the paper is structured as follows. In Section 2 we describe a general dy-
namic discrete choice model with hyperbolic discounting time preferences. In Section 3 we pro-
vide detailed analysis for identification. In Section 4, we propose two estimation strategies based
on the identification arguments for the discount factors and we also evaluate the performance of
our proposed estimation methods using Monte Carlo experiments. In Section 5 we provide the
background information for mammography, which is the decision we examine in our empirical


                                                 4
application; we also describe the data set used in our study and provide some basic descriptive
statistics of the samples; we then provide details about the empirical specification of our model
of the decision for undertaking mammography and present the main estimation results. Finally,
Section 6 concludes and discusses a few important issues abstracted away in our analysis. In the
Appendix, we provide additional details about how our identification argument can be extended
to finite horizon applications.


2        Dynamic Discrete Choice Model with Hyperbolic Discounting Time
         Preferences

2.1       Basic Model Setup

        Consider a decision maker whose intertemporal utility is additively time separable. The agent’s
instantaneous preferences are defined over the action she chooses from a discrete set of alterna-
tives 𝑖 ∈ ℐ = {0, 1, ..., 𝐼} , and a list of state variables denoted by ℎ ≡ (𝑥, 𝜺) where 𝑥 ∈ 𝒳 , which
for notational simplicity includes time 𝑡, are observed by the researcher, and 𝜺 ≡ (𝜀1 , ..., 𝜀𝐼 ) ∈ 𝑅𝐼
are the vector of random preference shocks for each of the 𝐼 alternatives.8 We make the following
assumption about the instant utility from taking action 𝑖, 𝑢∗𝑖 (ℎ) ≡ 𝑢∗𝑖 (𝑥, 𝜺):

Assumption 1. (Additive Separability) The instantaneous utilities are given by, for each 𝑖 ∈ ℐ,

                                                  𝑢∗𝑖 (𝑥, 𝜺) = 𝑢𝑖 (𝑥) + 𝜀𝑖 ,                                (1)

where 𝑢𝑖 (𝑥) is the deterministic component of the utility from choosing 𝑖 at 𝑥, and (𝜀1 , ..., 𝜀𝐼 ) has a joint
distribution 𝐺, which is absolutely continuous with respect to the Lebesgue measure in 𝑅𝐼 .

        We assume that the time horizon is infinite with time denoted by 𝑡 = 1, 2, ... The decision-
maker’s intertemporal preferences are represented by a simple and now commonly used formu-
lation of agents’ potentially time-inconsistent preferences: (𝛽, 𝛿)-preferences (Phelps and Pollak,
1968; Laibson, 1997; and O’Donoghue and Rabin 1999a):

Definition 1. (𝛽, 𝛿)-preferences are intertemporal preferences represented by

                                                                         +∞
                                                                         ∑
                                         𝑈𝑡 (𝑢𝑡 , 𝑢𝑡+1 , ...) ≡ 𝑢𝑡 + 𝛽           𝛿 𝑘−𝑡 𝑢𝑘
                                                                         𝑘=𝑡+1


where 𝛽 ∈ (0, 1] and 𝛿 ∈ (0, 1].
    8
        We assume that 𝒳 is a finite set and denote 𝑋 = #𝒳 to be the size of the state space.


                                                              5
    Following the terminology of O’Donoghue and Rabin (1999a), the parameter 𝛿 is called the
standard discount factor, which captures long-run, time-consistent discounting; and the parameter
𝛽 is called the present-bias factor, which captures short-term impatience. The standard model is
nested as a special case of (𝛽, 𝛿)-preferences when 𝛽 = 1. When 𝛽 ∈ (0, 1) , (𝛽, 𝛿)-preferences
capture “quasi-hyperbolic” time discounting (Laibson, 1997). We say that an agent’s preferences
are time-consistent if 𝛽 = 1, and are present-biased if 𝛽 ∈ (0, 1).
    The literature on time-inconsistent preferences distinguishes between naive and sophisticated
agents (Strotz, 1956; Pollak, 1968; O’Donoghue and Rabin, 1999a, 1999b). An agent is partially
naive if the self in every period 𝑡 underestimates the present-bias of her future selves, believing
                                        ˜ ∈ (𝛽, 1); in the extreme, if the present self believes that her
that her future selves’ present bias is 𝛽
                                        ˜ = 1, she is said to be completely naive. On the other hand,
future selves are time-consistent, i.e. 𝛽
an agent is sophisticated if the self in every period 𝑡 correctly knows her future selves’ present-bias
𝛽 and anticipates their behavior when making her period-𝑡 decision, i.e., if 𝛽  ˜ = 𝛽.
    Following previous studies of time-inconsistent preferences, we will analyze the behavior of
an agent by thinking of the single individual as consisting of many autonomous selves, one for
each period. Each period-𝑡 self chooses her current behavior to maximize her current utility
𝑈𝑡 (𝑢𝑡 , 𝑢𝑡+1 , ...) , while her future selves control her subsequent decisions.
    More specifically, let the observable state variable in period 𝑡 be 𝑥𝑡 ∈ 𝒳 where 𝒳 denotes
the support of the state variables and the unobservable choice-specific shock 𝜀𝑖𝑡 ∈ 𝑅, and 𝜺𝑡 =
(𝜀1𝑡 , ..., 𝜀𝐼𝑡 ) ∈ 𝑅𝐼 . A strategy profile for all selves is 𝝈 ≡ {𝜎 𝑡 }∞                    𝐼
                                                                        𝑡=1 where 𝜎 𝑡 : 𝒳 × 𝑅 → ℐ for all 𝑡. It
specifies for each self her action in all possible states and under all possible realizations of shock
                                                       ∞
vectors. For any strategy profile 𝝈, write 𝝈 +
                                             𝑡 ≡ {𝜎 𝑘 }𝑘=𝑡 as the continuation strategy profile from
period 𝑡 on.
    To define and characterize the equilibrium of the intra-personal game of an agent with poten-
tially time-inconsistent preferences, we first write 𝑉𝑡 𝑥𝑡 , 𝜺𝑡 ; 𝝈 +
                                                       (              )
                                                                    𝑡   as the agent’s period-𝑡 expected
continuation utility when the state variable is 𝑥𝑡 and the shock vector is 𝜺𝑡 under her long-run
time preference for a given continuation strategy profile 𝝈 +                                  +
                                                                                  (              )
                                                            𝑡 . We can think of 𝑉𝑡 𝑥𝑡 , 𝜺𝑡 ; 𝝈 𝑡 as rep-
resenting (hypothetically) her intertemporal preferences from some prior perspective when her
own present-bias is irrelevant. Specifically, 𝑉𝑡 𝑥𝑡 , 𝜺𝑡 ; 𝝈 +
                                                (              )
                                                             𝑡 must satisfy:


        𝑉𝑡 𝑥𝑡 , 𝜺𝑡 ; 𝝈 +   = 𝑢∗𝜎𝑡 (𝑥𝑡 ,𝜺𝑡 ) 𝑥𝑡 , 𝜀𝜎𝑡 (𝑥𝑡 ,𝜺𝑡 )𝑡 + 𝛿E 𝑉𝑡+1 𝑥𝑡+1 , 𝜺𝑡+1 ; 𝝈 +
          (              )                 (                   )    [    (                   )                    ]
                       𝑡                                                                  𝑡+1 ∣𝑥𝑡 , 𝜎 𝑡 (𝑥𝑡 , 𝜺𝑡 ) ,   (2)

where 𝜎 𝑡 (𝑥𝑡 , 𝜺𝑡 ) ∈ ℐ is the choice specified by strategy 𝜎 𝑡 , and the expectation is taken over both
the future state 𝑥𝑡+1 and 𝜺𝑡+1 .
    We will define the equilibrium for a partially naive agent whose period-𝑡 self believes that,



                                                             6
                                                                                             ˜ ∈
beginning next period, her future selves will behave optimally with a present-bias factor of 𝛽
[𝛽, 1]. Following O’Donoghue and Rabin (1999b, 2001), we first define the concept of an agent’s
perceived continuation strategy profile by her future selves.

Definition 2. The perceived continuation strategy profile for a partially naive agent is a strategy profile
     𝜎 𝑡 }∞
˜ ≡ {˜
𝝈                                                                         𝐼
          𝑡=1 such that for all 𝑡 = 1, 2, ..., all 𝑥𝑡 ∈ 𝒳 , and all 𝜺𝑡 ∈ 𝑅 ,

                                        {                                                         ]}
                ˜ 𝑡 (𝑥𝑡 , 𝜺𝑡 ) = arg max 𝑢∗𝑖 (𝑥𝑡 , 𝜖𝑖𝑡 ) + 𝛽𝛿E
                                                           ˜                       ˜+
                                                               [    (                    )
                𝜎                                               𝑉𝑡+1 𝑥𝑡+1 , 𝜺𝑡+1 ; 𝝈 𝑡+1   ∣𝑥𝑡 , 𝑖   .
                                    𝑖∈ℐ


                                                                                            ˜ then her
    That is, if an agent is partially naive with perceived present-bias by future selves at 𝛽,
                                                                            ˜+
period-𝑡 self will anticipate that her future selves will follow strategies 𝝈        𝜎 𝑘 }∞
                                                                              𝑡+1 ≡ {˜    𝑘=𝑡+1 . Note,
importantly, what the strategy profile 𝝈    𝜎 𝑡 }∞
                                       ˜ ≡ {˜    𝑡=1 describes is the perception of the partially naive
agent regarding what her future selves will play. It is not what will generate the actual play that we
observe in the data. What we actually observe is generated from the perception-perfect strategy
profile that we now define.

Definition 3. A perception-perfect strategy profile for a partially naive agent is a strategy profile 𝝈 ∗ ≡
{𝜎 ∗𝑡 }∞                                                                𝐼
       𝑡=1 such that, for all 𝑡 = 1, 2, ..., all 𝑥𝑡 ∈ 𝒳 , and all 𝜺𝑡 ∈ 𝑅 ,


                𝜎 ∗𝑡 (𝑥𝑡 , 𝜺𝑡 ) = arg max 𝑢∗𝑖 (𝑥𝑡 , 𝜀𝑖𝑡 ) + 𝛽𝛿E 𝑉𝑡+1 𝑥𝑡+1 , 𝜺𝑡+1 ; 𝝈
                                                                                   ˜+
                                         {                     [    (                   )       ]}
                                                                                     𝑡+1 ∣𝑥𝑡 , 𝑖   .
                                     𝑖∈ℐ


    That is, 𝝈 ∗ is the best response of the current self with (𝛽, 𝛿)-preference against 𝝈
                                                                                         ˜ , the perceived
continuation strategy profile of her future selves. It is key to note the difference and connection
        ˜ and 𝝈 ∗ . 𝝈
between 𝝈           ˜ is the unobserved perception of the partially naive agent regarding what her
future selves will do, under the partial naivety assumption that her future selves do not suffer
from the present bias as described by the parameter 𝛽, but instead is governed by present bias
          ˜ that may differ from 𝛽. 𝝈 ∗ is what the self in each period will optimally choose to do,
parameter 𝛽
and the actions generated from 𝝈 ∗ are what will be observed in the data. Note also that when 𝛽
    ˜ coincide, i.e., when the agent is sophisticated, we have 𝝈 ∗ = 𝝈
and 𝛽                                                                ˜.

Assumption 2. (Stationarity) We assume that the observed choices are generated under the stationary
perception-perfect strategy profile of the infinite horizon dynamic game played among different selves of the
decision makers.




                                                          7
2.2     Decision Process

      Now we describe the decision process of the decision maker. First, define the deterministic
component of the current choice-specific value function, 𝑊𝑖 (𝑥), as follows:
                                                            ∑
                                  𝑊𝑖 (𝑥) = 𝑢𝑖 (𝑥) + 𝛽𝛿           𝑉 (𝑥′ )𝜋(𝑥′ ∣𝑥, 𝑖),                      (3)
                                                         𝑥′ ∈𝒳


where 𝜋(𝑥′ ∣𝑥, 𝑖) denotes the transition probabilities for state variables 𝑥 when action 𝑖 is taken;
and 𝑉 (⋅) is the perceived long-run value function defined as:

                                              𝑉 (𝑥) ≡ E𝜺 𝑉 (𝑥, 𝜺; 𝝈
                                                                  ˜)                                      (4)

               ˜ ) is the stationary value function defined according to (2) under the perceived
where 𝑉 (𝑥, 𝜺; 𝝈
continuation strategy profile 𝝈
                              ˜ for a partially naive agent as defined in Definition 2.
      Using 𝑉 (⋅) as defined in (4), we can also define the choice-specific value function of the next-period
self as perceived by the current self, 𝑍𝑖 (𝑥) , as follows:
                                                            ∑
                                                    ˜
                                  𝑍𝑖 (𝑥) = 𝑢𝑖 (𝑥) + 𝛽𝛿           𝑉 (𝑥′ )𝜋(𝑥′ ∣𝑥, 𝑖).                      (5)
                                                         𝑥′ ∈𝒳


      There are two key difference between 𝑊𝑖 (𝑥) and 𝑍𝑖 (𝑥). The first difference is in how they
discount the future streams of payoffs: in 𝑊𝑖 (𝑥) the payoff 𝑡 periods removed from the current
period is discounted by 𝛽𝛿 𝑡 , while in 𝑍𝑖 (𝑥) the payoff 𝑡 periods removed from now is discounted
   ˜ 𝑡 . The second difference is interpretational: 𝑊𝑖 (𝑥) represents how the current-period self
by 𝛽𝛿
evaluates the deterministic component of the payoff from choosing alternative 𝑖, while 𝑍𝑖 (𝑥) is
how the current-period self perceives how her next-period self would evaluate the deterministic
component of the payoff from choosing alternative 𝑖. It is obvious but important to note that 𝑊𝑖 (𝑥)
will regulate the current self’s optimal choice, but 𝑍𝑖 (𝑥) will regulate the perception of the current
self regarding the choices of her future selves.
      Given 𝑍𝑖 (𝑥) , we know that the current self’s perception of her future self’s choice, i.e., 𝜎
                                                                                                   ˜ as
defined in Definition 2 is simply
                                              [                                                 ]
                                                                    ∑
                         𝜎                            ˜
                         ˜ (𝑥, 𝜺) = max 𝑢𝑖 (𝑥) + 𝜀𝑖 + 𝛽𝛿                   𝑉 (𝑥′ )𝜋(𝑥′ ∣𝑥, 𝑖)
                                        𝑖∈ℐ
                                                                   𝑥′ ∈𝒳
                                   = max [𝑍𝑖 (𝑥) + 𝜀𝑖 ] .                                                 (6)
                                        𝑖∈ℐ


Let us define the probability of choosing alternative 𝑗 by the the next period self as perceived by



                                                        8
the current period self, 𝑃˜𝑗 (𝑥) , when the next-period’s state is 𝑥 :

                        𝑃˜𝑗 (𝑥) = Pr [˜
                                      𝜎 (𝑥, 𝜺) = 𝑗]                                                                (7)
                                = Pr 𝑍𝑗 (𝑥) + 𝜀𝑗 ≥ 𝑍𝑗 ′ + 𝜀𝑗 ′ for all 𝑗 ′ ∕= 𝑗 .
                                     [                                         ]


   With the characterization of 𝜎
                                ˜ (𝑥, 𝜺), we can now provide a characterization of 𝑉 (⋅) . For this
purpose, further denote the perceived choice-specific long-run value function 𝑉𝑖 (𝑥) as follows:
                                                        ∑
                                  𝑉𝑖 (𝑥) = 𝑢𝑖 (𝑥) + 𝛿           𝑉 (𝑥′ )𝜋(𝑥′ ∣𝑥, 𝑖).                                (8)
                                                        𝑥′ ∈𝒳


According to the definition of 𝑉 (⋅) as given by (4), 𝑉 (𝑥) is simply the expected value of 𝑉𝑖 (𝑥) + 𝜀𝑖 ,
where 𝑖 is the chosen alternative according to 𝜎
                                               ˜ (𝑥, 𝜺) ; that is, we have the following relationship:

                                              [                         ]
                                    𝑉 (𝑥) = E𝜺 𝑉𝜎˜ (𝑥,𝜺) (𝑥) + 𝜀𝜎˜ (𝑥,𝜺) .                                         (9)

Now note from (5) and (8), we have
                                            (      ) ∑
                                                 ˜ 𝛿
                           𝑉𝑖 (𝑥) = 𝑍𝑖 (𝑥) + 1 − 𝛽     𝑉 (𝑥′ )𝜋(𝑥′ ∣𝑥, 𝑖).                                        (10)
                                                                𝑥′ ∈𝒳


Relationship (10) is crucial as it allows us to rewrite (9) as:

                      [                          ]
            𝑉 (𝑥) = E𝜺 𝑉𝜎˜ (𝑥,𝜺) (𝑥) + 𝜀𝜎˜ (𝑥,𝜺)
                      [                                                                                       ]
                                                        (          )      ∑
                                                         ˜ 𝛿
                    = E𝜺 𝑍𝜎˜ (𝑥,𝜺) (𝑥) + 𝜀𝜎˜ (𝑥,𝜺) + 1 − 𝛽                        𝑉 (𝑥′ )𝜋(𝑥′ ∣𝑥, 𝜎
                                                                                                  ˜ (𝑥, 𝜺))
                                                                          𝑥′ ∈𝒳
                                                 (          )           ∑
                                                  ˜ 𝛿E𝜺
                    = E𝜺 max [𝑍𝑖 (𝑥) + 𝜀𝑖 ] + 1 − 𝛽                             𝑉 (𝑥′ )𝜋(𝑥′ ∣𝑥, 𝜎
                                                                                                ˜ (𝑥, 𝜺) )
                            𝑖∈ℐ
                                                                        𝑥′ ∈𝒳
                                                        [                           ]
                                                 (  ) ∑          ∑
                                                  ˜ 𝛿                  ′    ′
                    = E𝜺 max [𝑍𝑖 (𝑥) + 𝜀𝑖 ] + 1 − 𝛽      𝑃˜𝑗 (𝑥)   𝑉 (𝑥 )𝜋(𝑥 ∣𝑥, 𝑗)                               (11)
                            𝑖∈ℐ
                                                                  𝑗∈ℐ               𝑥′ ∈𝒳


where the second equality just follows from (10); and the third equality follows from (6) and thus

                             [                         ]
                           E𝜺 𝑍𝜎˜ (𝑥,𝜺) (𝑥) + 𝜀𝜎˜ (𝑥,𝜺) = E𝜺 max [𝑍𝑖 (𝑥) + 𝜀𝑖 ] ;
                                                                   𝑖∈ℐ




                                                        9
and the fourth equality follows from the fact that
                                                               [                                                        ]
                 ∑                                       ∑                                   ∑
                             ′       ′                                                                   ′    ′
            E𝜺           𝑉 (𝑥 )𝜋(𝑥 ∣𝑥, 𝜎
                                       ˜ (𝑥, 𝜺) ) =                Pr (˜
                                                                       𝜎 (𝑥, 𝜺) = 𝑗)                 𝑉 (𝑥 )𝜋(𝑥 ∣𝑥, 𝑗)
                 𝑥′ ∈𝒳                                   𝑗∈ℐ                                 𝑥′ ∈𝒳
                                                               [                                         ]
                                                         ∑                   ∑
                                                                                         ′       ′
                                                    =              𝑃˜𝑗 (𝑥)           𝑉 (𝑥 )𝜋(𝑥 ∣𝑥, 𝑗 ).
                                                         𝑗∈ℐ                 𝑥′ ∈𝒳


      Now we make two additional standard assumptions about the transition of the state variables
and the distribution of the shocks [see, e.g., Rust (1994b)]:

Assumption 3. (Conditional Independence):

                                 𝜋(𝑥𝑡+1 , 𝜺𝑡+1 ∣𝑥𝑡 , 𝜀𝑡 , 𝑑𝑡 ) = 𝑞(𝜺𝑡+1 ∣𝑥𝑡+1 )𝜋(𝑥𝑡+1 ∣𝑥𝑡 , 𝑑𝑡 )
                                 𝑞(𝜺𝑡+1 ∣𝑥𝑡+1 ) = 𝑞(𝜺).

Assumption 4. (Extreme Value Distribution): 𝜺𝑡 is i.i.d extreme value distributed.

Remark 1. It is well-known that the distribution of the choice-specific shocks to payoffs in discrete choice
models are not non-parametrically identified (see Magnac and Thesmar 2002, for example). Thus one has
to make an assumption about the distribution of 𝜀. We make the extreme value distribution assumption for
simplicity, but it could be replaced by any other distribution 𝐺 .

      With the above preliminary notations, now we can describe how the agent will make the
choices when the state variables are given by (𝑥, 𝜺) . From Definition 3 for perception perfect strat-
egy profile and Equation (3), we know that the current period decision maker will choose 𝑖 if and
only if
                                             𝑖 ∈ arg max {𝑊𝑖 (𝑥) + 𝜀𝑖 } .
                                                        𝑖∈ℐ

That is, the perception-perfect strategy profile 𝜎 ∗ (𝑥, 𝜺) is:

                                         𝜎 ∗ (𝑥, 𝜺) = arg max {𝑊𝑖 (𝑥) + 𝜀𝑖 } .
                                                              𝑖∈ℐ


Under Assumption 4, the probability of observing action 𝑖 being chosen at a given state variable 𝑥
is:                              [                                                   ]
                                                                  exp [𝑊𝑖 (𝑥)]
                 𝑃𝑖 (𝑥) = Pr 𝑊𝑖 (𝑥) + 𝜀𝑖 > max {𝑊𝑗 (𝑥) + 𝜀𝑗 } = ∑𝐼                .                                         (12)
                                                                 𝑗=0 exp [𝑊𝑗 (𝑥)]
                                          𝑗∈ℐ∖{𝑖}

𝑃𝑖 (𝑥) is the current-period self’s equilibrium choice probabilities and will be observed in the data.
      Now we derive some important relationships that will be used in our identification exercise


                                                              10
below. First, note that by combining (3) and (5), we have that:

                                                          ˜
                                                          𝛽
                                     𝑍𝑖 (𝑥) − 𝑢𝑖 (𝑥) =      [𝑊𝑖 (𝑥) − 𝑢𝑖 (𝑥)] .                              (13)
                                                          𝛽

    Since both 𝑍𝑖 (⋅) and 𝑊𝑖 (⋅) depends on 𝑉 (⋅) , we would like to use (11) to derive a characteri-
zation of 𝑉 (⋅) . Note that under Assumptions 4, we have:
                                                               {                  }
                                                                ∑
                                 E𝜀 max{𝑍𝑖 (𝑥) + 𝜀𝑖 } = ln            exp [𝑍𝑖 (𝑥)] .                         (14)
                                     𝑖∈ℐ
                                                                𝑖∈ℐ


Moreover, from (7), we have that

                                                         exp [𝑍𝑗 (𝑥)]
                                             𝑃˜𝑗 (𝑥) = ∑𝐼                .                                   (15)
                                                        𝑖=0 exp [𝑍𝑖 (𝑥)]

Using (14) and (15), we can rewrite (11) as
                      {                    }
                                                (    ) ∑ exp [𝑍 (𝑥)]
                                                                   𝑗
                       ∑                                                     ∑
         𝑉 (𝑥) = ln           exp [𝑍𝑖 (𝑥)]         ˜ 𝛿
                                               + 1−𝛽       ∑𝐼                      𝑉 (𝑥′ )𝜋(𝑥′ ∣𝑥, 𝑗).       (16)
                        𝑖∈ℐ                            𝑗∈ℐ  𝑖=0 exp [𝑍𝑖 (𝑥)] 𝑥′ ∈𝒳


The three set of equations (5), (13) and (16) will form the basis of our identification argument
below. Let us first make a few useful remarks.

Remark 2. We have three value functions {𝑊𝑖 (𝑥) , 𝑍𝑖 (𝑥) , 𝑉𝑖 (𝑥) : 𝑥 ∈ 𝒳 } as defined respectively in (3),
(5) and (8). Both 𝑊𝑖 (⋅) and 𝑍𝑖 (⋅) are related to 𝑉𝑖 (⋅) . It is worth emphasizing that 𝑊𝑖 (𝑥) will regulate the
current self’s choice behavior as demonstrated by (12); and 𝑍𝑖 (𝑥) will regulate the current self’s perception
of future selves choices as demonstrated by (15). 𝑉𝑖 (𝑥) is an auxiliary value function that simply uses the
long-run discount factor 𝛿 to evaluate the payoffs from the choices that the current self perceives that will be
made by her future selves.

Remark 3. If 𝛽 ˜ = 1, i.e., if the decision maker is completely naive, we can see from (10) that 𝑉𝑖 (𝑥) = 𝑍𝑖 (𝑥)
for all 𝑥. This makes sense because when 𝛽     ˜ = 1, the current self perceives her future selves to be time
consistent. Thus the current self is already perceiving her future selves to be behaving according to the long
run discount factor 𝛿 only.
             ˜ = 𝛽, i.e., when an agent is sophisticated, then Eqs. (3) and (5) tell us that 𝑊𝑖 (𝑥) = 𝑍𝑖 (𝑥) .
Remark 4. If 𝛽
That is, if the decision maker is sophisticated, then the current self’s own choice rule will be identical to what
she perceives to be her future self’s choice rule.

Remark 5. When the decision maker is partially naive, there are two distinct value functions 𝑊𝑖 (𝑥) and
𝑍𝑖 (𝑥) that separately regulate the choice of the current self and the perceived choice of her future selves.

                                                          11
 Notation                                 Interpretation                              Equation/Definition
                Deterministic payoff from choosing alternative 𝑖
 𝑢𝑖 (𝑥)
                    when state vector is 𝑥
                Payoff, including the choice-specific shock, from choosing
 𝑢∗𝑖 (𝑥)                                                                              Eq. (1)
                    alternative 𝑖when state vector is 𝑥 : 𝑢∗𝑖 (𝑥) ≡ 𝑢𝑖 (𝑥) +𝜀𝑖
       𝛽        The present-bias factor                                               Definition (1)
       ˜
       𝛽                                       ˜ ∈ [𝛽, 1]
                The partial naivety parameter: 𝛽
       𝛿        The standard discount factor                                          Definition (1)
 𝑉𝑖 (𝑥)        Perceived choice-specific long-run value function                      Eq. (8)
 𝑉 (𝑥)         Perceived long-run value function                                      Eq. (4)
 𝑊𝑖 (𝑥)        Current choice-specific value function                                 Eq. (3)
                Choice-specific value function of the next-period self
 𝑍𝑖 (𝑥)                                                                               Eq. (5)
                    as perceived by the current self
 𝜎
 ˜ (𝑥, 𝜺)      Perceived continuation strategy profile for a partially naive agent    Definition (2)
 𝜎 ∗ (𝑥, 𝜺)    Perception-perfect strategy profile for a partially naive agent        Definition (3)

                                  Table 1: Summary of Key Notations.


Equation (13) clarifies that it is the fact that we allow for potential naivety in the hyperbolic model that is
creating the wedge between 𝑊𝑖 (𝑥) and 𝑍𝑖 (𝑥) : if 𝛽    ˜ = 𝛽, i.e., if agents are sophisticated (even when they
suffer from present bias), it would be true that 𝑊𝑖 (𝑥) = 𝑍𝑖 (𝑥) . This is an important point because, as
we see in (12), the observed choice probabilities (our data) would provide direct information about 𝑊𝑖 (𝑥),
without needing any information about the discount factors. Thus when 𝛽   ˜ = 𝛽, the observed choice proba-
                                                                 ˜ and 𝛽 are potentially not equal, we can no
bilities also provide direct information about 𝑍𝑖 (𝑥) ; but when 𝛽
longer learn about 𝑍𝑖 (𝑥) directly from the observed choice probabilities.


Summary. Table 1 summarizes the main notations we have introduced up to now.


2.3     Relationship with the Dynamic Games Literature

      We analyze the observed outcome of the dynamic discrete choice problem of a hyperbolic dis-
counting decision process as the equilibrium outcome of an intra-personal game with the players
being the selves at different periods. Thus our paper represents an interesting intermediate case be-
tween the classic literature on estimating single-agent dynamic discrete choice decision problems
and the more recent literature on estimating dynamic games. It is worth pointing out that there
are two crucial differences between the intra-personal games we analyze for agents with time-

                                                       12
inconsistent time preferences and those in the existing dynamic games literature.
      The first key difference is that in our case, we do not observe the actions of all the players. More
specifically, the outcomes – choices and the evolutions of the state variables – we observe in the
data are affected only by the current selves, even though the current selves’ choices are impacted
by their perception of future selves’ actions. The current self’s perception of how her future selves
will play has to be inferred by the researcher using the equilibrium restriction imposed by the
theory. As can be seen from the above discussion, 𝑃˜𝑗 (𝑥) as defined in (15), captures the current
self’s perception of how her future selves will play, which is crucial for us to understand the
current self’s actual choices. However, as a researcher, we do not observe 𝑃˜𝑗 , only observe 𝑃𝑗 ,
the choice probabilities by the current self. In the standard dynamic games literature, it is always
assumed that the action of all the players are observed.
      Secondly, the dynamic games literature (e.g. Bajari, Benkard and Levin 2007) may allow for
players to have different contemporaneous payoff functions, in our setting, however, the payoffs
for the players – the current self and the future selves – differ only in their time preferences;
moreover, under hyperbolic discounting, we are assuming a rather restricted form of difference in
time preferences between the selves in different periods.


3      Identification

3.1     Data and Preliminaries

      Before we describe our results on identification, let us assume that we have access to a data set
that provides us with the following information:

DATA:

      ∙ (Conditional Choice Probabilities) For all 𝑥 ∈ 𝒳 , we observe the choice probabilities 𝑃𝑖 (𝑥)
        for all 𝑖 ∈ ℐ;

      ∙ (Transitional Probabilities for Observable State Variables) For all (𝑥, 𝑥′ ) ∈ 𝒳 2 , all 𝑖 ∈ ℐ,
        we observe the transition probabilities 𝜋 (𝑥′ ∣𝑥, 𝑖) ; we denote

                                     𝝅 ≡ 𝜋 𝑥′ ∣𝑥, 𝑖 : 𝑥, 𝑥′ ∈ 𝒳 2 , 𝑖 ∈ ℐ ;
                                        { (        ) (     )             }



      ∙ (Short Panels) We have access to at least two periods of the above data, even though the
        data results from a stationary infinite horizon model.



                                                    13
          Following Magnac and Thesmar (2002), we assume that the structure of the model, denoted by
𝜃, is defined by the following parameters:9
                              {(         )                                                    }〉}
                                      ˜ 𝛿 , 𝐺, 𝑢𝑖 (𝑥) , 𝑍𝑖 𝑥′ , 𝑉𝑖 𝑥′ : 𝑖 ∈ ℐ, 𝑥 ∈ 𝒳 , 𝑥′ ∈ 𝒳
                                              〈{          ( )     ( )
                       𝜃=          𝛽, 𝛽,                                                          ,

where 𝐺 (⋅) , the distribution of the choice-specific payoff shocks 𝜀𝑖𝑡 , is assumed to have a Type-I
extreme value distribution by Assumption 4. Note that the elements in 𝜃 in our setting differs
                                                                                        ˜ that
from those in Magnac and Thesmar (2002) in that we have two additional parameters 𝛽 and 𝛽
measure present bias and naivety; moreover, the interpretation of 𝑉𝑖 (𝑥′ ) in our paper differs from
theirs. In their paper 𝑉𝑖 (𝑥′ ) directly informs about the actual choice probabilities of the decision
maker in the second period because Pr (𝑖∣𝑥′ ) = Pr (𝑉𝑖 (𝑥′ ) + 𝜀𝑖 > 𝑉𝑗 (𝑥′ ) + 𝜀𝑗 ∀𝑗 ∕= 𝑖) . In our paper,
𝑍𝑖 (𝑥′ ) captures the current self’s perception of the choice probability of the next period’s self, which
is never actually observed in the data; while 𝑉𝑖 (𝑥′ ) is just an auxiliary value function to account
for the exponentially discounted payoff streams from the perceived choices made according to
˜ (𝑥, 𝜺) . Another difference is that in Magnac and Thesmar (2002), the vector {𝑉𝑖 (𝑥′ ) : 𝑥′ ∈ 𝒳 } are
𝜎
completely free parameters; in our setting, however, neither 𝑍𝑖 (𝑥′ ) and 𝑉𝑖 (𝑥′ ) are completely free
parameters as they are subject to the restriction that they have to satisfy (5), (13) and (16).
          We denote by Θ the set of all permissible structures. The set Θ requires that the structure
satisfies the assumptions we adopted in the model, as well as the restrictions (5), (13) and (16).
    Given any structure 𝜃 ∈ Θ, the model predicts the probability that an agent will choose alter-
native 𝑖 ∈ ℐ in state 𝑥 ∈ 𝒳 , which we denote by 𝑃ˆ𝑖 (𝑥; 𝜃) and is given by
                       {                                                       [                                       ]      }
                                              ∑                                                 ∑
     𝑃ˆ𝑖 (𝑥; 𝜃) = Pr       𝑢𝑖 (𝑥) + 𝜀𝑖 + 𝛽𝛿               ′    ′
                                                      𝑉 (𝑥 )𝜋(𝑥 ∣𝑥, 𝑖) = max 𝑢𝑗 (𝑥) + 𝜀𝑗 + 𝛽𝛿               ′    ′
                                                                                                        𝑉 (𝑥 )𝜋(𝑥 ∣𝑥, 𝑗)   𝑥, 𝜃 .
                                                                         𝑗∈ℐ
                                              𝑥′ ∈𝒳                                             𝑥′ ∈𝒳


As is standard in the identification literature, we call the predicted choice probabilities 𝑃ˆ𝑖 (𝑥; 𝜃) as
the reduced form of structure 𝜃 ∈ Θ. We say that two structures 𝜃, 𝜃′ ∈ Θ are observationally equivalent
if
                                              𝑃ˆ𝑖 (𝑥; 𝜃) = 𝑃ˆ𝑖 𝑥; 𝜃′ ∀𝑖 ∈ ℐ and 𝑥 ∈ 𝒳 .
                                                              (     )


A model is said to be identified if and only if for any 𝜃, 𝜃′ ∈ Θ, 𝜃 = 𝜃′ if they are observationally
equivalent.


      9
    We could have included the vector {𝑊𝑖 (𝑥) : 𝑖 ∈ ℐ, 𝑥 ∈ 𝒳 } as part of the model parameters as well. But as seen from
Eq. (17), 𝑊𝑖 (𝑥) can be straightforwardly inferred from the data of choice probabilities 𝑃𝑖 (𝑥), subject to a normalization.
For this reason, we exclude them from our list of model parameters.




                                                                    14
3.2     Identification Results

    We first describe identification of ⟨{𝑢𝑖 (𝑥) , 𝑍𝑖 (𝑥′ ) , 𝑉𝑖 (𝑥′ ) : 𝑖 ∈ ℐ, 𝑥 ∈ 𝒳 , 𝑥′ ∈ 𝒳 }⟩ with for a given
                         〈        〉
set of discount factors 𝛽, 𝛽, ˜ 𝛿 . Then we provide conditions pertinent to the identification of
〈       〉
     ˜ 𝛿 .
  𝛽, 𝛽,

                                                                                              〈       〉
3.2.1                                                                                             ˜ 𝛿
         Identification of ⟨{𝑢𝑖 (𝑥) , 𝑍𝑖 (𝑥′ ) , 𝑉𝑖 (𝑥′ ) : 𝑖 ∈ ℐ, 𝑥 ∈ 𝒳 , 𝑥′ ∈ 𝒳 }⟩ for Given 𝛽, 𝛽,

      For any given joint distribution 𝐺 of ˜𝜀 ≡ (𝜀1 , ..., 𝜀𝐼 ) , the choice probability vector P (𝑥) =
(𝑃1 (𝑥) , ..., 𝑃𝐼 (𝑥)) is a mapping 𝑄 of W (𝑥) = (𝑊0 (𝑥) , 𝑊1 (𝑥) , ..., 𝑊𝐼 (𝑥)) . Hotz and Miller (1993)
showed that the mapping 𝑄 can be inverted if for each 𝑖 ∈ ℐ, one of the 𝑊𝑖 (𝑥) is normalized. That
is, one can find
                                    𝐷𝑖 (𝑥) ≡ 𝑊𝑖 (𝑥) − 𝑊0 (𝑥) = 𝑄𝑖 (P (𝑥) ; 𝐺)

where 𝑄𝑖 is the 𝑖𝑡ℎ component of the inverse 𝑄. Under our Assumption 4 (that 𝜀𝑖 has i.i.d Type-I
Extreme Value distribution), the mapping 𝑄𝑖 is especially simple [following from (12)]:

                                                                             𝑃𝑖 (𝑥)
                                       𝐷𝑖 (𝑥) = 𝑊𝑖 (𝑥) − 𝑊0 (𝑥) = ln                .                       (17)
                                                                             𝑃0 (𝑥)

Since we observe 𝑃𝑖 (𝑥) and 𝑃0 (𝑥) from the data, we immediately learn about 𝐷𝑖 (𝑥) . We thus
proceed as if 𝐷𝑖 (𝑥) is observable.
      From Eq. (13), we have that, for all 𝑖 ∈ ℐ,
                                                                 (      )
                                                ˜
                                                𝛽                   ˜
                                                                    𝛽
                                        𝑍𝑖 (𝑥) = 𝑊𝑖 (𝑥) +        1−          𝑢𝑖 (𝑥)                         (18)
                                                𝛽                   𝛽

Together with (17), we have, for all 𝑖 ∈ ℐ∖ {0} and 𝑥 ∈ 𝒳 ,
                                                             (          )
                                             ˜
                                             𝛽                      ˜
                                                                    𝛽
                            𝑍𝑖 (𝑥) − 𝑍0 (𝑥) = 𝐷𝑖 (𝑥) +           1−         [𝑢𝑖 (𝑥) − 𝑢0 (𝑥)] .             (19)
                                             𝛽                      𝛽

      Now let us examine the system of equations defined by Eq. (16), which can be re-written, using
(15), as, for all 𝑥 ∈ 𝒳 ,
                            {                           }
                             ∑                                (    ) ∑         ∑
   𝑉 (𝑥) = 𝑍0 (𝑥) + ln              exp [𝑍𝑖 (𝑥) − 𝑍0 (𝑥)]        ˜ 𝛿
                                                             + 1−𝛽     𝑃˜𝑗 (𝑥)   𝑉 (𝑥′ )𝜋(𝑥′ ∣𝑥, 𝑗).        (20)
                              𝑖∈ℐ                                             𝑗∈ℐ        𝑥′ ∈𝒳

                    {                         }
                        ˜ 𝛿, ⟨𝑍𝑖 (𝑥) : 𝑥 ∈ 𝒳 ⟩ as given, Eq. (20) is just a system of 𝑋 linear equa-
Note that if we take 𝛽, 𝛽,



                                                            15
tion in 𝑋 unknowns, namely, V ≡ [𝑉 (1) , ..., 𝑉 (𝑋)]𝑇 .10
                             [            {∑                         }]
    Specifically, if we stack 𝑍0 (𝑥) + ln   𝑖∈ℐ exp [𝑍𝑖 (𝑥) − 𝑍0 (𝑥)] 𝑥∈𝒳 into an 𝑋 ×1 column vec-
                          [              ]
tor A, denote by P̃ ≡ P̃0 ⋅ ⋅ ⋅ P̃𝐼 the 𝑋 × [(𝐼 + 1) 𝑋] matrix of choice probabilities,11 and
properly stack up the transition matrices 𝜋 (𝑥′ ∣𝑥, 𝑗) into an [(𝐼 + 1) 𝑋] × 𝑋 matrix as:12
                                                                 ⎡       ⎤
                                                             ⎢ Π0 ⎥
                                                             ⎢ . ⎥
                                                          Π ≡⎢  . ⎥
                                                             ⎢ . ⎥,
                                                             ⎣    ⎦
                                                               Π𝐼

we can write (20) as
                                                      (      )
                                                           ˜ 𝛿 P̃ΠV,
                                                  V=A+ 1 − 𝛽
                                               {                         }
                                                   ˜ 𝛿, ⟨𝑍𝑖 (𝑥) : 𝑥 ∈ 𝒳 ⟩ to be:
which yields the solution of V as a function of 𝛽, 𝛽,

                                                 [ (       )     ]−1
                                                         ˜ 𝛿 P̃Π
                                               V= I− 1 − 𝛽           A.                                                    (21)

                        (      )
                            ˜ 𝛿 , we can plug (21) into (5) and obtain, for all 𝑥 ∈ 𝒳 , and all
Thus for fixed values of 𝛽, 𝛽,
𝑖 ∈ ℐ ≡ {0, 1, ..., 𝐼} ,
                                                              ∑
                                                 ˜                    𝑉 𝑥′ 𝜋 𝑥′ ∣𝑥, 𝑖
                                                                       ( ) (         )
                               𝑍𝑖 (𝑥) = 𝑢𝑖 (𝑥) + 𝛽𝛿
                                                              𝑥′ ∈𝒳
                                                    ˜ 𝑖 (𝑥) V
                                         = 𝑢𝑖 (𝑥) + 𝛽𝛿Π                                                                    (22)
                                                            [ (      )     ]−1
                                                    ˜ 𝑖 (𝑥) I− 1 − 𝛽
                                         = 𝑢𝑖 (𝑥) + 𝛽𝛿Π            ˜ 𝛿 P̃Π     A,

where Π𝑖 (𝑥) = [𝜋 (1∣𝑥, 𝑖) , ..., 𝜋 (𝑋∣𝑥, 𝑖)] is an 𝑋 × 1 vector as defined in footnote 12.
  10
       Note that all the terms 𝑃˜𝑗 (𝑥) just depend on 𝑍𝑖 (⋅) .
                                                                         ⎡                                            ⎤
                                                                              𝑃˜𝑗 (0)       0        ⋅⋅⋅       0
                                                                                          𝑃˜𝑗 (1)
                                                                   ⎢                                                  ⎥
                                                                   ⎢             0                   ⋅⋅⋅       0      ⎥
  11
       For each 𝑗 ∈ ℐ, P̃𝑗 is the 𝑋 × 𝑋 matrix organized as: P̃𝑗 = ⎢                                                  ⎥.
                                                                   ⎢                                                  ⎥
                                                                                                     ..
                                                                   ⎢
                                                                   ⎣            0           0           .       0     ⎥
                                                                                                                      ⎦
                                                                                 0          0        ⋅⋅⋅     ˜
                                                                                                             𝑃𝑗 (𝑋)
  12
       Here, Π𝑗 is an 𝑋 × 𝑋 matrix defined by
                                         ⎡            ⎤   ⎡                                             ⎤
                                             Π𝑗 (1)              𝜋 (1∣1, 𝑗)     ...     𝜋 (𝑋∣1, 𝑗)
                                       ⎢              ⎥ ⎢                                               ⎥
                                       ⎢ Π𝑗 (2)       ⎥ ⎢        𝜋 (1∣2, 𝑗)     ...     𝜋 (𝑋∣2, 𝑗)      ⎥
                                  Π𝑗 = ⎢              ⎥=⎢                                               ⎥.
                                       ⎢              ⎥ ⎢                                               ⎥
                                            ..                                    ..
                                       ⎢
                                       ⎣     .        ⎥ ⎢
                                                      ⎦ ⎣                          .
                                                                                                        ⎥
                                                                                                        ⎦
                                         Π𝑗 (𝑋)                  𝜋 (1∣𝑋, 𝑗)     ...     𝜋 (𝑋∣𝑋, 𝑗)




                                                                  16
       Now consider the system of equations given by (19) and (22). We know from the standard
theories of discrete choice that we have to normalize the utility for the reference alternative 0,
which without loss of generality we set 𝑢0 (𝑥) = 0 for all 𝑥 ∈ 𝒳 . Thus, the unknowns contained
in the equation system of (19) and (22) include the following unknowns: (𝐼 + 1) × 𝑋 values for
{𝑍𝑖 (𝑥) : 𝑖 ∈ ℐ, 𝑥 ∈ 𝒳 } and 𝐼 × 𝑋 values for {𝑢𝑖 (𝑥) : 𝑖 ∈ ℐ/ {0} , 𝑥 ∈ 𝒳 } . That is, the total number
of unknowns is (2𝐼 + 1) × 𝑋. It is also easy to see that the total number of equations in the system
is also equal to (2𝐼 + 1) × 𝑋 : 𝐼 × 𝑋 equations in (19) and (𝐼 + 1) × 𝑋 equations in (22).
       Of course, having the same number of equations as the number of unknowns does not guaran-
tee the existence, or the uniqueness of the solutions. We will describe how the number of solutions
affect our estimation procedure below.
                                                                                          (       )
   Note that in the equation system of (19) and (22), the three discounting parameters 𝛽, 𝛽,  ˜ 𝛿
                                                                         (      )
                                                                  ˜ and 1 − 𝛽
appear in three different combinations: first, in Eqs. (22), both 𝛽𝛿          ˜ 𝛿 appear; second,
                                             (       )
˜
𝛽/𝛽                                       ˜
     appears in Eqs. (19). The fact that 𝛽𝛿,   1−𝛽  ˜ 𝛿 and 𝛽/𝛽
                                                              ˜   appear in the equation system is
                                            (       )
crucial for the separate estimation of the 𝛽, 𝛽, ˜ 𝛿 parameters.13 It is important to emphasize
                                                       (       )
that the non-linearities of how the three parameters 𝛽, 𝛽,˜ 𝛿 enter our problem is not by ad hoc
assumptions, instead they are driven by theoretical considerations.
       Finally, as we will see below, the main variables of interest that we would like to solve in
the equation system (19) and (22) are the 𝐼 × 𝑋 values for {𝑢𝑖 (𝑥) : 𝑖 ∈ ℐ/ {0} , 𝑥 ∈ 𝒳 } , and the
values for {𝑍𝑖 (𝑥) : 𝑖 ∈ ℐ, 𝑥 ∈ 𝒳 } are only auxiliary. In our actual estimation, we indeed fur-
ther eliminate {𝑍𝑖 (𝑥) : 𝑖 ∈ ℐ, 𝑥 ∈ 𝒳 } from the equation system (19) and (22) and only solve for
{𝑢𝑖 (𝑥) : 𝑖 ∈ ℐ/ {0} , 𝑥 ∈ 𝒳 } .
                                            〈       〉
3.2.2                                           ˜ 𝛿
           Exclusion Restriction to Identify 𝛽, 𝛽,
                                                              〈      〉
                                                                  ˜ 𝛿 . This discussion is closely
       Now we discuss conditions for identification related to 𝛽, 𝛽,
related to that in Magnac and Thesmar (2002). We impose the following exclusion restriction as-
sumption:

Assumption 5. (Exclusion Restriction) There exist state variable 𝑥1 ∈ 𝒳 and 𝑥2 ∈ 𝒳 with 𝑥1 ∕= 𝑥2 ,
such that

   1. for all 𝑖 ∈ ℐ, 𝑢𝑖 (𝑥1 ) = 𝑢𝑖 (𝑥2 ) ;
                                         〈    (    )      〉                                      〈      〉
  13                                       ˜
       Note that if the identification of 𝛽𝛿,    ˜ 𝛿, 𝛽/𝛽
                                               1−𝛽    ˜                                              ˆ 𝛿 :
                                                            is isomorphic to the identifcation of 𝛽, 𝛽,

                               (    )                  ˜
                                                       𝛽𝛿                      ˜
                                                                               𝛽𝛿
                                                                                       (˜)
                                                                                        𝛽
                            ˜ + 1−𝛽
                        𝛿 = 𝛽𝛿    ˜ 𝛿;        ˜=
                                              𝛽       (    ) ;        𝛽=      (    ) /     .
                                                   ˜ + 1−𝛽
                                                   𝛽𝛿     ˜ 𝛿              ˜ + 1−𝛽
                                                                           𝛽𝛿     ˜ 𝛿   𝛽




                                                           17
   2. for some 𝑖 ∈ ℐ, 𝜋 (𝑥′ ∣𝑥1 , 𝑖) ∕= 𝜋 (𝑥′ ∣𝑥2 , 𝑖) .

   More specifically, to satisfy the exclusion restriction assumption, there must exist at least one
variable that does not directly affect the contemporaneous utility function 𝑢𝑖 (⋅) for all 𝑖 ∈ ℐ, but
the variable may matter for choices because it affects the transition of state variables. The extent
to which individuals’ choice probabilities differ at state 𝑥1 and 𝑥2 reveals information about the
discount factors. This is the key intuition from Magnac and Thesmar’s (2002) result where they
are interested in identifying a single long-term discount factor 𝛿. In their setting, if 𝛿 = 0, i.e., if
individuals are completely myopic, then the choice probabilities would have been the same under
𝑥1 and 𝑥2 ; to the extent that choice probabilities differ at 𝑥1 and 𝑥2 , it reveals information about
the degree of time discounting. Their intuition, however, can be easily extended to the hyperbolic
discounting case, as we will exploit in the proposed estimation strategy below.
   For notational simplicity, we will divide the state variables into two groups (𝑥𝑟 , 𝑥𝑒 ) where
𝑥𝑟 ∈ 𝒳𝑟 refers to the state variables that directly enter the contemporaneous payoff function 𝑢𝑖 (𝑥𝑟 )
and 𝑥𝑒 ∈ 𝒳𝑒 refers to the state variables that satisfy the exclusion restriction (5). The key idea that
the existence of exclusion variables can provide the source of identification of the discount factors
                                       〈       〉
                                            ˜ 𝛿 , Section 3.2.1 tells us that we can identify, from the
is as follows: for any given values for 𝛽, 𝛽,
                                                                         〈      〉
                                                                             ˜ 𝛿 might be consistent
observed data, values of ⟨{𝑢𝑖 (𝑥) : 𝑖 ∈ ℐ, 𝑥 ∈ 𝒳 }⟩ , to the extent that 𝛽, 𝛽,
with the data at all. However, consider two state vectors 𝑥 = (𝑥𝑟 , 𝑥𝑒 ) and 𝑥′ = (𝑥𝑟 , 𝑥′𝑒 ) that only
                                                                           〈      〉
                                                                               ˜ 𝛿 are inconsistent
differ in the exclusion restriction components. If the postulated values of 𝛽, 𝛽,
with the true values, there is no guarantee that the identified values of 𝑢𝑖 (𝑥) and 𝑢𝑖 (𝑥′ ) are equal,
as required by the exclusion restriction. The exclusion restriction will allow us to select the values
   〈      〉
      ˜ 𝛿 such that the values of 𝑢𝑖 (𝑥) and 𝑢𝑖 (𝑥′ ) identified from the data only differ if 𝑥 and 𝑥′
of 𝛽, 𝛽,
differ in components of 𝑥𝑟 .

    Before we show how we can use the exclusion restriction to construct estimators for the three
                〈      〉                                                  〈      〉
                    ˜ 𝛿 , it is useful to provide some intuition as to how 𝛽, 𝛽,
discount factors 𝛽, 𝛽,                                                        ˜ 𝛿 come to affect
the observed choice behavior by the current self differently.


Distinguishing 𝛽 and 𝛿. It may seem counterintuitive that 𝛽 and 𝛿 could be separately identified
                                                                                               ˜ = 𝛽.
in a short two-period panel data set. To provide some intuition, let us consider the case that 𝛽
 The question is: “Can we distinguish the behavior of an agent with exponential discounting rate
ˆ𝛿 = 𝛽𝛿 from the behavior of a sophisticated time-inconsistent agent with preference (𝛽, 𝛿)?” Under
stationarity assumption, if an agent has time consistent exponential discounting rate ˆ𝛿 = 𝛽𝛿, her
expected continuation utilities is completely determined by the observed choice probabilities. To



                                                           18
                                                         ˜ by 1 and 𝛿 by ˆ𝛿, we will have
see this, observe that in equation (20), if one replaces 𝛽
                                                  {                          }
                                                   ∑
                            𝑉 (𝑥) = 𝑍0 (𝑥) + ln          exp [𝑍𝑖 (𝑥) − 𝑍0 (𝑥)] ,
                                                   𝑖∈ℐ


                                      ˜
which only depends on 𝐷𝑖 (𝑥) when 𝛽 = 𝛽.
      However, for a sophisticated time-inconsistent agent with preference (𝛽, 𝛿) , there is an incon-
gruence between current self and her perceived future self regarding how they evaluate the future
stream of payoffs. Though the current self has to defer to her next-period self in terms of the ac-
tual next-period choice that will be chosen, they disagree on how much weight to put on payoffs
two-periods from now. It is this incongruence that leads to the last term in Eq. (20), which in turn
breaks the tight link between observed choice probabilities and the continuation utilities.
      As we demonstrated in Section 3.2.1, the continuation utilities will ultimately determine the
identified values of ⟨{𝑢𝑖 (𝑥) : 𝑖 ∈ ℐ, 𝑥 ∈ 𝒳 }⟩ . Thus 𝛽 and 𝛿 can be distinguished when there are
exclusion variables because they requires that 𝑢𝑖 (𝑥) does not depend on the 𝑥𝑒 components of the
state vector.

                     ˜ To help provide intuition for why 𝛽 could be distinguished from 𝛽,
Distinguishing 𝛽 and 𝛽.                                                                     ˜ let
                                                 ˜
us suppose that 𝛿 = 1. First note that the ratio 𝛽/𝛽 appears in term 𝑍𝑖 (𝑥) [see Eq. (18)]. This
ratio regulates the incongruence between the current self’s own behavior and her perception of
                                                          ˜
the behavior of her future selves. Eq. (19) shows that if 𝛽/𝛽 = 1, then 𝑍𝑖 (𝑥) − 𝑍0 (𝑥) is uniquely
determined by the observed 𝐷𝑖 (𝑥) ; and thus the current self’s perception about her future self’s
                                                         ˜
action is identical to her own action. This implies that 𝛽/𝛽 = 1 (and 𝛿 = 1) will pin down com-
pletely the identified values of ⟨{𝑢𝑖 (𝑥) : 𝑖 ∈ ℐ, 𝑥 ∈ 𝒳 }⟩ from the data, which could be refuted if the
identified values of 𝑢𝑖 (𝑥) do not satisfy the exclusion restrictions, i.e., 𝑢𝑖 (𝑥) should not depend on
the 𝑥𝑒 components of the state vector.


3.3     The Exponential Discounting Special Case: 𝛽 = 𝛽˜ = 1

      Before discussing our estimation strategy, we here show that the non-linear equation system
(19) and (22), for the special case of dynamic discrete choice models with exponential discounting
                     ˜ = 𝛽 = 1), replicates the known results in the literature. In that case, (19) is
(i.e., the case with 𝛽
reduced to the well-known relationship

                                 𝑍𝑖 (𝑥) − 𝑍0 (𝑥) = ln 𝑃𝑖 (𝑥) − ln 𝑃0 (𝑥) ;                         (23)




                                                    19
that is, in standard models the difference in the choice probabilities for alternative 𝑖 and the refer-
ence alternative 0 informs us about the difference in the value from choosing 𝑖 relative to the value
from choosing 0. This is of course also true when 𝛽  ˜ = 𝛽 < 1. The potential naivety we allow in
our setup breaks this direct relationship between 𝑃𝑖 (𝑥) /𝑃0 (𝑥) and 𝑍𝑖 (𝑥) − 𝑍0 (𝑥) .
   Moreover, when 𝛽  ˜ = 𝛽 = 1, (22) for 𝑖 = 0 is reduced to (using the normalization that 𝑢0 (𝑥) =
0) :                                                             [            ]
                                 ∑         ( ′) ( ′         ∑      ∑ 𝑃𝑖 (𝑥′ )
                                                                                𝜋 𝑥′ ∣𝑥, 0 .
                                                       )                         (        )
                    𝑍0 (𝑥) = 𝛿           𝑍0 𝑥 𝜋 𝑥 ∣𝑥, 0 + 𝛿   ln          ′
                                                                     𝑃0 (𝑥 )
                                 𝑥′ ∈𝒳                      ′    𝑥 ∈𝒳      𝑖∈ℐ

For simplicity, denote the 𝑋 × 1 vector {𝑍0 (𝑥)}𝑥∈𝒳 as Z0 ; write the 𝑋 × 𝑋 matrix 𝜋 (𝑥′ ∣𝑥, 0) as Π0 ,
                                       𝑃𝑖 (𝑥′ )
                            { [∑                ]}
and write the 𝑋 × 1 vector ln      𝑖∈ℐ 𝑃0 (𝑥′ )    as m. The above equation can be written as
                                                          𝑥∈𝒳


                                                 Z0 = 𝛿Π0 (Z0 + m) .

Thus,
                                                 Z0 = (I−𝛿Π0 )−1 𝛿m.

Given this unique solution of Z0 , (23) immediately provides 𝑍𝑖 (𝑥) for all 𝑖 ∈ ℐ/ {0} and all 𝑥 ∈ 𝒳 .
To obtain 𝑢𝑖 (𝑥) for 𝑖 ∈ ℐ∖ {0}, note that (22) implies that

                                              u𝑖 = Z𝑖 − 𝛿Π𝑖 Z0 − 𝛿Π𝑖 m,                                                (24)

where Z𝑖 and u𝑖 are 𝑋 × 1 vectors of {𝑍𝑖 (𝑥)}𝑥∈𝒳 and {𝑢𝑖 (𝑥)}𝑥∈𝒳 respectively, Π𝑖 is the 𝑋 × 𝑋
matrix 𝜋 (𝑥′ ∣𝑥, 𝑖) . Recall that in the standard exponential discounting model we have 𝑍𝑖 (𝑥) =
𝑉𝑖 (𝑥) , thus we can conclude that , {u𝑖 }𝑖∈ℐ∖{0} and {V𝑖 }𝑖∈ℐ are identified once 𝛿, 𝐺 and {𝑢0 (𝑥)}𝑥∈𝒳
are fixed. This replicates the proof of Proposition 2 in Magnac and Thesmar (2002).14


4        Estimation Strategies

         In this section, we describe two estimation strategies based on our discussion about identifica-
tion above. Both estimation strategy involves two steps, and they share the same first step. In the
first step, we estimate from the data the choice probabilities 𝑃𝑖 (𝑥) for all 𝑖 ∈ ℐ and all 𝑥 ∈ 𝒳 , as
well as the state transition probabilities 𝜋 (𝑥′ ∣𝑥, 𝑖) for all 𝑖 ∈ ℐ and all (𝑥′ , 𝑥) ∈ 𝒳 2 .15
    14
      The only difference is that our argument above indicates that V0 does not have to be fixed. It can be identified from
the model.
   15
      It is useful to note that so far, our discussion has focused on short-panel (two period) data sets under stationarity
assumption. Having two-period data allows one to non-parametrically estimate the transition probabilities 𝜋 (𝑥′ ∣𝑥, 𝑖) ;
stationarity ensures that looking at a two-period slice of a potentially long panel is sufficient. Fang and Silverman (2006)
considered a case without stationarity (specifically a finite horizon model) and showed that 𝛽 and 𝛿 could be poten-


                                                            20
    The second step is different for the two estimation strategies. The first estimation strategy in-
volves two loops. In the inner loop, we solve equation system (19) and (22) for 𝑢𝑖 (𝑥) = 𝑢𝑖 (𝑥𝑟 , 𝑥𝑒 )
                                 〈      〉
                                     ˜ 𝛿 for all 𝑖 ∈ ℐ∖ {0} and all 𝑥 ∈ 𝒳 where we normalize
for a given triple of values for 𝛽, 𝛽,
𝑢0 (𝑥) = 0 for all 𝑥 ∈ 𝒳 . In the outer loop, we exploit the identifying assumption 5 in a straightfor-
                                                     〈        〉
ward manner. We know that at the true values of 𝛽, 𝛽,     ˜ 𝛿 , for all 𝑥
                                                                        ˜𝑒 ∈ 𝒳𝑒 , the standard deviation
of 𝑢        ˜𝑒 ) with respect to 𝑥
   ˆ𝑖 (𝑥𝑟 , 𝑥                    ˜𝑒 should be 0, because Assumption 5 requires that 𝑢𝑖 (𝑥𝑟 , 𝑥
                                                                                             ˜𝑒 ) does not
                                               〈       〉
depend on 𝑥                                         ˜ 𝛿 in our first estimation strategy is:
               ˜𝑒 . Therefore the estimator for 𝛽, 𝛽,


                              ˜ 𝛿 = arg min 1
                       〈         〉                   ∑        [ (           〈       〉)]
                           𝛽, 𝛽,                           std 𝑢
                                                               ˆ 𝑖 𝑥𝑟 , 𝑥       ˜ 𝛿
                                                                        ˜𝑒 ; 𝛽, 𝛽,      ,                            (25)
                                          ˜ } ∣𝒳𝑟 ∣
                                       {𝛽,𝛽,𝛿       𝑥𝑟 ∈𝒳𝑟

         [ (           〈       〉)]
where std 𝑢
          ˆ 𝑖 𝑥𝑟 , 𝑥       ˜ 𝛿
                   ˜𝑒 ; 𝛽, 𝛽,      is simply the sample standard deviation of 𝑢        ˜𝑒 ) , calculated
                                                                              ˆ𝑖 (𝑥𝑟 , 𝑥
                        〈       〉
under given values of 𝛽, 𝛽, ˜ 𝛿 , with respect to 𝑥˜𝑒 .
    The second estimation strategy is a maximum pseudo-likelihood estimation. As in the first
estimation strategy, we first solve equation system (19) and (22) for 𝑢𝑖 (𝑥) = 𝑢𝑖 (𝑥𝑟 , 𝑥𝑒 ) for a given
                    〈       〉
                        ˜ 𝛿 for all 𝑖 ∈ ℐ∖ {0} and all 𝑥 ∈ 𝒳 where we normalize 𝑢0 (𝑥) = 0 for all
triple of values for 𝛽, 𝛽,
𝑥 ∈ 𝒳 . Then we directly impose, by Assumption 5, the restriction that

                                                       1                     ∑
                             𝑢
                             ˆ𝑖 (𝑥𝑟 ) =                                                     𝑢
                                                                                            ˆ𝑖 (𝑥𝑟 , 𝑥
                                                                                                     ˜𝑒 )            (26)
                                          ∣{(𝑥𝑟 , 𝑥      ˜𝑒 ∈ 𝒳𝑒 }∣
                                                  ˜𝑒 ) : 𝑥
                                                                      {(𝑥𝑟 ,˜    𝑥𝑒 ∈𝒳𝑒 }
                                                                            𝑥𝑒 ):˜


where 𝒳𝑒 is the set of possible values for the payoff irrelevant state variables 𝑥𝑒 we discussed in
Assumption 5. Given 𝑢   ˆ𝑖 (𝑥𝑟 ) as defined by (26), we can then use the model to predict the implied
                        ( 〈          〉)
choice probabilities 𝑃ˆ𝑖 𝑥; 𝛽, 𝛽, ˜ 𝛿 , and formulate the pseudo-likelihood of the observed data,
which can be written as:
                                       ( 〈        〉)𝐷𝑖 (𝑥) [        ( 〈        〉)]1−𝐷𝑖 (𝑥)
                                              ˜ 𝛿
                ℒ = Π𝑛∈𝒩 Π𝐼𝑖=1 Π𝑥∈𝒳 𝑃ˆ𝑖 𝑥; 𝛽, 𝛽,                           ˜ 𝛿
                                                             1 − 𝑃ˆ𝑖 𝑥; 𝛽, 𝛽,              ,                         (27)

where in the likelihood function, 𝑛 stands for an individual and 𝒩 stands for the set of individ-
uals in the sample, and also note that we partialed out the contribution from the state transitions
𝜋 (𝑥′ ∣𝑥, 𝑖) in the likelihood since it is already estimated in step one. We then maximize the pseudo-
                                    〈         〉
likelihood function to estimate 𝛽, 𝛽,     ˜ 𝛿 .



tially distinguished without exclusion restriction if the researcher has access to at least three-period panel data. Also,
see Section 6 for discussions related to non-stationariy, longer panels and unobserved state variables or unobserved
heterogeity.




                                                             21
4.1      Discussions

       Now we discuss a few practical issues that may arise in the estimation.


Solutions to the Equation System (19) and (22). Even though the equation system (19) and (22)
have the same number of equations and unknowns, there is no guarantee that the system will have
                                              〈       〉
                                                  ˜ 𝛿 .16 In practice, we deal with the potential
a unique solution for any arbitrary values of 𝛽, 𝛽,
                                                                                        〈      〉
                                                                                            ˜ 𝛿 ,
no solution, or multiple solution problem as follows. If for a particular combination of 𝛽, 𝛽,
we are unable to find a solution to the equation system (19) and (22), we will simply set the objec-
                [ (            〈       〉)]
tive
     ∑
            std 𝑢 ˆ 𝑖 𝑥𝑟 , 𝑥       ˜ 𝛿
                           ˜𝑒 ; 𝛽, 𝛽,      in (25) for estimation method 1 to +∞ (i.e., a sufficiently
          𝑥𝑟 ∈𝒳𝑟
large value), and the objective likelihood in (27) for estimation method 2 to −∞ (i.e., a sufficiently
                                                                          〈       〉
small value). On the other hand, if for some particular combination of 𝛽, 𝛽,   ˜ 𝛿 , we find multi-
ple solutions to the equation system, we will, among all the solutions, pick the smallest values of
the objective (25) for estimation method 1 and pick the highest likelihood in (27) for estimation
method 2.


Size of the Support of exclusion Restriction State Variables 𝒳𝑒 .             As we described in Section 3.2,
the identification of the model comes from the presence of state variables that satisfy the exclusion
                                               〈      〉
                                                   ˜ 𝛿 by requiring that only those combinations
restriction 5. The exclusion variables identify 𝛽, 𝛽,
of the discount factors that can explain the observed data with payoffs ⟨{𝑢𝑖 (𝑥) : 𝑖 ∈ ℐ∖ {0} , 𝑥 ∈ 𝒳 }⟩
that do not vary with respect to changes in 𝑥𝑒 . Since we have three unknown discount factors
〈       〉
     ˜ 𝛿 , we need at least three cross-𝑥𝑒 restrictions, i.e., a minimum of four different points in the
  𝛽, 𝛽,
support 𝒳𝑒 are required. Also, the requirement for the size of the support 𝒳𝑒 seems to differ be-
tween the two proposed estimation methods. In estimation method 1, the larger the size of 𝒳𝑒 , the
                                          [ (            〈       〉)]                   〈        〉
                               ∑
smoother the objective function 𝑥𝑟 ∈𝒳𝑟 std 𝑢ˆ 𝑖 𝑥𝑟 , 𝑥       ˜ 𝛿
                                                     ˜𝑒 ; 𝛽, 𝛽,                            ˜ 𝛿 .
                                                                     is with respect to 𝛽, 𝛽,
The effect of the size of 𝒳𝑒 on the properties of the objective function in (27) is less pronounced.


Parametric Utility Function Specifications. Even though we described how ⟨{𝑢𝑖 (𝑥) : 𝑖 ∈ ℐ∖ {0} , 𝑥 ∈ 𝒳 }⟩
                                                                                       〈      〉
                                                                                           ˜ 𝛿 .
can be non-parametrically solved from equation system (19) and (22) for given values of 𝛽, 𝛽,
In practice, we may often parameterize it as a function of observed state variables 𝑥, including the
exclusion variables 𝑥𝑒 . In such cases, the estimation methods described above can be adapted to
minimize the standard deviation of the coefficient estimates for the exclusion variables 𝑥𝑒 for es-
timation method 1. Estimation method 2, though, still goes through unmodified (see Footnote 18
for an illustration in our Monte Carlo experiments).
  16
   As we show in Section 3.3, the system does have a unique solution under the exponential discounting case, i.e.,
     ˜ = 𝛽 = 1, for any 𝛿 ∈ (0, 1) .
when 𝛽


                                                       22
4.2     Monte Carlo Experiments

      In this section we provide Monte Carlo evidence for the identification of discount factors in a
dynamic discrete choice model using the two estimation methods described above. In this simple
Monte Carlo exercise, we consider a binary choice decision problem, 𝑖 ∈ {0, 1} , facing an agent
with infinite horizon, stationary state transition, and linear utility functions. There are two state
variables 𝑥𝑟 and 𝑥𝑒 . The state variable 𝑥𝑟 ∈ 𝒳𝑟 = {0, 1, 2, 3, 4, 5}, affects both instantaneous utility
and state transition; while state variable 𝑥𝑒 ∈ 𝒳𝑒 = {0, 1, 2, 3}, affects only the state transition.17
We parameterize the instantaneous payoff functions 𝑢𝑖 (𝑥𝑟 ) as follows: 𝑢1 (𝑥𝑟 ) = 𝛼0 + 𝛼1 𝑥𝑟 ; and
normalize 𝑢0 (𝑥𝑟 ) = 0 for all 𝑥𝑟 . The true parameters are set at: 𝛼0 = −0.1, 𝛼1 = 0.5, 𝛿 = 0.8,
             ˜ = 0.7.18 For each sample size (240,000, 120,000 and 12,500), we randomly generate
𝛽 = 0.6, and 𝛽
2,000 simulation samples, and estimate the discount factors and corresponding utility parameters
to examine the differences in performance of these two estimation methods.
      Table 2 presents the Monte Carlo results. It shows that both estimation methods do a good
job in recovering the true parameter values in large samples. Estimation results improve with in-
creases in sample sizes. Because the second estimation strategy, the maximum pseudo-loglikelihood
method, has only one loop in the second step, it is the method we use in our empirical exercise.


5     An Empirical Application: Mammography Decisions

   In this section, we present an illustrative application of the identification and estimation method
   〈        〉
       ˜ 𝛿 described in Sections 3.2 and 4. We provide estimates of these key time preference pa-
for 𝛽, 𝛽,
rameters and then examine the role of present bias and naivety in women’s decisions to undertake
mammography.


   17
      The state transition matrices are generated as follows. We first generate two random matrices 𝑀0 and 𝑀1 each with
dimension #𝒳𝑟 × #𝒳𝑒 = 6 × 4 = 24, with each entry a random number generated from a uniform [0, 1] distribution.
We then normalize the entry in each row by its row sum to ensure a proper probability matrix. The resulting matrices
are denoted Π0 and Π1 , the choice-specific state transition probabilities. The (𝑗, 𝑘)-th entry of matrix Π𝑖 where (𝑗, 𝑘) ∈
{1, ..., 24}2 is the probability that (𝑥′𝑟 , 𝑥′𝑒 ) takes on 𝑘-th combination condition on (𝑥𝑟 , 𝑥𝑒 ) taking on 𝑗-th combination
in this period and action chosen is 𝑖 ∈ {0, 1} . The matrices Π1 and Π0 are assumed to be known by the decision maker;
and are directly taken to be the state transition probabilities in our Monte Carlo exercise reported in Table 2.
   18
      Given the assumed linear utility functions in this Monte Carlo exercise, the objective function for the outer loop of
step two of the first estimation strategy can be simplified to:
                                                    〈      〉
                                                        ˜ 𝛿 = arg min ∣∣𝛼2 (𝑥𝑒 )∣∣.
                                                     𝛽, 𝛽,
                                                                   {𝛽,𝛽,𝛿
                                                                      ˜ }

                                                                                                                   〈      〉
where 𝛼2 is the estimated utility parameter for the exclusive restriction variables for a given combination 𝛽, 𝛽,      ˜ 𝛿 and
∣∣.∣∣ refers to the Euclidean metric.




                                                              23
  Estimation Method                 Estimation Strategy I                          Estimation Strategy II
  Parameters              𝛿         𝛽       ˜
                                            𝛽       𝛼0        𝛼1         𝛿         𝛽       ˜
                                                                                           𝛽       𝛼0       𝛼1
  True Values                 0.8    0.6     0.7     -0.1      0.5           0.8    0.6     0.7     -0.1      0.5
  Sample Size: 240, 000
        Mean              0.837     0.633   0.691   -0.098    0.499      0.815     0.588   0.696   -0.100   0.500
        Std. Dev.         0.064     0.064   0.069    0.006    0.002      0.045     0.050   0.057   0.007    0.002
  Sample Size: 120, 000
        Mean              0.860     0.632   0.672   -0.096    0.499      0.821     0.584   0.691   -0.099   0.499
        Std. Dev.         0.066     0.079   0.079    0.008    0.003      0.053     0.078   0.077   0.009    0.003
  Sample Size: 12, 500
        Mean              0.874     0.603   0.678   -0.095    0.499      0.838     0.553   0.713   -0.098   0.500
        Std. Dev.         0.104     0.162   0.119    0.020    0.008      0.107     0.160   0.123   0.020    0.009

Table 2: Monte Carlo Results Under the Two Proposed Estimation Methods.

Notes: For each sample size, we generate 2000 random simulation samples. The Mean and Standard Deviations of the
estimated parameters are with respect to the 2000 samples.



5.1      Background on Mammography

       Among American women, breast cancer is the third most common cause of death, and the
second leading cause of cancer death. According to American Cancer Society, from birth to age
39, one woman in 231 will get breast cancer (< 0.5% risk); from age 40-59, the chance is 1 in 25 (4%
risk); from age 60-79, the chance is 1 in 15 (nearly 7%). Assuming that a woman lives to age 90,
the chance of getting breast cancer over the course of an entire lifetime is 1 in 7, with an overall
lifetime risk of 14.3%.19
       Breast cancer takes years to develop. Early in the disease, most breast cancers cause no symp-
toms. When breast cancer is detected at a localized stage before it spreads to the lymph nodes),
the 5-year survival rate is 98%. If the cancer has spread to nearby lymph nodes (regional disease),
the rate drops to 81%. If the cancer has spread (metastasized) to distant organs such as the lungs,
bone marrow, liver, or brain, the 5-year survival rate is 26%.
       A screening, mammography, is the best tool available to find breast cancer before symptoms
appear. Mammography can often detect a breast lump before it can be felt and therefore save
lives by finding breast cancer as early as possible. For women over the age of 50, mammography
  19
    As a useful comparison, breast cancer has a higher incidence rate than lung cancer in the US. In 2004, there were
217, 440 new cases for breast cancer in the U.S. (American Cancer Society).




                                                         24
have been shown to lower the chance of dying from breast cancer by 35%.20,                     21   Leading experts,
the National Cancer Institute, the American Cancer Society, and the American College of Radiol-
ogy recommend annual mammography for women over 40.22 The guideline issued by the U.S.
Preventive Services Task Force in 2002 also recommended mammography screening for women
beginning at age 40 every 12-24 months in order to reduce the risk of death from breast cancer.23


5.2      Data

       The data used in this analysis are from the Health and Retirement Study (HRS). The HRS is a
nationally representative biennial panel study of birth cohorts 1931 through 1941 and their spouses
as of 1992. The initial sample includes 12,652 persons in about 7,600 households who have been
interviewed every two years since 1992. The most recent available data are for year 2008 (wave
9). The survey history and design are described in more details in Juster and Suzman (1995).
Since the HRS started asking women questions about their usage of mammography in 1996, our
sample is limited to women interviewed in the HRS from 1996 to 2008. We focus on the age group
51 to 64, and exclude those observations with missing values for any of the critical variables.24
We also exclude those who have ever been diagnosed of (breast) cancer,25 since those who are
diagnosed of cancer might be of a different group who do not make decisions on mammography
or any other preventive health care the same way as do others. Our final sample consists of 12,307
observations (each observation is a two-period short panel pooled from two consecutive waves)
for 7,021 individuals.

  20
      Source: American Cancer Society.
  21
      Also note that finding breast cancers early with mammography has also meant that many more women being
treated for breast cancer are able to keep their breasts. When caught early, localized cancers can be removed without
resorting to breast removal.
   22
      See American Cancer Society website: http://www.cancer.org/Cancer/BreastCancer/DetailedGuide. Women age
40 and older should have a screening mammogram every year and should continue to do so for as long as they are in
good health.
   23
      The new guideline by the U.S. Preventive Service Task Force issued in November of 2009 changed its recommenda-
tion for women in their 40s. Now the guideline recommends that women in their 40s should not get routine mammo-
grams for early detection of breast cancer. For women ages 50 to 74, it recommends routine mammography screenings
every two years. The American Cancer Society maintains its original recommendation that women from their 40s
should seek annual mammography.
   24
      The key variables are education status, non-Hispanic white, education, self-reported health, insurance status,
whether father and mother are alive or died after age 70, father and mothers education, income, and mammography
usage (see Table 3 for their summary statistics).
   25
      For those who entered in 1992 (i.e. the first wave), we know whether they have been diagnosed of breast cancer as
of 1992. But for those who entered HRS in later waves, we only know whether any cancer has been diagnosed of since
the survey from 1994 did not ask about breast cancer specifically.




                                                          25
5.3     Descriptive Statistics

      Table 3 provides summary statistics of the key variables for the sample we use in our empirical
analysis. The sample of women we select are aged from 51 to 64 (note that we are combining two-
period panels using individuals that appear in two consecutive samples), with an average age of
57.8. A large majority of the sample are non-Hispanic white (80%) and with at least high school
education (78%). The average household income in our sample is about 49,680 dollars. 23% of the
sample has a self-reported bad health and about 76% of the women undertook mammogram in
the survey year. About 1.5% of the women who were surveyed in a wave died within two years.
72% of our sample reported having at least one insurance plan. Finally, about 75% of the mothers
(respectively, about 61% of the fathers) of the women in our sample are either still alive or died
at age greater than 70 at the time of the interview. 43% of the mothers (respectively, about 40% of
the fathers) of the women in our sample finished at least high school. From one wave to the next
wave, there is slight increase in the fraction of survivors who report bad health (an increase from
23% to 25%).


5.4     Decision Time Line

      Figure 1 depicts the time line for mammography decisions for women in our sample. As we
mentioned earlier, we only consider women who are alive and have not yet been diagnosed with
any cancer (thus not breast cancer) in the first period. Given her period-1 state variables, she makes
the decision of whether to undertake mammography. Mammography detects breast cancer with
very high probability, though not for certain, if the woman has breast cancer. In the event that the
woman has breast cancer, early detection of breast cancer will lead to higher survival probability.
      To fully capture the diagnostic nature of mammography, we would need to have information
about whether the woman has breast cancer at any period, and estimate the probability of detect-
ing breast cancer with (𝑝1 in Figure 1) and without (𝑝2 in Figure 1) mammogram. However, we do
not have access to such data. In HRS, even though we have information on women’s mammogra-
phy choices from 1996 on and we know whether their doctors have told them that they have any
cancer, we do not have information on which kind of cancer they have been diagnosed of.26
      Due to these data issues, we decide to go directly from the mammography decision to the
live/death outcome and health status if alive (see our empirical specification below), without
going through the intermediate step (having breast cancer or not). That is, we simply capture the
ultimate effect of undertaking mammography as to lower the probability of dying, and to lower
   26
      Even for those over age 65 with matching Medicare claim data, the number of observations is not big enough for
us to get the needed probabilities of being diagnosed with breast cancer with and without mammography stratified by
all the state variables we want to control in our model such as age, race, health status, income, and education status.


                                                          26
          Variable                                             Mean    Std. Dev.    Min      Max       Obs.
          Mammogram                                            0.760   0.427        0        1         12307
          Bad Health                                           0.230   0.421        0        1         12307
          Married                                              0.704   0.456        0        1         12307
          White (Non-Hispanic)                                 0.797   0.402        0        1         12307
          High School                                          0.775   0.417        0        1         12307
          Age                                                  57.82   3.95         51       64        12307
          Death                                                0.015   0.120        0        1         12307
          Insurance                                            0.720   0.449        0        1         12307
          Household Income ($1000)                             49.68   68.34        0.101    2,136     12307
          Log of Household Income                              10.31   1.06         4.62     14.57     12307
          Mother Still Alive or Died After Age 70              0.750   0.432        0        1         12307
          Mother Education (High School or Higher)             0.431   0.495        0        1         12307
          Father Still Alive or Died After Age 70              0.611   0.488        0        1         12307
          Father Education (High School or Higher)             0.404   0.491        0        1         12307
          Bad Health (𝑡 + 1)                                   0.249   0.432        0        1         12128
          Household Income (𝑡 + 1) ($1000)                     48.75   178.70       0.103    17,600    12128
          Log of Household Income (𝑡 + 1)                      10.27   1.05         4.64     16.68     12128

Table 3: Summary Statistics of Key Variables in the Estimation Sample.

Note: The last three variables in the table are observed only for those who survive to the second period.




                                                          27
                                                    Alive and Does Not
                                                    Detect Breast Cancer
                                                            @
                                                             @
                                                         

                                                                        
                                                                    @
                                                                         @


                                                                          
                                              

                                                   
                                             
                                             =                             @R
                                                                            @
                                   Mammogram                              No Mammogram
                                                                                  Q
                                 𝑝1 
                                        Q
                                          Q                                𝑝2      Q
                                 
                                 
                                 +         Qs
                                            Q                             
                                                                          +           Q
                                                                                       s
                                                                                       Q
                              Detect     Does Not Detect             Detect        Does Not Detect

                         𝑝3 A                     J               𝑝4 J                     @
                                 A                 J                      J                 R
                                                                                             @
                                 U
                                  A                 ^
                                                     J                     ^
                                                                            J           
                       Alive     Dead     Alive     Dead          Alive    Dead     Alive   Dead


Figure 1: The Timeline for Mammography Decisions.

Notes: (1). 𝑝1 > 𝑝2 : mammogram can detect breast cancer at its early stage; 𝑝3 > 𝑝4 : survival rate is higher
when breast cancer is detected at earlier stage.
(2). The states with rectangular framebox are those in which she will keep making decisions on whether to undertake
mammography.



the probability of being in bad health status if alive.


5.5     Empirical Specification

      For this application, we assume that each woman in our sample decides whether or not to
undertake mammography each period (𝑖 = 1 if she does and 𝑖 = 0 if she does not). From the
previous section on identification, we need to impose some normalization of the contemporaneous
utilities. We normalize the individual’s instantaneous utility at the death state to be zero. Note
that no decision is necessary if one reaches the death state.
      Now we describe the state variables we use in our empirical specification. They include: Age
(A GE); Education Status (H IGH S CHOOL ); Bad Health (B AD H EALTH ) which indicates whether the
individual self reports bad health; Log of Per Capita Income (L OG I NCOME), Death (D EATH) and
whether her mother is still alive or died at age greater than 70 (M OTHER 70).
      If an individual stays alive, then we specify her utility from taking mammogram relative to not
taking mammogram as:

                     𝑢1 (𝑥) − 𝑢0 (𝑥) = 𝛼0 + 𝛼1 B AD H EALTH + 𝛼2 L OG I NCOME + 𝜀𝑡 ,                          (28)




                                                             28
where “B AD H EALTH” is a binary variable indicating whether the agent is in bad health or not
at time 𝑡; “L OG I NCOME” denotes the logarithm of household income of the agent at time 𝑡, 𝛼0
and 𝛼1 are the utility parameters, and 𝜀𝑡 denotes difference in the choice-specific utility shocks
at time 𝑡. It is important to remark that even though the other state variables A GE, W HITE and
H IGH S CHOOL do not show up in the above specification, it does not mean that these variables do
not affect the instantaneous utility of the individual; what it means is that these variables affect
the instantaneous utility under action 1 (mammogram) and action 0 (no mammogram) in exactly
the same way.
       The agents make their decisions about whether to get mammography by comparing the ex-
pected summations of current and discounted future utilities from each choice. Individuals are
uncertain about their future survival probabilities, and if alive, the transition probabilities of fu-
ture health and income. These probabilities depend on their choices about whether or not to
get mammography; time-variant state variables including their lagged health status, their lagged
income, and their age, denoted as A GE; and time-invariant state variables including their race,
denoted by a binary variable W HITE, their education status H IGH S CHOOL, and the longevity of
their mothers, denoted by the binary variable M OTHER 70 which takes value 1 if the mother is still
alive or died at the age older than 70 and 0 otherwise, and M OTHER H IGH S CHOOL (a binary vari-
able which takes value 1 if mother finished high school or more, and 0 otherwise), or analogously,
FATHER 70 and FATHER H IGH S CHOOL (see Table 5 for the specifications).


Exclusion Variables.        From the assumptions for exclusion restriction variables (see Assumption
5), we know that any variables that do not enter the relevant instantaneous payoff (after normal-
ization), i.e. 𝑢1 (𝑥) − 𝑢0 (𝑥) , but affect the transition of payoff relevant state variables, can qualify
as exclusion variables. Since only the variables B AD H EALTH, L OG I NCOME and D EATH enter the
instantaneous payoff functions (after normalization), the other variables that affect the transition
of the above three variables can all qualify as potential exclusion restriction variables, including
M OTHER 70, W HITE, M ARRIED, H IGH S CHOOL, A GE, or any other variables that one may find to
have important effects on the transition of the state variables relevant to the instantaneous payoff
functions, but do not directly affect the instantaneous payoff function (e.g., we experimented with
insurance status in some of our specifications).27 In what follows, we report estimation results
under two sets of exclusion variables. The sets of exclusion restriction variables are listed in the
last panel in Table 6, and they differ in whether we use M OTHER 70 and M OTHER H IGH S CHOOL
or we use FATHER 70 and FATHER H IGH S CHOOL. The first step estimates reported in Table 4 and
  27
    See, e.g., Ayanian et al (1993) and Decker (2005) for the relationship between health insurance and health outcomes
for women with breast cancer.



                                                          29
                 Variable                                     (1)                            (2)
                                                  Coeff. Est.       Std. Err.    Coeff. Est.       Std. Err.
                 B AD H EALTH                     0.049             (0.059)      0.022             (0.062)
                 M ARRIED                         0.220***          (0.058)      0.212***          (0.060)
                 W HITE                           -0.212***         (0.060)      -0.159***         (0.062)
                 I NSURANCE                       0.351***          (0.048)      0.354***          (0.050)
                 H IGH S CHOOL                    0.373***          (0.061)      0.347***          (0.063)
                 L OG I NCOME                     0.318***          (0.027)      0.324***          (0.028)
                 M OTHER 70                       -0.106**          (0.054)
                 M OTHER H IGH S CHOOL            0.107***          (0.050)
                 FATHER 70                                                       0.081*            (0.048)
                 FATHER H IGH S CHOOL                                            0.093***          (0.051)
                 A GE                             0.008             (0.006)      0.007             (0.006)
                 C ONSTANT                        -3.032***         (0.451)      -3.185***         (0.471)
                 Pseudo-𝑅2                                 0.0385                         0.0380

Table 4: Determinants of Mammography Decisions: The Choice Probabilities from Logit Regres-
sion.
Notes: *, **, *** represents statistical significance at 10%, 5% and 1% respectively. Robust standard errors are presented.



5, as well as Figure 2, suggest that both mother and father side variables affect the transitions of
the payoff relevant state variables.


5.6     Estimation Results

5.6.1    First Step Estimates

      As we noted earlier, our estimation strategy has two steps. In the first step, we need to use
the data to estimate choice probabilities, and the state transitions. Here we report these first-step
estimation results. The choice probabilities and the death probability are estimated using Logit
regressions; but the transition of B AD H EALTH and L OG I NCOME are estimated non-parametrically.


Logit Estimates of the Probability of Choosing Mammography as a Function of The State
Variables. Table 4 produces the reduced form Logit regression results for the determinants of
whether a woman will undertake mammogram in a given year under two specifications on the
exclusion variables. Column (1) uses M OTHER 70 and M OTHER H IGH S CHOOL together with other
exclusion variables, while Column (2) uses FATHER 70 and FATHER H IGH S CHOOL instead. In the


                                                             30
                 Variable                                     (1)                            (2)
                                                  Coeff. Est.       Std. Err.    Coeff. Est.       Std. Err.
                 M AMMOGRAM                       -0.525***         (0.174)      -0.498***         (0.182)
                 B AD H EALTH                     1.733***          (0.191)      1.715***          (0.193)
                 M ARRIED                         0.105             (0.197)      0.165             (0.202)
                 W HITE                           -0.132            (0.191)      -0.105            (0.202)
                 I NSURANCE                       0.209             (0.193)      0.357*            (0.205)
                 H IGH S CHOOL                    0.295             (0.198)      0.400*             (0.206)
                 L OG I NCOME                     -0.240***         (0.082)      -0.247***         (0.080)
                 M OTHER 70                       -0.366**          (0.180)
                 M OTHER H IGH S CHOOL            0.045             (0.194)
                 FATHER 70                                                       -0.325*           (0.175)
                 FATHER H IGH S CHOOL                                            -0.295            (0.206)
                 A GE                             0.073***          (0.022)      0.067***          (0.017)
                 C ONSTANT                        -6.609***         (1.557)      5.20              (20.47)
                 Pseudo-𝑅2                                 0.1073                          0.1055

Table 5: Determinants of Probability of Dying in Two Years.
Notes: *, **, *** represents statistical significance at 10%, 5% and 1% respectively. Robust standard errors are presented.



specification reported in Column (1), we find that women who are married with higher house-
hold income, with high school education, and with health insurance are more likely to undertake
mammograms, while white women are less likely than black women to undertake mammogram.
All these coefficient estimates are significant at 1%. Interestingly, we also find that women whose
mothers are still alive or died after age 70 are less likely, but those whose mothers have at least high
school are more likely to undertake mammograms. Finally, older women and women with bad
health are more likely to undertake mammogram, though these coefficients are not statistically
different from zero.
       In the specification reported in Column (2), where we use the information about women’s
father as the exclusion variables, none of the other coefficient estimates change qualitatively. In-
terestingly we found that FATHER 70 and FATHER H IGH S CHOOL both positively affect women’s
probability of undertaking mammogram.28
  28
    Note that the coefficient estimates from such reduced form regressions, while informative, does not shed light on
the mechanisms under which the observed relationships between a variable and the mammogram decision arises. For
example, we see in Table 4 that women whose mother is still alive or died after age 70 are less likely to undertake
mammogram. But it is not clear from the table why. The structural analysis we undertake below will help us to achieve



                                                             31
Transition Probabilities of the Payoff Relevant State Variables: Determinants of the Probabil-
ity of Dying in Two Years         Table 5 reports the Logit regression results for the probability of dying
in two years, again using two sets of exclusion variables, with Column (1) using M OTHER 70 and
M OTHER H IGH S CHOOL and Column (2) using FATHER 70 and FATHER H IGH S CHOOL. The coeffi-
cient estimates show that undertaking mammogram significantly lowers the probability of death
(notice that the average age of the sample is about 58 years). Not surprisingly, women with bad
health are more likely to die, but mammogram reduces the probability of dying conditional on
bad health. Also note that women whose mothers are either still alive or died after age 70 as well
as women whose fathers are either still alive or died after age 70, are less likely to die, suggesting
a genetic link of longevity between mothers as well as fathers and daughters.


Transition Probabilities of the Payoff Relevant State Variables: Evolution of Bad Health in Two
Years Figure 2 depicts a subset of the results from the non-parametric estimation of the evolution
of B AD H EALTH for a selective combinations of the other state variables and the mammogram
choice, for our exclusion restriction variable specification listed in Column (1) in Table 6. For
example, Panel (a) shows that how the probability of having bad health in period 2 is affected by
mammogram decision in the previous period and L OG I NCOME, for women whose mothers are
alive or died after age 70 and had bad health in the previous period. It shows that the probability
of bad health decreases with Log Income, and is lower if one undertakes mammogram in the
previous period. Similar negative relationship between the probability of bad health and income is
also shown in other panels. Across all panels, we see that mammogram always reduces probability
of bad health , and good health in the previous period predicts a higher probability of good health
this period, and mother living or having died after 70 reduces the probability of bad health. A
similar non-parametric estimation of L OG I NCOME is also conducted.


5.6.2   Second Step Estimates: Utility Parameters and Discount Factors

   Table 6 reports the estimation results for the parameters in the instantaneous utility function
                                                                ˜ as well as standard errors cal-
specification (28) and the identified discount factors 𝛿, 𝛽 and 𝛽,
culated from the asymptotic distributions of the maximum pseudo-likelihood estimator. We re-
port results from two specifications using different sets of exclusion restriction variables. In the
specification reported in Column 1, we include only W HITE, A GE , M ARRIED , H IGH S CHOOL , I N -
SURANCE ,    M OTHER 70, and M OTHER H IGH S CHOOL as the exclusion restriction variables, while
in the specification reported in Column 2, we replace M OTHER 70, and M OTHER H IGH S CHOOL by
FATHER 70, and FATHER H IGH S CHOOL.
a better understanding of the observed reduced form relationship reported in Table 4.


                                                         32
33
     Figure 2: Non-parametric Estimate of the Probability of B AD H EALTH as a Function of L OG I NCOME, Conditional on M OTHER 70,
     B AD H EALTH and M AMMOGRAM in Previous Period.
                                                                     (1)             (2)
                                Panel A: Instantaneous Utility Function Parameters
                                                                  -0.278***       -0.443***
                               B AD H EALTH
                                                                  (0.084)         (0.102)
                                                                  1.205***        1.278***
                               L OG I NCOME
                                                                  (0.060)         (0.034)
                                                                   -1.035         -2.079***
                               C ONSTANT
                                                                   (0.205)        (0.026)
                                         Panel B: Time Preference Parameters
                                                                  0.722***        0.795***
                               𝛿
                                                                  (0.089)         (0.026)
                                                                  0.718***        0.752***
                               𝛽
                                                                  (0.070)         (0.019)
                                                                  0.9999***       0.9999***
                               ˜
                               𝛽
                                                                  (0.060)         (0.000)
                                               Panel C: Hypothesis Tests
                               H0 : 𝛽 = 1                          Reject          Reject
                                    ˜=𝛽
                               H0 : 𝛽                              Reject          Reject
                               Exclusion Restriction Variables:
                               W HITE                                Yes             Yes
                               A GE                                  Yes             Yes
                               M ARRIED                              Yes             Yes
                               H IGH S CHOOL                         Yes             Yes
                               I NSURANCE                            Yes             Yes
                               M OTHER 70                            Yes             No
                               M OTHER H IGH S CHOOL                 Yes             No
                               FATHER 70                             No              Yes
                               FATHER H IGH S CHOOL                  No              Yes

Table 6: Parameter Estimates for the Instantaneous Utility Function and Time Preference Parame-
ters Under Two Sets of Exclusive Restriction Variables.

Notes: (1). The last panel indicates the exclusive restriction variables used in the specification in that column,
with ”Yes” meaning the variable is used, and ”No” otherwise; (2). Standard errors for parameter estimates are in
parenthesis, and *** indicates significance at 1% level; (3). For hypothesis tests reported in Panel C, all are rejected with
𝑝-value less than 0.01.




                                                             34
      The parameter estimates, both for the instantaneous payoff function parameters and the time
preference parameters, are quite similar both qualitatively and quantitatively, across the two spec-
ifications. We find that having bad health lowers the utility of undertaking mammography rela-
tive to not undertaking mammography. We also found that the relative utility of undertaking
mammography increases with income, consistent with the finding in Table 4 that women with
higher incomes are more likely to undertake mammography. The estimated negative constant
term, though not statistically significant for specification 1, is consistent with the idea that preven-
tative health care typically involves huge one time instantaneous cost, which once combined with
present bias and naivety about present bias might lead to undesirable health-related decisions.
   More interestingly, we estimate 𝛿, 𝛽 and 𝛽˜ to be 0.722, 0.718 and 0.9999 respectively in speci-
fication 1 and 0.795, 0.752, and 0.9999 respectively in specification 2. These point estimates show
that women exhibit substantial present bias (𝛽 < 1) as well as naivety about their present bias
 ˜ > 𝛽) when making mammography decisions. In Panel C, we reported the results from three
(𝛽
                                                                  ˜ = 𝛽 (no naivety) are rejected
hypothesis tests: the null hypothesis 𝛽 = 1 (no present bias) and 𝛽
under both specifications with 𝑝-value less than 0.01.
      It is also interesting to compare our estimates for 𝛽𝛿 with what is in the literature. Using the
estimates of 𝛽 and 𝛿 reported in Table 6, we have that our estimates for 𝛽𝛿 is equal to 0.718∗0.722 ≈
0.518 under specification 1 and is equal to 0.752 ∗ 0.795 ≈ 0.598 under specification 2. This can be
compared with the estimate in Fang and Silverman (2009) where they estimate 𝛽 to be 0.338 and 𝛿
to be 0.88, with 𝛽𝛿 ≈ 0.30 for a group of single mothers with dependent children. It is important to
note that our sample period is two years, while Fang and Silverman (2009)’s sample period is one
year; also the sample of women in this paper are older and have very different social economic
status (e.g. education and income) from the sample in Fang and Silverman (2009).


5.7     Counterfactual Experiments

      Table 7 reports the mammography compliance rates predicted by the model and implied by
two counterfactual experiments where in experiment [1], we assess the mammography rates pre-
                                             ˜ equal to the estimated 𝛽,
dicted by the model if we hypothetically set 𝛽                        ˆ and in experiment [2],
            ˜ and 𝛽 to 1. Experiment [1] allows us to assess the impact of naivety on mammog-
we set both 𝛽
raphy take-up rate, while experiment [2] allows us to assess the impact of both present bias and
the naivety about present bias. If women in our sample are present-biased but fully sophisti-
cated (i.e. in experiment 1), then the mammography compliance rate increases from 76.12% in the
data to 77.96%, and both are which is very similar to a baseline model predicted compliance rate
(76.09%). If, however, we have a case where the agents are exponential discounters (i.e., in exper-
iment 2), that is, they do not have time-inconsistent preference, then the compliance rate goes up

                                                   35
                                                                    Exclusion Restriction Variables
                                                                      (1)                (2)
             Data                                                   0.7612             0.7631
             Model                                                  0.7609             0.7794
             Counterfactual Experiments:
                             ˜ = 𝛽[= 𝛽]
             [1] No Naivety: 𝛽       ˆ                              0.7796             0.7874
                                                 ˜=𝛽=1
             [2] No Naivety and No Present Bias: 𝛽                  0.8196             0.8099

Table 7: Mammography Compliance Rates Predicted by the Model and Implied by Different
Counterfactual Experiments.

Notes: (1). The sample sizes slightly vary as we change the set of the exclusive restriction variables, which ex-
plains the changes in the mommography compliance rates in the data; (2). The exclusive restriction variables used in
Columns 1 and 2 corresponds to those used in specifications 1 and 2 in Table 6 respectively.



from 76.12% to 81.96%, which represents a 23.5% (= [(1 − 0.7612) − (1 − 0.8196)]/(1 − 0.7512))
reduction in the mammography noncompliance rate. Thus, time-inconsistent preferences caused
by present-bias and naivety about present-bias indeed have significant policy implications for the
low compliance rates of preventive health care in the U.S.


6    Conclusion and Discussions

    This paper extends the semi-parametric identification and estimation method for dynamic dis-
crete choice models using Hotz and Miller’s (1993) conditional choice probability (CCP) approach
to the setting where individuals may have hyperbolic discounting time preferences and may be
naive about their time inconsistency.
    Our analysis showed that the three discount factors, the present bias factor 𝛽, the standard
                                                        ˜ for naive agents can be separately iden-
discount factor 𝛿 and the perceived present bias factor 𝛽
tified. The key identifying restriction is that there exist variables that do not directly enter the
instantaneous utility function but affect the transition of other payoff relevant state variables.
    We proposed two estimation strategies based on the identification argument, and implement
the proposed estimation method to the decisions of undertaking mammography to evaluate the
importance of present bias and naivety in the under-utilization of mammography. Our estimates
are consistent with the presence of both present bias and naivety about present bias. In our coun-
terfactual experiments, we found that time-inconsistent preferences caused by present-bias and
naivety about present-bias indeed have significant policy implications for the compliance rates of
mammography take-up rates.

                                                        36
       In our paper, we also assume that the model is stationary. In many applications, such station-
arity assumption may not be valid. However, we show in the Appendix that the identification
arguments, properly modified, still work for the case of finite horizon models with non-stationary
state transitions. Of course, estimating finite horizon models with non-stationary state transitions
requires longer panels.
       In this paper, we assumed that other than the choice-specific idiosyncratic payoff shocks,
which we assume to be serially and cross-sectionally independent, we do not allow for any ob-
served heterogeneity or unobserved state variables among individuals. Recent results by Kasa-
hara and Shimotsu (2009) and Hu and Shum (2009) show that the conditional choice probabil-
ities, which are crucial for implementing Hotz-Miller type estimators, can be identified in the
presence of unobserved heterogeneity or unobserved state variables in the context of dynamic
discrete choice models with exponential discounting.29 Whether their arguments still work for
dynamic discrete choice models with hyperbolic discounting preferences remains an open ques-
tion. Provided that conditional choice probabilities for any given state, including both observed
and unobserved state variables, can be identified, the estimation methods we proposed here may
be still valid. This is an important question we will examine in future research.


References

 [1] Aguirregabiria, Victor, and Pedro Mira (2007a). “Sequential Estimation of Dynamic Discrete
        Games.” Econometrica, Vol 70, 1519-1543.

 [2] Aguirregabiria, Victor, and Pedro Mira (2007b). “Dynamic Discrete Choice Structural Models:
        A Survey.” Working Paper 297, Department of Economics, University of Toronto.

 [3] Ainslie, G., Picoeconomics: The Strategic Interaction of Successive Motivational States Within the
        Person (Cambridge [England]; New York: Cambridge University Press, 1992).

 [4] Arcidiacono, P., H. Sieg, and F. Sloan (2007). “Living Rationally Under the Volcano? An
        Empirical Analysis of Heavy Drinking and Smoking.” International Economic Review, 48(1),
        37-65.

 [5] Arcidiacono, P., and R. Miller (2007). “CCP Estimation of Dynamic Discrete Choice Models
        with Unobserved Heterogeneity.” Working Paper.
  29
    Arcidiacono and Miller (2007) proposed an EM algorithm to estimate such models with unobserved heterogeneity
using conditional choice probabilities.




                                                      37
 [6] Ayanian, J. Z., B. A. Kohler, T. Abe, and A. M. Esptein (1993). “The Relation between Health
    Insurance Coverage and Clinical Outcomes among Women with Breast Cancer.” The New
    England Journal of Medicine, 329(5), 326-331.

 [7] Bajari, Patrick, C. Lanier Benkard and Jonathan Levin (2007). “Estimating Dynamic Models
    of Imperfect Competition.” Econometrica, vol. 75, No. 5, 1331-1370.

 [8] Bajari, Patrick, Han Hong and Denis Nekipelov (2010). “Game Theory and Econometrics: A
    Survey of Some Recent Research.” Econometric Society World Congress in Shanghai.

 [9] Barro, Robert J., “Ramsey Meets Laibson in the Neoclassical Growth Model,” Quarterly Jour-
    nal of Economics 114 (November 1999), 1125-1152.

[10] Carrillo, Juan D., and Thomas Mariotti, “Strategic Ignorance as a Self-Disciplining Device,”
    Review of Economic Studies 67 (July 2000), 529-544.

[11] Chung, Doug, Thomas J. Steenburgh and K. Sudhir (2009). “Do Bonuses Enhance Sales Pro-
    ductivity? A Dynamic Structural Analysis of Bonus-Based Compensation Plans.” Working
    Paper, Yale School of Management.

[12] Decker, S. L. (2005). “Medicare and the Health of Women with Breast Cancer.” The Journal of
    Human Resources, 40(4), 948-968.

[13] Degnan, D., R. Harris, J. Ranney, D. Quade, J. A. Earp, and J. Gonzalez (1992). “Measuring the
    Use of Mammography: Two Methods Compared.” American Journal of Public Health, 82(10),
    1386-1388.

[14] Della Vigna, Stefano and Daniele Paserman (2005). “Job Search and Impatience.” Journal of
    Labor Economics, 23(3), July, 527-588.

[15] Fang, Hanming, and Dan Silverman (2004). “On the Compassion of Time-Limited Welfare
    Programs.” Journal of Public Economics, 88, 1445-1470.

[16] Fang, Hanming, and Dan Silverman (2006). “Distinguishing Between Cognitive Biases: Belief
    vs. Time Discounting in Welfare Program Participation.” in Behavioral Public Finance, edited
    by Edward J. McCaffery and Joel Slemrod, Russell Sage Foundation.

[17] Fang, Hanming, and Dan Silverman (2009). “Time-inconsistency and Welfare Program Par-
    ticipation. Evidence from the NLSY.” International Economic Review, Vol. 50, No. 4, 1043-1076.

[18] Gruber, J., and B. Koszegi (2001). “Is Addiction “Rational”? Theory and Evidence.” Quarterly
    Journal of Economics, 116(4), 935-958.

                                                38
[19] Hausman, Jerry A. (1979). “Individual Discount Rates and the Purchase and Utilization of
    Energy-using Durables.” Bell Journal of Economics, 10(1): 33-54.

[20] Hotz, Joseph, and Robert Miller (1993). “Conditional Choice Probabilities and Estimation of
    Dynamic Models.”Review of Economic Studies, 60, 497-529.

[21] Juster, F. Thomas, and Richard Suzman (1995). “An Overview of the Health and Retirement
    Study.” Journal of Human Resources, 30(5): S7-S56.

[22] Kasahara, H., and K. Shimotsu (2009). “Nonparametric Identification of Finite Mixture Mod-
    els of Dynamic Discrete Choices.” Econometrica, 77(1), 2009, 135-175.

[23] Krusell, Per, Burhanettin Kuruşçu and Anthony Smith, Jr., “Equilibrium Welfare and Govern-
    ment Policy with Quasi-Geometric Discounting,” Journal of Economic Theory 105 (July 2002),
    42-72.

[24] Laibson, David (1997). “Gloden Eggs and Hyperblic Discounting.” Quarterly Journal of Eco-
    nomics, 112(2), 443-477.

[25] Laibson, David, Andrea Repetto, and Jeremy Tobacman (2007). “Estimating Discount Func-
    tions with Consumption Choices Over the Lifecycle.” Working Paper, Harvard University.

[26] Loewenstein, George, and Jon Elster, Choice Over Time (Russell Sage: New York, 1992).

[27] Mahajan, Aprajit and Alessandro Tarozzi (2010). “Time Inconsistency, Expectations and Tech-
    nology Adoption: The Case of Insecticide Treated Nets.” Work in Progress, Stanford and
    Duke University.

[28] Magnac, T., and D. Thesmar (2002). “Identifying Dynamic Discrete Decision Processes.”
    Econometrica, 20(2), 801-816.

[29] Miller, Robert (1984). “Job Matching and Occupational Choice.” Journal of Political Economy,
    92(6), 1086-1120.

[30] O’Donoghue, T., and M. Rabin (1999a). “Doing It Now or Later.” The American Economic Re-
    view, 89(1), 103-124.

[31] O’Donoghue, T., and M. Rabin (1999b), “Addiction and Self-Control.” In Jon Elster, editor,
    Addiction: Entries and Exits, New York: Russell Sage.

[32] Pakes, Ariel (1986). “Patents as Options. Some Estimates of the Value of Holding European
    Patent Stocks.” Econometrica, 54, 755-785.

                                                 39
[33] Ariel Pakes and Paul McGuire (1994). “Computing Markov Perfect Nash Equilibrium: Nu-
    merical Implications of a Dynamic Differentiated Product Model.” RAND Journal of Eco-
    nomics, Vol. 25, No. 4, 555-589.

[34] Pakes, Ariel, Michael Ostrovsky, and Steven Berry (2007). “Simple Estimators for the Para-
    meters of Discrete Dynamic Games (with Entry/Exit Samples).” RAND Journal of Economics,
    Vol. 38, No.2, 373-399.

[35] Paserman, M. Daniele (2008). “Job Search and Hyperbolic Discounting: Structural Estimation
    and Policy Evaluation.” Economic Journal, 118(531), 1418-1452.

[36] Pesendorfer, Martin, and Philipp Schmidt-Dengler (2003). “Identification and Estimation of
    Dynamic Games.” NBER working paper 9726.

[37] Phelps, Edmund S., and Robert. A. Pollak (1968). “On Second-Best National Saving and
    Game-Equilibrium Growth.”The Review of Economic Studies, 35(2), 185-199.

[38] Rust, John (1987). “Optimal Replacement of GMC Bus Engines. An Empirical Model of
    Harold Zurcher.” Econometrica, 55(5), 999-1033.

[39] Rust, John (1994a). “Estimation of Dynamic Structural Models, Problems and Prospects: Dis-
    crete Decision Processes,” in Christopher Sims and J.J. Laffont, eds., Proceedings of the 6th
    World Congress of the Econometric Society. Cambridge University Press.

[40] Rust, John (1994b). “Structural Estimation of Markov Decision Processes,” in Robert Engle
    and Daniel McFadden eds., Handbook of Econometrics, Vol. IV. Amsterdam: North-Holland.

[41] Strotz, Robert H. (1956). “Myopia and Inconsistency in Dynamic Utility Maximization.” The
    Review of Economic Studies, 23(3), 165-180.

[42] Warner, John T., and Saul Pleeter (2001). “The Personal Discount Rate: Evidence from Military
    Downsizing Programs.” American Economic Review, 91(1): 33-53.

[43] Wolpin, Kenneth I. (1984). “An Estimable Dynamic Stochastic Model of Fertility and Child
    Mortality.” Journal of Political Economy, 92, 852-874.




                                                  40
A     Finite Horizon with Non-Stationary State Transition

    This Appendix discusses the identification strategy for a dynamic discrete choice model for
(potentially naive) hyperbolic discounters with finite horizon and non-stationary state transitions.
The time period in this case goes from 𝑡, the current period, until 𝑇 , the end of horizon. In this
section, we will use superscripts 𝑡, 𝑡+1, 𝑡+2, ..., 𝑇 to denote the time period for all the components
in our analysis for clarification. The discussion in this section will be shorter and less detailed that
that in Section 2, as will soon be clear that the identification strategy for this non-stationary case is
essentially the same as the one for the stationary case, with only minor modification.
   First, define the current choice-specific value function, 𝑊𝑖𝑡 𝑥𝑡 , as follows:
                                                                ( )

                                                       ∑
                         𝑊𝑖𝑡 (𝑥𝑡 ) = 𝑢𝑡𝑖 (𝑥𝑡 ) + 𝛽𝛿             𝑉 𝑡+1 (𝑥𝑡+1 )𝜋(𝑥𝑡+1 ∣𝑥𝑡 , 𝑖)𝑑𝑥𝑡+1 .                   (A1)
                                                      𝑥𝑡+1 ∈𝒳


    Then, define the choice-specific value function of the next-period self as perceived by the current
self, 𝑍𝑖𝑡+1 (𝑥𝑡+1 ), as follows:
                                                                ∑
                      𝑍𝑖𝑡+1 (𝑥𝑡+1 ) = 𝑢𝑡+1           ˜
                                           (𝑥𝑡+1 ) + 𝛽𝛿               𝑉 𝑡+2 (𝑥𝑡+2 ) 𝜋(𝑥𝑡+2 ∣𝑥𝑡+1 , 𝑖).                (A2)
                                       𝑖
                                                            𝑥𝑡+2 ∈𝒳


    Given 𝑍𝑖𝑡+1 (𝑥𝑡+1 ), we know that the current self’s perception of her future self’s choice, i.e., 𝜎
                                                                                                       ˜
as defined in Definition 2 is simply
                                       ⎡                                                                         ⎤
                                                                            ∑
                  t+1
                            = max ⎣𝑢𝑡+1                    ˜                        𝑉 𝑡+2 (𝑥𝑡+2 )𝜋(𝑥𝑡+2 ∣𝑥𝑡+1 , 𝑖)⎦
          (           )
        𝜎
        ˜ 𝑥𝑡+1 , 𝜺i                 𝑖   (𝑥𝑡+1 ) + 𝜀𝑖,𝑡+1 + 𝛽𝛿
                                 𝑖∈ℐ
                                                                          𝑥𝑡+2 ∈𝒳

                            = max 𝑍𝑖𝑡+1 (𝑥𝑡+1 ) + 𝜀𝑖,𝑡+1 .
                                 [                      ]
                                 𝑖∈ℐ


    Let us define the probability of choosing alternative 𝑗 by the the next period self as perceived
by the current period self, 𝑃˜𝑗 (𝑥𝑡+1 ), when next period state is 𝑥𝑡+1 :

              𝑃˜𝑗𝑡+1 (𝑥𝑡+1 ) = Pr [˜
                                   𝜎 (𝑥𝑡+1 , 𝜺𝑡+1 ) = 𝑗]
                                  [                                                             ]
                             = Pr 𝑍𝑗𝑡+1 (𝑥𝑡+1 ) + 𝜀𝑗,𝑡+1 ≥ 𝑍𝑗𝑡+1
                                                              ′  (𝑥𝑡+1 ) + 𝜀𝑗 ′ ,𝑡+1 , ∀𝑗 ′ ∕= 𝑗 .

    Further denote
                                                                ∑
                       𝑉𝑖𝑡+1 (𝑥𝑡+1 ) = 𝑢𝑡+1
                                        𝑖   (𝑥𝑡+1 ) + 𝛿               𝑉 𝑡+2 (𝑥𝑡+2 )𝜋(𝑥𝑡+2 ∣𝑥𝑡+1 , 𝑖).                 (A3)
                                                            𝑥𝑡+2 ∈𝒳




                                                            41
   According to the definition of 𝑉 (⋅) as given by (2), 𝑉 𝑡+1 (𝑥𝑡+1 ) is simply the expected value
of 𝑉𝑖 (𝑥𝑡+1 ) + 𝜀𝑡+1
  [ 𝑡+1              ]
                 𝑖     where 𝑖 is the chosen alternative according to 𝜎  ˜ (𝑥𝑡+1 , 𝜺𝑡+1 ). Thus it must
satisfy the following relationship:
                                                [                                             ]
                           𝑉 𝑡+1 (𝑥𝑡+1 ) = E𝜺t+1 𝑉𝜎˜𝑡+1
                                                     (𝑥𝑡+1 ,𝜺𝑡+1 ) (𝑥𝑡+1 ) + 𝜀 𝑡+1
                                                                               ˜ (𝑥𝑡+1 ,𝜺𝑡+1 ) .
                                                                               𝜎                            (A4)

    Now note from (A2) and (A3), we have
                                               (      ) ∑
                                                    ˜ 𝛿
                𝑉𝑖𝑡+1 (𝑥𝑡+1 ) = 𝑍𝑖𝑡+1 (𝑥𝑡+1 ) + 1 − 𝛽     𝑉 𝑡+2 (𝑥𝑡+2 )𝜋(𝑥𝑡+2 ∣𝑥𝑡+1 , 𝑖).                   (A5)
                                                                   𝑥𝑡+2 ∈𝒳


    The relationship in (A5) is crucial as it allows us to rewrite (A4) as:
                            [                                               ]
      𝑉 𝑡+1 (𝑥𝑡+1 ) = E𝜺𝑡+1 𝑉𝜎˜𝑡(𝑥𝑡+1 ,𝜺𝑡+1 ) (𝑥𝑡+1 ) + 𝜀𝜎˜ (𝑥𝑡+1 ,𝜺𝑡+1 ),𝑡
                            ⎡                                                                           ⎤
                                                      𝑡+1
                                                    𝑍𝑖 (𝑥𝑡+1 ) + 𝜀𝜎˜ (𝑥𝑡+1 ,𝜺t+1 ),𝑡
                    = E𝜺𝑡+1 ⎣ (
                            ⎢                                                                           ⎥
                                           ) ∑                                                          ⎦
                               + 1−𝛽     ˜ 𝛿               𝑉  𝑡+2 (𝑥
                                                                     𝑡+2  )𝜋(𝑥   ∣𝑥
                                                                              𝑡+2 𝑡+1  , 𝜎
                                                                                         ˜ (𝑥    , 𝜺
                                                                                             𝑡+1 𝑡+1 ))
                                                  𝑥𝑡+2 ∈𝒳
                                 [ 𝑡+1                      ]
                    = E𝜺𝑡+1 max 𝑍𝑖 (𝑥𝑡+1 ) + 𝜀𝑖,𝑡+1
                            𝑖∈ℐ
                        (       )             ∑
                      + 1−𝛽   ˜ 𝛿E𝜺                 𝑉 𝑡+2 (𝑥𝑡+2 )𝜋(𝑥𝑡+2 ∣𝑥𝑡+1 , 𝜎 ˜ (𝑥𝑡+1 , 𝜺𝑡+1 ))
                                       𝑡+1
                                                    𝑥𝑡+2 ∈𝒳

                                             𝑍𝑖𝑡+1 (𝑥𝑡+1 )
                                         [               ]
                        = E𝜺𝑡+1 max             + 𝜀𝑖,𝑡+1
                                𝑖∈ℐ
                          (      ) ∑                 ∑
                        +   1−𝛽 ˜ 𝛿  𝑃˜𝑗𝑡+1 (𝑥𝑡+1 )        𝑉 𝑡+2 (𝑥𝑡+2 )𝜋(𝑥𝑡+2 ∣𝑥𝑡+1 , 𝑗)                   (A6)
                                         𝑗∈ℐ                  𝑥𝑡+2 ∈𝒳


    The probability of observing action 𝑖 being chosen at a given state variable 𝑥, in this non-
stationary case, is still:

                                                                     exp 𝑊𝑖𝑡 (𝑥𝑡 )
                            [                                    ]       [         ]
            𝑃𝑖𝑡 (𝑥𝑡 )          𝑡
                                                      { 𝑡       }
                        = Pr 𝑊𝑖 (𝑥𝑡 ) + 𝜀𝑖,𝑡 > max 𝑊𝑗 (𝑥) + 𝜀𝑗,𝑡 = ∑        [          ],                   (A7)
                                              𝑗∈ℐ∖{𝑖}               𝐼          𝑡 (𝑥 )
                                                                    𝑗=0 exp  𝑊 𝑗     𝑡


where 𝑃𝑖𝑡 (𝑥𝑡 ) is the current-period self’s equilibrium choice probabilities and will be observed in
the data.
    The relationship between 𝑊𝑖 and 𝑍𝑖 can no longer be described as in Equation 13, however,
we still have                                                           {                    }
                                                                         ∑
                        E𝜺𝑡+1 max{𝑍𝑖𝑡+1 (𝑥𝑡+1 ) + 𝜀𝑖,𝑡+1 } = ln
                                                                                 [ 𝑡+1      ]
                                                                              exp 𝑍𝑖 (𝑥𝑡+1 ) ,              (A8)
                              𝑖∈ℐ
                                                                        𝑖∈ℐ




                                                              42
and                                                        [             ]
                                                       exp 𝑍𝑗𝑡+1 (𝑥𝑡+1 )
                                    𝑃˜𝑗𝑡+1 (𝑥𝑡+1 ) = ∑𝐼      [ 𝑡+1         ].                   (A9)
                                                      𝑖=0 exp 𝑍𝑖    (𝑥𝑡+1 )
   Using (A8) and (A9), we can rewrite (A6) as
                                           {                                }
                                            ∑
                      𝑡+1
                                                           𝑍𝑖𝑡+1 (𝑥𝑡+1 )
                                                       [                   ]
                  𝑉         (𝑥𝑡+1 ) = ln         exp
                                           𝑖∈ℐ
                                    [          ]
                      ( ) ∑ exp 𝑍𝑗𝑡+1 (𝑥𝑡+1 )         ∑
                      ˜ 𝛿
                  + 1−𝛽       ∑𝐼      [ 𝑡+1        ]        𝑉 (𝑥𝑡+2 )𝜋(𝑥𝑡+2 ∣𝑥𝑡+1 , 𝑗).        (A10)
                          𝑗∈ℐ  𝑖=0 exp 𝑍𝑖   (𝑥𝑡+2 ) 𝑥𝑡+2 ∈𝒳

   In this non-stationary case with finite horizon, at 𝑡 = 𝑇 where the continuation value is zero,
we have that
                                                   𝑍𝑖𝑇 = 𝑢𝑇𝑖 = 𝑉𝑖𝑇

which leads to:
                                                 ∑                         ∑
                                     𝑉 𝑇 = ln          exp[𝑍𝑖𝑇 ] = ln            exp[𝑢𝑇𝑖 ].    (A11)
                                                 𝑖∈ℐ                       𝑖∈ℐ

   Equations (A11) and (A2) combined give us 𝑍𝑖𝑇 −1 , which can be further combined with equa-
tions (A9) and (A10) for 𝑡 = 𝑇 − 1 to give us 𝑉 𝑇 −1 . We can keep doing backward induction in
this way until we reach 𝑉 𝑡+1 , which can be used in (A1) to derive 𝑊𝑖𝑡 , the current choice specific
continuation value function. Equation (A7) shows the relationship between the observed choice
pattern from the data and 𝑊𝑖𝑡 .




                                                               43
