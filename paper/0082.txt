                            NBER RKtNG PAPER SERIES




                        CERTAIN ASPECTS OF GENERPLIZED
                               BOX—JENICtNS MODELS



                                 Richard   W.   Hill*


                              Wor]dng Paper No. 82




       COMPUTER RESERCH CENTER FOR ECONOMICS AND MANAGflIENT SCIENCE
                  National Bureau of Economic Research, Inc.
                               575 Technology Square
                       Canbridge, Massachusetts         02139




                                     May 1975



                         Preliminary:   not     for quotation

    NBER working papers     are dis'ibuted    informally arid in limited rnmibers   for
    camients only. They should      not be   quoted without written permission.

    This   report has not   undergone the review accorded official   NBER publications;
    in particular, it has not     yet been suthiitted or apoval by the     Board of
    Directors.

*   NBER   Canpute.r Research Center. Research supported in part by National Science
    Foundation &'ant GJ.fl5L1X3 to the National. Bureau of Economic Research, Inc.
                               Abs1act


We define a class of models that are generalizations of regression models
arid moving average-autoregressive tine series models. Then we investigate
the asympotic and canputatiorial properties of the maximum likelihood
estimator, with numerical examples. The main conclusion is that care must
be excercised when using simple approxinations to the covariarice matrix
of the estimates.




                                                                             .



                                                                             .
                                  Contents


 I. The Model                                      1
II. Estimation                                     5

III. The Generalized Box—Jenkins Stup              9

IV. Special Results                               20

 V. Approximations to the Covariance Matrix       25

VI. I&unerical Considerations                     31

 References                                   .   32
        The main     purpose of         the paper is to examine        certain
aspects of      Box-Jenkins           models:    specifically     we will examine conputa-
tia1 nthods arid approximations to                       asymptotic   covariance matrices.
We begin,      however, by introducing             a nore general setup.


                                          I.    I} MJ]JEL


       We will work with the following model.                     Let 8 be a kxl vector

of paraJrters, m a twice differentiable function m: Rl<Z÷t, so that
m(B) is an nxl vector. V(o) is an nm synmetrip positive definite
matrix,    whose elennts are a function of the pxl vector,                   0.
       Our nodel is
              Y m(8) +           c,                                                    (1—1)

where         c 'bN(O, cy2v(8)),

SO that    if
              V(o)    =   cv½e)J        [V(e)JT,

              V(0) E             N (0, a2I).                                           (1—2)


For exarple if V(0) I, we have the usual nc)nlinear model, arid                       if
              m(8)                             then we   have

              Y-X8        N(0,   a2In)
                                               which is the usual     linear regression model.
                                      —2—



For    convenience, we put f( B)       Y-m( 8),         so that f(8) is the nxl vector

of   residuals. We let y (),           the combined parameter vector.                   In

our applications      we will find that        p,    the dimension of e, is much
naller than n, so that         V(e)   is unknown only up to few parameter
values,     which we wish to estimate. For example, if Y were a zero
mean time     series, we   could take f(8) =            Y, and   perhaps   assume

                                       o            0

                                       1            0

              v(e)



This
                                       o         o ...
       is a one parameter model, in which we are trying to estimate the

correlation between Y and Yi1, assuming that Y1
                                                                       0   e        1




                                                                                        uncor-
                                                                                                          .
related     for   t>2. The usual Box-Jenkins models described in Box and

Jenkins (1970) are special cases of (1-1). In fact, they can

be written as



             Yi                       "    ai—a            Cj1Cj               4'b si—b'
                                                                                                 (1—3)


where

              Cl "'     n                  N(0, c2) variables.

In   our   notation


             P(p)Y     T(4) c,                                                                   (1Li.)



                         ••'   "a '        =                       '
                   —3—




                  1




      P(p)
                               0
                  a—1 a—2
                               0
                         a—1
              o                0




              o    0     0
                               1/
and

                   o     0

                   1     0     0

                         1     0
                  _q1




      T() =                         (1—6)
                               0
                   a-1 a—2
                               0
                         a-1
              0    0           0




                   0     0     1
Letjg           e
                     (p1, ••.,   a' j' '
nd                                                             (1-8)


so that the          .ns   fltdels   fldeed   Cases   (1-1),
 th 1fl()           V(o) given                 We wjfl let P(p)

fld T()       defj by the abo           es.




                                                                       .
                                              —5—



                                       II. 'ESTIMATION


        Since we have not asszned that f(6) is linear, and V(o) is not
necessarily linear in 0, we are not in an exponential family, so                                the

theory of sufficiency is not applicable. We resort to the
principle of mathiium likelihood. We can only observe the nxl vector
Y, so we need the likelihood in terms of Y:

               L(f,6,8,a)      C   det(V(0))            exp
                                                                  fT(6)V;l(O)
                                                                                            ,       (2-1)
                                                                                 f(6) ]
                                                              [
where C is a constant (see Pao (1965)                    section 8a.4).

        For   all our applications           we will     have det(V(0))         1 (see 1-5

and 1-6), so we irrmediately siirlify things by assuming that

                                   1              for   all values of 0.                            (2-2)
               det( (0)) =
Hence

               log   L(f,6,0,ci)       -   j. fT(6) V(0) f(6) -
                                            2a2
                                                                            n   log a + C       .   (2-3)


To maximize this we differentiate and set the derivatives to 0.
(Recall that f( 6)         Y-m( 6), so for each 6, f( 6) is observable.)

               D log L                  1                                       =0
                                              fT(6) V1 (o)         f(6) —

                             or
                                       fT(6) V(o) f(6) = n a2

Hence
                     fT(s) V(e) f(s) ,                                                              (2-4)
                                          —6—


and   we can treat a2 as a constant throughout the rest of the discussion.
Note that we are row trying to mirthnjze

            fT(8) V1() f(S).

We write f( 5)                   f)T V1 (0)                   (V) for convenience.
                     (f1,

Then


            BlogL           -
                            —    -1        B
                                                                     f)
                                                                     J
                                 2a2           j        jj
                                                              3'




                            -—
                                 2a2
                                          (E
                                          ij
                                                   [af.1 v1Jf.+f.v'J—l])
                                                         5i
                                                                1



                            -    —1
                                          (E                 V'f.)
                                           ii       i



                                 —1
                                 a2
                                          af()          )T V1(0) f(S)




            BlogL =
                 m               2a2
                                      1    B
                                          Bm        ..ij f.vf)1



                            -
                                 2a2
                                          (E
                                           ..
                                          13
                                                         _
                                                   f.1 BO f.)
                                                           3
                                                              m



                            -     -1 fT(5) BV(5)
                                 2a2         m




                                                                                     .
                                            —7—


So    the k+p nornaJ. equations are


                           vce f(s) =           0
           J
                                                                                     (2—5)


                             m

Note how the first equation imposes the usual least squares condition:
residuals orthogonal (in the right ntric) to the "data", represented
here by the first derivative matrix.
       The second equation is also an orthogonality condition, albeit
somewhat less obvious: as we shall see later, for certain special
cases this condition becanes nre explicit.
       To solve these equations we propose to use some variant of Newton's
nethod, so we compute the second derivatives. Omitting the details we get


               _ci2    2 log L                      V(e)                  +   V(e) f(s)


               —a2
                       D2 log L =         fT()       3v1(e)        f(s)             (2—6)
                       i8m

                                 L                  2V(e)
               -2a2                     fT(s)



and   Newton's method is


               y
                   (i+l) -- y (j)    —H —l
                                         (y
                                            (i) )    G(y
                                                           (1) )   ,                (2—7)
                                                  —8—


where
                             /ff,]T V'f + f"        Vf                   [f,]T[V_l]tf\
                 H           I


and
                             [f,]T
                                     [lJ, f                          fT[V_l]flf
                                                                                         )
                                                                                              (2—8)



                             fT

The primes denoting the appropriate derivatives. (Note that the factor
is cmitted from the lower right hand corner of H, because it is omitted
in the lower half of C). The Fisher information matrix 1(y) is


                                  [f]T Vf' +                 T vi f                 1
                na2                                                                           (2—9)
                [. —— [f?]T [V1]'f                                                1 T[V
                                                                                      —1"


Holland (1973) described a method for carrying out the expectation in
                                                                                —f
                                                                                2a2
                                                                                        ] f
                                                                                                      .
                        2
2—9.       Since a is considered fixed, we treat it as a constant.Then

 E             [ft]T Vf' +           [ft]T
                                             V_if]
                    1
                 Th tft]T
                 a                    f' +     [fIt]T V_i [Ef]             2    [f,]T Vf',
since f'       () m' () was assumed fixed;
 E [2 [f]T [V_1]?f]                               [f?]T [v1]'            [Ef]       0,

since f(s)                  Y— m() N (0,a2V(O)) , by 1—1

                                      -l
                                                                                                      .
E [2           fT
                     [\fll]fl fj
                                      —
                                             2
                                                 trace       [E [ fT       [V]"f] ]
                                          2a

           1
       =   —2E          trace     [fT{v_i],tfl =
                                                         2
                                                             E   trace
           2a                                       2a
                                      - 8a   -


         1
         2a
              2
                  trace CEIrr1]"    ff]]          2
                                                 2a
                                                       trace [(V*I"       E[ffT]]




                  2   trace           V               trace [vCv]"]
          2a

 So we have




                              L [fI]T v1 f'                  0
                                                                                          (2—10
              ICy)
                                                                                 —1
                              0
                                                             1I2trace(V0              )


thder suitable regularity conditions, it               can       be shown that

                      (y-y) Nk+P(O    f1(1)).                                             (2-11:


We   will assi.mte that (2-U) holds.
       We now specialize to a subset of (1-1) for which the expressions
(2-7) are easy to canpute.
                                           —9—




                  III.   THE NERALJD BOX-JENKENS SETUP


      We restrict ourselves to the subset of (1-1) for which

             V(@) P(p)T()               [pJ(p) T()]T                               (3-1)


so   that            =   T($) p(p)                                                 (3—2)


where T, P are given by        (1-5) and      (1-6).
       Note that det (T( )) det (P( )) 1,                so that det (V( 0))
as required by (2-2).
      We will use the following lenurias:

Lemria 1     Let A a), B( a) be any non-singular matrices whose elements
are a function of a scalar a. Then

             i)          }—   A(a) = -A(ct) }-A(a) A(a)

            ii)               A(a) B(a)           A(ct) B(a) +    A(c*)    B(a)


Proof:
             1)           I A(a)       A(a)

So
                               3       E          kj
                          O--- kaik(a)a

                                                              3
                               k
                                   3
                                           a(a) a kj
                                                  (cx) +      —a
                                                                  kj
                                                                       (a) a(a))
Hence
                          o    -- A(a)      A(a) +     A(a)   f- A(a)

                                                                                           .
                                     — 10   -


and

                        hA(cL) —A(c)            f-A(c) A1(ct)


         ii)   follows similarly




Definition            A matrix A     is said    to be Column Thiarigular if A
                        can   be written as

                 a1            0       0                          0
                 a            a        0                          0

                                                                  0
                 a3           a2      a1
         A
                 a            an-i    a                           a
                  n                    n-2


Lenifra 2 If A and   B are arbitrary columi triangular matrices, then

          1) AB is column triangular
        ii)    A   is   column triangular (if it exists)
       iii) AB = BA
                    'l'
        iv) Trace (AB)
                                   il ia .
                                       n—i bn—i
         v) If furthermore the entries of A are a function of the
             scalar CL,then - is column triangular.
                                        — 11 —




Proof:      Let a1, ...,     a1   and b1, ...,   b detenine A and B respectively.
            i)          (AB)          Z A Bkj        ai_k+l bk...j+l

where       I     {k : 1 <   i-k+l <n and 1<k-j+i          <n}.
The   rerige in the surnni.tion can    be   rewritten as


                           -i   <-k <n-i-i
                              <k<n+j-1

            or         I
                        fi>k> 1+1-n
                        ),j<k<n+j-i
                                  =
                                      kj a±_k÷l bk_j+l
            Hence      (AB)..         0 whenever j   >i                             S
            and
                       (AB)1,+ kj+Z aik+i bk_j+l

                                                     a±_k+l bk_j_÷i
                                        j<k—9<i—2

                                        1—.Q
                                         Za.
                                         -. i—m—2+i bm—j+l
                                        m-j


                                      =(AB)


            which establishes coiiniui triangularity.




                                                                                    .
                                       — 12      —




            ii)    Note that a cohmn triangular natrix is lower triangular,
so   its   inverse can be computed column by column by simple forward
substitution. Letting

                         6.. =
                                  fi if i=j
                          1J

             We have
                                                 i-i         1•
                                      6..   -          A.   A'
                                       '
                        A                         -
                                                 k—

                                                 A..
                                                  11
                                                        :ik
                                                                        for ij,          ..., n

                                                 0                      for i1, ..., j—i


             where A1 is the          j elerient       of A1.

             But
                        A        a.k+l

                                       i—i


              so         A' =
                                 1j     .a.
                                       kj i—k+l
                                                A
                                                k
                                                                  ,         ...,
                                            a1


                                                       1—1
                                                              a±_k+l
                                                                        Ak,]
                         A1,j =       6±,j+i          k=j+i                          ,   i=j+l,   ...,


                                                                                 A
                                                                                   1
                                        tsi_+1,j+l                    ai+l_k+l                 . -.
              hence      Ai+l,j+i                         kj+l                               , 1—],   ...,
                                                             a1
                                      - 13 —




            and           A'1
                                      ES.. —
                                                    kj
                                                         a

                                                         a1
                                                             i+1—k
                                                                     A1,i
                                                                                    I=j, ...,   n—i
                                                                                                      .
Since this formula aflows us        to successively compute the elements                  Ai+l,j+1

for i=j,   ..., n-i and we Jow that A1+i1 0 for 1=1, ...,j—l,by
comparison with the   formula      for A1      we see that        A1'1              A1 for

1j, ...,   n-i,   which   establishes   column       triangularity.

                                           a11 bkj+l
                                      E b.÷1                         =   (BA)..


            by setting &         i+j-k, so that          k     i+j-2


                                       1
                             T
           iv)            CAB)..
                             '       k1 A B = k=i a1                       k+1 bjk÷l                  .
                          Thace (ABT) =                                           ak+l bjk+l
                                                                     i!l k=1


                                               n I                       nn-k
                                           =         E akb-
                                                                         k1 i0 a]b]
                                                E
                                               1:1 k1


                                               n                              n

                                               k=i
                                                     (n-k+1) abk
                                                                             i-i
                                                                                   ia11 b.1

            v) obvious.

                                                                                        QED
                                                    — lL -



                     Note   that P( p) and T( ) are both column triangular, so from the
               above lemna, we never need to actually carry around P and T, but only
               their first columns. This allows us to sinlify things considerebly.
               Specifically (omitting the arguments)

                            v1 = CTP] T1P
               so                /[TP ff]T TP f                                                    (3-3)
                            G
                                    [(TP)' f]T (TP) f

               since                  C(T_1P)t]T T1P + [T_1P]T (TP)'

               and          fT (V)' f is a scalar.

               Also H:

(TPf' ]T   T1Pf' +   [T1Pf' T TPf                   [(TP)f' ]T (T1P) 'f +   [(TP) ?f?   ]T (TP)f

                                                                                                   (3_14)


[(Tp)f,JT   (TP)'f +     r(TP)tf,]T      (TTP)f        [(TP),fJT (TP)'f +    [(TP)?,f]T (T)f

               since        (V)" [(TP)?t]T T1P + [(TP)tJT (TP)'

               Further   sinplification is çossible noting that

                                               T           T1 L. T1
                            .L... (TP)
                                           a
                                               p1
                                                       +
                                                             ap1      1          T1
                                                                                                   (3—5)

                            .L(T'P)              P =   -T LI T1P    1 T2P
                                                    - 15       -


          3 2(f1-p)

              pip
                        -   3   T
                                3p.
                                    1           3p1
                                                               —l    32P
                                                                     3pipj
                                                                                 =0
                                                                                                                       (3—6)
                                                                                                                               .
             32(flp) -          ____          - = -T1 3TT-13P_ 3T !I!L T2
                                              pj               34


             2(T1p)
                                             (-            TT1P) =               3T3f'T-lp 3T                  T        •P

             ai4j


                            -           3   T T1                                                      T3
                                '
                                        34.3.
                                                           T T1 T1
                                                           J
                                                                            P = 2
                                                                                          -h    h          P



     A similar simplification occurs for the information matrix.
Holland (1973) suggests             a method           for showing that:



      tmce (vc
                                    =       trace
                                                       [TP)9O')                       ((T_1P)                  1•
                                                                                                                       (3-7)
                                                                                                                               S
To simplify this canputation we will write V=QQT, V :Q_TQ_l, where
QT is co1.min triangular (leiin-ia 2 will be used in succeeding computations).
It is easy to show that

    32 V_i    = 2V1 3V V1                          av V—l -          V1     32V           V-i
                                                                            30   0:
                            302,                   3ocfl




Hence trace (           :),                         trace
                                                                    (av v1
                                                                     302,             m v)            - ra( t:om ri)

      = trace                                               Q_TQ_l                QT + Q                           +
           [(QT                 m                 302, /                    DO
                                                                                                3em   / QTQ11


   - trace
      1    r3
                m   L   c
               DQ QT + Q• QT QTQ1
                          80
                            m
                                        DO                                            J                                        .
                                                       - 16          -




               - trace r                      -1 3QT Q_T
                                                                                         T -T
                                                                                   !Q-1 +QJ+
                                 90                   30
                                                            2.           i\rn               /     0m



      —        trace     (       92Q          QT +      Q                          +
                                                                                       302. 90m
                                                                                                  +   Q 92QT
                                                                                                        302.-rn
                                                                                                           0
                                                                                                                      QTQl
                         L
                                 30 0
                                                             m
                                                                     30
                                                                             2,                                   )
          Now Q is lower triangular, with 1 on it 's main diagonal.                                               So

      is lower triangular with U on it mein diagonal. It follows
that any product of lower triangular matrices involving     will
have U trace. Similarly for                                                  and    for    products of upper triangular
                                                                 m
matrices involving —                          and       3QT              •
                                                                                  Using    this fact we obtain
                                                        30
                                                             rn


  trace     (                = ce (3Q Ql 3QT Q-T                                           +
                   tm                                2.              90rn              I

           +    trace                      Ql                    Q_T                       +
                             ( 30
                                                     302,                )

                             ( Ql •Q
                trace
                             \
                                 90
                                      rn
                                                             Q_T) -                      trace
                                                                                                  (Q           °m Q_T)

But   trace (AT)          trace (A) ,                for any matrix                      A, so we finally get

           —                     2v1   '\
                trace ( V 30        0
                                  t.rn )                trace[( 3QQ) (                                 Q) T]
                trace                                                9Q           \ Ti
                         1rQ_1
                         L                 302, ,)    (p_a.          w)iI
                                                                      mj
           (because     Q is coluirn triangu1r).
                             - 17   —




Now having estb1ished   3-7 we note     that
                                                                  .
         _ (PT)    =         T +   P1    -—-
                                               T




             k    PT +

So

         (TP) —p--- (PT)      -T           PT = - -- P1
                                                          (3—8)

        (f1P)      (PT) T1 LI. = LI T1



                                                                  .
                                — 18



       Expressions (3—5), (3—6), (3—7) and (3—8), together with lemma 2,
perndt   efficient computation of the expressions (2-8) required for
the computation of ewt's step (2—7). First we notice that              A,
and   .—j merely shift the coluims of A down by j   places, arid append
j zezos to the top of A.    Furthermüre, since Af   is a vector if A
is a matrix, and P and T are ]x)th coliru-i triangular, we see that
we will never need to actually compute any riai matrices (since we
need only compute expressions of the form Av, where v is a vector,
and A is cohuiu-i triangular, so this computation can be done trivially
witi-out expanding A into an nxn matrix). Specifically, we carl break
the computatioi down as follows:

Let        A T1P
           1)    Compute and store Af (requires n cells)
           2)    Compute and store Af' arid A' f (requires n x (k+p) cells)
           2.1) The gradient G is now given by computing
                 EAf,]T [    and   [Atf]T [hf]
           2.2) Compute and store the ttxTxt, matrix, ttiat is

                       ]T ,                [Af'    [A'

                   [Af]T [t]               [AtfJT [A'f]

                 :(requires (p+k) x (p+k) cells)
           3)    Compute arid add to the matrix computed in 2.2 the
                 nonlinear corction terms due to the second
                 derivatives, that is
                                 — 19   -

                                            [Atft]T [Af]
                                            [A,,f]T

                   (requires only n x 1 cells of temporary storage).
                  This gives   us the Hessian H.

      Of   course, the computation of' and At! must be further broken
down into special cases, depending on whether A = T1P or        just T1
or   P. This is done using specializations of (3-5) and (3-6). Note
that in both steps 2 and 3 we have only had to compute products of
the form Qv, where Q    is column triangular, and v is a vector. As
pointed    out previously, this can easily be done given only the first
colunri of Q. Steps   2.1, 2.2, and 3 also require    the computation of
inner   products; again, this can be done easily with no need for

additional   storage. In fact,    the entire algorithm given above does

not use sifficant1y irore storage than that      required for an ordinary
regression, and, thanks to     the special forms of the matrices involved,
the required derivatives are     computed fairly efficiently.   A similar
algorithm works for the infonmation matrix 1(y); the upper left k x k
corner is given by [Aft]T [aft] so we need only worry about the
lower right p x p corner. Using (3-7) and part 4 of lenma 2, we see
that it suffices to compute the p matrices given in formula (3-8), and
then to compute the trace of all cross produots. Again, note that
colunin triangularity allows us to compute only the first columns of
matrices, so we need only n cells for each matrix, rather than n2.
      In addition to the above, several interesting special results
can be gleaned easily     the simplified forms (3-5), (3-6), (3-7),
                        from

and (3-8). They are discussed in the next section.
                                         — 20 —




                                 IV.    SPECIAL    RESUL

     We   specialize to m()             0,   so we have a pure Box-Jenkins         iiüdel,
f(8) = Y.

         1) If T() I, so that we have a pure autoregressive
ndel, then defining Y 0 for i< 0 we have


                            [y]T py

                             n                         p
                        kj+l
                                               —
                                                   i1 1         k•—1
                                                                                              (4—1)



                             n                     p             n
                             E 'kk
                        kj+l —J
                                                   Z
                                                i1 1 k=j+l
                                                           p.     E    Yk—j
                                                                          .Yk—i


Hence   we want


                      kj+l k-j          k- •••                  kj+l k-j k-p      k=j+l   k-j k1
                                                                                              (L._ 2)
                                              for j1,           ...,   p

     Equation     (4-1) is i1minating: it shows that (at least for
this case) the second half of equations (2-5) reduce to an orthogonality
condition: residuals orthogonal to the "data", where now the data
is Y, rather than X as usual. This is reasonable because in this
type of nx,del, Y acts like X           in   the usual setup. In fact, recalling
(1-1)   and   (3-1)   our   rxodel is   now


              '"N      (0, a2 p_l{p_lJT)
                                    — 21   —




That   is
            PY "
                    N (0, a2 I),
or, expanding the product PY,



                       P1Y1 +   C


                     = lk-1         +
                                        pk-p
                                               +




                Y
                 n     pY
                        in-i+...+pY
                                pn-p +n
where       C   "N    (0, a2 I)
                                                                           .
Clearly this is foniialiy identical to the usual linea± regression model
Y   X8+C, where      here

                       0            0

                                    0
                      Yl




                      Y
                        n-i          n-2

So indeed LY-X ]Tx =        0 is equivalent to ('i-i).
                                           — 22 —




       The usual method for estimating               pure autoregressive models is               to

solve   the   Yule-Walker equations (see             Box and Jenkins (1970)            3.2.2).
In our notation these               equations are:


                n                                             n
                E     y . -7) ('i'k-7)                   (Y             .     (Y-7
              kj+1
              ___________
                     n
                         k—j
                                                 - p1
                                                 -    kj                                 +...
                                                                    ( 72
                    k=1                                           ki k

                          n
                          z         (yi-J
                                        . -?)(Y-7)
              +p
                    p
                      "        -i



                               n                              ,   j = 1, ..., p                       (4....3)




                               k1
                               E(Y—Yy


                                                      2
Eliminating the common term                               ,   and   recalling that in (4-2)
                                          k= 1
Y=0     for 1<0, we see that            (4-3)    differs from (4-2) only          in that 0 is
substituted for Y. This                nJces    sense, because the assumption m(13)E0

implies EY=0.

        So we see that         our method       of estimation reduces to the usual one

in   this   simple case. If we assume m()                         (a   scalar), so   that EY,
then    the two     estimation        methods are    similar,          but not identical, since

we estimate simultaneously with p, rather than merely setting Y.
(In practice, usually is close to 7).
                                       — 23 —




           ii) IfT()IandpO,then
                                 n—i       0       0       .          .     .         0

                                 o         n—2     0           .      .     .         0

                                 o         0       n—3         .      .     .         0

                 1(e)




                                           0.      0                                  n-p

This is a perfectly sensible answer, since we see from the above
equations that the estirrte for    is essentially based on n-j
observations. In per'ticular, for p1

                  n
                 i2E Y.1 Y.i—i
                   n
                    E Y.1
                  i2

          iii)    P\jrthernore, from fonTlulas (3-7)     and       (3-8)   we see that

if   either P( p) El or T( p) El, so that we have only 's or only p 'S

to   estimate,   the value   of 1(y) will depend only on the value of the

+ or p vector, and not on whether or not it i a c                  vector or    a p

vector.    That is, I (+ ) I(p) whenever + p and, respectively, P( p ) 1

or T(+)I.

       This result is   rather surprising:       it says that the asymptotic

variance   for   the p's is the same as that for the 4 's if only p ?s or

  s are present, even though they          represent quite different itodels:
                                        —      —




One   is
                   —             ••• -pY1     'v   N(O, a2)


The other is

                         —
                                             f)Cj)
where

               c1,
                             C     i.i.d.   N(O, a2)



           iv) If p, then I() is singular,                    since   it has the fonTi



(_2        )   .     This means that the paremeters are not estimable, and
this is reasonable since our nodel is n
               Y ".. N(O, a2 I)


and   many choices of p          arid   will give us this nodel.
                                               — 25 —



                 V.     APPROXIMAflONS TO THE COVARIANCE MAThIX
                                                                                                                       •
        We   have assumed that I(y)                           1(y), and     in   fact Rao       (1965)       shows
that if    is the distribution function of y arid Gn is the distri-
             F
bution function of a randan variable distributed MC 0, I ( y)), then

              1m IFn_Gl


By the strong law        of large numbers, and                       consistency we also have

                 H(y) -        1(y)           0,            since EH(y)         E ICy) -



(Note that it      is   not true        that H(y)             --
                                                                   1(y),   in   fact H(y)       need not

converge to 1(y), as we will see later.)

        On the basis of this            result,             it   has   been   suggested that we              use
  A                        a
H( y)   rather than 1(y) as an estimate of 1(y). We point out some
disadvantages      to this approach.

          1) Suppose that f( ) Y, and that p 4, so that 1(y)
is singular. 11(y) is not necessarily singular; in fact, let p                                                  = 0,

and p2. Then

                                    n    ,,
                                                                                       Y_
                                                                                       n
                                                                                        i
                                                                                                        n
                                                                                                               y



                                                                                           '
                               i=2 1
                                •                                                  •
                                                                                   i=2
                                                                                                    .
                                                                                                    i=3
                                                                                                             i—2i
              H(y) =
                                    n
                                    E Y.
                                         ,
                                         -
                                                       fl                              n   ,,           fl
                                •     1            •
                                                       E    Y. Y.
                                                             i—2i                  .
                                                                                                +
                                                                                                    •
                                                                                                        E Y. Y.
                                                                                                          i—2i
                               i=2                                                 i=2
                                           — 26




           ii) Let f(8)             Y—8, K        1, T(4)                I, p            1,          1.

Then

                                                               Y -Y
                                                                   in
                 H(O)                                              n
                                      Y-Y
                                       in
                                (n                             i2
                                                               .


                                                                             1)
Whereas                         I
                 I(O)
                                      o                        n—i
                                                                                     )
The    form for H( 0) is nest         easily     derived           by observing that                  here


           2log L(f, 8,     p)            (Y1-8)2
                                                      +
                                                          in
                                                           Z
                                                               2
                                                                       [(Y1-8)
                                                                                     -

So
               log L        —
                                  n
                                      [(y    )      —     (yi—i..)]              (yi—i       )
              alogL         — (Y1—8) + 2                   [(y.—B)           —                        [—l+p]
                 8                                    2
                                                               1                 P(Y1_f8)]

                          n
               logL         E (Y.
                 2             i—i_8)2
                          2


             2logL          1 +            [—l+] [—l+p] = N                      —   2(N—i)      p   + (N—i)     p
                                                                                                                     2

                 8                    2

                                n                                        n
             2   log   L-             [-l+p] (Y1_18) +                       [(Y1-8)
                                                                                              - p(Y118)]             (-1)
                  8             2



                              n                            n                             n                   n
                              z (Y11—8)           —
                                                        p Z (Y11—8)                  —               + p
                                                                                         2
                                                                                              (Y±—8)             (Y±i_8)


                        =     (Y—8)
                                1
                                            —
                                                (Y—8)
                                                  n
                                                               =Y—Y    in
                                        — 27 —




Clearly   H(O) does not converge in probability             to   1(0); however, under

the assumption p0


                          N(O, 2) , and




                :
               1=2
                   Y.
                      2
                    i-l
                           X     n—i


so we see that


            Y-Y
             1 n           0 ()
                n           pn
and



                    1=2
                          :i-l
                              -n+l)     o   ()
                                                                                                .
In   this case, however, 1(0) is the correct answer, so we see that

H(0)   is not as good.

       There   is   another      approximation which   is clearly superior to H(y):



                                 [f?]T Vf'              0

           H2(y)                                                                        (5—1)
                                 0                      fT[V_l],If



This is obtained by eliminating those corionents in (2-8) whose

expectation is obviously 0. For the example we have


                                 n

                                                                     I

                                 0
                                                        i_21)
                                           — 28 —




which   is still not as good as 1(0). H2 also still suffers from
disadvantage 1) above; in fact, the lower z'ight corner of H2 is
identical to that of H.
    We conclude that the variance of the 0's Bo enkins' parameters)
should not     be   estimated fran     H( y),   but from ICy),           since    the two   can

differ significantly: a numerical example                       follows.
       We generated Y by taking 100             points        from   a normal (0,1) distri-

bution, so that Y "..
                            N( 0,1).       Then we fit the rxdel (1-1) with

m(8)     8, where 8 is a scalar and             o=    (), so         that we fit a first

order noving     average,     first order autoregressive process. (I. e •,

both P and     T are present, but each depends                  only   on one parameter.)

We found
                                  .13536
                              —.36

                              —.3125


                                  .009328             .000476              .000826

                                                      .3'47967             .345833

                                                                           -   350404


                                  .009319             0                    0


              I_1(y)                             3.1134                 3.16488

                                                                        3. 22633



Since admissibility requires I               I . 1,       I
                                                              I < 1, this last expression
ans that p and         4,   are   essentially inestimable.

        It   is to be noted that the          large observed variances              for p   and
                                    — 29 —




4   are not accidental: if we had found p           -.36,    =   -.36, then
1(y) would have been singular, and the variances would have been
infinite. In fact, if we fix p at -.36 and vary , we get a sirDoth
progression from reasonable variance estimates to absurdly large ones.

                                Estimated   variance of q)

               0                       .0787
            —.2                        .33
            —.3                       2.06

One might conclude from this example that the estiniated variances
given by H(y) are absurd.
In this context Wall (1973) has suggested looking at the estimated
correlation matrix for p and 4), This is

                   .99           for H1 () and
         (i              04,)
           1                     for I(y)



This indicates at once that the estimates for p and 4) are unreliable,
since they are so highly correlated. We could also look at the condition
number for the covariance matrix of p and 4). For H1 the eigenvalu
are .0033505, .695021, the condition number 207; for I                        6.33525

and l,I+lL. The condition numbers for the correlation matrices are 208

for      and 1,l7 for I. So we see that in fact the estimated

covariance matrix is nearly singular, for H1 as well as i_l; this

                                                                                        .
                             — 30   —




indicates that the parameters are "nearly inestimable". That is, we
can reasonably conjecture that the estimated variances given by
are much too small.
     This example points out that blind acceptance of variances
estimated from H1, without examination of correlation coefficients,
eigenvalues or condition numbers, can be quite misleading for this class
of problems.
                                     — 31   -




                      VT.    NUMERICAL CONSIDERATIONS


       Assiining that m( )    is   not very nonlinear, one would expect that
if T()       I, Newton's method would work well, since then the model

is   almost linear: if m( ) is linear the nonlinearity is           caused by

the presence of products
                               p 3• This is in fact the case. However,
when T(q) is present    the   model is strongly nonlinear,      and, as   one

would expect, straight Newton's        method     does not work very well.

Various    schemes to insure convergence have been found to help:
these are all based on the principle that the objective function
fTV_lf should not be allowed to increase from one iteration to the
next. If the     step based   on   Newton's method would cause an increase,

it   is not taken, but a step based on some sort of gradient meti-od
is taken instead. The specific algorithm that was found to be most
effective is a derivative based modification of Powell's (1970)
dog-leg,   which was suggested by John          Dennis.
      Even with this method, Iwever, we have encountered models where
G was not zero, yet H1@ was.          This means the algorithm got stuck in
a valley or "rut", even though a minimum had not been found. The
only way out would be to start again with a different initial guess.
      A further problem for which we have no solution is that not all
values of U are allowable. The admissibility condition given by Box
and Jenkins (1970, pp. 5+ and 67)        is rather messy to compute, so we

do not attempt to verify athiissibility of the estimated U. As a
consequence   we may occasionally return ridiculous estimates. In
general, as pointed out by Box and Jenkins, great care should be
exercised when fitting this sort of model.
                                    — 32 —




       Finally a few words on    initial     guesses. The following seemed
to work reasonably well.
       1) Fit f( ) by ordinary nonlinear least squares. Let r            f( ).
       2)    Fit the Box-Jenkins model for P(p) only to r. Let these
             new residuals be r2.

       3) Fit the Box-Jenkins model for          T() only to r2.
       14)   Use   the estimated , p,      as   initial values for the full
             model.


RERENCES
Box, G.E. P. and Jenkins,     G.M. (1970), Time Series Analysis,     Holden-Day,
San ancisco, California.
Holland, P.W. (1973),      personal citunication.
Fbwell, M .   J .0. (1970), A New Algorithm for Unconsained Op€niization,
Nonlinear     Prograiruiiing (Rosen, Mangasarian, Ritter, editors), Academic
Press.
Rao, C.R. (1965), Linear Statistical Inference           and Its Applications,
John Wiley and Sons, New York, New York.

Wall, K. (1973), personal      communcation.
