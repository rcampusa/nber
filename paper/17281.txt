                                  NBER WORKING PAPER SERIES




                                   SYSTEMIC RISK EXPOSURES:
                                   A 10-BY-10-BY-10 APPROACH

                                               Darrell Duffie

                                          Working Paper 17281
                                  http://www.nber.org/papers/w17281


                        NATIONAL BUREAU OF ECONOMIC RESEARCH
                                 1050 Massachusetts Avenue
                                   Cambridge, MA 02138
                                       August 2011




I am grateful for comments from Viral Acharya, Lewis Alexander, Niki Anderson, Peter Axilrod,
Dick Berner, Markus Brunnermeier, Stacey Coleman, Rob Engle, Mike Fishman, Mark Flood, John
Gidman, Tobi Guldimann, Anil Kashyap, John Khambu, Arvind Krishnamurthy, Joe Langsam, Clinton
Lively, Stephen O’Connor, Mike Piwowar, Hélène Rey, and Chester Spatt, none of whom necessarily
agree with any of the views expressed here. In June 2007, I provided a preliminary version of this
approach to the Financial Advisory Roundtable of the Federal Reserve Bank of New York. This note
was prepared for a meeting on October 17, 2010, of the Systemic Risk Measurement Initiative of the
National Bureau of Economic Research, of which I am a research associate. This approach has been
presented to a number of regulators in Europe and the United States, whose comments have been extremely
helpful. I am especially grateful to the editors, Markus Brunnermeier and Arvind Krishnamurthy. The
views expressed herein are those of the author and do not necessarily reflect the views of the National
Bureau of Economic Research.

The author has disclosed a financial relationship of potential relevance for this research. Further information
is available online at http://www.nber.org/papers/w17281.ack

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2011 by Darrell Duffie. All rights reserved. Short sections of text, not to exceed two paragraphs,
may be quoted without explicit permission provided that full credit, including © notice, is given to
the source.
Systemic Risk Exposures: A 10-by-10-by-10 Approach
Darrell Duffie
NBER Working Paper No. 17281
August 2011
JEL No. G01,G28,G32

                                             ABSTRACT

Here, I present and discuss a “10-by-10-by-10” network-based approach to monitoring systemic financial
risk. Under this approach, a regulator would analyze the exposures of a core group of systemically
important financial firms to a list of stressful scenarios, say 10 in number. For each scenario, about
10 such designated firms would report their gains or losses. Each reporting firm would also provide
the identities of the 10, say, counterparties with whom the gain or loss for that scenario is the greatest
in magnitude relative to all counterparties. The gains or losses with each of those 10 counterparties
would also be reported, scenario by scenario.

Gains and losses would be measured in terms of market value and also in terms of cash flow, allowing
regulators to assess risk magnitudes in terms of stresses to both economic values and also liquidity.
Exposures would be measured before and after collateralization. One of the scenarios would be the
failure of a counterparty. The “top ten” counterparties for this scenario would therefore be those whose
defaults cause the greatest losses to the reporting firm.

In eventual practice, the number of reporting firms, the number of stress scenarios, and the number
of major counterparties could all exceed 10, but it is reasonable to start with a small reporting system
until the approach is better understood and agreed upon internationally.


Darrell Duffie
Graduate School of Business
Stanford University
Stanford, CA 94305-5015
and NBER
duffie@stanford.edu
This systemic risk monitoring system would be more effective if adopted by regulators in
several major jurisdictions. Pooled reports that are based on coordinated choices of stress
scenarios would reveal systemic risk more comprehensively.

With such a monitoring system in place, a regulator charged with supervision of the
stability of the financial system would be in a position to quickly answer a range of
questions concerning concentrations of stress on the central nodes and links of the
system. Examples of the questions that could arise include:

   1. Is it true that some large hedge funds have taken significant foreign-exchange
      positions with systemically important banks? Who are these hedge funds? Do any
      of them also pose potentially large counterparty default exposures to any of these
      banks? How large are the associated market-value and cash-flow impacts?
   2. If treasury yields were to rise dramatically, how much would systemically
      important financial institutions gain or lose in total, from each other, and from
      others?
   3. How prominent are central clearing counterparties (CCPs) among the top
      counterparties to systemically important firms?
   4. What sorts of major financial firms have short positions with respect to real estate
      markets, and with whom do they hold their largest positions in this asset class?
   5. Do the exposure results obtained from the reporting firms allow us to identify any
      previously undetected systemically important firms?


Although 10-by-10-by-10 reports would be collected from a small number of designated
firms, the results would likely shed light on risk flows between these firms and
potentially many other firms. Because of this, a regulator may be able to identify non-
reporting firms that are candidates to be designated as systemically important, and
perhaps also be added to the list of reporting firms. This process of augmenting the
reported network can be iterated. An analysis of 10-by-10-by-10 data could also trigger
follow-up supervisory conversations between regulators and individual firms, or groups
of firms. For example, a regulator might wish to alert a group of banks that they have
significant exposures in the same asset class and in the same direction with a
concentrated common set of counterparties.

It is to be emphasized that this approach to systemic risk monitoring is much broader than
a counterparty default exposure measurement system, although counterparty default
exposures are included in it. For a given scenario, large gains shed as much light on risk
flows through the financial system as do large losses. Moreover, even if reported gains
and losses do not threaten the viability of reporting firms or their immediate
counterparties, they may be important clues to the magnitudes of risk flows in given asset
classes, and may allow regulators to consider the potential for contagion through fire
sales.
Under this monitoring scheme, once revised and implemented, the reporting entities
would provide the stipulated measures periodically, say quarterly, to designated
regulators. Regulators from various jurisdictions would pool and then analyze the data.
The overall objective would be to monitor the exposure of the financial system to
systemically important stresses. The joint exposure of the system to the performance of
particular asset classes, macroeconomic events, and entities (or chains of entities) could
as a result be clarified. Summary information could be publicly disclosed, for example in
the form of histograms or population statistics, making a reasonable tradeoff of the costs
and benefits of releasing firm-specific or detailed data. For example, the Financial
Services Authority of the United Kingdom has provided semi-annual reports of the
default exposures of U.K. banks to hedge-fund counterparties. Public knowledge of
summary information regarding stresses across the financial system of various types may
contribute to an endogenous lowering of critical stresses through re-pricing and portfolio
adjustments.

Regulators may choose to be cautious, however, about creating additional uncertainty, or
potentially even triggering runs, through public reporting of detailed firm-specific
contemporaneous stress information.1 Rather, their objective may be to alert themselves
and the public to potential sources of financial instability before they reach dangerous
levels.

Full and immediate public disclosure of firm-specific stress reports could also dampen
the incentives of reporting firms to act as liquidity providers, temporarily warehousing
risk, as modeled by Grossman and Miller (1981) and Brunnemeier and Pedersen (2008).
Intermediaries would expect more severe price impacts when unloading large positions if
the sizes of their positions are known publicly. Bid-offer spreads would widen, and
market liquidity could suffer as a result. For similar reasons, in the face of instant public
disclosure of their positions, the incentives to gather fundamental information would be
reduced, worsening the price-discovery function of financial markets.

Separate analysis would likely suggest criteria for the selection of important stress
scenarios, as well as precise instructions for stress measurement. It is natural to specify
extreme-but-plausible scenarios for changes in market prices, or performance of non-
priced instruments, that could occur within, say, one quarter. The relevant shocks are
those likely to have occurred conditional on a major financial crisis. Illustrative examples
of these scenarios could include:

    1.   The default of a major entity.
    2.   A 4% simultaneous change in all credit yield spreads.
    3.   A 4% shift of the U.S.-dollar yield curve.
    4.   A 25% change in the value of the dollar relative to a basket of major currencies.
    5.   A 25% change in the value of the Euro relative to a basket of major currencies.
    6.   A 25% change in a major real estate index.

1 The security of the data is clearly a concern, and this should figure carefully into the design of the
reporting system. It should be possible, if desired, to use encryption methods to ensure that even some
regulators are unable to fully disaggregate the data.
    7. A 50% simultaneous change in the prices of all energy-related commodities.
    8. A 50% change in a global equities index.


The asset classes covered by these scenarios are broad, keeping the reporting system
relatively simple and robust. While individual financial firms may be heavily exposed to
long-short strategies within an asset class, major financial crises are more likely to be
connected with severe price movements across a large asset class.

Much of the required reporting methodology is within the scope of current state-of-the art
risk-management systems used by major financial institutions.2 For example, it is
somewhat routine for major banks to monitor their largest credit exposures, incorporating
for each major counterparty all significant contractual positions, covering loans, bonds,
equities, over-the-counter derivatives, and loan guarantees. Likewise, the gain or loss in
market value associated with a return scenario of the sort shown in the list above is often
captured within existing risk-management systems by replacing the current market prices
used for monitoring the values of positions with the stipulated artificial prices, and then
recalculating position values.3 The total change in value is the reported gain or loss. All
positions that are contractually linked to the indicated price scenario must be identified,
scenario by scenario. At least in terms of methodology, this is a conventional approach
for large sophisticated banks and large hedge funds. Notably, this approach is “model-
free.” That is, from the viewpoint of reporting firms, the stress scenarios are precisely
defined deterministic scenarios provided by the regulator. The reporting firms would not



2
   For example, J.P Morgan’s 10Q disclosure for June 2010 states: “The Firm conducts economic-value
stress tests using multiple scenarios that assume credit spreads widen significantly, equity prices decline
and significant changes in interest rates across the major currencies. Other scenarios focus on the risks
predominant in individual business segments and include scenarios that focus on the potential for adverse
movements in complex portfolios. Scenarios were updated more frequently in 2009 and, in some cases,
redefined to reflect the significant market volatility which began in late 2008. Along with VaR, stress
testing is important in measuring and controlling risk. Stress testing enhances the understanding of the
Firm’s risk profile and loss potential, and stress losses are monitored against limits. Stress testing is also
utilized in one-off approvals and cross-business risk measurement, as well as an input to economic capital
allocation. Stress-test results, trends and explanations based on current market risk positions are reported to
the Firm’s senior management and to the lines of business to help them better measure and manage risks
and to understand event risk-sensitive positions.” SEC Financial Reporting Release 48 and International
Financial Reporting Standard 7 mandate disclosure of value-at-risk or sensitivities to various market
stresses. IFRS7 requires sensitivities to interest rates, currencies, and “other price risk” (for example, that
from equities and commodities), including the impact on profits and on firm equity for “reasonably
possible” changes in the relevant variable (Section 40). The New York Fed, through its supervisory
monitoring program, collects information from reporting banks on the sensitivities to key risk factors of the
market values of their trading and held-to-maturity assets that are marked to market. The Federal Reserve
System currently collects additional information on the sensitivities of the portfolios of banks to specified
risk factors. The comments of Fed Governor Daniel Tarullo, of February 2010, suggest ongoing efforts in
this direction, and the need to further study systemic linkages.

3 An alternative is a “delta‐based” approach, by which the sensitivity of a position value to a unit shift
in the underlying price is multiplied by the stipulated price change. With extreme scenarios, the
delta‐based approach would be inaccurate for non‐linear positions, such as options.
use model-based probabilistic methods, such as those applied for Value-at-Risk
measurement.

In order to calculate the cash-flow impacts of a scenario, substantial contractual detail
would need to be captured by a risk-management system. Cash-flow impacts include
those associated with collateral exchanges, option exercises, termination settlement of
OTC derivatives, debt payments (or lack thereof), and so on. Some of the likely reporting
firms may not have the information technology needed to collect and aggregate the cash-
flow impacts of shocks to major asset classes, particularly with respect to specific
counterparties. This capability, going beyond that required for measuring Basel III
liquidity coverage ratios, would need to be added to their risk-reporting systems.

Brunnermeier, Gorton, and Krishnamurthy (2011) have proposed a new measure of
balance-sheet liquidity that would be complimentary to the cash-flow stress measures
proposed here. Notably, their liquidity measure addresses the ability of a reporting firm to
withstand a liquidity shock.

For asset classes that are not marked to market, such as the non-traded loan books of
major banks, scenarios can be converted by regulators into stipulated default losses or
other performance losses, as has been done in some cases for the recent system-wide
bank-capital stress tests of the United States and the Eurozone.

A macroeconomic scenario, such as a reduction in the growth rate of gross domestic
product, can be converted by regulators into stipulated return shocks for positions that are
marked to market, or into stipulated rates of loss for non-traded loan books. One is
interested in the expected gain or loss in value (or cash-flow impact) of each asset class,
conditional on the scenario. These return or performance shocks would be estimated by
the regulator and provided to all reporting firms as inputs to their reporting methodology.
In this way, standardization is promoted. Standardization is particularly valuable in a
network setting in which one hopes to follow the transmission of financial shocks from
node to node through the network. Standardization also reduces noise and moral hazard
that would otherwise arise in the interpretation by reporting firms of broadly defined
macroeconomic stresses.

Likewise, in designing a stress scenario, a regulator interested in the all-in impact of a
shock to a particular asset class could stipulate the given return shock to that asset class,
as well as the expected returns to all other major asset classes conditional on the return
shock to the target asset class.4 As such, each scenario is specified by regulators and
passed to reporting firms as a list of deterministic returns or performance shocks to all
asset classes.

Some care would be needed to ensure that all, or at least the vast majority, of a reporting
firm’s positions are mapped to associated exposures by asset classes. This is already
standard practice for the risk-management systems in use by many large financial firms,


4   I am grateful to Rob Engle for this suggestion.
but the list of asset classes and the methodologies that are currently used for these
instrument-to-asset-class mappings differ across firms.

One of the stipulated scenarios, the default of a single entity, entails a calculation of the
total loss associated with the failure of an issuer, borrower, or OTC counterparty,
combining all contractual exposures, including debt, equity, securities lending, and
derivatives. The regulator could specify a fractional loss of value given default, or require
based on zero recoveries. The associated 10 counterparties for this stress would be those
whose defaults would lead to the greatest losses to the reporting firm. These entities
could often include sovereigns, quasi-sovereigns, and financial utilities, such as central
clearing parties.

The U.K. Financial Services Authority (FSA) already conducts a regular survey of the
exposures to hedge funds (only) of U.K. banks. For example, in July 2010, the FSA
reported that the maximum potential credit exposure (which includes the effect of
10‐day 99% value at risk) of any one bank to any one hedge fund was approximately
$600m.

A significant amount of work may be needed in order to refine the definitions of the
exposure measures, including distinctions between gross and net losses. For example, a
given scenario loss could be measured:

   1. On a mark-to-market basis, assuming no collateral and allowing for netting only
      within legally enforceable master netting agreements. In this case, the measured
      gain or loss would effectively assume that any potentially netting offsets of gains
      or losses with a single counterparty cannot be realized except where clearly
      required by master netting agreements, and would be measured before offsetting
      reductions allowed by collateralization.
   2. On a net mark-to-market basis, after the use of collateral and legally enforceable
      netting.
   3. On a cash-flow basis, within a prescribed time period such as 30 days, the
      duration standard for the Basel III liquidity coverage ratio requirement.

Notwithstanding the ability of a reporting entity to offset losses by applying collateral,
gross-of-collateral exposure measures may assist regulators in understanding the
magnitudes of risks for a given asset class flowing across specific links in the financial
system, and also them to consider the potential impact of asset fire sales, including sales
of collateral. The objective is to capture systemic linkages, whether or not, by virtue of
collateral, they expose the reporting financial institution to significant losses. Likewise,
the “largest” counterparties for a given scenario are selected on the basis of the absolute
magnitude of the gain or loss, and not on the basis of the loss to the reporting institution.


Some Shortcomings
A shortcoming of the 10-by-10-by-10 approach is that the total sensitivity of a financial
entity to some relatively broadly defined risk factor may be moderate while at the same
time the entity has dangerously large long and short exposures within the broadly
specified risk class. For example, the 2006 failure of the hedge fund Amaranth Advisors
LLC was caused by approximately $6.5 billion in losses on roughly equally sized long
and short positions in natural gas futures contracts for two different delivery months,
March and April 2007, respectively. Similarly, the significant losses of certain “quant
equity” hedge funds in August 2007 stemmed from long and short equity positions that
left these funds relatively unexposed to a shift in the overall level of major stock indices.
The general concern that the defined risk factors may be too broad to capture some
important narrowly concentrated exposures is mitigated by the likelihood that firm-
threatening exposures to relative movements within a well chosen broad risk factor are
likely to be held by a relatively small set of firms. In any case, nothing rules out the
selection of long-short or cross-market stresses if these are believed to be among the most
important potential shocks to the financial system.

Another shortcoming of the 10-by-10-by-10 approach is that it would miss widely
dispersed potential sources of systemic risk that do not flow through major financial
institutions. For example, the U.S. Savings-and-Loan Crisis of the 1980s did not present
large directly measurable stresses to systemically important financial institutions. The 10-
by-10-by-10 approach captures only those sources of stress that pass through the center
of the financial system. Regulators could perhaps augment with additional network-based
stress analysis that reaches more broadly into the financial system.

The magnitudes of losses caused by a specific stress do not on their own determine
whether a firm has the necessary capital and liquidity to withstand the stress without
failure. The data provided through 10-by-10-by-10 reports may be useful in judging the
ability of firms to withstand important shocks, but for that purpose would need to be
accompanied by additional firm-specific capital and liquidity measures. In that sense, 10-
by-10-by-10 reports could provide useful data for the supervisory analysis of
systematically important firms.

Essentially any stress measurement system is subject to a financial-risk-management
analogue of the Heisenberg Uncertainty Principle, by which increasing the precision of
one’s measurement of one aspect of a system merely increases uncertainty regarding
other dimensions of the system. This endogeneity is similar to that of the well known
“Lucas Critique.” The shareholders and some of the employees of a financial institution
often have an incentive to take more risk than is socially optimal because they do not
internalize the costs of systemic risk. When a regulator focuses on a particular risk
measure, a reporting financial institution may adjust its risk taking behavior so as to
lower this risk measure while raising its risk elsewhere.

For example, regulators commonly focus on “value at risk,” the loss on a given portfolio
that is exceeded with a small defined probability, say 5%. A reporting financial
institution may as a result choose to increase its exposure to losses that occur with a
smaller probability than 5%. Similarly, if a regulator measures the exposure of a bank to
a 25% change in the value of an asset, the bank could buy and sell options on the asset so
as to lower this particular exposure, while raising its exposure to a 30% change in the
value of the asset. In the face of concerns about this form of window dressing, a regulator
could request the impacts to a graduated range of shock magnitudes, from moderate to
large. In general, by limiting the stress measures to a small number of extremely broad
asset classes, the “Heisenberg uncertainty effect” is significantly mitigated, but is not
eliminated.

Eventually, regulators may have sufficient instrument-level data to directly conduct risk
analyses without reliance on reporting by the firms they are monitoring. This would
dramatically increase the range of tests and studies that could be conducted, and lower
concerns over standardization of the implementation across reporting firms, as well as
window-dressing behavior. On the other hand, the cost and time delays associated with
comprehensive and accessible instrument-level regulatory databases currently seem large,
to say the least. In any case, the ability of each reporting firm to administer stress reports
within its own risk-management system is of some independent risk-management value.

The greater the standardization of risk measures, the greater is the danger of “group-
think,” that is, an unhelpful common focus or agreement on what matters, in the presence
of unconsidered relevant alternatives. Group-think that is caused by a common industry-
wide risk measurement approach could lower the chance that important alternative
sources of systemic risk would be identified by creative individual analysis, or would be
brought forward for treatment once identified.

Further, standardization of risk measures may encourage common approaches to hedging
or speculation that could destabilize markets if a significant number of important
financial institutions rush toward a common exit from dangerous positions that are
identified by a dramatic increase in a specific standardized risk measure.




References and Additional Readings


Brunnermeir, Markus, Gary Gorton, and Arvind Krishnamurthy (2011) “Risk
Topography,” Working Paper, Princeton University.

Brunnermeier, Marcus, and Lasse Pedersen (2009) “Market Liquidity and Funding
Liquidity,” Review of Financial Studies, 22, 2201-2238


Ahmed, Anwer, Anne Beatty, and Bruce Bettinghaus (2004) “Evidence on the Efficacy
of Interest-Rate risk Disclosures by Commercial Banks,” The International Journal of
Accounting, 39 (2004) 223– 251.
Aikman, David, Piergiorgio Alessandri, Bruno Eklund, Prasanna Gai, Sujit Kapadia,
Elizabeth Martin, Nada Mora, Gabriel Sterne and Matthew Willison, “Funding Liquidity
Risk in a Quantitative Model of Systemic Stability,” Working Paper No. 372, Bank of
England, June 2009.

Anderson, Jenny, "Betting on the Weather and Taking an Ice‐Cold Bath". New York
Times, September 29, 2006.
http://www.nytimes.com/2006/09/29/business/29insider.html.

Basel Committee on Banking Supervision, “Principles for the Management and
Supervision of Interest Rate Risk,” Bank for International Settlements, Basel, July, 2004.
http://www.bis.org/publ/bcbs108.pdf?noframes=1


Financial Services Authority, “Assessing Possible Sources of Systemic Risk from Hedge
Funds: A Report on the Findings of the Hedge Fund as Counterparty Survey and Hedge
Fund Survey, United Kingdom Financial Services Authority, London, July 2010
www.fsa.gov.uk/pubs/other/hedge_funds.pdf


Grossman, S. J., and M. H. Miller (1988) “Liquidity and Market Structure,” Journal of
Finance 43, 617–33.

Linsmeier, Thomas, Daniel B. Thornton, Mohan Venkatachalam, and Michael Welker
(2001) “Do FRR 48 Disclosures Reduce Investors’ Uncertainty and
Diversity of Opinion about Firms’ Market Risk Exposures?:
A Trading Volume Analysis,” Stanford University, Graduate School of Business,
Working Paper 1674.

Tarullo, Daniel, “Equipping Financial Regulators with the Tools Necessary to Monitor
Systemic Risk,” Testimony before the Senate Subcommittee on Security and
International Trade and Finance, Committee on Banking, Housing, and Urban Affairs,
Washington, D.C., February 12, 2010.
http://www.federalreserve.gov/newsevents/testimony/tarullo20100212a.htm
