                               NBER WORKING PAPER SERIES




                          MANAGING INNOVATION IN A CROWD

                                         Daron Acemoglu
                                        Mohamed Mostagir
                                        Asuman Ozdaglar

                                       Working Paper 19852
                               http://www.nber.org/papers/w19852


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                     January 2014




We thank Glenn Ellison, Luis Garicano, Karim Lakhani, Jonathan Levin, David Miller, and seminar
participants at Duke, Johns Hopkins, Michigan, Microsoft Redmond, MIT, University of Texas-Austin,
and University of Washington for useful comments and discussion. We gratefully acknowledge financial
support from Draper Labs and the Toulouse Network for Information Technology (supported by Microsoft).
The views expressed herein are those of the authors and do not necessarily reflect the views of the
National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2014 by Daron Acemoglu, Mohamed Mostagir, and Asuman Ozdaglar. All rights reserved. Short
sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided
that full credit, including © notice, is given to the source.
Managing Innovation in a Crowd
Daron Acemoglu, Mohamed Mostagir, and Asuman Ozdaglar
NBER Working Paper No. 19852
January 2014
JEL No. D20,D83,L22

                                              ABSTRACT

Crowdsourcing is an emerging technology where innovation and production are sourced out to the
public through an open call. At the center of crowdsourcing is a resource allocation problem: there
is an abundance of workers but a scarcity of high skills, and an easy task assigned to a high-skill worker
is a waste of resources. This problem is complicated by the fact that the exact difficulties of innovation
tasks may not be known in advance, so tasks that require high-skill labor cannot be identified and allocated
ahead of time. We show that the solution to this problem takes the form of a skill hierarchy, where
tasks are first attempted by low-skill labor, and high-skill workers only engage with a task if less skilled
workers are unable to finish it. This hierarchy can be constructed and implemented in a decentralized
manner even though neither the difficulties of the tasks nor the skills of the candidate workers are
known. We provide a dynamic pricing mechanism that achieves this implementation by inducing workers
to self select into different layers. The mechanism is simple: each time a task is attempted and not
finished, its price (reward upon completion) goes up.


Daron Acemoglu                                       Asuman Ozdaglar
Department of Economics, E18-269D                    Dept of Electrical Engineering
MIT                                                  and Computer Science
77 Massachusetts Avenue                              Massachusetts Institute of Technology
Cambridge, MA 02139                                  77 Massachusetts Ave, E40-130
and CIFAR                                            Cambridge, MA 02139
and also NBER                                        asuman@mit.edu
daron@mit.edu

Mohamed Mostagir
Ross School of Business
University of Michigan
701 Tappan Ave. R5316
Ann Arbor, MI 48109-1234
mosta@umich.edu
1       Introduction
Goldcorp, a gold mining company based in Vancouver, terminated its mining operations and was on
the brink of bankruptcy as a result of increases in production costs and its inability to reliably estimate
the value and location of gold on its property. As a final maneuver, the company published its geolog-
ical data online and asked people to submit their estimates and estimation methods in exchange for
prize money that totalled a little over half a million dollars. The crowd identified 110 targets that led
to the extraction of a staggering $8 million ounces of gold, transforming the $100 million company
into a $9 billion powerhouse. Today, Goldcorp is the second largest gold company in the world.1
More recently, the website “fold.it” provided the public with a chance to design and fold proteins, a
computational biology task that routinely stumps supercomputers. Within three weeks, the crowd of
participants were able to determine the structure of an AIDS-related enzyme, a task that the scien-
tific community had unsuccessfully tackled for over a decade, and that represents a significant step
forward in finding a cure for the disease.
        These are two examples of a growing number of success stories where innovation is sourced out
to the public.2 Historically, improvements in information and communication technology have led to
major revisions in the nature of the firm (see, e.g., Chandler (1977) and Garicano and Rossi-Hansberg
(2006)), and some argue that crowd innovation is poised to be a natural next step in this chain of
evolution. The idea that innovation can happen outside of the confinements of a firm is not new, see
for example Von Hippel (1976); Chesbrough et al. (2008); Von Hippel (2009), but it is only now that the
technological infrastructure has made it possible to facilitate this phenomenon on an unprecedented
scale.
        Despite its successes, crowd innovation remains a technology in infancy, using mostly ad hoc
methods and mechanisms, and faces a wealth of challenges in resource allocation, pricing, and in-
centive design. A firm can now have immediate access to an unlimited supply of labor and a wide
pool of talent and skills, but extracting the good from the bad and managing this pool of workers is
fraught with difficulties.
        This paper presents a simple model of crowd innovation in which a firm seeks to assign a range of
innovation tasks of unknown difficulty to a set of heterogeneous workers using a virtual marketplace.
Unlike organizations, where employers can assign tasks to workers at will, crowd innovation takes
place in a large and anonymous virtual market where employers cannot assign workers to specific
tasks and do not know the workers’ specific skills. In addition, the nature of innovation tasks pre-
cludes specific information about how difficult these tasks are and what type of workers will be able
to complete them.
    1
     “Innovation in the age of mass collaboration”, Bloomberg Businessweek 2007-02-01.
    2
     The emerging technology of “crowdsourcing” sources what has come to be known as “Human Intelligence Task” or
HITs to a virtual marketplace. HITs are simple tasks that can be performed by almost any one (for example, determining
whether a photograph contains a certain object or not). Because of their easy nature, these tasks are priced extremely low,
paying a fraction of a cent on average. We use the term “crowd innovation” for the application of crowdsourcing techniques
to innovation tasks, which are more difficult and require skills or innovative solutions to problems that cannot otherwise
be routinely handled within a firm.



                                                            1
       Our first contribution is conceptual. We show that the informational and coordination difficulties
described above not withstanding, crowdsourcing and innovation can be organized as if they were
taking place within an organization, but with some constraints resulting from the market allocation.
In particular, we show that by providing appropriate rewards and incentives in the marketplace, the
problem of crowd innovation can be related to the problem that an organization faces in assigning
workers of different skills to tasks of different difficulties.
       Our technical contribution formalizes this idea. We first characterize the optimal matching of tasks
to workers in environments in which tasks have unknown difficulties but worker skills are known
and workers can be assigned to sets of tasks (and thus their “voluntary participation” decisions can
be ignored). Under these assumptions, we show that the optimal matching takes the form of a skill
hierarchy: tasks are first attempted by the less-skilled workers and high-skilled workers only engage
in a task if workers with lesser skills are unable to finish it. In particular, workers are arranged into
groups according to their skill and tasks are offered to groups in a sequential fashion. We then derive
the structure of the optimal hierarchy by studying a dynamic programming formulation. The most
distinctive property of the optimal matching is that it ensures that the heterogeneous skills of the
available workers are utilized efficiently.
       We then show that this optimal matching can be implemented when worker skills are unknown
and workers choose when to participate and which tasks to work on. This implementation relies on
a simple pricing scheme in which rewards for completing tasks increase the longer these tasks re-
main uncompleted (i.e., the more times they are unsuccessfully attempted). What makes this pricing
scheme support the optimal matching is that, as we show, there is a natural comparative advantage
property in crowd innovation: if a worker of a given skill level prefers to participate later rather than
earlier, then more skilled workers would also choose to do so.3 Thus the increasing prices of difficult
(uncompleted) tasks and comparative advantage jointly provide incentives for higher-skilled workers
to delay their participation.4
       Most closely related to our paper is the work on the design of knowledge or skill hierarchies
within organizations, in particular, in Garicano (2000); Beggs (2001); Garicano and Rossi-Hansberg
(2004); Antràs et al. (2006); Garicano and Prat (2013). In these papers, workers belong to the same
firm and can cooperate on solving problems in order to increase output, and workers in different
levels of the hierarchy specialize in solving only certain kinds of problems that complement other
existing skills. The decision of which skills to obtain is a decision that is endogenous to the work-
ers and the organization, and can be based, as in Garicano (2000), on the difficulty distribution that
the firm faces. This ensures that the skills in the pool of workers and difficulties in the task pool are
aligned. This feature, though it makes these models elegantly tractable, does not provide an adequate
description of crowd innovation environments, where a mismatch between task difficulties and skills
is commonplace, where skills are often very dispersed and unknown, and where voluntary participa-
   3
     See Roy (1951); Sattinger (1975); Tinbergen (1974); Teulings (1995) on the role of comparative advantage in other prob-
lems of assignment of workers to tasks.
   4
     A small literature discusses practical ways of pricing Human Intelligence Tasks in crowdsourcing. See, e.g., Horton and
Chilton (2010) and Faridani et al. (2011).


                                                             2
tion of workers is a central issue. In addition, in this literature, there is an “infinite supply of tasks”:
each worker in the lowest level of the hierarchy produces a task, and if they are unable to perform
these tasks satisfactorily, then can ask for help from others in the organization. This naturally leads
to a pyramid-like hierarchy. These differences undergird several disparities in the results of the two
lines of work. First, though in our setting the optimal matching of skills to tasks is also hierarchical
(meaning that more skilled workers are assigned to tasks that less skilled workers attempt and can-
not complete), this hierarchy does not necessarily take the familiar pyramidal shape that it takes in
these works (as well as in most of the organizational economics literature) because it may be optimal
to preserve middle-skilled workers for higher echelons of the hierarchy and allocate only the lowest
skilled ones to the bottom layer. Second, in contrast to Garicano’s work, where more (possibly infi-
nite) layers in the hierarchy can increase output, increasing the number of layers in the hierarchy may
be detrimental. This result highlights the importance of the potential mismatch between skills and
tasks. More layers can lead to strictly lower output because they expose more workers to the most
difficult tasks that they would not be able to complete (this contrasts with the case where some sub-
set of workers can choose their skill level so as to be able to complete even the most difficult tasks).
Finally, another difference from the work on knowledge hierarchies is that crowd innovation works
in the marketplace, without knowledge of the exact skills of workers and without the ability to pre-
cisely control the assignment of a worker to a specific task, and thus the optimal hierarchy in crowd
innovation is not organized by a firm, but results from a market equilibrium.5
    Recent work by Fuchs et al. (2013) examines an environment similar to ours where producers
encounter tasks of unknown difficulties and try to solve them with the help of outside consultants
of unknown skills. A key difference is once again that Fuchs et al. (2013) look for a contractual so-
lution to this matching and informational asymmetry problem. Their optimal assignment is thus
implemented through a “firm-like” structure in which the highest skilled workers (“consultants”)
are residual claimants, and employ lower skilled workers and incentivize them through contracts.
In contrast, as noted in the previous paragraph, the optimal hierarchy in our setting emerges as a
market equilibrium. More specifically, it is implemented via the marketplace using a simple pricing
mechanism.6
    Also complementary to our work is the literature on innovation tournaments. An innovation
tournament encourages competition amongst participants in order to obtain a prize. There is still
little understanding of how to select the value and timing of these prizes to ensure that the goal
of the tournament is achieved.7 Our paper takes a different approach by combining elements of
both cooperation and competition, since workers compete for tasks but at the same time, under the
mechanism described above, act as if they are part of a cooperative, hierarchical organization that is
   5
     This point relates our work to the literature on experts Wolinsky (1993), where the primary difficulty is judging whether
or not a service that an expert provided is justified. This difficulty arises from informational asymmetries between the expert
and the party that receives and pays for the service. Recent work shows how an expert can reveal information in a way that
manipulates the receiver even when all parties involved are rational Kamenica and Gentzkow (2011).
   6
     Another differences that there is no matching among workers in our model.
   7
     A common method in the literature models an innovation tournament as a simple all-pay auction and utilizes existing
results in that area to draw conclusions about tournaments Moldovanu and Sela (2006); Chawla et al. (2012).


                                                              3
working in tandem on a project.8
        Finally, our model can be viewed as a specific instance of stochastic matching problems in com-
puter science, where nodes in a graph are connected by edges and these edges have ’success prob-
abilities’ attached to them. A matching of two nodes is successful with a probability equal to the
probability of the edge that joins these nodes, and success (or failure) is realized upon the actual
match. In our setting, one node is a worker and the other is a task, and the probability of successful
match indicates how likely it is that the difficulty of the task is within the worker’s skill. There has
been some recent interest in this problem because of its applications to online dating and ad alloca-
tion problems, for example, as in Feldman et al. (2009); Bansal et al. (2010). The stochastic nature of
the problem leads to an exponentially large dynamic programming formulation with no adequate ap-
proximate solution (see, e.g., Chen et al. (2009)). Because the supply of workers in a crowd innovation
environment is usually very large, we circumvent some of the technical problems encountered in the
stochastic matching literature by studying the continuum limit.
        The paper is organized as follows. Section 2 introduces the model and defines the assignment and
implementation problems. Section 3 derives the necessary results to analyze the dynamic program-
ming formulation of the assignment problem. Section 4 provides a pricing scheme for the implemen-
tation problem. Section 5 details the role of various assumptions in our results and discusses how the
results apply in more general settings, and Section 6 concludes the paper. Proofs are presented in the
Appendix.


2       Model
2.1       Setup

There is a set W of workers indexed by i ∈ [0, A] and a set T of tasks indexed by j ∈ [0, 1]. Both sets
are equipped with a Lebesgue measure λ and we assume that λ( T ) is normalized to one and that
λ(W) > λ(T ), i.e. there are more workers than tasks. The difficulty d of a task in a set T ⊆ T is a
nonnegative scalar distributed according to FdT . Similarly, the skill s of a worker in a set W ⊆ W is a
nonnegative scalar distributed according to FsW . We will assume that the workers in W are ordered
in ascending order of skill, so that si ≥ sj if i > j. Define G(s) : R → [0, λ(W)] to be the measure of
workers whose skill is less than or equal to s and let G−1 (w) be its inverse, i.e., G−1 (w) is the skill at
or below which a measure w of workers reside.9
        Motivated by the crowdsourcing application which takes place in the marketplace, we assume
that once a set of workers have been given access to a set of tasks, each will freely choose which tasks
to work on. We also assume that working on a task is time-consuming, so the worker can at most
work on a single task. This motivates our definition of a matching, which we give next.
    8
      Based on a large data set, Boudreau et al. (2011) find that more unrestricted entry into a tournament is useful the more
difficult (in a probabilistic sense) an innovation task is. We find that for some scenarios, even though in our setting workers
attempt tasks sequentially, the same recommendation holds true.
    9
      The difference between FsW (s) and G(s) is that the first is a probability distribution, while the second is not since
λ(W) > 1.


                                                              4
       A matching m(W, T ) is a measurable map satisfying measure consistency: for every open interval
Z ⊆ W, λ(Z) = λ(m(Z)). Furthermore, if Ŵ and W̄ are in W and Ŵ ∩ W̄ = ∅, then m(Ŵ )∩m(W̄ ) = ∅.
Therefore, a matching does not specify which of the workers in W will work on which of the tasks in
T , but imposes that this assignment will be one-to-one (since a single worker cannot simultaneously
work on two tasks).
       Define the output of a pairing of a worker of skill s with a task of difficulty d to be equal to 1 if s ≥ d
and 0 otherwise. The output of a match m, θ(m) is the total amount (measure) of tasks successfully
completed under m, and is thus given by integral of the output over all task-worker pairs in m.
       We also assume that the time a worker needs to spend working on a task until he realizes that he
cannot complete it is much smaller compared to the time spent by workers who are actually able to
finish their tasks.10 This implies that over time, though a single worker cannot successfully work on
two tasks, a single task can be sequentially assigned to two different workers. This then motivates
a central aspect of our approach, which allows matching to be sequential. In a sequential matching
process, a first match m1 would assign some tasks to some workers, and then a second match m2
would assign some tasks (possibly containing uncompleted tasks from the first match) to another set
of workers and so on. To capture this idea formally, we denote by Wi and Ti the sets of workers and
tasks that constitute the ith match. The set of tasks completed in the ith match is denoted by Tic and
                                                             0 .
the set of tasks leftover after the ith match is denoted by Tm i


Definition 1. Let T be a set of tasks. A sequential matching µ of tasks to workers is a series of
matchings {mi } with the following properties:

   1. Wi ∩ Wj = ∅ for all i and j,
                       0
   2. T1 ⊆ T and Ti ⊆ Tm     for i = 2, ....
                         i−1



       The first part of the definition implies that a worker can be part of at most one matching. The
second states that the pool of tasks available at any point is equal to the set of tasks we started with
minus the tasks that were completed in earlier matchings. Notice that a one-shot matching m of T to
W can be written as a degenerate sequential matching µ with T1 = T and W1 = W . As mentioned, we
use FdTi and FsWi to refer to the distributions of difficulties and skills in the task and worker groups
at stage i respectively. Throughout the paper we denote a sequential matching by µ and a regular,
  10
     While an unsuccessful worker could keep a task for longer rather than reveal that he is unable to complete it, we assume
that this is not the case, a result that can be derived formally by assuming that the worker has some positive opportunity
cost of time somewhere else. There is also a possibility that a worker who fails to complete a task ignores reporting the
task’s status and simply moves on, leaving the task in limbo. One strategy to deal with uncompleted tasks remaining in
limbo is the one employed by crowdsourcing platforms like Amazon’s Mechanical Turk, which gives only a fixed amount
of time to a worker to communicate the status of the task, after which the task is returned back to the pool of unassigned
tasks.
  We might also remark that in a hierarchical matching in the form we derive below, because remaining tasks become suc-
cessively more difficult in expectation, a worker who is unsuccessful at one stage would prefer to exercise his outside option
rather than attempt further tasks in later stages. We discuss how our results are modified when workers can participate in
further stages after failing to complete their assigned tasks in Section 5.




                                                              5
one-shot matching by m. The output of a sequential matching is the total output of the individual
                              P
matchings it comprises: θ(µ) = i θ(mi ).
       The next definition introduces a key concept of our analysis.

Definition 2. Consider a sequential matching and for all i, let min{Wi } = {minj sj |j ∈ Wi } and
max{Wi } = {maxj sj |j ∈ Wi } be the skills of the least and most skilled workers, respectively, in Wi .
A sequential matching is hierarchical if max{Wi } ≤ min{Wl } whenever i < l.

       A hierarchical matching is a partition of workers into several groups based on skill, such that
workers in group i are less skilled than workers in group j > i. Tasks are then offered to the least-
skilled group, where some tasks may be completed and some not. The remaining tasks are assigned
to the next group and the process repeats.11
       From the discussion above, a sequential matching is likely to take longer to conclude than a one-
shot matching. To capture this, we assume that the employer can afford to have at most k sequential
rounds of matchings. The objective then is to find a output-maximizing matching µ∗ that consists of
at most k matchings. Let us denote the number of individual matchings in a sequential matching µ
by |µ|, then the employer wants to solve

                                                          max θ(µ)                                    (1)
                                                            µ
                                                          s.t. |µ| ≤ k

       In this paper, we consider two versions of the employer’s problem: the assignment problem, and
the implementation problem, which we next discuss.


2.2      The Assignment Problem

The assignment problem involves solving (1) assuming that worker skills are known and workers
can be assigned to different stages of matching (without respecting any additional incentive com-
patibility or participation constraints). In imposing that the assignment of heterogeneous workers to
tasks be performed without respecting incentive compatibility constraints, this assignment problem
is similar to the approach in Garicano (2000) and the subsequent literature on knowledge hierarchies
in organizational economics, with the important differences noted earlier of having a finite (vs. in-
finite) measure of tasks and exogenous worker skills. Also, for our purposes, this problem is just a
step in the mathematical characterization of the market allocation rather than an economic problem
of interest.
       Note also that even in (1), we are imposing the constraints implied by the institutional structure
of outsourcing and crowd innovation problems whereby within a particular stage of a sequential
matching, the employer has no control over which worker will work on which task.
  11
       We use the terms ”groups”, ”levels”, and ”layers” interchangeably throughout.




                                                             6
2.3        The Implementation Problem

The implementation problem characterizes the optimal matching subject to the additional informa-
tional and incentive compatibility constraints of workers — which we ignore in the assignment prob-
lem. This problem can in general be quite difficult in view of the myriad of incentive compatibility
constraints which may distort the optimal matching away from the “first-best” matching — the solu-
tion to the assignment problem. In our case, however, we will show that with an appropriate pricing
scheme, the assignment problem can be decentralized, which is a much more tractable problem than
a general characterization of “second-best” matching mechanisms.


3        The Assignment Problem: Analysis and Optimal Matching
In this section we analyze the structure of the optimal sequential matching. We restrict our decision
variable in stage i to be the choice of Wi . This group is assigned a measure of tasks uniformly at
random from the pool of available tasks, i.e., choosing a particular group of tasks to match to workers
is not part of the decision process. This is a consequence of the fact that, as discussed in the previous
section, in a crowd innovation environment workers who decide to participate pick whichever task
they choose from the available group of tasks with no control from the employer.
         In light of this, we use the notation m(W, T ) to mean a random assignment of tasks in T to workers
in W . We will sometimes abuse notation slightly by referring to m(Wi , T ) as mi , the ith match.
         The structure of the optimal sequential matching may not be obvious at first. One can imagine
a scenario where the difficulty distribution makes assigning tasks to more skilled workers first and
then moving to less skilled ones optimal.12 The idea is that if there are few difficult tasks and lots
of easy tasks, then the skilled workers would finish the difficult tasks that can later burden the less
skilled workers, and hence these latter workers would get a chance to focus on the easy tasks without
running into difficult ones. This intuition turns out to be incorrect in our setting. The reason, which
will be highlighted in detail in Lemma 1, is that once tasks go through a matching, the difficulty
distribution of the remaining tasks is never easier –in a stochastic dominance sense– than the original
distribution before the matching. The main result of this section is the following theorem, which
characterizes the optimal sequential matching.

Theorem 1. Consider a set of tasks T of unknown difficulties and a set of workers W with λ(W) > λ( T )
and smooth distributions FdT and FsW . There exists a hierarchical matching µH of tasks to workers such that
θ(µH ) ≥ θ(µ) for all µ.

         Theorem 1 states that the optimal matching is obtained by arranging workers in a hierarchical
fashion. The rest of this section provides a series of lemmas that establish the structure of the optimal
matching and ultimately lead to the proof of the theorem. We first illustrate these ideas through a
simple example.
    12
    In fact, many of the approximation algorithms for the stochastic matching problem discussed in the Introduction rely
on the greedy algorithm, which here corresponds to assigning tasks to the most skilled workers first.


                                                           7
Example 1. Consider a set of tasks T with measure normalized to unity and let the distribution of
difficulties FdT be U (0, 1). Let W be a set of workers with λ(W) = 2 and the distribution of skills FsW ,
also U (0, 1). Assume that the number of desired groups, k, is equal to 1, then the optimal one-shot
matching assigns all tasks to the group of workers whose skills are in (0.5, 1), i.e. the most skilled
group of workers with measure equal to 1. The output of this matching is equal to 0.75, since any task
with difficulty less than or equal to 0.5 will be finished with probability 1 and a task with difficulty
x > 0.5 will be finished with probability 2(1 − x), leading to a total output of
                                      Z   1
                                1                                    1 1 3
                                  +           2(1 − x)fd T (x)dx =    + = .
                                2     0.5                            2 4 4

Assume now that k = 2, then it can be verified that the optimal grouping is as follows: W1 contains
all workers with skills in (0.25, 0.75) and W2 contains all workers whose skills are in (0.75, 1). The
matching m(W1 ) has θ(m1 ) = 0.5 (since any task with difficulty less than 0.25 is finished with prob-
ability one, any task whose difficulty is over 0.75 is not finished, and any task whose difficulty is
in (0.25, 0.75) is finished with probability 0.5). The leftover tasks from this matching constitute the
group T 0 which has measure 0.5 and difficulty distribution FdT 0 This distribution has two types of
tasks, those that are in (0.5, 0.75) and those that are in (0.75, 1), with each type having an equal mea-
sure of 0.25. Matching m(W2 ) assigns the remaining tasks to W2 and has θ(m2 ) = 0.375, since all tasks
with difficulties less than 0.75 will be finished, and tasks with difficulties in (0.75, 1) will be finished
with probability 0.5. Thus the total output of this matching is equal to θ(m1 ) + θ(m2 ) = 0.875, which
is higher than the one shot matching output of 0.75.

   Example 1 shows the idea behind our approach. The matching with two groups was able to
improve on the matching with a single group because in the latter, some of the skilled workers were
assigned tasks that could have been done by other less skilled workers, resulting in under-utilization
of their skills. The two-group solution filters out some of these task early in the process, so that there
is a smaller chance that the skills of more skilled workers in the second group are wasted on these
easier tasks. In particular, as we proceed through groups, tasks that would be too easy (meaning that
they can be done by less skilled workers) are completed, leaving more difficult tasks to more skilled
workers. It is also worth mentioning that the optimal two group solution does not use any worker
whose skill is less than 0.25. This is because the assignment process of tasks to workers within a
group is random, and so it is possible to decrease a group’s output by adding unskilled labor to a
group. In the example, the size of the first group of workers is equal to the size of the set of tasks,
and so adding less skilled workers to that group can only reduce output. Finally, note also that the
optimal two-group solution is contiguous; once we start the first group at a certain skill, every worker
whose skill is above that skill participates. As we will show, all of these properties hold for all optimal
sequential matchings.
   We now turn our attention to formalizing the above intuition. The following elementary facts will
be useful at several distinct points in our analysis.



                                                         8
Fact 1. (Probability of successful completion) Let FdT and FsW be the distributions of difficulties and
skills in a group of tasks T and a group of workers W , respectively, and consider matching m(W ).
The probability that a randomly-chosen task is successfully completed in m is given by π(m) and can
be written as                                  Z   d2
                                      π(m) =            (1 − FsW (δ))fdT (δ)dδ,
                                                 d1

where [d1 , d2 ] is the domain of difficulties in T and fdT is the density of difficulties.

    The probability of successful completion is simply the probability that a worker in W is matched
with a task in T such that the difficulty of the task is within the worker’s skill. A one-shot matching
m of tasks to workers results in a partition of tasks into three regions, defined as follows.

Fact 2. (Task regions) Consider matching m(W ) and assume for simplicity that λ(W ) = λ(T ). Let
sl = min{si |i ∈ W } and sh = max{si |i ∈ W }. We can then divide T into three regions:

  R1 These are the tasks that can be done by every worker in W . The probability that a task is in R1
      is equal to FdT (sl ), and this region has measure λ(T )FdT (sl ).

  R2 These are the tasks that cannot be completed by any worker in W . The probability that a task is
      in R2 is equal to 1 − FdT (sh ), and this region has measure λ(T )(1 − FdT (sh )).

  R3 These are the tasks that can be done by some, but not all, workers in W , and their difficulties
      lie in (sl , sh ). The probability that a task is in this region is equal to FdT (sh ) − FdT (sl ), and this
      region has measure λ(T )(FdT (sh ) − FdT (sl )).

    For two random variables A and B, we write A  B to indicate that A first-order stochastically
dominates B, i.e. A  B implies that FA (x) ≤ FB (x) for all x, with strict inequality for some x.
    We also define a notion of dominance for worker groups. Recall that the set of workers is arranged
in ascending order of skill.

Definition 3. (Group dominance) A group of workers W1 dominates group W2 if min{si : i ∈ W1 } >
max{sj : j ∈ W2 }. We write this as W1  W2 .

    In order to arrive at the characterization in the beginning of this section, we need to understand
how the output of a matching depends on the composition of workers and tasks that this matching
comprises. Lemmas A.1, A.2, A.3, and Corollary A.1 in the Appendix collect useful results about
the relationship between output and various worker group configurations. These results help us
develop the two central lemmas used in the proof of Theorem 1 and for the analysis of the dynamic
programming formulation in the next section. The first of these relates the pre- and post- matching
difficulty distributions.

Lemma 1. (Stochastic Dominance) Let m(W, T ) be a matching and T c be the set of tasks completed in m. Let
T 0 = T \ T c and assume that T 0 6= ∅, then dT 0  dT .


                                                            9
       Lemma 1 states that the distribution of difficulty in T 0 is skewed more towards difficult tasks than
it is in T , and therefore the chances of selecting a difficult task from T 0 is higher than it is in T . We can
gain an understanding for why that is the case by examining the task regions and how they change
after a matching. Note that the task regions in Fact 2 are arranged in order of difficulty. Tasks in R1
are easier than tasks in R2, which in turn are easier than tasks in R3. As tasks go through a matching,
the sizes of these regions shrink at different rates, with the size of R1 shrinking the most, followed
by R2, and with the size of R3 remaining constant. This means that the tasks that come out on the
other side of the matching have a higher proportion of R3 tasks (as well as the more difficult tasks
in R2) than before the matching, and therefore the overall distribution becomes more difficult. This
remains true regardless of the skills of the workers involved in the matching, with the exception of
the degenerate case where any worker can finish any available task and thus the resulting difficulty
distribution is the same as the distribution before the matching (if λ(T ) > λ(W )) or there are no tasks
remaining (if λ(T ) ≤ λ(W )).
       The second lemma examines what happens when we rearrange workers.13

Lemma 2. (Swapping Lemma) Let W1 and W2 be two arbitrary groups where neither W1  W2 nor W2  W1
                                                     0 ) . There exists a rearrangement of workers in W ∪W
                                                        
and denote by µ the matching m1 (W1 , T ), m(W2 , Tm  1                                                 1  2
                                                                               0
                                                                                   
into two groups W̄1 and W̄2 such that W̄2  W̄1 , µ̄ = m1 (W̄1 , T ), m(W̄2 , Tm1 ) , and θ(µ̄) ≥ θ(µ).

       This Swapping Lemma implies that the output of a matching that is obtained from two groups of
workers of arbitrary composition can be improved upon by swapping some workers between the two
groups to achieve a rearrangement where the workers in the second group all have higher skills than
those in the first. The proof of this result uses several intermediate results that are collected in the Ap-
pendix and are informally summarized in the following discussion. We first show in Lemma A.4 that
for two groups with one group dominating the other, it is always best to arrange these groups in a hi-
erarchical fashion, with the less-skilled group first. The reasoning for this is that since task assignment
is random, when the dominating group comes first, it finishes some tasks that the dominated group
could have finished. And yet this also implies that some of the tasks that would have been completed
by the dominating group but are too difficult for dominated group will remain unfinished. Having
the dominated group attempt tasks first would filter out some of the easier tasks that both can finish,
ensure a better utilization of the skills of the dominating group, and achieve a greater output overall.
       It is important to point out that while the combined output of two groups increases when they
are arranged in a hierarchical fashion, the output of the dominant group can only decrease, since by
Lemma 1, it now faces a more difficult distribution than the one it would have faced if it came first
in the ordering. The output of the dominant group is in fact lower when the skills in the dominated
group are higher. This is because more tasks that the dominant group can finish are completed before
they reach that group. This fact is formalized in Lemma A.5 and will play a particularly important role
in the implementation problem because workers always prefer to be in an earlier group regardless of
their skills, as these groups face easier difficulty distributions, and part of the implementation solution
  13
       Related results are present and play a similar role in the literature on knowledge hierarchies, e.g., in Garicano (2000).


                                                                10
is to adjust the workers’ incentives in order to re-align their goals with those of the employer.
      The next step in the proof of Lemma 2 is to show that any improvement over a hierarchical ar-
rangement has to maintain a hierarchical structure. This is shown in Lemma A.6. We then use this
result to show, by means of a contradiction argument, that the optimal arrangement has to be hi-
erarchical. The argument is that workers in a non-hierarchical matching can be rearranged into a
hierarchy, and we then use Lemma A.6 to show that any improvement over this hierarchical match-
ing must lead to a hierarchy, and not to the original non-hierarchical configuration, and therefore the
initial configuration cannot be optimal.


3.1     Dynamic Programming Formulation

Our analysis of the structure of the optimal matching relies on a dynamic programming formulation
for the problem. The state and action space, along with the transition function, can be given as:

      • State The state at stage κ is written as (Wκ , Tκ ), where Wκ is the set of remaining workers and
        Tκ are the tasks remaining at the beginning of κ.

      • Action At stage κ, the decision or action is what group Wκ ⊆ Wκ to assign tasks to.

      • Transition The transition function is derived from the outcome of matching mκ (Wκ , Tκ ). The
        new state is given by (Wκ+1 , Tκ+1 ), where Wκ+1 = Wκ \ Wκ and Tκ+1 = Tκ \ Tκc .

      Recall that the number of stages (or equivalently, groups), k, is an input to the problem. The value
function at stage κ satisfies
                                                      
                                Vκ = max θ m(Wκ , Tκ ) + Vκ+1 (Wκ+1 , Tκ+1 )
                                     Wκ ⊆Wκ


with Vk+1 = 0. Let us examine the solution to the formulation above when k = 1. In this case, the
problem is equivalent to searching for the best possible one-shot matching under the informational
constraints of the problem. Not surprisingly, in that scenario the employer chooses the top measure of
workers to participate in the matching. How would the optimal grouping change for the case k = 2?
      Before answering this question, it would be useful to point out that having more groups is not
always better. We will have more to say about this in the next section, but the intuition for two groups
is the following: as the proportion of difficult tasks increases, it becomes more likely that a worker will
pick a task that he cannot finish. In a one-shot setting, a difficult task may lead to wasting the efforts
of at most one worker, but as more groups are introduced, this task has the potential to repeatedly
’defeat’ other workers as well, as it gets carried through from one group to the next. These workers
could have been better utilized in performing other tasks, which is what would happen in a one-
shot setting. Thus breaking up a group may lead to an overall decrease in output. The next section
discusses when having more groups is profitable, and assuming that to be the case, the solution to
k = 2 follows directly from the Swapping Lemma, giving the following proposition, which we then
use as the basis for our inductive proof of Theorem 1.

                                                     11
Proposition 1. There exists an optimal hierarchical matching for k = 2.

      Using the results of this section and with induction on the number of groups, we arrive at a proof
of Theorem 1. Lemma 1 establishes that later groups (groups with higher indices) face more difficult
tasks regardless of the composition of earlier groups. Therefore, by Lemma A.1, workers with lower
skills would struggle if they are placed in latter groups but have a better chance at completing tasks
if they are in earlier ones. As an extreme example, consider the first group W1 and let it contain a
unit measure of the most skilled workers available, then any other group that follows W1 has to have
output equal to zero, since the workers in these groups have to tackle tasks at which more skilled
workers have failed. Conversely, by placing less skilled workers in earlier groups, the (easy) tasks
that they finish will not get in the way of more skilled workers later on. Instead, these workers will be
assigned a bigger share of tasks that are commensurate with their skills, leading to an overall increase
in output.
      The optimal matching, which as already noted is a hierarchy, satisfies the following properties.

  a) Necessary condition for optimality: at the beginning of round i < k, the number of workers left
        should be strictly higher than the measure of remaining tasks. At i = k, the measure of leftover
        tasks should be at least equal to the measure of workers remaining.

  b) The optimal groups are contiguous. Let s1 < s2 . If workers with skills less than s1 are assigned
        tasks and workers with skills higher than s2 are assigned tasks, then workers in (s1 , s2 ) should
        also be assigned tasks.

  c) Depending on the desired number of groups, the optimal solution may include a threshold for
        skill s̄ below which no worker is chosen to participate (in Example 1, s̄ = 0.25).


3.2     Examples and Comparative Statics

Beside incentive issues, which we discuss in Section 4, the solution to the dynamic programming for-
mulation further highlights the differences between our model and the existing work on assignment
of heterogeneous workers to tasks in the models of knowledge hierarchies. In particular, the works
by Garicano and Beggs, which were discussed in the Introduction, predict that the optimal hierarchy
always has a pyramidal structure, with successive layers getting smaller and smaller in size. More-
over, it is possible that the optimal hierarchy has an infinite number of levels. Both of these are not
true in our model of crowd innovation. First, successive groups can fluctuate in size, implying that
the optimal hierarchy may not look like a pyramid. Second, not only is the optimal number of lev-
els in our hierarchy always finite, but a hierarchy with more layers may even lead to a strictly lower
output. Third, the optimal hierarchies in our model can display some counter-intuitive behavior. For
example, by increasing the difficulties in the task pool, the optimal number of levels in the hierarchy
can go down, instead of up.
      Some of these differences are a consequence of the fact that Garicano’s framework considers an
“infinite pool of tasks” which need to be produced or processed by workers at the bottom layer of

                                                     12
the hierarchy, who can then ask for help from others if they are unable to perform these tasks. As
a result, the optimal allocation organizes workers into one (bottom) layer of producers and multiple
layers of problem solvers. Each worker in the bottom “producer” layer “generates” a task, and only
sends this task up to the problem solvers if they cannot complete it themselves. Consequently, tasks
at each level of the hierarchy are those that were not solved at the previous level, naturally implying
a pyramid-like structure. The presence of the fixed set of tasks that can be tackled by any worker at
any stage implies that optimal matching may not look like a pyramid. Additionally, the assumption
that skill acquisition is endogenous in the baseline knowledge hierarchy models ensures that there is
no mismatch between task difficulties and worker skills. In contrast, such mismatch is at the heart of
our model and is the reason why more layers can lead to strictly lower output — because they expose
more workers to tasks that they may be unlikely to complete, thus precluding them from using their
skills for other tasks.
   We now present a series of examples to illustrate the main ideas. To communicate these in the
clearest possible fashion, we focus on a series of examples where both tasks and workers come
with three levels of difficulties or skills, Low, Medium, and Hard. We use the notation of, say,
{ 41 L, 34 M, 41 H} to denote that a quarter measure of tasks/workers are of Low type, three quarter mea-
sures of Medium type, and a quarter measure of High type. All examples follow our assumptions
about λ( T ) = 1 and λ(W) > λ( T ). We start with two examples. The first illustrates a case when the
solution follows the standard pyramidal hierarchy, and the second has a solution where the hierarchy
is a reverse-pyramid.

Example 2. (Pyramidal Hierarchy) Consider T = { 14 L, 12 M, 14 H} and W = { 14 L, 43 M, 14 H}. The
optimal hierarchy for k = 2 has W1 = { 41 L, 34 M }, and W2 =     1
                                                                  4 H.   It can be verified that under this
               7
arrangement    8   of the tasks are completed successfully. Furthermore, the second group of workers is
of size smaller than the previous one, giving the familiar pyramidal structure.

Example 3. (Non-pyramidal Hierarchy) Consider the same setting as Example 2 but with a distribu-
tion of workers that shifts the mass from high-skilled to low-skilled workers, so that W = { 12 L, 34 M }.
The optimal hierarchy for k = 2 now has W1 = { 12 L} and W2 = { 34 M }, with ∼ 0.66 of the tasks
finished. Notice that the first group is smaller than the second and a pyramidal structure is no longer
maintained.

   Observe how we go from a pyramidal to a non-pyramidal structure in the examples above, even
though the differences between the two examples are minimal. To understand what gives rise to this
difference, note that the hierarchical matching process always attempts to balance two effects: (a) by
putting skilled workers in early groups, part of their output is wasted on easy tasks, and (b) by putting
workers in later groups, their output can be compromised by receiving tasks that they are unequipped
to deal with (cf. Lemma 1). In Example 2, the distributions of difficulties and skills were such that
it was best to protect the high-skilled workers from as many low- and medium-difficulty tasks as
possible, even if this meant compromising some of the medium-skilled workers to low-difficulty
tasks, and hence the low- and medium-skilled workers participated in the first group. In Example

                                                    13
3, it was best to protect the medium-skilled workers from as many low-skilled tasks as possible, and
this gave rise to the configuration in the example.
   It is tempting to extrapolate these examples in a natural way in order to arrive at an optimal policy
for how groups are divided, but this process is more subtle than it first appears. The next example
illustrates this and provides an entry point to our discussion of the optimal number of groups.

Example 4. Consider Example 2 but assume now that we want to find the optimal assignment for the
case k = 3. It seems plausible to have three groups as follows: W1 = { 14 L}, W2 = { 34 M }, W3 = { 14 H}.
The idea, based on the immediately preceding discussion, is that by keeping each of these skills in its
separate group, then we can achieve maximum utilization for each skill level. This turns out to not
be the case, and in fact, the optimal grouping is still exactly the same as in Example 2. In particular,
even though we can use one more group, by doing so we actually obtain a worse outcome than if we
had stuck with the k = 2 groups solution.

   Example 4 can be generalized to give the following result.

Proposition 2. Let µi be the optimal hierarchical matching that uses i groups and let µj be a hierarchical
matching that uses the exact same set of workers as µi but divides them into j > i groups, then θ(µi ) > θ(µj ).

   This result is in contrast to Garicano’s work, where it is possible that more layers always increase
output and the optimal number of layers can be infinite. Here, without any costs of communication,
more layers can strictly reduce output. In fact, one cannot benefit from adding an extra layer of
workers to an optimal solution of k groups unless more workers are introduced, i.e., more groups
require more entry. This immediately implies that for a fixed-size population of workers the number
of layers in an optimal solution is always bounded. The condition that having more groups requires
more entry is necessary but not sufficient: the additional (and less-skilled) workers should possess
skills that will allow them to reduce the load on more skilled workers later on. The result above is a
consequence of Lemma 1 and the fact that tasks cannot be differentiated based on their difficulties.
   Following this line of reasoning, we can investigate the optimal number of groups given the sup-
ply of workers, where optimal number means the minimum number of groups above which there is no
increase in output. In general, it is not easy to analytically characterize the optimal number of groups,
though a straightforward computational approach to answering this question would utilize Proposi-
tion 2 to figure out the optimal solutions to k = 1, k = 2, ..., with output monotonically increasing in
k until it drops or stays constant for the case k = k ∗ + 1, indicating that k ∗ is the optimal number of
groups in the hierarchy.
   The next example shows that the effect of increasing the difficulty of the task distribution on the
optimal number of groups is ambiguous. Again, this contrasts with existing models where higher
difficulties in the task pool call for more groups.

Example 5. Let T = {1L} and W = { 34 L, 21 M }. Obviously, any group W ⊂ W with λ(W ) = 1 will
finish all the tasks, and k = 1 is optimal. Now increase the difficulty in T so that T = { 34 L, 14 M },
then output for the case k = 1 is strictly less than 1, and can be improved on by k = 2 and setting

                                                      14
W1 = { 23 L, 13 M }, W2 = { 61 M }, which is a configuration that again finishes all the available tasks.
Now make the tasks in T even more difficult by letting T = {L, 14 M, (1 −              1
                                                                                        4   − )H}, where  is the
amount of low-difficulty tasks in the task pool. For 0 <  <≈ 0.245, the optimal k is again equal to
1, i.e., the optimal number of groups decreases even though the difficulties in the task pool increases,
and the optimal group is given by { 12 L, 12 M }. However, for 0.245 <  < 34 , the optimal k goes back to
2, with the optimal groups being W1 = { 34 L} and W2 = { 12 M }.

    In addition to establishing that as tasks become more difficult, the optimal number of groups
need not increase, and can in fact decrease, the previous example provides an important insight into
the workings of the assignment process. In particular, how the number of groups is governed by a
threshold on the ratio between the low-difficulty and high-difficulty tasks in the task pool. When
there were not that many low-difficulty tasks, it was not beneficial to separate the low and medium-
skilled workers into two groups, because only a small proportion of the medium-skilled workers were
exposed to the easy tasks. When low-difficulty tasks had more substantial presence in the task pool,
separation of low- and medium- skilled workers is beneficial because more medium-skilled workers
get more medium-difficulty tasks ands therefore are more appropriately utilized.


4    The Implementation Problem
We return to our full model where worker skills are private information and workers themselves
decide whether and when to participate. We will show that with a simple pricing mechanism, the
employer can nevertheless achieve the first-best allocation characterized in the previous section.
    In order to implement the first-best allocation from the assignment problem, we utilize a mech-
anism that charges a participation or entry fee q for workers and a tiered payment system for tasks.
A task finished in group i, i = 1, ..., k pays an amount pi , with pi > pj for i > j. Fix a configuration
of groups and let the probability that a worker with skill s finishes a task when he is a member of
group Wi be given by ψ(s, Wi ). The expected payment that this worker receives is equal to pi ψ(s, Wi ).
Groups are in equilibrium when no worker wants to change the group he is in. Denote by group W0
those workers who do not participate, then a formal definition for an equilibrium is the following

Definition 4. (Group Equilibrium) Groups W1 , ..., Wk are in equilibrium if for any skill s, a worker
with skill s in Wi , i = 1, ..., k receives expected payment pi ψ(s, Wi ) ≥ pj ψ(s, Wj ) for all j 6= i.

    Thus for a worker to voluntarily choose to belong to group Wi , we must have pi ψ(s, Wi ) ≥
pj ψ(s, Wj ) for all j 6= i. Lemma A.8 shows that the probability of finishing a task is non-increasing in
the index of a group.
    The following lemma is critical to the implementation of the optimal assignment.
                                                       ψ(s,Wi )
Lemma 3. (Comparative Advantage) Define φ(s) =         ψ(s,Wj )   for j > i. Then φ(s) is decreasing in s.

    Comparative advantage follows from the monotone relationship between skills and difficulties,
where a worker with higher skill can finish any task that a worker with lower skill can. Lemma

                                                       15
3 states that more skilled workers perform relatively better on more difficult tasks than less skilled
workers do. In the context of our model, this means that for two workers in group i with skills s1 and
s2 and with s1 < s2 , the drop in probability of success for the worker with skill s1 upon moving to a
higher group will be larger compared to the drop for the worker with skill s2 if he makes the same
move.
       We now give the main result of this section.

Theorem 2. Let W1∗ , ..., Wk∗ be an optimal k-level hierarchical assignment. There exists a participation fee q
and payments p1 < p2 < ...pk−1 < pk that induce an equilibrium in which a worker chooses to be in group
Wi∗ if and only if he is selected for that group in the optimal allocation.

       Let si = {min s|s ∈ Wi }. The proof of Theorem 2 shows that the values for the entry fee q and
payments p1 , ...pk can be obtained by solving the following simple system of equations.

                               p1 ψ(s1 , W1 ) = q
                              pi ψ(si+1 , Wi ) = pi+1 ψ(si+1 , Wi+1 ) i = 1, 2., , , k − 1



       The first equation above indicates that the least skilled worker who participates only breaks even
in expectation. Because ψ(s, W1 ) is monotonically increasing in s, any worker whose skill is less than
s1 will have negative expected payoff and therefore will not participate. Similarly, by recalling that
groups are contiguous, the second equation gives a condition that makes workers at the boundary
between successive groups indifferent. Again, from the monotonicity of ψ(s, Wi ) (increasing in s and
                                                                                                                     ψ(si+1 ,Wi )
decreasing in i), we find that an increase in payment pi+1 over payment pi by a factor                              ψ(si+1 ,Wi+1 )
will provide less payoffs to a worker with skill less than s who decides to move to group i + 1, and a
worker whose skill is higher than s and decides to move to group i. This is because, upon a move to
a group with higher index, the drop in probability of successful completion for a less skilled worker
is not sufficiently compensated by the increase in payment, and the opposite is true for a more skilled
worker who contemplates moving in the opposite direction.14

Example 6. We revisit Example 1 to show how the optimal two group assignment can be imple-
mented. We want to find q, p1 , and p2 that will provide the correct incentives to workers to participate
in the groups they were allocated to in that example. Let us denote by the dummy group W0 the
  14
     It is also useful to note that Theorem 2 shows that the first-best characterized in the previous section can be decentralized
as an equilibrium. It does not establish that this is the unique equilibrium. Multiplicity can arise for the following reason: if
the most skilled workers were all to select to participate in one of the earlier groups, say the first group, then the set of tasks
that remain uncompleted after the first round may become more difficult than in the optimal matching because instead of
the lowest skill active workers, now some of the highest skill workers are failing to complete these tasks. Given this, other
high skill workers may no longer find it optimal to wait for later matchings at the prices determined in Theorem 2.
   This sort of multiplicity is unlikely to be endemic because if the most skilled workers want to be in the first group, then
all workers want to be in the first group, and the excess supply of workers in the first group will reduce the return to each
significantly. This also suggests one way of dealing with this problem: if there is sufficient excess supply of workers at a
certain stage of matching, then reduce the set of tasks assigned at that stage until the expected return to any worker is very
low.


                                                                16
group of workers who choose not to participate. Recall that the optimal groups were (in terms of
skill) W0 = (0, 0.25), W1 = (0.25, 0.75), and W2 = (0.75, 1). By setting q = 0.25, p1 = 1, and p2 = 1.5,
we obtain the desired hierarchy. To see this, let us examine a deviation of a worker of skill s in W0 .
This worker makes 0 in that group, and by deviating to join group W1 , he obtains an expected utility
of p1 ψ(s, W1 ) − q. For this example, ψ(s, W1 ) = s, and so the expected payoff from deviation is equal
to 1s − 0.25, which is less than zero for s < 0.25. Similarly, a worker of skill s in W1 makes an expected
profit of 1s − 0.25, which is higher than 0 but also higher than what he would make had he decided
to join W2 instead. In that case he will be making p2 ψ(s, W2 ) − q = 1.5(s − 0.25) − 0.25, which is less
                                                                                                      1       s−0.75
than 1s − 0.25 for s ∈ (0.25, 0.75). Finally, a worker of skill s in W2 has ψ(s, W2 ) =               2   +     0.5    for an
expected payoff of     1.5( 12   +   s−0.75
                                       0.5 )   − 0.25. This is higher than what a worker whose skill is in (0.75, 1)
stands to gain by moving to W1 .

      In summary, a simple mechanism that implements the optimal assignment announces the entry
fee q and the prices pi for each group. A worker chooses either not to participate at all or to participate
in exactly one of the groups. A worker participating in group i is not allowed to participate in group
j > i.15


5     Extensions
We now present five extensions that explore the role of various assumptions in our analysis so far.
The first extension highlights the fact that our main result on replicating the optimal assignment of
tasks to workers through market matching in crowd innovation depends on the exact information
available to firms, and in particular, on information about what unsuccessful workers have worked
on. If firms can monitor this, then the optimal hierarchy cannot be achieved with a simple pricing
mechanism like the one we have utilized so far (though more complicated pricing and information-
sharing mechanisms can achieve it). Second, we introduce a type of task, which we refer to as an
“unstructured task,” that adds some murkiness to the notion of what a skilled worker is. Performing
these tasks might require skill, luck, or a combination of both, and so with some probability, these po-
tentially valuable tasks can be performed by less skilled workers. We then show that in the presence
of such tasks the optimal structure of the organization need not be a hierarchy any more. This high-
lights the role of the monotone relationship between worker skills and tasks difficulties in our results.
Finally, we discuss a couple of extensions that we left out from our analysis but whose inclusion has
no effect on our main results.


5.1    Semi-Observable Skills

The analysis so far has focused on the case where the employer cannot assign specific tasks to specific
workers (cf. Section 2.2). We now discuss what happens when this is not the case, and compare this
  15
     The solution also makes it clear why such a worker would in fact never wish to participate for later groups given the
optimal pricing scheme.


                                                              17
scenario with our earlier results. We refer to this setting as one with “semi-observable skills”— the
employer cannot ex ante observe worker skills but after assignment can verify what the skill level of
the worker was. The fact that the employer can observe the workers’ skills after they fail to complete a
task provides extra information about unfinished tasks relative to the case in which the employer only
knows the scent of workers who may have attempted the task. This extra information can only help in
the (re)assignment process. Nevertheless, the hierarchical structure of the solution is still maintained
because its main driver — attempting to best-utilize low-skilled workers and protect skilled labor
from easy tasks — is still in effect. In particular, Lemma 1, which states that the difficulty distribution
does not become easier still applies, and the previous reasoning can be used to show that it is still
optimal to assign tasks to less-skilled workers first. The possibility that the optimal hierarchy takes a
non-pyramidal shape still exists, as evidenced by Example 3, which is unaffected by this change.
      A halfway case between unobservable and semi-observable tasks is when the employer can parti-
tion the set of tasks and workers at a certain stage into subgroups and ensure that matching is within
subgroups. This is still gives additional information relative to our benchmark but less information
than the semi-observable case where the employer knows the exact skill of the worker who failed
to complete a task. (The difficulty is in ensuring that matching is within subgroups, something that
employers may not be able to achieve in a virtual marketplace). In this setting, the semi-observable
case can be approximated by breaking down a group into several smaller groups and keeping track
of which tasks were not completed by which group. Revisiting Example 1 clarifies both how this
approximation might work and why semi-observable skills improve output.

Example 7. Consider Example 1 and break group W1 into two groups, W1a and W1b , such that W1a
has workers whose skills are in (0.25, 0.5) and W1b has workers whose skills are in (0.5, 0.75). Break
W2 into two groups W2a with skills in (0.75, 0.90625) and W2b with skills in (0.90625, 1). Let the
                                                      0 , then the breakdown of tasks in T 0 is as
tasks remaining after matching m(W1i ) be denoted by T1i                                  1a
follows:   1
                tasks are in (0.25, 0.5),   1
                                                tasks are in (0.5, 0.75), and   1                                     0
                                                                                    tasks are in (0.75, 1). Tasks in T1b
           16                               8                                   8
are as follows:     1
                         tasks are in (0.5, 0.75) and     1                                              0 and
                                                              tasks are in (0.75, 1). Now let m(W2a ) = T1a
                    16                                    8
           0 (note that all of these sets have the same measure). The total output of these four
m(W2b ) = T1b
groups is ≈ 0.92, improving on the output in Example 1 while using the same set of workers.

      The reason we were able to improve output in the previous example is the newfound ability to
have more targeted matchings, which is facilitated by access to more information about unfinished
                                               0 that had an easier distribution to the less skilled
tasks. Here, we were able to assign the tasks T1a
workers in W2 (those workers in W2a ). As the granularity of these groups become finer, we approach
the case of semi-observable tasks. This breakdown of groups is still implementable using similar
ascending pricing schemes like the one we introduced in Section 4.


5.2    Unstructured Tasks

Our results follow from the type of tasks we have considered. The completion of these tasks requires
a certain set of skills, and we assume that these skills are cumulative, i.e., a worker whose skill allows

                                                              18
him to complete task 1 is also able to complete task 2 if d1 > d2 . We can thus think of these as
“structured tasks”. Suppose now that in addition to these tasks there is another type of task whose
completion is independent of a worker’s skill. Some of the early success stories in crowd innovation
have an element where a task that has eluded experts was completed by random workers through
chance or educated guess work. Often, these tasks are characterized by the fact that the actual skill set
required to finish them is not well-understood. We designate these tasks as unstructured, and model
them as a kind of task that can be finished by any worker with some small probability. If we now
consider a task pool that contains both structured and unstructured tasks, then there are two possible
scenarios: (a) either the type of task is an observable attribute, so that we can determine the type of the
task by simply examining it, or (b) we cannot distinguish between the two types. The solution to the
first scenario is obvious, and simply involves separating the tasks into two separate pools, structured
and unstructured, and solving two different problems in parallel. The structured tasks are dealt with
in a hierarchical fashion, and the unstructured tasks are simply given to low-skilled workers who
were not selected for the hierarchical match. The second scenario is more challenging, and does in
fact break the result that the optimal arrangement for maximizing task completion is a hierarchy, as
the following example illustrates.

Example 8. Consider T = { 31 M, 31 H, 31 U }, where U denotes unstructured tasks. Let W = { 13 L, 1M, 13 H}
be a set of workers and let the probability of completing an unstructured task be strictly less than one.
Assume that k = 2 and that it is not possible to observe whether a task in unstructured or not, then it
is optimal to set W1 = {1M } and W2 = { 31 L, 31 H}. The reason is that the productivity of L workers
on unstructured tasks is affected by them having to deal with the M tasks in the task pool, as some of
the L workers will be lost to some M tasks that they cannot finish, and hence their output on U tasks
decreases. Putting the M workers upfront ensures that all M tasks are removed from the task pool,
and therefore these tasks would not constitute an undue burden on either L or H workers.

      Of course, with the allowance of a larger number of groups and a larger supply of L workers,
the optimal assignment in the example above may resort back to being a hierarchy. Thus, whether
a solution is a hierarchy or not in the unobservable case is a function of several factors: the number
of groups, the supply and type of workers, and the distribution of tasks and task types in the task
pool. This is in contrast to any of the previous variations, where it was always optimal to have a
hierarchical assignment regardless of these factors.


5.3    Task Reassignment

As mentioned in the discussion preceding Definition 1, a key assumption of our analysis has been
that a worker can pick up and work on only one task, regardless of whether he or she was able to
finish that task or not. When it comes to innovation tasks, it is not difficult to imagine settings where
the time until a worker finishes a task is fairly long, making it reasonable that this worker can work on
at most a single task during the process. However, workers who were unable to complete their tasks
might be given another task to work on, a possibility we have not considered in our analysis, but one

                                                    19
that does not alter the hierarchical nature of the solution. This is a simple consequence of the fact that
the new task that will be assigned to that worker will not be a task that was not finished by someone
whose skill is higher than the worker in question, but rather a task that was unsuccessfully attempted
by someone with lesser skill, and hence the bottom-up approach to task assignment is preserved.


5.4     Discounting

Discounting, where tasks that are finished later in the process count for less than those finished ear-
lier, has no effect on any of our results. Depending on the discount factor, either a hierarchy is still an
optimal solution, or the solution is simply a single group that comprises the most skilled workers. To
see this, consider the case k = 2 and assume that under certain discounting the optimal assignment
has two groups of workers w0 and w00 , both in W1 and a group w ∈ W2 such that w0  w and w  w00 ,
i.e. the assignment is not a hierarchy. Recall that the reason a hierarchy emerges as an optimal assign-
ment is that later groups, instead of working on easy tasks, are more focused on working on tasks
that are commensurate with their skills. But if the earlier group in an optimal solution contains some
workers who are more skilled than those in the second group, then this indicates that discounting is
high enough that it is not worth the improvement we get from placing those high-skilled workers in
the second group, and in that case workers who are even less skilled are better utilized by including
them in the first group as well (potentially displacing some even less-skilled workers in that group),
especially since some of the tasks that they are meant to finish will be finished by the more skilled
group in W1 anyway.


5.5     Probabilistic Completion of Tasks

The model we presented assumes that a worker finishes a task if their skill is at least equal to the
difficulty of the task. A more reasonable assumption might be that workers do not always finish tasks
that are below their skills with certainty, but rather, that more skilled workers have a higher chance of
finishing a task compared to their less-skilled peers. This means that for workers i and j with si > sj
and a task t, we have P r(i finishes t) > P r(j finishes t) for all t with dt ≤ sj < si . This change does
not affect Lemmas 1 and 2, and our results carry through in that modified setting as well.


6     Conclusion
Crowd innovation involves the sourcing of innovation to a broad set of workers of unknown skills
using a virtual marketplace. In these large and anonymous virtual markets, employers cannot assign
workers specific tasks and do not know the workers’ specific skills. In addition, the nature of the
tasks to be performed often preclude specific information about how difficult the given task is and
what type of workers will be able to complete them.
      Our main conceptual contribution in this paper is that, these informational and coordination dif-
ficulties not withstanding, crowd innovation can be organized as if it was taking place within an


                                                    20
organization, but with some constraints resulting from the market allocation. In particular, the opti-
mal assignment involves a sequential matching in which workers are sorted into different groups of
increasing skill level, and are successively assigned to tasks with endogenously increasing difficul-
ties (endogenously because the remaining tasks assigned to later groups are those that earlier groups
were unable to complete). This application can be supported by a simple pricing mechanism in which
prices — rewards —for tasks increase the longer these tasks remain uncompleted.
   This optimal assignment is notable because of its ability to economize on the scarce factor in this
marketplace — the time of skilled workers. The effort to economize on these skills is reflected in
a range of interesting, and perhaps surprising, results of our framework. First, though the optimal
matching is hierarchical, this hierarchy may not look like a pyramid — which contrasts with exist-
ing results in organizational economics and on related assignment problems. This happens because
sometimes pyramids waste the skills of middle-skill workers as they expose them excessively to dif-
ficult tasks which they fail to perform. Second, for similar reasons, increasing the number of layers of
the hierarchy may not be beneficial — it may even lead to lower output. This is because more layers
will increase the number of workers that are exposed to the most difficult tasks which will waste the
skills of many types of workers. However, too few levels of hierarchy is also not optimal, because
these will waste the skills of the most skilled workers on easy tasks.
   There are several other tools that can be used in practice for ensuring an efficient allocation of
scarce resources. The first is an explicit tournament, where workers are rewarded for completing
tasks before others. This has not been a problem in our formulation because there is no moral hazard
or effort decision — in our framework, a worker can either complete or not complete a given task re-
gardless of effort or other choices she makes, and thus it is always better to sequentially assign work-
ers to tasks and not waste the time of a worker on a task that will already be successfully completed
by another worker. Enriching our framework with an additional effort decision is an interesting area
for theoretical research.
   Second, in practice, the asymmetry of information between employers and potential workers can
be ameliorated if workers are able to build a reputation. Such reputation building may even be pos-
sible in online markets as shown by the creative recent work of Pallais (2013). Nevertheless, at this
point crowd innovation platforms lack both a decent reputation tracking system and any meaningful
way to enforce liabilities. Moreover, recent experimental work by Dulleck et al. (2011) suggests that
workers have no incentive to build reputations as long as they can avoid liabilities, which further
complicates the efforts to build platforms that leverage reputation to improve the assignment of het-
erogeneous workers to tasks. A dynamic analysis of these issues and work on the design of better
platforms are other important areas for research.
   Finally, it is important to note that this area would benefit from more detailed empirical evidence
on how workers make their decisions of what types of tasks to work on and how firms design incen-
tives for crowdsourcing and innovation. Using experimental methods and different treatments for
workers on various online platforms is a possible way of tackling these questions and constitutes yet
another area for interesting future research.


                                                    21
Appendix

A     Proofs
This section starts by presenting a few straightforward lemmas that are used as building blocks for
the main results. Throughout, we will refer in different ways to the output of a sequential match
θ(µ) depending on context. Sometimes using the shorthand θ(W1 , W2 , ...) to indicate a sequential
matching that first assigns tasks uniformly at random to group W1 then to group W2 , etc. Also, recall
that even though a matching m randomly assigns tasks from the pool of available tasks to workers,
we will assign different subscripts when we refer to matchings in order to distinguish between them
based on the worker and tasks groups they comprise. This makes it easier to refer to matching mi and
mj instead of m(Wi , T ), m(Wj , T ), m(W, Tk ), and so on.
Lemma A.1. Let W be a group of workers, and consider matchings m1 (W, T1 ) and m2 (W, T2 ), where
T1 and T2 are two task pools with λ(T1 ) = λ(T2 ) and dT1  dT2 , then θ(m1 ) ≤ θ(m2 ).
Proof: Let fW (s) be the density function for skills in W , with support over [s1 , s2 ], and write the
outputs of m1 and m2 as
                                                             Z   s2
                                    θ(m1 ) = π(m1 )λ(W ) =            FdT1 (s)fW (s)ds                       (2)
                                                             Zs1s2
                                    θ(m2 ) = π(m2 )λ(W ) =            FdT2 (s)fW (s)ds                       (3)
                                                              s1

Since dT1  dT2 implies FdT1 (s) ≤ FdT2 (s) for all s and FdT1 (s) < FdT2 (s) for some s, we have (1) ≤ (2)
and hence θ(m1 ) ≤ θ(m2 ).
    Lemma A.1 states that the output of the same group of workers cannot improve when tasks be-
come more difficult. The next lemma complements this observation by showing that a group’s output
on the same tasks can only increase if some workers in the group are replaced by an equal number of
more skilled workers.
Lemma A.2. Consider matchings m1 (W, T ) and m2 (W 0 , T ), where W 0 = (W \ w) ∪ w0 , w ⊂ W and
w0 ∩ W = ∅, w0  w, and λ(w) = λ(w0 ), then θ(m) ≤ θ(m0 ).
Proof: Denote by S the set of skills in W ∪ w0 . Because w0  w, there is a set D such that FsW (dT ) =
FsW 0 (dT ) for dT ∈ D and FsW (dT ) > FsW 0 (dT ) for dT ∈ D̄, where D∩ D̄ = ∅ and D∪ D̄ = S. By writing
                                                                     Rd
down the expressions for π(m1 ) and π(m2 ), we get π(m1 ) = d12 (1 − FsW (δ))fdT (δ)dδ and π(m2 ) =
R d2
 d1 (1 − FsW 0 (δ))fdT (δ)dδ, where (d1 , d2 ) is the domain of difficulties in T . It is straightforward to see
that, for any δ ∈ (d1 , d2 )

                                                  FsW (δ) ≥ FsW 0 (δ)
                          Z    d2                            Z d2
                                    (1 − FsW (δ))fdT (δ)dδ ≤      (1 − Fs0W (δ))fdT (δ)dδ
                           d1                                         d1
                                                   π(m1 ) ≤ π(m2 )

                                                           22
Since θ(m1 ) = π(m1 )λ(W ) and θ(m2 ) = π(m2 )λ(W 0 ) and λ(W ) = λ(W 0 ), the result follows.


Lemma A.3. Consider matchings m(W, T ), m0 (W 0 , T ), and m00 (W, T 0 ). Let w and t be a group of
workers and a group of tasks such that W ∩ w = ∅, W 0 = W ∪ w, t ⊂ T , and T 0 = T \ t, then

  a. If λ(T ) = λ(W ) and w is such that maxi∈w si < minj∈W sj , then θ(m) ≥ θ(m0 ).

  b. If λ(T ) > λ(W ) and w is such that λ(w) = λ(T ) − λ(W ), then θ(m) ≤ θ(m0 ).

   c. If λ(T ) ≤ λ(W ), then θ(m00 ) = θ(m) − θ(m(W, t)).

Proof: For part a, note that W  w implies sW  sW 0 , i.e. FsW ≤ FsW 0 , and hence by the same
arguments of Lemma A.2 we have π(m) ≥ π(m0 ) → θ(m) ≥ θ(m0 ). For part b, let T̄ ⊂ T be the
set of tasks assigned to W in m, then by the assumption that matchings are uniformly random, the
exact same set of tasks will be assigned to W ⊂ W 0 in m0 , making θ(m0 ) ≥ θ(m). The same argument
applies to part c with the bigger set being W instead of T .
   Lemma A.3a states that if the number of workers in a group is equal to the number of tasks given
to that group, then there is no reason to add any more workers whose skills are less than the skills
of everyone else in the group. The reason is that this will cause a redistribution of tasks in a way
that results in some tasks going to less-skilled workers instead of the workers they were originally
assigned to, while the remaining tasks have their original assignment, and hence the output can only
go down. A simple corollary of this claim is that no optimal assignment will assign a group of tasks
to a group of workers such that the number of workers is more than the number of tasks.

Corollary A.1. In an optimal solution, no tasks T are assigned to a group W such that λ(W ) > λ(T ).

   In contrast to Lemma A.3a, Lemma A.3b says that extending the size of a group of workers to
make it equal to the number of assigned tasks in a matching cannot reduce output. This is because
adding more workers in this scenario does not affect the distribution of tasks in the original smaller-
sized group. Instead, the effect is that tasks that were not originally assigned due to a mismatch in
group size will now have extra workers to attempt them.
   Finally, Lemma A.3c states that when the number of workers is at least equal to the number of
tasks, removing some tasks from a matching does not affect the output of the group of workers on
the remaining tasks.


Proof of Lemma 1: Assume for simplicity that λ(W ) = λ(T ). We can divide T into three regions as
in Fact 2. Let γi be the probability that a worker in W finishes a task in region i, so that γ1 = 1 and
γ2 = 0. From Fact 1, γ3 is given by
                                             Z   sh
                                      γ3 =            (1 − FsW (δ))fdT (δ)dδ
                                             sl


   The set T 0 = T \ T c has two regions:

                                                          23
    - Region A: This is the same as R2 in Definition 2, with measure λ(T )(1 − FdT (sh )).

    - Region B: This contains the uncompleted tasks from R3, and has measure (1−γ3 )λ(T )(FdT (sh )−
        FdT (sl )).

This implies that the relative measure of tasks in R2 has increased. Tasks with difficulties over sh had
a proportion of 1 − FdT (sh ) in T , but in T 0 , the same tasks now have a proportion

                   λ(T )(1 − FdT (sh ))                                                    1 − FdT (sh )
                                                                        =
λ(T )(1 − FdT (sh )) + (1 − γ3 )λ(T )(FdT (sh ) − FdT (sl ))              1 − FdT (sh ) + (1 − γ3 )(FdT (sh ) − FdT (sl ))
                                                                                        1 − FdT (sh )
                                                                        =
                                                                          1 − FdT (sl ) − γ3 (FdT (sh ) − FdT (sl ))
                                                                        > 1 − FdT (sh )

To understand the distribution of the tasks in Region B, note that the probability 1−FsW (δ) of finishing
a task in R3 is decreasing in δ. Consider intervals d1 = (δ1 , δ2 ), and d2 = (δ3 , δ4 ), where d1 and d2 are
both in T , with δ3 > δ2 and λ(d1 ) = λ(d2 ). The probability of finishing a task in (δ1 , δ2 ) is given by
                                                  Z   δ2
                                          γ =              (1 − FsW (δ))fdT (δ)dδ
                                                   δ1
                                                  Z δ4
                                              ≥            (1 − FsW (δ))fdT (δ)dδ
                                                    δ3
                                                    0
                                              = γ

where γ 0 is the probability of finishing a task in (δ3 , δ4 ). Thus the measure of tasks in d1 decreases
by γλ(d1 ) while the measure of tasks in d2 decreases by γ 0 λ(d2 ). For i = 1, 2, let d0i ⊂ T 0 be the
                                                                                λ(d01 ) λ(d1 )(1−γ)     (1−γ)
tasks in di that were not finished in the matching. We have                     λ(d02 )
                                                                                          =
                                                                                       λ(d2 )(1−γ 0 ) = (1−γ 0 )   ≤ 1 and
therefore the relative measure of more difficult tasks in R3 is               nondecreasing in T 0 compared        to T . Let
j and   j0   be two randomly chosen tasks from T and             T 0,   respectively, then for any value of difficulty d,
P r(dj ≤ d) ≥ P r(dj 0 ≤ d)) and P r(dj ≤ d) > P r(dj 0 ≤ d)) for d > sh , implying that dT 0  dT .


   The following lemma derives a relationship between group dominance, group ordering, and out-
put.

Lemma A.4. Let T be a group of tasks and consider two groups of workers W1 and W2 with λ(W1 ) =
              λ(T )
λ(W2 ) ≤        2     and such that W2  W1 . Let µA = (W1 , W2 ) and µB = (W2 , W1 ), then θ(µB ) ≤ θ(µA ).
                                                                                          1
Proof: Let λ(T ) be normalized to 1 and let λ(W1 ) = λ(W2 ) = l ≤                         2.   Assume wlog that the least
difficult task in T and the lowest skill worker in W1 have value zero. Let d1 = max{si : i ∈ W1 } and
d2 = max{sj : j ∈ W2 }, and divide the difficulties in T into intervals (0, d1 ), (d1 , d2 ), and (d2 , dmax ),




                                                              24
where dmax is the maximum difficulty in T . Let
                                                          
                                                          x           d = d1
                                                           1
                                                          
                                                          
                                                 FdT (d) = x2          d = d2
                                                          
                                                          
                                                          
                                                          1           d = dmax

                                                                    ¯ and define matchings m(W1 , T(0,d ) )
              ¯ the set of tasks in T whose difficulties lie in (d, d)
Denote by T(d,d)                                                                                       1

and m0 (W2 , T(d1 ,d2 ) ). Recall that the probabilities of finishing a task in m and m0 are given by π(m)
and π(m0 ), respectively. Because W2  W1 , P r(sj ≥ d) = 1 for all j ∈ W2 and d ∈ (0, d1 ). Now
define µA = mA                A        0         B   B             4       0             0       0
                                                                              
                1 (W1 , T ), m2 (W2 , TmA ) and µ = m3 (W2 , T ), m (W1 , TmB ) , where TmA and TmB
                                                 1                                                3               1         1
are the tasks remaining after the respective matchings. We have θ(mA
                                                                   1 ) = θ(m) = lx1 π(m) and
   0 ) = 1 − lx π(m), with d 0
λ(Tm 1         1            T A distributed as
                                    m1

                                                       
                                                         x1 (1−lπ(m))
                                                                              d = d1
                                                        1−lx1 π(m)
                                                       
                                                       
                                                          x2 −lx1 π(m)
                                        FdT 0 (d) =      1−lx1 π(m)            d = d2
                                             mA
                                              1
                                                       
                                                       
                                                       
                                                       1                      d = dmax

                           x1 (1−lπ(m))+π(m0 )(x2 −x1 )
                                                         
and hence θ(mA
             2)=l                   1−lx1 π(m)                . This means that

                                                                          x1 (1 − lπ(m)) + π(m0 )(x2 − x1 )
                                                                                                             
              θ(µA ) = θ(mA        A
                          1 ) + θ(m2 ) = lx1 π(m) + l                                                                      (4)
                                                                                     1 − lx1 π(m)

Proceeding in the same fashion, we compute θ(mB                         0
                                              1 ) = l(x1 + (x2 − x1 )π(m )). The probability that a
                                    0
task has difficulty in (0, d1 ) in Tm B is given by
                                         1


                                                               x1 (1 − l)
                                     FdmB (d1 ) =
                                             1        1 − l(x + π(m0 )(x2 − x1 ))
                                                                
                                              x1 (1−l)
Consequently, θ(mB
                 2 ) = lπ(m)            1−l(x+π(m0 )(x2 −x1 ))       , and
                                                                                                                      
          B                                                            0                          x1 (1 − l)
       θ(µ ) =   θ(mB
                    1)   +   θ(mB
                                2)   = l(x1 + (x2 − x1 )π(m )) + lπ(m)                                                     (5)
                                                                                         1 − l(x + π(m0 )(x2 − x1 ))

Since d2 > d1 implies x2 > x1 , it can be verified that (4) is indeed greater than or equal to (5) for any
values of l, π(m), and π(m0 ), and hence θ(µA ) ≥ θ(µB ).


   Lemma A.4 indicates that it is optimal to arrange groups with dominance relationships in ascend-
ing order, with dominant groups placed later in the process. Lemma A.5 formalizes the idea that an
increase in the skill pool of the first group can only lead to the workers in the second group being
worse off in terms of output.


                                                                25
Lemma A.5. Let T be a group of tasks and consider groups W3  W1  W2 with λ(W1 ) = λ(W2 ) and
matchings µA = mA               A        0         B     B           B        0              B
                                                                                 
                  1 (W1 , T ), m2 (W3 , TmA ) and µ = m1 (W2 , T ), m2 (W3 , TmB ) , then θ(m2 ) ≥
                                               1                                           1
θ(mA
   2 ).

                                        f           0                                           0
Proof: Let sl = mins s ∈ W3 and define Tm i = {t ∈ Tmi |dt ≤ sl }. It is enough to note that λ(TmA ) ≤
                                                   1               1                                       1
   0 ) and T c ∩ T c    c                c         c               f         f
λ(Tm B      mA    mB
                     = Tm B and hence λ(TmB ) = λ(TmA ) − τ and λ(TmA ) = λ(TmB ) − τ for some
     1           1        1     1                      1               1               1           1
τ ≥ 0. This implies that

                                        f                             f
                                     λ(Tm A)                       λ(Tm B) − τ
                                          1                                1
                                            c )        =                   c )−τ
                                 λ(T ) − λ(Tm A                 λ(T ) − λ(Tm B
                                                   1                           1
                                                                      f
                                                                   λ(Tm B)
                                                                        1
                                                       ≤                   c )     ,
                                                                λ(T ) − λ(Tm B
                                                                               1


                                                                                  f          f
and therefore the proportion of the tasks that W3 can finish has shrunk. Since λ(Tm A ) ≤ λ(TmB ), W3
                                                                                               1       1
now finishes a smaller proportion from a smaller set of tasks in mA              B
                                                                  2 compared to m2 , and therefore
θ(mB        A
   2 ) ≥ θ(m2 ).
   We use Lemmas A.4 and A.5 to prove the following lemma in preparation for proving Lemma 2.
Roughly, Lemma A.6 states that any improvement on a two-group hierarchical arrangement can only
be hierarchical, by either moving some of the most skilled workers from the first group to the second,
or moving some of the least skilled workers from the second group to the first.

Lemma A.6. Let W1 and W2 be two worker groups such that W2  W1 and denote by µ the matching
(m(W1 ), m(W2 )).

   a. Consider w ⊂ W1 and w0 ⊂ W1 such that w  w0 and λ(w) = λ(w0 ) and let µ0 = m1 (W1 \
                         0 ) and µ00 = m (W \ w 0 , T ), m(W ∪ w 0 , T 0     . If θ(µ00 ) ≥ θ(µ), then
                                                                          
      w, T ), m(W2 ∪ w, Tm 1            2  1                2         m  2

      θ(µ0 ) ≥ θ(µ00 ).

  b. Consider w ⊂ W2 and w0 ⊂ W2 such that w  w0 and λ(w) = λ(w0 ) and let µ0 = m1 (W1 ∪
                        0 ) and µ00 = (m (W ∪ w 0 , T ), m(W \ w 0 , T 0 ) . If θ(µ0 ) ≥ θ(µ), then
                                                                         
     w, T ), m(W2 \ w, Tm1              2  1                2         m2
      θ(µ00 ) ≥ θ(µ0 ).

Proof: To prove Part a, assume as in the statement of the lemma that θ(µ00 ) ≥ θ(µ). We can switch w
and w0 in µ0 to obtain µ00 . By Lemma A.4, w0 followed by w has higher output than w followed by w0 ,
and because w  w0 , by Lemma A.5, θ(W2 , Tm
                                           0 ) ≥ θ(W , T 0 ). Combining these two observations
                                            1       2 m2
we get that θ(µ0 ) ≥ θ(µ00 ). The argument for Part b is similar: if we swap w0 for w in µ0 we get µ00 .
Again by Lemmas A.4 and A.5 having w0 precede w and W2 \ w can only increase output compared
to w preceding w0 , and therefore θ(µ0 ) ≤ θ(µ00 ).


   It is important to note that is that Lemma A.6 applies when removing several, possibly disjoint
intervals of workers simultaneously from one group to another. For example, consider two intervals

                                                           26
w1 and w2 of workers in W1 and assume that there is an improvement in output when these intervals
are moved to group W2 , then it is always at least as good to instead remove a measure w of workers
from W1 to W2 with w being the most skilled workers in W1 whose measure is equal to λ(w) =
λ(w1 + w2 ). The same idea holds when removing intervals from W2 to W1 . This observation along
with Lemma A.6 are used in the following proof.


Proof of Lemma 2: As in the statement of the lemma, assume that W1 and W2 are not hierarchical.
Construct W10 and W20 such that i ∈ (W1 ∪ W2 ) → i ∈ (W10 ∪ W20 ), λ(W1 ) = λ(W10 ), λ(W2 ) = λ(W20 ),
and W20  W10 . There exists w10 ⊂ W10 and w20 ⊂ W20 –not necessarily continuous intervals– such that
W1 = (W10 \ w10 ) ∪ w20 and W2 = (W20 \ w20 ) ∪ w10 . Thus, by moving w20 to W10 and moving w10 to W2 ,
we can reconstruct W1 and W2 . However, by Lemma A.6, unless either: a) w10 = ∅ and w20 is such that
(W20 \ w20 )  w20 or b) w20 = ∅ and w10 is such that w1  (W10 \ w10 ) – either of which imply that W1 and
W2 are hierarchical and hence contradict our assumption– there exists W̄1 and W̄2 such that W̄1 and
W̄2 are hierarchical and θ(W̄1 , W̄2 ) = θ(µ̄) ≥ θ(W1 , W2 ) = θ(µ).


       The optimal groups are contiguous:

Lemma A.7. Consider the optimal grouping W ∗ = (W1∗ , W2∗ ) for k = 2, and a worker i with skill si .
If i ∈ W ∗ , then {j|sj > si } ∈ W ∗ .

Proof: Assume that there is w1  w2  w3 such that w1 ∈ W ∗ and w3 ∈ W ∗ , and w2 6∈ W ∗ and
λ(w1 ) = λ(w2 )16 . The result follows from Lemma A.2 since the output of W ∗ improves by swapping
w1 and w2 , and hence W ∗ cannot be optimal.


Proof of Theorem 1: We prove the theorem by induction on the number of groups. Proposition 1
shows that the base case for k = 2 holds. Assume that the result holds for k and consider k + 1
groups. By the induction hypothesis, the optimal solution for the assignment of the remaining tasks
from the matching m1 (W1 , T ) is a hierarchy. Furthermore, Lemma A.7 applies to k groups since the
output of a group of workers can only increase by substituting a dominated subgroup within a group
by a group of equal size that dominates it but is not in the current selection of workers. This implies
that the optimal solution for k groups starts with a worker with skill s̄ and includes all workers up
to the maximum skill in W. Therefore, the optimal solution for k + 1 groups uses at most one more
measure of workers than the solution for k groups. This measure consists of workers whose skill lie in
(G−1 (G(s̄)−1), s̄). Assume that the optimal solution uses workers whose skills is less than G−1 (G(s̄)−
1), then by Lemma A.2 we can replace these workers by others whose skills are in (G−1 (G(s) − 1), s̄)
to improve output. Let W1 be the first group in the optimal k + 1 groups solution. Groups W2 through
Wk+1 form a hierarchy by the induction hypothesis. Consider moving w ∈ Wi , i > 2 to group W1 .
By Lemmas A.4 and A.5, this will decrease output. Conversely, by Lemmas 1 and A.1, removing
any workers from W1 to later groups would decrease their output and exchanging them with any of
  16
       We can always find groups that fulfill this measure requirement under the assumption w1 ∈ W ∗ and w2 6∈ W ∗ .


                                                             27
the more skilled workers in one of those groups is again output decreasing. By similar arguments to
Lemma A.6, the only move with a potential for output maximization is one that removes a group w0
from W2 such that (W2 \ w0 )  w0 , and adds it to W1 , with possible adjustments to later groups (again,
removing workers from the peripheries only), and hence the optimal k + 1 groups solution is also
hierarchical.


Proof of Proposition 2: The proof proceeds by induction. For k = 1, the optimal group W ∗ is the
top measure of workers. Consider splitting this group into two at a worker whose skill is s, so that
W1 has workers whose skills are in (smin , s) and W2 has workers whose skills are in (s, smax ). Let
                             0 ) . Notice that in this arrangement, workers in W get tasks in T 0
                                
µ = (m1 (W1 , T ), m2 (W2 , Tm1                                                 2                m1
                                                                       0 ) are larger than λ(W ).
whereas before they had tasks from T , and note that both λ(T ) and λ(Tm 1                    2
             0
By Lemma 1, Tm    T and hence by Lemma A.1, θ(m2 ) < θ(W2 , T ). The output of W1 is the same
               1

under both scenarios, therefore, θ(W ∗ ) > θ(µ). Now assume that the result holds for k groups. This
means that in order to have k + 1 groups we need more workers. Assume an incremental amount δ
of workers are added and that the skills of these workers are such that they are less than everyone
already used (but they can still perform some tasks). Let W1 contain these δ workers and let the
tasks finished in m(W1 , T ) be of size δ 0 , then λ(Tm
                                                      0 ) = 1 − δ 0 . Set aside the least skilled δ workers
                                                        1

from the original supply of workers and consider the assignment of the remaining 1 − δ 0 tasks to the
remaining workers. By the induction hypothesis, this assignment cannot simultaneously have more
than k groups and be better than the original assignment of those workers on those tasks, since if that
is the case then we can combine the discarded δ workers into the first group or into their own group
and have a better assignment with more than k groups, violating the induction hypothesis. Thus in
addition to the discarded δ workers we have group W1 , and at most k other groups. Breaking the
(tiny) W1 group into more than one group will only decrease output as we showed for the base case,
and adding the discarded workers into that first group can only improve output since they face an
easier difficulty distribution. Therefore the optimal arrangement cannot have more than k + 1 groups.




Lemma A.8. (Monotonicity of success probabilities) For all groups i and all skills s, ψ(s, Wi ) is mono-
tonically decreasing in i and monotonically increasing in s.

Proof: Let the distribution of difficulties in group i be given by FdTi and consider group j > i with
difficulty distribution FdTj . A worker with skill s has ψ(s, Wi ) = FdTi (s) in group i and ψ(s, Wj ) =
FdTj (s) in group j. By Lemma 1, dTj  dTi and therefore FdTi (s) ≥ FdTj (s), and ψ(s, Wi ) is mono-
tonically decreasing in i, and since F is a distribution function, it is monotonically increasing in its
argument s.




Corollary A.2. (Monotonicity of output) Denote by θ(s, i) the output of a worker with skill s in group

                                                    28
Wi . In the optimal hierarchical solution θ(s, i) ≥ θ(s, j) for j > i.

Proof of Lemma 3 Consider the optimal grouping and examine the ith matching m(Wi ) = Ti . Let
λ(Wi ) and λ(Ti ) be normalized to 1 and assume wlog that the least difficult task in T and the lowest
skill in Wi are normalized to zero. Let s1 and s2 be the skills of any two workers in W , with s2 > s1 .
Divide the difficulties in T into intervals (0, s1 ), (s1 , s2 ), and (s2 , smax ), where smax is the maximum
difficulty in T . Let FdT (s1 ) = x1 , FdT (s2 ) − FdT (s1 ) = x2 , FsWi (s1 ) = l1 , and FsWi (s2 ) − FsWi (s1 ) = l2 .
Denote by π1 the probability of finishing a task that is randomly assigned from (0, s1 ) to a worker
whose skill is in (0, s1 ). Similarly, denote by π2 the corresponding probability when a task with dif-
ficulty in (s1 , s2 ) is assigned to a worker whose skill is in (s1 , s2 ). Let Ti+1 be the set of tasks remain-
ing after m(Wi ) and let the measure of tasks in (s2 , smax ) in T 0 be equal to y. We have λ(Ti+1 ) =
y + x1 (l1 (1 − π1 )) + x2 (l1 + l2 (1 − π2 )). The distribution of Ti+1 is therefore given by
                                             
                                                           x1 l1 (1−π1 )
                                             
                                              y+x1 (l1 (1−π1 ))+x2 (l1 +l2 (1−π2 ))
                                                                                      d = s1
                                             
                                                x1 (l1 (1−π1 ))+x2 (l1 +l2 (1−π2 ))
                              FdTi+1 (d) =                                             d = s2
                                              y+x1 (l1 (1−π1 ))+x2 (l1 +l2 (1−π2 ))
                                             
                                             
                                             1                                        d = smax

    Using FdTi+1 we can write

                               ψ(s1 , Wi )       y + x1 (l1 (1 − π1 )) + x2 (l1 + l2 (1 − π2 ))
                   φ(s1 ) =                 = x1
                              ψ(s1 , Wi+1 )                     x1 l1 (1 − π1 )

and

                          ψ(s2 , Wi )                y + x1 (l1 (1 − π1 )) + x2 (l1 + l2 (1 − π2 ))
              φ(s2 ) =                 = (x1 + x2 )
                         ψ(s2 , Wi+1 )              x1 (l1 (1 − π1 ) + l2 )) + x2 (l1 + l2 (1 − π2 ))

Finally, we have
                                φ(s2 )             (x1 + x2 )l1 (1 − π1 )
                                       =                                            < 1,
                                 φs1     x1 (l1 (1 − π1 )) + x2 (l1 + l2 (1 − π2 ))
i.e. φ(s2 ) < φ(s1 ), as required, and the result obviously holds if i + 1 is replaced by any j > i + 1.


Proof of Theorem 2 Denote by W0 the group that includes workers whose skills are below the min-
imum skill for participation s̄. Let si = {min s|s ∈ Wi∗ }, so that s1 = s̄. Consider an entry fee q and
payments p1 , ...pk that satisfy the following system of equations

                              p1 ψ(s1 , W1∗ ) = q
                           pi ψ(si+1 , Wi∗ ) = pi+1 ψ(si+1 , Wi+1
                                                               ∗
                                                                  ) i = 1, 2., , , k − 1

The minimum payoff that can be obtained in W1∗ is equal to p1 ψ(s1 , W1∗ ) − q = 0. By Lemma A.8,
ψ(s0 , W1∗ ) < ψ(s1 , W1∗ ) for all s0 < s1 = s̄, and therefore p1 ψ(s0 , W1∗ ) − q < 0. Similarly, for s > s̄,
ψ(s, W1∗ ) > ψ(s̄, W1∗ ) and p1 ψ(s, W1∗ ) − q > p1 ψ(s1 , W1∗ ) − q ≥ 0. Consider a worker with skill s < si+1


                                                              29
in Wi∗ . This worker makes pi ψ(s, Wi∗ ) and upon moving to Wi+1
                                                              ∗ makes



                                     ∗        ψ(si+1 , Wi∗ )          ∗
                         pi+1 ψ(s, Wi+1 ) = pi           ∗ ) ψ(s, Wi+1 )
                                             ψ(si+1 , Wi+1
                                                                               ∗ )
                                                         ψ(si+1 , Wi∗ ) ψ(s, Wi+1
                                        = pi ψ(s, Wi∗ )            ∗ ) ψ(s, W ∗ )
                                                        ψ(si+1 , Wi+1           i
                                                        φ(s i+1 )
                                        = pi ψ(s, Wi∗ )
                                                         φ(s)
                                                    ∗
                                        ≤ pi ψ(s, Wi )

where the last inequality is obtained from Lemma 3 and the fact that s < si+1 . The inequality still
                                                                                        ∗ ) ≥
holds if we replace i + 1 with any j > i. A symmetrical argument shows that pi+1 ψ(s, Wi+1
pi ψ(s, Wi∗ ) for any s > si+1 .




                                                  30
References
Antràs, Pol, Luis Garicano, and Esteban Rossi-Hansberg (2006), “Offshoring in a knowledge econ-
  omy.” The Quarterly Journal of Economics, 121, 31–77.

Bansal, N., A. Gupta, J. Li, J. Mestre, V. Nagarajan, and A. Rudra (2010), “When LP is the cure for your
  matching woes: improved bounds for stochastic matchings.” Algorithms–ESA 2010, 218–229.

Beggs, Alan W (2001), “Queues and hierarchies.” The Review of Economic Studies, 68, 297–322.

Boudreau, K.J., N. Lacetera, and K.R. Lakhani (2011), “Incentives and problem uncertainty in innova-
  tion contests: An empirical analysis.” Management Science, 57, 843–863.

Chandler, A.D. (1977), The visible hand: The managerial revolution in American business. Belknap Press.

Chawla, S., J.D. Hartline, and B. Sivan (2012), “Optimal crowdsourcing contests.” In Proceedings of the
  Twenty-Third Annual ACM-SIAM Symposium on Discrete Algorithms, 856–868, SIAM.

Chen, N., N. Immorlica, A. Karlin, M. Mahdian, and A. Rudra (2009), “Approximating matches made
  in heaven.” Automata, Languages and Programming, 266–278.

Chesbrough, H., W. Vanhaverbeke, and J. West (2008), Open Innovation: Researching a New Paradigm:
  Researching a New Paradigm. OUP Oxford.

Dulleck, U., R. Kerschbamer, and M. Sutter (2011), “The economics of credence goods: An experiment
  on the role of liability, verifiability, reputation, and competition.” American Economic Review, 101,
  526–555.

Faridani, S., B. Hartmann, and P.G. Ipeirotis (2011), “Whats the right price? pricing tasks for finishing
  on time.” In Proc. of AAAI Workshop on Human Computation.

Feldman, J., A. Mehta, V. Mirrokni, and S. Muthukrishnan (2009), “Online stochastic matching: Beat-
  ing 1-1/e.” In Foundations of Computer Science, 2009. FOCS’09. 50th Annual IEEE Symposium on, 117–
  126, IEEE.

Fuchs, W., L. Garicano, and L. Rayo (2013), “Optimal contracting and the organization of knowledge.”
  Working Paper.

Garicano, L. (2000), “Hierarchies and the organization of knowledge in production.” Journal of Political
  Economy, 108, 874–904.

Garicano, Luis and Andrea Prat (2013), “Organizational economics with cognitive costs.” In Advances
  in Economics and Econometrics: Tenth World Congress, volume 1, 342, Cambridge University Press.

Garicano, Luis and Esteban Rossi-Hansberg (2004), “Inequality and the organization of knowledge.”
  American Economic Review, 94, 197–202.

                                                   31
Garicano, Luis and Esteban Rossi-Hansberg (2006), “The knowledge economy at the turn of the twen-
  tieth century: the emergence of hierarchies.” Journal of the European Economic Association, 4, 396–403.

Horton, J.J. and L.B. Chilton (2010), “The labor economics of paid crowdsourcing.” In Proceedings of
  the 11th ACM conference on Electronic commerce, 209–218, ACM.

Kamenica, E. and M. Gentzkow (2011), “Bayesian persuasion.” American Economic Review, 101.

Moldovanu, B. and A. Sela (2006), “Contest architecture.” Journal of Economic Theory, 126, 70–96.

Pallais, Amanda (2013), “Inefficient hiring in entry-level labor markets.” Technical report, National
  Bureau of Economic Research.

Roy, Andrew Donald (1951), “Some thoughts on the distribution of earnings.” Oxford economic papers,
  3, 135–146.

Sattinger, Michael (1975), “Comparative advantage and the distributions of earnings and abilities.”
  Econometrica: Journal of the Econometric Society, 455–468.

Teulings, Coen N (1995), “The wage distribution in a model of the assignment of skills to jobs.” Journal
  of Political Economy, 280–315.

Tinbergen, Jan (1974), “Substitution of graduate by other labor.” Kyklos, 27, 217–226.

Von Hippel, E. (1976), “The dominant role of users in the scientific instrument innovation process.”
  Research policy, 5, 212–239.

Von Hippel, E. (2009), “Democratizing innovation: the evolving phenomenon of user innovation.”
  International Journal of Innovation Science, 1, 29–40.

Wolinsky, A. (1993), “Competition in a market for informed experts’ services.” The RAND Journal of
  Economics, 380–398.




                                                     32
