                              NBER WORKING PAPER SERIES




              MEASURING "DARK MATTER" IN ASSET PRICING MODELS

                                          Hui Chen
                                       Winston Wei Dou
                                        Leonid Kogan

                                      Working Paper 26418
                              http://www.nber.org/papers/w26418


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                                   November 2019




We thank Alon Brav, Bradyn Breon-Drish, Murray Carlson, Xiaohong Chen, Xu Cheng, John
Cochrane, George Constantinides, Ian Dew-Becker, Frank Diebold, Stefano Giglio, Dan
Greenwald, Lars Peter Hansen, Yan Ji, Karen Lewis, Ye Luo, Robert Novy-Marx, Christian Opp,
Giorgio Primiceri, Tom Sargent, Frank Schorfheide, Martin Schneider, Bill Schwert, Chris Sims,
Rob Stambaugh, Luke Taylor, Di Tian, Laura Veldkamp, Pietro Veronesi, S. Viswanathan,
Jessica Wachter, Tan Wang, Ivo Welch, Yu Xu, Amir Yaron, Fernando Zapatero, Stan Zin,
participants at the 2019 MIT Capital Markets Research Workshop, and seminar participants at
University of Chicago, Chicago CITE, CKGSB, INSEAD, ITAM Finance Conference,
Macrofinance Workshop, MFM Summer Session, MFM Winter Conference, MIT Sloan,
Northwestern, Harvard, NYU, NBER Asset Pricing Meeting, NBER Capital Markets Meeting,
Red Rock Finance Conference, UBC Winter Finance Conference, University of Pennsylvania
(Economics), Utah Winter Finance Conference, WFA, Washington University (Olin), Wharton,
and Yale SOM for comments. We thank Xiaoliang Wang and Kan Xu for their research
assistance. All errors are our own. The views expressed herein are those of the authors and do not
necessarily reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2019 by Hui Chen, Winston Wei Dou, and Leonid Kogan. All rights reserved. Short sections
of text, not to exceed two paragraphs, may be quoted without explicit permission provided that
full credit, including © notice, is given to the source.
Measuring "Dark Matter" in Asset Pricing Models
Hui Chen, Winston Wei Dou, and Leonid Kogan
NBER Working Paper No. 26418
November 2019
JEL No. C52,D81,E32,G12

                                          ABSTRACT

We introduce an information-based fragility measure for GMM models that are potentially
misspecified and unstable. A large fragility measure signifies a GMM model's lack of internal
refutability (weak power of specification tests) and external validity (poor out-of-sample fit). The
fragility of a set of model-implied moment restrictions is tightly linked to the quantity of
additional information the econometrician can obtain about the model parameters by imposing
these restrictions. Our fragility measure can be computed at little cost even for complex dynamic
structural models. We illustrate its applications via two models: a rare-disaster risk model and a
long-run risk model.

Hui Chen                                         Leonid Kogan
MIT Sloan School of Management                   MIT Sloan School of Management
100 Main Street, E62-637                         100 Main Street, E62-636
Cambridge, MA 02142                              Cambridge, MA 02142
and NBER                                         and NBER
huichen@mit.edu                                  lkogan@mit.edu

Winston Wei Dou
2318 Steinberg Hall - Dietrich Hall
The Wharton School at
University of Pennsylvania
3620 Locust Walk
Philadelphia, PA 19104
wdou@wharton.upenn.edu
                             DARK MATTER IN ASSET PRICING MODELS                                            1

                                            1. INTRODUCTION

In cosmology, dark matter is a form of matter that is not directly observable, yet its presence is
required for Einstein's theory of general relativity to be consistent with the observable motions
of stars and galaxies. Certain economic models rely on an analogous form of "dark matter,"
namely model components or parameters that are difficult to verify and measure directly in the
data, despite having significant effects on the models' performance.1
      Should we be worried about models with dark matter features? Two common defenses for
economic models relying on dark matter are: (i) these features are not inconsistent with the
data, i.e., they cannot be rejected by the data; and (ii) the fact that they improve the model's
ability to fit the data provides indirect evidence supporting their very existence, analogous to
dark matter as posited in cosmology. In this paper, we propose a measure for economic dark
matter and show that the measure helps quantify the degree of model fragility. Specifically,
models with more dark matter tend to lack refutability and have higher overfitting tendency.
      We define a measure of economic dark matter for a general class of GMM models (Hansen,
1982) that summarize a structural model with a set of unconditional moment restrictions. Our
measure is based on the (relative) informativeness of the cross-equation restrictions imposed
by the structural model. Essentially, the measure compares the asymptotic variances of two
efficient GMM estimators for the model parameters , one based on the full set of moment
restrictions which we refer to as the full GMM model, and the other based on a subset of the
moment restrictions which we refer to as the baseline GMM model. The dark matter measure
is obtained by searching for the largest discrepancy between the two asymptotic variances in
all linear directions.
      Our dark matter measure above is inspired by rational expectations econometrics, where the
key assumption is that the agents in an economic model know more about model parameters
than conveyed by the primitive sources inside the model. Intuitively, our dark matter measure
will have a large value when the primary source of information about model parameters is
the cross-equation restrictions, rather than the primitive sources in the model. In such cases,
it may be challenging to argue that, as an approximation, economic agents have inferred pa-
rameters from rich histories of primitive data. Hence, the information obtained through the
cross-equation restrictions becomes unreliable because it heavily relies on the validity of cross-

  1
   For example, John Campbell referred to rare disasters as "dark matter for economists" in his 2008 Princeton
Lectures in Finance (Campbell, 2018).
2             HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

equation restrictions. In this paper, we formalize this intuition by showing what happens when
highly informative restrictions are potentially misspecified. Our setting applies, but is not lim-
ited to the rational expectations models.
        We show that the dark matter measure is linked to two key model properties: refutability
and overfitting tendency. Specifically, we show that the power of the optimal specification tests
vanishes as the dark matter measure for a GMM model approaches infinity. We also show that
those GMM models with more dark matter tend to overfit the data; namely, the out-of-sample
fit of the moment restrictions can deteriorate significantly relative to its in-sample fit once we
take into account the possibility that the GMM model is potentially misspecified and the true
data-generating process (DGP) is subject to local instability (e.g., Li and M¨
                                                                             uller, 2009).
        The dark matter measure has an intuitive sample-size interpretation, which can be thought
of as the amount of additional data needed for the baseline efficient GMM estimator to match
or exceed the precision that the full efficient GMM estimator can achieve with the aid of the
cross-equation restrictions. Technically, we extend the results on semiparametric local mini-
max efficiency bounds by Levit (1976), Nevelson (1977), and Chamberlain (1987, Theorem 2)
for unconditional moment restrictions to Markov processes with local instability.2 This result
formalizes the information interpretation of our measure.
        Model fragility is usually examined through the lens of sensitivity analysis in practice. The
fact that quantifying the informativeness of cross-equation restrictions is linked to sensitivity
analysis is intuitive. Cross-equation restrictions are informative under two conditions: (i) the
additional moments from the full model are sensitive to small changes in the parameter values;
and (ii) these additional moments can be measured precisely in the data relative to the baseline
moments. Thus, computing the dark matter measure resembles the dual of conducting a form
of sensitivity analysis. Intuitively, a GMM model is considered fragile if its key implications are
excessively sensitive to small perturbations of the data-generating process. Formally, one needs
to specify the relevant magnitude of "local perturbations" and define "excessive sensitivity."
In multivariate settings, there is the additional challenge that the simultaneous responses of
model parameters to the perturbations in the data-generating process must be considered in

    2
    Hansen (1985) and Chamberlain (1987, Thereom 3) study semiparametric local minimax efficiency bounds
for conditional moment restrictions. Hansen (1985) derives the efficiency bounds from the perspective of char-
acterizing the optimal instrument in the estimation of generalized instrumental variables in a non-i.i.d. context.
Chamberlain (1987, Theorem 3) focuses on moment restrictions parameterized in terms of a finite-dimensional
vector in an i.i.d. context. Newey (1990, 1993) proposes an estimator that attains Chamberlain's bounds. Ai
and Chen (2003) propose an estimation method, as well as its efficiency, for models of conditional moment
restrictions, which contain finite dimensional unknown parameters and infinite dimensional unknown functions.
                               DARK MATTER IN ASSET PRICING MODELS                                               3

order to assess the full scope of model fragility. However, little work has been done to formalize
the sensitivity analysis for model fragility quantification.
      Our dark matter measure formalizes the sensitivity analysis by (i) benchmarking the local
perturbation in the data-generating process against the identification derived from the base-
line model, and (ii) defining the excessive sensitivity of efficient GMM estimators to the local
perturbations in the data-generating process based on the sampling variability of the efficient
GMM estimators. Naturally, we require the baseline model to be a correct benchmark similar
to Eichenbaum, Hansen, and Singleton (1988), because we need the identification provided by
the baseline model to define the reasonable perturbations in the data-generating process. In
addition, our measure identifies the worst direction of perturbation for the multivariate set-
ting by searching for the direction in the model parameter space in which the cross-equation
restrictions are the most informative.
      An intuitive justification for the concern regarding model sensitivity is the high effective
degrees of freedom in models with high sensitivity. Such models can be fitted to a wide range
of empirical moments with minor changes to the parameter values. Models with high degrees
of freedom are well-documented as being more prone to overfitting, which is why statistical
model selection procedures impose penalties for model complexity, as measured by AIC, BIC,
LASSO, etc.
      Formally, the concern regarding model sensitivity originates in potential misspecification
and local instability of the data-generating process. Under the assumption that a model is
correctly specified, high sensitivity of the moments to parameter perturbations is a beneficial
feature. Imposing these model restrictions will facilitate estimating the model parameters sig-
nificantly more precisely, which is the foundation for structural estimation. However, if the
model restrictions are potentially misspecified, the information obtained from imposing such
restrictions may no longer be valid. Kocherlakota (2007) similarly emphasizes the "fallacy of
fit." The nontestable assumption of identification strength is related to the informativeness of
the cross-equation restrictions. They indicate the implicit degrees of freedom postulated by
the modeler, as the modeler effectively passes the statistical challenge of learning about model
parameters from the data onto economic agents.
      We analyze the consequences of misspecification and local instability by generalizing the
                                       uller (2009) to the semiparametric setting.3 We show
local instability framework of Li and M¨
  3
    We need a semiparametric framework for at least three reasons: (i) it provides a formal general econometric
framework for local perturbations in the space of local data-generating processes; (ii) it is needed for justifying
4          HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

that models with large dark matter measures tend to generate an excessively high quality
of in-sample fit. Due to this finding, these models are difficult to reject even when they are
misspecified, hence the lack of refutability. Moreover, we show that under local instability,
models with larger dark matter measures have a higher worst-case asymptotic expected degree
of overfitting, as measured by the gap between the in-sample model fit and the out-of-sample
model fit based on the Sargan-Hansen J statistic. Thus, we generalize the notion of sensitivity
analysis from the perturbations of model parameters to the perturbations of the underlying
data-generating processes.
    The recursive (two-stage) GMM estimation (e.g., Christiano and Eichenbaum, 1992; Ogaki,
1993; Newey and McFadden, 1994; Hansen and Heckman, 1996; Hansen, 2007b; Lee, 2007;
Hansen, 2012) has necessarily worse in-sample fit than does the efficient GMM estimation
(Hansen, 1982); however, the former can in fact deliver better out-of-sample fit when the dark
matter measure (i.e., the model fragility) is excessively high. Although the original impetus of
the recursive (two-stage) GMM estimation was primarily computational, we advocate it as a
robust estimation procedure against high model fragility. Thorough analyses on optimal robust
estimation, and even on optimal model selection, however, are beyond the scope of this paper.
    We evaluate the fragility of two models from the asset pricing literature. The first example
is a rare-disaster model. In this model, parameters describing the likelihood and magnitude
of economic disasters are difficult to estimate from the data unless information in asset prices
is used. We derive the dark matter measure in this example analytically. We also illustrate
how to incorporate uncertainty about the structural parameters (in this context, preference
parameters) when computing model fragility. The second example is a long-run risk model
with a nine-dimensional parameter space. We use this example to show that two calibrations of
the model with similar in-sample fit can differ vastly in fragility properties. We conduct Monte
Carlo simulation experiments for both examples and show that the calibrated models with large
dark matter measures lack in-sample refutability and have poor out-of-sample fit, consistent
with the theory.


Related Literature

The idea that a model's fragility is connected to its degrees of freedom (i.e., its complexity)
dates back at least to Fisher (1922). Traditionally, effective degrees of freedom of a model are
the information matrix interpretation of our dark matter measure based on semiparametric efficiency bounds;
and (iii) it is a natural way to connect the GMM model to the structural economic model.
                               DARK MATTER IN ASSET PRICING MODELS                                               5

measured by the number of parameters, simply because the two coincide in Gaussian-linear
models (e.g. Ye, 1998; Efron, 2004). Numerous statistical model selection procedures are based
on this idea.4
      However, the limitations of using the number of parameters to measure model's degrees of
freedom have been well documented. Hence, new methods have been developed to measure the
sensitivity of model implications to parameter perturbations in the statistics literature.5 A com-
mon feature of these proposals is that they rely on the same model being evaluated to determine
the parameter perturbations; this is potentially problematic when evaluating economic models
that are themselves fragile, partly due to a lack of internal refutability. In contrast, we propose
using a baseline model to assign weights to potential alternative underlying data-generating
processes or to determine the possible "reasonable" perturbations of data-generating processes.
      To be more specific, our fragility measure is different from the extant measures in four
aspects. First, we use a semiparametric framework to allow for general local perturbations of
data-generating processes similar to Hansen and Sargent (2001), but not only the local per-
turbations of model parameters that fit the model. Second, the reasonable local perturbations
of data-generating processes are generated by the baseline model that is less likely to be mis-
specified, and we use the baseline model as a benchmark to respect the primary purpose of the
economic structural model in the fragility assessment. Third, we directly connect the model
fragility measure to a model's internal refutability, i.e., the optimal power of specification tests.
Fourth, we also directly connect the model fragility measure to a model's out-of-sample fit, em-
phasized by, for example, Schorfheide and Wolpin (2012) and Athey and Imbens (2017, 2019),
for assessing economic models.6
      Further, we have built our model fragility measure based on a multivariate sensitivity anal-
ysis. M¨
       uller (2012) studies multivariate sensitivity analysis in Bayesian inference and the worst-
case direction. He focuses on the sensitivity of the posterior distribution with respect to the prior

  4
     Examples include the Akaike information criterion (AIC) (Akaike, 1973), the Bayesian information criterion
(BIC) (Schwarz, 1978), the risk inflation criterion (RIC) (Foster and George, 1994), and the covariance inflation
criterion (CIC) (Tibshirani and Knight, 1999).
   5
     Extant statistics literature covers several alternative approaches to measuring the "implicit degrees of free-
dom" or "generalized degrees of freedom" (e.g., Ye, 1998; Shen and Ye, 2002; Efron, 2004; Spiegelhalter, Best,
Carlin, and van der Linde, 2002; Ando, 2007; Gelman, Hwang, and Vehtari, 2013).
   6
     The terms "in-sample fit" and "out-of-sample fit", as well as other similar terms, are used commonly in
statistics, econometrics, and empirical asset pricing (e.g., Hastie, Tibshirani, and Friedman, 2001; Ferson, Nal-
lareddy, and Xie, 2013; Varian, 2014; Athey and Imbens, 2015; Mullainathan and Spiess, 2017; M¨         uller and
Watson, 2016). The terms "out-of-sample fit" and "external validity" have been used interchangeably in finance
and economics literature (e.g., Bossaerts and Hillion, 1999; Stock and Watson, 2002; Schorfheide and Wolpin,
2012).
6         HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

distribution by asking how much the posterior distribution changes in response to a perturba-
tion of the prior distribution. Differently, we perturb the underlying data-generating process,
and ask how much the moment restrictions and the baseline model parameters change. Simi-
lar to M¨
        uller (2012), we consider a multivariate sensitivity problem using asymptotic methods
and eigenvalue decomposition to identify the worst-case direction. In another related paper,
Andrews, Gentzkow, and Shapiro (2017) propose a local measure of the relationship between
parameter estimates and moments. In Section 5.2, we establish the connection between our
information-based dark matter measure and their sensitivity matrix. Their focus is to add
transparency in structural estimation, and they do not link the magnitude of the sensitivity
matrix to model properties. We formally connect the dark matter measure to model fragility,
and link its magnitude to the model's lack of refutability and overfitting tendency. Moreover,
our measure differs from their sensitivity matrix in two aspects: (i) it is a relative sensitivity
measure that uses the baseline GMM model as a benchmark; and (ii) it normalizes the expected
change of the estimator by its asymptotic covariance in the full model.
    Our work contributes to the literature on local instability in time series analysis. Evi-
dence abounds on structural changes and nonstationarity in asset pricing (e.g., Pesaran and
Timmermann, 1995; Bossaerts and Hillion, 1999; Pastor and Stambaugh, 2001; Lettau and
Van Nieuwerburgh, 2008; Lettau, Ludvigson, and Wachter, 2008; Welch and Goyal, 2008; Koi-
jen and Van Nieuwerburgh, 2011; Dangl and Halling, 2012). Econometric theory has largely
focused on testing whether or not the model is stable (see, e.g., Nyblom, 1989; Andrews, 1993;
Andrews and Ploberger, 1994; Sowell, 1996; Bai and Perron, 1998; Hansen, 2000; Andrews,
2003; Elliott and M¨
                   uller, 2006, for recent contributions). However, little research has explored
the next step: what implications arise once instabilities are suspected? One exception is Li and
M¨
 uller (2009) who show that the standard GMM inference (Hansen, 1982), despite ignoring the
partial instability of a subset of model parameters, remains asymptotically valid for the subset
of stable parameters. We show that the GMM models tend to have poor out-of-sample fit if
their dark matter measure, i.e., model fragility measure, is excessively large.
    Our work connects to the literature on structural estimation, including rational expectations
econometrics, in which economic assumptions (the cross-equation restrictions) have been used
extensively to increase efficiency in estimating the structural parameters. Classic examples in-
clude Saracoglu and Sargent (1978), Hansen and Sargent (1980), Campbell and Shiller (1988),
among others, and textbook treatments by Lucas and Sargent (1981), Hansen and Sargent
(1991). In a fragile model, cross-equation restrictions may imply excessively tight confidence
                             DARK MATTER IN ASSET PRICING MODELS                                          7

regions for the parameters, with low coverage probability under reasonable parameter pertur-
bations. An important potential source of fragility in this context is that the structural model
relies heavily on the agents possessing accurate knowledge of hard-to-estimate parameters.
      Hansen (2007a) offers an extensive discussion of the informational burden that rational
expectations models place on the agents, which is one of the key motivations for research
in Bayesian learning, model ambiguity, and robustness (e.g., Gilboa and Schmeidler, 1989;
Hansen and Sargent, 2001; Epstein and Schneider, 2003; Klibanoff, Marinacci, and Mukerji,
2005). This literature recognizes that the traditional assumption that agents possess precise
knowledge of the relevant probability distributions is not justifiable in certain contexts, and
explicitly incorporates robustness considerations into agents' decision problems. Our approach
complements this line of research, in that our measure of fragility helps diagnose situations
in which incorporating parameter uncertainty and agents' robustness considerations within an
economic model could be particularly important.
      Our analysis of the disaster-risk model relates to studies that have highlighted the challenges
in testing such models. One implication of the low probability of disasters is the so-called
"peso problem" (see Lewis, 2008, for an overview): if observations of disasters in a particular
sample under-represent their population distribution, standard inference procedures may lead
to distorted conclusions. Thus, the peso problem is a particular case of the weak identification
problem. Our analysis highlights that in applications subject to the peso problem, it is important
to guard against model fragility. On this front, Zin (2002) shows that certain specifications of
higher-order moments of the endowment growth distribution may help the model fit the asset
pricing moments while being difficult to reject in the endowment data. Our analysis of model
fragility encapsulates such considerations in a general quantitative measure.



                                     2. AN INTUITIVE EXAMPLE


In this section, we use a version of the Gordon growth model to illustrate how the dark matter
measure connects to model fragility. Suppose the dividend process for a stock is

                                                                                           2
(1)       Yt+1 /Yt = 1 +  + Y     Y,t+1 ,     Y,t   is i.i.d., with E[   Y,t ]   = 0, E[   Y,t ]   = 1.


The parameters  and Y are the mean and volatility of dividend growth. According to the
Gordon growth model, the price of the stock is the present value of expected future dividends.
8            HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

Assuming the risk-adjusted discount rate is r, then

                    
(2)       Pt =         Et [Yt+s ] /(1 + r)s ,
                 s=1


which implies a constant price-dividend ratio,


(3)       Pt /Yt = F (),          with F ()  (1 + )/(r - ).


      The econometrician evaluates a GMM version of this model in a sample of size n. To avoid
the stochastic singularity, we add i.i.d. shocks to the price-dividend ratio such that (3) only
holds on average,

                                                                                                  2
(4)       Pt+1 /Yt+1 = F () + P          P,t+1 ,   P,t   is i.i.d., with E[     P,t ]   = 0, E[   P,t ]   = 1.


Moreover,     P,t   and    Y,t   are mutually independent. For simplicity, we assume that the econo-
metrician knows all the parameters except for average dividend growth  and focuses on the
following moment conditions:
                                                                                
                                                         Yt+1 /Yt - 1 - 
(5)       E [m(yt , )] = 0,         with m(yt , )                               ,
                                                            Pt /Yt - F ()

where yt  (Yt , Pt )T . We denote the first element of m(yt , ) by m(1) (yt , ) and refer to it as
the baseline moment.
      Next, We assume that the Gordon growth model can be misspecified and that the true local
data-generating processes is
                                                                            
              Yt+1 /Yt        fn,t  1 + 0   Y                       Y,t+1
(6)                         =     +        +                                .
             Pt+1 /Yt+1         n   F (0 )   P                      P,t+1


The term fn,t captures the potential local bias and instability:

                                                                     T
                                                      (1)     (2)
(7)       fn,t = 1 + 2 b(t/n),           with i  i , i                   for i  {1, 2},


where b(·) is an unknown deterministic function on [0, 1] whose path has a finite number of
discontinuities and one-sided limits everywhere. Without loss of generality, we assume that
                              DARK MATTER IN ASSET PRICING MODELS                                     9
                                  1
supu[0,1] |b(u)|  1 and               b(u)du = 0.
                              0
      Instability in the data-generating process, for example, structural breaks and nonstationar-
ity, is an important consideration in asset pricing.7 Our specification in (7) follows the the lit-
erature on local instability (e.g., Andrews, 1993; Sowell, 1996; Li and M¨
                                                                         uller, 2009). Intuitively,
1 captures the stable local biases in the moments, while 2 captures their local instability.
      For calibration, we set 0 = 0, r = 3%, Y = 4%, and P = 5. Under the calibrated
distribution Q0 of yt , which corresponds to the parameter value 0 = 0, the Jacobian matrices
of the baseline and the full moment restrictions are
                                                                                         
                        (1)
                     m (yt , )                m(yt , )       -1
          D11 = E              = -1 and D = E          =             
                                                         (1 + r)/r 2



The spectral density matrices (at zero frequency) for the baseline and full models are
                                                                                                
                                                                                    2
                                                                                    Y       0
          11 = E m(1) (yt , 0 )2 = Y
                                   2
                                     and  = E m(yt , 0 )m(yt , 0 )T =                           .
                                                                                         2
                                                                                     0   P

The growth rate  can be estimated using either the baseline moment restrictions alone or using
the full moment restrictions. We denote these two efficient GMM estimators for  by  ~n and  ^n ,
which minimize the objectives

                                     T -1 (1)                         T -1
          J (1) ((1) , yn ) = nm(1)                       n
                                n ( ) 11 mn ( ) and J (, y ) = nmn ( )  mn ( ), respectively,


           (1)
where mn () and mn () are the sample means for m(1) (yt , ) and m(yt , ), respectively.




The dark matter measure

Panel A of Figure 1 displays the asymptotic distribution of the baseline estimator ~n (the
efficient GMM estimator for  based on the baseline moment of (5)),

                     d
          n(~n - 0 ) - N (0, I- 1             T
                                   where IB  D11 - 1
                              B ),               11 D11 .




  7
    See e.g., Pesaran and Timmermann (1995); Pastor and Stambaugh (2001); Lettau, Ludvigson, and Wachter
(2008); Lettau and Van Nieuwerburgh (2008); Welch and Goyal (2008); Koijen and Van Nieuwerburgh (2011).
 10                                   HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

                                     A. Baseline GMM ~n                                      B. Model restriction                                                        C. Full GMM ^n
                                                                                 60

                          900                                                                                                                            900
                                                                                                                                                                   ~n
                                                                                                                                                                   
                                                                                 55
                                                                                                                                                                   ^n
                                                                                                                                                                   
                          800                                                    50                                                                      800       ^f
                                                                                                                                                                     n
                     ~n




                                                                                                                                                    ^n
Asy. distribution of 




                                                                                                                               Asy. distribution of 
                          700                                                    45                                                                      700

                          600                                                    40                                                                      600




                                                                        Pt /Yt
                          500                                                    35                                                                      500

                          400                                                    30                                                                      400

                          300                                                    25                                                                      300

                          200                                                    20                                                                      200

                          100                                                    15                                                                      100

                           0                                                     10                                                                       0
                           -0.015 -0.01 -0.005   0   0.005 0.01 0.015             -0.015 -0.01 -0.005   0   0.005 0.01 0.015                              -0.015 -0.01 -0.005   0   0.005 0.01 0.015
                                                                                                                                                                                


    Figure 1.-- An example of an informative asset pricing restriction on the parameters.          ~n is the efficient
 GMM estimator only based on the baseline GMM model characterized by the baseline moment m(1) (yt , )
 and sample yn . Both    ^n and  ^f are the efficient GMM estimators based on the full GMM model and sample
                                  n
  n                ^f
 y , except that n is the estimator when the model is misspecified (fn,t  0). Panel A plots the asymptotic
                  ~
 distribution of n(    n - 0 ) with n = 100. Panel B plots the average price-dividend ratio as a function of  .
 The light blue dashed vertical lines represent the confidence band for      ~n with sample size n = 100, and the
 corresponding light blue dashed horizontal lines represent the model-implied average price-dividend ratio when
 perturbing  within the confidence band. The red shaded horizontal area represents the confidence band of
 the average price-dividend ratio Pt /Yt according to the data with n = 100, and the corresponding red shaded
 vertical area represents the model-implied parameter  according the data with n = 100. Panel C plots the
 asymptotic distribution of  ^n based on the assumed asset pricing restriction displayed in Panel B and the whole
           n
 sample y with n = 100; the normal density indicated by the red solid line is the asymptotic distribution of
 
   n( ^n - 0 ) when the model is correctly specified (fn,t  0). By contrast, the normal density indicated by the red
                                                  ^f                                                                T
 dashed line is the asymptotic distribution of n(      n - 0 ) when the model is locally misspecified (1 = [0, 30] ,
            T
 2 = [0, 0] , and b = 0).



 The graph illustrates the degree of uncertainty about the value of  according to the baseline
 model and the dividend data. When n = 100, the 95% asymptotic confidence interval for the
 growth rate  is approximately [-0.8%, 0.8%].
                           Panel B of Figure 1 plots the model-implied average price-dividend ratio F () as a function
 of the dividend growth rate . Because F () rises quickly with , there is only a narrow range
 of  for which the model-implied average price-dividend ratios would be consistent with the
 sample mean. To see this, we use the shaded horizontal region near 30 on the y -axis to denote
 the 95% confidence interval for the average price-dividend ratio from the data (assuming there
 is no local misspecification, i.e. fn,t  0). The corresponding shaded vertical region on the x-axis
 shows the range of  consistent with the model, which is significantly more concentrated than
 the asymptotic distribution of the baseline estimator.
                           The full estimator ^n , which is the efficient GMM estimator based on the full set of moment
 restrictions in (5), is significantly more precise than the baseline estimator. With the moment
                             DARK MATTER IN ASSET PRICING MODELS                                           11

restrictions correctly specified (i.e., fn,t  0),

                    d
         n(^n - 0 ) - N (0, I- 1
                                  where IF  DT -1 D.
                             F ),




When n = 100, the 95% asymptotic confidence interval for the growth rate  is approximately
[-0.06%, 0.06%]. A comparison between the asymptotic distributions of the baseline and full
estimators in Panel C of Figure 1 reveals how informative the asset pricing restriction in (5) is
about . This incremental informativeness of the asset pricing restrictions is the focus of our
dark matter measure. More precisely, we define the dark matter measure as

                                                 2
(8)       (0 )  IF /IB - 1 = [F (0 )Y /P ] = 83.82.


This simple example shows that the informativeness ( (0 )) increases in the sensitivity of the
asset pricing moment to the parameter value (F (0 )) and decreases in the variability of the
asset pricing moment (P ).


Dark matter and model fragility

While informative moment restrictions can be very helpful in identifying parameters in the
absence of local misspecification, they become a symptom of model fragility with misspecifi-
cation. It is conventional to define model fragility as the excessive sensitivity of the model's
implications, specifically, how well it fits the data, to small perturbations of the data-generating
process. To formalize this procedure, we need to be precise on (i) what constitutes small pertur-
bations in data-generating processes, and (ii) how to define excessive sensitivity of the model fit.
For (i), if trusting the baseline moment restrictions but lacking confidence in the additional mo-
ment restrictions from the structural model, it makes sense to benchmark the magnitude of the
perturbation to the uncertainty about  in the baseline moment restrictions.8 For (ii), we can
assess the extent to which the changes in the moments resulting from parameter perturbations
are statistically distinguishable from zero according to the data.
   Following the rules of the sensitivity analysis set above, Panel B of Figure 1 indicates that a
perturbation of  within the 95% confidence region of the baseline estimator    ~n (marked by the
two vertical dashed lines) can move the average model-implied price-dividend ratio far away
from the confidence region implied by the empirical moments (the narrow shaded region near
  8
    We formally justify this benchmark in Section 4.3 by considering local instability and misspecification in
the data-generating process.
12            HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

30 on the y -axis), which means the perturbed GMM model will likely be rejected by the data.
Similar to the informativeness of the asset pricing restriction, model sensitivity is higher when
the asset pricing moment has a larger gradient with respect to the model parameter , and
when the error of the asset pricing moment is smaller.
      More generally, the dark matter measure can be viewed as a multivariate model sensitivity
measure. The direction in which the two efficient asymptotic variances based on the baseline
and full models differ the most is also the one in which a local perturbation of the parameter
vector  results in the largest changes in the model fit.
      It is also worth noting that the connection between the informativeness of the structural
model restrictions and model fragility only makes sense in light of the possibility of model
misspecification. If a GMM model is correctly specified, the more sensitive the moments, then
the more precise will be the estimate of the parameters by imposing valid restrictions; this
can be seen from Panel C of Figure 1, where the asymptotic distribution of ^n with fn,t  0
is tightly distributed around the true value 0 = 0. However, if the asset pricing restrictions
are potentially misspecified and unstable, then the extra information they provide may not be
valid, thereby making inference problematic.


Lack of refutability

We are interested in testing the validity of the asset pricing moment restriction (i.e., whether
 (2)
1 = 0) given the prior information that the baseline moment restriction is correctly specified
        (1)
(i.e., 1 = 0). Considering an upper bound for the maximin local power, we can focus on a sub-
set of alternatives satisfying b  0 to obtain an upper bound characterized by the dark matter
measure, albeit it is not necessarily the tightest bound. In this example, the C test (Eichen-
baum, Hansen, and Singleton, 1988) is numerically equivalent to the J test (Hansen, 1982);
and Newey (1985a) shows that it is asymptotically optimal for these particular alternatives.
                                                              (1)              (2)
We consider the set of alternatives A (Q0 )  1  R2 : 1 = 0 and |1 |   .
      The C test statistic can be rewritten as:
                                                                     2
                                       (1)                     (2)
                             (0 )     1                1      1
(9)       Cn = Z n +                         +                           + op (1),
                          1 + (0 )    Y           1 + (0 )    P

                                             n                                       n
where Zn =        (0 )/(1 + (0 )) n-1/2      t=1 Y,t   +   1/(1 + (0 )) n-1/2        t=1 P,t   converges
to a standard normal variable in distribution. According to Newey (1985a) and Chen and Santos
                          DARK MATTER IN ASSET PRICING MODELS                                  13

(2018), the maximin asymptotic power of the GMM specification tests of size  is bounded from
above by

                                                                           2
                                                         -1
(10)       inf    lim P {Cn > c1- }  lim P          Zn + P  / 1 + (0 )         > c1- ,
        1 A (Q0 ) n                     n


where c1- is the 1 -  quantile of a chi-square distribution with degree of freedom one. The
right-hand side of (10) is an upper bound on the maximin asymptotic power, constructed by
           (1)           (2)
choosing 1 = 0 and 1 = . Further, according to the continuous mapping theorem, the
right-hand side (10) is equal to

                                           2
                       -1
(11)     lim P    Zn + P  / 1 + (0 )           > c1-   = P 2
                                                           1 (µ) > c1- ,
        n


where 21 (µ) represents a noncentral chi-square distribution with degree of freedom one and the
                              (/P )2
noncentrality parameter µ =            . Combining (10) and (11) leads to
                              1 + (0 )

(12)       inf    lim P {Cn > c1- }  P 2
                                       1 (µ) > c1- .
        1 A (Q0 ) n


Thus, when the GMM model has too much dark matter, the noncentrality parameter µ is very
close to zero and thus the upper bound P {2
                                          1 (µ) > c1- } is very close to , which means that

the test power is close to zero. The local power function is visualized in Panel A of Figure 2.
The power only starts to get close to one when the misspecification is 40 times of the standard
deviation P of the price-dividend ratio.
   Intuitively, the baseline moment restrictions have limited ability to refute the cross-equation
restrictions implied by the structural model when the dark matter measure (0 ) is large. It
is clear from Panel B of Figure 1 that, by tuning the parameter value of  inside the "accept-
able region" imposed by the baseline GMM model (i.e., within the 95% confidence region of
the baseline estimator ~n , marked by the two vertical dashed lines), the econometrician can fit
the average model-implied price-dividend ratio over an immensely wide range (i.e., the range
between the two horizontal dashed lines), which means the model-implied cross-equation re-
striction can hardly be rejected by the data. This can also be seen in Panel C of Figure 1:
even when the moment condition for the price-dividend ratio is severely misspecified (with
/P = 6), the baseline GMM model still cannot reject the point estimate  ^f (i.e., ^f is still
                                                                                 n       n

within the confidence interval of  based on ~n ).
14              HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019




   Figure 2.-- Panel A plots the local power of C tests with n = 100. In panel B we simulate 400 independent
time series with length n = 200. We set the break point  = 1/2, misspecification 1 = [0, 0]T , and instability
2 = [0, 30]T and b(·) specified in (13) for panels B and C. Panel B displays the difference between the logged
overfitting measure of the full efficient GMM estimator  ^e,n and that of the baseline efficient GMM estimator ~e,n .
                                               ^
Panel C plots the asymptotic distribution of e,n based on the assumed asset pricing restriction and the whole
sample
         yn with instability; the normal density indicated by the red dotted line is the asymptotic distribution of
      ^
  n(e,n - 0 ). By contrast, the normal density indicated by the red dashed line is the asymptotic distribution
          ^o,n - 0 ).
of n(



Poor out-of-sample fit

A common method for evaluating out-of-sample fit of GMM models is to hold out data from the
model estimation (e.g., Schorfheide and Wolpin, 2012; M¨
                                                       uller and Watson, 2016). We split the
entire time series yn  {y1 , · · · , yn } into two non-overlapping subsamples ye
                                                                               n
                                                                                  y1 , · · · , y               n
           n                                                                       n
and yo  y          n +1 , · · ·   , yn with   (0, 1/2]. The first segment ye is used as the estimation
                                  n
sample, while the second segment yo is used as the holdout sample.9 In particular, for the true
local data-generating process in (6) and (7), we assume that 1 = [0, 0]T , 2 = [0, 30]T ,  = 1/2,
and
                        
                         1,  when 1  t  n
(13)           b(t/n) =
                         -1, when n < t  n,


where the sequence b(t/n) captures the structural breaks and  is the break point.
         We consider the overfitting measure of the efficient GMM estimator ^e,n based on the esti-
               n
mation sample ye , defined as the extent to which the out-of-sample fitting error exceeds the

     9                                    n
    The out-of-sample approach, treating yo as future hypothetical data, can be viewed as a standard cross-
validation method based on observed data.
                               DARK MATTER IN ASSET PRICING MODELS                                         15

in-sample fitting error:10


(14)       O(^e,n , yn )  1 L(^e,n , yn ) - L(^e,n , yn ) ,
                                      o               e
                          2

with L(, ys
          n          n
            )  J (, ys             n
                       ) - J (0 , ys ) for s  {e, o} and the parameter value 0 ensures that the
baseline moment restriction E m(1) (yt , 0 ) = 0 is perfectly satisfied. It can be shown that (see
Theorem 2) the expected overfitting measure can be approximated by


(15)       E O(^e,n , yn )  1 + ((2) /P )2 (0 ),         as n approaches +.
                                 2



    Panel B of Figure 2 displays the histogram of difference between logged overfitting measures
log O(^e,n , yn ) of the full efficient GMM estimator ^e,n and those of the baseline efficient GMM
estimator  ~e,n . For the instability  = 30 (i.e. 6 times of P ), which is hard to reject using C
tests (see Panel A), the degree of overfitting by the efficient GMM estimator  ^e,n is substantial.
This result suggests that robust estimation is particularly relevant for GMM models with large
dark matter measure.
    Define ^o,n to be the efficient GMM estimator based on the holdout sample yn . The out-
                                                                                o

                                                              ^       ^              n
of-sample fit should be poor if the efficient GMM estimators e,n and o,n , based on ye and
 n
yo respectively, are statistically separate from each other. This can be seen in the case of
the asymptotic distributions of   ^e,n and ^o,n (Panel C of Figure 1), which are centered away
from the correct value 0 = 0 for the baseline GMM model and therefore distant from each
other. The distance between the in-sample estimator ^e,n and the out-of-sample estimator ^o,n is
significant according to the asymptotic distribution, which implies that the estimator ^e,n has
a poor out-of-sample fit.


General theory and empirical examples

In the remainder of the paper, we formally develop the set of results illustrated by the simple
example above. We consider the setting of weakly dependent time series data, which are preva-
lent in financial and macroeconomic studies, and allow for local perturbations (e.g., Hansen
and Sargent, 2001) and instability (e.g., Li and M¨
                                                  uller, 2009) of data-generating processes in a
semiparametric framework. We then define the dark matter measure for a general class of GMM
models, and formally establish the connection between the dark matter measure, the model's
  10
       Overfitting measure is also studied by Mullainathan and Spiess (2017) and Hansen and Dumitrescu (2018).
16           HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

refutability, and its out-of-sample fit. Further, We use the dark matter measure to analyze real
data examples including the rare disaster risk and the long-run risk models. We also provide
discussion on what to do with fragile models (i.e. models with large dark matter measure) in
Section 6.


                                    3. THE DARK MATTER MEASURE

In this section, we set up the model and introduce the dark matter measure. We then discuss
the connections between the dark matter measure, sensitivity analysis, and model testability.


                                              3.1. Model Setup

Let Y = Rdy , the dy -dimensional Euclidean space with Borel  -field F. Let P denote the col-
lection of all probability measures on the measurable space (Y × Y, F  F) with the product
sample space Y × Y and the product  -field F  F.


Markov processes

We consider a subspace of P, denoted by H, in which each probability measure is the bivariate
marginal distribution Q for a time-homogeneous Harris ergodic and stationary Markov process
{yt : t = 0, 1, · · · } satisfying the Doeblin condition.11 Following Bickel and Kwon (2001), we
parameterize time-homogeneous Markov processes by the bivariate marginal distributions Q of
(yt-1 , yt ) for any t  1. We denote the (n + 1)-variate joint distribution of yn  {y0 , · · · , yn }
corresponding to Q by Pn . A Markov process is Harris ergodic if it is aperiodic, irreducible,
and positive Harris recurrent (e.g. Jones, 2004; Meyn and Tweedie, 2009). Harris ergodicity
guarantees the existence of a unique invariant probability measure (e.g., Meyn and Tweedie,
2009). Given Harris ergodicity, stationarity only requires that the initial distribution of y0 is
the unique invariant probability measure. The Doeblin condition implies that the -mixing
coefficients (n) decay to zero exponentially fast (e.g. Bradley, 2005, Section 3.2 and Theo-
rem 3.4), which is useful for establishing the uniform law of large numbers (ULLN) (White and
Domowitz, 1984) and the central limit theorem (CLT) (e.g., Jones, 2004, Theorem 9).12
     11
      The set of Markov processes satisfying the Doeblin condition includes a broad class of time series commonly
used in finance and macroeconomics; see, e.g., Stokey and Lucas (1989) and Ljungqvist and Sargent (2004).
   12
      First-order Markov models are widely adopted for approximating financial and economic time series. Many
prominent structural asset pricing models feature state dynamics as first-order Markovian processes (e.g., Camp-
bell and Cochrane, 1999; Bansal and Yaron, 2004; Gabaix, 2012; Wachter, 2013).
                              DARK MATTER IN ASSET PRICING MODELS                                            17

Structural models and moment restrictions.

Consider a stable structural model denoted by Q, which aims to capture certain statistical
features of the observed data yn . The parameters of such a "stable" model, denoted by , are
                                  uller, 2009).13 We assume that the restrictions imposed by
constant over time (e.g., Li and M¨
the model on the data can be summarized by a set of moment restrictions, and that the model's
performance in a given data sample can be measured by the degree to which these moment
restrictions are violated (i.e., the fit of moment restrictions). As we will explain in Section 3.4
below, our notion of model fragility is also based on the moment restrictions, specifically their
sensitivity to local perturbations of the underlying data-generating process.14 We follow the lit-
erature (e.g., Li and M¨
                       uller, 2009; Chen and Santos, 2018), and refer to these models as GMM
models. As reflected in the original applications of GMM in asset pricing (Hansen and Single-
ton, 1982, 1983) and recently emphasized by Hansen (2014), structural asset pricing models
are typically partially specified. Further, GMM has proven particularly valuable for analyzing
structural models via focusing on key cross-equation restrictions such as Euler equations, with-
out being overly influenced by the details and potential singularities of the remainder of the
structural model. Accordingly, we adopt the semiparametric framework of GMM models.
    Specifically, we assume the moment function corresponding to the full structural model is
m(·, )  Rdm , defined on a compact parameter set   Rd with nonempty interior, and denote
the full GMM model by Q,


(16)     Q = Q  H : EQ [m(·, )] = 0, for some    ,


which is a collection of probability measures under which the moment restrictions hold for some
parameter vector . The system of moment restrictions is over-identified; that is, the number
of model parameters is less than that of moment restrictions (i.e., d < dm ).
    We assume that the moment function m(·, ) has a recursive structure:
                                                                                           
                                        (1)            (1)                           (1)
                                  m (yt-1 , yt ,  )                               
(17)     m(yt-1 , yt , ) =                                         ,   with  =             .
                                  (2)            (1)         (2)                     (2)
                                m (yt-1 , yt ,  ,  )                              


  13
      Technically, the model parameters may vary with the sample size n, though they do not depend on the
time index t  {1, · · · , n}.
   14
      Kocherlakota (2016) adopts a similar notion in studying the sensitivity of real macro models to the speci-
fication of the Phillips curve.
18         HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

Here (1) is a d,1 -dimensional sub-vector of , with d,1  d , and m(1) (·, (1) ) has dimension
dm,1  d,1 . The baseline moments can be represented by a selection matrix m,1 :


(18)     m(1) (yt-1 , yt , (1) ) = m,1 m(yt-1 , yt , ), with m,1  I, 0dm,1 ×(dm -dm,1 ) .


The assumption of the recursive structure for the moment function enables us to examine the
fragility of a subset of moment restrictions, namely those in m(2) (·, ). Such recursive structures
are common in asset pricing. For example, the moments m(1) (·, (1) ) could be derived from a
statistical model of the real quantities (such as consumption), while the additional moments
m(2) (·, ) may apply to the joint dynamics of the real quantities and asset prices. Since the
first coordinate block of the moment function m(·, ) only depends on (1) , the Jacobian matrix
D() is block lower triangular:
                                      
                    D11 ()        0
(19)     D ( ) =                       , where Dij ()  EQ (j) m(i) (·, ) and i, j = 1, 2.
                    D12 () D22 ()


Corresponding to the first coordinate block m(1) (·, (1) ) of the moment function m(·, ) in (17),
we define the baseline GMM model Q(1) ,


(20)     Q(1) = Q  H : EQ m(1) (·, (1) ) = 0 for some (1)  (1) .


The baseline model is a collection of probability measures under which the first block of moment
restrictions, hereafter referred to as the baseline moments, hold for some parameter vector (1) .
This definition is analogous to the definition of the full model, and clearly Q  Q(1) . The
subvector (2) can only be identified by the moment restrictions not contained in the baseline
model. We refer to (2) as the nuisance parameters.
     Although economic models often feature conditional moment restrictions, for estimation and
testing, it is common to focus on a finite number of implied unconditional moment restrictions
by using nonlinear instrumental variables (e.g., Hansen and Singleton, 1982, 1983; Hansen,
1985; Nagel and Singleton, 2011). For simplicity, we take these unconditional moments as the
starting point in our analysis.
     Following the definition of the full structural model (16), we define a mapping from the
probability measure of the bivariate marginal distribution Q  Q to model parameters ,  =
                             DARK MATTER IN ASSET PRICING MODELS                            19

(Q), such that


(21)    EQ [m(·, (Q))] = 0.


Calibrated models

Consider a calibrated model parameter value 0  int(), the interior of , such that the
moment restrictions evaluated at 0 hold under some Q0  Q:


(22)    EQ0 [m(·, 0 )] = 0.


Note that Q0 remains unknown to the econometrician, even though 0 may be known. The
calibrated full and baseline GMM models are sets of probability measures satisfying


(23)       Q(0 )  Q  H : EQ [m(·, 0 )] = 0 , and
              (1)                                (1)
(24)    Q(1) (0 )  Q  H : EQ m(1) (·, 0 ) = 0 , respectively.


By definition, Q(0 )  Q. Moreover, Q(0 ) is non-empty (due to the assumption for 0 ). We
pick one distribution from Q(0 ) and denote it by Q0 , which is a distribution under which the
moment restrictions of the full model hold under the calibrated parameters 0 .


                                 3.2. The Efficient GMM Estimation

Under the distribution Q0 , the spectral density matrices (at zero frequency) for the baseline
and full models are
                    
(25)    11 =           EQ0 m(1) (y0 , y1 , 0 )m(1) (yt-1 , yt , 0 )T , and
               t=-
                 
(26)      =            EQ0 m(y0 , y1 , 0 )m(yt-1 , yt , 0 )T , respectively,
               t=-


where 11 is the upper-left block of . We assume that both  and the Jacobian matrix D
are known. In general, computing the expectations requires knowledge of the distribution Q0 .
When Q0 is unknown in practice, expectations can be replaced by their consistent estimators.
For example, several consistent estimators of the covariance matrices are provided by Newey and
West (1987), Andrews (1991), and Andrews and Monahan (1992). These estimation methods
20         HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

usually require a two-step plug-in procedure introduced by Hansen (1982) when 0 is unknown.
We further assume that  = I , which is innocuous because we can always rotate the system
without altering the structure (Hansen, 2007b). More details are provided in Appendix G.1.
     For any given , we define

                                         (1)
         mt ()  m(yt-1 , yt , ) and mt ((1) )  m(1) (yt-1 , yt , (1) ),


and denote the empirical moment functions for the full and baseline GMM models by

                      n                                n
                1                                  1           (1)
         mn ()             mt () and   m(1) (1)
                                        n ( )                mt ((1) ), respectively.
                n    t=1
                                                   n   t=1


                                  ^n of the full model and that of the baseline model  (1)
                                                                                      ~n
Then, the efficient GMM estimator 
minimize

                                                                       2
(27)     J (, yn )  n |mn ()|2 and J (1) ((1) , yn )  n m(1) (1)
                                                         n ( ) , respectively.




            3.3. Information Matrices Based on Unconditional Moment Restrictions

We now introduce information matrices for the GMM models. In statistics and econometrics,
information regarding model parameters is often quantified by the efficiency bound on parameter
estimators. One example is the Fisher information matrix for a given parametric family of
likelihood functions, which is justified by the Cram´
                                                    er-Rao efficiency bound under the minimax
criterion. The same idea can be extended to semiparametric models (e.g., Bickel, Klaassen,
Ritov, and Wellner, 1993).
     In this paper, we extend the semiparametric efficiency bound result for unconditional mo-
ment restrictions of Chamberlain (1987, Theorem 2) from i.i.d. data-generating processes to
Markov processes with local instability. In Appendix B, we show that the optimal GMM covari-
ance matrix derived by Hansen (1982) achieves the semiparametric minimax efficiency bound
for unconditional moment restrictions with Markov data-generating processes that are locally
unstable. We denote


(28)     D  D(0 ) and Dij  Dij (0 ) for i, j = 1, 2.


Then, the information matrices for (1) in the baseline model and for  in the full model,
                          DARK MATTER IN ASSET PRICING MODELS                                 21
              (1)
evaluated at 0 and 0 , respectively, are
                                                                               
                                              T             T         T
              T
                                             D11 D11   +   D21 D21   D21 D22
(29)    IB = D11 D11 and IQ = DT D =                                           .
                                                   T                  T
                                                  D22 D21            D22 D22

                                                                                      (1)
We define the marginal information matrix for (1) in the full model, evaluated at 0 , as

                          -1
(30)    IF = ,1 I- 1 T
                 Q ,1          , where ,1  I, 0d,1 ×(d -d,1 ) ,


which accounts for the uncertainty concerning the nuisance parameters (2) when gauging the
information about (1) provided by the moment restrictions. Based on the inversion rule of
partitioned matrices, the marginal information matrix IF can be rewritten as


(31)          T
        IF = D11        T
                 D11 + D21                           T
                           2 D21 , with 2  I - D22 (D22 D22 )-1 D22
                                                                 T
                                                                    .


Although our objective is to measure model fragility, in Section 3.4 we introduce a measure
of the incremental informativeness of the moment restrictions about model parameters. We
then argue that this informativeness measure is intuitively connected to the notion of model
sensitivity described earlier in Section 2, and we shall formally establish the link between our
informativeness measure and model fragility in Sections 4 and 5.


                                  3.4. The Dark Matter Measure

In this section, we ask how informative the moment restrictions are regarding the model pa-
rameters (1) . Since (1) appears in both the baseline moment restrictions and the additional
moment restrictions in the full model, the cross-equation restrictions provide additional infor-
mation about (1) above and beyond the baseline model. The informativeness of the moment
restrictions naturally depends on the sensitivity of the moments to changes in model parame-
ters. If a small change in the parameter values can dramatically change the value of the moment
function (i.e., high sensitivity), then imposing the moment restrictions empirically will tend to
greatly restrict the parameter estimates (i.e., the moment restrictions are informative).
   Before introducing our information measure, we discuss the relevant regularity conditions,
including smoothness, rank, and identification.

Assumption 1 (GMM Regularity Conditions) We assume that the moment function m(·, ),
22          HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

defined on a compact set , satisfies the following regularity conditions:
  (i) The moment restrictions are over-identified: d < dm ;
              (1)                                                         (1)
 (ii) EQ0 [mt ((1) )] = 0 and EQ0 [mt ()] = 0 only when (1) = 0 and  = 0 ;
(iii) mt () is continuously differentiable in , and D has full column rank.


Remark 1 The compactness of  and the assumption 0  int() are the standard reg-
ularity conditions to ensure the uniform law of large numbers (ULLN) and the first-order-
condition characterization of GMM estimators, respectively. Condition (i) is the standard over-
identification condition in GMM (Hansen, 1982). Condition (ii) is also a standard identification
assumption to ensure that the sequence of GMM estimators has a unique limit (Hansen, 1982).
Condition (iii) is the rank condition for moment restrictions, and is the sufficient condition for
local identification enabling us to consistently estimate 0 .


      We now introduce our dark matter measure.


Definition 1 Let the incremental information matrix of the full model relative to the baseline
models be

                1/2         1/2
(32)        IF I-1
                B IF - I.


The dark matter measure is defined as the largest eigenvalue of , denoted by15


(33)       (0 )  max vT v.
                    |v|=1



      To better understand the dark matter measure, we rewrite it as

                            vT I-1
                                B v
(34)       (0 ) = max            1 - 1.
                    |v|=1   vT I-
                                F v



As Equation (34) shows, our measure effectively compares the asymptotic covariance matrices
of the two estimators of (1) : the matrix based on the baseline model, and the matrix based on
the full model. It is the largest ratio, over all possible directions v  Rd,1 , of the two asymptotic
variances of the efficient GMM estimator for a linear combination of model parameters vT (1)
under the baseline and full models.
     15
    We focus on the one-dimensional worst-case fragility. There are straightforward extensions to the cases in
which v is a matrix.
                           DARK MATTER IN ASSET PRICING MODELS                                     23

   Equation (34) shows that the dark matter measure has a natural "effective-sample-size"
interpretation. This equation gives the minimum sample size required for the estimator of the
baseline model to match the asymptotic precision (the inverse of the variance) of the estimator
of the full structural model in all directions of the parameter space. Because asymptotic variance
scales inversely with the sample size, the effective sample size is n [1 + (0 )].
   Our dark matter measure isolates the information provided by the structural model above
and beyond the baseline model. For the same structural model, alternative choices of the baseline
model affect the magnitude of the dark matter measure. To this point, we have been silent on the
question of how the baseline model should be chosen in relation to the full structural model.
In general, there is no hard rule for this choice, beyond the technical requirement that the
associated baseline parameters (1) be identified by the baseline model. Desirable choices of the
baseline model depend on which aspects of the model the fragility analysis aims to capture.


                        4. LOCAL MISSPECIFICATION AND INSTABILITY

A formal analysis of model fragility requires a framework for misspecification and instability.
We adopt a statistical method similar to that of Hansen and Sargent (2001): the econometrician
treats P0 as an approximation of the true data-generating process by taking into account a class
of alternative data-generating processes that are statistically difficult to distinguish from Q0
(i.e. a neighborhood of Q0 in the space of probability measures) and assuming that the true
process lies in such a collection of local alternatives. To model instability, we generalize the local
instability framework of Li and M¨
                                 uller (2009) to the semiparametric setting, which provides a
general econometric playground within which we analyze GMM model properties.
   We first specify the true local data generating process in Subsection 4.1. We then intro-
duce the concept of model misspecification in Subsection 4.2, and extend our framework by
incorporating the concept of local instability in Subsection 4.3.


                              4.1. Local Data-Generating Processes

Our analysis is local in nature. We focus on a calibrated model with model parameter 0 as
defined in (22), with the corresponding bivariate marginal distribution Q0 . To characterize
the locally perturbed models, we define the collection of local perturbations of Q0 , denoted by
N(Q0 ), as follows. Note that N(Q0 ) is a subset of L2 (Q0 ), the space of square-integrable random
variables on the probability space (Y × Y, F  F, Q0 ).
24            HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

Definition 2 The collection N(Q0 ) consists of the one-dimensional parametric family of
bivariate distributions Qs,f indexed by s  (- , ) for some > 0 and f  L2 (Q0 ), such that the
path Qs,f  H passes through the probability measure Q0  H at s = 0, and Qs,f satisfies the
smoothness condition (Hellinger-differentiability condition):16

            dQs,f
(35)              = 1 + sf + s(s),
             dQ0

where (s) converges to 0 in L2 (Q0 ) as s  0. Here, we refer to the scalar measurable function
f  L2 (Q0 ) as the "score" of the parametric model s  Qs,f .

Proposition 1 (Necessary Properties of Scores) If f  L2 (Q0 ) satisfies (35), then it follows
that (i) EQ0 [f ] = EQ0 [(s)] = 0 for all s, and (ii) EQ0 [f (y, y )|y] = EQ0 [f (y , y)|y].


Now, appealing to the concept in Definition 2, we specify the true local data-generating process.
We denote the joint distribution of yn corresponding to the bivariate marginal distribution
Q0 by P0,n . Deviating from P0,n , the true local data-generating process for yn has the joint
distribution Pn with a sequence of bivariate marginal distributions for each consecutive pair

(yt-1 , yt ), Q      
               n  Q1/ n,fn,t
                          , which is characterized by




            dQ1/n,fn,t
                                
                               fn,t
(36)                     = 1 +  + n , where
               dQ0               n
                      
                                                             
(37)                 fn,t  [1, b (t/n)]g  (yt-1 , yt ) and      nn  0 in L2 (Q0 ).

                                         T
The vector g  has two elements: g  = [g1               
                                         , g2 ] with g1                                  
                                                        , g2  L2 (Q0 ). In other words, fn,t =
                   
g1 (yt-1 , yt ) + g2 (yt-1 , yt )b (t/n) where g1
                                                                                                 
                                                  represents time-invariant perturbation, while g2 mul-
tiplied by b(t/n) represents time-varying perturbation (i.e., local instability). The unknown
function b (·) is a deterministic function on [0, 1] that generates local instability.17 When n is
            
                 
large, 1 + fn,t / n is approximately the Radon-Nikodym density of Q1/n,fn,t        with respect to
Q0 .
                                                                             
       Prior to imposing additional regularity conditions on the true score fn,t , we define a set of
square-integrable variables corresponding to Q0 .
     16
      The smoothness condition (35) is equivalent to the Hellinger-differentiability, shown in Appendix G.2. It is
a common regularity condition adopted for (semi)parametric inference (e.g., van der Vaart, 1988).
   17
      Similar to, for example, Andrews (1993), Sowell (1996), and Li and M¨   uller (2009), we assume instability
to be non-stochastic in contrast to, for example, Stock and Watson (1996, 1998), Primiceri (2005), and Cogley
and Sargent (2005). The assumption is for technical simplicity. We can extend from non-stochastic to stochastic
instability following the arguments in Li and M¨uller (2009).
                           DARK MATTER IN ASSET PRICING MODELS                                            25

Definition 3 (Set of Scores)         For Q0  Q, define


(38)    L2           2
         0 (Q0 )    L (Q0 ) : E
                                Q0
                                   [ (y, y )] = 0 and EQ0 [ (y, y )|y] = EQ0 [ (y , y)|y] .


Given the notation L2
                    0 (Q0 ), the necessary conditions for scores derived in Proposition 1 can be
                                                                               
restated as f  L2
                0 (Q0 ). We then make the following assumption about the true fn,t .


Assumption 2 (Local Data-Generating Process)               The true local data-generating process in
(36) satisfies the following conditions:
  (i) g   G(Q0 ), which is defined as


              G(Q0 )  g = [g1 , g2 ]T : EQ0 [g2 (y, y )|y] = 0 and g1 , g2  L2
                                                                             0 (Q0 ) ;



 (ii) b  B, which is defined as
                                                                  1
                                                                                             
                           |b(u)|  1 for all u  [0, 1] and
                                                                                             
                                                               b(u)du = 0, whose path has a 
              B b:                                           0                                .
               
                           finite number of discontinuities and one-sided limits everywhere.
                                                                                             

                                                                                    
Remark 2 The first part of Assumption 2 (i) implies that EQ0 fn,t (y, y )|y = EQ0 [g1 (y, y )|y]
is invariant over time, which further ensures that the univariate marginal distribution of the
true joint distribution Pn is invariant over time (Proposition 3). The second part of Assumption
             
2 (i) that g1 , g2  L2
                     0 (Q0 ) is not restrictive since it is guaranteed by Proposition 1.



   Next, we impose additional assumptions about the heteroskedasticity of the locally unsta-
ble data-generating process under consideration, thereby extending the statistical setting of
Andrews (1993), Sowell (1996) and Li and M¨
                                          uller (2009) to the semiparametric setting.

Assumption 3 (Tail Properties of Local Instability) As n  , it holds that under Q0
  (i) n-1 max1tn |g (yt-1 , yt )|2 = op (1);
 (ii) EQ0 [|g (yt-1 , yt )|2+ ] < , for some  > 0.

Remark 3       Condition (i) is needed for establishing the results on the law of large num-
bers (LLN) of Lemma 4 of Li and M¨
                                 uller (2009), which we use throughout in our proofs.
                               n                                                   n
Condition (ii) implies n-1     t=1   EQ
                                      t-1 [|g (yt-1 , yt )|
                                        0                  2+
                                                              ] = Op (1) and n-1   t=1   |g (yt-1 , yt )|2+ =
Op (1). Condition (ii) is needed for establishing the local asymptotic normality (LAN) for time-
26            HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

inhomogeneous Markov processes (see Proposition 5 in Appendix A) and thus ensuring that the
locally unstable data-generating process is contiguous to the stable data-generating process (see
Corollary 2 in Appendix A). Condition (ii) is also a commonly adopted assumption (e.g., Li
and M¨
     uller, 2009, Lemma 1). A direct implication of Assumption 3 is the LLN and CLT of
partial summations of score functions.


     Finally, we extend the global identification condition in Assumption 1 (ii) from the reference
distribution Q0 to its perturbations.

Assumption 4 (Global Identification Condition) There exists               > 0 such that (Qs,f ) is
unique if it exists, for all Qs,f  N(Q0 ) with the Hellinger distance H2 (Qs,f , Q0 ) < .

Remark 4 We define the collection of perturbed distributions N(Q0 ) in Definition 2, and the
mapping (·) in (21). This assumption ensures that the sequence of GMM estimators has a
unique limit when the true distribution is a perturbation of Q0 .


                                4.2. Misspecification of GMM Models

Regularity conditions on moments

Assumption 5 (Tail Properties of Moments) We assume that the moment function m(·, ),
defined on a compact set , satisfies the following conditions:
  (i) EQ0 [|mt (0 )|2+ ] <  for some  > 0, and EQ0 [sup || mt ()||2
                                                                  S ] < ,

 (ii) n-1/2 max1tn |mt (0 )| = op (1),
        
(iii)         EQ0 [|t |2 ] < , with t  EQ0 [mt (0 )|F1 ] - EQ0 [mt (0 )|F0 ],
        t=1
where || · ||S is the spectral norm of matrices, and the information set Ft is the sigma-field
generated by {yt-j }j =0 .


Remark 5 Conditions (i) and (ii) are needed to establish the functional central limit theo-
rem (invariance principle) of McLeish (1975b) and Phillips and Durlauf (1986). Condition (i)
imposes restrictions on the amount of heteroskedasticity allowed in the observed moment series
and their gradients, which also ensures the uniform square integrability of the moment function.
This condition is commonly adopted in the literature (e.g., Newey, 1985a; Andrews, 1993; Sow-
ell, 1996; Li and M¨
                   uller, 2009, for similar regularity conditions). Condition (iii) states that the
incremental information about the current moments between two consecutive information sets
                               DARK MATTER IN ASSET PRICING MODELS                             27

eventually becomes negligible as the information sets recede in history from the current observa-
tion. This condition ensures the martingale difference approximation for the temporal-dependent
moment function as in Hansen (1985), which plays a key role in analyzing the semiparametric
efficiency bound based on unconditional moment restrictions (see Proposition 7 in Appendix A
and Theorem 4 in Appendix B).


Tangent space and misspecification

For a given f  L2
                0 (Q0 ), we further require that the path of locally perturbed distributions

satisfies Qs,f  Q and that (Qs,f ), as a function of s, is differentiable with respect to s at
s = 0. The collection of such scores f is defined as follows:
                                                                                              
                                      a path Qs,f such that Qs,f  Q  N(Q0 ) for all s  (- , ) 
       T (Q0 )       f  L2
                         0 (Q0 ) :                                                             .
                                     for some > 0 and (Qs,f ) is differentiable at s = 0      


We refer to the set T (Q0 ) above as the tangent set of Q at Q0 . We further characterize the
tangent set T (Q0 ) as follows:


(39)      T (Q0 ) = f  L2
                        0 (Q0 ) : (f )  lin(D ) , with (f )  E
                                                              Q0
                                                                 [m(·, 0 )f ] ,


where (f ) is a linear operator on L2
                                    0 (Q0 ) and linear space lin(D ) is spanned by the columns

of the Jacobian matrix D defined in (28). This characterization is standard in the literature
(e.g., Severini and Tripathi, 2013; Chen and Santos, 2018) and can be proved using an implicit
function theorem. Equation (39) implies that T (Q0 ) is a linear space. Whenever fn,t
                                                                                  
                                                                                       L2
                                                                                        0 (Q0 ) \

T (Q0 ), the GMM model Q is locally misspecified with respect to the true local data-generating
process (yt-1 , yt ), Q      
                       n  Q1/ n,fn,t
                                  , defined in (36).



   One direct implication of (39) is that, if d < dm , then T (Q0 ) = L2
                                                                       0 (Q0 ), and thus the

distribution Q0 is locally overidentified by Q (Chen and Santos, 2018); further, if dm = d , then
T (Q0 ) = L2
           0 (Q0 ), and thus Q0 is locally just identified by Q.

   Similar to (39), the tangent set of the baseline GMM model Q(1) at Q0 is characterized by

                                                                                  (1)
(40)      T (1) (Q0 )  f  L2   (1)                     (1)
                           0 :  (f )  lin(D11 ) , with  (f )  E
                                                               Q0
                                                                  m(1) (·, 0 )f ,


where operator (1) (f ) is a linear operator on L2
                                                 0 (Q0 ), linear space lin(D11 ) is spanned by the
                                         (1)
column vectors of D11 , and m(1) (·, 0 ) contains the top dm,1 elements of m(·, 0 ).
28          HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

                         4.3. Local Instability of Data-Generating Processes

To formalize the analysis on out-of-sample fit (i.e. external validity), we need to consider data-
generating processes that allow for structural breaks in a non-stationary manner. More precisely,
we consider the set M(Q0 ) consisting of all probability measures, each of which is a joint
distribution for yn following a Markov process with local instability around a Markov process
characterized by Q0 . Now, we formalize the definition of M(Q0 ) as follows.

Definition 4     The collection M(Q0 ) contains all join distributions P1/n,g,b , for local Markov
data-generating processes, characterized by a sequence of bivariate marginal distributions Qs,fn,t 
N(Q0 ) with t = 1, 2, · · · , n and index s  (- , ) for some   > 0 such that


(41)    fn,t = [1, b(t/n)]g (yt-1 , yt ) with g  G(Q0 ) and b  B.


The unique corresponding model parameter value is also time-varying:


(42)    n,t  (Q1/n,fn,t ), for any fn,t  T (Q0 ) with 1  t  n and sufficiently large n.


Definition 4 says that all the local data-generating processes in M(Q0 ) are characterized by the
pair (g, b)  G(Q0 ) × B and sample size n. The data-generating process is a time-homogeneous
Markov process if b(u)  0 or g2 (y, y )  0. Assumption 4 ensures the uniqueness of (42).


Local moment biases

Under the local data-generating process P1/n,g,b characterized by a sequence of bivariate
marginal distributions Q1/n,fn,t for t = 1, · · · , n, the moment restrictions evaluated at 0
are locally biased. We summarize the result in Proposition 2 with the proof in Appendix D.

Proposition 2 (Local Biases of Moment Restrictions) Suppose Assumptions 1 ­ 5 hold.
Under the bivariate marginal distribution Q1/n,fn,t  M(Q0 ) for the consecutive pair (yt-1 , yt )
where fn,t = g1 (yt-1 , yt ) + g2 (yt-1 , yt )b(t/n) and (g, b)  G(Q0 ) × B, the moment restrictions
evaluated at 0 are locally biased:

          Q1/n,fn,t                                               
(43)    E             [mt (0 )] = [(g1 ) + (g2 )b(t/n)] / n + o 1/ n ,


where the linear operator (·) is defined in (39).
                              DARK MATTER IN ASSET PRICING MODELS                                              29

                              5. WHY IS MODEL FRAGILITY A CONCERN?

We specify the notion of model fragility using high sensitivity of moment restrictions to local
perturbations in the data-generating process. Using the semiparametric framework in Section
4, we now show that a fragile model lacks internal refutability and external validity. More
specifically, we show that our dark matter measure is inversely linked to the power of the C
test (i.e. internal refutability) and the out-of-sample fit (i.e. external validity) in Sections 5.1
and 5.2, respectively.
    The baseline GMM model plays a special role in the test power and out-of-sample fit analyses
                                                                                        (1)
as a "benchmark", characterizing the correct baseline parameter values n,t and discipline the
asset pricing cross-equation restrictions.


Assumption 6 (Correct Baseline GMM Model) We assume that the true local data-generating
process with a joint distribution P1/n,g ,b satisfies

                                 
(44)     (1) (g1 ) = 0 and (1) (g2 )  lin(D11 ),


where the linear operator (1) (·) is defined in (40).18


Remark 6 Assumption 6 ensures that the baseline GMM model is correctly specified since
(1) (fn,t ) = (1) (g2 )b(t/n)  lin(D) for every t  {1, · · · , n}. If we define


(45)     GB (Q0 )  g  G(Q0 ) : (1) (g1 ) = 0 and (1) (g2 )  lin(D11 ) ,


Assumption 6 can be simply rewritten as g   GB (Q0 ).


The following corollary shows the correct baseline parameters are invariant under Assumption 6.


Corollary 1 (Correct Baseline Parameters) Suppose Assumptions 1 ­ 6 hold. Then, the cor-
                               (1)
rect baseline parameters n,t  (1) (Q1/n,fn,t ) exists for fn,t = g1 (yt-1 , yt ) + g2 (yt-1 , yt )b(t/n)
with 1  t  n, and they can be approximated by

         (1)   (1)                                     
(46)                  T
         n,t - 0 = -(D11 D11 )-1 D11
                                  T (1)
                                      (fn,t )/ n + o 1/ n .
  18                                                                        
     We can replace (44) by a seemingly weaker assumption (1) (g1  ), (1) (g2 )  lin(D11 ). But, this does not add
generality, because we can always replace 0 by a sequence of new reference points (reparametrization) to ensure
that (44) is satisfied.
30          HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

                                     5.1. Test Power and Dark Matter

We now establish the connection between the dark matter measure and the local asymptotic
maximin power. We focus on a subset of alternatives satisfying b  0 to obtain an upper bound
on the maximin local power, which is characterized by the dark matter measure. A specification
test for a GMM model Q against its baseline GMM model Q(1) is a test of the null hypothesis
that there exists some parameter for which all moment restrictions hold under the true data-
generating process against the alternative that there exists some parameter for which only the
baseline moment restrictions hold. That is,


          H0 : Qn  Q vs. HA : Qn  Q    \ Q.
                                   (1)
(47)


Let n be an arbitrary GMM test statistic that maps yn to [0, 1] (e.g. Hansen, 1982; Newey,
1985a). We restrict our attention to GMM specification tests n that have local asymptotic
level  and possess an asymptotic local power function.19 More precisely, we consider the local
data-generating process P1/n,g,0 for yn with a bivariate marginal distribution Q1/n,g1 that
converges to Q0  Q(0 ) as n  .
      The test n has a local asymptotic level  if


(48)      lim sup     n dP1/n,g,0  ,
                                                g  G(Q0 ) such that g1  T (Q0 ),
            n


and the test n has a local asymptotic power function q (g, ) if


(49)      q (g, )  lim         n dP1/n,g,0 ,
                                                   g  G(Q0 ) such that g1  T (1) (Q0 ),
                      n


where   {n }n1 is the sequence of test statistics.
      Finally, a test n for (47) with a local asymptotic power function q (·, ) : G(Q0 )  [0, 1] is
said to be locally unbiased if q (g, )   for all g such that g1  T (Q0 ), and q (g, )   for
                     0 (Q0 ) \ T (Q0 ). We denote the set of locally unbiased GMM specification
all g such that g1  L2
tests with level  as  (Q0 ).

     19
     As the sample size n approaches infinity, the distance between the null hypothesis and the data-generating
process necessarily diminishes according to n-1/2 . If this distance were held fixed, then the power of all consistent
tests would tend to unity as n increases to infinity. Local power analysis, the evaluation of the behavior of the
power function of a hypothesis test in a neighborhood of the null hypothesis invented by Neyman (1937), has
become an important and commonly utilized technique in econometrics (e.g., Newey, 1985b; Davidson and
MacKinnon, 1987; Saikkonen, 1989; McManus, 1991).
                             DARK MATTER IN ASSET PRICING MODELS                                          31

   The guaranteed local asymptotic power of tests, over all feasible local data-generating pro-
cesses, can be characterized by the power of maximin tests (e.g., Lehmann and Romano, 1996,
Chapter 8). Studies have demonstrated that the C test or incremental J test (e.g., Eichen-
baum, Hansen, and Singleton, 1988) has the asymptotic optimality property in the maximin
sense (e.g., Newey, 1985a; Chen and Santos, 2018).20 Based on this observation, we establish
Theorem 1 below, which formally connects the maximin optimal power of tests to the dark
matter measure. We present the proof in Appendix C.
   We consider the set of alternatives:


(50)     A (Q0 )  g  GB (Q0 ) : |(2) (g1 )|   and (2) (g1 )  lin(D22 )


where (2) (g1 )  EQ0 m(2) (·, 0 )g1 is the bottom dm - dm,1 elements of (g1 ) defined in (39).


Theorem 1 Suppose Assumptions 1 ­ 6 hold. The local asymptotic power of maximin tests
is bounded above by

                                                           2      
(51)       sup       inf    q (g, )  M dm,2 -d,2                 , c1-       ,
          (Q0 ) g A (Q0 )
                                             2          1 + (0 )

where c1- is the 1 -  quantile of a chi-square distribution with degrees of freedom dm,2 - d,2 ,
and M (x1 , x2 ) is the generalized Marcum Q-function. By definition of c1- , it holds that

                        
(52)     M dm,2 -d,2 (0, c1- ) = .
                 2



Therefore, the local asymptotic power of maximin tests vanishes as the dark matter measure
rises:


(53)       sup       inf    q (g, )  , as (0 )  .
          (Q0 ) g A (Q0 )
         



   The generalized Marcum Q-function M (x1 , x2 ) is strictly increasing in  and x1 , and it is
strictly decreasing in x2 (e.g., Sun, Baricz, and Zhou, 2010, Theorem 1). Intuitive interpretation
of (51) is that there exists a difficult specific alternative characterized by the score g  A (Q0 )
such that the power of the optimal locally unbiased GMM specification test with level  cannot

  20
    Alternative asymptotically equivalent approaches can be found in the literature (e.g., Newey, 1985a; Chen
and Santos, 2018).
32          HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

                            2      
exceed M dm,2 -d,2        1+ (0 )
                                  , c1-     , which is almost  when (0 ) is extremely large. The
                2
coefficient  captures the extent to which the alternatives under consideration are separate
from the null, and thus, the upper bound for the test power (i.e., the right-hand side of (51))
naturally increases with .


                               5.2. Overfitting Tendency and Dark Matter

A common method adopted by economists and statisticians for assessing the external validity of
models is to hold out data from the model estimation (e.g., Schorfheide and Wolpin, 2012). The
assessment of external validity serves two important purposes: first, it mitigates the concern of
in-sample overfitting (e.g., Foster, Smith, and Whaley, 1997; Kocherlakota, 2007; Lettau and
Van Nieuwerburgh, 2008; Welch and Goyal, 2008; Koijen and Van Nieuwerburgh, 2011; Ferson,
Nallareddy, and Xie, 2013; Athey and Imbens, 2017, 2019); and second, it serves as a primary
criterion when the goal is long-run prediction (e.g., Valkanov, 2003; M¨
                                                                       uller and Watson, 2016).
The literature has emphasized that out-of-sample fit evaluation captures model specification
uncertainty, model instability, calibration uncertainty, and estimation uncertainty, in addition
to the usual uncertainty of future events (Stock and Watson, 2008).
      The holdout approach to selecting a model among competing structural models amounts
to splitting the entire time series yn  {y1 , · · · , yn } into two non-overlapping subsamples
 n                              n
ye  y1 , · · · , y   n     and yo  y       n +1 , · · ·   , yn with   (0, 1/2].21 Here, x is the largest
                                                                    n
integer less than or equal to the real number x. The first segment ye is used as the estimation
                                  n
sample, while the second segment yo is used as the holdout sample (e.g., Schorfheide and
Wolpin, 2012).22 This approach has been commonly adopted in the literature on forecasting
and model selection. Further, the holdout approach is also a natural way to investigate the long-
run forecast problems in financial and macroeconomic time series, because the salient definition
of a long-run forecast is that the prediction horizon is long relative to the sample length of the
estimation sample (M¨
                    uller and Watson, 2016, Section 5.2).
      To consider the out-of-sample fit of estimated time-series models, we focus on model insta-
bility, because the constant misspecification over time would not affect the out-of-sample fit of
estimated models based on in-sample data. Thus, in this subsection we focus on the case with
     21
      We specify an upper bound for  to prevent the out-of-sample fit problem from becoming trivial. Without
loss of generality, we choose the upper bound for  to be 1/2.
   22
      The non-overlapping equal-length estimation and holdout subsamples are standard exercises in cross-
                                                                                                 n
validation for out-of-sample fit evaluation; in the statistics and machine learning literature, ye is also referred
                              n
to as training sample, and yo as testing sample (e.g., Hastie, Tibshirani, and Friedman, 2001, Chapter 7).
                              DARK MATTER IN ASSET PRICING MODELS                                      33

(g1 )  lin(D).
   The idea is to quantify the overfitting tendency as a model property by focusing on the J
                                                (1)
statistic as the loss function. We define n,t  (1) (Q1/n,fn,t ) for t = 1, · · · , n, and

                       n                                      n
          (1)    1           (1)        (1)        1                 (1)
(54)     e,n                 n,t   and o,n                          n,t .
                 n     t=1
                                               (1 -  )n
                                                          t= n +1


More precisely, we consider the goodness-of-fit of the full set of moments under any given
baseline parameters (1) :


(55)     L((1) ; ys
                  n
                    )  J ((1) , s ((1) ), ys
                                           n        (1)
                                             ) - J (s,n      (1)
                                                        , s (s,n     n
                                                                 ), ys ), with s  {e, o}

      (1)
where s,n is the average of those correct baseline parameter values that perfectly fit baseline
moment restrictions (see (46)) and s ((1) ) is chosen to minimize the J statistic while taking
(1) as given:23


(56)     s ((1) )  argmin J ((1) , (2) , ys
                                          n
                                            ) for any fixed (1) with s  {e, o}.
                       (2)


In the definition of L((1) ; ys
                              n
                                ), we benchmark the goodness-of-fit measure against the J statistic
                                                              (1)
evaluated at the average of correct baseline parameter values s,n for s  {e, o} to control the
mechanical influence of instability on the J statistic. The lower the goodness-of-fit measure
L((1) ; ys
         n
           ), the better the baseline parameter value (1) fits the moments in the sample ys
                                                                                          n
                                                                                            with
s  {e, o}. Importantly, by minimizing over all possible values of the nuisance parameters (2) ,
the measure L((1) ; ys
                     n
                       ) captures the best possible fit of the parameter value (1) only.
   We consider a GMM estimator of the baseline parameters (1) , denoted by (1) , based on
                                                                           e,n

                       n
the estimation sample ye and all moment restrictions. We then assess the out-of-sample fit of
(1) on the holdout sample by looking at the magnitude of the expected out-of-sample fitting
 e,n


error   L((1) , yn )dP1/n,g,b . The overfitting measure of the estimator (1) can be defined as the
          e,n    o                                                        e,n

extent to which the out-of-sample fitting error is larger than the in-sample fitting error:


(57)     O((1) , yn )  1 L((1) , yn ) - L((1) , yn ) .
           e,n             e,n    o       e,n    e
                       2


  23
    Mathematically, the formulation (55) and (56) follow the generic recursive GMM estimation procedure in
Hansen (2007b) and Hansen (2012).
34          HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

The asymptotic expected overfitting measure of the sequence of estimators (1) is                     24
                                                                          e,n




(58)       (g, b, (1) )  lim lim        O((1) , yn )1 (1) n          dP1/n,g,b ,
                  e
                          l n
                                          e,n        {|O(e,n ,y )|l}



where (1)         (1)
                             is a sequence of GMM estimators.  (g, b, (1) ) quantifies the extent
      e           e,n   n1                                            e

to which the structural model over-fits the data when the true local data-generating process
is P1/n,g,b . Similar in spirit to information criteria in model selection such as AIC and BIC,
models whose expected overfitting measures are sizable compared with those of other models
that fit the sample data equally well in sample should be penalized.



Two types of estimators

Here we focus on two particular estimation procedures ­ the efficient GMM estimation procedure
and the recursive GMM estimation procedure.25 The former is designed to use the identification
                                                                                               (2)
strength provided by the additional asset pricing moment restrictions EQ0 mt () = 0 as
much as possible, while the latter does not use any identification assumptions imposed by the
                                                             (2)
additional asset pricing moment restrictions EQ0 mt () = 0. The identification strength is a
nontestable assumption postulated by the structural model. The literature on recursive GMM
estimation is substantial and dates back decades (e.g., Christiano and Eichenbaum, 1992; Ogaki,
1993; Newey and McFadden, 1994; Hansen and Heckman, 1996; Hansen, 2007b; Lee, 2007;
Hansen, 2012). While the original impetus of the recursive GMM estimation was primarily
computational, we advocate it as a more robust procedure against potential instability and
misspecification since the procedure barely relies on the nontestable assumption of identification
                                                           (2)
strength of the additional moment restrictions mt (); the robustness of the recursive GMM
estimation procedure is especially valuable when the dark matter measure is excessively large.
    Characterized by selection matrices, the efficient GMM estimator and the recursive GMM
estimator based on the estimation sample yn , denoted by   ^e,n and ~e,n respectively, have the
                                                      e

selection matrices A = D and A = diag{D11 , A22 } with the (constrained) efficient selection
                                              -1
                  T
matrix A22  D21 (D11 D11 )-1 D21
                              T
                                 +I                D22 (Hansen, 2007b).


     24
     The method of first calculating the truncated statistic, then letting the ceiling l increase to infinity, is
commonly adopted in the literature for technical simplification (e.g. Bickel, 1981; Le Cam and Yang, 2000;
Kitamura, Otsu, and Evdokimov, 2013).
  25
     The recursive GMM estimation procedure is also referred to as the sequential (two-step) GMM estimation
procedure in the literature.
                               DARK MATTER IN ASSET PRICING MODELS                              35

Overfitting of the efficient GMM estimator ^e,n

Recall that (g2 ) captures the magnitude of instability. We consider the set of possible magni-
tudes of instability U (Q0 )  {g  GB (Q0 ) : |(g2 )|  }. A larger  allows for a higher degree
of instability in the fragility analysis.


Theorem 2 Suppose Assumptions 1 ­ 6 hold. The overfitting of the efficient GMM estimator
^e,n based on the estimation sample yn is defined as the worst-case asymptotic expected overfitting
                                            e

measure. It is characterized by the dark matter measure:


(59)         sup         (g, b, ^(1) ) = d,1 + c( ) (0 )2 ,
                                 e
         g U (Q0 ),bB



where c( )   1 +         
                      1 -  with 0 <   1/2. Therefore, the asymptotic expected overfitting
of the efficient GMM estimator sequence ^e  ^e,n  can be arbitrarily large, being linearly
                                                              n1
related to the dark matter measure.


   The overfitting of the efficient GMM estimator has two sources. The first term d,1 cap-
tures the traditional overfitting due to the sampling uncertainty in the estimation sample (see
Theorem 3), while the second term c( ) (0 )2 captures the overfitting due to potential mis-
specification and instability. The latter component is the focus of our paper and directly depends
on the dark matter measure. The second component, c( ) (0 )2 , vanishes if there is no local
instability (i.e.,  = 0).


Overfitting of the recursive GMM estimator ~e,n

Theorem 3 Suppose Assumptions 1 ­ 6 hold. The overfitting of the recursive GMM estimator
~e,n based on the estimation sample yn is defined as the worst-case asymptotic expected overfitting
                                            e

measure, which only depends on the number of baseline parameters:


(60)         sup         (g, b, ~(1) ) = d,1 ,
                                 e
         g U (Q0 ),bB


where U (Q0 )  {g  GB (Q0 ) : |(g2 )|  }. Therefore, the overfitting of the recursive GMM
estimator sequence ~e  ~e,n    is determined by model parameter dimensionality, not affected
                                     n1
by the dark matter of the model.
36          HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

     The results above echo the traditional information criteria such as AIC and BIC, where the
number of parameters captures the overfitting tendency due to sampling uncertainty. The re-
cursive GMM estimator is not affected by the nontestable assumptions of identification strength
                     (2)
imposed by EQ0 mt () = 0, thus its overfitting is not affected by the misspecified (local)
instability. Importantly, Theorem 3 suggests that the recursive GMM estimator provides a ro-
bust estimator for models with large dark matter measures (i.e. large (0 )) and thus subject
to severe (local) instability concerns (i.e. large U (Q0 )).




Instability of the efficient GMM estimator

Intuitively, the formal results about out-of-sample fit above can be appreciated through the
sensitivity of efficient GMM estimators to local instability (see Panel C of Figure 1). We consider
a local perturbation of the model from Q0 in the direction of g  GB (Q0 ) with instability b  B.
According to Proposition 6 (in Appendix A),
                                    
               1
                                                                       
                          m (
                           t 0 )
                 n     tn
                                     d  me            me    (g, b,  )
                                                         = e
(61)                                 -      , with E                   ,
         
                 1
                        t>n mt (0 )     mo            mo   o (g, b,  )
              (1 -  )n

where (me , mo ) are independent normals with the identity covariance matrix and means:

                                                                                                         
                     (g )    T                                            (g )    T         1-
(62)     e (g, b,  )                                     and o (g, b,  )                    1            .
                                                                                                         
                                                                           1-
                                                                               
                                                 b(u)du                                         b(u)du
                                          0                                              


Further, Proposition 9 (in Appendix A) shows that the in- and out-of-sample estimators satisfy


              
                                                                                                             
                   ^(1)      (1)                       ^(1)                 ^(1)
                n(e,n - e,n )                          e                    e                     (g, b,  )
(63)                                  d
                                      -                      , with E             = -(LF - LB )  e           ,
                        ^(1)     (1)                    (1)
                                                       ^o                    (1)
                                                                            ^o
             (1 -  )n( -  )o,n      o,n                                                          o (g, b,  )

                                          ^ ^                   (1)   (1)
where LB  I-1 T                -1 T
           B D11 m,1 , LF  ,1 IQ D , and (e , o ) are independent normals with co-

variance matrix I-1
                 F . Therefore, the amount of estimator instability (normalized by covariance

matrix I- 1
        F ) as a function of moment instability is



          1/2 ^(1) - ^(1) =  E [mo - me ] ,
(64)     IF E  e,n    o,n
                              DARK MATTER IN ASSET PRICING MODELS                                37
                 1/2
where  = -IF (LF - LB ). The largest sensitivity can be captured by the spectral norm of the
sensitivity matrix  ; that is || ||S =     (0 ). Thus, a large dark matter measure implies high
sensitivity in the form of severe instability of the efficient GMM estimator out of sample versus
in sample.
   This result resembles that of Andrews, Gentzkow, and Shapiro (2017), but there are two
key differences. When there is no nuisance parameter (i.e., (1) = ), LF is the same as the
sensitivity matrix in Andrews, Gentzkow, and Shapiro (2017). Relative to their measure, we
add a baseline GMM model as a benchmark (replacing LF by LF - LB ), and we normalize the
expected change in the efficient GMM estimator by its asymptotic covariance matrix in the full
                      ^(1) -             1/2
                              ^(1) ] by IF
model (multiplying E[   e,n      o,n         ).




                              6. EXAMPLES AND SIMULATION STUDIES


We now use the dark matter measure to analyze a rare disaster model, one of the leading
consumption-based asset pricing models. We analyze a long-run risk model in Appendix H.
   Rare economic disasters are a natural source of "dark matter" in asset pricing models. It
is difficult to evaluate the likelihood and magnitude of rare disasters statistically. Yet, agents'
aversion to large disasters can have large ex-ante effects on asset prices. In this subsection, we
use our measure to analyze a disaster risk model similar to Barro (2006).
   The model specifies the joint dynamics of the log growth rate of aggregate consumption
(endowment) gt and the excess log return on the market portfolio rt . There is an observable state
variable zt , which follows an i.i.d. Bernoulli distribution and is equal to one with probability p.
When zt = 1, the economy is in a disaster regime, while the normal regime corresponds to zt = 0.
In the normal regime, the log consumption growth gt = ut , which is i.i.d. normal, ut  N (µ,  2 ).
In a disaster state, gt = -vt , where vt follows a truncated exponential distribution with density

             i.i.d.
(65)    t  1{vt > v }e-(vt -v) .


Here the lower bound for disaster size is v and the average disaster size is v + 1/ .
   The joint distribution of log consumption growth gt and excess log return rt changes with
the underlying state zt . When the economy is in the normal regime (zt = 0), gt and rt are
38         HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

jointly normal, and

                 
(66)     rt =  +  (gt - µ) +       1 - 2  0,t ,
                 

where 0,t is i.i.d. standard normal. The parameter  is the return volatility in the normal regime,
while  is the correlation between return and consumption growth in this regime. When the
economy is in a disaster state (zt = 1), gt = -vt , and


(67)     rt = gt + 1,t ,


where 1,t is i.i.d. standard normal.
     Next, we assume that the representative agent has a constant relative risk aversion utility
                    t 1-D
function ut (ct ) = D ct  /(1 - D ), where D > 0 is the coefficient of relative risk aversion and
D < 1 is the time preference parameter. The log equity premium, r  E[rt ], is available in
closed form (see Appendix F for details) as follows:


(68)     r(p,  ) = (1 - p) - p (v + 1/ ) ,    where
                                                                                 2
                2        D2 2
                                 p                                   eD v   e 2 +(D - )v
(69)       D  -   + eD µ- 2 ( )     , with ( ) =                          -                  .
                2               1-p                                   - D    + - D

The term  in (68) is the log equity premium in the normal regime. The first two terms of 
in (69) describe the market risk premium due to Gaussian consumption shocks; the third term
is the disaster risk premium, which explodes as  approaches D from above. In other words,
there is an upper bound on the average disaster size for the equity premium to remain finite,
which also limits how heavy the tail of the disaster size distribution can be.
     The fact that the equity premium explodes as  approaches D is an important feature of
our version of the disaster risk model. No matter how rare the disasters are (i.e., a very small
p), an arbitrarily large equity premium can be generated as long as the average disaster size is
sufficiently large (or equivalently,  is sufficiently small). Extremely rare but large disasters can
be consistent with the data in the sense that they are difficult to rule out based on the observable
data (and standard statistical tests). Below we illustrate how our dark matter measure can
detect and quantify the fragility of these models.
     To apply our framework to the disaster risk model, we first formulate the economic model
                          DARK MATTER IN ASSET PRICING MODELS                                  39

above as a GMM model Q with the (transformed) moments:
                                                                    
                             zt - p
        mt () = ()-1/2 
                                                             
(70)                    gt - (1 - zt )µ + zt (v + 1/ )
                                                             .
                                                             
                                              
                        rt - (1 - zt )  +   (gt - µ) - zt gt

The first two moments in mt () are the baseline moments, the third is the asset pricing moment,
and () is the asymptotic covariance matrix of the untransformed moments. To simplify the
example, we focus on the parameters  = (p,  ) when constructing the dark matter measure,
while treating the parameters (D , µ, , v, , , ,  ) as auxiliary parameters fixed at known values,
making them a part of the functional-form specification. In other words, the nuisance parameter
vector (2) is empty in this example.
   Based on the approximation (69), the dark matter measure is (see Appendix F for details):

                  p ( )2 + p (1 - p)  2  ( )2       2 2
(71)     ( )  1 +                       2     e2D µ-D  ,
                           2   2
                     (1 -  )  (1 - p)

        ) is the first derivative of ( ), and
where (

                 D v     (D - )v
          ) = - e D + e          (D - )  2 /2
(72)    (              2               e .
               ( - D )   ( - D + )2

                                                    ) approach infinity, which suggests
All else equal, when  approaches D , both ( ) and (
that disaster risk models featuring large but rare disasters (i.e., small  and small p) will be
more fragile according to our measure.



Quantitative analysis

To take the model to the data, we use annual real per-capita consumption growth (nondurables
and services) from the National Income and Product Accounts (NIPA) and returns on the CRSP
value-weighted market portfolio from 1929 to 2011. We fix the following auxiliary parameters at
the values of the corresponding moments of the empirical distribution of consumption growth
and excess stock returns: µ = 1.87%,  = 1.95%,  = 19.14%,  = 34.89% and  = 0.59. The
lower bound for disaster size is set to v = 7%, and the leverage factor in the disaster regime is
 = 3.
   In Figure 3, we plot the 95% and 99% confidence regions for (p,  ) based on the baseline
40          HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019




   Figure 3.-- The 95% and 99% confidence regions of (p,  ) for the baseline model and the equity premium
isoquants implied by the asset pricing moment restriction (68) for D = 3, 10, 24. p is disaster probability, and
 characterizes the inverse of average disaster size. The efficient GMM estimates are (p,  ) = (0.012, 78.79),
indicated by the red dot inside the confidence region. Four additional points mark the intersections of the equity
premium isoquants for D = 3 and 24 and the boundary of the 95% confidence region. Only p and  are treated
as unknown to the econometrician, and all other parameters are treated as auxiliary parameters with fixed
known values; therefore, the dark matter measure is defined only based on  = (p,  ).



model. As expected, the confidence regions are large, which confirms that the baseline model
provides limited information about p and  . We also plot the equity premium isoquants: for a
given level of risk aversion D , each dashed line in Figure 3 shows the different calibrations of the
disaster risk model that match the unconditional equity premium of 5.09%. In particular, even
for low risk aversion (e.g., D = 3), there exist models that not only match the observed equity
premium, but are also consistent with the macro data in the sense that the model parameters
(p,  ) remain inside the 95% confidence region.26
      While it is difficult to distinguish among a wide range of calibrations based on the fit with
the macro data, these calibrated models can differ vastly based on our dark matter measure.
For illustration, we focus on the following four calibrations, which are the four points where the
equity premium isoquants for D = 3 and 24 intersect the boundary of the 95% confidence region
in Figure 3. For D = 3, the two points are (p = 3.96%,  = 4.65) and (p = 0.31%,  = 3.179).

     26
    Julliard and Ghosh (2012) estimate the consumption Euler equation using the empirical likelihood method
and show that the model requires a high level of relative risk aversion to match the equity premium. Their
empirical likelihood criterion rules out any large disasters that have not occurred in the historical sample, hence
requiring the model to generate high equity premium using moderate disasters.
                               DARK MATTER IN ASSET PRICING MODELS                                                      41

                      5.5
                                                                   550


                                                                   500
                       5


                                                                   450
                      4.5
                                                                   400

                       4
                                                                   350

                      0.0324   0.0360   0.0396   0.0432   0.0468         0.014       0.016   0.018   0.02       0.022




                       5                                           40

                      4.5
                                                                   35
                       4

                      3.5                                          30
                       3

                      2.5                                          25

                       2
                                                                   20
                      1.5

                                2        3        4         5                    5       6     7     8      9
                                                          10-3                                                   10-4


   Figure 4.-- Visualization of the dark matter measure through the 95% confidence regions for the asymp-
totic distribution of the efficient GMM estimators for four "acceptable" calibrations. In Panels A through D,
the dark matter measures are () = 74.03, 1.49, 1.78 · 104 , and 5.60 · 102 , respectively, which are obtained in
the direction marked by the vector vmax . Parameter p is disaster probability, and  characterizes the inverse
of average disaster size. Only p and  are treated as unknown to the econometrician, and all other parameters
are treated as auxiliary parameters with fixed known values; therefore, the dark matter measure is defined only
based on  = (p,  ).



For D = 24, the two points are (p = 1.81%,  = 446.36) and (p = 0.07%,  = 28.43).
    With just two parameters in  = (p,  ), we can visualize the dark matter measure by
plotting the asymptotic confidence regions for (p,  ) in the baseline model and the full model,
as determined by the respective information matrices IB and IF . In each panel of Figure 4,
the largest dashed-line circle marks the 95% asymptotic confidence region for (p,  ) under the
baseline model. The smaller solid-line ellipse indicates the 95% asymptotic confidence region
for (p,  ) under the full model. Intuitively, the direction in Figure 4, along which the asset
pricing restriction does not provide additional information about the parameters  = (p,  ),
is parallel to the tangent direction of the dashed lines (i.e., the equity premium isoquants) in
Figure 3, evaluated at the black dots. This highlights the straightforward fact that the structural
restriction does not increase informativeness in the direction along which the equity premium
does not change.
42          HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

     In Panel A of Figure 4, the dark matter measure is () = 74.07. This means that under
the baseline model, we need to increase the amount of consumption data by a factor of 74.07
to match or exceed the precision in estimation of any linear combination of p and  afforded
by the equity premium constraint. Panels C and D of Figure 4 correspond to the calibrations
with "extra rare and large disasters," and for D = 3 and 24, the dark matter measure ()
rises to 1.78 × 104 and 5.60 × 102 , respectively. If, in Panel B of Figure 4, we raise D to 24
while changing the annual disaster probability to 1.81% and lowering the average disaster size
to 7.002% ( = 446.36), the dark matter measure () declines to 1.49. The reason for the
reduced fragility in this calibration is the combination of a higher disaster probability and a
lower average disaster size.



Monte Carlo experiments

We use simulations to illustrate the connection between the dark matter measure and the
model fragility (i.e., the internal refutability and external validity) of disaster risk models in
finite samples. More precisely, we assume that the true local data-generating process has a
time-varying relation between the expected log excess return and other dynamic parameters:
                                           
                            t r             1,  when 1  t  n
(73)      rn = r(p0 , 0 ) +     , with t =
                              n             -1, when n < t  n,


where the time series t captures the structural breaks and   (0, 1/2] is the break point. Such
a simple process t characterizes one structural break in the middle of the time-series sample.
The corresponding moment biases, evaluated at 0 , are

                                (2)                                t r
                                        T
                                                 (2)
(74)      EQ0 [mt (0 )] = 0, 0, t / n       with t                                     .
                                                         (1 - p0 )(1 - 2 ) 2 + p0  2

Therefore, data-generating processes A and C in Figure 4 have identical moment's local biases
 (2)
t      after substituting the calibrated parameter values into (74), which guarantees that the
comparisons across models in Panels A and B of Figure 5 are valid.
     Figure 5 shows three different simulation experiments. Panel A displays the local power func-
tions of C tests. The solid and dotted curves reflect the test powers when the data-generating
processes are characterized by calibrations A and C in Figure 4, respectively. In this experi-
ment, we vary the local misspecification r in the risk premium moment restriction. The data-
                             DARK MATTER IN ASSET PRICING MODELS                                         43




   Figure 5.-- Monte Carlo experiments for disaster risk models. In Panel A, we simulate 1000 independent
yearly time series with length n = 100 (i.e. 100 years). In Panels B and C, we set r = 0.4, and simulate 400
independent yearly time series with length n = 100 (i.e. 100 years) and break point  = 1/2. Only p and  are
treated as unknown to the econometrician, and all other parameters are treated as auxiliary parameters with
fixed known values; therefore, the dark matter measure is defined only based on  = (p,  ).




generating process under calibration C features an excessively large amount of dark matter
according to Panel C of Figure 4, and not surprisingly, it has little internal refutability (i.e.
little test power) consistent with Theorem 1.
   Panel B of Figure 5 displays the histograms of logged overfitting measures log O(^(1) , yn )
                                                                                     e,n

of efficient GMM estimators for two data-generating processes under calibrations A and C in
Figure 4. The estimator ^e,n is based on the estimation sample yn = y1 , · · · , y n/2 . In this
                                                                e

experiment, we specify a structural break in the risk premium in the middle of the time-series
sample with r = 0.4. Panel B shows that the efficient GMM estimator is likely to be overfitting
the data in the calibrated structural model with a high dark matter measure, which is consistent
with Theorem 2.
    Panel C of Figure 5 compares the expected out-of-sample fit of the recursive GMM estimator
~e,n with that of the efficient GMM estimator 
                                                ^e,n , based on the estimation sample yn . We
                                                                                         e

describe the two types of estimators in Section 5.2. Consistent with the conventional intuition,
under the data-generating process A, the efficient GMM estimator yields a better expected out-
of-sample fit than the recursive GMM estimator. This is because the additional identification
information is reliable and meaningful when the amount of dark matter is not excessively large.
In contrast, the recursive GMM estimator delivers a better expected out-of-sample fit under
the data-generating process C, which exhibits a much higher dark matter measure. This finding
44         HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

indicates that the concern about misspecification and instability may offset ­ and even reverse
­ the efficiency gain from the additional moment restrictions. The result for the data-generating
process C suggests that the econometrician should prioritize robustness over efficiency when
estimating models that rely heavily relies on dark matter (i.e., with an excessively large (0 )).




What to do with fragile models?

From an econometrician's perspective, robust estimation is particularly important for a GMM
model with large dark matter measure, because the concern of misspecification and instability
offsets the efficiency gain from imposing cross-equation restrictions. As discussed above, a com-
bination of the recursive and efficient GMM estimators by deviating from the optimal weighting
matrix is a potential way to construct estimators that balance robustness and efficiency. We
leave a systematic econometric investigation on optimal robust estimation in the presence of
dark matter for future research.
     From a modeler's perspective, fragile models are unsatisfactory, because they lack refutabil-
ity, and they are prone to over-fitting. Our analysis shows how to select model calibration
based on robustness. Our analysis also highlights the parameter combinations in which the
dark matter is embedded.
     How to improve the robustness of a model? One approach is to bring in more data to iden-
tify the problematic parameter combinations better under the baseline model, (for example,
see Barro and Urs´
                 ua, 2012; Nakamura, Steinsson, Barro, and Urs´
                                                              ua, 2013, who use interna-
tional data to better estimate the distribution of consumption disasters). Another approach
is to modify the preference specification or the belief formation mechanism so that the model
parameters are better identified by the baseline moments and do not rely excessively on the
restrictions implied by the asset pricing moments (e.g., Hansen and Sargent, 2010; Bidder and
Dew-Becker, 2016; Collin-Dufresne, Johannes, and Lochstoer, 2016; Nagel and Xu, 2019). Yet
another approach is to extend the model to connect the problematic parameter combinations
of the baseline model to additional data ­ for example, G^
                                                         arleanu, Panageas, and Yu (2012)
and Kung and Schmid (2015) explicitly model production and innovation to endogenize the
consumption dynamics, with a particular focus on low-frequency fluctuations. This ties the
properties of R&D investment to those of the consumption process.
                               DARK MATTER IN ASSET PRICING MODELS                                        45

                                             7. CONCLUSION

In this paper, we propose a new tractable measure of model fragility based on quantifying
the informativeness of the cross-equation restrictions that a structural model imposes on the
model parameters. We argue that our measure quantifies a useful model property related to the
model's tendency to over-fit the data in sample.
   Our fragility measure should be used as a model selection criterion. When faced with a set
of candidate models consistent with available data, selecting the less fragile model can be an
appealing criterion from the point of view of out of sample performance. We leave the formal
development of model selection based on our measure of model fragility to future research.
   Our model fragility measure is easy to implement, and the worst-case direction is particularly
instructive. This direction provides guidance on which features of the model are most vulnerable
to overfitting. Additional data or model elements would be needed to alleviate this tendency.
Further, the worst-case direction is useful to consider when constructing robust estimators based
on considerations of out-of-sample fit, e.g., following the idea of recursive GMM estimators.
   Our methodology has a broad range of potential applications. In addition to the examples
involving asset pricing, our measure can be used to assess the robustness of structural models
in other areas of economics, such as industrial organization and corporate finance.


                                              REFERENCES

Ai, C., and X. Chen, 2003, "Efficient Estimation of Models with Conditional Moment Restrictions Containing
  Unknown Functions," Econometrica, 71, 1795­1843.
Akaike, H., 1973, "Information theory and an extension of the maximum likelihood principle," in Second Inter-
  national Symposium on Information Theory (Tsahkadsor, 1971) . pp. 267­281, Akad´
                                                                                 emiai Kiad´
                                                                                           o, Budapest.
Ando, T., 2007, "Bayesian predictive information criterion for the evaluation of hierarchical Bayesian and
  empirical Bayes models," Biometrika, 94, 443­458.
Andrews, D. W. K., 1991, "Heteroskedasticity and Autocorrelation Consistent Covariance Matrix Estimation,"
  Econometrica, 59, 817­58.
Andrews, D. W. K., 1993, "Tests for Parameter Instability and Structural Change with Unknown Change Point,"
  Econometrica, 61, 821­856.
Andrews, D. W. K., 2003, "End-of-Sample Instability Tests," Econometrica, 71, 1661­1694.
Andrews, D. W. K., and J. C. Monahan, 1992, "An Improved Heteroskedasticity and Autocorrelation Consistent
  Covariance Matrix Estimator," Econometrica, 60, 953­66.
Andrews, D. W. K., and W. Ploberger, 1994, "Optimal Tests when a Nuisance Parameter is Present Only Under
  the Alternative," Econometrica, 62, 1383­1414.
Andrews, I., M. Gentzkow, and J. M. Shapiro, 2017, "Measuring the Sensitivity of Parameter Estimates to
46          HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

  Estimation Moments," The Quarterly Journal of Economics, 132, 1553­1592.
Athey, S., and G. W. Imbens, 2015, "A Measure of Robustness to Misspecification," American Economic Review,
  105, 476­480.
Athey, S., and G. W. Imbens, 2017, "The State of Applied Econometrics: Causality and Policy Evaluation,"
  Journal of Economic Perspectives, 31, 3­32.
Athey, S., and G. W. Imbens, 2019, "Machine Learning Methods Economists Should Know About," Papers,
  Stanford University.
Bai, J., and P. Perron, 1998, "Estimating and Testing Linear Models with Multiple Structural Changes," Econo-
  metrica, 66, 47­78.
Bansal, R., D. Kiku, and A. Yaron, 2012, "An Empirical Evaluation of the Long-Run Risks Model for Asset
  Prices," Critical Finance Review, 1, 183­221.
Bansal, R., D. Kiku, and A. Yaron, 2016a, "Risks for the long run: Estimation with time aggregation," Journal
  of Monetary Economics, 82, 52 ­ 69.
Bansal, R., D. Kiku, and A. Yaron, 2016b, "Risks for the long run: Estimation with time aggregation," Journal
  of Monetary Economics, 82, 52 ­ 69.
Bansal, R., and A. Yaron, 2004, "Risks for the Long Run: A Potential Resolution of Asset Pricing Puzzles,"
  Journal of Finance, 59, 1481­1509.
Barro, R. J., 2006, "Rare disasters and asset markets in the twentieth century," The Quarter Journal of Eco-
  nomics, 121, 823­866.
Barro, R. J., and J. F. Urs´
                           ua, 2012, "Rare Macroeconomic Disasters," Annual Review of Economics, 4, 83­109.
Bickel, P. J., 1981, "Quelques aspects de la statistique robuste," in Ninth Saint Flour Probability Summer
  School--1979 (Saint Flour, 1979), vol. 876 of Lecture Notes in Math., . pp. 1­72, Springer, Berlin-New York.
Bickel, P. J., C. A. J. Klaassen, Y. Ritov, and J. A. Wellner, 1993, Efficient and adaptive estimation for
  semiparametric models . Johns Hopkins Series in the Mathematical Sciences, Johns Hopkins University Press,
  Baltimore, MD.
Bickel, P. J., and J. Kwon, 2001, "Inference for semiparametric models: some questions and an answer," Statist.
  Sinica, 11, 863­960, With comments and a rejoinder by the authors.
Bidder, R., and I. Dew-Becker, 2016, "Long-Run Risk Is the Worst-Case Scenario," The American Economic
  Review, 106, 2494­2527.
Bossaerts, P., and P. Hillion, 1999, "Implementing Statistical Criteria to Select Return Forecasting Models:
  What Do We Learn?," The Review of Financial Studies, 12, 405­428.
Bradley, R. C., 2005, "Basic properties of strong mixing conditions. A survey and some open questions," Probab.
  Surv., 2, 107­144, Update of, and a supplement to, the 1986 original.
Campbell, J. Y., 2018, Financial Decisions and Markets: A Course in Asset Pricing, Princeton University Press.
Campbell, J. Y., and J. H. Cochrane, 1999, "By Force of Habit: A Consumption-Based Explanation of Aggregate
  Stock Market Behavior," Journal of Political Economy, 107, 205­251.
Campbell, J. Y., and R. J. Shiller, 1988, "Stock Prices, Earnings, and Expected Dividends," Journal of Finance,
  43, 661­76.
Chamberlain, G., 1987, "Asymptotic efficiency in estimation with conditional moment restrictions," Journal of
  Econometrics, 34, 305­334.
                               DARK MATTER IN ASSET PRICING MODELS                                              47

Chen, X., and A. Santos, 2018, "Overidentification in Regular Models," Econometrica, 86, 1771­1817.
Christiano, L. J., and M. Eichenbaum, 1992, "Current Real-Business-Cycle Theories and Aggregate Labor-
  Market Fluctuations," The American Economic Review, 82, 430­450.
Cogley, T., and T. J. Sargent, 2005, "Drifts and volatilities: monetary policies and outcomes in the post WWII
  US," Review of Economic Dynamics, 8, 262 ­ 302.
Collin-Dufresne, P., M. Johannes, and L. A. Lochstoer, 2016, "Parameter Learning in General Equilibrium: The
  Asset Pricing Implications," American Economic Review, 106, 664­698.
Constantinides, G. M., and A. Ghosh, 2011, "Asset Pricing Tests with Long-run Risks in Consumption Growth,"
  The Review of Asset Pricing Studies, 1, 96­136.
Dangl, T., and M. Halling, 2012, "Predictive regressions with time-varying coefficients," Journal of Financial
  Economics, 106, 157 ­ 181.
Davidson, R., and J. G. MacKinnon, 1987, "Implicit Alternatives and the Local Power of Test Statistics,"
  Econometrica, 55, 1305­1329.
Dou, W., D. Pollard, and H. H. Zhou, 2010, "Functional Regression for General Exponential Families," Submitted
  to Annals of Statistics.
Efron, B., 2004, "The estimation of prediction error: covariance penalties and cross-validation," J. Amer. Statist.
  Assoc., 99, 619­642, With comments and a rejoinder by the author.
Eichenbaum, M. S., L. P. Hansen, and K. J. Singleton, 1988, "A Time Series Analysis of Representative Agent
  Models of Consumption and Leisure Choice Under Uncertainty," The Quarterly Journal of Economics, 103,
  51­78.
Elliott, G., and U. K. M¨
                        uller, 2006, "Efficient Tests for General Persistent Time Variation in Regression Coef-
  ficients1," The Review of Economic Studies, 73, 907­940.
Epstein, L., and S. Zin, 1989, "Substitution, Risk Aversion, and the Temporal Behavior of Consumption Growth
  and Asset Returns I: A Theoretical Framework," Econometrica, 57, 937­969.
Epstein, L. G., and M. Schneider, 2003, "Recursive multiple-priors," Journal of Economic Theory, 113, 1­31.
Ferson, W., S. Nallareddy, and B. Xie, 2013, "The "out-of-sample" performance of long run risk models," Journal
  of Financial Economics, 107, 537 ­ 556.
Fisher, R. A., 1922, "On the mathematical foundations of theoretical statistics," Phil. Trans. R. Soc. Lond. A,
  222, 309­68.
Foster, D. P., and E. I. George, 1994, "The risk inflation criterion for multiple regression," Ann. Statist., 22,
  1947­1975.
Foster, F. D., T. Smith, and R. E. Whaley, 1997, "Assessing Goodness-Of-Fit of Asset Pricing Models: The
  Distribution of the Maximal R2 ," The Journal of Finance, 52, 591­607.
Gabaix, X., 2012, "Variable Rare Disasters: An Exactly Solved Framework for Ten Puzzles in Macro-Finance,"
  The Quarterly Journal of Economics, 127, 645­700.
G^
 arleanu, N., S. Panageas, and J. Yu, 2012, "Technological Growth and Asset Pricing," The Journal of Finance,
  67, 1265­1292.
Gelman, A., J. Hwang, and A. Vehtari, 2013, "Understanding predictive information criteria for Bayesian mod-
  els," Statsitics and Computing.
Gilboa, I., and D. Schmeidler, 1989, "Maxmin expected utility with non-unique prior," Journal of Mathematical
48            HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

  Economics, 18, 141­153.
Gordin, M. I., 1969, "The central limit theorem for stationary processes," Dokl. Akad. Nauk SSSR, 188, 739­741.
Greenwood, P. E., and W. Wefelmeyer, 1995, "Efficiency of Empirical Estimators for Markov Chains," Ann.
  Statist., 23, 132­143.
Hansen, B. E., 2000, "Testing for structural change in conditional models," Journal of Econometrics, 97, 93 ­
  115.
Hansen, L., and T. J. Sargent, 2010, "Fragile beliefs and the price of uncertainty," Quantitative Economics, 1,
  129­162.
Hansen, L. P., 1982, "Large Sample Properties of Generalized Method of Moments Estimators," Econometrica,
  50, 1029­54.
Hansen, L. P., 1985, "A method for calculating bounds on the asymptotic covariance matrices of generalized
  method of moments estimators," Journal of Econometrics, 30, 203­238.
Hansen, L. P., 2007a, "Beliefs, Doubts and Learning: Valuing Macroeconomic Risk," American Economic Review,
  97, 1­30.
Hansen, L. P., 2007b, "Generalized Method of Moments Estimation," in The New Palgrave Dictionary of Eco-
  nomics . edited by Steven N. Durlauf and Lawrence E. Blume, Palgrave Macmillan.
Hansen, L. P., 2012, "Proofs for large sample properties of generalized method of moments estimators," Journal
  of Econometrics, 170, 325 ­ 330, Thirtieth Anniversary of Generalized Method of Moments.
Hansen, L. P., 2014, "Nobel Lecture: Uncertainty Outside and Inside Economic Models," Journal of Political
  Economy, 122, 945 ­ 987.
Hansen, L. P., and J. J. Heckman, 1996, "The Empirical Foundations of Calibration," Journal of Economic
  Perspectives, 10, 87­104.
Hansen, L. P., and T. J. Sargent, 1980, "Formulating and estimating dynamic linear rational expectations
  models," Journal of Economic Dynamics and Control, 2, 7­46.
Hansen, L. P., and T. J. Sargent, 1991, Rational Expectations Econometrics, Westview Press, Boulder, Colorado.
Hansen, L. P., and T. J. Sargent, 2001, "Robust Control and Model Uncertainty," American Economic Review,
  91, 60­66.
Hansen, L. P., and K. J. Singleton, 1982, "Generalized Instrumental Variables Estimation of Nonlinear Rational
  Expectations Models," Econometrica, 50, 1269­86.
Hansen, L. P., and K. J. Singleton, 1983, "Stochastic Consumption, Risk Aversion, and the Temporal Behavior
  of Asset Returns," Journal of Political Economy, 91, 249­65.
Hansen, P. R., and E.-I. Dumitrescu, 2018, "Parameter Estimation with Out-of-Sample Objective," Working
  paper.
Hastie, T., R. Tibshirani, and J. Friedman, 2001, The elements of statistical learning . Springer Series in
  Statistics, Springer-Verlag, New York, Data mining, inference, and prediction.
Jones, G. L., 2004, "On the Markov chain central limit theorem," Probab. Surv., 1, 299­320.
Julliard, C., and A. Ghosh, 2012, "Can Rare Events Explain the Equity Premium Puzzle?," Review of Financial
  Studies, 25, 3037­3076.
Kitamura, Y., T. Otsu, and K. Evdokimov, 2013, "Robustness, Infinitesimal Neighborhoods, and Moment
  Restrictions," Econometrica, 81, 1185­1201.
                               DARK MATTER IN ASSET PRICING MODELS                                            49

Klibanoff, P., M. Marinacci, and S. Mukerji, 2005, "A Smooth Model of Decision Making under Ambiguity,"
  Econometrica, 73, 1849­1892.
Kocherlakota, N., 2016, "Fragility of Purely Real Macroeconomic Models," NBER Working Papers 21866,
  National Bureau of Economic Research, Inc.
Kocherlakota, N. R., 2007, "Model fit and model selection," Federal Reserve Bank of St. Louis Review,
  July/Augst, 349­360.
Koijen, R. S., and S. Van Nieuwerburgh, 2011, "Predictability of Returns and Cash Flows," Annual Review of
  Financial Economics, 3, 467­491.
Kung, H., and L. Schmid, 2015, "Innovation, Growth, and Asset Prices," The Journal of Finance, 70, 1001­1037.
Le Cam, L., and G. L. Yang, 2000, Asymptotics in statistics . Springer Series in Statistics, Springer-Verlag, New
  York, second edn., Some basic concepts.
Lee, L.-f., 2007, "The method of elimination and substitution in the GMM estimation of mixed regressive,
  spatial autoregressive models," Journal of Econometrics, 140, 155­189.
Lehmann, E., and J. P. Romano, 1996, Weak convergence and empirical processes . Springer Series in Statistics,
  Springer-Verlag, New York, With applications to statistics.
Lettau, M., S. Ludvigson, and J. Wachter, 2008, "The Declining Equity Premium: What Role Does Macroeco-
  nomic Risk Play?," Review of Financial Studies, 21, 1653­1687.
Lettau, M., and S. Van Nieuwerburgh, 2008, "Reconciling the Return Predictability Evidence," Review of
  Financial Studies, 21, 1607­1652.
Levit, B. Y., 1976, "On the Efficiency of a Class of Non-Parametric Estimates," Theory of Probability & Its
  Applications, 20, 723­740.
Lewis, K. K., 2008, "Peso problem," in Steven N. Durlauf, and Lawrence E. Blume (ed.), The New Palgrave
  Dictionary of Economics, Palgrave Macmillan, Basingstoke.
Li, H., and U. K. M¨
                   uller, 2009, "Valid Inference in Partially Unstable Generalized Method of Moments Models,"
  Review of Economic Studies, 76, 343­365.
Ljungqvist, L., and T. Sargent, 2004, Recursive Macroeconomic Theory, 2nd Edition . , vol. 1, The MIT Press,
  2 edn.
Lucas, R. E., and T. J. Sargent, 1981, Rational Expectations and Econometric Practice, University of Minnesota
  Press, Minneapolis.
McLeish, D. L., 1975a, "Invariance principles for dependent variables," Wahrscheinlichkeitstheorie verw Gebiete,
  32, 165­178.
McLeish, D. L., 1975b, "A maximal inequality and dependent strong laws," Ann. Probability, 3, 829­839.
McManus, D. A., 1991, "Who Invented Local Power Analysis?," Econometric Theory, 7, 265­268.
Meyn, S., and R. L. Tweedie, 2009, Markov chains and stochastic stability, Cambridge University Press, Cam-
  bridge, second edn., With a prologue by Peter W. Glynn.
Mullainathan, S., and J. Spiess, 2017, "Machine Learning: An Applied Econometric Approach," Journal of
  Economic Perspectives, 31, 87­106.
M¨
 uller, U. K., 2012, "Measuring prior sensitivity and prior informativeness in large Bayesian models," Journal
  of Monetary Economics, 59, 581 ­ 597.
M¨
 uller, U. K., and M. W. Watson, 2016, "Measuring Uncertainty about Long-Run Predictions," The Review of
50           HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

  Economic Studies, 83, 1711­1740.
Nagel, S., and K. J. Singleton, 2011, "Estimation and Evaluation of Conditional Asset Pricing Models," The
  Journal of Finance, 66, 873­909.
Nagel, S., and Z. Xu, 2019, "Asset Pricing with Fading Memory," Discussion paper.
Nakamura, E., J. Steinsson, R. Barro, and J. Urs´
                                                ua, 2013, "Crises and Recoveries in an Empirical Model of
  Consumption Disasters," American Economic Journal: Macroeconomics, 5, 35­74.
Nevelson, M. B., 1977, "On One Informational Lower Bound," Problemy Peredachi Informatsii, 13, 26­31.
Newey, W. K., 1985a, "Generalized method of moments specification testing," Journal of Econometrics, 29,
  229­256.
Newey, W. K., 1985b, "Maximum likelihood specification testing and conditional moment tests," Econometrica,
  53, 1047­1070.
Newey, W. K., 1990, "Efficient Instrumental Variables Estimation of Nonlinear Models," Econometrica, 58,
  809­837.
Newey, W. K., 1993, "Efficient Estimation of Models with Conditional Moment Restrictions," in Handbook of
  Statistics, vol. 11, . chap. 16, Amsterdam: North-Holland, by g.s. maddala, c.r. rao, and h.d. vinod edn.
Newey, W. K., and D. McFadden, 1994, "Chapter 36 Large sample estimation and hypothesis testing," , vol. 4
  of Handbook of Econometrics . pp. 2111 ­ 2245, Elsevier.
Newey, W. K., and K. D. West, 1987, "A Simple, Positive Semi-definite, Heteroskedasticity and Autocorrelation
  Consistent Covariance Matrix," Econometrica, 55, 703­08.
Neyman, J., 1937, ""Smooth" tests for goodness of fit," Scandinavian Actuarial Journal, 1937, 149­199.
Nyblom, J., 1989, "Testing for the Constancy of Parameters Over Time," Journal of the American Statistical
  Association, 84, 223­230.
Ogaki, M., 1993, "17 Generalized method of moments: Econometric applications," in Econometrics, vol. 11 of
  Handbook of Statistics, . pp. 455 ­ 488, Elsevier.
Pastor, L., and R. Stambaugh, 2001, "The Equity Premium and Structural Breaks," Journal of Finance, 56,
  1207­1239.
Pesaran, M. H., and A. Timmermann, 1995, "Predictability of Stock Returns: Robustness and Economic Sig-
  nificance," The Journal of Finance, 50, 1201­1228.
Phillips, P. C. B., and S. N. Durlauf, 1986, "Multiple Time Series Regression with Integrated Processes," The
  Review of Economic Studies, 53, 473­495.
Primiceri, G. E., 2005, "Time Varying Structural Vector Autoregressions and Monetary Policy," The Review of
  Economic Studies, 72, 821­852.
Saikkonen, P., 1989, "Asymptotic relative efficiency of the classical test statistics under misspecification," Journal
  of Econometrics, 42, 351 ­ 369.
Saracoglu, R., and T. J. Sargent, 1978, "Seasonality and portfolio balance under rational expectations," Journal
  of Monetary Economics, 4, 435­458.
Schorfheide, F., D. Song, and A. Yaron, 2018, "Identifying Long-Run Risks: A Bayesian Mixed-Frequency
  Approach," Econometrica, 86, 617­654.
Schorfheide, F., and K. I. Wolpin, 2012, "On the Use of Holdout Samples for Model Selection," The American
  Economic Review, 102, 477­481.
                              DARK MATTER IN ASSET PRICING MODELS                                             51

Schwarz, G., 1978, "Estimating the dimension of a model," Ann. Statist., 6, 461­464.
Severini, T. A., and G. Tripathi, 2013, "Semiparametric Efficiency Bounds for Microeconometric Models: A
  Survey," Foundations and Trends in Econometrics, 6, 163­397.
Shen, X., and J. Ye, 2002, "Adaptive model selection," J. Amer. Statist. Assoc., 97, 210­221.
Sowell, F., 1996, "Optimal Tests for Parameter Instability in the Generalized Method of Moments Framework,"
  Econometrica, 64, 1085­1107.
Spiegelhalter, D. J., N. G. Best, B. P. Carlin, and A. van der Linde, 2002, "Bayesian measures of model
  complexity and fit," J. R. Stat. Soc. Ser. B Stat. Methodol., 64, 583­639.
Stock, J. H., and M. W. Watson, 1996, "Evidence on Structural Instability in Macroeconomic Time Series
  Relations," Journal of Business & Economic Statistics, 14, 11­30.
Stock, J. H., and M. W. Watson, 1998, "Median Unbiased Estimation of Coefficient Variance in a Time-Varying
  Parameter Model," Journal of the American Statistical Association, 93, 349­358.
Stock, J. H., and M. W. Watson, 2002, Introduction to Econometrics, Addison Wesley; United States, 4th edn.
Stock, J. H., and M. W. Watson, 2008, "Phillips Curve Inflation Forecasts," Nber working papers, National
  Bureau of Economic Research, Inc.
Stokey, N. L., and R. E. Lucas, 1989, Recursive Methods in Economics Dynamics, 1st Edition, The Harvard
  Press, 1 edn.
Sun, Y., A. Baricz, and S. Zhou, 2010, "On the monotonicity, log-concavity, and tight bounds of the generalized
  Marcum and Nuttall Q-functions," IEEE Trans. Inform. Theory, 56, 1166­1186.
Tibshirani, R., and K. Knight, 1999, "The Covariance Inflation Criterion for Adaptive Model Selection," Journal
  of the Royal Statistical Society: Series B (Statistical Methodology), 61, 529­546.
Valkanov, R., 2003, "Long-horizon regressions: theoretical results and applications," Journal of Financial Eco-
  nomics, 68, 201 ­ 232.
van der Vaart, A. W., 1988, Statistical estimation in large parameter spaces . , vol. 44 of CWI Tract, Stichting
  Mathematisch Centrum, Centrum voor Wiskunde en Informatica, Amsterdam.
van der Vaart, A. W., 1998, Asymptotic Statistics . , vol. 3 of Cambridge Series in Statistical and Probabilistic
  Mathematics, Cambridge University Press, Cambridge.
van der Vaart, A. W., and J. A. Wellner, 1996, Weak convergence and empirical processes . Springer Series in
  Statistics, Springer-Verlag, New York, With applications to statistics.
Varian, H. R., 2014, "Big Data: New Tricks for Econometrics," Journal of Economic Perspectives, 28, 3­28.
Wachter, J. A., 2013, "Can Time-Varying Risk of Rare Disasters Explain Aggregate Stock Market Volatility?,"
  Journal of Finance, 68, 987­1035.
Weil, P., 1989, "The Equity Premium Puzzle and the Risk-Free Rate Puzzle," Journal of Monetary Economics,
  24, 401­421.
Welch, I., and A. Goyal, 2008, "A Comprehensive Look at The Empirical Performance of Equity Premium
  Prediction," Review of Financial Studies, 21, 1455­1508.
White, H., and I. Domowitz, 1984, "Nonlinear Regression with Dependent Observations," Econometrica, 52,
  143­61.
Ye, J., 1998, "On measuring and correcting the effects of data mining and model selection," J. Amer. Statist.
  Assoc., 93, 120­131.
52           HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

Zin, S. E., 2002, "Are behavioral asset-pricing models structural?," Journal of Monetary Economics, 49, 215­228.




                                                  Appendix
We first list all additional theoretical results in Appendices A and B. Then, we show the proofs of the theorems
in Appendix C and those of the propositions and corollaries in Appendix D. The derivation of the disaster risk
model can be found in Appendix F. Other miscellaneous derivations and proofs are collected in Appendix G.
                                   n                    n
In the appendix, we denote        t=1   by   tn   and   t= n +1   by   t>n   for notational simplicity.



                                    APPENDIX A: AUXILIARY RESULTS

                                A.1. Auxiliary Results on Data-Generating Processes

Here we introduce auxiliary propositions that characterize the useful properties of the data-generating pro-
cesses under regularity conditions. Proposition 3 derives the corresponding scores (or local perturbations) of
the univariate marginal distribution µs,f and the Markov transition kernel Ks,f when we perturb the bivariate
distribution from Q0 to Qs,f (i.e., the score of Qs,f is f ). Proposition 4 considers local data-generating processes
characterized by scores fn,t and shows that the scores fn,t satisfy the law of large numbers and the central
limit theorem. Proposition 4, together with Hellinger-differentiability, is needed to ensure the local asymptotic
normality of the local data-generating processes, as established in Proposition 5. The LAN property is needed to
establish the contiguity property of the locally unstable data-generating process P1/n,g,b as a local perturbation
with respect to the reference process P0 for asymptotic equivalence arguments.


Proposition 3 (Implied Scores of Marginal and Transition Distributions)           Suppose Qs,f  N(Q0 ) for some
Q0  H. Let µ and K be the univariate marginal distribution and the Markov transition kernel of Q0 , respec-
tively. Then, the marginal distribution µs,f and Markov transition kernel Ks,f of Qs,f satisfy the Hellinger
differentiability conditions:


(75)
          dµs,f        ¯ + sµ (s) and dKs,f (·|y ) = 1 + sf
                = 1 + sf                                  ~(y, ·) + sK (y, s)  y  Y,
           dµ0                         dK0 (·|y )

where µ (s) and K (y, s) converge to 0 in L2 (Q0 ) for all y  Y as s  0, and the marginal score and the
conditional score are


(76)      ¯(y)  EQ0 [f (y, y )|y] = EQ0 [f (y , y)|y] and f
          f                                               ~(y, y )  f (y, y ) - f
                                                                                ¯(y).


                                                       ~             Q0
Proposition 4      Suppose Assumptions 2 ­ 3 hold. Let fn,t  fn,t - Et-1 [fn,t ] and g
                                                                                     ~(yt-1 , yt )  g (yt-1 , yt ) -
EQ0
 t-1 [g (yt-1 , yt )]. Then it holds that under Q0 ,


                          p                                  p
(77)      n-1        ~2 -
                     fn,t  ( ) and n
                                     -1
                                                   EQ   ~2 
                                                    t-1 fn,t - ( ), where
                tn                            tn
                                    DARK MATTER IN ASSET PRICING MODELS                                            53


                                                                                    
                                                                        
                                                                          b(u)du
(78)                  ~T B g
              ( )  EQ g    ~ with B                                   
                                                                       0            .
                                                           0
                                                             b(u)du   0
                                                                         b(u)2 du

Further, the asymptotic normality result follows:

                           ~    d
(79)          n-1/2        fn,t -
                                 N (0, ( )) .
                      tn


Proposition 5 (LAN of Unstable Parametric Submodels)                        Suppose Assumptions 2 ­ 3 hold. For any g 
G(Q0 ) and b  B, the corresponding locally unstable data-generating process with distribution P1/n,g,b for
yn = {y0 , · · · , yn } satisfies
                                                                      
                 dP1/n,g,b  1                                    1
              ln           =               ~(yt-1 , yt )T 
                                           g                          - 1 (1) + op (1),
                    dP0      n                                b(t/n)    2
                                    tn


      ~ and (·) are defined in Proposition 4, and op (1) denotes a sequence of random variables that converge
where g
to zero in probability P0 .

Corollary 2 (Contiguity)            Suppose Assumptions 2 ­ 3 hold. The locally unstable data-generating process with
distribution P1/n,g,b is contiguous to the stable data-generating process with distribution P0 . More precisely,
       p                               p
Xn -                       0 under P1/n,g,b for all Fn -measurable random variables Xn : Yn  R.
    0 under P0 implies Xn -


                                           A.2. Auxiliary Results on Moment Functions

Here we introduce the basic results (Proposition 6) extending the standard moment function approximations
(Hansen, 1982). Similar results on the (functional) central limit theorem with local instability are developed
and used in Andrews (1993), Sowell (1996), and Li and M¨
                                                       uller (2009).

    Define (g T )  [(g1 ), (g2 )] for all g = [g1 , g2 ]T with g  G(Q0 ). We denote
                                                                                                        
                          (g ) T                                           (g )     T      1-
(80)          e (g, b,  )                      
                                                          and o (g, b,  )                  1            .
                                                                                                        
                                                                            1-
                                                                                
                                                  b(u)du                                       b(u)du
                                           0                                               

Proposition 6          Suppose Assumptions 1 ­ 5 hold. Then, under P1/n,g,b ,

             1
                                                                
                                               1 W ( )
                                                                                 
                       mt (0 )                
               n tn                d                             e     (g, b,  )
   (i) 
       
                                  -                            +                  on D([0, 1]) for all split
               1          mt (0 )       1      (W (1) - W ( ))       o (g, b,  )
            (1 -  )n t>n                 1-
       point   [0, 1], where W ( ) is a dm -dimensional Wiener process and D([0, 1]) is the space of right
       continuous functions on [0, 1] endowed with the Skorohod J1 topology;
             1                                1
                                                                                      
                       mt (n,t )                        m t (0 )
               n tn                             n tn                  e (g, b,  ) 
  (ii)                              =                               -                  + op (1), for all random
                                         
               1          mt (n,t )             1           mt (0 )       o (g, b,  )
            (1 -  )n t>n                     (1 -  )n t>n
54           HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

       variables g1 , g2  T (Q0 );

             1                                      I - D(DT D)-1 DT 1
                                                                                                 
                         mt (^e,n )                                             mt (0 )
                n tn                                                     n tn
 (iii)                                  =                                                         + op (1),
                                                                                                 
               1            mt ( ^e,n )       1          mt (0 ) - D(D D)-1 DT 1
                                                                       T
                                                                                        m t (0 )
            (1 -  )n t>n                   (1 -  )n t>n                          n tn
              ^                                                             n
       where e,n is the efficient GMM estimator based on estimation sample ye ;

             1                                      I - D(AT D)-1 AT 1
                                                                                                 
                         mt (~e,n )                                             mt (0 )
                n tn                                                     n tn
 (iv)                                    =                                                        + op (1),
                                                                                                 
               1                 ~
                            mt (e,n )
                                              1                       T
                                                         mt (0 ) - D(A D) A-1 T 1
                                                                                        mt (0 )
            (1 -  )n t>n                   (1 -  )n t>n                          n tn
              ~                                                              n
       where e,n is the recursive GMM estimator based on estimation sample ye .


     We construct the martingale difference array h(y, y , 0 ) inspired by the martingale difference approximation
for the temporal-dependent moment function in Hansen (1985). The martingale difference approximation plays
a key role in analyzing the semiparametric efficiency bound of estimation based on moment restrictions. To
guarantee that h(y, y , 0 ) is well defined in (81), we postulate the condition of asymptotic negligibility of
innovations (Assumption 5 (iii)), which has been used to establish Gordin's CLT (Gordin, 1969).


Proposition 7       Suppose Assumptions 1 ­ 5 hold. Then h(·, 0 ) is defined as follows:


(81)       h(y, y , 0 ) = m(y, y , 0 ) - EQ0 [m1 (0 )|y0 = y]
                             
                         +         EQ0 [mt+1 (0 )|y1 = y ] - EQ0 [mt+1 (0 )|y0 = y] .
                             t=1


Moreover, h(·, 0 ) satisfies EQ0 [h(y, y , 0 )|y] = 0 and EQ0 h(y, y , 0 )h(y, y , 0 )T = I and


(82)       EQ0 [m(·, 0 )f ] = EQ0 [h(·, 0 )f ] for all f  L2
                                                           0 (Q0 ).



Therefore, the tangent set of Q at the distribution Q0 can be represented by


(83)       T (Q0 ) = f  L2
                         0 (Q0 ) : (f )  lin(D ) ,



where the operator (f )  EQ0 [h(·, 0 )f ] is a linear operator on L2
                                                                   0 (Q0 ), and the linear space lin(D ) is spanned

by columns of D, defined in (28).



                  A.3. Auxiliary Results on GMM Estimators Based on the Estimation Sample

We now introduce the basic results, which extend the standard GMM approximations (Hansen, 1982) in Propo-
sition 8. Then, we introduce a new set of GMM approximations in Proposition 9, which are new and unique to
our paper.


Proposition 8       Suppose Assumptions 1 ­ 5 hold. Let ~e,n and ^e,n be the recursive GMM and the efficient
                                               n
GMM estimators based on the estimation sample ye = {y1 , · · · , y     n   }, respectively. Then, under P1/n,g,b ,
                                     DARK MATTER IN ASSET PRICING MODELS                                                         55

                ~e,n - 0 = -(AT D)-1 AT 1
    (i)     n                                   mt (0 ) + op (1),
                                         n tn
                               
                       D11  0                                                        -1
          with A =                              T
                                and A22 = D21 (D11 D11 )-1 D21
                                                            T
                                                               +I                         D22 ;
                        0  A22

          
   (ii)      n ^e,n - 0 = -(DT D)-1 DT               1    mt (0 ) + op (1).
                                                     n tn


Proposition 9              Suppose Assumptions 1 ­ 6 hold and g  GB (Q0 ). Let ~e,n and ^e,n be the recursive GMM
                                                                      n
estimator and efficient GMM estimator based on the estimation sample ye = {y1 , · · · , y                   n    }, respectively.
Then, under P1/n,g,b ,
                               
               ~(1)   (1)
               e,n - e,n
    (i) n                       = -I- 1 T    -1 T
                                    Q ,1 IF IB D11
                                                   1        (1) (1)
                                                         mt (n,t ) + op (1);
              ~(1)        (1)
           s (e,n ) - s (e,n )                      n tn

                               
               ^(1) - (1)
               
                                = -I-         LF 1
                e,n   e,n             1 T
   (ii) n                           Q ,1 IF             mt (0 ) - LB e (g, b,  )                           + op (1).
              ^(1)
           s ( ) - s ( )  (1)                      n tn
                           e,n      e,n


Here the matrices LB and LF are

                                        -1 T
(84)         LB  I- 1 T
                  B D11 m,1 and LF  ,1 IQ D ,



and D11 and D are Jacobian matrices defined in (28), the information matrices IB and IQ are defined in (29)
­ (30), and the selection matrices m,1 and ,1 are defined in (18) and (30), respectively.


Proposition 10       Suppose Assumptions 1 ­ 6 hold and g  GB (Q0 ). Let L((1) , ·) be the loss function for
assessing the goodness of fit of the baseline parameter (1) to the data as defined in (55) ­ (56). Let   ~e,n
and  ^e,n be the recursive GMM estimator and efficient GMM estimator based on the estimation sample yn =
                                                                                                                             e
                                           n
{y1 , · · · , y   n   }, respectively. Let yo = {y   n +1 , · · ·   , yn } be the holdout sample. Then, under   P1/n,g,b ,
                                                                             
            ~(1) ; yn )                                 T
         L(  e,n    e      ((LB - 2LF )e,n - 2L e ) IF (LB e,n )
    (i)                 =
                                                          T
                                                                              + op (1), and
         L( ~(1) ; yn )   (L B  e,n - 2LF  o,n - 2 L  o )   I F (L  B  e,n )
             e,n    o

                                                                                          
            ^(1) ; yn )                               T
         L ( e,n    e               - (LF e,n + L e ) IF (LF e,n + L e )
   (ii)                 =
                                                                  T
                                                                                           + op (1),
         L (^(1) ; yn )   (LF (e,n - 2o,n ) + L (e - 2o )) IF (LF e,n + L e )
                  e,n    o


where e (g, b,  ) and o (g, b,  ) are defined in (80), and the random vectors e,n and o,n are

                  1                                    1
(85)         e,n        mt (0 ) - e (g, b,  ) and o,n         mt (0 ) - o (g, b,  ),
                   n tn                                 n t>n

and the matrices LF , LB are defined in (84) and L  LF - LB . Further, using Proposition 6,
                                              
                              1 W ( )
                        
                  e,n         
(86)
                        d 
                        -
                               
                                              .
                                              
                  o,n       1 (W (1) - W ( ))
                           1-
56          HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

                APPENDIX B: SEMIPARAMETRIC MINIMAX EFFICIENCY BOUNDS

Given the LAN for the Markov processes with potential local instability, the local asymptotic minimax (LAM)
justification for the efficiency bounds can be established using the asymptotic equivalence argument.27 For the
local data-generating process that is described by a locally unstable distribution P1/n,g,b , the goal is to estimate
the average model parameter value:

                              n
                          1
(87)      (P1/n,g,b )               (Q1/n,fn,t ), with fn,t = g1 (yt-1 , yt ) + g2 (yt-1 , yt )b(t/n).
                          n   t=1


We formalize the precise meaning of semiparametric efficiency bounds based on local asymptotic minimax risk,
which is stated in the following theorem.


Theorem 4    (LAM Lower Bounds) Suppose assumptions 1 ­ 5 hold and (P1/n,g,b ) exists . Thus, for any
v  Rd , any arbitrary estimator sequence n satisfies

                                                                          2
          lim lim inf     sup            l      nv T n - (P1/n,g,b )          dP1/n,g,b  v T (DT D)-1 v.
          l n g G(Q0 ),bB



The method of first calculating the truncated mean squared error (MSE), then letting the ceiling l increase to
infinity, is widely adopted in the literature (e.g., Bickel, 1981; Le Cam and Yang, 2000; Kitamura, Otsu, and
Evdokimov, 2013).


Theorem 5     (LAM Upper Bounds) Suppose assumptions 1 ­ 5 hold and (P1/n,g,b ) exists. Then, for any
v  Rd , there exists an estimator sequence ^n such that

                                                                              2
          lim lim inf     sup            l      nv T ^n - (P1/n,g,b )             dP1/n,g,b  v T (DT D)-1 v.
          l n g G(Q0 ),bB



In our proof, we show that the efficient GMM estimator (Hansen, 1982) can achieve the semiparametric efficiency
bound. Importantly, the proof is similar to that of Theorem 1 in Li and M¨
                                                                         uller (2009) through using Le Cam's
theory of asymptotic equivalence. Therefore, Theorems 4 and 5 extend the results on the minimax efficiency
bounds for unconditional moment restrictions developed in Levit (1976), Nevelson (1977), and Chamberlain
(1987, Theorem 2) to general Markov processes with local instability.


                          APPENDIX C: PROOFS OF THE MAIN THEOREMS

1. Proof of Theorem 1

The test statistic based on the C statistic is ^n  1{Cn >c1- } , where c1- is the (1 - ) quantile of a chi-square
distribution with dm,2 - d,2 degrees of freedom. From Proposition 6, we know that Assumption 3.1 of Chen and
Santos (2018) is satisfied. Thus, by Lemma 3.2 of Chen and Santos (2018) and the results of Newey (1985a),
     27
    Dou, Pollard, and Zhou (2010) also appeal to the asymptotic equivalence argument to establish the global
minimax upper bound for a non-parametric estimation problem.
                                       DARK MATTER IN ASSET PRICING MODELS                                                                      57

it follows that for any GMM specification test n with an asymptotic level  and an asymptotic local power
function ( n   (Q0 )),


(88)         inf       lim      n dP1/n,g,0 
                                                              inf      lim         ^n dP1/n,g,0        (i.e., C test is asymptotically optimal)
          g A (Q0 ) n                                    g A (Q0 ) n
                                                                                                  2
(89)                                                 =        inf      lim P1/n,g,0        Gn         > c1- ,
                                                         g A (Q0 ) n


where A (Q0 )  g  GB (Q0 ) : |(2) (g1 )|   and (2) (g1 )  lin(D22 ) , and

                                                                    n
                                                    -1/2      1              (2)
                                                                              ^n ) ;
(90)      Gn = 2 - 2 D21 I- 1 T
                          F D21 2                                         mt (
                                                               n    t=1

                                                                                 T
see page 243 of Newey (1985a) and Appendix G.3 of this paper. Here 2 = I - D22 (D22 D22 )-1 D22
                                                                                             T
                                                                                                .

   Now, we obtain (e.g., Newey, 1985a; Chen and Santos, 2018, or Proposition 6 of this paper)

                   d
(91)      |Gn |2 -
                  2dm,2 -d,2 (µg ),



where 2
      dm,2 -d,2 (µg ) is a noncentral chi-squared random variable with degrees of freedom dm,2 - d,2 and the
noncentrality parameter µg = (2) (g1 )T 2 - 2 D21 I-1 T
                                                   F D21 2 
                                                            (2)
                                                                (g1 ).

   From (49) and (88) ­ (89), we conclude that

                                                                             2
(92)         inf       q (g, )         inf        lim P1/n,g            Gn         > c1-   =         inf   P 2
                                                                                                             dm -d (µg ) > c1- .
          g A (Q0 )               g A (Q0 ) n                                                  g A (Q0 )


Note that µg > 0 for all g  A (Q0 ), since 2 D21 I- 1 T
                                                  F D21 2 does not have unit eigenvalues. The local asymptotic

maximin power is then bounded from above by

                                                                                                                              
(93)         inf       q (g, )         inf        M dm,2 -d,2          µg , c1- = M dm,2 -d,2                  inf        µg , c1- ,
          g A (Q0 )               g A (Q0 )              2                                       2         g A (Q0 )


where the equality above is due to the continuity and monotonicity of the Marcum Q-function M (x1 , x2 ).

   Following the definition of µg and the fact that 2
                                                    2 = 2 as a projection matrix onto the linear space spanned

by the column vectors of D22 , it holds that


             inf       µg =      inf      (2) (g1 )T 2 I - 2 D21 I- 1 T
                                                                  F D21 2 2 
                                                                            (2)
                                                                                (g1 )
          g A (Q0 )           g A (Q0 )

                         =       inf      |(2) (g1 )T 2 (2) (g1 )| × the smallest eigenvalue of I - 2 D21 I- 1 T
                                                                                                           F D21 2
                              g A (Q0 )

                         = 2 × the smallest eigenvalue of I - 2 D21 I-1 T
                                                                     F D21 2 ,



where the last equality is due to the definition of the set A (Q0 ), in which |(2) (g1 )|   and (2) (g1 )  lin(D22 ).
                                                                                                              
   We shall now show that 1/(1 + (0 )) is an eigenvalue of I - 2 D21 I-        1 T
                                                                             F D21 2 , and thus inf g A (Q0 )  µg 
                                                                                        -1/2                -1/2        -1/2     T         -1/2
  2 /(1 + (0 )). In fact, 1 - 1/(1 + (0 )) is an eigenvalue of IF                              (IF - IB ) IF         = IF      (D21 2 D21 )IF     ,
                                          T  -1                                                                                      -1
                                                                                                                                      T
and thus an eigenvalue of       2 D21 IF D21 2 .             Therefore, 1/(1 + (0 )) is an eigenvalue of I -                2 D21 IF D21 2 .
58           HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

     Due to the monotonicity of the generalized Marcum Q-function, the local asymptotic maximin power is
upper bounded by

                                                             2      
(94)          inf      q (g, )  M dm,2 -d,2                        , c1-                 .
           g A (Q0 )                     2                1 + (0 )




Proof of Theorem 2

According to Proposition 10 (ii), we can show that

                       1   ^e,n ; yn ) - L(^e,n ; yn )
(95)       E wlim        L(        o               e             =  -1 E W ( )T LT
                                                                                 F IF LF W ( )
              n        2
                                                                                                             T
                                                                         + [e (g, b,  ) - o (g, b,  )] LT
                                                                                                         IF L e (g, b,  ),



where wlimn is the weak convergence limit and W (·) is a dm -dimensional Wiener process. The first term
above is

                                                                      1/2                              1/2
(96)        -1 E W ( )T LT
                         F IF LF W ( ) = 
                                          -1
                                             E tr IF LF W ( )W ( )T LT
                                                                     F IF

                                                             1/2         1/2
(97)                                                 = tr IF LF LT
                                                                 F IF              .


According to the definition of LF in (84),

                       -1 T    -1
(98)       LF LT
               F = ,1 IQ ,1 = IF .



Combining (97) and (98) yields


(99)        -1 E W ( )T LT
                         F IF LF W ( ) = d,1 .



Because (g1 )  lin(D), it holds that L (g1 ) = 0, and thus

                                                                                                2
                   T           1                      1   1
(100)      [e - o ] LT
                      IF L e =                         +                               b(u)du       (g2 )T LT
                                                                                                             IF L (g2 ).
                                                         1-                    0


The left-hand side of (100) is bounded from above by

                                                             2
           1        1   1
(101)                +                              b(u)du       (g2 )T LT
                                                                          IF L (g2 )
                       1-                    0
                                    
                     1+                             |(g2 )|2 × the largest eigenvalue of LT
                                                                                           IF L .
                                   1-

                                                                   1/2                 1/2
The largest eigenvalue of LT                         T
                            IF L is that of  = IF L L IF , which is the dark matter measure (0 ).
                                DARK MATTER IN ASSET PRICING MODELS                                                 59

Proof of Theorem 3

According to Proposition 10 (i), we can show that

                 1   ~e,n ; yn ) - L(~e,n ; yn )
(102)    E wlim    L(        o               e           =  -1 E W ( )T LT
                                                                         F IF LB W ( ) ,
               n 2


where wlimn is the weak convergence limit and W (·) is a dm -dimensional Wiener process. Further,

                                                  1 /2         1/2
(103)     -1 E W ( )T LT                         T
                       F IF LB W ( ) = tr(IF LB LF IF ).



                 -1 T                          -1 T       -1 T    -1
Because LB LT
            F = IB D11 D11 , 0dm,1 ×(d -d,1 ) IQ ,1 = ,1 IQ ,1 = IF , the equality (103) can further be

rewritten as


(104)     -1 E W ( )T LT
                       F IF LB W ( ) = d,1 .




Proof of Theorem 4

The local asymptotic normality (LAN) (see Proposition 5), as well as the implied contiguity, and Le Cam's
first and third lemmas play crucial roles in the proof as in the standard proof of semiparametric minimax lower
bounds (e.g. van der Vaart, 1998, Theorem 8.11 and Theorem 25.21). Our results are new in the sense that they
apply to Markov processes with local instability, which is more general than the i.i.d. case.

   Following the literature (e.g. Bickel, Klaassen, Ritov, and Wellner, 1993; van der Vaart, 1998), we define
the functional (Q) to be pathwise differentiable at Q0 relative to the parametric submodels s  Qs,f , if there
exists a measurable function  : Y × Y  Rd with       L2 (Q0 ) such that
                                                                  0


            1                          ,
(105)     lim [(Qs,f ) - (Q0 )] = EQ0 f
         s0 s


where  (yt-1 , yt )  (DT D)-1 DT h(yt-1 , yt , 0 ) with h(yt-1 , yt , 0 ) defined in Proposition 7 (e.g., Greenwood
and Wefelmeyer, 1995). According to Proposition 7, h(·, 0 ) satisfies the conditions: EQ0 [h(y, y , 0 )|y] = 0 and
EQ0 h(y, y , 0 )h(y, y , 0 )T = I .

   First, we only need to consider the case g1 (y, y ) = v T  (y, y ), g2 (yt-1 , yt )  0, and b(u)  0 for establishing
the lower bound. In such case, f (yt-1 , yt )  g1 (yt-1 , yt ) for all 1  t  n. Second, we further focus on the
estimators n such that n     n - 0 is uniformly tight under the distribution P0 , similar to van der Vaart
(1998). The tightness assumption can be dropped by a compactification argument (e.g. van der Vaart, 1988;
van der Vaart and Wellner, 1996, Chapter 3.11). Moreover, without loss of generality, due to Prohorov's theorem,
we can assume that

                                       n
                                 1                            d
(106)           n vT n - v T 0 ,            g1 (yt-1 , yt )   -
                                                               (0 , U0 ),
                                  n   t=1


where U0  N (0, v T (DT D)-1 v ) (see Proposition 4). Using the contiguity between P1/n,g,0 and P0 , Le Cam's
third lemma (e.g. van der Vaart, 1998, Theorem 6.6), and differentiability of (Qs,f ) with respect to s, we know
60            HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

that under the sequence of distributions P1/n,g,0 ,

                                                    d
(107)         n vT n - v T (P1/n,g,0 ) -
                                        g ,


where, appealing to Theorem 8.3 of van der Vaart (1998), the limiting random variable g has the following
representation with a certain measurable function  : Rd  R:


(108)      g =  (Xg ) - v T 
                                  
               =  (Xg ) - EQ0 v T f

               =  (Xg ) - v T (DT D)-1 v .


Here, the local estimation bias is   (DT D)-1 DT (g1 ) = (DT D)-1 v (similar to Corollary 1 or the proof of
Proposition 6 (ii)) and Xg  N (, (DT D)-1 ). Based on Theorem 8.6 of van der Vaart (1998) for estimating
normal means, it holds that for all measurable function  ,

                                                    2
(109)      EQ1/   n,f   2
                        g E
                           Q0
                                           v T X0       = v T (DT D)-1 v.


The key idea of (106) ­ (108) is a change-of-measure argument, inspired by Le Cam's theory of asymptotic
equivalence, whose stronger form has also been developed and used in the minimax inference of Dou, Pollard,
and Zhou (2010).

     Consequently, it suffices to show that the left-hand side of (109) is a lower bound for the minimax risk R:

                                                                             2
(110)      R  lim lim inf              l      nv T n - (P1/n,g,0 )                dP1/n,g,0 .
                  l n


In fact, it holds that

                                                                  2
           lim inf      l        nv T n - (P1/n,g,0 )                  dP1/n,g,0
            n
                                                                              2
                      lim inf          l      nv T n - (P1/n,g,0 )                dP1/n,g,0
                         n
                              
                     = EQ1/      n,g,0   l  2
                                            g .



Thus, the minimax risk can be bounded from below by

                                                              
(111)      R  lim EQ1/           n,f   l  2
                                          g  lim E
                                                  Q1/            n,f    l  2
                                                                           g .
                  l                                 l


According to the monotone convergence theorem, it follow that

                        
(112)      R  EQ1/      n,f   2
                              g .



Combining (109) and (112), the local asymptotic minimax lower bound result holds: R  v T (DT D)-1 v .
                                   DARK MATTER IN ASSET PRICING MODELS                                               61

Proof of Theorem 5

We start with

                                                               
(113)        n ^n - (P1/n,g,b ) =          n ^n - 0 -             n (P1/n,g,b ) - 0 .


According to Proposition 8 (ii), it follows that

                                                      n
                                               1
(114)        n ^n - 0 = -(DT D)-1 DT                       mt (0 ) + op (1).
                                                n    t=1


Consequently, similar to Corollary 1 or the proof of Proposition 6 (ii),

          
(115)        n (P1/n,g,b ) - 0 = -(DT D)-1 DT (g1 ) + o(1).


Thus, appealing to Proposition 6 (i), we can show that

                                d
(116)        n ^n - (P1/n,g,b ) -
                                 -(DT D)-1 DT W (1),


where W (·) is a dm -dimensional Wiener process. Therefore, for any v  Rd ,

                                                           2
(117)     lim inf   l         nv T ^n - (P1/n,g,b )            dP1/n,g,b = E l  X 2 , with X  N (0, v T (DT D)-1 v ).
           n


Let l increase monotonically to infinity, and using the monotonic convergence theorem, we obtain

                                                                   2
(118)     lim lim inf      l       nv T ^n - (P1/n,g,b )               dP1/n,g,b = E X 2 = v T (DT D)-1 v.
          l n




                                  APPENDIX D: PROOFS OF PROPOSITIONS


1. Proof of Proposition 1

Following the standard argument such as in the proof of Theorem 7.2 of van der Vaart (1998), we can show
that EQ0 [f ] = 0. Thus,

                                 dQs,f
(119)     EQ0 [(s)] = EQ0              -1 =         dQs,f -            dQ0 = 0.
                                  dQ0

According to Proposition 3, the conditional expectations denoted by f          ¯(yt-1 ) = EQ0 [f (yt-1 , yt )|yt-1 ] and
¯(yt ) = EQ0 [f (yt-1 , yt )|yt ] are the scores for the marginal distributions of yt-1 and yt , respectively. Because
f
the marginal distributions are constant over time,


(120)     EQ0 [f (y, y )|y] = EQ0 [f (y , y)|y] .
62            HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

2. Proof of Proposition 2

According to Definition 4, it follows that

              Q1/n,fn,t                                     
(121)     E               [mt (0 )] =     mt (0 ) 1 + fn,t / n + n dQ0 .


Because EQ0 [mt (0 )] = 0, the equality (121) above leads to

              Q1/n,fn,t                 (g1 ) + (g2 )b(t/n)
(122)     E               [mt (0 )] =                       +        mt (0 )n dQ0 .
                                                 n

Based on Assumption 5 and Definition 4, the Cauchy-Schwarz inequality leads to

                                                      1/2               1/2        1
(123)     |     mt (0 )n dQ0 |  EQ0 |mt (0 )|2              EQ0 |n |2         =o        .
                                                                                    n




3. Proof of Proposition 3

By the definition of a marginal distribution,


          dµs,f (y) =            dQs,f (y, y ) =         [1 + sf (y, y ) + sQ (s)] dQ(y, y )
                           y Y                     y Y

                     = 1+s               f (y, y )dKs,f (y |y) + s          Q (s)dKs,f (y |y) dµ(y).
                                   y Y                                y Y


                     ¯(y), we know that
By the definition of f


(124)                      ¯(y) + sµ (s) dµ(y),
          dµs,f (y) = 1 + sf


where µ (s)  EQ [Q (s)|y] and it converges to zero in quadratic mean under µ as s  0. Further, by definition,
it holds that

                             dQs,f (y, y )    1 + sf (y, y ) + sQ (s) dQ(y, y )
          dKs,f (y |y) =                   =          ¯(y) + sµ (s)
                               dµs,f (y)        1 + sf                 dµ(y)
                             1 + sf (y, y ) + sQ (s)
                           =
                               1 + sf¯(y) + sµ (s) dK (y |y).

Rearranging and combining terms leads to


(125)                                      ¯(y) + sK (y, s) dK (y |y),
          dKs,f (y |y) = 1 + s f (y, y ) - f


where K (y, s) converges to zero in quadratic mean under K (y |y) as s  0 for all y  Y. By definition of
~(y, y ), it follows that EQ f
f                            ~(y, y )|y = 0. Thus, similar to the proof of Proposition 1, we can show that
EQ [K (y, s)|y] = 0.
                                 DARK MATTER IN ASSET PRICING MODELS                                                             63

4. Proof of Proposition 4

According to Assumption 3 (i),

                                     p
(126)    n-1 max |g (yt-1 , yt )|2 -
                                    0.
               1tn


According to simple algebra, we can show that


(127)    n-1        ~2 = n-1
                    f                    ~1 (yt-1 , yt )2 + 2~
                                         g                   g1 (yt-1 , yt )~                       ~2 (yt-1 , yt )2 b(t/n)2 .
                                                                            g2 (yt-1 , yt )b(t/n) + g
                     n,t
               tn               tn


Therefore, by Lemma 4 of Li and M¨
                                 uller (2009), it follows that
                                                                                            
                         p
         n-1        ~2 -   Q0   2
                                   + 2EQ0 [~                        b(u)du + EQ0 g 2
                                                                                               b(u)2 du,
                    fn,t  E   g
                              ~1           g1 g
                                              ~2 ]                               ~1
               tn                                            0                          0


and hence


(128)    n-1        ~2  ( )  EQ0 g
                    f            ~T B g
                                      ~ .
                     n,t
               tn


Using the same argument, we can show that

                              p
(129)    n-1        EQ   ~2 
                     t-1 fn,t - ( )  EQ0 g
                                         ~T B g
                                              ~ .
               tn


The results above and Assumption 3 (i) together lead to a Lindeberg-type condition. Thus, according to the
mixing condition implied by the Doeblin condition for the Markov process, we can obtain the following CLT
result for martingale difference sequences:

          1         ~    d
(130)               fn,t -
                          N (0, ( )).
           n
               tn



5. Proof of Proposition 5

The proof is similar to that of Theorem 7.2 in van der Vaart (1998), except that we allow for non-IID time
                                                                                                 dKn,t
series and local instability. For brevity, we denote Kn,t  K1/n,gn,t . The random variable Wn,t        - 1 is
                                                                                                  dK0
well defined with probability one. According to (125), it follows that

                      1         ~       1          ~ n,t .
(131)          Wn,t =           f n,t +            
                       n                 n
         tn                tn                 tn


      ~              Q0                    Q0  ~             Q0 ~ 2
where f n,t  fn,t - Et-1 [fn,t ]. Because Et-1 n,t = 0 and E    n,t  0 as n   for all t = 1, · · · , n, it
follows that
                                                                         
              1           ~ n,t  = 0 and varQ0  1                    ~ n,t   1            ~ 2  0.
(132)    EQ0                                                                          EQ0   n,t
               n                                 n                           n
                     tn                                      tn                  tn
64            HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

Thus, 1            ~ n,t = op (1) under Q0 . And hence, the following approximation holds:
                   
              tn
       n

                     1             ~
(133)         Wn,t =               f n,t + op (1).
                      n
         tn                   tn


By Taylor expansion, we have

                        1
(134)    ln(1 + x) = x - x2 + x2 R(x),
                        2

where R(x) is a continuous function such that R(x)  0 as x  0. Therefore, it follows that

                   dKn,t                                               1 2      2
(135)    ln              =         ln(1 + Wn,t ) =               Wn,t - Wn,t + Wn,t R(Wn,t )
                    dK0                                                2
              tn             tn                           tn
                                          1           2                 2
(136)                    =         Wn,t -            Wn,t +            Wn,t R(Wn,t ).
                                          2
                             tn                tn                tn


Combining (133) and (136) yields

                   dKn,t  1              ~       1             2             2
(137)    ln              =               f n,t -              Wn,t +        Wn,t R(Wn,t ) + op (1).
                    dK0    n                     2
              tn                    tn               tn                tn


We shall first show that

               2         1        ~2 + op (1).
(138)         Wn,t =              f n,t
                         n
         tn                  tn


In fact, by the triangular inequality and the Cauchy-Schwarz inequality, it follows that


                 2       1        ~2             1 ~              2 ~      1 ~
(139)           Wn,t -            f n,t              n,t           f n,t +  n,t
                         n                        n                n        n
           tn                tn            tn
                                                                1/2                                 1/2
                                          1                                                     2
(140)                                                 ~2
                                                       n,t
                                                                       1          ~
                                                                                 2f      ~
                                                                                   n,t + n,t
                                                                                                          .
                                          n                            n
                                                 tn                         tn



Based on (125), it is straightforward to show that n    1        ~2
                                                            tn n,t = op (1). Further, according to Assumption 3
                                             2
                      1
(ii), it follows that n          ~      ~      n  1         ~2     ~2
                         tn 2fn,t + n,t                tn 4fn,t +2n,t = Op (1). Substituting them into (140) leads

to tn Wn,t    2
                 -n 1      ~2
                        tn fn,t = op (1). Therefore, the equality (137) can be rewritten as


                   dKn,t  1              ~        1            ~2 +          2
(141)    ln              =               f n,t -               fn,t         Wn,t R(Wn,t ) + op (1)
                    dK0    n                     2n
              tn                    tn                tn               tn
                                                          1
                          1              ~       1                              2
(142)                    =               f n,t -              (u)du +          Wn,t R(Wn,t ) + op (1).
                           n                     2    0
                                    tn                                   tn
                                       DARK MATTER IN ASSET PRICING MODELS                                                                 65
                                    2                                                                               2
Finally, we show that         tn   Wn,t R(Wn,t ) = op (1). Because we have shown that                        tn    Wn,t = Op (1), and

                 2                                               2
(143)           Wn,t |R(Wn,t )|  max |R(Wn,t )|                 Wn,t ,
                                       1tn
          tn                                               tn


it suffices to show that max1tn |R(Wn,t )| = op (1).

For any   > 0, there exists        R   > 0 such that

                                                                                         2
(144)     P0     max |R(Wn,t )| >                    P0 (|R(Wn,t )| > )              P0 Wn,t >          R
                 1tn
                                               tn                               tn

(145)                                                   ~2 > n
                                                     P0 f            R /4   +        P0 ~2
                                                         n,t                             n,t > n            R /4   .
                                               tn                               tn


By Markov's inequality, we can further show that

                                                 4             ~2 1{f~2 > n                           4              ~2
(146)     P0     max |R(Wn,t )| >                          EQ0 f n,t  n,t            R /4}       +               EQ0  n,t .
                 1tn                            n R                                                  n R
                                                      tn                                                    tn


                                                               ~2 are uniformly integrable, and thus
According to Assumption 3 (ii), the squared conditional scores f n,t


          1             ~2 1{f~2 > n
(147)               EQ0 f n,t  n,t           R /4}     0 as n  .
          n
               tn


Further, according to (125), it holds that

          1             ~ 2  0 as n  .
(148)               EQ0   n,t
          n
               tn


Therefore, P0 (max1tn |R(Wn,t )| > )  0 as n  .




6. Proof of Proposition 6
                                                                                                                                        
                                                                                     1 (g T )                                    1
                                                                 ~ t (0 )  mt (0 ) - 
We first prove part (i). According to Proposition 2, if defining m                                     for
                                                                                      n        b(t/n)
t = 1, · · · , n, we have
                                                                                                     
              Q1/n,fn,t                    1                                                 1
(149)     E               [m
                           ~ t (0 )] = o         , with fn,t = g (yt-1 , yt )T                       .
                                            n                                           b(t/n)

Further, for mt (0 ) which satisfies Assumption 5, we know that the corresponding m
                                                                                  ~ t (0 ) also satisfies Assump-
tion 5. Therefore, appealing to the functional central limit theorem (invariance principle) of McLeish (1975a)
and Phillips and Durlauf (1986), we know that

          1                    d
(150)                 ~ (0 ) -
                      m       W ( ), for all   [0, 1].
           n
                tn
66           HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

Thus,
                                                                                                                                        
           1                     1                         1      (g T )      1     d W (  ) ( g T
                                                                                                   )                           
(151)                  mt (0 ) =                ~ t (0 ) +
                                                m                                  -  +                                    
                                                                                                                                        .
            n                     n                        n              b (t/n )                                             b(u)du
                 tn                        tn                  tn                                                          0


Similarly, we can show that
                                                                                                
                1                    W (1) - W ( )
                                       d            (g T )                          1-
(152)                      mt (0 ) -
                                                   +                              1
                                                                                                .
              (1 -  )n t>n                1-         1-                               b(u)du
                                                                                  



     Now, we prove part (ii). Because g1 , g2  T (Q0 ), by the definition of n,t , we know that


(153)      0=       mt (n,t )dQ1/n,fn,t , for all t, n.


Using the Taylor expansion, we obtain

                                                                                 
(154)      0=        mt (0 ) +  mt (n,t )(n,t - 0 )          1 + fn,t / n + n,t / n dQ0 , for all t, n,


where n,t lies between 0 and n,t for all t and n. Suppose n,t converges 0 at the rate of n (as we verify
later). According to Assumption 5, it follows that
                               
               1           1                                            1
(155)      0 =  (g T )          + D(n,t - 0 ) + o                            , for all t, n.
                n       b(t/n)                                           n


Therefore, the parameter sequence n,t can be specified as
                                                  
                                  1           1                                  1
(156)      n,t - 0 = -(DT D)-1 DT  (g T )         +o                                   , for all t, n.
                                   n       b(t/n)                                 n


Hence, using the Taylor expansion again leads to
                                                                                                                           
                                                                                                     1        T
           1                       1                           1           n,t )(DT D)-1 DT (g ) 
(157)                  mt (n,t ) =               mt (0 ) -             mt (                               + o (1) .
            n                       n                          n                                  b(t/n)
                 tn                        tn                      tn


Due to Assumption 5, appealing to Lemma 4 of Li and M¨
                                                     uller (2009) leads to
                                                                                                              
                                                                                        T            
           1                       1                                   (g )
(158)                  mt (n,t ) =               mt (0 ) - D(DT D)-1 DT                          
                                                                                                               + o (1) .
            n                       n                                                                b(u)du
                 tn                        tn                                                    0


Because g1 , g2  T (Q0 ), it holds that (g1 ), (g2 )  lin(D), and thus
                                                                                            
                                                                    T            
           1                       1                      (g )
(159)                  mt (n,t ) =               mt (0 ) -                   
                                                                                             + o (1) .
            n                       n                                            b(u)du
                 tn                        tn                                0
                                       DARK MATTER IN ASSET PRICING MODELS                                                                  67

Similarly, we can show that
                                                                                                                  
                      1                                  1                 (g T )                     1-
(160)                              mt (n,t ) =                   mt (0 ) -                           1
                                                                                                                   + o (1) .
                 (1 -  )n t>n                       (1 -  )n t>n            1-                           b(u)du
                                                                                                     



   Finally, we prove parts (iii) and (iv). Using the Taylor expansion, we obtain

             1                                                                                   
(161)                       m t (^e,n ) = 1             mt (0 ) +
                                                                    1
                                                                              m t ( e,n )           n(^e,n - 0 ) + o (1) ,
              n                           n                         n
                       tn                          tn                   tn


where e,n lies between ^e,n and 0 . According to Proposition 8 (ii),

                                                                                                                  
             1                   ^e,n ) = 1                                     1
(162)                       m t (                       mt (0 ) - D(DT D)-1 DT                           mt (0 ) + op (1)
              n                           n                                      n
                       tn                          tn                                            tn


Further rearranging the terms on the right-hand side of (162) leads to
                                                                                             
             1                   ^e,n ) = I - D(DT D)-1 DT           1
(163)                       m t (                                                   mt (0 ) + op (1) .
              n                                                      n
                       tn                                                    tn


Similarly,
                                                                                                                               
                      1                 ^e,n ) =         1                               1
(164)                              m t (                         mt (0 ) - D(DT D)-1 DT                                mt (0 ) + op (1) .
                 (1 -  )n t>n                       (1 -  )n t>n                          n
                                                                                                                  tn


Part (iv) can be proved using analogous steps, which we do not repeat.




7. Proof of Proposition 7

Similar to the results in Severini and Tripathi (2013) and Chen and Santos (2018), the tangent set T (Q0 ) can
be characterized as follows:


(165)        T (Q0 ) = f  L2
                           0 (Q0 ) : E
                                      Q0
                                         [m(·, 0 )f ]  lin(D) ,


where lin(D) is the linear space spanned by the column vectors of D. Therefore, it suffices to show that


(166)        EQ0 [m(·, 0 )f ] = EQ0 [h(·, 0 )f ] for all f  L2
                                                             0 (Q0 ).



Under the assumption, the following identity holds:

                                                                                    
                 Q0                                Q0
(167)        E        [h(y, y , 0 )f (y, y )] = E       [m(y, y , 0 )f (y, y )] -         Ak ,
                                                                                    k=1
68          HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

where


(168)     Ak = EQ0 EQ0 [m(yk-1 , yk , 0 )|y0 = y] f (y, y ) - EQ0 EQ0 [m(yk , yk+1 , 0 )|y1 = y ] f (y, y ) .


Further, for each k  1, the Markov property implies that


(169)     EQ0 [m(yk , yk+1 , 0 )|y1 = y ] f (y, y ) = EQ0 [m(yk-1 , yk , 0 )|y0 = y ] f (y, y ).


Thus, the equation (168) can be rewritten as


(170)     Ak = EQ0 EQ0 [m(yk-1 , yk , 0 )|y0 = y] f (y, y ) - EQ0 EQ0 [m(yk-1 , yk , 0 )|y0 = y ] f (y, y ) .


It suffices to show that Ak = 0 for all k . In fact, the following equalities hold:


          EQ0 EQ0 [m(yk-1 , yk , 0 )|y0 = y ] f (y, y )
               = EQ0 EQ0 [m(yk-1 , yk , 0 )|y0 = y ] EQ0 [f (y, y )|y ]         (Law of Iterated Projections)
               = EQ0 EQ0 [m(yk-1 , yk , 0 )|y0 = y ] EQ0 [f (y , y)|y ]         (Proposition 3)
               = EQ0 EQ0 [m(yk-1 , yk , 0 )|y0 = y ] f (y , y)          (Law of Iterated Projections)


Therefore, Ak = 0 for all k  1, and hence from (167), it follows that


(171)     EQ0 [h(y, y , 0 )f (y, y )] = EQ0 [m(y, y , 0 )f (y, y )] .


According to Greenwood and Wefelmeyer (1995), we know that

                                                   
(172)     EQ0 h(y0 , y1 , 0 )h(y0 , y1 , 0 )T =         EQ0 m(y0 , y1 , 0 )m(y , y +1 0 )T = I.
                                                   =-


By Markov's property and the law of iterated projections, for all k  0,


(173)     EQ0 EQ0 [m(yk , yk+1 , 0 )|y1 ] |y0 = EQ0 [m(yk , yk+1 , 0 )|y0 ] .


Therefore, EQ0 [h(y, y , 0 )|y] = 0.



8. Proof of Proposition 8.

The proof follows the standard GMM approximations in Hansen (1982), Hansen (2007b), and Hansen (2012).



9. Proof of Proposition 9.

The cases of s with s  {e, o} follow the same derivations, and so we only show the case s = e. We first prove
                                    (1)                                            (1)      (1) T
part (i). Given the parameter value e,n , the constrained efficient GMM estimator (e,n , e (e,n )) for the full
                                   DARK MATTER IN ASSET PRICING MODELS                                                               69

model satisfies the first-order condition

             (1)      (1)     n
(174)     J (e,n , e (e,n ); ye ) = T
                                    ,1 e,n ,     with ,1 = [I, 0d,1 ×d,2 ],

                                                                                                       (1)
and e,n is a d,1 × 1 vector of Lagrangian multipliers for the constraints ,1  = n in search of the constrained
               (1)      (1) T                               (1)      (1)     n
GMM estimator (e,n , e (e,n )) . The Taylor expansion of J (e,n , e (e,n ); ye ) around 0 leads to
                                                                                                   
                                                                            (1)        (1)
          1             T  1
                                                                            e,n - 0
(175)      T,1 e,n = 2D                         mt (0 ) + 2IQ n                              (2)
                                                                                                    + op (1).
          n                 n                                                (1)
                                                                          e (e,n ) - 0
                                        tn


                                                                                         -1
We first multiply both sides of (175) by ,1 I-1
                                             Q , and then by ,1 I- 1 T
                                                                 Q ,1                           . The optimal Lagrangian multi-
pliers can be represented as
                                                                                 
          1                            -1        1 T  1
(176)      e,n = 2 ,1 I- 1 T
                       Q ,1                 ,1 I-
                                                Q D                     mt (0 )
          n                                           n
                                                               tn
                                            -1                (1)
                          + 2 ,1 I- 1 T
                                  Q ,1
                                                      (1)
                                                    n(e,n - 0 ) + op (1).


Substituting (175) and (176) into (174) yields
                                                                                                                    
          1                                  -1 T              -1      1 T  1
(177)         (1)
           J (e,n      (1)
                  , e (e,n     n
                           ); ye ) = 2T
                                      ,1 ,1 IQ ,1                 ,1 I-
                                                                      Q D                                    mt (0 )
          n                                                                 n
                                                                                                   tn
                                                        -1 T -1          (1)
                                             + 2T
                                                ,1 (,1 IQ ,1 )
                                                                   (1)
                                                                 n(e,n - 0 ) + op (1).


According to Proposition 1, we substitute (46) into (177) and obtain
                                                                                             
          1   (1)      (1)     n                -1 T  1
(178)      J (e,n , e (e,n ); ye ) = 2T
                                      ,1 IF ,1 IQ D                              mt (0 )
          n                                            n
                                                                          tn

                                                                                                                       
                                                       -1 T
                                             - 2T
                                                ,1 IF IB D11           (1) (g1 ) + (1) (g2 )                    b(u)du/  + op (1).
                                                                                                         0


Based on (80), we have
                                                                                                                             
        1                                     -1 T  1
(179)       (1)
         J (e,n      (1)
                , e (e,n     n
                         ); ye ) = 2T
                                    ,1 IF ,1 IQ D
                                                                                 mt (0 ) - I- 1 T
                                                                                            B D11 m,1  (g, b,  ) + op (1).
                                                                                                                
        n                                            n
                                                                          tn


Given the baseline efficient GMM estimator ~(1) based on the estimation sample, the constrained GMM estimator
                                            e,n
 ~(1)   ~ (1) T
( , e ( )) for the full model satisfies the first-order condition
  e,n     e,n



(180)     J (~(1) , e (~(1) ); yn ) = T (1) ,     with ,1 = [I, 0d,1 ×d,2 ],
              e,n       e,n     e     ,1 e,n



and (1)                                                                               ~(1)
    e,n is a d,1 × 1 vector of Lagrangian multipliers for the constraints ,1  = e,n in search of the constrained

GMM estimator (   ~(1) , e (~(1) ))T . The Taylor expansion of J ( ~(1) , e (~(1) ); yn ) around ((1) , e ((1) ))T , to-
                    e,n      e,n                                           e,n         e,n         e                   e,n   e,n
70          HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

gether with (180), leads to
                                                                            
          1         1                                      ~(1) - (1)
                                                            e,n    e,n
(181)      T  (1) =  J (e,n
                        (1)      (1)
                            , e (e,n     n
                                     ); ye ) + 2IQ n                         + op (1).
          n ,1 e,n  n                                 e ( ~(1) ) - e ((1) )
                                                           e,n         e,n


                                                                                    -1
We first multiply both sides of (181) by ,1 I- 1                   T
                                             Q , and then by ,1 IQ ,1                    . The optimal Lagrangian multipliers
can be represented as

          1              -1 1                              
           (1)                   (1)      (1)     n           ~(1) - (1) ) + op (1).
(182)       e,n = IF ,1 IQ    J (e,n , e (e,n ); ye ) + 2IF n( e,n   e,n
          n                 n

Further substituting (177) into equation (182) above yields
                                                             
          1               -1 T  1                                   
(183)      (1)                                                         ~(1) - (1) ) + op (1).
            e,n = 2IF ,1 IQ D                          mt (0 ) + 2IF n( e,n   0
          n                      n
                                                 tn


Based on Proposition 8, we obtain
                                                                  
                        (1)         1 T  1                (1) (1)
(184)       n(~(1) -    0 )   = -I -     
               e,n                 B D11                 mt (0 )     + op (1).
                                          n
                                                    tn



Substituting (184) into (183) gives the following asymptotic representation of 1 (1) :
                                                                               n e,n
                                                                                                             
          1               -1 T  1                                       1 T  1                   (1) (1)
(185)      (1)
            e,n = 2IF ,1 IQ D                          mt (0 ) - 2IF I-
                                                                      B D11                     mt (0 ) + op (1).
          n                      n                                           n
                                                 tn                                        tn


We substitute (177) and (185) into (181) and multiply the both sides by I- 1
                                                                         Q /2. The estimator can be represented
by
                                                                                        
                   ~(1) - (1)
                    e,n   e,n       = -I -1 T     -1 T  1       (1) (1)    (1)
(186)       n                            Q ,1 IF IB D11        mt (0 ) - e     (g, b,  ) + op (1)
                  ~(1)        (1)
               e (e,n ) - e (e,n )                        n
                                                            tn
                                                                        
                                                         1      (1) (1)
                                    = -I -1 T     -1 T 
                                         Q ,1 IF IB D11        mt (n,t ) + op (1).
                                                          n
                                                                          tn



                                                (1)
    Now we prove part (ii). The estimators e (e,n   ) and ^(2) = e (^(1) ) are the constrained efficient GMM
                                                           e,n       e,n

estimators for the nuisance parameter (2) when controlling for ,1  = (1) and ,1  =      ^(1) , respectively. Due
                                                                                    e,n                    e,n
                                   (1)
                                ^n , e (      (1)
                                        ^n ); yn ) = 0, the Taylor expansion of J (^n , e (          (1)
                                                                                           ^n ); yn ) around     (1)
to the first order condition J (               e                                                  e
 (1)      (1) T
(e,n , e (e,n )) leads to
                                                                         
                                                        ^(1) - (1)
                                                        
                (1)      (1)     n                       e,n   e,n
(187)    0 = J (e,n , e (e,n ); ye ) + 2 IQ      n                        + op (1).
                                                       ^(1)        (1)
                                                    e (e,n ) - e (e,n  )
                                     DARK MATTER IN ASSET PRICING MODELS                                        71

Substituting (177) into (187) and multiplying the both sides by I- 1
                                                                 Q /2, we have

                                                                                                
                       ^(1) - (1)
                                                             -1 T  1
                                                                                                
(188)           n 
                        e,n    e,n       = -I -
                                              Q
                                                1 T
                                                    I
                                                  ,1 F     I
                                                         ,1 Q  D         m (
                                                                          t 0 ) - I -1 T
                                                                                    B D      
                                                                                       11 m,1 e  + op (1).
                   e (^(1) ) - e ((1) )                             n                           
                       e,n         e,n                                tn


10. Proof of Proposition 10

We first approximate L(~(1) ; yn ). According to the second-order Taylor expansion around ((1) , e ((1) )), it
                        e,n    e                                                           e,n      e,n

follows that
                                                                                           
                                                           T
                                                                   ~(1)
                                                                   e,n - e,n  (1)
(189)        L(~(1) ; yn ) = 1 J ((1) , e ((1) ); yn )     n                               
                e,n    e          e,n         e,n    e
                              n                                   ~(1)
                                                               e (e,n  ) - e (e,n  (1)
                                                                                       )
                                                           T                                       
                                         ~(1) - (1)
                                                                             ~(1) - (1)
                                                                             
                                          e,n     e,n                         e,n       e,n
                             + n                            IQ n                                    + op (1).
                                  e (   ~(1) ) - e ((1) )               e ( ~(1)
                                                                                 ) -     e ( (1)
                                                                                                 )
                                         e,n           e,n                   e,n             e,n



Thus, following (179) and (186),


(190)        L(~(1) ; yn ) = -2 [LF e,n + L e ]T IF LB e,n +  T LT IF LB e,n + op (1).
                e,n    e                                     e,n B




   We now approximate L(~(1) ; yn ). According to the second-order Taylor expansion around ((1) , o ((1) )), it
                         e,n    o                                                           o,n      o,n

follows that
                                                                                          
                                                           T
                                                                         ~(1) - (1)
                                                                         
(191)        L(~(1) ; yn ) = 1 J ((1) , o ((1) ); yn )            n 
                                                                          e,n    o,n      
                e,n    o          o,n      o,n     o
                             n                                       o (~(1) ) - o ((1) )
                                                                           e,n        o,n
                                                               T                           
                                            ~(1) - (1)
                                                                          ~(1) - (1)
                                                                          
                                             e,n    o,n                    e,n    o,n
                              +      n                        IQ n                          + op (1).
                                        o (~(1) ) - o ((1) )         o ( ~(1)
                                                                              ) -     (1)
                                                                                  o (o,n )
                                            e,n         o,n               e,n



Similarly,

                                                   T
               ~(1) ; yn ) = -2 [LF o,n + L o ] IF LB e,n +  T LT IF LB e,n + op (1).
(192)        L( e,n    o                                    e,n B




   We now approximate L(^(1) ; yn ). According to the second-order Taylor expansion around ((1) , o ((1) )), it
                         e,n    e                                                           e,n      e,n

follows that
                                                                                  
                                                           T   ^(1) - (1)
                                                               
(193)        L(^(1) ; yn ) = 1 J ((1) , e ((1) ); yn ) n 
                                                                e,n     e,n       
                e,n    e          e,n      e,n     e
                             n                             e (^(1) ) - e ((1) )
                                                               e,n          e,n
                                                       T                                  
                                       ^(1) - (1)
                                                                       ^(1) - (1)
                                                                       
                                        e,n   e,n                       e,n     e,n
                              + n                       IQ n                               + op (1).
                                      ^(1)        (1)
                                   e (e,n ) - e (e,n )                ^(1)
                                                                  e (e,n ) - e (e,n (1)
                                                                                        )

Similarly,

                                               T
               ^(1) ; yn ) = - [LF e,n + L e ] IF [LF e,n + L e ] + op (1).
(194)        L( e,n    e
72             HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

     We now approximate L(^(1) ; yn ). According to the second-order Taylor expansion around ((1) , o ((1) )), it
                           e,n    o                                                           o,n      o,n

follows that
                                                                                          
                                                          T
                                                                         ^(1) - (1)
                                                                         
(195)        L(^(1) ; yn ) = 1 J ((1) , o ((1) ); yn )            n 
                                                                          e,n    o,n      
                e,n    o          o,n      o,n     o
                             n                                       o (^(1) ) - o ((1) )
                                                                           e,n      o,n
                                                                  T                      
                                             ^(1) - (1)
                                                                        ^(1) - (1)
                                                                        
                                              e,n   o,n                  e,n   o,n
                               +      n                       IQ n                        + op (1).
                                            ^(1)        (1)
                                         o (e,n ) - o (o,n )           ^(1)        (1)
                                                                    o (e,n ) - o (o,n  )

Similarly,

                                                   T                                      T
               ~(1) ; yn ) = -2 [LF o,n + L o ] IF [LF e,n + L e ] + [LF e,n + L e ] IF [LF e,n + L e ] + op (1).
(196)        L( e,n    o




                                      APPENDIX E: PROOFS OF COROLLARIES

1. Proof of Corollary 1

We can derive the result following the same derivations for (156) under the baseline GMM model Q(1) .



2. Proof of Corollary 2

The proof is similar to that of Lemma 1 of Li and M¨
                                                   uller (2009), which is based on Le Cam's first lemma (see,
e.g., van der Vaart, 1998, Page 88).



                        APPENDIX F: DERIVATION OF THE DISASTER RISK MODEL

We first show how to derive the Euler equation, and then how to obtain the dark matter measure (p,  ). The
total return of market equity from t to t +1 is erM,t+1 , which is unknown at t, and the total return of the risk-free
bond from t to t + 1 is erf,t , which is known at t. Thus, the excess log return of equity is rt+1 = rM,t+1 - rf,t .
The inter-temporal marginal rate of substitution is Mt,t+1 = D e-D gt+1 . The Euler equations for the risk-free
rate and the market equity return are


(197)        1 = Et [Mt,t+1 erM,t+1 ] and e-rf,t = Et [Mt,t+1 ] .


Thus, we obtain the following Euler equation for the excess log return:


(198)        Et [Mt,t+1 ] = Et [Mt,t+1 ert+1 ] .


The left-hand side of (198) is equal to

                                                              1   2   2   e D v
             Et [Mt,t+1 ] = Et e-D gt+1 = (1 - p)e-D µ+ 2 D  + p                ,
                                                                           - D
                                        DARK MATTER IN ASSET PRICING MODELS                                               73

and the right-hand side of (198) is equal to

                                                                                                          2
                                                                         -D µ+ + 1  2 2 2             e 2 +(D -b)v
           Et [Mt,t+1 e   rt+1
                                 ] = Et e   -D gt+1 +rt+1
                                                            = (1 - p)e           2 (D  + -2D  )   + p              .
                                                                                                        + b - D

Thus, the Euler equation (198) can be rewritten as

                                                                                                      2
                            1 2 2
                      -D µ+ 2                  2                                         eD v   e 2 +(D -b)v
(199)      (1 - p)e           D 
                                         e+ 2 -D        - 1 = p( ), where ( ) =               -                     .
                                                                                          - D     + b - D

Using the Taylor expansion, we obtain the approximation

                 2
                     -D                      2
(200)      e +   2           -1+               - D ,
                                             2

which, combined with (199), gives the approximated Euler equation in (69).

   Now, we show how to derive the dark matter measure. The Jacobian matrix of the moment restrictions and
the asymptotic variance-covariance matrix are
                                                                                                            
                        -1        0             p(1 - p)        0       p(1 - p)                          0
(201)      D11 =                   p  and 11 =                    2 p                                     p  , respectively.
                        0        - 2                0    (1 - p) + 2        0
                                                                                                          2

The approximation above is simply due to the tiny magnitude of  2  0. The information matrix for the baseline
model is
                                                         
                                           1           0
                                       p(1 - p)
(202)           T
           1 = D11 - 1
                   11 D11                              p .
                                                         
                                           0
                                                       2

Next, the Jacobian matrix of moments restrictions and the asymptotic variance-covariance matrix for the full
model are
                                                                             
                                 -1                      0
                                                          p
                                                                             
                                 0                      - 2
                                                                             
(203)      D=                                            
                                                                             ,
                                                                             
                                   (p,  )                (p,  ) pb           
                     -(1 - p)                  -(1 - p)        - 2
                                   p                            

and
                                                                                  
                     p(1 - p)                  0                         0
                                                 p
                                                                                 
(204)      =
                        0              (1 - p) 2 +           (1 - p) + bp/ 2     ,
                                                 2                               
                        0             (1 - p) + bp/ 2        (1 - p) 2 + pb2 / 2


where

                                                                                  ( -b)v
                                      2                2 2
                                                       D            e D v    1 2 e D          p
(205)       (p,  )  D  -                + ln 1 + eD µ- 2                  - e2                   .
                                      2                              - D         + b - D     1-p
74          HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

We can also derive the closed-form solution for the dark matter measure in (71) if we use the approximate Euler
equation in (69). In this case, using the notation introduced in (69) and (72), we can express the information
matrix for (p,  ) under the full GMM model as

                        ( )2 e2D µ-D 
                                                             2    2                        2 2             
              1                                                              p    e2D µ-D  ( )(     )
          p(1 - p) + (1 - 2 ) 2 (1 - p)3                                (1 - 2 ) 2 (1 - p)2                
(206)                         2 2
                                                                                    2                  2
                                                                                                           .
                p     e2D µ-D  ( )(   )                                 p
                                                                           +
                                                                                 ( )
                                                                                        e
                                                                                               2 2
                                                                                          2D µ-D     p     
           (1 -  )2 2
                        (1 - p)
                               2
                                                                         2
                                                                               1- 2   2            1 -   p

                                                                                                         -1/2   -1/2
The largest eigenvalue of the matrix 1/2 -1 1/2
                                         1      is also the largest eigenvalue of 1                             1      . In this case,
the eigenvalues and eigenvectors are available in closed form. This gives us the formula for () in (71).



                       APPENDIX G: MISCELLANEOUS PROOFS AND DERIVATIONS

                                                      G.1. Moment Rotations
                                                                                  
                                                                  L11        0
Construct a lower block triangular matrix L =                                      such that
                                                                  L21       L22


(207)    -1 = LT L.


It is most straightforward to analyze a rotated system of moment restrictions. Let
                                                                                                     
                                                       (1)                                (1)
                                                 L11 mt ((1) )                          ~ t ((1) )
                                                                                        m
(208)    m
         ~ t () = Lmt () =                     (1)                    (2)
                                                                                  =
                                                                                           (2)
                                                                                                     .
                                       L21 mt ((1) ) + L22 mt ()                         m
                                                                                         ~ t ()

Further, we let
                                                                                           
                                     L11 D11                 0           D~            0
(209)    ~ = LD = 
         D                                                             =  11               .
                              L21 D11 + L22 D21        L22 D22           D~ 21        ~ 22
                                                                                      D

For notational simplicity, we drop the ~ but use the transformed system.



                                            G.2. Hellinger-Differentiability Condition

The condition (35) is equivalent to the condition

                       1/2
           dQs,g                  1
(210)                        = 1 + sg + s(s),
            dQ                    2

where (s) converges to zero in L2 (Q) as s  0. Equation (210) is equivalent to

                                      1/2                    2
                   1         dQs,g                    1
(211)    lim                                -1       - g         dQ = lim         (s)2 dQ = 0.
         s0        s          dQ                      2                  s0
                                  DARK MATTER IN ASSET PRICING MODELS                                                         75

                                                 G.3. The Expression of 

                          T     T     T         T        T
Let D = [D1 , D2 ] where D1 = [D11 , D21 ] and D2 = [0, D22 ]. Thus, we have28
                                                           
                        T          -1    T       I     0
(212)      P2 = I - D2 D2 D2            D2 =               .
                                                 0    2

Using the rules for the inversion of partitioned matrices, we have
                                                                                                                                         
                              T          -1                                         T              -1    T     T      -1
         -1                  D1 P2 D1                                            - D1 P2 D1             D1 D2 D2 D2
 DT D         =              -1                       -1                 -1                -1                    -1                 -1
                                                                                                                                         .
                     T             T     T                     T                 T               T     T               T     T
                  - D2 D2         D2 D1 D1 P2 D 1             D2 D2           + D2 D2           D2 D1 D1 P2 D1        D1 D2 D2 D2

We can then show that

                     -1                          -1                              -1
           D DT D         DT = D1 D1
                                   T
                                     P2 D1             T
                                                      D1       T
                                                         - D1 D1 P2 D1                  T
                                                                                       D1 (I - P2 )
                                                        T                -1    T
                                        - (I - P2 ) D1 D1 P2 D1               D1
                                                                    T                     -1    T
                                        + (I - P2 ) + (I - M2 ) D1 D1 P2 D1                    D1 (I - P2 )
                                               T                -1    T
(213)                        = I - P2 + P2 D1 D1 P2 D1               D1 P2 .


We conclude that

                              -1                                        -1
(214)       = I - D DT D                            T
                                   DT = P2 - P2 D1 D1 P2 D1                   T
                                                                             D1 P2 .

                  T
Recall that IF = D1 P2 D1 (from Equation (31)). The matrix  can be rewritten as
                                                                     
                   I - D11 I- 1 T
                            F D11
                                                -1 T
                                           D11 IF D11 2
(215)      =                                                         .
                    2 D11 I- 1 T
                           F D11        2 - 2 D21 I- 1 T
                                                   F D21 2




                      APPENDIX H: DARK MATTER OF LONG-RUN RISK MODELS

In the second example, we consider a long-run risk model similar to Bansal and Yaron (2004) and Bansal, Kiku,
and Yaron (2012). In the model, the representative agent has recursive preferences as in Epstein and Zin (1989)
and Weil (1989) and maximizes her lifetime utility,

                                                                            1
                                                              1-1/L      1-1/L
                           1-1/L                   1-          1-L
(216)      Vt = (1 -   L )Ct         + L      Et Vt+1 L                            ,


where Ct is consumption at time t, L is the rate of time preference, L is the coefficient of risk aversion for
timeless gambles, and L is the elasticity of intertemporal substitution when there is perfect certainty. The
log growth rate of consumption ct , the expected consumption growth xt , and the conditional volatility of

  28
       The matrix inversion is the generalized inversion.
76           HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

consumption growth t evolve as follows:


(217a)     ct+1 = µc + xt + t              c,t+1 ,

(217b)       xt+1 = xt + x t           x,t+1 ,

             2      2    2   2
(217c)       t +1 =  +  (t -  ) + w                     ,t+1 ,

             2          2  2
(217d)       t +1 = max  , t+1 ,



where the shocks       c,t , x,t ,   and     ,t   are i.i.d. N (0, 1) and mutually independent. The volatility process (217c)
                                          2
potentially allows for negative values of t . Following the literature, we impose a small positive lower bound
 (= 1 bps) on variance t in solutions and simulations. Negative values of conditional variance can also be
                                                                   2
avoided by changing the specification. For example, the process of t can be specified as a discrete-time version
of the square root process.29

     Next, the log dividend growth dt follows


(218)      dt+1 = µd + d xt + d,c t                  c,t+1   + d,d t   d,t+1 ,



where the shocks       d,t   are i.i.d. N (0, 1) and independent of the other shocks in (217a­217c). The equilibrium
excess log return follows

            e      e
(219)      rt+1 = µr,t + c t         c,t+1   + x  t     x,t+1   +  w     ,t+1    + d,d t   d,t+1 ,



where the conditional average log excess return is

                                         1 2
(220)      µe         2         2     2
            r,t = c c t + x x x t +   w - rm ,t ,
                                         2
                 2        2 2    2 2    2 2
(221)      where r m ,t
                        = c  t + x  t +  w + 2   2
                                             d,d t .



The expressions for c , x ,  , c , x ,  , and Am,j with j = 0, 1, 2 are presented in Online Appendix.
                                                                                              e
     The model contains stochastic singularities. For instance, the excess log market return rt+1 is a deterministic
                                      2         2
function of ct+1 , dt+1 , xt+1 , xt , t+1 , and t . The log price-dividend ratio zm,t is a deterministic function
          2
of xt and t . To avoid the problems posed by stochastic singularities, we add noise shocks r t                 r,t+1   to stock
returns, with   r,t   being i.i.d. standard normal variables and mutually independent of other variables. This is a
standard approach in the dynamic stochastic general equilibrium (DSGE) literature for dealing with stochastic
singularity. The stochastic singularity is one of the main reasons why we adopt the moment-based method,
rather than the likelihood-based method, to evaluate and characterize the structural models.
     29
     To ensure that our analysis applies as closely as possible to the model as formulated in the literature, we
deliberately choose to follow Bansal, Kiku, and Yaron (2012, 2016a). In particular, following these papers, we
also solve the model using a local log-linear expansion around the steady state. Thus, the approximate price-
dividend ratio is not affected by the presence of the lower bound on the conditional variance process. As Bansal,
Kiku, and Yaron (2016a) show, the resulting approximation error, when compared to the global numerical
solution, is negligible. When computing our asymptotic Fisher fragility measure, we impose the lower bound on
conditional variance. Thus, our asymptotic measure reflects the specification of the conditional variance process
with the lower bound.
                                DARK MATTER IN ASSET PRICING MODELS                                          77
                                                       TABLE I
                      Parameters of the Benchmark Long-Run Risk Model (M1).

                        Preferences          L        L       L
                                           0.9989      10     1.5
                        Consumption          µc               x                            w
                                           0.0015    0.975   0.038     0.0072   0.999   2.8e - 6
                        Dividends            µd       d       d,c       d,d
                                           0.0015     2. 5    2.6       5.96
                        Returns              r
                                             3.0
Note: Model M2 has  = 0.98 and L = 27, while the other parameters are the same as in Model M1.


Quantitative analysis

In our computation of the dark matter measure, we consider a system of moment restrictions based on the joint
                                     2           e     30
dynamics of time series (ct+1 , xt , t , dt+1 , rt+1 ).

   We choose the model of consumption (217a)­(217d) and dividend (218) as the baseline model Q(1) with
                       2
variables (ct+1 , xt , t , dt+1 ). The moment restrictions associated with the baseline model constitute the set
of baseline moment restrictions. We assume that the econometrician observes the processes of consumption and
                                                                2
dividends, including the conditional mean and volatility xt and t , and the process of asset returns.

   The simulated moments and sample moments are listed in Table II. The sample moments are based on
annual data from 1930 to 2008, and the simulated moments are 80-year annual data aggregated from monthly
simulated data.

                                                       TABLE II
                                          Simulated and Sample Moments.
                                Data                    Model 1                         Model 2
                Moment         Estimate         5%      Median       95%         5%     Median     95%
                E [rM - rf ]      7.09          2.33     5.88        10.58      3.65     6.78      10.05
                E [rM ]            7.66         2.91     6.66        11.20       4.42     7.75     11.20
                 (rM )            20.28        12.10     20.99       29.11      15.01    17.55     20.33
                E [rf ]           0.57         -0.20     0.77        1.45       0.47      0.96      1.46
                 (rf )            2.86          0.64     1.07        1.62       0.73     0.94      1.23
                E [p - d]          3.36         2.69     2.99         3.30       2.77     2.81      2.85
                 (p - d)          0.45          0.13     0.18         0.28      0.09     0.11       0.13



   Accordingly, the baseline parameters are (1) = (µc , , x ,  2 , , w , µd , d , d,c , d,d ) with d,1 = 10. By
measuring the fragility of the long-run risk model relative to this particular baseline, we can interpret the
fragility measure as quantifying the information that asset pricing restrictions provide for the consumption and
dividend dynamics above and beyond the information contained in consumption and dividend data. We explicitly
account for uncertainty about preference parameters L and L by including them in the nuisance parameter
vector (2) . Thus, (2) = (L , L ). The extra data investigated by the full structural model Q are the excess log
                e
market returns rt+1 . Other parameters, included in the auxiliary parameter vector (L , r ), are fixed at known

  30
       Details can be found in the Online Appendix.
78           HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

                                                      TABLE III
                        Dark Matter Measures for the Long-Run Risk Models
                                                                   (1)
              Model        (0 )
                                    µc          x       2              w     µd    d      d,c   d,d

                                      I. Nuisance parameter vector  : (L , L )
               (M1)         196.3   1.0   1.1   1.0     48.9    97.8   1.0   1.0    3.4   1.0    1.0
               (M2)          21.1   1.0   1.1   1.0      1.0     3.4   1.0   1.4    4.2   1.0    1.0
                                      II. Nuisance parameter vector  : empty
               (M1) 3.57 · 105 1.0 2.1          1.1    115.6   117.5   1.3   1.1    7.1   1.0    1.0
               (M2)     287.7 1.0 2.5           1.0      1.0     6.3   1.0   1.9   31.3   1.0    1.0
Note: The direction corresponding to the worst-case one-dimensional fragility measure (0 ) for Model M1 is
           
given by vmax  = [0.000, 0.000, -0.000, 0.020, -0.001, 0.999, -0.001, 0.000, -0.000, 0.000]. Model M2 has  = 0.98
and L = 27 with other parameters unchanged. In Panel I, we account for the uncertainty of preference
parameters (2) = (L , L ) to compute the dark matter measure of the baseline parameters (1) . That is, (1)
and (2) are treated as unknown parameters, while (L , r ) are treated as auxiliary parameters with known
fixed values in Panel I. In Panel II, these preference parameters are fixed as auxiliary parameters with the
nuisance parameter vector (2) empty. That is, (1) is treated as unknown parameters, while (L , L ) and
(L , r ) are treated as auxiliary parameters with known fixed values in Panel II.



values. These values form a part of the imposed functional-form specification of the structural component that
is under fragility assessment. Note that the baseline model covers the joint dynamics of consumption growth
and dividend growth. The structural model adds the description of the distribution of stock returns in relation
to the consumption and dividend growth processes.

     The parameter values of Model M1 follow Bansal, Kiku, and Yaron (2012) and are summarized in Table I.
As Bansal, Kiku, and Yaron (2012) (Table 2, page 194) show, the simulated first and second moments, based
on the parametrization of Model M1, match the set of key asset pricing moments in the data reasonably well.
The same is true for Model M2, whose parameter values are also reported in Table III (see Table II for the asset
pricing moment matching). Our main purpose of presenting Table III is to compare the fragility of M1 and M2,
two different calibrations of the LRR model, while the two panels are meant to further illustrate the fact that
different treatments of the nuisance parameters can also affect the fragility measure.

     First, consider Panel I of Table III. This panel contains fragility measures computed under the specification
that treats preference parameters as unknown nuisance parameters whose uncertainty needs to be taken into
account when computing the dark matter measure. The row (M1) of Panel I reports fragility measures for Model
M1 when the unknown nuisance parameters are L and L . The dark matter measure (0 ) = 196.3 is large.
This implies that to match the precision of the estimator for the full structural model in all directions, the
estimator based on the baseline model would require a time-series sample that is 196.3 times as long.

     A high value of (0 ) suggests that the asset pricing implications of the structural model are highly sensitive
to plausible perturbations of parameter values. We compute the fragility measure for each individual parameter
in the vector (1) . All of the univariate measures are much lower than the worst-case one-dimensional fragility
                                DARK MATTER IN ASSET PRICING MODELS                                                 79

measure (i.e. the dark matter measure) (0 ), with a larger fragility measure for  2 (the long-run variance of
consumption growth) and  (the persistence of conditional variance of consumption growth) than for the other
individual parameters. This shows that it is not sufficient to consider perturbations of parameters one at a time
to quantify model fragility; M¨
                              uller (2012) highlighted a similar insight on sensitivity analysis.

   In comparison, in Panel II of Table III we show fragility measures under the specification that ignores the
uncertainty about preference parameters. This type of analysis is sensible if the model is not fully estimated, but
rather the preference parameters are fixed at certain values. For instance, one may specifically design a model to
capture the moments of asset returns with a low value of risk aversion. In that case, the choice of the preference
parameters is effectively subsumed by the specification of the functional form of the model, and treating them
as auxiliary parameters is in line with the logic of the model construction. The fragility measures in Panel II
are higher. In particular, the worst-case one-dimensional fragility (i.e. the dark matter measure) (0 ) increases
dramatically from 196.3 to 3.57 · 105 .

   In our model we have assumed that the conditional mean and volatility of consumption growth, xt and t , are
observable. An interesting question is whether the model becomes more or less fragile when agents observe xt and
t but the econometrician does not (e.g., Schorfheide, Song, and Yaron, 2018). When the agents themselves need
to learn about the latent states and potentially deal with model uncertainty (e.g., Collin-Dufresne, Johannes,
and Lochstoer, 2016; Hansen and Sargent, 2010), the cross-equation restrictions implied by asset prices differ
from the case of fully observable state variables. It is therefore difficult to establish the precise effect of limited
observability on model fragility without further analysis, which is beyond the scope of this paper. Numerically,
                           2                                                                 2
the assumption that xt and t are observable means that we do not need to integrate out xt or t in the moment
restrictions when computing the model fragility measure. Furthermore, since we are examining the fragility of
a specific calibration of the model, we can compute the fragility measure under the set of calibrated parameter
                                                                   2
values, instead of having to first filter out the values of xt and t from the data, as in Constantinides and
Ghosh (2011), Bansal, Kiku, and Yaron (2016b), and Schorfheide, Song, and Yaron (2018), and then estimate
the corresponding parameter values.




Monte Carlo experiments

We use simulations to illustrate the connections between the dark matter measure, internal refutability, and
external validity of long-run risk models in finite samples. In the simulation experiment, we assume that all the
parameters except  are treated as auxiliary parameters, fixed at known constant values and thus subsumed into
the functional form of the moment function (i.e. model specifications). From the dark matter evaluation in Table
III, we learn that the assumed identification of  (i.e., the uncertainty of  ) is a major source of model fragility
for long-run risk models. Focusing on  simplifies our simulation illustration and increases the transparency
by allowing us to consider a few key (transformed) moment restrictions (i.e. a small yet essential subset of the
moment restrictions used in constructing Table III):
                                                                                       
                                (~
                                 t 2
                                     - 2 )   ,t+1
(222)     mt () = ()-1/2                                                                and  = ,
                                 e      e
                                rt+1 - µr,t - c t   c,t+1 - x t   x,t+1 -  w    ,t+1
80            HUI CHEN, WINSTON WEI DOU, AND LEONID KOGAN NOVEMBER 26, 2019

where variables      c,t+1 ,   x,t+1 ,   and   ,t+1   are the residuals in (217a) ­ (217d) depending on observed data and
unknown parameters in , and                µe
                                            r,t   is defined in (220) and also dependent on observed data and unknown
parameters in . Here () is the asymptotic covariance matrix of the untransformed moments, and it is a
                          2                 2
diagonal matrix () = diag{w /(1 -  2 ), 2
                                        d,d  }. In equation (222), the first matrix element is the baseline
moment, and the second is the asset pricing moment. Clearly, the nuisance parameter vector (2) is empty in
this simulation example.

     We assume that the true local data-generating process has a time-varying relation between the expected log
excess return and the dynamic parameters:
                                      
             e        e     
                           t r
                                       1,  when 1  t  n
(223)       rt,n   = rt +  , with t =
                             n         -1, when n < t  n,


where the time series t captures the structural breaks. The corresponding moment biases, evaluated at 0 , are
                                           
                                     0     t r
                                       (2)
(224)       EQ0 [mt (0 )] =  (2)  with t        .
                                 
                             t             d,d 
                               n

Therefore, under the data-generating processes M1 and M2 in Table I, the moments have identical local biases
 (2)
t      after substituting the calibrated parameter values into (224). This guarantees that the comparisons across
models in Panels A and B of Figure 6 are valid.

     Figure 6 shows three different simulation experiments. Panel A displays the local power functions of C tests.
The solid and dotted curves reflect the test powers when the data-generating processes are characterized by
calibrations M1 and M2 in Table I, respectively. In this experiment, we vary the local misspecification r in
the risk premium. The data-generating process under calibration M1 features an excessively large amount of
dark matter according to Table I, and thus it has low internal refutability (i.e. little test power) consistent with
Theorem 1.

     Panel B of Figure 6 displays the histograms of logged overfitting measures log O(^(1) , yn ) of efficient GMM
                                                                                       e,n

estimators for two data-generating processes under calibrations M1 and M2 in Table I. In this experiment, we
specify a structural break in the risk premium in the middle of the time-series sample with r = 0.02. Panel B
shows that the calibrated structural model with too much dark matter (model M1) is likely to have more severe
overfitting concerns for the efficient GMM estimator, which is consistent with Theorem 2.

     Panel C of Figure 6 compares the expected out-of-sample fits between recursive GMM estimators        ~e,n and
efficient GMM estimators   ^e,n . The two types of estimators are defined in Section 5.2. Consistent with the con-
ventional intuition, efficient GMM estimators outperform their recursive counterparts in terms of the expected
out-of-sample fit under the data-generating process M2. This is because the additional identification information
is reliable and meaningful when the amount of dark matter is not excessively large. On the contrary, recursive
GMM estimators outperform their efficient counterparts in terms of the expected out-of-sample fit under the
data-generating process M1 with too much dark matter. This means that the concern of misspecification and
instability entirely offsets­ and even reverses ­ the efficiency gain from the additional moment restrictions.
Again, this experiment suggests that the econometrician should back off from efficiency to gain more robustness
                             DARK MATTER IN ASSET PRICING MODELS                                         81




  Figure 6.-- Monte Carlo experiments for long-run risk models. In Panel A, we simulate 1000 independent
monthly time series with length n = 1200 (i.e. 100 years). In Panels B and C, we simulate 400 independent
monthly time series with length n = 1200 (i.e. 100 years) and break point  = 1/2. We set r = 0.02 for Panels
B and C. In the simulation experiment, we assume that all the parameters except  are treated as auxiliary
parameters fixed at known constant values, subsumed into the functional form of the moment function (i.e.
model specifications).


for the estimation results when the model contains a large amount of dark matter.
