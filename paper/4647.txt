                            NBER WORKING PAPER SERIES




                       DID COMPUTER TECHNOLOGY DIFFUSE
                          QUICKLY?: BEST AND AVERAGE
                       PRACI1CE IN MAINFRAME COMPUTERS,
                                    1968-1983




                                   Shane M. Greenstein




                                  Working Paper No. 4647




                   NATIONAL BUREAU OF ECONOMIC RESEARCH
                            1050 Massachusetts Avenue
                              Cambridge, MA 02138
                                 February 1994

This paper is a condensed version of Greenstein [1993a]. I would like to thank Ernst Berndt,
Paul David, Zvi Griliches, Larry Neal, Ed Steinmueller, and Manuel Trajtenberg for useful
conversations connected with this work. Seminar participants at the NBER productivity
workshop, the University of Illinois, and University of Oregon provided many comments on
earlier drafts. Julie Lee and Jennifer Howitt entered data, and Sandra Ospina and Ken Brown
provided outstanding research assistance. Patrick McGovern and the Charles Babbage
Institute deserve thanks for helping out in the assembly of the data used in this paper. The
Center for Economic Policy Research at Stanford University and the Arnold 0. Beckman
Endowment at the University of Illinois provided funding. Only I am responsible for the
errors contained in this paper. This paper is part of NBER's program in Productivity. Any
opinions expressed are those of the author and not those of the National Bureau of Economic
Research.
                                                                 NBER Working Paper #4647
                                                                            February 1994


                       DID COMPUTER TECHNOLOGY DIFFUSE
                          QUICKLY?: BEST AND AVERAGE
                       PRACTICE IN MAINFRAME COMPUTERS,
                                    1968-1983


                                        ABSTRACT


       An economy benefits from advances in technical frontiers only when new technology

comes into general use. This paper measures the diffusion of computing equipment at a time

when computing technology underwent dramatic technical improvement. These data shed light

on the long lag between advances in computing technology and advances in economic

performance of users. There is little evidence that long lags were produced by the 'slow

diffusion' of new technology embodied in new hardware. "Average practice" in computing

advanced as rapidly as "best practice," lagging it by a maximum of 6 to 7 years.




Shane M. Greenstein
Department of Economics
David Kinley Hall, Box 70
University of Illinois
Urbana, IL 61801
and NBER
1. Inliixhction



        Best-practice computing technology has advanced rapidly in the last 30 years) Yet, it is hasty

to infer that economic ve1fare improved at the same rate. What matters for economic lfare is the

advance of echnologies in general use, not necessarily the advance of the best practice, ich very

few may put into use quickly. Despite all the attention paid to the advances in best practice, little

economic research examines the diffusion of computing technology or the economic value of systems

in 2
        This paper provides rneasuces of diffusion for 1968 to 1983, a time when the best practice

technology wxiernt rapid improvemenL              analysis sho that average practice advanced rapidly
in the United States. In most years, average practice advanced at a rate comparable to best practice,

irrespective of the measuce used for either. Average practice never lagged best practice by more than 6

to 7 years and usually by less. Compared vith many other studies of the diffusion of important

historical innovation of the last 200 years (e.g., Mansfield [1968]), this represents an extraordinary fast

diffusion of new technology.

        These results support tw conclusions. First, the papet's results relate to several difftision

mechanisms, analyzed in David [1989], that could account for the long lag beten advance of best

practice computing technology and productivity growth. The analysis shos that there is no evidence

to support the simplist possible mechanism, that hardware embodying new technology diffused slowly.

This result is consistent with David's [1989] emphasis on other mechanisms, e.g., the time it takes to

learn about new capabilities and the re-organize business enterprises.




     See Gordon [1989], EXilberger [1989], Cole et al [1986], Triplett [1989], Berndt, Sho1ter, and Woolridge
[1990], Bemdt and Griliches [1991], and (Miner [1993a]. Despite some disagreement, most indexes of
mainframes yield advances in qua1it'price on the order of 20% to 25% a year over the last thirty years.

   2Exceptions include: Berndt and Mxrison [1991], Berndt, N'krrison and Rosenblum [1992], and Bresnahan
[1987].
        In the same spirit, the paper highlights others ways in which best practice frontiers for

computing. usually estimated with hedonic methods (Tiipplett [1989]), may provide a deceptive

indicator of the economic benefits accmeing to computer users. The besic economics of the problem is

straightforward and wil-known Each old user reacts to new technology with a different adoption

response. Advances in best practice do not necessarily translate into uniform economic benefits across

all computer users because new practice does not uniformly replace old practice everywhere very

quickly. The open issues addressed in this paper are empirical, i.e., how varied is the response across

users and how does this variation influence measurement of the benefits from technical change?



2. Data on the Installed Base of CompterSysteim

        This study uses data from DC, & best historical data available on the size of installed bese

of computers and their rental prices. No other comparable data source exists for the l960s and 1970s.

Only a few studies of the computing market (e.g., Mlcheals [1979], Phister [1979], Flamm [l987a,b],

Ehilberger [1989], Oliner [1993a]) have used data from a similar source and none ever exploited all

facets of it. Before beginning U analysis, the paper must discuss the limitations these data impose on

the measure of best and average practice. lvkre detailed descriptions of these data are included in the

appendix

       The anaiysis begins with the December 31, l%8 report and end with the January 1, 1983

report. It begins with 1968 because this is the first year in which DC distinguished between the

nunther of installations within the US and outside the United States. It ends with the 1983 report,

because all of IDCs census undeznt a massive reclassification after 1983, the last year that DC

maintains its mainframe file separately from other types of computer systems.

       This paper accepts IDCs definitions of what is a mainframe computer (as opposed to a mini-

computer, a small business system or a desktop system). This makes my estimates comparable with


                                                  2
Phister's [1979] and Flarnm's [1987] description of the diffusion of computing equipment, vhith used

more aggregate IDC data It also makes my results comparable to Olinefs [1993a] analysis of the

retirement patterns anxng IBM mainframes, wiith uses similar DC data for IBM systems. As a

secondary benefit, employing IDCs definitions renves any suspicion that tho defmition vas chosen

arbitrarily or chosen to manipulate the results (though I have found that most of this paper's analysis is

robust to small changes in definitions). Over the entire 16 year period, these data concern the installed

base of over 350 different computer systems. 11 appendix provides a list of the important frluded

systems.
        Three biases arise from maintaining exclusive use of IDCs definition of a mainframe. First, in

1968 and 1969 IDCs early definition of a mainframe is too broad, including some systems that they

reclassifS' as "Digital Dedicated Application" in i97O. This will influence some of the results below.

Second, more redefinition problems arise on a smaller scale when DC began several data bases for

systems other than mainframes (i.e., minicomputers, small business systems, desktop). Its researchers

occasionally move a system into the mainframe category that was not there previously or move a

system out of the mainframe category that was there previously. Most of these redefinitions do not

matter, but a few influence the results below. The most important case is IDCs decision to include the

IBM System 36 in the sample in 1976 (estimated installed base at 5000 units) and exclude it from

mainframes thereafter (but include it in "small business systems"). Third, by the end of the sample, the

difference between mainframes and some large mini-computers (a.k.& "super-minis") becomes bkuTed,

raising questions about the survey's completeness.           main issue is whether IDC includes in the

mainframe category all the super-minicomputer systems that ware close substitutes for mainframes. A




    3Phister identifies several years in ich IDC revised the reported number of installations in previous years,
particular for IBM models in 1967-1972. In those cases, Phist&s reported updates were used.

    4This occulTed as part of a general reclassification of all IDC censuses.

                                                         3
reasonable case could be made that DC incloded most relevant systems.5 A reasonable case could also

be made that they did not, especially by 1983.' Overall, the omissions do not bias important results

below except in one place, which svill be noteci



3. A first look at different vintages.

        IDCs surveys do not record when a user installs each new acquisition. However, IDC does

record the date (year-month) at which each model of a system was first installed anywhere in the

United States. For example, the IBM 360i20 was first installed in November 1965, the IBM 37&125

in May 1973, and the IBM 3031 inFebmasy 1978. Asummasy of product introductions is presented

in the appendix. Call this munber VINFAGE. VThffAGE provides one measure of the technology

embedded in each systen because systems developed later arid introduced later tend to be better in

several respects than those developed and introduced earlier.

        As a measure of technological capability, VINFAGE has two significant dmwhecks. First, it

does not measure differences in the performance of different systems introduced at the same time.

Thus, VINFAGE is likely to be a poor measure of success in inter-system competition. This deficiency

is difficult to correct because there is no standard method for using installed base to weight results

(e.g., See Greenstein [1 993b] for one such attempt). A second important drawback is that VINTAGE



      It is not clear whether the money spent on super-minis ever amounted to more than a small fraction of the
amount of money spent on mainframes. According to the 1983 IDC census for mini-computers and mainframes,
the value of installed base associated with super-minicomputers came to roughly half the value of all mini-
computers, or roughly 15 percent of the value of the installed base of mainframes. IDCs census differs from the
other censuses, particularly CBEMA's, because IDC includes several systems as mainframes (i.e., those from
IBM) which others classify as super-minicomputers. This matters a great deal by the end of the sample. For
example, according to the CBEMA [1992], in 1976 mainframe shipments reached over 5 billion dollars, while
the total spent on all minicomputers was 1.8 billion. By 1982, howaver, mainframe shipments reached 10.6
billion and minicomputer shipments reached 7.7 billion. CBEMA does not state what fraction went to super-
minicomputers.

  'The most questionable omissions in IDCs mainframe tables are those regarding the VAX models from
DEC, and similar competitive models from other firms such as Prime and Data General.

                                                      4
overlooks differences betveen cohort and age effects. It assumes that the same measured difference

between an earlier and later technical vintage means the same thing in tvv different periods. That is, it

presumes that a 1968 technology is better than a 1965 technology by exactly tha same aniunt that a

1981 technology is better than a 1978 technology, and so on. Some corrections are possible (see

below).

          The advantage of using VINFAGE for rneasuiing technical capability is that it available for all

systems in all 16 years of the data and it is easy to use. Second, over the long run, VINFAGE

provides a quick and reasonable measure of imvements in new tec11ogy embedded in successive

generations of computing equipment, which is finc for the diffusion issues addressed in this paper.

Third, this measure does not rely on an arbitraiy estimate of best practice technology, nor does it rely

on a company's announcement regarding tl product Rather, it uses a historical event, when the

product first came to market. Thus, it is an appealing definition for an economic study.

          ?vkst important; VINTAGE provides a bound on the degree of technical knowledge embodied

in a system. This occurs for three reasons. First, the installed base of systems in use must be yoimger

than VIWFAGE indicates because the date of first installation is older than the date at which most

users install their rented or purchased model. Second, VINFAGE overstates a system's true technical

age in situations where new installations of an old vintage technology are using technology retrofitted

th improvements. Lastly, VIWFAGE does not correct for typical utilization rates of especially older

systems. In other wxds, it overstates how important old systems may be by assuming a "one-boss-

shay" model for old systems - if a system is installed, then it is still in use. In sian, VINFAGE will

give the most pessimistic picture possible. If the results are positive in spite of this bias then

VI1'H'AGE does a good job.

          Rather than analyze t& vintages of systems in each year, it is easier to examine their

"technical age," which makes various years comparable.          "technical age" of a system is defined as


                                                     5
the difference betwen the date of observation and a system's vintage.That is



        TECHAGE = YROBS - VINFAGE



where YROBS is the date of observation.1 AU systems introduced on the same date have the same

technical age. The same strengths and wakness that apply to VINTAGE also apply to TECHAGE



4. The Disthhilion of Technical Age.

        Figure 1 presents a summary of the changing technical age of US mainframe computer

installations over the entire 16 years (fl wlerlying data are presented in Table Al in the appendix).

A few technical generations dominate the distribution of the technical age over the first years of the

sample. The first major technical cohort in the data is associated primarily with the introduction of the

IBM system 360. In the end of 1968, there e 17580 systems installed whose technical generation is

1965. In each of the next t successive years this technical generation grows to a peak of 27040

systems, which 'vas over 40% of the systems in use in 1970. This technical cohort continues to be

quite large for many more years, making up more than 20% of the systems in use up to 1974. The

second major cohort is associated with the IBM system 3 and system 370 (spread primarily through

vintages 70-73). By year-end 1974 more than one quarter of the installed systems in use are associated

with this new technical generation. The importance of the system 370 and system 3 continues for a

few more years. As will be clear below, no other singje system introduction influences the

rneasureincnt results as much as the technical cohorts associated with the system 360 and 370.

        Figure 2 presents three different estimates of the average technical age of mainframe



   7Srnce each survey samples the market at the start of the year, YROBS for the first year of the sample will
equal 1968.0. YROBS ll equal 1983.0 in the final sample year.

                                                      6
computing systems in the United States able A2 in the appendix present the raw calculation). Three

measures are used because the inferences are sensitive to the measure usei The average technical age

of all installations emphasizes popular systems Th average technical age, vvighting by the rental

vaiue of the installations, emphasizes tbe r systems, the bigger systems, aixi popular systems.'

11 median technical age of t1 systems installed de-emphasizes any skesss in the distribution.

        Figure 2 illustrates tha trends. The median has tbe most unusual pattern. Because of the

diffusion patterns associated vith the system 360 and 370 tha median technical age jumps discretely

year to year. It grows from 1968 until 1973 at a rate of one per year, ich reflects tha influence of

the 360 cohort As many users bought the system 3 and upgraded their 360 systems to 370s the

influence of the 370 cohort rose. The aqt decline in tbe median age of systems between 1973 and

1974 reflects the accumulation of users shifting ay from tbe 360 and to the 370 and system 3. Both

the shifts avy from the 360 and to the 370 se recessaiy to produre this abnipt change. It is

difficult to make any strong inferences from these movements in the median after 1974. After 1974 the

median technical age increases for a few years, stays virtually unchanged for a few years, and then

fails markedly in the last couple of years.

        The measures of the average technical age of systems stay remarkably close to one another,

despite the different weighting used in each case. Not surprisingly, these measures are smoother than

the median. They too show a rising average technical age over the early part of the sample. The

technical age weighted by value rises 2.3 years from 1968 to 1979 and stays just above six years from

1975 until 1983. The unweighted technical age rises by 3.3 years from 1968 to 1980 and also stays

above six years from 1975 onwsrcL

        The rise in the technical age over the first half of the sample years is not surprising. The



    'It may also slightly exaggerate the importance of older systenis, as Phister [1979] werns. See appendix for
further discussion of these and other potential biases.

                                                       7
computing market had just experienced dramatic growth in the late 1960s and only moderate growth in

the early 1970s. The average age of systems grew as users held on to their systems and did not retire

them. By the mid 1 970s, however, users phased out enough of the oldest systems and replaced them

with ner systems, resulting in no increasing trend for these averages. The stabilization of the

average technical age in the later years of the sample is surprising because the continuing existence of

somo very old systems should bias the maasure upward as the market grows older. It seems that the

only way to get a stabilization of the average technical age is for buyers to acquire new systems at a

fast pace.

        Figure 3 verifies the above conjecture. It shows the different quartiles of the vintages of

computing capital stock (it also shows the maximum and minimum). The percentage of yoimg systems

is growing in the early 1980s and the age of the oldest quartile is falling. Thus, despite the possibility

that users could and did hold on to old computing stock, the average age does not change much over

the late 1970s and early 1980s. Note that the abmpt change in the maximum technical age betveen

1976 and 1977 reflects one system's retirement and does not reflect any important economic factor.

        Is an average technical age of 6 to 7 years a high level or a low level? The obvious

benchmark to compare TECHAGE ainst are several classic diffusion studies. Mansfield's [1968]

sumnmazy of the diffusion of 12 important innovations in bituminous coal, iron, steel, brewing and

railroads, shows enormous variance, as does Griliches' [1957] analysis of the adoption of hybrid seed

corn, and David's [1975] analysis of the MCormick Reaper. Most innovations take longer than 10

years to be filly adopted and several take 20 or more years. The comparison is not perfect because

these and similar studies analyze the adoption of the first generation of a product innovation (e.g.,

automobile, radio, television) or process innovation (e.g. continnous mining machine, diesel

locomotive), not the turnover in technical vintages of a stock of systems in use. Despite this

precaution, a technical age of 6 to 7 years seems small in comparison. This measure is biased towards


                                                    8
a pessimistic answer. New generations of computers must be turning over every few years to prodixe

this result Very few of the classic stndies just mentioned show adoption taking a few years.

        A few tentative conclusions enge. Fust, the market displays a pattern consistent with the

heavy growth of new users in the late 1960s. By the early 1970s this growth slowed and much new

technology adoption is beg made by experience users. Consistent with this story, estimates of the

levels of best practice frontiers are certain to be closer to average practice in the early years of this

sample wn first adoptions are made. Similarly, best practice frontiers may provide a deceptive

picture of the economic benefits from technical progress in the later years because the gap between

best and average practice is likely to be greater for many experienced users. Second, users added new

systems at a fast pace in     late 1970s and early 1980s. This last result is surprising, given the rising

importance of small substitutes for mainframe computers. Third, there is some indication that new

technology comes into use quickly, particular in comparison to previous major innovations. However,

this conclusion needs more careful analysis of turnover of computers from different technical

generations.



5. Technical fronlieis and the fvance of average practice

        The ultimate goal of this section is to measure the speed with which "best practice" diffuses

into general economic use. This section corrects for the main deficiency of TECHAGE, that one unit

of TECHAGE means the same thing in every year, though each vintage's capabilities differ.

        What is meant by "best practice" and "average practice" in a heterogenous product market?

Economists typically represent best practice by a "frontier" of models that can provide combinations of

product traits at the lowest cost It follows that "average" practice is a measure of the typical type (and

typical cost) of systems in use.

        This paper employs traditional hedonic estimates of the best practice frontier in computing.


                                                    9
Researchers have usually foi.nxi that the rate of improvement in the performance per dollar of new

systems lies somewhere betven 15% and 25% per year over the ss1le sample. Hover, these rates

vary year toy and over periods. Unfortunately, meet researchers do not estimate changes in the

hedonic frontiers over the entire period of interest, from the early 1950s until 1983 - exceptions are

Gordon's [1989] estimates and Tripletts [1989] synthesis of estimates from different researchers.

         For estimates of technical frontier, I employ Triplett's [1989] best practice index for computing

equipment (Tables 4. 13A and 4.14.). This iriex was Triplett's evaluation and synthesis of the best

hedonic research on computer technology. Triplett's indexes start in the imd 1950s and go all the way

until 1984. They cover all vintages and all manufacti.wers in the computing stock. Triplett's index

completely covers the industry, which makes it the best choice for this paper.9

         Even with an appropriate index, how should it be used to estimate best and average practice?

This is particularly important in light of the recent discussion about the existence of multiple hedonic

frontiers operating in the market at the same time)° Is it better to assume that all systems for sale are

priced on the same frontier or not? In a putty-putty 'vrld, all systems are on the same frontier. Then a

system's price and hedonic index are sufficient for comparing different systems' value. If systems are

not on the same frontier, what is the appropriate scheme for differentiating between different

applications and intensity of use?

         The strategy of this paper is to compute a bound on average practice even if system are on



     9Since Gordon's index and Triplett's index do not sharply differ in the long run, the results are not sensitive
to this choice.
    '°
      Fisher, et al. [1983] argue that the computer market is subject to "disequilibrium." That is, the introduction
of new products frequently disrupts expectations, market pricing, and investment patterns. Buyers may lock
themselves into investments, but regret the decision as conditions change unexpectedly. In the short run, buyers
may be uncertain about the true capabilities of the latest systems and may defer new purchases until better
information is available. M a result, the market may never settle into uniform prices for systems with similar
charteristics. Hedonic researchers, such as Dulberger [1989] and Oliner [1993a], interpret this to mean that new
Froducts and older commercial systems may not lie on the same hedonic frontier. Departures from the frontier
may differ with age. Dulberger find evidence in favor of disequilibrium, while Oliner finds a more mixed bag.

                                                        10
different frontiers. Thus, I assign the vorse possible frontier to each system. The frontier associated

th a system's VIN1AGE provides such a lo bound, i.e., the loswst technical frontier for a system

is usually realized wien a system is first introduced. This is a 1over bound because this index will not

change with market conditions even though new systems may improve with the introduction of more

software or other peripherals. Prices of old systems may also decline in response to new entry driving

the technical frontier outrcLU

        Table 1 and Figure 4 show this measure of the computing capital stock. More precisely, Table

1 computes the quality adjusted vah for each system by dividing the introductory price of the system

by a hedonic index for new systems that year. In other vords,



        EU1 =



wiere P, is the pt-ice of system i introduced in year v, wiich is its first year, and H. is the hedonic

value of systems of vintage v. EU1 represents "efficiency units" or the quality embedded in a system

at its introduction, so the number does not change over time. This computation is exactly right if

sellers price all new systems on their vintage hedonic surface and the productivity of each model does

not dramatically change over time. Othervise, EU should be interpreted as a lor bound. Table I and

Figure 4 present the average EU for each year. This equals



        AVE(EU) = [E Q EU,]!         [Q],

    11Particularly lithe price for a system declines over time or lithe technical capabilities for systems improve
over the production lifetime of a system. See Oliner [1993a] for evidence that discounting from list prices
foIlo a general predictable pattern over the commercial life of a system. See Flartman and Teece [1990] for a
similar discussion about strategic pricing in the mini-computer industy.

                                                       11
 where Q, is the installed base of model i in year t. Median EU is done in an analogous manner. The

 table ends in 1981 because this is the last year IDC publishes rental price data A mean and median

 were used (instead of a total) because these measures minimize biases from arbitrary changes to the

 definition of a mainframe. The abeolute value of the mean is higher than the median because in any

 year U distribution of prices of systems is skewL That is, the larger systems are more expensive

 than the smaller systems are cheap.

          Consistent with the previous figtues there is r evidence in this table that diffusion is slow.

The median and mean start at different levels, but grow at roughly the same rate. The mean growa at

22.6 percent a year, while the median grows at 23.6 percent a year. The mean shows steady growth

after 1970. The decrease from 1969 to 1970 was likely caused by IDCs redefinition of a mainframe,

which resulted in the exclusion of many systems from the 1970 census that had been in the 1969

census. The median shows steady growth through out the whole sample, with a few exceptions in the

early to mid 1970s. The decline from 1969 to 1970 is an artifact of abrupt changes in the sample of

systems. IDC removed several newer systems, mostly minicomputers, from the survey.'2

         The rate of growth shown in Table 1 compres closely with the hedonic index presented in

Table 2. The index declines at 19.8 percent a year from 1958 to 1984, with the biggest declines

coming from 1958 to 1970. Thus, the decrease in the cost per i.ntit of quality translates into roughly

the same rate of growth in the quality of U installed computing capital. Sometimes the rate of growth

was even faster.



6 Diffusion lags

        This section defines and analyzes diffusion lags, which measure how manyyears average



   t2Overall, these results do not seem to be a consequence of a change in the typical size of systems in this
sample over time. All experiments with changes to the sample of systems yielded similar results.

                                                      12
practice is behind best practice. A diffusion lag is the difference beteen average practice in one

period and its equivalent best practice in a previous time. Diffusion laga are easy to compute vith

logistic curves in single-product, single-vintage nrkets. A similar index in a multiple vintage,

multiple product market involves a bit more effort.

        The paper's measure of the diffusion lag computes the average practice in one year. 11n, it

fixes that value and searches for the previous year in which best practice fronti sere at this level.

The difference in time provides a measure of the "vii tage-eçiivelant" of a given yea? s average

practice. Mre precisely, let FJ be the best practice value for all systezn of vintage v, and let

AVEPRAC be the average practice for year t. This paper uses the AVEPRAC in time t and compares

it against previous H, interpolating where necessazy. In othervvrds, the diffusion lag. DIFLAG, is

defined by the fol1ong procedure:



        If AVEPRAC(t) = FL then

        DIFLAGt-v.


This procedure takes advantage of the most data available.

        Different definitions of "best practice" and "average practice" provide different insights. As

argued above, hedonic measures can represent the technical frontier in time t for all systems

introduced in that year. It follo that average practice is the average (or median) of these values over

all systems in use.

        Table 2 and Figure 5 present the results for 1968 through 1983. The results of this procedure

are striking. For the average, diffusion la grow over the early and middle part of the sampi;

reaching a peak of over 10 years in 1979, 1980, and 1982. The la essentially level off in the last

five years of the sample. The results show that average practice changes at over 14.4 percent a year


                                                   13
from 1%8 to 1983, which is just under the 16.4 percent change in best practice during the same years.

The diffusion 1a lengthen because a number of very old systems are still in the installed base in the

late 1970s. Users may or may not use these old systems as intensively as they use new. }wvver, an

average does not correct for intensity of use.

         One possible correction is sbown in Figure 5 and presented in Table 2 under the heading

"median practice." It computes the hedonic frontier value of the median system in use. This definition

is not as sensitive to the existence of older systems. Of course, this measure will also abruptly change

any tin the median TECHAGE abruptly changes. The diffusion lag associated with the median

practice is markedly different than average practice, as expectei It grows over the early years of the

sample, but levels off by 1972 It drops abruptly in 1974, reflecting the abrupt change in the median

system, as described in the discussion about the median techage. This drop is in contrast to the average

diffusion lag. In addition, the median diffusion lag never exceeds 7 years, which is markedly less than

the average diffusion lag This maximum is reached in 1972, 1973, 1977, 1979, 1980, and 1981. The

turnover in the number of young systems is sufficiently fast to prevent the installed base of old

systems from mattering as mueh I conclude that the median is a less reasonable measure when there

are abrupt changes in the median system, as in the mid 1970s. Howvver, it is a more reasonable

measure of long run trends under the assumption that users do not intensively use very old systems. D

So it is probably more appropriate for the late 1970s and early l980s.

        Several conclusions emerge from Table 2 and Figure 5. First the overall rate of diffusion of

new technology to users embedded in new technology is quite fast, especially considering that all the

above measures represent a pessimistic estimate. The average computer user possessed new technology

that was improving at roughly the same rate as the best practice frontier, though the level of average


      This result is also consistent with the industiy perception that the "typical" user turns over their system
eveiy 4 to 6 years. If the "typical" user makes this purchase I to 3 years after the iroduction of a product, then
a median of roughly 6 to 7 years will result

                                                       14
practice obviously lagged behind. Second, tlp between the levels of best and average practice

grew in the first five years, as or    uld expect in a relatively new market Thereafter, the retirement

patterns of the older vintages largely detenriines the nasured diffusion p. Third, despite the

generally positive overall picture, there is considerable variation in the experience of users. A

substantial minority continued to possess old equipment much of it representing generations that were

easily 10 years old or older. This observation focuses attention on the need to better wderstand the

relationship between the installed base of old computing equipment, the intensity with which it is used,

and users' tendency to make another purchase.



7. Ciosing reimrks

        This paper's analysis aimed to prevent any hasty inference about economic welfare based

solely on estimates of growth in the computing technical frontier. \Mat matters for economic welfare

is what technologies users employ, not only what is available or what wes recently bought. In terms of

this motivation, the results were quite positive. Average practice generally lagged best practice by a

maximum of 6 to 7 years and wss often shorter. While this answer is somewhat sensitive to

assumptions about the intensity of use of old systems, it is biased towards a pessimistic answer. A

maximum of 6 to 7 years is hardly slow, especially in comparison to the diffusion of other important

innovations.

        The analysis highlighted several important features of the diffusion of computing. A few

vintages and computer system models greatly influence the results in some years. It follows that any

measurement of diffusion will be sensitive to the valuation placed on popular systems, particularly the

IBM system 360 and the IBM system 370. This is a disturbing conclusion, given the different hedonic

estimates for these systems (Gordon [1989], Dulberger [1989], Oliner [l993aD.
        Second, the analysis found a general correlation between advances in technical frontiers and


                                                   15
advances in average practice, but also fotaxi mh variation arotuxi the trerii A large number of users

continued to hold onto old equipment and did not turnover technical generations quickly. By

impliction, a complete description of the advance of average practice requires a complete survey of

the experience of new and popular systems, and also a survey of the use of old vintages. Thus, at

best hedonic frontiers alone are a eak approximation of the general economic benefits from technical

advance in the short rtni These observations highlight the need to better axierstand the relationship

between the elasticity of demand for computing, U intensity of use of old technical vintages, and the

adoption of new technology (e.g., See Bresnahan and Greenstein [1993]). Further research on the

intensity of use of old equipment and its retirement patterns (e.g., Oliner [1993a}, [1993bJ) can

partially address this gap in knowledge.

        The paper's results have another important implication. Economists have been puzzied by the

abeence of any of the expected produetivity improvements that should follow technical advances in

computers. One set of possible hypotheses emphasize that average practice lagged far behind best

practice. This paper provides a quantitative test of the simplist slow-diffusion mechanism, that new

technology embedded in hardware diffused slowly. The analysis rejects this mechanism because

average practice advanced at a rate comparable to best practice and the diffusion lag associated with

new technology embodied in mainframe hardware was typically short Thus, to remain viable, the

slow-diffusion hypothesis must focus on the slow development of software, human learning. and

appropriate organization forms, as suggested in David [1989], if it is to survive as a viable explanation

for the productivity pule.t4

        This paper's experiment ends at an interesting turning point in the mainframe computer


    '4mese is not likely any supporting evidence in the diffusion of products complementaiy to hardware, such
as software or peripheral components. Recent hedonic research shos a rapid rise in the technical frontier for
many different peripherals (Cole et al [1986], Oliner [1993b]). Since the sale of these peripherals positively
correlates sith sale of processors, there is likely to be little difference in the diffusion lag for peripheral
technologies in the United States.

                                                      16
industry. Ser minicomputers had already begun cutting into the mainfran market share by 1983

and personal computers became much nire ubiquitous thin businesses after 1983 Besnahan and

Greenstein [1993]). One might expect tha retirement patterns and acquisition patterns to change as a

result. Furtber research may be able to identify thei tha diffusion 1a increased or decreased after

1983.

        Fwther rk could constnt estimates of the demand for computing capabilities. Demand

estimates will say something about the degree of change in the surplus of users due to technical

improvement This is the spirit of Flamm's [1987a1 estimate of the benefits from improvements in

computer systems, Bresnahan's [1987] research on the use of computers in the fmancial services sector,

and Trajtenbergs [1989,1990] estimates of tbe sv1fare gain from the adoption of CT scanners. Since

the data in this paper incindes data on quantity and prices, it is possible to rk in this direction.

Greenstein [1993bJ contains such research.




                                                   17
             Table 1
Median and Average   Efficiency Units
            1968-1981

 Year        Mean          Median
  1968         22.28          5.00
  1969         22.33          7.04
  1970         19.33         10.55
  1971         25.41         10.55
  1972         35.90         10.55
  1973         45.10         11.41
  1974         54.99         11.41
  1975         65.19         11.41
  1976         71.02         13.70
  1977         92.65         28.92
  1978        135.16         48.40
  1979        209.45         63.52
  1980        323.40         70.04
  1981        529.00        136.61




                18
                            Table 2
                  Average versus Beat Practice
                           1968-1983

       Hedonic                       Average               Median
Year   Beat         Average          Diffusion Median     Diffusion
       Practice      Practice        Lag        Practice Lag
1957    3640.9
1958    2895.5
1959    2422.7
1960    1863.6
1961    1377.3
1962     927.3
1963     700.0
1964     568.2
1965     454.6
1966     286.4                                 .


1967     231.8
1968     190.9        794.2            5.4         568.2     4
1969     172.7        671.7            5.8         454.6     4
1970     159.1        556.3            5.8         454.6     5
1971     122.7        503.6           6.4          454.6     6
1972     100.0        422.8            6.8         454.6     7
1973      98.6        380.9            7.6         286.4     7
1974      80.3        313.0            8.2         159.1     4
1975      73.2        274.5            8.8         159.1     5
1976      65.7        229.4            8.9         159.1     6
1977      51.4        224.2            9.8         159.1     7
1978      34.5        199.1            10.2        100.0     6
1979      29.6        186.4            10.7        100.0     7
1980      23.9        168.7           10.7          98.6     7
1981      21.8        136.6            10.3         80.3     7
1982      20.4        116.0            10.7         65.7     6
1983      16.3         91.4             9.6         34.6     5




                                19
                                               C,)
                                               aD


         It   IT
                                               c'J
         VV.4.
       <<<II
       I—I--H V
                                               3D


       V V V<                                  a,

                                               0
                                               cc
C.')

E                                              C)
                                               N
G)

>
Ci)

(I)
                                               cc
                                               N
-o
0)
.4—'
0)                                             (0

                                               U)
                                               N.




                                               C,)
                                               N


I                                              c.'J
                                               N.



                           k/rAr%r4r4rAr%
                                               0
                                               C)
                                               (0

                                               cc
                                               (0




                   00009    0000t   00O0   0
                                                                   gm2
                           Technical Age of Installed Systems

                                                                                                                 2,
                                                                                                            ./
                                                                                                       2'
                                                                                                                      2
                                               %
                                          ,/                                                                               2,
                                                   '
                                     //
                                 /                 I
                             3
                            /'                     I

co-

                            2                                               I


lt)-                                                   I               3
                                                                                                                                 3

                                                                   I
                                                                                         Mean when weighted by value
                                                           I                             Mean when weighted by installations
                                                           I,
                                                           3                         3   Median when weighted by installations
            3
       3-
            I    I    I      I                                 I       I        I         I      I     I              I    I

       68   69   70   71    72             73              74          75       76       77     78    79         80   81   82    83
                                              F1gm3
                                  Technical Age of Installed Systems

c'J
                                                            5—\
                                  ——I
                                                                                            5_——,J
                      5___
                                                                       \             5__•
               5__•
          5—                            ____________________
                                           Minimum
                                           First quantile
                                           Median
                                           Third quantile
                                           Maximum
o     —                                 ______________________
                                        _____________________                                         4


                                    .1
               4                                                 __3--_    3- 3___ 3-.__ 3--- 3-..    3
If)   -                                          '          2              2         2      2
                                            2                     2             2                2
          2                                                                                           2•   2

o     -   i_1—11_11—1—1—1—1—11—1—1—1—1
          I    I      I       I     I        I       I      I      I       I    I    I      I    I

          68   69     70     71    72       73       74     75    76       77   78   79     80   81   82   83
                                                Rgure4
                                           Efficiency Units

0
C
('4




0
0
0                          Average


C
0-
0
0-
CD




0
0-
0
0-
('4




              I             I        I    I      I

      1968   1969   1970   1971   1972   1973   1974    1975   1976   1977   1978   1979   1980   1981


                                                     year
                                     Mgt   5
                                 Diffusion Laos




cD
0•
(0                                                  —       Price Index
                                                                     Practice
                                                    - - - - Average
                                                            Median Practice


0
0

0
0
c'J




0
      62   63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83
Pefernces

Bemdt, Ernst [1991], The Practice of Econometrics: Classic and Conteniporary Reading, MA.
Addison-Wesley.

Berndt, Ernst, and Zvi Griliches [1990], "Price Indexes for Microcomputers: An Exploratory
Study," NBER working paper #8878, Cambridge, MA.

Berndt, E. R, M. H. Showalter, and J. M Woolridge [19911, "On the sensitivity of hedonic
price indexes for computers to the choice of fuentional form," Mlmeo.

Berndt, Ernst, R and Catherine J. Morrison [1991], "Assessing the Productivity of
Information Technology Equipment in U.S. Manufacturing Industries" NBER Working Paper
3582, Cambridge, MA., Januaiy 1991.

Bemdt, Ernst, R, Catherine J. Morrison, and Larry Rosenbium [1992], "High-Tech Capital
formation and labor Composition in U.S. Manufacturing Industries: An Exploratory Analysis,"
NBER Working Paper 4010, Cambridge MA., March 1992.

Bresnahan, Tunothy, F. [1987], "Measuring the Spillover from Technical Advance:
Mainframe Computer in Financial SeMces" American Economic Review, Marth

Bresnahari, Timothy, F. and Shane M. (3reenstein [1993], "The Competitive Crash in Large
Scale Computing," mimeo, University of Illinois.

Brock, Gerald W. [1975], U.S. Computer Industi : A Study in Market Powet, Cambridge
Mass: Ballinger Publishing Co. 1975

CBEMA [1992], Information Technology Industri Databook, 1992, Washington, D.C.

Cole Rosanne, Chen, Y.C., Barquin-Stolleman, Joan A., Dulberger, Ellen, Helvacian, Hurhan,
and Hodge, James FL [1986], "Quality-Adjusted Price Indexes for Computer Processors and
Selected Peripheral Equipment," Survey of Current Business, 66(Januazy), pp. 41-50.

David, Paul A. [1975], "The Mechanization of Reaping in the Ante-Bellum Midwest," in
Technical Choice. Innovation.. and Economic (T3ro'vth: Essays on American and British
Experience in the Nineteenth Centiy. Cambridge University Press, New York, NY.

  avid, Paul A. [1989], "The Computer and the Dynamo: the Modern Productivity Paradox in
a Not-Too-Distant Mirror," CEPR Working Paper no. 172, Stanford University, July.

lAilberger, Ellen R [1989], "The application of a Hedonic Model to Quality-Adjusted Price
Index for Computer Processors," in Technology and Capital Formation, Edited by Dale W.
Jorgenson and Ralph Landau, MIT Press.

                                            20
Fisher, Franklin M. and McGowan, John 3., and Greenwood, Joen E. [1983], Folded,
Spindled, and Mutilated: Economic Analysis and U.S. vs. IBM, MIT Press, Cambridge Mass..

Flarnm, Kenneth [1987a}, Targeting the Computen Government Support and International
Competition. Washington D.C.: The Brookings Institute.

Flamm, Kenneth [1987b}, Creating the Computen Government Industiy, and High
Technology, Washington D.C.: The Brookings Institute.

Gordon. Robert J. [1989], "The Postwar Evolution of Computer Prices," in Technology and
Capital Formation, Edited by Dale W. Jorgenson and Ralph Landau, MIT Press.

Greenstein, Shane [1993a], "The Diffusion of Multiple Vintages in a Differentiated Product
Market: Best and Average Practice in Mainframe Computers: 1968-1983," mimeo, University
of Illinois.

Greenstein, Shane [1993b], "From Superminis to Super-computers: Estimating the Benefits
from Improvements in Computing," Mlmeo, University of Illinois, November.

Griliches, Zvi [1957], "Hybrid Corn: An Exploration in the Economics of Technological
Change," Econometrics, 25, pp. 501-22.

Hartman, Raymond S. and Teece, David 3. [1990], "Product Emulation Strategies in the
Presence of Reputation Effects and Network Externalities: Some evidence form the
Minicomputer Industiy," Economics of Innovation and New Technology.

Michels, Robert [1979], "Hedonic Prices and the Structure of the Digital Computer Industry,"
Journal of Industrial Economics.

Mansfield, Edwin [1968], Industrial Research and Technological Innovation, New York:
Norton.

Oliner, Steve [1993a], "Constant Quality Price Changes, Depreciation, and Retirement of
Mainframe Computers," in Price Measurement and Their Uses, edited by Murray F. Foss,
Marilyn E. Manser, and Allan FL Young, University of Chicago Press, Chicago, IL.

Oliner, Steve [1993b], "Estimates of Depreciation and Retirement for Computer Peripheral
Equipment," Mlrneo, Board of Govemers of the Federal Reserve System, Division of
Research and Statistics.

Phister, Montgomery, Jr. [1979], Data Processing Technology and Economics, Digital Press,
Santa Monica

Trajtenberg. Manuel [1990], Economic Analysis of Product Innovation, The Case of CT

                                             21
Scanners, Harvard University Press, Cambridge MA.

Trajtenberg, Manuel [1989], "The Welfare Analysis of Product Innovations, th an
Application to Computed Tomography Scanners," Journal of Political Economy, 97, 2, April.

Triplett, Jack R [1989], "Price and Technological Change in A Capital Good: A Survey of
Research on Computers," in Technology and Capital Formation, Edited by Dale W. Jorgenson
and Ralph Landau, MIT Press.




                                           22
Appetilix

Al. Dati docunntation
         These data on computer prices, quantities, and vintages come from the archives of the Charles Babbage

Institute at the University of Minnesota, which contains a collection of industry "censuses" from International

Data Corporation's ([DC) EDP Industry Reports (EDP/IR). This paper also makes use of a set of EDP Industry

Reports contained at the Library for the Graduate School of Business at Stanford University. Patrick McGovern

began compiling this census in 1962 in Computers and Automation magazine. It continued in modified form

under IDC auspices from the mid 1960s onward. IDC annually surveyed most mainframe users and suppliers in

the country and estimated the number of installations of each type of computer system. In addition, until 1981

[DC estimated the monthly rental at which an average type of the system leased. AiIer 1981 they estimated an

average purchase price for the system.

         The [DC data on the installed base of each model is the right magnitude, though not precise, especially

in capturing yearly changes. IDCs own literature warns against the hazards of inferring net sales from changes

in the data on installed base. The problem is that they update their figures for tw reasons: (1) Real changes in

the holdings of users; (2) changes in IDCs information about (proprietary) sales activity, both in the present and

in the past Patrick McGovern recalls (in a private communication) that most suppliers except IBM cooperated

with [DC, which is why IDC had to undertake a major revision of the data pertaining to IBMs systems (Phister

[1979] contains a complete set of these revisions).

         Phister [1979] clearly believes that IDC's estimates are the best among the available alternatives. He

states on pg. 250 "It is my opinion that IDCs staff; files, and data sources make that organization's published

statistics the best available." Nevertheless, he warns about several potential problems that could influence

calculations using these data. For example, due to occasional revisions of previous EDP/IR reports, Phister is not

convinced that IDCs estimates of the size of installed base are precise. However, many of his uses of these data

indicate that he believes [DC got the general order of magnitude correct

        Dulberger also questions the accuracy of IDCs estimates of installed base, while conceding that they are

the best publicly available. One especially difficult problem is that [DC may underestimate the number of users

who upgrade their systems (Dulberger, private communication). However, she relies less directly on IDCs

numbers. She used them only to determine the size of her data sample of systems for sale in a given year. For
each year's sample she included processors associated with systems wfiose installed base s still growing, since

these systems are likely to still be experiencing positive sales.

         Given these concerns, I also subjected these data to some internal consistency checks, wiuich they

readily met. The history of each new system was examined. Did the development of its installed base follow a

reasonable pattern of growth, i.e., several years of growth followed by several years of decline? The absence of

such a pattern vuld bring into question the plausibility of the data.

         Similar issues influence the use of IDCs rental price data. IDC estimated the price of a typical system

configuration. Phister believes that the prices for obsolete systems are too high, since IDC uld use the last

offered price for a system in the absence of any rent transaction. Nonetheless, Phister uses these prices for

estimates of the value of installed base. He believes that the bias in old prices influences only a few of the

systems in the United Stales. Flamm reaches a similar conclusion before using Phister's estimates for a few

caiculations. In addition, using these prices is not without precedent in the hedonic literature. The prices for new

systems used by Gordon (as well as many others) are very similar to those used here. Gordon's prices for his

sample after 1977 were taken from Computerworld. which is published by IDC.
         These research&s experiences show that IDCs estimates are probably the right order of magnitude but

also subject to measurement error. These observations warrant a cautious research strategy. No strong

conclusions should rely exclusively on one data point. Strong inferences will arise only from procedures in which

cumulative measurement errors wash out.
A2. The Technical VINTAGE of Inoilant irifxame Qnuter Systetm

VINTAGE=50
UNI 1103/5

VINTAGE=51
ll/ll
VINTAGE=54
BUR2O5
1BM650

VINTAGE=55
1BM704
1BM705

VINFAGE=57
1BM305
UN
VINTAGE=58
BUR22O
1BM709
P1-11210(211
UN1SS0
VINTAGE=59
1BM7090
UNI5OI

VINTAGE6O
CDC16O4/AIB, GEL2IO, HONHSOO, IBMI4OI, 1BM1620, 1BM7070174, IBM709cV94, NCR3O4, UNI3OI,
UNTLARC

VWrAGE=61
BUR200, CDCG-20, GEN225r255, HONI-1400, IBMI4IO, 1BM7030, 1BM7080, NCR3IO, NCR39O, RCA3O1,
1JN14911492,

VINTAGE62
1BM7094, NCR315, RCA6O5, UNIifi UNII 107,

VINTAGE=63
BURB55/5700, CDO600, GEL2I5, 1BM1440, 1BM1460, IBM7OIO, 1BM7040/44, PHI1000, P1-11212,
UNI4 I 8V11, UN! 1004, UNI 1050,

VINFAGE=64
BURBIOOS, CDC3I/3 150, CDO200, CDC3400, CDC6600, DECPDP6, GEL2O5, GEL2351265, GEL415/420,
GEL425/430, HON200, HONI400, HONI800, 1-KGAMMA10, IBMI4OIG, 1BM7094-ll, UN13301, XER9300,

VINTAG5
BURB300S, CDC3300, CDC3 800, GEL235/265, GEL4351440, GEL625, GEL635, IBM3&V20, IBM3&V30,
LBM3&V40, 1BM360/50, 1BM360/65, NCR3I5RMC, NCR500, Rc1\S7'15, RCAS7Q'25, UNJ11O8,

VINTAGE6
CDC6400, GEL55, GELI 15, GEL645, HONI-1120, HONH1200, HONH2200, IBM3&V44, 1BM360167,
1BM360175, IBMI 130, RCAS7cV55, UN1494, UNIIOO5, XERSIGMA7, XER94O

VWFA67
BUBB2500, BURB3500, CDC6500, DEC1O4O/50, GEL225r255, GEL415/420,   HONHI25, IBM36x,
IBM1401H RCAS7O/35, SCCIC6000, UN19200, UN19300, XERSIGMA5,

VINFAGD=68
BURB500, GEL4O5/410, HON1 10, H0N1250, H0N4200, 1BM364Y25, NCRCaITIoo, RCAS7O/46, SSCIC400

VINTAGE=69
BURB6500, BURB8500, CDc3soO, CDC7600, GEL58, GELIO5, GELI3O, GEL2451275, GEL15, H0NH8200,
NCRCENT200, SCCIC7000, UN1418111, UNI1IO6, UN19400

V1NTAGE70
CDC317O, CDC6200, CDC6700, FRISYSTEM1O, GELS3, GELI2O, GEL4OS/410, GEL425/430, GEL435/440,
H4H1 05/115, HONH3200, IBMSYS3/6, IBMSYS3/10, SENSYS1 0, RCAS7cV6O, XERSIGMA6,

VINTAGE=71
BURB4500, CDCCYBER72, GEL6O3O/40, GEL6O5O/60, GEL607W80,
HONIH1OI5/2015, 1BM37W145, 1BM370/155, 1BM370/165, 1BM370/195,

V]NTAGE=71
1BM360122, NCRCENT5O, RCAS7O/61, RCAS7Oi2, RCAS7O/3
RCAS7cV6, RCAS7Y7, XERSIGMA8, XERSIGMA9,

VINTAGE=72
BIIRB2700, BURB3700, CDCCYBER73, CDCCYBER74, CDCCYBER76, DEC 1060170, HONI-12040,
HONI-12050/2060, HONH2O7O, 1BM37U'135, NCRCr101, NCRCEfl00, UNTI 110, UNI9O/70/9700

ViNI'AGE=73
BURB172O, BURB7700, GEN6023125, H0NH2020130, 1BM370/125, 1BM370/158, 1BM370/168,
NCRCENfl25 1, XER53O

VINTAGE=74
CDcSTARI00, GEN6 180, FIONH6I/58, HONH61/60, HONHLEVEL62, HONHLEVEL64, HONH6&'20,27,
HcH66/40/60, HONH66/80, 1-10NH68/80, LBMSYS3/15, 1BM370/115, UNI9O/60, XERS5O/560,

V1NTAGE75
AMD47OW6II, BURB17IO, CDCCYBERI72, CDCCYBER173, CDCCYBERI74
CDCCYBERI75, DEC1O8CV9O, l-10NH66/ICWI7, IBMSYS3/8, NCRCfl51, UNI90/30, UNII 100/20,
liNT 1100/40,

V1NrA76
BURB2800, BURB4800, CDCCYBER71, CRAY1A/1B, DEC2041'50, HONH6I/40, HONH6605/07,
IBMSYS3/4, IBMSYS3/12, 1BM37CV138, NCRS55O, NCR8570, NCRCENT7S, UNI9O/80, UN11 100/10,

VNrAGE=77
AMD47OV/511, BURB18I5,25/3, BURB1855-85, BURB3SOO, BURB6SOO, CDCOMEGA48O-1,
CDCCYBERI71, 1BM37W148, NASAS/4, NASAS/5, NCRS35O, NCR8450, NCR8560, UN90125,
UNII 100/80-82

V1NFA78
AMD47OV/7AB, BURB7800, CDCOMEGA48O-2, CDcCYBER176, DEC2020, HONH66/DPS/BC,
HONH6S/DPS, 1BM303 1, IBM3 032, mM3033U,A,M MAGMSO/4, NASAS/3, NASAS/703 1, NASAS/6,
NCRS37O, NCRS43O, NCR8S8O, UNI9O/40, UNI 1100/83, UNI 1100/84,

VINTAGE79
AMD47OV/8, CAX1638/40, CDCCYB17O-720, CDCCYB17O.-730, CDCCYBI7O-750, CDCCYBI7O-760,
DEC2060, HONH64/300, H0NH66144U1520, HONCOM/XER, 1BM4331-1, 1BM4341-1, MAGM8W3,
NASiW7O2O,30 , NCRS27O, NCRS4IO, NCR8455, NCR8555, NCR3565, NCR8575, NCR8585,,,

VWrAGE8O
BURB 1905, BURB1955/85 , BURB2900, BURB6900, CAXI64I, CDCOMEGA4SO-3, CDCCYBER2O3,
CDCCYB17O-740 , CRAY1S HONDPS&20, HONDPS&/44, HONDPS8/52, HONDPSSI7O, HONDPS4,
IBMSYS38/3, IBMSYS38/5, 1BM433 1-Z 1BM3033N, 1PL4436, 1PL4443, MAGMSOI3 1, MAGM8(2,
NASAS/3000, NASAS/5000, NASASI7000, NASAS/9000, UNISYS8O-3-4 UNII 100/60,

VLNTAG81
AMD47OVI7C, BURB3955, BURB593O, CAX1636, CDCCYBER2O5 , HONDPSS/62, HONDPS7,
IIBMSYS38/4, 1BM4341-2, 1BM3033S, IBM3O8ID, 1PL4446, MAGM8V3O, GM8W30E, MAGM8O/42,
MAGM80/43, NCR8650,

VThiFAG1>=82
AMDS8cV586O, BURB592O, BURB692S, CAXI 651, CDCCYBER855, CDCCYB17O-825 , CDCCYB 170-835,
CDCCYBI7O-855 , CDCCYB17O-875 , DENHEPIBMSYS38/7, 1BM4321, 1BM4331-11, 1BM4341-10,
1BM4341-1 1, IBM3O8IG, IBM3O8IK, 1PL4445, MAGM80, MAGM8cW4I, NASAS/6600, NASASI9O4O,
NASASJ9O5O, NASAS/9060, ,NASA&'9070, NASAS/9080, NCR853511, NCR854511, NCRS5S5H, NCR856511,
NCRS67O, NCR857511, NCR858511, NCR859511, UNISYS8O-5-6

VINTA3
AMDS8O/5850, AMD68W5870 , AMD5SV5S8O, BURB2925, BURB49S5, BURB7900FI-IK, CAX1636-10,
CAX164I-1 1, CAXI651-I 1, CDCCYBI7O-865 , CDCCYBI7O-875D, CRAYXMP22, CRAYXMP24, CRAYM
1-IONDPS88/81 , FKDPS8&82 , HONDPS837, HOND?S849, IBMSYS38J8, 1BM4341-9, 1BM4341-12,
1BM3083E, 11BM3083B, 1BM3083J, 1PL4460, 1PL4480, NCR3635, NCR8645, NCR8655, NCR8665, NCR8675,
NCR8685, NCR8695, UNISYS8O-8,
                                   Table Al
        The Technical Age    of    the Inatalled Baae       of   CputerB
                                   1968-1983


 Age            68      69        70    71      72     73         74         75

 <1           549   338  493  476            1500    1353 1509         2121
1-2           1651 1182 2920 3138            4073    5211 3539         3900
2-3         17580 2653 2698 3839             7119    3315 6392         5433
3-4          3491 25824  719 2935            4965    9702 5137         5964
4-5          4168 3031 27040  730            3605    3816 16596        5204
5-6          3223 3157 4152 28240  759 3773 2691 17987
6-7          1882 2946 1477   910 27791 5942 3953 1974
7-8          6642 2424 3195 1329 856 17923 4501 3381
8-9           220 4784 1087 2475 1251 1295 12244 4021
9-10          184  203 3259  908 2277 1889 1063 10229
10-11          76  142  360 2730   712  480 1611   912
11-12         124   58  131  309 2401   859  375 1387
  >12         503  532   90  141   303 2232 2636 2523
Total       40293 47274 47621 48160 57612 57790 62247 65036




              76       77    78        79      80     81     82         83

 <1         6888     2507 1028   700  947 3483   873                   5940
1-2         5152     4512 6870 2802 2157 6937 6556                 5409
2-3         5186     4949 6355 7923 3994 3499 10851                6190
3-4         5927     5882 5480 6312 7129 4380 3285                 9563
4-5         4845     6291 4424 5765 4779 5839 4406                 3137
5-6         5824     4093 5712 4079 6202 3486 4147                 3392
6-7        17632      4276 3547 5218 3801 5832 2378                3094
7-8         1338     13123 3078 3035 4056 3349 4711                2331
8-9         3169       742 8810 2713 2419 3082 2800                3902
9-10        3360     2136   547 7624 2280 2038 2105                2250
10-11       8671     2703 1680   502 6065 1984 1511                1340
11-12        813     6469 2186 1569 401 4925 1601                  1054
  >12       3089     3417 8306 9718 9013 7681 10418                9358
Total       71894 61100 58023 57960 53243 56515 55642 56960
Table A2
Technical age of a typical ystn
1968-1983

Year        Average    Average    Median
            weighted   wei?hted
            by value         tall
                       by 3.flS
1968         4.29       4.18       3.50
1969         4.62       4.60       3.75
1970         5.13       4.99       4.66
197].        5.85       5.46       5.33
1972         5.79       5.53       6.33
1973         5.60       5.67       6.91
1974         5.53       5.63       4.00
1975         5.69       5.93       5.00
1976         6.05       5.85       6.00
1977         6.37       6.45       6.25
1978         6.48       6.51       5.66
1979         6.52       7.02       6.25
1980         6.38       7.38       6.58
1981         6.20       6.87       6.25
1982         6.61       6.77       5.50
1983         6.16       6.25       4.83
