                                 NBER WORKING PAPER SERIES




                    MONETARY POLICY WITH MODEL UNCERTAINTY:
                        DISTRIBUTION FORECAST TARGETING

                                          Lars E. O. Svensson
                                            Noah Williams

                                         Working Paper 11733
                                 http://www.nber.org/papers/w11733


                       NATIONAL BUREAU OF ECONOMIC RESEARCH
                                1050 Massachusetts Avenue
                                  Cambridge, MA 02138
                                     November 2005




We thank Pierpaolo Benigno, Marvin Goodfriend, Boris Hoffman, Eric Leeper, Rujikorn Pavasuthipaisit,
and participants in the New York Area Workshop on Monetary Policy, New York, May 2005, the Conference
on Macroeconomic Risk and Policy Responses, Berlin, May 2005, and the Conference on Computing in
Economics and Finance, Washington, DC, June 2005, for helpful comments. Expressed views and any
remaining errors are our own responsibility. The views expressed herein are those of the author(s) and do
not necessarily reflect the views of the National Bureau of Economic Research.

©2005 by Lars E. O. Svensson and Noah Williams. All rights reserved. Short sections of text, not to exceed
two paragraphs, may be quoted without explicit permission provided that full credit, including © notice, is
given to the source.
Monetary Policy with Model Uncertainty: Distribution Forecast Targeting
Lars E. O. Svensson and Noah Williams
NBER Working Paper No. 11733
November 2005
JEL No. E42, E52, E58

                                            ABSTRACT

We examine optimal and other monetary policies in a linear-quadratic setup with a relatively general
form of model uncertainty, so-called Markov jump-linear-quadratic systems extended to include
forward-looking variables. The form of model uncertainty our framework encompasses includes:
simple i.i.d. model deviations; serially correlated model deviations; estimable regime-switching

models; more complex structural uncertainty about very different models, for instance, backward-

and forward-looking models; time-varying central-bank judgment about the state of model

uncertainty; and so forth. We provide an algorithm for finding the optimal policy as well as solutions

for arbitrary policy functions. This allows us to compute and plot consistent distribution forecasts---

fan charts---of target variables and instruments. Our methods hence extend certainty equivalence and

"mean forecast targeting" to more general certainty non-equivalence and "distribution forecast

targeting."

Lars E. O. Svensson
Department of Economics
Fisher Hall
Princeton University
Princeton, NJ 08544-1021
and NBER
svensson@princeton.edu

Noah Williams
Department of Economics
001 Fisher Hall
Princeton University
Princeton, NJ 08544-1921
and NBER
noahw@princeton.edu
Contents
1 Introduction                                                                                           1

2 The    model                                                                                           4
  2.1    The baseline model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .    4
  2.2    Reformulation according to the recursive saddlepoint method . . . . . . . . . . . . .           6
  2.3    Optimal policy and dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .       7

3 Interpretation of model uncertainty in our framework                                                   9

4 Examples                                                                                     11
  4.1 An estimated backward-looking model . . . . . . . . . . . . . . . . . . . . . . . . . . 11
  4.2 An estimated forward-looking model . . . . . . . . . . . . . . . . . . . . . . . . . . . 14

5 Arbitrary time-varying instrument rules and instrument paths                                      19
  5.1 Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
  5.2 Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23

6 Arbitrary time-invariant instrument rules and optimal restricted                      instrument
  rules                                                                                               23
  6.1 Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   . . . . . . . 24
  6.2 Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .    . . . . . . . 24
  6.3 Optimal Taylor-type instrument rules in a forward-looking model . . . .           . . . . . . . 25

7 Unobservable modes                                                                               27
  7.1 Optimal policy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
  7.2 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29

8 Conclusions                                                                                           32

Appendix                                                                                                35

A Incorporating central-bank judgment                                                                   35

B An algorithm for the value function and optimal policy function                                       36

C A unit discount factor                                                                                39

D Mean square stability                                                                                 40

E Alternative models with diﬀerent predetermined and forward-looking variables 41

F Details of the estimation                                                                             43

G Details for arbitrary time-varying instrument rules                                                   44

H Details for arbitrary time-invariant instrument rules                                                 45
I   Details with unobservable modes                                                                                             48
    I.1 Unobservable modes and forward-looking variables . . . .    .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   48
    I.2 An algorithm for the model with forward-looking variables   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   51
    I.3 Unobservable modes without forward-looking variables . .    .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   53
    I.4 An algorithm for the backward-looking model . . . . . . .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   54

J Optimization under discretion                                                                                                 55
1        Introduction

In recent years there has been a renewed interest in the study of optimal monetary policy under
uncertainty. Classical analyses of optimal policy consider only additive sources of uncertainty, where
in a linear-quadratic framework the well-known certainty-equivalence result applies and implies that
optimal policy is the same as if there were no uncertainty. Recognizing the uncertain environment
that policymakers face, recent research has considered broader forms of uncertainty for which
certainty equivalence no longer applies. While this may have important implications, in practice
the design of policy becomes much more diﬃcult outside the classical linear-quadratic framework.
        One of the conclusions of the Onatski and Williams [28] study of model uncertainty is that, for
progress to be made, the structure of the model uncertainty has to be explicitly modeled. In line
with this, in this paper we develop a very explicit but still relatively general form of model uncer-
tainty that remains quite tractable, using a so-called Markov jump-linear-quadratic (MJLQ) model,
where model uncertainty takes the form of diﬀerent “modes” that follow a Markov process. Our
approach allows us to move beyond the classical linear-quadratic world with additive shocks, yet
remains close enough to the linear-quadratic framework that the analysis is transparent. We exam-
ine optimal and other monetary policies in an extended linear-quadratic setup, extended in a way
to capture model uncertainty. The forms of model uncertainty our framework encompasses include:
simple i.i.d. model deviations; serially correlated model deviations; estimable regime-switching mod-
els; more complex structural uncertainty about very diﬀerent models, for instance, backward- and
forward-looking models; time-varying central-bank judgment–information, knowledge, and views
outside the scope of a particular model (Svensson [36])–about the state of model uncertainty; and
so forth. Moreover, while we focus on model uncertainty, our methods also apply to other linear
models with changes of regime which may capture boom/bust cycles, productivity slowdowns and
accelerations, switches in monetary and/or fiscal policy regimes, and so forth. We provide an algo-
rithm for finding the optimal policy as well as solutions for arbitrary policy functions. This allows
us to compute and plot consistent distribution forecasts–fan charts–of target variables and in-
struments. Our methods hence extend certainty equivalence and “mean forecast targeting,” where
only the mean of future variables matter (Svensson [36]), to more general certainty non-equivalence
and “distribution forecast targeting,” where the whole probability distribution of future variables
matter (Svensson [35]).1
    1
     The importance of the whole distribution of future target variables was recently emphasized by Greenspan [18]
at the 2005 Jackson Hole symposium, with reference to his [17] so-called risk-management approach:



                                                        1
    Certain aspects of our approach have been known in economics since the classic works of Aoki
[2] and Chow [8], who allowed for multiplicative uncertainty in a linear-quadratic framework. The
insight of those papers, when adapted to our setting, is that in MJLQ models the value function
remains quadratic in the state, but now with weights that depend on the mode. MJLQ models
have also been widely studied in the control-theory literature for the special case when there are no
forward-looking variables (see Costa and Fragoso [10], Costa, Fragoso, and Marques [11] (henceforth
CFM), do Val, Geromel, and Costa [14], and the references therein). More recently, Zampolli
[41] uses an MJLQ model to examine monetary policy under shifts between regimes with and
without an asset-market bubble, although still in a model without forward-looking variables. Blake
and Zampolli [4] provide an extension of the MJLQ model to include forward-looking variables,
although with less generality than in our paper and with the analysis and the algorithms restricted
to discretion equilibria.
    Relative to this previous literature, our contribution is the development of a general approach
for handling MJLQ models that include forward-looking variables. This extension is key for policy
analysis under rational expectations, but the forward-looking variables make the model nonrecur-
sive. We show that the recursive saddlepoint method of Marcet and Marimon [26] can nevertheless
be applied to express the model in a convenient recursive way, and we derive an algorithm for
determining the optimal policy and value functions.
    In addition to considering the optimal policy, we also consider the behavior of the model for
arbitrary time-varying or time-invariant instrument rules. This allows us to construct model-
consistent probability distributions —fan charts–of the variables relevant to policy makers for any
arbitrary instrument-rate path. Moreover, much of the literature in monetary policy analysis has
focused on “simple” instrument rules which are restricted to respond to only a subset of all available
information, with Taylor rules and various generalizations being most prominent. We show how to
derive optimal restricted instrument rules in our setting. Importantly, our approach is not restricted
to instrument rules; any given or optimal restricted policy rule, including targeting rules, can be
considered.
    For most of the paper, we focus on the case where agents can directly observe the mode. While
       In this [risk management] approach, a central bank needs to consider not only the most likely [rather:
       mean] future path for the economy but also the distribution of possible outcomes about that path. The
       decisionmakers then need to reach a judgment about the probabilities, costs, and benefits of various
       possible outcomes under alternative choices for policy.
   We agree with Feldstein [15] that Greenspan’s risk-management approach is best interpreted as standard expected-
loss minimization and we consider the risk-management approach and the approach of this paper as completely
consistent. See Blinder and Reis [5] for further discussion of possible interpretations of the risk-management approach.


                                                           2
this may be plausible for some environments, such as for example when a new policy regime is
announced, in many cases it is more fitting to assume that the modes are not observable. When
the modes are not observable, we can represent the decision maker’s information as a probability
distribution over possible modes, and optimal policy will depend on that distribution. In this
paper, we analyze the special case where decision makers do not learn from endogenous variables,
but rather the future the subjective distribution over modes is entirely governed by the transition
probabilities. In this case, the value function remains quadratic in the state, but with weights that
depend now on the probability distribution over modes. We develop a simple method of solving
this case.
       The more general case where decision makers infer from their observations the probability
of being in a particular mode is much more diﬃcult to solve. The optimal filter is nonlinear,
which destroys the tractability of the MJLQ approach.2 Additionally, as in most Bayesian learning
problems, the optimal policy will also include an experimentation component. Thus, solving for the
optimal decision rules will be a more complex numerical task. Due to the curse of dimensionality, it
is only feasible in models with a relatively small number of state variables and modes. Confronted
with these diﬃculties, the literature has focused on approximations such as linearization or adaptive
control.3 While these issues are important, they remain outside the scope of the present paper.
       The rest of the paper is organized as follows. In section 2, we lay out the model. In section
3, we discuss how diﬀerent kinds of model uncertainty can be incorporated by our framework.
In section 4, we present examples based on two empirical models of the US economy: regime-
switching versions of the backward-looking model of Rudebusch and Svensson [30] and the forward-
looking New Keynesian model of Lindé [24]. In section 5, we show how probability distributions of
forecasts of relevant variables can be constructed for arbitrary time-varying instrument-rate paths
or functions. In section 6, we show how the same probability distributions can be constructed
for arbitrary time-invariant instrument rules and optimal restricted instrument rules. Here we
derive optimal generalized and mode-dependent Taylor-type rules in the Lindé model. In section
7, we show how the optimal policy and value functions can be expressed as a function of the
probability distribution of the modes, in the realistic case when these modes are not observable.
   2
     The optimal nonlinear filter is well-known, and it is a key component of the estimation methods as well (Hamilton
[19] and Kim and Nelson [22]).
   3
      In the first case, restricting attention to (sub-optimal) linear filters preserves the tractability of the linear-
quadratic framework. See CFM [11] for a brief discussion and references. In adaptive control, agents do not take into
account the informational role of their decisions. See do Val and Başar [13] for an application of an adaptive control
MJLQ problem in economics. In a diﬀerent setting, Cogley, Colacito, and Sargent [9] have recently studied how well
adaptive procedures approximate the optimal policies.



                                                           3
We then reconsider the examples from section 4 in the unobservable case, and find that the eﬀects
of unobservability diﬀer greatly across the two models. In section 8, we present some conclusions.
The appendices contain some technical details and extensions of the material in the text.


2        The model

We set up a relatively flexible model of an economy with a central bank, which allows for relatively
broad additive and multiplicative uncertainty as well as diﬀerent relevant representations of the
central-bank information and judgment about the economy.


2.1       The baseline model

Consider the following model of an economy with a central bank:

                             Xt+1 = A11,t+1 Xt + A12,t+1 xt + B1,t+1 it + Ct+1 εt+1 ,                     (2.1)

                      Et Ht+1 xt+1 = A21,t Xt + A22,t xt + B2,t it ,                                      (2.2)

where Xt is an nX ×1 vector of predetermined variables (the state) in period t (the first element may
be unity to incorporate nonzero intercepts in a convenient way), xt is an nx × 1 vector of forward-
looking variables in period t, it is an ni × 1 vector of central-bank instruments (control variables) in
period t, and εt is an nX × 1 vector of zero-mean i.i.d. shocks realized in period t with covariance
matrix I. The forward-looking variables and the instruments are the nonpredetermined variables.4
The matrix A22,t is nonsingular, so equation (2.2) determines the forward-looking variables in period
t. There is no restriction in including the shock εt only in the equations for the predetermined
variables, since, if necessary, the set of predetermined variables can always be expanded to include
the shocks and the shocks this way indirectly enter into the equations for the forward-looking
variables. The expression Et qt+1 denotes the conditional expectation in period t of any random
variable qt+1 realized in period t + 1. The informational assumptions underlying the conditional
expectations operator Et are specified below.
        The central bank has an intertemporal loss function in period t:
                                                     ∞
                                                     X
                                                Et          δ τ Lt+τ ,                                    (2.3)
                                                     τ =0
    4
    Predetermined variables have exogenous one-period-ahead forecast errors, whereas non-predetermined variables
have endogenous one-period-ahead forecast errors.




                                                            4
where the period loss, Lt , satisfies
                                                   Lt ≡ Yt0 Λt Yt ,

where                                                      ⎡  ⎤
                                                           Xt
                                                 Yt ≡ Dt ⎣ xt ⎦
                                                           it
is an nY × 1 vector of target variables and the weight matrix Λt is a symmetric and positive
semidefinite matrix. It follows that the period loss function satisfies
                                          ⎡      ⎤0    ⎡     ⎤
                                             Xt          Xt
                                     Lt ≡ ⎣ xt ⎦ Wt ⎣ xt ⎦ ,                                                    (2.4)
                                              it          it

where the matrix Wt ≡ Dt0 Λt Dt is symmetric and positive semidefinite. The scalar δ is a discount
factor satisfying 0 < δ ≤ 1.5
       The matrices A11,t , A12,t , B1,t , Ct , Ht , A21,t , A22,t , B2,t , Λt , Dt , and Wt (assumed to be of
appropriate dimension) are random and can each take n diﬀerent values in period t, corresponding
to the n modes jt = 1, 2, ..., n in period t. We denote these values A11,t = A11jt , A12,t = A12jt , and
so forth. The modes jt follow a Markov process with constant transition probabilities:

                               Pjk ≡ Pr{jt+1 = k | jt = j}            (j, k = 1, ..., n).                       (2.5)

While we focus throughout on the time-homogeneous case, it is straightforward to allow the modes
to depend directly on calendar time. Furthermore, P denotes the n × n transition matrix [Pjk ] and
the 1 × n vector p ≡ (p1t , ..., pnt ) (where pjt ≡ Pr{jt = j}, j = 1, ..., n) denotes the probability
distribution of the modes in period t, so

                                                    pt+1 = pt P.

Finally, the 1 × n vector p̄ denotes the unique stationary distribution of the modes, so6

                                                      p̄ = p̄P .

       The shocks εt and the modes jt are assumed to be independently distributed (although we
allow the impact on the economy of the shocks εt to depend on the modes jt through the matrix
   5
      When δ = 1, the loss function (2.3) normally becomes unbounded. To handle this case, we scale the intertemporal
                                                                                             S
                                                                                             ∞
loss function by 1−δ for δ < 1 and consider the loss function to be the limit limδ→1 (1−δ)Et   δ τ Lt+τ . See appendix
                                                                                            τ =0
C for details.
   6
     We assume that the Markov chain is recurrent and aperiodic, so the stationary distribution is unique and does
not depend on the initial mode (Karlin and Taylor [21]). A simple suﬃcient condition is that the matrix P m has all
elements positive for some m ≥ 1 (Ljungqvist and Sargent [25]).


                                                          5
Cjt ). However, this assumption is not restrictive. Mode-dependent additive shocks are actually
incorporated, since the fact that we allow one of the predetermined variables to be unity implies
that all our equations may have mode-dependent intercepts.7
    In the beginning of period t, before the central bank chooses the instruments, it , the central
bank’s information set includes the history of the realizations of Xt , jt , εt , Xt−1 , jt−1 , εt−1 , xt−1 ,
it−1 , ... The central bank also knows the probability distribution of the innovation εt , the tran-
sition matrix P , and the n diﬀerent values each of the matrices can take. Hence, the conditional
expectations operator, Et , refers to expectations conditional on that information. In section 7 we
consider an alternative situation, which in many cases is more realistic, where the mode jt is not
observable in period t, and hence policy in period t is based on the probability distribution pt of
the modes.
    We consider the optimization problem of minimizing (2.3) in period t, subject to (2.1), (2.2),
(2.4), and Xt and jt given. In particular, we consider the optimization under commitment in a
timeless perspective (see Woodford [40] and Svensson and Woodford [39]).


2.2    Reformulation according to the recursive saddlepoint method

In order to apply the methods developed for similar models in control theory, we require that
the system be recursive. However, the presence of the forward-looking variables in (2.2) makes
the problem nonrecursive. Fortunately, the recursive saddlepoint method of Marcet and Marimon
[26] can be applied to reformulate the non-recursive problem with forward-looking variables as a
recursive saddlepoint problem (see Marcet and Marimon [26] for the general method and Svensson
[37] for the method applied to linear-quadratic problems).
    More precisely, the problem of minimizing the intertemporal loss function in each period t under
commitment in a timeless perspective can be reformulated as the dual saddlepoint problem:
                                                                            ∞
                                                                            X
                                         max            min            Et          δ τ L̃t+τ ,                    (2.6)
                                      {γ t+τ }τ ≥0 {xt+τ ,it+τ }τ ≥0
                                                                            τ =0

with the dual period loss function,
                                                 ∙            ¸0            ∙             ¸
                                                     X̃t+τ                      X̃t+τ
                                      L̃t+τ ≡                      W̃jt+τ                     ,                   (2.7)
                                                      ı̃t+τ                      ı̃t+τ
   7
     Without significant loss of generality, we could assume that the ε shocks are discrete, εt ∈ {ε̄h }n̄
                                                                                                         h=1 , and hence
depend on separate modes h = 1, ..., n̄ which may be correlated with the j modes. Then we could consider nn̄
generalized modes (j, h) (j = 1, ..., n, h = 1, ..., n̄) and incorporate the ε shocks in intercepts that depend on the
generalized modes. This way we could, without loss of generality, write the model without any explicit additive ε
shocks.


                                                              6
subject to the dual model:

                            X̃t+τ +1 = Ãjt+τ +1 X̃t+τ + B̃jt+τ +1 ı̃t+τ + C̃jt+τ +1 εt+τ +1                                          (2.8)

for τ ≥ 0, where X̃t and jt are given. Here, the new nX̃ × 1 vector of predetermined variables X̃t
(nX̃ ≡ nX + nx ) and the new nı̃ × 1 vector of instruments ı̃t (nı̃ ≡ nx + ni + nx ) are defined as
                                                                                     ⎡   ⎤
                                                   ∙           ¸                      xt
                                                        Xt
                                          X̃t ≡                    ,          ı̃t ≡ ⎣ it ⎦ .                                          (2.9)
                                                       Ξt−1
                                                                                      γt

The elements of the nx × 1 vector Ξt−1 are the Lagrange multipliers for the equations (2.2) for the
forward-looking variables in period t−1 from the optimization problem in that period. Hence, Ξt−1
captures the history dependence of the optimal policy under commitment in a timeless perspective
(see Woodford [40] and Svensson and Woodford [39]). The elements of the nx × 1 vector γ t are
the Lagrange multipliers for equations (2.2) in period t, considered as control variables in period t.
Hence, we have
                                                               Ξt = γ t                                                              (2.10)

as an additional dynamic equation, which is incorporated in (2.8).
   The matrix W̃jt in (2.7) is constructed so the dual period loss L̃t satisfies

                                                                            1
                          L̃t ≡ Lt − γ 0t (A21jt Xt + A22jt xt + B2jt it ) + Ξ0t−1 Hjt xt .                                          (2.11)
                                                                            δ

The matrices Ãjt+1 , B̃jt+1 , and C̃jt+1 (partitioned conformably with X̃t and, for B̃jt+1 , also with ı̃t )
satisfy
                 ∙               ¸                      ∙                                       ¸                ∙           ¸
                     A11jt+1 0                              A12jt+1 B1jt+1 0                                         Cjt+1
      Ãjt+1 ≡                       ,      B̃jt+1 ≡                                                ,   C̃jt ≡                   .   (2.12)
                       0     0                                0       0    I                                          0

2.3       Optimal policy and dynamics

The solution of the dual saddlepoint problem will result in a conditionally linear optimal policy
function with mode-dependent coeﬃcients,

                                               ı̃t = Fjt X̃t               (jt = 1, ..., n)                                          (2.13)

and a dual conditionally quadratic value function with mode-dependent coeﬃcients,
                                                                                   ∞
                                                                                   X
                 X̃t Ṽjt X̃t + w̃jt =      max             min               Et          δ τ L̃t+τ ,   (jt = 1, ..., n)             (2.14)
                                         {γ t+τ }τ ≥0 {xt+τ ,it+τ }τ ≥0
                                                                                   τ =0



                                                                       7
(see appendix B for details and a convenient algorithm for computing Ṽj and Fj for j = 1, ..., n).
The optimal policy function for the dual problem is also the solution to the original problem.
    Consider the composite state (X̃t , jt ) in period t, where ı̃t = Fjt X̃t . The transition from this
composite state to the composite state (X̃t+1 , jt+1 ) in period t+1 with ı̃t+1 = Fjt+1 X̃t+1 will satisfy

                                      X̃t+1 = Mjt jt+1 X̃t + C̃jt+1 εt+1 ,

where
                                        Mjt jt+1 ≡ Ãjt+1 + B̃jt+1 Fjt ,

and will, for given realization of εt+1 , occur with probability Pjt jt+1 . This determines the optimal
distribution of future X̃t+τ , jt+τ , and ı̃t+τ (τ ≥ 1) conditional on (X̃t , jt ).
    Such conditional distributions can be illustrated by plots of future means, medians, and per-
centiles (fan charts). Plots of future means, medians, and percentiles can also be constructed for
individual chains of the modes, for instance, the median or mean chain corresponding to no model
uncertainty. The simplest way to generate such plots is by simulation, which we illustrate in some
examples below.
    Note that the value function in (2.14) above corresponds to the dual period loss function and
the dual saddlepoint problem. The value function for the original problem of minimizing (2.3)
subject to (2.1), (2.2), and (2.4) under commitment in a timeless perspective with X̃t given is

                                               X̃t0 Vjt X̃t + wjt .                                (2.15)

The matrices Vj and the scalars wj for j = 1, ..., n, can be determined in the following way.
    Let Fjt be partitioned conformably with xt , it , and γ t ,
                                               ⎡         ⎤
                                                    Fxjt
                                        Fjt ≡ ⎣ Fijt ⎦ ,
                                                    Fγjt
and note that we have                     ⎡    ⎤ ⎡        ⎤
                                            Xt       I 0
                                          ⎣ xt ⎦ = ⎣ Fxjt ⎦ X̃t .
                                            it       Fijt
It follows that we can write the period loss function as

                                               Lt = X̃t0 W̄jt X̃t ,

where                                         ⎡    ⎤0    ⎡      ⎤
                                              I 0          I 0
                                     W̄jt ≡ ⎣ Fxjt ⎦ Wjt ⎣ Fxjt ⎦ .                                (2.16)
                                              Fijt         Fijt

                                                        8
For each j = 1, ..., n, the matrix Vj will then satisfy the Lyapunov equation:
                                                         X
                                                                        0
                                         Vj = W̄j + δ              Pjk Mjk Vk Mjk ,                              (2.17)
                                                           k

and the scalar wj will satisfy the equation:8
                                                 X
                                        wj = δ        Pjk [tr(Vk C̃k C̃k0 ) + wk ].                              (2.18)
                                                  k

        The matrices Vj and the scalar wj can also be found in a more direct way from the matrices Ṽj
and the scalar w̃j . Note that, by (2.2), (2.11), and (2.10), the identity

                                                            1
                     X̃t0 Vj X̃t + wj ≡ X̃t0 Ṽj X̃t + w̃j − Ξ0t−1 Hj Fxj X̃t           (j = 1, ..., n)          (2.19)
                                                            δ

must hold. We can write
                                                                           ∙                       1 0      0         ¸
1 0                1                                                               0               2δ FxXj Hj
  Ξt−1 Hj Fxj X̃t ≡ (Ξ0t−1 Hj Fxj X̃t +X̃t0 Fxj
                                             0
                                                Hj0 Ξt−1 ) ≡ X̃t0              1            1               0   0         X̃t ,
δ                  2δ                                                          2δ Hj FxXj   2δ (Hj FxΞj + FxΞj Hj )

where Fxj is partitioned conformably with Xt and Ξt−1 as Fxj ≡ [FxXj FxΞj ]. Then, identification
of terms implies that wj and Vj are determined by

                                            wj = w̃j           (j = 1, ..., n),
                                 ∙                       1 0      0               ¸
                                         0               2δ FxXj Hj
                    Vj = Ṽj −       1            1               0   0                 (j = 1, ..., n).
                                     2δ j FxXj
                                       H          2δ (Hj FxΞj + FxΞj Hj )
        As discussed in CFM [11], mean square stability is an appropriate concept of stability for our
framework. Appendix D provides some details on the definition of mean square stability and shows
how the necessary and suﬃcient conditions for mean square stability derived in CFM [11] can be
applied to our framework.


3        Interpretation of model uncertainty in our framework

The assumption that the random matrices of coeﬃcients take a finite number of values correspond-
ing to a finite number of modes allows us to use the convenient and flexible framework of MJLQ
systems–once we apply the recursive saddlepoint method of Marcet and Marimon to reformulate
the non-recursive model with forward-looking variables as a recursive model. By specifying diﬀerent
configurations of modes and transition probabilities, we can approximate many diﬀerent kinds of
model uncertainty.
    8
     Note that C̃k C̃k0 is the covariance matrix of the shocks C̃k εt+1 to X̃t+1 when jt+1 = k (k = 1, ..., n). Note also
that wj will normally have a bounded solution only if δ < 1. See appendix C for how to handle the case δ = 1.


                                                               9
• Both i.i.d. and serially correlated random coeﬃcients of the model can be handled. This can
  capture either generalized parameter uncertainty or diﬀerent behavior in diﬀerent modeled
  regimes (such boom/bust states, and so forth).

• The modes can correspond to diﬀerent structural models. The models can diﬀer by having
  diﬀerent relevant variables, diﬀerent number of leads or lags, or the same variable being
  predetermined in one model and forward-looking in another. For example, one mode can
  represent a model with forward-looking variables such as the New Keynesian model of Lindé
  [24], another a backward-looking model such as that of Rudebusch and Svensson [30] (see
  appendix E for details).

• The modes can correspond to situations when variables such as inflation and output have more
  or less inherent persistence (are more or less autocorrelated), when the exogenous shocks have
  more or less persistence (introduce a predetermined variable equal to the serially correlated
  shock, letting it be an AR(1) process with a high or low coeﬃcient), or when the uncertainty
  about the coeﬃcients or models is higher or lower.

• The modes can be structured such that they correspond to diﬀerent central-bank judgments
  about model coeﬃcients and model uncertainty. Let jt = 1, ..., n correspond to n diﬀerent
  model modes (diﬀerent coeﬃcients, diﬀerent variances or persistence of coeﬃcient distur-
  bances, or diﬀerent variances of the εt shocks). Let kt = 1, ..., m correspond to m diﬀer-
  ent central-bank judgment modes, depicting some central-bank information about the model
  modes. This can generally be modeled as a situation where the transition matrix for the
  model modes depends on the judgment mode. Thus let the transition matrix for model modes
  be P̃ (kt ), and hence depend on kt . Let P 0 denote the transition matrix for the judgment
  modes (assumed independent of the model modes). We can then consider a composite model-
  judgment mode (jt , kt ) in period t, with the transition probability from model-judgment mode
                                                                       0 . For instance, the judgment
  (h, k) in period t to mode (j, l) in period t + 1 given by P̃ (k)hj Pkl
  modes may correspond to diﬀerent persistence of the model modes.

• The mode jt may be observed in period t, in which case optimal policy and the value function
  is conditional on the mode jt , as shown above. Alternatively, and more realistically, we may
  assume that the mode cannot be perfectly observed. Then we can represent the central bank’s
  information in period t about the mode as the distribution pt of the modes. Then optimal


                                               10
      policy and the value function in period t will depend on the distribution pt . This case is
      considered in section 7.

    • As noted in appendix A, we can combine multiplicative uncertainty about the modes with
      the additive uncertainty about future deviations. This way we can simultaneously handle
      central-bank judgment about future additive deviations as in Svensson [36] and central-bank
      judgment about model modes as in this paper. For instance, we can handle situations when
      there is more or less uncertainty about shocks farther into the future relative to those in the
      near future.

    Generally, aside from dimensional and computational limitations, it is diﬃcult to conceive of a
situation for a policymaker that cannot be approximated in this framework.


4     Examples

In this section we present examples based on two empirical models of the US economy: regime-
switching versions of the backward-looking model of Rudebusch and Svensson [30] and the forward-
looking New Keynesian model of Lindé [24].


4.1    An estimated backward-looking model

In this section we consider the eﬀects of model uncertainty in the quarterly model of the US
economy of Rudebusch and Svensson [30], henceforth RS. Using the same data set as in their
paper, we estimate a three-mode MJLQ model using Bayesian methods to locate the maximum of
the posterior distribution, and we compare the implications to the constant-coeﬃcient version of
RS.
    The key variables in the model are quarterly annualized inflation π t , the output gap yt , and the
instrument rate (the federal funds rate) it . The model has a Phillips curve and an aggregate-demand
relation of the following form:
                              2
                                                    Ã    2
                                                                       !
                              X                          X
                 π t+1 =             ατ j π t−τ +   1−          ατ j       π t−3 + α3j yt + cπj επ,t+1 ,              (4.1)
                              τ =0                       τ =0
                  yt+1 = β 1j yt + β 2j yt−1 + β 3j (ı̄t − π̄ t ) + cyi εy,t+1 ,

                                                        P3                                 P3
where j ∈ {1, 2, 3} indexes the mode, ı̄t ≡               τ =0 it−τ /4        and π̄ t ≡      τ =0 π t−τ /4   are 4-quarter
averages, and the shocks επt and εyt are each independent standard normal random variables.

                                                         11
                       Parameter    Constant    Mode 1        Mode 2     Mode 3
                          α0          0.6922     0.2402        0.4236      1.2387
                          α1         −0.1033     0.1654       −0.2219     -0.6911
                          α2          0.2786     1.0388        0.0714      0.5491
                          α3          0.1284     0.1514        0.2755    −0.0304
                          β1          1.1591     1.0015        1.0302      1.8943
                          β2         −0.2521    −0.0853       −0.1069    −1.0312
                          β3         −0.0990    −0.3244        0.0315    −0.1011
                           cπ         0.9962     1.5504        0.1798      0.1562
                           cy         0.8132     1.2696        0.1447      0.2365

   Table 4.1: Estimates of the constant-coeﬃcient and three-mode Rudebusch-Svensson model.

   Table 4.1 reports our estimates of the peak of the posterior, with the OLS estimates of the
constant-coeﬃcient version of the model for comparison. For the MJLQ model, we center our prior
distribution at the OLS estimates. Details of the estimation method and prior setting are given in
appendix F. Here we see that many of the coeﬃcients diﬀer substantially across modes. Perhaps
most notable is the large diﬀerence in volatility, as the standard deviations of the shocks (cπ and
cy ) are from five to ten times larger in mode 1 than in the other two modes. In addition, the slope
of the Phillips curve, α3 , ranges from a large positive response in mode 2 to a small negative value
in mode 3. Similarly, the slope of the IS curve, β 3 , ranges from a relatively large negative response
in mode 1 to a small positive one in mode 2. The large diﬀerences in these key model coeﬃcients
lead to sharp diﬀerences in the optimal policy across modes, as we show below.
   The estimated probabilities of being in the diﬀerent modes are shown in figure 4.1. The plots
show both the filtered estimates, in which the distribution in period t is estimated using data
only up to t, as well as the smoothed estimates, in which the distribution in period t is estimated
using data for the whole sample. Clearly, there are more fluctuations in the filtered estimates than
in the smoothed ones, since by looking backward we can better assess the probability of being
in a particular regime. We see that, for the early part of the sample, the economy was mostly
assessed to be in the more volatile mode 1. From the early 1980s onward, the modes 2 and 3 were
more prominent, as the volatility moderated. The estimated transition matrix P and its implied
stationary distribution p̄ are
                   ⎡                      ⎤
                     0.8331 0.0921 0.0748                     £                          ¤
              P = ⎣ 0.0305 0.9194 0.0501 ⎦ ,           p̄ =       0.1652 0.4483 0.3866       .
                     0.0360 0.0541 0.9100

From the standpoint of these estimates, the early part of the sample is a bit of an aberration, as
mode 1 has the lowest weight in the stationary distribution. Thus, although similar episodes will

                                                  12
                                                Probability in Mode 1, RS Model
                   1


                 0.5


                   0
                  1960      1965      1970        1975       1980        1985        1990   1995   2000
                                                     Probability in Mode 2
                   1


                 0.5


                   0
                  1960      1965      1970        1975       1980        1985        1990   1995   2000
                                                     Probability in Mode 3
                   1


                 0.5


                   0
                  1960      1965      1970        1975       1980        1985        1990   1995   2000




Figure 4.1: Estimated probabilities of being in the diﬀerent modes. Smoothed (full-sample) infer-
ence is shown with solid lines, while filtered (one-sided) inference is shown with dashed lines.


re-occur in the model, they would tend to be balanced with longer periods of more tranquility.
    We let the period loss function be

                                         Lt = π 2t + λyt2 + ν(it − it−1 )2 .                                       (4.2)

Hence, the vector of target variables is Yt ≡ (π t , yt , it − it−1 )0 and the weight matrix Λ is a diagonal
matrix with the diagonal (1, λ, ν)0 . We set the weights to λ = 1 and ν = 0.2. We set the discount
factor in the intertemporal loss function to δ = 1. We then solve for the optimal policy function,

                                             it = Fij Xt ,          (j = 1, 2, 3),

where Xt ≡ (π t , π t−1 , π t−2 , π t−3 , yt , yt−1 , it−1 , it−2 , it−3 )0 , using the methods described above.
    The optimal policy functions are given in table 4.2. In figure 4.2, we plot the distribution of the
impulse responses of inflation, the output gap, and the instrument rate to the two shocks in the
model. In particular, for 10,000 simulation runs, we first draw an initial mode of the Markov chain
from its stationary distribution, then simulate the chain for 50 periods forward, tracing out the
impulse responses. The figure plots the mean response at each date, along with 30% quantiles of

                                                             13
the empirical distribution. More precisely, the dark, medium, and light grey band show 30%, 60%,
and 90% probability bands, respectively, with 5% of the distribution above the light gray band and
5% below. Also shown for comparison are the responses under the optimal policy for the estimated
constant-coeﬃcient model given above.9

  Mode              πt        π t−1        π t−2       π t−3          yt        yt−1         it−1         it−2        it−3
 Constant       0.9921      0.3465       0.4273      0.1381       1.7974     −0.4639      0.3713      −0.0899     −0.0456
 Mode 1         1.4796      1.3130       1.0760     −0.2853       1.9834     −0.4890     −0.1723      −0.3271     −0.1834
 Mode 2        −0.1510     −0.1739      −0.2132     −0.2077      −1.0595     −0.2824      0.3311      −0.0840     −0.0326
 Mode 3         1.1526      0.0988       0.5878      0.0309       4.6475     −4.6851     −0.0205      −0.2364     −0.1245

Table 4.2: Optimal policy functions for the constant-coeﬃcient and three-mode Rudebusch-
Svensson model.

    Both the table and the figure illustrate that the model uncertainty leads to a change in the
nature of policy. Compared to the constant-coeﬃcient model, most of the mass of the distribution
of the impulse responses lies closer to zero. This is particularly the case for the instrument-rate
responses. Thus our results here are in accord with the common intuition based on Brainard [6], that
model uncertainty should lead to less aggressive (that is, smaller in magnitude) policy responses.10
Interestingly, the probability distributions of responses are asymmetric, with the mean impulse
responses diﬀerent from the median responses (the latter lie inside the dark gray bands). In many
cases, the tails of the distributions appear relatively wide. This is perhaps most noticeable in the
responses of inflation to the two shocks. Here again the bulk of the distribution lies below the
constant-coeﬃcient model responses, but there is a significant right tail showing relatively large
and persistent eﬀects of the initial shock. These results illustrate that with model uncertainty
policy makers must go beyond forecasting the means of target variables and consider the entire
forecast distributions, and our approach makes this process quite manageable.


4.2     An estimated forward-looking model

We now consider the eﬀects of uncertainty in a model with both forward- and backward-looking
variables. The structural model is a mode-dependent simplification of the model of the US economy
   9
     The shocks are επ0 = 1 and εy0 = 1, respectively, for the two diﬀerent columns in the figure. Thus the shocks
to inflation and the output gap in period 0 are mode dependent and equal to cπj and cyj (j = 1, 2, 3), respectively.
We initialize by drawing from the stationary distribution, so the distribution of modes in each period remains the
stationary distribution.
  10
     Of course, this is only a loose parallel, as the Brainard result need not apply for the type of uncertainty considered
here, especially since the policy is here allowed to be mode-dependent.




                                                            14
                            Response of π to π shock
                                                                            Response of π to y shock
                   1.5                           Mean                 0.3
                                                 Constant
                    1                                                 0.2
                   0.5                                                0.1
                    0                                                  0

                     0     10     20      30      40        50          0   10    20      30      40   50
                            Response of y to π shock                        Response of y to y shock
                    0
                                                                       1
                  −0.2
                  −0.4                                                0.5
                  −0.6
                                                                       0
                     0     10     20      30      40        50          0   10    20      30      40   50
                            Response of i to π shock                        Response of i to y shock
                    2                                                  2

                    1                                                  0

                    0
                                                                      −2
                     0     10     20      30      40        50          0   10    20      30      40   50




Figure 4.2: Unconditional impulse responses to shocks under the optimal policy for the mode-
dependent Rudebusch-Svensson model. Solid lines: Mean responses. Dark/medium/light gray
bands: 30/60/90% probability bands. Dashed lines: Optimal responses for the constant-coeﬃcient
model.

of Lindé [24] and is given by

         π t = ω f j Et π t+1 + (1 − ω f j )π t−1 + γ j yt + cπj επt ,                                       (4.3)
                                            £                          ¤
         yt = β f j Et yt+1 + (1 − β f j ) β yj yt−1 + (1 − β yj )yt−2 − β rj (it − Et π t+1 ) + cyj εyt ,
               ¡                 ¢¡                 ¢
         it = 1 − ρ1j − ρ2j γ πj π t + γ yj yt + ρ1j it−1 + ρ2j it−2 + cij εit ,

where an instrument rule is added to the Phillips curve and the aggregate-demand relation.11 Again,
j ∈ {1, 2, 3} indexes the mode, and the shocks επt , εyt , and εit are independent standard normal
random variables. We use the same data set as above, and again estimate a three-mode MJLQ
model along with a constant-coeﬃcient model using Bayesian methods. Once again, we explicitly
state our prior settings in appendix F. We use the same prior for the structural coeﬃcients in the
constant-coeﬃcient and MJLQ cases, and the priors for the Markov chain coeﬃcients are the same
  11
     Because of the forward-looking expectations in the model, estimation of the model requires that a policy rule
be specified.


                                                                 15
as in the RS model.

                         Parameter   Constant   Mode 1        Mode 2    Mode 3
                            ωf         0.4908    0.4644        0.3380    0.3198
                             γ         0.0081    0.0112        0.0786    0.0312
                            βf         0.4408    0.0889        0.2356    0.3911
                            βr         0.0048    0.0396        0.1395    0.0000
                            βy         1.1778    1.1119        1.1570    1.2312
                             ρ1        0.9557    1.1486        0.8525    0.7967
                             ρ2       −0.0673   −0.2340       −0.1172    0.0516
                            γπ         1.3474    1.2439       −0.0643    2.3427
                            γy         0.7948    0.5799        0.9717   −0.3101
                             cπ        0.5923    0.4861        0.7232    0.9801
                             cy        0.4162    0.4744        0.5083    0.6720
                             ci        0.9918    0.2995        0.3930    1.2341

           Table 4.3: Estimates of the constant-coeﬃcient and three-mode Lindé model.

    Table 4.3 reports our estimates, with the estimates from the constant-coeﬃcient version of
the model for comparison. Our constant-coeﬃcient estimates are similar to those in Lindé [24],
with the main diﬀerence that we find much smaller estimates of γ and β r . At least some of the
diﬀerence may be due to our diﬀerent data series and sample period. We again see that many
of the key structural coeﬃcients change substantially across modes, particularly the instrument-
rule coeﬃcients and shock standard deviations. For example, mode 3 has the largest shocks to all
variables, while mode 1 has the smallest. The instrument-rule coeﬃcients γ π and γ y in mode 1 are
relatively close to those of the constant-coeﬃcient model, while in mode 3 the response to inflation,
γ π , is actually negative.
    The estimated transition   matrix P and its implied stationary distribution p̄ are given by
                 ⎡                            ⎤
                    0.9403     0.0340 0.0257              £                           ¤
             P = ⎣ 0.0625      0.8924 0.0451 ⎦ ,      p̄ = 0.5229 0.2741 0.2030 .
                    0.0695     0.0576 0.8729
Thus mode 1 is the most persistent and has the largest mass in the invariant distribution. This is
consistent with our estimation of the modes as shown in figure 4.3. Again, the plots show both the
smoothed and filtered estimates. We see that mode 1 was experienced the most throughout much
of the sample, holding for most of the sample until 1970 and then most of time after 1985. The
volatile mode 3 held for much of the early 1970s and early 1980s, alternating with the intermediate
mode 2.
    We again solve for the optimal policy function,

                                             it = Fij X̃t ,

                                                  16
                                             Probability in Mode 1, Linde Model
                   1


                 0.5


                   0
                  1960       1965     1970      1975       1980       1985          1990    1995    2000
                                                   Probability in Mode 2
                   1


                 0.5


                   0
                  1960       1965     1970      1975       1980       1985          1990    1995    2000
                                                   Probability in Mode 3
                   1


                 0.5


                   0
                  1960       1965     1970      1975       1980       1985          1990    1995    2000




Figure 4.3: Estimated probabilities of being the diﬀerent modes. Smoothed (full-sample) inference
is shown with solid lines, while filtered (one-sided) inference is shown with dashed lines.

            Mode           π t−1      yt−1      yt−2           it−1           επt         εyt   Ξπ,t−1     Ξy,t−1
           Constant      0.3552     1.0714   −0.2231        0.7853         0.6975     2.2437    0.0024     0.0182
           Mode 1        0.8915     2.0766   −0.2338        0.5962         1.6644     2.2929    0.0037     0.0066
           Mode 2        1.4625     1.6985   −0.2666        0.3271         2.2092     2.2216    0.0090     0.0393
           Mode 3        0.8348     0.7955   −0.2085        0.8016         1.2273     1.4812    0.0006     0.0021

   Table 4.4: Optimal policy functions of the constant-coeﬃcient and three-mode Lindé model.


where X̃t ≡ (π t−1 , yt−1 , yt−2 , it−1 , επt , εyt , Ξπ,t−1 , Ξy,t−1 )0 , using the methods described above. We
use the same loss function as for the backward-looking model. The optimal policy functions are
given in table 4.4. In figure 4.4, we plot the distribution of the impulse responses of inflation, the
output gap, and the instrument rate to the two structural shocks in the model. Again we consider
10,000 simulations of 50 periods, and plot the mean responses along with 30% probability bands
and the corresponding optimal responses for the constant-coeﬃcient model.12
       Again, the model uncertainty leads to a change in the nature of policy. Compared to the
constant-coeﬃcient case, most of the mass of the distribution of impulse responses is consistent
  12
     Again, the shocks are επ0 = 1 and εy0 = 1, respectively, so the shocks to the inflation and output-gap equations
in period 0 are mode-dependent and equal to cπj and cyj (j = 1, 2, 3), respectively. The distribution of modes in
period 0 (and thereby all periods) is again the stationary distribution.


                                                            17
                       Response of π to π shock
                                                                      Response of π to y shock
                                           Mean
                                                                0.4
                  1                        Constant

                0.5                                             0.2

                  0                                              0
                   0    10    20      30     40       50          0   10     20     30    40     50
                       Response of y to π shock                       Response of y to y shock
                  0
                                                                 1
               −0.2
               −0.4                                             0.5
               −0.6
                                                                 0
               −0.8
                   0    10    20      30     40       50          0   10     20     30    40     50
                       Response of i to π shock                       Response of i to y shock
                  6
                  4                                              3
                                                                 2
                  2
                                                                 1
                  0
                                                                 0
                   0    10    20      30     40       50          0   10     20     30    40     50



Figure 4.4: Unconditional impulse responses to shocks under the optimal policy for the mode-
dependent Lindé model. Solid lines: Mean responses. Dark/medium/light grey bands: 30/60/90%
probability bands. Dashed lines: Optimal responses for the constant-coeﬃcient model.


with earlier peak eﬀects of the shocks which more rapidly return to zero. This is particularly the
case for the instrument-rate responses, although the relative magnitudes diﬀer somewhat with the
type of the shock. For shocks to the output gap, most of the mass of the instrument-rate response
distribution under model uncertainty lies below the response for the constant-coeﬃcient model. For
shocks to inflation, most of the distribution is consistent with larger and more prompt instrument-
rate responses than for the constant-coeﬃcient model. Once again, the distribution of the impulse
responses is asymmetric, with the mean responses diﬀerent from the median responses (the latter
lie inside the dark gray bands), and again the tails of the distributions appear relatively wide.
As in the RS model above, this is perhaps most noticeable for the inflation responses, where the
center of the distribution lies below the constant-coeﬃcient case but there is a relatively large right
tail showing more significant and persistent responses. However in the Lindé model, the long-run
behavior is better anchored as the distributions of responses in all cases collapse tightly around
zero after roughly thirty quarters.



                                                           18
5         Arbitrary time-varying instrument rules and instrument paths

In this section we derive the dynamics of the system, including the distribution of forecasts of
relevant future variables, for arbitrary time-varying instrument rules. This includes time-varying
instrument paths such as a constant instrument rate for arbitrary (but finitely many) periods,
analogous to the constant-rate forecasts of the some central banks. We also specify the optimization
problem for instrument rules in a given class. Furthermore, as we shall note, although we explicitly
only deal with instrument rules, our method generalizes to arbitrary policy rules, including targeting
rules (Svensson and Woodford [39]).


5.1        Setup

Consider implementing an arbitrary time-varying instrument rule during period t = 0, 1, ..., T − 1
and implementing the optimal policy function from period T on. Let the arbitrary instrument rule
be conditionally linear but otherwise of the rather general form

                                    it = FX̃tjt X̃t + Fxtjt xt      (0 ≤ t ≤ T − 1),                 (5.1)

where X̃t denotes the nX̃ × 1 vector (Xt0 , Ξ0t−1 )0 , FX̃tjt and Fxtjt are (ni × nX̃ ) and (ni × nx )
matrices, respectively, which depend on both the period t and the mode jt . For added generality,
we also allow a possible response to the forward-looking variables, xt . Indeed, we could consider
any arbitrary policy rule, including targeting rules, of the form

                     Et H3,t+1,jt+1 xt+1 = A31tjt X̃t + A32tjt xt + B3tjt it      (0 ≤ t ≤ T − 1),   (5.2)

where H3tj , A31tj , A32tj , and B3tj are potentially time-varying and mode-dependent matrices of the
appropriate dimension (in particular, having ni rows and giving rise to ni independent equations,
which is required to determine the instruments in each period).
         If Fxtjt ≡ 0, (5.1) is an explicit instrument rule; that is, the instrument responds to predeter-
mined variables only.13 If Fxtjt 6≡ 0 (Fxtjt 6= 0 for some mode jt with positive probability), it is
an implicit instrument rule; that is, the instrument depends also on forward-looking variables. In
the latter case, there is a simultaneity problem, in that the instrument and the forward-looking
variables are simultaneously determined. Thus, an implicit instrument rule can be interpreted
as an equilibrium condition. As discussed in Svensson [36] and Svensson and Woodford [39], the
implementation of an implicit instrument rule is problematic, since in practice a central bank can
    13
         Note that policy functions and explicit instrument rules are the same.


                                                            19
literally only respond to predetermined variables.14 We disregard these problems here, and consider
(5.1) as just another equilibrium condition added to equations (2.1) and (2.2).
    We can write (5.1) in the more general form

                                       0 = FX̃tjt X̃t + Fı̃tjt ı̃t        (0 ≤ t ≤ T − 1),                             (5.3)

where
                                                Fı̃tjt ≡ [Fxtjt − Ini 0ni ×nx ],                                       (5.4)

where ı̃t ≡ (x0t , i0t , γ 0t )0 as in (2.9). Assume that the policy function shifts permanently to the
optimal policy function (2.13) in period T .15 This is a reasonably general formulation. Since one of
the elements of Xt may be unity, (5.3) includes the case of an exogenous time-varying and mode-
dependent instrument level for the first T periods, including the case of a constant instrument
level.
    It follows from section 2 that there exists Ṽj and w̃j (j = 1, ..., n) such that, for t ≥ T , the
intertemporal loss for the dual saddlepoint problem satisfies

                X̃t0 Ṽjt X̃t + w̃jt ≡ max min {L̃t + δEt (X̃t+1
                                                             0
                                                                 Ṽjt+1 X̃t+1 + w̃jt+1 )}               (t ≥ T )
                                          γt   (xt ,it )

subject to
                                          X̃t+1 = Ãjt+1 X̃t + B̃jt+1 ı̃t + C̃jt+1 εt+1                                (5.5)

and X̃t given (X̃t , L̃t , ı̃t , Ãjt+1 , B̃jt+1 , and C̃jt+1 are defined as in (2.11) and (2.12)). Recall that
this dual intertemporal loss is associated with the dual loss function, not the original loss function.
    The recursive saddlepoint method of Marcet and Marimon [26] provides a simple and compact
way to incorporate the fact that the equilibrium forward-looking variables xt and the Lagrange
multiplier Ξt−1 will be aﬀected by the constraint (5.1). Working backward, for t = T −1, T −2, ..., 0,
we define Ṽtjt and w̃tjt recursively from the saddlepoint problems:
                                              (          ³                             ´           )
                                                L̃  + ϕ0 −F          X̃  −  F      ı̃
                                                  t                    t     ı̃tj    t
 X̃t0 Ṽtjt X̃t +w̃tjt ≡ max min                       t       X̃tjt             t
                                                                                                       (0 ≤ t ≤ T −1), (5.6)
                         (γ t ,ϕt ) (xt ,it )             0 Ṽ
                                                + δEt (X̃t+1             X̃      +    w̃t+1,jt+1 )
                                                              t+1,jt+1 t+1


subject to (5.3) and (5.5), where ṼT jt ≡ Ṽjt and w̃T jt ≡ w̃jt . Here, ϕt can be interpreted as an
ni × 1 vector of Lagrange multipliers for the ni equations (5.3). Formally, (5.3) is added to the
  14
      In practice, because of a complex and systematic decision process (Brash [7], Sims [31], Svensson [34]), the
information modern central banks respond to is at least a few days old, and most of the information is one or several
months old.
  15
     Alternatively, the policy rule could shift to an arbitrary time-invariant policy rule for which a unique solution
exists.


                                                                  20
equations (2.2) and the Lagrange multiplier γ t is augmented to (γ 0t , ϕ0t )0 . Normally, the recursive
saddlepoint method would then involve augmenting the Lagrange multiplier Ξt−1 to (Ξ0t−1 , Φ0t−1 )0 ,
with the added dynamic equation
                                                            Φt = ϕt .

However, the augmented period loss is here
                                                         ³                          ´
                                     L̂t ≡   L̃t + ϕ0t    it − FX̃tjt X̃t − Fxtjt xt .                       (5.7)

Since the analogue of Et Ht+1 xt+1 , the left side of (5.3), is zero, there is no term including Φ0t−1 aug-
mented to the period loss. Hence, we do not need to consider Φt−1 as an additional predetermined
variable here.16
       The solution determines the time- and mode-dependent optimal policy function F̃tjt ,
                             ⎡    ⎤               ⎡        ⎤
                               xt                   F̃xtjt
                       ı̃t ≡ ⎣ it ⎦ = F̃tjt X̃t ≡ ⎣ F̃itjt ⎦ X̃t (0 ≤ t ≤ T − 1),
                               γt                   F̃γtjt

where of course it in ı̃t satisfies (5.1). The interesting part of the solution is

                                                         xt = F̃xtjt X̃t ,                                   (5.8)

and F̃xtjt and F̃itjt will satisfy
                                              F̃itjt ≡ FX̃tjt + Fxtjt F̃xtjt .

There is also a solution for ϕt , ϕt = F̃ϕtjt X̃t , but that solution is not needed for the intertemporal
loss and the dynamics. It follows that the dynamics of X̃t satisfies

                         X̃t+1 = Mtjt jt+1 X̃t + C̃jt+1 εt+1                   (0 ≤ t ≤ T − 1),

                         X̃t+1 = Mjt jt+1 X̃t + C̃jt+1 εt+1                   (t ≥ T )

where

                           Mtjt jt+1 ≡ Ãjt+1 + B̃jt+1 F̃tjt                  (0 ≤ t ≤ T − 1),

                            Mjt jt+1 ≡ Ãjt+1 + B̃jt+1 F̃jt                  (t ≥ T ).

       The intertemporal loss in period 0 for the dual period loss function (5.7) will be given by

                                                   X̃00 Ṽ0j0 X̃0 + w̃0j0 .
  16
     If we were considering the more general policy rule (5.2), the term Et H3,t+1,jt+1 xt would require us to also
consider Φt−1 as an additional predetermined variable.


                                                               21
However, this is not the intertemporal loss in period 0 for the original period loss function, (2.4).
In order to find that, note that the intertemporal loss for the optimal policy for t ≥ T will be given
by
                                                   X̃t0 Vjt X̃t + wjt ,

where the matrix Vj will satisfy the Lyapunov function (2.17) and the scalar wj will satisfy (2.18).
      For t = T − 1, T − 2, ..., 0, we can define Vtj and wtj recursively from the equations
                                                  ⎡     ⎤0   ⎡       ⎤
                                                  I 0          I 0
                                         W̄tj ≡ ⎣ F̃xtj ⎦ Wj ⎣ F̃xtj ⎦ .
                                                  F̃itj        F̃itj
                                                       X
                                                                 0
                                     Vtj ≡ W̄tj + δ         Pjk Mtjk Vt+1,k Mtjk ,
                                                        k
                                              X
                                   wtjt ≡ δ       Pjk [tr(Vt+1,k C̃k C̃k0 ) + wt+1,k ],
                                              k

where VT j ≡ Vj and wT j ≡ wj .17
      Then, the intertemporal loss in period 0 for the original period loss function (5.7) is

                                                  X̃00 V0j0 X̃0 + w0j0 .

This corresponds to the loss under commitment in a timeless perspective when the instrument is
restricted to fulfill (5.1) and shifts to the optimal policy in period T . That is, when the restriction
(5.1) is removed in period T and optimal policy is feasible, the commitment is not from scratch
in period T (in which case ΞT −1 would equal zero) but takes into account the previous Lagrange
multiplier ΞT −1 . In principle, this formulation also allows us to consider nonzero Ξ−1 in period 0.
      The method described above also works for the backward-looking case, in which case

                                                        L̃t ≡ Lt

and there are no variables γ t , xt , and Ξt−1 (equivalently, they are identically equal to zero). Then
the intertemporal loss for the saddlepoint problem is equal to the intertemporal loss for the original
problem.
      Details about the computation of F̃tjt and Ṽtjt are provided in appendix G.
 17
      Note that we could also determine Vtjt and wtjt relying on the analogue of the identity (2.19) for this case.




                                                            22
5.2    Optimization

Let Ft ≡ {FX̃tjt , Fxtjt }njt =1 for 0 ≤ t ≤ T − 1, and let F ≡ {Ft }Tt=0
                                                                       −1
                                                                          denote the time- and mode-
dependent policy functions for 0 ≤ t ≤ T − 1. We may assume that there is a feasible set F of
such policy functions, so F ∈ F. Then we can, in principle, consider choosing the policy functions
optimally according to
                                        min {X̃00 V0j0 (F )X̃0 + w0j0 (F )},                                   (5.9)
                                        F ∈F

where the notation emphasizes that V0jt and w0jt will depend on F . With the policy problem
formulated this way, the optimal F would depend on X̃0 (including Ξ−1 ) and j0 as well as the
covariance matrix C̃k C̃k0 of the shocks C̃k εt+1 to X̃t+1 in mode jt+1 = k (k = 1, ..., n). That is,
certainty equivalence does not necessarily hold for restricted classes of policy functions. If the class
of time- and mode-dependent policy functions is suﬃciently big, it would include the optimal policy
function (2.13). If we were to add 1δ Ξ−1 Hj0 x0 to the period loss function in period 0, the optimal
policy function would then be a solution to (5.9).
    Note that, if F is such that Fxtjt 6= 0, the optimal F is generally not unique. The reason is that
for (5.8), if
                                               it = FX̃tjt X̃t + Fxtjt xt

is a solution, so is

            it = FX̃tjt X̃t + Fxtjt xt + ζ 0 (xt − F̃xjt X̃t ) = (FX̃tjt − ζ 0 F̃xjt )X̃t + (Fxtjt + ζ 0 )xt

for any nx × 1 vector ζ.


6     Arbitrary time-invariant instrument rules and optimal restricted
      instrument rules

In this section we derive the dynamics of the system, including the distribution of forecasts of
relevant future variables, for arbitrary time-invariant instrument rules. We also specify the opti-
mization problem for time-invariant instrument rules in a given class. While this is a special case of
the previous section, it is important in its own right and, in particular, allows a simpler algorithm.




                                                          23
6.1    Setup

Consider an arbitrary time-invariant instrument rule,

                                it = FX̃jt X̃t + Fxjt xt       (jt = 1, ..., n),                   (6.1)

combined with (2.1) and (2.2). We can consider this as a special case of the time-varying instrument
rules in section 5, if we let FX̃tjt = FX̃jt and Fxtjt = Fxjt and apply the algorithm of that section
by iterating from t = T > t0 to t = t0 but instead of stopping at t0 = 0 letting t0 → −∞. In
practice, the iteration would stop when F̃tjt and Ṽtjt have converged to F̃jt and Ṽjt . Partitioning
F̃jt conformably with xt , it , and γ t , we have

                             xt = F̃xjt X̃t ,

                             it = FX̃jt X̃t + Fxjt F̃xjt X̃t ≡ F̃ijt X̃t ,

                          X̃t+1 = Mjt jt+1 X̃t + C̃jt+1 εt+1          (jt = 1, ..., n).

This gives rise to a probability distribution of X̃t+τ , xt+τ , and it+τ (τ ≥ 0) conditional on X̃t
and jt . This solution will be associated with a value function for the original period loss function,

                                              X̃t0 Vjt X̃t + wjt .


6.2    Optimization

For a given restricted class F of instrument rules, we can consider the optimal restricted (time-
invariant) instrument rule F̂ , which minimizes an intertemporal loss function. This intertemporal
loss function could be the conditional loss in a given period, say period 0,

                                 F̂ ≡ arg min {X̃00 Vj0 (F )X̃0 + wj0 (F )},
                                           F ∈F

where the notation takes into account that Vj0 (F ) and wj0 (F ) depend on F ∈ F. This would
make the optimal restricted time-invariant instrument rule depend on X̃0 , j0 , and the covariance
matrices C̃j C̃j0 of the shocks C̃j εt+1 to X̃t+1 in mode j = 1, ..., n. Alternatively, the intertemporal
loss function could be the unconditional mean of the period loss function:

                                            F̂ = arg min E[Lt ].
                                                      F ∈F

Note that
                                E[Lt ] = (1 − δ)E[X̃t0 Vjt (F )X̃t + wjt (F )].

                                                      24
Furthermore, the unconditional and conditional intertemporal loss are approximately the same
when the intertemporal loss is scaled by 1 − δ and δ is close to one,
          ∞
          X                                                                           X
   lim Et   (1 − δ)δ τ Lt+τ = E[Lt ] = lim (1 − δ)E[wjt ] = E[tr(Vjt C̃jt C̃j0 t )] =   p̄j tr(Vj C̃j C̃j0 ),
  δ→1−                                     δ→1−
           τ =0                                                                           j

where we recall that p̄ = (p̄1 , ..., p̄n ) is the stationary distribution of modes.


6.3    Optimal Taylor-type instrument rules in a forward-looking model

We now apply the methods outlined above to derive optimal Taylor-type instrument rules in the
estimated forward-looking model from section 4.2 above. In particular, we consider simple implicit
instrument rules of the general form (disregarding the implementation problems mentioned above):

                                      it = fijt it−1 + fπjt π t + fyjt yt .                               (6.2)

This is a Taylor rule with interest-rate smoothing, whose coeﬃcients may depend on the mode jt
in period t. As special cases, we consider mode-independent Taylor rules, where the coeﬃcients are
constrained to be the same in all modes, and original Taylor rules without the smoothing coeﬃcient
fi . We use the unconditional mean of the period loss, E[Lt ], as the intertemporal loss function.
   Note that, compared to (6.1), (6.2) implies a response to the predetermined variables Xt rather
than to X̃t ≡ (Xt0 , Ξ0t−1 )0 . That is, we need not consider the Lagrange multiplier Ξt−1 . Then the
equilibrium solution will be of the simpler form

           xt = Gjt Xt ,

            it = (FXjt + Fxjt Gjt )Xt ≡ Fjt Xt .

         Xt+1 = (A11jt+1 + A12jt+1 Gjt + B1 Fjt )Xt + Cjt+1 εt+1 ≡ Mjt jt+1 Xt + Cjt+1 εt+1 ,

and not involve Ξt−1 . This allows us to use a somewhat simpler algorithm than that discussed
above. In appendix H, we discuss in more detail this simpler algorithm for the calculations of the
optimal time-invariant instrument rules and the associated losses.
   The results are summarized in table 6.1, where we report the optimal response coeﬃcients
of the diﬀerent forms of the instrument rules for the constant-coeﬃcient and MJLQ versions of
the model. Interestingly, we find that the optimal Taylor-type rules that are constrained to have
the same responses in all modes are more aggressive in the MJLQ model than in the constant-
coeﬃcient model. This contrasts with the impulse responses for the optimal policy shown in table
4.4 above, where we found that the optimal policy in the MJLQ model had on average a slightly

                                                       25
                                  Mode      it−1    πt    yt   Loss
                                      Constant-coeﬃcient model
                                   Optimal policy function     11.10
                                    -         -    2.93 1.69 15.13
                                    -       0.89 0.80 0.83 11.67
                                            MJLQ model
                                   Optimal policy function     14.62
                                All modes     -    3.97 2.07 20.96
                                 Mode 1       -    3.01 3.10
                                 Mode 2       -    6.39 2.85 18.09
                                 Mode 3       -    1.94 0.86
                                All modes 0.73 1.60 1.49 16.18
                                 Mode 1     0.69 1.27 1.78
                                 Mode 2     0.87 3.06 2.40 15.32
                                 Mode 3     0.81 1.16 0.83

   Table 6.1: Optimal Taylor-type instrument rules for the estimated three-mode Lindé model.


more aggressive inflation response but a more attenuated output-gap response than in the constant-
coeﬃcient model. Similar conclusions apply for both the original and smoothed Taylor rules. This
increased aggressiveness is further illustrated in figure 6.1. The figure shows the loss in the constant-
coeﬃcient and MJLQ models for mode-independent original and smoothed Taylor rules. For both
smoothed and original Taylor rules, the loss function is more sensitive to variations in the inflation
response coeﬃcient of the policy rule. For both kinds of rules, performance in the MJLQ model is
enhanced by more aggressive responses.
   These results suggest that constraining the rules to react in the same way in all modes may push
the optimal simple rules towards more aggressive responses. Moreover, as table 6.1 shows, the mode-
independent original Taylor rules are suboptimal by a fairly sizeable margin. This stands in contrast
to the constant-coeﬃcient model, where the smoothed Taylor rule has a loss only slightly higher
loss than the fully optimal policy. Thus we also consider mode-dependent original and smoothed
Taylor rules, which are reported in the table. There we see that there is significant variation in
the responses across modes, with mode 3 having the weakest responses (particularly for the output
gap), while mode 2 has the strongest (particularly for the smoothed Taylor rules). In at least two
of the three modes, the rules are again more aggressive than in the constant-coeﬃcient model.
Above we saw that the eﬀects of uncertainty on policy, captured by comparison of the constant
coeﬃcient model to the MJLQ model, had ambiguous eﬀects on optimal policy. In contrast, when
the instrument rule is constrained to respond to fewer variables and not be history-dependent (that



                                                   26
                                                     Original Taylor Rule, Const.−coef. model                                                                                                    Original Taylor Rule, MJLQ model
                                                    5                                                                                                                                  5
                                                                                                                                                                                                                                  2
                                                                             −18                                                                                                                                                −2




                                                                                                                                                                                           −30
                                                                 9                                                                 −17




                                                                                                                                                                                                                     4
                                                               −1




                                                                                                                                                                                                                  −2



                                                                                                                                                                                                                           2
                                                                                                                                                                                                                23
                            Response to inflation




                                                                                                                                                               Response to inflation




                                                                                                                                                                                                                          −2
                                                                                                                                                                                                                   −23−
                                                    4                   7                                                        −16                                                   4                                                              1
                                                                     −1                                                                                                                                                                     −21 −2




                                                                                                                                                                                                       −24
                                                                                                                                                                                           −30
                                                                                             −15.5                                                                                                                                                              −22




                                                                                                                                                                                                         −25−
                                                                                                                                                                                                                                                           −22
                                                    3                                                                                                                                  3                                                                        23
                                                                                                                                                                                                                                                          −23 −24




                                                                                                                                                                                                              25
                                                                                                                                 5.5                                                                                                                         −




                                                                      − 16
                                                                                                             −15.2          −1                                                                                                              −24             −25−25
                                                         −1                                                                            −16
                                                           8




                                                                                                                                                                                           −4
                                                                                                                                                                                                 −4
                                                                                                                                                                                                   0                                      −30
                                                    2                                                                                                                                  2




                                                                                                                                                                                             0
                                                                −19                                                                                                                                                       −30
                                                                                                       −17                 −18 −19                                                                                                                    −40−40
                                                                  −20                                                            −20
                                                                  −25                                                                                                                            −−110                                                       −100
                                                                                                                                 −25                                                             −−55000                                                    −100
                                                                  −40                                                            −40                                                                 000                                                     −500
                                                                                                                                                                                                                                                            −500
                                                                 −100                                                           −100
                                                    1                                                                                                                                  1
                                                     0                        1           2                                                  3                                          0                        1           2                                            3
                                                                          Response to output gap                                                                                                             Response to output gap
                           Smoothed Taylor Rule, f = 0.8, Const.−coef. model                                                                                                           Smoothed Taylor Rule, f = 0.8, MJLQ model
                                                                                                   i                                                                                                                                  i
                                                    3                                                                                                                                  3
                                                                                             6                                                                                                                                        1     −20
                                                                                          −1                                                                                                                                     −2
                                                        − 25




                                                                                                       5
                                                                                                 −1                         −14                                                                                                                                    −1
               Response to inflation




                                                                                                                                                  Response to inflation



                                                                                                                                                                                                       −40
                                          2.5                                                                                                                                2.5                                                                                      9
                                                                                                                                                                                                                                                          −1
                                                          −20




                                                                                                                                                                                                                                                            8
                                                    2                                                                                                                                  2




                                                                                                                                                                                                             −25
                                                                                                                                                                                                                                      −17
                                                                                                                           −13




                                                                                                                                                                                                                                                               −18
                                                                                                                                                                                                                     9
                                                                                     .5                                                                                                                                         −16
                                          1.5                                                                                                                                1.5
                                                                     4




                                                                                                                                                                                                                   −1
                                                                                  12
                                                                     −1




                                                                              −                                                                                                                                                      .5




                                                                                                                                                                                                                                            7
                                                                                                                                                                                                                                            −1
                                                                     3




                                                                               2                                                                                                                                                                               −20 −21
                                                                     −1




                                                                             −1                                            −14




                                                                                                                                                                                             −100
                                                    1                                                                                                                                  1                                                        −19




                                                                                                                                                                                                            −18
                                                                                                                                                                                                           −20
                                                                                                                           −15
                                                          −17




                                                                                              .5
                                                                                          −12
                                                        −15
                                                         −16




                                                                                                                                                                                                                                                −25




                                                                                                                                                                                                           −2
                                          0.5                        −13                         −16 −17             −20                                                     0.5                                                                                −40




                                                                                                                                                                                                             1
                                             0                                1           2                                                  3                                  0                                1           2                                            3
                                                                          Response to output gap                                                                                                             Response to output gap




Figure 6.1: Contours of the loss function for the Lindé model under mode-independent Taylor-type
instrument rules. Left column: Constant-coeﬃcient model. Right column: MJLQ model. Top row:
Original Taylor rules. Bottom row: Smoothed Taylor rules with fi = 0.8.


is, not respond to Ξt−1 ), uncertainty leads to more aggressive responses.


7    Unobservable modes

In this section we consider the case when the modes are not observable, showing how the optimal
policy and value functions can be expressed as a function of the probability distribution of modes.
Then we apply the results in our two estimated examples. As noted in the introduction, we do
not consider the case where policymakers update their subjective distribution over modes based on
observations. While this case is important, the learning which it implies introduces nonlinearities
which destroy the tractability of the MJLQ framework. Instead, we assume here that the subjective
distribution simply evolves according to the exogenous transition probabilities.




                                                                                                                                                 27
7.1     Optimal policy

Assume that central bank cannot observe the actual mode in period t and but believes that the
distribution of modes in period t is pt ≡ (p1t , ..., pnt ). Conditional on pt in period t, the distribution
of the modes in period t + τ is given by

                                             pt+τ = pt P τ       (τ ≥ 0).                                         (7.1)

    With forward-looking variables, the dual model can be written

                                   X̃t+1 = Ãjt+1 X̃t + B̃jt+1 ı̃tjt + C̃jt+1 εt+1 ,

where                                                       ⎡       ⎤
                                                              xtjt
                                                  ı̃tjt   ≡ ⎣ it ⎦ .
                                                              γ tjt
Note that it will only depend on pt and be independent of jt , since the instrument must reflect the
central bank’s information, whereas xt and γ t will depend on both pt and jt . Appendix I shows
that the optimal policy function can be written
                                  ⎡       ⎤ ⎡            ⎤
                                    xtjt      Fx (pt )jt
                          ı̃tjt ≡ ⎣ it ⎦ = ⎣ Fi (pt ) ⎦ X̃t ≡ F (pt )jt X̃t .
                                    γ tjt     Fγ (pt )jt
The dynamics of the predetermined variables will follow

                                       X̃t+1 = M (pt )jt jt+1 X̃t + C̃jt+1 εt+1 ,

where
                                           M (pt )jk ≡ Ãk + B̃k F (pt )j .

The value function for the original problem can be written

                                               X̃t0 V (pt )X̃t + w(pt ).

    Appendix I shows how the functions F (pt )j , V (pt ), and w(pt ) can be computed by modifying
the iterations specified in appendix B. Computing the functions F (pt )j and V (pt ) for all feasible
values of pt requires standard function-approximation methods. However, as shown in appendix B,
computing the functions for a particular value pt = p̃t is straightforward.18
   18
      Consider the degenerate distributions, pt = ej where ej is the distribution where pj = 1, pk = 0 (k 6= j). That
is, pt = ej corresponds to the case when the mode j is observed in period t. Note that V (ej ) 6= Vj and F (ej )j 6=
Fj , where Vj and Fj (j = 1, ..., n) denote the value function and optimal policy function matrices for the case when
the modes are observed in each period. The reason is that even if pt = ej and the mode is observed in this period,
the distribution of the modes in the next period will be pt+1 = ej P = (Pj1 , Pj2 , ..., Pjn ) and the modes will not be
observed in the next period. In contrast, Vj and Fj are derived under the assumption that the modes are observed
in this period as well as every future period.


                                                            28
   Consider now the optimal decision of a central bank in a given period t, with a given realization
of the predetermined variables, X̃t , and a given probability distribution of the modes, pt . The
probability distribution of the modes τ periods ahead is then given by (7.1). It follows that the
optimal policy function for period t + τ (τ ≥ 0) is time-varying and can be written

                                      it+τ = Fi,t+τ X̃t+τ                (τ ≥ 0),

where
                                                Fi,t+τ ≡ Fi (pt P τ ).

Hence, this situation is a special case of that discussed in section 5, where the policy function is time-
varying but independent of the mode. That is, the instrument rule in (5.1) satisfies FX̃,t+τ ,jt+τ ≡
Fi,t+τ and Fx,t+τ ,jt+τ ≡ 0.


7.2     Examples

In this section we reconsider the two examples from section 4 above, now under the assumption
that the modes are unobservable. We suppose that the central bank has an initial distribution over
the modes which is equal to the stationary distribution p̄. From equation (7.1), we see that the
stationary distribution is also the central bank’s distribution of the future modes. We then apply
the algorithms described in appendix I to find the optimal policies. As in the observable-mode
case, we represent the solutions via impulse responses from 10,000 simulations, drawing the initial
mode from the stationary distribution and tracing out the distribution as the modes vary (now in
an unobservable manner) over time.

        Case           πt     π t−1     π t−2       πt−3            yt        yt−1      it−1       it−2       it−3
       Constant    0.9921   0.3465    0.4273      0.1381        1.7974     −0.4639   0.3713    −0.0899    −0.0456
      Unobserved   1.1828   0.3610    0.7304      0.1861        1.9103     −1.0563   0.1538    −0.1573    −0.0758

Table 7.1: Optimal policy functions for the constant-coeﬃcient and unobserved-mode versions of
the Rudebusch-Svensson model.

   In table 7.1 we show the optimal policy functions for the constant-coeﬃcient and unobservable-
mode versions of the RS model from section 4.1 above. In figure 7.1 we plot the impulse responses.
The distributions of the impulse responses are again asymmetric, with the mean impulse responses
diﬀerent from the median ones. Compared to the observable-mode case in figure 4.2 above, we see
that the mean policy responses are longer lasting, if not noticeably more aggressive at the start.
However most of the center of the distribution is consistent with smaller responses, with the mean

                                                           29
                          Response of π to π shock
                                                                             Response of π to y shock
                 1.5                           Mean
                                                                     0.6
                                               Constant
                  1                                                  0.4
                                                                     0.2
                 0.5                                                   0
                                                                    −0.2
                  0                                                 −0.4
                   0      10      20    30      40        50            0   10       20      30     40   50
                          Response of y to π shock                           Response of y to y shock

                   0                                                  1
                −0.2                                                 0.5
                −0.4                                                  0
                −0.6                                                −0.5
                −0.8
                    0     10      20    30      40        50           0    10       20      30     40   50
                          Response of i to π shock                           Response of i to y shock
                  2                                                   2
                                                                      1
                  1
                                                                      0
                  0                                                  −1
                   0      10      20    30      40        50           0    10       20      30     40   50




Figure 7.1: Unconditional impulse responses to shocks under the optimal policy for the unobserved-
mode version of the Rudebusch-Svensson model. Solid lines: Mean responses. Dark/medium/light
grey bands: 30/60/90% probability bands. Dashed lines: Optimal responses for constant coeﬃ-
cients.

reflecting the very wide tails. Further, although the impulse-response distributions become rela-
tively concentrated around zero over time, the tails remain quite wide after the full 50 quarters
shown. Since the coeﬃcients of the mode-dependent optimal policy functions change dramati-
cally across modes, being restricted to mode-independent (although distribution-dependent) policy
functions limits the possibility to stabilize the economy and generates wider distributions.

            Case          π t−1      yt−1         yt−2             it−1        επt            εyt   Ξπ,t−1    Ξy,t−1
           Constant     0.3552     1.0714      −0.2231          0.7853      0.6975        2.2437    0.0024    0.0182
          Unobserved    1.0987     1.7439      −0.2497          0.4788      1.7987        2.1787    0.0059    0.0194

Table 7.2: Optimal policy functions of the constant-coeﬃcient and unobserved-mode versions the
Lindé model.

   In table 7.2 we show the optimal policy functions for constant-coeﬃcient and the unobservable-
mode versions of the Lindé model from section 4.2 above. In figure 7.2 we plot the impulse responses.



                                                               30
                       Response of π to π shock
                                                                        Response of π to y shock
                                             Mean
                 2                           Constant             0.2

                 1                                                0.1

                 0                                                 0
                  0    10     20      30      40        50          0   10    20      30      40   50
                       Response of y to π shock
                                                                        Response of y to y shock
                 0
                                                                  0.6
                                                                  0.4
               −0.5
                                                                  0.2
                                                                    0
                −1
                  0    10     20      30      40        50          0   10    20      30      40   50
                        Response of i to π shock                        Response of i to y shock
                 8
                 6                                                 2
                 4
                 2                                                 1
                 0                                                 0
                  0    10     20      30      40        50          0   10    20      30      40   50




Figure 7.2: Unconditional impulse responses to shocks under the optimal policy for the unobserved-
mode version of the Lindé model. Solid lines: Mean responses. Dark/medium/light grey bands:
30/60/90% probability bands. Dashed lines: Optimal responses for constant coeﬃcients.


As for the backward-looking model above, unobservability of the modes has some eﬀects on the
distribution of impulse responses in this forward-looking model. Comparing to figure 4.4 above, we
see that, although the mean and median policy responses are similar in the two cases, the tails are
wider for responses to inflation shocks, whereas they are tighter for output-gap shocks. As we have
seen above, the optimal policy in the observable-mode case reacts more strongly in some of the
modes (particularly in mode 2) and hence the diﬀerent distributions in the observable-mode case
reflects the variation in the policy across modes. In the unobservable-mode case, the optimal policy
averages across modes. This averaging leads to slower convergence of the distributions over time,
although not to the same sustained dynamics as in the backward-looking model. Apart from the
other diﬀerences across the forward and backward-looking models, it seems, also when the modes
cannot be observed, that expectations play a key role in stabilizing the economy.




                                                             31
8    Conclusions

This paper demonstrates that the Markov jump-linear-quadratic (MJLQ) framework is a very flexi-
ble and powerful tool for the analysis and determination of optimal policy under model uncertainty.
It provides a very tractable way of handling the absence of certainty equivalence that is an impor-
tant aspect of model uncertainty. Our approach builds on the control-theory literature, for instance,
Costa, Fragoso, and Marques [11], which has explored many properties of the MJLQ framework.
That literature uses recursive methods and does not consider forward-looking variables. However
the forward-looking variables characteristic of rational expectations make the models nonrecursive.
We show that the recursive saddlepoint method of Marcet and Marimon [26] can be applied to this
problem which allows us to use recursive methods, and hence to solve relatively general models.
    We show that our framework can incorporate a large variety of diﬀerent configurations of un-
certainty. We provide algorithms to derive the optimal policy and value functions. We apply the
framework to two examples: regime-switching variants of two empirical models of the US econ-
omy, the backward-looking model of Rudebusch and Svensson [30] and the forward-looking New
Keynesian model of Lindé [24]. We also show how the dynamics of the model can be specified
for arbitrary time-varying or time-invariant policy functions, including exogenous instrument paths
such as a constant instrument rate, and we discuss how to optimize over restricted instrument
rules. Finally, we show how the framework an be adapted to a situation with unobservable modes,
arguably the most realistic situation for policy. In the examples we study, we find some substantial
deviations from certainty equivalence. In some cases, we find support for the common intuition
that uncertainty should make policy more cautious, but this is not a general result. Overall, our
results illustrate the importance of considering the entire distribution of future outcomes.
    The MJLQ framework makes it possible to provide advice on optimal monetary policy for a
large variety of diﬀerent configurations of model uncertainty. The framework also makes it possible
to incorporate diﬀerent kinds of central-bank judgment–information, knowledge, and views outside
the scope of a particular model–about the kind and degree of model uncertainty. Furthermore, the
framework can incorporate the kind of central-bank judgment about additive future deviations–
add factors–that is discussed in Svensson [36] and Svensson and Tetlow [38].
    While the particular examples we study in this paper are informative, they are only a small
sample of the applications which can be analyzed with our approach. In addition to the further
examples outlined above and sketched in the paper, some natural applications would embed the



                                                 32
diﬀerent specifications of fully specified dynamic stochastic general equilibrium models as modes
in the MJLQ setting. We could thus incorporate uncertainty about the structure of the economy,
such as diﬀerent forms of price or wage setting (as discussed in Levin, Onatski, Williams, and
Williams [23]). Alternative specifications could also capture uncertainty about the low-frequency
behavior of the key driving processes, which could describe potential productivity slowdowns (as
in, for example, Kahn and Rich [20]) or moderations in overall volatility (as in McConnell and
Perez-Quiros [27] and Stock and Watson [33]). This would help address a drawback of our results
so far, that the diﬀerent modes are not readily interpretable in terms of fundamentals. Instead,
by having the modes represent diﬀerent structural models there will be natural restrictions on the
parameters and how they co-move. This would allow us to study monetary policy with unknown
and potentially time-varying structural models.
   Overall, our results point to some important changes from approaches considering additive
uncertainty. In the “mean forecast targeting” applications in Svensson [36] and Svensson and
Tetlow [38], certainty equivalence is preserved, since the uncertainty is restricted to additive future
stochastic deviations in the model’s equations. With certainty equivalence, only the means of
future variables matter for policy, and optimal policy can be derived as if there were no uncertainty
about those means. Furthermore, the optimal mean projection of future target variables and
the instrument can be calculated in one step, and those projections–including the optimal mean
instrument path– are the natural objects for policy discussion. There is no need to use recursive
methods, and there is no need to specify the optimal policy function for the policy makers (the
explicit policy function is also a high-dimensional vector that is not easy to interpret). Instead, the
policy discussion can be conducted with the help of computer-generated graphs of projections of the
target variables and the instrument under alternative assumptions, weights in the monetary-policy
loss function, and central-bank judgments.
   In the absence of certainty equivalence, mean forecast targeting is in principle no longer suf-
ficient. The whole distribution of future target variables matters for policy, and the optimal in-
strument decision should in principle take this into account. The optimal policy plan should be
chosen such that the whole distribution, rather than the mean, of the future target variables “looks
good.” The central bank should engage in “distribution forecast targeting” rather than mean fore-
cast targeting. The application of the MJLQ framework in this paper to model uncertainty and
certainty non-equivalence indicates that recursive methods and the explicit policy function are rela-
tively more useful for the derivation of the optimal policy than under certainty equivalence, perhaps


                                                  33
even necessary. Still, the resulting distributions of future target variables and instruments under
alternative assumptions can conveniently be illustrated and presented to policy makers in the form
of graphs, although graphs of distributions rather than of means.




                                                34
Appendix

A        Incorporating central-bank judgment

In order to incorporate (additive) central-bank judgment as in Svensson [36], consider the model

                               Xt+1 = A11,t+1 Xt + A12,t+1 xt + B1,t+1 it + Ct+1 zt+1 ,                     (A.1)

                       Et Ht+1 xt+1 = A21,t Xt + A22,t xt + B2,t it ,                                       (A.2)

where zt , the (additive) deviation, is a an exogenous nz × 1 vector stochastic process. Assume that
zt satisfies
                                                            T
                                                            X
                                            zt+1 = εt+1 +         εt+1,t+1−j
                                                            j=1

for given T ≥ 0, where (ε0t , εt 0 )0 ≡ (ε0t , ε0t+1,t , ..., ε0t+T,t )0 is a zero-mean i.i.d. random (T + 1)nz × 1
vector realized in the beginning of period t and called the innovation in period t. For T = 0,
zt+1 = εt+1 is a simple i.i.d. disturbance. For T > 0, the deviation is a version of a moving-average
process.
       The dynamics of the deviation can be written
                                  ∙       ¸      ∙    ¸ ∙      ¸
                                     zt+1          zt     εt+1
                                            = Az       +         ,
                                    z t+1          zt     εt+1

where z t ≡ (Et zt+1
                 0 , E z 0 , ..., E z
                      t t+2
                                          0
                                   t t+T ) can be interpreted as the central bank’s (additive) judgment

in period t and the (T + 1)nz × (T + 1)nz matrix Az is defined as
                      ⎡                                          ⎤
                           0nz ×nz        Inz      0nz ×(T −1)nz   ∙        ¸
                                                                     0 Az21
                Az ≡ ⎣ 0(T −1)nz ×nz 0(T −1)nz ×nz   I(T −1)nz ⎦ ≡            ;
                                                                     0 Az22
                           0nz ×nz      0nz ×nz    0nz ×(T −1)nz

in the second identity Az is partitioned conformably with zt and z t . Hence z t is the central bank’s
mean projection of future deviations, and εt can be interpreted as the new information the central
bank receives in period t about those future deviations.19
       It follows that the model can be written in the state-space form (2.1) and (2.2) as
                   ⎡        ⎤            ⎡     ⎤
                     Xt+1                   Xt                                  ∙      ¸
                   ⎣ zt+1 ⎦ = Â11,t+1 ⎣ zt ⎦ + Â12,t+1 xt + B̂1,t+1 it + Ĉt+1 εt+1    ,
                                                                                  εt+1
                     z t+1                  zt
                                       ⎡     ⎤
                                         Xt
                 Et Ht+1 xt+1 = Â21,t ⎣ zt ⎦ + A22,t xt + B2,t it ,
                                         zt
  19
       The graphs in Svensson [36] can be seen as impulse responses to εt .


                                                           35
where                             ⎡                         ⎤              ⎡         ⎤
                                      A11,t+1 0 Ct+1 Az21                    A21,t+1
                    Â11,t+1    ≡⎣       0    0     Az21    ⎦ , Â21,t+1 ≡ ⎣   0     ⎦,
                                         0    0     Az22                       0
                                           ⎡        ⎤           ⎡            ⎤
                                             B1,t+1                0 Ct+1
                                B̂1,t+1 ≡ ⎣    0    ⎦ , Ĉt+1 ≡ ⎣ Inz     0 ⎦,
                                               0                   0     Inz
and the new predetermined variables are (Xt0 , zt0 , z t 0 )0 .


B     An algorithm for the value function and optimal policy function

Consider the dual saddlepoint problem of (2.6) in period t, subject to (2.7), (2.8), and X̃t given.
Let us use the notation Zt = Zjt for any matrix Z that is a function of the mode jt , and let the
matrix W̃t = W̃jt be partitioned conformably with X̃t and ı̃t as
                                             ∙         ¸
                                               Qt Nt
                                       W̃t ≡             .
                                               Nt0 Rt

We use that the value function for the dual problem will be quadratic and can be written

                                                           X̃t0 Ṽt X̃t + w̃t ,

where Ṽt is a matrix and w̃t a scalar. It will satisfy the Bellman equation
                                             n                                                                           o
        X̃t0 Ṽt X̃t + w̃t = max min          X̃t0 Qt X̃t + 2X̃t0 Nt ı̃t + ı̃0t Rt ı̃t + δEt (X̃t+1
                                                                                                0
                                                                                                    Ṽt+1 X̃t+1 + w̃t+1 ) ,
                           γt    (xt ,it )

where X̃t+1 is given by (2.8) and Et refers to the expectations conditional on X̃t and jt .
    The first-order condition with respect to ı̃t is

                      X̃t0 Nt + ı̃0t Rt + δ X̃t0 Et Ã0t+1 Ṽt+1 B̃t+1 + δı̃0t Et B̃t+1
                                                                                    0
                                                                                        Ṽt+1 B̃t+1 = 0,

which can be written
                                                        Jt ı̃t + Kt X̃t = 0,

where

                                                               0
                                               Jt ≡ Rt + δEt B̃t+1 Ṽt+1 B̃t+1 ,                                              (B.1)

                                              Kt ≡ Nt0 + δEt B̃t+1
                                                               0
                                                                   Ṽt+1 Ãt+1 .                                              (B.2)

This leads to the optimal policy function

                                                             ı̃t = Ft X̃t ,                                                   (B.3)

                                                                   36
where
                                                           Ft ≡ −Jt−1 Kt .                                                  (B.4)

Furthermore, the value function satisfies

X̃t0 Ṽt X̃t ≡ X̃t0 Qt X̃t + 2X̃t0 Nt Ft X̃t + X̃t0 Ft0 Rt Ft X̃t + δ X̃t0 Et [(Ã0t+1 + Ft0 B̃t+1
                                                                                               0
                                                                                                   )Ṽt+1 (Ãt+1 + B̃t+1 Ft )]X̃t .

This implies

             Ṽt = Qt + Nt Ft + Ft0 Nt0 + Ft0 Rt Ft + δEt [(Ã0t+1 + Ft0 B̃t+1
                                                                           0
                                                                               )Ṽt+1 (Ãt+1 + B̃t+1 Ft )],

which can be simplified to the Riccati equation

                                      Ṽt = Qt + δEt Ã0t+1 Ṽt+1 Ãt+1 − Kt0 Jt−1 Kt .                                     (B.5)

Equations (B.1), (B.2), and (B.5) show how Ṽt+1 = Ṽjt+1 for jt+1 = 1, ..., n is mapped into Ṽt = Ṽjt
for jt = 1, ..., n.
       Iteration backwards of (B.4) and (B.5) from any constant positive semidefinite matrix Ṽ should
converge to stationary matrices functions Fj and Ṽj (j = 1, ..., n), where Ṽj satisfies the Riccati
equation (B.5) with (B.1) and (B.2).
       Taking account of the finite number of modes, we have

                         Fj ≡ −Jj−1 Kj
                                             n
                                             X
                         Jj ≡ Rj + δ                Pjk B̃k0 Ṽk B̃k
                                             k=1
                                             Xn
                        Kj ≡ Nj0 + δ                Pjk B̃k0 Ṽk Ãk ,
                                              k=1
                                              Xn
                         Ṽj = Qj + δ               Pjk Ã0k Ṽk Ãk − Kj0 Jj−1 Kj            (j = 1, ..., n),              (B.6)
                                              k=1

where Pjk is the transition probability from jt = j to jt+1 = k.
       The scalars w̃j solve the equations
                                                      X
                                           w̃j = δ          Pjk [tr(Ṽk C̃k C̃k0 ) + w̃k ].
                                                       k

       Thus determining the optimal policy function (B.3) reduces to solving a system of coupled
algebraic Riccati equations (B.6). In order to solve this system numerically, we adapt the algorithm
of do Val, Geromel, and Costa [14]. In a very similar problem, they show how the coupled Riccati
equations can be uncoupled for numerical solution.20
  20
     In their problem, the matrices A and B next period are known in the current period, so the averaging in the
Riccati equation is only over the Vj matrices.


                                                                  37
   The algorithm consists of the following steps:
                    p               p
  1. Define Âj =    Pjj Ãj , B̂j = Pjj B̃j and initialize Ṽj0 = 0, j = 1, . . . , n.

  2. Then at each iteration l = 0, 1, . . . , for each j define:
                                                            X
                                          Q̂j = Qj + δ             Pjk Ã0k Ṽkl Ãk
                                                            k6=j
                                                            X
                                          R̂j = Rj + δ             Pjk B̃k0 Ṽkl B̃k
                                                            k6=j
                                                            X
                                          N̂j = Nj + δ             Pjk Ã0k Ṽkl B̃k .
                                                            k6=j

     Then for each j solve the standard Riccati equation for the problem with matrices (Âj , B̂j , Q̂j ,
     R̂j , N̂j ). Note that these are uncoupled since Ṽkl is known. Call the solution Ṽjl+1 .
             Pn        l+1
  3. Check     j=1 kṼj      − Ṽjl k. If this is lower then a tolerance, stop. Otherwise, return to step 2.

   do Val, Geromel, and Costa [14] show that the sequence of matrices Ṽjl converges to the solution
of (B.6) as l → ∞. In order to understand the algorithm, recall that, in the standard linear-
quadratic regulator (LQR) problem (Anderson, Hansen, McGrattan, and Sargent [1] and Ljungqvist
and Sargent [25]), we have

                                      F    ≡ −J −1 K

                                      J    ≡ R + δB 0 V B

                                      K ≡ N 0 + δB 0 V A,

                                      V    = Q + δA0 V A − K 0 J −1 K.

If we can redefine the matrices so the equations conform to the standard case, we can use the
standard algorithm for the LQR problem to find Fj and Vj . The above definitions allow us to write

                         Fj ≡ −Jj−1 Kj ,

                         Jj ≡ R̂j + δ B̂j0 Ṽj B̂j ,

                        Kj ≡ N̂j0 + δ B̂j0 Ṽj Âj ,

                         Ṽj = Q̂j + δ Â0j Ṽj Âj − Kj0 Jj−1 Kj            (j = 1, ..., n),

so we can indeed use the standard algorithm.
   Note that the above algorithm is easily modified to solve the Lyapunov equation (2.17) for the
matrix Vj for the true value function of the original problem.

                                                       38
C      A unit discount factor

The expected discounted losses (2.3) and (2.6) are normally bounded only for δ < 1. More precisely,
wj (j = 1, ..., n) in (2.15) is normally bounded only for δ < 1. The case δ = 1 can be handled by
scaling the intertemporal loss function by 1 −δ for δ < 1 and then consider the limit when δ → 1, as
mentioned in footnote 5. That is, we can replace the intertemporal loss function in (2.3) and (2.6)
              P
              ∞                         P
                                        ∞
by Et (1 − δ)   δ τ Lt+τ and Et (1 − δ)   δ τ L̃t+τ , respectively. In particular, we can write (2.15) as
               τ =0                                τ =0

                                                                                         ∞
                                                                                         X
                                    (1 − δ)X̃t0 Vjt X̃t + δwj ≡ min Et (1 − δ)                    δ τ Lt+τ .                          (C.1)
                                                                                         τ =0

Then, Vj (j = 1, ..., n) still satisfies (2.17), whereas wj now satisfies
                                    X
                        wj (δ) =         Pjk {(1 − δ)tr[Vk (δ)C̃k C̃k0 ] + δwk (δ)}                  (j = 1, ..., n),                 (C.2)
                                     k

where our notation emphasizes that wj and Vj depend on δ.
     From (C.1), we see that
                                                       ∞
                                                       X
                                 lim min Et (1 − δ)           δ τ Lt+τ = wj (1)              (j = 1, ..., n).
                                 δ→1−
                                                       τ =0

Furthermore, from (C.2), we see that
                                                     X
                                          wj (1) =        Pjk wk (1)           (j = 1, ..., n),
                                                     k

so the vector [w1 (1), ..., wn (1)]0 is an eigenvector for the eigenvalue 1 of the transition matrix P . By
our assumptions on the Markov chain in footnote 6, the Markov chain is fully regular, so the only
such eigenvector is (1, ..., 1) (and scalar multiples thereof) (Gantmacher [16]). Therefore, wj (1) is
independent of j:
                                                 wj (1) = w              (j = 1, ..., n)

for some scalar w.
     For δ < 1, we multiply (C.2) by p̄j and sum over j. This gives
X                   XX                                                                       X                                 X
     p̄j wj (δ) =                p̄j Pjk {(1−δ)tr[Vk (δ)C̃k C̃k0 ]+δwk } = (1−δ)                   p̄k tr[Vk (δ)C̃k C̃k0 ]+δ       p̄k wk (δ).
 j                  j        k                                                                k                                k
                    P
Letting w̄(δ) ≡          j   p̄j wj (δ), we see that
                                                          X
                                                w̄(δ) =           p̄k tr[Vk (δ)C̃k C̃k0 ].
                                                              k


                                                                    39
We conclude that in the limit, when δ → 1, the expected minimum loss is given by
                                             X
                          wj (1) = w̄(1) =       p̄k tr[Vk (1)C̃k C̃k0 ]    (j = 1, ..., n)
                                             k

and is independent of X̃t and jt . Intuitively, for δ → 1, current losses become insignificant relative
to expected losses far into the future, and then the stationary distribution p̄ applies. Therefore,
the expected discounted loss becomes independent of both the current predetermined variables and
the current mode, even though the optimal policy function depends on the current mode (when the
modes are observable) or the distribution of the current modes (when the modes are unobservable,
as in section 7 and appendix I).


D     Mean square stability

Costa, Fragoso, and Marques [11, chapter 3] (CFM) provide a discussion of stability for MJLQ
systems. An appropriate concept of stability for our purpose is mean square stability, which is
defined as follows:
    Consider the system
                                                 Xt+1 = Γθt Xt ,

for t = 0, 1, ..., where Xt ∈ RnX , θt ∈ Θ ≡ {1, ..., N } is a Markov process with transition probabil-
ities Pjk = Pr{θt+1 = k | θt = j} (j, k ∈ Θ), transition matrix P = [Pjk ], and Γθ is an nX × nX
matrix that depends on θ ∈ Θ, and X0 ∈ RnX and θ0 ∈ Θ are given. The system is mean square
stable (MSS) if, for any initial X0 ∈ RnX and θ0 ∈ Θ, there exist a vector μ ∈ RnX and an nX × nX
matrix Q independent of x0 and θ0 such that ||E[Xt ] − μ|| → 0 and ||E[Xt Xt0 ] − Q|| → 0 when
t → ∞.
    CFM [11, theorem 3.9] provide six equivalent necessary and suﬃcient conditions for mean square
stability. The following necessary and suﬃcient condition is appropriate for our purpose:
    Define the matrices C and N by
                                                 C ≡ P 0 ⊗ In2 ,
                                                                 X
                                             ⎡                                                ⎤
                                                 Γ1 ⊗ Γ1             0     ···       0
                                           ⎢                               ..        ..       ⎥
                                           ⎢         0         Γ2 ⊗ Γ2        .       .       ⎥
                      N ≡ diag(Γθ ⊗ Γθ ) ≡ ⎢
                                           ⎢         ..          ..        ..
                                                                                              ⎥.
                                                                                              ⎥
                                           ⎣          .             .         .      0        ⎦
                                                     0            ···       0     ΓN ⊗ ΓN
The system above is MSS if and only if the spectral radius (the supremum of the modulus of the
eigenvalues) of the matrix CN is less than unity.

                                                          40
    Applying CFM’s definition of and conditions for mean square stability requires a simple redef-
inition of the modes in our framework. Start from the system

                                              Xt+1 = Mjt jt+1 Xt ,

where t = 0, 1, ..., Xt ∈ RnX , jt ∈ {1, ..., n}, P = [Pjk ], Pjk = Pr{jt+1 = k | jt = j}, and X0 and
j0 are given. This system diﬀers from CFM’s system in that the matrix Mjt jt+1 depends on the
realization of the modes in both period t and period t + 1.
    Define the new composite mode θt ≡ (jt , jt+1 ), which can take N = n2 values, and consider a
Markov chain for θt with transition probabilities Pθκ ≡ Pr{θt+1 = κ ≡ (k, l) | θt = θ ≡ (j, k)}. We
note that the transition probability from θt = (j, k) to θt+1 = (k, l) does not depend on j but only
on k and l. Furthermore, it is simply Pkl , so

                                   P(j,k),(k,l) = Pkl        (j, k, l = 1, ..., n).

    Thus, we can consider the new system

                                                Xt+1 = Mθt Xt ,

where θt is a Markov chain that can take n2 diﬀerent values and has a transition matrix P with the
transition probabilities Pθt θt+1 defined above. Then the results of CFM on MSS apply directly, and
we only need to define Γθ , P, C, and N using the n2 -mode composite Markov chain for θt ≡ (jt , jt+1 )
instead of just the n-mode chain for jt .


E     Alternative models with diﬀerent predetermined and forward-
      looking variables

Our MJLQ framework allows us to consider situations when the modes j = 1, ..., n correspond to
alternative structural models, including not only when some coeﬃcients are zero or nonzero but
also when a variable is predetermined in one model and forward-looking in another. This allows
us include optimal policy when it is known what structural model is true in the current period but
there is uncertainty about the true structural model in the future.21
   21
      If the current model is not observed, we would have to include Bayesian learning of the subjective probabil-
ity distribution over models and encounter problems of experimentation versus “adaptive” loss minimization [give
reference(s)].




                                                        41
   In order to see this, consider a particular simple example, when there are two modes, j = 1, 2,
with transition matrix P = [Pjk ], j, k = 1, 2. Let j = 1 corresponds to a model with an acceleration
Phillips curve (the AP model),
                                       π t+1 = π t + αyt + ε1,t+1 ,

and let j = 2 corresponds to a New Keynesian Phillips curve (the NK model),

                                       Et π t+1 = π t − κyt − ε2,t ,

where ε1t and ε2t are i.i.d. with zero means. Thus, inflation, π t+1 is predetermined in AP model and
forward-looking in the NK model. Regard the output gap, yt , as the control variable, for simplicity.
   Let π t denote actual inflation in period t, and introduce the two variables π 1t and π 2t , where π 1t
is predetermined and denotes inflation in the AP model (AP inflation) and π 2t is forward-looking
and denotes inflation in the NK model (NK inflation). Actual actual inflation then satisfies

                                       π t = θt π 1t + (1 − θt )π 2t ,

where θt = 1 in mode 1 and θt = 0 in mode 2. We thus have

                                     π 1,t+1 = π t + αyt + ε1,t+1 ,

                                    Et π t+1 = π 2t − κyt − ε2t ,                                   (E.1)

where we assume that, in the AP model, current actual inflation aﬀects future AP inflation and,
in the NK model, the expected future actual inflation aﬀects current NK inflation.
   We want to write this model as (2.1) and (2.2) by suitable definitions of Xt , xt , it , and εt , and
the matrices. The trick is to treat actual inflation, π t , as a non-predetermined variable even though
this is not the case when the AP model is true. This works, because an additional predetermined
variable identical to an existing predetermined variable can always be introduced as a trivial non-
predetermined variable by adding an equation in the block of equations for the forward-looking
variables. Suppose that the new variable, yt , is identical to an existing predetermined variable,
X1t , say. Then we can just add the equation

                                              0 = X1t − yt ,

to that block, where the left side has zero instead of a linear combination of expected future forward-
looking variables. Generally, a new variable that is a linear combination of current predetermined


                                                     42
and forward-looking variables can always be introduced as a new forward-looking variable in this
way.
    Observe that

                                Et π t+1 = Et [θt+1 π 1,t+1 + (1 − θt+1 )π 2,t+1 ]

                                           = Et θt+1 (π t + αyt ) + Et (1 − θt+1 )π 2,t+1

and use this to substitute for Et π t+1 in (E.1). Let Xt ≡ (π 1t , ε2t )0 , xt ≡ (π 2t , π t )0 , and it ≡ yt .
Then we can write the model in the form (2.1) and (2.2) as
                          ∙       ¸      ∙       ¸      ∙   ¸      ∙        ¸
                             1 0           0 0            α          ε1,t+1
                   Xt+1 =           Xt +           xt +       it +
                             0 0           0 0            0          ε2,t+1
         ∙                ¸            ∙          ¸          ∙                        ¸          ∙                    ¸
             1 − θt+1 0                    0 −1                    0    1 − Et θt+1                  − κ − αEt θt+1
    Et                        xt+1 =                  Xt +                                xt +                            it .
                0     0                    θt 0                  1 − θt     −1                             0


F        Details of the estimation

Here we lay out the details of the priors we use in our Bayesian estimation.
    For the RS model in section 4.1, we base our prior for the MJLQ case on our OLS estimates.
The priors are identical across modes. In particular, the priors for the vectors of coeﬃcients [αi ]
and [β i ] are each multivariate normal distributions, with mean given by the OLS point estimates
and a covariance matrix given by the covariance matrix of the estimates scaled up by a factor of
4. For the parameters of the transition matrix P of the Markov chain, we take independent beta
distributions (subject to the constraint that the rows sum to one). We let the diagonal elements
have mean 0.9 and standard deviation 0.08, while the oﬀ-diagonals have means 0.05 and standard
deviations 0.05. For the variances of the shocks, we assume an inverse gamma prior distribution
with two degrees of freedom.
    For the Lindé model in section 4.2, we take independent priors for the diﬀerent structural
coeﬃcients, again with the priors being identical across modes. For the coeﬃcients ω f and β f ,
we assume a beta distribution with mean 0.5 and standard deviation 0.25. The other structural
coeﬃcients have normal distributions, with γ ∼ N (0.1, 0.05), β r ∼ N (0.15, 0.075), β y ∼ N (1.5, 0.5),
ρ1 ∼ N (0.9, 0.2), ρ1 ∼ N (0.2, 0.2), γ π ∼ N (1.5, 0.5), and γ y ∼ N (0.5, 0.5). Again for the variances
of the shocks, we assume an inverse gamma prior distribution with two degrees of freedom. The
prior over the Markov chain transition matrix is the same as in the RS model.



                                                                 43
G     Details for arbitrary time-varying instrument rules

For t = 0, ..., T − 1, introduce the new (nı̃ + ni ) × 1 vector of instruments,
                                                    ∙     ¸
                                                      ı̃t
                                              ı̂t ≡         ,
                                                      ϕt

and write the model
                                      X̃t+1 = Ãjt+1 X̃t + B̂jt+1 ı̂t + C̃jt+1 εt+1 ,

where the new nX̃ × (nı̃ + ni ) matrix B̂jt+1 satisfies

                                                       £                             ¤
                                            B̂jt+1 ≡       B̃jt+1 0nX̃ ×ni               .

Partition the (nX̃ + nı̃ ) × (nX̃ + nı̃ ) matrix W̃jt conformably with X̃t and ı̃t as
                                                  ∙           ¸
                                                     Qjt Njt
                                           W̃jt =               .
                                                     Nj0t Rjt

Furthermore, write the augmented period loss as
                                  ∙      ¸0 "                                 #∙             ¸
                                    X̃t       Qjt                  N̂tjt             X̃t
                            L̂t ≡                                                                ,
                                     ı̂t      N̂tj0 t              R̂tjt              ı̂t

where the new nX̃ × (nı̃ + nx ) and (nı̃ + nx ) × (nı̃ + nx ) matrices N̂jt and R̂jt satisfy, respectively,
                         h                   i                ∙               0 /2
                                                                                     ¸
                                     0                            Rjt      −Fı̃tj
                N̂tjt ≡    Njt   −F X̃tjt
                                          /2   ,     R̂tjt ≡                     t     .
                                                                −Fı̃tjt /2 0nı̃ ×nı̃

    Then, the first-order condition for an optimum of the Bellman equation will, in the standard
way, result in a time- and mode-dependent optimal policy function

                               ı̂t = F̂tjt X̃t        (0 ≤ t ≤ T − 1, 0 ≤ jt ≤ n),

which is defined in a compact way as

                                                   F̂tjt ≡ − Jtj−1t Ktjt ,

where Jtjt and Ktjt are defined recursively from Ṽt+1,jt as
                                                                                             X
                Jtjt ≡ R̂tjt + δEt B̂j0 t+1 Ṽt+1,jt+1 B̂jt+1 = R̂tjt + δ                            Pjt k B̂k0 Ṽt+1,k B̂k ,
                                                                                             k
                                                                                             X
               Ktjt ≡     N̂tj0 t   + δEt B̂j0 t+1 Ṽt+1,jt+1 Ãjt+1   =   N̂tj0 t   +δ              Pjt k B̂k0 Ṽt+1,k Ãk .
                                                                                             k




                                                             44
Substitution of this optimal policy function in the Bellman equation results in the recursive equation
for Ṽtjt ,
                                                                              X
  Ṽtjt = Qjt + δEt Ã0jt+1 Ṽt+1,jt+1 Ãjt+1 − Ktj
                                                 0
                                                    J −1 Ktjt = Qjt + δ
                                                   t tjt
                                                                                    Pjt k Ã0k Ṽt+1,k Ãk − Ktj
                                                                                                              0
                                                                                                                  J −1 Ktjt .
                                                                                                                 t tjt
                                                                               k

     Finally, the optimal policy function F̃tjt for t = 0, ..., T − 1 can be identified by partitioning F̂tjt
conformably with ı̃t and ϕt ,                           ∙           ¸
                                                            F̃tjt
                                              F̂tjt ≡                   .
                                                            Fϕtjt


H       Details for arbitrary time-invariant instrument rules

Consider the case when the time-invariant instrument rule can be written

                                  it = FXjt Xt + Fxjt xt            (jt = 1, ..., n),                                   (H.1)

and the instrument rate hence does not respond to Ξt−1 . In that case, we can use a simpler
algorithm than letting t → − ∞ in the algorithm described in appendix G. If there is a unique
solution associated with a specified instrument rule, it will determine the forward-looking variables
as a linear function of the predetermined variables,

                                                    xt = Gjt Xt .

Given a quadratic intertemporal loss function, this will also determine a value of the loss function
of the form
                                                Xt0 Vjt Xt + wjt .

     In order to specify an algorithm for finding Gj , Vj , and wj , suppose the instrument rule can be
                                                                            (t+1)
written as (H.1). Consider period t + 1, and assume that Gjt+1 in

                                            (t+1)
                                  xt+1 = Gjt+1 Xt+1            (jt+1 = 1, ..., n),

is known in period t. This will imply

                                            (t+1)
              Et Hjt+1 xt+1 = Et Hjt+1 Gjt+1 Xt+1
                              X            (t+1)
                            =     Pjk Hk Gk      [(A11k + B1k FXj )Xt + (A12k + B1k Fxj )xt ]
                                  k
                             = (A21j + B2j FXj )Xt + (A22j + B2j Fxj )xt .



                                                         45
We can then solve for xt in period t,
                                                                     (t)
                                                       xt = Gj Xt ,

where
                           "                                                                        #−1
                 (t)
                                                        X                (t+1)
                Gj     ≡       A22j + B2j Fxj −                  Pjk Hk Gk     (A12k      + B1k Fxj )
                                                            k
                               "                                                                          #
                                X              (t+1)
                           ·           Pjk Hk Gk     (A11k           + B1k FXj ) − (A21j + B2j FXj ) .
                                   k

   It follows that, starting with a guess G0j , the iteration for l = 0, 1, ..., according to
                               "                                                                   #−1
                                                             X
                 Gl+1
                  j   =            A22j + B2j Fxj −                 Pjk Hk Glk (A12k + B1k Fxj )
                                                                k
                                   "                                                                     #
                                    X
                               ·           Pjk Hk Glk (A11k         + B1k FXj ) − (A21j + B2j FXj ) ,
                                       k

will hopefully make Glj converge to the correct Gj ,

                                                        xt = Gj Xt .                                          (H.2)

   This then implies
                                                 Xt+1 = Mjk Xt + Ck εt+1 ,

where
                               Mjk ≡ A11k + A12k Gj + B1k (FXj + Fxj Gj ).

Clearly, G ≡ {Gj } and M ≡ {Mjk } will be functions of F ≡ {(FXj , Fxj )}.
   Let the period loss function be
                                           ⎡ ∙        ¸ ⎤0                     ⎡ ∙        ¸ ⎤
                                                 Xt          ∙             ¸         Xt
                                                                    Q N
                               Lt = ⎣            xt     ⎦                      ⎣     xt     ⎦.                (H.3)
                                                                    N0 R
                                                 it                                  it

Given (H.1), (H.2), and (H.3), we can define the matrix
                               ⎡           ∙       ¸    ⎤0          ⎡   ∙     ¸    ⎤
                                                I          ∙      ¸        I
                                                             Q N ⎣
                       W̄j ≡ ⎣                 Gj       ⎦                 Gj       ⎦,
                                                             N0 R
                                   FXj         + Fxj Gj               FXj + Fxj Gj

in which case the period loss satisfies
                                                      Lt = Xt0 W̄j Xt .



                                                                 46
It follows that the value function corresponding to the intertemporal loss function
                                                          ∞
                                                          X
                                                    Et           δ τ Lt+τ
                                                          τ =0

will satisfy
                                                   X
               Xt0 Vj Xt + wj = Xt0 W̄j Xt + δ           Pjk [Xt0 Mjk
                                                                   0
                                                                      Vk Mjk Xt + tr(Vk Ck Ck0 ) + wk ].
                                                   k

   Hence, the matrix Vj will satisfy the Lyapunov equation
                                           X
                                                        0
                            Vj = W̄j + δ           Pjk Mjk Vk Mjk                (j = 1, ..., n),
                                               k

and wj will satisfy
                                    X
                           wj = δ       Pjk [tr(Vk Ck Ck0 ) + wk ]                (j = 1, ..., n).
                                    k

Note that we can, for each j, define
                                                                 X
                                                                             0
                                     Ŵj ≡ W̄j + δ                      Pjk Mjk Vk Mjk
                                                                 k6=j
                                             p
                                    M̂jj   =  δPjj Mjj ,

and then solve the more standard Lyapunov equation

                                              0
                                 Vj = Ŵj + M̂jj Vj M̂jj                    (j = 1, ..., n).

Clearly, V ≡ {Vj } will be a function of F and δ, and w ≡ {wj } will be a function of F , δ and Σ.
                                                                                          P
    Let p̄j (j = 1, ..., n) denote the stationary distribution of the states, and let V̄ ≡ j p̄j Vj and
     P
w̄ ≡ j p̄j wj denote the unconditional means of Vj and wj . We note that

                                                δ X
                                        w̄ =        p̄k tr(Vk Ck Ck0 ).
                                               1−δ
                                                           k

   Suppose that the intertemporal loss function is 1 − δ times the one above,
                                                  ∞
                                                  X
                                               Et   (1 − δ)δ τ Lt+τ ,
                                                   τ =0

and suppose that we consider the limit when δ → 1,
                                               ∞
                                               X
                                     lim Et      (1 − δ)δ τ Lt+τ = E[Lt ].
                                     δ→1
                                               τ =0




                                                               47
In that case, the intertemporal loss function is just the unconditional mean of the period loss
function, E[Lt ]. Furthermore, the unconditional mean of 1 − δ times the value function above will
be
                                                                              X
                  (1 − δ){E[Xt0 Vjt Xt ] + w̄} = (1 − δ)E[Xt0 Vt Xt ] + δ            p̄k tr(Vk Ck Ck0 ).
                                                                                 k

We see that, when δ → 1, the first term on the right side goes to zero, and we conclude that, in
the limit,
                                                 X
                                      E[Lt ] =       p̄k tr[Vk (F, 1)Ck Ck0 ],
                                                 k

where we also explicitly note that Vk depends on F and δ.
      Suppose the instrument rule is restricted to a given class F of instrument rules

                                                     F ∈ F.

The optimal instrument rule in this class, F̂ , can now be defined as
                                                     X
                                   F̂ ≡ arg min          p̄k tr[Vk (F, 1)Ck Ck0 ].
                                             F ∈F
                                                     k

It will obviously depend on Ck Ck0 , the covariance matrix of the shock Ck εt+1 . Hence, certainty
equivalence does generally not hold for optimal restricted instrument rules.


I      Details with unobservable modes

I.1     Unobservable modes and forward-looking variables

Consider the dual saddlepoint problem with X̃t given, unobservable modes, and the distribution pt
of modes in period t. For notational convenience, it is practical to change the order of variables in
the dual instrument vector, put the instrument first, and denote it by ı̂tj ,
                                                 ⎡      ⎤
                                                    it
                                          ı̂tj ≡ ⎣ xtj ⎦ .
                                                   γ tj

We note that it will only depend on pt and be independent of j, whereas xtj and γ tj will depend
on both pt and j. Instead of the dual matrix W̃j , we then define the dual matrix Ŵj accordingly
and partition it conformably with X̃t and ı̂tj as
                                               "                    #
                                                         Qj N̂j
                                            Ŵj ≡                       .
                                                         N̂j0 R̂j


                                                         48
    The value function for the dual problem will be quadratic in X̃t and can be written

                                                               X̃t0 Ṽ (pt )X̃t + w̃(pt ),

where Ṽ (pt ) is a symmetric positive semidefinite matrix and w̃(pt ) is a scalar. It will satisfy the
Bellman equation
                                                                              (                                                              )
                                           X                                      X̃t0 Qj X̃t + 2X̃t0 N̂j ı̂tj + ı̂0tj R̂j ı̂tj
    X̃t0 Ṽ (pt )X̃t   + w̃(pt ) = min                  ptj max min                     P          0                                             ,
                                      it                     γ tj   xtj           + δ k Pjk [X̃t+1,k       Ṽ (pt P )X̃t+1,k + w̃(pt P )]
                                                j

where
                                                    X̃t+1,k = Ãk X̃t + B̂k ı̂tj + C̃k εt+1

and the matrix B̂k is used instead of B̃k and has columns ordered according to ı̂tj .
    The first-order conditions with respect to it and x̃tj ≡ (x0tj , γ 0tj )0 are, respectively,
                                "                                                                                     #
                       X                                             X
                            ptj X̃t0 N̂·ij + ı̂0tj R̂·ij + δ                  Pjk (X̃t0 Ã0k + ı̂0tj B̂k0 )Ṽ (pt P )B̂·ik = 0,
                        j                                                 k
                                                X
               X̃t0 N̂·x̃j + ı̂0tj R̂·x̃j + δ            Pjk (X̃t0 Ã0k + ı̂0tj B̂k0 )Ṽ (pt P )B̂·x̃k = 0         (j = 1, ..., n),
                                                    k

where N̂j , R̂j and B̂k are partitioned conformably with it and x̃tj as
                                                     ∙                ¸
         £              ¤            £           ¤     R̂iij R̂ix̃j                                                       £                  ¤
  N̂j ≡ N̂·ij N̂·x̃j ,         R̂j ≡ R̂·ij R̂·x̃j ≡                     ,                                         B̂k ≡       B̂·ik B̂·x̃k       .
                                                       R̂x̃ij R̂x̃x̃j

We can rewrite the first-order conditions as
            "                                                                                                #
    X                                               X
               0                                            0
         ptj N̂·ij X̃t + R̂iij it + R̂ix̃j x̃tj + δ   Pjk B̂·ik Ṽ (pt P )(Ãk X̃t + B̂·ik it + B̂·x̃k x̃tj ) = 0,
           j
                                                                          k
                                                X
    0                                                          0
 N̂·x̃j Xt + R̂x̃ij it + R̂x̃x̃j x̃tj + δ                Pjk B̂·x̃k Ṽ (pt P )(Ãk X̃t + B̂·ik it + B̂·x̃k x̃tj ) = 0             (j = 1, ..., n).
                                                    k

It is then apparent that the first-order conditions can be written compactly as
                                           ⎡      ⎤
                                              it
                                           ⎢ x̃t1 ⎥
                                           ⎢      ⎥
                                    J(pt ) ⎢ . ⎥ + K(pt )X̃t = 0,                                                                                (I.1)
                                               .
                                           ⎣ . ⎦
                                             x̃tn

where                                                    ⎡                                                 ⎤
                                                             Jii (pt ) Ji1 (pt ) · · ·           Jin (pt )
                                               ⎢             J1i (pt ) J11 (pt ) 0                  0      ⎥
                                               ⎢                                                           ⎥
                                      J(pt ) ≡ ⎢                 ..               ..                       ⎥,
                                               ⎣                  .       0          .              0      ⎦
                                                             Jni (pt )    0        0             Jnn (pt )

                                                                                  49
                                              "                                               #
                                   X                         X
                                                                        0
                   Jii (pt ) ≡          ptj R̂iij + δ             Pjk B̂·ik Ṽ   (pt P )B̂·ik ,
                                   j                          k
                                       "                                                  #
                                                        X
                                                                   0
                  Jij (pt ) ≡ ptj R̂ix̃j + δ                 Pjk B̂·ik Ṽ (pt P )B̂·x̃k             (j = 1, ..., n),
                                                         k
                                                  X
                                                             0
                  Jji (pt ) ≡ R̂x̃ij + δ               Pjk B̂·x̃k Ṽ (pt P )B̂·ik         (j = 1, ..., n),
                                                   k
                                                  X
                                                             0
                  Jjj (pt ) ≡ R̂x̃x̃j + δ              Pjk B̂·x̃k Ṽ (pt P )B̂·x̃k         (j = 1, ..., n),
                                                   k
                                    ⎡ P     h         P                          i                      ⎤
                                        p     N̂ 0 +δ      P   B̂ 0 Ṽ (p P )Ã
                                         tj                 jk           t     k
                                    ⎢ j 0 ·ij P k 0 ·ik                                                 ⎥
                                    ⎢   N̂·x̃1 + δ k P1k B̂·x̃k Ṽ (pt P )Ãk                           ⎥
                           K(pt ) ≡ ⎢
                                    ⎢                   ..
                                                                                                        ⎥.
                                                                                                        ⎥
                                    ⎣                    .                                              ⎦
                                           0 +δ
                                                   P         0
                                        N̂·x̃n      k nk B̂·x̃k Ṽ (pt P )Ãk
                                                      P
    This leads to the optimal policy function
                                                                        ⎡                 ⎤
                                    ⎡             ⎤                         Fi (pt )
                                            it                      ⎢       Fx (pt )1     ⎥
                                                                    ⎢                     ⎥
                                    ⎢      x̃t1   ⎥                 ⎢       Fγ (pt )1     ⎥
                                    ⎢             ⎥                 ⎢                     ⎥
                                    ⎢        ..   ⎥ = F̌ (pt )X̃t ≡ ⎢           ..        ⎥ X̃t ,
                                    ⎣         .   ⎦                 ⎢            .        ⎥
                                                                    ⎢                     ⎥
                                           x̃tn                     ⎣ Fx (pt )n           ⎦
                                                                      Fγ (pt )n

where
                                                  F̌ (pt ) ≡ −J(pt )−1 K(pt ).

Hence, we can write
                               ⎡    ⎤ ⎡            ⎤
                                it       Fi (pt )
                      ı̂tj ≡ ⎣ xtj ⎦ = ⎣ Fx (pt )j ⎦ X̃t ≡ F̂ (pt )j X̃t                      (j = 1, ..., n).
                               γ tj      Fγ (pt )j

    Furthermore, the value function for the dual saddlepoint problem satisfies
                                (                                                                             )
                          X       X̃t0 Qj X̃t + 2X̃t0 N̂j F̂ (pt )j X̃t + X̃t0 F̂ (pt )0j R̂j F̂ (pt )j X̃t
          0                             P
        X̃t Ṽ (pt )X̃t ≡   ptj                                                                                 .
                                  + δ k Pjk X̃t0 [Ã0k + F̂ (pt )0j B̂k0 ]Ṽ (pt P )[Ãk + B̂k F̂ (pt )j ]X̃t
                           j

This implies the following Riccati equation for Ṽ (pt ):
                              (                                                                     )
                        X       Qj + N̂j F̂ (pt )j + F̂ (pt )0j N̂j0 + F̂ (pt )0j R̂j F̂ (pt )j
             Ṽ (pt ) =   ptj      P                                                                  .
                                + δ k Pjk [Ã0k + F̂ (pt )0j B̂k0 ]Ṽ (pt P )[Ãk + B̂k F̂ (pt )j ]
                           j

    In terms of our standard dual instrument                  vector, ı̃tj , the policy function is
                                  ⎡      ⎤ ⎡                            ⎤
                                    xtj                       Fx (pt )j
                           ı̃tj ≡ ⎣ it ⎦ = ⎣                   Fi (pt ) ⎦ X̃t ≡ F (pt )j X̃t .                         (I.2)
                                    γ tj                      Fγ (pt )j

                                                                  50
The value function for the original problem with X̃t given is

                                                         X̃t0 V (pt )X̃t + w(pt ),

where the matrix function V (pt ) and the scalar function w(pt ) are determined in the following way:
Note that we have                                ⎡    ⎤ ⎡             ⎤
                                                   Xt        I 0
                                                 ⎣ it ⎦ = ⎣ Fi (pt ) ⎦ X̃t ,
                                                   xt       Fx (pt )j
                                             X̃t+1 = M (pt )jk X̃t + C̃k εt+1 ,

                                                 M (pt )jk ≡ Ãk + B̂k F̂ (pt )j .

It follows that we can write the period loss as

                                                         Lt = X̃t0 W̄ (pt )j X̃t ,

where                                                    ⎡    ⎤0   ⎡           ⎤
                                                     I 0              I 0
                                      W̄ (pt )j ≡ ⎣ Fi (pt ) ⎦ Ŵj ⎣ Fi (pt ) ⎦ .                                   (I.3)
                                                    Fx (pt )j        Fx (pt )j
The matrix function V (pt ) will then satisfy the Lyapunov function
                                   "                                                 #
                            X                     X
                  V (pt ) =     ptj W̄ (pt )j + δ   Pjk M (pt )0jk V (pt P )M (pt )jk ,                             (I.4)
                                     j                             k

and the function w(pt ) will satisfy the equation22
                                            XX
                               w(pt ) = δ                 ptj Pjk [tr(V (pt P )C̃k C̃k0 ) + w(pt P )].              (I.5)
                                             j       k


I.2      An algorithm for the model with forward-looking variables

Consider an algorithm for determining F (pt )j and V (pt ) in (I.2) and (I.4), respectively, for a given
distribution of the modes in period t, pt . In order to get a starting point for the iteration, we
assume that the modes become observable T + 1 periods ahead, that is, in period t + T + 1. Hence,
from that period on, the relevant solution is given by the matrices Fj and Ṽj , where Fj is the
optimal policy function and Ṽj is the value-function matrix for the dual saddlepoint problem with
observable modes determined by the algorithm in appendix B. We consider these matrices and the
horizon T as known, and we will consider an iteration for τ = T, T − 1, ..., 0 that determines F (pt )j
  22
       Note that C̃k C̃k0 is the covariance matrix of the shocks C̃k εt+1 to X̃t+1 when jt+1 = k (k = 1, ..., n).



                                                                    51
and thereby V (pt ) as a function of T . The horizon T will then be increased until F (pt )j and V (pt )
converges.23
       Let pt+τ ,t for τ = 0, ..., T and given pt be determined by (7.1), and let Ṽ T +1 denote the mode-
dependent matrices Ṽk (k = 1, ..., n) (or any arbitrary symmetric positive semidefinite matrix).
Then, for τ = T, T − 1, ..., 0, let the mode-dependent matrix Fjτ and the mode-independent matrix
Ṽ τ be determined recursively by
                                            "                                             #
                               X                           X
                     Jiiτ ≡          pt+τ ,j R̂iij + δ                0
                                                                Pjk B̂·ik Ṽ τ +1 B̂·ik ,
                                 j                          k
                                       "                                              #
                                                       X
                    Jijτ ≡ pt+τ ,j R̂ix̃j + δ                    0
                                                           Pjk B̂·ik Ṽ τ +1 B̂·x̃k           (j = 1, ..., n),
                                                       k
                                           X
                     τ                                 0
                    Jji ≡ R̂x̃ij + δ             Pjk B̂·x̃k Ṽ τ +1 B̂·ik      (j = 1, ..., n),
                                            k
                                           X
                     τ                                 0
                    Jjj ≡ R̂x̃x̃j + δ            Pjk B̂·x̃k Ṽ τ +1 B̂·x̃k      (j = 1, ..., n),
                                             k
                                                   ⎡                               ⎤
                                                  Jiiτ Ji1   τ     · · · Jin τ
                                             ⎢ Jτ Jτ                 0      0 ⎥
                                             ⎢ 1i           11                     ⎥
                                      Jτ ≡ ⎢ .                      ..             ⎥,
                                             ⎣ ..           0          .    0 ⎦
                                                   τ
                                                  Jni       0        0 Jnn   τ

                                ⎡ P              h              P                            i ⎤
                                         p         N̂   0 +δ            P   B̂ 0 Ṽ τ +1 Ã
                                        j t+τ ,j       ·ij           k jk ·ik              k
                                ⎢                         P                                    ⎥
                                ⎢          N̂ 0 +δ             P     B̂  0 Ṽ τ +1 Ã          ⎥
                           τ
                         K ≡⎢   ⎢            ·x̃1            k   1k ·x̃k               k       ⎥,
                                                                ..                             ⎥
                                ⎣                                .                             ⎦
                                              0
                                                          P              0     τ +1
                                           N̂·x̃n + δ k Pnk B̂·x̃k Ṽ               Ãk
                                               ⎡ τ ⎤
                                                   Fi
                                               ⎢ Fx1  τ ⎥
                                               ⎢ τ ⎥
                                               ⎢ F ⎥
                                               ⎢ γ1 ⎥
                                      F̌ τ ≡ ⎢ . ⎥ = − (J τ )−1 K τ ,
                                               ⎢ .. ⎥
                                               ⎢           ⎥
                                               ⎣ Fxn  τ ⎦

                                                  Fγn τ

                                             ⎡ τ ⎤
                                                 Fi
                                     F̂jτ ≡ ⎣ Fxj  τ ⎦
                                                                   (j = 1, ..., n),
                                                   τ
                                                 Fγj
                                     (                                                                 )
                         X               Qj + N̂j F̂jτ + F̂jτ 0 N̂j0 + F̂jτ 0 R̂j F̂jτ
                      τ                      P
                    Ṽ =     pt+τ ,j                        0         τ0 0       τ +1 [Ã + B̂ F̂ τ )]   .
                         j
                                         + δ    k Pjk [Ãk + F̂j B̂k ]Ṽ                 k     k j

  23
     It is obviously not necessary to assume that the modes become observable in some future period. We could
instead let the iteration start far in the future with an arbitrary symmetric positive definite matrix instead of Ṽj .




                                                                52
      For τ = 0, ..., T , let
                                                         ⎡  ⎤0    ⎡     ⎤
                                                        I 0         I 0
                                               W̄jτ ≡ ⎣ Fiτ ⎦ Ŵj ⎣ Fiτ ⎦ ,
                                                          τ
                                                        Fxj           τ
                                                                    Fxj
                                                      τ
                                                     Mjk ≡ Ãk + B̂k F̂jτ .

Let V T +1 denote the mode-dependent value-function matrix Vj for the original problem with
forward-looking variables and observable modes. For τ = T, T −1, ..., 0 define the mode-independent
matrix V τ recursively as
                                                         "                                           #
                                        X                              X
                                Vτ =           pt+τ ,j W̄jτ + δ                     τ 0 τ +1
                                                                               Pjk Mjk V      τ
                                                                                             Mjk .
                                         j                                 k

      This procedure will give F̂j0 and V 0 as functions of T . We let T increase until F̂j0 and V 0 have
converged. Then, the optimal policy function F (pt )j and the matrix V (pt ) are given by
                                         ⎡           ⎤ ⎡ 0 ⎤
                                           Fx (pt )j        Fxj
                              F (pt )j ≡ ⎣ Fi (pt ) ⎦ = ⎣ Fi0 ⎦ ,
                                           Fγ (pt )j         0
                                                            Fγj

                                                             V (pt ) = V 0 .


I.3      Unobservable modes without forward-looking variables

When the model is backward-looking, the Bellman equation is,
                                    ½ 0              0               0
                                                                                             ¾
                                     Xt Q(p
                                         P t )X
                                             P t + 2Xt N (p t )it + it R(pt )it
       Xt0 V (pt )Xt + w(pt ) = min                       0                                    ,
                                 it  + δ j k ptj Pjk [Xt+1,k     V (pt P )Xt+1,k + w(pt P )]

where                             ∙                           ¸                                  ∙            ¸
                                      Q(pt ) N (pt )                  X               X              Qj Nj
                      W (pt ) ≡                                   ≡        ptj Wj ≡        ptj                    ,   (I.6)
                                      N(pt )0 R(pt )                                                 Nj0 Rj
                                                                       j               j

                                          Xt+1,k = Ak Xt + Bk it + Ck εt+1 .

      The first-order condition with respect to it is
                                               XX
                Xt0 N (pt ) + i0t R(pt ) + δ             ptj Pjk [Xt0 A0k V (pt P )Bk + i0t Bk0 V (pt P )Bk ] = 0
                                                j    k

and can be written
                                                    J(pt )it + K(pt )Xt = 0,                                          (I.7)

where
                                                              XX
                                  J(pt ) ≡ R(pt ) + δ                      ptj Pjk Bk0 V (pt P )Bk ,
                                                                  j    k


                                                                      53
                                                                     XX
                                   K(pt ) ≡ N (pt )0 + δ                        ptj Pjk Bk0 V (pt P )Ak ].
                                                                      j     k

This leads to the optimal policy function

                                                                 it = F (pt )Xt ,

where
                                                     F (pt ) = − J(pt )−1 K(pt ).

      This implies the following Riccati equation for V (pt ):

                V (pt ) = Q(pt ) + N (pt )F (pt ) + F (pt )0 N (pt )0 + F (pt )0 R(pt )F (pt )
                             XX
                          +δ          ptj Pjk [A0k + F (pt )0 Bk0 ]V (pt P )[Ak + Bk F (pt )]
                                         j   k
                                                 XX
                             = Q(pt ) + δ                        ptj Pjk A0k V (pt P )Ak − K(pt )0 J(pt )−1 K(pt ).
                                                     j       k

      The scalar w(pt ) solves the equation:
                                             XX
                              w(pt ) = δ                     ptj Pjk [tr(V (pt P )Ck Ck0 ) + w(pt P )].
                                                 j       k


I.4     An algorithm for the backward-looking model

For the backward-looking model, the algorithm can be written
                               "                         #
                      X                 X
             JT ≡        pt+T,j Rj + δ      Pjk Bk0 Vk Bk ,                                                                   (I.8)
                               j                                 k
                                             "                                       #
                              X                                  X
                    T
                K        ≡          pt+T,j   Nj0         +δ          Pjk Bk0 Vk Ak       ,                                    (I.9)
                               j                                 k
                                             "                                       #
                              X                                  X
                    T
                V        =          pt+T,j Qj + δ                    Pjk A0k Vk Ak       − (K T −1 )0 (J T −1 )−1 K T −1 .   (I.10)
                               j                                 k

Given this, consider the iteration for τ = T − 1, ..., 0,
                                      "                            #
                           X                  X
                   τ                                      0 τ +1
                  J ≡          pt+τ ,j Rj + δ    Pjk Bk V        Bk ,                                                        (I.11)
                                     j                               k
                                                     "                                       #
                                   X                                 X
                        Kl ≡             pt+τ ,j Nj0 + δ                  Pjk Bk0 V l+1 Ak ,                                 (I.12)
                                     j                               k
                                                     "                                       #
                                   X                                 X
                        Vl =             pt+τ ,j Qj + δ                   Pjk A0k V l+1 Ak − (K l )0 (J l )−1 K l .          (I.13)
                                     j                               k



                                                                          54
Then, T should be increased until V 0 converges. Then24

                                            V (pt ) = V 0 ,

                                            F (pt ) = − (J 0 )−1 K 0 .


J     Optimization under discretion

Here we also specify the equilibrium under discretionary optimization, that is, when the central
bank cannot commit but reoptimizes each period. Oudiz and Sachs [29] derive an algorithm for
the solution of this problem when there is no model uncertainty (and with H = I). This algorithm
is further discussed in Backus and Driﬃll [3], Currie and Levin [12], Söderlind [32], and Svensson
[37]. The algorithm is here adapted to the MJLQ framework. Blake and Zampolli [4] also provide
an algorithm for the discretion equilibrium in the MJLQ framework.
    Consider the central bank’s decision problem to choose it in period t to minimize the intertem-
poral loss function (2.3) under discretion, that is, subject to (2.1), (2.2), and Xt and jt given.25
Furthermore, the central bank anticipates that it will reoptimize in period t + 1. That reoptimiza-
tion will result in the instruments and the forward-looking variables in period t + 1 being functions
of the predetermined variables and the mode in period t + 1 according to

                                it+1 = Ft+1,jt+1 Xt+1             (jt+1 = 1, ..., n),                           (J.1)

                                xt+1 = Gt+1,jt+1 Xt+1             (jt+1 = 1, ..., n).                           (J.2)

The reoptimization will also result in value of the problem in period t + 1,

                             0
                            Xt+1 Vt+1,jt+1 Xt+1 + wt+1,jt +1          (jt+1 = 1, ..., n).

For any t, we here let Ft ≡ {Ftj }nj=1 , Gt ≡ {Gtj }nj=1 , and Vt ≡ {Vtj }nj=1 denote the set of matrices
Ftj (j = 1, ..., n), Gtj (j = 1, ..., n), and Vtj (j = 1, ..., n), respectively. We assume that the set of
matrices Ft+1 , Gt+1 , and Vt+1 in period t + 1 are known by the central bank in period t. We will see
that optimization in period t will then determine the set of matrices Ft , Gt , and Vt in period t as a
function of the set of matrices Gt+1 and Vt+1 . This specifies a mapping of (Gt+1 , Vt+1 ) to (Gt , Vt ).
  24
     A related paper is do Val and Başar [13], who consider the problem of “receding horizon control.” They introduce
a terminal payoﬀ, and at each date t they solve a finite-horizon optimization problem looking ahead T periods given
the current probability distribution. The action taken at the current date is then the first optimal choice in the
solution of the finite horizon problem. Then the distribution is updated and the problem repeats.
  25
     That is, we assume that the modes are observable. The algorithm is easily modified to the case when the modes
are unobservable.



                                                         55
We are looking for a fixed point of this mapping. We denote the fixed point by G ≡ {Gj }nj=1 and
V ≡ {Vj }nj=1 .
    First, by (J.2) and (2.1) we have,

                    Et Ht+1 xt+1 = Et Ht+1 Gt+1 Xt+1

                                   = Et Ht+1 Gt+1 (A11,t+1 Xt + A12,t+1 xt + B1,t+1 it )

                                      Pn
(where Et Ht+1 Gt+1 Xt+1 denotes         k=1 Pjt k Hk Gt+1,k Xt+1,k       conditional on a given jt = 1, ..., n and
Xt+1,k refers to the realization of Xt+1 when jt+1 = k). Combining this with (2.2) gives

             Et Ht+1 Gt+1 (A11,t+1 Xt + A12,t+1 xt + B1,t+1 it ) = A21,t Xt + A22,t xt + B2,t it .

Solving for xt gives
                                  xt = Ātjt Xt + B̄tjt it       (jt = 1, ..., n),                           (J.3)

where

                  Ātj ≡ (A22j − Et Ht+1 Gt+1 A12,t+1 )−1 (Et Ht+1 Gt+1 A11,t+1 − A21,t ),                   (J.4)

                  B̄t ≡ (A22j − Et Ht+1 Gt+1 A12,t+1 )−1 (Et Ht+1 Gt+1 B1,t+1 − B2,t )                       (J.5)

(we assume that A22,t − Et Ht+1 Gt+1 A12,t+1 is invertible). Using (J.3) in (2.1) then gives

                                   Xt+1 = Ãt+1 Xt + B̃t+1 it + Ct+1 εt+1 ,                                  (J.6)

where

                                      Ãt+1 ≡ A11,t+1 + A12,t+1 Āt ,                                        (J.7)

                                      B̃t+1 ≡ B1,t+1 + A12 t+1 B̄t .                                         (J.8)

    Third, using (J.3) in (2.4) gives
                                            ∙        ¸0 ∙            ¸∙        ¸
                                                Xt          Qt Nt         Xt
                                     Lt =                                          ,                         (J.9)
                                                it          Nt0 Rt        it

where

                           Qt ≡ WXX,t + WXx,t Āt + Ā0t WXx,t
                                                          0
                                                               + Ā0t Wxx,t Āt ,                           (J.10)

                           Nt ≡ WXx,t B̄t + Ā0t Wxx,t B̄t + WXi,t + Ā0t Wxi,t ,                           (J.11)

                           Rt ≡ Wii,t + B̄t0 Wii,t B̄t + B̄t0 Wxi,t + Wxi,t
                                                                       0
                                                                            B̄t ,                           (J.12)


                                                            56
and Wt is partitioned conformably with Xt , xt ,       and it ,
                                    ⎡                               ⎤
                                       WXX,t            WXx,t WXi,t
                              Wt ≡  ⎣  WxX,t            Wxx,t Wxi,t ⎦ .
                                       WiX,t            Wix,t Wii,t

   Fourth, the value of the problem in period t is associated with the symmetric positive semidef-
inite matrix Vt and the scalar wt , and it satisfies the Bellman equation

                            ©                                         ª
      Xt0 Vtj Xt + wtj ≡ min Ltj + δE[Xt+1
                                       0
                                           Vt+1 Xt+1 + wt+1 | jt = j]                      (j = 1, ..., n),     (J.13)
                           it


subject to (J.6) and (J.9). Indeed, the problem has been transformed to a MJLQ problem without
forward-looking variables, albeit with time-varying coeﬃcients. The first-order condition is, by
(J.9) and (J.13),

          0 = Xt0 Ntj + i0t Rtj + δE[Xt+1
                                      0
                                          Vt+1 B̃t+1 | jt = j]

             = Xt0 Ntj + i0t Rtj + δE[(Xt0 Ã0t+1 + i0t B̃t+1
                                                          0
                                                              )Vt+1 B̃t+1 | jt = j]          (j = 1, ..., n).

The first-order condition can be solved for the policy function,

                                       it = Ftjt Xt      (jt = 1, ..., n),                                      (J.14)

where
                                              Ftj ≡ − Jtj−1 Ktj ,                                               (J.15)


                                                 0
                                Jtj ≡ Rtj + δE[B̃t+1 Vt+1 B̃t+1 | jt = j],

                                Ktj ≡ Ntj0 + δE[B̃t+1
                                                  0
                                                      Vt+1 Ãt+1 | jt = j]

(we assume that Jtj is invertible). Using (J.14) in (J.3) gives

                                      xt = Gtjt Xt          (jt = 1, ..., n),

where
                                            Gtj ≡ Ātj + B̄tj Ftj .                                             (J.16)

Furthermore, using (J.14) in (J.13) and identifying terms result in

  Vtj ≡ Qtj + Ntj Ftj + Ftj0 Ntj0 + Ftj0 Rtj Ftj + δE[(Ãt+1 + B̃t+1 Ft )0 Vt+1 (Ãt+1 + B̃t+1 Ft ) | jt = j]
                                                  0 −1
        ≡ Qtj + δE[Ã0t+1 Vt+1 Ãt+1 | jt = j] − Ktj Jtj Ktj            (j = 1, ..., n).                        (J.17)


                                                       57
   Thus, the above equations (J.4), (J.5), (J.7), (J.8), (J.10)—(J.12), (J.15), (J.16), and (J.17))
define a mapping from the set of matrices (Gt+1 , Vt+1 ) to the set of matrices (Gt , Vt ). This
mapping also determines the set of matrices Ft .       The discretion equilibrium is a fixed point
(G, V ) ≡ {Gj , Vj }nj=1 of the mapping and a corresponding F ≡ {Fj }nj=1 . The fixed point can
be obtained as the limit of (Gt , Vt ) when t → − ∞.
   The details of this algorithm can be completed in the same way as for our other algorithms.
The algorithm is easily generalized to the case when the modes are not observable.




                                                58
References

 [1] Anderson, Evan W., Lars Peter Hansen, Ellen R. McGrattan, and Thomas J. Sargent (1995),
    “Mechanics of Forming and Estimating Dynamic Linear Economies,” working paper, home-
    pages.nyu.edu/~ts43/.

 [2] Aoki, Masanao (1967), Optimization of Stochastic Systems, Academic Press, New York.

 [3] Backus, David, and John Driﬃll (1986), “The Consistency of Optimal Policy in Stochastic
    Rational Expectations Models,” CEPR Discussion Paper No. 124.

 [4] Blake, Andrew P., and Fabrizio Zampolli (2005), “Time Consistent Policy in Markov Switching
    Models,” working paper, Bank of England.

 [5] Blinder, Alan S., and Ricardo Reis (2005), “Understanding the Greenspan Standard,” in The
    Greenspan Era: Lessons for the Future, a symposium sponsored by the Federal Reserve Bank
    of Kansas City, forthcoming, www.federalreserve.gov.

 [6] Brainard, W. (1967), “Uncertainty and the Eﬀectiveness of Policy,” American Economic Re-
    view 57, 411—425.

 [7] Brash, Donald T. (2000), “Making Monetary Policy: A Look Behind the Curtains,” speech in
    Christchurch, January 26, 2000, Reserve Bank of New Zealand, www.rbnz.govt.nz.

 [8] Chow, Gregory C. (1973) “Eﬀect of Uncertainty on Optimal Control Policies,” International
    Economic Review 14, 632—45.

 [9] Cogley, Timothy, Riccardo Colacito and Thomas J. Sargent (2005) “The Benefits from U.S.
    Monetary Policy Experimentation in the Days of Samuelson and Solow and Lucas,” working
    paper, NYU.

[10] Costa, Oswaldo L.V., and Marcelo D. Fragoso (1995), “Discrete-Time LQ-Optimal Control
    Problems for Infinite Markov Jump Parameter Systems,” IEEE Transactions on Automatic
    Control 40, 2076—2088.

[11] Costa, Oswaldo L.V., Marecelo D. Fragoso, and Ricardo P. Marques (2005), Discrete-Time
    Markov Jump Linear Systems, Springer, London.




                                               59
[12] Currie, David, and Paul Levine (1993), Rules, Reputation and Macroeconomic Policy Coordi-
    nation, Cambridge University Press, Cambridge.

[13] do Val, João B.R., and Tamer Başar (1999), “Receding Horizon Control of Jump Linear
    Systems and a Macroeconomic Policy Problem,” Journal of Economic Dynamics and Control
    23, 1099—1131.

[14] do Val, João B.R, José C. Geromel, and Oswaldo L.V. Costa (1998), “Uncoupled Riccati
    Iterations for the Linear Quadratic Control Problem of Discrete-Time Markov Jump Linear
    Systems,” IEEE Transactions on Automatic Control 43, 1727—1733.

[15] Feldstein, Martin (2004), “Innovations and Issues in Monetary Policy: Panel Discussion,”
    American Economic Review 94 (May) 41—43.

[16] Gantmacher, Felix R. (1959), The Theory of Matrices, Volume II, Chelsea Publishing Company,
    New York.

[17] Greenspan, Alan (2004), “Risk and Uncertainty in Monetary Policy,” American Economic
    Review 94 (May) 33—40.

[18] Greenspan, Alan (2005), “Reflections on Central Banking,” in The Greenspan Era: Lessons for
    the Future, a symposium sponsored by the Federal Reserve Bank of Kansas City, forthcoming,
    www.federalreserve.gov.

[19] Hamilton, James D. (1994), Time Series Analysis, Princeton University Press.

[20] Kahn, James A. and Robert W. Rich (2004) “Tracking the New Economy: Using Growth
    Theory to Detect Changes in Trend Productivity,” working paper, Federal Reserve Bank of
    New York.

[21] Karlin, Samuel, and Howard M. Taylor (1975), A First Course in Stochastic Processes, 2nd
    edition, Academic Press, San Diego, CA.

[22] Kim, Chang-Jin and Charles R. Nelson (1999), State-Space Models with Regime Switching,
    MIT Press, Cambridge, MA.

[23] Levin, Andrew T., Alexei Onatski, John C. Williams, and Noah Williams (2005), “Monetary
    Policy Under Uncertainty in Micro-Founded Macroeconometric Models,” working paper for
    the 2005 NBER Macroeconomics Annual.

                                              60
[24] Lindé, Jesper (2002), “Estimating New-Keynesian Phillips Curves:          A Full Informa-
    tion Maximum Likelihood Approach,” Sveriges Riksbank Working Paper Series No. 129,
    www.riksbank.se.

[25] Ljungqvist, Lars, and Thomas J. Sargent (2005), Recursive Macroeconomic Theory, 2nd edi-
    tion, MIT Press, Cambridge, MA.

[26] Marcet, Albert, and Ramon Marimon (1998), “Recursive Contracts,” working paper,
    www.econ.upf.edu.

[27] McConnell, Margaret M. and Gabriel Perez-Quiros (2000) “Output Fluctuations in the United
    States: What Has Changed since the Early 1980’s?”, American Economic Review 90, 1464—76.

[28] Onatski, Alexei, and Noah Williams (2003), “Modeling Model Uncertainty,” Journal of the
    European Economic Association 1, 1087—1022.

[29] Oudiz, Gilles, and Jeﬀrey Sachs (1985), “International Policy Coordination in Dynamic Macro-
    economic Models,” in William H. Buiter and Richard C. Marston, eds., International Economic
    Policy Coordination, Cambridge University Press, Cambridge.

[30] Rudebusch, Glenn D., and Lars E.O. Svensson (1999), “Policy Rules for Inflation Targeting,”
    in John B. Taylor (ed.), Monetary Policy Rules, University of Chicago Press.

[31] Sims, Christopher A. (2002), “The Role of Models and Probabilities in the Monetary Policy
    Process,” Brookings Papers on Economic Activity 2:2002, 1—62.

[32] Söderlind, Paul (1999), “Solution and Estimation of RE Macromodels with Optimal Policy,”
    European Economic Review 43, 813—823.

[33] Stock, James H. and Mark W. Watson (2002) “Has the Business Cycle Changed and Why?”
    in Mark Gertler and Ken Rogoﬀ, eds., NBER Macroeconomics Annual 2002, MIT Press,
    Cambridge.

[34] Svensson, Lars E.O. (2001a), Independent Review of the Operation of Monetary Policy in New
    Zealand: Report to the Minister of Finance, www.princeton.edu/∼svensson.

[35] Svensson, Lars E.O. (2001b), “Price Stability as a Target for Monetary Policy: Defining
    and Maintaining Price Stability,” in Deutsche Bundesbank, ed., The Monetary Transmis-


                                               61
    sion Process: Recent Developments and Lessons for Europe, Palgrave, New York, 60—102,
    www.princeton.edu/∼svensson.

[36] Svensson, Lars E.O. (2005a), “Monetary Policy with Judgment: Forecast Targeting,” Inter-
    national Journal of Central Banking 1, 1—54, www.ijcb.org.

[37] Svensson, Lars E.O. (2005b), “Optimization under Commitment and Discretion, the Re-
    cursive Saddlepoint Method, and Targeting Rules and Instrument Rules: Lecture Notes,”
    www.princeton.edu/∼svensson.

[38] Svensson, Lars E.O., and Robert J. Tetlow (2005), “Optimal Policy Projections,” International
    Journal of Central Banking, forthoming, www.princeton.edu/∼svensson.

[39] Svensson, Lars E.O., and Michael Woodford (2005), “Implementing Optimal Policy through
    Inflation-Forecast Targeting,” in Bernanke, Ben S., and Michael Woodford, eds., Inflation
    Targeting, University of Chicago Press, www.princeton.edu/∼svensson.

[40] Woodford, Michael (2003), Interest and Prices: Foundations of a Theory of Monetary Policy,
    Princeton University Press.

[41] Zampolli, Fabrizio (2005), “Optimal Monetary Policy in a Regime-Switching Economy: The
    Response to Abrupt Shifts in Exchange-Rate Dynamics,” working paper, Bank of England.




                                               62
