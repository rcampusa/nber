                               NBER WORKING PAPER SERIES




         READING THE RECENT MONETARY HISTORY OF THE U.S., 1959-2007

                                    Jesús Fernández-Villaverde
                                    Pablo A. Guerrón-Quintana
                                       Juan Rubio-Ramírez

                                       Working Paper 15929
                               http://www.nber.org/papers/w15929


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                      April 2010




We thank André Kurmann, Jim Nason, Frank Schorfheide, Tao Zha, and participants at several seminars
for useful comments, and Béla Személy for invaluable research assistance. Beyond the usual disclaimer,
we must note that any views expressed herein are those of the authors and not necessarily those of
the Federal Reserve Bank of Atlanta, the Federal Reserve Bank of Philadelphia, or the Federal Reserve
System. Finally, we also thank the NSF for financial support. The views expressed herein are those
of the authors and do not necessarily reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2010 by Jesús Fernández-Villaverde, Pablo A. Guerrón-Quintana, and Juan Rubio-Ramírez. All
rights reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit
permission provided that full credit, including © notice, is given to the source.
Reading the Recent Monetary History of the U.S., 1959-2007
Jesús Fernández-Villaverde, Pablo A. Guerrón-Quintana, and Juan Rubio-Ramírez
NBER Working Paper No. 15929
April 2010
JEL No. C11,E10,E30

                                              ABSTRACT

In this paper we report the results of the estimation of a rich dynamic stochastic general equilibrium
(DSGE) model of the U.S. economy with both stochastic volatility and parameter drifting in the Taylor
rule. We use the results of this estimation to examine the recent monetary history of the U.S. and to
interpret, through this lens, the sources of the rise and fall of the great American inflation from the
late 1960s to the early 1980s and of the great moderation of business cycle fluctuations between 1984
and 2007. Our main findings are that while there is strong evidence of changes in monetary policy
during Volcker's tenure at the Fed, those changes contributed little to the great moderation. Instead,
changes in the volatility of structural shocks account for most of it. Also, while we find that monetary
policy was different under Volcker, we do not find much evidence of a big difference in monetary
policy among Burns, Miller, and Greenspan. The difference in aggregate outcomes across these periods
is attributed to the time-varying volatility of shocks. The history for inflation is more nuanced, as a
more vigorous stand against it would have reduced inflation in the 1970s, but not completely eliminated
it. In addition, we find that volatile shocks (especially those related to aggregate demand) were important
contributors to the great American inflation.


Jesús Fernández-Villaverde                           Juan Rubio-Ramírez
University of Pennsylvania                           Duke University
160 McNeil Building                                  P.O. Box 90097
3718 Locust Walk                                     Durham, NC 27708
Philadelphia, PA 19104                               juan.rubio-ramirez@duke.edu
and NBER
jesusfv@econ.upenn.edu

Pablo A. Guerrón-Quintana
Federal Reserve Bank of Philadelphia
pablo.guerron@phil.frb.org
1. Introduction

Uncovering monetary policy is hard. While the instruments of policy, such as the federal
funds rate or reserve requirements, are directly observed, the process that led to their choice
is not. Instead, we have the documentary record of the minutes of di¤erent meetings, the
memoirs of participants in the process, and internal memos circulated inside the Federal
Reserve System.
       Although this paper trail is valuable, it is not and cannot be a complete record of the
policy process. First and foremost, documents are not a perfect photograph of reality. For
example, participants at FOMC meetings do not say or vote what they really would like to
say or vote, but what they think is appropriate at the moment given their objectives and their
assessment of the strategic interactions among the members of the committee (the literatures
on cheap talk and on strategic voting are precisely based on those insights). Also, memoirs are
often incomplete or faulty and sta¤ memos are the product of negotiations and compromises
among several actors. Second, even the most complete documentary evidence cannot capture
the full richness of a policy decision process in a modern society. Even if it could, it would
probably be impossible for any economist or historian to digest the whole archival record.1
Third, even if we could forget for a minute about the limits of the documents, we would
face the fact that actual decisions tell us only about what was done, but say little about
what would have been done in other circumstances. And while the absence of an explicit
counterfactual may be a minor problem for historians, it is a deep ‡aw for economists who
are interested in evaluating whole policy rules and on making recommendations regarding
the response to future events that may be very di¤erent from past experiences.
       Therefore, in this paper we investigate the history of monetary policy in the U.S. from
1959 to 2007 from a di¤erent perspective. We will build and estimate a rich dynamic stochastic
general equilibrium (DSGE) model of the U.S. economy with both stochastic volatility and
parameter drifting in the Taylor rule that determines monetary policy. Then, we will use the
results of our estimation to examine, through the lens of the model, the recent monetary policy
history of the U.S. Most of our attention will be focused on understanding two fundamental
observations: the rise and fall of the great in‡ation from the late 1960s to the early 1980s, the
only signi…cant peacetime in‡ation in U.S. history, and the great moderation of business cycle

   1
    For instance, Allan Meltzer, in his monumental “A History of the Federal Reserve,” uses the summaries
of the minutes of FOMC meetings compiled by nine research assistants (page X, volume 2, book 1). This
shows how even a several-decades-long commitment to getting acquainted with the archives is not enough to
process all the relevant information. Instead, it is necessary to rely on summaries, with all the potential biases
and distortions that they might bring. This is, of course, not a criticism of Meltzer: he just proceeded, as
many other great historians do, by standing on the shoulders of others. Otherwise, modern archival research
would be plainly impossible.


                                                        3
‡uctuations that the U.S. economy experienced between 1984 and 2007, as documented by
Kim and Nelson (1998), McConnell and Pérez-Quirós (2000), and Stock and Watson (2002).
   All the di¤erent elements in our exercise are necessary. We need a DSGE model because
we are interested in counterfactuals. Thus, we require a model that is structural in the sense
of Hurwicz (1962), that is, invariant to interventions such as the ones that we consider. We
need a model with stochastic volatility because, otherwise, any changes in the variance of
aggregate variables would be interpreted as the consequence of variations in monetary policy.
The evidence in Sims and Zha (2006), Fernández-Villaverde and Rubio-Ramírez (2007), and
Justiniano and Primiceri (2008) points out that these changes in volatility are …rst-order
considerations when we explore the data. We need a model with parameter drifting in the
monetary policy rule because we want to introduce changes in policy that obey a fully speci…ed
probability distribution, and not a “once and for all” change around 1979-1980, as is often
postulated in the literature (for example, in Clarida, Galí, and Gertler, 2000, or Lubick and
Schorfheide, 2004).
   Besides using our estimation to interpret the recent monetary policy history of the U.S.,
we will follow Sims and Zha’s (2006) call to connect estimated changes to historical events
(we are also inspired by Cogley and Sargent, 2002 and 2005). In particular, we will discuss
how our estimation results relate both to the observations about the economy (for instance,
how is our model interpreting the e¤ects of oil shocks?) and to the written record.
   Our main …ndings are that, while there is strong evidence of changes in monetary policy
during Volcker’s tenure at the Fed, those changes contributed little to the great moderation.
Instead, changes in the volatility of structural shocks account for most of it. Also, while we
…nd that monetary policy was di¤erent under Volcker, there is no much evidence of a di¤erence
in monetary policy among Burns, Miller, and Greenspan. The reduction in the volatility of
aggregate variables after 1984 is attributed to the time-varying volatility of shocks. The
history for in‡ation is more subtle. According to our estimated model, a more aggressive
stance of monetary policy would have reduced in‡ation in the 1970s, but not completely
eliminated it. In addition, we …nd that volatile shocks (especially those related to aggregate
demand) were important contributors of the great American in‡ation.
   Most of the material in this paper is based on a much more extensive and detailed
work, Fernández-Villaverde, Guerrón-Quintana, and Rubio-Ramírez (2010), FGR hereafter,
in which we present the DSGE model in all of its detail, we characterize the decision rules
of the agents, we build the likelihood function, and we estimate the model. Here, we will
concentrate instead on understanding recent U.S. monetary history through the lens of our
theory. Let us start, then, by introducing our model.



                                              4
2. A DSGE Model of the U.S. Economy with Stochastic Volatility
   and Parameter Drifting

As we argued in the introduction, we need a structural equilibrium model of the economy to
evaluate the importance of each of the di¤erent mechanisms behind the evolution of in‡ation
and aggregate volatility in the U.S. over the past several decades.
   However, while the previous statement is transparent, it is much less clear how to decide
which particular elements of the model we wish to include. On the one hand, we want a
model that is su¢ ciently detailed to account for the dynamics of the data reasonably well.
But this goal con‡icts with the objective of having a parsimonious and soundly microfounded
description of the aggregate economy.
   Given our investigation, a default choice for a model is a standard DSGE economy with
nominal rigidities, such as the ones in Christiano, Eichenbaum, and Evans (2005) or Smets and
Wouters (2003). This class of models is currently being used to inform policy in many central
banks, and it is a framework that has proven to be successful at capturing the dynamics
of the data. But we will not limit ourselves to using a standard DSGE model. Instead,
we will extend it in what we think are important and promising directions by incorporating
stochastic volatility into the structural shocks and parameter drifting in the Taylor rule that
governs monetary policy.
   Unfortunately, for our purposes, the model has two weak points that we must recognize
before proceeding further: money and Calvo pricing. Most DSGE models introduce a de-
mand for money through money in the utility function (MIA) or cash in advance (CIA). By
doing so, we endow money with a special function without a sound justi…cation. This hides
inconsistencies that are di¢ cult to reconcile with standard economic theory (Wallace, 2001).
Moreover, the relation between structures where money is essential and the reduced forms
embodied by MIA or CIA is not clear. This means that we do not know whether that relation
is invariant to changes in monetary policy or to the stochastic properties of the shocks that
hit the economy such as the ones we study. This is nothing more than the Lucas critique
dressed in a di¤erent way.
   The second weakness is Calvo pricing. Probably the best way to think about Calvo pricing
is as a convenient reduced form of a more complicated pricing mechanism that is easier to
handle, thanks to its memoriless properties. However, if we are entertaining the idea that
monetary policy or the volatility of shocks has changed over time, it is exceedingly di¢ cult
to believe that the parameters that control Calvo pricing have been invariant over the same
period (see the empirical evidence that backs up this argument in Fernández-Villaverde and
Rubio-Ramírez, 2008).


                                              5
   However, getting around these two limitations seems, at the moment, infeasible. Micro-
founded models of money are either too di¢ cult to work with (Kiyotaki and Wright, 1989),
rest in assumptions nearly as implausible as MIA (Lagos and Wright, 2005), or that the data
…nd too stringent (Aruoba and Schorfheide, 2010). State-dependent models of pricing are
too cumbersome computationally for estimation (Dotsey, King, and Wolman, 1999).
   So, with a certain reluctance, we will use a mainstream DSGE model with households,
…rms (a “labor packer,”a …nal good producer, and a continuum of intermediate good produc-
ers), a monetary authority, the Federal Reserve, which implements monetary policy through
open market operations following a Taylor rule; and nominal rigidities in the form of Calvo
pricing with partial indexation.

2.1. Households

We begin our discussion of the model with households. We will work with a continuum of
them, indexed by j. Households are di¤erent because each supplies a speci…c type of labor
in the market: some households are carpenters and some households are economists. If,
in addition, each household has some market power over its own wage and it stands ready
to supply any amount of labor at posted prices, it is relatively easy to introduce nominal
rigidities in wages. Some households will be able to change their wages, and some will not,
and the relative demand for each type of labor will adjust to compensate for those di¤erences
in input prices.
   At the same time, we do not want to have a complicated model with heterogeneous
agents that is daunting to compute. We resort to two “tricks” to get around that problem.
First, we have a utility function that is separable between consumption, cjt , real money
balances, mjt =pt ; and hours worked, ljt . Second, we will have complete markets in Arrow
securities. Complete markets allow us to equate the marginal utilities of consumption across
all households in all states of nature. And, since by separability this marginal utility depends
only on consumption, all households will consume the same amount of the …nal good. The
result makes aggregation trivial. Of course, it also has the unpleasant feature that those
households that do not update their wages will work di¤erent hours than those who do. If,
for example, we have an increase in the average wage, those households stuck with the old,
lower wages will work longer hours and will have lower total utility. This is the price we need
to pay for tractability.
   Given our previous choice of a separable utility function and our desire to have a balanced
growth path for the economy (which requires a marginal rate of substitution between labor




                                               6
and consumption that is linear in consumption), we postulate a utility function of the form:
                                              (                                                                    )
                             X
                             1
                                                                                            mjt
                                                                                                             1+#
                                                                                                            ljt
                                     t
                      E0                 dt   log (cjt         hcjt 1 ) + log                          't              ;                 (1)
                             t=0
                                                                                            pt              1+#

where E0 is the conditional expectation operator,                                   is the discount factor for one quarter (the
time period for our model), h controls habit persistence, and # is the inverse of the Frisch
labor supply elasticity. In addition, we introduce two shifters to preferences, common to all
households. First, a shifter to intertemporal preference dt that makes utility today more or
less desirable. This is a simple device to capture shocks to aggregate demand. A prototypical
example could be increases in aggregate demand caused by …scal policy, a whole aspect of
reality that we ignore in the model. Other possibility is to think about dt as the consequence
of demographic shocks that propagate over time. Second, we will have a shifter to labor
supply, 't . As emphasized by Hall (1997), this shock is crucial to capture the ‡uctuation of
hours in the data.
   A simple way to parameterize the evolution of the two shifters is to assume AR(1)
processes:
                                   log dt =       d   log dt     1   +    dt "dt   where "dt          N (0; 1);

and:
                               log 't =           '   log 't     1   +    't "'t   where "'t          N (0; 1):

The most interesting feature of these processes is that the standard deviations,                                           dt   and   't ,   of
the innovations, "dt and "'t , evolve over time. This is the …rst place where we will introduce
time-varying volatility in the model: sometimes the preference shifters are highly volatility,
sometimes they are less so. This changing volatility may re‡ect, for instance, the di¤erent
regimes of …scal policy or the consequences of demographic forces (Jaimovich and Siu, 2009).
   We can specify many di¤erent processes for                                      dt   and    't .   A simple procedure will be to
assume that      dt     and        't    follow a Markov chain and take a …nite number of values. While
this speci…cation seems straightforward, it is actually quite involved. The distribution that
it implies for     dt   and         't    is discrete and, therefore, perturbation methods (such as the ones
that we will use later on) are ill-designed to deal with it. This would force us to rely on global
solution methods that are too slow for estimation.
   Instead, we can postulate simple AR(1) processes in logs (to ensure the positivity of the
standard deviations):

             log        dt   = 1              d
                                                  log    d   +       d
                                                                         log   dt 1     +   d udt   where udt     N (0; 1)



                                                                           7
and
             log   't   = 1         '
                                        log   '   +     '
                                                            log     't 1   +   ' u't     where u't         N (0; 1):

This speci…cation is both parsimonious (with only four new parameters,                                      d
                                                                                                                ,   '
                                                                                                                        ,    d,   and   ')
and rather ‡exible. Because of these advantages, we will impose the same speci…cation for
the other three time-varying standard deviations in the model that will appear below (the
ones a¤ecting an investment-speci…c technological shock, a neutral technology shock, and a
monetary policy shock). Also, here and in the rest of the paper, agents perfectly observe the
structural shocks, and the level and innovation to the standard deviations and have rational
expectations about their stochastic properties.
   Households keep a rich portfolio: they own (physical) capital kjt , nominal government
bonds bjt that pay a gross return Rt 1 , Arrow securities ajt+1 ; which pay one unit of con-
sumption in event ! jt+1;t , traded at time t at unitary price qjt+1;t , and cash.
   The evolution of capital deserves some description. Given a depreciation rate , the
amount of capital owned by household j at the end of period t is

                                                                                xjt
                               kjt = (1       ) kjt    1    +   t    1     V                xjt :
                                                                               xjt 1

Investment, xjt , gets multiplied by a term that depends on a quadratic adjustment cost
function
                                                                                     2
                                               xt                    xt
                                        V          =                            x
                                              xt 1   2              xt 1
written in deviations with respect to the balanced growth rate of investment,                                               x,   with ad-
justment parameter , and an investment-speci…c technology level                                     t.   This technology level
evolves as a random walk in logs:

                         log    t   =     + log       t 1   +       t" t   where "      t   N (0; 1)

with drift         and innovation " t , whose standard deviation                             t   evolves according to our
favorite autoregressive process:

             log    t   = 1             log       +         log      t 1   +    u   t    where u     t     N (0; 1):

We introduce this shock convinced by the evidence in Greenwood, Herkowitz, and Krusell
(1997) that this is a key mechanism to understanding aggregate ‡uctuations in the U.S. over
the last 50 years.




                                                                8
    Thus, the j          th household’s budget constraint is:
                                                                                Z
                                          mjt bjt+1
                              cjt + xjt +    +      +                                 qjt+1;t ajt+1 d! jt+1;t
                                          pt   pt
                                           1                                    mjt        1              bjt
                 = wjt ljt + rt ujt    t        [ujt ] kjt          1       +                  + Rt   1       + ajt + Tt + zt
                                                                                 pt                       pt

where wjt is the real wage, rt the real rental price of capital, ujt > 0 the rate of use of
                 1
capital,     t       [ujt ] is the cost of using capital at rate ujt in terms of the …nal good,                                             t   is an
investment-speci…c technology level, Tt is a lump-sum transfer, and zt is the pro…ts of the
…rms in the economy. We postulate a simple quadratic form for                                                     [ ]:

                                                                                       2
                                           [u] =       1   (u           1) +               (u       1)2
                                                                                      2

and normalize u, the utilization rate in the balanced growth path of the economy, to 1. This
                                                                                                                    0
imposes the restriction that the parameter                              1   must satisfy                  1   =          [1] = re, where re is the
balanced growth path rental price of capital (rescaled by technological progress, as we will
explain later).
    Of all the choice variables of the households, the only one that requires special attention is
hours. As we explained above, each household j supplies their own speci…c type of labor. This
labor is aggregated by a “labor packer” into homogenous labor ltd according to a constant-
elasticity of substitution technology
                                                            Z       1           1              1

                                                ltd   =                 ljt dj
                                                                0


The “labor packer” is perfectly competitive and takes all the individual wages wjt and the
wage wt for ltd as given.
    The household decides, given the demand function for its type of labor generated by the
“labor packer,”
                                                           wjt
                                               ljt =                            ltd            8j
                                                           wt
which wage maximizes its utility and stands ready to supply any amount of labor at that
wage. However, when it chooses the wage, the household is subject to a nominal rigidity: a
Calvo pricing mechanism with partial indexation. At the start of every quarter, a fraction
1    w     of households are randomly selected and allowed to reoptimize their wages. All the
rest can only index their wages given past in‡ation with an indexation parameter                                                       w   2 [0; 1].




                                                                        9
2.2. Firms

Besides the “labor packer,”we have two other types of …rms in this economy. First, the …nal
good producer, a perfectly competitive …rm that just aggregates a continuum of intermediate
goods with the technology:
                                                               Z     1    " 1
                                                                                            "
                                                                                           " 1

                                                 ytd   =                 yit di
                                                                           "
                                                                                                                               (2)
                                                                 0

This …rm takes as given all intermediate goods prices pti and the …nal good price pt and
generates a demand function for each intermediate good:
                                                                          "
                                                               pit
                                                yit =                         ytd           8i                                 (3)
                                                               pt

     Second, we have the intermediate good producers. Each of these has access to a Cobb-
Douglas production function:
                                                                                       1
                                                  yit = At kit            1     litd

where kit    1   is the capital and litd is the “packed”labor rented by the …rm, and At (our fourth
structural shock) is the neutral productivity level, which evolves as a random walk in logs:

                            log At =   A   + log At        1   +         At "At        where "At       N (0; 1):

with drift       A   and innovation "At . We keep the same speci…cation for the standard deviation
of this innovation as we did for all previous volatilities:

             log      At   = 1     A
                                       log      A   +      A
                                                                log       At 1         +    A uAt   where uAt      N (0; 1):

     The quantity sold of the good is determined by the demand function (3). Given (3), the
intermediate good producers set prices to maximize pro…ts. As was the case for households,
intermediate good producers are subject to a nominal rigidity in the form of Calvo pricing. In
each quarter, a proportion 1               p   of them can reoptimize their prices. The remaining fraction
 p   indexes their prices by a fraction                 2 [0; 1] of past in‡ation.

2.3. The Policy Rule of the Federal Reserve

In our model, the Federal Reserve implements monetary policy through open market opera-
tions (that generate lump-sum transfers Tt to keep a balanced budget). In doing so, the Fed
follows a modi…ed Taylor rule that targets the ratio of nominal gross return Rt of government




                                                                     10
bonds over the balanced growth path gross return R:

                                                                                                yt
                                                                                                              !    y;t
                                                                                                                         !1   R
                            Rt            Rt 1           R
                                                                       t
                                                                                   ;t
                                                                                               yt    1
                               =                                                                                                  t:
                            R              R                                              exp (          y)


This rule depends on (1) the past Rt 1 , which smooths changes over time; (2) the “in‡ation
gap,”      t=    , where      is the balanced growth path of in‡ation;2 (3) the “growth gap”: the
ratio between the growth rate of the economy yt =yt 1 and                                                     y,   the balanced path gross growth
rate of yt , dictated by the drifts of neutral and investment-speci…c technological change; and
                                                                 m;t "mt
(4) a monetary policy shock                    t   = exp                   , with an innovation "mt                               N (0; 1) and standard
deviation of the innovation,                   m;t ,   that evolves as:

                            log      mt   = 1                    m
                                                                     log    m      +       m
                                                                                               log        mt 1      +     m um;t :


Note that, since we are dealing with a general equilibrium model, once the Fed has chosen a
value of        , R is not a free target, as it is determined by technology, preferences, and                                                         .
       We introduce monetary policy changes through a parameter drift over the responses of
Rt to the in‡ation,           ;t ,   and growth gaps,                      y;t :


                 log    t   = 1                    log           +         log           t 1   +         "    t    where "    t        N (0; 1)

and
                 log   yt   = 1            y
                                                   log       y   +     y
                                                                           log          yt 1   +     y "yt        where "yt          N (0; 1):

In preliminary estimations, we discovered that, while other parameters, such as                                                              R,   could also
be changing, the likelihood of the model did not seem to care much about that possibility,
and thus, we eliminated those channels.
       Our parameter drifting speci…cation tries to capture mainly two di¤erent phenomena.
First, changes in the composition of the voting members of the FOMC (through changes in
governors and in the rotating votes of presidents of regional reserve banks) may a¤ect how
strongly the FOMC responds to in‡ation and output growth because of variations in the

   2
    Here we are being careful with our words:       is in‡ation in the balanced growth path, not the target of
in‡ation in the stochastic steady state. As we will see below, we solve the model using a second-order approx-
imation. The second-order terms move the mean of the ergodic distribution of in‡ation, which corresponds in
our view to the usual view of the in‡ation target, away from the balanced growth path level. We could have
expressed the policy rule in terms of this mean of the ergodic distribution, but it would amount to solving a
complicated …xed-point problem (for every in‡ation level, we would need to solve the model and check that
indeed this is the mean of the ergodic distribution), which is too complicated a task for the potential bene…ts
we can get out of it.



                                                                            11
political-economic equilibrium in the committee.3 Similarly, changes in sta¤ may have e¤ects
as long as their views have an impact on the voting members through brie…ngs and other,
less structured interactions. This may have been particularly true in the late 1960s, when
a majority of sta¤ economists embraced Keynesian policies and the MPS model was built.4
The second phenomenon is the observation that, even if we keep constant the members of the
FOMC, their reading of the priorities and capabilities of monetary policy may evolve (or be
more or less in‡uenced by the general political climate of the nation). Below, we will argue
that this is a good description of Martin, who changed his beliefs about how strongly the Fed
could …ght in‡ation in the late 1960s, or Greenspan’s growing conviction in the mid 1990s
that the long-run growth rate of the U.S. economy had risen.
       While this second channel seems well described by a continuous drift in the parameters
(beliefs plausibly evolving slowly), changes in the voting members, in particular the chair-
man, might potentially be better understood as discrete jumps in                   ;t   and   y;t .   In fact, our
smoothed path of        ;t ,   which we will estimate from the data, gives some support to this
view. But, in addition to our pragmatic consideration that computing models with discrete
jumps is hard, we will argue in Section 6 that, historically, changes have occurred more slowly
and even new chairmen have required some time before taking a decisive lead 0n the FOMC
(Goodfriend and King, 2007).
       In Section 7, we will talk about other objections to our form of parameter drifting, in
particular to the assumption that agents observe the changes in parameters without problem,
its exogeneity, or its avoidance of open-economy considerations.

2.4. Aggregation and Equilibrium

The model is closed by …nding an expression for aggregate demand

                                      ytd = ct + xt +       t
                                                                1
                                                                    [ut ] kt   1


and another for aggregate supply:

                                              1                            1
                                      yts =       At (ut kt 1 )      ltd
                                              vtp

   3
     According to Walter Heller, president Kennedy clearly stated, “About the only power I have over the
Federal Reserve is the power of appointment, and I want to use it” (cited by Bremner, 2004, page 160). The
slowly changing composition of the Board of Governors may lead to situations, such as the one in February
1986 that we will discuss below, when Volcker was outvoted by Reagan’s appointees on the Board.
   4
     The MPS (MIT-Penn-Federal Reserve System) model is the high-water mark of traditional Keynesian
macroeconometric models in the Cowles tradition. The MPS model was operationally employed by sta¤
economists at the Fed from the early 1970s to the mid 1990s (see Brayton et al., 1997).


                                                       12
where:                                                            Z       1
                                                       1
                                               ltd   = w                      ljt dj
                                                      vt              0

is demanded labor,
                                                     Z    1
                                                                  wjt
                                         vtw    =                                      dj
                                                      0           wt
is the aggregate loss of labor input induced by wage dispersion and
                                                     Z       1                    "
                                                                  pit
                                          vtp   =                                      di
                                                         0        pt

the aggregate loss of e¢ ciency induced by price dispersion of the intermediate goods. By
market clearing, yt = ytd = yts :
   The de…nition of equilibrium for this model is rather standard and it is just the path
of aggregate quantities and prices that maximize the problems of households and …rms, the
government follows its Taylor rule, and markets clear. But while the de…nition of equilibrium
is straightforward, its computation is not. We now move into it.


3. Solution and Likelihood Evaluation

The solution of our model is challenging. We have 19 state variables, 5 innovations to the
structural shocks, ("dt ; "'t ; "At ; " t ; "mt ), 2 innovations to the parameter drifts, (" t ; "yt ), and
5 innovations to the volatility shocks, (udt ; u't ; u t ; uAt ; umt ), for a total of 31 variables that
we must consider.
   A vector of 19 states makes it impossible to use value function iteration or projection
methods (…nite elements or Chebyshev polynomials). The curse of dimensionality is too acute
even for the most powerful of existing computers. Standard linearization techniques do not
work either: stochastic volatility is inherently a non-linear process. If we solved the model by
linearization, all terms associated with stochastic volatility would disappear, due to certainty
equivalence, and our investigation would be essentially worthless.
   Then, nearly by default, using perturbation to obtain a higher-order approximation to
the equilibrium dynamics of our model is the only option. A second-order approximation
will include terms that depend on the level of volatility. Thus, these terms will capture
the responses of agents (households and …rms) to changes in volatility. At the same time, a
second-order approximation can be found su¢ ciently fast, which is of the utmost importance,
since we want to estimate the model and that forces us to solve it again and again for many
di¤erent parameter values. Thus, a second-order approximation is an interesting compromise
between accuracy and speed.

                                                                 13
   The idea of perturbation is simple. Instead of the exact decision rule of the agents in
the model, we use a second-order Taylor expansion to it around the steady state. That
Taylor expansion depends on the state variables and on the innovations. However, we do
not know the coe¢ cients multiplying each term of the expansion. Fortunately, we can …nd
them by an application of the implicit function theorem as follows (see also Judd, 1998, and
Schmitt-Grohé and Uribe, 2005).
   First, we write all the equations describing the equilibrium of the model (optimality
conditions for the agents, budget and resource constraints, the Taylor rule, and the laws of
motion for the di¤erent stochastic processes). Second, we rescale all the variables to remove
the balanced growth path induced by the presence of the drifts in the evolution of technology
(neutral and investment-speci…c). Third, we …nd the steady state implied by the rescaled
variables. Fourth, we linearize the equilibrium conditions around the steady state found in
the previous step. Then, we solve for the unknown coe¢ cients in this linearization, which
happens to be, by the implicit function theorem, the coe¢ cients of the …rst-order terms of the
decision rules in the rescaled variables that we are looking for (which can be easily re-arranged
to deliver the decision rules in the original variables). The next step is to take a second-order
approximation of the equilibrium conditions, plugging in the terms found before, and solve
for the coe¢ cients of the second-order terms of the decision rules.
   While we could keep iterating in this procedure for as long as we want, Aruoba, Fernández-
Villaverde, and Rubio-Ramírez (2006) show that, for the basic stochastic neoclassical growth
model (the backbone of the model we have here) calibrated to the U.S. data, a second-
order approximation delivers excellent accuracy at great computational speed. In our ac-
tual computation, we undertake the symbolic derivatives of the equilibrium conditions using
Mathematica 6.0. The code generates all of the relevant expressions and exports them au-
tomatically into Fortran …les. Then, Fortran will send particular parameter values in each
step of the estimation, evaluate those expressions, and determine the terms of the Taylor
expansions that we need.
   Once we have the approximated solution to the model, given some parameter values, we
use it to build a state space representation of the dynamics of states and observables. This
representation is, as we argued before, non-linear and hence standard techniques such as the
Kalman …lter cannot be applied to evaluate the associated likelihood function. Instead, we
resort to a simulation method known as the particle …lter, as applied to DSGE models by
Fernández-Villaverde and Rubio-Ramírez (2007). The particle …lter generates a simulation
of di¤erent states of the model and evaluates the probability of the innovations that make
these simulated states explain the observables. These probabilities are also called weights.
A simple application of a law of large numbers tells us that the mean of the weights is an


                                               14
evaluation of the likelihood. The secret of the success of the procedure is that, instead of doing
the simulation over the whole sample, we only perform it period by period, resampling from
the set of simulated state variables according to the weights we just found. This sequential
structure, which makes the particle …lter a case of a more general class of algorithms called
sequential Monte Carlo, ensures that the simulation of the state variables remains centered
on the true but unknown value of the state variables. This dramatically limits the numerical
variance of the procedure.
   Now that we have an evaluation of the likelihood of the model given observables, we only
need to search over di¤erent parameter values according to our favorite estimation algorithm.
This can be done in two ways. One is with a regular maximum likelihood algorithm: we look
for a global maximum of the likelihood. This procedure is complicated by the fact that the
evaluation of the likelihood function that we get from the particle …lter is non-di¤erentiable
with respect to the parameters because the inherent discreteness of the resampling step.
An easier alternative, and one that allows the introduction of presample information, is to
follow a Bayesian approach. In this route, we specify a prior over the parameters, multiply
the likelihood by it, and sample from the resulting posterior by means of a random-walk
Metropolis-Hastings algorithm. In this paper, we choose this second route. In our estimation,
however, we do not take full advantage of presample information since we impose ‡at priors to
facilitate the communication of the results to other researchers: the shape of our posteriors
will be proportional to the likelihood. We must note, however, that relying on ‡at priors
forces us to calibrate some parameters to values typically used in the literature (see FGR for
the values and justi…cation of the calibrated values).
   While our description of the solution and estimation method has been necessarily brief,
the reader is invited to check FGR for additional details. In particular, FGR characterizes
the structure of the higher-order approximations, showing that many of the relevant terms
are zero, and exploiting this result to quickly solve for the innovations that explain the
observables given some states. This result, proved for a general class of DSGE models with
stochastic volatility, is bound to be of wide application in all cases where stochastic volatility
is an important aspect of the problem.


4. Estimation

To estimate our model, we use …ve time series for the U.S. economy: 1) the relative price of
investment goods with respect to the price of consumption goods, 2) the federal funds rate,
3) real output per capita growth, 4) the consumer price index, and 5) real wages per capita.
Our sample covers from 1959.Q1 to 2007.Q1.


                                               15
   In …gure 1, we plot three of those …ve series: in‡ation, (per capita) output growth, and
the federal funds rate. The three series are the most commonly discussed when commentators
talk about monetary policy. By refreshing our memory about their evolution in the sample,
we can frame the rest of our discussion. To ease reading of the series, each of the vertical bars
corresponds to the tenure of one chairman of the Fed after Martin (column without color):
Burns-Miller (we merge these last two because of Miller’s short tenure), Volcker, Greenspan,
and Bernanke.




        Figure 1: Times series for in‡ation, output growth, and the federal funds rate.


                                               16
   The …rst panel tells us the history of the great American in‡ation: from the late 1960s to
the mid 1980s, the U.S. experienced its only signi…cant in‡ation in peace time, with peaks of
around 12-14 percent during the 1973 and 1979 oil shocks. The second panel tells us about
the great moderation: a simple inspection of the series after 1984 reveals a much smaller
amplitude of ‡uctuations (especially between 1993 to 2000) than before that date. The great
American in‡ation and the great moderation are the two main empirical facts to keep in mind
for the rest of the paper. The third panel is the federal funds rate, which follows a pattern
similar to in‡ation: it goes up in the 1970s (although less than in‡ation during the earlier
years of the decade and more during the last years), and stays much lower in the 1990s, to
reach historical minima by the end of the sample.
   The point estimates we get from our posterior agree with other estimates in the literature.
For example, we document a fair amount of nominal rigidities in the economy. In any case,
we refer the reader to FGR and avoid a lengthy discussion of them. Here, we report only the
modes and standard deviations of the posterior distributions associated with the parameters
governing stochastic volatility (table 1) and policy (table 2). In our view, those parameters
are the most relevant for our reading of the recent history of monetary policy in the U.S.

         Table 1: Posterior, Parameters of the Stochastic Processes for Volatility Shocks
                           log       d   log       '   log        log       A   log       m

                            1:9834       2:4983        6:0283     3:9013          6:000
                           (0:0726)      (0:0917)      (0:1278)   (0:0745)       (0:1471)

                                 d             '                        a               m

                           0:9506        0:1275        0:7508     0:2411        0:8550
                           (0:0298)      (0:0032)      (0:035)    (0:005)        (0:0231)

                                 d             '                        a             m
                           0:3246        2:8549        0:4716     0:7955        1:1034
                           (0:0083)      (0:0669)      (0:006)    (0:013)        (0:0185)


   The main lesson from table 1 is that the scale parameters,                      i,   are clearly positive and
bounded away from zero, con…rming the presence of time-variant volatility in the data. Shocks
to the volatility of the intertemporal preference shifter,           d,     are the most persistent (also, the
standard deviations are su¢ ciently tight as to suggest that we are not su¤ering from serious
identi…cation problems). The innovations to the volatility shock of the intratemporal labor
shock,    ',   are large in magnitude, which suggests that labor supply shocks may have played an
important role during the great in‡ation period by moving the marginal cost of intermediate
good producers. Finally, the estimates for the volatility process governing investment-speci…c
productivity suggests that such productivity shocks are important in accounting for business
cycles ‡uctuations in the U.S. (Fisher, 2006).


                                                        17
                                     Table 2: Posterior, Policy Parameters
                                        R     log   y                     log
                                  0:7855       1:4034 1:0005 0:0441 0:1479
                                  (0:0162)    (0:0498)         (0:0043)   (0:0005)        (0:002)



       The results from table 2 indicate that the central bank smooths interest rates (                                 R   >
0). The parameter             is the average magnitude of the response to in‡ation in the Taylor
rule. Its estimated value (1:045 in levels) is just enough to guarantee determinacy in the
model (Woodford, 2003).5 The size of the innovations to the drifting in‡ation parameter,
  , rea¢ rms our view of a time-dependent response to in‡ation in monetary policy. The
estimates for     y;t   (the response to output deviations in the Taylor rule) are not reported
because preliminary attempts at estimation convinced us that                                  y   was nil. Hence, in our next
exercises, we set       y
                            and     y   to zero.


5. Two Graphs

In this section, we present two graphs that will tell us much about the evolution and e¤ects
of monetary policy. First, the estimated smoothed path of                                 t   over our sample. Second, the
evolution during the same years of a measure of the real interest rate. In the next section,
we will map these graphs into the historical record.
       We start with …gure 2, perhaps the most important graph in this paper. In it, we plot the
smoothed estimate of the evolution of the response of monetary policy to in‡ation plus/minus
a two-standard-deviation interval given our point estimates of the structural parameters. The
message of …gure 2 is straightforward. According to our model, the response of monetary
policy to in‡ation was, at the arrival of the Kennedy administration, around its estimated
mean, slightly over 1.6 It grew more or less steadily during the 1960s, until reaching a peak
at the end of 1967-beginning of 1968. At that moment,                                t   fell so quickly that it was below
1 by 1971. For nearly all of the 1970s,                  t   stayed below 1 and only picked up with the arrival
of Volcker. Interestingly, the two oil shocks did not have an impact on the estimated                                       t.
The parameter stayed high during all of Volcker years and only fell after a few quarters into
Greenspan’s tenure, when it returned to levels even lower than during the Burns and Miller
years. The likelihood function favors an evolving monetary policy even after introducing
stochastic volatility in the model. In FGR, we assess this statement more carefully with

   5
    In this model, local determinacy depends only on the mean of   :
   6
    This number nearly coincides with the estimate of Romer and Romer (2002a) of the coe¢ cient using data
from the 1950s.



                                                                18
several measures of model …t, including the construction of Bayes factors and the computation
of Bayesian information criteria between di¤erent speci…cations of the model.




    Figure 2: Smoothed path for the Taylor rule parameter on in‡ation +/- 2 standard
                                          deviations.


   The reader could argue, with some justi…cation, that we have estimated a large DSGE
model and that it is not clear what is driving the results and what variation in the data
is identifying the movements in monetary policy. While a fully worked out identi…cation
analysis is beyond the scope of this paper, as a simple reality check, we can plot, in …gure 3, a
measure of the (short-term) real interest rate de…ned as the federal funds rate minus current



                                               19
in‡ation.7




                Figure 3: Real interest rate (federal funds rate minus current in‡ation).


       In this …gure we can see that Martin kept the real interest rate at positive values around
2 percent during the 1960s (with a peak by the end, which corresponds with the peak of our
estimated         t ).   However, during the 1970s, the real interest rate was often negative and only
rarely above 2 percent, a rather conservative lower bound on the balanced growth real interest
rate given our point estimates. The likelihood can only interpret those observations as a very
low       t   (remember that the Taylor principle calls for increases in the real interest rate when
in‡ation rises; that is, nominal interest rates must grow more than in‡ation). Real interest

   7
     Since in‡ation is nearly a random walk (Stock and Watson, 2007), its current value is an excellent proxy
for its expected value. In any case, our argument is fully robust to slightly di¤erent de…nitions of the real
interest rate.


                                                      20
rates skyrocketed with the arrival of Volcker, reaching a historical record of 13 percent by
1981.Q2. After that date, they were never even close to zero, and only in two quarters where
they below 3 percent. Again, the likelihood function can only interpret that observation as
a high         t.   The history with Greenspan is more complicated, since real interest rates were
not particularly low in the 1990s. However, output growth was very positive, which pushed
the interest rates up in the Taylor rule. Since the federal funds rate was not as high as the
policy rule would have predicted with a high            t,   the smoothed estimate of the parameter
is lowered. During the 2000s, real interest rates close to zero are enough, by themselves, to
keep       t   low.


6. Reading Monetary History Through the Lens of Our Model

Now that we have our model and our estimates of the structural parameters, we can smooth
the structural and volatility shocks implied by the data and use them to read the recent
monetary history of the U.S. Somewhat conventionally, we will organize our discussion around
the di¤erent chairmen of the Fed from Martin to Greenspan, except for Miller, whom we group
with Burns due to his short tenure.
   One fundamental lesson from this exercise is that …gure 2 can successfully guide our
interpretation of policy from 1959 to 2007. We will document how both Martin and Volcker
believed that in‡ation was dangerous and that the Fed had both the responsibility and the
power to …ght it, although growing doubts about that power overcame Martin during his last
term as chairman. Burns, on the other hand, thought the costs of in‡ation were lower than
the cost of a recession triggered by disin‡ation. In any case, he was rather skeptical about
the Fed’s ability to successfully disin‡ate. Greenspan, despite his constant warnings about
in‡ation, had in practice a much more nuanced attitude. According to our estimated model,
good positive shocks to the economy gave him the privilege of skipping a daunting test of his
resolve.
   Thanks to the fact that by using a DSGE model we have a complete set of structural and
volatility shocks, in FGR, we complete this analysis with the construction of counterfactual
exercises. In those, we build arti…cial histories of economies in which some source of variation
has been eliminated or modi…ed in an illustrative manner. For example, we can evaluate how
the economy would have behaved in the absence of changes in the volatility of the structural
shocks or if the average monetary policy of one period had been applied in another one. By
interpreting those counterfactual histories, we will attribute it most of the defeat of the great
American in‡ation to monetary policy under Volcker and most of the great moderation after
1984 to good shocks. We will incorporate information from those counterfactuals as we move


                                                   21
along.
       Our exercise in this section is closely related to the work of Christina and David Romer
(1989, 2002a and 2002b, and 2004), except that we attack the problem from exactly the oppo-
site perspective. While they let their “narrative approach”guide their empirical speci…cation
and they like to keep a ‡exible relation with equilibrium models, we start from a tightly pa-
rameterized DSGE model of the U.S. economy and use the results of our estimation to read
the narrative told by the documents. We see both strategies as complementary since each
can teach us much of interest. Quite remarkably, given the di¤erent research designs, many
of the conclusions that we reach are similar to the views expressed by Romer and Romer.

6.1. The Era of Martin: Resistance and Surrender

William McChesney Martin, the chairman of the Fed between April 2, 1951 and January 31,
1970, knew how to say no. On December 3, 1965, he dared to raise the discount rate for the
…rst time in more than …ve years, despite warnings from the Treasury secretary, Henry Fowler,
and the chairman of the Council of Economic Advisors, Gardner Ackley, that the President
Lyndon Johnson disapproved of such move. Johnson, a man not used to seeing his orders not
carried out and angered by Martin’s unwelcome display of independence, summoned him to
a meeting at his Texas ranch. There, for over an hour, he tried to corner the chairman of the
Fed with the infamous bullying tactics that had made him a master of the Senate in years
past. Martin, however, held his ground and carried the day: the raise would stand. Robert
Bremner starts his biography of Martin with this story.8 The choice is most appropriate. The
history of this confrontation illustrates better than any other event our econometric results.
       The early 1960s were the high years of Martin’s tenure. The era of the “new economics”
combined robust economic growth, in excess of 5 percent, and low in‡ation, below 3 percent.
According to our estimated model, this moderate in‡ation was, in part, a re‡ection of Martin’s
views about economic policy. Bremner (2004, p. 121) summarizes Martin’s guiding principles
this way: stable prices were crucial for the correct working of a market economy and the Fed’s
main task was to maintain that stability. In Martin’s own words, the Fed “has a responsibility
to use the powers it possesses over economic events to dampen excesses in economic activity
[by] keeping the use of credit in line with resources available for production of goods and
services.”9 Martin was also opposed to the idea (popular at the time) that the U.S. economy

   8
     Bremner (2004), pp. 1-2. This was not the only clash of Martin with a President of the U.S. In late
1952, Martin bumped into Truman leaving the Waldorf Astoria hotel in New York City. To Martin’s “Good
afternoon,”Truman wryly replied “Traitor!”Truman was deeply displeased by how the Fed had implemented
the accord of March 3, 1951 between the Fed and the Treasury that ended the interest rate peg in place since
1942 (Bremner, 2004, p. 91).
   9
     Martin’s testimony to the Joint Economic Committee, February 5, 1957. Cited by Bremner (2004), p.


                                                    22
had a built-in bias toward in‡ation, a bias the Fed had to accommodate through monetary
policy. Sumner Slichter, an in‡uential professor of economics at Harvard, was perhaps the
most vocal proponent of the built-in bias hypothesis. In Martin’s own words, “I refuse to
raise the ‡ag of defeatism in the battle of in‡ation” and “[t]here is no validity whatever in
the idea that any in‡ation, once accepted, can be con…ned to moderate proportions.”10 As we
will see in the next subsection, this opposition stands in stark contrast to Burns’s pessimistic
view of in‡ation, which had many points of contact with Slichter’s.
       Our estimates of     ;t ,   above 1 and growing during the period, clearly tell us that Martin
was doing precisely that: working to keep in‡ation low. Our result also agrees with Romer
and Romer’s (2002a) narrative and statistical evidence regarding the behavior of the Fed
during the late 1950s. We must not forget, however, that our estimates in FGR suggest as
well that the good performance of the economy from 1961 to 1965 was also the consequence
of good positive shocks.
       The stand against in‡ation started to be tested around 1966. Intellectually, more and more
voices had been raised since the late 1950s defending the notion that an excessive concern with
in‡ation was keeping the economy from working at full capacity. Bremner (2004, p. 138) cites
Walter Heller and Paul Samuelson’s statements before of the Joint Economic Committee in
February, 1959 as examples of an attitude that would soon gain strength. The following year,
Samuelson and Robert Solow’s classic paper about the Phillips curve was taken by many as
providing an apparently sound empirical justi…cation for a much more sanguine position with
respect to in‡ation: “In order to achieve the nonperfectionist’s goal of high enough output to
give us no more than 3 per cent unemployment, the price index might have to rise by as much
as 4 to 5 per cent per year. That much price rise would seem to be the necessary cost of high
employment and production in the years immediately ahead” (Samuelson and Solow, 1960,
p. 192).11 Heller’s and Tobin’s arrival on the Council of Economic Advisors transformed the
critics into the insiders.
       The pressures on monetary policy were contained during Kennedy’s administration, in

123.
  10
     The …rst quotation is from the New York Times, March 16, 1957, where Martin was expressing dismay
for having reached a 2 percent rate of in‡ation! The second quotation is from the Wall Street Journal, August
19, 1957. Martin also thought that Keynes himself had changed his views on in‡ation after the war (they had
talked privately on several occasions) and that, consequently, Keynesian economists were overemphasizing
the bene…ts of in‡ation. See Bremner (2004), pp. 128 and 229.
  11
     The message of the paper is, however, much more subtle than laying down a simple textbook Phillips
curve. As Samuelson and Solow also say in the next page of the article: “All of our discussion has been phrased
in short-run terms, dealing with what might happen in the next few years. It would be wrong, though, to
think that our Figure 2 menu that relates obtainable price and unemployment behavior will maintain its
shape in the longer run. What we do in a policy way during the next few years might cause it to shift in a
de…nite way.”


                                                      23
good part because C. Douglas Dillon, the secretary of the Treasury and a Rockefeller Repub-
lican, sided on many occasions with Martin against Heller.12 But the changing composition of
the Board of Governors and the arrival of Johnson, with his expansionary …scal programs, the
escalation of the Vietnam war, and the departure of Dillon from the Treasury Department,
changed the weights of power.
       While the e¤ects of the expansion of federal spending in the second half of the 1960s often
play a central role in the narrative of the start of the great in‡ation, the evolution of the
Board of Governors has received less attention. Heller realized that, by carefully selecting the
governors, he could shape monetary policy without the need to ease Martin out. This was an
inspired observation, since up to that moment, the governors that served under the chairman
had played an extremely small role in monetary policy and the previous administrations
had, consequently, shown little interest in their selection. The strategy worked. Heller’s …rst
choice, George W. Mitchell would become a leader of those preferring a more expansionary
monetary policy on the FOMC.
       By 1964, Martin was considerably worried about in‡ation. He told Johnson: “I think
we’re heading toward an in‡ationary mess that we won’t be able to pull ourselves out of”
(oral history interview with Martin, Lyndon B. Johnson Library, quoted by Bremner, 2004,
p. 191). In 1965, he ran into serious problems with the president, as we discussed at the
beginning of this section. The problems appeared again in 1966, with the appointment
of Brimmer as a governor against Martin’s recommendation. During all this time, Martin
was sticking to his guns, trying to control in‡ation even if it meant erring on the side of
overtightening the economy. Our estimated               ;t   captures this attitude with an increase from
around 1965 to around 1968.
       But by the summer of 1968, Martin gave in to an easing of monetary policy after the tax
surcharge was passed by Congress. As reported by Hetzel (2008), at the time the FOMC was
divided between members more concerned about in‡ation (such as Al Hayes, the president of
the Federal Reserve Bank of New York) and members more concerned about output growth
(Brimmer,13 Maisel,14 and Mitchell, all three appointees of Kennedy and Johnson) with Mar-

  12
     In particular, Dillon’s support for Martin’s reappointment for a new term in 1963 was pivotal. Hetzel
(2008) p. 69, suggests that Kennedy often sided with Dillon and Martin over Heller to avoid a gold crisis on
top of the problems with the Soviet Union over Cuba and Berlin.
  13
     Brimmer is also the …rst African American to have served as governor and, for a while, a faculty member
at the University of Pennsylvania.
  14
     Sherman Maisel was a member of Board of Governors between 1965 and 1972. Maisel, a professor at the
Haas School of Business-UC Berkeley, has the honor of being the …rst academic economist appointed as a
governor after Adolph Miller, one of the original governors in 1914. As he explained in his book, Managing
the Dollar, one of the …rst inside looks at the Fed and still a fascinating read today, Maisel was also a strong
believer in the Phillips curve: “There is a trade-o¤ between idle men and a more stable value of the dollar.
A conscious decision must be made as to how much unemployment and loss of output is acceptable in order


                                                      24
tin, always a seeker of consensus, growlingly incapable of carrying the day.15 Perhaps Martin
felt that the political climate had moved away from a commitment to …ght in‡ation.16 Or
perhaps he was just exhausted after many years running the Fed (at the last meeting of the
FOMC in which he participated, he expressed feelings of failure for not having controlled
in‡ation). No matter what the exact reason was, monetary policy eased drastically in com-
parison with what was being called for by the Taylor rule with a                    ;t     above 1. Thus, our
estimated      ;t   starts to plunge in the spring of 1968, re‡ecting that the increases in the fed-
eral funds rate passed at the end of 1968 and in 1969 were, according to our estimated Taylor
rule, not aggressive enough given the state of the economy. The genie of the great American
in‡ation was out of the bottle.

6.2. The Era of Burns and Miller: Monetary Policy in the Time of Turbulence

Arthur F. Burns started his term as chairman of the Fed on February 1, 1970. A professor
of economics at Columbia University and the president of the National Bureau of Economic
Research between 1957 and 1967, Burns was the …rst academic economist to hold the chair-
manship. All the previous 9 chairmen had been bankers and lawyers. However, any hope
that his economics education would make him take an aggressive stand against the in‡ation
brewing during the last years of Martin’s tenure quickly disappeared. The federal funds rate
fall from an average of 8.02 percent during 1970.Q1 to 4.12 percent by 1970.Q4. The justi-
…cation for those reductions was the need to jump-start the economy, which was stacked in
the middle of the …rst recession in nearly a decade since December, 1969. But, since in‡ation
stayed at 4.55 percent by end of 1970, the reduction in the nominal rate meant that real
interest rates sank into the negative region.
    Our smoothed estimate of           ;t   in …gure 2 responds to this behavior of the Fed by quickly
dropping during the same period. This re‡ects that the actual reduction on the federal
funds rate was much more aggressive than the reduction suggested by the (important) fall in
output growth and the (moderate) fall in in‡ation. Furthermore, the likelihood accounts for
the persistence fall in the real interest rate with a persistent fall in            ;t .


to get smaller price rises”(Maisel, 1973, p.285). Maisel’s academic and Keynesian background merged in his
sponsoring of the MPS model that we mentioned in section 2.
   15
      On one occasion, Maisel felt strongly enough to call a press conference to explain his dissenting vote in
favor of more expansion.
   16
      Meltzer (2010, p. 549) points out that Martin and the other board members might have been worried by
Johnson’s appointment, at the suggestion of Arthur Okun (the chairman of the Council of Economic Advisors
at the time), of a task force to review changes in the Federal Reserve System. The message only got reinforced
with the arrival of a new administration in 1969 given Nixon’s obsession with keeping unemployment as low
as possible (Nixon’s was convinced that he had lost the 1960 presidential election to a combination of vote
fraud and tight monetary policy).


                                                      25
    Burns did little over the next few years to return            ;t   to higher values. Even if the federal
funds rate had started to grow by the end of 1971 (after the 90-day price controls announced
on August 15 of that year as part of Nixon’s New Economic Policy), and reached new highs
in 1973 and 1974, it barely kept up with in‡ation. The real interest rate was not over our
benchmark value of 2 percent until the second quarter of 1976. Later, in 1977, the federal
funds rate was only raised cautiously, despite the evidence of strong output growth after the
1973-1975 recession and that in‡ation remained relatively high.
    Our econometric results come about because the Taylor rule does not care about the level
of the interest rate in itself, but by how much in‡ation deviates from                   . If    ;t     > 1, the
increases in the federal funds rate are bigger than the increases in in‡ation. This is not what
happened during Burns’s tenure: the real interest rate was above the cuto¤ of 2 percent that
we proposed before only in three quarters, his two …rst quarters as chairman (1970.Q2 and
1970.Q3) and in 1976.Q2. This observation, by itself, should be su¢ cient proof of the stand
of monetary policy during the period.17
    Burns’s successor, William Miller, did not have time to retract these policies in the brief
interlude of his tenure, from March 8, 1978 to August 6, 1979. But he also did not have
either the capability, since his only experience in the conduct of monetary policy was serving
as a director of the Federal Reserve Bank of Boston, or desire, since he had little faith in
restrictive monetary policy’s ability to lower in‡ation.18 Thus, our estimated                     ;t   remains
low during that time.19
    Burns was subject to strong pressure from Nixon.20 His margin of maneuver was also lim-
ited by the views among many leading economists that overestimated the costs of disin‡ation

   17
      Revealing of the climate of the time is the memorandum prepared by two of Carter’s advisers at the
end of December 1977 proposing not to reappoint Burns for a third term as chairman because he was “more
concerned with in‡ation than unemployment” (memo for the president on the Role of the Federal Reserve,
Box 16, R.K. Lipshitz Files, Carter Library, December 10, 1977, 1-2, cited by Meltzer, 2010, p. 922).
   18
      “Our attempts to restrain in‡ation by using conventional stabilization techniques have been less than
satisfactory. Three years of high unemployment and underutilized capital stock have been costly in terms
both of lost production and of the denial to many of the dignity that comes from holding a productive job.
Yet, despite this period of substantial slack in the economy, we still have a serious in‡ation problem”(Federal
Reserve Bulletin, March 1978, p. 193). Quoted by Romer and Romer (2004), p. 140.
   19
      The situation with Miller reached the surrealistic point where, as narrated by Kettl (1986), Charles
Schultze, the chairman of the Council of Economic Advisors and Michael Blumenthal, the Treasury secretary,
were leaking information to the press to pressure Miller to tighten monetary policy.
   20
      Perhaps the clearest documented moment is the meeting between Nixon and Burns on October 23, 1969,
right after Burn’s nomination, as narrated by John Ehrlichman (1982, pp. 248–49):
   “I know there’s the myth of the autonomous Fed...” Nixon barked a quick laugh. “. . . and when you go
up for con…rmation some Senator may ask you about your friendship with the President. Appearances are
going to be important, so you can call Ehrlichman to get messages to me, and he’ll call you.”
   The White House continued its pressure on Burns by many di¤erent methods, from constant conversations
to leaks to the press (falsely) accusing Burns of requesting a large wage increase. These, and many other
histories, are collected in a fascinating article by Abrams (2006).


                                                      26
and that were in any case skeptical of monetary policy.21 But his own convictions leaned
in the same direction. According to the recollections of Stephen H. Axilrod, a senior sta¤
member at the Board back then, Burns did not believe any theory of the economy -whether
Keynesian or monetarist- could account for the business cycle, he dismissed the relation be-
tween the stock of money and the price level, and he was unwilling or unable to make a
persuasive case against in‡ation to the nation and to the FOMC.22
       In addition, Burns had a sympathetic attitude toward price and wage controls. For
instance, Burns testi…ed to Congress on February 7, 1973: “[T]here is a need for legislation
permitting some direct controls over wages and prices...The structure of our economy-in
particular, the power of many corporations and trade unions to exact rewards that exceed
what could be achieved under conditions of active competition-does expose us to upward
pressure on costs and prices that may be cumulative and self-reinforcing” (cited by Hetzel,
2008, p. 79). He reiterated that view in a letter to the president on June 1, 1973, in which he
proposed to reintroduce mandatory price controls for large …rms.23 In his view, controls could
break the cost-push spiral of the economy and the in‡ationary pressures triggered by the social
unrest of the late 1960s and be a more e¤ective instrument than open market operations,
which could be quite costly in terms of employment and …nancial disturbances.24 In fact,
many members of the FOMC believed that the introduction of price and wage controls in
di¤erent phases between 1971 and 1973 had not only eased the need for monetary tightening,
but it also positively suggested that monetary policy should not impose further restraint on

  21
      Three examples. First, Franco Modigliani testi…ed before the U.S. Congress on July 20, 1971:
   “[Y]ou have to recognize that prices are presently rising, and no measure we can take short of creating
massive unemployment is going to make the rate of change of prices substantially below 4 percent.”
   Second, Otto Eckstein, the builder of one of the large macroeconometric models at the time, the DRI U.S.
model, argued that it was not the Fed’s job to solve structural in‡ation.
   Third, James Tobin (1974): “For the rest of us, the tormenting di¢ culty is that the economy shows
in‡ationary bias even when there is signi…cant involuntary unemployment. The bias is in some sense a
structural defect of the economy and society .... Chronic and accelerating in‡ation is then a symptom of a
deeper social disorder, of which involuntary unemployment is an alternative symptom. Political economists
may di¤er about whether it is better to face the social con‡icts squarely or to let in‡ation obscure them
and muddle through. I can understand why anyone who prefers the …rst alternative would be working for
structural reform, for a new social contract. I cannot understand why he would believe that the job can be
done by monetary policy. Within limits, the Federal Reserve can shift from one symptom to the other. But
it cannot cure the disease.”
   The examples are quoted by Hetlzel (2008), pp. 86, 89, and 128.
   22
      “After all, he (Burns) said, the same amount of money could support either more or less economic activity.
If the economy were strong, an existing stock of money would just be turned over more rapidly, with any rise
of interest rates attributable to the strength of credit demand relative to the supply.”This quotation and the
material in the main text come from Axilrod (2009), pp. 58-60.
   23
      Burns papers, B_N1, June 1, 1973, as cited by Meltzer (2010), p.787.
   24
      At the time, many …nancial institutions were subject to ceiling rates on deposits, which could have made
them bankrupt in the case of a fast tightening of monetary policy.



                                                      27
the economy (Maisel’s diary, entry for August 25, 1971, as cited by Meltzer, 2010, p. 790).
More interestingly, if price and wage controls were an argument for loose monetary policy,
their easing was also an argument for expansionary policy, or as governor Charles Partee put
it during the FOMC meeting of January 11, 1973, the lifting of controls “might necessitate a
somewhat faster rate of monetary growth to …nance the desired growth in real output under
conditions of greater cost-push in‡ation than would have prevailed with tighter controls”
(cited by Meltzer, 2010, p. 815).
   Burns’s 1979 Per Jacobsson lecture is a revealing summary by Burns himself of his views
on the origins and development of in‡ation. He blamed the growing demands of di¤erent
social groups during the late 1960s and early 1970s and the federal government’s willingness
to concede to them as the real culprit behind in‡ation. Moreover, he felt that the Fed could
not really stop the in‡ationary wave: “If the Federal Reserve then sought to create a monetary
environment that fell seriously short of accommodating the upward pressures on prices that
were being released or reinforced by governmental action, severe di¢ culties could be quickly
produced in the economy. Not only that, the Federal Reserve would be frustrating the will
of Congress to which it was responsible...”
   But beyond Burns’s own defeatist attitude toward in‡ation, he was a most unfortunate
chairman. He was in charge during a period of high turbulence and negative shocks, not
only the 1973 oil shock, but also poor crops in the United States and the Soviet Union. Our
model estimates large and volatile intertemporal shocks, dt ; and labor supply shocks, 't ,
during his tenure (see FGR for a plot of these shocks). Examples of intertemporal shocks
include the …nal breakdown of the Bretton Woods agreement, …scal policy during the 1973-
1975 recession (with a temporary tax cut signed in March 1975 and increases in discretionary
spending) and Nixon’s price and wage controls (which most likely distorted intratemporal
allocations). Examples of labor supply shocks include the historically high level of strikes
in American industry during the early 1970s (a major issue in the Republican primary of
1976 between Ford and Reagan was picketing rules for striking workers, a policy issue most
unlikely to grab many voters’attention nowadays).
   Both types of shocks complicated monetary policy. Large positive intertemporal shocks
increase aggregate demand. In our model, this translates partly into higher output and
partly into higher in‡ation. Positive labor supply shocks increase wages, which pushes up the
marginal cost and, therefore, in‡ation. Moreover, FGR show that, if volatility had stayed at
historical levels, even with negative innovations, in‡ation would have been much lower and
the big peak of 1973 avoided.
   However, those negative shocks should not make us forget that, according to our model,
if monetary policy had engineered higher real interest rates during those years, the history of


                                              28
in‡ation could have been di¤erent. In FGR we calculate that, had monetary policy behaved
under Burns and Miller as it did under Volcker, in‡ation would have been 4.36 percent on
average, instead of the observed 6.23 percent. The experience of Germany or Switzerland,
which had much lower in‡ation than the U.S. during the same time, suggests that this was
possible. After all, the peak of in‡ation in Germany was in 1971, well before any of the oil
shocks and in neither of these two European countries do we observe statements such as the
ones of Governor Sheehan on the January 22, 1974, FOMC meeting: “[T]he Committee had
no choice but to validate the rise in prices if it wished to avoid compounding the recession”
(Hetzel, 2008, p. 93).
       Thus, our reading of monetary policy during the Burns years through the lens of our model
emphasizes the con‡uence of two phenomena: an accommodating position with respect to
in‡ation and large and volatile shocks that complicated the implementation of policy. There
is ample evidence in the historical record to support this view. This was, indeed, monetary
policy in the time of turbulence.

6.3. The Era of Volcker: The Moment of Truth

In his 1979 lecture that we cited before, Burn had concluded: “It is illusory to expect central
banks to put an end to the in‡ation that now a- icts the industrial democracies.” Paul
Volcker begged to di¤er. He had been president of the Federal Reserve Bank of New York
since August 1975 and, from that position, a vocal foe of in‡ation. In particular, during his
years as a member of the FOMC, Volcker expressed concern that the Fed was consistently
underpredicting in‡ation and that, therefore, monetary policy was more expansionary than
conventionally understood (Meltzer, 2010, p. 942).25
       In the summer of 1979, Carter, in a desperate stunt to save his sinking presidency, moved
Miller to the Treasury Department. Then, he o¤ered Volcker the chairmanship of the Board
of Governors. Volcker did not hesitate to take it, but not before warning the president of “the
need for tighter money -tighter than Bill Miller had wanted” (Volcker and Gyothen, 1992,
p. 164) and the senate in his con…rmation hearings that “the only sound foundation for the
continuing growth and prosperity of the American economy is much greater price stability”
(U.S. Senate. 1979, p. 16), quoted by Romer and Romer (2004), p. 156. Deep changes were
coming and the main decision-makers were aware of them.
       We should not risk, however, to overemphasize a sharp break in monetary policy with
Volcker’s appointment. In 1975, the House passed Concurrent Resolution 133, the brainchild

  25
    This position links to an important point made by Orphanides (2002): monetary policy decisions are
implemented using real-time data, a point that our model blissfully ignores. In turbulent times such as the
1970s, this makes steering the ship of policy targets exceedingly di¢ cult.


                                                    29
of Karl Brunner (Weintraub, 1977). This resolution, which asked the Fed to report to the
House Banking Committee on “objectives and plans with respect to the ranges of growth or
diminution of monetary and credit aggregates in the upcoming twelve months,” was a …rst
victory for monetarism. Although the resolution probably did little by itself, it was a sign that
times were changing. Congress acted again with the Full Employment and Balanced Growth
Act of 1978, which imposed on the Fed the requirement to report monetary aggregates in its
reports to Congress. In April 1978, the federal funds rate started growing quickly, from a
monthly average of 6.9 percent to 10 percent by the end of the year. This re‡ected a growing
consensus on the FOMC (still with many dissenting voices) regarding the need for lower
in‡ation. We can see in …gure 2 the start of an increase in           ;t   around that time. At the same
time, the new procedures for monetary policy that targeted money growth rates and reserves
instead of the federal funds rate were not announced until October 6, 1979. Additionally,
Goodfriend and King (2007) have argued that Volcker required some time before asserting his
control over the FOMC. For instance, in the Board meeting of September 18, 1979, Volcker
could only obtain a rise in the discount rate with three dissenting votes. As we argued in
section 2, all of these observations suggest that modelling the evolution of monetary policy
as a smooth change may be more appropriate than assuming a pure break.
       Regardless of the exact timing of changes in monetary policy, the evidence of …gure 2 is
overwhelming: on or about August 1979 monetary policy character changed. The federal
funds rate jumped to new levels, with the …rst signi…cant long-lasting increase in the real
interest rate in many years. Real interest rates would remain high for the remainder of the
decade of the 1980s, partly re‡ecting high federal fund rates, partly re‡ecting the deeply
rooted expectations of in‡ation among the agents. In any case, the response of monetary
policy to in‡ation,      ;t ,   was consistently high during the whole of Volcker’s years.
       An important question is the extent to which the formalism of the Taylor rule can capture
the way in which monetary policy was conducted at the time, when money growth targeting
and reserve management were explicitly tried (what Volcker called “practical monetarism”).
We are not overly concerned about this aspect of the data because, in our DSGE model,
there is a mapping between money targeting and the Taylor rule (Woodford, 2003). Thus,
as long as we are careful to interpret the monetary policy shocks during the period (which
we estimate were, indeed, larger than in other parts of the sample), our exercise should be
relatively robust to this consideration.26 A much more challenging task could be to build a

  26
     This begets the question of why Volcker spent so much e¤ort on switching the operating procedure of the
Fed between 1979 and 1982. Volcker himself ventures that it was easier to sell a restrictive monetary policy
in terms of money growth rates than in terms of interest rates: “More focus on the money supply also would
be a way of telling the public that we meant business. People don’t need an advanced course in economics
to understand that in‡ation has something to do with too much money” (Volcker and Gyohten 1992, pp.


                                                    30
DSGE model with a richer set of monetary policy rules and switches between them. However,
at the moment, this goal seems infeasible.27
    The impressions of participants in the monetary policy process reinforced the message
of …gure 2. For instance, Axilrod (2009, p. 91) states: “During Paul Volcker’s eigth-year
tenure as chairman of the Fed...policy changed dramatically. He was responsible for a major
transformation -akin to a paradigm shift- that was intended to greatly reduce in‡ation, keep
it under control, and thereby restore the Fed’s badly damaged reputation.”Furthermore, “it
was almost solely because of Volcker that this particular innovation was put in place -one of
the few instances in my opinion where a dramatic shift in policy approach could be attributed
to a particular person’s presence rather than mainly or just to circumstances.”
    Volcker himself was very explicit about his views: “...my basic philosophy is over time
we have no choice but to deal with the in‡ationary situations because over time in‡ation
and unemployment go together...Isn’t that the lesson of the 1970s? We sat around [for]
years thinking we could play o¤ a choice between one of the other...It had some reality when
everybody thought processes were going to be stable...So in a very fundamental sense, I don’t
think we have the choice...” (Volcker papers, Federal Reserve Bank of New York, speech at
the National Press Club, Box 97657, January 2, 1980, quoted by Meltzer, 2010, p. 1034). In
fact, Volcker’s views put him in the rather unusual position of being outvoted on February
24, 1986. In that meeting, a majority of 4 members of the Board voted to lower the discount
rate 50 basis points against Volcker and 2 other dissenting members.
    At the same time, and according to our model, Volcker was also an unlucky chairman.
The economy still su¤ered from large and negative shocks during his tenure, since the level
and volatility of the intratemporal preference shifter did not fall until later in his term. In
FGR, we build a counterfactual in which Volcker is faced with the same structural shocks he
faced in real life, but having the historical average volatility. In this counterfactual history,
in‡ation falls to negative values by the end of 1983, instead of still hovering around 3-4
percent. It was a tough policy in a di¢ cult time. However, despite these misfortunes and
heavy inheritance from the past, our model tells us that monetary policy conquered the great
American in‡ation. The great moderation would have to wait for better shocks.
    We started this subsection with Burns’s own words in the 1979 Per Jacobsson lecture.
In 1989, Volcker was invited to give the same lecture. What a di¤erence a decade can
make! While Burns was sad and pessimistic (his lecture was entitled The Anguish of Central

167-168).
  27
     The impact of the credit controls imposed by the Carter administration starting on March 14, 1980 are
more di¢ cult to gauge. Interestingly, we estimate a large negative innovation to the intratemporal preference
shifter at that moment, a likely re‡ection of the distortions of the controls in the intertemporal choices of
households (see the historical description in Shreft, 1990).


                                                     31
Banking), Volcker was happy and con…dent (and his lecture was entitled The Triumph of
Central Banking? ). In‡ation had been defeated and he warned that “our collective experience
strongly emphasizes the importance of dealing with in‡ation at an early stage...”

6.4. The Era of Greenspan: Speaking Like a Hawk and Walking Like a Dove

These are the colorful words in which Lawrence Meyer (2004, p. 83) summarizes Greenspan’s
behavior during his time as a governor (June 1996 to January 2002). Once and again,
Greenspan: “seemed to fall into a pattern: The Chairman would ask for no change in the
funds rate suggesting that the time was approaching for action, and indicate that there was a
high probability of a move at the next meeting. Then at the next meeting, he would explain
that the data did not yet provide a credible basis for tightening, and in any case the markets
didn’t expect a move. However, he would conclude that he expected the Committee would
be forced to move at the next meeting.” Meyer means these words in a positive way. In
his opinion, Greenspan discovered before he did that the economy was being hit during the
second half of the 1990s by an unusual sequence of positive shocks and directed monetary
policy to take advantage of them.
       We quote Meyer because it illustrates that Greenspan showed from the start that he knew
how to respond to changing circumstances. He was appointed in August 11, 1987. In his
con…rmation hearings, he clearly rea¢ rmed the need to …ght in‡ation.28 But, after just a
couple of months, in October 19, 1987, he reacted to the big crash of the stock market by
declaring the Fed’s disposition to serve as a source of liquidity, even if, in the short run, this
could complicate the control of in‡ation.
       Later, in early 1989, the federal funds rate started to fall, despite the fact that in‡ation
remained at around 6 percent until the end of 1990. As we can see in …gure 2, our estimate of
   ;t   picks up this fall by dropping itself. Moreover, it dropped fast. We estimate that            ;t   was
soon below 1, back to the levels of Burns-Miller (although, for a while, there is quite a bit of
uncertainty in our estimate). The parameter stayed there for the rest of Greenspan’s tenure.
The reason for this estimated low level of            ;t   is that the real interest rate also started to
fall rather quickly. At the same time, a remarkable sequence of good shocks delivered rapid
output growth and low in‡ation.
       In fact, in FGR we …nd that all of the shocks went right for monetary policy during the

  28
    He stated in his con…rmation hearings: “[W]e allowed our system to take on in‡ationary biases which
threw us into such a structural imbalance that, in order to preserve the integrity of the system, the Federal
Reserve had to do what it did. Had it not acted in the way which it did at that time, the consequences would
have been far worse than what subsequently happened” (U.S. Senate, 1987, p. 35), quoted by Romer and
Romer (2004), p. 158.



                                                     32
1990s. A large string of positive and stable investment-speci…c technological shocks delivered
fast productivity growth, a falling intertemporal shifter lowered demand pressures, and labor
supply shocks pressured wages downward and, with them, marginal costs. This fantastic
concatenation of shocks accounted for the bulk of the great moderation. In FGR, we calculate
that, without changes in volatility, the great moderation would have been much smaller. The
standard deviation of in‡ation would have fallen by only 13 percent (instead of 60 percent in
the data), the standard deviation of output growth would have fallen by 16 percent (instead
of 46 percent in the data), and the standard deviation of the federal funds rate would have
fallen by 35 percent (instead of 39 percent in the data). That is, the moderation in in‡ation
‡uctuations would have been only one-…fth as big as in the data (and the counterfactual mean
would have actually been higher than in the data) and the moderation in output growth’s
standard deviation only one-third.
   We can push the argument even further. In FGR we build the counterfactual in which
the average    ;t   during Greenspan years is plugged into the model at the time of Burns’s
appointment. Then, we keep        ;t   at that level and we hit the model with exactly the same
shocks that we backed out from our estimation. This exercise is logically coherent, since
we are working with a DSGE model and, therefore, the structural and volatility shocks are
invariant to this class of interventions. We compute that the average monetary policy during
Greenspan’s years would not have made much of a di¤erence in the 1970s. If anything,
in‡ation would have been even slightly higher (6.83 percent in the counterfactual instead of
6.23 percent in the data). This …nding contrasts with our counterfactual in which Volcker
is moved to Burns-Miller’s time. In this counterfactual, in‡ation would have been just 4.36
percent. Summarizing: our reading of monetary policy during the Greenspan years is that
it was not too di¤erent from the policy in the Burns-Miller era; it just faced much better
shocks.
   Is this result credible? First, it is clear that is not a pure artifact of our model. A similar
result is found in Sims and Zha (2006). These authors, using structural vector autoregres-
sions with Markov-switching, which imposes many fewer cross-equation restrictions than our
analysis, do not …nd much evidence of di¤erences in monetary policy across time (actually,
Sims and Zha’s position is even stronger than ours, since they do …nd that monetary policy
was di¤erent even under Volcker). Second, there are hints in the data that lead us to believe
that the results make sense. At the start of the 1994 in‡ation scare, when there were no signs
of the new economy anywhere to be seen, Greenspan argued (Board of Governors FOMC
Transcripts, February 3-4, 1994, p. 55):
   “You know, I rarely feel strongly about an issue, and I very rarely sort of press this
Committee. But let me tell you something about what’s gnawing at me here. I am very


                                                 33
sympathetic with the view that we’ve got to move and that we’re going to have an extended
period of moves, assuming the changes that are going on now continue in the direction of
strength. It is very unlikely that the recent rate of economic growth will not simmer down
largely because some developments involved in this particular period are clearly one-shot
factors–namely, the very dramatic increase in residential construction and the big increase
in motor vehicle sales. Essentially the two of those have added one-shot elements to growth.
In the context of a saving rate that is not high, the probability is in the direction of this
expansion slowing from its recent pace, which at the moment is well over 4 percent and,
adjusting for weather e¤ects, may be running over 5 percent. This is not sustainable growth,
and it has nothing to do with monetary policy. In other words, it will come down. And the
way a 3 percent growth feels, if I may put it that way, is a lot di¤erent from the way the
expansion feels now.
   I would be very concerned if this Committee went 50 basis points now because I don’t
think the markets expect it... I’ve been in the economic forecasting business since 1948, and
I’ve been on Wall Street since 1948, and I am telling you I have a pain in the pit of my
stomach, which in the past I’ve been very successful in alluding to. I am telling you–and
I’ve seen these markets–this is not the time to do this. I think there will be a time; and
if the sta¤’s forecast is right, we can get to 150 basis points pretty easily. We can do it
with a couple of 1/2 point jumps later when the markets are in the position to know what
we’re doing and there’s continuity. I really request that we not do this. I do request that we
be willing to move again fairly soon, and maybe in larger increments; that depends on how
things are evolving.”
   We construe this statement as revealing a low       t:   We could present similar evidence
regarding the behavior of policy in the aftermath of the LTCM …asco or in the exit of the
2001 recession. But we feel the point has been made. We believe that our estimates are right:
monetary policy in the Greenspan years was similar to monetary policy under Burns-Miller.
Instead, time-varying structural shocks were the mechanism that played a key role in the
great moderation and the low in‡ation of 1987-2007.


7. What Are We Missing?

What is our model missing that is really important? The answer will tell us much about
where we want to go in terms of research and where we need to be careful in our reading of
monetary history. Of all of the potential problems of our speci…cation, we are particularly
concerned about the following.
   First, households and …rms in the model observe the changes in the coe¢ cients    t   and   yt



                                             34
when they occur. A more plausible scenario would involve …ltering in real time by the agents
who need to learn the stand of the monetary authority from observed decisions.29 A similar
argument can be made for the values of the standard deviations of all of the other shocks in
the economy. Unfortunately, introducing learning su¤ers from two practical di¢ culties. First,
it is not obvious what is the best way to model learning about monetary policy, especially in
a non-linear environment such as ours where simple least-square rules may not work properly.
Second, it would make the computation of the model nearly infeasible.
       Second, we assume that monetary policy changes are independent of the events in the
economy. However, many channels make this assumption untenable. For instance, each
administration searches for governors of the Board who conform with its views on the economy
(after all, this is what a democracy is supposed to be about). We saw how Heller discovered
that an administration could select governors to twist the FOMC toward its policy priorities.
This is a tradition that has continued. Meyer (2004, p. 17) describes the process for his
own appointment as one clearly guided by the desire of the Clinton administration to “make
monetary policy more accommodative and growth oriented.”As long as the party in power is a
function of the state of the economy, the composition of the FOMC will clearly be endogenous.
Similarly, changes in public perception of the dangers of in‡ation certainly weighed heavily
on Carter when he appointed Volcker to lead the Fed in 1979.
       Third, and a related issue to our two previous points, evolving beliefs about monetary pol-
icy might be endogenous to the developments of events and lead to self-con…rming equilibria.
This is a point emphasized by Cho, Williams, and Sargent (2002) and Sargent (2008).
       Fourth, our technological drifts are constant over time. The literature on long-run risk
has highlighted the importance of slow-moving components in growth trends (Bansal and
Yaron, 2004). It may be relevant to judge monetary policy to estimate a model in which we
have these slow-moving components, since the productivity slowdown of the 1970s and the
productivity acceleration of the late 1990s are bound to be re‡ected in our assessment of the
stance of monetary policy during those years. This links us back to some of the concerns
expressed in Orphanides (2002). At the same time and nearly by de…nition, there is very
little information in the data about this component.
       Fifth, our model is a closed economy. However, the considerations regarding exchange
rates have often played an important role in monetary policy making. For instance, during
the late 1960s, the United States fought an increasingly desperate battle to keep the Bretton

  29
     The di¢ culties in observing monetary policy changes can be illustrated by Axilrod’s description of a lunch
he had with Arthur Burns shortly after the announcement of Volcker’s new policy. According to Axilrod (page
100), Burns stated: “You are not really going to be doing anything di¤erent from what we were doing.”If an
insider like Burns had di¢ culties in …ltering Volcker’s behavior, it is hard to conclude anything but that the
average agents in the economy had di¢ culties as well.


                                                      35
Woods agreement alive, which included the Fed administering a program to “voluntarily”
reduce the amount of funds that American banks could lend abroad (Meltzer, 2010, p. 695)
or purchasing long-term Treasury bonds to help the British pound stabilize after its 1967
devaluation. The end of Bretton Woods also deeply in‡uenced policy makers in the early
1970s. Later, Volcker’s last years at the Fed were colored by the Plaza and Louvre Accords,
and the attempts to manage the exchange rate between the U.S. dollar and the Japanese yen.
       Finally, our model ignores …scal policy. The experience of the 1960s, in which there was
an explicit attempt at coordinating …scal and monetary policies, or the changes in long-
run interest rates possibly triggered by the …scal consolidations of the 1990s indicate that
the interaction between …scal and monetary policies deserves much more attention, a point
repeatedly made by Chris Sims (for example in Sims, 2009).


8. Concluding Remarks

The title of this paper is not only a tribute to Friedman and Schwartz’s (1971) opus magnum,
but also a statement of the limitations of our investigation. Neither the space allocated to us30
nor our own abilities allow us to get even close to Friedman and Schwartz’s achievements. We
have tried to demonstrate, only, that the use of modern equilibrium theory and econometric
methods allows us to read the monetary policy history of the U.S. since 1959 in ways that
we …nd fruitful. We proposed and estimated a DSGE model with stochastic volatility and
parameter drifting. The model gave us a clear punchline. First, there is ample evidence
of both strong changes in the volatility of the structural shocks that hit the economy and
of changes in monetary policy. The changes in volatility accounted for most of the great
moderation. The changes in monetary policy mattered for the rise and conquest of the great
American in‡ation. In‡ation stayed low during the next decades in large part due to good
shocks. When we go to the historical record and use the results of our estimation to read
and assess the documentary evidence, we …nd ample con…rmation, in our opinion, that the
model, despite all its limitations, is teaching us important lessons.
       As we argued in the previous section, we leave much unsaid. Hopefully, the results in this
paper will be enticing enough for other researchers to continue a close exploration of recent
monetary policy history with the tools of modern dynamic macroeconomics.

  30
    For an only slightly longer period than ours, Meltzer (2010) requires 1300 pages to cover the details of
the history of monetary policy in the U.S., including the evolution of operational procedures that we have
not even mentioned.




                                                    36
References
 [1] Abrams, B.A. (2006). “How Richard Nixon Pressured Arthur Burns: Evidence from the
     Nixon Tapes.”Journal of Economic Perspectives 20, 177-188.

 [2] Aruoba, S.B., and F. Schorfheide (2010). “Sticky Prices versus Monetary Frictions: an
     Estimation of Policy Trade-o¤s.”Forthcoming, American Economic Journal: Macroeco-
     nomics.

 [3] Aruoba, S.B., J. Fernández-Villaverde, and J. Rubio-Ramírez (2006). “Comparing So-
     lution Methods for Dynamic Equilibrium Economies.” Journal of Economic Dynamics
     and Control 30, 2477-2508.

 [4] Axilrod, S.H. (2009). Inside the Fed: Monetary Policy and its Management, Martin
     through Greenspan to Bernanke. The MIT Press

 [5] Bansal, R. and A. Yaron (2004). “Risks For The Long Run: A Potential Resolution of
     Asset Pricing Puzzles.”Journal of Finance 59, 1481-1509.

 [6] Board    of   Governors   (1994).  FOMC      Transcripts,  February   3-4.
     http://www.federalreserve.gov/monetarypolicy/files/FOMC19940204meeting.pdf.

 [7] Brayton, Flint, Andrew Levin, Ralph Lyon, and John C. Williams (1997). “The Evo-
     lution of Macro Models at the Federal Reserve Board.” Carnegie-Rochester Conference
     Series on Public Policy 47, 43-81.

 [8] Bremner, R.P. (2004). Chairman of the Fed: William McChesney Martin Jr, and the
     Creation of the American Financial System. The Yale University Press.

 [9] Burns, A.F. (1979). “The Anguish of Central Banking.”The 1979 Per Jacobbson Lecture.
     http://www.perjacobsson.org/lectures/1979.pdf.

[10] Christiano, L., M. Eichenbaum, and C.L. Evans (2005). “Nominal Rigidities and the
     Dynamic E¤ects of a Shock to Monetary Policy.” Journal of Political Economy 113,
     1-45.

[11] Cho, I„ N. Williams, and T.J. Sargent (2002). “Escaping Nash In‡ation.” Review of
     Economic Studies 69, 1-40.

[12] Cogley, T. and T.J. Sargent (2002). “Evolving Post-World War II U.S. In‡ation Dynam-
     ics.”NBER Macroeconomics Annual 2001, 331-388.

[13] Cogley, T. and T.J. Sargent (2005). “Drifts and Volatilities: Monetary Policies and
     Outcomes in the Post WWII U.S.”Review of Economic Dynamics 8, 262-302.

[14] Clarida, R., J. Galí, and M. Gertler (2000). “Monetary Policy Rules and Macroeconomic
     Stability: Evidence and Some Theory.”Quarterly Journal of Economics 115, 147-180.




                                           37
[15] Dotsey, M., R. G. King, and A.L. Wolman (1999). “State-Dependent Pricing and the
     General Equilibrium Dynamics of Money and Output.”Quarterly Journal of Economics
     114, 655-690.
[16] Ehrlichman, J. (1982). Witness to Power. Simon and Schuster.
[17] Fernández-Villaverde, J. and J. Rubio-Ramírez (2007). “Estimating Macroeconomic
     Models: A Likelihood Approach.”Review of Economic Studies 74, 1059-1087.
[18] Fernandez-Villaverde, J. and J. Rubio-Ramirez (2008). “How Structural Are Structural
     Parameters?”NBER Macroeconomics Annual 2007, 83-137.
[19] Fernández-Villaverde, J., P. Guerrón-Quintana, and J. Rubio-Ramírez (2010). “For-
     tune versus Virtue: Time-Variant Volatilities Versus Parameter Drifting in U.S. Data.”
     Mimeo, University of Pennsylvania.
[20] Fisher, J., (2006). “The Dynamic E¤ects of Neutral and Investment-Speci…c Technology
     Shocks.”Journal of Political Economy 114, 413-52.
[21] Friedman, M. and A.J. Schwartz (1971). A Monetary History of the United States, 1867-
     1960. Princeton University Press.
[22] Goodfriend, M. and R. King (2007). “The Incredible Volcker Disin‡ation.” Journal of
     Monetary Economics 52, 981-1015.
[23] Greenwood, J., Z. Herkowitz, and P. Krusell (1997). “Long-Run Implications of
     Investment-Speci…c Technological Change.”American Economic Review 87, 342-362.
[24] Hall, R. (1997). “Macroeconomic Fluctuations and the Allocation of Time.” Journal of
     Labor Economics, 15 (1), 223-250.
[25] Hetzel, R.L. (2008). The Monetary Policy of the Federal Reserve, A History. Cambridge
     University Press.
[26] Hurwicz, L. (1962). “On the Structural Form of Interdependent Systems.” Logic,
     Methodology and Philosophy of Science, Proceedings of the 1960 International Congress,
     232-39.
[27] Jaimovich, N. and H. Siu (2009). “The Young, the Old, and the Restless: Demographics
     and Business Cycle Volatility.”American Economic Review 99, 804–826.
[28] Judd, K.L. (1998). Numerical Methods in Economics. MIT Press.
[29] Justiniano A. and G.E. Primiceri (2008). “The Time Varying Volatility of Macroeco-
     nomic Fluctuations.”American Economic Review 98, 604-641.
[30] Kettl, D. (1986). Leadership at the Fed. Yale University Press.
[31] Kim, C. and C.R. Nelson (1998) “Has the U.S. Economy Become More Stable? A
     Bayesian Approach Based on a Markov-Switching Model of the Business Cycle.”Review
     of Economics and Statistics 81, 608-616.

                                             38
[32] Kiyotaki, N. and R. Wright (1989). “On Money as a Medium of Exchange.” Journal of
     Political Economy 97, 927-54.

[33] Lagos, R. and R. Wright (2005). “A Uni…ed Framework for Monetary Theory and Mon-
     etary Analysis”. Journal of Political Economy 113, 463-484.

[34] Lubick, T. and F. Schorfheide (2004). “Testing for Indeterminacy: An Application to
     U.S. Monetary Policy.”American Economic Review 94, 190-217.

[35] Maisel, S. (1973). Managing the Dollar. Norton.

[36] McConnell, M.M. and G. Pérez-Quirós (2000). “Output Fluctuations in the United
     States: What Has Changed Since the Early 1980’s?” American Economic Review 90,
     1464-1476.

[37] Meltzer, A. (2010). A History of the Federal Reserve, Volume 2 (Books 1 and 2). The
     University of Chicago Press.

[38] Meyer, L. H. (2004). A Term of the Fed: an Insiders View. Harper Collins.

[39] Orphanides, A. (2002). “Monetary Policy Rules and the Great In‡ation.” American
     Economic Review 92, 115-120.

[40] Romer, C.D. and D. Romer (1989). “Does Monetary Policy Matter? A New Test in the
     Spirit of Friedman and Schwartz”NBER Macroeconomics Annual 4, 121-170.

[41] Romer, C.D. and D. Romer (2002a). “A Rehabilitation of Monetary Policy in the 1950s.”
     American Economic Review 92, 121-127.

[42] Romer, C.D. and D. Romer (2002b). “The Evolution of Economic Understanding and
     Postwar Stabilization Policy.”In Rethinking Stabilization Policy (Federal Reserve Bank
     of Kansas City, 2002), 11-78.

[43] Romer, C.D. and D. Romer (2004). “Choosing the Federal Reserve Chair: Lessons from
     History”Journal of Economic Perspectives 18, 129-162.

[44] Samuelson, P.A. and R.M. Solow (1960). “Analytical Aspects of Anti-In‡ation Policy.”
     American Economic Review 50, 177-194.

[45] Sargent, T.J. (2008). “Evolution and Intelligent Design.” American Economic Review
     98, 5-37.

[46] Schmitt-Grohé, S. and M. Uribe (2005). “Optimal Fiscal and Monetary Policy in a
     Medium Scale Macroeconomic Model”. NBER Macroeconomic Annual 2005, 382-425.

[47] Schreft, S. (1990). “Credit Controls: 1980.”Federal Reserve Bank of Richmond Economic
     Review 1990, 6, 25-55.

[48] Sims, C.A. (2009). “Price Level Determination in General Equilibrium.”Plenary talk at
     SED 2009.

                                            39
[49] Sims, C.A. and T. Zha (2006). “Were There Regime Switches in U.S. Monetary Policy?”
     American Economic Review 96, 54-81.

[50] Smets, F. and R. Wouters (2003). “An Estimated Dynamic Stochastic General Equi-
     librium Model of the Euro Area”. Journal of the European Economic Association 1,
     1123-1175.

[51] Stock, J.H. and M.W. Watson (2002). “Has the Business Cycle Changed, and Why?”
     NBER Macroeconomics Annual 17, 159-218.

[52] Stock, J.H. and M.W. Watson (2007). “Why Has U.S. In‡ation Become Harder to Fore-
     cast?”Journal of Money, Credit and Banking 39, 3-33.

[53] Tobin, J. (1974). “Monetary Policy in 1974 and Beyond.”Brookings Papers on Economic
     Activity 1974:1, 219-232.

[54] U.S. Senate (1979). Committee on Banking, Housing, and Urban A¤airs. Nomination of
     Paul A. Volcker. Washington, D.C.: U.S. Government Printing O¢ ce.

[55] U.S. Senate (1987). Committee on Banking, Housing, and Urban A¤airs. Nomination of
     Alan Greenspan. Washington, D.C.: U.S. Government Printing O¢ ce.

[56] Volcker, P. (1990). “The Triumph of Central Banking?”The 1990 Per Jacobbson Lecture.
     http://www.perjacobsson.org/lectures/1990.pdf.

[57] Volcker, P. and T. Gyohten(1992). Changing Fortunes. Crown

[58] Wallace, N. (2001). “Whither Monetary Economics?” International Economic Review
     42, 847-869.

[59] Weintraub, R. (1977). “Monetary Policy and Karl Brunner.” Journal of Money, Credit
     and Banking 9, 255-258.

[60] Woodford, M.D. (2003). Interest and Prices. Princeton University Press.




                                            40
