                                NBER WORKING PAPER SERIES




                    PREFERENCES, SELECTION, AND VALUE ADDED:
                            A STRUCTURAL APPROACH

                                         Şaziye Pelin Akyol
                                           Kala Krishna

                                        Working Paper 20013
                                http://www.nber.org/papers/w20013


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                     March 2014




We would like to thank Nikhil Agarwal, Verónica Frisancho, Paul Grieco, Susumu Imai, Sung Jae
Jun, Corinne Jones and Cemile Yavas for comments on an earlier draft. We would also like to thank
participants of the CES-IFO Area Conference on Applied Microeconomics 2013 and the Penn State
Applied Econ JMP Conference 2013 for their useful comments on an earlier draft. We benefited from
the helpful comments of seminar participants at University of Kentucky and Warwick University.
All errors are our own. The views expressed herein are those of the authors and do not necessarily
reflect the views of the National Bureau of Economic Research.

At least one co-author has disclosed a financial relationship of potential relevance for this research.
Further information is available online at http://www.nber.org/papers/w20013.ack

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2014 by Şaziye Pelin Akyol and Kala Krishna. All rights reserved. Short sections of text, not to
exceed two paragraphs, may be quoted without explicit permission provided that full credit, including
© notice, is given to the source.
Preferences, Selection, and Value Added: A Structural Approach
Şaziye Pelin Akyol and Kala Krishna
NBER Working Paper No. 20013
March 2014
JEL No. I20,I21

                                            ABSTRACT

This paper investigates two main questions: i) What do applicants take into consideration when choosing
a high school? ii) To what extent do schools contribute to their students’ academic success? To answer
these questions, we model students’ preferences and derive demand for each school by taking each
student’s feasible set of schools into account. We obtain average valuation placed on each school from
market clearing conditions. Next, we investigate what drives these valuations by carefully controlling
for endogeneity using a set of creative instruments suggested by our model. Finally, controlling for
mean reversion bias, we look at each school’s value-added.

We find that students infer the quality of a school from its selectivity and past performance on the
university entrance exam. However, the evidence on the value- added by schools shows that highly
valued or selective schools do not have high value- added on their students’ academic outcomes.


Şaziye Pelin Akyol
Department of Economics
303 Kern Graduate Building
University Park, PA 16802
spd161@psu.edu

Kala Krishna
Department of Economics
523 Kern Graduate Building
The Pennsylvania State University
University Park, PA 16802
and NBER
kmk4@psu.edu




An online appendix is available at:
http://www.nber.org/data-appendix/w20013
    “The C student from Princeton earns more than the A student from Podunk not mainly
because he has the prestige of a Princeton degree, but merely because he is abler. The golden
touch is possessed not by the Ivy League College, but by its students.”
    Shane Hunt, “Income Determinants for College Graduates and the Return to Educational
Investment,” Ph.D. thesis, Yale University, 1963, p. 56.



1       Introduction

    In much of the world, elite schools are established and very often subsidized by the
government. Entry into these schools is based on performance in open competitive entrance
exams. Applicants leave no stone unturned in their quest for higher scores on these entrance
exams creating enormous stress. The belief seems to be that getting into these schools
is valuable, presumably because future outcomes are better in this event. Students, it is
argued, will do better by going to an exam school where they are challenged by more difficult
material and exposed to better peers. What actually happens? Students of these elite exam
high schools, without a doubt, do better on college entrance exams and are more likely to
be placed at the best university programs. But is this due to selection or value-added by
these schools? It is quite possible that the success of students from exam schools creates the
belief that these schools add value. This belief results in better students sorting into exam
schools so that students from these schools do better, which perpetuates the belief system.
    The usual way of ranking schools is in terms of their selectivity, how hard they are to
get into in terms of some performance measure like the SATs in the US1 , or in terms of how
well students who graduate from them do as measured by wages, eminence in later life, or
admission into further schooling. However, schools may do well in all of these dimensions
merely because they admit good students and not because they provide value added and

    1
     Schools are sometimes less than honest: some inflate their statistics on the performance of their entering
class. Some schools manipulate the system by keeping their class size small, thereby having high SATs and
looking very selective. See “Academic integrity should count in rankings” in the Kansas City Star, 2/8/2013.
http://www.centredaily.com/2013/02/12/3499088/editorial-academic-integrity-should.html

                                                      2
thereby improve the performance of the students they admit.2 How can we control for such
selection and estimate value added? In this paper, we develop a simple model of student’s
school preferences and use it to understand equilibrium sorting across schools. We estimate
preferences with a view to understanding what students seem to value in a school. Finally,
we estimate the extent to which a school contributes to their students’ academic success.
   Turkey is a good place to look for answers to these questions for a number of reasons.
To begin with, the Turkish admissions system is exam-driven. Admissions are rationed on
the basis of performance on open competitive national central exams at the high school and
university level. In addition, the allocation of students to high schools is based on strategy-
proof Deferred Acceptance algorithm on the high school entrance exam which eliminates
incentive problems.3 Second, as education is highly subsidized in public institutions, educa-
tional options outside the country or at private institutions are much more expensive so that
these exams are taken seriously by the applicants.4 When the stakes are high, as in Turkey,
it is less likely that outcomes are driven just by noise.
   We develop a way to answer the questions of interest by taking a more structural approach
than much of the literature. Using data on the admission cutoff scores, the size of each high
school class, and the overall distribution of scores, we estimate a nested logit model of
preferences over high schools taking into account that exam schools only admit the highest
scoring students who apply. Thus, students choose their best school from schools whose
cutoff is below their score. We do this in multiple steps. First, by using information on
the minimum cutoff scores, we derive demand for each school conditional on the correlation
of shocks within a nest. We obtain the mean valuation for each school by setting demand
equal number of available seats. Second, we pin down the correlation of shocks within a
nest using information on the maximum and minimum cutoff scores in each school. This
   2
      There has recently been considerable effort in determining value-added by a school as part of the
accountability in the No Child Left Behind legislation. See Darling et al. (2012) for a critique of the
approach usually taken.
    3
      Students prefer to report their true preferences, no matter what other students report.
    4
      Many experiments, especially non-natural ones, rely on performance measures or evaluations that do
not matter for the student, which makes the effects hard to interpret.

                                                   3
twist, to our knowledge, is novel. The idea is quite simple. If preference shocks are perfectly
correlated within a nest, then preferences are purely vertical and the minimum score in the
most valued school in the nest cannot be lower than the maximum score in the second most
valued school in the nest. Thus, the extent of overlap in the scores between schools within a
nest identifies the correlation in preference shocks in the nest. Third, to see what applicants
care about in a school, we regress mean valuation of schools on the schools’ characteristics
using clever instruments suggested by our model to correct for endogeneity. We use the
data on the overall distribution of scores on the high school entrance exam, along with
the estimated preference parameters to allocate students to high schools and obtain the
simulated distribution of students’ scores on the high school entrance exam in each school.
Then, by using information on university entrance exam scores and the simulated high school
entrance exam scores in a school, we obtain a contaminated estimate of the value-added by
a school. The contamination comes from mean reversion and is especially severe at the top
and bottom of the school hierarchy. This mean reversion is a consequence of randomness in
performance. Students in the best (worst) schools disproportionately include those who are
just lucky (unlucky) so that their performance in the university entrance exams will tend to
be below (above) that in the high school entrance exams even if there is zero value added.
We use simulation-based methods as well as information on each student in a single school
to estimate the average value-added by a school while controlling for mean reversion. Note
that the extent of the mean reversion depends on both preferences and the extent of noise
in the high school entrance exam score so that correcting for it can only be done by taking
a structural approach.
   Our results suggest that students care about a school’s selectivity, its students’ past
performance on the university entrance exam, and they value elite science schools highly.
However, the evidence on the value-added by schools shows that highly valued schools do
not all have high value-added on their students’ academic outcomes. Some have negative
value added while others have positive value added. Our results suggest that students like


                                              4
more selective, better performing elite schools so that better students are sorted into these
schools, even when they need not add value to the students in terms of their performance on
the university entrance exam. This may also be because of signaling and/or the consumption
value of going to such schools.
   Exam schools in Turkey are given more funding per student, and they have better teacher
to student ratios. The better off are also more likely to be able to get into these schools (For
example, see Caner and Okten (2012)) so that such funding is likely to be a regressive force.5
Providing funding based on value-added by a school may make such funding less regressive
as well as better align the incentives of schools and society. Though our data is on Turkey,
the issues raised in this paper are of universal interest.
   We proceed as follows. First, we relate our work to the literature. In Section 2, we
provide the necessary background regarding the Turkish system and the data. Section 3 lays
out the model, the estimation of preferences and the results. In Section 4, we estimate the
value-added by the schools. Then, we conclude. Additional figures, tables and details about
the estimation strategy can be found in the Appendix.


1.1       The Literature

   There is a large literature that deals with school choice and school effects in the US, as
well as in other developed and developing countries. In the US, the consensus seems to be
that attending a better school does not have much of an impact on a student’s academic
achievement. Abdulkadiroglu, Angrist, and Pathak (2011), and Dobbie and Fryer (2011)
investigate the effects of attending Boston and New York exam schools by using a Regression-
Discontinuity approach. They look at students who were just below the cutoff and those
that were just above and find no significant effect of being above the cutoff and thereby
going to exam schools.
   Cullen, Jacob and Levitt (2005) and (2006) use data from randomized lotteries that

   5
       This regressive nature is common across countries as the better off are advantaged in many ways.

                                                      5
determine the allocation of students in the Chicago public school system. Students who win
the lottery attend the better schools. They find that winning this lottery does not improve
students’ academic performance. Clark (2010) investigates the effect of attending a selective
high school (Grammar School) in the UK (where selection is based on a test given at age 11
and primary school merit) and finds no significant effect on performance in courses taken by
students, although the probability of attending a university is positively affected.
    Dale and Krueger (2002) and (2011) look at the effect of attending elite colleges on labor
market outcomes. Their work is among the most careful and well-cited on the topic. Much
of the work in this area controls for selection by using a two step Heckman approach or
matching estimators. Unobservables are typically controlled for by allowing the error terms
in the selection and outcome variables to be correlated.6 What is unique about their work
is that they control for selection by controlling for the colleges to which the student applied
and was accepted. The former provides an indication of how the student sees himself while
the latter provides a way of controlling for how the colleges rank the student. Intuitively,
the effect of selective schools on outcomes is identified by the performance of students who
go to a less selective school despite being admitted to a more selective one, relative to
those who go to the more selective one. Of course, if this choice is based on unobservables,
this estimate would be biased.7 They find that black and Hispanic students in addition to
students from disadvantaged backgrounds, less-educated or low-income families, do seem to
gain from attending elite colleges. However, for most students the effect is small and fades
over time.
    In contrast to these results, Pop-Eleches and Urquiola (2013) and Jackson (2010) estimate
the effect of elite school attendance in Romania and Trinidad and Tobago, respectively. They
find a large positive effect on students’ exam performance in the university entrance exams.
    From the school choice literature, Hastings, Kane, and Staiger (2009) and Burgess et

   6
    See Frisancho and Krishna (2012) for an application using Indian data.
   7
    For example, if confident students go to the selective school and less confident ones do not, and confident
students do better, the effect of selective schools would be overestimated.

                                                      6
al. (2009) investigate what parents care about in a school using data from the Charlotte-
Mecklenburg School District and Millennium Cohort Study (UK), respectively. Hastings,
Kane, and Staiger (2009) take a structural approach and estimate a mixed logit model
of preferences. A major contribution of their work is to use information on the stated
preferences for schools and compare these to what was available to them to back out the
weight placed on factors like academics, distance from home, and so on. They are then able
to see whether the impact of a school differs according to “type”. For example, they can
determine whether students who put a high value on academics do better in a good school
than students who place a high value on being close to the school. If such differences are
large, the reduced form effects estimated for attending good schools could be biased if such
selection is not properly accounted for. If students in developing countries place greater
value on good schools than do students from developed countries, this insight could explain
why we see such different results for attending better schools between the two. Burgess et
al. (2009) also compare the first choice school to the set that was available, constructed
by the authors by using students’ residence areas, and estimate trade-offs between school
characteristics.
   Although we don’t estimate peer effects separately, our estimate of the school’s value-
added includes peer effects. Ding and Lehrer (2007) estimate peer effects using data from
a county in China, where students are allocated to high schools based on a criteria that is
mainly based on students’ entrance exam scores.8 They find a positive peer effect on students’
college entrance exam scores. Several other papers (Hanushek et al. (2003), Hoxby (2000),
Kang (2007), Zabel (2008), and Zimmerman (2003)) also study peer effects on academic
achievements.9 Duflo, Dupas and Kremer (2011) suggest that the behavior of teachers is
crucial. They use data from a randomized experiment in Kenya to investigate how tracking
students affects outcomes, and find that tracking helps both high achieving and low achieving
students if teachers adjust their instruction level, but not otherwise.
   8
       This differs slightly from the Turkish system where allocation solely depends on exam scores.
   9
       Epple and Romano (2010) present a detailed survey about peer effects.

                                                       7
    In sum, the evidence available suggests that selective schools/tracks can have a positive
impact on disadvantaged groups who care about quality schooling and would otherwise have
had a low quality education, or who live in developing countries.
    Our contribution to the literature is twofold. First, much of the work described above is
reduced form rather than structural. An advantage of the slightly more structural approach
taken here is that we can estimate preferences, understand what seems to drive them, look
at sorting over schools, as well as estimate the value-added by a school. In other words, we
examine the whole process and not just one of its components. Second, despite the lack of
panel data, i.e., not having the high school entrance exam score and the college entrance
exam score for each student, we show how one can use fairly limited data on each high school,
along with data on university entrance exam takers along with the model, to get around this
deficiency. That is to say, our approach allows us to economize on data in the estimation.
With richer data that includes information on each students’ performance in both exams, as
well as some background information on them, we could estimate students’ preferences using
standard techniques in industrial organization such as those developed in Berry, Levinsohn
and Pakes (1995), or variations that also use information on stated preferences as in Hastings,
Kane and Staiger (2009). This would help mitigate the impact of unobservables that remain
an issue even when selection is controlled for as in Dale and Krueger (2002).



2     Background

    In Turkey, competitive exams are everywhere. Unless a student chooses to attend a
regular public high school, he must take a centralized exam at the end of 8th grade to
get into an “exam school”. These are analogous to magnet schools in the US, though the
competition for placement into them is national and widespread, rather than local as in the
US. After high school there is an open competitive university entrance exam given every
year. So many students retake these university entrance exams that only a third of the 1.5



                                              8
                                        Figure 1: Distribution of ÖSS-SAY score




                             .06
                             .04
                   density
                             .02
                             0




                                   80   90    100   110    120     130 140 150    160   170   180    190
                                                                 OSS−SAY score

                                             Science Lycee                       Anatolian−Science Track
                                             Public Regular−Science Track
                                   Source: ÖSYM data on 2002 ÖSS applicants




million students taking the exam in a given year do so for the first time. Most students go to
cram schools (dershanes) to prepare for the university entrance exam. Much of high school
is also spent preparing students for this exam. Such exams weaken the formal schooling
system as schools focus on teaching to the exam rather than on the curriculum or fostering
the ability to think. If exam schools, in fact, have little value-added, then the system itself
may have adverse welfare effects. This is especially so if such schools are subsidized relative
to the alternatives, as is often the case.10 In this event, students expend possibly wasteful
effort to capture these rents which reduces welfare.11
    Students from exam schools do perform much better in university entrance exams. Figure
1 shows the distribution of average scores (ÖSS-SAY) in the university entrance exam of
science track students coming from the different kinds of high schools. Science high schools
are clearly doing better, followed by the almost as selective Anatolian high schools, while

  10
      The best teachers are allocated to these schools, their facilities are better, and their class sizes are
smaller than that of regular schools. In addition, Caner and Ökten (2012) shows that school subsidies are
regressive as better off students tend to do better on exams and so go to better schools which are more
highly subsidized.
   11
      See Krishna and Tarasov (2013) for more on this subject.

                                                                    9
regular Public schools seem to do the worst. However, this says little about the contribution
of exam schools in terms of value-added.


2.1    The Institutional Structure

   The educational system in Turkey is regulated by the Ministry of Education. All children
between the ages of 6 and 14 must go to school. At 14 they take the high school entrance
exam (OKS) if they want to be placed in public exam schools. Performance on this exam
determines the options open to a student. The better the performance, the greater the
number of schools with a cutoff score below what the student has obtained. There are
four types of public exam schools: Anatolian high schools, Anatolian Teacher Training high
schools, Science high schools, and Anatolian Vocational high schools.
   Anatolian high schools place a strong emphasis on foreign language education although
their specific goals may vary across the different types of Anatolian schools. The main goal
of Anatolian high schools is to prepare their students for higher education while teaching
them a foreign language at a level that allows them to follow scientific and technological
developments in the world. Anatolian Vocational high schools aim to equip their students
with skills for certain professions and prepare them both for the labor market and higher
education. Anatolian Teacher Training high schools train their students to become teachers
though they can choose other paths as well.
   The most prestigious of the exam schools are the Science high schools. These were
established in the mid 1980s to educate the future scientists of Turkey and initially accepted
very few students. Over the next decade, the success of their students on the university
entrance exams, as well as the rigorous education these schools were famous for, created
considerable demand for these schools and they spread throughout the country.
   In public high schools, Anatolian high schools and Anatolian Teacher Training high
schools, students can choose between four tracks: the Science track, the Turkish-Math track,
the Social Science track and the Language track. In Science high schools they must take the


                                              10
                               Figure 2: Education System in Turkey


                                          8th grade


                                                            High School Entrance
                                                                   Exam




                                            Anatolian                                Anatolian
                    Non-exam             Teacher Training     Anatolian   Science    Vocational
                     Schools                 Schools           Schools    Schools     Schools




                 Turkish-       Social                       Science
                                             Language                      Science
                  Math         Science                        Track
                                              Track                         Track
                  Track         Track




                                               11th grade
                                           University Entrance
                                             Exam (ÖSS )



science track. In Anatolian Vocational high schools there are no tracks, which puts them a
little outside the mainstream. All of this is depicted in Figure 2.
   After 11th grade, students who wish to pursue higher education take a centralized na-
tionwide university entrance exam (ÖSS), which is conducted by the Student Selection and
Placement Center (ÖSYM). This exam is highly competitive and placement of students into
colleges is based on their ÖSS score, high school grade point average (GPA), and their pref-
erences. For each student a placement score is constructed as a weighted average of the
ÖSS score and the GPA and students choose from schools with cutoffs no higher than their
placement scores.
   Below, we use high school and university entrance exam scores to infer the value-added
of schools. For this reason, it is important to explain what these exams consist of and how
similar they are. Both high school and university entrance exams are multiple choice tests
that are held once a year. The high school entrance exam is taken by students at the end


                                                        11
of eighth grade. There are four tests, Turkish, social science, math, and science, with 25
questions on each test. Students are given 120 minutes to answer the 100 questions. The
University entrance exam is similar. It is a nationwide central exam with four parts, Turkish,
social science, math, and science, with 45 questions in each part. Students are given 180
minutes. The questions on both exams are based on the school curriculum and are meant
to measure the ability to use the concepts taught in school. To discourage guessing, there is
negative marking for incorrect answers in both exams.


2.2     The Data

   The data we use comes from several public sources. To measure students’ academic
performance at the end of high school, we rely on information on the performance of each
school on the university entrance exam from 2002 to 2007. This information is published
by the Student Selection and Placement Center (ÖSYM) and is made available to schools
and families so that they are informed about the standing of each school. The information
includes the number of students who took university entrance exam from each school, as well
as the mean and standard deviation of their scores in each field of the exam.
   A student’s performance in the high school entrance exam is seen as a (noisy) measure
of his performance prior to attending high school. We obtained data on the minimum and
maximum scores and on the number of seats in 2001 for each exam high school from the
Ministry of Education’s website.12 The summary statistics for these variables are presented
in Table A.5. We also collected data on the average ÖSS performance of each high school
on each part of the exam in the previous year, 2000, from ÖSYM’s Results booklet for that
year, which is publicly available from their website. This is used as one possible quality
dimension along which schools vary. Additional high school characteristics were collected
from the Ministry of Education’s website (education language, dormitory availability, and
location) and the high schools’ websites (age of the schools). We use this data along with
  12
     This data was collected using the website http://archive.org/web/web.php, which provides previous
versions of websites.

                                                 12
the score distribution of all students who took the high school entrance exam in 2005 (see
Table A.6) in our analysis below. Ideally we would have liked to have this information for
2001, but as this was not available and as these distributions are very stable, we use data
from 2005.
     In the next section we show how to use information on the allocation process, seats avail-
able, the distribution of scores overall on the high school entrance exam, and the preference
structure to back out the mean valuation placed on each high school.



3        The Model

     Seats in public exam schools are allocated according to students’ preferences and their
performance on a centralized exam (conducted once a year). All schools have an identical
ranking over students based on their test scores. Each exam school has a fixed quota,
qj , which is exogenously determined.13 The allocation process basically assigns students to
schools according to their stated preferences, with higher scoring students placed before lower
scoring ones. Students know past cutoffs for schools when they put down their preferences.
They are allowed to put down up to 12 schools.14
     We model preferences as follows. Student i’s utility from attending school j takes the
form


                                   Uij (Xj , ξj , εij ; β) = βXj + ξj + εij

     where Xj are the observed school characteristics, ξj are the unobserved school characteris-
tics, and εij is a random variable which has a Generalized Extreme Value (GEV) distribution.
    13
      In general, the seats available are close to the size of the graduating class as schools are capacity
constrained.
   14
      Students do face a location restriction in listing their Anatolian high school preferences. They are not
allowed to list preferences on Anatolian high schools in Ankara, İstanbul, İzmir, and their current city: they
have to pick one of these locations and make all their Anatolian high school preferences from their chosen
location. However, if preferences are stated after the score is known, and cutoffs are stable over time (as in
our setting) this restriction should not have any impact. A student would put his most preferred school with
a cutoff below his score at the top of his list and be assigned there.

                                                      13
Let δj denote the school specific mean valuation where


                                             δj = βXj + ξj

so that


                                     Uij (Xj , ξj , εij , β) = δj + εij

   This structure implies that variation in individual preferences comes from the error term,
conditional on the students having the same feasible choice set. If two alternatives are in the
same nest, their errors are allowed to be correlated. Otherwise, the errors are assumed to be
independent.
   In general, the cumulative distribution function of ε = hεi0 , εi1 , . . . , εiN i is given by

                                                                                      !λk 
                                                          K
                                                          X     X              εij
                   H(εi0 , εi1 , . . . , εiN ) = exp −                exp(−       )               (1)
                                                          k=1   j∈Bk
                                                                               λk


where Bk is the set of alternatives within nest k, K is the number of nests, and λk measures
the degree of independence among the alternatives within nest k (see Train (2009)). As
λk increases, the correlation between alternatives in nest k decreases. If λk is equal to 1,
there is no correlation between alternatives within nest k, whereas as λk goes to 0, there
is perfect correlation among all alternatives in the same nest. In this case, the choice of
alternatives for any individual is driven by the δj component alone so that there is pure
vertical differentiation among schools in a nest.
   We partition the set of high schools in Turkey according to their type and location.
Figure 3 shows the nesting structure we adopt. Since we want to allow for vertical and
horizontal differentiation, it makes sense to put similar schools in the same nest. Thus, at
the upper level of the nest, students have seven options: Science high schools, Anatolian
Teacher Training high schools, Anatolian high schools in Ankara, in İstanbul and in İzmir,


                                                    14
                                    Figure 3: School Choice in Turkey




                   Local      Anatolian    Anatolian    Anatolian    Anatolian   Anatolian   Science
                  Schools     Vocational   in Ankara   in Istanbul    in Izmir    Teacher    Schools




            Regular    Local
            Public    Anatolian
            Schools



Anatolian Vocational high schools, and the local school option. The local school option
for a student includes a local Anatolian school and a public regular high school which is
modeled as the outside option. Since computational intensity will increase with the size of
the choice set, we aggregate Anatolian Vocational high schools into five subgroups according
to their types with seats equal to the sum of seats of schools in that subgroup. We define
the maximum and minimum score of each subgroup as the maximum and minimum of the
cutoff scores of the schools in that subgroup. Other nests include all schools in Turkey of
a given type: 91 Teacher Training high schools, 48 Science high schools, 24 Anatolian high
schools in Ankara, 38 Anatolian high schools in İstanbul, and 18 Anatolian high schools in
İzmir.15 Thus, we have 226 options overall.16
    Each student chooses a school that maximizes his utility given his feasible set of schools,
which is determined by his own score, si , and the cutoff scores of each school


                                            max Uij (Xj , ξj , εij ; β)
                                            j∈Fi



    where

  15
      These schools are located in the center of the Ankara, İstanbul, and İzmir. Anatolian high schools
located in a town in the provinces are defined as local Anatolian high schools by Ministry of Education.
   16
      We ignore private exam high schools as they comprise less than 5% of the total and there is no data on
them.

                                                        15
                                                Fi = {j : cj ≤ si }

The feasible set of a student, Fi , includes all the schools whose cutoff score is below the
student’s score. Given the demand for each school and the number of seats available, the
cutoff score, cj , is endogenously determined in equilibrium.
      Let the set of N schools be partitioned into K mutually exclusive sets (nests) where the
elements of each of these sets correspond to schools within that nest. For example, Bk , where
k = 1, 2, . . . , K, would have as its elements all schools that are in nest k. If there were no
rationing, the probability that school j in nest k was chosen by student i would be given
by17
                                                                                       !λk −1
                                                        δ
                                                                         exp( λδkl )
                                                                  P
                                                   exp( λjk )
                                                                  l∈Bk
                                    Pij (δ, λ) =                                  λn
                                                       K
                                                             
                                                                       exp( λδnl )
                                                       P         P
                                                       n=1      l∈Bn

which would be equivalent to the fraction of students whose best alternative was alternative
j.
      However, students’ choices are constrained by the cutoff scores in each school, cj , and by
their own exam performance, si . Suppose that there are N + 1 choices (including the outside
option) and let the cutoff scores for each alternative be ordered in ascending order


                                      c0 = 0 < c1 < c2 < . . . < cN −1 < cN

where 0 indexes the outside option. Students whose score is in the interval [cm , cm+1 ) have
the first m schools in their feasible choice set and we call this interval Im . Similarly, students
whose scores are below c1 have scores in interval I0 and have their choice set containing only
the outside option, while students with si ≥ cN get to choose from all the N + 1 alternatives
and have scores in interval IN . Thus, the probability that student i with a score in interval

     17
          The derivation of the nested logit probability, Pij , can be found in the Appendix A.1

                                                             16
Ij chooses school t, t ≤ j, in nest k from his feasible set will be

                                                                                    k −1
                                                                             λ                       
                                             δ                           δ
                                       exp( λt )                  exp( λ l
                                                          P
                                                                               )
                                      
                                                                                                       
                                                                                                        
                                              k        l∈Bk (Ij )         k                             
                    Pjt(k) (δ, λ) =         Kj
                                                                              λn         if si ∈ Ij
                                                                        δ
                                                                                                       
                                                                   exp( λ l )
                                           P            P                                              
                                                                                                      
                                                                         n
                                           n=1        l∈Bn (Ij )



where bold variables denote vectors and where Bk (Ij ) denotes the restriction placed on
the elements of nest k when the individuals’ score is in the interval Ij . λk is the extent of
independence between alternatives in nest k, and Kj is the total number of nests available
to a student whose score is in interval Ij .
   Aggregate demand for each school will thus depend on the distribution of scores, F (s),
the minimum entry cutoff scores of all other schools whose cutoff score is higher, and the
observed and unobserved characteristics of all schools. Using the equilibrium cutoff scores
and the students’ score distribution we can get the density of students that are eligible for
admission to each school.
   For simplicity, we will write the demand function for school j in nest s, dj(s) (δ, λ), as
dj(s) . The demand for school N, the best school, which is in nest k comes only from those
in IN :


                                 dN (k) = PN N (k) (δ, λ)[1 − F (cN )]



   Only students with scores above cN have the option to be in school N which gives the
term [1 − F (cN )]. In addition, N in nest k has to be their most preferred school; hence the
term PN N (k) (δ, λ). Similarly, the demand for school j which is in nest s comes from those in




                                                           17
Ij ,... IN


               dj(s) = PN j(s) (δ, λ)[1 − F (cN )]

                         +P(N −1)j(s) (δ, λ)[F (cN ) − F (cN −1 )]

                         +.. + P(j)j(s) (δ, λ)[F (cj+1 ) − F (cj )]
                         N
                         X −1
                     =          Pwj(s) [F (cw+1 ) − F (cw )] + PN j(s) (δ, λ)[1 − F (cN )]
                          w=j


    Students with higher scores have more options open to them which is what makes higher
scores valuable to a student in this setting.


3.1      Estimation Strategy and Results

    Given the preference parameters and the number of seats in each school, the real world
cutoffs are determined by setting the demand for seats, as explained above, equal to their sup-
ply and obtaining the market clearing score cutoffs. This is not what we will do. For us, the
cutoffs and the number of seats are data. We want to use this data and the nesting structure
imposed to obtain the preference parameters. In particular, we want to estimate the coeffi-
cients of school characteristics (β) and the parameter vector λ,where λ = [λ1 , λ2 , . . . , λK ],
that best fit the data and respect the solution of the model that equates demand (d) with
supply (q).
    We do this in three steps. In Step 1, we back out the values of δj for each school j for a
given λ. In essence, the minimum cutoff in each school denoted by the vector c = (c1 , ..cN ),
the number of seats in each school denoted by the vector q = (q1 , ..qN ), together with the
market clearing conditions of the model, pin down the mean valuation of each school for a
given vector, λ = (λ1 ,...λK ). In step 2, we find λ so as to best match the extent of overlap in
the scores of schools in the same nest. A higher correlation in the errors within a nest means
that there is less of a role for preference shocks to play in choice, so that preferences are
driven by the non-random terms. This corresponds to having more of a vertical preference

                                                   18
structure. As a result there is less overlap in the range of student scores across schools in a
nest. If there is perfect correlation, the maximum score in a worse school will be less than the
minimum score in a better one. In step 3, we relate our estimates of δj to the characteristics
of each school to see what drives the preferences for schools.
    We do not use the standard nested logit setup because the cutoff score constrains choice.
Only those students with scores above the cutoff for a school have the option of attending it.
Had we ignored this constraint, we would have obtained biased estimates of δj . For example,
small and selective colleges would be wrongly seen as undesirable.18


3.2     Step 1

    Our model includes unobserved school characteristics, and these unobserved character-
istics enter the demand function non linearly, which complicates the estimation process.
Berry (1994) proposed a method to transform the demand functions so that unobserved
school characteristics appear as school fixed effects. By normalizing the value of the outside
option to zero, δ0 = 0, we have N demand equations with N unknowns. This permits us to
get the vector δ(q, c, λ) for given vectors q and c, conditional on a vector λ such that


                                          q = d(δ(q, c, λ), λ).

On the left hand side we have supply of seats, and on the right hand side we have the
demand for seats for a given vector of mean school valuations and school cutoffs (denoted
by δ and c respectively) and correlation of shocks within nests (λ). For a given λ, and with
q and c coming from the data, we can invert the above to obtain δ(q, c, λ). Our setup is
more complex than the models presented in Berry (1994) so we cannot solve for δ(q, c, λ)
analytically. Our setup is closer to that in Bresnahan, Stern and Trajtenberg (1997) who

  18
     There is a growing literature on the structural estimation of matching models that uses data on who is
matched with whom (See Fox (2009)). Since we do not observe all matches and only see the minimum and
maximum scores associated with each school as well as the number of seats, our approach has to differ from
theirs.

                                                    19
solve the system numerically as we do. Thus, inverting the demand function numerically
gives us the vector of the mean valuation of the alternatives, δ(q, c, λ).


3.3    Step 2

   Once we get δ(q, c, λ), we can specify individual i’s utility from alternative j as


                                Uij (λ, q, εij ) = δj (q, c, λ) + εij


At this stage, the only unknown in the utility function is the vector λ. As the λ for a nest
falls, the correlation of the utility shock within the nest will increase. In the extreme case,
when the correlation is perfect, if one agent values a particular school highly so do all other
agents, which can be interpreted as pure vertical differentiation. In this case, there will be
no overlap in the score distributions of different schools within the nest. If correlation is
low, then some students will choose one school and others will choose another and there will
be overlap in the score distributions. The extent of overlap in the minimum and maximum
scores of schools that are next to each other in cutoffs within a nest helps to pin down the
λ in the nest.
   Figure 4 shows how different values of λ affect the fit of the model to the data for the
Science high school nest. For each λ, the simulated minimum scores lie exactly on top of the
actual minimum scores as depicted in Figure 4, a consequence of our estimation strategy.
The figure shows the actual maximum score and simulated maximum scores for λ = 0.25,
0.5 and 1. Note how the lines move up as λ rises (or correlation falls) so that the extent of
overlap increases.
   We pin down λ using a simulation-based approach. The simulation algorithm works as
follows: For a given vector λ, we obtain the vector δ(q, λ) and simulate the minimum and
maximum cutoff scores, cj , and c̄j for each school. Then we find the vector λ that best
                       ¯
matches the actual maximum (and minimum) cutoff scores.


                                                 20
                                     Figure 4: Real and Simulated Cutoff Scores for λ = 0.25, 0.5, 1

                           960




                           940




                           920




                           900
           Cutoff Scores




                           880




                                                                                                         Simulation Min (λ=1)
                           860
                                                                                                         Simulation Min (λ=0.5)
                                                                                                         Simulation Min (λ=0.25)
                                                                                                         Actual Min
                                                                                                         Simulation Max (λ=1)
                           840
                                                                                                         Simulation Max (λ=0.5)
                                                                                                         Simulation Max (λ=0.25)
                                                                                                         Actual Max
                           820
                                 0        5     10         15       20        25       30        35          40               45   50
                                                                            Schools




   Simulating the error terms in the nested logit model creates some difficulties: taking
a draw from the GEV distribution with the standard Markov Chain Monte Carlo Method
is computationally intensive. We use a method proposed by Cameron and Kim (2001)
which takes a draw from the GEV distribution using a far less computationally intensive
procedure.19
   We draw M (= 100) sets of error terms εij from the distribution function given in equation
1 by using the parameters, λ. For each of the M sets of errors drawn, εk = hεkij i, k = 1, ..M,
we allocate students to schools by using the placement rule. After drawing each set of errors
we get a distribution of scores for students in each school. Let gjk be the set of scores in
school j in simulation k, ordered to be increasing.20


                                                     gjk (λ) = hskj1 (λ), skj2 (λ), . . . , skjqj (λ)i


  19
     This method is explained in Appendix A.2.
  20
     In the method proposed by Cameron and Kim (2001), a change in λ only affects the coefficients. This
allows us to keep the random seeds drawn from the extreme value distribution over simulations and only
change coefficients.

                                                                           21
   After ordering scores in ascending order for each school j and simulation M , we find the
expected value of the score for each rank within each school across the M simulations. The
expected score of student with rank r in school j is thus:

                                                            M
                                                         1 X k
                                            s∗jr (λ) =        s (λ)
                                                         M k=1 jr

   Let gj∗ (λ) be
                                   gj∗ (λ) = hs∗j1 (λ), s∗j2 (λ), . . . , s∗jqj (λ)i.

   We take the lowest and highest rank mean simulated score in each school. We find the
λ that gives the least square distance between these simulated minimum and maximum
cutoff scores and observed minimum and maximum cutoff scores. In effect, we are matching
the maximum scores as the minimum scores are matched on average given our estimation
procedure for obtaining δ.

                                       1 X ∗                    1 X ∗
                        λ̂ = arg min       (sjqj (λ) − c̄j )2 +    (s (λ) − cj )2
                                   λ   N j                      N j j1


Table 1 shows the λ values for each nest that minimize the distance between simulated
and real maximum and minimum cutoff scores. As we mentioned before, λ is a measure of
dissimilarity in preferences within a nest. If λ is small, students rank schools in the same
nest according to their perceived quality (δ) so that students tend to agree on the ranking of
schools. However as λ gets bigger, students differ in their preferences and no such ranking
exists as their tastes for schools differ.
   The correlation in shocks is low for vocational, teacher and local schools, suggesting that
preferences are more horizontal there. The correlation is highest in the Izmir, Ankara, and
Istanbul Anatolian high school nests (as λ is lowest). Note that the smaller the city, the
higher the correlation in the city nest, as might be expected.21 Science high schools are also
more vertically differentiated than Local schools, Vocational schools and Teachers schools.
  21
       Large cities are more likely to have the room for niche schools which are horizontally differentiated.

                                                          22
                               Table 1: Nesting Parameters: λ


                                    Variable    Coefficient
                                    λloc          0.958
                                    λvoc          0.986
                                    λank          0.795
                                    λist          0.837
                                    λizm          0.777
                                    λteach        0.999
                                    λsci          0.897




These findings suggest that students’ preferences are vertical for selective Anatolian and
Science high schools, but less so for less selective vocational, teacher and local schools.
   The real and simulated cutoff scores for λ presented in Table 1 are given in Figure 5.
As we can see simulated maximum scores track the real maximum cutoffs quite well. Note
that the actual maximum score is more variable than that estimated one. This comes from
differences in preferences only coming from one source: the error term. This is a consequence
of our lack of information about students. We expect that students have preferences over
school location relative to where they themselves come from. For example, a very good
student may choose a less selective Anatolian School just because it is close. This would
raise the maximum score there above what the model predicts. If we had better information
of this sort on students, we expect that we could do better at matching the maximum score.
   Figure 6 depicts the relationship between the perceived valuation and the selectivity of
schools. More selective schools clearly seem to be more valued. Close to the top of the score
distribution a small increase in the score raises utility a lot while a similar increase at low
scores has little effect. In the next step, we investigate the factors affecting the students’
perceived valuations of the schools.




                                               23
                               Figure 5: Real and Simulated Cutoff Scores


                950




                900
Cutoff Scores




                850




                800


                                                                      Simulation Min
                750                                                   Actual Min
                                                                      Simulation Max
                                                                      Actual Max

                700
                      0              50         100             150        200         250
                                                      Schools
                          15




                 Figure 6: Perceived Valuation w.r.t. Minimum Cutoff Score
                          10
                          5
                      δ
                          0
                          −5




                               650        700          750         800           850         900
                                                        Minimum cutoff score




                                                       24
3.4    Step 3

   Once we pin down the λ that gives the best match of the actual and the simulated cutoffs,
we get δ̂(q, λ̂). Returning to the definition of δ, the vector of mean valuations for schools,


                                           δ̂ = βX + ξ

where X is the observed characteristics of the school, and ξ is the school specific component of
mean valuations. ξ is the unobserved, common across all agents, school specific preference
shock. X includes the school’s success on the ÖSS the previous year, its age/experience,
type, education language, dormitory availability, whether it is located in a big city (Ankara,
İstanbul, or İzmir), the number of seats, and the cutoff score of the school. The dummy for
being a Science or Anatolian high school incorporates the possibility that such schools have
a good reputation and this makes people value them. This need not be for what they add
in value: it could be for consumption purposes, perhaps for the bragging rights associated
with going there.
   There is an econometric issue associated with including the cutoff score as an explanatory
variable. If ξ, the school specific shock, is large and positive, then the cutoff score will be
high as well, so that the cutoff will be correlated with ξ. This will bias the estimates of
β obtained. This is the familiar endogeneity problem. To deal with this we need a good
instrument for the cutoff score.
   We can partition X as [X̃, c] so that


                                       δ̂ = β̃ X̃ + γc + ξ


A good instrument is an exogenous variable that shifts the cutoff score, but does not affect
a school’s average valuation δ directly. The first variable that comes to mind that shifts the
minimum cutoff score is the number of available seats in a school. However, the available
number of seats may affect the valuation of the school directly. In addition, it may be a

                                               25
response to a high ξ which makes it less than optimal. This is less of a concern in Turkey,
where the number of seats is usually equal to the size of the graduating class as the overall
school size is set by the central authority and can be thought of as exogenous. Fortunately,
the model suggests which instruments to use for the minimum cutoff score. Next, we explain
what these are and how we construct them, and then present our results.
   The model predicts that the number of available seats in schools worse than a given school
has no effect on the demand for the school. However, the number of seats in better schools
does affect the demand for a school: more seats in better schools is predicted to reduce
the cutoff score of a school. This result comes from the observation that the demand for a
school comes from those who like it the most among the alternatives that are open to them.
Changing the cutoff in worse schools has no effect on the alternatives open to a student going
to a better school and hence on their demand. In other words, if Podunk University offers
more seats, there is no effect on the demand for Harvard since everyone choosing to go to
Harvard had, and continues to have, Podunk in their choice set. But if Harvard offers more
seats, it may well reduce the demand for Podunk University. It could be that someone chose
Podunk because they could not get into Harvard. Once Harvard increases its seats and so
reduces its own cutoff, Harvard may become feasible for such a student. As we use seats in
other schools to instrument for a school’s cutoff we need not worry about any correlation
with ξ.
   To construct the instrumental variable, we need a ranking of schools free of ξ. We will
use the schools’ success on the verbal and quantitative part of the ÖSS in the previous year
to rank schools.
   We construct our instrumental variable as follows:

  1. For each school, we find the schools that have better average test scores in both di-
     mensions, verbal and quantitative.

  2. We find the total number of seats in all of the schools found in step 1. The available
     number of seats in the school itself is not included.

                                             26
    The second set of instruments we use is constructed using a different insight. A large
positive draw of ξ, the school specific demand shock, would raise demand for the school
and so raise both the cutoff or minimum score and the maximum score. As a result, the
residual from the regression of the cutoff score on a flexible form of the maximum score will
be correlated with the minimum cutoff, but orthogonal to the school specific demand shock,
ξ. This makes it a good instrument.22 We thus use the residual of the minimum score on
a polynomial function of maximum cutoff score as an instrument for the minimum cutoff
score23 .
                                    c = λ0 + λ1 c̄ + λ2 c̄2 + λ3 c̄3 + ν

    Table 2 shows our first stage estimation:


                         c = η X̃ + κ1 ∗ Seats in better schools + κ1 ∗ ν + ε


Note that the number of seats in better schools has a negative coefficient: more seats in better
schools reduces the school’s own cutoff as expected. The second instrumental variable, the
residual from the regression of minimum cutoff on a polynomial function of maximum cutoff
score, has a positive coefficient as expected since the minimum score would be increased by
a positive shock as captured by a positive residual.
    We also validate the use of the number of seats in better schools. According to the model,
the number of seats in worse schools should have no effect on the school’s own cutoff. Table
A.7 presented in Appendix A.4 shows the first stage estimation with our instruments and
the instrument constructed by using the number of seats in lower scoring schools. Only the
instruments constructed with higher scoring schools and the residual from the regression of
minimum cutoff on a polynomial function of maximum cutoff score are significant. This is
exactly what the model predicts!

   22
      One might ask what could affect the maximum score and not the minimum score. The score distribution
around the cutoff score of a school does not affect its maximum score but it affects its minimum cutoff score.
   23
      Hoxby (2000) uses an instrumental variable constructed with similar logic.

                                                     27
            Table 2: First Stage Estimation



Variable                                      Coefficients

Number of Available Seats                         0.086
                                                 (0.062)
Average Quantitative Score in 2000 ÖSS          1.212*
                                                 (0.532)
Average Verbal Score in 2000 ÖSS                 0.971
                                                 (0.653)
Age                                               0.198
                                                 (0.419)
Science High School                             57.46***
                                                (14.900)
Teacher High School                              45.86**
                                                (16.770)
Anatolian High School in Istanbul                24.340
                                                (18.120)
Anatolian High School in Izmir                   19.980
                                                (19.800)
Education Language- English                       12.610
                                                (14.220)
Education Language- German                        -1.576
                                                (14.030)
Dormitory Availability                            12.750
                                                 (6.847)
Ankara                                           26.88*
                                                (13.100)
Istanbul                                         23.98*
                                                (11.200)
Izmir                                            26.62*
                                                (12.830)
Seats in better schools                        -0.00395*
                                                 (0.002)
Residual from min regression                    0.718***
                                                 (0.089)
Constant                                        715.8***
                                                (33.170)
Note: Standard errors are reported in parentheses. *, **,
*** indicate significance at the .90, .95 and .99 levels, re-
spectively.




                             28
                     Table 3: School Choice: Estimation Results



Variable                                    (OLS)       (OLS)       (2SLS)     ( LIML)

Number of Available Seats                    0.005     0.00842*       0.007       0.007
                                            (0.007)     (0.004)     (0.004)     (0.004)
Average Quantitative Score in 2000 ÖSS    0.218***    0.0680*      0.120**     0.121**
                                            (0.053)     (0.033)     (0.036)     (0.037)
Average Verbal Score in 2000 ÖSS          0.306***     0.0865*    0.163***    0.164***
                                            (0.053)     (0.038)     (0.040)     (0.040)
Age                                          0.026       0.032        0.030       0.030
                                            (0.062)     (0.031)     (0.041)     (0.041)
Science High School                        8.422***   3.237***     5.031***    5.072***
                                            (1.764)     (0.765)     (1.078)     (1.091)
Teacher High School                         4.039*       0.867        1.965       1.990
                                            (1.931)     (0.763)     (1.092)     (1.103)
Anatolian High School in Istanbul            1.928       -0.544       0.312       0.331
                                            (2.152)     (0.728)     (1.192)     (1.204)
Anatolian High School in Izmir               1.715       0.392        0.850       0.860
                                            (2.280)     (0.679)     (1.077)     (1.091)
Education Language- English                  2.671       -0.028       0.906       0.927
                                            (2.192)     (1.118)     (1.451)     (1.462)
Education Language- German                   1.198        0.330       0.630       0.637
                                            (2.254)     (1.175)     (1.485)     (1.493)
Dormitory Availability                       1.617        0.500       0.886       0.895
                                            (0.893)     (0.455)     (0.561)     (0.564)
Ankara                                      4.235**      0.733       1.945*      1.972*
                                            (1.494)     (0.485)     (0.810)     (0.821)
Istanbul                                   4.485***    1.687**      2.655**     2.677**
                                            (1.297)     (0.522)     (0.795)     (0.802)
Izmir                                       3.746*       0.608      1.694**     1.719**
                                            (1.449)     (0.381)     (0.607)     (0.617)
Minimum Cutoff Score                                  0.0846***   0.0553*** 0.0547***
                                                        (0.006)     (0.008)     (0.008)
Constant                                     -22.95***-76.18***   -57.76*** -57.34***
                                               (3.121)  (4.363)     (4.823)     (4.883)
F-statistic (excluded instruments)                                  37.773       37.773
Note: Corrected standard errors are reported in parentheses. *, **, *** indicate signifi-
cance at the .90, .95 and .99 levels, respectively.




                                           29
   The first column of Table 3 shows our baseline estimates, where we regress average
valuation on the exogenous variables and do not include the minimum cutoff score of a
school. This column suggests that past performance on the university entrance exam (ÖSS
scores) and school type drive preferences. The second column of Table 3 shows the results
of the regression of the average valuation on the exogenous variables and the school’s cutoff
score. The coefficient on the minimum score is positive and highly significant suggesting that
a more selective school is highly valued. The significance of past scores on the university
entrance exam are less significant, as would be expected given that the cutoff is positively
correlated with the past performance of a school so that including it picks up some of this
variation. However, as explained above, cutoffs are not exogenous. As cutoffs are high when
the school preference shocks are high, cutoffs are positively correlated with the error term
which imparts an upward bias to the coefficient. The third and fourth columns show the
results when we instrument for cutoffs. The third column reports the 2SLS estimates, and
the fourth column reports the limited information maximum likelihood (LIML) estimates.
The latter has better small sample properties. It is reassuring that the estimates from both
methods are very similar. In addition, note that after instrumenting for the cutoff score,
the coefficient on it falls (as expected) but remains positive and significant. This suggests
that students value the selectivity of a school and blindly put greater value on more selective
ones. Past performance on the university entrance exam becomes more significant suggesting
that, conditional on the cutoff, a school’s performance on the university entrance exam is
an important determinant of its valuation. Thus, students do look at how well students
graduating, or the output of a school, in forming their valuation of a school. These results
are consistent with the findings of Burgess et al. (2009) and Hastings, Kane, and Staiger
(2009) who reach a similar conclusion using data from the Millennium Cohort Study in the
UK, and school choice data from the Charlotte-Mecklenburg School District, respectively.
   Science high schools and schools in Istanbul, Ankara, and Izmir are also valued beyond
what they would be based on their selectivity alone. As mentioned before, Science high


                                              30
schools are very prestigious. It could be that attending such schools gives one contacts in
the future as well as a consumption value in the present.
    Macleod and Urquiola (2013) show that a school’s reputation can affect wages as the
identity of the school attended gives information about a student’s ability. This could also
rationalize the high valuation placed on Science high schools. It could also be that the high
valuation of Science high schools comes from the students’ use of school type as a proxy for
school quality. In the next section we look at the value-added of each Science high school by
estimating the effect or the value added of the high school on their students’ performance
on the university entrance exam.



4     High School’s Value-Added

    In the previous section, we estimated the preference parameters and recovered the high
school entrance exam scores for students in each school. We allocated students to schools
using the estimated preference parameters and the overall score distribution by simulation.
The goal in this section is to estimate the value-added by a school to the students’ academic
performances. Here we are limited by the data. We do not have a panel, so we cannot match
the score the student obtained on the high school entrance exam to what he obtained on
the university entrance exam. Rather, we infer the effects of schools on student performance
by comparing the mean high school entrance exam (OKS) score to the mean university
entrance exam (ÖSS) scores for each school. We have many years for the latter, but only
one year for the former. We discover patterns that suggest that better schools are resting
on their laurels, while the schools at the bottom are scrambling to improve. However, we
argue that this could be reflecting mean reversion. By using simulation based methods as
well as information on each student in a single school, we estimate the average value-added
by a school while controlling for mean reversion.




                                             31
4.1      The Approach

   In this section, we look only at science high school students because their program is
homogeneous since all students follow the science track. Students in these schools will placed
on the basis of a score that gives greater weight to the science and math part of the exam,
the ÖSS-SAY score, which is what we use as the performance measure on the university
entrance exam. We standardize scores by using the mean and the standard deviation of
scores within all Science high schools. Thus a score of −1 means the school is 1 standard
deviation below the mean.
   We assume that student i’s high school entrance exam score depends on his ability, αi ,
and his i.i.d. mean zero shock, εhs.
                                 i , and that his university entrance exam score depends

on his ability, the value-added of the school he attended, and the shock to the university
entrance exam score, εcij . Thus
                                           shs        hs
                                            i = αi + εi


   and


                                       scij = αi + γj + εcij
                                                       |{z}
                                                       uj +vic


where j indexes schools and γj is the school value-added. Assume that αi , γj , uj , vic and εhs
                                                                                              i are

independent of each other, and uj and vic which are the school specific and individual specific
components of the university entrance exam score shock, are independently distributed, mean
zero error terms. The school level common shock, uj , is a shock affecting the performance
of all students in the school. We do not observe the individual students’ scores, but only the
school level average scores for the university entrance exam. Thus, aggregating to the school
level in the model above, we get the mean scores in the OKS and ÖSS from school j :


                                   E(shs                    hs
                                      i |j) = E(αi |j) + E(εi |j)




                                                32
   and


                          E(scij |j, t) = E (αi |j, t) + γj,t + E(εcij |j, t)

   The t is a time index as we have more than a single year’s data on the university entrance
exam. Under the following assumptions, we can get a consistent estimate of the school value-
added, γj,t , by using the data on the performance of the schools over time.


Assumption 1: E(εhs
                 i |j) = 0



   Assumption 1 is a heroic one and is unlikely to hold in the data we have. Students with
better scores, and hence with better shocks to their scores on the high school entrance exam,
get into a better school while those with worse ones do not. As a result, it is to be expected
that the mean scores of students in the best (worst) high schools will look like they have
fallen (risen) in the university entrance exam even if there is actually no value added by any
school. This is the familiar mean reversion issue. All we are saying here is that if Assumption
1 holds, then we can easily estimate value added. If it is grossly untrue then our estimates
will be biased due to mean reversion and we will need to correct for this.


Assumption 2: E(αi |j, t) = E(αi |j) ∀t


   Assumption 2 states that students placed in a school have the same ability on average
over time. This is a reasonable assumption in the Turkish system. The cutoff scores are
fairly stable as the educational environment in Turkey has been unchanged over the last few
decades. In Appendix A.3 we present evidence on the stability of cutoff scores.


Assumption 3: γj,t = γj ∀t


   Assumption 3 says that school value-added is time-invariant. Assumptions 1-3 imply that
the variation in the performance of a school comes from the shock, ujt , received by that school
in that year.

                                                  33
          Table 4: Correlation of the Mean OKS score with the Mean ÖSS Scores

 Mean Score      OKS     ÖSS 2002    ÖSS 2003     ÖSS 2004    ÖSS 2005     ÖSS 2006    ÖSS 2007
   OKS             1
 ÖSS 2002      0.6667       1
 ÖSS 2003      0.7239    0.8474           1
 ÖSS 2004      0.7242    0.8816        0.8949          1
 ÖSS 2005      0.7146    0.6666        0.7522       0.7989           1
 ÖSS 2006       0.838    0.7761        0.8231        0.863        0.8027          1
 ÖSS 2007       0.811    0.7902        0.8807       0.8851        0.7893       0.8664          1


      Table 5: Correlation of the Rank of the Mean OKS and the Mean ÖSS Scores


 Rank of Mean Score       OKS      ÖSS 2002     ÖSS 2003    ÖSS 2004     ÖSS 2005    ÖSS 2006   ÖSS 2007
        OKS                 1
     ÖSS 2002           0.8341         1
     ÖSS 2003           0.8191      0.7988          1
     ÖSS 2004           0.8347      0.8228       0.8533           1
     ÖSS 2005           0.7438      0.6365       0.7479        0.8013          1
     ÖSS 2006           0.8758      0.8171       0.8971        0.8927       0.7968           1
     ÖSS 2007            0.851      0.7983       0.8489         0.87        0.7754        0.8825       1




   Under these assumptions the average performance of students in school j at time t can
be written as
                          E(scij |j, t) = E(shs                   c
                                             i |j) + γj + E(uj + vi |j, t)




                             E(scij |j, t) − E(shs
                                                i |j) = γj + E(uj |j, t)


   To account for the correlation in the shocks received by a school over time, we cluster
standard errors at the school level.


4.2    Results

   Before we present our results, we examine the patterns in the data on the schools’ average
performance on the university and high school entrance exam, to understand the effect of

                                                   34
                     Figure 7: Average ÖSS Score by Average OKS Score




                        2    1
                   OSS score
                    −1 0−2
                        −3


                                 −2   −1                  0                   1        2
                                                       OKS score

                                           µOSS,2002               linear fit (2002)
                                           µOSS,2003               linear fit (2003)
                                           µOSS,2004               linear fit (2004)
                                           µOSS,2005               linear fit (2005)
                                           µOSS,2006               linear fit (2006)
                                           µOSS,2007               linear fit (2007)
                                           µHS




noise on the average performance of schools. Looking at the raw patterns in the data we
see that there seems to be a role for ability in the sorting between schools. If ability did
not affect the scores on the high school and the university entrance exams, then allocation
of students to schools would be independent of ability. In that case, the correlation between
the average ÖSS score and the average OKS score would be zero if there is no value-added
by schools. The correlation and rank correlation of the mean OKS and the mean ÖSS scores
are strongly positive as in Table 4 and Table 5. Thus, in the absence of value-added, this is
evidence of sorting on the basis of ability between schools. However, if better schools add
value, then the correlation could be coming from the value-added component and not the
ability sorting one. Hence given our data we cannot separate between these two. We need,
at the very least, information over time for the schools’ mean OKS scores to have a hope
of pinning down a school-level value-added effect. When we plot normalized OKS and ÖSS
scores as in Figure 7, the fitted line is flatter than the 45 degree line, which is in red. This
is exactly what we would see with mean reversion and/or with better more selective high
schools adding less value than less selective ones.
   The less the randomness in the OKS score relative to the variation in ability, the more



                                                       35
                             Figure 8: Average OKS and ÖSS scores




               4
               2
             score
               0
               −2
               −4




                     1 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45
                      2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46
                                                School

                                Positive Value−added           Negative Value−added
                                µOSS,2002                      µOSS,2003
                                µOSS,2004                      µOSS,2005
                                µOSS,2006                      µOSS,2007
                                µOKS




informative is the high school entrance exam score and the lower the extent of mean reversion
bias. If we knew, or could assume something about the this, we might be able to pin down
the value-added by a school.
   Figure 8 presents the same data in a slightly different way. It orders schools on the basis
of their cutoffs with School 1 being the least selective one. Thus, the schools are ordered
from worst to best. Each school’s score on the university entrance exam from 2002-2007
as well as the high school entrance exam score in 2001 is plotted. The high schools with
positive and significant value-added are highlighted in blue, while those with significantly
negative value-added are highlighted in red. No highlight means the estimated value-added
is not significantly different from zero.
   Note that the worst schools seem to add value on average and the best ones reduce it,
although School 4, one of the worst schools, reduces value. As discussed above, this broad
pattern could be just a reflection of mean reversion. In the next section, by using auxiliary
student level data from a school, we estimate the magnitude of the mean reversion bias and



                                                  36
correct for it.


4.3       Mean Reversion Bias

   In the previous section we noted that the mean difference in school performance in the
OKS and OSS exams captures both mean reversion and value-added. In this section, by using
some auxiliary student-level data we were able to obtain for only one school, we develop a
way to correct for the bias due to mean reversion. This auxiliary data contains each student’s
name, their high school score and their college entrance exam score.
   As in the previous section, we normalize scores within the school so that the mean score
is zero and its standard deviation is 1 on both exams. If the value-added by a school is
assumed to be constant across students as is assumed, then student i’s high school and
university entrance exam scores are given by24


                                               shs        hs
                                                i = αi + εi




                                                sci = αi + vic

where αi is the ability of student i. We assume that αi , vic and εhs.
                                                                   i are independent of each

other. Students’ scores on the high school entrance exam and university entrance exam differ
from each other only by the difference in the shocks received.
   We used the approach introduced in Chay, McEvan and Urquiola (2005) to understand if
there is mean reversion in the data. We look at the ”regression” coefficient relating the score
difference between high school and university entrance exam scores to high school entrance
exam scores.


                                           sci − shs    hs
                                                  i = ρsi + ωi

  24
       As the scores are normalized, value-added is wiped out.

                                                     37
                             Table 6: ”Regression” Coefficient: ρ


                                               ρ
                                          -0.663***
                                           (0.0559)




                              Cov(sci − shs    hs
                                          i , si )    Cov(sci , shs
                                                                 i )
                          ρ̂ =            hs
                                                   =           hs
                                                                     −1
                                   V ar(si )           V ar(si )
                                  σα2              −σε2hs
                            =             −1= 2
                              σα2 + σε2hs         σα + σε2hs

If there is no mean reversion, ρ̂ is zero. To build intuition, consider two extreme cases that
show how ρ̂ is related to mean reversion. Firstly, if we assume that high school entrance
exam scores depend only on students’ abilities and there is no noise, then σε2hs = 0 so ρ̂ = 0.
In this case, we don’t expect to see mean reversion bias since there is no randomness in the
high school entrance exam scores. Secondly, if we assume that high school entrance exam
scores are just noise, shs   hs
                        i = εi , then ability does not affect score variation, which results in

ρ̂ being equal to −1. In this case, the mean reversion bias is at its highest level. Therefore,
ρ̂ can be thought as showing how severe the mean reversion is.
   We observe students’ scores on the high school and university entrance exams, so we can
run the following regression to estimate ρ :


                                     sci − shs    hs
                                            i = ρsi + ωi


   Table 6 shows the estimate of ρ. As a result of our normalization process the variance
of each of the scores is unity. As ability and shocks are orthogonal, σα2 + σε2hs = 1. So we
can recover the variance of the error distribution and the variance of the ability distribution
from our estimate of ρ.




                                               38
          Figure 9: Mean Reversion Bias: εhs ∼ N (0,−ρ̂), εhs ∼ N (0,−ρ̂ ± 2σ−ρ̂ )


          2
          1
       Score
         0−1
          −2




               1       3       5       7    9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45
                   2       4       6       8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46
                                                               School

                                                           µOSS if ε ∼ N(0, −ρ−2σ−ρ)
                                                                   HS


                                                           µOSS if ε ∼ N(0, −ρ)
                                                                    HS


                                                           µOSS if ε ∼ N(0, −ρ+2σ−ρ)
                                                                     HS


                                                           Simulated µOKS
                                                           Actual µOKS




                                                        σε2hs = −ρ̂

                                                          σα2 = 1 + ρ̂


   The estimate of ρ is quite large in absolute terms: noise accounts for 66% of the variance
in the OKS score.
   In our system, the allocation rule of students to schools is known, and in the previous
section, we estimated students’ preferences over high schools. We can recover the average
ability and shock received by students in each school by making a parametric assumption
on the distribution of ability and noise on the high school entrance exam. We will assume
that the ability has a normal distribution with the mean equal to zero and the variance
equal to (1 + ρ̂). Similarly the distribution of the error term, εhs
                                                                  i , is normal with mean equal

to zero and variance −ρ̂. Under these assumptions, we generate high school entrance exam
scores and allocate students to schools based on the estimated preferences. This gives the


                                                              39
                           Figure 10: Value-added: εhs ∼ N (0,−ρ̂)




             4
             2
           score
             0
             −2
             −4




                   1 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45
                    2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46
                                              School

                              Positive Value−added           Negative Value−added
                              µOSS,2002                      µOSS,2003
                              µOSS,2004                      µOSS,2005
                              µOSS,2006                      µOSS,2007
                              µOKS−E(εOKS)




orange line (connecting the dots) in Figure 9. We also present the mean scores on university
entrance exams for this simulated allocation of students to schools when there is no value-
added for different levels of variance in εhs         2
                                           i , i.e., σεhs . The middle curve corresponds to the

university entrance exam score with σε2hs = −ρ̂. The ones above and below it correspond to
the simulations where σε2hs is set at the 95% bands. In addition, we present the actual mean
scores on the high school entrance exam to see if the simulated mean scores deviate from the
actual ones. It is comforting to see that they look remarkably similar. They differ slightly
for the most and least selective schools.
   It is worth noting that preferences also affect the extent of mean reversion bias: the more
vertical the preferences, the more the bias. With purely horizontal preferences, students who
get lucky in their high school entrance exam performance are less likely to end up in the
more selective schools reducing the extent of mean reversion bias.
   Now we adjust for the mean reversion bias in our estimates by adding E(εhs
                                                                           i |j) to our

estimates of value added to correct for mean reversion. In the figures we also depict µOKS −
E(εOKS ) which is the mean high school entrance exam score adjusted for the mean reversion


                                                40
                    Figure 11: Value-added: εhs ∼ N (0,−ρ̂ + 2σ−ρ̂ )


  4
  2
score
  0
  −2
  −4




        1       3       5       7    9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45
            2       4       6       8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46
                                                        School

                                     Positive Value−added            Negative Value−added
                                     µOSS,2002                       µOSS,2003
                                     µOSS,2004                       µOSS,2005
                                     µOSS,2006                       µOSS,2007
                                     µOKS−E(εOKS)




                    Figure 12: Value-added: εhs ∼ N (0,−ρ̂ − 2σ−ρ̂ )
  4
  2
score
  0
  −2
  −4




        1 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45
         2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46
                                   School

                                     Positive Value−added            Negative Value−added
                                     µOSS,2002                       µOSS,2003
                                     µOSS,2004                       µOSS,2005
                                     µOSS,2006                       µOSS,2007
                                     µOKS−E(εOKS)




                                                       41
bias which rises far less slowly than the unadjusted one. Figure 10 shows the schools’
value-added estimates when we correct for the mean reversion bias. There is no particular
pattern in value-added estimates according to selectivity. The most selective schools do
not seem to have a positive effect on their students’ test scores. However, it is also clear
that some schools, such as schools 13, 29 and 35, improve their students scores, while others
have negative value-added, such as schools 4, 11, 33 and 45. Figures 11 and 12 do the
same thing but allow for higher and lower levels of variance in εhs
                                                                 i respectively as defined

by the confidence intervals above. As can be seen, with higher variance, there is more mean
reversion to correct for so that more schools on the right add value and more on the left
reduce value. With lower variance, we get the opposite happening.
     These results show that there is reason to think that the circular causation hypothesis
has some merit. Although better schools do not seem to have any significant effect on their
students’ test scores, students act like they do! It is also important to note that we are
only investigating the effect of exam schools on academic achievement. However, students
attending exam schools may have other benefits that are valuable to them, but unobservable
to us.25



5        Conclusion

     Schools are hard to evaluate in the real world. Unlike most experience goods, where
consumers can know how much they like the good upon consuming it, with schooling, liking
the experience is only part of what people care about. They care about attributes, like
reputation or selectivity that might signal something, as well as the value-added by the
teaching in the school. Since consumers are unlikely to have information about the latter,
even if they have information about the former, information frictions are likely to be rampant
in this market. This may well result in the market working poorly. Schools with high value-

    25
     Alstadsæter (2011), and Jacob, McCall, and Stange (2011) show the importance of the role of consump-
tion value in students’ school choices in different contexts.

                                                   42
added may thus be ranked below those that are adding little value but are very selective.
   School choice programs are thought to increase the productivity of public schools by
encouraging competition in the market. Just like firms producing better products can charge
a higher price for them, it is tempting to think of schools competing in their products with
good schools delivering a better product, i.e., adding more value to their students, and
as a result being more selective and having greater status. However, as argued above,
quality is hard to infer in this market. As a result, the market may work poorly if quality
information is not made available. In this paper, we use data available from public sources
to show that, indeed, consumers value academic success on the university entrance exam,
the selectivity of the school, elite school status and location. However, what people like and
value-added are not related. Our results suggest it is hard to acquire information on the
quality of the product by the schools so that families/students cannot infer the quality of
a school. Therefore providing better information on value-added by a school, rather than
just information on the performance of its students is essential to the market working well
in this area. Elite schools seem to get better students because everyone wants to go to them,
even when they need not add value to the students in terms of their performance on the
university entrance exam. This may also be because of signaling and/or the consumption
value of going to such schools: bragging rights or networks formed in such schools that are
of value later. In this case, especially because better-off students are more likely to be able
to get into such schools, it is hard to defend the subsidies received by elite schools.
   Finally, our results illustrate the value of taking a structural, model based approach.
First, as is well understood, by using the model, one can do more with less data. Second,
even if we had better data, we would still need to correct for much of what we describe
above. For example, if we had data at the student level on high school and university en-
trance exams, just looking at the difference in student performance by school would not give
a bias free estimate of value added. Mean reversion as above would still be an issue. Its
extent depends on the signal used and the extent of noise in the signal as explained above.


                                              43
If U.S. schools use a host of factors in deciding on their admissions, not just high school per-
formance or SAT scores, the noise in their admissions could rise worsening mean reversion
bias. However, if preferences are horizontal more than vertical, as may well be the case in
a large country like the U.S. where schools find a niche for themselves, the extent of mean
reversion bias could be lower. Thus, preferences, the allocation system, and the strength of
the signal present in the scores are critical inputs when developing measures of value added.
They can only be obtained by taking a structural approach.




                                              44
References

Abdulkadiroglu, A., Angrist, J. D., and Pathak, P. A. (2011). The elite illusion: Achievement
effects at Boston and New York exam schools (No. 17264). National Bureau of Economic
Research.

Alstadsæter, A. (2011). Measuring the consumption value of higher education. CESifo Eco-
nomic Studies, 57(3), 458-479.

Berry, S. T. (1994). Estimating discrete-choice models of product differentiation. The RAND
Journal of Economics, 242-262.

Berry, S., Levinsohn, J., and Pakes, A. (1995). Automobile prices in market equilibrium.
Econometrica, 841-890.

Bresnahan, T. F., Stern, S., and Trajtenberg, M. (1997). Market Segmentation and the
Sources of Rents from Innovation: Personal Computers in the Late 1980s. RAND Journal of
Economics, S17-S44.

Burgess, S., Greaves, E., Vignoles, A., and Wilson, D. (2009). What parents want: School
preferences and school choice. CMPO.

Cameron, A. C., and Kim, N. (2001). Simulation Methods for Nested Logit Models. Depart-
ment of Economics, University of California, Davis, California.

Caner, A., and Okten, C. (2013). Higher education in Turkey: Subsidizing the rich or the
poor?. Economics of Education Review.

Chay, K. Y., McEwan, P. J., and Urquiola, M. (2005). The Central Role of Noise in Eval-
uating Interventions That Use Test Scores to Rank Schools. American Economic Review,
1237-1258.

Clark, D. (2010). Selective schools and academic achievement. The BE Journal of Economic
Analysis & Policy, 10(1)

                                             45
Cullen, J. B., Jacob, B. A., and Levitt, S. D. (2005). The impact of school choice on student
outcomes: an analysis of the Chicago Public Schools. Journal of Public Economics, 89(5),
729-760.

Cullen, J. B., Jacob, B. A., and Levitt, S. (2006). The effect of school choice on participants:
Evidence from randomized lotteries. Econometrica, 74(5), 1191-1230.

Dale, S. B., and Krueger, A. B. (2002). Estimating the payoff to attending a more selective
college: An application of selection on observables and unobservables. The Quarterly Journal
of Economics, 117(4), 1491-1527.

Dale, S., and Krueger, A. B. (2011). Estimating the return to college selectivity over the ca-
reer using administrative earnings data (No. 17159). National Bureau of Economic Research.

Darling-Hammond, L., Amrein-Beardsley, A., Haertel, E., and Rothstein, J. (2012). Evalu-
ating teacher evaluation. Phi Delta Kappan, 93(6), 8-15.

Ding, W., and Lehrer, S. F. (2007). Do peers affect student achievement in China’s secondary
schools?. The Review of Economics and Statistics, 89(2), 300-312.

Dobbie, W., and Fryer Jr, R. G. (2011). Exam high schools and academic achievement:
Evidence from New York City (No. 17286). National Bureau of Economic Research.

Duflo, E., Dupas, P., and Kremer, M. (2006). Peer Effects, Teacher Incentives, and the
Impact of Tracking: Evidence from a Randomized Evaluation in Kenya. American Economic
Review, 101(5), 1739-74.

Epple, D., and Romano, R. (2011). Peer effects in education: A survey of the theory and
evidence. Handbook of Social Economics, 1(11), 1053-1163.

European Commission, (2009/2010). Organization of the Education System in Turkey.




                                              46
Frisancho Robles, V., and Krishna, K. (2012). Affirmative Action in Higher Education in
India: Targeting, Catch Up, and Mismatch (No. 17727). National Bureau of Economic Re-
search.

Fox, J. T. (2009). Structural Empirical Work Using Matching Models. In S. N. Durlauf and
L. E. Blume (Eds.), New Palgrave Dictionary of Economics (Online ed.).

Hanushek, E. A., Kain, J. F., Markman, J. M., and Rivkin, S. G. (2003). Does peer ability
affect student achievement?. Journal of Applied Econometrics, 18(5), 527-544.

Hastings, J. S., Kane, T., and Staiger, D. (2009). Heterogeneous preferences and the efficacy
of public school choice. NBER Working Paper, No. 12145 and No. 11805.

Heckman, J. J. (1979). Sample selection bias as a specification error. Econometrica: Journal
of the econometric society, 153-161.

Hoxby, C. (2000). Peer effects in the classroom: Learning from gender and race variation
(No. 7867). National Bureau of Economic Research.

Hoxby, C. M. (2000). The effects of class size on student achievement: New evidence from
population variation. The Quarterly Journal of Economics, 115(4), 1239-1285.

Jackson, C. K. (2010). Do Students Benefit from Attending Better Schools? Evidence from
Rule-based Student Assignments in Trinidad and Tobago. The Economic Journal, 120(549),
1399-1429.

Jacob, B., McCall, B., and Stange, K. (2011). The consumption value of postsecondary
education. Working Paper

Kang, C. (2007). Classroom peer effects and academic achievement: Quasi-randomization
evidence from South Korea. Journal of Urban Economics, 61(3), 458-495.

Krishna, K., and Tarasov, A. (2013). Affirmative Action: One Size Does Not Fit All (No.
19546). National Bureau of Economic Research.

                                             47
Macleod, W. B., and Urquiola, M. (2013). Anti-Lemons:              Reputation and Educa-
tional Quality. Working paper. Retrieved from http://www.columbia.edu/~msu2101/
MacLeod-Urquiola(2013).pdf

Pop-Eleches, C., and Urquiola, M. (2013). Going to a better school: Effects and Behavioral
Responses. American Economic Review, 103(4): 1289-1324.

ÖSYM (2002). Ortaöğretim Kurumlarına Göre 2002 Öğrenci Seçme Sınavı Sonuçları Kitabı.

Train, K. (2009). Discrete choice methods with simulation. Cambridge University Press.

Zabel, J. E. (2008). The Impact of Peer Effects on Student Outcomes in New York City
Public Schools. Education Finance and Policy, 3(2), 197-249.

Zimmerman, D. J. (2003). Peer effects in academic outcomes: Evidence from a natural
experiment. Review of Economics and Statistics, 85(1), 9-23.




                                             48
A      Appendix

A.1     The Nested Logit Model

    Suppose that individual i’s choice set, C, contains N + 1 alternatives. These alternatives
are partitioned into K nests according to certain characteristics. Therefore we can write the
choice set as:
                                       C = {B1 , B2 , . . . , Bk }

Let utility of the individual i from alternative j in nest k be


                                           Uij = δkj + εij


where δkj is the mean valuation of the alternative j. We can decompose δkj as:


                                           δkj = Wk + Vj


    where Wk is the valuation related only to the nest characteristics and Vj is the valuation
related to alternative j’s attributes.
    Let λk be the scale parameter of nest k, which is inversely related to the correlation of
error terms within nest k.
    The probability alternative j is chosen conditional on nest k being chosen is given by:

                                                            V
                                                   exp( λkj )
                                      P (j|Bk ) = P
                                                     exp( λVkl )
                                                    l∈Bk

    The probability of nest k being chosen depends on the nest characteristics Wk , and
inclusive value Ik , which depends on all the alternatives in the nest k.


                              exp(Wk + λk Ik )                  X         Vl
                 P (Bk ) =   K
                                                where Ik = log(      exp(     ))
                             P                                            λ k
                               exp(Wn + λn In )                 l∈Bk
                             n=1


                                                   49
We can write P (j) as:


                     P (j) = P (j|Bk )P (Bk )
                                                    V
                                     exp( λkj )    exp(Wk + λk Ik )
                                 = P          Vl PK
                                        exp( λk )
                                   l∈Bk             exp(Wn + λn In )
                                                                 n=1



                         exp( λVkl ))
                     P
Replace Ik by log(
                  l∈Bk




                                                                exp( λVkl )))
                                                            P
                                 Vj        exp(Wk + λk log(
                            exp( λk )                      l∈Bk
             P (j) =       P        Vl P  K
                               exp( λk )
                                                                  exp( λVnl )))
                                                              P
                          l∈Bk               exp(Wn + λn log(
                                         n=1                 l∈Bn

                                                           exp( λVkl ))λk
                                                       P
                                 Vj        (exp(Wk ))(
                            exp( λk )                 l∈Bk
                     =     P        Vl P  K
                               exp( λk )
                                                             exp( λVnl ))λn
                                                         P
                          l∈Bk              (exp(Wn ))(
                                         n=1            l∈Bn


                              Wk
                          exp( λk
                                     )
Multiply both sides by        W          :
                          exp( λ k   )
                                k



                                                                        V
                                                                                       exp( λVkl ))λk −1
                                                                                 P
                                             (exp(Wk ))(exp( λkj ))(
                          exp( W
                               λk
                                 k
                                   )                                            l∈Bk
             P (j) =
                          exp( W k
                                   )              K
                                                                                   exp( λVnl ))λn
                               λk
                                                  P                           P
                                                        (exp(Wn ))(
                                                  n=1           l∈Bn
                                                  W k λk       Vj
                                                                                         exp( λVkl ))λk −1
                                                                      P
                                             (exp( λk ) )(exp( λk ))(
                          exp( W
                               λk
                                 k
                                   )                                 l∈Bk
                     =         Wk                 K
                          exp( λk )
                                                        (exp( W                        exp( λVnl ))λn
                                                  P             n λn
                                                                                P
                                                              λn
                                                                 ) )(
                                                  n=1                          l∈Bn
                                               V
                          exp( W k λk −1                             Wk
                                                                                     exp( λVkl ))λk −1
                                                                            P
                               λk
                                  )      (exp( λkj               +   λk
                                                                        ))(
                                                                           l∈Bk
                     =                   K
                                              (exp( W                         exp( λVnl ))λn
                                         P            n λn
                                                                       P
                                                    λn
                                                       ) )(
                                         n=1                           l∈Bn


Therefore
                                                    δ
                                                                       exp( δλklk ))λk −1
                                                                 P
                                             (exp( λkjk ))(
                                                             l∈Bk
                           P (j) =                K
                                                                  exp( δλnln ))λn
                                                  P         P
                                                        (
                                                  n=1 l∈Bn


                                                            50
A.2    Cameron and Kim (2001)

   Suppose that ε1 and ε2 are jointly distributed with bivariate extreme value distribution

                                                             
                                              ε1        ε2  λ
                     H(ε1 , ε2 ) = exp − exp(− ) + exp(− )
                                               λ         λ

   Cameron and Kim (2001) propose that


                                    ε1 = aξ + bv1 + c

                                    ε2 = aξ + bv2 + c

   where ξ, v1 , v2 are independently distributed with extreme value distribution, and a, b
and c are the weights that match the moments of extreme value distribution.


                       E(εi ) = E(aξ + bv1 + c) = aγ + bγ + c = γ

                                               π2      π2   π2
                              V ar(εi ) = a2      + b2    =
                                               6       6    6


                                                              a2
                            Corr(ε1 , ε2 ) = [1 − λ2 ] =
                                                           a2 + b2

   This results in
                                            √
                                       a=       1 − λ2

                                            √
                                       b=       1 − a2

                                     c = (1 − a − b)γ

   where γ is the Euler constant.




                                               51
                     Table A.1: Correlation in Minimum Cutoff Scores


                     Min Score 2000 2001 2002 2003                 2004
                        2000      1.00 0.97 0.97 0.96              0.96
                        2001      0.97 1.00 0.97 0.96              0.95
                        2002      0.97 0.97 1.00 0.98              0.97
                        2003      0.96 0.96 0.98 1.00              0.98
                        2004      0.96 0.95 0.97 0.98              1.00
                     Source: Science and Anatolian high school’s cutoff
                     scores from 2000 - 2004 from the Ministry of Education
                     website



   This method is generalized to the multivariate extreme value distribution,
                                                                                     !λk 
                                                         K
                                                         X     X              εij
                  H(εi0 , εi1 , . . . , εiN ) = exp −                exp(−       )      
                                                         k=1   j∈Bk
                                                                              λk


   such that
                                       εj = ak ξ + bk vj + ck

   where
                            q              q
                     ak =    1 − λ2k , bk = 1 − a2k , ck = (1 − ak − bk )γ


A.3     Stability of Exam Schools’ Cutoff Scores

   The following tables show the correlation of cutoff scores over the five year period from
2000 to 2004. As Tables A.1 and A.2 show the correlation between minimum cutoff scores
over the years is never less than 0.95. The correlation between maximum cutoff scores is
lower than between minimum cutoff scores, but it is still around 0.8. Similarly we also look at
how the ranks of schools with respect to their minimum and maximum scores are correlated
over time. Table A.3 shows the correlation in rank of schools’ minimum cutoff scores over
the five year period. Similarly, Table A.4 shows the corresponding table for the maximum
cutoff scores. These tables show that exam schools’ cutoff scores are stable in Turkey.



                                                   52
    Table A.2: Correlation in Maximum Cutoff Scores


    Max Score 2000 2001 2002 2003                 2004
       2000      1.00 0.82 0.83 0.83              0.82
       2001      0.82 1.00 0.80 0.82              0.78
       2002      0.83 0.80 1.00 0.87              0.85
       2003      0.83 0.82 0.87 1.00              0.86
       2004      0.82 0.78 0.85 0.86              1.00
    Source: Science and Anatolian high school’s cutoff
    scores from 2000 - 2004 from the Ministry of Education
    website




Table A.3: Correlation in Rank of Minimum Cutoff Scores


Rank of Min Score 2000 2001 2002 2003                 2004
       2000          1.000 0.953 0.946 0.943          0.946
       2001          0.953 1.000 0.973 0.969          0.968
       2002          0.946 0.973 1.000 0.985          0.979
       2003          0.943 0.969 0.985 1.000          0.979
       2004          0.946 0.968 0.979 0.979          1.000
Source: Science and Anatolian high school’s cutoff scores from
2000 - 2004 from the Ministry of Education website




Table A.4: Correlation in Rank of Maximum Cutoff Scores


Rank of Max Score 2000 2001 2002 2003                  2004
       2000          1.000 0.785 0.800 0.793          0.771
       2001          0.785 1.000 0.829 0.837          0.798
       2002          0.800 0.829 1.000 0.858          0.838
       2003          0.793 0.837 0.858 1.000          0.847
       2004          0.771 0.798 0.838 0.847          1.000
Source: Science and Anatolian high school’s cutoff scores from
2000 - 2004 from the Ministry of Education website




                             53
   Table A.5: Descriptive Statistics: High School Entrance Exam

Variable                                     Obs     Mean     Std.Dev.    Min       Max

                            Anatolian High Schools in Ankara

Number of Available Seats                     24     85.000    49.782      30       240
Minimum Cutoff Score                          24    813.573    30.792    768.819   872.254
Maximum Cutoff Score                          24    859.001    21.543    825.171   912.31
Age                                           24     10.292    6.182       5         30
Average Math Score in 2000 ÖSS*              17     29.071    3.598      23.07     34.84
Average Science Score in 2000 ÖSS*           17     18.425    6.691       3.1      28.41
Average Turkish Score in 2000 ÖSS*           17     34.656    1.857      31.35     37.81
Average Social Science Score in 2000 ÖSS*    17     25.920    2.477      21.78     30.21
Language offered: English                     24     0.792     0.415       0         1
Language offered: German                      24     0.167     0.381       0         1
Language offered: French                      24     0.042     0.204       0         1
Dormitory Availability                        24     0.167     0.381       0         1

                            Anatolian High Schools in Istanbul

Number of Available Seats                     38    100.658    48.186      30       240
Minimum Cutoff Score                          38    827.916    41.686    654.059   898.332
Maximum Cutoff Score                          38    874.426    23.135    830.076   933.735
Age                                           38     10.105    6.501       1         26
Average Math Score in 2000 ÖSS*              23     29.201    4.152      18.72     37.61
Average Science Score in 2000 ÖSS*           23     19.553    4.568      11.85     32.48
Average Turkish Score in 2000 ÖSS*           23     35.819    2.524      29.19     41.05
Average Social Science Score in 2000 ÖSS*    23     26.359    3.446      20.83     34.74
Language offered: English                     38     0.763     0.431       0         1
Language offered: German                      38     0.184     0.393       0         1
Language offered: French                      38     0.053     0.226       0         1
Dormitory Availability                        38     0.184     0.393       0         1

                             Anatolian High Schools in Izmir

Number of Available Seats                     18     90.000    63.431      30       300
Minimum Cutoff Score                          18    810.994    32.805    762.369   878.236
Maximum Cutoff Score                          18    868.863    30.033    818.16    915.172
Age                                           18     14.500    16.111      1         48
Average Math Score in 2000 ÖSS*              12     26.553    6.916      12.61     31.03
Average Science Score in 2000 ÖSS*           12     17.968    4.550      9.45      22.17
Average Turkish Score in 2000 ÖSS*           12     33.875    4.792      24.02     37.48
Average Social Science Score in 2000 ÖSS*    12     25.014    5.621      14.59    33.3779
Language offered: English                     18     0.556     0.511       0         1
Language offered: German                      18     0.278     0.461       0         1

                                   (continued on next page)




                                             54
    Variable                                       Obs   Mean      Std.Dev.       Min         Max

    Language offered: French                        18    0.167      0.383         0               1
    Dormitory Availability                          18    0.278      0.461         0               1

                                       Science High Schools

    Number of Available Seats                       48   83.000     21.556         48             96
    Minimum Cutoff Score                            48   878.010    18.120      837.949      920.268
    Maximum Cutoff Score                            48   910.355    14.484      879.825      941.566
    Age                                             48    8.250      6.380         1              38
    Average Math Score in 2000 ÖSS*                38   37.270      2.652       29.22        41.4
    Average Science Score in 2000 ÖSS*             38   32.973      3.919       22.54        39.59
    Average Turkish Score in 2000 ÖSS*             38   35.945      3.908       26.07        41.35
    Average Social Science Score in 2000 ÖSS*      38   27.843      6.209       12.92        38.06
    Language offered: English                       48     1           0           1               1
    Language offered: German                        48     0           0           0               0
    Language offered: French                        48     0           0           0               0
    Dormitory Availability                          48     1           0           1               1

                             Anatolian Teacher Training High Schools

    Number of Available Seats                       91   56.703     21.322         24             120
    Minimum Cutoff Score                            91   798.716    35.943      712.758      864.296
    Maximum Cutoff Score                            91   864.419    16.861       827.49      902.864
    Age                                             91    8.571      3.763         1              12
    Average Math Score in 2000 ÖSS*                71   15.401      4.704        5.2         27.65
    Average Science Score in 2000 ÖSS*             71    9.745      3.340        2.26        18.35
    Average Turkish Score in 2000 ÖSS*             71   31.726      3.405       22.65        37.87
    Average Social Science Score in 2000 ÖSS*      71   23.476      3.483       10.81        30.19
    Language offered: English                       91     1           0           1               1
    Language offered: German                        91     0           0           0               0
    Language offered: French                        91     0           0           0               0
    Dormitory Availability                          91    0.846      0.363         0               1

    * : The differences in the number of observations across variables comes from some schools
    being new so that there are no students graduating in 2000.



   Table A.6: Descriptive Statistics: High School Entrance Exam Scores

                                                                             Quantiles

Variable       Number of Students   Mean     Std.Dev.     Min       0.25      Median       0.75         Max

OKS Score           553495          592.35       86.34   442.53    526.76     572.83      637.44        941.49




                                                  55
            Table A.7: Validity Check: Instrumental Variables


Variable                                                             Coefficients

Number of Available Seats                                               0.083
                                                                       (0.061)
Average Quantitative Score in 2000 ÖSS                                 0.631
                                                                       (0.750)
Average Verbal Score in 2000 ÖSS                                       -0.071
                                                                       (1.212)
Age                                                                     0.166
                                                                       (0.420)
Science High School                                                   58.23***
                                                                      (14.450)
Teacher High School                                                    45.77**
                                                                      (16.310)
Anatolian High School in Istanbul                                       23.990
                                                                      (17.990)
Anatolian High School in Izmir                                         18.230
                                                                      (19.210)
Education Language- English                                            11.720
                                                                      (13.900)
Education Language- German                                              -2.157
                                                                      (13.680)
Dormitory Availability                                                 12.360
                                                                       (6.808)
Ankara                                                                 26.90*
                                                                      (12.590)
Istanbul                                                               23.89*
                                                                      (11.640)
Izmir                                                                  27.06*
                                                                      (12.300)
Instrument for Minimum Score (with better schools)                   -0.00465*
                                                                       (0.002)
Instrument for Minimum Score (with worse schools)                        0.002
                                                                       (0.002)
Residual from min regression                                          0.720***
                                                                       (0.090)
Constant                                                              756.5***
                                                                      (52.540)
Note: Standard errors are reported in parentheses. *, **, *** indicate significance at the .90,
.95 and .99 levels, respectively.




                                             56
                                   Figure A.1: Model Fit: Science High Schools Nest

                960


                940


                920
Cutoff Scores




                900


                880


                860
                                                                            Simulation Min
                                                                            Actual Min
                840                                                         Simulation Max
                                                                            Actual Max

                820
                             0             10        20              30             40             50
                                                           Schools




                                   Figure A.2: Model Fit: Teacher High Schools Nest

                                 950




                                 900
                 Cutoff Scores




                                 850




                                 800


                                                                          Simulation Min
                                 750                                      Actual Min
                                                                          Simulation Max
                                                                          Actual Max

                                 700
                                       0        20    40             60        80            100
                                                           Schools




                                                            57
Figure A.3: Model Fit: Ankara Anatolian High Schools Nest

                 960

                 940               Simulation Min
                                   Actual Min
                 920               Simulation Max
                                   Actual Max
                 900
 Cutoff Scores




                 880

                 860

                 840

                 820

                 800

                 780

                 760
                       0       5          10          15           20          25        30
                                                    Schools




Figure A.4: Model Fit: Istanbul Anatolian High Schools Nest

                 960

                 940

                 920

                 900
 Cutoff Scores




                 880

                 860

                 840

                 820
                                                                        Simulation Min
                 800                                                    Actual Min
                                                                        Simulation Max
                 780                                                    Actual Max

                 760
                       0   5         10        15     20      25          30        35   40
                                                    Schools




                                                     58
Figure A.5: Model Fit: Izmir Anatolian High Schools Nest

                960

                940       Simulation Min
                          Actual Min
                920       Simulation Max
                          Actual Max
                900
Cutoff Scores




                880

                860

                840

                820

                800

                780

                760
                      0   5           10             15   20   25
                                           Schools




                                            59
