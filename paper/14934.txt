                              NBER WORKING PAPER SERIES




              THE RANDOM COEFFICIENTS LOGIT MODEL IS IDENTIFIED

                                          Patrick Bajari
                                           Jeremy Fox
                                           Kyoo il Kim
                                         Stephen P. Ryan

                                       Working Paper 14934
                               http://www.nber.org/papers/w14934


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                                     April 2009




Bajari thanks the National Science Foundation, various grants, for generous research support. Fox
thanks the National Science Foundation, the Olin Foundation, and the Stigler Center for generous
funding. Thanks to helpful comments from Azeem Shaikh. The views expressed herein are those of
the author(s) and do not necessarily reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

¬© 2009 by Patrick Bajari, Jeremy Fox, Kyoo il Kim, and Stephen P. Ryan. All rights reserved. Short
sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided
that full credit, including ¬© notice, is given to the source.
The Random Coefficients Logit Model Is Identified
Patrick Bajari, Jeremy Fox, Kyoo il Kim, and Stephen P. Ryan
NBER Working Paper No. 14934
April 2009
JEL No. C14,C25,L00

                                             ABSTRACT

The random coefficients, multinomial choice logit model has been widely used in empirical choice
analysis for the last 30 years. We are the first to prove that the distribution of random coefficients in
this model is nonparametrically identified. Our approach exploits the structure of the logit model, and
so requires no monotonicity assumptions and requires variation in product characteristics within only
an infinitesimally small open set. Our identification argument is constructive and may be applied to
other choice models with random coefficients.


Patrick Bajari                                      Kyoo il Kim
Professor of Economics                              Department of Economics
University of Minnesota                             University of Minnesota
4-101 Hanson Hall                                   949 Heller Hall
1925 4th Street South                               271 19th Ave South
Minneapolis, MN 55455                               Minneapolis, MN 55455
and NBER                                            kyookim@umn.edu
bajari@econ.umn.edu
                                                    Stephen P. Ryan
Jeremy Fox                                          MIT Department of Economics
Department of Economics                             E52-262C
University of Chicago                               50 Memorial Drive
1126 East 59th Street                               Cambridge, MA 02142
Chicago, IL 60637                                   and NBER
and NBER                                            sryan@mit.edu
fox@uchicago.edu
1        Introduction
In economics, it is common to observe that otherwise identical agents behave differently when
faced with identical choice environments, due to such factors as heterogeneity in preferences. A
growing econometric literature has addressed this problem by providing estimators that allow the
coefficients of the economic model to vary across agents. One of the most commonly used models
in applied choice analysis is the random coefficients logit model, which models the decision of a
consumer to choose between one of a finite number of competing alternatives. Hausman and Wise
(1978) introduced flexible specifications for discrete choice models, while Boyd and Mellman (1980)
as well as Cardell and Dunbar (1980) introduced the random coefficients logit model. Since then,
the random coefficients logit model has formed the basis for hundreds of empirical studies. The
book by Train (2003) calls the random coefficients logit the ‚Äúmixed logit‚Äù. An expanded version of
the random coefficients logit that deals with aggregate demand shocks was introduced by Berry,
Levinsohn and Pakes (1995) and itself has been used in hundreds of studies, including Nevo (2001)
and Petrin (2002).
        In the random coefficients logit, consumers can choose between j = 1, ..., J mutually exclusive
inside goods and one outside good. The exogenous variables for choice j are in the K √ó 1 vector
xj . In the example of demand estimation, xj might include the product characteristics of good j
and the demographics of the consumer. We shall let x = (x01 , ..., x0J )0 denote the stacked vector of
all the xj . Each consumer has a preference parameter Œ≤, which is a vector of K marginal utilities
that give the consumer‚Äôs preferences over the K product characteristics. The consumer‚Äôs utility for
choice j is equal to
                                                      ui = x0j Œ≤ + j .                                           (1)

The outside good has a utility of u0 = 0 . The logit model is defined when the errors j are
i.i.d. across choices and each error has the Type I extreme value distribution, which has a CDF
of exp (‚àí exp (‚àíj )).1 The random coefficients logit arises when Œ≤ varies across the population,
with unknown density f (Œ≤). The object of identification is the density f . Under the standard
assumption that Œ≤ is independent of x, choice probabilities are
                                                                   
                                                  Z       exp x0j Œ≤
                               Pr (j | x; f ) =                            f (Œ≤) dŒ≤.                             (2)
                                                       1 + Jh=1 exp x0h Œ≤
                                                          P

    1
    The Type I extreme value distribution gives the scale normalization for utility values. The outside good‚Äôs utility
gives the location normalization.




                                                             2
This specification is popular with empirical researchers because the resulting choice probabilities
are relatively flexible. Let price be in xj . In terms of modeling own and cross-price elasticities,
the random coefficients logit model allows products with similar x‚Äôs to be closer substitutes, which
the logit model without random coefficients does not allow. McFadden and Train (2000) consider
a nonparametric choice of f and allow the linear index x0j Œ≤ to be a flexible polynomial in some
underlying product characteristics. They prove that this combination can flexibly approximate any
choice probabilities (using the same underlying product characteristics) that arise from a random
utility model. McFadden and Train do not study identification.
       Previous empirical implementations have made functional form assumptions (often normal) on
f , so that f is known up to a finite vector of parameters. We are the first to explore whether the
distribution f is nonparametrically identified: whether variation in x is enough so that the true
f 0 is the only f that solves (2) for some j and all x. In operator notation, (2) can be written as
Pj = Qj (f ). The density f 0 is nonparametrically identified if the choice probability operator Qj
is one-to-one: each density f gives a unique choice-probability (data) function Pj . For the true f 0
and an alternative f 1 6= f 0 , Qj being one-to-one is equivalent to saying there exists an x where
Pr j | x; f 0 6= Pr j | x; f 1 .2
                             

       Our identification theorem is constructive. We iteratively find all moments of Œ≤, and thus
identify the density f 0 within the class of densities that are uniquely determined by all of their
moments. This class is the class of densities that satisfies Carleman‚Äôs condition, which we review
below. Our proof strategy is not unique to the logit: it could be applied to identify the density of
heterogeneity in many differentiable economic models. We outline the main theorem using generic
notation and verify its main condition for the multinomial logit model.
       Showing that the density f 0 is nonparametrically identified is a necessary component for any
consistency proof for a nonparametric estimator of f . Indeed, we introduce a computationally
simple, nonparametric sieve estimator for f 0 in Bajari, Fox, Kim and Ryan (2009) for general
mixtures models. This identification theorem therefore completes our proof of consistency for the
estimator of the random coefficients logit in Bajari et al. Identification does not rule out that the
operator Qj has a discontinuous inverse and that the estimation problem is ill-posed. Hence, we
use a sieve estimator to gain consistency under a potential ill-posed inverse problem. Alternative
nonparametric estimators include the Bayesian MCMC estimator in Rossi, Allenby, and McCulloch
   2
     Our identification
                      ` approach  ¬¥ applies
                                        ` to differentiable,    and hence continuous, functions Pr (j | x; f ). Hence,  if there
                                0                  1
                                                                                                                          f 0 6=
                                                     ¬¥                                                            `          ¬¥
exists an x where  Pr  j | x; f    6
                                   = Pr   j | x; f    , by continuity there will exist a continuum of x where  Pr  j | x;
Pr j | x; f 1 . If x has
   `         ¬¥
                      ` positive ¬¥ support    on an ¬¥ open set in this continuum, there will exist a positive probability of
covariates where Pr j | x; f 0 6= Pr j | x; f 1 . This positive probability of x‚Äôs is necessary to prove the consistency
                                        `

of extremum estimators.


                                                               3
(2005) and the EM algorithm used in Train (2008). Neither work discusses consistency, ill-posedness,
or identification.
    The proof of identification is also comforting to empirical researchers. Prior to our theorem,
it was not known whether variation in x was sufficient to identify the density f 0 . One possibility
was that the normality assumptions typically imposed on f 0 were crucial to identification: without
restricting attention to a particular parametric functional form, two f ‚Äôs would indeed solve (2) for
all x, even with data on a continuum of x. We show that indeed the random coefficients logit
model is identified, which provides backing to its immensely large use in the empirical industrial
organization, marketing, transportation, environmental and engineering literatures.


2    Previous and Subsequent Literature
Previously, Ichimura and Thompson (1997) studied the case of binary choice: one inside good
(J = 1) and one outside good. The binary-choice restriction makes their method inapplicable for
most empirical applications to demand analysis. Ichimura and Thompson identify the CDF of,
in our notation, (Œ≤, 1 ‚àí 0 ). They use a theorem due to Cram√©r and Wold (1936) and do not
exploit the structure of the extreme value assumptions on the 1 and 0 . Consequently, they need
stronger assumptions: a monotonicity assumption (sign restriction) on one of the K components of
Œ≤ (Œ≤k > 0 for all consumers) and a full support assumption for all K elements of x1 . In contrast, we
need only local variation in one xj within an infinitesimally small open set. Gautier and Kitamura
(2008) provide a computationally simpler estimator and some alternative identification arguments
(the results are equivalent) for the same binary choice model as Ichimura and Thompson.
    The identification of the logit mixtures model occurs by varying the linear index x0j Œ≤ around a
neighborhood of 0. This is a very local form of identification, and is much weaker on the data than
identification arguments that rely on identification at infinity, such as Lewbel (2000). On the other
hand, Lewbel uses a large-support ‚Äúspecial regressor‚Äù to avoid our assumption of the independence
of x and , does not require that all elements of xj be continuous, and does not use the logit, so
the two sets of assumptions are non-nested. Lewbel does not identify the distribution of random
coefficients,
              but the centrality
                                 parameters E [Œ≤] and the distribution M of the remaining errors,
      0       0
M xj Œ≤ ‚àí xj E [Œ≤] + j | x , which is not enough for some structural uses of demand systems, as
explained below in the Berry and Haile discussion.
    Subsequent to the circulation of this theorem, Berry and Haile (2008) and Fox and Gandhi (2009)
introduced identification arguments for multinomial choice models without the Type I extreme
value distribution or additive errors. Like the analysis of binary choice in Ichimura and Thompson

                                                 4
(1997), both Berry and Haile and Fox and Gandhi need a monotonicity assumption on one of
the K components of Œ≤ (Œ≤k > 0 for all consumers) and (for full identification) a full support
assumption on the corresponding kth component xk,j , for all choices j ‚àà J. By exploiting the
functional form assumption on the j ‚Äôs, we do not need extreme values of covariates to induce
switching behaviour for consumers with very high values of j . Berry and Haile identify only the
conditional-on-x distribution of utility values G (u0 , u1 , . . . , uJ | x) and not f (Œ≤). Knowledge of
the full structural model, in the logit case f (Œ≤), is necessary for welfare analysis, for example to
construct the distribution of welfare gains between choice situations x1 and x2 , or H ‚àÜu | x1 , x2 ,
                                                                                                   

where
                                      ‚àÜu = max uj x1 ‚àí max uj x2 ,
                                                               
                                             j‚ààJ‚à™{0}            j‚ààJ‚à™{0}

               1     is just the realized utility value (1) for x1 = x11 , . . . , x1J . Fox and Gandhi do identify
                                                                                     
where uj x
the full structural model, in that they identify a distribution D over J utility functions (not utility
values) of x, as in D (u1 (x) , . . . , uJ (x)), where uj (x) is a complete function that describes utility
values for choice j at all x. Again, like Berry and Haile, Fox and Gandhi rely on monotonicity and
large support assumptions on a single regressor, if the true model has additive errors j in it. Fox
and Gandhi work in the class of multinomial distributions with unknown numbers and identities
of support points, which is non-nested with our class of distributions, those that admit a density
satisfying Carleman‚Äôs condition.3
        Our paper focuses on continuous covariates in x. All arguments can be made conditional on
the values of discrete covariates, but no paper has explored identifying a distribution of random
coefficients on discrete covariates in a discrete choice setting.


3        Main Theorem
When stating the main theorem, we shall consider a more general model which includes the random
coefficients logit as a special case. In the next section we verify the key condition for the multinomial
logit. The econometrician observes covariates x and the probability of some binary outcome, P (x).
For a model with a more complex outcome (including a continuous outcome y), we can always
                                             1
consider whether some event (y <             2   say) happened or did not happen. P (x) is the probability
of the event happening. x is independent of Œ≤. Let g (x, Œ≤) be the probability of an agent with
    3
   Lewbel, Berry and Haile and Fox and Gandhi all discuss using instrumental variables for identification when
some regressors are not independent of unobservables. We do not discuss endogenous regressors here, in concert with
many empirical applications of the multinomial logit model.



                                                           5
characteristics Œ≤ taking the action. Our goal is to identify the density function f in the equation
                                                         Z
                                              P (x) =        g (x, Œ≤) f (Œ≤) dŒ≤.                                   (3)


Identification means that a unique f solves this equation for all x.4
      Here we propose to identify the density of f by finding its moments when g is differentiable
and satisfies the single-index condition g (x, Œ≤) = g (x0 Œ≤). A probability measure f satisfying the
Carleman condition is uniquely determined by its moments (Shohat and Tamarkin 1943, p. 19).
The Carleman condition is weaker than requiring the moment generating function to exist.

Assumption 3.1

                                                                   kŒ≤kl f (Œ≤) dŒ≤, are finite for l ‚â• 1 and satisfy the
                                                               R
      ‚Ä¢ The absolute moments of f , given by ml =
                                           ‚àí1/l
        Carleman condition: Œ£l‚â•1 ml               = ‚àû.

      The Carleman condition gives uniqueness for distributions with unrestricted support. If the
support of Œ≤ is known and compact, uniqueness follows without the Carleman condition. The
component function g (x0 Œ≤) does not have to be a distribution function. We mainly require that
g (x0 Œ≤) be continuously differentiable. We do heavily exploit the linear index x0 Œ≤.

Assumption 3.2

      ‚Ä¢ g (x0 Œ≤) ‚àà C ‚àû (infinitely continuously differentiable) in a neighborhood of x = 0.

      ‚Ä¢ g (l) (0) is nonzero and finite for all l ‚â• 1 where g (l) (¬∑) denotes the lth derivative of g(¬∑).

      Assumption 3.2 restricts the class of g (x0 Œ≤). Some classes of functions satisfy the condition but
others do not. For example, if g (w) = C ¬∑ exp (w), then Assumption 3.2 is trivially satisfied, because
g (l) (0) = C for all l. If g (x0 Œ≤) is a polynomial function of any finite degree, g does not satisfy the
condition because its derivative becomes zero at a certain point. For polynomials, we identify the
density f up to the vth moment, where v is the order of the polynomial function. Because of our
focus on differentiability, we require covariates with continuous support, but not at all wide support.

Assumption 3.3

      ‚Ä¢ The covariates in the vector x take on support in an open set containing x = 0.
  4
      This is the definition used in the statistics literature, see Teicher (1963).


                                                               6
      We observe P (x) in the population data and know the function g. We wish to identify the
density f . The general identification argument can be illustrated for the special case where K = 2
and so x0 Œ≤ = x1 Œ≤1 + x2 Œ≤2 . At x1 = x2 = 0,
                                                           Z
                              ‚àÇP (x)
                                             = g (1) (0)       Œ≤1 f (Œ≤) dŒ≤ = g (1) (0) E [Œ≤1 ] ,
                               ‚àÇx1     x=0

where Œ≤1 arises from the chain rule and the expression identifies the mean of Œ≤1 , because P (x)
                                                                                                            ‚àÇP (x)
is data and g (1) (0) is a known constant that does not depend on Œ≤.5 Likewise,                              ‚àÇx2 x=0 /g
                                                                                                                        (1) (0)

                  ‚àÇ 2 P (x)      (2) (0)                                ‚àÇ 2 P (x)
                                                                                     /g (2) (0)            E Œ≤12 . Additional
                                                                                                              
equals E [Œ≤2 ],   ‚àÇx1 ‚àÇx2 x=0 /g           equals E [Œ≤1 Œ≤2 ], and         ‚àÇ 2 x1 x=0
                                                                                                  equals
derivatives will identify the other moments of Œ≤ =                  (Œ≤1 , Œ≤2 ).

Theorem 3.1

      ‚Ä¢ Suppose Assumptions 3.1, 3.2 and 3.3 hold. Then the true f 0 is identified.

      ‚Ä¢ Assume the lth derivative of g (z) is nonzero when evaluated evaluated at z = 0. Then under
        Assumption 3.3, all moments of order l (including cross moments) of the elements of the
        vector Œ≤ are identified.


      The proof is in the appendix. Note the approach‚Äôs simplicity: we need only to check for non-
zero derivatives of g (z) at z = 0. This technique can be applied to show identification of many
differentiable economic models. The approach is also constructive: if g 2 (0) 6= 0, we can identify all
own second derivatives and all cross-partial derivatives between two random coefficients. If only the
first 100 derivatives of g (z) at z = 0 are nonzero, then we identify at least the first 100 moments of
the random coefficients.
      The problem of identifying a distribution uniquely from the first L moments of the corresponding
random variable is known as the determinacy (unique solution) of the truncated Hamburger moment
problem (Akhiezer 1965, Krein and Nudel‚Äôman 1973). Truncated moment problems are a well
studied topic in probability theory. A key tool is a Hankel matrix, which is formed from the first L
moments. If the Hankel matrix has a zero determinant, a unique distribution has these particular L
moments. Extensions of these results exist for multidimensional random variables (Akhiezer 1965).
What is important here is that results on the truncated moments problem exist and are not related
to the type of economic model in which the unobserved heterogeneity enters.
  5
      Assumption 3.2 allows us to exchange differentiation and integration, via Leibniz‚Äôs integral rule.



                                                                7
4      Identification of The Logit Model
We can fit the random coefficients logit model into the mixtures framework by defining the logit
choice probabilities for some particular choice j as
                                                               
                                                      exp x0j Œ≤
                                        g (x, Œ≤) =                    .
                                                   1 + Jh=1 exp x0h Œ≤
                                                      P


To highlight our main result, we state as a theorem that the logit model is identified. Surprisingly,
identification in the random coefficients logit model has never been proved despite its 30 years of
use.

Theorem 4.1

     ‚Ä¢ Let Assumptions 3.1 and 3.3 hold. Let g (¬∑) be the random coefficients logit model with J ‚â• 2
        inside goods and one outside good. Then the true f 0 is identified.


     The proof in the appendix uses Theorem 3.1; the proof consists largely of verifying Assumption
3.2. The key idea in the proof is the use of the ‚Äúrational zero test‚Äù, which allows us to focus on the
integer solutions to polynomials that arise in the expressions for the derivatives of the logit choice
probabilities.
     For the case of one inside good (J = 1), algebra (for a known order of derivatives) shows that
g (l) (0)   6= 0 when l is odd and g (l) (0) = 0 when l is even. The zero derivatives mean that we will need
to impose that the true density of Œ≤ generates statistically independent random variables. In other
words, we show the logit mixtures model with f (Œ≤) = K
                                                         Q
                                                            k=1 fk (Œ≤k ) (an independent multivariate
distribution) that also satisfies Assumptions 3.1 and 3.3 is identified. We identify the odd moments
of Œ≤ using Theorem 3.1, but because f (Œ≤) = K
                                               Q
                                                 k=1 fk (Œ≤k ), we also identify any even moments. To
see this for an example, from Theorem 3.1 we can obtain two odd moments such as E Œ≤1 Œ≤22 and
                                                                                              

E [Œ≤1 ]. As Œ≤1 and Œ≤2 are independent, we also obtain the even moment E Œ≤22 = E Œ≤1 Œ≤22 /E [Œ≤1 ].
                                                                                          



5      Conclusions
The random coefficients logit model has been used in empirical studies for over 30 years. We
are the first to show that the density of random coefficients is nonparametrically identified. This
allows complete proofs for the consistency of nonparametric estimators of the density of random


                                                       8
coefficients. We also confirm to empirical researchers that identification of the density of preferences
relies on variation in covariates and not only on functional form assumptions for the density.
    Compared to previous and subsequent identification results in the literature for binary and
multinomial choice, we exploit the type I extreme value distribution on the additive errors. Thus,
we remove the need to consider the monotonicity and large support assumptions needed in the
literature.


A     Proofs of the Theorems
A.1    Proof of Theorem 3.1
First we introduce some notation for gradients of arbitrary order, which we need because f (Œ≤) has
a vector of K arguments, Œ≤. Let w be a vector of length W . For a function h (w), we denote the
1 √ó K v block vector of œÖth order derivatives as ‚àáœÖ h (w). ‚àáœÖ h (w) is defined recursively so that the
kth block of ‚àáœÖ h (w) is the 1 √ó W vector hœÖk (w) = ‚àÇhœÖ‚àí1     0         œÖ‚àí1
                                                      k (Œ∏)/‚àÇw , where hk   is the kth element of
                                                                                  ‚àÇ œÖ h(w)
‚àáœÖ‚àí1 h (w). Using a Kronecker product ‚äó, we can write ‚àáœÖ h (w) =            0       0             .
                                                                     |‚àÇw ‚äó ‚àÇw {z   ‚äó . . . ‚äó ‚àÇw}0
                                                                       œÖ Kronecker product of ‚àÇw0
    Take the derivatives with respect to the covariates x of both sides of P (x) = g (x0 Œ≤) f (Œ≤) dŒ≤
                                                                                       R

and evaluate the derivatives at x = 0. By Assumption 3.2, for any v = 1, 2, . . . and the chain rule
repeatedly applied to the linear index x0 Œ≤,
                                    Z
                                      g (v) x0 Œ≤
                                                        0
                      œÖ
                                                        Œ≤ ‚äó Œ≤ 0 ‚äó ¬∑ ¬∑ ¬∑ ‚äó Œ≤ 0 f (Œ≤) dŒ≤
                                                 
                    ‚àá P (x)|x=0 =                                                                   (4)
                                                   x=0
                                            Z
                                                0
                                    (v)
                                 = g (0)         Œ≤ ‚äó Œ≤ 0 ‚äó ¬∑ ¬∑ ¬∑ ‚äó Œ≤ 0 f (Œ≤) dŒ≤.


For each v there are K v equations. Recall g is a known function. Therefore, as long as g (v) (0) is
nonzero and finite for all v = 1, 2, . . .., we obtain the vth moments of f for all v ‚â• 1. Now by
Assumption 3.1, f satisfies the Carleman condition. Therefore, f is identified since a probability
measure satisfying the Carleman condition is uniquely determined by its moments.

A.2    Proof of Theorem 4.1
Identification arises from identifying all moments, as in Theorem 3.1. The main condition to verify
is Assumption 3.2: all derivatives are nonzero when evaluated at 0. Let xh = 0 for all h 6= j. With




                                                   9
one outside good and J inside goods, the choice probability of alternative j given Œ≤ is
                                                                                                                  
                                                                              exp x0j Œ≤                   exp   x 0Œ≤
                                                                                                                  j
 gj x01 Œ≤, . . . , x0j Œ≤, . . . , x0J Œ≤ = gj   0, . . . , x0j Œ≤, . . . , 0 =
                                                                         
                                                                                                    =               .
                                                                             1 + (J ‚àí 1) + exp x0j Œ≤    J + exp x0j Œ≤

                       ea
Define gJ (a) =       J+ea   and let Dap denote the derivative operator of order p with respect to a. We
wish to show
                                 Dap gJ (a)|a=0 6= 0 for all integer J ‚â• 2 and for all p.

We obtain


                                             1                              1
                                                    Jea , Da2 gJ (a) =              J 2 ea ‚àí Je2a
                                                                                                  
                  Da gJ (a) =                     2                               3
                                       (J   + ea )                      (J + ea )
                                             1
                  Da3 gJ (a) =                         3 a        2 2a      3a
                                                                               
                                               a  4 J e ‚àí 4J e + Je
                                       (J   +e )
                                             1
                  Da4 gJ (a) =                         4 a         3 2a        2 3a       4a
                                                                                             
                                                     J   e  ‚àí 11J   e   + 11J    e  ‚àí  Je
                                       (J   + ea )5
                                             1
                  Da5 gJ (a) =                       J 5 ea ‚àí 26J 4 e2a + 66J 3 e3a ‚àí 26J 2 e4a + Je5a
                                                                                                       
                                                  6
                                       (J   + ea )
                                  ..
                                   .

For p ‚â• 3, now we denote the (p ‚àí 1)th derivative as

                                                                    p‚àí1
                                                             1      X    (p)
                                        Dap‚àí1 gJ (a)   =                Œ∏p‚àíj J p‚àíj eja .
                                                         (J + ea )p
                                                                     j=1


Then, we can write the p-th derivative as




                                                               10
       Dp gJ (a)
       Ô£Æa                                  Ô£π
                      p
               1      X  (p+1)
     = Ô£∞        a p+1
                        Œ∏p+1‚àíj J p+1‚àíj eja Ô£ª                                                             (5)
         (J + e )
                            j=1

     = Da Dap‚àí1 gJ (a)
          Ô£Æ                               Ô£π
                       p‚àí1
                 1     X    (p)
     = Da Ô£∞                Œ∏p‚àíj J p‚àíj eja Ô£ª
            (J + ea )p
                             j=1
                      p‚àí1                                      p‚àí1
             1        X       (p)                    1         X (p)
     =                      jŒ∏p‚àíj J p‚àíj eja   ‚àí              p  Œ∏p‚àíj J p‚àíj e(j+1)a
         (J + ea )p                             (J + ea )p+1
                      j=1                                      j=1
                        Ô£´                                                            Ô£∂
                                      p‚àí1                      p‚àí1
              1       Ô£≠(J + ea )
                                      X  (p)
                                                               X (p)
     =                                 jŒ∏p‚àíj J p‚àíj eja ‚àí       pŒ∏p‚àíj J p‚àíj e(j+1)a Ô£∏
         (J + ea )p+1
                                   j=1                     j=1
                      Ô£´                                                                                Ô£∂
                        p‚àí1                       p‚àí1                          p‚àí1
              1        X       (p)
                                                  X       (p)
                                                                               X     (p)
     =                Ô£≠     jŒ∏p‚àíj J p+1‚àíj eja +        jŒ∏p‚àíj J p‚àíj e(j+1)a ‚àí       pŒ∏p‚àíj J p‚àíj e(j+1)a Ô£∏
         (J + ea )p+1
                        j=1                       j=1                          j=1
                          (p) p a       Pp‚àí1 0 (p) p+1‚àíj 0 j 0 a Pp‚àí1 (p) p‚àíj (j+1)a !
              1          Œ∏p‚àí1 J e + j 0 =2 j Œ∏p‚àíj 0 J           e + j=1 jŒ∏p‚àíj J e
     =         a  p+1                            Pp‚àí1 (p) p‚àíj (j+1)a                                      (6)
         (J + e )                              ‚àí j=1 pŒ∏p‚àíj J e
                          (p)           Pp‚àí2            (p)                     Pp‚àí1 (p) p‚àíj (j+1)a !
              1          Œ∏p‚àí1 J p ea + j=1    (j + 1)Œ∏p‚àíj‚àí1 J p‚àíj e(j+1)a + j=1       jŒ∏p‚àíj J e
     =         a  p+1                                Pp‚àí1 (p) p‚àíj (j+1)a                                  (7)
         (J + e )                                 ‚àí j=1 pŒ∏p‚àíj J e
                      Ô£´                                                                                  Ô£∂
                                       p‚àí2
              1          (p) p a
                                      X              (p)          (p)       (p)                    (p)
     =         a  p+1
                      Ô£≠Œ∏p‚àí1   J e +        {(j + 1)Œ∏p‚àíj‚àí1 + jŒ∏p‚àíj ‚àí pŒ∏p‚àíj }J p‚àíj e(j+1)a ‚àí Œ∏1 J 1 epa Ô£∏(8)
         (J + e )
                                          j=1


where in (6) and (7), we take out the first element in the first sum and change the index j 0 to j + 1.
(8) is obtained by rearranging terms and collecting coefficients on J p‚àíj e(j+1)a for j = 1 to p ‚àí 2.
                                                    (p)
   To fix the undetermined coefficients Œ∏p‚àíj ‚Äôs, we compare the coefficients from (5) and (8) and




                                                          11
obtain
p                                                     p‚àí1
       (p+1)                                                  (p+1)                          (p+1) 1 pa
X                                                     X
      Œ∏p+1‚àíj J p+1‚àíj eja   =   Œ∏p(p+1) J p ea   +            Œ∏p+1‚àíj J p+1‚àíj eja + Œ∏1                J e
j=1                                                   j=2
                                                      p‚àí2
                                                              (p+1)                          (p+1) 1 pa
                                                      X
                           =   Œ∏p(p+1) J p ea   +            Œ∏p‚àíj J p‚àíj e(j+1)a + Œ∏1                J e
                                                      j=1
                                               p‚àí2 n                               o
                                (p)                          (p)       (p)     (p)                  (p)
                                               X
                           =   Œ∏p‚àí1 J p ea   +      (j + 1) Œ∏p‚àíj‚àí1 + jŒ∏p‚àíj ‚àí pŒ∏p‚àíj J p‚àíj e(j+1)a ‚àí Œ∏1 J 1 epa .
                                                  j=1


We find

                                                (p)
                           Œ∏p(p+1) = Œ∏p‚àí1                                                                            (9)
                            (p+1)                     (p)                       (p)         (p)
                           Œ∏p‚àíj       =      (j + 1) Œ∏p‚àíj‚àí1             +     jŒ∏p‚àíj   ‚àí   pŒ∏p‚àíj   for p ‚â• 3
                            (p+1)               (p)
                           Œ∏1         =      ‚àíŒ∏1 .                                                                  (10)

                                                                                                              (2)
This system generates the coefficients for all p ‚â• 1. For the initial value, we obtain Œ∏1 = 1. When
p = 2, we find

                                                       (3)              (2)
                                                      Œ∏2       = Œ∏1 = 1
                                                       (3)                  (2)
                                                      Œ∏1       = ‚àíŒ∏1 = ‚àí1

and when p = 3, we find

                                          (4)                (3)
                                       Œ∏3        = Œ∏2 = 1
                                          (4)                 (3)        (3)          (3)
                                       Œ∏2        = 2Œ∏1 + Œ∏2 ‚àí 3Œ∏2 = ‚àí4
                                          (4)                  (3)
                                       Œ∏1        = ‚àíŒ∏1 = 1.

      Now we examine whether Dap gJ (a)|a=0 can take the value of zero for some p and some J. For
this purpose, we evaluate the derivatives at a = 0 and obtain equations with respect to J for the
pth order derivative as
                                                                       p
                                                                   1   X          (p+1)
                                 Dap gJ (a)|a=0 =                              Œ∏p+1‚àíj J p+1‚àíj = 0
                                                              J p+1
                                                                        j=1




                                                                       12
for all p ‚â• 1. This is equivalent to solving
                                         p
                                                (p+1)
                                         X
                                               Œ∏p+1‚àíj J p‚àíj = 0.                                      (11)
                                         j=1


Now note that the coefficient on J p‚àí1 (the highest order term in the equation) in (11) is equal to

                                                Œ∏p(p+1) = 1

                                                                               (p+1)
for all p. Also note that the constant term (the coefficient on J 0 in (11)), Œ∏1       , is equal to 1 when
p is odd and is equal to ‚àí1 when p is even. By the well-known ‚Äúrational zero test‚Äù, this implies that
the only possible positive integer solution in (11) is J = 1. A positive integer greater than 1 cannot
be the solution of (11) for any p. This concludes our claim.




                                                    13
References
 [1] Akhiezer, N.I. (1965), The classical moment problem and some related questions in analysis,
    Oliver & Boyd.

 [2] Bajari, P, JT Fox, KI Kim, and S Ryan (2009), ‚ÄúA Simple Nonparametric Estimator for the
    Distribution of Random Coefficients in Discrete Choice Models‚Äù, working paper.

 [3] Berry, S., J. Levinsohn, and A. Pakes (1995), ‚ÄúAutomobile Price in Market Equilibrium‚Äù, Econo-
    metrica (63), July 1995.

 [4] Berry, S and Haile, P. (2008), ‚ÄúNonparametric Identification of Multinomial Choice Models
    with Heterogeneous Consumers and Endogeneity‚Äù, working paper.

 [5] Boyd, JH and RE Mellman (1980), ‚ÄúEffect of Fuel Economy Standards on the US Automotive
    Market‚Äù, Transportation Research. 14(5), 367‚Äì378.

 [6] Cardell, NS and FC Dunbar (1980), ‚ÄúMeasuring the societal impacts of automobile downsizing‚Äù,
    Transportation Research. 14(5), 423‚Äì434.

 [7] Cram√©r, H. and H. Wold (1936), ‚ÄúSome Theorems on Distribution Functions‚Äù, Journal of the
    London Mathematical Society, s1-11(4), 290‚Äì294.

 [8] Fox, Jeremy T. and Amit Gandhi (2009), ‚ÄúIdentifying Heterogeneity in Economic Choice and
    Selection Models Using Mixtures‚Äù, working paper.

 [9] Gautier, Eric and Kitamura, Yuichi. (2008), ‚ÄúNonparametric Estimation in Random Coefficients
    Binary Choice Models‚Äù, working paper.

[10] Hausman, J. and D. Wise (1978), ‚ÄúA Conditional Probit Model for Qualitative Choice: Discrete
    Decisions Recognizing Interdependence and Heterogeneous Preferences‚Äù, Econometrica, 46(2),
    403‚Äì426.

[11] Ichimura, Hidehiko and T. Scott Thompson (1998), ‚ÄúMaximum likelihood estimation of a binary
    choice model with random coefficients of unknown distribution,‚Äù Journal of Econometrics,
    86(2), 269‚Äì295.

[12] Krein, M.G. and A.A. Nudel‚Äôman (1973, translation 1977), The Markov moment problem and
    extremal problems: ideas and problems of P. L. ƒåeby≈°ev and A. A. Markov and their further


                                                14
    development. Translations of mathematical monographs v. 50, American Mathematical Society,
    Providence.

[13] Lewbel, Arthur. (2000) ‚ÄúSemiparametric qualitative response model estimation with unknown
    heteroscedasticity or instrumental variables‚Äù, Journal of Econometrics, 97, 1, 145-177.

[14] McFadden, Daniel and Kenneth Train (2000), ‚ÄúMixed MNL models for discrete response‚Äù,
    Journal of Applied Econometrics, 15(5): 447‚Äì470.

[15] Nevo, Aviv. 2001, ‚ÄúMeasuring Market Power in the Ready-to-Eat Cereal Industry‚Äù, Economet-
    rica, 69(2): 307‚Äì342.

[16] Petrin, Amil (2002), ‚ÄúQuantifying the Benefits of New Products: The Case of the Minivan‚Äù,
    Journal of Political Economy, 110:705-729, 2002.

[17] Rossi, Peter E., Greg M. Allenby, and Robert McCulloch (2005), Bayesian Statistics and Mar-
    keting. West Sussex: John Willy & Sons.

[18] Shohat, J.A. and Tamarkin, J.D. (1943), The Problem of Moments, American Mathematics
    Society, Providence, RI.

[19] Teicher, H. (1963), ‚ÄúIdentifiability of Finite Mixtures‚Äù, Annals of Mathematical Statistics, 34,
    1265-1269.

[20] Train, Kenneth. 2003. Discrete choice methods with simulation. Cambridge.

[21] Train, Kenneth. 2008. ‚ÄúEM Algorithms for Nonparametric Estimation of Mixing Distributions.‚Äù
    Journal of Choice Modeling, 1, 1, 40‚Äì69.




                                                 15
