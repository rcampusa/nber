                                NBER WORKING PAPER SERIES




                       TRANSPARENCY IN STRUCTURAL RESEARCH

                                           Isaiah Andrews
                                         Matthew Gentzkow
                                          Jesse M. Shapiro

                                        Working Paper 26631
                                http://www.nber.org/papers/w26631


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                     January 2020




Prepared as a discussion paper for the Journal of Business and Economic Statistics. We
acknowledge funding from the National Science Foundation, the Brown University Population
Studies and Training Center, and the Stanford Institute for Economic Policy Research (SIEPR).
Patrick Kline, Emi Nakamura, participants in a 2020 ASSA session, discussants Stephane
Bonhomme, Christopher Taber, and Elie Tamer, editor Christian Hansen, and an anonymous
associate editor provided valuable comments. We thank our many dedicated research assistants
for their contributions to this project.The views expressed herein are those of the authors and do
not necessarily reflect the views of the National Bureau of Economic Research.

At least one co-author has disclosed a financial relationship of potential relevance for this research.
Further information is available online at http://www.nber.org/papers/w26631.ack

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2020 by Isaiah Andrews, Matthew Gentzkow, and Jesse M. Shapiro. All rights reserved. Short sections
of text, not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including © notice, is given to the source.
Transparency in Structural Research
Isaiah Andrews, Matthew Gentzkow, and Jesse M. Shapiro
NBER Working Paper No. 26631
January 2020, Revised July 2020
JEL No. C10

                                        ABSTRACT

We propose a formal definition of transparency in empirical research and apply it to structural
estimation in economics. We discuss how some existing practices can be understood as attempts
to improve transparency, and we suggest ways to improve current practice, emphasizing
approaches that impose a minimal computational burden on the researcher. We illustrate with
examples.

Isaiah Andrews                                 Jesse M. Shapiro
Department of Economics                        Economics Department
Harvard University                             Box B
Littauer M18                                   Brown University
Cambridge, MA 02138                            Providence, RI 02912
and NBER                                       and NBER
iandrews@fas.harvard.edu                       jesse_shapiro_1@brown.edu

Matthew Gentzkow
Department of Economics
Stanford University
579 Jane Stanford Way
Stanford, CA 94305
and NBER
gentzkow@stanford.edu
1       Introduction

Structural empirical research can sometimes look like a black box. Once upon a time, a structural
paper might begin with an elaborate model setup containing dozens of assumptions, present a
similarly complex recipe for estimation, and then jump immediately to reporting model estimates
and counterfactuals that answer the research question of interest. A reader who accepted the full
list of assumptions could walk away having learned a great deal. A reader who questioned even
one of the assumptions might learn very little, as they would find it hard or impossible to predict
how the conclusions might change under alternative assumptions.
    Modern research articles taking a structural approach often look very different from this carica-
ture. Many devote significant attention to descriptive analysis of important facts and relationships
in the data. Many provide detailed discussions of how these descriptive statistics relate to the struc-
tural estimates, connecting specific data features to key parameter estimates or conclusions. Such
analysis has the potential to make structural estimates more transparent, helping skeptical readers
learn from the results even when they do not fully accept all the model assumptions.
    In this paper, we consider the value of transparency in structural research. We propose a formal
definition of the transparency of a statistical report. We argue that our definition provides a ratio-
nale for many current practices, and suggests ways these practices can be improved. We discuss
these potential improvements, emphasizing those that impose a minimal computational burden on
the researcher.
    Our definition of transparency follows the one proposed in Andrews et al. (2017).1 We situate
it in a model of scientific communication based on Andrews and Shapiro (2020). In the model, a
researcher observes data informative about a quantity of interest c. The researcher reports an esti-
mate c                                      ^ to a set of readers indexed by r. Under the researcher's
     ^ of c along with auxiliary statistics t
maintained assumptions a0 , c
                            ^ is valid, for example in the sense that it is asymptotically normal and
unbiased. Not all readers accept a0 , however, and different readers may entertain different alterna-
tive assumptions a = a0 . After receiving the report (c  ^), each reader updates their prior beliefs,
                                                      ^, t
selects an estimate dr of c, and realizes a quadratic loss (dr - c)2 . For a given reader, we define the
transparency of the report to be the reduction in expected loss from observing (c  ^), relative to the
                                                                                ^, t
reduction from observing the full data. In other words, research is transparent to the extent that it
makes it easy for readers to reach the same inference about c that they would reach by analyzing

1 See   also the discussions of transparency in Angrist and Pischke (2010) and Heckman (2010).


                                                           2
the data in full under their preferred assumptions. We show that transparency is distinct from other
econometric desiderata such as efficiency and robustness.
    After describing our model and definition of transparency in section 2, we discuss several
practices that we believe can improve the transparency of structural estimation. We illustrate
throughout with stylized examples drawn from our model and real-world examples drawn from
the literature.
                                                                                 ^ statistics s
    Section 3 discusses descriptive analysis, which we interpret as including in t            ^ that are
either directly informative about the parameter of interest c, or informative about the plausibility
of the assumptions a0 . We argue that descriptive statistics of both kinds can aid transparency.
    Section 4 discusses the analysis of identification. Although transparency is a distinct property
from model identification, we argue that clear discussion of identification can improve transparency
by sharpening readers' beliefs about the appropriateness of the researcher's assumptions.
    Section 5 discusses ways to improve the transparency of the estimator. We argue that trans-
parency is improved when c
                         ^ depends to a large degree on some interpretable statistics s
                                                                                      ^ and when
the form of the relationship between the two is made clear to the reader. We suggest this as a ratio-
nale for targeting descriptive statistics directly in estimation. Building on work by Andrews et al.
(2017, forthcoming), we discuss how local approximations can be used to clarify the relationship
between c
        ^ and s
              ^.
    Section 6 discusses sensitivity analysis, which we take to encompass a range of approaches
for demonstrating the sensitivity of conclusions to alternative assumptions. When readers are
concerned about a small number of known alternative assumptions a, the researcher can improve
transparency by reporting estimates c
                                    ^a that are valid under these alternatives, as in a traditional
sensitivity analysis. When readers are concerned about a richer or unknown set of alternatives a,
then it is no longer practical to report an estimate corresponding to each of these. Building on
                                                                                    ^ statistics
work by Conley et al. (2012) and Andrews et al. (2017), we discuss how including in t
based on local approximations can help readers assess a larger set of assumptions. For cases where
a qualitative conclusion (e.g., the direction of a causal effect or welfare change) is important, we
also discuss the value of reporting features of alternative realizations of the data that would lead to
a conclusion different from the researcher's.




                                                   3
2      Transparency in a Model of Scientific Communication

2.1     Setup

A researcher observes data D  D . The researcher makes a set of assumptions a0 under which D 
F (a0 ,  ) for   H an unknown parameter. The researcher computes a point estimate c
                                                                                  ^=c
                                                                                    ^ (D) of
                                                                                       ^=t
a scalar quantity of interest c (a0 ,  ) , along with a vector of auxiliary statistics t ^ (D). The latter
may include descriptive evidence, sensitivity analysis, and various auxiliary statistics as discussed
in sections 3-6 below.2
       The researcher reports (c  ^) to readers r  R who do not have access to the underlying data.
                               ^, t
In most applications researchers and readers focus on statistics of much lower dimension than the
raw data (though researchers might also make the data available), so we will primarily consider
     ^)
dim (t        dim (D) and ask what readers learn from (c  ^). Readers are concerned that the re-
                                                       ^, t
searcher's model may be misspecified, and they consider assumptions a  A that may be different
from a0 . Under assumption a  A , D  F (a,  ) where  is again unknown, and the quantity
of interest is c (a,  ) .3 Each reader r has a prior r on the assumptions a and model param-
eter  , and aims to estimate c (a,  ), choosing a decision dr  R and incurring quadratic loss
L (dr , c (a,  )) = (dr - c (a,  ))2 .
       Following Andrews and Shapiro (2020), we define reader r's communication risk from (c  ^)
                                                                                           ^, t
as their ex-ante expected loss from taking their optimal action based on (c  ^). Under squared error
                                                                          ^, t
loss this optimal action is simply r's posterior mean for c given (c  ^), so
                                                                   ^, t


                                Er min Er (dr - c)2 |c  ^
                                                     ^, t          = Er [Varr (c|c  ^)] .
                                                                                 ^, t
                                      dr


Here Er [·] and Varr (·) denote the expectation and variance under r , respectively, and we write
c as shorthand for c (a,  ). Reader r's risk from observing the full data is Er [Varr (c|D)] 
Er [Varr (c|c  ^)]  Varr (c) , with equality in the first comparison only if r's posterior mean based
            ^, t
on (c  ^) is almost surely the same as that based on the full data.
    ^, t
       We define the transparency of (c  ^) for r as the reduction in communication risk from observing
                                      ^, t

2 In settings where c is partially identified under the assumptions a0 , one could instead take c
                                                                                                ^ to report an estimate for
  the identified set. Some of our analysis (particularly in section 5 below) would need to be adapted to this case. See
  Tamer (2010) and Molinari (2019) for overviews of the partial identification literature.
3 We assume a common parameter  for simplicity, but one could more generally have different model parameters 
                                                                                                                          a
  for each a  A . Alternatively, one can view a as just another unknown parameter, though in many interesting cases
  (a,  ) will not be jointly identified.


                                                            4
(c  ^), relative to the reduction from observing the full data
 ^, t

                                                     Varr (c) - Er [Varr (c|c  ^)]
                                                                            ^, t
                                          ^ (·)) =
                                  ^ (·) , t
                              Tr (c                                                ,
                                                     Varr (c) - Er [Varr (c|D)]

and define transparency to be one when the denominator is zero. Thus, the transparency of (c  ^)
                                                                                           ^, t
for r lies between zero and one, is equal to one when observing (c  ^) yields the same risk for r as
                                                                 ^, t
observing the full data, and is equal to zero when observing (c  ^) yields no reduction in risk, while
                                                              ^, t
observing D would yield some reduction.
      It is sometimes straightforward to construct fully transparent reports, i.e., reports with trans-
                         ^ is sufficient for (a,  ), for instance, then (c
parency equal to one. If t                                                  ^) is fully transparent for all
                                                                         ^, t
readers. When it is infeasible to report a sufficient statistic, we can still construct a fully transpar-
                                                                  ^ = Er [c|D]. Note, however, that
ent report for reader r by reporting that reader's posterior mean t
in this case (c  ^) need not be transparent for readers r with r = r . Heterogeneity in r across
              ^, t
readers is thus central to the study of transparency.


2.2     Example and Comparison to Other Econometric Properties

A linear IV example helps to fix ideas and clarify the difference between transparency and other
econometric properties. Suppose that the data D = {(Yi , Xi , Zi )}n
                                                                   i=1 consist of observations of an
outcome Yi , an endogenous regressor Xi , and a candidate instrument Zi , all of which are scalar.
Readers believe that the data follow


                                             Yi = Xi c + Zi a + i                                      (1)

                                                Xi = Zi  + Vi ,                                        (2)

where the instruments Zi are fixed. The reduced-form error from regressing Yi on Zi is Ui = cVi + i .
We assume the errors (Ui , Vi ) are i.i.d. normal across i, (Ui , Vi )  N (0, ), with  commonly
known, so the parameter is  = (c,  )  R2 . Suppose that A = R, so that assumptions a  A
correspond to the coefficient on Zi in (1) above, and that the researcher's assumption is a0 = 0.
Under assumption a0 , Zi is a valid instrument in the regression of Yi on Xi , while under a = 0 the
                                                             ^ =  ZiYi /  Zi Xi and the first-stage
exclusion restriction fails. Denote the usual IV estimate by c
coefficient by ^ =  Zi Xi /  Zi2 .
      The report c
                 ^ may not be fully transparent. For example, consider a reader r who has a degen-


                                                          5
erate prior on a = a0 but a continuous joint prior on (c,  ). Note that for n large, c
                                                                                     ^ converges in
probability to c + a/ under mild conditions. Because the reader is uncertain about the value of  ,
however, they cannot infer the value of c from the estimate c
                                                            ^ even in a large sample. By contrast,
with access to the full data they would learn the value of  , and thus be able to infer c. Thus, as
n   the transparency of c
                        ^ for such a reader is bounded away from one. In contrast, the report
(c
 ^, ^) has transparency Tr = 1 for all readers r, as (c
                                                      ^, ^) is sufficient for the unknown parameters
(c,  ). Reporting the auxiliary statistic ^ can thus improve transparency in this example.
    Transparency is distinct from a number of other properties discussed in the econometrics liter-
ature. For example, estimators are often evaluated based on their efficiency in mean squared error,
                                                                ^)2 . The estimator c
                                ^ under (a,  ) is EF (a, ) (c - c
where the mean squared error of c                                                   ~ dominates the
estimator c
          ^ in mean squared error under the assumptions a if it achieves a lower mean squared error
for all  , with strict inequality for some  . Efficiency and transparency can imply substantially
different rankings of estimators. To illustrate, continue with the instrumental variables example
and suppose along the lines of Andrews and Shapiro (2020) that all readers believe c lies between
values cL and cU with probability one, Prr {c  [cL , cU ]} = 1 for all r. Let c
                                                                              ^ again denote the IV
                                                                             ~ = max {cL , min {c
                   ~ denote the IV estimator censored to lie in [cL , cU ] , c
estimator, and let c                                                                            ^, cU }} .
The estimator c
              ~ dominates c
                          ^ in mean squared error (indeed, the mean squared error of c
                                                                                     ^ is infinite
whenever  has full rank).4 At the same time, since c                                       ^, the
                                                   ~ is a non-invertible transformation of c
report c                                            ~ for all readers r, and the report (c
       ^ is weakly more transparent than the report c                                    ^, ^) achieves
full transparency (Tr = 1) for all readers r, while the report (c
                                                                ~, ^) does not.
    While we allow the possibility that the readers and the researcher contemplate different as-
sumptions, transparency is also distinct from traditional measures of robustness. To illustrate,
note that in our instrumental variables example with A = R, the report (c
                                                                        ^, ^) is fully transparent,
                   ¯ of c have infinite worst-case mean squared error over (c, a)  R2 for any  ,
but all estimators c
                         ¯)2 = , and so are non-robust in that sense.
sup(c,a)R2 EF (a, ) (c - c
    Finally, transparency is distinct from identification. In our instrumental variables example,
(c
 ^, ^) is fully transparent, but c is unidentified under A absent further restrictions, in the sense that
any distribution for D allowed by the model is consistent with any value of c.




4 The absolute deviation of c
                            ~ from c is weakly smaller than that of c
                                                                    ^ for all realizations of the data, and strictly smaller
 for some, so c~ also dominates c^ in many other senses, e.g. as measured by quantiles of the absolute deviation.


                                                             6
2.3    Relationship to Other Recent Discussions of Transparency and Interpretability

We define transparency as a property of the statistics that the researcher reports. The usefulness of
a given statistical report depends on the reader's understanding of the process that generated the
statistic. Transparency as we define it is thus related to growing literature on research transparency
in economics, which emphasizes issues such as clear documentation of experimental procedures
(see, for example, Christensen and Miguel 2018). One focus of that literature is the open sharing
of research data, which achieves transparency equal to one for any reader r with the capacity to
analyze the full data D.
      We focus on applications to structural research in economics, where statistical methods are
often derived from explicit assumptions about economic primitives. Applications of machine
learning, by contrast, often focus on exploring relationships among observed variables without
an explicit causal framework. A recent literature considers ways to improve the interpretability of
the models used in machine learning, and of the resulting estimates (see, for example, Murdoch et
al. 2019). Some of the approaches emphasized in that literature, such as the highlighting of data
features important for a given prediction, seem related in spirit to those we discuss below.


2.4    Routes to Improved Transparency

The remaining sections of the paper discuss practical approaches to improving transparency in
structural estimation. We emphasize alternative assumptions a that we think are likely to be of most
interest to readers of structural research. Likewise, we limit attention to reporting strategies that
we view as reasonable, ruling out for instance that researchers encode the full data in the decimal
             ^. Finally, because working with nonlinear structural models is often computationally
expansion of t
expensive, we emphasize approaches that impose a minimal additional computational burden on
the researcher.


3     Descriptive Analysis

The first element that can contribute to transparent structural research is descriptive analysis. In
                                                                     ^ to include some statistics s
our framework, a descriptive analysis takes the auxiliary statistics t                            ^
that are either directly informative about c or informative about the plausibility of the assumptions
a0 . Examples include summary statistics, data visualization, or correlations illustrating key causal
relationships. Such evidence is sometimes described as "model-free," in the sense that it has a

                                                  7
meaningful interpretation that does not rely explicitly on the assumptions of the structural model.5
Pakes (2014) formalizes the role of descriptive analysis in providing a set of facts that the structural
model should rationalize.6
       Our framework suggests two ways that such descriptive analysis can improve transparency.
First, descriptive statistics s
                              ^ may provide evidence about c that is informative under a wider range
of assumptions than a0 . This would be true, for example, if |Corrr (c, s
                                                                        ^)| is large under many priors
r , including those that do not put much mass on a0 .7
       A leading case is where s
                               ^ includes convincing experimental or quasi-experimental estimates of
treatment effects closely related to c. Autor et al. (2019), for example, present quasi-experimental
evidence on the effects of disability insurance (DI) receipt in Norway on outcomes including total
income, consumption expenditure, and transfer income, using random assignment of DI judges
as a source of exogenous variation. They then estimate a structural model that allows them to
back out the welfare effects of DI awards. A reader who is skeptical of the structural model's
assumptions might still learn a lot about the welfare effects based on the descriptive evidence
alone. For example, such a reader might update positively on the welfare effects to the extent that
DI substantially increases consumption or update negatively to the extent that it crowds out other
transfer income.
       Similarly, Attanasio et al. (2012) present treatment-control differences from a randomized
evaluation of the PROGRESA conditional cash transfer that show how the program affected school
enrollment of children in various age groups. They then estimate a dynamic model of the school
enrollment decision that allows them to simulate alternative policies such as one that reallocates
grant funding from younger children to older children. The observed treatment-control differ-
ences do not speak directly to the effect of this reallocation because it was not part of the original
experiment. A reader who does not accept all of the assumptions of the structural model might
nevertheless learn a fair amount about the likely effects of the reallocation from comparing the
treatment effects on older and younger children.
       Second, descriptive statistics s
                                      ^ may provide evidence that helps readers evaluate the researcher's
assumptions a0 . Allcott et al. (2019) estimate a structural model of grocery demand that allows
them to decompose sources of nutritional inequality in the US. To estimate price sensitivity, the

5 See,   for example, Polyakova (2016) and Rossi and Chintagunta (2016).
6 See   also the discussion in Lewbel (2019, section 5.1).
7 In                                ^, Er [Varr (c|s
    particular note that for scalar s                                          ^)2 , so a large correlation directly bounds
                                                   ^)]  Varr (c) 1 - Corrr (c, s
 the average posterior variance.


                                                            8
authors instrument for the price of a product in a given store with the price of the same product in
other stores in the same chain. The exclusion restriction is that the variation in prices due to the
composition of chains in a particular market is orthogonal to unobserved preference differences.
In their descriptive analysis, the authors support the plausibility of this assumption by showing that
this variation in prices is orthogonal to observed demographics that predict choices.
     Agarwal et al. (2018) use an estimated structural model of bank lending to predict the extent
to which credit expansions are passed on to borrowers. A key assumption of the model is that
borrowers' unobserved characteristics are smooth around a set of credit score thresholds where
credit limits change discontinuously. The authors' descriptive analysis confirms the "first stage"
effect of the discontinuities on credit limits and then shows that observed borrower characteristics
are smooth around the discontinuities, increasing the plausibility of the assumption that unobserved
characteristics are smooth as well.
     An important strength of descriptive analysis is that it permits a wider range of robustness
and sensitivity analysis than is typically possible for computationally demanding structural esti-
mates. Considering many alternative sets of controls, isolating variation along discontinuities, or
adding highly saturated fixed effects are often not possible in complex models. Performing such
checks is typically easier for the statistics reported in a descriptive analysis, and reporting them
can strengthen confidence in model assumptions.
     Descriptive statistics s
                            ^ can improve a reader's ability to evaluate the researcher's model even
if they do not directly test its formal assumptions. For example, if an important assumption in
the model is that a jurisdiction-level policy variable is assigned independently of unobservables,
providing a map illustrating the spatial distribution of the policy can be very helpful to a reader.8
Because many readers will have prior beliefs on the spatial distribution of unobservables, such a
map can complement more formal balance tests that evaluate the correlation of the policy variable
with observable characteristics of the jurisdiction. In a similar way, many types of summary statis-
tics and data visualization can help to sharpen readers' priors on the researcher's assumptions and
                                                                                 ^|s
                                                  ^, in the sense that Corrr (c, c
thus aid readers' interpretation of the estimator c                                ^) is much larger than
Corrr (c, c
          ^) for some realizations of s
                                      ^.




8 See,for example, Fetter and Lockwood (2018, Figure 3), Bernard et al. (2019, Figure 8), and Hackmann (2019,
 Figure 3).


                                                     9
4    Identification

A second element that can contribute to transparent research is explicit discussion of identification.
Such discussion is now common in much empirical research including structural research. Angrist
and Pischke (2010) call "a conceptual framework that highlights specific sources of variation" one
of the "hallmark[s] of contemporary applied microeconomics" (p. 12). Kleven (2018) shows that
the share of NBER working papers in public economics discussing identification has risen from
roughly zero percent in 1980 to almost 50 percent today. Of the 123 structural papers published
in the American Economic Review, Econometrica, the Quarterly Journal of Economics, and the
Journal of Political Economy between January 2018 and November 2019, 80 percent included
explicit discussion of identification.9
    Formally, a quantity c is identified in the researcher's model if c (a0 ,  ) = c (a0 ,  ) implies
F (a0 ,  ) = F (a0 ,  ) (Matzkin 2013; Lewbel 2019). In other words, distinct values of c cor-
respond to distinct distributions of the data under the researcher's maintained assumptions. A
                                                            ^ if c (a0 ,  ) = c (a0 ,  ) implies distinct
quantity c is identified by a specific vector of statistics s
                 ^ under F (a0 ,  ) and F (a0 ,  ).
distributions of s
    There is a disconnect between this formal econometric definition and the discussions of identi-
fication that appear in some empirical papers. Keane (2010, p. 6) writes,

         What is meant by `identified' [by some authors] is subtly different from the traditional
         use of the term in econometric theory.... Here, the phrase `how a parameter is identi-
         fied' refers... to a more intuitive notion that can be roughly phrased as follows: What
         are the key features of the data, or the key sources of (assumed) exogenous variation
         in the data, or the key a priori theoretical or statistical assumptions imposed in the
         estimation, that drive the quantitative values of the parameter estimates, and strongly
         influence the substantive conclusions drawn from the estimation exercise?

There are two important differences between the formal definition of identification and the "intu-
itive notion" Keane (2010) describes. First, point identification is formally a binary property. A
quantity of interest c either is or is not identified by a statistic s
                                                                     ^. It is not clear in what meaningful
sense a particular feature or source of exogenous variation could be the "key" source of identifica-
tion. Second, identification is a property of a model, not a property of an estimator. Whether or
9 Here
     we define "structural" broadly to include any paper that explicitly estimates the parameters of an economic
 model.


                                                      10
not c is identified by s
                       ^ need not be related to whether or not s
                                                               ^ "drive[s] the quantitative values of
the parameter estimates." Indeed, it is possible that c is identified by s
                                                                         ^ yet the estimator c
                                                                                             ^ does not
depend on s
          ^ at all.
    Many discussions of identification in recent structural work fit Keane's (2010) description. A
number refer to particular quantities as "primarily," "mainly," or "largely" identified by particular
data features.10 Some focus on properties of estimators rather than models, using "identification"
as essentially a synonym for "estimation."11 Many acknowledge that they are departing from
formal statements by saying they discuss identification "intuitively" or "loosely," or by noting
explicitly that they discuss relationships of individual parameters to specific statistics even though
all parameter estimates are determined jointly.12
    We believe that clear and precise discussions of identification have an important role to play in
making structural research transparent. In our framework, such discussions can be understood as
a way to communicate and clarify the implications of the baseline assumptions a0 and the space
of relevant alternatives a = a0 , allowing readers to form more precise priors r . Focusing on par-
tial identification, Tamer (2010) writes: "[The partial identification approach] links conclusions
drawn from various empirical models to sets of assumptions made in a transparent way. It al-
lows researchers to examine the informational content of their assumptions and their impacts on
the inferences made." We believe clear discussions of point identification can likewise increase
transparency.
    Such clarifying discussions would of course be unnecessary if readers could fully evaluate all
of a model's assumptions directly. In reality, doing so is difficult. The abstract mathematical space
in which assumptions are stated is often not one in which readers have well-formed intuitions.
An assumption that sounds innocuous may in fact be highly restrictive, while another that sounds
10 For  example, Beraja et al. (2018) write, "Any empirical measure of refinancing elasticities to interest rate reductions
   will always be primarily identified from recession periods" (p. 156, emphasis added). Fu and Gregory (2019) write,
   "The dispersion... is thus identified mainly from the size of RDD parameter" (p. 407, emphasis added). Crawford et
   al. (2018) write, "The pro-competitive effects of vertical integration are largely identified from the degree to which
   RSN carriage is higher for integrated distributors" (p. 893, emphasis added).
11 See, for example, the subsection titled "Identification Strategy" in Harasztosi and Lindner (2019, p. 2701), the

   section titled "Identification of Structural Parameters" in Head and Mayer (2019, p. 3095), and the section titled
   "Estimation and Identification" in Hackmann (2019, p. 1702).
12 For example, Allcott et al. (2019) write, "Loosely, the first set of moments identify the  parameters..." (p. 1827,

   emphasis added). Autor et al. (2019) write, "While the mapping between model parameters and sample moments
   is less direct for the disutility parameters, there are data moments that intuitively provide identifying information.
   While all parameters are estimated simultaneously, it can be instructive to focus on one parameter at a time" (p.
   2644, emphasis added). Fu and Gregory (2019) write, "Although all of the structural parameters are identified
   jointly, we provide a sketch of identification here by describing which auxiliary models are most informative about
   certain structural parameters" (p. 407).


                                                           11
obviously unrealistic may in fact be a reasonable approximation. Identification discussions can
illuminate the way the model's assumptions map the distribution of observables to the key quantity
c. This is often a valuable complement to direct inspection of the assumptions in mathematical
terms.
    To illustrate what we mean, suppose a discrete-choice demand model assumes that the utility of
a consumer i for a good j contains an additive error i j which is i.i.d. type 1 extreme value. How
would a reader unfamiliar with such models evaluate the distributional assumption on the error
term? Mathematically, the assumption is that the CDF of i j is F ( ) = exp (- exp (- )). Plotting
the implied CDF or PDF would show that this is a single-peaked distribution not too different from
a normal. It seems challenging to judge by introspection whether either the formula or the plot is
a reasonable representation of the distribution of consumer utility, or under what circumstances it
would be a better or worse approximation.
    Studying the implications of the extreme value assumption for identification turns out to be
instructive. As is now well understood (e.g., Anderson et al. 1992), imposing this form on the
errors can mean that the share of consumers choosing each good j is alone sufficient to identify:
(i) the relative own-price elasticities and markups of any two goods j and k; (ii) how consumers
reallocate if any good is removed from the choice set; (iii) relative consumer welfare under different
choice sets. An unfamiliar reader who learned these implications might update in the direction of
thinking the distributional assumption is stronger than they thought and worth additional scrutiny.
The reader might also be able to form new intuitions about what alternative assumptions a are
most relevant to consider -- for example, alternative error distributions that decouple substitution
patterns from market shares (Berry et al. 1995).
    We suggest that two principles should guide discussions of identification. First, these discus-
sions should be precise, with the verb "identify" used only in its formal econometric sense. It is
best to avoid quantitative modifiers like "primarily identifies" or "mainly identifies" with uncer-
tain meaning. Like any other theoretical statement, statements about identification that are not
immediately obvious should either be accompanied by formal proof or introduced explicitly as
conjectures.
    The statement that a quantity c "is identified by" a particular vector of statistics s
                                                                                         ^ should mean
that the distribution of s
                         ^ is sufficient to infer the value of c under the model. If this statement applies
only given knowledge of some other parameters, then this should be made explicit. Looking over
cases in the recent literature where authors claim something is "identified by" specific features of


                                                    12
the data, one sees three common structures of argument.13 The first structure is to prove identifi-
cation as a formal proposition.14 The second structure is an informal "triangular" argument. In the
case where the object of interest is a parameter vector  , this might show that 1 is identified by a
statistic s
          ^1 alone, 2 is identified by s
                                       ^2 once the value of 1 is known, 3 is identified by s
                                                                                           ^3 once
the values of 1 and 2 are known, and so on.15 When formalized, this can of course be a valid
method of proof that  is identified by s
                                       ^. The final structure is an elementwise argument where say-
ing that  j is identified by s
                             ^k means this is true given that all other elements of  are known. Many
"heuristic" or "informal" discussions of identification seem to take this form, though sometimes
without making explicit the requirement that the other elements of  are known.16 Enumerating
such relationships for all  j does not establish identification of  from s
                                                                         ^. In many models, the
statement that  j is identified by s
                                   ^k in this sense will be true for many different statistics s
                                                                                               ^k . Such
discussions may nevertheless provide some useful intuition about the model.
    Some authors support discussions of identification with simulations showing how the distribu-
tions of some statistics s
                         ^ change when each parameter is varied in turn, holding all other parameters
constant.17 A statistic is then sometimes said to "identify a parameter" if the distribution of the
statistic responds strongly as the parameter varies. Note that this amounts to a version of the third
argument structure above, establishing elementwise relationships that do not imply formal identi-
fication of the model as a whole. We see this kind of simulation as valuable provided it is clear that
it speaks to identification of the parameter of interest only if the values of the other parameters are
known.
    The second principle we would recommend is that discussion of model identification be clearly
distinguished from discussion of estimation. How s
                                                 ^ and c are related under the model is distinct
from how s
         ^ is related to the specific estimator c
                                                ^, and the statement "c is identified by s
                                                                                         ^ j " need not
imply that s
           ^ j is an important determinant of c
                                              ^. How to clarify the data features that actually do
drive c
      ^ is the topic we take up in section 5. As we note there, transparency is often improved when
the discussion of identification elucidates the same relationships that turn out to be important in
estimation.

13 See also Gentzkow et al. (2014, sections V.A and VI.A).
14 See, for example, Agarwal and Somaini (2018); Bonhomme et al. (2019); Chiappori et al. (2019).
15 See, for example, Eckstein et al. (2019, pp. 235-236); Fr´
                                                            echette et al. (2019, p. 2976); Fu and Gregory (2019, pp.
   407-409).
16 Two papers that make this requirement explicit are Autor et al. (2019, pp. 2644-5) and David and Venkateswaran

   (2019, pp. 2548-9).
17 See, for example, Autor et al. (2019, Figure 4) and David and Venkateswaran (2019, section III.C).



                                                         13
    In some cases, discussion of the construction of an estimator can itself constitute a heuristic
proof of identification. For example, it may be that estimation consists of a series of plug-in
or linear estimators for parameters whose identification is well understood.18 Such cases may
explain how "identification strategy" has come to be used in some of the literature as a synonym
for "estimation strategy."19


5     Estimation

Descriptive analysis and discussion of identification can together help readers understand how
the researcher's model maps features of the data to conclusions about c, and assess the validity
of the assumptions underlying this mapping. Research is most transparent when readers can use
this and other information to interpret the structural estimates c
                                                                 ^ taking account of the forms of
misspecification they find most relevant.
    In order to do so, the reader needs to understand how the specific estimator c
                                                                                 ^ depends on the
data D. There are often many distinct vectors of intuitive statistics s
                                                                      ^ that each identify c under
the researcher's model, and in over-identified settings there are many different transformations of
a given vector s
               ^ that estimate c. Identification discussions can at best clarify the sets of possible
statistics and transformations.
    Knowing the form of the estimator c
                                      ^ is essential to transparency for two reasons. First, for
reasons related to the discussion in section 4, the statistics s
                                                               ^ on which the estimator depends--the
statistics that "drive" the estimator in common parlance--influence which violations of assump-
tions matter most. Second, as we elaborate below, knowing how the estimator depends on these
statistics can allow a reader to judge the likely bias induced by specific violations.
    In this section, we consider how to make estimation more transparent. We focus on the value
of both highlighting a specific vector of statistics s
                                                     ^ that determine the estimator c
                                                                                    ^ either exactly or
approximately, and making the form of the relationship between the two clear to the reader. To fix
ideas, without loss of generality we can write


                                                     ^ = h (s
                                                     c      ^) + h ,


where h (·) is some function and h is a residual whose structure depends on h (·). The first ap-

18 See,   for example, the section titled "Identification of Structural Parameters" in Head and Mayer (2019, p. 3095).
19 The    "Identification Strategy" section in Harasztosi and Lindner (2019, p. 2701) is a recent example.


                                                            14
                                            ^ such that h = 0 and then characterize the form of
proach we discuss is to choose an estimator c
the function h (·). The second approach we discuss is to choose an estimator c
                                                                             ^ such that h = 0 and
                                                                 ^  h (s
then demonstrate that h is small in an appropriate sense so that c     ^). In section 6, we discuss
how a reader can assess specific forms of misspecification in the context of such estimators.


5.1     Target Descriptive Statistics in Estimation

The first approach is to target s                                 ^ = h (s
                                ^ directly in estimation, so that c      ^). This is of course only
sensible when c is identified by s
                                 ^. If c is identified by the population value s of s
                                                                                    ^ and the implied
relationship c =  (s, a) does not vary across the alternatives a of interest (i.e., c =  (s) for all
a  A ), the plug-in estimator c
                              ^ = h (s
                                     ^) =  (s
                                            ^) may have high transparency for all readers. Related
ideas appear in the literature as a justification for basing model estimation and testing on matching
certain statistics of interest. (See, for example, Dridi et al. 2007, DellaVigna 2018, and Nakamura
and Steinsson 2018.) Even when  (s, a) depends on a, an estimator of the form c
                                                                              ^ = h (s
                                                                                     ^) =  (s
                                                                                            ^, a0 )
may still be reasonably transparent if the form of the relationship c =  (s, a0 ) is made clear.
      In practice, estimation based on targeting a vector of descriptive statistics s
                                                                                    ^ is often imple-
mented via some form of minimum distance estimation that chooses parameters to match the ob-
served s
       ^ to the value predicted under the model. Transparency provides a potential justification for
choosing such estimators even when more efficient estimators, such as the MLE, are available.
      The literature contains numerous examples of estimators that target descriptive statistics. Gour-
inchas and Parker (2002) estimate a lifecycle model of consumption and savings with a precau-
tionary motive. After estimating properties of the income process in a first step, Gourinchas and
Parker (2002) estimate structural preference parameters in a second step by minimizing the dis-
tance between the observed age profile of consumption and the profile predicted by their economic
model. De Nardi et al. (2010) likewise estimate a model of consumption and savings by retirees
by targeting observed median asset profiles for different groups of individuals. See also Goettler
and Gordon (2011), DellaVigna et al. (2012), Nikolov and Whited (2014), and Autor et al. (2019).
      These examples have in common that the estimator is (at least asymptotically) a function of
descriptive statistics that a reader might find intuitively related to the parameters of interest. Part
of the reason for this choice of estimator may be computational, for example due to the difficulty
of computing the likelihood. However, in some cases the authors invoke non-computational con-
siderations in justifying their choice of moments to match, some of which seem related to the



                                                   15
considerations we discuss here.20
    To formalize the value of targeting descriptive statistics, we consider a variant of the instru-
mental variables example introduced in section 2.2.
                                                                                                               n
Example. Suppose that the underlying data consist of n i.i.d. draws (Yi , Xi , Zi,1 , ...Zi,J )                i=1
                                                                                                                     for
Zi = (Zi,1 , ...Zi,J ) a vector of J mutually orthogonal and mean-zero instruments proposed by the
researcher. For c  R and a  A = RJ , the data follow


                                                  Yi = Xi c + Zi a + i ,


where we now treat the instruments Zi as random and allow the error i to be non-normal. Let G
denote the joint distribution of (Zi , Xi , i ) and assume all readers believe that G  G for some class
of distributions with EG [Zi i ] = 0 for all G  G .
    The instruments are valid under the researcher's assumption a0 = 0, but readers suspect they
may in fact be invalid. Suppose that each instrument j has a non-zero first-stage coefficient,
EG Zi, j Xi = 0 for all G  G . Under distribution G, true parameter value c, and assumptions
a, the probability limit of the instrumental variables estimator based on the jth instrument alone,
^ j =  Zi, jYi /  Zi, j Xi , is
c


                                  E(G,a,c) Zi, jYi           EG Zi2
                                                                  ,j                aj
                                                     = c+                  a = c+      ,
                                    EG Zi, j Xi             EG Zi, j Xi             j


for  j = EG Zi, j Xi /EG Zi2
                           , j the first stage coefficient on the j th instrument.
    To illustrate the value of targeting descriptive statistics in this example, let the descriptive
statistics s                                                       ^ = (c
           ^ consist of the first m single-instrument coefficients s    ^1 , ..., c
                                                                                  ^m ) for m < J . We suppose
that readers have sharp priors on the bias in these estimates, in the sense that reader r believes the
first m elements of the bias vector b = (a1 /1 , ..., aJ /J ) equal a known vector br with probability
one, Prr (a1 /1 , ..., am /m ) = br = 1. Thus, all readers are certain about the bias from using
the first m instruments, while they may be uncertain about the remaining instruments. This could
20 For example, De Nardi et al. (2010) write that "Because our underlying motivations are to explain why elderly
  individuals retain so many assets and to explain why individuals with high income save at a higher rate, we match
  median assets by cohort, age, and permanent income" (p. 47). Nikolov and Whited (2014) write that "The success of
  [the approach to estimation] relies on model identification, which requires that we choose moments that are sensitive
  to variations in the structural parameters...We now describe and rationalize the ... moments that we match" (p. 1899).
  Autor et al. (2019) include certain moments "...to discipline the model to recover our estimates of the causal effects
  of" a policy variable of interest (p. 2645).


                                                           16
be because the potential biases from the first m instruments are especially intuitive, for instance
because these instruments are highly credible and br = 0, or because the researcher has clarified
the potential biases, for example through descriptive analysis and discussion of identification.
    In this case, an estimator targeting the descriptive statistics s
                                                                    ^ may be more transparent than the
maximum-likelihood estimator under the researcher's assumption a0 = 0. To provide a concise
illustration, suppose the sample size is large enough that c
                                                           ^ is approximately normal and neglect the
approximation error to obtain


                                     ^ =  c + b +  ,   N (0, ) ,
                                     c                                                               (3)


for  the vector of ones. In this asymptotic model  = (c,  , ). Suppose further that the researcher
                   ^, ), that c and (b, ) are independent under r for all r  R , and that  is
observes only D = (c
commonly known.
                           -1
           ^0 =  -1 
    We let c                     -1 c
                                    ^ denote the maximum-likelihood estimator under the assump-
tion a0 = 0, and we let c
                        ^S denote the estimator that efficiently minimizes the distance between Sc
    ^ = Sc
and s    ^ for S the selection matrix such that Sc
                                                 ^ picks out the first m elements of c
                                                                                     ^. The variance
of c
   ^0 given c under r is

                                             -1             -2
                          ^0 |c) =  -1 
                    Varr (c                       +  -1           -1Varr (b) -1 


where the first term is the sampling variance of the MLE and the second term reflects instrument
invalidity. By contrast, the variance of c
                                         ^S given c under r is simply the sampling variance of
^S . When reader r is very uncertain about instrument validity (in the sense that the variance of
c
the last J - m elements of b is large), c                               ^0 .21 This is intuitive in
                                        ^S may be more transparent than c
the case where br = 0, so reader r believes that the first m instruments are valid. Note, however,
that it remains true even when br = 0. Hence, what is important for transparency in this setting is
not that the first m instruments are valid, but that readers have precise beliefs about the bias these
instruments induce.
    While we have motivated (3) as an asymptotic approximation to over-identified instrumental
variables regression with potentially invalid instruments, it is equivalent to some other important
problems. For instance, (3) can be interpreted as a regression model for Y = c
                                                                             ^ with omitted vari-

21 For                                                        ^0 |c)   by taking Varr (b)  , we have that
      such a reader, if we hold Varr (c) fixed and take Varr (c
  Varr (c|c
          ^0 )  Varr (c).


                                                   17
able b. As discussed in Armstrong and Koles´
                                           ar (2019), this model can also be understood as an
asymptotic approximation to GMM under local misspecification.

                                           ^ = h (s
   Knowing that the estimator has the form c      ^) means that readers know the estimator de-
pends on the data only through the statistics s
                                              ^, but they may not know the nature of the dependence.
As noted above, there are often many different functions h (·) that constitute valid estimators under
the model--in particular, whenever different subsets or transformations of s are each sufficient to
identify c. Some of these functions h (·) may be convincing to a large set of readers, in the sense
that  (s, a)  h (s) for many a  A , while others may only be convincing to readers who accept
a0 . In such cases, communicating the geometry of h (·) can help readers evaluate the estimator and
so improve transparency.
   In practice, research papers typically provide a formal definition of the estimator. Even a
precise definition may not make the geometry of h (·) obvious, however. In linear models, for in-
stance, recent papers characterized regression discontinuity estimators (Gelman and Imbens 2019)
and two-way fixed effect estimators (e.g., Athey and Imbens 2018, Goodman-Bacon 2019, Sun
and Abraham 2020, de Chaisemartin and D'Haultfoeuille forthcoming, Imai and Kim forthcom-
ing) and in some cases argued that these estimators use the data in ways that may be unanticipated
and undesired by many readers and researchers.
   In nonlinear models, such characterizations may be even more difficult to come by and there-
fore even less obvious ex ante. One solution could be to fully describe h (·) by brute-force enu-
meration, but this is often infeasible. For example, Gourinchas and Parker (2002) summarize the
age profile of consumption with the mean adjusted log consumption at each of the 40 ages from 26
through 55. As even a single estimation step may be computationally demanding, computing and
visualizing Gourinchas and Parker's (2002) estimator on a 40-dimensional domain seems daunting.
   Andrews et al. (2017) propose to focus on the local sensitivity of the estimator to the statistics
targeted in estimation. Sensitivity corresponds (in a sense made precise in Andrews et al. 2017)
to the derivatives of h (·) when h (·) is differentiable. It is possible to approximate this derivative
                                                                                  ^ +  e j for  a
numerically, for example by evaluating the estimator at perturbations of the form s
small number and e j the jth standard basis vector, and then computing the numerical derivative
   ^ +  e j - h (s
 h s             ^) / . Repeated estimation may be computationally demanding, but Andrews
et al. (2017) show that in many applications (including Gourinchas and Parker 2002) repeated
estimation is unnecessary if the reader is willing to focus on the asymptotic value of the derivative.
   Andrews et al. (2017) plot the local sensitivity of the estimators of key structural parameters in

                                                  18
Gourinchas and Parker (2002) with respect to the statistics s
                                                            ^ targeted in estimation. They argue that
the local properties of h (·) revealed by this exercise make qualitative sense in light of the economic
analysis and discussion in Gourinchas and Parker (2002), and that knowledge of sensitivity could
be useful to a reader who wishes to learn from c
                                               ^ but is concerned about misspecification of the
assumptions a0 .

Example. (continued) Continue to suppose that the first m elements of b are known under r , but
now suppose that  may not be commonly known. The estimator c
                                                           ^S can be written as

                                              -1       -1           -1
                          ^S =  S SS
                          c                        S         S SS        ^ = S s
                                                                         s     ^


    ^ = Sc
for s    ^, where S is the sensitivity of c
                                          ^S to s
                                                ^ as defined by Andrews et al. (2017). Re-
porting (c
         ^S , S , S ) -- that is, taking c
                                         ^=c      ^ = (S , S ) for S the standard error of c
                                           ^S and t                                        ^S
-- is weakly more transparent for all readers r than reporting (c
                                                                ^S , S ) alone. To see that it
                                                                                         2 .
may be strictly more transparent, suppose that reader r has a normal prior on c, c  N 0, r
The average posterior variance for reader r based on the full data is then bounded below by
                           -2 +  -2     -1
Er [Varr (c|D, b)] = Er    r    0            for 0 the usual standard error of c
                                                                               ^0 , while the average
                                                               -2 +  -2      -1
posterior variance based on observing (c
                                       ^S , S , S ) is Er      r    S              . This bounds the trans-
parency of reporting (c
                      ^S , S , S ) from below. By contrast, the transparency of (c
                                                                                 ^S , S ) alone may be
small when br is large. Consider, for instance, priors which imply that S is fixed while S br is uni-
                                                          ^S , S ) goes to zero as Varr (S br )  .
formly distributed on some interval. The transparency of (c
Intuitively, even if the reader knows the bias br of estimates based on the first m instruments, to in-
fer the bias of c
                ^S they must also know how these m estimates are combined to form c
                                                                                  ^S . Absent such
knowledge, uncertainty about how the bias in s
                                             ^ translates to bias in c
                                                                     ^S renders c
                                                                                ^S uninformative
when br is large.


5.2   Show How Much the Estimator Depends on the Descriptive Statistics

Basing estimation directly on s
                              ^ may not be feasible or desirable. For example, it may be that
even though s
            ^ are intuitive statistics closely related to c, their distribution is not sufficient for
identification. It may be that s
                               ^ identifies c but that identification using these statistics alone is weak.
Or, it may be that the share of readers who accept the researcher's exact parametric assumptions is
large enough that the efficiency gain for these readers from learning the MLE outweighs the loss
of transparency for those who are more skeptical.

                                                       19
                   ^ = h (s
   In these cases, c      ^) + h for h not necessarily equal to zero. Then, making clear to readers
the magnitude of h as well as the form of h (·) can improve transparency. An example is where
at least some readers believe that c =  (s, a), in which case they may find c
                                                                            ^ especially informative
when h  0 and h (·)   (·, a).
   Characterizing the finite-sample relationship between c
                                                         ^ and s
                                                               ^, either analytically or numeri-
cally, can be difficult. For example, numerical exploration by repeatedly drawing data D from one
or more data-generating processes and then computing the implied values of c
                                                                           ^ and s
                                                                                 ^ may be very
computationally demanding.
   Andrews et al. (forthcoming) show that, under asymptotic conditions related to those consid-
ered in Andrews et al. (2017), many common estimators can be represented in the form


                                      ^  constant + s
                                      c             ^+ 


for  an analogue of the local sensitivity defined in Andrews et al. (2017), and  asymptotically
uncorrelated with s
                  ^. Andrews et al. (forthcoming) propose to measure the size of  by the local
informativeness of s
                   ^ for c
                         ^, which is given by

                                       AVar (s  ^)      AVar ( )
                                  =                = 1-
                                        AVar (c
                                              ^)        AVar (c
                                                              ^)

for AVar (V ) the asymptotic variance of a random variable V . When local informativeness  = 1,
Andrews et al. (forthcoming) show that (under the maintained conditions)  = 0 and the setting
collapses to that considered in section 5.1. When local informativeness  = 0, c
                                                                              ^ is asymptotically
               ^, in which case a reader believing that c =  (s, a) may not find c
independent of s                                                                 ^ to be very
informative about c.
   Andrews et al. (forthcoming) show that it is often possible to approximate local sensitivity
and local informativeness without the need for additional simulation or estimation of the structural
model. Moreover, although both local sensitivity and local informativeness can depend on the
data-generating process, Andrews et al. (2017, forthcoming) show that the approximations they
consider hold under local violations of the researcher's assumptions, meaning that these objects
can be interpreted even if the reader does not have complete confidence in the researcher's model.
Andrews et al. (forthcoming) also establish conditions under which a greater informativeness 
corresponds to a larger reduction in the worst-case bias of the estimator c
                                                                          ^ from accepting the
model-implied relationship between c and the population value of the descriptive statistics s
                                                                                            ^.

                                                20
    Andrews et al. (forthcoming) apply their framework to Hendren's (2013) study of the market
for long-term care insurance. They take c
                                        ^ to be the maximum likelihood estimator for the mini-
mum pooled price ratio, a quantity that determines the range of preferences for which insurance
markets cannot exist, and s
                          ^ to be statistics summarizing the joint distribution of individuals' sub-
jective beliefs about the likelihood of needing long-term care and their eventual need for such care.
Andrews et al. (forthcoming) estimate that these descriptive statistics have an informativeness of
                       ^, implying that the descriptive statistics can explain (in an R2 sense) 68% of
0.68 for the estimator c
the variation in the estimator under the joint asymptotic distribution of the estimator and descrip-
tive statistics, and that (under given conditions) accepting the model-implied relationship between
the minimum pooled price ratio and the population value of the descriptive statistics reduces the
                                               
worst-case bias of the estimator by a factor of 1 - 0.68  0.43.

Example. (continued) The asymptotic results of Andrews et al. (forthcoming) hold exactly in the
linear instrumental variables example that we consider in this section. To illustrate the value of in-
formativeness calculations, let us again suppose that under r the first m elements of b are known
to equal br , and c  N 0, r 2 . Let us further suppose that reader r thinks the degree of misspecifi-
                                                                           
cation is bounded relative to sampling uncertainty, in the sense that Prr     b -1 b < µ 2 = 1 for
some constant µ . In this case, one can show that for c
                                                      ^0 again the maximum likelihood estimator,
the increase in reader r's average posterior variance from observing (c
                                                                      ^0 , 0 , 0 ) for 0 the standard
error of c
         ^0 and 0 the sensitivity of c
                                     ^ to s
                                          ^, rather than the full data, is bounded above by

                                                 2            2
                                                r                 2 2
                                      Er      2 +2
                                                                  0 µ (br ) (1 - )
                                              r    0



for µ (br ) =     µ 2 - br (SS )-1 br .22 Thus, when reader r is confident about the impact of mis-
specification on s
                 ^ and the informativeness  of s
                                               ^ for c
                                                     ^0 is high, observing c
                                                                           ^0 is nearly as good as
observing the full data.




22 Reader r's average posterior variance from observing D is bounded below by that from observing both D and b. In
                                                         2                           -1
 the latter case, r's posterior mean is Er [c|D, b] = w2wr
                                                        + 2
                                                            ^0 - b , for  =  -1 
                                                            c                            -1 the sensitivity of c
                                                                                                               ^0 to
                                                      r   0
                                                                                                       2
 ^. When r observes only (c
 c                          ^0 , 0 , 0 ) they cannot construct Er [c|D, b], but can construct c = w2w r
                                                                                                        2 (c^0 - 0 br ) , and
                                                                                                   r +0
                                                                                                 2
 the results of Andrews et al. (forthcoming) show that if b -1 b < µ 2 , then b - 0 br  0               2 µ 2 (b ) (1 - ) .
                                                                                                                r


                                                              21
6       Sensitivity Analysis

A key premise of the model in section 2 is that different readers may accept different assumptions.
Ideally the researcher would report the estimator that is optimal for each reader. When the set of
assumptions entertained by the readers is small enough, this ideal may be achievable. This situation
is one way to understand the sensitivity analysis that is common in research articles, showing how
the key conclusions of the analysis change under a small set of assumptions different from those on
which most of the analysis is based. When the set of assumptions entertained by the readers is rich,
however, such an approach has limits, and it is desirable to help each reader assess how their own
ideal estimator differs from the one reported by the researcher. In cases where a key conclusion of
the researcher's analysis is qualitative, it may be useful, in addition, to report the properties of a
data realization that would have led to a different qualitative conclusion.


6.1     Show the Conclusion under Specific Alternative Assumptions

Suppose that under each set of assumptions a  A there is a natural estimator c
                                                                             ^a (e.g. maximum
likelihood or efficient GMM). If the researcher knows that all (or many) readers entertain only a
limited set of assumptions, in the sense that each prior r puts mass on a single a  A and the
number of distinct elements |A | is small, then it is natural to report the estimate c
                                                                                     ^a under each of
element of A .
      For example, in their study of automobile demand Berry et al. (1995, Table IX) report how
a key conclusion--the markup associated with each of a set of vehicle models--changes under
six different alternative models, each of which corresponds to a modification of the cost or utility
function specified in the baseline model. A reader who believes in one of these alternative speci-
fications a j is therefore able to learn about c from an estimator that is asymptotically valid under
a j . Tables reporting estimates of key parameters of interest under alternative assumptions are a
common feature of many applied research papers (see, e.g., Gourinchas and Parker 2002, Table
V).23
      It is useful to contrast such a sensitivity analysis with a bounds analysis that reports the set
              ^a : a  A } without specifying which estimate corresponds to which assumption
of estimates {c

23 We   focus on cases where c is point-identified under each a  A . When point identification may fail, the researcher
    can report an estimate of the identified set under each a  A . If the assumptions in A can be ranked in increasing or-
    der of strength, this approach allows the reader to see how conclusions sharpen with each incremental strengthening
    of the assumptions. See the discussion in, for example, Manski (2003, 2007) and Tamer (2010).


                                                            22
(see e.g. Leamer 1981). In some cases the mapping from assumptions to elements of the set of
estimates may be obvious, at least for extreme points (e.g. the upper and lower bounds). In other
cases, however, a bounds analysis can be less transparent than a sensitivity analysis with respect
to the same set of assumptions. Similar considerations can apply to a partial identification-robust
analysis that ensures validity under all a  A .24 At the same time, bounds and identification-robust
analyses often remain feasible with large sets of assumptions (again, see e.g. Leamer 1981).


6.2     Show How the Conclusion Depends on Assumptions

If the set of assumptions A entertained by the readers is sufficiently rich, then reporting an esti-
      ^a associated with each assumption a  A is no longer feasible. A possible alternative is
mator c
                                                                    ^a - c
to provide information about the (possibly random) function u (a) = c    ^a0 that relates the esti-
mator under the researcher's baseline assumption a0 to the natural one under the reader's preferred
assumption a. If all readers knew u (·), then each reader could adjust the baseline estimate c
                                                                                             ^a0 to
reflect the reader's own preferred assumption a.
      The omitted variables bias formula (OVBF) is perhaps the most famous tool for intuiting the
properties of u (·). Given beliefs a about the covariance properties of an omitted regressor, the
OVBF allows a reader to determine the bias in the estimator of a given coefficient resulting from
the exclusion of that regressor, which might correspond to a researcher's baseline assumption a0 .
The OVBF thus avoids the need to enumerate the bias implied by all possible beliefs about omitted
regressors. Conley et al. (2012) generalize the OVBF to an instrumental variables setting, showing
how to translate beliefs about violations of the exclusion restriction to beliefs about bias in the
IV estimator. Like the OVBF, Conley et al.'s (2012) approach allows different readers to reach
different conclusions regarding the appropriate adjustments to the reported estimator.
      Andrews et al. (2017) study the problem of translating these ideas to nonlinear structural mod-
els, where the OVBF does not apply directly. In the wide class of models that can be estimated via
minimum distance, the identifying assumptions can be represented as restrictions on the popula-
tion value a of a moment condition under the true value of the structural parameters. For example,
in nonlinear instrumental variables estimators such as that in Berry et al.'s (1995) study of automo-
24 To give an extreme example, consider the instrumental variables model discussed in section 2.2. The maximum
                                                                   ^ - a/
  likelihood estimator for c under assumption a in this setting is c     ^, for c
                                                                                ^ again the usual instrumental variables
  estimator, so the set of maximum likelihood estimators under a  A is equal to R almost surely, and thus has
  transparency equal to zero for readers r who find the full data informative. Correspondingly, the identified set for c
  under A is equal to R, and therefore any confidence set with coverage 1 -  for c under all a  A and   H must
  have infinite length with probability at least 1 -  . See Dufour (1997).


                                                          23
bile demand, the restriction is that a vector of observed instruments is orthogonal in population to
a vector of unobserved structural errors. In indirect inference and other moment-matching type es-
timators, such as that in Gourinchas and Parker (2002), the restriction is that the population values
of some statistics must match those predicted by the model.
   In such settings, specific violations of the identifying assumptions can be represented as spe-
cific alternative restrictions--for example, that the covariance between the instruments and the
structural error takes some specific nonzero value in population, or that the model systematically
mispredicts the population value of some statistics by some specific amount. For linear models,
the OVBF and its analogues tell the reader how to adjust the estimator to accommodate such per-
turbations to the researcher's identifying assumptions. For nonlinear models, we are not aware of
a similar formula, and exhaustively checking the implications of each possible perturbation can be
costly or impossible.
   Andrews et al (2017) show that if the perturbations are local--that is, small in an appropriate
asymptotic sense--then the implied asymptotic bias of the estimator is given by  (a - a0 ), where
the coefficients  are the local sensitivity discussed in section 5.1, now replacing the descriptive
statistics with the vector of estimation moments evaluated at the true parameter value. It is thus
practical to approximate and report the coefficients of the asymptotic bias formula in many appli-
cations. In this sense, local sensitivity provides an analogue of the OVBF for general minimum
distance estimators under small violations of identifying assumptions.
   Andrews et al. (2017) report the local sensitivity of the estimated average vehicle markup
to violations of the identifying assumptions in Berry et al. (1995). This analysis shows that the
estimator is especially sensitive to violations of the assumption that unobserved shocks to the utility
from or cost of producing a given vehicle model are orthogonal to the number of other models
offered by the same or rival firms. Berry et al. (1995, p. 854) discuss the economic interpretation
of these and other identifying assumptions. Andrews et al. (2017) show how a reader could use
information on sensitivity to approximate the effect of different economically interesting violations
of the identifying assumptions. Importantly, this approach does not require the researcher to know
the alternative assumptions a of interest in advance, as readers can use information about sensitivity
to calculate the implications of different assumptions a for themselves. Andrews et al. (2017)
report a similar analysis of the sensitivity of the estimated preference parameters in Gourinchas
and Parker (2002) to violations of the identifying assumptions.



                                                  24
6.3    Show How to Reverse the Conclusion

Some of the questions answered by structural analysis are qualitative--e.g., will a given policy in-
crease or decrease consumer surplus? Will a merger increase or decrease product quality? Empiri-
cal answers to such questions depend, by definition, on the realization of the data. To characterize
this dependence, it can be helpful for researchers to discuss data realizations that would have led
to the opposite conclusion. In some cases the properties of the data required for such a reversal
are obvious. For example, if the effect of some policy on an outcome is estimated in a multivariate
linear regression, then to reverse the researcher's conclusion about whether the policy increases the
outcome requires changing the sign of the residual covariance between the policy and the outcome.
      For estimators in nonlinear models, by contrast, it is sometimes not obvious what realizations
of the data would lead to conclusions different from the one reached by the researcher's analysis,
or even whether such realizations exist. We think that exhibiting such realizations can improve
transparency, both by showing that the researcher's answer to the qualitative question is indeed
an empirical one, and (in the spirit of section 5.1 above) showing what sort of data realization is
associated with a given conclusion.
      Such an exercise might be called a reverse sensitivity analysis: rather than changing the in-
puts (e.g., data or assumptions) and investigating the effects on the outputs (conclusions), as in a
traditional sensitivity analysis, here we seek to change the outputs and reverse engineer sufficient
changes to the inputs. In this section we focus on describing the required changes in the data or
parameters. A complementary approach characterizes the required change in assumptions (see e.g.
Horowitz and Manski 1995, Kline and Santos 2013, and Masten and Poirier 2020).
      Goettler and Gordon (2011) study whether Intel is more innovative in the production of micro-
processors as a result of competition from AMD. To answer this question they estimate a dynamic
model of the microprocessor industry and simulate behavior under alternative market structures.
Goettler and Gordon (2011) conclude that the presence of AMD reduces the rate at which Intel
innovates. They observe that their model is able to generate the opposite conclusion and exhibit
parameter values for which the presence of the competitor increases the rate of innovation.
      Likewise, Cu´
                  esta et al. (2019) study whether vertical integration between hospitals and insurers
raises total surplus in the health care system. They find that it does. The paper shows that changing
the degree of consumer price sensitivity can reverse this qualitative conclusion.

Example. Suppose for simplicity that we are interested in a binary conclusion (e.g., that c
                                                                                          ^ is


                                                  25
positive). Following Abadie (2020), consider how much reader r updates their beliefs about c
                       ^ > 0. As noted in Abadie (2020), the law of total probability implies that
based on learning that c
for any set of values C for c,

                                       Prr {c
                                            ^  0}                              Prr {c
                                                                                    ^  0}
       |Prr {C } - Prr {C |c
                           ^ > 0}| =               |Prr {C } - Prr {C |c
                                                                       ^  0}|              .
                                       Prr {c
                                            ^ > 0}                             Prr {c
                                                                                    ^ > 0}

Hence, if reader r thinks it very likely that the model will generate a positive estimate, Prr {c
                                                                                                ^ > 0} 
                                                   ^ > 0. By contrast, if a researcher can provide
1, they barely update their beliefs when told that c
evidence that plausible realizations of the data would have led to a different conclusion, learning
     ^ > 0 becomes much more informative. To formalize this in our model, suppose the report is
that c
(1 {c        ^ (X , )), where Prr {c
    ^ > 0} , t                           ^}
                                   ^ > 0|t     Prr {c
                                                    ^ > 0}. For example, t (X , ) might record a set
of values Y for Y that would have led to negative estimates. Since we still have


                                    |Prr {C |t
                                             ^} - Prr {C |c      ^}|
                                                          ^ > 0, t

                              Prr {c
                                   ^  0|t^}
                          =                 |Pr {C |t
                                                    ^} - Prr {C |c     ^}| ,
                                                                 ^  0, t
                              Prr {c     ^} r
                                   ^ > 0|t
                                                            ^ > 0.
the reader may now update substantially after learning that c


7   Conclusion

Estimators of nonlinear models with multiple interacting agents or sectors can be complicated
functions of the data and therefore difficult for readers to understand. Yet such models form an
important part of the economist's toolkit for many real-world problems. Fortunately, economists
working with such models have developed many practices that aid the transparency of their re-
search. Here we survey those practices and suggest areas for further improvement. Many of these
improvements can be adopted at little or no computational cost to the researcher.




                                                  26
References

Abadie, Alberto. 2020. Statistical non-significance in empirical economics. American Economic
     Review: Insights 2(2): 193-208.
Agarwal, Nikhil and Paulo Somaini. 2018. Demand analysis using strategic reports: An applica-
     tion to a school choice mechanism. Econometrica 86(2): 391-444.
Agarwal, Sumit, Souphala Chomsisengphet, Neale Mahoney, and Johannes Stroebel. 2018. Do
     banks pass through credit expansions to consumers who want to borrow? Quarterly Journal
     of Economics 133(1): 129-190.
Allcott, Hunt, Rebecca Diamond, Jean-Pierre Dub´      e, Jessie Handbury, Ilya Rahkovsky, and Molly
     Schnell. 2019. Food deserts and the causes of nutritional inequality. Quarterly Journal of
     Economics 134(4): 1793-1844.
Anderson, Simon P., Andre De Palma, and Jacques-Francois Thisse. 1992. Discrete Choice Theory
     of Product Differentiation. MIT Press.
Andrews, Isaiah, Matthew Gentzkow, and Jesse M. Shapiro. 2017. Measuring the sensitivity of
     parameter estimates to estimation moments. Quarterly Journal of Economics 132(4): 1553­
     1592.
Andrews, Isaiah, Matthew Gentzkow, and Jesse M. Shapiro. Forthcoming. On the informativeness
     of descriptive statistics for structural estimates. Econometrica.
Andrews, Isaiah and Jesse M. Shapiro. 2020. A model of scientific communication. NBER
     Working Paper No. 26824.
Angrist, Joshua D. and J¨  orn-Steffen Pischke. 2010. The credibility revolution in empirical eco-
     nomics: How better research design is taking the con out of econometrics. Journal of Eco-
     nomic Perspectives 24(2): 3-30.
Armstrong, Timothy and Michal Koles´       ar. 2019. Sensitivity analysis using approximate moment
     condition models. Cowles Foundation Discussion Paper No. 2158R.
Athey, Susan and Guido W. Imbens. 2018. Design-based analysis in difference-in-differences
     settings with staggered adoption. Working Paper arXiv:1808.05293v3.
Attanasio, Orazio P., Costas Meghir, and Ana Santiago. 2012. Education choices in Mexico:
     Using a structural model and a randomized experiment to evaluate PROGRESA. Review of
     Economic Studies 79(1): 37­66.
Autor, David, Andreas Kostøl, Magne Mogstad, and Bradley Setzler. 2019. Disability benefits,
     consumption insurance, and household labor supply. American Economic Review 109(7):
     2613­2654.
Beraja, Martin, Andreas Fuster, Erik Hurst, and Joseph Vavra. 2018. Regional heterogeneity and
     the refinancing channel of monetary policy. Quarterly Journal of Economics 134(1): 109-


                                                27
     183.
Bernard, Andrew B., Andreas Moxnes, and Yukiko U. Saito. 2019. Production networks, geogra-
     phy, and firm performance. Journal of Political Economy 127(2): 639-688.
Berry, Steven, James Levinsohn, and Ariel Pakes. 1995. Automobile prices in market equilibrium.
     Econometrica 63(4): 841-890.
Bonhomme, St´   ephane, Thibaut Lamadon, and Elena Manresa. 2019. A distributional framework
     for matched employer-employee data. Econometrica 87(3): 699-739.
Chiappori, Pierre A., Bernard Salani´  e, Franc
                                              ¸ ois Salani´
                                                          e, and Amit Gandhi. 2019. From aggregate
     betting data to individual risk preferences. Econometrica 87(1): 1-36.
Christensen, Garret and Edward Miguel. 2018. Transparency, reproducibility, and the credibility
     of economics research. Journal of Economic Literature 56(3): 920-980.
Conley, Timothy G., Christian B. Hansen, and Peter E. Rossi. 2012. Plausibly exogenous. Review
     of Economics and Statistics 94(1): 260­272.
Crawford, Gregory S., Robin S. Lee, Michael D. Whinston, and Ali Yurukoglu. 2018. The welfare
     effects of vertical integration in multichannel television markets. Econometrica 86(3): 891-
     954.
Cu´esta, Jose Ignacio, Carlos Noton, and Benjam´      in Vatter. 2019. Vertical integration between
     hospitals and insurers. Working Paper.
David, Joel M. and Venky Venkateswaran. 2019. The sources of capital misallocation. American
     Economic Review 109(7): 2531-67.
de Chaisemartin, Cl´ ement and Xavier D'Haultfoeuille. Forthcoming. Two-way fixed effects esti-
     mators with heterogeneous treatment effects. American Economic Review.
De Nardi, Mariacristina, Eric French, and John B. Jones. 2010. Why do the elderly save? The role
     of medical expenses. Journal of Political Economy 118(1): 39-75.
DellaVigna, Stefano, John A. List, and Ulrike Malmendier. 2012. Testing for altruism and social
     pressure in charitable giving. Quarterly Journal of Economics 127(1): 1-56.
DellaVigna, Stefano. 2018. Structural behavioral economics. In B. Douglas Bernheim, Stefano
     DellaVigna, and David Laibson, Eds., Handbook of Behavioral Economics - Foundations and
     Applications 1: 613-723.
Dridi, Ramdan, Alain Guay, and Eric Renault. 2007. Indirect inference and calibration of dynamic
     stochastic general equilibrium models. Journal of Econometrics 136(2): 397-430.
Dufour, Jean-Marie. 1997. Some impossibility theorems in econometrics with applications to
     structural and dynamic models. Econometrica 65(6): 1365-1388.
Eckstein, Zvi, Michael Keane, and Osnat Lifshitz. 2019. Career and family decisions: Cohorts
     born 1935­1975. Econometrica 87(1): 217-253.
Fetter, Daniel K. and Lee M. Lockwood. 2018. Government old-age support and labor supply:


                                                28
     Evidence from the Old Age Assistance Program. American Economic Review 108(8): 2174-
     2211.
Fr´
  echette, Guillaume R., Alessandro Lizzeri, and Tobias Salz. 2019. Frictions in a competitive,
     regulated market: Evidence from taxis. American Economic Review 109(8): 2954-2992.
Fu, Chao and Jesse Gregory. 2019. Estimation of an equilibrium model with externalities: Post-
     disaster neighborhood rebuilding. Econometrica 87(2): 387-421.
Gelman, Andrew and Guido W. Imbens. 2019. Why high-order polynomials should not be used in
     regression discontinuity designs. Journal of Business & Economic Statistics 37(3): 447-456.
Gentzkow, Matthew, Jesse M. Shapiro, and Michael Sinkinson. 2014. Competition and ideological
     diversity: Historical evidence from US newspapers. American Economic Review 104(10):
     3073­3114.
Goettler, Ronald L. and Brett R. Gordon. 2011. Does AMD spur Intel to innovate more? Journal
     of Political Economy 119(6): 1141-1200.
Goodman-Bacon, Andrew. 2019. Difference-in-differences with variation in treatment timing.
     NBER Working Paper No. 25018.
Gourinchas, Pierre-Olivier and Jonathan A. Parker. 2002. Consumption over the life cycle. Econo-
     metrica 70(1): 47-89.
Hackmann, Martin B. 2019. Incentivizing better quality of care: The role of Medicaid and compe-
     tition in the nursing home industry. American Economic Review 109(5): 1684-1716.
Harasztosi, P´eter and Attila Lindner. 2019. Who pays for the minimum wage? American Economic
     Review 109(8): 2693-2727.
Head, Keith and Thierry Mayer. 2019. Brands in motion: How frictions shape multinational
     production. American Economic Review 109(9): 3073-3124.
Heckman, James J. 2010. Building bridges between structural and program evaluation approaches
     to evaluating policy. Journal of Economic Literature 48(2): 356­398.
Hendren, Nathaniel. 2013. Private information and insurance rejections. Econometrica 81(5):
     1713­1762.
Horowitz, Joel L. and Charles F. Manski. 1995. Identification and robustness with contaminated
     and corrupted data. Econometrica 63(2): 281-302.
Imai, Kosuke and In Song Kim. Forthcoming. On the use of two-way fixed effects regression
     models for causal inference with panel data. Political Analysis.
Keane, Michael P. 2010. Structural vs. atheoretic approaches to econometrics. Journal of Econo-
     metrics 156(1): 3­20.
Kleven, Henrik Jacobsen. 2018. Language trends in public economics. Slides accessed at
     <https://www.henrikkleven.com/uploads/3/7/3/1/37310663/languagetrends slides kleven.pdf>
     on December 7 2019.


                                             29
Kline, Patrick and Andres Santos. 2013. Sensitivity to missing data assumptions: Theory and an
     evaluation of the US wage structure. Quantitative Economics 4.2: 231-267.
Leamer, Edward E. 1981. Sets of estimators of location. Econometrica. 49(1): 193-204.
Lewbel, Arthur. 2019. The identification zoo: Meanings of identification in econometrics. Journal
     of Economic Literature 57(4): 835­903.
Manski, Charles. 2003. Partial Identification of Probability Distributions. Springer.
Manski, Charles. 2007. Identification for Prediction and Decision. Harvard University Press.
Masten, Matthew A. and Alexandre Poirier. 2020. Inference on breakdown frontiers. Quantitative
     Economics 11(1): 41-111.
Matzkin, Rosa L. 2013. Nonparametric identification in structural economic models. Annual
     Review of Economics 5(1): 457-486.
Molinari, Francesca. 2019. Econometrics with partial identification. Handbook of Econometrics
     (forthcoming).
Murdoch, W. James, Chandan Singh, Karl Kumbier, Reza Abbasi-Asl, and Bin Yu. 2019. Def-
     initions, methods, and applications in interpretable machine learning. Proceedings of the
     National Academy of Sciences 116(44): 22071-22080.
Nakamura, Emi and J´  on Steinsson. 2018. Identification in macroeconomics. Journal of Economic
     Perspectives 32(3): 59-86.
Nikolov, Boris and Toni M. Whited. 2014. Agency conflicts and cash: Estimates from a dynamic
     model. Journal of Finance 69(5): 1883-1921.
Pakes, Ariel. 2014. The 2013 Lawrence R. Klein Lecture: Behavioral and descriptive forms of
     choice models. International Economic Review 55(3): 603-624.
Polyakova, Maria. 2016. Regulation of insurance with adverse selection and switching costs:
     Evidence from Medicare Part D. American Economic Journal: Applied Economics 8(3): 165-
     95.
Rossi, Federico and Pradeep K. Chintagunta. 2016. Price transparency and retail prices: Evidence
     from fuel price signs in the Italian highway system. Journal of Marketing Research 53(3):
     407-423.
Sun, Liyang and Sarah Abraham. 2020. Estimating dynamic treatment effects in event studies
     with heterogeneous treatment effects. MIT Working Paper.
Tamer, Elie. 2010. Partial identification in econometrics. Annual Review of Economics 2(1):167­
     95.




                                               30
