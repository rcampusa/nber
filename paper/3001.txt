                           NBER WORKING PAPER SERIES




                  DATA-SNOOPING BIASES IN TESTS OF FINANCIAL
                             ASSET PRICING MODELS




                                 Andrew W. Lo

                              A. Craig MacKinlay




                            Working Paper No. 3001




                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                           1050 Massachusetts Avenue
                              Cambridge, MA 02138
                                   June 1989




We thank David Aldous, Herbert David, Mike Gibbons and seminar participants
at Columbia University, M.I.T., Princeton University, and Stanford University
for useful comments and suggestions. Research support form the Geewax-Terker
Research Fund (MacKinlay), the John M. Olin Fellowship at the National Bureau
of Economic Research (Lo), and the National Science Foundation is gratefully
acknowledged. This paper is part of NBER's research program in Financial
Markets and Monetary Economics. Any opinions expressed are those of the
authors not those of the National Bureau of Economic Research.
                                                NBER Working Paper #3001
                                                June 1989


        DATA-SNOOPING BIASES IN TESTS OF FINANCIAL
                                                            ASSET PRICING MODELS


                                        ABSTRACT


We investigate the extent to which tests of financial asset pricing models may be biased
 by using properties of the data to construct the test statistics. Specifically, we focus on
 tests using returns to portfolios of common stock where portfolios are constructed by
sorting on some empirically motivated characteristic of the securities such as market
value of equity. We present both analytical calculations and Monte Carlo simulations
that show the effects of this type of data-snooping to be substantial. Even when the
sorting characteristic is only marginally correlated with individual security statistics, 5
percent tests based on sorted portfolio returns may reject with probability one under
the null hypothesis. This bias is shown to worsen as the number of securities increases
given a fixed number of portfolios, and as the number of portfolios decreases given
a fixed number of securities. We provide an empirical example that illustrates the
practical relevance of these biases.




  Andrew W. La
                                             A. Craig   MacKinlay
  Sloan School of Management                 Department of Finance
  M.I.T.
                                            Wharton School
  50 Memorial Drive
                                            University of Pennsylvania
  Cambridge, MA 02138
                                            Philadelphia, PA 19104
 1. Introduction.

      The reliance of economic science upon non-experimental inference is, at once, one of
  the most challenging and most nettlesome aspects of the discipline. Because of the vir-
 tual impossibility of controlled experimentation the importance and influence of statistical
 data analysis in economics is now well-established. However, there is a growing concern
 that the procedures under which formal statistical inference have been developed may not
 correspond to those followed in practice. For example, the classical statistical approach to
 selecting a method of estimation generally involves minimizing an expected loss function
 irrespective of the actual data at hand. Yet in practice the properties of the realized data
 almost always influence the choice of estimator. Of course, ignoring obvious features of
 the data can lead to nonsensical inferences even when the estimation procedures are opti-
mal in some metric. But the way we incorporate aspects of the data into our estimation
and testing strategies can affect subsequent inferences considerably. Indeed, by the very
nature of empirical innovation in economics, the axioms of classical statistical analysis are
violated routinely: future research is often motivated by the successes and failures of past
investigations. Consequently, few empirical studies are free of the kind of data-instigated
pre-test biases discussed in Leamer (1978). A meta-corollary of this proposition is that
the degree of such biases is an increasing function of the number of published studies per-
formed on any single data set. The more scrutiny a collection of data is subjected to, the
more likely will interesting (spurious) patterns seem to emerge. Since stock market prices
are perhaps the most studied economic quantities to date, tests of financial asset pricing
models seem especially susceptible.
      In this paper we attempt to quantify the inferential biases associated with one par-
ticular method of testing financial asset pricing models such as the Capital Asset Pricing
Model (CAPM) and the Arbitrage Pricing Theory (APT). Because there are often many
more securities than there are time series observations of stock returns, asset pricing tests
are generally performed on the returns of portfolios of securities. Besides reducing the
cross-sectional dimension of the joint distribution of returns, grouping into portfolios has
also been advanced as a method of reducing the impact of measurement error.' However,
the selection of securities to be included in a given portfolio is almost never at random
but is often based on some of the stocks' empirical characteristics. The formation of size-
sorted portfolios, portfolios based on the market value of the companies' equity, is but
  'S.. Buck, J.n..n, and Schol.. (1972), and Fama and MacBeth (1973).

7.5                                                  —1—                               5.89
one example. Constructing classical statistical tests on portfolios formed this way creates
potentially significant biases in the test statistics. These are examples of "data-snooping
statistics," a term used by Aldous (1989, p. 252) to describe the situation "where you have
a family of test statistics T(a) whose null distribution is known for fixed a, but where you
use the test statistic T = T(a) for some a chosen using the data." In our application the
quantity a may be thought of as a vector of zeros and ones that indicate which securities
are to be included or excluded from a given portfolio. If the choice of a is based on the
data then the sampling distribution of the resulting test statistic is generally not the same
as the null distribution with a fixed a, hence the actual size of the test may differ substan-
tially from its nominal value under the null. Under empirically plausible assumptions our
calculations show that this kind of data-snooping can yield test sizes of unity for commonly
used nominal 5 percent tests.
     Although the term "data-snooping" has an unsavory connotation our usage neither
implies nor infers any sort of intentional misrepresentation or dishonesty. That prior
empirical research may influence the way current investigations are conducted is often
unavoidable and this very fact results in what we have called data-snooping. Moreover, it
is not at all apparent that this phenomenon necessarily imparts a "bias" in the sense that it
affects inferences in an undesirable way. After all, one purpose of the public dissemination
of scientific discovery is to add to a store of common knowledge on which future research
may build.
     However, when scientific discovery is statistical in nature we must take care to evaluate
the significance of newly discovered relations in view of past inferences. This is recognized
implicitly in many formal statistical circumstances, as in the theory of sequential hypothesis
testing.2 But it is considerably more difficult to correct for the effects of specification
searches in practice since such searches often consist of sequences of empirical studies
undertaken by many individuals. For example, as a consequence of the many investigations
relating the behavior of stock returns to size Chen, Roll and Ross (1986, p. 394) write:
"It has been facetiously noted that size may be the best theory we now have of expected
returns. Unfortunately, this is less of a theory than an empirical observation." But as
Merton (1987, p. 107) asks in a related context: "Is it reasonable to use the standard
t-statistic as a valid measure of significance when the test is conducted on the same data
used by many earlier studies whose results influenced the choice of theory to be tested?"
We re-phrase this question in the following way: Are standard tests of significance valid
      for exanipi., Siegmund (1985).

7.5                                        —2—                                          5.89
when the construction of the test statistics is influenced by empirical relations derived from
the very same data to be used in the test? Our results show that using prior information
only marginally correlated with statistics of interest can distort inferences dramatically.
     In Section 2 we quantify the data-snooping biases associated with testing financial
asset pricing models with portfolios formed by sorting on some empirically motivated
characteristic. Using the theory of induced order statistics we derive in closed-form the
asymptotic distribution of a commonly-used test statistic before and after sorting. This
not only yields a measure of the effect of data-snooping but also provides the appropriate
sampling theory when snooping is unavoidable. In Section 3 we report the results of Monte
Carlo experiments designed to gauge the accuracy of the previous section's asymptotic
approximations. Section 4 provides an empirical example that illustrates the potential
importance of data-snooping biases in existing tests of asset pricing models, and Section
5 shows how these biases can arise naturally from our tendency to focus on the unusual.
We conclude in Section 6.




7.5                                       —3—                                          5.89
2. Quantifying Data-Snooping Biases With Induced Order Statistics.

      Many tests of the CAPM and APT have been conducted on returns of groups of
securities rather than on individual security returns, where the grouping is often according
to some empirical characteristic of the securities. Perhaps the most common attribute
by which securities are grouped is market value of equity or "size."3 The prevalence of
size-sorted portfolios in recent tests of asset-pricing models has not been precipitated by
any economic theory linking size to asset prices. It is a consequence of a series of empirical
studies demonstrating the statistical relation between size and the stochastic behavior of
stock returns.4 Therefore we must allow for our foreknowledge of size-related phenomena
in evaluating the actual significance of tests performed on size-sorted portfolios. More
generally, grouping securities by some characteristic that is empirically motivated may
affect the size of the usual significance tests,5 particularly when the empirical motivation
is derived from the very data set on which the test is based. We quantify these effects in
the following sections by appealing to asymptotic results for induced order statistics and
show that even mild forms of data-snooping can change inferences substantially. Section
2.1 provides a brief summary of the asymptotic properties of induced order statistics.
Section 2.2 presents results for tests based on individual securities, and Section 2.3 reports
corresponding results for portfolios. In Section 2.4 we discuss directions in which the
assumptions of the previous sections may be relaxed, and in Section 2.5 we provide a more
positive interpretation of data-snooping biases as power against deviations from the null
hypothesis.


2.1. Asymptotic Properties of Induced Order Statistics.
    Since the particular form of data-snooping we are investigating is most common in
empirical tests of financial asset pricing models our exposition will lie in that context.
Suppose for each of N securities we have some consistent estimator &j of a parameter zj
which is to be used in the construction of an aggregate test statistic. For example, in the
Sharpe_Lintner CAPM à would be the estimated intercept from the following regression:
    The following is only a partial list of the more recent atudie, using siae-sorted portfolios: Chan and Chen (1988), Chan.
Chen, and Much (1985), Chen, Roll, and Ross (1986), Connor and Icorajceyk (1988), Kandel and Stambaugh (1987), Lehmann
and Modest (1988), MacKinlay (1987), and Shanken (1985).
  'See Bans (1983), Brown, Kleidon, and Marsh (1983), and Chan, Chen, and Hsieh (1985) for example.
    Unfortunately the use of ajue to mean both market value of equity and type I error is unoidable. Readers beware.



75                                                        ....4                                                        5.89
                             — Ri = aj + (Rmt — RIt)a. + €tt                               (2.1)


where Rj,    R,   and Rj are the period-t returns on security i, the market portfolio, and
a risk-free asset respectively. A test of the null hypothesis that a = 0 would then be
a proper test of the Sharpe-Lintner version of the CAPM, thus &j may serve as a test
statistic itself. However, more powerful tests may be obtained by combining the &j's for
many securities. But how to combine them?
      Suppose for each security i we observe some characteristic X2, such as its out-of-sample
  market value of equity or average annual earnings, and we learn that X, is correlated em-
  pirically with &. By this we mean that the relation between X and àj is an empirical fact
  uncovered by "searching" through the data, and not motivated by any a priori theoreti-
  cal considerations. This search need not be a systematic sifting of the data, but may be
  interpreted as any one of Learner's (1978) six specification searches which even the most
  meticulous of classical statisticians has conducted at some point. The key feature is that
  our interest in characteristic X1 is derived from a look at the data, the same data to be
  used in performing our test. Common intuition suggests that using information contained
  in the X8's can yield a more powerful test of economic restrictions on the &j's. But if this
  characteristic is not a part of the original null hypothesis, and only catches our attention
  after a look at the data (or after a look at another's look at the data), using it to form our
  test statistics may lead us to reject those economic restrictions even when they obtain.
•       This is most evident in the extreme case where the null hypothesis aj = 0 is tested by
  performing a standard t-test on the largest of the &j's. Clearly such a test is biased toward
  rejection unless we account for the fact that the largest àj has been drawn from the set
  {àj}. Otherwise, extreme realizations of estimation error will be confused with a violation
  of the null hypothesis. If instead of choosing &j based on its value relative to other
  our choice is based on some characteristic X correlated with the estimation errors of &j,
  a similar bias might arise, albeit to a lesser degree.
       To formalize the preceding intuition, suppose that only a subset of n securities are
  used to form the test statistic and these n are chosen by sorting the X2's. That is, let us
  re-order the bivariate vectors [X &j]' according to their first components, yielding the
sequence:



7.5                                                                                       5.89
                              (X1:N \           ' (X2:N'\ '                            ' (XN:N                                  22
                                                   92:N)                                    [N:NJ

where X1:N < X2:N <                                  < XN:N and the notation Xj:N follows that of the
statistics literature in denoting the i-th order statistic from the sample of N observations
{X1}.6 The notation           denotes the i-th induced order statistic corresponding to X1.N
or the i-th concomitant of the order statistic X:N.7 That is, if the bivariate vectors
[X2    &]1 are ordered according to the X, entries, a[i.N] is defined to be the second
component of the i-th ordered vector. The       are not themselves ordered but correspond
to the ordering of the X1.N's.8 We call this procedure induced ordering of the &j's. It is
apparent that if we construct a test statistic by choosing n securities according to the
ordering (2.2) the sampling theory cannot be the same as that of n securities selected
independently of the data. Due to the following remarkably simple result by Yang (1977)
an asymptotic sampling theory for test statistics based on induced order statistics may be
derived analytically:9




   cIt is implicitly assumed throughout that both 5. and X have continuous joint and marginal c.d.f.'., hence strict inequalities
suffice.
   TTh. term co*comitaat of order statitics was introduced by David (1973), who was perhaps the first to systematically
investigate its properties and application.. The term iedaced order statjtics was coined by Bhattacharya (1974) at about
the same time. Although the former term seem. to be more common usage, we us. the latter in the interest of brevity. See
Bhattacharya (1984) for an excellent review.
   51f the vectors are independently and identically distributed and X,T is perfectly correlated with 5,, then             are also
order statistics. But as long as the correlation coefficient p is strictly between —1 and 1 then, for example, 51NNI will generally
not be the largest 5. In fsct, it may readily be shown that for any fixed k:

                      plim(2alogN)'/2XN_kN = 1
                      N—os
                                                                  ,     plim(2ologN)_lf2&(_J
                                                                        N—os
                                                                                                           =

thts the largest X, is almost never paired with the largest 5.. See David (1981), David, O'Connell, and Yang (1977) and
Galainbos (1987) for further details.
   °Se. also David and Galambos (1974) and Watterson (1959). Yang (1977) also provides the exact finite-sample distribution
of any finite collection of induced order statistics. However, even assuming bivanat. normality does not yield a tractable form
for this distribution. For example, the exact joint c.d.f. of the i-th and j-th induced order statistics is given by:
                                                          —   a —p(X;,N —                      —   a   p(X1,N —
                    < a..51i'Nl <a1) = [•
                                                    (as                        iso))     (a1                         ss)) ]
where   (.) is the standard normal c.d.f. and th. expectation is taken with respect to the joint distribution of the order statistics
(X,N,X1,N).




7.5                                                            —6—                                                             5.89
Theorem 2.1. Let the vectors [X &', i = 1, . . . , N be independently and identically
distributed and let 1 < i < i < ... < i, < N be sequences of integers such that, as
N—+oo,ik/N--s'ekE(O,1)(k=l,2,...,n).Then

         limPr(&[jj:N] <a1,... ,aN] <as) = [JPr(&1 <aIF(Xj) =                                                               (2.3)

where F(•) is the marginal c.d.f. of X.

Proof. See Yang (1977).
                                                                                                                        I

This result gives the large-sample joint distribution of a finite subset of induced order
statistics whose identities are determined solely by their relative rankings ek (as ranked
according to the order statistics X.N). From (2.3) it is evident that {.NJ} are mutually
independent in large samples. if X were the market value of equity, or "size," of the i-th
security Theorem 2.1 shows that the &j of the security with size at the 27-th percentile is
asymptotically independent of the &j corresponding to the security with size at the 45-th
percentile.10 If the characteristics {X1} and {àj} are statistically independent, clearly the
joint distribution of the latter cannot be influenced by ordering according to the former. It
is tempting to conclude that as long as the correlation between X and &j is economically
small, induced ordering cannot greatly affect inferences. Using Yang's result we show the
fallacy of this argument in Sections 2.2 and 2.3.


2.2. Biases of Tests Based on Individual Securities.
       We evaluate the bias of induced ordering under the following assumption:

      (A)        The vectors [X1    &]' (1 = 1,2,.. . , N) are independently and identically
                 distributed bivariate random normal vectors with mean [j a]', variance
                  [o ciJ', and correlation p E (—1, 1).

The null hypothesis H is then:
  °Thii is a limiting result and, in particular, implies that the identitie, of the stock, with 27.th and 45.th percentile size,
may change as N increase,.
  U Some of our results are robust to this parametric specification but more general distributional assumptions will not admit
explicit numerical evaluation.

7.5                                                         —7--                                                            5.89
                                                 H: a=O.
Examples of asset pricing models that yield restrictions of this form are the Sharpe-Lintner
CAPM and the exact factor pricing version of Ross's APT.12 Since the sampling theory
provided by Theorem 2.1 is asymptotic we construct our test statistics using a finite subset
of i securities where it is assumed that n z N. if these securities are selected without the
prior use of data then we have the following well-known result:


                                            0                         'x                                              (2.4)




where o       is any consistent estimator of a.'3 Therefore, a 5 percent test of H may be
performed by checking whether 0 is greater or less than C'5, where C5 is defined by:


                                                 F2(Cs) = .95                                                         (2.5)


and F2(.) is the c.d.f. of a x variate.
      Suppose we construct 0 from the induced order statistics &[jk.NJ, k = 1,. . . n, instead
of the àj's. Specifically, define the following test statistic:


                                                0=                           .                                        (2.6)
                                                             k=1


Using Theorem 2.1, the following proposition is easily established:
  125e Chamberlain (1983), Huberman and Kandel (1987), and Lehmann and Modest (1988) for the exact (actor pricing
model. Examples of tests which fit into the framework of H are those in Campbell (1987), Connor and Korajcsyk (1988),

  '
Gibbons (1982), Gibbons and Ferson (1985), Gibbons, Roes, and Shanken (1987), Huberman and Kandel (1987), MacKinlay
(1987), Lehrnann and Modest (1988), Stambaugh (1982), and Shank (1985).
    In most contexts the consistency of & is with respect to the number of time series observations T. In that case something

                                                                              i
must be said of the relative rates at which T and N increase without bound so as to guarantee convgence of D. Howevsi under
H the parameter o may be estimated cross-sectionally hence the relation '' (2.4) need only represit N-aaymptotics.




7.5                                                       —8—                                                          5.89
Proposition 2.1.     Under the null hypothesis H and assumption (A), as N increases
without bound the induced order statistics &[ik:NI (k 1,. . . n) converge in distribution
to independent Gaussian random variables with mean k and variance a where:



                            Ik                                             = pua'(ek)       (2.7)


                             or          o(1—p2)                                            (2.8)



which implies:


                                                               —
                                                          (1       p2)   x(A)               (2.9)


with non-centrality parameter:


                           A=               ()2 =                  1
                                                                                {'k)J2 .   (2.10)



where (.) is the standard normal c.d.t.14

Proposition 2.1 shows that the null hypothesis H is violated by induced ordering since the
means of the ordered &fs are no longer zero. Indeed, the mean of &(ikN1 may be positive
or negative depending on p and the (limiting) relative rank ek. For example, if p = .10
and a0 = 1 the mean of the induced order statistic in the 95-th percentile is 0.164.
    To evaluate the size of a 5 percent test based on the statistic 0 we need only evaluate
the c.d.f. of the non-central (A) at the point C'5/(1 — p9, where C5 is given in (2.5).
Observe that the non-centrality parameter A is an increasing function of p2. If p2 0
then the distribution of reduces to a central x which is identical to the distribution of
o in (2.4). This is consistent with common intuition since sorting on a characteristic that
is statistically independent of the &j's cannot disturb its null distribution. As &j and X1
 '4Tha second equality in (2.7) follow, from the fact   that () = Fg(O, + i).
7.5                                                        —9—                              5.89
become more highly correlated the non-central x2 distribution shifts to the right. However,
this does not imply that the actual size of a 5 percent test necessarily increases since the
relevant critical value for C5/(1 — p2), also grows with p2.15
     Numerical values for the size of a 5 percent test based on 0 may be obtained by first
specifying choices for the relative ranks {ek} of the n securities. We consider three sets of
{ek} yielding three distinct test statistics ë,                           and 03:



                                       =                                                                                        (2.11)
                                             n-1

                                                                                fork = 1,2,... ,n0.
           -                                   I (n+1)(n0+1)
           02                           =
                                               I
                                               IS
                                                    k+m(n0+1)—no or
                                                       (m+1)(no+1)
                                                                    — O +1
                                                                 f k—                                  '       2no.
                                                                                                                                (2.12)




                                               (I k+n0+1                              ,tor I_1
                                                                                            — i,,. ..
                                                    (m-i-i)(no+i)
                                        =
                                                                              "
           —

           93
                                                                                                                                (2.13)
                                                     k + (m—1)(no+1) —                  k — n0 + 1 ,..., 2no.
                                                                                      for
                                               I          (m+1)(no+1)



where n 2n0 and n0 is an arbitrary positive integer. The first method (2.11) simply sets
the 's so that they divide the unit interval into n equally-spaced increments. Thesecond
procedure (2.12) first divides the unit interval into m + 1 equally-spaced increments, sets
the first half of the ek's to divide the fir8t such increment into equally-spaced intervals
each of width 1/(m + 1)(n0 + 1), and then sets the remaining half so as to divide the
last increment into equally-spaced intervals also of width 1/(m + 1)(n0 ÷ 1) each. The
third procedure is similar to the second, except that the k' are chosen to divide the
 second smallest and second largest m + 1-increments into equally spaced intervals of width


  '
 1/(m + 1)(no + 1).
     In fact, if p2 = 1 the limiting distribution of lie degenerate since the test etatistic converge, in probability to the following
 limit:



 Thu. limit may be greater or less than
 zero or unity.
                                          CJ depending on the values of     ,   hence the size   of the teet in this case   may be either




 7.5                                                          — 10    —                                                            5.89
     These three ways of choosing i securities allow us to see how an attempt to create (or
remove) dispersion — as measured by the characteristic X — affects the null distribution of
the statistics. The first choice for the relative ranks is the most disperse, being evenly dis-
tributed on (0,1). The second yields the opposite extreme: the ex[jk:N1'S selected are those
with characteristics in the lowest and highest 100/(m + 1)-percentiles. As the parameter
in increases more extreme outliers are used to compute            This is also true for 03, but
to a lesser extent since the statistic is based on à[$:NI's in the second lowest and second
highest 100/(m + 1)-percentiles.
     Table 1 reports the size of the 5 percent test using ëi, J2, and 03 for various values
of n, p2, and m. For concreteness observe that p2 is simply the R2 of the cross-sectional
regression of àj on X1, so that p =         implies that only 1 percent of the variation in &
is explained by X1. For this value of R2 the entries in the first panel of Table 1 show that
the size of a 5 percent test using 01 is indeed 5 percent for samples of 10 to 100 securities.
However, using securities with extreme characteristics does affect the size, as the entries in
the '02-Test' and '03-Test' columns indicate. Nevertheless the largest deviation is only 8.1
percent. As expected, the size is larger for the test based on 2 than for that of 03 since
the former statistic is based on more extreme induced order statistics than the latter.
     When the R2 increases to 10 percent the bias becomes more important. Although tests
based on a set of securities with evenly-spaced characteristics still have sizes approximately
equal to their nominal 5 percent value, when securities with extreme characteristics are
used the size can deviate substantially. For example, the size of the 02 test that uses the
100 securities in the lowest and highest characteristic-decile is 42.3 percent! In comparison,
the 5 percent test based on the second lowest and highest two deciles exhibits only a 5.8
percent rejection rate. These patterns become even more pronounced for R2's higher than
10 percent.
      The intuition for these results may be found in (2.7): the more extreme induced order
statistics have means farther away from zero, hence a statistic based on evenly-distributed
CZ[i:N1's will not provide evidence against the null hypothesis a = 0. If the relative ranks
are extreme, as is the case for 2 and 03 the resulting &[i:NJ'5 may appear to be statistically
incompatible with the null.


2.3. Biases of Tests Based on Portfolios of Securities.
      The entries in Table 1 show that as long as the & securities chosen have characteristics

7.5                                        —   11   —                                     5.89
4evenly distributed in relative rankings, test statistics based on individual securities yield
 little inferential bias. However, in practice the ordering by characteristics such as market
 value of equity is used to group securities into portfohos and the portfolio returns are used
 to construct test statistics. For example, let n n0q where n0 and q are arbitrary positive
 integers, and consider forming q portfolios with n0 securities in each portfolio where the
 securities are chosen independently of the data. Under the null hypothesis H we have the
following:


                                    kn0                        2

                                    >                  N(O,-)      k=1,2,...,q         (2.14)
                             j=(k— 1)n0+ 1

                                          - x.                                         (2.15)
                            a k=1


 To perform a 5 percent test of H using 0, we compare it with the critical value C5 defined
 by:


                                          F2(C5) =         .95 .                       (2.16)


 Suppose we compute this test statistic using the induced order statistics {â[s.jv} instead
 of {&}. From Theorem 2.1 we have:

 Proposition 3.2.      As N increases without bound, under the null hypothesis H the
 statistics 4k (k = 1,2,... ,q) and 0,, converge in distribution to the following:




                                                   N(               ,              )
                                                                                       (2.17)




                    a k=1
                               '        (i—p2).4(A)                                    (2.18)

 7.5                                          —   12   —                                 5.89
with non-centrality parameter:



                  A
                             oP
                               2    q


                                   k=1
                                            11
                                            (
                                            \   °
                                                             krs0

                                                                        [1] I
                                                                            J
                                                                                .       (2.19)




The non-centrality parameter (2.19) is similar to that of the statistic based on individual
securities; it is increasing in p2 and reduces to the central x of (2.19) when p         0.
However, it differs in one respect: because of portfolio aggregation each term of the outer
sum (the sum with respect to k) is the average of '—1(e) over all j in the k-th portfolio.
To see the importance of this consider the case where the relative ranks are chosen to
be evenly-spaced in (0,1), i.e.,


                                        e       =                   .                   (2.20)
                                                     n0q+1

Recall from Table 1 that for individual securities the size of 5 percent tests based on
 even! y-spaced 's was not significantly biased. Table 2a reports the size of 5 percent tests
based on the portfolio statistic 0p also using evenly spaced relative rankings. The contrast
is striking. Even for an R2 as low as 1 percent, implying a correlation of only       percent
between &j and X, a 5 percent test based on 50 portfolios each with 50 securities rejects 67
percent of the time! We can also see how portfolio grouping affects the size of the test for a
fixed number of securities by comparing the (q = 1, no = j) entry with the (q j, n0 = 1)
entry. For example, in a sample of 250 securities a test based on 5 portfolios of 50 securities
has size 16.5 percent, whereas a test based on 50 portfolios of 5 securities has only a 7.5
percent rejection rate. Grouping securities into portfolios increases the size considerably.
The entries in Table 2a are also monotonically increasing across rows and across columns,
implying that the test size increases with the number of securities regardless of whether
the number of portfolios or the number of securities in each portfolio is held ftxed.
      To understand why forming portfolios yields much higher rejection rates than using
individual securities, recall from (2.7) and (2.8) that the mean of            is a function of
its relative rank i/N (in the limit), whereas its variance o(1 — p2) is fixed. Forming a
portfolio of the induced order statistics within a characteristic-fractile amounts to averaging
a collection of no approximately independent random variables with similar means and
7.5                                             —   13   —                               5.89
identical variances. The result is a statistic 4'k with a comparable mean but with a variance
i0 times smaller than each of the &[i:NJ'S. This variance reduction amplifies the importance
of the deviation of the 4b mean from zero and is ultimately reflected in the entries of Table
2a. A more dramatic illustration is provided in Table 2b, which reports the appropriate 5
percent critical values for the tests in Table 2a: when R2 = .05 the 5 percent critical value
for the x2 test with 50 securities in each of 50 portfolios is 211.67. If induced ordering is
unavoidable these critical values may serve as a method of bounding the effects of data-
snooping on inferences.
    When the R2 increases to 10 percent, implying a cross-sectional correlation of about
     percent between &j and X, the size approaches unity for tests based on 20 or more
portfolios with 20 or more securities in each portfolio. These results are especially surpris-
ing in view of the sizes reported in Table 1, since the portfolio test statistic is based on
evenly-spaced induced order statistics i:NI Using 100 securities, Table 1 reports a size
of 4.3 percent with evenly-spaced &[i:N] 's; Table 2a shows that placing those 100 securities
into 5 portfolios each with 20 securities increases the size to 56.8 percent. Computing 0p
with extreme         would presumably yield even higher rejection rates. The biases re-
ported in Tables 2a,b are even more surprising in view of the limited use we have made of
the data. The only data-related information impounded into the induced order statistics
is the ordering of the characteristics {X}. Nowhere have we exploited the values of the
Xi's, which contains considerably more precise information about the &j's.


2.4. Relaxing Assumption (A).
     The sharp results of Sections 2.2 and 2.3 are based on the assumption that the vec-
tors [X àj]' are bivariate normal and independently and identically distributed. These
requirements may be relaxed to some extent. In particular, X and àj need not be Gaus-
sian, but need only satisfy a linear regression equation such as the following to yield the
asymptotic sampling theory derived in Propositions 2.1 and 2.2:16


                                      =        + $(X —        ) + Z,                   (2.21)


where E[ZJ = 0 and X and Z are independent. Of course, Yang's (1977) theorem applies
 1Ig D&vid (1973), D&vjd ftnd G1mbo. (1974), nd Wt.rscn (1959).

7.5                                              —   14   —                              5.89
to any bivariate distribution for X2 and àj, and although departures from linearity will
change the limiting distributions of our test statistics 6 and 0,, a sampling theory may still
be obtained in principle. In such cases, the magnitude of data-snooping biases need not be
directly related to the squared correlation between X1 and àj, as it is under assumption (A).
To see this, suppose the àj's were i.i.d. standard normal random variables, and consider the
characteristic X1         Z where Z is also a standard normal variate independent of all the
&j'S. Clearly X1 and âj are uncorrelated and the vectors [X1 &jj' are independently and
identically distributed. But the induced order statistics        will be perfectly ordered!
Not surprisingly, the correlation coefficient need not play an important role when X1 and
& are not linearly related.
     Unfortunately, the assumptions of independence and identical distributions are not
as easily relaxed. When X1 and âj satisfy (2.21), the induced order statistics have the
following representation:17


                                          = ia + 13(X.N — 'z) + Z11                    (2.22)


where Z1 denotes the particular Z paired with the order statistic X.N. To develop the
properties of induced order statistics for dependent and non-identically distributed X1's
 and àj's then requires an understanding of how Xi.N and Z11] behave under these weaker
 conditions. Although David (1981, chapters 2.8 and 5.6) does present some results for the
 non-identically distributed and the dependent cases separately, combining and applying
'them to (2.22) is a formidable task which we leave to the more industrious.


2.5. Interpreting Data-Snooping Bias As Power.
     We have so far examined the effects of data-snooping under the null hypothesis that
aj = 0 for all i. Therefore, the degree to which induced ordering increases the probability of
rejecting this null is implicitly assumed to be a bias, an increase in Type I error. However,
the results of the previous sections may be re-interpreted as describing the power of tests
based on induced ordering against certain alternative hypotheses. Recall that àj is defined
to be a consistent estimator of some parameter cxj, hence:
 'IS.. David (1981, chapter 5.1) and David and Galambo. (1974).


7.5                                                   —   15   —                        5.89
                                                                                                                       (2.23)


where    denotes estimation or, more generally, "measurement" error. Since all aj's are
zero under H, the induced ordering of the estimates & creates a spurious incompatibility
with the null arising solely from the sorting of the estimation errors    But if the aj's
are non-zero and vary across i, then sorting by some characteristic X related to aj and
forming portfolios does yield a more powerful test. Grouping by X1 increases dispersion
of the afs and forming portfolios reduces the estimation error through diversification (or
the law of large numbers). Therefore what were called biases in Sections 2.1—2.3 may also
be viewed as measures of the power of induced ordering against alternatives in which the
a's differ from zero and vary cross-sectionally with X. The values in Table 2a show that
                                                                                          18
grouping on a marginally correlated characteristic can increase the power substantially.
     Of course, the essence of the data-snooping problem lies in our inability to distinguish
between this situation and that considered in the preceding sections. We observe an
empirical relation between X and &j but we do not know whether the characteristic
varies with aj or with measurement error . It is a type of identification problem that is
unlikely to be settled by data analysis alone, but must be resolved by providing theoretical
motivation for a relation, or no relation, between K and aj. We shall return to this issue
in our empirical example.


3. Monte Carlo Results.

     Although the values in Tables 1 and 2a,b plainly show the magnitude of the biases
associated with induced ordering their practical relevance may be limited in three respects.
First, although the test statistics considered are similar in spirit to those used in empirical
tests of asset pricing models, the assumption of cross-sectional independence has been
used in their construction. In practice the covariances of N asset returns are estimated
  'However, implicit in Table 2*1. the auumption that the &'s are cross-sectionally independent which may be too restrictive
arequirwn.nt for interesting alternative hypotheses. For example, if the null hypothesis    = 0 corresponde to the Sharp.-
Lintner CAPM then on. natural alternative might be a two-factor APT. In that case the &s would tend to be positively
crou-,ectionally correlated as a result of the omitted factor (assuming that the included factc is the return on the market).
This positive correlation reduces the benefits of grouping in much the same way that positive correlation among etock return.
reduces the benefits of diversification in a portfolio. Grouping by induced ordering does tend to cluster &. with eirnilar (non-
.ero) means together, but correlation work, against the variance-reduction that gives portfolio-based tests their power. The
importance of cro..-s.ctional dependence is evident in MacKinlays (1987) pow calculations. We provide further discussion
in Section 3.3.


7.5                                                        —   16   —                                                     5.89
with a finite number T of time series observations which, under certain assumptions,
yields an F-distributed test statistic. Both sampling error from the covariance matrix
estimator and cross-sectional dependence will affect the null distribution in finite samples.
Second, the sampling theory of Section 2 is based on asymptotic approximations, and few
results on rates of convergence for Theorem 2.1 are available.19 How accurate are such
approximations for empirically realistic sample sizes? Finally, the form of the asymptotics
does not correspond exactly to procedures followed in practice. Recall that the limiting
result involves a finite number n of securities with relative ranks that converge to fixed
constants j as the number of securities N increases without bound. This implies that as
N increases the number of securities in between any two of our chosen -z must also grow
without bound. However, in practice characteristic-sorted portfolios are constructed from
all securities within a fractile, not just from those with particular relative ranks. Although
intuition suggests that this may be less problematic when ii is large (so that within any
given fractile there will be many securities), it is surprisingly difficult to verify.20
     In this section we report results from Monte Carlo experiments that show the asymp-
totic approximations of Section 2 to be quite accurate in practice despite these three
reservations. Section 3.1 evaluates the quality of the asymptotic approximations for the
   test used in calculating Tables 2a,b. Section 3.2 considers the effects of induced or-
dering on F-tests with fixed N and T when the covariance matrix is estimated and the
data-generating process is cross-sectionally independent. Section 3.3 considers the effects
of relaxing the independence assumption.


3.1. Simulation Results for 9,,.

      The x () limiting distribution of 0,, obtains because any finite collection of induced
order statistics, each with fixed unique limiting relative rank in (0,1), becomes mutually
independent as the total number N of securities increases without bound. This asymptotic
approximation implies that between any two of the n chosen securities there will be an
increasing number of securities omitted from all portfolios as N increases. However, in
practice all securities within a particular characteristic fractile are included in the sorted
  "Howev.r, ise Shattacharyc (1984) and Sen (1981).
  20ffowever when ii is larg. relative to a fInite N the asymptotic apprcudmaticn breaks down. In particular, the dependence
betwe adjacent induced order statistics becomes important when n/N is large. A few elegant asymptotic approximation. for
sums of induced order statistice are available using functional central limit theory and may allow us to generaliae our results to
the more empirically relevant case. See, for example, Bhattadiarya (1974), Nagaraja (1982*, 1982b, 1984), Sandström (1987),
Sen (1976, 1981), and Yang (1981*, 1981b).


7.5                                                         —   17   —                                                     5.89
portfolios, hence the theoretical sizes of Table 2a may not be an adequate approximation to
this more empirically relevant situation. To explore this possibility we simulate bivariate
normal vectors (&, X1) with squared correlation R2, form portfolios using the induced
ordering by the Xe's, compute 0p using oil the '(i:NI' (in contrast to the asymptotic
experiment where only those induced order statistics of given relative ranks are used), and
then repeat this procedure 5,000 times to obtain the finite sample distribution.
     Table 3 reports the results of these simulations for the same values of R2, n0, and q
as in Table 2a. Except when both n0 and q are small, the empirical sizes of Table 3 match
their asymptotic counterparts in Table 2a closely. Consider, for example, the R2 = .05
panel; with 5 portfolios each with 5 securities, the difference between theoretical and
empirical size is 1.1 percentage points, whereas this difference is only 0.2 percentage points
for 25 portfolios each with 25 securities. When n0 and q are both small the theoretical
and empirical sizes differ more for larger R2, by as much as 10.3 percent when R2 = .30.
However, for the more relevant values of R2 the empirical and theoretical sizes of the 0p
test are virtually identical.


3.2. Effects of Induced Ordering on F-Tests.

     Although the results of Section 3.1 support the accuracy of our asymptotic approxi-
mation to the sampling distribution of J,, the closely related F-statistic is more frequently
used in practice. In this section we consider the finite-sample distribution of this test statis-
tic after induced ordering. We perform Monte Carlo experiments under the now standard
multivariate data-generating process common to virtually all static financial asset pricing
models. Let rst denote the return of asset i between dates t — 1 and t, where * 1,     2,. N
and t = 1,2,... ,T. We assume that for all assets i and dates t the following obtains:

                                                     Ic

                                        aj +              +                                (3.1)
                                                2=1


where   a and J3 are fixed parameters, r is the return on some portfolio j          (systematic
risk), and c is mean-zero (idiosyncratic) noise. Depending on the particular application,
r;t may be taken to be nominal, real, or excess asset returns. The process (3.1) may be
viewed as a factor model where the factors correspond to particular portfolios of traded

7.5                                         —   18    —                                     5.89
assets, often called the "spanning portfolios" of an "exact factor pricing model."21 In
matrix-form, we have:


                          = a + Br' + Et                      ,          E[Et   =0,           E[r'] =                        (3.2)



                                                                           ( E       foro=t.
                                                      E[EsE'J =                                                              (3.3)
                                                                           (.   0 otherwise.
                                                                           1    fl fors=t.
                                                                                                                            (3.4)
                                                                                0 otherwise.

where r is the Nxl-vector of asset returns at time t, B is the Nxk-matrix of factor loadings,
r' is the kxl-vector of time-t spanning portfolio returns, and a and are Nxl-vectors of
asset return means and disturbances respectively.
       This data-generating process is the starting point of the two most popular static
models of asset-pricing, the CAPM and the APT. Further restrictions are usually imposed
by the specific model under consideration.22 Such restrictions often reduce to the following
null hypothesis:
                                                 H:          g(a,B) =            0

where the function g is model-dependent.23 Many tests simply set g(a, B) = a and define
   as excess returns, such as those of the Sharpe-Lintner CAPM and the exact factor-
pricing APT. With the added assumption that r and r' are jointly normally distributed
the finite-sample distribution of the following test statistic is well-known:


                        = c ______                                                   ic
                                                                                              T-k-N                         (3.5)
                                                              FN,T_k....N                            N
                                   1+ ppO-lpp
  2l5,
  22
       for example,Lehmann and Modest (1988).
         example, under the Sharp.-Lintner CAPM the vector of disturbances e it temporally independent, k = 1, and the
single factor is the return on the v*lu..weight.d market portfolio. Alternatively under the exact factor-pricing version of the
APT the k factors ar, th. returns of spanning portfolios, portfolios for which there exists a linear combination that is a tangency
portfolio. See, for example, Chamberlain (1983), llub.rinsn and Kendel (1987), and L.hmann and Modest (1988).
  23Exsmples of tests which fit Into this framework are thos, in Campbell (1987), Connor and Korajcsyk (1988), Gibbons
(1982), Gibbons and Person (1985), Gibbons, Shanken, and Roes (1987), Eub.rinan and Kandel (1987), MacKinlay (1987)
L.hmann and Modest (1988), Stambaugh (1982), and Shank.n (1985).




7.5                                                         —     19 —                                                       5.89
    where E and fl are the maximum likelihood estimators of the covariance matrices of the
    disturbances t and the spanning portfolio returns r respectively, and F' is the vector of
    sample means of r'. If the number N of available securities is greater than the number
    of time series observations T less k + 1 the estimator i is singular and the test statistic
    (3.5) cannot be computed without additional structure. This problem is most often cir-
    cumvented in practice by forming portfolios. That is, let rt be a qxl-vector of returns of q
    portfolios of securities where q < N. Since the return-generating process is linear for each
    security i, a linear relation also obtains for portfolio returns. However, as the analysis of
    Section 2 foreshadows, if the portfolios are constructed by sorting on some characteristic
    correlated with & then the null distribution of ,' is altered.
         To evaluate the null distribution of under characteristic-sorting data-snooping, we
    design our simulation experiments in the following way. The number of time series obser-
    vations T is set to 60 for all simulations. With little loss in generality we set the number
    of spanning portfolios k to zero so that &j =           r/T. For simplicity we also assume
    that the covariance matrix E of et is equal to the identity matrix I; this assumption is
    relaxed in Section 3.3. We simulate T observations of the Nxl Gaussian vector r (where
    N takes the values 200, 500, and 1000), and compute &. We then form q portfolios (where
    q takes the values 10 and 20) by constructing a characteristic X that has correlation p
    with & (where p2 takes the values .01, .05, .10, .20, and .30) and then sorting the &s by
    this characteristic. To do this we define:


•
               Xi       &i + 'is        ,     ii   i.i.d. N(0,a)        =     P2           (3.6)



    Having constructed the X1's we order {&} to obtain {&[.N]}, construct portfolio intercept
    estimates which we call k' k = 1,. .. ,

                                            kn,,
                             =     --                           ,   N   n0q                 (3.7)
                                    °
                                        i=(k—1)no+1


    from which we form the F-statistic:




    7.5                                            —   20   —                               5.89
                        =                                                        T—q
                                                  Fq,T_q                                   (3.8)


 where denotes the qxl-vector of k's and E is the maximum likelihood estimator of the
 qxq covariance matrix of the q portfolio returns. This procedure is repeated 5,000 times
 and the mean and standard deviation of the resulting distribution for the statistic & are
reported in Table 4a, as well as the size of 1, 5, and 10 percent F-tests.
      Even for as small an    as 1 percent the empirical size of the 5 percent F-test differs
significantly from its nominal value for all values of q and n0. For the sample of 1,000
securities grouped into 10 portfolios the empirical rejection rate of 36.7 percent deviates
substantially from 5 percent both economically and statistically. The size is somewhat
 lower — 26.8 percent — when the 1,000 securities are grouped into 20 portfolios, matching
the pattern in Table 2a. Also similar is the monotonicity of the size with respect to
the number of securities; for 200 securities the empirical size is only 7.1 percent with 10
portfolios, but is more than quintupled for 1,000 securities. When the squared correlation
between âj and X1 increases to 10 percent, the size of the F-test is essentially one for
sample sizes of 500 or more. Thus even for finite sample sizes of practical relevance, the
importance of data-snooping via induced ordering cannot be over-emphasized.


3.3. F-Tests Without Cross-Sectional Independence.

    The intuition for the substantial bias that induced ordering imparts on the size of
portfolio-based F-tests is that the induced order statistics {&(j.N } generally have non-
zero means,24 hence the average of these statistics within sorted portfolios have non-zero
means and reduced variances about those means. Alternatively, the bias from portfolio-
formation is a result of the fact that the &j's of the extreme portfolios do not approach
zero as more securities are combined, whereas the residual variances of the portfolios (and
consequently the variances of the portfolio à's) do tend to zero. Of course, our assumption
that the disturbances of (3.2) are cross-sectionally independent implies that the portfolio
residual variance approaches zero rather quickly (at rate i-). But in many applications
(such as the CAPM) cross-sectional independence is too strong an assumption. Firm size
and industry membership are but two characteristics that might induce cross-sectional
 24    those    for which   —.   will have zero expectation under the null hypotheeli H.


7.5                                              — 21   —                                  5.89
correlation of security residuals. In particular, when the residuals are (positively) cross-
sectionally correlated the bias is likely to be smaller since the variance-reduction due to
portfolio-formation is less sharp than in the cross-sectionally independent case.
     To provide a measure of the importance of relaxing the independence assumption,
in this section we simulate a data-generating process in which disturbances are cross-
sectionally correlated. The design is identical to that of Section 3.2 except that the residual
covariance matrix E is not diagonal. Instead, we set:


                                        E        oS'+i                                   (3.9)


where 8 is an Nxl vector of parameters and I is the identity matrix. Such a covariance
matrix would arise, for example, from a single common factor model for the Nxl vector
of disturbances et:


                                            = öA + i't                                 (3.10)


where At is some i.i.d. zero-mean unit-variance common factor independent of Vt, and Vt
is (N-dimensional) vector white-noise with covariance matrix I. For our simulations, the
parameters 8 are chosen to be equally-spaced in the interval [—1, 1]. With this design the
cross-correlation of the disturbances will range from —0.5 to 0.5. The X1's are constructed
as in (3.6) with:



                                    2   =       (1—p2)a2(a)
                                                                                       (3.11)



                               o2(a)                     + 1)                          (3.12)




where p2 is fixed at .05.



7.5                                         —   22   —                                   5.89
      With this design, the results of the simulation experiments may be compared to the
second panel of Table 4a and are reported in Table 4b.25 Despite the presence of thecross-
sectional dependence the impact of induced ordering on the size of the F-test is significant.
For example, with 20 portfolios each containing 25 securities the empirical size of the 5
percent test is 32.3 percent; with 10 portfolios of 50 securities each the empirical size
increases to 82.0 percent. As in the cross-sectionally independent case the bias increases
with the number of securities given a fixed number of portfolios and the bias decreases as
the number of portfolios is increased given a fixed number of securities. Not surprisingly,
for fixed n0 and q, cross-sectional dependence of the àj's lessens the bias. However, the
entries in Table 4b demonstrate that the effects of data-snooping may still be substantial
even in the presence of cross-correlation.



4. An Empirical Example.

     To illustrate the potential empirical relevance of data-snooping biases associated with
induced ordering we draw an example from the recent literature. Lehmann and Modest
(1988) present a multivariate test of a 15-factor APT model which rejects the zero-intercept
null hypothesis using five portfolios formed by grouping securities ordered by market value
of equity.26 We select this example because under its null hypothesis the disturbances c
of (3.2) are cross-sectionally independent, an assumption we adopted in Sections 2 and
3•27 Moreover, since 15 factors are included in the cross-sectional regressions, a diagonal
covariance matrix for is a plausible assumption.
     It is a well-known fact that the estimated intercept j from the single-period CAPM
regression (excess individual security returns regressed on an intercept and the market risk
premium) is negatively cross-sectionally correlated with log-size.28 Since this &j will in
general be correlated with the estimated intercept from a 15-factor APT regression, it is
likely that the estimated APT-intercept and log-size will also be empirically correlated.29
 26The correspondenc, between the two tables is not exact because the dependency introduced in (3.9) induce. cross-sectional
heteroscedastiaty in the &'. hence p = .05 yields an R2 of .05 only approximately.
 26See Lehmann and Modest (1988, Table 1, last row). Connor and Korajciyk (1988) report similar finding..
  27Although Ross's (1978, 1977) original formulation assumes the cross-sectional uncorrelatednees of the disturbances (which is
equivalent to independence under multivariate normality), generalizations by Chamberlain (1983), Chamberlain and Rothschild
(1983), and Wang (1988) allow for cross-sectional dependence. We conjecture that the asymptotic results of Section 2 also obtain
under the more general framework, however the finite sample propertie. deduced in Section S will be sensitive to cross-sectional
dependence.
  2$ See for example, Ban, (1982) and Brown, Kleidon, and Marsh (1983).
  20 We recognize that correlation is not traritive, so if X ii correlated with Y and Y with Z, X need not be correlated with
Z. However, since the intercepts from the two regressions will be functions of some common random variables, situations in
which they are independent are the exception rather than the rule.

7.5                                                        —   23 —                                                       5.89
Unfortunately we do not have a direct measure of the correlation of the APT intercept
and log-size which is necessary to derive the appropriate null distribution after induced
ordering.30 As an alternative we estimate the cross-sectional R2 of the estimated CAPM
alpha, &, with log-size of market value X2 and use this R2 as well as R2 and R2 to
estimate the bias attributable to induced ordering.
     Following Lehmann and Modest (1988) we consider four 5-year time periods from
January 1963 to December 1982. X is defined to be the logarithm of beginning-of-period
market values of equity. The & 's are the intercepts from regressions of excess returns on
the market risk premium as measured by the difference between an equal-weighted NYSE
index and monthly Treasury bill returns, where the NYSE index is obtained from the
Center for Research in Security Prices (CRSP) database. The R2's of these regressions are
reported in the second column of Table 5. One cross-sectional regression of & on log-size
X is run for each 5-year time period using monthly NYSE-AMEX data from CRSP. We
run regressions only for those stocks having complete return histories within the relevant
5-year period.
     Table 5 contains the test statistics for a 15-factor APT framework using five size-
sorted portfolios. The first four rows contain results for each of the four sub-periods and
the last row contains aggregate test statistics. To apply the results of Sections 2 and 3 we
transform Lehmann and Modest's (1988) F-statistics into (asymptotic) x2 variates.31 The
total number of available securities portfolios ranges from a minimum of 1001 for the first
5-year sub-period to a maximum of 1359 for the second sub-period. For each test statistic
in Table 5 we report four different p—values: the first is with respect to the null distribution
that ignores data-snooping and the next three are with respect to null distributions that
account for induced ordering to various degrees.
     The entries in Table 5 show that the biases from sorting by characteristics that have
been empirically selected can be immense. The p—values range from 0.008 to 0.070 in
the four sub-periods according to the standard theoretical null distribution, yielding an
aggregate p—value of 0.00014, considerable evidence against the null. When we adjust for
the fact that the sorting characteristic is selected empirically (using the R2 from the cross-
sectional regression of êç on X1), the p-values for these same four sub-periods range from
0.272 to 1.000, yielding an aggregate p-value of 1.000! Therefore, whether or not induced
  30Nor did L.hmann and Modest prior to their extensive inve.tigatioi. If they ar, subject to any data-snooping blues it
ii only from
           their awareness of sie,-mlated empirical results for the .ingla-pariod CAPM, and of corresponding results for the
APT as in Chan, Chen, and Hsl.h (1986).
 "Since L.hmann and Modest (1988) use weekiy data th. null distribution of their test statistics is F5240. In practice the
inference, ar. virtually iderjcal using the   distribution after multiplying the teat statistic by 5.

7.5                                                        —   24   —                                                 5.89
ordering is allowed for can change inferences dramatically.
     The appropriate R2 in the preceding analysis is the squared correlation between log-
size and the intercept from a 15-factor APT regression and not the one used in Table 5.
To see how this may affect our conclusions recall from (2.23) in Section 2.5 that the cross-
sectional correlation between &j and log-size can arise from two sources: the estimation
error in &, and the cross-sectional dispersion in the "true" CAPM (which is zero under
the null hypothesis). Correlation between X and will be partially reflected in correlation
between the estimated APT intercept and log-size. The second source of correlation will
not be relevant under the APT null hypothesis since under that scenario we assmne that
the 15-factor APT obtains and therefore the intercept vanishes for all securities. As a
conservative estimate for the appropriate R2 to be used in Table 5, we set the squared
correlation equal to 12 and k2, yielding the p—values reported in the last two columns
of Table 5. Even when the squared correlation is only k2 the inferences change markedly
after induced ordering, with p—values ranging from 0.078 to 0.720 in the four sub-periods,
and 0.298 in the aggregate. This simple example illustrates the severity with which even
a mild form of data-snooping can bias our inferences in practice.
     Nevertheless, it should not be inferred from Table 5 that all size-related phenomena
are spurious. After all, the correlation between X and â may be the result of cross-
sectional variations in the population cc's, and not estimation error. Even so, tests using
size-sorted portfolios are still biased if based on the same data from which the size effect
was previously observed. A procedure that is free from such biases is to decide today that
size is an interesting characteristic, collect ten years of new data, and then perform tests on
size-sorted portfolios from this fresh sample. if our maintained assumption (A) holds, this
will yield a perfectly valid test of the null hypothesis H since the X2's are then independent
of the âj's and induced ordering by an independent characteristic cannot disturb the null
distribution of the test statistics.




7.5                                        —   25   —                                    5.89
5. How the Data Gets Snooped.
     Whether the probabilities of rejection in Table 2a are to be interpreted as size or
power depends, of course, on the particular null and alternative hypotheses at hand, the
key distinction being the source of correlation between &j and the characteristic X,. Since
our starting point in Section 2 was the assertion that this correlation is "spurious," the
values of Table 2a represent probabilities of falsely rejecting the null hypothesis. We
suggested in Section 2.5 that the source of this spurious correlation is correlation between
the characteristic and the estimation errors in &j, since such errors are the only source
of variation in à under the null. But how does this correlation arise? One possibility is
the very mechanism by which characteristics are selected. Without any economic theories
for motivation, a plausible behavioral model of how we determine characteristics to be
particularly "interesting" is that we tend to focus on those that have unusually large
squared sample correlations or R2's with the &j's. If so, then even in a collection of K
characteristics all of which are independent of the &'s, correlation between the &j's and
the most "interesting" characteristic is artificially created.
    More formally, suppose for each of N securities we have a collection of K distinct
and mutually independent characteristics Y, k = 1, 2, ..., K, where Yk is the k-th
characteristic of the i-th security. Let the null hypothesis obtain so that aj = 0 for all i,
and assume that all characteristics be independent of {&}. This last assumption implies
that the distribution of a test statistic based on grouped j 's is unaffected by sorting on
any of the characteristics. For simplicity let each of the characteristics and the àj's be
normally distributed with zero mean and unit variance, and consider the sample correlation
coefficients:




                                                                 k   = 1,2,..., K (5.1)
                                      /N1(& -
      Plc                                                  ,
                                  .
                \/Ei(Yik

where k and are the sample means of characteristic k and the &j 's respectively. Suppose
we choose as our sorting characteristic the one that has the largest squared correlation with
the àj's, and call this characteristic X1. That is, X Y1ks where the index k is given by
the relation:

7.5                                       —   26 —                                      5.89
                                                           =                         •
                                                                                                                             (5.2)


X is a new characteristic in the statistical sense, in that its distribution is no longer the
same as that of the Y1k's.32 It is apparent that X, and à are not mutually independent
since the &j's were used in selecting this characteristic. By construction, extreme real-
izations of the random variables {X} tend te :cur when extreme realizations of {&}
occur.
     To estimate the magnitude of correlation spuriously induced between X and a2, first
observe that although the correlation between Y2k and & is zero for all k, E[p]
under our normality assumption. In fact, since the j's are well-known to be independently
and identically distributed Beta(, (N — 2)) variates, the distribution and density func-
tions of ., denoted by F5 (v) and f (v) respectively, may be readily derived as:33


                            F5(v) = [F(v)JK                       ,            V   E (0,1)                                   (5.3)


                             fs(v) = K{F(v)]K_lf(v)                                      ,   vE(O,i)                        (5.4)


where F and f are the c.d.f. and p.d.f. of the Beta distribution with parameters and
       —   A measure of that portion of squared correlation between X2 with &j due to
           2).
sorting on   is then given by:

                                                                          ci                      1
                                     E[,3.J — E[,] = j vf,(v)dv                              —
                                                                                                 N—1                        (5.5)
                                                       0


For 25 securities and 50 characteristics, -y is 20.5 percent!34 With 100 securities, y is still
  32 In fact, if we denote by Yj, the Nxl vector containing values of characteristic k for each of the N securities then the vector
most highly correlated with S (which we have called X) may be viewed as the concomitant IKKI of the K-th order statitic
       = ,.. As in the scaler case, induced ordering does change the distribution of the vector concomitants.
  3SThat the squared correlation coefficients are lid. Beta random variable. follow, from our assumptions of normality and
the mutual independeece of the characteristic, and the S,. (see Stuart and Ord (1987, chapter 16.28) for example). The
distribution and density functions of the maximum follow directly from this.
  34Note that i is only an approximation to the squared population correlation:
                                                   E(X. — E[Xl)(&1 — Eta))
                                                     —
                                                         E(X])2 v'E(&, — E[&l)2

7.5                                                          —   27   —                                                      5.89
5.4 percent and only declines to 1.1 percent for N = 500. Although there is in fact no
statistical relation between any of the characteristics and the &j'S, a procedure that focuses
on the most striking characteristic can create spurious statistical dependence.
      As the number of securities N increases, this particular source of dependence becomes
less important since all the sample correlation coefficients Pk converge almost surely to
zero, as does y. However, recall from Table 2a that as the sample size grows the bias
increases if the number of portfolios is held fixed, hence a larger N and thus a smaller -
does not necessarily imply a smaller bias. Moreover, since -' is increasing in the number of
characteristics K, we cannot find refuge in the Law of Large Numbers without weighing the
number of securities against the number of characteristics and portfolios in some fashion.
      It can be argued that even the most unscrupulous investigator might hesitate at the
 kind of data-snooping we have just considered. However, the very review process that
 published research undergoes can have much the same effect, since competition for limited
journal space tilts the balance in favor of the most striking and dissonant of empirical
 results.35 As a consequence, interest may be created in otherwise theoretically irrelevant
characteristics. In the absence of an economic paradigm, such data-snooping biases are
 not easily distinguishable from violations of the null hypothesis. This inability to sepa-
 rate pre-test bias from alternative hypotheses is perhaps the most compelling criticism of
 "measurement without theory."




However, Monte Carlo simulation, with 10,000 replications show that this approximation is excelI,t even for small sample
sues. For example, fixing K at 50, the correlation from the simulations is 22.82 percent for N = 25, whereas (5.5) yield,
  = 20.47 percent; for N = 100 the simulations yield a correlation of 6.25 percent, compared to a of 5.39 percent.
  35The Anomal*e section of the Joensal of Ecoromic PeupecHeea is perhaps th. most obvious example of our deliberate
search for the untual in econcinics.




7.5                                                    —   28   —                                                  5.89
 6. Conclusion.

      Although the size effect may signal important differences between the economic struc-
 ture of small and large corporations, how these differences are manifested in the stochastic
properties of their equity returns cannot be reliably determined purely through data anal-
ysis. Much more convincing would be the empirical significance of size, or any other
quantity, that is based on a model of economic equilibrium in which the characteristic is
shown to be related to the behavior of asset returns. Our findings show that tests using
securities grouped according to theoretically-motivated correlations between X1 and & can
be powerful indeed. Interestingly, tests of the APT with portfolios sorted by such charac-
teristics (own-variance and dividend yield) no longer reject the null hypothesis.36 Sorting
on size yields rejections whereas sorting on theoretically relevant characteristics such as
own-variance and dividend yield does not. This suggests that data-motivated grouping
procedures should be employed cautiously.
      It is widely acknowledged that incorrect conclusions may be drawn from procedures
violating the assumptions of classical statistical inference, but the nature of these violations
is often as subtle as it is profound. In observing that economists (as well as those in the
natural sciences) tend to seek out anomalies, Merton (1988, p.104) writes: "All this fits
well with what the cognitive psychologists tell us is our natural individual predilection to
focus, often disproportionately so, on the unusual. . . . This focus, both individually and
institutionally, together with little control over the number of tests performed, creates a
fertile environment for both unintended selection bias and for attaching greater significance
to otherwise unbiased estimates than is justified." The recognition of this possibility is
a first step in guarding against it. The results of our paper provide a more concrete
remedy for such biases in the particular case of portfolio formation via induced ordering
on data-instigated characteristics. However, non-experimental inference may never be
completely free from data-snooping biases since the attention given to empirical anomalies,
incongruities, and unusual correlations is also the modus operandi for genuine discovery
and progress in the social sciences. Formal statistical analyses such as ours may serve
as primitive guides to a better understanding of economic phenomena, but the ability to
distinguish between the spurious and the substantive is likely to remain a cherished art.

    See Lehmann and Modest (1988). Chen, Roll, and Roe. (1986, footnote 8) report similar negative finding. for the APT
with portfolio. formed by sorting on CAPM betas, the standard deviation of returns in a market.model regression, and the
level of the stock price.



7.5                                                    —   29 —                                                   5.89
                                           References


Aldous, D., 1989, Probability Approximations via the Poisson Clumping Heuristic, New
   York: Springer—Verlag.
Banz, R. W., 1981, "The Relationship Between Return and Market Value of Common
      Stocks," Journal of Financial Economics 9, 3—18.
Bhattacharya, P. K., 1974, "Convergence of Sample Paths of Normalized Sums of Induced
   Order Statistics," Annals of Statistics 2, 1034—1039.
          1984, "Induced Order Statistics: Theory and Applications," in P. R. Krishnaiah
      and P. K. Sen (eds.) Handbook of Statistics 4: Nonparametric Methods, Amsterdam:
      North—Holland.
Black, F., Jensen, M., and M. Scholes, 1972, "The Capital Asset Pricing Model: Some
   Empirical Tests," in M. Jensen (ed.) Studies in the Theory of Capital Markets, New
   York: Praeger.
Brown, P., Kleidon, A. and T. Marsh, 1983, "New Evidence on the Nature of Size Related
      Anomalies in Stock Prices," Journal of Financial Economics 12, 33—56.
Campbell, J. Y., 1987, "Stock Returns and the Term Structure," Journal of Financial
      Economies 18, 373—400.
Chamberlain, G., 1983, "Funds, Factors, and Diversification in Arbitrage Pricing Models,"
      Econometrica 51, 1305—1323.
           and M. Rothschild, 1983, "Arbitrage, Factor Structure, and Mean-Variance Anal-
      ysis on Large Asset Markets," Econometrica 51, 1281—1304.
Chan, K. and N. Chen, 1988, "An Unconditional Asset-Pricing Test and the Role of Firm
  Size as an Instrumental Variable for Risk," Journal of Finance 43, 309—325.
           andD. Hsieh, 1985, "An Exploratory Investigation of the Firm Size Effect," Jour-
      nal of Financial Economics 14, 451—471.
Chen, N., Roll, R. and S. Ross, 1986, "Economic Forces and the Stock Market," Journal
      of Business 59, 383—403.
Connor, G. and R. Korajczyk, 1988, "Risk and Return in an Equilibrium APT: Application
  of a New Test Methodology," Journal of Financial Economics 21, 255—290.
David, H. A., 1973, "Concomitants of Order Statistics," Bulletin of the International
      Statistical Institute 45, 295—300.
           1981, Order Statistics, Second Edition, New York: John Wiley and Sons.
            and J. Galambos, 1974, "The Asymptotic Theory of Concomitants of Order Statis-
      tics," Journal of Applied Probability 11, 762—770.
          O'Connell, M. J. and S. S. Yang, 1977, "Distribution and Expected Value of the
      Rank of a Concomitant of an Order Statistic," Annals of Statistics 5, 216—223.

7.5                                          —   30   —                                5.89
Fama, E. and J. MacBeth, 1973, "Risk, Return, and Equilibrium: Empirical Tests," Jour-
      no.! of Politico.! Economy 71, 607—636.
Galambos, J., 1987, The A8ymptotic Theory of Extreme Order Statistic8, Second Edition,
   Malabar: Krieger Publishing Company.
Gibbons, M. R., 1982, "Multivariate Tests of Financial Models: A New Approach," Journal
   of Financial Economic8 10, 3—27.
           and W. Ferson, 1985, "Testing Asset Pricing Models With Changing Expectations
      and an Unobservable Market Portfolio," Journal of Financial Economics 14, 217—236.
           Ross, S. A. and J. Shanken, 1987, "A Test of the Efficiency of a Given Portfolio,"
      to appear in Econometrica
Huberman, C. and S. Kandel, 1987, "Mean Variance Spanning," Journal of Finance 42,
      873—888.

Kandel, S. and R. Stambaugh, 1987, "On Correlations and Inferences About Mean-Variance
   Efficiency," Journal of Financial Economics 18, 61—90.
Learner, E., 1978, Specification Searches, New York: John Wiley and Sons.
Lehrnann, B. N. and D. Modest, 1988, "The Empirical Foundations of the Arbitrage Pricing
   Theory," Journal of Financial Economics 21, 213—254.
MacKinlay, A. C., 1987, "On Multivariate Tests of the CAPM," Journal of Financial
      Economics 18, 341—372.
Merton, R., 1987, "On the Current State of the Stock Market Rationality Hypothesis," in
  R. Dornbusch, S. Fischer, and J. Bossons (eds.), Macroeconomics and Finance: Essays
  in Honor of Franco Modigliani, Cambridge: M.I.T. Press.
Nagaraja, H. N., 1982a, "Some Asymptotic Results for the Induced Selection Differential,"
   Journal of Applied Probability 19, 233—239.
           1982b, "Some Nondegenerate Limit Laws for the Selection Differential," Annals
      of Statistics 10, 1306—1310.
           1984, "Some Nondegenerate Limit Laws for Sample Selection Differential And
      Selection Differential," Sankhyd 46, Series A, 355—369.
Sandstróm, A., 1987, "Asymptotic Normality of Linear Functions of Concomitants of Order
   Statistics," Met rika 34, 129—142.
Sen, P. K., 1976, "A Note On Invariance Principles For Induced Order Statistics," Annals
      of Probability 4, 474—479.
            1981, "Some Invariance Principles for Mixed Rank Statistics and Induced Order
      Statistics and Some Applications," Communication.s in Statistics AlO, 1691—1718.
Shanken, J., 1985, "Multivariate Tests of the Zero-Beta CAPM," Journal of Financial
      Economics 14, 327—348.
Siegmund, D., 1985, Sequential Analysis, New York: Springer-Verlag.


7.5                                         —   31   —                                  5.89
Stambaugh, R. F., 1982, "On the Exclusion of Assets from Tests of the Two Parameter
      Model," Journal of Financial Economics 10, 235—268.
Stuart, A. and J. Ord, 1987, Kendall's Advanced Theory of Statistics, New York: Oxford
   University Press.
Wang, T., 1988, Essays on the Theory of Arbitrage Pricing, unpublished doctoral disser-
  tation, Wharton School, University of Pennsylvania.
Watterson, G. A., 1959, "Linear Estimation in Censored Samples from Multivariate Normal
  Populations," Annals of Mathematical Statistics 30, 814—824.
Yang, S. S., 1977, "General Distribution Theory of the Concomitants of Order Statistics,"
  Annals of Statistics 5, 996-1002.
           1981a, "Linear Functions of Concomitants of Order Statistics With Application
      to Nonparametric Estimation of a Regression Function," Journal of the American Sta-
      tistical Association 76, 658—662.
           1981b, "Linear Combinations of Concomitants of Order Statistics with Application
      to Testing and Estimation," Annals of the Institute of Statistical Mathematics 33 (Part
      A), 463—470.




7.5                                        —   32   —                                   5.89
                                                                 Table 1


Theoretical sires of nominal 5 percent        -tests of H:       = 0 (i =       1. n) using the test statistics I     where   9
it &.(.)/Q. j =             1,   2, 3 for variot sample sires n. The statistic •
                                 is constructed from induced order statistics
                                                                                  based on induced order statistics with relative
                                                                                   is
                                                                              ranked in the lowest and hight 100/(,n+ 1)-percent
ranks evenly spaced in (01); i
fractiles; and 93 is constructed from those ranked in the second lowest and second highest 100/(m + 1)-percent fractiles. The
R2 is the square of the correlation between &, and the sorting characteristic.




                 n           1-Test        93-Test     93-Test        92-Test      93-Test    12-Test      93-Test
                                           (in = 4)    (,n = 4)      (in = 9)      (in = 9)   (in = 19)   (in = 19)


             R2 =     .01

                 10              0.049      0.053       0.048         0.056         0.050      0.059       0.053
                 20              0.049      0.054       0.047         0.058         0.050      0.063       0.054
                 50              0.049      0.056       0.046         0.063         0.051       0.071      0.057
                100              0.049      0.059       0.045         0.069         0.051      0.081       0.059


              R3 =    .05

                 10              0.045      0.063       0.041         0.080         0.051       0.101      0.066
                 20              0.045      0.070       0.038         0.096         0.052      0.130       0.073
                 50              0.046      0.086       0.033         0.135         0.053      0.201       0.087
                 100             0.047      0.107       0.028         0.190         0.054      0.304       0.106


              R2 =    .10

                 10              0.040      0.076       0.032         0.116         0.052      0.166       0.083
                 20              0.041      0.093       0.028         0.158         0.053      0.244       0.099
                 50              0.042      0.133       0.020         0.267         0.055      0.442       0.137
                 100             0.043      0.192       0.014         0.423         0.058      0.680       0.191


              R3 =    .20

                 10              0.030      0.104       0.019         0.202         0.052      0.330       0.121
                 20              0.032      0.146       0.013         0.318         0.054      0.528       0.163
                 50              0.034      0.262       0.006         0.599         0.059      0.862       0.272
                 100             0.036      0.432       0.002         0.857         0.064      0.987       0.429


              R2 =    .30

                  10             0.021      0.134       0.010          0.307        0.050       0.520       0.163
                  20             0.023      0.212       0.005          0.511        0.053       0.786       0.242
                  50             0.026      0.428       0.001          0.863        0.060       0.989       0.447
                 100             0.029      0.696       0.000          0.989        0.069       1.000       0.692




7.2.1                                                                                                                         2.89
                                                          Table 2a

Theoretical else. of nominal 5 percent X.teatI of H: . = 0 (1 = 1,... ii) using the test statistic i, where 1, q_1    /o
and        - k—1)q+1 &.zqJ is constructed from portfolio k, with portfolios formed by sorting on some characteristic
correlated with estimates &. This induced ordering alters the null distribution of e, from x to (1 — R2)             where the
non-cestraIity parameter.\ is a function of the number q of portfolios, the number n, of securitie, in each portfolio, and the
squared correlation coefficient R2 between &, and the sorting characteristic.




                               q          r=5       n.,=1O       =20         n0=25        n.,=50


                           R2 =     .01

                                5         0.056       0.066       0.087       0.099        0.165
                               10         0.060       0.075       0.110       0.130        0.247
                               20         0.065      0.088        0.146       0.179        0.382
                               25         0.067       0.093       0.161       0.202        0.440
                               50         0.075       0.117       0.232       0.302        0.669



                           R2 =     .05

                               5          0.080       0.140       0.288       0.368        0.716
                               10         0.104       0.212       0.477       0.602        0.941
                               20         0.142       0.333       0.728       0.854        0.998
                               25         0.159       0.387       0.808       0.914        1.000
                               50         0.235       0.607       0.971       0.995        1.000


                               = .10

                               5          0.114       0.255       0.568       0.697        0.971
                               10         0.174       0.434       0.847       0.935        1.000
                               20         0.276       0.688       0.985       0.998        1.000
                               25         0.323       0.773       0.996        1.000       1.000
                               50         0.523       0.960       1.000        1.000       1.000


                           R2 =     .20

                                5         0.193       0.514       0.913       0.971        1.000
                               10         0.348       0.816       0.997        1.000       1.000
                               20         0.596       0.980       1.000        1.000       1.000
                               25         0.688       0.994       1.000        1.000       1.000
                               50         0.926       1.000       1.000        1.000       1.000


                           R2 =     .30

                                5         0.285       0.747       0.993       0.999        1.000
                               10         0.547       0.970       1.000        1.000       1.000
                               20         0.848       1.000       1.000        1.000       1.000
                               25         0.918       1.000       1.000        1.000       1.000
                               50         0.997       1.000       1.000        1.000       1.000




7.2.2*                                                                                                                   2.89
                                                           Table 2b

 Critical values Co5 for 5 percent y2-tests of H:  o   = 0 (i = 1      n) using the test statistic •p, where 8,
 and                                  is constructed from portfolio k, with portfolio, formed by sorting on some charactertic
 correlated with e.timat &,. This induced ordering alters the null distribution of i, from          to (1 — R2) . () where the
 non-centrality parameter is a function of the number q of portfolio., the number n of secunties in each portfolio, and
 the squared correlation coefficient R2 between &, and the sorting characteristic. C.06 is defined implicitly by the relation
 Pr($,. > C.o5) = 1 — F,c,i(-,-) = .05. For comparison, we also report the 5 percent critical value of for the central
 distribution in the second column.




                q
                           C.o5—X      C,o5—(A)
                                        (n0 = 5)
                                                       C.o5-(A)
                                                        (no = 10)
                                                                      C.o5)
                                                                      (n0 = 20)
                                                                                      C.O5-X(A)
                                                                                       (no = 25)
                                                                                                      C.os-x(A)
                                                                                                      (n = 50)

                = .01

                 5          11.07         11.36          11.83           12.74           13.19           15.31
                10          18.31         18.89          19.73           21.36          22.16            26.00
                20          31.41         32.52          34.01           36.93          38.36            45.31
                25          37.65        39.01           40.81           44.34          46.08            54.52
                50         67.50          70.05          73.33           79.79          82.98            98.60


                = .05

                5           11.07        12.45           14.53           18.39          20.21           28.68
                10          18.31        21.09           24.88           32.00          35.41           51.54
                20         31.41         36.72           43.62           56.75          63.09           93.59
                25         37.65         44.18           52.56           68.59          76.35          113.82
                50         67.50         79.85           95.41          125.47         140.16          211.67



                     .10

                           11.07         13.65           17.45          24.37           27.63           42.96
                           18.31         23.58           30.62          43.74           50.02           79.98
                           31.41         41.60           54.63          79.32           91.27          148.98
                           37.65         50.21           66.13          96.44          111.15          182.43
                           67.50         91.49          121.42         179.11          207.33          345.24



                     .20

                           11.07         15.7            22.44          34.82           40.71           68.73
                           18.31         27.98           40.86          65.01           76.65          132.76
                           31.41         50.51           74.89         121.32          143.91          253.93
                           37.65         61.32          91.29          148.61          176,58          313.10
                           67.50        113.43          170.67         281.43          335.83          603.10



                    .30

                           11.07         17.38          26.77           44.17           52.52          92.59
                           18.31         31.84          50.11           84.66          101.41         182.73
                           31.41         58.63          93.72          160.99          193.88         354.84
                           37.65        71.55          114.88          198.18         239.01          439.25
                           67.50       134.10          217.65          380.06         460.06          854.55




7.2.2b                                                                                                                  2.89
                                                          Table 3

Empirical sizes of nominal 5 percent X-te.ts of H: a = 0 (i = 1,..., n) using the test statistic 9,, where I,q_1
and       -
correlated with estimstee &,. This induced ordering alters the null distribution ofl from        to (1 — R2)()
                            &li,:?i is constructed from portfolio k, with portfolio. formed by sorting on some characteristic
                                                                                                                   where the
non-centrality parameter is a function of the number q of portfolios, the number n of securities in each portfolio, and the
squared correlation coefficient R2 between & and the sorting characteistic. Each simulation is based on 5,0(X) replications;
asymptotic standard errors for the size estimates may be obtained from the usual binomial approximation, and ii 3.08 x i0—
for the 5 percent test.




                                         n0=5       n,=l0       n0=20        n0=25       n0=50

                                 .01

                                         0.058       0.064       0.093        0.105       0.174
                                         0.059       0.076       0.119        0.130       0.257
                                         0.057       0.083       0.140        0.188       0.385
                                         0.069       0.100       0.170        0.206       0.445
                                         0.083       0.118       0.244        0.300       0.679


                                 .05

                                         0.091       0.149       0.310        0.392       0.723
                                         0.117       0.227       0.493        0.611       0.943
                                         0.156       0.351       0.744        0.854       0.999
                                         0.163       0.401       0.818        0.916       1.000
                                         0.249       0.616       0.971        0.997       1.000


                                 .10

                                         0.141       0.285       0.601        0.721       0.973
                                         0.197       0.473       0.854        0.937       1.000
                                         0.308       0.709       0.985        0.998       1.000
                                         0.338       0.789       0.995        1.000       1.000
                                         0.545       0.961       1.000        1.000       1.000


                                 .20

                                         0.287       0.577       0.922        0.974       1.000
                                         0.405       0.833       0.997        1.000       1.000
                                         0.635       0.982       1.000        1.000       1.000
                                         0.728       0.996       1.000        1.000       1.000
                                         0.933       1.000       1.000        1.000       1.000


                                 .30

                                         0.388       0.790       0.992        1.000       1.000
                                         0.620       0.971       1.000        1.000       1.000
                                         0.868       1.000       1.000        1.000       1.000
                                         0.922       1.000       1.000        1.000       1.000
                                         0.997       1.000       1.000        1.000       1.000




7.2.3                                                                                                                   2.89
                                                              Table 4a

 Empirical sire of Fq,_, tests based on q portfolios sorted by a random characteristic whose squared correlation with &, is
 R3. n is the number of securities in each portfolio and n n0q is the total number of securities. The number of time series
 ob.ervatons T is set to 60. The mean and standard deviation of the test statistic over the 5,000 replication. are reported. The
 population mean and standard deviation of F10,50 are 1.042 and 0.523 respectively; those of the F20,40 are 1.053 and 0.423
 respectively. Asymptotic standard errors for the sire estimate. may be obtained from the usual binomial apprceamation; they
 are 4.24 x io—, 3.08 x iO—, and 1.41 x iO— for the 10, 5, and 1 percent tests respectively.




                      q          n0      n        Mean         Std. Dcv.    Size-10%     Sire-5%      Size-i%


                     = .01

                     10          20     200       1.225          0.619        0.181       0.071        0 026
                     20          10     200       1.148          0.460        0.148       0.079        0.018
                     10         50      500       1.512          0.728        0.318       0.152        0.070
                     20         25      500       1.301          0.514       0.240        0.143        0.036
                     10         100     1000      2.030          0.908       0.576        0.367        0.203
                     20         50      1000      1.554          0.596       0.405        0.268        0.098


                  R2 =    .05

                     10          20     200       1.980          0.883       0.549        0.342        0.189
                     20          10     200       1.505          0.582       0.369        0.241        0.082
                     10          50     500       3.501          1.335       0.945        0.846        0.700
                     20          25     500       2.264         0.801        0.798        0.670        0.382
                     10         100    1000       5.991         1.976        0.999        0.997        0.986
                     20         50     1000       3.587         1.169        0.992        0.972        0.879


                 R2 =     .10

                     10         20      200       2.961         1.196        0.868        0.713        0.538
                     20         10      200       1.977         0.727        0.658        0.510        0.257
                     10         50      500       5.939         1.931        0.999        0.997        0.987
                     20         25      500       3.526         1.128        0.988        0.968        0.868
                     10         100    1000      10.888         3.050        1.000        1.000        1.000
                     20         50     1000       6.123         1.811        1.000        1.000        0.999


                 R2 =     .20

                     10         20      200      4.831          1.657        0.997        0.982       0.937
                     20          10     200      2.895          0.992        0.948        0.882       0.667
                     10         50      500     10.796          3.022        1.000        1.000       1.000
                     20         25      500      6.006    '
                                                                1.758        1.000        1.000       0.998
                     10         100    1000     20.695          5.112        1.000        1.000       1,000
                     20         50     1000     11.194          2.988        1.000        1.000       1.000


                 R2 =     .30

                     10          20     200      6.710          2.119        1.000        0.999       0.997
                    20           10     200      3.841          1.204        0.996        0.987       0.928
                     10          50     500     15.619          3.996        1.000        1.000       1.000
                    20           25     500      8.535          2.368        1.000        1.000       1.000
                     10         100    1000     30.671          7.156        1.000        1.000       1.000
                    20           50    1000     16.183          4.112        1.000        1.000        1.000




7.2.4a                                                                                                                    2.sc
                                                           Table 4b



Empirical size of F,,.r_q tests based on q portfolios sorted by a random characteristic whose squared correlation with â is
apprumately .05. n0 is the number of securities in each portfolio and n n0q is the total number of securities. The &, 'i of the
portfolios are cross-sectionally correlated where the source of correlation is an i.i.d. zero-mean common factor in the returns.
The number of time series observations T is set to 60. The mean and standard deviation of the test statistic over the 5,000
replications are reported. The population mean and standard deviation of Fio,50 are 1.042 and 0.523 respectively; those of
the P30,40 are 1.053 and 0.423 respective1y Asymptotic standard error, for the size estimates may be obtained from the usual
binomial approximation; they are 4.24 x iO—, 3.08 x 10', and 1.41 x i0 for the 10, 5, and 1 percent tests respectively.




                        q          n0     n       Mean      Std. Dcv.      Size-10%     Size-5%      Size-1%



                   R2        .05

                        10         20    200      1.700       0.763         0.422        0.216        0.100
                        20         10    200      1.372       0.528         0.270        0.167        0.047

                        10         50    500      2.520        1.041        0.765        0.565        0.367
                        20         25    500      1.867       0.693         0.593        0.322        0.205

                        10         100   1000     3.624       1.605         0.925        0.820        0.682
                        20          50   1000     2.516       0.966         0.844        0.743        0.501




7.2.4b                                                                                                                      2.89
                                                               Table 5



Comparison of p—value for Lehmann and Modeate (1988) teats of the APT with and without correcting for the effects of induced
ordering. In the absence of data-snooping, the appropriate test statistics and their p—valuee [using the central x2
                                                                                                                      distribution)
are give in Lehmann and Modest (1988, Table 1) and reported below in columns 4 and 5 [we transform their F-statistics into
x3  variates for purposes of comparison). Corresponding p—values that account for induced ordering are calculated in columns
labelled 2(A) p—value' (i = 1,2,3) [using the non-central x2 distribution] where          ), and ), are non-centrality parameters
computed with A2, A2, and kA2 respectively. In all casee, 5 portfolio. are formed from the total number of securities; this
yields 5 degrees of freedom for the x2 statistica in the first four rows and 20 degree, of freedom for the aggregate x2 statistics




          Sample        N        2          j       2 p—value        2(Ai) p—value       y2(A2) p—value       2(A3) p—value


        6301 —6712    1001      0.015     13.70        0.018             0.687                0.315                0131
        6801 — 7212   1359      0.040     15.50        0.008             1.000                0.919                0.520
        7301 — 7712   1346      0.033     10.20        0.070             1.000                0.963                0.720
        7801 — 8212   1281      0.004     12.05        0.034             0.272                0.134                0.078


        Aggregate      —         —        51.45       0.00014            1.000                0.917               0.298




7.2.5                                                                                                                        2.89
