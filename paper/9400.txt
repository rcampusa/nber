                                 NBER WORKING PAPER SERIES




                              THE CONSEQUENCES OF MERIT AID

                                             Susan Dynarski

                                          Working Paper 9400
                                  http://www.nber.org/papers/w9400


                       NATIONAL BUREAU OF ECONOMIC RESEARCH
                                1050 Massachusetts Avenue
                                  Cambridge, MA 02138
                                     December 2002




Andrea Corso, Vanessa Lacoss-Hurd, Maya Smith and, especially, Betsy Kent provided excellent
research assistance. Support from the Kennedy School of Government, the Milton Fund and the NBER
Non-Profit Fellowship is gratefully acknowledged. The views expressed herein are those of the authors
and not necessarily those of the National Bureau of Economic Research.



© 2002 by Susan Dynarski. All rights reserved. Short sections of text not to exceed two paragraphs, may
be quoted without explicit permission provided that full credit including, © notice, is given to the source.
The Consequences of Merit Aid
Susan Dynarski
NBER Working Paper No. 9400
December 2002
JEL No. I22, J24




                                           ABSTRACT

       Since the early Nineties, a dozen states have established broad-based merit aid programs.
The typical program waives tuition and fees at public colleges and universities in one’s home
state. Unlike traditional merit programs, such as the National Merit Scholarship, this aid requires
relatively modest academic performance and provide scholarships to hundreds of thousands of
students. This paper examines how merit aid programs in seven states have affected an array of
schooling decisions, paying particular attention to how the effects have varied by race and
ethnicity. I find that the new programs typically increase the attendance probability of college-
age youth by five to seven percentage points. The merit programs also shift students toward four-
year schools and away from two-year schools. The Georgia HOPE Scholarship, which has been
found to widen racial gaps in college attendance (Dynarski, 2000) is atypical in its distributional
impact, with the other state’s programs tending to have a more positive effect on the college
attendance rate of Blacks and Hispanics. I attribute HOPE’s unique distributional effect to its
relatively stringent academic requirements and a recently-eliminated provision that channeled
the most generous scholarships to higher-income students.

Susan Dynarski
Kennedy School of Government
Harvard University
79 JFK Street
Cambridge, MA 02138
and NBER
susan_dynarski@harvard.edu
          Merit aid, a discount to college costs contingent upon academic performance, is not new.

Colleges and private organizations have long rewarded high-achieving high school students with

scholarships and tuition waivers. The privately-funded National Merit Scholarship program,

established in 1955, awards grants to entering college freshmen according to performance on the

PSAT. Colleges, especially private schools, have long used scholarships to capture students with

strong academic credentials.

          While merit aid has a long history at private colleges and foundations, it has not played a

major role in the public sector. Historically, federal aid for college has been strongly focused on

low-income students. Eligibility for the two largest federal aid programs, the Pell Grant and

Stafford Loan, is determined by a complex formula that defines financial need on the basis of

income, assets and family size. The formula is quite progressive: 90 percent of dependent

students who receive federal grants grew up in families with incomes less than $40,000.1

          Merit aid has played a similarly minor role at the state level. While most states have long

had some form of merit aid program, it is generally offered to only the very highest-performing

students. New York state gives $1,500 to the top scorer on the Regents exam in each of the

state’s high schools, and the University of Massachusetts at Amherst offers valedictorians a free

ride if they perform well on an achievement test. While small merit programs like these abound,

the vast bulk of state spending on higher education is delivered to students in the form of low

tuition at public colleges. These low sticker prices are made possible by the $50 billion in

subsidies that states annually provide their post-secondary institutions. These institutional

subsidies are highest at the flagship universities, which draw the highest-achieving students. In




1
    Calculated from data in National Center for Education Statistics (1998), Table 314.



                                                                                                      2
this sense, these institutional subsidies are, by far, the largest “merit aid” program in the US.

Access to this subsidy has traditionally been controlled by the schools themselves, who

determine which students are sufficiently meritorious to gain access to their school. Once a

student was admitted, each student had equal access to their subsidized education.

        Recently, however, the rules of the game have changed. State legislatures have gotten

into the business of awarding merit to large numbers of students. Since the early Nineties, more

than a dozen states have established broad-based merit aid programs. The typical program

awards tuition and fees to young residents who have maintained a certain grade point average in

high school. Unlike the older merit scholarships, the new programs require relatively modest

academic performance in high school and provide scholarships to hundreds of thousands of

students. Many require a high school grade-point average of 3.0 or above, not a particularly high

threshold: in 1999, 40 percent of high school seniors met this standard.2 Georgia, for example,

gives a free ride at its public colleges and universities to residents who have a GPA of 3.0 in high

school and who maintain that average in college. In Arkansas, the GPA cutoff is 2.5.

        This new breed of merit aid differs from the old style in both its breadth and, plausibly,

its effect on students’ decisions. The old style of merit aid was aimed at top students, whose

decision to attend college is not likely contingent upon the receipt of a scholarship. By design, if

not by intent, this elite form of merit aid goes to students whose operative decision is not whether

to attend college, but which high-quality, four-year college to choose. By contrast, the new,

broad-based merit aid programs are open to students with solid though not necessarily

exemplary academic records. Such students may be uncertain about whether to go to college at



2
  Author’s calculations from the 1997 National Longitudinal Survey of Youth. As I will discuss later in
the paper, this figure varies quite dramatically by race and ethnicity.



                                                                                                          3
all. When offered a well-publicized, generous scholarship – the typical program pays full tuition

and fees at public colleges – some of these students may decide to give college a try. For those

who would have gone to college even without the scholarship, some may choose a four-year

school over a two-year school, or a private school over a public school.

       What are the consequences of this new breed of student aid? A rich array of individual

and institutional decisions could potentially be impacted by the presence of a merit aid program.

On the individual level, consider the many types of high school students, and how each might

respond to the offer of a merit scholarship. One youth may not plan to attend college at all; the

offer of merit aid may convince her to try college. Another may be certain he is going to college,

but the offer of merit aid may lead him to choose a four-year college over a two-year college.3

Another student who is planning to go to college out of state may instead decide to stay closer to

home so that she can take advantage of her state’s merit scholarship.

       This chapter will examine how merit aid affects this array of schooling decisions, using

household survey data to measure the impact of the new state programs. I start with a case study

of the Georgia HOPE Scholarship, the namesake and inspiration of many of the new state

programs. I then extend the analysis to other states that now have broad-based, HOPE-like

programs. In the empirical analysis, I pay particular attention to how the effect of merit aid has

varied by race and ethnicity.

       Merit aid might affect the decisions of not only students, but of institutions. Do colleges

increase their tuition prices, in order to capture some of the subsidy? Do they reduce other forms

of aid? Does the linkage of scholarships to grades lead to grade inflation at high schools and



3
 Two-year colleges are generally cheaper than four-year colleges. Most merit aid programs make them
both free.



                                                                                                      4
colleges? A number of studies have addressed these questions, and I will review the evidence on

these topics. Finally, I will briefly discuss the political economy of merit aid. Why has it arisen

where it has, and when it has? What are the prospects for its continuation and growth, given the

current, poor fiscal prospects of the states?




                                     State Merit Aid: A Primer

        Broad-based state merit aid became common in a very short span of time. In 1993, just

two states, Arkansas and Georgia, had programs in place. By 2002, twelve states had introduced

large merit aid programs. Most of this growth has occurred quite recently, with six programs

starting up since 1999. As is clear from the map in Figure 1, merit aid is heavily concentrated in

the southern region of the United States. Of the twelve states with broad-based merit aid

programs, nine are in the South. Table 1 summarizes the characteristics of the twelve broad-

based merit programs. As was discussed earlier, dozens of states have some form of merit aid in

place. The state programs detailed in Table 1 were chosen because they have particularly lenient

eligibility criteria, with at least thirty percent of high school students having grades and test

scores high enough to qualify.4

        For example, the Arkansas award requires a GPA of 2.5, a standard met by 60 percent of

high school students nationwide. The state also requires a minimum on the ACT of 19, a score



4
  The estimates of number eligible are based on data from the NLSY97. Some of the states listed in Table
1 do not have enough observations in the NLSY97 to allow state-specific estimates of the share of
students whose GPA qualifies them for their state’s merit program. For all states, therefore, I use the
national grade distribution to impute the share in a state that meet the eligibility criteria. When available,
state-level data on the ACT and SAT are used to measure the share of students who meet these criteria.
Note that these estimates are used only to choose the merit programs to be analyzed; they are not used in
the paper’s regression analyses.



                                                                                                             5
exceeded by 60 percent of test-takers nationwide and well below the Arkansas state average of

20.4. Five other states, like Arkansas, condition eligibility on a minimum GPA and test score.

Six states use only GPA to determine eligibility. Of the states that require a minimum GPA, four

require a GPA of 3.0, while two make awards to those with a GPA of 2.5, a standard met by 60

percent of high school seniors nationwide.

          Only one state – Michigan – bases eligibility solely on standardized test performance. For

the class of 2000, 31 percent of Michigan students had scores sufficiently high to merit an award.

However, this overall eligibility rate masks substantial heterogeneity: just 7.9 percent of African

American students met the Michigan requirement. Civil rights groups have protested that this

wide gap in eligibility indicates that Michigan’s achievement test is an inappropriate instrument

with which to determine eligibility for a state-funded scholarship. Similar objections were raised

in Arkansas, which initially based eligibility for its program only on performance on

standardized tests but later broadened the criteria to include academic performance in high

school.

          These controversies point to a shared characteristic of merit programs: their scholarships

flow disproportionately to white and upper-income students. One reason is that Blacks,

Hispanics and low-income youth are relatively unlikely to attend college, so any subsidy to

college students will flow disproportionately to white, upper-income youth. But even among

those non-white, low-income youth who do attend college, academic performance is a barrier to

merit aid eligibility. For merit programs that are based on standardized test performance, it is

unsurprising to see (as in Michigan) a large gap in the eligibility rates of whites and African-

Americans, as the correlation between standardized test performance and race is well-

documented. However, even those programs with only a GPA cutoff will produce large racial




                                                                                                    6
differences in eligibility. Forty percent of high school seniors have a 3.0 GPA or higher while

only 15 percent of African Americans and Hispanics meet this standard. In Georgia, where

renewal of the scholarship is contingent on academic performance in college, Blacks are

substantially less likely than whites to renew, as their college grades are too low.

       For all of these reasons, the merit programs are likely to have a differential impact by

race and ethnicity. Since non-white youth are less likely to qualify, it is plausible that merit aid

programs will have little positive impact upon their college attendance. Further, if the new merit

aid crowds out state spending on need-based aid or leads to higher tuition prices, the programs

may actually decrease low-income, non-white college attendance, since these populations will

face the resulting cost increases but will be disproportionately ineligible for the new merit

scholarships.




                     Case Study: The Georgia Hope Scholarship

       In 1991, Georgia Governor Zell Miller requested that the state’s General Assembly

consider the establishment of a state-run lottery, with the proceeds to be devoted to education.

The Georgia General Assembly passed lottery-enabling legislation during its 1992 session and

forwarded the issue to voters, who approved the required amendment to the state’s constitution

in November of 1992. The first lottery tickets were sold in June of 1993. $2.5 billion in lottery

revenue has flowed into Georgia’s educational institutions since 1993. The legislation and

amendment enabling the lottery specified that the new funds were not to crowd out spending

from traditional sources. While it is not possible to establish conclusively that such crowd-out

has not occurred, spending on education has risen substantially since the lottery was initiated,

both in absolute dollars and as a share of total state spending. Roughly equal shares of lottery


                                                                                                       7
funds have gone to four programs: the HOPE Scholarship, educational technology for primary

and secondary schools, a new pre-kindergarten program, and school construction.

        Residents who have graduated since 1993 from Georgia high schools with at least a 3.0

grade point average are eligible for HOPE.5 The first scholarships were disbursed in the fall of

1993. Participation in HOPE during its first year was limited to those with family incomes below

$66,000; the income cap was raised to $100,000 in 1994 and eliminated in 1995. HOPE pays for

tuition and required fees at Georgia’s public colleges and universities. Those attending private

colleges are eligible for an annual grant, which was $500 in 1993 and had increased to $3,000 by

1996. These amounts are offset by other sources of aid. A student who receives the maximum

Pell Grant gets no HOPE Scholarship but receives a yearly book allowance of $400.6 A $500

education voucher is available to those who complete a General Education Diploma (GED).

Public college students must maintain a GPA of 3.0 to keep the scholarship; a similar

requirement was introduced for private school students in 1996.

        Georgia education officials, concerned that students would forgo applying for federal aid

once the HOPE Scholarship was available, created an application process designed to prevent

this outcome. Those from families with adjusted gross incomes lower than $50,000 must

complete the Free Application for Federal Student Aid (FAFSA) in order to apply for HOPE; the



5
  The high school GPA requirement is waived for those enrolled in certificate programs at technical
institutes. For high school seniors graduating after 2000, only courses in English, math, social studies,
science and foreign languages count toward the GPA requirement.
6
  As a result of this provision and the scaling back of the state’s need-based State Student Incentive
Grants (SSIGs), some low-income students have actually seen their state aid reduced slightly since HOPE
was introduced (Jaffe, 1997). This contemporaneous shift in SSIG spending has the potential to
contaminate the paper’s estimates, especially the specifications in which low-income youth are used as a
control group for upper-income youth. However, SSIG spending was so miniscule – $5.2 million in 1995,
before the program was scaled back – that the impact of its elimination on the estimates is likely
inconsequential.



                                                                                                            8
rationale for the $50,000 income threshold is that few students above that cutoff are eligible for

need-based federal aid.7 The four-page FAFSA requests detailed income, expense, asset and tax

data from the family. Those with family incomes above $50,000 fill out a short, one-page form

that requires no information about finances other than a confirmation that family income is

indeed above the cutoff. As a consequence of these provisions, low-income students face

relatively high transaction costs and relatively low average scholarships.

        In 2000-2001, 75,000 students received $277 million in HOPE Scholarships. Georgia

politicians have deemed HOPE a great success, pointing to the steady rise in the number of

college students receiving HOPE. The key question is whether the program is actually increasing

college attendance or simply subsidizing students who would have attended college even in the

absence of HOPE. In the next section, I discuss the data and empirical strategy I will use to

answer this question.


                                                 Data

        Any empirical analysis of state financial aid policy quickly comes face to face with

frustrating data limitations. The data requirements appear minor, since eligibility for merit aid is

determined by a very short list of characteristics: state of residence at the time of high school

graduation, high school grade point average, standardized test score and, in some states, parental

income. In order to use this information in an evaluation of the effect of merit aid, we would

want these characteristics for repeated cohorts of high school students, both before and after

merit aid is introduced in their state, so that schooling decisions of eligible and ineligible cohorts



7
  In 1995, only 3.7 percent of dependent students from families with incomes over $40,000 received
federal grant aid, while 57 percent of those from families with income under $20,000 did so (National
Center for Education Statistics, 1998a).



                                                                                                        9
can be compared.8 Finally, we need a dataset with state-level samples large enough to allow for

informative analysis.

        No publicly-available dataset meets all of these requirements. Surveys that are limited to

college students do not, by their nature, allow us to examine the college attendance margin. For

example, the National Postsecondary Student Aid Survey (NPSAS) surveys college students

about their aid packages and contains detailed information from students’ aid applications. By

design, this dataset cannot inform us about those students who did not decide to go to college and

the aid packages that they faced. Without making strong assumptions about how those who do

not go to college differ from those who do, we cannot use NPSAS to examine how aid affects the

college attendance margin.

        NPSAS can be used to answer other questions of interest, however. For example, we

might be interested in whether merit aid leads to higher tuition prices, or more or less

government spending on other forms of aid. Or, we might be interested in how the racial

composition of a state’s schools changes, if at all, after the introduction of a merit aid program.

NPSAS, as well as data that institutions gather about their students and report to the government

through the Integrated Postsecondary Data System (IPEDS), can answer questions of this type.9

Later in the paper, I use data from both IPEDS and the University System of Georgia to examine




8
  Alternatively, we could make use of the sharp discontinuities in the eligibility requirements to estimate
the effect of merit aid from a single cohort. Kane (2002) uses this approach in an evaluation of
California’s CalGrant program, comparing the college attendance of those very slightly above and very
slightly below the grade point cutoff. This approach requires very large samples; Kane uses an
administrative dataset that is a near-census of potential college entrants.
9
 Papers that use college-based surveys in this way include Long (2002) and Cornwell, Mustard and
Sridhar (2002), both of which evaluate the Georgia HOPE Scholarship.



                                                                                                          10
how HOPE has affected tuition policy and the student composition of Georgia’s postsecondary

schools.

        The National Longitudinal Surveys of Youth of 1979 and 1997 are particularly rich

sources of data, containing information about academic performance on standardized tests,

grades, parental income, and schooling decisions.10 In a few years, the NLSY97 will be a useful

resource for evaluating the newer merit aid programs, in particular those that have been

introduced since the late Nineties. The only weakness of the NLSY97 is that it is unlikely to

interview enough youth in any one state to allow for detailed examination of a single merit aid

program. Observations from multiple merit states could be pooled, however, as is done in some

analyses in this paper.

        Another potentially fruitful option for research in this area is data from administrative

sources. Kane (2002) and Henry and Rubinstein (2002) take this approach in evaluations of

programs in California and Georgia, respectively.11 Kane matches enrollment data from

California’s public universities and colleges to federal aid applications and high school

transcripts. He then uses regression-discontinuity methodology to estimate the effect of

California’s merit program on schooling decisions. Henry and Rubinstein uses data from the

College Board on high school grades and SAT scores in order to examine whether Georgia

HOPE has led to grade inflation in high schools.




10
  The US Department of Education’s longitudinal surveys of the high school cohorts of 1972, 1982 and
1992 contain similarly rich data. But because each survey contains a single cohort, we cannot use these
data observe the schooling decisions of youth in a given state both before and after merit aid is
introduced.
11
  California’s program is not among the dozen programs evaluated in this chapter, as it is relatively
narrow in its scope due to income provisions that exclude many middle- and upper-income youth.



                                                                                                        11
The Current Population Survey and the Analysis of State Aid Policy

        The bulk of the analysis in this paper is based on a publicly-available survey dataset, the

Current Population Survey (CPS). The CPS is a national household survey that each October

gathers detailed information about schooling enrollment. Data on type of school attended, as well

as basic demographics such as age, race and ethnicity, are included in the CPS. While the CPS is

the world’s premier labor force survey, from the perspective of this chapter it has some key

omissions.

        First, the CPS lacks information about academic performance. We therefore cannot

narrow the analysis to those whose academic performance makes them eligible, and thereby

measure the effect on schooling decisions of offering a scholarship to those who are eligible.

From a policy perspective, the question we can answer is quite relevant: How does the existence

of a merit aid program affect the schooling decisions of a state’s youth? To answer this question,

I will estimate a program effect (denoted β ) that is the product of two interesting parameters: 1)

π , the behavioral response to the offer of aid of youth eligible for the scholarship and 2) δ , the

share of youth eligible for the scholarship:12

                                                        β = πδ

When considering the effect of a financial aid program such as the Pell Grant, we generally are

interested only in π . We assume that the parameters that determine Pell-eligibility, such as

family size and income, cannot easily be manipulated by those eager to obtain the grant. By

contrast, merit aid is a program that intends to induce behavior that will increase the share that is




12
   This formulation ignores heterogeneity in the effect of the offer of aid to those who are eligible ( π ). It
is almost certain that this effect differs for those whose grades place them just on the margin of aid
eligibility and those whose grades are so strong that they are well within this margin.



                                                                                                             12
aid-eligible. Policy-makers consistently cite their desire to give students a financial incentive to

work hard in high school and college as their motivation for establishing merit aid programs.

Estimating π while ignoring δ would therefore miss half the story. Fortunately, data constraints

prevent us from making this mistake!

          A more serious weakness of the CPS is it provides family background data for only a

subset of youth. Parental income, parental education and other measures of socio-economic

status are available only for those youth who live with their families or who are temporarily

away at college.13 The probability that a youth has family background information available is

therefore a function of her propensity to attend college. Under these circumstances, we cannot

limit the analysis to those who have family background data, as this will produce bias in analyses

in which college attendance is an outcome of interest.14 In the analysis, therefore, I will make use

only of background variables that are available for all youth.



Is State of Residence Systematically Mismeasured in the CPS?

          A final weakness of the CPS is that it explicitly identifies neither the state in which a

person attended high school nor the state in which she attends college. In this paper, I proxy for

the state in which a person attended high school with current state of residence. This is a

reasonable proxy, for two reasons. First, in a population this young, migration across state lines

for reasons other than college is minimal. Second, when a youth does go out of state to college,




13
  These youth appear on their parents’ CPS record, and so can be linked to parental data. Other youth will
show up in the CPS as members of their own households.
14
     Cameron and Heckman (1999) discuss this point.



                                                                                                       13
CPS coding standards are that she is recorded as a resident of her state of origin, rather than the

state in which she attends college.

        The key question is whether these standards are followed in practice. We are confident

that this protocol has been followed for those youth (78% of the sample) who appear on their

parents’ record. 15 Whether the CPS correctly captures the state of residence for the other 22% is

an important question, as error in the collection of these data will bias the chapter’s estimates.

        If state of residence is simply a noisy measure of state of origin for these 22% of youth,

then the paper’s estimates will be biased toward zero. But consider the following scenario, in

which we will be biased toward finding a positive effect of merit aid on the probability of college

attendance. Say that HOPE has no effect on the college entry margin, but does affect whether

students go to college in-state. If the CPS incorrectly codes the state of residence as the state in

which one is attending college, then the drop in the out-migration of Georgia college students

will mechanically induce an increase in the observed share of Georgia youth attending college.

        A few simple tabulations can give us a sense of whether this is a problem. If the scenario

laid out in the previous paragraph holds, then we should observe relative growth in the size of the

college-age population in Georgia after HOPE is introduced. To test this hypothesis, I predicted

the size of Georgia’s college-age population by aging forward the high-school-age population.

Specifically, I compared the population of 18-to 19-year-olds in a given state to the population of

16- to 17-year-olds in the same state two years earlier. This is an admittedly crude prediction of

cohort size. It will be wrong for any number of reasons, among them immigration, variation in

the size of cohorts at birth and incarceration (prisons are not in the CPS sampling frame).



15
  We cannot restrict the analytical sample to this subset because, as discussed above, whether a youth is
on her parents’ record is correlated with whether she is in college.



                                                                                                        14
However, the relevant issue is not how error-ridden this prediction is, but whether the sign and

magnitude of its error changes systematically when a merit program is introduced in a state. In

particular, does the population of college-age youth expand unexpectedly when a state introduces

a merit program?

        Figure A plots the difference between the predicted and actual cohort sizes, with the

difference normed by the predicted size. I plot the normed error for Georgia, and the average

normed error for the other states in the Southeast and the US.16 For measurement error to be

inducing positive bias in the paper’s estimates, the errors should grow relatively more negative in

Georgia after HOPE is introduced. There is no such clear trend. The large negative errors in

Georgia in 1993 through 1995 are somewhat disturbing, even though a muted version of this

pattern also appears in the US and Southeastern series. In Figure B, I show the same series for

West Virginia, a southern state that had no merit program during this period. This state’s pattern

is almost identical to that of Georgia, suggesting that Georgia’s shifts in cohort size are not

driven by the availability of merit aid and that the paper’s estimates will not be contaminated by

this source of bias.




16
   That is, I calculate the prediction error for each state-year and divide it by the predicted value for that
state-year. I take the average of these normed, state-year errors separately for the Southeastern US and the
entire US, in both cases excluding Georgia. Each state-year is treated as a single observation; I have not
weighted by population.

The Georgia series is substantially more volatile than those of the Southeast and US; however, any state’s
error will look volatile compared to averages for the region and country. See Figure B for an example of
an equally volatile state.



                                                                                                           15
                                     Georgia HOPE Analysis


I begin by examining how the college attendance rate has changed in Georgia since HOPE was

introduced, compared to how it has evolved in the other Southern states that have not introduced

merit programs. The outcome of interest is whether an 18- to 19-year-old is currently enrolled in

college. I start with a parsimonious specification, in which an indicator variable for being

enrolled in college is regressed against a set of state, year and age effects, along with a variable,
HOPE , that is set to one in survey years 1993 through 2000 for those who are from Georgia. In

this equation, the HOPE variable therefore indicates that a young person of college age resides

in Georgia after HOPE is in operation.

        The estimating equation is as follows:
                           (1)      yiast = β 0 + β1HOPEst + δ s + δ t + δ a + ε iast

where yiast is a indicator of whether person i of age a living in state s in year t is enrolled in

college, δ s , δ t , and δ a denote state, year and age fixed effects, respectively, and ε iast is an

idiosyncratic error term. I use Ordinary Least Squares (OLS) to estimate this equation, correcting

standard errors for heteroskedasticity and correlation of the error terms within state cells.

        Recall that HOPE a) decreases the price of college b) decreases the price of in-state

colleges relative to out-of-state colleges and c) decreases the price of four-year colleges relative

to two-year colleges. The corresponding predicted behaviors for Georgia residents are a)

increased probability of college attendance, b) increased probability of in-state attendance,
relative to out-of-state attendance and c) increased probability of four-year attendance relative to

two-year attendance.

        Column 1 of Table 2 show the college attendance results. The estimate indicates that the

college attendance rate in Georgia rose 8.6 percentage points relative to the other Southern, non-

merit states after HOPE was introduced. The estimate is highly significant, with a standard error

of 0.8 percentage points. This estimate is quite close to the estimate in Dynarski (2000), which




                                                                                                        16
was based on CPS data for 1989 through 1997.17 The result suggests that HOPE did, as
predicted, increase the share of youth attending college.

        I next probe the robustness of this result by adding a set of covariates to this regression.

For reasons discussed earlier, I limit myself to covariates that are available for the entire sample

and exclude any that require that a youth and her parents appear on the same survey record, such

as parental education and income. Control variables indicate whether a youth lives in a

metropolitan area, is African-American, or is Hispanic. These three variables are each interacted

with a full set of year effects, so that the effect of these attributes on schooling decisions is

allowed to vary flexibly over time. I also include the state’s unemployment rate and the median

income of families with children who are near college age. These two variables are intended to

capture any Georgia-specific economic shocks that may have affected college attendance

decisions. Results are in Column (2). The coefficient does not change, though the standard error

increases to 1.3 percentage points..

        I next examine whether the effect of merit aid extends across state borders. Since students

travel across state lines for college, changes in postsecondary education policy in one state will

reverberate in neighboring states. If more Georgians want to go to college, and the supply of

colleges is inelastic, students from Florida, for example, will be pushed out of school when

HOPE is introduced. The estimating equation is as follows:

        (2)      yiast = β 0 + β1HOPEst + β 2border _ meritst + β 4 X st + β 5 X i + δ s + δ t + δ a + ε iast



β 3 captures the effect of having a merit program in a neighboring state. Results are in Column

(3). The results weakly suggest that having a merit program on one’s border has a small, negative

effect on college attendance, indicating the presence of supply constraints. The point estimate is


17
  The standard error is substantially smaller, however. In Dynarski (2000), standard errors were
conservatively corrected for correlation at the state-year level. Bertrand, Duflo, and Mullainathan (2001)
conclude that, in this type of application, the appropriate correction is for correlation at the state level.



                                                                                                                17
fairly imprecise, however: -0.5 percentage points, with a standard error of 1.3 percentage

points.18
          An identifying assumption of the preceding analysis is that Georgia and the control states

were on similar trends in their college attendance rates before HOPE was introduced. If they

were instead on divergent trends the estimates will be biased. In particular, if attendance was

rising in Georgia relative to the other states pre-1993, then we will falsely attribute to HOPE the

continuation of this trend. The inclusion of these pre-existing trends in the equation will

eliminate this source of bias. In Column (4), I add to the regression separate time trends for

Georgia and the rest of non-merit states.19 The point estimate drops moderately, to 6.9

percentage points, indicating that Georgia was trending away from the rest of the South pre-

HOPE. However, there is still a substantial relative increase in attendance in Georgia that cannot

be explained by this trend.


The Effect of HOPE on School Choice

          I next examine whether HOPE has affected decisions other than college entry. In

particular, I examine the type of college that a student chooses to attend. The October CPS

contains information about whether a student attends a public or private college, and whether it is

a two- or four-year institution. I use this information to construct four variables that indicate

whether a person attends a two-year private school, a two-year public school, a four-year private

school, or a four-year public school. I then run a series of four regressions in which these are the

outcomes, including the same covariates as in the richest specification of Table 2. I show results




18
  I have also tested the inclusion of the interaction of having a merit program in one’s own state and in a
neighboring state. The interaction is never large or significant and its inclusion does not affect the paper’s
estimates.
19
     The time trends are estimated using pre-1993 data.



                                                                                                           18
that both do and do not include time trends. The results are shown in Table 3. The attendance

results of previous table are included for ease of comparison with the choice results.

        HOPE appears to increase the probability of attendance at four-year public institutions

substantially, from 4.5 percentage points (no time trends) to 8.4 percentage points (time trends

included). Attendance at four-year private schools also rises, though the estimates are

substantially smaller (2.2 to 2.8 percentage points). There is a somewhat smaller rise in the

probability of attendance at two-year private schools (about 1.5 percentage points) and a drop at

two-year public schools (of 1.7 to 5.5 percentage points). All but two of the estimates are

significant at conventional levels.

        These shifts in schooling decisions are in the expected direction. Any subsidy to college

will both push students into two-year public schools (from not going to college at all) and push

them out (into four-year colleges). HOPE appears to push more students out of two-year, public

institutions than it pushes in, producing a net drop at these schools. Most of these students appear

to shift toward four-year public institutions, though some also shift into the private sector.20



The Effect of HOPE on Migration to College

        We might expect that HOPE would also affect whether students choose to attend college

in their home state. Data from both the data from the University System of Georgia (USG) and

the Department of Education’s Residence and Migration Survey suggest that HOPE has had the

effect of encouraging Georgia residents who would have attended a four-year college out of state

to stay in Georgia instead. Data from the Residence and Migration Survey indicate that in 1992


20
   Note that the coefficients for the four schooling options do not sum to the overall attendance effect.
This is because the type of school is unknown for some student, and they therefore do not appear as
attending any type of school.



                                                                                                            19
about 5,000 Georgians were freshmen at two- and four-year colleges in the states that border

Georgia. This represented an average of 3.4 percent of the border states’ freshmen enrollment.

By 1998, just 4,500 Georgians crossed state lines to enter college in the border states, accounting

for an average of 2.9 percent of freshmen enrollment in those states. This drop in migration was

concentrated in a group of border schools that have traditionally drawn large numbers of

Georgians. At the ten border schools drawing the most Georgia freshmen in 1992, students from

Georgia numbered 1,900 and averaged 17 percent of the freshman class. By 1998, the ten top

destinations enrolled 1,700 Georgians, who represented nine percent of freshman enrollment.

Jacksonville State College in Florida, for example, drew 189 Georgian freshmen in 1992 and

only 89 in 1998; the share of the freshman class from Georgia dropped from 17 to 11 percent.

       Further supporting the conclusion that Georgia’s four-year college students are now more

likely to attend college in state is a shift in the composition of Georgia’s four-year colleges. In

Figure 4 shows data from the USG on the share of freshmen enrollees that are Georgia residents

at Georgia’s two- and four-year public colleges. The data are separately plotted for the two-year,

four-year and the elite four-year colleges in the state. Here we see a definite shift toward Georgia

residents since HOPE was introduced, with the effect most pronounced at four-year colleges

(especially the top schools) and least evident at the two-year schools. This pattern fits with our

understanding that four-year students are most mobile when making college attendance

decisions.


The Differential Impact of HOPE by Race and Ethnicity

The effect of merit programs may vary across racial and ethnic groups for a number of reasons.

First, as was discussed earlier, academic performance in high school is strongly correlated with

race and ethnicity. A far smaller proportion of African Americans than whites will be eligible for



                                                                                                      20
HOPE, for example, since only 15% have a GPA of 3.0 or above. Second, the rules of the

programs are sometimes such that they are likely to have a lesser impact on low-income youth.

Until recently, Georgia did not offer the grant to those youth who had substantial Pell Grants and

low college costs. Mechanically, then, the program would have had a lower impact on African

Americans and Hispanics, who tend to have lower incomes: in Georgia, 94 percent of African-

American and 62 percent of white 16- to 17-year-olds live in families with incomes less than

$50,000.21 The numbers for the rest of the United States are similar.22 Third, states that have
merit programs may shift funds away from need-based aid or appropriations to colleges (which

hold down tuition prices). Both of these effects would tend to make college more expensive,

especially for those who don’t qualify for the merit programs to which the money is being

channeled.

        To explore how the effect of merit aid programs varies by race and ethnicity, I repeat the

analysis of the preceding section, but allow the effect of HOPE to differ across racial and ethnic

groups. I divide the population into two, mutually exclusive categories: 1) white non-Hispanics

and 2) Hispanics of any race plus Blacks.23 I then estimate the effect of merit aid separately for

each group. The estimating equation is:


              yiast = β 0 + β1Meritst + β 2 Meritst × black _ hispi + β 3border _ meritst
        (3)
                   + β 4 X st + β 5 X i + δ s + δ t + δ a + ε iast




21
  Note that this refers to the nominal income distribution. This is appropriate, since the Georgia rules are
written in nominal rather than real terms.
22
  These figures for the share with income below $50,000 may appear high. This is because the unit of
observation is not the family but the child. Since lower-income families have more children, the
distribution of family income within a sample of children has a lower mean than the distribution of family
income within a sample of families.
23
  I would prefer to separately examine effects on Blacks and Hispanics. I have attempted to do so, but the
Hispanic results are too imprecisely estimated to be informative.



                                                                                                          21
        Results for Georgia are in Column (1) of Table 4; I defer the discussion of the
distributional effects of the other programs shown in the other columns to the next section.

Results are shown for specifications that do and do not include pre-existing time trends.24 These

estimates are relatively unstable, changing substantially when time trends are included. The two

sets of estimates both indicate, however, that HOPE had a substantially greater effect on white

attendance than Black and Hispanic attendance. The estimated effect of HOPE on the white

attendance rate is 9.6 to 14.0 percentage points, while that on Blacks and Hispanics is –0.7 to 6.6

percentage points. The results indicate that HOPE has increased racial and ethnic gaps in college

attendance in Georgia.



                   The Effect of Broad-Based Merit Aid in Other States


The Georgia program was one of the first, largest, and most well-publicized merit aid programs.

I now turn to whether the experience in Georgia is distinct from that in other states. I limit the

analysis to the South, where all but three of the programs in Table 1 are located.25 A benefit of

focusing on the Southern merit states is that they have a natural control group: the non-merit

Southern states. The programs of two Southern states (Maryland and West Virginia) are

excluded, as they were introduced after 2000, the last year of the sample. That leaves seven merit

programs, located in Arkansas, Florida, Georgia, Kentucky, Louisiana, Mississippi and South

Carolina.


24
  When time trends are included, they are estimated separately by state and race/ethnicity. Trends are
estimated for four separate groups: 1) non-Hispanic whites in Georgia 2) non-Hispanic whites in the rest
of the Southern non-merit states 3) Blacks and Hispanics in Georgia 4) Blacks and Hispanics in the rest of
the non-merit Southern states.
25
  Binder and Ganderton (2002) have examined the effect of New Mexico’s merit program. They
conclude that New Mexico Success has not affected the college attendance rate but, like HOPE, has
shifted students toward four-year schools.



                                                                                                       22
       I follow the approach used in the analysis of HOPE, creating a variable that indicates a

year and state in which a merit program is in place. In Column (1) of Table 4 are the results of

estimating the following equation:


        (4)     yiast = β 0 + β1meritst + β 2border _ meritst + β 4 X st + β 5 X i + δ s + δ t + δ a + ε iast


The overall effect of the seven merit programs is 4.7 percentage points. The estimate is highly

significant, with a standard error of 1.1 percentage points. In Column (2), I allow this affect to

vary across the seven states, by replacing the single merit dummy with a set of seven dummies,

one for each state’s program. The specification of Column (2) is otherwise identical to that of

Column (1), and so the appropriately-weighted average of the seven coefficients is the 4.7

percentage points of Column (1). Six of the estimates are highly significant. Five are clustered

between 4.9 (Mississippi) and 7.4 (Georgia). Well below Mississippi are Florida and South

Carolina, with estimated effects of 3.0 and 0.2 percentage points, respectively.

       We might suspect that the merit states are somehow different from the non-merit states,

and that the non-merit states therefore form a poor control for these purposes. We can test the

sensitivity of our results to the choice of control group by dropping the non-merit states from the

sample and estimating the effect of merit aid purely from the staggered timing of its rollout

across the states. In this approach, the merit states form their own control group. Figure 5

graphically illustrates the identification strategy. During the first years of the sample (1988-90),

before the first merit program is introduced, all of the states are in the control group. In 1991,

Arkansas moves into the treatment group, followed in 1993 by Georgia. By 2000, all of the states

are in the treatment group. This approach assumes that the states that eventually have a merit

program are on similar trends in the schooling outcomes of young people. The assumption is that




                                                                                                                23
the year in which a state’s merit program begins is quasi-random, uncorrelated with any state-

specific trends in or shocks to schooling decisions.

        Results are in Columns (4) and (5) of Table 4. The estimated overall effect is not

sensitive to the choice of control group, with the estimate rising slightly, from 4.7 percentage

points to 5.2 percentage points. The state-specific coefficients are somewhat more sensitive to

the choice of control group. For five of the states, each approach yields similar results. Two

exceptions are Arkansas and Florida, for whom the estimates vary substantially between Column

(2) and Column (4). Arkansas’ estimate drops from 4.8 to 1.6, while Florida’s rises from 3.0 to

6.3. I will probe the results for these programs further.

        Only South Carolina has a consistently small and insignificant effect, which may be

explained by its requirement that students score at least 24 on the ACT. Nationally, just 30

percent of test-takers scored above South Carolina’s cutoff in 2000, while 88 percent met

Missouri’s requirement and about 60 percent met the requirements of Arkansas (19), Florida (20)

and Louisiana (19.6).26 The South Carolina legislature has come under pressure to loosen the

scholarship requirements and has responded by adding another route to eligibility. As of 2002,

students can qualify for a scholarship by meeting two of three criteria: 24 on the ACT, a GPA of

3.0, and graduating in the top 30 percent of one’s high school class.27 Further, the ACT

requirement has been dropped completely for those attending two-year institutions. It will be of




26
  These figures refer to the national ACT distribution, which has a mean of 21. The Black and Hispanic
distributions have lower means, of 16.9 and 19, respectively. Fewer members of these groups will meet
the state ACT cutoffs.
27
  Personal conversation with Bichevia Green, South Carolina Commission on Higher Education (June
14, 2002).



                                                                                                     24
interest to see if the effect of South Carolina’s program on the college attendance margin rises

with this shift in policy.

           Next, I examine whether the inclusion of pre-existing time trends affects the results. Pre-

existing trends could contaminate the results for both control groups. The merit states may be on

different time trends from the non-merit states, and they may be on different trends from each

other. I estimate a trend for the entire 1988-2000 period for each state. Deviations from these

trends after a state introduces merit aid can then be attributed to the new program.28 Results are

in Columns (3) and (6). As was true in the specification without time trends, the merit-only

control group produces somewhat larger estimates. Both approaches indicate that the effect of

merit aid evolves over time, with the effect rising from 2.4 percentage points in the first year a

program is in effect to 6.0 percentage points in year three and beyond. When the merit states are

used as their own control group, the effect rises from 5.1 percentage points in year one to 9.8

percentage points in the third year).29 The effect of merit aid may rise during the first years of a

program for several reasons. It may take time for information about them to diffuse. It also takes

time for high school students who are inspired to work harder to increase their overall GPAs.

Those who are high school seniors when a program is first introduced can do little to increase

their cumulative GPAs, while those who are freshmen have four years to increase their effort.

The pool of eligible youth may thereby expand over time. The effect could also diminish over

time, if many college students fail to qualify for scholarship renewals and their younger peers are


28
  In this specification, a simple merit dummy will not properly identify the effect of the merit aid
program, as such an approach would inappropriately attribute part of the aid-induced change to the trend.
We can solve this problem by replacing the merit dummy with either a separate time trend or year effects
after merit aid is introduced in a state. Wolfers (2002) uses this approach to estimate the effect of divorce
law reform, which occurred in different states in different years.
29
     Note that these are not cumulative effects, but period-specific program effects.



                                                                                                           25
discouraged from taking up the scholarship. The results in Table 4 indicate that, across the merit

states, the incentive and information effects dominate the discouragement effect.



The Effect of Merit Aid on College Choice

The analysis of the previous section indicates that the state merit aid programs have increased

college attendance. I next examine whether these programs have also affected the choice of

college, as was true in Georgia. I use the analytical framework of the previous section, though I

will only show results that pool the merit states in order to gain precision. All of the Southern

states are included in the sample; results are similar, but less precise, when the sample is limited

to the Southern merit states. I show results that do and do not include time trends.

       Table 5 indicates that, overall, the Southern merit programs have had a strong effect on

the choice of college, with a considerable shift toward four-year public schools of 4.4 percentage

points, which is about the same as the overall attendance effect. There are no effects on other

choices of college. As was discussed earlier, this is likely the results of equally-sized shifts

toward and away from two-year public schools, by students on the margin of college entry and

four-year-college attendance, respectively. The time-trend specification gives similar results,

though here there is more indication of a net drop in the probability of attendance at two-year

public colleges.



Do All Merit Aid Programs Have the Distributional Impact of HOPE?

Many of the merit programs are quite new. Of the seven programs examined in Table 4, three

had been operative for fewer than four years old by 2000. In this section, I examine the four

more mature programs – those of Georgia, Florida, Arkansas and Mississippi – in greater depth.




                                                                                                    26
An advantage of focusing on the older programs is that these states have sufficient post-program

observations to allow for the finer cuts of the data needed to examine heterogeneity in the effect

of aid across demographic groups. Given the strong impact of HOPE on the racial/ethnic gap in

schooling, it is of interest to examine whether the other programs have had a similar impact.

        In Table 6, I examine how the effect of the four programs varies by race and ethnicity.

The control group is the non-merit states. I show the results of specifications that do and do not

include pre-program time trends.30 While the estimates do change when time trends are included,

and some are quite imprecisely estimated, a consistent story emerges from the table. The

estimates concord with Table 4, which showed that each of these four programs had a strong

impact on the college attendance rate. However, Table 6 shows that the relative effects on Blacks

and Hispanics differ substantially across programs. In particular, Georgia is an outlier in its

relatively low effect on Blacks and Hispanics, as compared to its effect on whites.

        Georgia’s HOPE has had the largest impact of all the state programs on the college

attendance of whites, with the estimated effect ranging from 9.6 to 14.0 percentage points

(without and with time trends, respectively). Analogous effects in the other states are

substantially smaller, with no state’s estimates for white, non-Hispanics larger than six

percentage points. Further, the effect of Georgia HOPE on Blacks and Hispanics is 3.0 to 14.7

points lower than the effect on whites. In the other three states, the estimated effect of merit aid

on Blacks and Hispanics is consistently more positive than its effect on white, non-Hispanics.

        This is an important finding, as Georgia is the only program whose distributional effect

has been examined in depth, and the assumption has been that, in other states, merit aid would


30
   In the analysis of each program, four pre-program trends are estimated: two for white, non-Hispanics
(one for the treatment state and one for the control states) and two for Blacks/Hispanics (one for the
treatment state and one for the control states).



                                                                                                          27
similarly widen the racial gap in college attendance.31 The results in Table 6 indicate that the

other mature merit aid programs have not had this effect, with nearly all of the estimates

suggesting that merit aid has actually narrowed the gap.

          Why is Georgia different? HOPE diverges from the other three programs in two key

ways. First, its GPA requirements are unusually stringent. Georgia requires a high school GPA

of 3.0, while Arkansas and Mississippi require a GPA of only 2.5. Florida’s high school GPA

requirement is similar to Georgia’s, but its renewal requirements are less stringent, with a college

GPA of 2.75 allowing a student to keep her scholarship. A college GPA of 2.75 also qualifies a

student for renewal in Arkansas, and only a 2.5 is required in Mississippi.

          Scholarship renewal rates for Blacks are substantially lower than those of whites in

Georgia, indicating that the college GPA requirement hits them particularly hard. Blacks at the

University of Georgia are twice as likely as whites to lose their scholarship after the freshman

year.32 A study at the Georgia Institute of Technology also found that Blacks were substantially

more likely than whites to lose their scholarships, though this differential disappeared after

accounting for differences in ability (as measured by SAT scores).33 More generally, since

Blacks and Hispanics have relatively low high school and college grades, less stringent GPA

requirements will disproportionately benefit this group.

          A second key difference between HOPE and the other state programs is its treatment of

other sources of aid. During the period under analysis, HOPE was reduced dollar-for-dollar by a

student’s other aid. As a result, upper-income youth received substantially larger HOPE


31
     See, for example, Dynarski (2000) and Cornwell et al (2002).
32
     Healy (1997).
33
     Dee and Jackson (1999).



                                                                                                   28
scholarships than their lower-income counterparts. Lower-income youth also faced a far more

difficult application process, since they were required to complete substantial paperwork (the

FAFSA) in order to even be considered for HOPE. The perverse impact of these requirements is

that lower-income students have to work harder to get aid that is less generous than that awarded

their well-off counterparts.34 In stark contrast, Arkansas gives larger awards to low-income

students, by allowing students who receive the Pell to keep their Academic Challenge

Scholarships and by excluding from eligibility students from families with incomes above

$55,000.35




             Other Effects of Merit Aid on Individuals and Institutions


        The analysis in this paper has focused on the effect of merit aid on two critical margins:

the decision to attend college and the type of college chosen. I have touched on another outcome

that is quite important, at least to legislators: the decision to attend college within one’s home

state. I have found that merit aid moderately increases college attendance, and has an effect on

college choice, generally shifting students from two-year schools toward four-year schools. The

data also suggest that Georgia’s merit aid program has increased the probability that a student

will attend college in her home state. It remains to be determined whether merit aid keeps those

students in state after they have completed their education, which is the ultimate goal of many of

those who hope to use merit aid to stanch a perceived “brain drain.” It also remains to be settled


34
  Georgia recently eliminated this aspect of its program. As more data become available, it will be of
interest to examine whether this change has altered the distributional impact of HOPE.
35
  This is the income cutoff for a family of four. Median income for a family of four in Arkansas is
$45,000, so a large share of students fall under these income guidelines.



                                                                                                         29
whether the merit programs have increased completed schooling, as opposed to attempted

schooling.36

        There are many other margins of behavior that merit aid may affect. Thoroughly

addressing all of these potential effects would expand this lengthy chapter into a lengthy book.

Here I will provide a comprehensive, but necessarily shallow, discussion of these issues.



Academic Effort and Grade Inflation

Merit aid may affect academic performance, both in high school and college. Merit aid may

cause students to try harder in high school and college in order to qualify for and maintain their

scholarships. This would be reflected in higher grades and test scores. Observed academic

performance may improve for less positive reasons, however: pressure from students and parents

may lead to grade inflation at both the high school and college level.

        Henry and Rubinstein (2002) show that the average high school GPA of freshmen

entering the Georgia public universities rose from 2.73 in 1992 to 2.98 in 1999. However, so too

did the average SAT score (from 968 to 1010), suggesting that grade inflation does not explain

all of the increase.37 Grades at the college level also appear to be affected by HOPE. Whether

due to increased, effort, or grade inflation, grades at University of Georgia are on the rise, with




36
  Data limitations, rather than conceptual difficulties, hamper the analysis of this particular margin of
behavior. At a minimum, we require data on the completed schooling of adults, along with information
about the state in which they graduated high school. As of 2002, these data are not available in any data
set large enough for informative analysis of the existing merit programs. The 2000 Census micro-data
may prove useful in this context, and I plan to examine this question using these data.
37
  Since this study examines only grades in Georgia, it cannot rule out that secular trends in the
relationship between SAT score and grades are driving the results, rather than HOPE.



                                                                                                        30
the proportion of freshmen grades falling below a B dropping from 40 percent in 1993 to 27

percent in 1996. 38

          Merit aid may also induce students to choose less demanding courseloads in order reach

the required GPA. Binder and Ganderton (2002) conclude that New Mexico’s merit program has

induced students to reduce their credit hours. Students also have the incentive to drop a difficult

class when they fear they may get less than a B. At University of Georgia, the share of students

dropping classes rose from 5.5 percent to 7.3 percent (Healy, 1997).




Characteristics and Behavior of Institutions

Cornwell and Mustard (2002) also provide insight into how a merit aid program affects

institutions of higher education. They examine the enrollment data of Georgia’s two- and four-

year colleges, and find that enrollment as a share of the state’s college-eligible population rose

after the introduction of HOPE, relative to enrollment in comparable states. These results provide

insight into how the impact of HOPE on thousands of individuals’ choice of college aggregate up

into major shifts in the demographic composition of Georgia’s schools. For example, in this

paper we have seen that Georgia HOPE had a small impact on the propensity of black Georgians

to attend college, but a much larger impact on which college they chose to attend, with a marked

shift of these students toward four-year colleges. We have also seen that HOPE appears to have

encouraged Georgians to attend college in Georgia rather than across state lines. In Cornwell




38
     This paragraph draws on Healy (1997).



                                                                                                     31
and Mustard’s institutional analysis, this nets out as a sharp rise in the enrollment of black

students at Georgia’s four-year colleges.39

        Long (2002) has examined the effect of HOPE on tuition prices and other school

financial indicators. Like Dynarski (2000), she finds that the full cost of attendance at public,

four-year schools rose faster in GA than in comparable states after HOPE was introduced. The

increase is fully explained by increases in room and board, which is not covered by HOPE. As

Long points out, schools may have been under pressure from the state not to raise tuition, since

any increases here would have to be met by increased HOPE outlays. Increases in room and

board, however, could slip by with less attention. Private schools face no such incentives to game

the form taken by their price increases, and accordingly their price increases are more evenly

divided between tuition, room and board after HOPE.



Consumption

        Even the largest estimates of the effect of merit aid on schooling decisions suggest that

the great majority of aid goes to infra-marginal families – that is, to families whose schooling

decisions are unaffected by their receipt of aid.40 Of interest is what actually happens to this

money. Do students use it to reduce the number of hours they work while in school? Do they

increase their spending in leisure activities? Do families save the money, for retirement or later




39
  This result has frequently been misinterpreted as suggesting a very large impact of HOPE on the
propensity of black Georgians to go to any college.
40
   It is important to note that merit aid is not unique in this way. Estimates of the effects of other forms of
student aid also indicate that aid largely goes to those whose observable schooling decisions are
unaffected by the receipt of aid. Targeting of subsidies is a classic topic of public economics; there is no
transfer program that is 100% effective in limiting its subsidy to those whose decisions are contingent on
the receipt of the subsidy.



                                                                                                             32
bequests to their children? One study suggests that at least part of the money is used for

increased current consumption. Cornwell and Mustard (2002) examine new car registrations in

Georgia and comparison states and find that car purchases rose faster in Georgia after the

introduction of HOPE than before. They reach similar conclusions by examining the correlation

between car registrations and the number of HOPE recipients at the county level within Georgia,

finding an elasticity of new car registrations with respect to HOPE recipients of about two

percent.


                                     The Future of Merit Aid

How will the effect of merit aid evolve over time?
       The Georgia HOPE results give us the effect of merit aid program for a "first mover."

What is the effect when a new merit program is introduced in a region which already has many

such programs? In the presence of supply constraints, the effect of latecomer programs would be

smaller than that of earlier programs, as attendance grows and the supply grows tighter. There is

no evidence of such a trend in the present analysis; Arkansas’ program is the oldest and has not

had an unusually large effect, while Kentucky’s is the youngest and has not had an unusually

small effect (see Table 4). Of course, the various state programs differ in aspects other than their

age, so the unconditional correlation between program age and program effect does not
constitute conclusive evidence.

       What would the world look like if every state introduced such a program? Would the

states be right back where they started, with students distributed across schools and states as they

were before this burst of spending? Probably not. Consider the college attendance margin. We

have seen that the existing merit programs have increased college attendance rates. The only

scenario in which the new programs would not have the same effect is one in which supply of

seats at schools is inelastic. If the total supply is indeed inelastic, then the current programs can

have increased attendance only by reducing attendance in other states. In the empirical analysis, I



                                                                                                    33
find no evidence that the introduction of a merit program reduces attendance in adjoining states,

which suggests that, at least at the present, supply constraints are not binding.

          What about college choice? While we might think that supply is elastic among the non-

selective schools, this is certainly not the case for the elite institutions. Competition for positions

at elite, in-state institutions will intensify when merit aid is introduced. This has been the case in

University of Georgia, where SAT scores of entering freshmen have risen considerably and UG

alumni complain bitterly that their children have been frozen out of their alma mater by the

intense competition for admission induced by HOPE.

          An clear effect of the spread of merit aid will be reduced migration across state lines for

college. Merit aid both pulls students toward their own states’ schools and pushes them out of

other states’ schools. Like low tuition for state residents, merit aid pulls students toward home.

Increased competition for seats in merit states will push them home.



Lotteries as a Source of Funding

          Education is the most common use of lottery funds; 16 of the 38 states with lotteries

devote all or some of the revenue to education.41 In Georgia, for example, all of the funds are

devoted to education. At inception, roughly equal amounts were devoted to the HOPE

scholarship, universal pre-kindergarten for four year-olds and education infrastructure. HOPE

has gradually eaten up a larger and larger portion of the lottery revenue, by 1999 74% of Georgia

lottery revenues were spent on HOPE and pre-kindergarten.42

          Lottery funds spent on elementary and secondary education are, by their nature, more

evenly spread across the population than are funds devoted to postsecondary education. The


41
     Clotfelter and Cook (1999).
42
     Rubinstein and Scafidi (2002).



                                                                                                     34
high-achieving college students who receive merit funds are particularly likely to be white and

from upper-income families. Further, lottery spenders tend to be disproportionately concentrated

in the bottom of the income distribution. Through both the revenue and spending channels, then,

lottery-funded merit programs are regressive in their impact.



The Politics of Merit Aid

Why have merit aid programs spread so rapidly and maintained such strong political support?

One possibility is that merit aid is a politically astute way to build support for spending on

postsecondary education. Consider two alternatives for subsidizing college: low public tuition

prices and need-based aid. Merit aid has a political advantage over low tuition in that it has a

high profile. Parents (voters) generally do not understand that the public university tuition they

pay is kept artificially low by state appropriations to the schools. As a result, they may be

unsympathetic to legislative efforts to increase funding through this route. If, instead, their child

receives a “scholarship” that pays for tuition, the perceived benefit is personal and immediate,

inducing political support for the spending. That students “earn” merit aid may also place it at a

political advantage over other funding mechanisms. A merit program is akin to the Social

Security program: in both cases, voters are fiercely supportive of transfers that they perceive as

earned rewards rather than unconditional entitlements.

       Merit aid is analogous to Social Security in a second way. William Julius Wilson (1987)

and Theda Skocpol (1991) have argued that robust welfare states are characterized by benefits

that are widely available, and therefore, widely supported. They argue that means-tested anti-

poverty programs are politically weak because their scope is narrow. A similar dynamic could

explain weak funding growth for need-based aid programs. Ninety percent of Pell Grants flow to




                                                                                                   35
those with family incomes below $40,000. The price of this highly progressive spending is that

many voters do not perceive themselves as its potential beneficiaries.

        Is a progressive aid system therefore politically unviable? Not necessarily. Politically

popular “universal” programs can potentially provide political cover for redistributive transfers.

As Social Security shows, a universal program can be layered with transfers that channel extra

dollars toward those with greater need. In the case of merit aid, the universal benefit of waived

tuition and fees could be combined with a living allowance for lower-income youth, thereby

piggybacking need-based aid onto a politically-popular program. This does not necessarily

require new spending, as existing need-based programs could simply be relabeled in a way that

enhances their political popularity.




How will the recession affect merit aid?
        State merit aid programs have grow rapidly over the past decade, a period characterized

by strong economic growth and overflowing state coffers. Recently, merit programs have begun

to feel the pinch of the economic downturn. As state legislators struggle to balance their budgets,

merit aid programs dependent upon legislative appropriations (Arkansas, California, Louisiana,
Maryland and Mississippi) find themselves in direct competition with other state priorities such

as elementary and secondary education and health care. Arkansas, the first state to introduce a

broad-based merit aid program, has temporarily closed the program to new enrollees. While

current scholarship recipients can renew their awards, no new students are being admitted to the

program. Funding for Louisiana’s program barely avoided the chopping block during the state’s

last legislative session.

        Those merit programs with committed revenue streams have been relatively buffered

from the economic and political effects of the recession. Six states (Florida, Georgia, New

Mexico, West Virginia, South Carolina and Kentucky) fund their programs with revenues from a


                                                                                                   36
state lottery, while two (Nevada and Michigan) use funds from the tobacco litigation settlement.

With their dedicated funding sources, merit aid in these states is not vulnerable to legislators

seeking to cut spending in the face of sinking tax revenues. This puts merit aid in a unique

position, since other sources of funding for higher education at the state level are not protected in

the same way. Public universities are experiencing leaner times this fiscal year as their state

appropriations are reduced. Aid for low-income students is also vulnerable. West Virginia’s

need-based aid program could not deliver scholarships to all those low-income students who

were eligible during the 2002-2003 academic year. The same year, the state’s new merit

program, which has no income cap, was launched with full funding.



Conclusion
       A similar dynamic has emerged at the federal level. The fastest-growing subsidies for

college students – tax credits, savings tax incentives, and loans –are programs whose funding is

not contingent upon legislative appropriation. By contrast, spending on the Pell Grant program,

which funds the most needy students, is determined by annual legislative appropriation. At both

the state and federal level there has emerged a set of policies that put subsidies for the well-off

on a firmer financial footing than aid for those with low incomes.

       Policy advocates concerned by the stubbornly low rate of college attendance and
completion among low-income youth have fought hard against the spread of merit aid, as well as

against the federal and state tax incentives for education that blossomed rapidly in recent years.

They argue that this spending channels funds toward middle- and high-income families, and

advocate for enhanced spending on need-based programs such as the Pell Grant.

       From a political and revenue standpoint, however, the middle-class programs are on firm

footing. There is a near-zero probability that they will be scrapped and their funding shifted to

need-based grants. Rather than fighting a losing battle, it may be time to think of aid for low-

income students in terms of Skocpol’s and Wilson’s “targeted universalism,” harnessing need-

based subsidies to the politically-popular middle-class programs. For example, grants could be


                                                                                                      37
delivered to needy students through the tax system by making the Hope and Lifetime Learning

tax credits refundable.43 This would eliminate one layer of paperwork (the FAFSA) yet allow aid
eligibility to still be determined with the detailed financial information that is provided in tax

filings. More importantly, funding for low-income students would be shifted into a program with

broad-based political appeal and a guaranteed funding stream. At the state level, merit programs

could be similarly tweaked to provide greater funding for low-income students within the context

of programs that have widespread support.




43
  Those who assail the need-based aid system for its complex application process will likely be horrified
by this suggestion, as the federal tax system is also notoriously complex. But the Earned Income Tax
Credit has proved to be an effective mechanism for transferring money to low-income families, and a
refundable education tax credit has the potential to do the same for low-income students.



                                                                                                       38
Figure 1: States with Broad-Based Merit Aid Programs


                       1993




                       2002




                                                       39
                            Figure 2a: Does Measurement Error in State of Residence Bias

0.3



0.2



0.1



  0
       1988   1989   1990       1991    1992    1993    1994    1995    1996    1997   1998   1999   2000

-0.1



-0.2



-0.3


                                                                                                            GA
-0.4                                                                                                        Rest of US
                                                                                                            Rest of Southeast

-0.5



-0.6
             Figure 2b: Does Measurement Error in State of Residence Bias the Estimates?


0.3


0.2


0.1


  0
       198     198   199    199   199   199    199   199    199   199   199    199   200

-0.1
                                                                                           GA
                                                                                           WV
-0.2


-0.3


-0.4


-0.5


-0.6




                                                                                                41
                                                            Figure 3:
                                              University System of Georgia Students
                                    Share of Georgia Residents Enrolled in Four-Year Colleges

80.0%




77.5%




75.0%




72.5%




70.0%
            1989-90



                       1990-91



                                   1991-92



                                              1992-93



                                                         1993-94



                                                                    1994-95



                                                                               1995-96



                                                                                          1996-97



                                                                                                      1997-98



                                                                                                                 1998-99



                                                                                                                            1999-00
Graphed is the share of USG students from Georgia who are enrolled in four-year colleges. Source: University System of Georgia
Ten-Year Enrollment Report, various years.




                                                                                                                                      42
                                                                   Figure 4:
                                                     University System of Georgia Students
                                                 Georgia Residents as Share of Total Enrollment




100.0%

98.0%

96.0%

94.0%

92.0%

                                                                                                                        Two-Year Colleges
90.0%
                                                                                                                        Four-Year Colleges
                                                                                                                        Total
88.0%                                                                                                                   Top Four-Year Colleges

86.0%

84.0%

82.0%

80.0%
         1989-90



                   1990-91



                             1991-92



                                       1992-93



                                                  1993-94



                                                            1994-95



                                                                      1995-96



                                                                                1996-97



                                                                                          1997-98



                                                                                                    1998-99



                                                                                                              1999-00
                                                                                                                                   43
                                    Figure 5:
                  Timing of Introduction of State Merit Programs




                 Treatment                                         Control

                 1988
                 1989
                 1990
                 1991
                 1992
                 1993
                 1994
                 1995
                 1996
                 1997
                 1998
                 1999
                 2000
                 1988
                 1989
                 1990
                 1991
                 1992
                 1993
                 1994
                 1995
                 1996
                 1997
                 1998
                 1999
                 2000
Arkansas
Georgia
Mississippi
Florida
Louisiana
South Carolina
Kentucky
                              Table 1: Merit Aid Program Characteristics, 2002

                                                                                               Award
   State       Start                          Eligibility
                                                                               in-state attendance only, exceptions noted


Arkansas       1991     initial: 2.5 GPA in HS core & 19 ACT                 public: $2,500
                        renew: 2.75 college GPA                              private: same


Florida         1997    initial: 3.0-3.5 HS GPA & 970-1270 SAT/20-28 ACT public: 75-100% tuition/fees*
                        renew: 2.75-3.0 college GPA                      private: 75-100% avg public tuition/fees*


Georgia        1993     initial: 3.0 HS GPA                                  public: tuition/fees
                        renew: 3.0 college GPA                               private: $3,000


Kentucky       1999     initial: 2.5 HS GPA                                  public: $500-3,000*
                        renew: 2.5-3.0 college GPA                           private: same


Louisiana      1998     initial: 2.5-3.5 HS GPA & ACT > state mean           public: tuition/fees + $400-800*
                        renew: 2.3 college GPA                               private: avg public tuition/fees*


Maryland        2002    initial: 3.0 HS GPA in core                          2-yr school - $1,000
                        renew: 3.0 college GPA                               4-yr school - $3,000


Michigan        2000    initial: level 2 of MEAP or 75th pctile of SAT/ACT   in-state: $2,500 once
                        renew: NA                                            out-of-state: $1,000 once


Mississippi     1996    initial: 2.5 GPA & 15 ACT                            public fresh/soph: $500
                        renew: 2.5 college GPA                               public jr/sr: $1,000
                                                                             private: same

Nevada         2000     initial: 3.0 GPA & pass Nevada HS exam               public 4 yr: tuition/fees (max $2,500)
                        renew: 2.0 college GPA                               public 2-yr: tuition/fees (max $1,900)
                                                                             private: none

New Mexico     1997     initial: 2.5 GPA 1st semester of college             public: tuition/fees
                        renew: 2.5 college GPA                               private: none


S. Carolina     1998    initial: 3.0 GPA & 1100 SAT/24 ACT                   2-yr school - $1,000
                        renew: 3.0 college GPA                               4-yr school - $2,000


W. Virginia    2002     initial: 3.0 HS GPA in core & 1000 SAT/21 ACT        public: tuition/fees
                        renew: 2.75-3.0 college GPA                          private: avg public tuition/fees



*Amount of award rises with GPA and/or test score.
                                                                       Table 2:
                                                    Estimated Effect of Georgia Hope Scholarship
                                                     on College Attendance of 18-19-Year-Olds
                                                               Southern Census Region


                                                                           (1)              (2)            (3)              (4)
                                                                           .086             .085           .085             .069
          HOPE Scholarship                                                (.008)           (.013)         (.013)           (.019)
                                                                                                           -.005            -.006
          Merit Program in Border State                                                                   (.013)           (.013)

          State and Year Effects                                            Y                Y              Y                Y

          Median Family Income                                                               Y              Y                Y

          Unemployment Rate                                                                  Y              Y                Y

          Interactions of Year Effects w/: Black, Metro, Hispanic                            Y              Y                Y

          Time Trends                                                                                                        Y

          R2                                                               .020            .059            .059             .056

          N                                                               8,999            8,999          8,999            8,999


Note: Regressions are weighted by CPS sample weights. Standard errors are adjusted for heteroskedasticity and correlation within state cells.
Sample consists of 18- to 19-year-olds in Southern Census region, excluding states (other than Georgia) that introduce merit programs by 2000.
See Table 1 for a list of these states.
                                            Table 3:
                    Effect of Georgia Hope Scholarship on Schooling Decisions
                                    October CPS, 1988-2000
                                     Southern Census Region
                                            N=8,999



                                    (1)              (2)        (3)           (4)          (5)
                                 College            2-year    2-year        4-year        4-year
                                Attendance          Public    Private       Public        Private



                                             No Time Trends

                                   .085             -.017       .015         .045          .022
Hope Scholarship                  (.013)            (.010)     (.003)       (.015)        (.007)

R2                                 .059             .026       .012          .030          .026


                                           Add Time Trends

                                   .069             -.055       .014         .084          .028
Hope Scholarship                  (.019)            (.013)     (.004)       (.023)        (.016)

R2                                 .056             .026       .010          .030          .026




Specification in top panel is that of Column (3) in Table 2. Specification in bottom panel adds trends
estimated on pre-treatment data. In each column, two separate trends are included, one for Georgia
and one for the rest of the states. Sample consists of 18- to 19-year-olds in Southern Census region,
excluding states (other than Georgia) that introduce a merit program by 2000.
                                                   Table 4:
                                   Effect of All Southern Merit Programs
                                  on College Attendance of 18-19-Year-Olds

                                               All Southern States              Southern Merit States Only
                                                    N=13,965                            N=5,640
                                        (1)            (2)            (3)      (4)         (5)          (6)
                                       .047                                    .052
Merit Program                         (.011)                                  (.018)
                                                      .048                                 .016
Merit Program, Arkansas                              (.015)                               (.014)
                                                      .030                                 .063
Merit Program, Florida                               (.014)                               (.031)
                                                      .074                                 .068
Merit Program, Georgia                               (.010)                               (.014)
                                                      .073                                 .063
Merit Program, Kentucky                              (.025)                               (.047)
                                                      .060                                 .058
Merit Program, Louisiana                             (.012)                               (.022)
                                                      .049                                 .022
Merit Program, Mississippi                           (.014)                               (.018)
                                                      .004                                 .014
Merit Program, South Carolina                        (.013)                               (.013)
                                                                      .024                             .051
Merit Program, Year 1                                                (.019)                           (.027)
                                                                      .010                             .043
Merit Program, Year 2                                                (.032)                           (.024)
                                                                      .060                             .098
Merit Program, Year 3 and after                                      (.030)                           (.039)

State Time Trends                                                      Y                                Y

R2                                     .046           .046           .047     .035        .036         .036




     Note: Specification is that of Column (3) in Table 2, with the addition of state time trends where
     noted. Sample consists of 18- to 19-year-olds in Southern Census region, with the last three columns
     excluding states that have not introduced a merit program by 2000.
                                               Table 5:
                               Effect of All Southern Merit Programs
                             on Schooling Decisions of 18-19-Year-Olds
                                          All Southern States
                                            N=13,965

                                         (1)         (2)            (3)         (4)      (5)
                                      College      2-Year         2-Year      4-Year   4-Year
                                     Attendance    Public         Private     Public   Private
                                                             No Time Trends

                                         .047       -.010          .004        .044     .005
  Merit Program                         (.011)      (.008)        (.004)      (.014)   (.009)

  R2                                    .046        .030           .007        .030     .020

                                                              Time Trends
                                         .024       -.025          .009        .034     .010
  Merit Program, Year 1                 (.019)      (.012)        (.005)      (.012)   (.007)
                                         .010       -.015          .002        .028     -.001
  Merit Program, Year 2                 (.032)      (.018)        (.003)      (.035)   (.011)
                                         .060       -.037          .005        .065     .022
  Merit Program, Year 3 and after       (.030)      (.013)        (.003)      (.024)   (.010)

  R2                                    .047        .031           .009        .032     .022




Note: Specification is that of Column (3) in Table 2, with the addition of state time trends where
noted. Sample consists of 18- to 19-year-olds in Southern Census region. Estimates are similar but
less precise when sample is limited to Southern merit states.
                      Table 6: Effect of Merit Aid on College Attendance
                                Analysis by Race and Ethnicity
                                    October CPS, 1988-2000
                                     Southern Census Region



                                        (1)             (2)       (3)          (4)
                                     Georgia          Florida   Arkansas   Mississippi
                                     N=8,999         N=10,213   N=8,949     N=8,969

                                         No Time Trends
                                       .096            .001       .054        .002
            Merit Program             (.014)          (.022)     (.023)      (.011)
                                      -.030            .077       .045        .120
            Merit*Black/ Hispanic     (.020)          (.021)     (.026)      (.032)

            R2                         .059            .055       .061        .058

                                              Time Trends
                                       .140            .030       .060        .016
            Merit Program             (.013)          (.021)     (.024)      (.015)
                                      .-147            .000       .043        .083
            Merit*Black/ Hispanic     (.039)          (.030)     (.043)      (.033)

            R2                         .056            .052       .059        .055



Note: Specification in top panel is that of Column (3) in Table 2. Specification in bottom panel adds
trends estimated on pre-treatment data. In each column, separate trends are included for four groups:
white-control, white-treat, nonwhite-control and nonwhite-treat. In each column, sample consists of
18- to 19-year-olds in Southern Census region, excluding states (other than the treatment state) that
introduce a merit program by 2000.
                                                 References


Bell, Julie Davis and DeMaree Michelau (2001). “Making College Affordable” Legislatures Magazine,
        November. National Conference of State Legislatures.

Berker, Ali Murat (2001). “The Impact of Merit-Based Aid on College Enrollment: Evidence from
       “HOPE-Like Scholarship Programs.” Unpublished working paper, Michigan State University.

Bugler, Daniel and Gary Henry (1997). “Evaluating the Georgia HOPE Scholarship Program: Impact on
       Students Attending Public Colleges and Universities.” Unpublished manuscript, Council for
       School Performance, Georgia State University.

Bugler, Daniel and Gary Henry (1998). “An Evaluation of Georgia’s HOPE Scholarship Program:
       Impact on College Attendance and Performance.” Unpublished manuscript, Council for School
       Performance, Georgia State University.

Byron, Kris and Gary Henry (1996). “Report on the Expenditure of Lottery Funds Fiscal Year 1996.”
       Unpublished manuscript, Council for School Performance, Georgia State University.

Byron, Kris and Gary Henry (1997). “Report on the Expenditure of Lottery Funds Fiscal Year 1997.”
       Unpublished manuscript, Council for School Performance, Georgia State University.

Byron, Kris and Gary Henry (1998). “Report on the Expenditure of Lottery Funds Fiscal Year 1998.”
       Unpublished manuscript, Council for School Performance, Georgia State University.

Cameron, Stephen and James Heckman (1999). “Can Tuition Policy Combat Rising Wage Inequality?”
      In Marvin Kosters, ed., Financing College Tuition: Government Politics and Educational
      Priorities. Washington, D.C.: American Enterprise Institute.

Clotfelter, Charles T., Philip J. Cook, et. al. (1999). “State Lotteries at the Turn of the Century:
        Report to the National Gambling Impact Study Commission.”

College Board (1998). Trends in Student Aid. New York: College Board Publications.

Dee, Thomas and Linda Jackson (1999). “Who Loses Hope? Attrition from Georgia’s College
       Scholarship Program.” Southern Economic Journal 66:2, pp. 379-90.

Dynarski, Susan (forthcoming). “Does Aid Matter? Measuring the Effect of Student Aid on College
      Attendance and Completion.” American Economic Review.

Ellwood, David and Thomas Kane (1999). “Who Is Getting a College Education? Family Background
      and the Growing Gap in Enrollment.” Unpublished manuscript, Harvard University.


                                                                                                       52
Healy, Patrick (1997). “HOPE Scholarships Transform the University of Georgia.” The Chronicle of
       Higher Education, November 7, p. A32.

Henry, Gary and others (undated). “Hope Longitudinal Study, First-Year Results.” Unpublished
       manuscript, Council for School Performance, Georgia State University.

Henry, Gary T. and Ross Rubenstein (2002). “Paying for Grades: Impact of Merit-Based Financial Aid
       on Educational Quality.” Journal of Policy Analysis and Management 21:1, pp. 93-109.

Jaffe, Greg (1997). “Free for All: Georgia’s Scholarships Are Open to Everyone, and That’s a Problem.”
        The Wall Street Journal, June 2, p. 1.

Kane, Thomas (1994). “College Entry by Blacks since 1970: The Role of College Costs, Family
       Background, and the Returns to Education.” Journal of Political Economy 102:5, 878-911.

__________ (2002). “A Quasi-Experimental Estimate of the Impact of Financial Aid on College-
      Going.” Unpublished Manuscript, University of California Los Angeles.


Leslie, Larry and Paul Brinkman (1988). The Economic Value of Higher Education. New York:
        Macmillan.

Long, Bridget Terry (2002). “Merit-Based Financial Aid and College Tuition: The Case of Georgia’s
       HOPE Scholarship.” Unpublished Manuscript, Harvard University and National Bureau of
       Economic Research.

National Center for Education Statistics, US Department of Education (1995). Making the Cut: Who
       Meets Highly Selective College Entrance Criteria? Washington, D.C.: Government Printing
       Office.

_________(1997). Digest of Education Statistics. Washington, D.C.: Government Printing Office.

_________(1998a). Digest of Education Statistics. Washington, D.C.: Government Printing Office.

_________(1998b). State Comparisons of Education Statistics: 1969-70 to 1996-97. Washington, D.C.:
      Government Printing Office.

Rubenstein, Ross and Benjamin Scafidi (2002). “Who Pays and Who Benefits? Examining the
      Distributional Consequences of the Georgia Lottery for Education.” National Tax Journal 55:2,
      pp.223-238.

Selingo, Jeff (2001). “Questioning the Merit of Merit Scholarships.” Chronicle of Higher Education,
       January 19, p.A20.

Skocpol, Theda (1991). “Targeting within Universalism: Politically Viable Policies to Combat Poverty
      in the United States,” in Christopher Jencks and Paul Peterson, eds., The Urban Underclass.
      New Washington, D.C.: Brookings Institution.

Wilson, William Julius (198t). The Truly Disadvantaged. Chicago: University of Chicago.

                                                                                                      53
54
