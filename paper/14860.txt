                                  NBER WORKING PAPER SERIES




COMPLEMENTARITY AND AGGREGATE IMPLICATIONS OF ASSORTATIVE MATCHING:
                    A NONPARAMETRIC ANALYSIS

                                            Bryan S. Graham
                                            Guido W. Imbens
                                              Geert Ridder

                                          Working Paper 14860
                                  http://www.nber.org/papers/w14860


                        NATIONAL BUREAU OF ECONOMIC RESEARCH
                                 1050 Massachusetts Avenue
                                   Cambridge, MA 02138
                                        April 2009




 Financial support for this research was generously provided through NSF grant SES 0136789, SES
 0452590, and SES 0820361. We thank participants in seminars at Harvard-MIT, Princeton, UC Berkeley,
 NBER Labor Studies, Cemmap, and Brown University for comments. We thank Cristine Pinto for
 excellent research assistance. The views expressed herein are those of the author(s) and do not necessarily
 reflect the views of the National Bureau of Economic Research.

 NBER working papers are circulated for discussion and comment purposes. They have not been peer-
 reviewed or been subject to the review by the NBER Board of Directors that accompanies official
 NBER publications.

 © 2009 by Bryan S. Graham, Guido W. Imbens, and Geert Ridder. All rights reserved. Short sections
 of text, not to exceed two paragraphs, may be quoted without explicit permission provided that full
 credit, including © notice, is given to the source.
Complementarity and Aggregate Implications of Assortative Matching: A Nonparametric
Analysis
Bryan S. Graham, Guido W. Imbens, and Geert Ridder
NBER Working Paper No. 14860
April 2009
JEL No. C14,C21,C52

                                              ABSTRACT

This paper presents methods for evaluating the effects of reallocating an indivisible input across production
units, taking into account resource constraints by keeping the marginal distribution of the input fixed.
When the production technology is nonseparable, such reallocations, although leaving the marginal
distribution of the reallocated input unchanged by construction, may nonetheless alter average output.
Examples include reallocations of teachers across classrooms composed of students of varying mean
ability. We focus on the effects of reallocating one input, while holding the assignment of another,
potentially complementary, input fixed. We introduce a class of such reallocations -- correlated matching
rules -- that includes the status quo allocation, a random allocation, and both the perfect positive and
negative assortative matching allocations as special cases. We also characterize the effects of local
(relative to the status quo) reallocations. For estimation we use a two-step approach. In the first step
we nonparametrically estimate the production function. In the second step we average the estimated
production function over the distribution of inputs induced by the new assignment rule. These methods
build upon the partial mean literature, but require extensions involving boundary issues. We derive
the large sample properties of our proposed estimators and assess their small sample properties via
a limited set of Monte Carlo experiments.


Bryan S. Graham                                       Geert Ridder
Department of Economics                               Department of Economics
University of California, Berkeley                    University of Southern California
508-1 Evans Hall #3880                                Kaprielian Hall
Berkeley, CA 94720-3880                               Los Angeles, CA 90089
and NBER                                              ridder@usc.edu
bgraham@econ.berkeley.edu

Guido W. Imbens
Department of Economics
Littauer Center
Harvard University
1805 Cambridge Street
Cambridge, MA 02138
and NBER
imbens@fas.harvard.edu
1    Introduction
Consider a production function depending on a number of inputs. We are interested in the
effect of a particular input on output, and specifically in the average effects of policies that
change the allocation of this input across production units. For each production unit output
may be monotone in this input, but at different rates. If the input is indivisible, and its
aggregate stock fixed, it is impossible to simultaneously raise the input level for all production
units. In such cases it may be of interest to consider the output effects of reallocations of
the input across production units. Here we investigate econometric methods for assessing
the effect of such reallocations on average output. We will call the average causal effects of
such policies Aggregate Redistributional Effects (AREs). A key feature of the reallocations
we consider is that, although they potentially alter input levels for each firm, they keep the
marginal distribution of the input across the population of firms fixed.
    The first contribution of our paper is to introduce a framework for considering such re-
allocations, and to define novel estimands that capture their key features. These estimands
include the effects of focal reallocations, and a semiparametric class of reallocations, as well as
the effect of a local reallocation. One focal reallocation redistributes the input across produc-
tion units such that it has perfect rank correlation with a second input. We refer to this as
the positive assortative matching allocation. We also consider a negative assortative matching
allocation where the primary input is redistributed to have perfect negative rank correlation
with the second input. A third allocation involves randomly assigning the input across firms.
This allocation, by construction, ensures independence of the two inputs. A fourth allocation
simply maintains the status quo assignment of the input. More generally, we consider a two
parameter family of feasible reallocations that include these four focal allocations as special
cases. Reallocations in this family may depend on the distribution of a second input or firm
characteristic. This characteristic may be correlated with the firm-specific return to the input
to be reallocated. Our family of reallocations, called correlated matching rules, includes each
of the four focal allocations as special cases. In particular the family traces a path from the
positive to negative assortative matching allocations. Each reallocation along this path keeps
the marginal distribution of the two inputs fixed, but it induces a different level of correlation
between the two inputs. Each of the reallocations we consider are members of a general class of
reallocation rules that keep the marginal distributions of both inputs fixed. We also provide a
local measure of complementarity that requires much weaker conditions on the support of the
input distribution. This estimand measures whether a small step away from the status quo,
towards perfect assortative matching allocation raises average output.
    The second contribution of our paper is to derive statistical methods for estimation and
inference for the proposed estimands. We derive an estimator for average output under all
correlated matching allocations, and for the local complementarity measure. Our estimator
requires that the first input is exogenous conditional on the second input and additional firm
characteristics. Except for the case of perfect negative and positive rank correlation the esti-
mator has the usual parametric convergence rate. For the two extremes the rate of convergence
is slower, comparable to that of estimating a regression function with a scalar covariate at a
point. In all cases we drive the asymptotic distribution of the estimator. In the first step of
the estimation procedure we use a nonparametric estimator for the production function. We
modify existing kernel estimators to deal with boundary issues that arise in our setting.
    Our focus on reallocation rules that keep the marginal distribution of the inputs fixed is


                                                [1]
appropriate in applications where the input is indivisible, such as in the allocation of teachers
to classes, or managers to production units. In other settings it may be more appropriate to
consider allocation rules that leave the total amount of the input constant by fixing its average
level. Such rules would require some modification of the methods considered in this paper.
    Our methods may be useful in a variety of settings. One class of examples concerns com-
plementarity of inputs in production functions (e.g. Athey and Stern, 1998). If the first and
second inputs are everywhere complements, then the difference in average output between the
positive and negative assortative matching allocations provides a nonparametric measure of
the degree of complementarity. This measure is invariant to monotone transformations of the
inputs. If the production function is not supermodular, the interpretation of this difference is
not straightforward, although it still might be viewed as some sort of ‘global’ measure of input
complementarity.
    A second example concerns educational production functions. Card and Krueger (1992)
study the relation between adult wages and teacher quality. Teacher quality may improve
outcomes for all students, but average outcomes may be higher or lower depending on whether,
given a fixed supply of teachers, the best teachers are assigned to the least prepared students
or vice versa. Parents concerned solely with outcomes for their own children may be most
interested in the effect of raising teacher quality on expected outcomes. A school board, however,
may be more interested in maximizing expected outcomes given a fixed set of classes and and
a fixed set of teachers, by optimally matching teachers to classes.
    A third class of examples arises in settings with social interaction (c.f., Manski 1993; Brock
and Durlauf 2001). Sacerdote (2001) studies peer effects in college by looking at the rela-
tion between individual outcomes and roommate characteristics. From the perspective of the
individual student it may again be of interest whether having a roommate with different char-
acteristics would, in expectation, lead to a different outcome. This is what Manski (1993) calls
an exogenous or contextual effect. The college, however, may be interested in a different effect,
namely the effect on average outcomes of changing the procedures for assigning roommates.
While it may be very difficult for a college to quickly change the distribution of characteristics
in incoming classes, it may be under its control to change the way roommates are assigned.
In Graham, Imbens and Ridder (2006b) we study the peer effect setting further, developing
methods appropriate for social groups of arbitrary size when agents are binary-typed. Our
focus in that work is on the outcome and inequality effects of segregation.
    If production functions are additive in inputs, the questions posed above have trivial an-
swers: average outcomes are invariant to input reallocations. Although reallocations may raise
outcomes for some units in that case, they will necessarily lower them by an offsetting amount
for others. Reallocations are zero-sum games in this additive setting. With additive and linear
functions, even more general assignment rules that allow the marginal input distribution to
change, while keeping its average level fixed, do not affect average outcomes. In order for these
questions to have non-trivial answers, one therefore needs to explicitly recognize, and allow
for, non-additivity and non-linearity of a production function in its inputs. For this reason our
approach is fully nonparametric.
    The current paper builds on the larger treatment effect and program evaluation literature.1
More directly, it is complementary to the small literature on the effect of treatment assignment
rules (Manski, 2004; Dehejia, 2004; Hirano and Porter, 2005). Our focus is different from
  1
    For recent surveys see Angrist and Krueger (2001), Heckman, Lalonde and Smith (2000), and Imbens and
Wooldridge (2009).


                                                  [2]
that in the Manski, Dehejia, and Hirano-Porter studies. First, we allow for continuous rather
than discrete or binary treatments. Second, our assignment policies take into account resource
constraints (by leaving unchanged he marginal distribution of the treatment), whereas in the
previous papers treatment assignment for one unit is not restricted by the assignments for other
units. Our policies are redistributions. In the current paper we focus on estimation and inference
for specific assignment rules. It is also interesting to consider optimal rules as in the Manski,
Dehejia and Hirano-Porter studies. The class of feasible reallocations/redistributions includes
all joint distributions of the two inputs with fixed marginal distributions. When the inputs are
continuously-valued, as we assume in the current paper, this class of potential rules is very large.
Characterizing the optimal allocation within this class is therefore a non-trivial problem. When
both inputs are discretely-valued the problem with finding the optimal allocation is tractable
as the joint distribution of the inputs is characterized by a finite number of parameters. In
Graham, Imbens and Ridder (2006a) we consider optimal allocation rules when both inputs are
discrete, allowing for general complementarity or substitutability of the inputs.
     Our paper is also related to recent work on identification and estimation of models of
social interactions (e.g., Manski, 1993; Brock and Durlauf, 2001; Graham, 2008; Moffitt, 2001).
We do not focus on directly characterizing the within-group structure of social interactions, an
important theme of this literature. Rather our goal is simply to estimate the average relationship
between group composition and outcomes. The average we estimate may reflect endogenous
behavioral responses by agents to changes in group composition, or even equal an average over
multiple equilibria. Viewed in this light our approach is reduced form in nature. However it is
sufficient for, say, an university administrator to characterize the outcome effects of alternative
roommate assignment procedures, as long as the average response to group composition remains
unchanged across such procedures.
     The econometric approach taken here builds on the partial mean literature (e.g., Newey,
1994; Linton and Nielsen, 1995). In this literature one first estimates a regression function
nonparametrically. In the second stage the regression function is averaged, possibly after some
weighting with a known or estimable weight function, over some of the regressors. Similarly
here we first estimate a the production function nonparametrically as the conditional mean
of the outcome given the observed inputs. In the second stage the averaging is over the dis-
tribution of the regressors induced by the new assignment rule. This typically involves the
original marginal distribution fo some of the regressors, but a different conditional distribution
for others. Complications arise because this conditional covariate distribution may be degen-
erate, which will affect the rate of convergence for the estimator. In addition the conditional
covariate distribution itself may require nonparametric estimation through its dependence on
the assignment rule. For the policies we consider the assignment rule will involve distribution
functions and their inverses similar to the way these enter in the changes-in-changes model of
Athey and Imbens (2006).
     The next section lays out our basic model and approach to identification. Section 3 then
defines and motivates the estimands we seek to estimate. Section 4 presents of our estimators,
and derives their large-sample properties, for the case where inputs are continuously-valued.
Section 5 presents the results from a small Monte Carlo exercise.




                                                [3]
2     Model
In this section we present the basic set up and identifying assumptions. For clarity of exposition
we use the production function terminology; although our methods are appropriate for a wide
range of applications, as emphasized in the introduction. For production unit or firm i, for
i = 1, . . ., N , the production function relates a triple of observed inputs, (Wi , Xi, Vi), and an
unobserved input εi , to an output Yi :

      Yi = k(Wi , Xi, Vi, εi).                                                                (2.1)

The inputs Wi and Xi, and the output Yi are scalars. The third observed input Vi and the
unobserved input εi can both be vectors. We are interested in reallocating the input W across
production units. We focus upon reallocations which hold the marginal distribution of W fixed.
As such they are appropriate for settings where W is a plausibly indivisible input, such as a
manager or teacher, with a certain level of experience and expertise. The presumption is also
that the aggregate stock of W is difficult to augment. In addition to W there are two other
(observed) firm characteristics that may affect output: X and V , where X is a scalar and V
is a vector of dimension LV . The first characteristic X could be a measure of, say, the quality
of the long-run capital stock, with V being other characteristics of the firm such as location
and age. These characteristics may themselves be inputs that can be varied, but this is not
necessary for the arguments that follow. In particular the exogeneity assumption that we make
for the first input need not hold for these characteristics.
    We observe for each production unit, indexed by i = 1, . . ., N , the level of the input, Wi ,
the characteristics Xi and Vi , and the realized output level, Yi . In the educational example the
unit of observation would be a classroom. The variable input W would be teacher quality, and
X would be a measure of quality of the class, e.g., average test scores in prior years. The second
characteristic V could include other measures of the class, e.g., its age or gender composition,
as elements. In the roommate example the unit would be the individual, with W the quality
of the roommate (measured by, for example, a high school test score), and the characteristic
X would be own quality. The second set of characteristics V could be other characteristics of
the dorm or of either of the two roommates such as smoking habits (which may be used by
university administrators in the assignment of roommates).
    Our key identifying assumption is that conditional on firm characteristics (X, V ) the as-
signment of W , the level of the input to be reallocated, is exogenous:
Assumption 2.1 (Exogeneity)

      ε ⊥ W       X, V.

Let

      g(w, x, v) = E[Y |W = w, X = x, V = v],                                                 (2.2)

and

      σ 2 (w, x, v) = V[Y |W = w, X = x, V = v],                                              (2.3)

denote the expectation and the variance of the output conditional on input level w and char-
acteristics x and v. We often refer to the derivative of g(w, x, v) with respect to w, which will

                                                [4]
be denoted by
                        ∂
      gW (w, x, v) =      g(w, x, v),                                                        (2.4)
                       ∂w
Under exogeneity we have – among firms with identical values of X and V – an equality between
the counterfactual average output that we would observe if all firms in this subpopulation
were assigned W = w, and the average output we observe for the subset of firms within this
subpopulation that are in fact assigned W = w. Alternatively, the exogeneity assumption
implies that the difference in g(w, x, v) evaluated at two values of w, w0 and w1 , has a causal
interpretation as the average effect of assigning W = w1 rather than W = w0 :

      g(w1, x, v) − g(w0, x, v) = E [ k(w1 , X, V, ε) − k(w0 , X, V, ε)|X = x, V = v] .

    Assumption 2.1 is often controversial. It holds under conditional random assignment of W to
units; as would occur in a randomized experiment. However randomized allocation mechanisms
are also used by administrators in some institutional settings. For example some universities
match freshman roommates randomly conditional on responses to housing questionnaires (e.g.,
Sacerdote 2001). This assignment mechanism is consistent with Assumption 2.1. In other
settings, particularly where assignment is bureaucratic, as may be true in some educational
settings, a plausible set of conditioning variables may be available. In this paper we focus
upon identification and estimation under Assumption 2.1. In principle, however, the methods
could be extended to accommodate other approaches to identification based upon, for example,
nonparametric instrumental variables methods (e.g., Matzkin, 2008, Imbens and Newey, 2009).
    Much of the treatment effect literature (e.g., Angrist and Krueger, 2000; Heckman, Lalonde
and Smith, 2000; Manski, 1990; Imbens and Wooldridge, 2009) has focused on the average
effect of an increase in the value of the treatment. In particular, in the binary treatment case
(w ∈ {0, 1}) interest has centered on the average treatment effect

      E[g(1, X, V ) − g(0, X, V )].

With continuous inputs one may be interested in the full average output function g(w, x, v)
(Imbens, 2000; Flores, 2005) or in its derivative with respect to the input,

      gW (w, x, v),

at a point, or a weighted average,

      E [ω(W, X, V ) · gW (W, X, V )] ,

See Powell, Stock and Stoker (1989) or Hardle and Stoker, (1989) for estimands of this type.
     Here we are interested in a fundamentally different class of estimands, one which has received
little attention in the econometrics literature. We focus on policies that redistribute the input
W , according to a rule based on the X characteristic of the unit. For example upon assignment
mechanisms that match teachers of varying experience to classes of students based on average
ability in the classes. One might assign those teachers with the most experience (highest
values of W ) to those classrooms with the highest ability students (highest values of X) and
so on. In that case average outcomes would reflect perfect rank correlation between W and
X. Alternatively, we could be interested in the average outcome if we were to assign W to

                                                 [5]
be negatively perfectly rank correlated with X. A third possibility is to assign W so that it
is independent of X. We are interested in the effect of such policies on the average value of
the output. We refer to such effects in general as Aggregate Redistributional Effects (AREs).
The three reallocations mentioned are a special case of a general set of reallocation rules that
fix the marginal distributions of W and X, but allow for correlation in their joint distribution.
For perfect assortative matching the correlation is 1, for negative perfect assortative matching
-1, and for random allocation 0. By using a bivariate normal cupola we can trace out the path
between these extremes.
    We wish to emphasize that there are at least two limitations to our approach. First, we focus
on comparing specific assignment rules, rather than searching for the optimal assignment rule.
The latter problem is a particularly demanding problem in the current setting with continuously-
valued inputs as the optimal assignment for each unit depends both on the characteristics of
that unit as well as on the marginal distribution of characteristics in the population. When
the inputs are discretely-valued both the problems of inference for a specific rule as well as
the problem of finding the optimal rule become considerably more tractable. In that case any
rule, corresponding to a joint distribution of the inputs, is characterized by a finite number of
parameters. Maximizing estimated average output over all rules evaluated will then generally
lead to the optimal rule. Graham, Imbens and Ridder (2006a) and, motivated by an early
version of the current paper, Bhattacharya (2008), provide a discussion for the case with discrete
covariates.
    A second limitation is that the class of assignment rules we consider leaves all aspects of the
marginal distribution of the inputs unchanged. This latter restriction is perfectly appropriate in
cases where the inputs are indivisible, as, for example, in the social interactions and educational
examples. In other cases one need not be restricted to such assignment rules. A richer class
of estimands would allow for assignment rules that maintain some aspects of the marginal
distribution of inputs but not others. An interesting class consists of assignment rules that
maintain the average (and thus total) level of the input, but allow for its arbitrary distribution
across units. This can be interpreted as assignment rules that “balance the budget”. In such
cases one might assign the maximum level of the input to some subpopulation and the minimum
level of the input to the remainder of the population. Finally, one may wish to consider arbitrary
decision rules where each unit can be assigned any level of the input within a set. In that
case interesting questions include both the optimal assignment rule as a function of unit-level
characteristics as well as average outcomes of specific assignment rules. In the binary treatment
case such problems have been studied by Dehejia (2005), Manski (2004), and Hirano and Porter
(2005).


3    Aggregate Redistributional Effects
Let fW |X,V (w|x, v) denote the conditional distribution of W given (X, V ) in the data, and let
f˜W |X,V (w|x, v) denote a potentially different conditional distribution. We will allow f˜W |X,V (w|x, v)
to correspond to any distribution such that the implied marginal distribution for Wi remains
unchanged, or
       Z                                         Z
           ˜
          fW |X,V (w|x, v)fX,V (x, v)dwdxdv = fW |X,V (w|x, v)fX,V (x, v)dwdxdv.




                                                  [6]
This includes degenerate conditional distributions. In general we are interested in the average
outcome that would result from the current distribution of (X, V, ε), if the distribution of W
given (X, V ) were changed from its current distribution, fW |X,V (w|x, v) to f˜W |X,V (w|x, v). We
denote the expected output given such a reallocation by
             Z
       are
      βf˜ = g(w, x, v)f̃W |X,V (w|x, v)fX,V (x, v)dwdxdv.                                      (3.5)

In the next two sections we discuss some specific choices for f˜(·).

3.1   Positive and Negative Assortive Matching Allocations
The first estimand we consider is expected average outcome given perfect assortative matching
of W on X conditional on V :
                h                               i
      β pam = E g FW −1
                       |V
                          (FX|V (X|V )|V ), X, V    ,                                    (3.6)

                                                                  −1
where FX|V (X|V ) denotes the conditional CDF of X given V , and FW |V (q|V ) is the q-th quan-
                                                                                        −1
tile (for q ∈ [0, 1]) associated with the conditional distribution of W given V (i.e., FW |V
                                                                                             (q|V ) is
                                                 −1
a conditional quantile function). Therefore FW    |V (FX|V (X|V )|V ) computes a unit’s location on
the conditional CDF of X given V and reassigns it the corresponding quantile of the conditional
distribution of W given V . Thus, among units with the same realization of V , those with the
highest value of X are reassigned the highest value of W , and so on.
    In order for β pam to be well defined, we need some conditions on the joint distribution of
(Y, W, X, V ). We do not state these conditions here explicitly. When we discuss estimation,
in Section 4, we provide conditions for consistent estimation., including compact support and
smooth distributions for (W, X), and moment conditions for the conditional distribution of Y
given (W, X). These conditions imply that β pam is well defined.
    The focus on reallocations within subpopulations defined by V , as opposed to population-
wide reallocations, is motivated by the fact that the average outcome effects of such reallocations
solely reflect complementarity or substitutability between W and X. To see why this is the
case consider the alternative estimand
                                             
      β pam−pop = E g FW  −1
                             (FX (X)) , X, V .                                                 (3.7)

This gives average output associated with population-wide perfect assortative matching of W
on X. If, for example, X and V are correlated, then this reallocation, in addition to altering
the joint distribution of W and X, will alter the joint distribution of W and V . Say V is also a
scalar and is positively correlated with X. Population-wide positive assortative matching will
induce perfect rank correlated between W and X, but it will also affect the degree of correlation
between W and V . This complicates the interpretation of the estimand when g (w, x, v) is non-
separable in w and v, as well as in w and x.
    An example helps to clarify the issues involved. Let W denote an observable measure of
teacher quality, X mean (beginning-of-year) achievement in a classroom, and V the fraction
of the classroom that is female. If begining-of-year achievement varies with gender, (say, with
classes with a higher fraction of girls having higher average achievement) then X and V will be
correlated. A reallocation that assigns high quality teachers to high achievement classrooms,
will also tend to assign such teachers to classrooms will an above average fraction of females.

                                                 [7]
Average achievement increases observed after implementing such a reallocation may reflect
complementarity between teacher quality and begining-of-year student achievement or it may
be that the effects of changes in teacher quality vary with gender and that, conditional on
gender, their is no complementarity between teacher quality and achievement. By focusing
on reallocations of teachers across classrooms with similar gender mixes, but varying baseline
achievement, (3.6) provides a more direct avenue to learning about complementarity between
W and X.2
    Both (3.6) and (3.7) may be policy relevant, depending on the circumstances, and both
are identified under Assumption 2.1 and additional support conditions (which we make explicit
below). Under the additional assumption that

        g(w, x, v) = g1 (w, x) + g2 (v),

the estimands, although associated with different reallocations, also have the same basic inter-
pretation. In the current paper we focus upon (3.6), although it is conceptually straightforward
to extend our results to (3.7).
    Our second estimand is the expected average outcome given negative assortative matching:
                h                                    i
                      −1
      β nam = E g FW   |V
                           1 −  FX|V (X|V )|V   , X, V    .                                 (3.8)

If, within subpopulations homogenous in V , the two inputs W and X are everywhere comple-
ments, then the difference β pam − β nam provides a measure of the strength of input complemen-
tarity. When g (·) is not supermodular, the interpretation of this difference is not straightfor-
ward. In Section 3.1 below we present a measure of ‘local’ (relative to the status quo allocation)
complementarity between X and W .

3.2      Correlated Matching Allocations
The perfect positive and negative assortative allocations are focal allocations, being emphasized
in the economic theory literature (e.g., Becker and Murphy, 2000; Legros and Newman, 2004).
There are many more possible allocations. Two others that are of particular importance are the
status quo allocation, and the random matching allocation. Average output under the status
quo allocation is given by

        β sq = E[Y ] = E[g(W, X, V )].

Average output under the random matching allocation is given by
            Z Z Z                                 
     β rm =         g(w, x, v)fW |V (w|v)fX|V (x|v) fV (v)dwdxdv.
                 v    x   w

This last estimand gives average output when W and X are independently assigned within
subpopulations indexed by V .
    These allocations are just four among the class of feasible allocations. This class is com-
prised of all joint distributions of inputs consistent with fixed marginal distributions (within
subpopulations homogenous in V ). As noted in the introduction, if the inputs are continuously
distributed this class of joint distributions is very large. For this reason we only consider a
  2
      We make the connection to complementarity more explicit in Section 3.3.


                                                      [8]
subset of these joint distributions. To be specific, we concentrate on a family of the feasible
allocations, indexed by two parameters, τ and ρ, that includes as special cases the negative and
positive assortative matching allocations, the independent allocation, and the status quo alloca-
tion. Let β cm (τ, ρ) denote average output under the allocation indexed by τ and ρ. By changing
the two parameters we trace out a “path” in two directions: further from or closer to the status
quo allocation, and further from, or closer to, the perfect sorting allocations. Borrowing a
term from the literature on cupolas, we call this class of feasible allocations “comprehensive,”
because it contains all four focal allocations as a special case. For ease of exposition we focus
in the remainder of the paper on the case with no covariates beyond W and X, and so drop
the argument V in the production function.
    For the purposes of estimation, the correlated matching allocations are redefined using a
truncated bivariate normal cupola. The truncation ensures that the denominator in the weights
of the correlated matching ARE are bounded from 0, so that we do not require trimming. The
bivariate standard normal probability density function (pdf) is
                              1      −   1
                                              (x2 −2ρx1 x2 +x22 )
     φ(x1 , x2; ρ) =        p       e 2(1−ρ2 ) 1                  ,       −∞ < x1 , x2 < ∞
                          2π 1 − ρ2

with a corresponding joint cumulative distribution function (cdf) denoted by Φ(x1 , x2 ; ρ). Ob-
serve that

     Pr(−c < x1 ≤ c, −c < x2 ≤ c) = Φ(c, c; ρ) − Φ(c, −c; ρ) − [Φ(−c, c; ρ) − Φ(−c, −c; ρ)],

so that the truncated standard bivariate normal pdf is given by
                                                φ(x1 , x2 ; ρ)
    φc (x1 , x2 ; ρ) =                                                            ,         −c < x1 , x2 ≤ c.
                          Φ(c, c; ρ) − Φ(c, −c; ρ) − [Φ(−c, c; ρ) − Φ(−c, −c; ρ)]
Denote the truncated bivariate cdf by Φc .
    The truncated normal bivariate CDF gives a comprehensive cupola, because the correspond-
ing joint cdf
                                                    
      HW,X (w, x) = Φc Φ−1             −1
                         c (FW (w)), Φc (FX (x)); ρ

has marginal cdf’s equal to HW,X|V (w, ∞|v) = FW (w) and HW,X (∞, x) = FX (x), it reaches
the upper and lower Fréchet bounds on the joint cdf for ρ = 1 and ρ = −1, respectively, and it
has independent W, X as a special case for ρ = 0.
    To define β cm (ρ, τ ), we note that joint pdf associated with HW,X (w, x) equals
                                                                            fW (w)fX (x)
     hW,X (w, x) = φc Φ−1           −1
                       c (FW (w)), Φc (FX (x)); ρ                                                  .
                                                                    φc Φc (FW (w)) φc Φ−1
                                                                        −1
                                                                                         c (FX (x))

Then we define β cm (ρ, 0) in terms of the truncated normal, as
                      Z                                            
         cm                         φc Φ−1           −1
                                        c (FW (w)), Φc (FX (x)); ρ
     β        (ρ, 0) =     g(w, x)                                 fW (w)fX (x)dwdx.                   (3.9)
                       w,x         φc Φ−1               −1
                                       c (FW (w)) φc Φc (FX (x))

Average output under the correlated matching allocation is given by

     β cm (ρ, τ ) = τ · E[Y ] + (1 − τ ) · β cm (ρ, 0)                                                (3.10)

                                                         [9]
             = τ · E[Yi ] + (1 − τ )
                     Z                                               
                                      φc Φ−1           −1
                                          c (FW (w)), Φc (FX (x)); ρ
                   ×       g(w, x)                                   fW (w)fX (x)dwdx,
                       x,w           φc Φ−1               −1
                                         c (FW (w)) φc Φc (FX (x))

for τ ∈ [0, 1] and ρ ∈ (−1, 1).
    The case with τ = 1 corresponds to the status quo:

      β sq = β cm (ρ, 1).

The case with τ = ρ = 0 corresponds to random matching allocation of inputs:
                       Z Z
      rm     cm
     β = β (0, 0) =          g(w, x)dFW (w)dFX (x).
                            x    w

The cases with (τ = 0, ρ → 1) and (τ = 0, ρ → −1) correspond respectively to the perfect
positive and negative assortative matching allocations:

      β pam = lim β cm (ρ, 0),       and β nam = lim β cm (ρ, 0).
               ρ→1                                ρ→−1

More generally, with τ = 0 we allocate the inputs using a normal copula in a way that allows for
arbitrary correlation between W and X indexed by the parameter ρ. It would be conceptually
straightforward to use other copulas.

3.3   Local Measures of Complementarity
A potential disadvantage of the correlated matching reallocation family of estimands β cm (ρ, τ ),
including the focal allocations β pam and β nam is that the support requirements that allow for
precise estimation may be difficult to satisfy in practice. This is particularly relevant for allo-
cations ‘distant’ from the status quo. For example, if the status quo is characterized by a high
degree of correlation between the inputs, evaluating the effect of allocations with a small, or
even negative, correlation between inputs, such as random matching, or negative assortative
matching, can be difficult because such allocations rely on knowledge of the production funhc-
tion at pairs of input values (W, X) that are infrequently seen in the data. For this reason a
measure of local (close to the status quo) complementarity between W and X would be valu-
able. To this end we next characterize the expected effect on output associated with a ‘small’
increase toward either positive or negative assortative matching. Such estimands may also be
informative regarding the effects of “modest” policies that stay close to the status quo. The
resulting estimand forms the basis of a simple test for local efficiency of the status quo allo-
cation. We derive this local measure by considering matching on a family of transformations
of Xi and Wi , indexed by a scalar parameter λ, where for some values of λ the matching is
on Wi (corresponding to the status quo), and for other values of λ the matching is on Xi or
−Xi , corresponding to positive and negative assortative matching respectively. We then focus
on the derivative of the expected outcomes from matching on this family of transformations,
evaluated at the value of λ that corresponds to the status quo.
    For technical reasons, and to be consistent with the subsequent formal statistical analysis
in Section 4 of the previously discussed estimands β pam and β nam , we assume that the support
of Xi is the interval [xl , xu ], with midpoint xm = (xu + xl )/2, and similarly that the support of
Wi is the interval [wl , wu], with midpoint wm = (wu + wl )/2. Without loss of generality we will

                                                [10]
assume that xl = 0, xm = 1/2, xu = 1, wl = 0, wm = 1/2, and wu = 1. To focus on the key
conceptual issues we continue to ignore the presence of additional covariates Vi. First define a
smooth function d(w) that goes to zero at the boundary of the support of Wi :

      d(w) = 1w>wm · (wu − w) + 1w≤wm · (w − wl ).

We implement our local reallocation as follows: for λ ∈ [−1, 1], define the random variable Uλ
as a transformation of (X, W ):
                                 p
      Uλ = λ · X · d(W )1−|λ| + ( 1 − λ2 ) · W.

This gives us a parametric transformation of (W, X) that moves smoothly between W = U0
and X = U1 . Now we consider reallocations based on positive assortative matching on Uλ , for
a range of values of λ, as a smooth way of moving from the status quo (matching on W ) to
positive assortative matching (matching on X). For general λ the average output associated
with positive assortative matching on Uλ is given by the local reallocation

      β lr (λ) = E[g(FW
                      −1
                         (FUλ (Uλ )), X)].                                                         (3.11)

For λ = 0 and λ = 1 we have Uλ = W and Uλ = X respectively, and hence β lr(0) = β sq and
β lr (1) = β pam . Perfect negative assortative matching is also nested in this framework since

      Pr (−X ≤ −x) = Pr (X ≥ x) = 1 − FX (x) ,

and hence for λ = −1 we have β lr(−1) = β nam . Values of λ close to zero induce reallocations
of W that are ‘local’ to the status quo, with λ > 0 and λ < 0 generating shifts toward positive
and negative assortative matching respectively.
   We focus on the effect of a small reallocation as our local measure of complementarity:

               ∂β lr
      β lc =         (0).                                                                          (3.12)
                ∂λ
This local complementarity measure has two interesting alternative representations which are
given in the following theorem. Before stating this result we introduce one assumption. This
assumption is stronger than needed for this theorem, but its full force will be used later. The
required values of the parameters in this assumption, p and q, will be specified in the theorems.

Assumption 3.1 (Distribution of Data)
(i) (Y1 , W1 , X1), (Y2 , W2 , X2), . . . , , (YN , WN , XN ) are independent and identically distributed,
(ii) The support of W is W = [wl , wu], a compact subset of R,
(iii) the support of X is X = [xl , xu ], a compact subset of R,
(iv) the joint probability density function of W and X is bounded and bounded away from zero,
and q times continuously differentiable on W × X,
(v) g(w, x) is q times continuously differentiable with respect to w and x on W × X,
(vi) E[|Yi |p|Xi = x] is bounded.

The first representation is as the expected value of the conditional (on W ) covariance of X and
                                 ∂g
the returns to W , gW (w, x) = ∂w   (w, x), weighted by d(W ). The second representation is as a
                                            ∂ 2g
weighted average of the cross-derivative ∂w∂x    (w, x). Formally:


                                                   [11]
Theorem 3.1 Suppose Assumption 3.1 holds with q ≥ 2. Then, β lc has two equivalent repre-
sentations:

       β lc = E [d(W ) · Cov ( gW (W, X) , X| W )] ,                                             (3.13)

and,
                                 
        lc              ∂2g
       β = E δ(W, X) ·      (W, X) ,                                                             (3.14)
                       ∂w∂x

where the weight function δ(w, x) is non-negative and has the form

                   FX|W (x|w) · (1 − FX|W (x|w))                                      
 δ(w, x) = d(w)·                                · E [X|X > x, W = w]−E [X|X ≤ x, W = w] .
                            fX|W (x|w)

The proofs for the Theorems given in the body of the text are presented in Appendix C.
    Representation (3.13), as we demonstrate below, suggests a straightforward nonparametric
approach to estimating β lc . Representation (3.14) is valuable for interpretation. Equation
(3.14) demonstrates that a test of H0 : β lc = 0 is a test of the the null hypothesis of no
complementarity or substitutability between W and X. If β lc > 0, then in the ‘vicinity of the
status quo’ W and X are complements; if β lc < 0, they are substitutes. The precise meaning
of the “vicinity of the status quo” is implicit in the form of the weight function δ(w, x).
    Deviations of β lc from zero imply that the status quo allocation does not maximize average
outcomes. For β lc > 0 a shift toward positive assortative matching will raise average outcomes,
while for β lc < 0 a shift toward negative assortative matching will do so. Theorem 3.1 therefore
provides the basis of a test of the null hypothesis that the status quo allocation is locally efficient.


4      Estimation and inference with continuously-valued inputs
In this section we discuss estimation and inference. For ease of exposition we focus on the case
without additional exogenous covariates. Allowing for these would complicate the notation,
without adding much insight. The estimators are all weighted averages of (derivatives of) non-
parametric estimators for the regression function. These are what Newey (1994) calls full and
partial means and derivatives. First, in Section 4.1 we describe the nonparametric estimators
for the regression functions. In order to deal with boundary issues we use develop a new non-
parametric kernel estimator. Note that in Newey (1994) fixed trimming methods are used to
deal with these boundary issues. These are less attractive here because they change the nature
of the estimands. Next, in Section 3.1 we present estimators for the first pair of estimands,
β pam and β nam . In Section 4.3 we discuss estimation and inference for β cm (including β rm ),
and in Section 4.4 we discuss β lc. Estimation of and inference for the status quo allocation β sq
is straightforward, as this estimand is a simple expectation, estimated by a sample average.

4.1    Estimating the Production and Distribution Functions
For the two distributions functions we use the empirical distribution functions:
                   N                                      N
                 1 X                                    1 X
       F̂W (w) =     1Wi ≤w ,           and   F̂X (x) =     1Xi ≤x .
                 N                                      N
                     i=1                                   i=1


                                                  [12]
For the inverse distribution functions we use the definition:
        −1                                     −1
      F̂W  (q) = inf 1F̂W (w)≥q ,      and   F̂X  (q) = inf 1F̂X (x)≥q .
                 w∈W                                    x∈X

   The estimands we consider in this paper depend on the regression function g(w, x) (in the
case of β pam , β nam, and β cm ), or its derivative in the case of β lc . The latter also depends on
the regression function m(w), defined as

      m(w) = E[X|W = w].                                                                      (4.15)

In order to estimate these objects, we need estimators for the regression functions m(w) and
g(w, x), and the derivative gW (w, x). Write the regression function as

                                          h2 (w, x)
      g(w, x) = E [Y |W = w, X = x] =               ,
                                          h1 (w, x)

where

      h1 (w, x) = fW X (w, x),      and h2 (w, x) = g(w, x) · fW X (w, x).

To simplify the following discussion, we rewrite h1 (w, x) and h2 (w, x) as
                    h                  i
     hm (w, x) = E Ỹm |W = w, X = x · fW X (w, x),                                           (4.16)

for m = 1, 2, where Ỹ = (Ỹ1 Ỹ2 )0 , with Ỹ1 = 1, Ỹ2 = Yi .
    We focus on estimators for hm (w, x), and use those to estimate g(w, x) and its derivatives.
The standard Nadaraya-Watson (NW) estimator for hm (w, x) is, for some bivariate kernel
K(·, ·),
                             N                          
                        1 X               Wi − w X i − x
      ĥnw,m (w, x) =          Ỹim · K         ,          .                                  (4.17)
                      N · b2                 b       b
                             i=1

We denote the resulting nonparametric estimator by ĝ(w, x). We estimate the derivative of
g(w, x) with respect to w by taking the derivative of the NW estimator of g(w, x).
    Because the support of (Wi , Xi) is assumed to be bounded, we have to deal with boundary
bias of the kernel estimators. Because we also need bias reduction by using higher order
kernels we adopt the Nearest Interior Point (NIP) estimator of Imbens and Ridder (2009). This
estimator divides, for given bandwidth b, the support of (W, X) into an internal region and a
boundary region. On the internal region the uniform convergence of the standard NW kernel
estimators holds, but the estimators must be modified on the boundary region of the support.
The NIP estimator coincides with the usual NW kernel estimator on the internal set, but it is
equal to a polynomial on the boundary set. The coefficients of this polynomial are those of a
Taylor series expansion in a point of the internal set.
    To obtain a compact expression for the NIP estimator we adopt the following notation. The
vector z = (w x)0 has L = 2 components. Some of the results below are stated for general L,
although we only use the case with L = 2. Let Z = W × X denote the (compact) support of Z.
                                                             P                    QL
Let λ denote an L vector of nonnegative integers, with |λ| = L  l=1 λl , and λ! =  l=1 λl !. For L



                                                 [13]
vectors of nonnegative integers λ and µ let µ ≤ λ be equivalent to µl ≤ λl for all l = 1, . . . , L,
and define
                                Y        L          Y           L            
           λ             λ!               λl !                             λl
                   =            =                   =                               .
           µ         µ!(λ − µ)!     µl !(λl − µl )!                        µl
                                       l=1                       l=1
                                               QL    λl
For L vectors λ and z, let z λ =                l=1 zl .   As shorthand for partial derivatives of some function
g we use g (λ)(z):

                     ∂g |λ|
       g (λ)(z) =           (z).
                     ∂z λ
The definition of the internal region depends on the support of the kernel. Let K : RL 7→ R
denote the kernel function. We will assume that K(u) = 0 for u ∈      / U with U compact, and
K(u) bounded. For the bandwidth b define the internal set of the support Z as the subset of Z
such that all z̃ with a distance of up to b times the support of the kernel from z are also in Z
                                             
       I                     L z − z̃
      Zb = z ∈ Z z̃ ∈ R               ∈U ⊂Z .                                              (4.18)
                                 b

This is a compact subset of the interior of Z that contains all points that are sufficiently far
away from the boundary that the standard kernel density estimator at those points is not
affected
     NL by any potential discontinuity
                                     NL     of the density at the boundary. If U = [−1, 1]L and
Z = l=1 [zll , zul ], we have Zb = l=1 [zll + b, zul − b].3 The complement of the interior region
                               I

is the boundary region:
                                                      
                                            z − z̃
      ZBb = Z/Z  I
                 b  =   z ∈ Z  ∃z̃ ∈
                                   / Z s.t.        ∈ U   .                                 (4.19)
                                              b

    Next, we need to develop some notation for Taylor series approximations. Define for a given,
q times differentiable function g : Z 7→ R, a point r ∈ RL and an integer s ≤ q, the (s − 1)-th
order polynomial function t : Z 7→ R based on the Taylor series, expansion of order s − 1, of
g(z) around the point r ∈ Z:
                       s−1 X
                       X     1
       t(z; g, r, s) =          · g (λ)(r) · (z − r)λ .                                                      (4.20)
                             λ!
                         j=0 |λ|=j


Because the function g(z) is q ≥ s times continuously differentiable on Z, the remainder term
in the Taylor series expansion is
                                   X 1
       g(z) − t(z, g, r, s) =           g (λ)(r(s)) · (z − r)λ .
                                     λ!
                                   |λ|=s

with r(z) intermediate between z and r. Because Z is compact, and the the s-th order contin-
uous, the sth order derivative must be bounded, and therefore this remainder term is bounded
   3                                                                                              NL
    The set [−1, 1]L is the set of L vectors with components that are between -1 and 1. The set      l=1 [zll , zul ]   is
the set of L vectors with l-th component between zll and zul .



                                                              [14]
by C|z − r|s . For the NIP estimator we use this Taylor series expansion around a point that de-
pends on z and the bandwidth. Specifically, we take the expansion around rb (z), the projection
on the internal region

      rb (z) = argminr∈ZI kz − rk                                                                 (4.21)
                              b


With this preliminary discussion, the NIP estimator of order s of hm (z) can be defined as:
                         p−1 X
                         X     1
      ĥm,nip,s (z) =            · ĥ(µ) (rb(z))(z − rb (z))µ                                     (4.22)
                               λ! m,nw
                         j=0 |λ|=j

       (λ)
with ĥm,nw the λ-th derivative of the kernel estimator ĥm,nw . For values of z in the internal
region ZIb , the NIP estimator is identical to the NW kernel estimator, ĥm,nip,s (z) = ĥm,nw (z).
It is only in the boundary region that a s − 1-th order Taylor series expansion is used to address
the poor properties of the NS estimator in that region.
     Now the NIP estimator for g(w, x) is

                         ĥ2,nip,s (w, x)
      ĝnip,s (w, x) =                      ,                                                     (4.23)
                         ĥ1,nip,s (w, x)

and the NIP estimator for the first derivative of g(w, x) with respect to w is

      \                      ∂
                                                      ĥ2,nip,s (w, x) · ∂w∂
      ∂g nip,s              ∂w ĥ2,nip,s (w, x)                              ĥ1,nip,s (w, x)
               (w, x) =                           −                              2          .   (4.24)
       ∂w                    ĥ1,nip,s (w, x)                    ĥ1,nip,s (w, x)

Unlike the NW kernel estimator, the NIP estimator is uniformly consistent. Its properties are
discussed in more detail in Imbens and Ridder (2009). A formal statement of the relevant
properties for our discussion is given in Lemmas A.9, A.10, and A.11, and Theorems A.1, A.2,
and A.3 in Appendix A.
    In the remainder of the paper we drop the subscripts from the estimator of the regression
function. Unless specifically mentioned, ĝ(w, x) will be used to denote ĝnip,s (w, x), for s equal
to the order of the kernel, with its value stated in the Lemmas and Theorems.
    Next we introduce two more assumptions. Assumption 4.1 describes the properties of the
kernel function, and Assumption 4.2 gives the rate on the bandwidth. Before stating the next
assumption we need to introduce a class of restrictions on kernel functions. The restrictions
govern the rate at which the kernel, which is assumed to have compact support), goes to zero
on the boundary of its support. This property allows us to deal with some of the boundary
issues. Such properties have previously been used in, for example, Powell, Stock and Stoker
(1989).

Definition 4.1 (Derivative Order of a Kernel) A kernel function K : U 7→ R is of
derivative order d, if, for all u in the boundary of the set U, and all |λ| ≤ d − 1,

          ∂λ
      lim     K(v) = 0.
      v→u ∂uλ




                                                             [15]
Assumption 4.1 (Kernel)
                                Q
(i) K : RL 7→ R, with K(u) = L     l=1 K(ul ),
(ii) K(u) = 0 for u ∈ / U, with U = [−1, 1]L,
(iii) K(·) is r times continuously differentiable, with the r-th derivative bounded on the interior
of U,                                    R                     R
(iv) K(·) is a kernel of order s, so that U K(u)du = 1 and U uλ K(u)du = 0 for all λ such that
0 < |λ| < s, for some s ≥ 1,
(v) K is a kernel of derivative order d.
We refer a kernel satisfying Assumption 4.2 as a derivative kernel of order (s, d).
Assumption 4.2 (Bandwidth) The bandwidth bN = N −δ for some δ > 0.

4.2    Estimation and Inference for βbpam and βbnam
In this section we introduce the estimators for β pam and β nam and present results on the large
sample properties of the estimators. We estimate β pam and β nam by substituting nonparametric
estimators for the unknown functions g(w, x), FW (w), and FX (x):

              1 X  −1                  
                N
      βbpam =     ĝ F̂W (F̂X (Xi )), Xi ,                                                     (4.25)
              N
                     i=1
and
              1 X  −1                      
                N
      b nam
      β     =     ĝ F̂W (1 − F̂X (Xi )), Xi .                                                 (4.26)
              N
                     i=1
It is straightforward to demonstrate consistency for these estimators. The nonparametric es-
timators ĝ, F̂W , and F̂X are uniformly consistent under our assumptions, and consistency of
β̂ pam follows directly from that. It is more difficult to derive the large sample distributions
for these estimators. There are four components to their asymptotic approximations. Here we
discuss the decomposition for β̂ pam . A similar argument holds for β̂ nam . In both cases the first
component corresponds to the estimation error in g(w, x). This component converges at a rate
slower than the regular parametric (root-N ) rate. This is because we estimate in the first stage
a nonparametric regression function with more arguments than we average over in the second
stage. As a result β̂ pam (and β̂ nam ) is a partial (as opposed to a full) mean in the terminology
of Newey (1994). The other three terms converge faster, at the regular root−N rate. There is
one term each corresponding to the estimation error in FW (w) and FX (x) respectively, and one
                                                               −1
corresponding to the difference between the average of g(FW       (FX (Xi )), Xi) and its expectation.
In describing the large sample properties we include all four of these terms, which leaves a re-
mainder that is op (N −1/2). In principle one could ignore the three terms of order Op (N −1/2),
since they will get dominated by the term describing the uncertainty stemming from estima-
tion of g(w, x), but including the additional terms is likely to lead to more accurate confidence
intervals. We provide evidence for this in the simulations in Section 5.
     In order to describe the formal properties of the estimator β̂ pam it is useful to introduce
notation for an intermediate quantity, and some additional functions. Define the average with
the true regression function g(w, x) (but still the estimated distribution functions F̂W and F̂X ),

                   1 X  −1              
                     N
           pam
      β̃         =     g F̂W F̂X (Xi ) , Xi ,                                                  (4.27)
                   N
                     i=1


                                                 [16]
so that we can write β̂ pam − β pam = (β̂ pam − β̃ pam) + (β̃ pam − β pam). Then the first term
                                                                               −1/2
β̃ pam − β pam = Op (N −1/2), and the second term β̂ pam − β̃ pam = Op(N −1/2 bN ). Recall the
notation for the derivative of g(w, x) with respect to w,
                           ∂g
        gW (w, x) =           (w, x),
                           ∂w
and define
                                 −1                                       
                            gW (FW  (FX (x)), x)
        q pam (w, x) =            −1
                                                 · 1FW (w)≤FX (x) − FX (x) ,
                             fW (FW (FX (x)))
         pam
        ψW   (w) = E [q pam (w, X)] ,
                                 −1
                            gW (FW  (FX (z)), z)
        r pam (x, z) =            −1             · (1x≤z − FX (z)) ,
                             fW (FW (FX (z)))
and
         pam
        ψX   (x) = E [r pam(x, X)] .

Theorem 4.1 (Large Sample Properties of β̂ pam )
Suppose Assumptions 2.1, 3.1, 4.1, and 4.2 hold, with q ≥ 2s + 1, r ≥ s + 3, p ≥ 4, d ≥ s − 1,
and 1/(2s) < δ < 1/8. Then
                                 !          pam                
     √         1/2
             bN β̂ pam − β̃ pam       d        0        Ω11      0
       N·                            −→ N           ,           pam      ,
                  β̃ pam − β pam               0         0    Ω22

where
               "                                   Z    Z                                              !   !2
                                                                                fX (X)
  Ωpam
   11     =E σ     2        −1
                           FW    (FX (X)) , Xi ·             K      u1 +         −1
                                                                                             · u2 , u2 du2 du1
                                                   u1   u2                 fW   FW  (FX (X))
                                                                                                         (4.28)
                                                    #
                                     −1
                                                   
                           ·fW |X   FW  (FX (X)) |X ,

and
                       h                                                               2 i
        Ωpam
         22 = E
                            pam
                           ψW           pam
                                (W ) + ψX            −1
                                            (X) + g(FW  (FX (X)), X) − β pam                  .

                                                    pam
In the expression for the large sample variance, ψX       captures the uncertainty resulting from
                             pam
estimation of FX (x), and ψW      captures the uncertainty resulting from estimation of FW (w).
    Note that the component of the variance that captures the uncertainty from estimation
of g(w, x), Ωpam
             11 , depends on the kernel in a way that involves the distribution of the data.
Often when one estimates nonparametric functionals at parametric rates, the dependence on
the kernel vanishes asymptotically if one undersmoothes. Here the kernel shows up in the
leading term. This is also the case in the discussion of partial means in Newey (1994).
    Suppose we wish to construct a 95% confidence interval for β pam . In that case we approxi-
                                              pam                pam
mate the variance of β̂ pam − β pam by V̂ = Ω̂11 · N −1 · b−1
                                                           N + Ω̂22 · N
                                                                        −1
                                                                           , using suitable plug-in

                                                             [17]
                                                                                          p
              pam        pam                                                 pam − 1.96 ·
estimators
       p   Ω̂ 11  and Ω̂ 22  , and construct the confidence interval as ( β̂               V̂, β̂ pam +
1.96 · V̂). Although the first term in V̂ will dominate the second term in large samples, in
finite samples the second term may still be important. We shall see this in the simulations in
Section 5.
    Similar results hold for β nam , with some appropriately redefined concepts. Define

                    1 X  −1                  
                      N
        β̃ nam =        g F̂W 1 − F̂X (Xi ) , Xi ,                                                         (4.29)
                    N
                      i=1

                               −1                                           
                          gW (FW  (1 − FX (x)), x)
        q nam (w, x) =          −1                 · 1FW (w)≤FX (x) − FX (x) ,
                           fW (FW (1 − FX (x)))
         nam           nam
        ψW   (w) = E [qW X (w, X)] ,
                               −1
                          gW (FW  (1 − FX (z)), z)
        r nam (x, z) =          −1                 · (1x≤z − FX (z)) ,
                           fW (FW (1 − FX (z)))
and
         nam           nam
        ψX   (x) = E [rXZ  (x, X)] .

Theorem 4.2 (Large Sample Properties of β̂ nam )
Suppose Assumptions 2.1, 3.1, 4.1, and 4.2 hold, with q ≥ 2s + 1, r ≥ s + 3, p ≥ 4, d ≥ s − 1,
and 1/(2s) < δ < 1/8. Then
                                 !          nam                
     √         1/2
             bN β̂ nam − β̃ nam       d        0        Ω11      0
       N·                            −→ N           ,                    ,
                  β̃ nam − β nam               0         0    Ωnam
                                                                22


where
            "                                  Z    Z                                                     !!2
                                                                              fX (X)
Ωnam
 11     =E σ    2    −1
                    FW    (1 − FX (X)) , X ·             K       u1 +         −1
                                                                                             · u2 , u2         du1
                                               u1   u2                  fW   FW (1 − FX (X))
                                                         #
                               −1
                                                        
                       ·fW |X FW     (1 − FX (X)) |X         ,

and
               h                                      i
                                                nam 2
        Ωnam      nam       nam
         22 = E (ψW (W ) + ψX (X) + g(W, X) − β    ) .

4.3     Estimation and Inference for β cm(ρ, τ )
The starting point for estimation of β cm is the representation of β cm (ρ, 0) in equation (3.9):
                 Z                                              
       cm                       φc Φ−1             −1
                                    c (FW (w)), Φc (FX (x)); ρ
     β (ρ, 0) =        g(w, x)                                  fW (w)fX (x)dwdx.
                   w,x         φc Φ−1                 −1
                                   c (FW (w)) φc Φc (FX (x))




                                                        [18]
Note that this expression is an integral over the product of the marginal pdf’s of W and X,
not the joint. We estimate this by replacing the integrals with sums over the two empirical
distribution functions to get analog estimator
                                                                              
                       N X N               φ   Φ −1 (F̂ (W )), Φ−1(F̂ (X )); ρ
                    1 X                     c    c     W  i     c    X   j
      βbcm (ρ, 0) = 2         ĝ(Wi , Xj )                                   .
                   N                      φ Φc (F̂ (W )) φ Φ−1
                                                −1
                                                                   c (F̂ (X ))
                        i=1 j=1            c           W   i   c        X    j

This estimator would be a standard second order V statistic if we had the true regression func-
tion and the true distribution functions. The dependence on the esimated regression function
complicates its analysis.
    Observe that if ρ = 0 (random matching) the ratio of densities on the right hand side is
equal to 1, so that
                   N N
                1 XX
      β̂ rm =          ĝ(Wi, Xj ).
                N2
                   i=1 j=1

    For τ > 0, the β cm (ρ, τ ) estimand is a convex combination of average output under the
status quo and a correlated matching allocation. The corresponding sample analog is

      βbcm (ρ, τ ) = τ · βbsq + (1 − τ ) · βbcm (ρ, 0),
                      P
where βbsq = Y = N        i=1 Yi /N , the average outcome. This estimator is linear in the nonpara-
metric regression estimator ĝ and nonlinear in the empirical CDFs of X and W .
    A useful and insightful representation of β cm (ρ, 0) is as an average of partial means (c.f.,
Newey 1994). This representation provides intuition both about the structure of the estimand
as well as its large sample properties. Fixing W at W = w, but averaging over the distribution
of X we get the partial mean:

      η (w) = EX [g(w, X) · d(w, X)],                                                       (4.30)

where
                  φc (Φ−1            −1
                        c (FW (w)), Φc (FX (x)); ρ)
      d(w, x) =                                     .                                       (4.31)
                  φc (Φc (FW (w)))φc(Φ−1
                       −1
                                        c (FX (x)))

Observe that (4.30) is a weighted averaged of the production function over the distribution of
X holding the value of the input to be reallocated W fixed at W = w. The weight function
d(w, X) depends upon the truncated normal cupola. In particular, the weights give greater
emphasis to realizations of g(w, X) that are associated with values of X that will be assigned
a value of W close to w as part of the correlated matching reallocation. Thus (4.30) equals
the average post-reallocation output for those firms being assigned W = w. To give a concrete
example (4.30) is the post-reallocation expected achievement of those classrooms that will be
assigned a teacher of quality W = w.
    Equation (4.30) also highlights the value of using the truncated normal copula. Doing so
ensures that the denominators of the copula ‘weights’ in (4.30) are bounded from zero. The
copula weights thus play the role similar to fixed trimming weights used by Newey (1994).
    If we average these partial means over the marginal distribution of W we get β cm (ρ, 0), since

      β cm (ρ, 0) = EW [η (W )] ,

                                                [19]
yielding average output under the correlated matching reallocation.
    ¿From the above discussion it is clear that our correlated matching estimator can be viewed
as a semiparametric two-step method-of-moments estimator with a moment function of
        m(Y, W, β cm(ρ, τ ), η (W )) = τ Y + (1 − τ ) η (W ) − β cm (ρ, τ ).
Our estimator, βbcm (ρ, τ ), is the feasible GMM estimator based upon the above moment function
after replacing the partial mean (η(w) defined in (4.30)) with a consistent estimate. While the
above representation is less useful for deriving the asymptotic properties of βbcm (ρ, τ ) it does
provide some insight as to why we are able to achievement parametric rates of convergence.
    To state the large sample properties of the correlated matching estimator we need some
additional notation. Define:
                           ρφc (Φ−1             −1
                                   c (FW (w)), Φc (FX (x)); ρ)
        eW (w, x) =                                               ×
                       (1 − ρ2 )φc (Φ−1          2     −1 b
                                     c (FW (w))) φc (Φc (FX (x)))
                        −1                          
                        Φc (FX (x)) − ρΦ−1c (FW (w)) ,

                           ρφc (Φ−1              −1
                                 c (FW (w)), Φc (FX (x)); ρ)
        eX (w, x) =                                                ×
                     (1 − ρ2 )φc (Φ−1                  −1 b
                                    c (FW (w)))φc(Φc (FX (x)))
                                                                 2
                      −1                                
                      Φc (FW (w)) − ρΦ−1   c (FX (Xk )) ,
                              −1             −1
                                                             
                       φ c  Φ c  (FW (w)), Φ c  (F X (x)); ρ
        ω cm (w, x) =                                        ,                                  (4.32)
                      φc Φ−1                     −1
                             c (FW (w)) φc Φc (FX (x))

        ψ0cm (y, w, x) =                                                                          (4.33)
                (E [g(W, x) · ω(W, x)] − β cm (ρ, 0)) + (E [g(w, X) · ω(w, X)] − β cm (ρ, 0)) ,
                       fW (w) · fX (x)
        ψgcm (y, w, x) =               (y − g(w, x))ω(w, x),                                      (4.34)
                         fW X (w, x)
                       Z Z
         cm
        ψW (y, w, x) =      g(s, t)eW (s, t) (1w≤s − FW (s)) fW (s) fX (t) dsdt,                  (4.35)

and
                           Z Z
         cm
        ψX  (y, w, x) =          g(s, t)eX (s, t) (1x≤t − FX (t)) fW (s) fX (t) dsdt.             (4.36)

Theorem 4.3 Suppose Assumptions 2.1, 3.1, 4.1, and 4.2 hold with q ≥ 2s − 1, r ≥ s + 1,
p ≥ 3, d ≥ s − 1, and (1/2s) < δ < 1/4, then
                     p
        βbcm (ρ, τ ) → β cm (ρ, τ )
and
        √                                 d
            N(βbcm (ρ, τ ) − β cm (ρ, τ )) −→ N (0, Ωcm),
where
               h                                         i
        Ωcm = E (τ (Y − β sq ) + (1 − τ ) ψ cm(Y, W, X))2 ,

and
        ψ cm (y, w, x) = ψ0cm(y, w, x) + ψgcm(y, w, x) + ψW
                                                          cm              cm
                                                             (y, w, x) + ψX  (y, w, x).           (4.37)


                                                      [20]
Note that this estimator is rootN consistent, unlike β̂ pam and β̂ nam .
   If there was no estimation error in ĝ(w, x), F̂W (w), and F̂X (x), the estimator would be
root−N consistent with normalized asymptotic variance equal to [ψ0cm (Yi , Wi, X)i)2]. The re-
                                           cm              cm
maining terms in the influence function, ψW   (y, w, x), ψX   (y, w, x), and ψgcm(y, w, x), capture
the uncertainty coming from estimation of FW (w), FX (x), and g(w, x) respectively.

4.4     Estimation and Inference for β lc
Estimation of β lc proceeds in two steps. First we estimate g (w, x) = E[Y |W = w, X = x] (and
its derivative with respect to w) and m (w) = E[X|W = w] using kernel methods as in Section
4.1. In the second step we estimate β lc by method-of-moments using the sample analog of the
moment condition
                                                   
            ∂                                    lc
      E       g (W, X) · d(W ) · (X − m (W )) − β = 0.
           ∂w
Thus,
                  1 XN ∂
        β̂ lc =             gb (Wi , Xi) · d(Wi ) · (Xi − m
                                                          b (Wi )).                                      (4.38)
                  N  i=1 ∂w

   Define
                                    1       ∂fW,X (w, x)
        ψglc (y, w, x) = −                               d(w) (y − g (w, x)) (x − m (w))
                                fW,X (w, x)     ∂W
                          ∂m
                        −    (w)d(w) (y − g (w, x))
                          ∂w
                          ∂d
                        −    (w)(y − g(w, x))(x − m (w)).
                          ∂w
and
                                            
         lc                  ∂
        ψm  (y, w, x)    =E    g (w, X) W = w · d(w) · (x − m(w)).
                            ∂w

As in the previous results, the ψ lc are the influence functions, with ψglc(y, w, x) capturing the un-
certainty from estimation of g(w, x), and ψm   lc (y, w, x) capturing the uncertainty from estimation

of m(w).
    The asymptotic properties of β̂ lc are summarized by Theorem 4.4.
Theorem 4.4 Suppose Assumptions 2.1, 3.1, 4.1, and 4.2 hold with q ≥ 2s + 1, r ≥ s + 1,
p ≥ 4, d ≥ s − 1, and 1/(2s) < δ < 1/12. Then
              p
        β̂ lc → β lc,

and
        √                   d
            N(β̂ lc − β lc ) → N (0, Ωlc),

where
                  "                                                                                   2 #
      lc                 ∂
      Ω =E                 g (W, X) · d(W ) · (X − m (W )) − β lc       + ψglc (Y, W, X) +    lc
                                                                                             ψm  (Y, W, X)      .
                        ∂w


                                                       [21]
5    A Monte Carlo Study
To assess whether the asymptotic properties derived in Section 4 provide useful approximations
to finite sample distributions, we carry out a small simulation study. In the interest of brevity we
focus on β pam and β lc . We consider the following data generating process. The pair (Wi∗ , Xi∗)
are drawn from a bivariate normal distribution with both means equal to zero, both variances
equal to one, and correlation coefficient equal to ρ. The two covariates Wi and Xi are then
constructed as Wi = 2 · Φ(Wi∗ ) − 1 and Xi = 2 · Φ(Xi∗ ) − 1, so that both Wi and Xi have a
uniform distribution on [−1, 1], with potentially some correlation between them. The outcome
is generated as

      Yi = Wi + Xi + Wi · Xi + εi ,        εi |Wi , Xi ∼ N (0, 0.25).

Under this data generating process β pam = 0.3333, irrespective of the value of the correlation
between the covariates, ρ. The expected outcome under the current allocation is E[Y ] = 0 if
ρ = 0, and E[Y ] = 0.1212 if ρ = 0.5. We fix the weight function d(w) in the definition of the
local complementarity measure at d(w) = 1 − |w|. The value of the local reallocation parameter
is β lc = 0.1667 if ρ = 0 and β lc = 0.1355 if ρ = 0.5.
    We estimate β pam using equation (4.26), and β lc using equation (4.38). We use a rectangular
kernel on [−1, 1], and local linear regression for estimating g(w, x). The bandwidth for the
regression estimation is choosen using cross-validation, after which we divide the bandwidth
by two to ensure some undersmoothing. For density estimation we use the Silverman rule of
thumb, modified for a uniform kernel. For univariate density estimation this leads to

      bN = 1.84 · σ · N −1/5 .

For estimating the bivariate density we use a bivariate uniform kernel, with the bandwidths in
each direction equal to

      b0N = 1.84 · σ · N −1/6 ,

where the σ is estimated on the data, and so may differ in the two directions for the bivariate
kernel.
    We consider four designs, based on two sample sizes, N = 200 and N = 1000, and two
dependence structures, ρ = 0 and ρ = 0.5. For both designs we calculate the two estimators
β̂pam and β̂lc, and their variances. In Table 1 we report some summary statistics from the
simulations. We report the average and median bias, the standard deviation, the average of
the standard errors, the root mean squared error, the median absolute error, and the coverage
rates for the nominal 90 and 95% confidence intervals. The estimators appear to work fairly
well. Note that the average standard error for β̂ lc is large relative to its standard deviation (the
ratio is more than six). The reason is that occasionally the estimated standard error is very
large. This happens with low probability, so the median standard error is not affected, and the
coverage rate is also fine.
    The estimators have a complicated structure, with the asymptotic distribution relying on a
number of approximations. We further investigate these approximations in Table 2. Define
                   N
                 1 X     −1
                                           
      β̂gpam   =     ĝ FW  (FX (Xi )) , Xi ,                                                 (5.39)
                 N
                    i=1


                                                [22]
                    1 X  −1                
                      N
        pam
      β̂W   =           g F̂W (FX (Xi)) , Xi ,                                             (5.40)
                    N
                      i=1

                  1 X  −1             
                    N
        pam
      β̂X       =     g FW F̂X (Xi ) , Xi ,                                                (5.41)
                  N
                      i=1
and
                    N
          pam     1 X    −1
                                          
      g         =     g FW  (FX (Xi)) , Xi .                                               (5.42)
                  N
                      i=1

Then, as stated formally in Appendix A, Lemma A.15,

      β̂ pam − β pam =
                                                                          
                             pam            pam
           β̂gpam − gpam + β̂W   − gpam + β̂X   − gpam +(gpam − β pam )+op N −1/2 . (5.43)

In Panel A of Table 2, we show the mean and standard deviation of β̂ pam − β pam , β̂gpam − gpam ,
  pam            pam
β̂W   − gpam , β̂X   − gpam , and the remainder term,
                            
      rem = β̂ pam − β pam
                                                                             
                                        pam            pam
                −     β̂gpam − gpam + β̂W   − gpam + β̂X   − g pam + (gpam − β pam ) .

The results in Panel A of Table 2 suggest that the remainder term is indeed small compared
to the terms that are taken into account in the asymptotic distribution. Moreover, the relative
magnitude of the Op (N −1/2) terms are supportive of the fact that we take into account these
                                                   −1/2
terms, not just the leading term which is N −1/2 bN .
    In the appendix we also show that
                              
             1/2                  d
      N 1/2 bN · β̂gpam − g pam −→ N (0, Ωpam
                                            11 ) ,                                       (5.44)
           pam
where Ω11    is defined in (4.28),
                                    pam      
                pam            d
      N 1/2 · β̂W    − gpam −→ N 0, E ψW   (W )2 ,                                         (5.45)
                                 pam   
                pam       d
      N 1/2 · β̂X − gpam −→ N 0, E ψX (X)2 ,                                               (5.46)
and
                                      h                             2 i
                               d           −1
      N 1/2 · (gpam − β pam ) −→ N 0, E g(FW  (FX (Xi), Xi)) − β pam       .               (5.47)

To assess the normal approximations we calculate the t-statistics based on these distributions
(the point estimates divided by estimates of the standard deviations), and report in Panel B of
Table 2 summary statistics for these random variables, which should have approximate normal
distributions. The summary statistics we report are averages, standard deviations, and tail
frequencies. We find that the actual means, standard deviations, and tail frequencies are close
to the nominal ones from the normal distribution.

                                                 [23]
6    Conclusions
In this paper we introduce a new class of estimands involving reallocation of inputs, and develop
statistical methods for analyzing them. We consider a class of problems where a fixed set of
inputs is reallocated to a fixed set of units. Whereas a large part of the literature in econometrics
has focused on estimating the causal effects of changing inputs for all units, or for a subset of
units, here we focus on reallocation rules that take into account resource constraints, by keeping
the distribution of the inputs fixed. The effects we focus on depend critically on the degree
of complementarity between inputs. We therefore follow a flexible nonparametric approach
where the nature of the complementarity is not restricted to a parametric form. We propose
estimators for the effects of various reallocation rules, and derive the asymptotic properties of
these estimators.




                                                [24]
                                         References
Angrist, J. D. and A. B. Krueger. (1999). “Empirical Strategies in Labor Economics,” Handbook
   of Labor Economics 3A: 1277 - 1366 (O. Ashenfelter and D. Card, Eds). New York: Elsevier
   Science.
Athey, S., and G. Imbens (2006), “Identification and Inference in Nonlinear Difference-In-Differences
   Models,”Econometrica, 74(2): 431-497.
Athey, S., and S. Stern. (1998). “An Empirical Framework for Testing Theories About Comple-
   mentarity in Organizational Design”, NBER Working Paper No. 6600.
Becker, Gary S. and Kevin M. Murphy. (2000). Social Economics: Market Behavior in a Social
   Environment. Cambridge, MA: Harvard University Press.
Bhattacharya, D., (2008), “Inferring Optimal Peer Assignment from Experimental Data,”
forthcoming Journal of the American Statistical Association.
Brock, W. and S. Durlauf. (2001). “Interactions-based Models,” Handbook of Econometrics 5 :
   3297 - 3380 (J. Heckman & E. Leamer, Eds.). Amsterdam: North-Holland.
Card, D., and A. Krueger. (1992). “Does School Quality Matter? Returns to Education and
   the Characteristics of Public Schools in the United States, ”Journal of Political Economy 100(1):
   1-40.
Dehejia, R. (2005). “Program evaluation as a decision problem,” Journal of Econometrics 125 (1-2):
   141 - 173.
Flores, C. (2005). “Estimation of Dose-Response Functions and Optimal Doses with a Continuous
    Treatment,” Mimeo.
Graham, B. (2008). “Identifying Social Interactions Through Conditional Variance Restrictions,”
   Econometrica 76(3): 643-660.
Graham, B., G. Imbens, and G. Ridder,(2006a). “Complementarity and the Optimal Allocation
   of Inputs,” Mimeo.
Graham, B., G. Imbens, and G. Ridder,(2006b). “Measuring the Average Outcome and Inequality
   Effects of Segregation in the Presence of Social Spillovers,” Mimeo.
Glaeser, E., and J. Scheinkman, (2003), “Nonmarket Interactions,”Advances in Economics and
   Econometrics: Theory and Applications, Eighth World Congress 1: 339 - 369, (M. Dewatripont el
   al, Eds.). Cambridge: Cambridge University Press.
Härdle, W. and T.M. Stoker. (1989). “Investigating smooth multiple regression by the method
    of average derivatives,” Journal of the American Statistical Association 84 (408): 986 - 995.
Heckman, J., R. Lalonde, and J. Smith. (2000). “The Economics and Econometrics of Active
   Labor Markets Programs,” Handbook of Labor Economics 3A: 1865-2097 (O. Ashenfelter and D.
   Card, Eds). New York: Elsevier Science.
Heckman, J., J. Smith, and N. Clements. (1997). “Making The Most Out Of Programme
   Evaluations and Social Experiments: Accounting For Heterogeneity in Programme Impacts,”
   Review of Economic Studies 64 (4): 487 - 535.
Hirano, K. and J. Porter. (2005). “Asymptotics for statistical treatment rules,” Mimeo.
Imbens, G. (2000). “The Role of the Propensity Score in Estimating Dose-Response Functions,”
    Biometrika 87 (3): 706 - 710.
Imbens, G. (2004). “Nonparametric Estimation of Average Treatment Effects under Exogeneity: A
    Survey,” Review of Economics and Statistics 86 (1): 4 - 30.
Imbens, G., and G. Ridder (2009) “Estimation and Inference for Generalized Full and Partial Means
    and Derivatives,”unpublished manuscript, dept of economics, Harvard University,
    http://www.economics.harvard.edu/faculty/imbens/papers imbens.
Imbens, G., and J. Wooldridge (2009). “New Developments in the Econometrics of Program
    Evaluation,” Journal of Economic Literature 47(1): 5 - 86.

                                                [25]
Lehman, E. (1998), Elements of Large-Sample Theory, Springer-Verlag, New York.
Linton, O., and J. Nielsen. (1995), “A Kernel Method of Estimating Structured Nonparametric
    Regression Based on Marginal Integration,” Biometrika 82 (1): 93 - 100.
Manski, C. (1990). “Nonparametric Bounds on Treatment Effects,” American Economic Review
   80(2): 319 - 323.
Manski, C. (1993). “Identification of Endogenous Social Effects: The Reflection Problem,” Review of
   Economic Studies 60(3): 531 - 542.
Manski, C. (2003). Partial Identification of Probability Distributions. New York: Springer-Verlag.
Manski, C. (2004). “Statistical Treatment Rules for Heterogenous Populations,” Econometrica 72(4):
   1221 - 1246.
Moffitt, R. (2001), “Policy interventions, low-level equilibria and social interactions,”Social Dynam-
   ics: 45 - 82 (S. Durlauf and P. Young, Eds.). Cambridge, MA: MIT Press.
Newey, W. (1994). “Kernel Estimation of Partial Means and a General Variance Estimator,” Econo-
   metric Theory 10(2): 233 - 253.
Powell, J., J. Stock and T. Stoker. (1989). “Semiparametric Estimation of Index Coefficients,”
   Econometrica 57(6): 1403 - 1430.
Rosenbaum, P., and D. Rubin. (1983). “The Central Role of the Propensity Score in Observational
    Studies for Causal Effects,” Biometrika 70(1): 41 - 55.
Legros, P. and A. Newman. (2004). “Beauty is a beast, frog is a prince: assortative matching with
    nontransferabilities,” Mimeo.
Sacerdote, B. (2001). “Peer effects with random assignment: results for Dartmouth roommates,”
    Quarterly Journal of Economics 116(2): 681 - 704.




                                                [26]
     Table 1: Simulation Results for β̂ pam and β̂ lc , 10,000 simulations




                                   N = 200                               N = 1000
                          ρ = 0.0            ρ = 0.5             ρ = 0.0           ρ = 0.5
                        pam        lc      pam
                     β̂         β̂      β̂         β̂ lc    β̂ pam
                                                                       β̂ lc
                                                                              β̂ pam
                                                                                         β̂ lc
mean bias           -0.009 -0.018 -0.002 -0.016            -0.003 -0.011 -0.000 -0.010
median bias         -0.010 -0.020 -0.003 -0.017            -0.003 -0.011 -0.001 -0.010
s.d                  0.093 0.039 0.088 0.043                0.040 0.013 0.039 0.013
ave s.e.             0.085 0.256 0.088 0.578                0.041 0.418 0.044 0.306
median s.e.          0.085 0.051 0.087 0.064                0.040 0.020 0.044 0.039
r.m.s.e.             0.093 0.043 0.088 0.046                0.040 0.017 0.039 0.016
m.a.e.               0.061 0.027 0.060 0.028                0.028 0.013 0.027 0.012
cov rate 90% c.i.    0.871 0.938 0.897 0.959                0.905 0.931 0.935 0.991
cov rate 95% c.i.    0.929 0.968 0.947 0.980                0.953 0.965 0.971 0.997




                                            [27]
Table 2: Simulation Results: Assessing the Adequacy of the Asymptotic Approx-
imations for β̂ pam (N = 1000, ρ = 0.0)




                           β̂ pam   β̂gpam       pam
                                               β̂W          pam
                                                          β̂X       g pam   remainder
                           −β pam   −gpam      −g pam     −g pam   −β pam

        Panel A
        mean               -0.003   -0.002     -0.000     0.001    0.000     -0.001
        s.d.                0.040    0.031      0.019     0.019    0.038     0.004

                            t̂pam     t̂g           t̂W    t̂X       t̂g    nominal

        Panel B
        mean               -0.074   -0.078     -0.015     0.049    0.002      0.000
        s.d.                0.989    1.018      1.005     1.018    1.008      1.000
        pr(|T | ≥ 1.645)    0.095    0.105      0.102     0.111    0.107      0.100
        pr(|T | ≥ 1.96)     0.047    0.055      0.053     0.058    0.052      0.050
        pr(T ≥ 1.645)       0.039    0.043      0.052     0.062    0.053      0.050
        pr(T ≤ −1.645)      0.056    0.062      0.050     0.049    0.054      0.050
        pr(T ≥ 1.96)        0.018    0.021      0.026     0.033    0.027      0.025
        pr(T ≤ −1.96)       0.029    0.034      0.027     0.025    0.025      0.025




                                             [28]
                          Appendix A: Additional Lemmas and Theorems

In this appendix we state a number of additional results that will be used in the proofs of the four Theorems
3.1-4.4. Specifically, Theorem 3.1 uses Lemmas A.1 and A.2. Theorems 4.1 and 4.2 use Lemmas A.3-A.8, A.14,
A.15, Theorem A.1, Lemmas A.16-A.18, A.9-A.11. Theorem 4.3 uses Lemmas A.14, Theorem A.1, Lemmas
A.9-A.11, Theorem A.3, and Lemmas A.24-A.28. Theorem 4.4 uses Lemma A.13, Theorem A.1, and Lemmas
A.19-A.11.

Definition 6.1 (Sobolev Norm) The norm that we use for functions g : Z ⊂ RL → R that are at least j times
continuously differentiable is the Sobolev norm
                      ˛ |λ|      ˛
                      ˛ ∂g       ˛
      |g|j = sup ˛˛        λ
                              (z)˛.
                                 ˛
             z∈Z,|λ|≤j ∂z


Lemma A.1 Let f : X 7→ R, with X = [xl, xu ] a compact subset of R, be a twice continuously differentiable
function, and let g : R 7→ R satisfy a Lipschitz condition, |g(x + y) − g(x)| ≤ c · |y|. Then
       ˛          „                                      «˛           ˛ 2      ˛
       ˛                                                  ˛           ˛        ˛
       ˛f (g(λ)) − f (g(0)) + ∂ f (g(0)) · (g(λ) − g(0)) ˛ ≤ 1 · sup ˛ ∂ f (x)˛ · c2 · λ2 .
       ˛                       ∂x                         ˛    2 x∈X ˛ ∂x2     ˛

Lemma A.2 Let X be a real-valued random variable with support X = [xl, xu ], with density fX (x) > 0 for all
x ∈ X, and let h : X 7→ R be a continous function. Suppose that E[|h(X) · X] is finite. Then
                          »                –
                            ∂
      Cov(h(X), X) = E         h(X) · γ(X) ,
                            ∂x
where
                  FX (x) · (1 − FX (x)
        γ(x) =                         · (E [X|X > x] − E [X|X ≤ x]) ,
                         fX (x)

and FX (x) is the cumulative distribution function of X.

For completeness we state a couple of results from Athey and Imbens (2006, AI from hereon).

Lemma A.3 (Lemma A.2 in AI) Suppose Y is a real-valued, continuously distributed random variable with
compact support Y = [yl, yu ], with the probability density function fY (y) continuous, bounded, and bounded away
from zero, on Y. Then, for any δ < 1/2:
                                    p
        sup N δ · |F̂Y (y) − FY (y)| → 0.
        y∈Y




Lemma A.4 (Lemma A.3 in AI) Suppose Y is a real-valued, continuously distributed random variable with
compact support Y = [yl, yu ], with the probability density function fY (y) continuous, bounded, and bounded away
from zero, on Y. Then, for any δ < 1/2:
                                            p
         sup N δ · |F̂Y−1 (q) − FY−1 (q)| → 0.
        q∈[0,1]




Lemma A.5 (Lemma A.5 in AI) Suppose Y is a real-valued random variable with compact support Y = [yl , yu ],
and suppose that the cumulative distribution function FY (y) is twice continuously differentiable on Y, with its
first derivative fY (y) = ∂FY
                           ∂y
                              (y) bounded away from zero on Y. Then, for 0 < η < 3/4 and δ > max(2η − 1, η/2),
                               ˛                                             ˛
                               ˛                                             ˛ p
               sup       N η · ˛F̂Y (y + x) − F̂Y (y) − (FY (y + x) − FY (y))˛ −→ 0.
        y∈Y,x≤N −δ ,x+y∈Y




                                                          [29]
Lemma A.6 (Lemma A.6 in AI) Suppose Y is a real-valued random variable with compact support Y = [yl , yu ],
and suppose that the cumulative distribution function FY (y) is twice continuously differentiable on Y, with its
first derivative fY (y) = ∂F  ∂y (y) bounded away from zero on Y. Then, for all 0 < η < 5/7,
                               Y


                    ˛                                     “                     ”˛˛
                    ˛                             1                                 p
         sup N η · ˛˛F̂Y−1 (q) − FY−1 (q) +                 F̂ Y (F −1
                                                                    Y  (q)) − q   ˛→
                                                                                  ˛   0.
        q∈[0,1]                             fY (FY−1 (q))


Lemma A.7 Suppose X and Y are real-valued, continuously distributed, random variables with compact support
Y = [yl , yu ] and X = [xl, xu ], with the probability density functions fY (y) and fX (x) continuous, bounded, and
bounded away from zero, on Y and X. Then, for any δ < 1/2:
                 ˛    “        ”                ˛
                 ˛                              ˛ p
      sup N δ · ˛F̂Y−1 F̂X (x) − FY−1 (FX (x))˛ → 0.
       x∈X




Lemma A.8 Suppose Y is a real-valued random variable with compact support Y = [yl , yu ], and the cumulative
distribution function FY (y) is twice continuously differentiable on Y, with its first derivative fY (y) = ∂FY
                                                                                                            ∂y
                                                                                                               (y)
bounded away from zero on Y. Then, for 0 < η < 3/4 and δ > max(2η − 1, η/2),
                              ˛                                  ˛
                              ˛                                  ˛ p
              sup       N η · ˛F̂Y (y + x) − F̂Y (y) − fY (y) · x˛ −→ 0.
       y∈Y,x≤N −δ ,x+y∈Y




The next three lemmas are given without proof. Proofs can be found in IR. The first gives a bound on the bias
of the NIP estimator.

Lemma A.9 (Bias)
If for m = 1, 2 Assumptions 3.1-4.1 hold, and q ≥ 2s − 1 and r ≥ s − 1, then
           ˛ h             i        ˛
           ˛                        ˛
       sup ˛E ĥm,nip,s (z) − hm (z)˛ = O (bs ) .
       z∈Z


Note that by matching the order of the kernel and the degree of the polynomial in the NIP estimator we obtain
the same reduction in the bias on the full support as on the internal region, i.e. the NIP estimator has a bias
that is of the same order as that of the NW estimator on the internal region. The variance is bounded in the
following lemma. We only use the following two results for the case with L = 2, but for convenience we give the
general results.

Lemma A.10 (Variance)
If Assumptions 3.1-4.1 hold and q ≥ s − 1, r ≥ s − 1 + L, then
           ˛                 h             i˛      „       «1/2 !
           ˛                                ˛        log N
       sup ˛ĥm,nip,s (z) − E ĥm,nip,s (z) ˛ = Op                .
       z∈Z                                           N bLN


This is the same bound as for the NW estimator on the internal set.
The two lemmas imply a uniform rate for the NIP estimator

Lemma A.11 (Uniform Convergence)
If Assumptions 3.1-4.1 hold and q ≥ 2s − 1, r ≥ s − 1 + L, then
                                         „        «1/2      !
           ˛                      ˛
           ˛                      ˛        log N          s
       sup ˛ĥm,nip,s (z) − hm (z)˛ = Op               + bN .
       z∈Z                                 N · bL
                                                N



Lemma A.12 If ĥ(z) is a nonparametric estimator of h(z) then
                                 „                   «
    inf |ĥ(z)| = inf |h(z)| + Op sup |ĥ(z) − h(z)|
       z∈Z          z∈Z              z∈Z




                                                         [30]
Therefore if supz∈Z |ĥ(z) − h(z)| = op(1) and inf z∈Z |h(z)| > 0, then inf z∈Z |ĥ(z)| converges in probability to a
positive number. This lemma is useful if ĥ(z) appears in the denominator. In this paper z = (w, x) or z = w.

Lemma A.13 Suppose Assumptions 3.1-4.2 hold. Moreover, suppose that in these assumptions q ≥ 2s − 1,
r ≥ s. Then,
                               „        «1/2      !
                                 ln(N )         s
       sup |m̂(w) − m(w)| = Op               + bN .
       w∈W                       N · bN

Lemma A.14 Suppose Assumptions 3.1-4.2 hold. Moreover, suppose that q ≥ 2s + 1 and r ≥ s + 3, Then, (i)
                                    „         «1/2      !
                                      ln(N )          s
      sup |ĝ(w, x) − g(w, x)| = Op                + bN ,
    w∈W,x∈X                           N · b2N

(ii)
              ˛                        ˛          „             «1/2             !
              ˛ ∂ĝ          ∂g        ˛              ln(N )
         sup ˛˛     (w, x) −    (w, x)˛˛ = Op                          +   bsN       ,
       w∈W,x∈X ∂w            ∂w                       N · b4N

and iii),
               ˛ 2                     ˛              „             «1/2             !
               ˛ ∂ ĝ      ∂2 g        ˛                  ln(N )
         sup ˛˛ 2 (w, x) −      (w, x) ˛ = Op
                                       ˛                                   +   bsN       .
       w∈W,x∈X  ∂w         ∂w 2                           N · b6N

The next lemma shows that we can separate out the uncertainty in β̂ pam into five components: the uncertainty
                                                        −1
from estimating g(·), the uncertainty from estimating F̂W  (·), the uncertainty from estimating F̂X
                                                                                                  “ (·), and
                                                                                                           ” the
                              −1
uncertainty from averaging g(FW  (FX (Xi)), Xi ) over the sample, and a remainder term that is op N −1/2 . As
defined in section 5
                     N
                  1 X ` −1                   ´
       β̂gpam =         ĝ FW (FX (Xi )) , Xi ,
                  N i=1

                  1 X “ −1                   ”
                     N
         pam
       β̂W   =          g F̂W (FX (Xi )) , Xi ,
                  N i=1

                  1 X “ −1 “          ”    ”
                     N
         pam
       β̂X   =          g FW F̂X (Xi ) , Xi ,
                  N i=1
and
                     N
                  1 X ` −1                 ´
       g pam =          g FW (FX (Xi)) , Xi .
                  N i=1

Lemma A.15 Suppose Assumptions 3.1, 4.1, and 4.2 hold with q ≥ 2s + 1, r ≥ s + 3, and 0 ≤ δ < 1/6. Then

       β̂ pam − β pam =
               “              ” “            ” “            ”                       “      ”
                 β̂gpam − gpam + β̂W
                                   pam
                                       − gpam + β̂X
                                                  pam
                                                      − gpam + (g pam − β pam ) + op N −1/2 .                  (A.1)

The next two results are special cases of theorems in Imbens and Ridder (2009). The first one refers to the full
mean case, and focuses on the case where we take full means of regression functions and their first derivatives.
The second result focuses on partial means of regression functions. The results in Imbens and Ridder (2009)
allow for more general dependence on higher order derivatives, even in the partial mean case. Here we also
restrict the analysis to the case where the regressors are the pair (Wi , Xi ). We also state the conditions that IR
invoke.
Let Zi = (Wi , Xi ), with Xi ∈ X ⊂ RLX , Wi ∈ W ⊂ RLW , Zi ∈ W × X ⊂ RLZ , with LZ = LX + LW . As before
h(z) = (h1 (z), h2 (z))0, with h1 (z) = fZ (z), and h2 (z) = E[Y |Z = z] · fZ (z). Let n : RK 7→ R, t : X 7→ W, and


                                                             [31]
ω : X 7→ R, and define Ỹ = (Ỹi1 Ỹi2 )0 , with Ỹi1 = 1 and Ỹi2 = Yi . We are interested in full means (possibly
depending on derivatives) of the regression function,
              h       “        ”i
       θfm = E ω(Z)n h[λ] (Z) ,                                                                              (A.2)

or partial means,
       θpm = E [ω(X)n (h (X, t(X)))] .                                                                            (A.3)
Note that in the full mean case ω : Z 7→ R, and in the partial mean case ω : X 7→ R: the weight function
depends only on the covariates that are being averaged over. In the full mean example h[λ] denotes the vector
with elements including all derivatives h(µ) for µ ≤ λ. The estimators we focus on are

                    1 X
                       N           “             ”                        1 X
                                                                             N         “                     ”
                                      [λ]
       θ̂fm =             ω (Zi ) n ĥnip,s (Zi ) ,     and θ̂pm =              ω(Xi )n ĥnip,s (t(Xi ), Xi ) .
                    N i=1                                                 N i=1

It will also be useful to define the averages over the true regression functions and their derivatives,

           fm       1 X
                       N         “          ”                 pm       1 X
                                                                          N
       θ        =         ω(Zi )n h[λ] (Zi ) ,        and θ        =         ω(Xi )n (h(t(Xi ), Xi )) .
                    N i=1                                              N i=1

Assumption A.1 (Distribution)
(i) (Y1 , Z1 ), (Y2 , Z2 ), . . . , are independent
                                               N and identically distributed,
(ii) the support of Z is Z ⊂ RL , Z = L          m=1 [zml , zmu ], zll < zul for all l = 1, . . . , L.
(iii) supz∈Z E[|Y |p |Z = z] < ∞.
(iv) g(z) = E[Y |Z = z] is q times continuously differentiable on the interior of Z with the q-th derivative bounded,
(v) fZ (z) is bounded and bounded away from zero on Z, is q times continuously differentiable on the interior of
Z with the q-th derivative bounded.

Assumption A.2 (Kernel) Q
(i) K : RL → R, with K(u) = L    l=1 K(ul ),
(ii) K(u) = 0 for u ∈/ U, with U = [−1, 1]L , and U1 = [−1, 1]LW , and U2 = [−1, 1]LX ,
(iii) K is r times continuously differentiable,
                                       R        with the r-thRderivative bounded on the interior of U,
(iv) K is a kernel of order s, so that U K(u)du = 1 and U uλ K(u)du = 0 for all λ such that 0 < |λ| < s, for
some s ≥ 1,
(v) K is a kernel of derivative order d.

Assumption A.3 The bandwidth bN = N −δ for some δ > 0.

Assumption A.4 (Smoothness of n and ω)
(i) The function n is t times continuously differentiable with its t-th derivative bounded, and
                                                                                       µ
(ii) the function ω is t times differentiable on X with bounded t-th derivative, and ∂∂z µω (z) is zero on the boundary
of Z.

Assumption A.5 (Smoothness of t)
The function t : X 7→ W is twice continuously differentiable on X with its first derivative positive, bounded, and
bounded away from zero.

Theorem A.1 (Generalized Full Mean and Average Derivative, [Theorem 4.2, Imbens and Ridder,
2009])
If Assumptions A.1, A.2, A.3, and A.4 hold with q ≥ |λ| + 2s − 1, r ≥ |λ| + s − 1 + L, t ≥ |λ| + s, p ≥ 3,
d ≥ max{λ1 , . . . , λL } + s − 1, all µ ≤ λ, 0 ≤ |µ| ≤ |λ| − 1, and
                         (                                )
       1                          2 − p4            1
          < δ < min                            ,
       2s                  2L + 4 max{1, |λ|} 2L + 4|λ|

then θ̂fm is asymptotically linear with

                              1 X“                          h       “          ”i”
                                  N
       √
           N (θ̂fm − θfm ) = √       ω(Zi )n(h[λ] (Zi )) − E ω(Zi )n h[λ] (Zi )
                               N i=1


                                                               [32]
               0                                                1
             N              2 “                               ”
         1 X @X            X
       +√          (−1)|κ|      α(κ)               (κ)
                                 κm (Xi )Ỹim − E[ακm(X)Ỹm ]
                                                                A + op(1).
          N i=1 κ≤λ        m=1

with
         (κ)                                  ∂n                                             (κ)                        ∂n
       ακ1 (z) = fX (z)ω(z)                   (κ)
                                                         (h[λ] (z)),           and ακ2 (z) = fX (z)ω(z)                 (κ)
                                                                                                                                (h[λ] (z)),
                                            ∂h1 (z)                                                                  ∂h2 (z)

and Ỹ = (Ỹi1 Ỹi2 )0 , with Ỹi1 = 1 and Ỹi2 = Yi .

The second theorem from IR gives the asymptotic properties of the GPM estimators

Theorem A.2 (Generalized Partial Mean, [Theorem 4.3, Imbens and Ridder, 2009])
If Assumptions A.1, A.2, A.3, A.4, and A.5 hold with q ≥ 2s − 1, r ≥ s − 1 + L, t ≥ s, p ≥ 4, d ≥ s − 1, and
                    (            )
       1               2 − p4 1
          < δ < min          ,     ,
       2s             2L + 4 2L

then θ̂pm is asymptotically linear with
        √                  √     “ pm   ”
          N (θ̂pm − θpm) = N · θ − θpm

                                              2 „
                                            N X
                                            X                              Z            „         «
                              1                               Wi − t(Xi)       ∂
                   +              √     ·                 αm(Xi )0 Ỹim   +      t(XKi ) · u2 , u2 du2
                       bN LW N i=1 m=1                  U2        bN          ∂x
                              »           Z      „                             «     –«
                                                   W − t(X)    ∂
                            −E αm (X)0Ỹm      K            +    t(X) · u2 , u2 du2        + op (1) ,
                                            U2       bN       ∂x
with
                                               ∂n                                                                             ∂n
       α1 (x) = fZ (t(x), x)ω(x)                   (h(t(x), x)),                    and           α2 (x) = fZ (t(x), x)ω(x)       (h(t(x), x)).
                                               ∂h1                                                                            ∂h2
Moreover,
               √      “ pm     ”                     !           „„        « „                         ««
                   N · θ − θpm                            d            0       V1                  0
           √                                pm
                                                         −→ N               ,                               ,
                   L
               N bNW
                         /2
                              (θ̂pm − θ          )                     0       0                  V2

with
             ˆ                           ˜
       V1 = E (ω(X)n(h(t(X), X)) − θpm )2 ,

and
               2
               X 2
                 X Z                                                           Z        „Z             „                  «   «2
                                                                                                             ∂t
       V2 =                           µmm0 (x, t(x))αm(x)αm0 (x)                                  K     u1 ,    (x)u1 + u2 du1 du2 fX (x, t(x))dx1 ,
               m=1 m0 =1          X                                                U2        U1              ∂x

with µmm0 (x) = E[Ỹim Ỹim0 |X = x] for m, m0 = 1, 2.

Lemma A.16 Suppose Assumptions 3.1, 4.1, and 4.2 hold, with q ≥ 2s − 1, r ≥ s + 1, p ≥ 4, d ≥ s − 1, and
1/(2s) < δ < 1/8. Then
       √ “ pam         ”
        N β̂g − gpam

                   N                      Z                                                                 !
            1     X                                 Wi − FW−1
                                                              (FX (Xi ))          fX (Xi )
       = √           (Yi − g(Wi , Xi )) ·      K                         +     ` −1              ´ · u2 , u2 du2
            N bN i=1                        u2              bN              fW F W    (FX (Xi ))
          N
             (                                          Z                                                                   !
    1    X     `                  −1                  ´         Wi − FW  −1
                                                                            (FX (Xi ))           fX (Xi)
 +√              g(Wi , Xi ) − g(FW  (FX (Xi )), Xi ) ·     K                          +     ` −1                ´ · u2 , u2 du2
    N bN i=1                                             u2               bN             fW FW (FX (Xi ))
        "                                       Z                                                                !      #)
          `                                  ´                  −1
                            −1                           Wi − FW   (FX (X))            fX (X)
    − E g(W, X) − g(FW (FX (X)), X) ·                K                        +     ` −1              ´ · u2 , u2 du2
                                                  u2             bN             fW F W     (FX (X))


                                                                                    [33]
                                                     +op (1) .
and
         √           “                ”
               1/2                      d
             N bN        β̂gpam − gpam −→
          "                      Z             Z                                                    !         !2                                #!
             ` −1             ´                                            fX (X)                                             ` −1             ´
N     0, E σ2 FW  (FX (X)) , X ·                     K   u1 +         `    −1
                                                                                      ´ · u2 , u2       du2        du1 · fW |X FW  (FX (X)) |X     .
                                          u1    u2               fW       FW  (FX (X))

Lemma A.17 Suppose Assumptions 3.1, 4.1, and 4.2 hold with q ≥ 2. Then
                                 N
                              1 X pam            “      ”
           pam
         β̂W   − gpam =             ψW (Wi ) + op N −1/2 .
                              N i=1

Lemma A.18 Suppose Assumptions 3.1, 4.1, and 4.2 hold, with q ≥ 2. Then
                                 N
                              1 X pam            “      ”
           pam
         β̂X   − gpam =             ψX (Xi ) + op N −1/2 .
                              N i=1

Define
                      N
                   1 X ∂ĝ
         β̂glc =            (Wi , Xi ) · d(Wi ) · (Xi − m(Wi )),
                   N i=1 ∂w

                      N
           lc      1 X ∂g
         β̂m  =             (Wi , Xi) · d(Wi ) · (Xi − m̂(Wi )),
                   N i=1 ∂w
and
                      N
                   1 X ∂g
         g lc =             (Wi , Xi ) · d(Wi ) · (Xi − m(Wi )).
                   N i=1 ∂w

Lemma A.19 Suppose Assumptions 3.1, 4.1, and 4.2 hold. Moreoever, suppose that the estimators for g(w, x)
and m(w), ĝ(w, x) and m̂(w) respectively, satisfy
              ˛                        ˛
              ˛ ∂ĝ          ∂g        ˛
       sup ˛  ˛     (w, x) −    (w, x)˛˛ = op(N −η ) and sup |m̂(w) − m(w)| = op (N −η ),
     w∈W,x∈X    ∂w           ∂w                          w∈W


for some η > 1/4. Then
                     “            ” “           ” “           ”    “      ”
       β̂ lc − β lc = β̂glc − g lc + β̂m
                                       lc
                                          − g lc + g lc − β lc + op N −1/2 .                                                         (A.4)

Lemma A.20 Suppose Assumptions 3.1, 4.1, and 4.2 hold, with q ≥ 2s, r ≥ s, p ≥ 3, d ≥ s, and 1/(2s) < δ <
1/12. Then:
                             N
                          1 X lc                       “      ”
         β̂glc − g lc =         ψg (Yi , Wi , Xi ) + op N −1/2 ,                                                                     (A.5)
                          N i=1

where
                                     1      ∂fW,X (W, X)
         ψglc (Y, W, X) = −                              (Y − g (W, X)) d(W ) (X − m (W ))
                                fW,X (W, X)     ∂W
                                     ∂m (W )
                                   −         d(W ) (Y − g (W, X))
                                      ∂W
                                     ∂d
                                   +    (W ) (X − m(W )) (Y − g(W, X)) .
                                     ∂w



                                                                  [34]
Lemma A.21 Suppose Assumptions 3.1-4.2 hold, with q ≥ 2s − 1, r ≥ s, p ≥ 3, d ≥ s − 1, and
       1     1   2
          <δ< −    ,
       2s    3  3p
then
           ˛                              ˛
           ˛         “                 ”2 ˛   “      ”
           ˛ 1                            ˛
       sup ˛           fbW (w) − fW (w) ˛ = op N −1/2 .
       w∈W ˛ fbW (w)                      ˛

Lemma A.22 Let h (w) = (h1 (w) , h2 (w))0 = (E [ X| W = w] fW (w) , fW (w))0 , and suppose Assumptions 3.1-
4.2 hold, with q ≥ 2s − 1, r ≥ s, p ≥ 3, d ≥ s − 1, and
       1     1   2
          <δ< −    ,
       2s    3  3p
then
           ˛                                            ˛
           ˛        “                ”“                ”˛     “      ”
           ˛ 1        b                                 ˛
       sup ˛          h1 (w) − h1 (w) b h2 (w) − h2 (w) ˛ = op N −1/2 .
       w∈W ˛ b
             h2 (w)                                     ˛

Lemma A.23 Suppose Assumptions 3.1-4.2 hold, with q ≥ 2s − 1, r ≥ s, p ≥ 3, and
       1     1
          <δ< .
       2s    8
Then
                       1 X
                          N                                                       “      ”
         lc
       β̂m  − g lc =         E [ gW (Wi , Xi )| Wi ] · d(Wi ) · (Xi − m(Wi )) + op N −1/2 ,                   (A.6)
                       N i=1

                                                                                  0    0 0
Before the next theorem we need some additional definitions. We split Zi into (Zi1  , Zi2 ) , with the dimension
of Zi1 equal to LZ1 , and the dimension of Zi2 equal to LZ2 , so that L = LZ1 + LZ2 . We are interested in the
distribution of
                        N   N                              N N
                                                                               !
            √        1 XX                                1 XX
       V = N·                  n(ĥnip,s (Z1j , Z2k )) − 2     n(h(Z1j , Z2k )) .                          (A.7)
                   N 2 j=1                              N j=1
                                 k=1                                     k=1

We show that this is, to first order, equivalent to a single normalized sum.
Theorem A.3 Suppose that Assumptions A.1-A.4, hold with q ≥ 2s − 1, r ≥ s − 1 + L, 1/(2s) < δ < 1/(2L),
and t ≥ 2. Then
                N                                           »                                   –ff
            1 X ∂n            0                                ∂n       0
      V = √           (h(Zi )) Ỹi fZ1 (Z1i )fZ2 (Z2i ) − EZ      (h(Z)) Ỹ fZ1 (Z1i )fZ2 (Z2i )     + op (1). (A.8)
             N i=1 ∂h                                          ∂h

(To be clear here we index the expectation by the random variable the expectation is taken over, in this case Z.)
Before stating some additional lemmas that will be used for proving Theorem 4.3 we need some additional
definitions. Define
                    N N               `                                ´
               1 XX                 φc Φ−1             −1
                                        c (FW (Wi )), Φc (FX (Xj )); ρ
        g cm = 2        g(Wi , Xj ) ` −1           ´ ` −1               ´
              N i=1 j=1            φc Φc (FW (Wi )) φc Φc (FX (Xj ))

                    N   N                     `                                         ´
                1 XX                      φc Φ−1                     −1
                                                 c (FW (Wi )), Φc (FX (Xj )); ρ
       β̂gcm =             ĝ(Wi , X j )    `                    ´    `                  ´
               N 2 i=1 j=1               φc Φ−1                          −1
                                                c (FW (Wi )) φc Φc (FX (Xj ))
                                              “                                          ”
                                                  −1                  −1
                1  XN X N                 φ c   Φ c  ( F̂ W (Wi )), Φ c  (F X (X j )); ρ
         cm
       β̂W    = 2          g(Wi , Xj ) “                         ” `                      ´
               N i=1 j=1                 φc Φ−1                           −1
                                                c (F̂W (Wi )) φc Φc (FX (Xj ))
                                       “                                  ”
                  N
                1 XX
                      N              φc Φ−1              −1
                                          c (FW (Wi )), Φc (F̂X (Xj )); ρ
         cm
       β̂X    = 2
               N i=1 j=1
                         g(Wi , Xj ) `               ´ “ −1                ”
                                    φc Φ−1
                                         c (FW (Wi )) φc Φc (F̂X (Xj ))




                                                                  [35]
Lemma A.24 Suppose Assumptions 3.1-4.2 hold with q ≥ 2s + 2, r ≥ s + 3, and 1/(2s) < δ < 1/4, then
        βbcm(ρ, 0) − β cm(ρ, 0)
                   “            ” “          ” “           ”                          “      ”
                = β̂gcm − gcm + β̂W cm
                                       − g cm + β̂X
                                                  cm
                                                     − g cm + (g cm − β cm(ρ, 0)) + op N −1/2 .

Lemma A.25 Suppose Assumptions 3.1-4.2 hold, then
                            N
                         1 X cm                      “      ”
        β̂gcm − g cm =         ψg (Yi , Wi , Xi) + op N −1/2 ,
                         N i=1
where
                             fW (w) · fX (x)
        ψgcm (y, w, x) =                     (y − g(w, x))ω(w, x).
                              fW X (w, x)
Lemma A.26 Suppose Assumptions 3.1-4.2 hold, then
                            N
                         1 X cm                      “      ”
          cm
        β̂W  − g cm =          ψW (Yi , Wi , Xi) + op N −1/2 ,
                         N i=1
where
                             Z Z
         cm
        ψW  (y, w, x)    =         g(s, t)eW (s, t) (1 (w ≤ s) − FW (s))fW (s) fX (t) dsdt.

Lemma A.27 Suppose Assumptions 3.1-4.2 hold, then
                            N
                         1 X cm                      “      ”
          cm
        β̂X  − g cm =          ψX (Yi , Wi , Xi) + op N −1/2 .,
                         N i=1

where
                             Z Z
         cm
        ψX  (y, w, x) =            g(s, t)eX (s, t) (1 (x ≤ t) − FX (t))fW (s) fX (t) dsdt.

Lemma A.28 Suppose Assumptions 3.1-4.2 hold, then
                                   N
                                1 X cm                       “      ”
        g cm − β cm(ρ, 0) =           ψ0 (Yi , Wi , Xi ) + op N −1/2 ,
                                N i=1
where
        ψ0cm (w, x) = (E [g(W, x) · ω(W, x)] − β cm (ρ, 0)) + (E [g(w, X) · ω(w, X)] − β cm(ρ, 0)) .   (A.9)

The following theorem is a simplifed version of the V-statistics results in Lehman (1998).
Theorem A.4 (V-statistics) Suppose Z1 , . . . , ZN are independent and identically distributed random vectors
with dimension K, with support Z ⊂ RK . Let ψ : ZK × ZK 7→ R be a real-valued function. Define
        θ = E [ψ(Z1 , Z2 )] ,           ψ1 (z) = E [ψ(z, Z)] ,          ψ2 (z) = E [ψ(Z, z)] ,
         2
        σ = Cov(ψ(Z1 , Z2 ), ψ(Z1 , Z3 )) + Cov(ψ(Z2 , Z1 ), ψ(Z1 , Z3 ))
                         +Cov(ψ(Z1 , Z2 ), ψ(Z3 , Z1 )) + Cov(ψ(Z2 , Z1 ), ψ(Z3 , Z1 )).
and
                   N   N
               1 XX
        V =               ψ(Zi , Zj ).
              N 2 i=1 j=1

Then, if 0 < σ2 < ∞,

              1 X
                 N                                        “      ”
        V =         {(ψ1 (Zi ) − θ) + (ψ2 (Zi ) − θ)} + op N −1/2 ,
              N i=1

and
        √                d  `     ´
            N · (V − θ) −→ N 0, σ2 .



                                                                 [36]
                  Appendix B: Proofs of Additional Lemmas and Theorems

In the following proofs c is a generic constant.
Proof of Lemma A.1: Because f (·) is twice continuously differentiable on X, a compact subset of R, it follows
that for all a, b ∈ X, by a Taylor series expansion,

                           ∂f                1 ∂2f
       f (b) = f (a) +        (a) · (b − a) + ·    (c) · (b − a)2 ,
                           ∂x                2 ∂x2
for some c ∈ X. Hence
       ˛          „                                    «˛           ˛ 2      ˛
       ˛                                                ˛           ˛        ˛
       ˛f (g(λ)) − f (g(0)) + ∂f (g(0)) · (g(λ) − g(0)) ˛ ≤ 1 · sup ˛ ∂ f (x)˛ · (g(λ) − g(0))2 .
       ˛                      ∂x                        ˛   2 x∈X ∂x˛   2    ˛

By the Lipschitz condition on g(λ), this is bounded by
              ˛ 2      ˛
      1       ˛∂ f     ˛
        · sup ˛    (x)˛˛ · c2 · λ2 .
      2 x∈X ˛ ∂x2

                                                          Rx                            ∂
Proof of Lemma A.2: Let µ = E[X], and write h(x) = h(xl ) + x                                 h(z)dz. Then:
                                                                                       l ∂x

                                                             »„         Z     X               «               –
                                                                                  ∂
       Cov(h(X), X) = E [h(X) · (X − µ)] = E                   h(xl ) +              h(z)dz       · (X − µ)
                                                                             xl   ∂x
                      »Z    X                            –
                                 ∂
              =E                    h(z)dz · (X − µ)
                           xl    ∂x
                      »Z    xu                                    –
                                           ∂
              =E                 1X>z ·       h(z)dz · (X − µ)
                           xl              ∂x
                  Z   xu
                            ∂
              =                h(z) · E [1X>z · (X − µ)] dz
                   xl       ∂x
                  Z xu
                            ∂
              =                h(z) · E [X − µ|X > z] · Pr(X > z)dz
                   xl       ∂x
                  Z xu
                            ∂
              =                h(z) · FX (z) · (1 − FX (z)) · (E[X|X > z] − E[X|X ≤ z]) dz
                   xl       ∂x
                  Z   xu
                      ∂        FX (z) · (1 − FX (z))
              =         h(z) ·                       · (E[X|X > z] − E[X|X ≤ z]) fX (z)dz
                   xl∂x               fX (z)
                 »                 –
                   ∂
              =E      h(X) · γ(X) .
                   ∂x

Proof of Lemma A.7: By the triangle inequality
               ˛     “       ”               ˛
               ˛                             ˛
     sup N δ · ˛F̂Y−1 F̂X (x) − FY−1 (FX (x))˛
       x∈X
                          ˛     “       ”      “       ”˛
                          ˛                             ˛
              ≤ sup N δ · ˛F̂Y−1 F̂X (x) − FY−1 F̂X (x) ˛
                  x∈X
                                       ˛    “       ”      “       ”˛
                                       ˛                            ˛
                           + sup N δ · ˛FY−1 F̂X (x) − FY−1 F̂X (x) ˛
                                x∈X
                          ˛                    ˛
                          ˛                    ˛
              ≤ sup N δ · ˛F̂Y−1 (q) − FY−1 (q)˛
                  q∈[0,1]
                                                        ˛                ˛
                                                   1 ˛                   ˛
                           +     sup      Nδ ·          ˛F̂X (x) − FX (x)˛ .
                                x∈X,y∈Y          fY (y)
The first term is op (1) by Lemma A.4, and the second by the fact that fY (y) is bounded away from zero, in
combination with Lemma A.3. 



                                                                      [37]
Proof of Lemma A.8: By the triangle inequality
                        ˛                                  ˛
                        ˛                                  ˛
           sup    N η · ˛F̂Y (y + x) − F̂Y (y) − fY (y) · x˛
       y∈Y,x≤N −δ ,x+y∈Y
                                                ˛                                   ˛
                                                ˛                                   ˛
              ≤            sup            N η · ˛F̂Y (y + x) − (FY (y + x) − FY (y))˛
                  y∈Y,x≤N −δ ,x+y∈Y

                       +            sup          N η · |FY (y + x) − FY (y) − fY (y) · x| .
                           y∈Y,x≤N −δ ,x+y∈Y

The first term on the right-hand side converges to zero in probability by Lemma A.5. To show that the second
term converges to zero note that

              sup          N η · |FY (y + x) − FY (y) − fY (y) · x|
       y∈Y,x≤N −δ ,x+y∈Y

              ≤               sup               N η · |fY (y + λx) · x − fY (y) · x|
                  y∈Y,x≤N −δ ,x+y∈Y,λ∈[0,1]
                                                       ˛         ˛
                                                       ˛ ∂fY     ˛
              ≤                   sup           N η · ˛˛     (z)˛˛ · λx2
                  y∈Y,z∈Y,x≤N −δ ,x+y∈Y,λ∈[0,1]           ∂y
                                          ∂fY
              ≤      sup         N η x2       (y) → 0,
                  y∈Y,x≤N −δ               ∂y
because ∂f
         ∂y
           Y
             (y) is bounded, x < N −δ , and δ > η/2. 
Proof of Lemma A.12: By the inequality |a| ≥ |b| − |a − b|

       inf |ĥ(z)| ≥ inf |h(z)| − sup |ĥ(z) − h(z)|
       z∈Z           z∈Z             z∈Z

from which the result follows. 
Proof of Lemma A.13: This follows directly from Theorem 7.1 in IR 
Proof of Lemma A.14: This follows directly from Theorem 7.1 in IR. 
Proof of Lemma A.15: First note that by the assumptions in the Lemma the conditions for Lemma A.14
are satisfied. Moreoever, by the assumption that 0 < δ < 1/6, it follows that Op (bN ) = op(N −η ) for η < δ · s,
and Op (ln(N )N −1 b−2
                    N ) = Op (ln(N )N
                                      −1+2δ
                                            ) = op (1), Op (ln(N )N −1 b−4
                                                                        N ) = Op (ln(N )N
                                                                                          −1+4δ
                                                                                                ) = op(N −η ) for
                            −1 −6                −1+6δ
η < 1 − 4δ, and Op (ln(N )N bN ) = Op (ln(N )N         ) = op (1). Hence the results from Lemma A.14 imply
                                        „         «1/2       !
                                           ln(N )          s
          sup |ĝ(w, x) − g(w, x)| = Op                 + bN = op(1),                                      (B.1)
       w∈W,x∈X                            N · b2N
              ˛                        ˛                 „             «1/2             !
              ˛ ∂ĝ          ∂g        ˛                     ln(N )                             `    ´
         sup ˛˛     (w, x) −    (w, x)˛˛ = Op                                 +   bsN       = op N −η ,     (B.2)
       w∈W,x∈X ∂w            ∂w                              N · b4N
for η < min(1 − 4δ, δ · s), and
               ˛ 2                          ˛                „             «1/2             !
               ˛ ∂ ĝ           ∂2 g        ˛                    ln(N )
         sup ˛˛ 2 (w, x) −           (w, x) ˛ = Op
                                            ˛                                     +   bsN       = op (1).   (B.3)
       w∈W,x∈X  ∂w              ∂w 2                             N · b6N

Now,

                           1 X “ −1 “            ”    ”
                              N
                                                          ˆ ` −1              ´˜
       β̂ pam − β pam =          ĝ F̂W F̂X (Xi ) , Xi − E g FW  (FX (X)) , X
                           N i=1

                  1 X “ −1 “           ”    ”  1 X “ −1 “           ”     ”
                     N                            N
              =         ĝ F̂W F̂X (Xi) , Xi −       g F̂W F̂X (Xi ) , Xi                                   (B.4)
                  N i=1                        N i=1
                                N                            N
                                                                                     !
                             1 X ` −1                  ´  1 X ` −1                  ´
                       −           ĝ FW (FX (Xi)) , Xi −       g FW (FX (Xi)) , Xi                         (B.5)
                             N i=1                        N i=1
                              N                             N
                           1 X ` −1                   ´  1 X ` −1                   ´
                       +         ĝ FW (FX (Xi )) , Xi −       g FW (FX (Xi )) , Xi                         (B.6)
                           N i=1                         N i=1


                                                                    [38]
                        1 X “ −1 “           ”      ”   1 X “ −1 “           ”      ”
                           N                               N
                      +       g F̂W F̂X (Xi ) , Xi −          g FW F̂X (Xi ) , Xi                                (B.7)
                        N i=1                          N i=1
                                                                                      !
                          1 X “ −1                   ”
                             N                              N
                                                         1 X ` −1                   ´
                      −         g F̂W (FX (Xi )) , Xi −        g FW (FX (Xi )) , Xi                              (B.8)
                          N i=1                          N i=1

                          1 X “ −1                   ”
                             N                             N
                                                        1 X ` −1                  ´
                      +         g F̂W (FX (Xi )) , Xi −       g FW (FX (Xi)) , Xi                                (B.9)
                          N i=1                         N i=1

                          1 X “ −1 “          ”    ”
                             N                           N
                                                      1 X ` −1                  ´
                      +         g FW F̂X (Xi ) , Xi −       g FW (FX (Xi)) , Xi                                 (B.10)
                          N i=1                       N i=1
                             N
                          1 X ` −1                  ´   ˆ ` −1             ´˜
                      +         g FW (FX (Xi )) , Xi − E g FW  (FX (X)) , X .                                   (B.11)
                          N i=1

Since (B.6) is equal to β̂pam,g − g pam , (B.9) equals β̂pam,W − g pam , (B.10) equals β̂pam,X − g pam , and (B.11)
equals gpam − β pam, we only need to show that the sum of (B.4), (B.5), and that of (B.7), (B.8) are op (N −1/2 ).
First consider the sum of (B.4) and (B.5) that is equal to


       1 X “ −1 “            ”    ”
          N                             N
                                     1 X ` −1                    ´
             ĝ F̂W F̂X (Xi ) , Xi −       ĝ FW (FX (Xi )) , Xi
       N i=1                         N i=1
                                                                                                        !
                            1 X “ −1 “           ”    ”
                               N                            N
                                                         1 X ` −1                   ´
                      −           g F̂W F̂X (Xi ) , Xi −       g FW (FX (Xi )) , Xi                         .
                            N i=1                        N i=1
                                                          −1
By a second order Taylor series expansion of ĝ and g in FW  (FX (Xi )) this is, for some W̃i and W̄i , equal to
                 N
              1 X ∂ĝ ` −1               ´ “ −1 “         ”
                                                              −1
                                                                            ”
                       FW (FX (Xi )) , Xi F̂W    F̂X (Xi ) − FW  (FX (Xi ))
              N i=1 ∂w

                           1 X ∂ 2 ĝ “           ”“       “             ”                     ”2
                              N
                                                        −1                     −1
                      +                 W̃i , X i    F̂ W    F̂ X (X i )   − F W  (F X (X i ))                  (B.12)
                          2N i=1 ∂w 2
                             N
                          1 X ∂g ` −1                ´ “ −1 “         ”
                                                                          −1
                                                                                        ”
                      −            FW (FX (Xi )) , Xi F̂W    F̂X (Xi ) − FW  (FX (Xi ))
                          N i=1 ∂w
                              N
                          1 X ∂2 g `                ´ “ −1 “                ”
                                                                                  −1
                                                                                                 ”2
                      −                 W̄  i , X i   ·  F̂ W   F̂ X (X i )   − F W  (F X (X i ))   .           (B.13)
                         2N i=1 ∂w 2
                     N „                                                                     «
                 1 X ∂ĝ ` −1                             ´    ∂g ` −1                     ´
              =                  FW (FX (Xi )) , Xi −                FW (FX (Xi )) , Xi
                N i=1 ∂w                                       ∂w
                         “      “          ”                        ”         “       ”
                            −1                       −1
                       × F̂W      F̂X (Xi ) − FW        (FX (Xi )) + op N −1/2 .
                     ˛                                                           ˛
                     ˛ ∂ĝ ` −1                 ´ ∂g ` −1                       ´˛
              ≤ sup ˛˛      FW (FX (x)) , x −                FW (FX (x)) , x ˛˛                                 (B.14)
                x∈X ∂w                                 ∂w
                             ˛“       “         ”                     ”˛        “        ”
                             ˛ −1                       −1              ˛
                       × sup ˛ F̂W F̂X (x) − FW              (FX (x)) ˛ + op N −1/2 .                           (B.15)
                          x∈X

We used the fact that (B.13) is op (N −1/2 ) because ∂ 2 g(w, x)/∂w 2 is bounded and because supx∈X (F̂W−1
                                                                                                           (F̂X (x)) −
 −1          2          −1/2                                              −1/2
FW (FX (x))) is op (N        ) by Lemma A.7. Also (B.12) is op(N               ) by the same argument because the
bandwidth choice implies supw∈W,x∈X |∂ 2 ĝ(w, x)/∂w 2 − ∂ 2 g(w, x)/∂w 2 | = op (1) by (B.3), so that
           ˛ 2          ˛           ˛ 2         ˛            ˛ 2                      ˛           ˛ 2        ˛
           ˛ ∂ ĝ(w, x) ˛           ˛           ˛            ˛               2        ˛           ˛          ˛
     sup ˛˛             ˛ ≤ sup ˛ ∂ g(w, x) ˛ + sup ˛ ∂ ĝ(w, x) − ∂ g(w, x) ˛ = sup ˛ ∂ g(w, x) ˛ + op(1)
   w∈W,x∈X      ∂w 2    ˛  w∈W,x∈X
                                    ˛   ∂w   2  ˛  w∈W,x∈X
                                                             ˛   ∂w 2           ∂w 2  ˛   w∈W,x∈X
                                                                                                  ˛   ∂w 2   ˛

Finally by Lemma A.7
           ˛    “        ”              ˛     “         ”
           ˛ −1              −1         ˛
       sup ˛F̂W   F̂X (x) − FW  (FX (x))˛ = op N −1/2+η
       x∈X



                                                                [39]
for all η > 0. By the assumption of the lemma
             ˛                                             ˛
             ˛ ∂ĝ ` −1            ´  ∂g ` −1            ´˛
        sup ˛˛      FW (FX (x)) , x −     FW (FX (x)) , x ˛˛ = op(N −η )
        x∈X ∂w                        ∂w
                                                                     “   ”
for some η > 0. We conclude that the sum of (B.4) and (B.5) is op N −1/2 .
Next, consider the sum of (B.7) and (B.8) that is bounded by
           ˛h “     “        ” ”     “     “        ” ”i h “                  ”   ` −1             ´i˛˛
           ˛     −1                    −1                      −1
       sup ˛ g F̂W    F̂X (x) , x − g FW     F̂X (x) , x − g F̂W  (FX (x)) , x − g FW  (FX (x)) , x ˛
        x∈X


By a second order Taylor series expansion with intermediate values W̃ (x) and W̄ (x) and the triangle inequality
this is bounded by
              ˛
              ˛ ∂g “ −1 “          ” ”h            “         ”            “        ”i
         sup ˛˛      FW F̂X (x) , x F̂W         −1
                                                     F̂X (x) − FW   −1
                                                                           F̂X (x)
         x∈X ∂w

           ∂g ` −1                  ´ h −1                                   i˛˛
         −        F (FX (x)) , x F̂W (FX (x)) − FW (FX (x)) ˛˛ +
                                                              −1
           ∂w W
       ˛                                                           ”i2 ˛˛ 1       ˛ 2                                                 i2 ˛˛
     1 ˛ ∂2 g “            ”h      “          ”         “                         ˛∂ g `           ´ h −1
sup ˛˛      2
                 W̃ (x), x   F̂ −1
                                W    F̂ X (x)   −  F −1
                                                     W    F̂ X (x)      ˛ +   sup ˛
                                                                        ˛ 2 x∈X ˛ ∂w 2   W̄ (x), x    F̂ W (F X (x)) − F −1
                                                                                                                         W  (F X (x))     ˛
                                                                                                                                          ˛
x∈X 2 ∂w

where because the second derivative of g(w, x) is bounded on W × X, by Lemma A.4 the expression on the last
line is op(N −1/2 ). The first term is bounded by
             ˛»                                                  –                                ”i˛˛
             ˛ ∂g “ −1 “         ” ”      ∂g ` −1               ´ h −1 “        ”        “
        sup ˛˛       FW F̂X (x) , x −         FW (FX (x)) , x        F̂W F̂X (x) − FW −1
                                                                                           F̂X (x) ˛˛
        x∈X     ∂w                       ∂w
                ˛                                                                                       i˛˛
                ˛ ∂g ` −1            ´ −1 “
                                      h             ”         “         ”
        + sup ˛˛      FW (FX (x)) , x F̂W    F̂X (x) − FW  −1               −1
                                                                F̂X (x) − F̂W  (FX (x)) + FW −1
                                                                                                (FX (x)) ˛˛
          x∈X ∂w
                                                “     “        ” ”
                                            ∂g     −1
By a first order Taylor series expansion of ∂w    FW    F̂X (x) , x in FX (x) we have, because the second derivative
of g(w, x) is bounded and the density of W is bounded from 0 on its support, that by Lemmas A.4 and A.3, the
expression on the first line is op (N −1/2 ). The bound on the expression in the second line is proportional to
           ˛     “        ”         “        ”                              ˛
           ˛ −1                 −1                −1             −1         ˛
       sup ˛F̂W    F̂X (x) − FW       F̂X (x) − F̂W  (FX (x)) + FW  (FX (x))˛
        x∈X

This expression is bounded by
      ˛                                                                                                  ˛
      ˛                      h   “    “        ””        i                   h                         i˛˛
      ˛          1                                                 1             `            ´
 sup ˛˛   “      “                 −1
                           ”” F̂W FW    F̂X (x) − F̂X (x) −   ` −1                 −1
                                                                            ´ F̂W FW  (FX (x)) − FX (x) ˛˛
 x∈X ˛ f
         W FW
              −1
                   F̂X (x)                                  fW F W  (FX (x))                             ˛
               ˛                                                                                ˛
               ˛                                                                              i˛˛
               ˛ −1 “       ”       “       ”          1           h   “      “     ””
        + sup ˛˛F̂W F̂X (x) − FW F̂X (x) −
                                 −1
                                                  “    “         ”” F̂W FW F̂X (x) − F̂X (x) ˛˛
                                                                           −1
          x∈X ˛                                     −1                                          ˛
                                               fW F W    F̂X (x)
               ˛                                                                            ˛
               ˛                                                h    ` −1         ´        i˛
               ˛ −1             −1                  1                                       ˛
        + sup ˛F̂W  (FX (x)) − FW  (FX (x)) −   ` −1          ´ F̂W FW    (FX (x)) − FX (x) ˛
          x∈X ˛                               fW FW (FX (x))                                ˛

By Lemma A.6 the expressions in the last two lines are op(N −1/2 ). The expression in the first line is bounded
by
          ˛2                                           3                                ˛
          ˛                                              h  “      “      ””          i˛˛
          ˛        1                       1
     sup ˛˛4  “    “       ”” −      ` −1            ´ 5 F̂W FW F̂X (x) − F̂X (x) ˛˛
                                                               −1
     x∈X ˛ fW F −1 F̂X (x)        fW F W    (FX (x))                                    ˛
                W

              ˛                                                                      ˛
              ˛                 h   “    “     ””              ` −1        ´        i˛
              ˛       1               −1                                             ˛
        + sup ˛   ` −1
                              ´  F̂W FW F̂X (x) − F̂X (x) − F̂W FW (FX (x)) + FX (x) ˛
          x∈X ˛ fW FW (FX (x))                                                       ˛



                                                                  [40]
The expression in the first line is bounded by
           ˛                                          ˛
           ˛                                          ˛       ˛   “    “       ””        ˛
           ˛         1                      1         ˛       ˛                          ˛
      sup ˛˛  “      “        ”” −      ` −1       ´ ˛˛ × sup ˛F̂W FW
                                                                    −1
                                                                        F̂X (x) − F̂X (x)˛
      x∈X ˛ fW F −1 F̂X (x)          fW FW (FX (x)) ˛ x∈X
                  W

                                                          1
By a first order Taylor series expansion of                             in FX (x), the fact that fW (w) is bounded from 0 and
                                                   fW (FW
                                                        −1
                                                           (F̂X (x)))
its derivative bounded on W, and Lemma A.3 the first factor is op (N −δ ) for all δ < 1/2 and by Lemma A.3 the
same is true for the second factor, so that the product is op (N −1/2 ). Because fW (w) is bounded from 0 on W,
the expression on the second line has a bound that is proportional to
            ˛   “     “        ””               ` −1           ´          ˛
            ˛      −1                                                     ˛
        sup ˛F̂W FW     F̂X (x) − F̂X (x) − F̂W FW   (FX (x)) + FX (x)˛
       x∈X

We rewrite this as
          ˛    “      “        ””    ` −1         ´ “  “    “       ”    ` −1         ´””˛˛
          ˛        −1                                    −1
      sup ˛F̂W FW       F̂X (x) − F̂W FW  (FX (x)) − FW FW   F̂X (x) − FW FW  (FX (x))    ˛≤
       x∈X
           ˛   “    “        ””    ` −1         ´ “  “    “       ”    ` −1         ´””˛˛
           ˛     −1                                    −1
       sup ˛F̂W FW    F̂X (x) − F̂W FW  (FX (x)) − FW FW   F̂X (x) − FW FW  (FX (x))    ˛×
       x∈X
       1sup |      −1           −1
                                  |    + 4 · 1sup |F −1 (F̂ (x))−F −1 (F (x))|>N −δ
                                              −δ
              x∈X FW (F̂X (x))−FW (FX (x)) ≤N     x∈X W    X      W     X

By Lemma A.7 and the mean value theorem, the final term is op(1) if 1/3 < δ < 1/2. By
         “        ”                 h    “        ”                i
      −1              −1              −1               −1
     FW    F̂X (x) = FW  (FX (x)) + FW     F̂X (x) − FW   (FX (x))
                                              “        ”
                   −1                      −1              −1
and defining w = FW   (FX (x)) and w̃ = FW      F̂X (x) − FW  (FX (x)) we have that the first term on the right
hand side is bounded by
                          ˛                                                ˛
                          ˛                                                ˛        −2/3
               sup        ˛F̂W (w + w̃) − F̂W (w) − (FW (w + w̃) − FW (w))˛ = op (N      )
       w∈W,|w̃|≤N −δ ,w̃+w∈W

by Lemma A.5 with 1/3 < δ < 1/2, η = 2/3, so that we finally conclude that the sum of (B.7) and (B.8) is
op (N −1/2 ). 
Proof of Lemma A.16: The proof involves checking the conditions for Theorem A.2 from IR (given in Appendix
A in the current paper), and simplifying the conclusions from that Theorem to the case at hand.
Define
       h1 (w, x) = fW X (w, x),          and       h2 (w, x) = fW X (w, x) · g(w, x),
                  h2
       n(h) =        ,
                  h1
so that
       ω(x) = 1,
                                    ` −1                ´
          ∂n           h2         g( FW    (FX (x)) , x
              (h) = −        = −       `  −1
                                                          ´,
          ∂h1         (h1 )2     fW X ( F W  (FX (x)) , x
          ∂n        1               1
              (h) =    =       ` −1             ´,
          ∂h2       h1   fW X ( FW (FX (x)) , x
               −1                  ∂               fX (x)
       t(x) = FW  (FX (x)) ,          t(x) =        −1           ,
                                   ∂x        fW (FW    (FX (x)))
                   ` −1            ´
       α1 (x) = −g( FW (FX (x)) , x ,        α2 (x) = 1.
With Ỹi = (Ỹi1 Ỹi2 )0 = (1 Yi )0 , we have
                          ` −1               ´
      α(x)0 ỹ = y − g( FW      (FX (x)) , x .
Applying the results in Theorem A.2, we have
     Z      „                                 «      Z    „         −1                                    «
              Wi − t(Xi )   ∂t                                Wi − FW  (FX (Xi ))        fX (Xi)
          K               +    (Xi ) · u2 , u2 du2 =     K u,                     +      −1
                                                                                                       · u du,
       U2         bN        ∂x                         u             bN             fW (FW (FX (Xi )))

                                                                [41]
Substituting this into the result from Theorem A.2 we get
       √ “ pam           ”
        N θ̂g − g pam

                 N                                  Z                                                         !
           1    X     `      ` −1               ´´         Wi − FW−1
                                                                     (FX (Xi ))        fX (Xi )
       = √             Yi − g FW (FX (Xi )) , Xi ·      K                       +    ` −1             ´ · u, u du
           N bN i=1                                   u            bN             fW F W  (FX (Xi))
                  "                             Z                                                       ! #!
                    `      ` −1              ´´               −1
                                                         W − FW  (FX (X))          fX (X)
               −E Y − g FW (FX (X)) , X ·           K                     +      ` −1           ´ · u, u du
                                                  u            bN             fW F W  (FX (X))
                                     +op (1) .
Adding and subtracting g(Wi , Xi ) in both terms, this is equal to
              N
                 (                      Z                                                            !
         1   X                                  Wi − FW−1
                                                          (FX (Xi))            fX (Xi )
      √            (Yi − g(Wi , Xi )) ·     K                        +      ` −1            ´ · u, u du
        N bN i=1                          u             bN              fW F W    (FX (Xi))
                         "                   Z                                                         ! #)
                                                            −1
                                                    W − FW     (FX (X))            fX (X)
                    −E (Y − g(W, X)) ·          K                        +      ` −1           ´ · u, u du
                                              u              bN             fW F W    (FX (X))
         N
            (                                          Z                                                              !
    1   X     `               ` −1                 ´´           Wi − FW−1
                                                                           (FX (Xi ))          fX (Xi )
+√             g(Wi , Xi ) − g FW (FX (Xi)) , Xi ·        K                           +     ` −1              ´ · u, u du
   N bN i=1                                             u               bN               fW F W    (FX (Xi ))
                 "                                       Z                                                            ! #)
                  `              ` −1                ´´                  −1
                                                                 W − FW     (FX (X))            fX (X)
             −E g(W, X) − g FW (FX (X)) , X ·                K                         +     ` −1             ´ · u, u du
                                                           u              bN              fW F W    (FX (X))
                                     +op (1) .
                   N                        Z                                                              !
            1      X                              Wi − FW −1
                                                             (FX (Xi ))          fX (Xi )
       = √             (Yi − g(Wi , Xi )) ·    K                        +     ` −1              ´ · u2 , u2 du2
            N bN i=1                     u2                bN              fW F W    (FX (Xi ))
          N
             (                                         Z                                                                   !
    1    X     `                  −1                ´          Wi − FW  −1
                                                                           (FX (Xi ))           fX (Xi)
 +√              g(Wi , Xi ) − g(FW (FX (Xi )), Xi ) ·     K                          +     ` −1                ´ · u2 , u2 du2
    N bN i=1                                            u2               bN             fW F W      (FX (Xi ))
        "                                    Z                                                                  !      #)
          `                               ´                    −1
                            −1                          Wi − FW   (FX (X))            fX (X)
    − E g(W, X) − g(FW (FX (X)), X) ·              K                         +     ` −1              ´ · u2 , u2 du2
                                                u2              bN             fW F W     (FX (X))
                                             +op (1) .
Having checked the conditions for Theorem A.2, the second part of the result in the Lemma follows directly from
the second part of the Theorem. 
Proof of Lemma A.17: We prove the result in three parts. First, we show

       1 X “ −1                   ”
          N                             N
                                     1 X ` −1                   ´
             g F̂W (FX (Xi )) , Xi −       g FW (FX (Xi )) , Xi
       N i=1                         N i=1

                  1 X
                     N
                          ` −1                ´ “ −1               −1
                                                                                ”    “       ”
              =         gW FW  (FX (Xi )) , Xi · F̂W (FX (Xi )) − FW  (FX (Xi )) + op N −1/2                     (B.16)
                  N i=1
Second, we will prove that

       1 X
          N
               ` −1                ´ “ −1               −1
                                                                      ”
             gW FW  (FX (Xi )) , Xi · F̂W (FX (Xi )) − FW  (FX (Xi ))
       N i=1
                  ` −1              ´
           1 X gW FW (FX (Xi )) , Xi “                             ”    “      ”
              N
                                         ` −1           ´
       =            ` −1          ´ · F̂W FW  (FX (Xi )) − FX (Xi ) + op N −1/2 .                                (B.17)
           N i=1 fW FW (FX (Xi ))
Third, we will show that
                 ` −1           ´
       1 X gW FW (FX (Xi )) , Xi “                              ”
          N
                                     ` −1           ´
                   ` −1       ´ · F̂W FW  (FX (Xi )) − FX (Xi )
       N i=1 fW FW (FX (Xi ))


                                                         [42]
                       N
                    1 X pam            “      ”
                =         ψW (Wi ) + op N −1/2 .                                                           (B.18)
                    N i=1
Together these three claims, (B.16)-(B.18), imply the result in the Lemma.
First we prove (B.16).
       ˛
       ˛ X  N   “                    ”      N
       ˛1          −1                   1 X ` −1                    ´
       ˛       g F̂W  (FX (Xi )) , Xi −        g FW (FX (Xi )) , Xi
       ˛N                               N
           i=1                             i=1
                                                                                       ˛
                          1 X
                             N
                                   ` −1               ´ “ −1                          ”˛
                                                                          −1           ˛
                        −       gW FW (FX (Xi )) , Xi · F̂W (FX (Xi )) − FW (FX (Xi )) ˛
                          N i=1                                                        ˛
                      ˛ “                  ”   ` −1              ´
                      ˛     −1
                ≤ sup ˛g F̂W   (FX (x)) , x − g FW  (FX (x)) , x
                    x∈X
                        ` −1                ´ “ −1                   −1
                                                                                ”˛
                                                                                 ˛
                   −gW FW     (FX (x)) , x · F̂W     (FX (x)) − FW      (FX (x)) ˛
                          ˛ 2           ˛          ˛                    ˛2
             1            ˛ ∂           ˛
          ≤ · sup ˛˛            g(w, x) ˛ · sup ˛˛F̂W−1
                                                        (q)) − FW −1    ˛
                                                                     (q)˛ .
             2 w∈W,x∈X ∂w     2         ˛
                                           q∈[0,1]
                                                                ˛                   ˛
                                                                ˛ −1                ˛
By Lemma A.3 it follows that for all δ < 1/2, supq∈[0,1] N δ · ˛F̂W           −1
                                                                       (q) − FW  (q)˛ = op(1). In combination with
                ∂2g
the fact that   ∂w 2
                     (w, x)
                    is bounded this implies that
             ˛ 2        ˛          ˛                 ˛2    “      ”
             ˛∂ g       ˛          ˛ −1              ˛
        sup ˛˛ 2 (w, x)˛˛ · sup ˛F̂W           −1
                                        (q) − FW  (q)˛ = op N −1/2 .
      w∈W,x∈X ∂w           q∈[0,1]

This finishes the proof of (B.16).
Next, we prove (B.17).
       ˛
       ˛ X  N
                  ` −1                 ´ “ −1                             ”
       ˛1                                                   −1
       ˛       gW FW    (FX (Xi )) , Xi · F̂W (FX (Xi )) − FW  (FX (Xi ))
       ˛N
           i=1

                                     ` −1                ´                               ˛
                         1 X gW FW (FX (Xi )) , Xi “
                            N
                                                               ` −1           ´         ”˛
                                                                                         ˛
                      +                ` −1             ´ · F̂W FW (FX (Xi )) − FX (Xi ) ˛
                         N i=1 fW FW         (FX (Xi ))                                  ˛
                                  ˛                                                           ˛
                                  ˛            “                ”                “   ` −1  ´ ”˛
                                  ˛                −1      −1        gW (w, x)                ˛
                ≤      sup        ˛gW (w, x) · F̂W (q) − FW (q) +     ` −1 ´ · F̂W FW (q) − q ˛
                  w∈W,x∈X,q∈[0,1] ˛                                fW F W   (q)               ˛
                                                ˛                                               ˛
                                                ˛“               ”                “   ` −1 ´  ”˛
                                                ˛ −1        −1           1                      ˛
                ≤ sup |gW (w, x)| · sup ˛ F̂W (q) − FW (q) +           ` −1 ´ · F̂W FW (q) − q ˛ ,
                  w∈W,x∈X               q∈[0,1] ˛                   fW F W   (q)                ˛
so that Lemma A.6 implies that (B.17) holds.
Finally, let us prove (B.18).
                   ` −1            ´
        1 X gW FW (FX (Xi )) , Xi “                                   ”
            N
                                           ` −1           ´
                     ` −1        ´ · F̂W FW     (FX (Xi )) − FX (Xi )
       N i=1 fW FW (FX (Xi ))

                     N     ` −1               ´      N
                                                                                     !
                  1 X gW FW (FX (Xi )) , Xi        1 X
                =            ` −1            ´ ·       1     −1           − FX (Xi )
                  N i=1 fW FW     (FX (Xi ))      N j=1 Wj ≤FW (FX (Xi ))
                               ` −1               ´
                   1 X X gW FW (FX (Xi )) , Xi “                                ”
                      N N
                = 2              ` −1            ´ · 1F (Wj )≤F (Xi ) − FX (Xi ) .
                  N i=1 j=1 fW FW (FX (Xi))            W       X


This is a two-sample V-statistic. The projection is the sample average of the sum of the expectation over Wj if
                                                                                                       pam
we fix Xi = x (this expectation is zero), and the expectation over Xi if we fix Wj = w, which gives ψW     (w).
Thus,
                 ` −1                ´
        1 X gW FW (FX (Xi )) , Xi “                                     ”                         “       ”
           N                                                                    N
                                             ` −1            ´                1 X pam
                   ` −1            ´ · F̂W FW      (FX (Xi )) − FX (Xi ) =         ψW (Wi ) + op N −1/2 ,
       N i=1 fW FW (FX (Xi ))                                                N i=1


                                                      [43]
which is the claim in (B.18). 
Proof of Lemma A.18: We prove this result in two steps. First we prove
      ˛
      ˛ X   N   “     “        ”    ”       N
      ˛1                               1 X ` −1                      ´
      ˛        g Fw−1 F̂X (Xi ) , Xi −          g Fw (FX (Xi )) , Xi
      ˛N                               N i=1
           i=1
                           ` −1               ´                        ˛
                        gW FW (FX (Xi)) , Xi “                       ”˛   “      ”
                                                                       ˛
                     −       ` −1          ´ · F̂X (Xi ) − FX (Xi ) ˛ = op N −1/2 .                                      (B.19)
                          fw FW (FX (Xi ))                             ˛
Second, we prove
              ` −1              ´
       1 X gW FW (FX (Xi )) , Xi “                    ”                    “      ”
          N                                                 N
                                                         1 X pam
                ` −1          ´ · F̂X (Xi ) − FX (Xi ) =       ψX (Xi) + op N −1/2 .                                     (B.20)
       N i=1 fW FW (FX (Xi ))                            N i=1

Together these two results imply the claim in Lemma A.18.
First we prove (B.19). By a second order Taylor series expansion, using the fact that g(w, x) is at least twice
continuously differentiable,
       ˛
       ˛ X N    “       “         ”     ”        N
       ˛1                                    1 X ` −1                        ´
       ˛      g Fw−1 F̂X (Xi ) , Xi −               g Fw (FX (Xi )) , Xi
       ˛N                                   N i=1
          i=1
                              ` −1                 ´                           ˛
                          gW FW (FX (Xi )) , Xi “                             ”˛
                                                                               ˛
                       −        ` −1             ´ · F̂X (Xi ) − FX (Xi ) ˛
                            fW F W    (FX (Xi ))                               ˛
                     ˛                                                         ` −1               ´                    ˛
                     ˛ “       “        ” ”       ` −1                 ´ gW FW       (FX (x)) , x “                   ”˛
                     ˛     −1                                                                                          ˛
              ≤ sup ˛g FW F̂X (x) , x − g FW (FX (x)) , x −                      ` −1
                                                                                                ´   · F̂X (x) − FX (x) ˛
                 x∈X ˛                                                       fW F W   (FX (x))                         ˛
                             ˛ 2                                 ˛
                             ˛ ∂ g (w, x)               ∂f
                                            gW (w, x) · ∂w  (w) ˛˛     ˛                ˛2       “        ”
                 1           ˛ 2                                       ˛                ˛            −1/2
              ≤       sup ˛ ∂w            −               2
                                                                 ˛ sup ˛F̂X (x) − FX (x)˛ = op N            ,
                 2 w∈W,x∈X ˛ fW (w)              (fW (w))        ˛ x∈X
by Lemma A.3. This finishes the proof of (B.19).
Second we prove (B.20).
                ` −1               ´
       1 X gW FW (FX (Xi )) , Xi “                        ”
         N
                  ` −1           ´ · F̂X (Xi ) − FX (Xi )
      N i=1 fW FW (FX (Xi ))

                          N N    ` −1             ´
                       1 X X gW FW (FX (Xi )) , Xi `                     ´
                  =     2
                                   ` −1
                                                ´   · 1Xj ≤Xi − FX (Xi )
                      N i=1 j=1 fW FW (FX (Xi))
This is a one-sample V-statistic. To obtain the projection we first fix Xi = x and take the expectation over Xj .
                                                                                                  pam
This gives 0 for all x. Second, we fix Xj = x and take the expectation over Xi . This gives ψX        (x) defined
above. This finishes the proof of (B.20), and thus completes the proof of Lemma A.18. 
Proof of Lemma A.19: Adding and subtracting terms we have
       β̂ lc − β lc
                  N                                               N
               1 X ∂ĝ                                         1 X ∂g
           =            (Wi , Xi ) · d(Wi ) · (Xi − m̂(Wi )) −          (Wi , Xi) · d(Wi ) · (Xi − m̂(Wi ))              (B.21)
               N i=1 ∂w                                        N i=1 ∂w
                         N                                              N
                                                                                                                     !
                      1 X ∂ĝ                                        1 X ∂g
              −                (Wi , Xi ) · d(Wi ) · (Xi − m(Wi )) −          (Wi , Xi ) · d(Wi ) · (Xi − m(Wi ))        (B.22)
                      N i=1 ∂w                                       N i=1 ∂w
                         N                                              N
                      1 X ∂ĝ                                        1 X ∂g
                  +            (Wi , Xi ) · d(Wi ) · (Xi − m(Wi )) −          (Wi , Xi ) · d(Wi ) · (Xi − m(Wi ))        (B.23)
                      N i=1 ∂w                                       N i=1 ∂w
                         N                                               N
                      1 X ∂g                                          1 X ∂g
                  +            (Wi , Xi ) · d(Wi ) · (Xi − m̂(Wi )) −          (Wi , Xi ) · d(Wi ) · (Xi − m(Wi ))       (B.24)
                      N i=1 ∂w                                        N i=1 ∂w
                         N
                      1 X ∂g
                  +            (Wi , Xi ) · d(Wi ) · (Xi − m(Wi )) − β lc .                                              (B.25)
                      N i=1 ∂w


                                                               [44]
Because (B.23) is equal to βglc − g lc , (B.24) is equal to βm
                                                             lc
                                                                − glc , and (B.25) is equal to glc − β lc , it follows that it
is sufficient for the proof of Lemma A.19 to show that the sum of (B.21) and (B.22) is op(N −1/2 ). We can write
the sum of (B.21) and (B.22) as
          N                                               N
       1 X ∂ĝ                                         1 X ∂g
                (Wi , Xi ) · d(Wi ) · (Xi − m̂(Wi )) −          (Wi , Xi ) · d(Wi ) · (Xi − m̂(Wi ))
       N i=1 ∂w                                        N i=1 ∂w

                                N                                              N
                                                                                                                                  !
                             1 X ∂ĝ                                        1 X ∂g
                        −             (Wi , Xi ) · d(Wi ) · (Xi − m(Wi )) −          (Wi , Xi ) · d(Wi ) · (Xi − m(Wi ))
                             N i=1 ∂w                                       N i=1 ∂w
                        N            „                                 «
                      1 X              ∂ĝ               ∂g
                   =        d(Wi ) ·       (Wi , Xi ) −     (Wi , Xi ) · (m(Wi ) − m̂(Wi ))
                     N i=1             ∂w                ∂w
                                            ˛                         ˛
                                            ˛ ∂ĝ           ∂g        ˛                              `    ´    `    ´
                   ≤ sup |d(w)| · sup ˛˛          (w, x) −     (x, x)˛˛ · sup |m̂(w) − m(w)| = C · op N −η · op N −η ,
                     w∈W         w∈W,x∈X ∂w                ∂w             w∈W

for some η > 1/4, and so this expression is op(N −1/2 ). 
Proof of Lemma A.20: The proof consists of checking the conditions for Theorem A.1, and specializing the
result in Theorem A.1 to the case in the Lemma.
We apply Theorem A.1 with z = (z1 z2 )0 = (w x)0 , Zi = (Wi Xi )0 , ω(z) = d(z1 ) · (z„2 − m(z
                                                                                           « 1 )) = d(w) · (x − m(w))
                                                                                         1
(so that ω(z) goes smoothly to zero on the boundary of Z), L = 2, and λ =                    . Then {κ : κ ≤ λ} =
                                                                                         0
              „     « „    «ff
                  0       1
{κ0 , κ1 } =          ,         , and
                  0       0
                      0 (κ )         1
                        h1 0 (w, x)
                      B (κ0 )        C
                      B h2 (w, x) C
        h[λ] (w, x) = B (κ   )       C,
                      @ h1 1 (w, x) A
                         (κ1 )
                        h2 (w, x)

with
         (κ0 )
       h1        (w, x) = fW X (w, x)
         (κ0 )
       h2   (w, x) = fW X (w, x) · g(w, x)
        (κ )          ∂
       h1 1 (w, x) =     fW X (w, x)
                     ∂w
       (κ )                     ∂                                 ∂
      h2 1 (w, x) = g(w, x) ·      fW X (w, x) + fW X (w, , x) ·    g(w, x).
                               ∂w                                ∂w
The functional of interest is
        “    ”   ∂
                          (κ )
                         h 1
                                  (κ )
                                 h 0 · h1 1
                                           (κ )
       n h[λ] =    g(·) = 2(κ ) − 2“       ” 2
                ∂w       h1 0         (κ )
                                     h1 0

The derivatives of this functional are
            ∂      “    ”       (κ )
                              h 1
                                        (κ )
                                       h 0 · h1 1
                                                 (κ )

         (κ )
                  n h[λ] = − “ 2 ”2 + 2 2“       ”3
       ∂h1 0                   (κ )
                              h1 0
                                            (κ )
                                           h1 0

                                         ∂                          ∂                                              ∂
                        fW X (w, x) ·   ∂w
                                           g(w, x)   + g(w, x) ·      f
                                                                   ∂w W X
                                                                          (w, x)        g(w, x) · fW X (w, x) ·        f
                                                                                                                  ∂w W X
                                                                                                                         (w, x)
                   =−                                        2                     +2                                3
                                             (fW X (w, x))                                         (fW X (w, x))
                         ∂                           ∂
                        ∂w
                           g(w, x)        g(w, x) · ∂w fW X (w, x)
                   =−                 +
                        fW X (w, x)           (fW X (w, x))2

                “     ”         (κ )         ∂
            ∂     [λ]         h1 1          ∂w fW X (w, x)
              n  h      = − “       ” 2 = −
         (κ )
       ∂h2 0                   (κ )
                             h1 0           (fW X (w, x))2


                                                                    [45]
          ∂      “     ”         (κ )
                               h2 0         g(w, x) · fW X (w, x)      g(w, x)
                   [λ]
         (κ1 )
               n  h      = − “       ”2 = −                  2    =−
       ∂h1                      (κ )           (fW X (w, x))         f W X (w, x)
                              h1 0


          ∂       “    ”               1               1
         (κ )
                 n h[λ] =             (κ0 )
                                              =               .
       ∂h2 1                      h1              fW X (w, x)

                                                                                                                         !
                                                                              ∂                         ∂
                                                                             ∂w
                                                                                g(w, x)       g(w, x) ·   f
                                                                                                       ∂w W X
                                                                                                                (w, x)
       ακ0 ,1 (w, x) = d(w) · (x − m(w)) · fW (w, x) ·                 −                  +
                                                                           fW X (w, x)             (fW X (w, x))2
                                                                                                     !
                                                                                ∂
                                                         ∂           g(w, x) · ∂w fW X (w, x)
                 = d(w) · (x − m(w)) ·                −    g(w, x) +
                                                        ∂w                 fW X (w, x)

                                                                                               !
                                                                            ∂                                                 ∂
                                                                              fW X (w, x)                                    ∂w fW X (w, x)
       ακ0 ,2 (w, x) = d(w) · (x − m(w)) · fW X (w, x) ·                 − ∂w                      = −d(w) · (x − m(w)) ·
                                                                           (fW X (w, x))2                                     fW X (w, x)

                                                        „              «
                                                            g(w, x)
       ακ1 ,1 (w, x) = d(w) · (x − m(w)) · fW X (w, x) · −               = −d(w) · (x − m(w)) · g(w, x)
                                                           fW X (w, x)


                                                                             1
       ακ1 ,2 (w, x) = d(w) · (x − m(w)) · fW X (w, x) ·                            = d(w) · (x − m(w))
                                                                        fW X (w, x)

                                                                                                                                     !
                                                                                                               ∂
              |κ0 |    (κ )                                                             ∂           g(w, x) · ∂w fW X (w, x)
       (−1)           ακ00,1 (w, x)   = ακ0 ,1 (w, x) = d(w) · (x − m(w)) ·          −    g(w, x) +
                                                                                       ∂w                 fW X (w, x)

                                                                                       ∂
                       (κ )                                                              f
                                                                                      ∂w W X
                                                                                             (w, x)
       (−1)|κ0 | ακ00,2 (w, x) = ακ0 ,2 (w, x) = −d(w) · (x − m(w)) ·
                                                                                          fW X (w, x)

                                              „                             «
                       (κ )                 ∂
       (−1)|κ1 | ακ11,1 (w, x) =                d(w) · (x − m(w)) · g(w, x)
                                           ∂w
                                                     ∂                                   ∂                          ∂
                 = d(w) · (x − m(w)) ·                 g(w, x) + g(w, x) · (x − m(w)) ·    d(w) − g(w, x) · d(w) ·    m(w)
                                                    ∂w                                  ∂w                         ∂w

                       (κ )                    ∂                                      ∂                ∂
       (−1)|κ1 | ακ11,2 (w, x) = −               (d(w) · (x − m(w))) = −(x − m(w)) ·    d(w) + d(w) ·    m(w)
                                              ∂w                                     ∂w               ∂w
Then
       X                 2
                         X
             (−1)|κ|            (κ)
                               ακm  (w, x)ỹim
       κ≤λ               m=1

                                      (κ )                            (κ )                         (κ )                       (κ )
                 = (−1)|κ0 | ακ00,1 (w, x) + Yi · (−1)|κ0 | ακ00,2 (w, x) + (−1)|κ1 | ακ11,1 (w, x) + Yi · (−1)|κ1 | ακ11,2 (w, x)
                                                                                           !
                                                                           ∂
                                                ∂              g(w, x) · ∂w  fW X (w, x)
                 = d(w) · (x − m(w)) · −           g(w, x) +
                                              ∂w                       fW X (w, x)
                                                                   ∂
                                                                     f
                                                                  ∂w W X
                                                                         (w, x)
                              −Yi · d(w) · (x − m(w)) ·
                                                        fW X (w, x)
                                                    ∂                                   ∂                          ∂
                              +d(w) · (x − m(w)) ·    g(w, x) + g(w, x) · (x − m(w)) ·    d(w) − g(w, x) · d(w) ·    m(w)
                                                   ∂w                                  ∂w                         ∂w

                                                                         [46]
                                „                                       «
                                                ∂                ∂
                           +Yi · −(x − m(w)) ·    d(w) + d(w) ·    m(w)
                                               ∂w               ∂w
                                                                                                                          !
                                   ∂
                                     f
                                  ∂w W X
                                         (W, X)                                            ∂                  ∂
        = − (Y − g(W, X))·                           · d(w) · (X − m(W )) + (X − m(W )) ·    d(W ) − d(W ) ·    m(W )         .
                                   fW X (W, X)                                            ∂w                 ∂w
Since
         "                                                                                                        !#
                                  ∂
                                 ∂w fW X (w, x)                                         ∂                ∂
        E − (y − g(w, x)) ·                       · d(w) · (x − m(w)) + (x − m(w)) ·      d(w) − d(w) ·    m(w)        = 0,
                                   fW X (w, x)                                         ∂w               ∂w

it follows that
               0                                     1
             N
         1 X @X            X2   h                   i
        √          (−1)|κ|     E α(κ)
                                  κm (Wi , Xi )Ỹim
                                                     A = 0,
          N i=1 κ≤λ        m=1


and therefore
                                 0                                    1
                               N                2                              N
        √       lc    lc   1 X @X          |κ|
                                               X    (κ)                    1 X lc
            N (β̂ − β ) = √           (−1)         ακm (Wi , Xi )Ỹim A = √       ψ (Yi , Wi , Xi ).
                            N i=1 κ≤λ          m=1                          N i=1

where
                                                                                                                     !
                                        ∂
                                       ∂w fW X (w, x)                                         ∂                ∂
 ψlc (y, w, x) = − (y − g(w, x))·                       · d(w) · (x − m(w)) + (x − m(w)) ·      d(w) − d(w) ·    m(w) .
                                        fW X (w, x)                                          ∂w               ∂w

.
Proof of Lemma A.21: We start with the inequality
                                          „     ˛                    ˛«2
          ˛                             ˛       ˛b                   ˛
          ˛        “                 ”2 ˛   sup ˛ f W (w) −  f W  (w)˛
          ˛ 1                           ˛  w∈W
      sup ˛          fbW (w) − fW (w) ˛ ≤              ˛         ˛       .
     w∈W ˛ fbW (w)                      ˛              ˛         ˛
                                                   inf ˛fbW (w)˛
                                                            w∈W

Under the stated restriction on δ the bandwidth sequence satisfies

         N 1/4 1/2
        p        bN → ∞,            N 1/4 bsN → 0,
          ln(N )

which, by Lemma A.11, implies
      „     ˛                ˛«2     “      ”
            ˛                ˛
        sup ˛fbW (w) − fW (w)˛   = op N −1/2 .
          w∈W
                                                                                         ˛       ˛
                                                                                         ˛       ˛
Now observe that the the denominator is bounded away from zero since, by the TI, we have ˛fbW (w)˛+|fW (w)| ≥
˛                ˛                    ˛      ˛         ˛                 ˛
˛b               ˛                    ˛      ˛         ˛                 ˛
˛fW (w) − fW (w)˛ and therefore inf ˛fbW (w)˛ ≥ sup ˛fbW (w) − fW (w)˛ − inf |fW (w)| ≥ inf |fW (w)| −
                                w∈W               w∈W                        w∈W               w∈W
    ˛                 ˛
    ˛                 ˛
sup ˛fbW (w) − fW (w)˛ . By Assumption 3.1 inf |fW (w)| is bounded away from zero, with the result then
w∈W                                                   w∈W
following. 
Proof of Lemma A.22:We start with the inequality
                                                                  ˛                ˛       ˛                ˛
            ˛                                              ˛      ˛                ˛       ˛                ˛
            ˛        “                ” “                ” ˛  sup ˛bh1 (w) − h1 (w)˛ × sup ˛bh2 (w) − h2 (w)˛
            ˛ 1        b                                   ˛  w∈W                      w∈W
        sup ˛          h1 (w) − h1 (w) b  h2 (w) − h2 (w) ˛ ≤                      ˛        ˛                 .
        w∈W ˛ b                                            ˛                       ˛        ˛
              h2 (w)                                                           inf ˛bh (W )˛ 2   i
                                                                                   w∈W

The remainder of the proof is along the lines of that to Lemma A.21. 




                                                              [47]
Proof of Lemma A.23: Let h (w) = (h1 (w) , h2 (w))0 = (m(w) · fW (w) , fW (w))0 , then
                N
                                                             !
              1 X                               b
                                                h1,nip (Wi )
     β̂lc,m =     gW (Wi , Xi ) · d(Wi ) · Xi −
              N                                 b
                                                h2,nip (Wi )
                             i=1
                           N
                        1 X
                      =       gW (Wi , Xi ) · d(Wi ) · (Xi − m(Wi ))                                                     (B.26)
                        N i=1
                             N
                                                                                      !
                          1 X                               b
                                                            h1,nip (Wi )   h1 (Wi )
                      −         gW (Wi , Xi ) · d(Wi ) ·                 −                .                              (B.27)
                          N i=1                             b
                                                            h2,nip (Wi )   h2 (Wi )

Expanding the ratio4 in (B.27) yields
              N
                                                                                !
           1 X                                    h1 (Wi )   b
                                                             h1,nip (Wi )
                 gW (Wi , Xi ) · d(Wi ) ·                  −
           N i=1                                  h2 (Wi )   b
                                                             h2,nip (Wi )

                   1 X
                      N
                                                     1     “                                   ”
            =−           gW (Wi , Xi ) · d(Wi ) ·           bh1,nip (Wi ) − m(Wi )b
                                                                                  h2,nip (Wi )                           (B.28)
                   N i=1                          fW (Wi )

                1 X
                   N
                                                     h1 (Wi )         “                          ”2
            −         gW (Wi , Xi ) · d(Wi ) ·                          b
                                                                        h 2,nip (Wi ) − h2 (Wi )                         (B.29)
                N i=1                          h2 (Wi )2 b
                                                         h2,nip (Wi )
                1 X
                   N
                                                    h1 (Wi )         “                        ”“                        ”
            −         gW (Wi , Xi ) · d(Wi ) ·                        bh1,nip (Wi ) − h1 (Wi ) b h2,nip (Wi ) − h2 (Wi ) .
                N i=1                          h2 (Wi ) b
                                                        h2,nip (Wi )
                                                                                                                          (B.30)

First consider (B.29). By Lemma A.12,
        ˛                                                                                   ˛
        ˛ X N                                                   “                        ”2 ˛
        ˛1                                    h1 (Wi )           b                          ˛
        ˛      gW (Wi , Xi ) · d(Wi ) ·                           h2,nip (Wi ) − h2 (Wi ) ˛
        ˛N
           i=1                          h2 (Wi )2 b
                                                  h2,nip (Wi )                              ˛
                  ˛                                    ˛     ˛                                   ˛
                  ˛ 1                                  ˛     ˛           “                    ”2 ˛
                  ˛                                    ˛     ˛ 1           b                     ˛
        ≤ sup ˛             gW (w, x) · d(w) · m(w)˛ sup ˛                 fW (w) − fW (w) ˛
          w∈W,x∈X fW (w)                                 w∈W ˛ fbW (w)                           ˛
             “      ”
        = op N −1/2

if the NIP estimator is uniformly op (N −1/4“) which” holds if 4s
                                                                1
                                                                  < δ < 81 . An analogous application of Lemma
                                               −1/2
A.12 can be used to show that (B.30) is op N          under the same condition.
Now consider (B.28) that we express as the sum of a variance and a bias term

     1 X
        N
                                    1     “                 h            i        “                 h             i””
 −         gW (Wi , Xi )·d(Wi )·            b
                                            h1,nip (Wi ) − E b
                                                             h1,nip (Wi ) − m(Wi ) bh2,nip (Wi ) − E b
                                                                                                     h2,nip (Wi )     +
     N i=1                       fW (Wi )

           1 X
              N
                                             1     “             h            i        “            h             i””
                 gW (Wi , Xi ) · d(Wi ) ·            h1 (Wi ) − E b
                                                                  h1,nip (Wi ) − m(Wi ) h2 (Wi ) − E b
                                                                                                     h2,nip (Wi )
           N i=1                          fW (Wi )

The bias term is Op (N −1/2 ) if δ >            1
                                                2s .   After substitution of the NIP estimator the variance term is
                  N                                    s−1 X
               1 X                               1     X     1
           −         gW (Wi , Xi ) · d(Wi ) ·
               N i=1                          fW (Wi ) j=0   µ!
                                                                 |µ|=j
           “                 h                  i        “                      h                  i”                          ”
                (µ)             (µ)                         (µ)                    (µ)
               ĥ1,N W    − E ĥ1,N W (rb (Wi )) − m(Wi ) ĥ2,N W (rb (Wi )) − E ĥ2,N W (rb (Wi )) (rb (Wi ))(Wi − rb (Wi ))µ

     4
         The ratio expansion is of the form
           a
           b    a    1“     a ”      a b           a
             − =        a− b
                        b     b +       (b − b)2 − (ba − a)(b
                                                            b − b).
           b
           b    b    b      b       b2b
                                      b           bb
                                                   b



                                                                         [48]
We consider separately

                                               1 “ (µ)                  h                  i”
        N                                s−1 X
     1 X                           1     X                                 (µ)
 −         gW (Wi , Xi)·d(Wi )·                   ĥ1,N W (rb (Wi )) − E ĥ1,N W (rb (Wi )) (Wi −rb (Wi ))µ (B.31)
     N i=1                      fW (Wi ) j=0   µ!
                                                             |µ|=j

and

                               m(Wi ) X X 1 “ (µ)                   h                  i”
     N                                 s−1
  1 X                                                                  (µ)
        gW (Wi , Xi )·d(Wi )·                 ĥ2,N W (rb (Wi )) − E ĥ2,N W (rb (Wi )) (Wi −rb (Wi ))µ (B.32)
  N i=1                       fW (Wi ) j=0 µ!
                                                             |µ|=j


We show that (B.31) is asymptotically equivalent to an average. The same method shows that (B.32) is also
asymptotically equivalent to an average, but we omit the details. The expression (B.31) is a linear combination
of terms

                         1 X
                            N
                                                           1     “                       h                  i”
                                                                     (µ)                    (µ)
           Dµ = −              gW (Wi , Xi ) · d(Wi ) ·            ĥ1,N W (rb (Wi )) − E ĥ1,N W (rb (Wi )) (Wi − rb (Wi ))µ =
                         N i=1                          fW (Wi )

                  N   N
               1 XX
           −             aN,µ (Wi , Xi , Xj , Wj )
               N i=1 j=1
with
                                                                                           „                    «
                                              gW (Wi , Xi ) d(Wi )         1                   Wj − rbN (Wi )
           aN,µ (Wi , Xi , Xj , Wj ) =                                    1+|µ|
                                                                                Xj K (µ)                            −
                                                  fW (Wi )               bN                         bN
               "                    „                    «#!
                     1                  W − rbN (Wi )
           E        1+|µ|
                          XK (µ)                                (Wi − rbN (Wi ))µ
                   bN                       bN
Therefore Dµ is a V-statistic with a kernel that depends on N so that the usual projection theorem does not apply
directly. Instead we derive the projection directly. First we bound the second moments of aN,µ (Wi , Xi , Xj , Wj ).
For j 6= i we have
                                                                "          „                «2 #
          ˆ                       2˜   supw∈W |w − rb (w)|2|µ|     2   (µ)   Wj − rbN (Wi )
        E aN,µ (Wi , Xi, Xj , Wj ) ≤ C           2|µ|+2
                                                               E Xj K                            ≤
                                               b                                  bN
                                                                     N
                    "        „                    «2 #
           C                     Wj − rbN (Wi )
               E K (µ)
           b2N                        bN
because the conditional variance of X given W is bounded. Because given Wi = w̃
        "       „                «2         # Z         „              «2
            (µ)   Wj − rbN (Wi )                          w − rbN (w̃)
      E K                           |Wi = w̃ =    K (µ)                   fW (w)dw
                       bN                       W             bN

we have by a change of variables to t = (w − rbN (w̃))/bN with Jacobian bN and the boundedness of K (µ)(t) and
fW (w) that this integral is bounded by CbN and we conclude
        ˆ                        ˜
      E aN,µ (Wi , Xi, Xj , Wj )2 = O(b−1
                                       N )

For j = i we have
                                                         "                                       „                      «2                           #
       ˆ                                2˜        1     gW (Wi , Xi )2 d(Wi )2 2 (µ)                 Wi − rbN (Wi )                             2µ
     E aN,µ (Wi , Xi , Xi, Wi )              = 2+2|µ| E                       Xi K                                           (Wi − rbN (Wi ))            +
                                              bN             fW (Wi )2                                    bN
                         "                        »         „               «–2                     #
                1       gW (Wi , Xi)2 d(Wi )2           (µ)   W − rbN (Wi )                      2µ
                    E                          E XK                             (Wi − rbN (Wi ))      −
             2+2|µ|
            bN               fW (Wi )2                            bN
                     »                                  „                « »          „                «–                      –
              2        gW (Wi , Xi )2 d(Wi )2       (µ)   Wi − rbN (Wi )          (µ)   W − rbN (Wi )                       2µ
            2+2|µ|
                   E                  2       X i K                       E  XK                           (Wi − rb N (Wi ))
           bN               fW (Wi )                           bN                           bN



                                                                          [49]
The first term on the right hand side is bounded by
             "     „                «2 #     Z          „             «2
        C      (µ)   Wi − rbN (Wi )        C        (µ)   w − rbN (w)
           E K                           = 2      K                      fW (w)dw+
       b2N                bN               bN WI              bN
                                                             bN

              Z               „                 «2
        C                         w − rbN (w)
                      K (µ)                          fW (w)dw
        b2N   W\WI                    bN
                 bN


with WIbN the internal set of the support. Because the argument of K (µ) is 0 on the interior set, the first integral
is obviously O(b−2
                 N ). The second integral is
           Z wl +bN       „           «2                 Z wu         „              «2
        C             (µ)   w − wl                    C           (µ)   w − wu
                    K              − 1   f W (w)dw +            K                + 1    fW (w)dw
        b2N wl                bN                     b2N wu −bN            bN

Because the kernel has support [−1, 1] and its derivatives op to order µ are bounded so that
            „           «2                                „            «2
              w − wl                                        w − wu
      K (µ)          − 1 ≤ C1wl ≤w≤wl +2bN          K (µ)          + 1 ≤ C1wu −2bN ≤w≤wu
                bN                                            bN

so that the second integral by the boundedness of fW is O(b−1       N ). The second term on the right hand side is
bounded by
     Z „Z           „              «           «2                    Z Z        „              «2
   C            (µ)   w − rbN (w̃)                               C          (µ)   w − rbN (w̃)
              K                      f W (w)dw    f W ( w̃)dw̃ ≤          K                       fW (w)fW (w̃)dwdw̃
  b2N W    W              bN                                     b2N W W              bN

This integral is O(b−1
                     N ) by a change of variables with Jacobian bN in the inner integral. The third term on the
right hand side is bounded by
           ˛Z        „               «Z        „              «                       ˛
        C ˛˛     (µ)   w̃ − rbN (w̃)       (µ)   w − rbN (w̃)                         ˛
                                                                                      ˛ = O(b−1
               K                         K                      f   (w)dwf   ( w̃)dw̃        N )
       b2N ˛ W                                                                        ˛
                                                                  W        W
                            bN         W             bN
by a change of variables in the inner integral. We conclude
        ˆ                        ˜
       E aN,µ (Wi , Xi, Xi, Wi )2 = O(b−2
                                        N )

The next step is to express Dµ as an average. Define
                               1
        cN,µ (Xj , Wj ) =     1+|µ|
                                      ·
                             bN
  Z Z                         „         „              «    »       „             «–«
            gW (w, x) d(x)                Wj − rbN (w)                W − rbN (w)
                               Xj K (µ)                  − E XK (µ)                   (w −rbN w))µ fW X (w, x)dwdx
   X    W      fW (w)                         bN                         bN
and
                     N
                  1 X
        Eµ = −          cN,µ (Xj , Wj )
                  N j=1

Then
                                                       „                «
                      N (N − 1)                            N (N − 1)
        Dµ − Eµ =               (Dµ,1 − Eµ ) +                       − 1  Eµ + Dµ,2
                         N2                                   N2
with
                             N
                             X                                                           N
                       1                                                             1 X
        Dµ,1 = −               aN,µ (Wi , Xi , Xj , Wj )                 Dµ,2 = −           aN,µ (Wi , Xi , Xi , Wi )
                   N (N − 1)                                                        N 2 i=1
                                   i6=j=1

Now
                                     XN
                             1
        Dµ,1 − Eµ = −                     (aN,µ (Wi , Xi , Xj , Wj ) − cN,µ (Xj , Wj ))
                         N (N − 1) i6=j=1


                                                                  [50]
with

         E[(aN,µ (Wi , Xi , Xj , Wj ) − cN,µ (Xj , Wj ))(aN,µ (Wi0 , Xi0 , Xj 0 , Wj 0 ) − cN,µ (Xj 0 , Wj 0 ))] = 0

if (i) i 6= i0 , j 6= j 0 , (ii) i = i0 , j 6= j 0 (iii) i 6= i0 , j = j 0 , because

          E[aN,µ (Wi , Xi , Xj , Wj )|Wi , Xi ]       =     0
                   E[aN,µ (Wi , Xi , Xj , Wj )]       =     0
         E[aN,µ (Wi , Xi , Xj , Wj )|Xj , Wj ]        =     cN,µ (Wj , Xj )
                              E[cN,µ (Wj , Xj )]      =     0

Therefore

         E[(Dµ − Eµ )2 ] =
             1      XX
                         E[(aN,µ (Wi , Xi, Xj , Wj ) − cN,µ (Xj , Wj ))(aN,µ (Wi0 , Xi0 , Xj 0 , Wj 0 ) − cN,µ (Xj 0 , Wj 0 ))] =
       N 2 (N − 1)2  0 0i6=j i 6=j

              1      X
           2       2
                         E[(aN,µ (Wi , Xi , Xj , Wj ) − cN,µ (Xj , Wj ))2 ] =
          N (N − 1) i6=j
Because

         E[(aN,µ (Wi , Xi , Xj , Wj ) − cN,µ (Xj , Wj ))2 ] = E[(aN,µ (Wi , Xi , Xj , Wj )2 ] − E[cN,µ (Xj , Wj ))2 ] ≤

         E[(aN,µ (Wi , Xi , Xj , Wj )2 ] = O(b−1
                                              N )

we have

         E[(Dµ − Eµ )2 ] = O(N −2 b−1
                                   N )

so that
          N (N − 1)                          −1/2
                    (Dµ,1 − Eµ ) = Op (N −1 bN )
             N2
Also

         E[cN,µ (Xj , Wj )2 ] ≤
                    "„Z Z                               „              «                                 «2 #
             1                 gW (w, x) d(x)       (µ)   Wj − rbN (w)                µ
           2+2|µ|
                  E                           X j K                      (w − rbN w))   f WX  (w, x)dwdx      ≤
         bN            X W        fW (w)                      bN
                    "Z Z                                „              «2                                  #
             1               gW (w, x)2 d(x)2 2 (µ) Wj − rbN (w)                        2µ
                  E                           X j K                       (w −  rbN w))    f WX (w, x)dwdx    ≤
         bN
           2+2|µ|
                      X W        fW (w)2                       bN
              Z Z Z           „              «2
          C               (µ)   w̃ − rbN (w)
                       K                         fW X (w, x)dwdxfW (w̃)dw̃ = O(b−1N )
         b2N W X W                   bN
by a change of variables in the outer integral, so that
       „               «
         N (N − 1)                       −1/2
                   −  1  Eµ = Op (N −1 bN )
            N2
Finally
                         1                                  1p
         E[|Dµ,2|] ≤       E[|aN,µ (Wi , Xi , Xi , Wi )|] ≤   E[aN,µ (Wi , Xi , Xi , Wi )2 ] = O(N −1 b−1
                                                                                                       N )
                         N                                  N
so that

         Dµ,2 = Op (N −1 b−1
                          N )

Therefore if δ < 1/2 then

         Dµ = Eµ + op(N −1/2 )


                                                                        [51]
Under the same condition (B.32) is a linear combination of terms

                1 X gW (Wi , Xi ) d(Wi )m(Wi ) “ (µ)                  h                  i”
                   N
                                                                         (µ)
       Fµ =                                     ĥ2,N W (rb (Wi )) − E ĥ2,N W (rb (Wi )) (Wi − rb (Wi ))µ =
                N i=1        fW (Wi )

          N N
       1 XX
                 eN,µ (Wi , Xi, Wj )
       N i=1 j=1
with
                                                                                       „                    «
                                          gW (Wi , Xi ) d(Wi )m(Wi )      1                Wj − rbN (Wi )
       eN,µ (Wi , Xi , Wj ) =                                            1+|µ|
                                                                               K (µ)                            −
                                                   fW (Wi )             bN                      bN
           "                     „                   «#!
                1          (µ)       W − rbN (Wi )
       E       1+|µ|
                       K                                   (Wi − rbN (Wi ))µ
               bN                        bN
such that

       Fµ = Gµ + op (N −1/2 )

with
                       N
                    1 X
       Gµ =               fN,µ (Wj )
                    N i=1

and
                                 1
       fN,µ (Wj ) =         1+|µ|
                                      ·
                           bN
 Z Z                         „       „              «   »      „             «–«
        gW (w, x) d(x)m(w)       (µ)   Wj − rbN (w)        (µ)   W − rbN (w)
                               K                      −E K                       (w−rbN w))µ fW X (w, x)dwdx
  X W          f W (w)                     bN                       bN

The final step is to show that
                        N                         N
                     1 X                       1 X
       E0 = −              cN,µ (Xj , Wj ) = −       (ζj − E[ζj ]) + op (N −1/2 )
                     N j=1                     N j=1

with

       ζj = Xj E[gW (Wj , X)d(X)|Wj ]

where the expectation is over the conditional distribution of X given W , and
                   N                       N
                1 X                     1 X
       G0 =           cN,µ (Xj , Wj ) =       (ξj − E[ξj ]) + op (N −1/2 )
                N j=1                   N j=1

with

       ξj = m(Wj )E[gW (Wj , X)d(X)|Wj ]

and

       Eµ = op (N −1/2 )                                    Gµ = op(N −1/2 )

for |µ| ≥ 1. We only consider E0 and Eµ . The proof for G0 and Gµ is analogous. Define
                       Z Z                           „              «
                  1          gW (w, x) d(x)      (µ)   Wj − rbN (w)
        ψN,µ,j = 1+|µ|                      Xj K                      (w − rbN w))µ fW X (w, x)dwdx
                bN      X W     f W (w)                    bN


so that cN,µ (Xj , Wj ) = ψN,µ,j − E[ψN,µ,j ]. Now

       ψN,0,j = ψN,0,j,0 + ψN,0,j,1


                                                                       [52]
with
                             Z Z      wu −bN                          „            «
                         1                      gW (w, x) d(x)            Wj − w
       ψN,0,i,0 =                                              Xj K                    fW X (w, x)dwdx
                        bN   X    wl +bN           fW (w)                  bN

and
                             Z Z      wl +bN                   „         «
                        1                 gW (w, x) d(x)         Wj − wl
       ψN,0,j,1      =                                    Xj K             fW X (w, x)dwdx+
                       bN    X    wl          fW (w)               bN
               Z Z    wu                               „         «
           1                 gW   (w, x) d(x)            Wj − wu
                                              Xj K (µ)             fW X (w, x)dwdx
          bN   X   wu −bn         fW (w)                   bN
so that
                        N                                 N
                     1 X                               1 X
       E0 = −              (ψN,0,j,0 − E[ψN,0,j,0 ]) −       (ψN,0,j,1 − E[ψN,0,j,1 ])
                     N j=1                             N j=1

Obviously
        2                                                                          !2 3
               N                                 N
            1 X                               1 X                                     5 ≤ 1 E[(ψN,0,j,0 − ζj )2 ]
       E4 −       (ψN,0,j,0 − E[ψN,0,j,0 ]) +       (ζj − E[ζj ])
            N i=1                             N j=1                                       N

By a change of variables to t = (Wj − w)/bN with Jacobian bN
                 Z Z 1
                                                gW (Wj − bN t, x) d(x)
      ψN,0,j,0 =        1 Wj −wu         Wj −wl                        Xj K (t) fW X (Wj − bN t, x)dtdx
                  X −1
                         1+   bN  ≤t≤−1+  bN       fW (Wj − bN t)

so that
                              Z Z       1
       |ψN,0,j,0 − ζi | ≤                   1    Wj −wu       W −wl
                                            1+    bN    ≤t≤−1+ jb
                                  X    −1                        N
       ˛                                                                                      ˛
       ˛ gW (Wj − bN t, x) d(x)                              gW (Wj , x) d(x)                 ˛
       ˛                         f     (W      − b  t, x) −                   f     (W   , x) ˛ |Xj ||K (t) |dtdx+
       ˛     fW (Wj − bN t)
                                   W X     j      N
                                                                fW (Wj )
                                                                                W X    j      ˛
       Z ˛                                   ˛         Z 1 ˛                                   ˛
          ˛ gW (Wj , x) d(x)                 ˛              ˛                                  ˛
          ˛                  f     (W   , x) ˛ dx|Xj |      ˛1 Wj −wu                          ˛
                                                                                 Wj −wl − 1 |K (t) |dt+
          ˛    fW (Wj )
                               W X    j      ˛              ˛ 1+ b      ≤t≤−1+ b               ˛
          X                                                   −1            N                N

By the mean value theorem the first term on the right hand side is bN |Xj |p(Wj ) with p(Wj ) a (generic) bounded
function of Wj . The second term on the right hand side is |Xj |p(Wj )(1 − Pr(wl + 2bN ≤ Wj ≤ wu − 2bN )).
Therefore

       |ψN,0,j,0 − ζi | ≤ |Xj |p(Wj )(bN + (1 − Pr(wl + 2bN ≤ Wj ≤ wu − 2bN )))

so that

       E[(ψN,0,j,0 − ζj )2 ] = O(bN )

and
       ˛                                                      ˛
       ˛    N                                 N               ˛
       ˛ 1 X                               1 X                ˛
       ˛−      (ψN,0,j,0 − E[ψN,0,j,0 ]) +       (ζj − E[ζj ])˛ = op (N −1/2 )
       ˛ N                                 N j=1              ˛
           i=1


if δ < 21 . For ψN,0,j,1 we consider the first term on the right hand side
        ˛ „             «       Z wl +bN Z                                   ˛
        ˛                                                                    ˛
        ˛K Wj − wl Xj 1                      gW (w, x) d(x)
                                                            fW X (w, x)dxdw ˛˛ ≤ C|Xj |1wl ≤Wj ≤wl +bN
        ˛        bN          bN wl               f W (w)
                                           X

For the other term on the right hand side we get a similar bound and we conclude
          2
       E[ψN,0,j,1 ] = O(bN )



                                                                      [53]
so that if δ < 12
       ˛                                 ˛
       ˛ X   N                           ˛
       ˛1                                ˛
       ˛        (ψN,0,j,1 − E[ψN,0,j,1 ])˛ = op (N −1/2 )
       ˛N                                ˛
            j=1

Finally if µ ≥ 1
                                Z Z    wl +bN                             „             «
                          1                     gW (w, x) d(x)                Wj − wl
         ψN,µ,j =       1+|µ|
                                                               Xj K (µ)                     (w − wl )µ fW X (w, x)dwdx+
                    bN            X   wl           fW (w)                       bN
                  Z Z wu                                     „             «
            1                     gW (w, x) d(x)                 Wj − wu
          1+|µ|
                                                 Xj K (µ)                      (w − wu )µ fW X (w, x)dwdx
          bN        X    wu −bN      fW (w)                        bN
The first term on the right hand side is bounded by
       ˛     „          «˛         Z Z wl +bN ˛                             ˛
       ˛ (µ) Wj − wl ˛                        ˛ gW (w, x) d(x)              ˛
       ˛K                ˛ |Xj | 1            ˛                f     (w, x) ˛ dwdx ≤ C|Xj |1w ≤W ≤w +b
       ˛         bN      ˛      bN X wl       ˛    fW (w)
                                                                 W X        ˛                l  j  l   N



so that
            2
         E[ψN,µ,j ] = O(bN )

and therefore
                    N
                    X
         Eµ = −       (ψN,µ,j − E[ψN,µ,j ]) = op (N −1/2 )
                    j=1


if δ < 12 . 
Proof of Theorem A.3: Because the class of ‘doubly averaged’ estimators has not been considered previously,
we provide a somewhat detailed proof. The proof consists of four steps. In the first we approximate the estimator
by a linear function of the kernel estimator ĥnip,s (linearization). Formally, we show that
                                                                                              „                ˛2 «
                   1XN X N
                            ∂n                  “                                      ”       √ ˛˛            ˛
         V =       √            (h(Z1j , Z2k ))   ĥnip,s (Z1j , Z2k ) − h(Z1j , Z2k )   + Op   N ˛ ĥnip,s − h˛ .        (B.33)
                N N j=1 k=1 ∂h0

By the assumptions, and Lemma A.11, the remainder term is op (1).
In the second step we express the difference between the linearized estimator and the estimand as the sum of a
bias term (that is asymptotically negligible) and a variance term (bias-variance decomposition). The bias term
will be shown to satisfy
       ˛                                                                           ˛
       ˛       N    N                                                              ˛     “√      ”
       ˛ 1 X X ∂n                                                                  ˛
       ˛ √               0
                           (h(Z1j , Z2k ))(E[ĥnip,s (Z1j , Z2k )] − h(Z1j , Z2k ))˛ = O    N bpN .     (B.34)
       ˛N N            ∂h                                                          ˛
              j=1         k=1


By the assumption on the bandwidth rate, the remainder term is o(1). Note that by E[ĥ(Zi1 , Zi2 ] we mean the
expectation of ĥ(z1 , z2 ), evaluated at z1 = Z1i and z2 = Z2j : the expectation is taken over the estimator of the
function h(·).
The second step leaves us with
                       „                  ˛2 «
                         √ ˛˛             ˛      √
       V = W + Op           N ˛ĥnip,s − h˛ + O( N bpN ),

where

                    1 XN X N
                              ∂n                 “                  h                    i”
         W =        √           0
                                  (h(Z1j , Z2k )) ĥ(Z1j , Z2k ) − E ĥnip,s (Z1j , Z2k ) .                               (B.35)
                  N N j=1 k=1 ∂h

Define
                          ∂n
         ν(z1 , z2 ) =        (h(z1 , z2 )),
                          ∂h0


                                                                    [54]
and

         aN,µ (Ỹi , Zi , Z1j , Z2k )
                                                          „                       «
                                                     1      Zi − rbN (Z1j , Z2k )
                  = ν(Z1j , Z2k )0 ·     L+|µ|
                                               Ỹi K  (µ)

                                        bN                          bN
                                    "                  „                      «#! „„      «                    «µ
                                        1         (µ)    Z − rbN (Z1j , Z2k )         Z1j
                              −EỸ Z L+|µ| Ỹ K                                     ·       − rbN (Z1j , Z2k )
                                      b                          bN                   Z2k
                                             N
so that
                   X          1
         W =                     Wµ ,                                                                                                     (B.36)
                              µ!
                 µ:|µ|≤s−1

where
                              N X
                              X N X
                                  N
                       1
         Wµ =          √                         aN,µ (Ỹi , Zi , Z1j , Z2k )
                  N2 N        i=1 j=1 k=1

Define
                                        Z        Z               „          „                     «        »         „                    «–«
                                   1                                          Zi − rbN (z1 , z2 )                      Z − rbN (z1 , z2 )
         cN,µ (Ỹi , Zi ) =    L+|µ|
                                                     ν(z1 , z2 )0 Ỹi K (µ)                         − EỸ Z Ỹ K (µ)
                              bN         Z2       Z1                                bN                                       bN
                           × ((z10 z20 )0 − rbN (z1 , z2 ))µ fZ1 (z1 )fZ2 (z2 )dz1 dz2

and
                   N
               1 X
         Uµ = √       cN,µ (Ỹi , Zi ),
                N i=1

or, equivalently

        Uµ =
      √ Z Z                            (µ)                             (µ)
       N               ν(z1 , z2 )0 (ĥN W (rbN (z1 , z2 )) − E[ĥN W (rbN (z1 , z2 ))])((z10 z20 )0 − rbN (z1 , z2 ))µ fZ1 (z1 )fZ2 (z2 )dz1 dz2 .
            Z2    Z1

In the third step we show that
                      “          ”
       Wµ = Uµ + Op N −1/2 b−L N                                                                                                          (B.37)

In the fourth step we show that
                   N                                           »                                   –ff
               1 X ∂n            0                                ∂n       0
         U0 = √          (h(Zi )) Ỹi fZ1 (Z1i )fZ2 (Z2i ) − EZ      (h(Z)) Ỹ fZ1 (Z1i )fZ2 (Z2i )     + op (1).                         (B.38)
                N i=1 ∂h                                          ∂h

which gives us the representation in the Theorem.
In the fifth and final step we show that we can ignore Uµ for µ such that |µ| ≥ 1, because for such µ,

         Uµ = Op (bN ) .                                                                                                                  (B.39)

Proving these statements implies the result in the Theorem.
Now we turn to proving each of the statements (B.33), (B.34), (B.37), (B.38), and (B.39).

Step 1: Linearization In the first step of the proof we prove equality (B.33). First define
                                                                         ∂n
         d(z1 , z2 ) ≡ n(ĥnip,s (z1 , z2 )) − n(h(z1 , z2 )) −              (h(z1 , z2 ))(ĥnip,s (z1 , z2 ) − h(z1 , z2 )).
                                                                         ∂h0
By a second order Taylor series expansion of n(ĥnip,s (Z1i , Z2j )) around h(Z1i , Z2j ) we have,
                       ˛                                                                                                 ˛
                     1˛                                      ∂2 n                                                        ˛
      |d(z1 , z2 )| = ˛˛(ĥnip,s (z1 , z2 ) − h(z1 , z2 ))0       (h(z 1 , z 2 ))( ĥnip,s (z 1 , z 2 ) − h(z 1 , z 2 )) ˛
                                                                                                                         ˛
                     2                                      ∂h∂h0

                                                                                [55]
                        ˛ 2              ˛ ˛                                  ˛2
                        ˛ ∂ n            ˛ ˛                                  ˛
                 ≤ sup ˛˛         (h(z))˛˛ · ˛ĥnip,s (z1 , z2 ) − h(z1 , z2 )˛
                          ∂h∂h  0
                    z
                       ˛            ˛2
                       ˛            ˛
                 ≤ C · ˛ĥnip,s − h˛ ,

with h(z1 , z2 ) intermediate between ĥnip,s (z1 , z2 ), and h(z1 , z2 ) so that
      ˛                            ˛                          „˛
      ˛       N    N               ˛     ˛           ˛2                      ˛2 «
      ˛ 1 XX                       ˛     ˛           ˛         ˛             ˛
      ˛ 2             d(Z1j , Z2k )˛ ≤ C ˛ĥnip,s − h˛ = Op ˛ĥnip,s − h˛ .
      ˛N                           ˛
             j=1   k=1

Hence
                   N h “
                 N X
                 X                          ”                    i
           1
           √          n ĥnip,s (Z1j , Z2k ) − n (h(Z1j , Z2k ))
          N N    j=1 k=1

                          N
                      1 X X ∂n
                              N                     “                                     ”
                 =    √            0
                                     (h(Z1j , Z2k )) ĥnip,s (Z1j , Z2k ) − h(Z1j , Z2k )
                     N N j=1 k=1 ∂h
                                       N X
                                       X N
                                  1
                           +      √              d(Z1j , Z2k )
                               N N     j=1 k=1
                                                                                                  „                 ˛2 «
                         N
                    1 X X ∂n
                             N                     “                                      ”         √ ˛˛            ˛
                 =  √              (h(Z1j , Z2k ))   ĥnip,s (Z1j , Z2k ) − h(Z1j , Z2k )   + Op     N ˛ ĥnip,s − h˛
                 N N j=1 k=1 ∂h0
                                                                             √ ˛˛               ˛2
                                                                                                ˛
so that the linearization remainder has the same stochastic order as N ˛ĥnip,s − h0 ˛ .

Step 2: Bias-variance decomposition In the second step of the proof we proof equation (B.34).
Define
                    N
                1 X X ∂n
                        N                     “                                    ”
         E=     √            0
                               (h(Z1j , Z2k )) ĥnip,s (Z1j , Z2k ) − h(Z1j , Z2k ) .
               N N j=1 k=1 ∂h

so that
                         „         ˛           ˛2 «
                             √     ˛           ˛
         V = E + Op              N ˛ĥnip,s − h˛ .

We decompose E into a bias and variance part, E = EUbias + W , where
                        N
                    1 X X ∂n
                            N                     “ h                    i               ”
         Ebias =    √            0
                                   (h(Z1j , Z2k )) E ĥnip,s (Z1j , Z2k ) − h(Z1j , Z2k ) ,
                   N N j=1 k=1 ∂h

and W is defined in (B.35). The bias part is bounded by
     ˛                                                                           ˛
     ˛         N   N                     “ h                    i               ”˛
     ˛ 1 X X ∂n                                                                  ˛
     ˛ √                0
                          (h(Z1j , Z2k )) E ĥnip,s (Z1j , Z2k ) − h(Z1j , Z2k ) ˛
     ˛N N             ∂h                                                         ˛
              j=1 k=1
                        ˛        ˛
                        ˛ ∂n     ˛ √ ˛˛              ˛
                                                     ˛     √
                 ≤ sup ˛˛ (h(z))˛˛ N ˛E[ĥnip,s ] − h˛ = O( N bpN ),
                   z∈Z    ∂h
due to smoothness of the function and Lemma A.9.

Step 3: Projection In the third step of the proof we prove equation (B.37), Wµ = Uµ + Op (N −1/2 b−L
                                                                                                  N ).
This is the most complicated step. First, note that
                             N X
                             X N X
                                 N
                     1
         Wµ =        √                     aN,µ (Ỹi , Zi , Z1j , Z2k ),
                N2 N         i=1 j=1 k=1




                                                                       [56]
is a third order V-statistic with kernel (that depends on N ) aN,µ . We show that this V-statistic is asymptotically
equivalent to a projection that is a single sum. Because the kernel depends on N we cannot use a standard
result.
The projection of Wµ is
                 N
             1 X
       Uµ = √       cN,µ (Ỹi , Zi ),
              N i=1
with
       cN,µ (Ỹi , Zi )
                              Z        Z                  „          „                     «        »         „                    «–«
                          1                                            Zi − rbN (z1 , z2 )                      Z − rbN (z1 , z2 )
                =    L+|µ|
                                              ν(z1 , z2 )0 Ỹi K (µ)                         − EỸ Z Ỹ K (µ)
                    bN            Z2       Z1                                bN                                       bN
                   ×((z10 z20 )0 − rbN (z1 , z2 ))µ fZ1 (z1 )fZ2 (z2 )dz1 dz2 .
The projection remainder is
                                                     „                           «
              N (N − 1)(N − 2)                         N (N − 1)(N − 2)
  Wµ − Uµ =                       (W µ,1 −  U µ  ) +                         −  1  Uµ + Wµ,2 + Wµ,3 + Wµ,4 + Wµ,5 (B.40)
                     N3                                        N3
with
                              √
                           N              X
       Wµ,1 ≡                                   aN,µ (Ỹi , Zi , Z1j , Z2k )
                  N (N − 1)(N − 2)
                                        i6=j6=k
                  √
                    N X
       Wµ,2 ≡                aN,µ (Ỹi , Zi , Z1i , Z2k )
                  N3
                      i=j6=k
                  √
                    N X
       Wµ,3 ≡                aN,µ (Ỹi , Zi , Z1j , Z2i )
                  N3
                      i=k6=j
                  √
                    N X
       Wµ,4 ≡                aN,µ (Ỹi , Zi , Z1j , Z2j )
                  N3
                      i6=j=k
                  √
                    N X
       Wµ,5 ≡                aN,µ (Ỹi , Zi , Z1i , Z2k )
                  N 3 i=j=k

We prove that the projection remainder Wµ − Uµ = Op (N −1/2 b−L
                                                             N ) by proving the following six equalities:
                      “            ”
                              −L/2
      Wµ,1 − Uµ = Op N −1 bN         ,                                                                 (B.41)
      „                       «        “          ”
        N (N − 1)(N − 2)                     −L/2
                          − 1 Uµ = Op N −1 bN       ,                                                  (B.42)
               N3
                 “                 ”
                          −L+L2 /2
      Wµ,2 = Op N −1/2 bN            ,                                                                 (B.43)
                 “                 ”
                          −L+L1 /2
      Wµ,3 = Op N −1/2 bN            ,                                                                 (B.44)
                 “           ”
                        −L/2
      Wµ,4 = Op N −3 bN        ,                                                                       (B.45)
                 “           ”
                    −1/2 −L
      Wµ,5 = Op N        bN .                                                                          (B.46)
In order to prove these results, we establish bounds on the second moment of aN,µ (Ỹi , Zi , Z1j , Z2k ). This will
be relatively straightforward if i 6= j and i 6= k. The derivation of the bound is more involved if i = j and/or
i = k. We could simplify the proof by omitting these observations and redefining the estimator by restricting
the averaging to observations with i 6= j and i 6= k. This would amount to redefining the kernel estimator in
(A.7) by omitting observations i = j and i = k in ĥnip,s . We will keep these observations and derive bounds on
all second moments. We derive the following bounds, considering four separate cases (note that the bounds do
not depend on µ)
       E[aN,µ (Ỹi , Zi , Z1j , Z2k )2 ] = O(b−L
                                              N )                    j 6= i, and k 6= i,                                             (B.47)
       E[aN,µ (Ỹi , Zi , Z1i , Z2i ) ] = O(b−2L
                                            2
                                              N  )                   i = j = k,                                                      (B.48)
       E[aN,µ (Ỹi , Zi , Z1i , Z2k )2 ] = O(bN
                                              −2L+L2
                                                     )               k 6= i = j,                                                     (B.49)
       E[aN,µ (Ỹi , Zi , Z1j , Z2k )2 ] = O(bN
                                              −2L+L1
                                                     )               j 6= i = k.                                                     (B.50)


                                                                        [57]
Step 3A: Equation (B.47) First if j 6= i and k 6= i
       E[aN,µ (Ỹi , Zi , Z1j , Z2k )2 ]
                         "       „                       «2                                                                          #
              1                    Zi − rbN (Z1j , Z2k )
       ≤ 2L+2|µ| E K (µ)                                    ν(Z1j , Z2k )0 Ỹi Ỹi0 ν(Z1j , Z2k )((Z1j
                                                                                                     0
                                                                                                       Z2k0 0
                                                                                                             ) − rbN (Z1j , Z2k ))2µ
          bN                                bN
                                          "      „                        «2                                      #
          supz∈Z |z − rbN (z)|2µ             (µ)   Zi − rbN (Z1j , Z2k )                      0    0
       ≤             2L+2|µ|
                                         E K                                  ν(Z1j , Z2k ) Ỹi Ỹi ν(Z1j , Z2k )
                   bN                                      bN
                 "         „                        «2                                      #
           1          (µ)    Zi − rbN (Z1j , Z2k )                  0       0
       ≤ 2L E K                                        ν(Z1j , Z2k ) Ỹi Ỹi ν(Z1j , Z2k )
          bN                             bN

Now by the Cauchy-Schwartz inequality
       "      „                       «2                                        #
                Zi − rbN (Z1j , Z2k )
      E K (µ)                             ν(Z1j , Z2k )0 Ỹi Ỹi0 ν(Z1j , Z2k )
                        bN
          "       „                       «2                           #
              (µ)   Zi − rbN (Z1j , Z2k )                      0     2
      =E K                                   (ν(Z1j , Z2k ) Ỹi )
                            bN
          "       „                       «2                           #
              (µ)   Zi − rbN (Z1j , Z2k )                     2      2
      ≤E K                                   |ν(Z1j , Z2k | |Ỹi |
                            bN
          "       „                       «2                                  #
                    Zi − rbN (Z1j , Z2k )                          h        i
              (µ)                                             2          2
      =E K                                   |ν(Z1j , Z2k | E |Ỹi | |Zi
                            bN
                     h            i
By Assumption 3.1 E |Ỹ |2 |Z = z an ν are bounded on Z so that this is bounded by (condition on Z1j and Z2k )
           "          „                         «2 #        Z           „                        «2
                (µ)       Zi − rbN (Z1 , Z2 )                               z − rbN (Z1 , Z2 )
       CE K                                            =C       K (µ)                                 fZ (z)dz
                                 bN                         Z                     bN

and by a change of variables to t = (z − rbN (Z1 , Z2 ))/bN with Jacobian bL    N we obtain
           Z                                                                            Z
      CbLN                              K (µ) (t)2 fZ (bN t + rbN (Z1 , Z2 ))dt ≤ C1 bL
                                                                                      N   K (µ) (t)2 dt ≤ C2 bL
                                                                                                              N
               {t|t=(z−rb        (Z1 ,Z2 ))/bN ,z∈Z}                                                             U
                             N

by Assumptions 3.1 and 4.1. We conclude
       E[aN,µ (Ỹi , Zi , Z1j , Z2k )2 ] = O(b−L
                                              N )                                                                               (B.51)

The same proof and the same bound holds if j 6= k 6= i or j = k 6= i .

Step 3B: Equation (B.48) Next, we consider E[aN,µ (Ỹi , Zi , Z1i , Z2i )2 ] where we note that E[aN,µ (Ỹi , Zi , Z1i , Z2i )] 6=
0. Because

       aN,µ (Ỹi , Zi , Z1i , Z2i )
                    »               „                «                       „           „               «                   «–
              1                       Zi − rbN (Zi )                                       Z − rbN (Zi )
        = L+|µ| ν(Zi )0 Ỹi K (µ)                      (Zi − rbN (Zi ))µ − EZ ν(Zi )0(µ)                   (Zi − rbN (Zi ))µ
          bN                               bN                                                  bN

we have
       E[aN,µ (Ỹi , Zi , Z1i , Z2i )2 ]                                                                                        (B.52)
                                 "        „                «2                                   #
                        1             (µ)   Zi − rbN (Zi )            0    2                 2µ
              = 2L+2|µ| E K                                   (ν(Zi ) Ỹi ) (Zi − rbN (Zi ))                                    (B.53)
                   bN                            bN
                                            »                     „                «
                                 2                                   Zi − rbN (Zi )
                          − 2L+2|µ| EZi        ν(Zi )0 g(Zi )K (µ)                                                              (B.54)
                            bN                                             bN
                                           »                 „                «–                    ff–
                                                               Z − rbN (Zi )
                                   − EZ ν(Z)g(Z)K (µ)                            (Zi − rbN (Zi ))2µ
                                                                     bN

                                                                        [58]
                                              "„         „          „               «««2                     #
                                          1           0         (µ)   Z − rbN (Zi )                       2µ
                                + 2L+2|µ| EZi   ν(Zi ) EZ g(Z)K                          (Zi − rbN (Zi ))                                                                  (B.55)
                                 bN                                       bN
By Assumption 3.1 and smoothness (B.53) is bounded by
          Z         „             «2                 Z           „             «2
       C        (µ)   z − rbN (z)                 C          (µ)   z − rbN (z)
              K                      f Z (z)dz =           K                      fZ (z)dz
      b2L
       N    Z             bN                     b2L
                                                  N    ZI
                                                        bN
                                                                       bN
                                                     Z             „             «2
                                                  C            (µ)   z − rbN (z)
                                               + 2L         K                       fZ (z)dz
                                                 bN Z\ZI                 bN
                                                                                        bN


If rb (z) is the projection on the internal set, then z − rb (z) = 0 if z is in the internal set. Therefore
              Z          „             «2
          C          (µ)   z − rbN (z)               CK (µ)(0)2
          2L
                   K                      fZ (z)dz ≤
         bN ZI                 bN                       b2L
                                                         N
                  bN


Next we consider the second integral. If s ∈ ZB          I
                                               bN ≡ Z \ ZbN , then at least one component of z is in the boundary
region. We can subdivide ZbN into disjoint subsets ZbN ,p , p = 1, . . . , 2L − 1 and in each such subset Lp ≥ 1
                            B                           B

components of z are within bN from the boundary. We further partition ZB                                  B
                                                                                bN ,p into disjoint sets ZbN ,p,r , r =
          Lp
1, . . . 2 with 0 ≤ Kr ≤ Lp components with zll ≤ Zl ≤ zll + bN and the remaining Lp − Kr components with
zul − bN ≤ Zl ≤ zul . Without loss of generality we assume that the first Kr components of z are near the lower
bound, the next Lp − Kr are near the upper bound and the rest is in the internal region, so that
             Z                        „                     «2
        C                                 z − rbN (z)
                            K (µ)                                fZ (z)dz
       b2L
        N        ZB                           bN
                  bN ,p,r
            Z    zl1 +bN          Z   zl,Kr +bN      Z    zu,Kr +1            Z    zu,Lp          Z   zu,Lp+1 −bN                  Z           Kr
                                                                                                                                       zuL −bN Y              „               «2
                                                                                                                                                      (µl )        Zl − zll
        =                   ···                                         ···                                                  ···                     Kl                     −1
                zl1                zl,Kr                 zu,Kr +1 −bN             zu,Lp −bN       zl,Lp +1 +bN                     zlL +bN     l=1
                                                                                                                                                                     bN
                                                                                             Lp
                                                                                             Y                    „                      «2    L
                                                                                                                                               Y
                                                                                                       (µl )          Zl − zul                             (µl )
                                                                                    ×                 Kl                               +1               Kl         (0)2 fZ (z)dz
                                                                                                                         bN
                                                                                        l=Kr +1                                               l=Lp +1

                                                                                                                      (µ )
Because the support of the kernel is [−1, 1] and by Assumption 4.1 Kl l is bounded on this support we have
             „             «                                       „             «
       (µl )   Zl − zll                                      (µl )   zl − zul
     Kl                 − 1 ≤ C · 1 (zll ≤ zl ≤ zll + 2bN ) Kl                + 1 ≤ C · 1 (zul − 2bN ≤ zl ≤ zul )
                 bN                                                     bN
and substitution gives the upper bound
             Z    zl1 +bN          Z   zlKr +bN       Z   zu,Kr +1            Z    zu,Lp          Kr
                                                                                                  Y
       C1
                             ···                                        ···                            1 (zll ≤ zl ≤ zll + 2bN )
       b2L
        N        zl1                  zlKr               zu,Kr +1 −bN             zu,Lp −bN l=1

                                                                     Lp
                                                                     Y                                                                                                    C2
                                                              ×               1 (zul − 2bN ≤ zl ≤ zul ) fZ (z1 , . . . zLp )dz1 . . . dzLp ≤                             2L−Lp
                                                                  l=Kr +1                                                                                               bN

Because Lp ≥ 1 the integral over the boundary region is O(b−2L+1
                                                           N     ). Combining the results we have that
       E[aN,µ (Ỹi , Zi , Z1i , Z2i )2 ] = O(b−2L
                                              N   )                                                                                                                        (B.56)
which is larger than the bound in (B.51) and could be a reason to omit the terms i = j = k (and redefine the
kernel estimator).

Step 3C: Equation (B.49) Third, we consider E[aN,µ (Ỹi , Zi , Z1i , Z2k )2 ]. Again we have E[aN,µ (Ỹi , Zi , Z1i , Z2k )] 6=
0. We have
       E[aN,µ (Ỹi , Zi , Z1i , Z2k )2 ]

                                   "            „                                 «2                                                                                                 #
                        1                 (µ)       Zi − rbN (Z1i , Z2k )                                  0
             =        2L+2|µ|
                                E K                                                    ν(Z1i , Z2k )           Ỹi Ỹi0 ν(Z1i , Z2k )((Z1i
                                                                                                                                        0       0
                                                                                                                                               Z2k )0     − rbN (Z1i , Z2k ))   2µ

                  bN                                        bN


                                                                                       [59]
                                                                                                                                                                    (B.57)
                                                     »                                  „                       «
                                        2                                                 Zi − rbN (Z1i , Z2k )
                                    − 2L+2|µ| EZi Z2k ν(Z1i , Z2k )0 g(Z1i , Z2k )K (µ)                                                                             (B.58)
                                     bN                                                           bN
                                                „        „                         ««                                     –
                                                             Z − rbN (Z1i , Z2k )
                                          ×EZ g(Z)0(µ)                                     0
                                                                                        ((Z1i  0 0
                                                                                              Z2k ) − rbN (Z1i , Z2k ))2µ
                                                                       bN
                                                       "„                       „          „                      «««2                                     #
                                1                                                            Z − rbN (Z1i , Z2k )
                    +              E
                            2L+2|µ| Zi Z2k
                                                            ν(Z1i , Z2k )0 EZ    g(Z)K (µ)                                  0
                                                                                                                       × ((Z1i  0 0
                                                                                                                               Z2k ) − rbN (Z1i , Z2k ))2µ
                           bN                                                                       bN
                                                                                                                                                                    (B.59)

By Assumptions 3.1 and smoothness (B.57) is bounded by
          Z Z        „                      «2
       C                z − rbN (z1 , z̃2 )
       2L
               K (µ)                           fZ (z)fZ2 (z̃2 )dzdz̃2
      bN Z2 Z                  bN
            Z Z         Z          „                     «2
          C                    (µ)   z − rbN (z1 , z̃2 )
      = 2L                  K                                fZ (z1 , z2 )fZ2 (z̃2 )dz2 dz1 dz̃2
         bN Z2 ZI        Z2                  bN
                  bN ,1
            Z Z           Z           „                      «2
          C                              z − rbN (z1 , z̃2 )
      + 2L                      K (µ)                           fZ (z1 , z2 )fZ2 (z̃2 )dz2 dz1 dz̃2
         bN Z2 Z1 \ZI       Z2                  bN
                                      bN ,1


Because z1 − rb (z1 , z̃2 ) = 0 if z1 ∈ ZIbN ,1 , the first term on the right hand side is equal to
          (µ )     Z Z            Z           „                      «2
      CK1 1 (0)                         (µ2 )   z2 − rbN (z1 , z̃2 )                                             −2L+L2
                                       K                                fZ (z1 , z2 )fZ2 (z̃2 )dz2 dz1 dz̃2 = O(bN      ),
          b2L
           N          Z2 ZI         Z2                  bN
                                           bN ,1


(where K(u) is the univariate kernel), by a change of variables to t2 = (z2 − rbN (z1 , z̃2 )/bN with Jacobian bL           N .
                                                                                                                             2

                                      B            I                 B                        L1
For the second integral we partition Z1,bN ≡ Z1 \ ZbN ,1 into sets Z1,bN ,p , p = 1, . . . , 2 − 1 in which 1 ≤ L1p ≤ L1
components of z1 are in the boundary region. Each ZB                                              B
                                                     1,bN ,p is partitioned further into sets Z1,bN ,p,r , r = 1, . . . , 2
                                                                                                                           L1p

in which 0 ≤ K1r ≤ L1r components of z1 are near the lower, L1r − K1r are near the upper boundary, and the
remaining L1 − L1p components are in the internal set. Hence, if we without loss of generality assume that the
first Kr components of z1 are near the lower boundary, the next L1p − K1r are near the upper boundary, and
the remaining components are in the internal set,
              Z        Z                   Z               „                   «2
         C                                                 z − rbN (z1 , z̃2 )
                                                   K (µ)                          fZ (z1 , z2 )fZ2 (z̃2 )dz2 dz1 dz̃2
        b2L
         N        Z2    Z1 \ZI              Z2                   bN
                             b      N ,1
                    Z       Z    zl,l1 +bN             Z zl1,K +bN Z zu1,K +1
               C                                               1r                  1r
        =                                        ···
              b2L
               N   Z2           zl,11                   zl1,K1r            zu1,K1r +1 −bN
              Z zu1,L                 Z    zu1,L1p+1 −bN             Z   zu1,L1 −bN     Z   K
                                                                                            Y 1r             „                «2
                           1p                                                                        (µl )       z1l − zl1l
        ···                                                    ···                                 Kl                       −1
               zu1,L1p −bN                zl1,L1p +1 +bN              zl1,L1 +bN        Z2 l=1                       bN
              L1p
              Y                      „                       «2          L1
                                                                         Y                                „                          «2
                            (µ )           z1l − zu1l                            (µ )         2    (µ )       z2 − rbN (z1 , z̃2 )
        ×                  Kl l                            +1                   Kl l    (0)       K2 2                                    fZ (z1 , z2 )fZ2 (z̃2 )dz2 dz1 dz̃2
                                               bN                                                                    bN
            l=K1r +1                                                 l=L1p +1


After a change of variables to t2 = (z2 − rbN (z1 , z̃2 )/bN with Jacobian bL
                                                                            N we have by analogous argument as
                                                                             2

                           −2L+L2 +L1p
above that this term is O(bN           ). Because L1p ≥ 1 we have by combining the results

        E[aN,µ (Ỹi , Zi , Z1i , Z2k )2 ] = O(bN
                                               −2L+L2
                                                      )                                                                                                             (B.60)

Step 3D: Equation (B.50) An analogous argument gives
        E[aN,µ (Ỹi , Zi , Z1j , Z2i )2 ] = O(bN
                                               −2L+L1
                                                      )                                                                                                             (B.61)

This finishes the derivation of the bounds on the second moments of the kernel of the V-statistic.
Now we turn to the proofs of equalities (B.41)-(B.46).


                                                                                        [60]
Step 3E: Equation (B.41) For the first term
                                     √
                                   N        X
        Wµ,1 − Uµ =                           (aN,µ (Ỹi , Zi , Z1j , Z2k ) − cN,µ (Ỹi , Zi ))                                                 (B.62)
                           N (N − 1)(N − 2)
                                                     i6=j6=k

so that

        E[(Wµ,1 − Uµ )2 ]
                   N             X                   X
        = 2                                                       E[(aN,µ (Ỹi , Zi , Z1j , Z2k ) − cN,µ (Ỹi , Zi ))
           N (N − 1)2 (N − 2)2 i6=j6=k
                                                  i0 6=j 0 6=k0

          × (aN,µ (Ỹi0 , Zi0 , Z1j 0 , Z2k0 ) − cN,µ (Ỹi0 , Zi0 ))]

This expression can be simplified using

                                                    E[aN,µ (Ỹi , Zi , Z1j , Z2k )] = 0                                                         (B.63)
                                                                     E[cN,µ (Ỹi , Zi )] = 0                                                    (B.64)
                                           E[aN,µ (Ỹi , Zi , Z1j , Z2k )|Ỹi , Zi ] = cN,µ (Ỹi , Zi )                                         (B.65)
               E[aN,µ (Ỹi , Zi , Z1j , Z2k )aN,µ (Vi0 , Zi0 , Z1j 0 , Z2k )|Z2k ] = 0                                                          (B.66)
               E[aN,µ (Ỹi , Zi , Z1j , Z2k )aN,µ (Vi0 , Zi0 , Z1j , Z2k0 )|Z1j ] = 0                                                           (B.67)
        E[aN,µ (Ỹi , Zi , Z1j , Z2k )aN,µ (Vi0 , Zi0 , Z1j , Z2k0 )|Z1j , Z2k ] = 0                                                            (B.68)

Therefore

        E[(aN,µ (Ỹi , Zi , Z1j , Z2k ) − cN,µ (Ỹi , Zi ))(aN,µ (Vi0 , Zi0 , Z1j 0 , Z2k0 ) − cN,µ (Vi0 , Zi0 ))] = 0

if i 6= i0 , j 6= j 0 , k 6= k0 by (B.63) and (B.64), if i = i0 , j 6= j 0 , k 6= k0 by (B.65), if i 6= i0 , j 6= j 0 , k = k0 by (B.66),
and if i 6= i0 , j = j 0 , k 6= k0 by (B.67), and if i =
                                                       6 i0 , j = j 0 , k = k0 by (B.68). Using this we obtain

        E[(Wµ,1 − Uµ )2 ]                                                                                                                       (B.69)
                   N           X
        = 2           2     2
                                     E[(aN,µ (Ỹi , Zi , Z1j , Z2k ) − cN,µ (Ỹi , Zi ))2 ]
           N (N − 1) (N − 2) i6=j6=k
                       N                     X
          +                                              E[(aN,µ (Ỹi , Zi , Z1j , Z2k ) − cN,µ (Ỹi , Zi ))(aN,µ (Ỹi , Zi , Z1j , Z2k0 ) − cN,µ (Ỹi , Zi ))]
              N 2 (N − 1)2 (N − 2)2
                                          i6=j6=k6=k0

                         N                   X
          +                                              E[(aN,µ (Ỹi , Zi , Z1j , Z2k ) − cN,µ (Ỹi , Zi ))(aN,µ (Ỹi , Zi , Z1j 0 , Z2k ) − cN,µ (Ỹi , Zi ))]
              N 2 (N   − 1)2 (N − 2)2
                                          i6=k6=j6=j 0


Because E[aN,µ (Ỹi , Zi , Z1j , Z2k )|Ỹi , Zi ] = cN,µ (Ỹi , Zi ) we have E[aN,µ (Ỹi , Zi , Z1j , Z2k )cN,µ (Ỹi , Zi )] = E[cN,µ (Ỹi , Zi )2 ]
so that by the bounds on the second moment of aN,µ (Ỹi , Zi , Z1j , Z2k ), given in (B.47)-(B.50),

        E[(aN,µ (Ỹi , Zi , Z1j , Z2k ) − cN,µ (Ỹi , Zi ))2 ] = E[(aN,µ (Ỹi , Zi , Z1j , Z2k )2 ] − E[cN,µ (Ỹi , Zi )2 ]
                                                                      ≤ E[(aN,µ (Ỹi , Zi , Z1j , Z2k )2 ] = O(b−L
                                                                                                                N ).


Further (note that E[aN,µ (Ỹi , Zi , Z1j , Z2k )aN,µ (Ỹi , Zi , Z1j , Z2k0 )] = E[(EZ2 [aN,µ (Ỹi , Zi , Z1j , Z2 )])2 ] ≥ 0)

        E[(aN,µ (Ỹi , Zi , Z1j , Z2k ) − cN,µ (Ỹi , Zi ))(aN,µ (Ỹi , Zi , Z1j , Z2k0 ) − cN,µ (Ỹi , Zi ))]
          = E[aN,µ (Ỹi , Zi , Z1j , Z2k )aN,µ (Ỹi , Zi , Z1j , Z2k0 )] − E[cN,µ (Ỹi , Zi )2 ]
                                                                                       ≤ E[aN,µ (Ỹi , Zi , Z1j , Z2k )aN,µ (Ỹi , Zi , Z1j , Z2k0 )]




                                                                             [61]
and

      E[aN,µ (Ỹi , Zi , Z1j , Z2k )aN,µ (Ỹi , Zi , Z1j , Z2k0 )]
                        »                                           „                         «        „                        «
              1                                                       Zi − rbN (Z1j , Z2k )              Zi − rbN (Z1j , Z2k0 )
      = 2|µ|+2L E ν(Z1j , Z2k )0 Ỹi Ỹi0 ν(Z1j , Z2k0 )K (µ)                                   K (µ)
         bN                                                                     bN                                bN
            0      0 0                        µ      0     0    0                     µ
                                                                                        ˜
      ×((Z1j Z2k ) − rbN (Z1j , Z2k )) ((Z1j Z2k0 ) − rbN (Z1j , Z2k0 ))
                       »                       »          „                       «–        »          „                       «–
             1                                               S − rbN (Z1j , Z2k )                        Z − rbN (Z1j , Z2k0 )
      − 2|µ|+2L E ν(Z1j , Z2k )0 EỸ Z Ỹ K (µ)                                        EỸ Z Ỹ V 0(µ)                            ν(Z1j , Z2k0 )
         bN                                                          bN                                          bN
            0      0 0                                                                µ˜
      ×((Z1j    Z2k  ) − rbN (Z1j , Z2k ))µ ((Z1j    0
                                                        Z2k0    0
                                                             0 ) − rbN (Z1j , Z2k0 ))
                        »                                           „                         «        „                        «
              1                                                       Zi − rbN (Z1j , Z2k )              Zi − rbN (Z1j , Z2k0 )
      ≤ 2|µ|+2L E ν(Z1j , Z2k )0 Ỹi Ỹi0 ν(Z1j , Z2k0 )K (µ)                                   K (µ)
         bN                                                                     bN                                bN
            0      0 0                        µ      0     0    0                     µ
                                                                                        ˜
      ×((Z1j Z2k ) − rbN (Z1j , Z2k )) ((Z1j Z2k0 ) − rbN (Z1j , Z2k0 ))

because both expectations are nonnegative. By Assumptions 3.1 and smoothness this is bounded by
            »      „                       «       „                        «–
       C1      (µ)   Zi − rbN (Z1j , Z2k )     (µ)   Zi − rbN (Z1j , Z2k0 )
          E  K                               K                                 ≤ C2 b−L
                                                                                     N
      b2L
       N                     bN                              bN

by a change of variables to t = (Zi − rbN (Z1j , Z2k ))/bN with Jacobian bL
                                                                          N and Assumption 4.1. By interchanging
the roles of j and k we obtain a bound of the same order for the third term on the right hand side of (B.69).
Combining these results we find

      E[(Wµ,1 − Uµ )2 ] = O(N −2 b−L
                                  N ) + O(N
                                            −1 −L
                                              bN ) = O(N −1 b−L
                                                             N )                                                                 (B.70)
                                                                                                                     −L/2
so that by the Markov inequality the first term in the projection remainder (B.40) is Op (N −1/2 bN                         ).

Step 3F: Equation (B.42) For the second term of the projection remainder (B.40) we have by the
Cauchy-Schwartz inequality

      E[cN,µ (Ỹi , Zi )2 ]
                        "„Z Z                              „                     «                                                       «2 #
             1                                  0      (µ)   Zi − rbN (z1 , z2 )      0    0 0                µ
      ≤ 2L+2|µ| E                    ν(z1 , z2 ) Ỹi K                             ((z1 z2 ) − rbN (z1 , z2 )) fZ1 (z1 )fZ2 (z2 )dz1 dz2
         bN                  Z2 Z1                                  bN
                        "       „Z Z                     ˛      „                     «˛                                                       «2 #
             1                                           ˛ (µ) Zi − rbN (z1 , z2 ) ˛ ˛ 0 0 0                         ˛
      ≤ 2L+2|µ| E |Ỹi |      2                          ˛
                                           |ν(z1 , z2 )| ˛K                             ˛ ˛                         µ˛
                                                                          bN            ˛ ((z1 z2 ) − rbN (z1 , z2 ) fZ1 (z1 )fZ2 (z2 )dz1 dz2
         bN                         Z2 Z1
                    "„Z Z ˛             „                        «˛                            «2              #
         C1                       ˛ (µ) Zi − rbN (z1 , z2 ) ˛
      ≤ 2L EZi                    ˛K                              ˛ fZ1 (z1 )fZ2 (z2 )dz1 dz2 E(|Ỹi |2 |Zi )
         bN                       ˛                  bN           ˛
                           Z2 Z1
              Z „Z Z ˛                „                      «˛                             «2
         C2                     ˛ (µ) z̃ − rbN (z1 , z2 ) ˛
      ≤ 2L                      ˛K                            ˛ fZ1 (z1 )fZ2 (z2 )dz1 dz2 fZ (z̃)dz̃
         bN Z                   ˛                 bN          ˛
                       Z2 Z1


by Assumptions 3.1 and smoothness. By a change of variables t = (z̃ − rbN (z1 , z2 ))/bN with Jacobian bL
                                                                                                        N we
conclude that

      E[cN,µ (Ỹi , Zi )2 ] = O(b−L
                                 N )                                                                                             (B.71)

Therefore

      E[Uµ2 ] = E[cN,µ (Ỹi , Zi )2 ] = O(b−L
                                           N )

                                                                             −L/2
so that the second term of the projection remainder is Op (N −1bN                   ).




                                                                [62]
Step 3F: Equations (B.43)-(B.46) The other terms of the projection remainder can be bounded
using (B.47)-(B.50). For the third term (note E[aN,µ (Ỹi , Zi , Z1i , Z2k )] 6= 0) by (B.47)-(B.50)
                    √
                      N(N − 1)
       E[|Wµ,2 |] ≤            E[|aN,µ (Ỹi , Zi , Z1i , Z2k )|]
                       N2
                    √          q
                      N(N − 1)
                  ≤      2
                                 E[|aN,µ (Ỹi , Zi , Z1i , Z2k )|2 ]
                     „N             «
                           1 −L+ L2
                  = O N − 2 bN    2



                        „             L
                                         «
                              1 −L+ 2
so that that term is Op N − 2 bN       2
                                           . In the same way by (B.47)-(B.50) the fourth term of the remainder is
   „            L1
                   «
         1 −L+
Op N − 2 bN      2
                    . For the fifth term (note aN,µ (Ỹi , Zi , Z1j , Z2j ) = 0)

                  N 2 (N − 1)                                       “        ”
           2
        E[Wµ,4 ]=        6
                              E[aN,µ (Ỹi , Zi , Z1j , Z2j )2 ] = O N −3 b−L
                                                                          N
                       N
                         “             ”
                                 −L/2
so that that term is Op N −3/2 bN        . Finally, the sixth term (note E[aN,µ (Ỹi , Zi , Z1i , Z2i )] 6= 0) is by a similar
                                                                  “          ”
argument as for the third term and by (B.47)-(B.50), Op N −1/2 b−L        N    . This is the largest term in the projection
remainder.
This finishes the proof of
                       “   1
                                 ”
       Wµ = Uµ + Op N − 2 b−L N                                                                                        (B.72)

Note again that the remainder is smaller if we redefine the kernel estimators. In that case the sixth term of the
projection remainder is 0.


Step 4: Asymptotic distribution The fourth step in the proof is the derivation of the asymptotically
normal distribution of the projection Uµ . In particular, we show that U0 is asymptotically normal and we obtain
the variance of that distribution. We show that Uµ /bN also converges to a normal distribution for |µ| ≥ 1 so
that Uµ = Op (bN ) if |µ| ≥ 1. Because W in (B.36) is a linear combination of the Wµ that are asymptotically
equivalent to the Uµ if a rate condition is met, W is asymptotically equivalent to U0 under that rate condition.
Define
                       Z Z                            „                     «
                   1                                    Zi − rbN (z1 , z2 )
       ψN,µ,i ≡ L+|µ|          ν(z1 , z2 )0 Ỹi K (µ)                         ((z10 z20 )0 − rbN (z1 , z2 ))µ fZ1 (z1 )fZ2 (z2 )dz1 dz2
                bN       Z2 Z1                                bN

so that

        cN,µ (Ỹi , Zi ) = ψN,µ,i − E[ψN,µ,i ].

We have
                        Z    Z                           „                         «
                    1                                        Zi − rbN (z1 , z2 )
        ψN,0,i ≡                    ν(z1 , z2 )0 Ỹi K                                 fZ1 (z1 )fZ2 (z2 )dz1 dz2
                   bL
                    N   Z2    Z1                                   bN

The integration region Z1 × Z2 can be partitioned into a set where all components of z1 and z2 are in the internal
region, ZI1,bN × ZI2,bN , and its complement, Z1 × Z2 \ ZI1,bN × ZI2,bN . We define
                       Z       Z                         „          «    „          «
                    1                                      Z1i − z1        Z2i − z2
       ψN,0,i,0 ≡ L                  ν(z1 , z2 )0 Ỹi K1              K2              fZ1 (z1 )fZ2 (z2 )dz1 dz2
                   bN ZI        ZI                           bN              bN
                             2,bN       1,bN


and
                    N
                1 X
        U0,0 ≡ √       (ψN,0,i,0 − E[ψN,0,i,0 ])
                 N I=1



                                                                          [63]
We apply the Liapounov central limit theorem for triangular arrays that requires
         ` ˆ                           ˜´2
      N 2 E |ψN,0,i,0 − E[ψN,0,i,0 ]|3
                                           →0
              N 3 Var(ψN,0,i,0 )

and a sufficient condition is that E [|ψN,0,i,0 |m ] < ∞ for m = 1, 2, 3. By a change of variables to t1 = (Z1i −z1 )/bN
and t2 = (Z2i − z2 )/bN with Jacobians bL              L2
                                            N and bN , respectively
                                              1



        |ψN,0,i,0 |m
           ˛Z Z L „                                                              « L2 „                                                «
           ˛         Y                                               Z1li − zl1l Y
                       1
           ˛                     Z1li − zu1l                                                   Z2li − zu2l                 Z2li − zl2l
         =˛              1 1+                     ≤ t1l ≤ −1 +                         1 1+                 ≤ t2l ≤ −1 +
           ˛ U1 U2                   bN                                  bN                        bN                          bN
                     l=1                                                           l=1
                                                                                                            ˛m
                                        0                                                                   ˛
         ×ν (Z1i − bN t1 , Z2i − bN t2 ) Ỹi K1 (t1 )K2 (t2 )fZ1 (Z1i − bN t1 )fZ2 (Z2i − bN t2 )dt1 dt2 ˛
             Z Z Y     L1   „                                                     « L2 „                                                «
                                  Z1li − zu1l                         Z1li − zl1l Y             Z2li − zu2l                 Z2li − zl2l
         ≤                1 1+                      ≤ t1l ≤ −1 +                        1 1+                 ≤ t2l ≤ −1 +
               U1 U2 l=1               bN                                 bN        l=1
                                                                                                    bN                          bN
                                                                                                                        ”m
         ×|ν (Z1i − bN t1 , Z2i − bN t2 ) | · |Ỹi | · |K1(t1 )| · |K2(t2 )|fZ1 (Z1i − bN t1 )fZ2 (Z2i − bN t2 )dt1 dt2
                                                       n                o             n               o
                                                                Z −z                           Z −z
by the Cauchy-Schwartz inequality . Because max −1, 1 + jlib ujl ≤ tjl ≤ min 1, −1 + jlib ljl , j = 1, 2
                                                                    N                             N
if and only if zljl + bN ≤ Zjli − bN tjl ≤ zujl − bN , we obtain by Assumptions 3.1, 4.1 and smoothness

        |ψN,0,i,0 |m ≤ C|Ỹi |m                                                                                               (B.73)

and E[|Ỹ |3 ] is finite by Assumption 3.1. Therefore the condition of the Liapounov theorem holds.
The above expressions also show that for almost all Z1i , Z2i

        ψN,0,i,0 → ν (Z1i , Z2i )0 Ỹi fZ1 (Z1i )fZ2 (Z2i )
                   m
and by (B.73) E[ψN,0,i,0 ] converges to the corresponding expectation by dominated convergence. The conclusion
is that U0,0 has the same asymptotic distribution as

         1 Xn                                                                                     o
             N
        √       ν (Z1i , Z2i )0 Ỹi fZ1 (Z1i )fZ2 (Z2i ) − E[ν (Z1 , Z2 )0 Ỹ fZ1 (Z1 )fZ2 (Z2 )]                             (B.74)
          N i=1

We still have to derive the stochastic order of
                    N
                1 X
        U0,1 ≡ √       (ψN,0,i,1 − E[ψN,0,i,1 ])
                 N I=1

with the integration region in ψN,0,i,1 , i.e. Z1 × Z2 \ ZI1,bN × ZI2,bN , such that at least one component of z1 or z2 is
in the boundary region. We partition Z1 ×Z2 \ZI1,bN ×ZI2,bN into subsets ZB                          B
                                                                                      1,bN ,p1 ×Z1,bN ,p2 , p1 = 1, . . . , 2
                                                                                                                             L1
                                                                                                                                , p2 =
1, . . . , 2L2 , min{p1 , p2 } ≥ 1 and in each such set 0 ≤ L1p1 ≤ L1 , 0 ≤ L2p2 ≤ L2 , min{L1p1 L1p1 } ≥ 1 components
of z1 and z2 are near the boundary. We take without loss of generality ZB                               I         B
                                                                                          1,bN ,1 = Z1,bN and Z2,bN ,1 = Z2,bN
                                                                                                                                   I

so that we exclude the set with p1 = p2 = 1 because in that set all components are in the internal region. For
                                                                                                L1pj
j = 1, 2 each ZB                                                B
                     j,bN ,pj is partitioned further into sets Zj,bN ,pj ,rj , rj = 1, . . . , 2      in which 0 ≤ Kjrj ≤ Ljrj
components of zj are near the lower, Ljrj − K1rj are near the upper boundary, and the remaining Lj − Ljpj
components are in the internal set. Without loss of generality we assume that the first Kjrj components of zj
are near the lower boundary, the next Ljpj − Kjrj are near the upper boundary, and the remaining components




                                                                [64]
are in the internal set, j = 1, 2. Therefore
                      ˛     Z                                        „                       «                           ˛m
                      ˛                                                  Zi − rbN (z1 , z2 )                             ˛
                  m   ˛ 1                                    0                                                           ˛
       |ψN,0,i,1 | = ˛ L                          ν(z1 , z2 ) Ỹi K                            fZ1 (z1 )fZ2 (z2 )dz1 dz2 ˛      (B.75)
                      ˛ bN Z2 ×Z1 \ZI ×ZI                                      bN                                        ˛
                                       1,bN  2,bN
                             Z                                         ˛ „                       «˛                            !m
                          1                                            ˛     Zi − rbN (z1 , z2 ) ˛˛
                    ≤                                                  ˛
                                                   |ν(z1 , z2 )||Ỹi | ˛K
                         bL                                                         bN             ˛ fZ1 (z1 )fZ2 (z2 )dz1 dz2
                          N    Z2 ×Z1 \ZI   ×ZI      1,bN           2,bN

                         XXXX                                       Z   zl21 +bN            Z    zl2K2r +bN            Z   zu2,K2r +1                 Z   zu2,L2p          Z    zu2,L2p +1 −bN                Z   zu2,L2 −bN
                                                         1                                             2                          2                                2                   2
                     ≤                                                                ···                                                       ···                                                     ···
                          p1        p2    r1   r2
                                                        bL
                                                         N           zl21                       zl2K2r                  zu2,K2r +1 −bN                zu2,L2p −bN              zl2,L2p +1 +bN                 zl2,L2 +bN
                                                                                                         2                     2                               2                      2
                    Z    zl,l1 +bN             Z   zl,1K1r +bN              Z   zu1,K1r +1                    Z    zu1,L1p           Z    zu1,L1p +1 −bN               Z   zu1,L1 −bN
                                                                1                      1                                         1               1
                                         ···                                                         ···                                                       ···                           |ν(z1 , z2 )||Ỹi |
                        zl,l1                  zl,1K1r                       zu1,K1r +1 −bN                       zu1,L1p −bN            zu1,L1p +1 +bN                zl1,L1 +bN
                                                            1                       1                                    1                      1

                     Y ˛˛   „               «˛                                                  ˛   „               «˛                                    ˛   „          «˛
                    K1r1                                                            L1p1                                                      L1
                                             ˛                                      Y           ˛                    ˛                        Y           ˛               ˛
                        ˛K1l Z1li − zl1l − 1 ˛                                                  ˛K1l Z1li − zl1l + 1 ˛                                    ˛K1l Z1li − z1l ˛
                        ˛        bN          ˛                                                  ˛        bN          ˛                                    ˛       bN      ˛
                     l=1                                                     l=K1r1 +1                                                   l=L1p1 +1

                    K2r1 ˛   „                  «˛ LY  2p2    ˛    „              «˛
                     Y ˛                         ˛            ˛                    ˛
                         ˛K2l Z2li − zl2l − 1 ˛               ˛K2l Z2li − zu2l + 1 ˛
                         ˛         bN            ˛            ˛           bN       ˛
                     l=1                           l=K2r2 +1
                                                                             1m
                        L2   ˛    „             «˛
                       Y     ˛      Z2li − z 2l  ˛
                             ˛K2l                ˛ fZ1 (z1 )fZ2 (z2 )dz1 dz2 A
                             ˛         bN        ˛
                     l=L2p2 +1


By a change of variables to t1l = (Z1li − z1l )/bN , l = L1p1 + 1, L1 and t2l = (Z2li − z2l )/bN , l = L2p2 + 1, L2 with
          L−L1p1 −L2p2
Jacobian bN             we have

                         XXXX                                                           Z   zl,21 +bN              Z    zl,2K2r +bN       Z    zu2,K2r +1                  Z    zu2,L2p         Z   1
                                                                        1                                                      2                      2                                  2
        |ψN,0,i,1 |m ≤                                      m(L1p1 +L2p2 )
                                                                                                             ···                                                    ···
                          p1        p2    r1   r2      bN                                  zl,21                       zl,2K2r
                                                                                                                                 2
                                                                                                                                              zu2,K2r +1 −bN
                                                                                                                                                     2
                                                                                                                                                                               zu2,L2p −bN
                                                                                                                                                                                     2
                                                                                                                                                                                                  −1
                          Z     1   Z    zl,l1 +bN       Z          zl,1K1r +bN         Z    zu1,K1r +1                      Z   zu1,L1p         Z    1
                                                                                1                   1                                     1
                    ···                              ···                                                               ···
                            −1       zl,l1                      zl,1K1r                     zu1,K1r +1 −bN                   zu1,L1p −bN             −1
                                                                            1                      1                                1
                          Z     1   2
                                    Y          Lj
                                               Y            „                                             «
                                                                    Zjli − zujl             Zjli − zljl
                    ···                                 1                       + 1 ≤ tjl ≤             −1
                            −1 j=1 l=L                                  bN                      bN
                                      jpj +1


                    |ν(z11 , . . . , z1L1p1 , Z1,L1p1 +1,i − bN t1L1p1 +1 , . . . , Z1,L1 ,i
                     − bN t1L1 , z21 , . . . , z2L2p2 , Z2,L2p2 +1,i                         − bN t2L2p2 +1 , . . . , Z2,L2 ,i − bN t2L2 )||Ỹi|
                     Y ˛˛      „                        «˛ LY                                ˛    „                     «˛
                    K1r1                                      1p1
                                                         ˛                                   ˛                            ˛
                         ˛K1l Z1li − zl1l − 1 ˛                                              ˛K1l Z1li − zl1l + 1 ˛
                         ˛              bN               ˛                                   ˛          bN                ˛
                     l=1                                                     l=K1r1 +1

                       ˛
                    K2r1   „               «˛                                       L2p2        ˛   „               «˛
                     Y ˛                    ˛                                       Y           ˛                    ˛
                       ˛K2l Z2li − zl2l − 1 ˛                                                   ˛K2l Z2li − zu2l + 1 ˛
                       ˛        bN          ˛                                                   ˛        bN          ˛
                     l=1                                                     l=K2r2 +1

                          L1                                    L2
                          Y                                 Y
                                        |K1l (t1l )|                        |K2l (t2l )| fZ1 (z11 , . . . , z1L1p1 , Z1,L1p1 +1,i − bN t1L1p1 +1 , . . . , Z1,L1 ,i − bN t1L1 )
                    l=L1p1 +1                          l=L2p2 +1

                    fZ2 (z21 , . . . , z2L2p2 , Z2,L2p2 +1,i − bN t2L2p2 +1 , . . . , Z2,L2 ,i − bN t2L2 )dz11 · · · dz1L1p1 dt1,L1p1 +1 · · · dt1L1
                                                                ´m
                     dz21 · · · dz2L2p2 dt2,L2p2 +1 · · · dt2L2

In this integral the function ν takes only values in the support Z and this function and the kernel functions are




                                                                                            [65]
bounded by smoothness and Assumption 4.1 so that

      |ψN,0,i,1 |m
                          XXXX                                   1
       ≤ C|Ỹi |m                                       m(L  +L   )
                           p1    p2    r1        r2    bN 1p1 2p2
           0
            ˛   „K1r1            «˛                                        L1p1      ˛   „               «˛
          Y ˛                     ˛                                        Y         ˛                    ˛
       ×@   ˛K1l Z1li − zl,11 − 1 ˛                                                  ˛K1l Z1li − zl1l + 1 ˛
            ˛         bN          ˛                                                  ˛        bN          ˛
                 l=1                                                 l=K1r1 +1

         ˛
       K2r1  „               «˛                                  L2p2       ˛   „               «˛
       Y ˛                    ˛                                  Y          ˛                    ˛
         ˛K2l Z2li − zl2l − 1 ˛                                             ˛K2l Z2li − zu2l + 1 ˛
         ˛        bN          ˛                                             ˛        bN          ˛
       l=1                                                  l=K2r2 +1
       Z   zl,21 +bN            Z   zl,2K2r +bN             Z   zu2,K2r +1                 Z   zu2,L2p        Z       1
                                                 2                     2                                  2
                          ···                                                        ···
        zl,21                    zl,2K2r                    zu2,K2r +1 −bN                  zu2,L2p −bN           −1
                                             2                     2                               2
             Z   1   Z   zl,l1 +bN           Z       zl,1K1r +bN       Z   zu1,K1r +1                 Z   zu1,L1p           Z     1         Z   1
                                                            1                     1                                   1
       ···                             ···                                                      ···                                   ···
              −1        zl,l1                    zl,1K1r                zu1,K1r +1 −bN                zu1,L1p −bN             −1            −1
                                                            1                  1                                  1

      fZ1 (z11 , . . . , z1L1p1 , Z1,L1p1 +1,i − bN t1L1p1 +1 , . . . , Z1,L1 ,i − bN t1L1 )
       × fZ2 (z21 , . . . , z2L2p2 , Z2,L2p2 +1,i − bN t2L2p2 +1 , . . . , Z2,L2 ,i − bN t2L2 )
                                                                                               ´m
       dz11 · · · dz1L1p1 dt1,L1p1 +1 · · · dt1L1 dz21 · · · dz2L2p2 dt2,L2p2 +1 · · · dt2L2
                                                                                                              L           +L2p2
Because the density is bounded, the integral is bounded by CbN1p1                                                                 . Moreover because the kernel has
support [−1, 1]L and is bounded on that support we have that

       Y ˛˛   „               «˛                                            ˛   „               «˛
       K1r1                                                      L1p1
                               ˛                                 Y          ˛                    ˛
          ˛K1l Z1li − zl1l − 1 ˛                                            ˛K1l Z1li − zl1l + 1 ˛
          ˛        bN          ˛                                            ˛        bN          ˛
       l=1                                                  l=K1r1 +1

           ˛
           K2r1„               «˛                                    L2p2      ˛   „               «˛
         Y ˛                    ˛                                    Y         ˛                    ˛
       ×   ˛K2l Z2li − zl2l − 1 ˛                                              ˛K2l Z2li − zu2l + 1 ˛
           ˛        bN          ˛                                              ˛        bN          ˛
             l=1                                                 l=K2r2     +1

                 K1r1                                                         L1p1
                  Y                                                              Y
       ≤C                1 (zl1l ≤ Z1li ≤ zl1l + 2bN )                                     1 (zl1l − 2bN ≤ Z1li ≤ zl1l )
                  l=1                                                      l=K1r1 +1

                                                                       K2r1                                                     L2p2
                                                                        Y                                                         Y
                                                                  ×              1 (zl2l ≤ Z2li ≤ zl2l + 2bN )                                  1 (zu2l − 2bN ≤ Z2li ≤ zu2l )
                                                                        l=1                                                 l=K2r2 +1


Therefore
                                                  1r1                   K                                                         L1p1
                                             XXXX Y                                                                                   Y
      |ψN,0,i,1 |m ≤ C|Ỹi |m                                                     1 (zl1l ≤ Z1li ≤ zl1l + 2bN )                                 1 (zl1l − 2bN ≤ Z1li ≤ zu1l )
                                             p1        p2   r1    r2       l=1                                               l=K1r1 +1

                                K2r1                                                        L2p2
                                Y                                                              Y
                          ×            1 (zl2l ≤ Z2li ≤ zl2l + 2bN )                                  1 (zu2l − 2bN ≤ Z2li ≤ zu2l )
                                l=1                                                    l=K2r2 +1


and because E[|Ỹ |3 |Z = z] is bounded on Z and the density of Z is bounded, we have because L1p1 + L2p2 ≥ 1
for m = 1, 2, 3

      E [|ψN,0,i,1 |m ] = O(bN )

By the Liapounov central limit theorem U01 /bN converges in distribution and hence

      U01 = Op (bN )                                                                                                                                                    (B.76)




                                                                                            [66]
Step 5: Ignoring Higher Order Terms The final step is to show that Uµ is asymptotically negligible
if |µ| ≥ 1. Note that if |µ| ≥ 1, then the integrand in ψN,µ,i is 0 if z1 and z2 are both in the internal region.
Hence we can take the integration region such that at least one component of either z1 or z2 is in the boundary
region

      |ψN,µ,i |m
          ˛           Z                                                 „                     «                                                           ˛m
          ˛                                                               Zi − rbN (z1 , z2 )                                                             ˛
          ˛ 1                                                                                                                                             ˛
       = ˛ L+|µ|                                ν(z1 , z2 )0 Ỹi K (µ)                          ((z10 z20 )0 − rbN (z1 , z2 ))µ fZ1 (z1 )fZ2 (z2 )dz1 dz2 ˛
          ˛b                     I
                        Z2 ×Z1 \Z1,b ×Z2,bI                                      bN                                                                       ˛
             N                       N        N
                        Z                                             ˛      „                    «˛
                 1                                                    ˛        Zi − rbN (z1 , z2 ) ˛˛
       ≤      L+|µ|
                                                 |ν(z1 , z2 )||Ỹi | ˛˛K (µ)                         ˛
             bN                    I
                         Z2 ×Z1 \Z1,b ×Z2,b I                                        bN
                                      N        N
                                                                        ”m
       |(z10 z20 )0 − rbN (z1 , z2 )||µ| fZ1 (z1 )fZ2 (z2 )dz1 dz2
                   Z                                              ˛     „                     «˛                              !m
              1                                                   ˛ (µ) Zi − rbN (z1 , z2 ) ˛
       ≤                                                          ˛
                                              |ν(z1 , z2 )||Ỹi | ˛K                            ˛
             bL                                                                   bN            ˛ fZ1 (z1 )fZ2 (z2 )dz1 dz2
              N      Z2 ×Z1 \ZI
                            1,bN    ×ZI2,bN

                                                                                                                                            Uµ
We obtained a bound on the right hand side in (B.75). Therefore by the Liapounov central limit theorem                                      bN
converges in distribution so that if |µ| ≥ 1

      Uµ = Op (bN )                                                                                                                     (B.77)

By (B.33) (linearization), (B.34) (bias), (B.72) (projection), (B.76) (boundary remainder), and (B.77) (NIP
remainder) we have that
                                   N X
                                   X N
      √                    1
          N (θ̂ − θ) =     √           (n(h0 (Z1j , Z2k )) − θ)                                                                         (B.78)
                         N N       j=1 k=1
                           N                                                    »                                    –ff
                       1 X ∂n                                                      ∂n
                    +√              (h0 (Zi ))0 Ỹi fZ1 (Z1i )fZ2 (Z2i ) − EỸ Z      (h0 (S))0 Ỹ fZ1 (Z1 )fZ2 (Z2 )
                        N i=1 ∂h                                                   ∂h
                         „    ˛             ˛  «
                           √ ˛              ˛2           √
                    + Op    N ˛ĥnip,s − h0 ˛ + O( N bpN ) + Op (N −1 b−L        N ) + Op (bN )


The first term on the right hand side is a V statistic that is asymptotically equivalent to
            N
        1 X
       √       {(E[n(h0 (Z1i , Z2 )) − θ) + E[n(h0 (Z1 , Z2i )) − θ)} .
         N i=1


Proof of Lemma A.24: Using Lemma A.14, the assumptions imply that
                                      „        «1/2      !
                                        ln(N )               `    ´
        sup |ĝ(w, x) − g(w, x)| = Op        2      + bN = op N −η ,
                                                       s
                                                                                                                                        (B.79)
     w∈W,x∈X                            N · bN

For 1/4 < δ < 1/4s we can find an η > 1/4 such that this holds. Using the definitions preceding the statement
of the Lemma, we have, by adding and subtracting terms,

      βbcm(ρ, 0) − β cm(ρ, 0) = (βbcm (ρ, 0) − β̂gcm )                                                                                  (B.80)
                                          cm        cm
                                   −   (β̂W    −g        )                                                                              (B.81)
                                          cm        cm
                                   −   (β̂X    −g        )                                                                              (B.82)
                                       “                  ”   “          ”    “              ”
                                   + β̂gcm − g cm + β̂W
                                                      cm
                                                         − g cm + β̂X
                                                                    cm
                                                                       − g cm + (gcm − β cm(ρ, 0)) .
                                                                                      “      ”
The result then follows if we can show that the sum of (B.80), (B.81) and (B.82) is op N −1/2 . Define
                        “                               ”
                      φc Φ−1             −1
                           c (F̂W (w)), Φc (F̂X (x)); ρ
      ω̂ cm (w, x) =   “             ” “                 ”,
                     φc Φ−1                 −1
                          c (F̂W (w)) φc Φc (F̂X (x))



                                                                   [67]
                        “                              ”
                      φc Φ−1             −1
                           c (F̂W (w)), Φc (FX (x)); ρ
         cm
       ω̂W  (w, x) =   “             ” `                ´,
                     φc Φ−1                 −1
                          c (F̂W (w)) φc Φc (FX (x))

and
                          “                              ”
                        φc Φ−1            −1
                             c (FW (w)), Φc (F̂X (x)); ρ
         cm
       ω̂X  (w, x)   =   `            ´ “ −1              ”,
                       φc Φ−1
                            c (FW (w)) φc Φc (F̂X (x))


Then, using the definition of ω cm (w, x) given in (4.32), we can write the sum of these three components as

       (βbcm(ρ, 0) − β̂gcm) − (β̂W
                                 cm
                                    − g cm) − (β̂X
                                                 cm
                                                    − g cm )
                         N N
                      1 XX
                =      2
                                             ω cm (Wi , Xj ) − ω cm (Wi , Xj )]
                               ĝ(Wi , Xj ) [b
                     N i=1 j=1
                                  N   N
                              1 XX
                         −                            ωW (Wi , Xj ) − ω cm (Wi , Xj )]
                                         g(Wi , Xj ) [b
                             N 2 i=1 j=1
                                  N   N
                              1 XX
                         −                            ωX (Wi , Xj ) − ω cm (Wi , Xj )]
                                         g(Wi , Xj ) [b
                             N 2 i=1 j=1
                         N N
                      1 XX
                =      2
                                             ω cm (Wi , Xj ) − ω cm (Wi , Xj )]
                               ĝ(Wi , Xj ) [b
                     N i=1 j=1
                         N   N                                                           N   N
                     1 XX                       cm                 cm                1 XX
                −               g(Wi , X j ) [b
                                              ω    (Wi , X j ) − ω    (Wi , X j )]+                          ω cm (Wi , Xj ) − ω
                                                                                                g(Wi , Xj ) [b                 bW (Wi , Xj )]
                    N 2 i=1 j=1                                                     N 2 i=1 j=1
                                  N   N
                              1 XX
                         −                            ωX (Wi , Xj ) − ω cm (Wi , Xj )]
                                         g(Wi , Xj ) [b
                             N 2 i=1 j=1
                         N N
                      1 XX
                =      2
                                                             ω cm (Wi , Xj ) − ω cm (Wi , Xj )]
                               [ĝ(Wi , Xj ) − g(Wi , Xj )] [b                                                                (B.83)
                     N i=1 j=1
                              N    N
                          1 XX
                         +                         ω cm (Wi , Xj ) − ω
                                      g(Wi , Xj ) [b                                 bX (Wi , Xj ) + ω cm(Wi , Xj )]
                                                                     bW (Wi , Xj ) − ω                                        (B.84)
                        N 2 i=1 j=1
                                                                    “       ”
It remains to be shown that both (B.83) and (B.84) are op N −1/2 .
Now define
                        `                        ´
                     φc Φ−1           −1
                            c (z1 ), Φc (z2 ); ρ
      k(z1 , z2 ) =   `          ´     `           ´        so that ω  b cm(w, x) = k(F̂W (w), F̂X (x)).                      (B.85)
                    φc Φ−1               −1
                          c (z1 ) · φc Φc (z2 )

By a second order Taylor expansion we have
                                       ∂k                                       ∂k
       b cm (w, x) − ω cm (w, x) =
       ω                                   (FW (w), FX (x))(F̂W (w) − FW (w)) +     (FW (w), FX (x))(F̂X (x) − FX (x))
                                       ∂z1                                      ∂z2
                             1 ∂2 k                                     2  1 ∂2 k
                         +        2 (F W (w), F X (x))(F̂W (w) − FW (w)) +        (F W (w), F X (x))(F̂X (x) − FX (x))2
                             2 ∂z1                                         2 ∂z22
           1 ∂2 k
       +             (F W (w), F X (x))(F̂W (w) − FW (w))(F̂X (x) − FX (x))
           2 ∂z1 ∂z2
with F W (w) and F X (x) intermediate values. By Lemma A.3 it follows that for any 0 < δ < 1/2, supx |F̂X (x) −
FX (x)| = op (N −δ ), and supw |F̂W (w) − FW (w)| = op(N −δ ). In combination with the fact that |∂ 2 k/∂z12 |,
|∂ 2 k/∂z22 |, and |∂ 2 k/∂z1 ∂z2 | are bounded, this implies that

       b cm (w, x) − ω cm (w, x)
       ω                                                                                                                      (B.86)
                     ∂k                                       ∂k                                                       “         ”
                =        (FW (w), FX (x))(F̂W (w) − FW (w)) +     (FW (w), FX (x))(F̂X (x) − FX (x)) + op                  N −1/2 .
                     ∂z1                                      ∂z2

                                                                [68]
The same argument implies that
                                   ∂k                                         “      ”
      bW (w, x) − ω cm (w, x) =
      ω                                (FW (w), FX (x))(F̂W (w) − FW (w)) + op N −1/2 ,
                                   ∂z1
and
                                  ∂k                                         “      ”
      bX (w, x) − ω cm (w, x) =
      ω                               (FW (w), FX (x))(F̂X (x) − FX (x)) + op N −1/2 .
                                  ∂z2
                                                            “      ”
Substituting in these results, it follows that (B.84) is op N −1/2 .
Equation (B.86) also implies, by Lemma A.3, that
                                    “      ”
      b cm (w, x) − ω cm (w, x) = op N −1/4 .
      ω
                                                               “      ”
In combination with (B.79), this implies that (B.83) is also op N −1/2 . 
Proof of Lemma A.25: The proof of this Lemma make use of an application of Theorem A.3. Using the
notation of that Theorem we have Z1 = W, Z2 = X, Ỹ = (Y, 1)0 ,
                  „                       «
                    g(w, x) · fW X (w, x)
       h (w, x) =
                        fW X (w, x)

and
                       h1 (w, x) cm
      n(h(w, x)) =               ω (w, x) = g(w, x) · ω cm (w, x).
                       h2 (w, x)
In terms of this notation we can write this in the form of Theorem A.3:

                        1 XX “                     ”
                            N   N                           N   N
                                                        1 XX
      β̂gcm − g cm =               n ĥ(Wi , X j )   −             n (h(Wi , Xj )) .
                       N 2 i=1 j=1                     N 2 i=1 j=1

We also have
                                 1
                                         !                            1
                                                                                !
       ∂n                    h2 (w,x)            cm               fW X (w,x)
          (h(w, x)) =         h1 (w,x)       ω        (w, x) =      g(w,x)          ω cm (w, x) ,
       ∂h                   − h (w,x)2                           −f
                               2                                    W X (w,x)


and hence
       ∂n                              fW (w)fX (x)
          (h(w, x))0 ỹfW (w)fX (x)) =              · (y − g(w, x)) · ω cm (w, x) ,
       ∂h                               fW X (w, x)
which is mean zero. Therefore, by the result of Theorem A.3, we have
                          N                                            »                                 –   “       ”
                       1 X ∂n                                            ∂n
 β̂gcm −β cm(ρ, 0) =            (h(Wi , Xi ))0 Ỹi fW (Wi )fX (Xi ))−E      (h(W, X))0 ỹY fW (W )fX (X)) +op N −1/2
                       N i=1 ∂h                                          ∂h

              N                                                       »                                            –   “       ”
           1 X fW (Wi )fX (Xi )                                         fW (W )fX (X)
       =                        ·(Yi − g(Wi , Xi ))·ω cm (Wi , Xi )−E                 · (Y − g(W, X)) · ω cm (W, X) +op N −1/2
           N i=1 fW X (Wi , Xi)                                          fW X (W, X)
                      N
                   1 X fW (Wi )fX (Xi )                                             “       ”
               =                         · (Yi − g(Wi , Xi )) · ω cm (Wi , Xi ) + op N −1/2
                   N i=1 fW X (Wi , Xi )
                      N
                   1 X cm                                      “      ”
               =         ψg (Yi , Wi , Xi ) + op (N −1/2 ) + op N −1/2 .
                   N i=1

Proof of Lemma A.26:            Using the definition of k(z1 , z2 ) in (B.85) and the Taylor expansion in the proof of
Lemma A.24 we have
                            N   N
        cm              1 XX                   ∂k
      β̂W  − g cm =                g(Wi , Xj )     (FW (Wi ), FX (Xj ))(F̂W (Wi ) − FW (Wi ))
                       N 2 i=1 j=1             ∂z1


                                                                 [69]
                                   N   N
                              1 1 XX                 ∂2k
                          +      2
                                          g(Wi , Xj ) 2 (F W (Wi ), F X (Xj ))(F̂W (Wi ) − FW (Wi ))2 .
                              2 N i=1 j=1            ∂z1

By Lemma A.3 supw |F̂W (w) − FW (w)| = op(N −δ ) for all δ < 1/2, and using the fact that the second derivatives
of k(z1 , z2 ) are bounded, this implies
                             N
                          1 XX
                                N
                                               ∂k                                                 “      ”
           cm
         β̂W  − g cm =     2
                                   g(Wi , Xj )     (FW (Wi ), FX (Xi ))(F̂W (Wi ) − FW (Wi )) + op N −1/2 .
                         N i=1 j=1             ∂z1

                                                                            ∂k
Inspection of the definition of eW (w, x) shows that eW (w, x) =            ∂s1
                                                                                (FW (w), FX (x))   and therefore

                             N
                          1 XX
                                N                                                      “       ”
           cm
         β̂W  − g cm =     2
                                   g(Wi , Xj )eW (Wi , Xj ) (F̂W (Wi ) − FW (Wi )) + op N −1/2
                         N i=1 j=1

                         N N
                      1 XXX
                               N                                                        “      ”
                 =     3
                                 g(Wi , Xj )eW (Wi , Xj ) (1 (Wk ≤ Wi ) − FW (Wi )) + op N −1/2 .
                     N i=1 j=1
                                     k=1
                              −1/2
This is, up to the op (N       ) term, a third order V -statistic,
                               “       ”
           cm
         β̂W  − g cm   = V + op N −1/2

where
                    N   N  N
                1 XXX
         V =                 ψ(Wi , Xi , Wj , Xj , Wk , Xk ),
               N 3 i=1 j=1
                              k=1

with

         ψ(w1 , x1 , w2 , x2 , w3 , x3 ) = g(w1 , x2 )eW (w1 , x2 ) (1 (w3 ≤ w1 ) − FW (w1).

Define

         ψ1 (w, x) = E [ψ(w, x, W2 , X2 , W3 , X3 )] ,         ψ2 (w, x) = E [ψ(W1 , X1 , w, x, W3 , X3 )] ,

         ψ3 (w, x) = E [ψ(W1 , X1 , W2 , X2 , w, x)] ,         and θ = E[ψ(W1 , X1 , W2 , X2 , W3 , X3 )].
Using V-statistic theory, this V-statistic can be approximated as

               1 X
                  N                                                                        “      ”
         V =         {(ψ1 (Wi , Xi ) − θ) + (ψ2 (Wi , Xi ) − θ) + (ψ3 (Wi , Xi ) − θ)} + op N −1/2 .
               N i=1

Note that E[ψ(w1 , x1 , w2 , x2 , W, X)] = 0. Hence θ = 0, ψ1 (w, x) = 0, and ψ2 (w, x) = 0. Thus,

               1 X
                  N                    “      ”
         V =         ψ3 (Wi , Xi ) + op N −1/2 .
               N i=1

                       N Z Z                                                              “      ”
                     1 X
                 =           g(s, t)eW (s, t) (1 (Wi ≤ s) − FW (s))fW (s) fX (t) dsdt + op N −1/2 ,
                     N
                        k=1
                        N
                     1 X cm                       “      ”
                 =         ψW (Yi , Wi , Xi ) + op N −1/2 ,
                     N i=1
as required. 
Proof of Lemma A.27: The proof is entirely analogous to that of Lemma A.26 and therefore omitted. 
Proof of Lemma A.28: Define

         ψ(w, x) = g(w, x) · ω cm(w, x),

         ψ1 (w) = E [ψ(w, X)] = E [g(w, X) · ω cm (w, X)] ,



                                                               [70]
and

       ψ2 (x) = E [ψ(W, x)] = E [g(W, x) · ω cm(W, x)] .

Then, by the V-Statistic Projection Theorem, given as Theorem A.4 in Appendix A, it follows that

                             1 X
                                N                                                          “       ”
       g cm − β cm(ρ, 0) =         {(ψ1 (Wi ) − β cm(ρ, 0)) + (ψ2 (Xi ) − β cm(ρ, 0))} + op N −1/2
                             N i=1

                      N
                   1 X cm                       “      ”
               =         ψ0 (Yi , Wi , Xi ) + op N −1/2 .
                   N i=1
                                                                                 P    PN
Proof of Theorem A.4: Define φ(z1 , z2 ) = (ψ(z1 , z2 ) + ψ(z2 , z1 ))/2. Then V = N
                                                                                   i=1
                                                                                                         2
                                                                                        j=1 φ(Zi , Zj )/N is a
V-statistic with a symmetric kernel. In the notation of Lehman (1998),

       σ12 = Cov (φ(Zi , Zj ), φ(Zi , Zk )) ,

for i, j, k distinct, which simplifies to σ12 = σ2 /4. Therefore, by Theorems 6.1.2 (with a = 2) and 6.2.1 in Lehman
(1998), the result follows. .




                                                           [71]
                               Appendix C: Proofs of Theorems in Text

Proof of Theorem 3.1 Define

       Vλ,i = λ · Xi · d(Wi ) + Wi ,

       h(λ, a) = pr(Vλ ≤ a) = FVλ (a),          and      k(w, x, λ) = h(λ, λ · x · d(w, x) + w).
First we focus on
                     ˆ                       ˜   ˆ                           ˜
       β lr,v (λ) = E g(FW
                         −1                          −1
                            (FVλ (Vλ,i )), X) = E g(FW  (k(Wi , Xi, λ)), Xi ) .

We then prove four results. First, we show that for small λ, β lr,v (λ) and β lr (λ) are close, or

       β lr,v (λ) = β lr(λ) + o(λ).                                                                          (C.1)

Second, we show that

       β lr,v (λ) = E[g(W, X)]
                           »                                                        –
                             ∂g              1
                       +E       (Wi , Xi)          (k(Wi , Xi , λ) − k(Wi , Xi , 0)) + o(λ).                 (C.2)
                             ∂w           fW (Wi )
Next we show that β lr,v (λ) has the two representations in Theorem 3.1. In particular, the third part of the proof
                       lr,v
shows that β lc,v = ∂β∂λ (0) satisfies
                 »                                                                –
                   ∂g
      β lc,v = E       (Wi , Xi) · (Xi · d(Wi , Xi ) − E [ Xi · d(Wi , Xi )| Wi ]) .                          (C.3)
                   ∂w

Fourth, we show that β lc,v satisfies
                »                              –
                                ∂2 g
      β lc,v = E δ(Wi , Xi ) ·       (Wi , Xi ) .                                                            (C.4)
                               ∂w∂x

We start with the proof of (C.1). Define
                                         p
      u(w, x, λ) = λ · x · d(w, x)1−|λ| + 1 − λ2 · w,             and   u(w, x, λ) = λ · x · d(w, x) + w.

Then
                                               ` ´
            sup   |u(w, x, λ) − v(w, x, λ)| = O λ2 .
       w∈W,x∈X

Define also

       hU (λ, a) = pr(Uλ ≤ a),          and   kU (w, x, λ) = hU (λ, u(w, x, λ)).

Then
                                    ` ´
       sup |hU (λ, a) − h(λ, a)| = O λ2 ,
        a

and
                                                 ` ´
            sup   |kU (w, x, λ) − k(w, x, λ)| = O λ2 .
       w∈W,x∈X

Combined with the smoothness assumptions, this implies that
                             ˆ                            ˜   ˆ                              ˜
     β lr,v (λ) − β lr(λ) = E g(FW
                                 −1                               −1
                                    (k(Wi , Xi , λ)), Xi ) − E g(FW  (kU (Wi , Xi , λ)), Xi ) = O(λ2 ).

This finishes the proof of (C.1).
Next, we prove (C.2). Let c1 and c2 satisfy

        sup |k(w, x, λ + γ) − k(w, x, λ)| ≤ c1 · γ,
       x,w,γ,λ




                                                           [72]
and
              ˛ 2        ˛
              ˛ ∂        ˛
              ˛
         sup ˛ 2 g(w, x)˛˛ ≤ c2 ,
       w∈W,x∈X ∂w

                                                         −1
respectively. Then, applying Lemma A.1 with f (a) = g(FW    (a), x) and h(λ) = k(w, x, λ), we obtain
       ˛                                                                                               !˛
       ˛                                               ∂     −1                                         ˛
       ˛    −1                    −1                  ∂w g(FW (k(w, x, 0), x)                           ˛
       ˛g(FW (k(w, x, λ), x) − g(FW (k(w, x, 0), x) +        −1               (k(w, x, λ) − k(w, x, 0)) ˛
       ˛                                               fW (FW (k(w, x, 0)))                             ˛

                                ≤ c2 c21 λ2 = o(λ).
Since the bound does not depend on x and w, we can average over W and X and it follows that
       ˛                                         "                             #˛
       ˛ ˆ                    ˜                     ∂
                                                      g(W, X)                   ˛
       ˛     −1                                    ∂w                           ˛
       ˛E g(FW (k(W, X, λ), X) − E [g(W, X)] − E              (k(W, X, λ) − W ) ˛ ,
       ˛                                             fW (W )                    ˛

where we also use the fact that k(w, x, 0) = FW (w). This finishes the proof of (C.2).
Now we prove (C.3). By definition,

       h(λ, a) = Pr (Vλ,i < a) = Pr (Vλ,i < a, Wi < wm ) + Pr (Vλ,i < a, Wi ≥ wm )

               = Pr (λ · Xi · d(Wi , Xi ) + Wi ≤ a, Wi < wm )
                         +Pr (λ · Xi · d(Wi , Xi ) + Wi ≤ a, Wi ≥ wm ) .
               = Pr (λ · Xi · (Wi − wl ) + Wi ≤ a, Wi < wm )
                      +Pr (λ · Xi · (wu − Wi ) + Wi ≤ a, Wi ≥ wm )
                     „           „                        ««
                                        a + λ · Xi · w l
               = Pr Wi ≤ min wm ,
                                          1 + λ · Xi
                           „                                 «
                                          a − λ · Xi · w u
                      +Pr wm ≤ Wi ≤                            .
                                              1 − λ · Xi
For λ sufficiently close to zero, we can write this as
                                                           „                         «
                                                                    a + λ · Xi · w l
       h(λ, a) = 1a>wm · Pr(Wi ≤ wm ) + 1a≤wm · Pr Wi ≤
                                                                       1 + λ · Xi
                                    „                                  «
                                                      a − λ · Xi · w u
                      +1a>wm · Pr wm < Wi ≤
                                                         1 − λ · Xi
                             „                          «
                                      a + λ · Xi · w l
               = 1a≤wm · Pr Wi ≤
                                        1 + λ · Xi
                                    „                          «
                                             a − λ · Xi · w u
                      +1a>wm · Pr Wi ≤
                                                1 − λ · Xi
                            » „                            ˛ «–
                                         a + λ · Xi · wl ˛˛
               = 1a≤wm · E Pr Wi ≤                          Xi
                                            1 + λ · Xi ˛
                                   » „                             ˛ «–
                                                  a − λ · Xi · wu ˛˛
                      +1a>wm · E Pr Wi ≤                             Xi
                                                    1 − λ · Xi ˛
                          Z        „                  ˛ «
                                      a + λ · z · wl ˛˛
               = 1a≤wm · FW |X                          z fX (z)dz
                                        1+λ·z ˛
                                 Z        „                  ˛ «
                                             a − λ · z · wu ˛˛
                      +1a>wm · FW |X                           z fX (z)dz
                                                1−λ·z ˛
Substituting a = λ · x · d(w, x) + w, we get
                                       Z     „                                   ˛ «
                                               λ · x · d(w, x) + w + λ · z · wl ˛˛
       k(w, x, λ) = 1λ·x·d(w,x)+w≤wm · FW |X                                     ˛ z fX (z)dz
                                                            1+λ·z
                                           Z    „                                    ˛ «
                                                   λ · x · d(w, x) + w − λ · z · wu ˛˛
                     +1λ·x·d(w,x)+w>wm · FW |X                                       ˛ z fX (z)dz
                                                               1−λ·z

                                                            [73]
                                                                  Z           „                      ˛ «
                                                                 λ · x · (w − wm) + w + λ · z · wl ˛˛
                     = 1λ·x·(w−wl )+w≤wm 1w≤wm ·                      FW |X                          ˛ z fX (z)dz
                                                                                1+λ·z
                                                             Z         „                                     ˛ «
                                                                          λ · x · (wu − w) + w + λ · z · wl ˛˛
                           +1λ·x·(wu −w)+w≤wm 1w>wm · FW |X                                                  ˛ z fX (z)dz
                                                                                         1+λ·z
                                                             Z         „                                       ˛ «
                                                                          λ · x · (w − wm ) + w − λ · z · wu ˛˛
                           +1λ·x·(w−wl )+w>wm · 1w≤wm FW |X                                                    ˛ z fX (z)dz
                                                                                         1−λ·z
                                                              Z        „                                       ˛ «
                                                                           λ · x · (wu − w) + w − λ · z · wu ˛˛
                           +1λ·x·(wu −w)+w>wm · 1w>wm FW |X                                                    ˛ z fX (z)dz
                                                                                         1−λ·z
                                                     Z          „                                     ˛ «
                                                                  λ · x · (w − wm ) + w + λ · z · wl ˛˛
                     = 1w≤wm (1+λxwl /wm )/(1+λx) · FW |X                                             ˛ z fX (z)dz
                                                                                 1+λ·z
                               Z         „                                         ˛ «
                                            λ · x · (wu − w) + w + λ · z · wl ˛˛
                           +0 · FW |X                                              ˛ z fX (z)dz
                                                           1+λ·z
                                                                  Z          „                                      ˛ «
                                                                                λ · x · (w − wm ) + w − λ · z · wu ˛˛
                           +1wm (1+λxwl /wm )/(1+λx)≤w≤wm · FW |X                                                   ˛ z fX (z)dz
                                                                                              1−λ·z
                                      Z          „                                        ˛  «
                                                    λ · x · (wu − w) + w − λ · z · wu ˛˛
                           +1w≥wm · FW |X                                                 ˛ z fX (z)dz.
                                                                 1−λ·z
The last equality uses the following four facts: (i), λ · x · (w − wl ) + w ≤ wm implies w ≤ wm(1 + λxwl /wm )/(1 +
λx) ≤ wm , (ii) λ·x·(wu−w)+w ≤ wm implies w ≤ wm (1−λxwu /wm )/(1−λx) < wm , (iii), λ·x·(w−wl)+w > wm
implies w ≥ wm (1+λxwl/wm )/(1+λx), and (iv) λ·x·(wu−w)+w > wm implies w ≥ wm (1−λxwu/wm )/(1−λx).
Now we will look at
         »                                       –
           ∂g               1
       E      (Wi , Xi )          k(Wi , Xi , λ)
           ∂w            fW (Wi )
                 Z xu Z wu
                             ∂g            1
              =                  (w, x)           k(w, x, λ)fW,X (w, x)dwdx.
                  xl     wl  ∂w         f W (w)
Substituting the three terms of k(w, x, λ) in here we get
         »                                       –
           ∂g               1
       E      (Wi , Xi )          k(Wi , Xi , λ)
           ∂w            fW (Wi )

            Z         Z         1+λxwl /wm
                                             ∂g               Z           „                                      ˛ «
                xu         wm      1+λx
                                             ∂w
                                                   (w, x)                     λ · x · (w − wl) + w + λ · z · wl ˛˛
       =                                                          FW |X                                          ˛ z fX (z)dzfW,X (w, x)dwdx
               xl         wl                     fW (w)                                   1+λ·z
                                                                                                                                       (C.5)

           Z          Z                      ∂g             Z             „                                       ˛ «
                xu        wm
                                             ∂w    (w, x)                     λ · x · (w − wl ) + w − λ · z · wu ˛˛
       +                                                          FW |X                                           ˛ z fX (z)dzfW,X (w, x)dwdx
               xl         wm
                               (1+λxwl /wm       fW (w)                                    1−λ·z
                                  1+λx

                                                                                                                                       (C.6)
            Z         Z    wu ∂g             Z            „                                      ˛ «
                 xu
                              ∂w    (w, x)                    λ · x · (wu − w) + w − λ · z · wu ˛˛
        +                                         FW |X                                          ˛ z fX (z)dzfW,X (w, x)dwdx           (C.7)
                xl        wm      fW (w)                                   1−λ·z
Next, we take the derivative with respect to λ for each of these three terms, and evaluate that derivative at
λ = 0. For the first term, (C.5) this derivative consists of two terms, one corresponding to the derivative with
respect to the λ in the bounds of the integral, and one corresponding to the derivative with respect to λ in the
integrand. For the second term we only have the term corresponding to the derivative with respect to the λ in
the bounds of the integral since the other term vanishes when we evaluate it at λ = 0. The third term, (C.6)
only has λ in the integrand. So,
             »                                      –˛
        ∂      ∂g               1                     ˛
           E      (Wi , Xi )          k(Wi , Xi , λ) ˛˛
       ∂λ      ∂w            fW (Wi )                  λ=0
                                »                 ˛         –
                                   ∂              ˛
              = (wl − wm ) · E        g(wm , Xi )˛˛ Wi = wm
                                  ∂w

                                                                                  [74]
              Z   xu   Z   wm                 Z xu
                        ∂                1
          +                 g(w, x)                fW |X (w|z) (x · (w − wl ) + z · wl − z · w) fX (z)dzfW,X (w, x)dwdx
             xl   wl   ∂w            fW (w) xl
                                  »                 ˛          –
                                     ∂              ˛
                −(wl − wm) · E          g(wm , Xi )˛˛ Wi = wm
                                    ∂w
            Z xu Z wm                         Z xu
                        ∂                1
          +                 g(w, x)                fW |X (w|z) (x · (wu − w) + z · w − z · wu ) fX (z)dzfW,X (w, x)dwdx
             xl   wl   ∂w            fW (w) xl
                  Z xu Z wm                 Z xu
                                ∂
                =                  g(w, x)       fX|W (z|w) (x · d(w, x) − z · d(w, z)) dzfW,X (w, x)dwdx
                   xl    wl   ∂w              xl
            Z xu Z wm                Z xu
                        ∂
          +                 g(w, x)        fX|W (z|w) (x · d(w, x)) − z · d(w, z)) dzfW,X (w, x)dwdx
             xl   wl   ∂w              xl
                  Z xu Z wu                Z xu
                               ∂
                =                  g(w, x)       fX|W (z|w) (x · d(w, x) − z · d(w, z)) dzfW,X (w, x)dwdx
                   xl    wl   ∂w             xl
                  Z xu Z wu
                               ∂
                =                  g(w, x) ((Xi · d(w, Xi) − E [ Xi · d(w, Xi ))| Wi = w]) fW,X (w, x)dwdx
                   xl    wl   ∂w
                    »                                                                –
                      ∂g
                =E        (Wi , Xi ) · (Xi · d(Wi , Xi) − E [ Xi · d(Wi , Xi )| Wi ]) = β lc,v .
                      ∂w
This finishes the proof of (C.3).
Finally, we show (C.4), by showing the equality of
                  »                                                     –
                    ∂g
       β lc,v = E      (Wi , Xi) · (Xi · d(Wi ) − E [ Xi · d(Wi )| Wi ]) ,                                         (C.8)
                    ∂w
and
          »                              –
                           ∂2 g
         E δ (Wi , Xi ) ·       (Wi , Xi) .                                                                        (C.9)
                          ∂w∂x
Define
                       »                                                  ˛      –
                      ∂g                                                  ˛
         b(w) = E        (w, Xi) · (Xi · d(w) − E [ Xi · d(w)| Wi = w])˛˛ Wi = w
                      ∂w
                      »                                              ˛       –
                        ∂g                                           ˛
                   =E      (w, Xi ) · d(w) · (Xi − E [ Xi | Wi = w])˛˛ Wi = w ,
                        ∂w
                                                                  ∂g
so that β lc,v = E[b(W )]. Apply Lemma A.2, with h(x) =           ∂w   (w, x) · d(w), to get
                  » 2                       –
                     ∂
       b(w) = E           g(w, X) · δ(w, X)
                   ∂w∂x
with
                                FX|W (x|w) · (1 − FX|W (x|w))
         δ(w, x) = d(w) ·                                     · (E [X|X > x, W = w] − E [X|X ≤ x, W = w]) .
                                        fX|W (x|w)

Thus
                                   »                         –
                                        ∂2
         β lc,v = E[b(W )] = E              g(W, X) · δ(W, X) .
                                       ∂w∂x

Proof of Theorem 4.1: We apply Lemmas A.15-A.18. The assumptions in the theorem imply that the
conditions for those lemmas are satisfied. 
Proof of Theorem 4.2: The proof is essentially the same as that for Theorem 4.1 and is omitted. 
Proof of Theorem 4.3: We apply Lemma’s A.24-A.28 to get an asymptotic linear representation for β̂ cm(ρ, τ ).
The assumptions in the Theorem imply that the conditions for the applications of these lemmas are satisfied.
Therefore, by Lemma A.24, we have
                                  “            ” “          ” “          ”                         “      ”
       β̂ cm(ρ, 0) = β cm (ρ, 0) + β̂gcm − g cm + β̂W
                                                    cm
                                                       − gcm + β̂X
                                                                 cm
                                                                    − gcm + (gcm − β cm(ρ, 0)) + op N −1/2 .


                                                              [75]
By Lemmas A.25-A.28, this is equal to

                         N
                      1 X ˘ cm                                                                                   ¯   “       ”
        β cm(ρ, 0)+                               cm
                            ψg (Yi , Wi , Xi ) + ψW                     cm
                                                     (Yi , Wi , Xi ) + ψX  (Yi , Wi , Xi ) + ψ0cm (Yi , Wi , Xi ) +op N −1/2
                      N i=1

                                                                                       1 X
                                                                                          N                       “      ”
                                                                    = β cm(ρ, 0) +           ψ(Yi , Wi , Xi ) + op N −1/2 ,
                                                                                       N i=1

with ψgcm (y, w, x) given in (4.34), ψW
                                      cm                             cm
                                         (y, w, x) given in (4.35), ψX  (y, w, x) given in (4.36), ψ0cm (y, w, x) given in
(4.33), and ψ(y, w, x) given in (4.37). Then we have an asymptotic linear representation for β̂ cm(ρ, τ ):

        β̂ cm(ρ, τ ) = τ · Y + (1 − τ ) · β̂ cm(ρ, 0)
                                                                     “                         ”
                   = β cm (ρ, τ ) + τ · (Y − β cm(ρ, 1)) + (1 − τ ) · β̂ cm(ρ, 0) − β cm(ρ, 0)
                                                                           N
                                                                        1 X
                   = β cm (ρ, τ ) + τ · (Y − β cm(ρ, 1)) + (1 − τ ) ·         ψ(Yi , Wi , Xi ).
                                                                        N i=1
                                                          P
Since by a law of large numbers Y → β cm (ρ, 1), and i ψ(Yi , Wi , Xi )/N → E[ψ(Yi , Wi , Xi )] = 0, it follows that
β̂ cm (ρ, τ ) → β cm(ρ, τ ). By a central limit theorem the second part of the Theorem follows. 
Proof of Theorem 4.4: The proof uses Lemmas A.13, A.14, A.19, A.20, and A.23.
By the conditions on q, r, s, and δ, Lemma A.13 implies that for some η > 1/4
                                     `      ´
          sup |m̂(w) − m(w)| = op N −η .
        w∈W

Moreover, by the same conditions, Lemma A.14 implies that for some η > 1/4,
              ˛                        ˛
              ˛ ∂ĝ          ∂g        ˛     `    ´
        sup ˛˛      (w, x) −    (w, x)˛˛ = op N −η .
      w∈W,x∈X ∂w             ∂w

Then, the conditions for Lemma A.19 are satisfied, so we can write
      √ “ lc        ”
        N β̂ − β lc

                   N
               1 X ∂g                                        √
            = √          (Wi , Xi ) · d(Wi ) · (X − m(Wi )) − N · β lc
                N i=1 ∂w
                      N                                               N
                  1 X ∂ĝ                                         1 X ∂g
                +√          (Wi , Xi ) · d(Wi ) · (X − m(Wi )) − √          (Wi , Xi ) · d(Wi ) · (X − m(Wi ))
                   N i=1 ∂w                                        N i=1 ∂w
                     N                                                N
                 1 X ∂g                                           1 X ∂g
               +√          (Wi , Xi ) · d(Wi ) · (X − m̂(Wi )) − √          (Wi , Xi ) · d(Wi ) · (X − m(Wi )) + op (1).
                  N i=1 ∂w                                         N i=1 ∂w
By Lemma A.20,
             N                                                   N
         1 X ∂                                               1 X ∂
        √          gb (Wi , Xi) · d(Wi ) · (Xi − m (Wi )) − √          g (Wi , Xi ) · d(Wi ) · (Xi − m (Wi ))
          N i=1 ∂w                                            N i=1 ∂w

                       N
                   1 X lc
                = √       ψg (Yi , Wi , Xi) + op (1),
                    N i=1
where
                                 1       ∂fW,X (w, x)
        ψglc (y, w, x) = −                            (y − g (w, x)) d(w) (x − m (w))
                             fW,X (w, x)     ∂W

                                   ∂m (w)
                                 −        d(w) (y − g (w, x))
                                     ∂W
                                    ∂
                                 +    d(w) (x − m(w)) (y − g(w, x)) .
                                   ∂w

                                                             [76]
By Lemma A.23,
             N                                           N
         1 X ∂                                       1 X ∂
        √                                 b (Wi ) − √
                   g (Wi , Xi) · d(Wi ) · m                    g (Wi , Xi ) · d(Wi ) · m (Wi )
          N i=1 ∂w                                    N i=1 ∂w

                                 N
                             1 X lc
                          = √       ψm (Yi , Wi , Xi ) + op (1),
                              N i=1
where
                              »               ˛        –
         lc                       ∂g(w, Xi ) ˛˛
        ψm  (y, w, x) = E                     ˛ Wi = w   · d(w) · (x − m(w)).
                                     ∂W
Combining these results implies that

        √    “            ”       N
                              1 X lc
            N β̂ lc − β lc = √       ψ (Yi , Wi , Xi ) + op(1),
                               N i=1

with
                          „                                         «
                              ∂g(w, x)
        ψlc (y, w, x) =                · d(w) · (x − m(w)) − β lc       + ψglc (y, w, x) + ψm
                                                                                            lc
                                                                                               (y, w, x).
                                ∂w
Using a law of large numbers then implies the first result in the theorem, and using a central limit theorem
implies the second result in the Theorem. 




                                                                 [77]
        Notation: (page number indicates where it was first introduced)

(Yi , Wi , Xi, Vi) observed variables for unit i, i = 1, . . . , N . Yi , Wi , Xi are scalars, Vi is vector.
      (page 3)

k(w, x, v, ε) is production function (page 3)

g(w, x, v) is average production function (conditional expectation of Y given (W, X, V )). (page
    4, equation 2.2)

σ 2 (w, x, v) is conditional variance of Y given (W, X, V )). (page 4, equation 2.3)

gW (w, x, v) is derivative of average production function. (page 4, equation 2.4)

hW |X,V (w|x, v) is potential conditional distribution of W given X and V (page 6)

fW |X,V (w|x, v) is conditional distribution of W given X and V (page 6)

βhare is output given new allocation indexed by h. (page 6)

FW |V (w|v) denotes conditional distribution function of W given V . (page 6)

β pam is positive assortive matching output (page 6, equation (3.6))

β pam−pop is alternative positive assortive matching output (page 7, equation (3.7))

β nam is negative assortive matching output (page 7, equation (3.8))

β sq is status quo output (page 8)

β rm is random matching output (page 8)

φ(x1 , x2 , ρ) bivariate normal density with correlation ρ, (page 8)

Φ(x1 , x2 , ρ) bivariate normal distribution with correlation ρ, (page 8)

φc (x1 , x2 , ρ) truncated bivariate normal density with correlation ρ, (page 8)

Φc (x1 , x2 , ρ) truncated bivariate normal distribution with correlation ρ, (page 9)

HW,X (w, mx) joint distribution function from truncated bivariate normal cupola (page 9).

hW,X (w, mx) joint density function from truncated bivariate normal cupola (page 9).

β cm (ρ, τ ) correlated matching estimand (page 8, and page 9, equation (3.10))

d(w) weight function in local complementarity measure (page 10)

Uλ combination of W and X for local allocation (page 10)

β lr (λ) path of local reallocations page 10, equation (3.11))

β lc local reallocation measure (page 11, equation (3.12)

W support of W (page 11, assumption 3.1)


                                                   [78]
X support of X (page 11, assumption 3.1)

δ(w, x) weight function in local complementarity measure in representation as weighted average
     of cross derivative (page 11)

q is the number of derivatives of g and fW X (page 11).

F̂W (w) estimate of cumulative distribution function for W (page 12)

m(w) (page 12, equation 4.15)

h1 (w, x) = fW,X (w, x) notation for density and product of density and regression function
     (page 12)

h2 (w, x) = g(w, x) · FW,X (w, x) notation for density and product of density and regression
     function (page 12, equation (4.16))

Ỹ = (Ỹi1 , Ỹi2 ) with Ỹi1 = 1, Ỹi2 = Yi (page 12)

ĥnw,m (w, x) nadaraya-watson kernel estimator for hm (w, x) (page 12, equation (4.17))

z = (w, x)0 and Z = (W, X)0 compact notation for pair of covariates (page 13)

L dimension of Z (is equal to 2 (page 13)

λ vector of nonnegative integers of dimension L = 2 (page 13)
     Q
zλ = L      λl
       l=1 zl (page 13)

               ∂g |λ|
g (λ)(z) =     ∂zλ
                      (z)   (page 13)

ZIb internal region (page 13, equation (4.18)

ZB
 b boundary region (page 13, equation (4.19)

t(z; g, r, p) taylor series expansion evaluated at z, equation (4.20)

rb (z) projection on internal region (page 14, equation 4.21)

ĥm,nip,s (z) NIP estimator for hm (z) (page 14, equation 4.22)

ĝnip,s (w, x) NIP estimator for g(w, x) (page 14, equation 4.23)

\
∂ gnip,s
  ∂w       (w, x) NIP estimator for derivative of g(w, x) 4.24

ĝ(w, x) = ĝnip,s (w, x) NIP estimator for g(w, x) short hand for NIP estimator (page 14)

derivative order of kernel is defined in definition 4.1 on page 14

K(·) bivariate kernel (page 15)

K(·) univariate kernel (page 15)

U support of bivariate kernel (page 15).


                                                   [79]
r is number of derivatives of kernel K(u) (page 15)

s is order of kernel K(u), and order of NIP kernel estimator (page 14, 15)

d is derivative order of kernel K(u) (page 15)

bN = N −δ is bandwidth (page 15)

β̂ pam estimator for β pam (page 15, equation 4.25)

β̂ nam estimator for β nam (page 15, equation 4.26)

β̃ pam estimator for β pam given known g(·) (page 15, equation 4.27)

q pam (w, x) (page 16)
 pam
ψW   (w) (page 16)

r pam (x, z) (page 16)
 pam
ψX   (x) (page 16)

Ωpam
 11 (page 16)

Ωpam
 22 (page 16)

β̃ nam (page 16, equation 4.29)

q nam (w, x) (page 17)
 nam(w) (page 17)
ψW
 nam (x, z) (page 17)
rXZ
 nam(x) (page 17)
ψX

Ωnam
 11 (page 17)

Ωnam
 22 (page 17)

β̂ cm (ρ, τ ) (page 17)

β̂ sq (page 17)

η(w) (page 18, equation 4.30)

d(w, x) (page 18, equation 4.31)

m(Y, W, β cm(ρ, τ ), η (W )) moment function (page 18)

eW (w, x) (page 18)

eX (w, x) (page 18)

ω cm (w, x) (page 18)


                                             [80]
ψ0cm (y, w, x) (page 19)

ψgcm (y, w, x) (page 19)
 cm
ψW  (y, w, x) (page 19)
 cm
ψX  (y, w, x) (page 19)

Ωcm (page 19)

ψ cm (y, w, x) (page 19)

Ωlc (page 20)

ψglc(y, w, x) (page 20)
 lc
ψm  (y, w, x) (page 20)
    pam
β̂g        (page 21, equation 5.39)
  pam
β̂W   (page 21, equation 5.40)
  pam
β̂X   (page 21, equation 5.41)

g pam (page 21, equation 5.42)

Z = (W, X)0 (page 29)

ω(Z) and ω(X) (page 29)

n(h[λ] ) and n(h) (page 29)

t(x) (page 29)

θfm (page 29, A.2)

θ± (page 29, A.3)

θ̂fm (page 29)

θ̂pm (page 29)
    fm
θ         (page 29)
    pm
θ         (page 29)
    (κ)
ακ1 (z) (page 30)

αm (z) (page 30)

V1 , V2 (page 30)

β̂glc (page 31)
  lc (page 31)
β̂m

                                      [81]
g lc (page 31)

g cm (page 33)

β̂gcm (page 33)
  cm
β̂W  (page 33)
  cm (page 33)
β̂W
  cm
β̂X  (page 33)




                  [82]
