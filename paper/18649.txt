                                NBER WORKING PAPER SERIES




                         ALGEBRA FOR 8TH GRADERS:
         EVIDENCE ON ITS EFFECTS FROM 10 NORTH CAROLINA DISTRICTS

                                         Charles T. Clotfelter
                                           Helen F. Ladd
                                          Jacob L. Vigdor

                                        Working Paper 18649
                                http://www.nber.org/papers/w18649


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                    December 2012




We are grateful to the Institute for Education Sciences and American Institutes for Research, through
the Center for the Analysis of Longitudinal Data in Education Research (CALDER), for financial support
and to Alexandra Oprea and Kyle Ott for research assistance. The views expressed herein are those
of the authors and do not necessarily reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2012 by Charles T. Clotfelter, Helen F. Ladd, and Jacob L. Vigdor. All rights reserved. Short sections
of text, not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including © notice, is given to the source.
Algebra for 8th Graders: Evidence on its Effects from 10 North Carolina Districts
Charles T. Clotfelter, Helen F. Ladd, and Jacob L. Vigdor
NBER Working Paper No. 18649
December 2012, Revised February 2013
JEL No. H75,I21

                                             ABSTRACT

This paper examines the effects of policies that increase the number of students who take the first course
in algebra in 8th grade, rather than waiting until 9th grade. Extending previous research that focused
on the Charlotte-Mecklenberg school system, we use data for the 10 largest districts in North Carolina.
We identify the effects of accelerating the timetable for taking algebra by using data on multiple cohorts
grouped by decile of prior achievement and exploiting the fact that policy-induced shifts in the timing
of algebra occur at different times in different districts to different deciles of students. The expanded
data make it possible to examine heterogeneity across students in the effect of taking algebra early.
We find negative effects among students in the bottom 60% of the prior achievement distribution.
In addition, we find other sources of heterogeneity in effects.


Charles T. Clotfelter                               Jacob L. Vigdor
Sanford Institute of Public Policy                  Sanford School of Public Policy
Duke University                                     Box 90245
Box 90245                                           Duke University
Durham, NC 27708                                    Durham, NC 27708
and NBER                                            and NBER
charles.clotfelter@duke.edu                         jacob.vigdor@duke.edu

Helen F. Ladd
Sanford School of Public Policy
Box 90245 Duke University
Durham, NC 27708
hladd@duke.edu
                        ALGEBRA FOR 8TH GRADERS:
       EVIDENCE ON ITS EFFECTS FROM 10 NORTH CAROLINA DISTRICTS1

                                             Charles T. Clotfelter
                                               Helen F. Ladd
                                              Jacob L. Vigdor


        During the past few decades, many states and school districts have been aggressively

pushing more 8th graders to take algebra, a course that historically has been offered primarily to

high school students in the United States. Although it has always been common for some high-

ability math students to take algebra by 8th grade, between 1996 and 2008, the percentage of 13

year olds taking algebra increased from 16% to 30% (Rampey et al. 2009) and by far higher

percentages in some areas. The reasons for this push for algebra by 8th grade include a new

focus on STEM courses and the recognition that algebra serves as a gateway course to the higher

level math courses needed for college and other careers. It has also become an issue of social

justice, based on concerns that some groups are being unfairly denied access to early algebra.

The policy remains controversial: critics argue that evidence for a causal impact of algebra

timing on later outcomes is slight, and that some students struggle if placed in advanced

coursework before they are ready (Loveless, 2008).

        In a prior paper based on data mainly from a single North Carolina district (Clotfelter,

Ladd, and Vigdor 2012, hereafter CLV 2012), we documented that some of the concerns raised

by critics appear to be valid. In particular we found that in the Charlotte-Mecklenburg district,

which had pursued a well-documented policy to place more students into early algebra in the

2003 and 2004 school years and then subsequently retracted that policy, students who were

1
 We are grateful to the Institute for Education Sciences and American Institutes for Research, through the Center
for the Analysis of Longitudinal Data in Education Research (CALDER), for financial support and to Alexandra
Oprea and Kyle Ott for research assistance.


                                                         2
pushed to take algebra by 8th grade performed less well in subsequent math courses, especially

geometry, as they progressed through high school. Our prior work is limited, however, because

our estimated effects are local to those students actually affected by the Charlotte-Mecklenburg

policy shift. In the current paper, we circumvent that limitation by extending the analysis to 10

large North Carolina districts.

       This expansion allows us to enrich the analysis and explore a wider range of effects. In

particular we are able to estimate effects for high-performing students – who were not affected

by the Charlotte-Mecklenburg policy shift – and to examine heterogeneous impacts by the

student’s race, and by the income and education status of the student’s parents. Following the

same methodology as in the earlier paper, we identify the effects of accelerating algebra by using

data on multiple cohorts of students disaggregated by their prior math achievement and

exploiting the fact that shifts in algebra timing typically apply only to students in certain

segments of the math achievement distribution, and occur in different years in different districts.

With the use of instrumental variables based on the inferred policy changes by district we are

able to isolate the causal effects of the policy interventions on a number of subsequent math

outcomes. As in our previous paper, we find that the overall effect of taking algebra by 8th grade

is to increase the probability that students will pass Algebra I by 10th grade, but to depress their

performance on the Algebra I test and decrease the likelihood they will pass Geometry by 11th

grade. In addition, we find significant heterogeneity in effects.

       In the next two sections of the paper, we provide the policy context and outline the model

we employ to infer the effects of taking algebra in middle school on several important outcomes.

Section III describes our data and the steps we take to trim the sample in an effort to increase our

confidence that our estimates are useful and not subject to omitted variable bias. In section IV we



                                                  3
present instrumental variables estimates of the causal effect of teaching algebra to middle school

students, and in sections V and VI we consider effects on taking calculus and pre-calculus

courses and on repeating Algebra I. Section VII concludes the paper.

I.US and North Carolina Context

         One of the seemingly most uncomplicated school reforms to take hold in the United

States in the last two decades has been the push to have more 8th graders take algebra, a course

traditionally taught in high school. Noting the success that other countries have had in teaching

the course to students at this age, a chorus of scholars and blue ribbon panels have urged the U.S.

to follow suit.2 For some proponents, expanding access to algebra in middle school can help the

country to regain global leadership in STEM training. For others, it is a social justice issue:

scholar Alan Schoenfeld (1995) called algebra “a new literacy requirement for citizenship, and

civil rights veteran Bob Moses (1995) dubbed it “the new civil right.”3 To proponents, what

makes algebra so important is its “gateway” role: “The earlier a student proceeds successfully

through algebra, and then on to courses such as geometry and algebra II, the more opportunities

he or she has for reaching higher level mathematics courses (e.g., trigonometry, precalculus, and

calculus) in high school….” (Walston and McCarroll 2011). This call for algebra in middle

school has been taken up with enthusiasm in many parts of the country.

         This push to teach algebra to 8th graders has not been without its critics, however.

Naysayers point out the logical problems in drawing causal inferences from observed differences

2
  See, for example, Schoenfeld (1995), Schmidt (2004), and National Mathematics Advisory Panel (2008). The
panel urged that math courses in elementary and middle school be adjusted to prepare more students to be able to
take algebra by 8th grade.
3
  Schoenfeld (p. 11, 1995) elaborates: “Algebra today plays the role that reading and writing did in the industrial
age. If one does not have algebra, one cannot understand much of science, statistics, business, or today’s technology.
Thus, algebra has become an academic passport for passage into virtually every avenue of the job market and every
street of schooling. With too few exceptions, students who do not study algebra are therefore relegated to menial
jobs and are unable often even to undertake training programs for jobs in which they might be interested. They are
sorted out of the opportunities to become productive citizens in our society.”

                                                          4
among students who take algebra at varying ages, and have worried that accelerating the math

timetable in this way would create more problems than opportunities for many students ill-

equipped to deal with the abstractions of algebra in middle school. Loveless (2008) presents

NAEP data to show that thousands of 8th graders taking algebra or geometry do not know basic

arithmetic, leaving them unable to profit from these courses and taking up the time and attention

of teachers who might otherwise be helping students with stronger math backgrounds. In

Clotfelter, Ladd and Vigdor (2012), we examine the effect of one district’s short-lived policy of

teaching Algebra I to large numbers of its 8th graders. Our findings suggest that at least some of

the critics’ concerns are well-founded. We found that, on average, students who were subjected

to the push to take algebra earlier in the Charlotte-Mecklenberg school district scored lower on

the statewide end-of-course algebra test and were less likely than other similar students

subsequently to pass the follow-on course in geometry by 11th grade.

       Because it relied on policy changes and data primarily from just one school district, that

study (CLV 2012) left several pressing questions unanswered. Crucially, our research design

limited us to assessing the impact of algebra acceleration for the set of students affected by the

policy initiative, namely those in the middle of the prior math test score distribution. That ruled

out, for example, analyzing the effect of the policy change in Charlotte-Mecklenburg on high-

achieving students (as defined by being near the top of the 6th grade test score distribution)

because virtually all such students took algebra by 8th grade both before and after the policy

change. Moreover, the absence of meaningful variation for high-performers implied that we

also had little chance of observing a hypothetical positive impact of early algebra taking on

progression to calculus or other advanced courses in high school.

       In the current paper, we combine data for the 10 largest school districts in North Carolina



                                                 5
over a period of six academic years to infer the effects on students of taking algebra by 8th grade,

rather than later or never at all. For all of the districts, we observe significant changes over time

in the probability that students in at least some deciles of prior math achievement – independent

of measurable characteristics of those students – will take the state’s standard Algebra I course.

We use these temporal variations in probability as an instrument in equations predicting the score

on the state’s end-of-course test in Algebra I and success in passing Algebra I, Geometry, and

Algebra II. As in our previous paper, we find that the broad effect of taking algebra by 8th grade

is to increase the chance that students will pass Algebra I by 10th grade, but to depress their

performance on the Algebra I test and decrease the likelihood they will pass Geometry by 11th

grade. In addition, we find significant heterogeneity in effects. Supporting the suspicions of

Loveless and other skeptics, we find that the effect of early algebra-taking differs by students’

previous math achievement, with the deleterious effects being the most pronounced for students

with the weakest previous achievement. We also find differences in policy impact by gender,

free lunch eligibility, and parents’ education, some of which differences are unexpected.

II. Model

         Our objective is to assess the effects of variations in school policies and practices that

manifest themselves in differing rates with which otherwise similar students are assigned to take

Algebra I in middle school. That is, we examine the effect on students of changing the timing,

not the content, of the first course in algebra. So far as we know, the content of the Algebra I

course in North Carolina did not change during our period of study.4

         We examine three kinds of possible effects on students. The first is on the student’s

4
 In 2007, the state changed the scoring and passing standard of the standardized end-of-course test in Algebra I. the
proportion of students failing the EOC test increased substantially relative to previous years. To our knowledge, this
change in test scoring did not coincide with a change in curriculum for the course. In our specifications below we
account for the change in scoring scale and passing standard by defining “passing” the test as scoring above the 20th
percentile, which approximates the pre-2007 standard.

                                                          6
knowledge of algebra, as indicated by performance on the state’s mandatory test administered to

all Algebra I students at the completion of the course. By design, this test is intended to assess

understanding of the course material, and we can be confident that students and teachers took the

test seriously, since at least a quarter of the course grade must be based on its outcome. The

second possible effect of taking algebra early is on how well the student succeeds in passing not

only Algebra I itself, but also the two other basic courses in the state’s mathematics sequence:

Geometry and Algebra II. The third kind of outcome we examine is whether students took

courses beyond Algebra II, including calculus. For reasons explained below, our identification

strategy is not particularly well suited to estimating the impact of algebra timing on calculus-

taking; instead we offer estimates in the spirit of a “bounds” analysis (Manski, 1990). This

outcome is important because one of the arguments for moving algebra to 8th grade is that it

opens up for students the opportunity to take more advanced coursework in mathematics during

high school. In CLV (2012), we were unable to examine this last outcome because any effects on

enrollment in math courses beyond Algebra II are most likely concentrated among higher-

performing students, for whom we observed very little policy variation in our initial single-

district study.

        In devising our estimation strategy, we have endeavored to produce estimates that reflect

causation, not simply correlation. Logic and experience suggest that, in deciding whether a 7th or

8th grader should be assigned to take algebra rather than another pre-algebra course, a school

may well take numerous student-level factors into consideration, not all of which are reflected in

measures contained in administrative data sets such as the one we use. Thus any attempt to

assess the effect of early assignment to algebra based on observational, within-cohort-and-district

variation will inevitably be subject to omitted variable, or selection, bias.



                                                  7
          To combat that statistical challenge, our estimating models use instrumental variables

estimation, along the same lines as the model we employed in CLV (2012). The larger number of

districts used in this study means that a wider range of students were subjected to shifts in

algebra placement policy over time. As in the initial study, we use this policy-induced variation

to assess the impact of algebra timing on student outcomes. This task is complicated in the

present study by the absence of clear documentation of any official shift in policy in some

districts. We infer that a policy shift has occurred in those circumstances where the across-

cohort variation in Algebra I placement patterns is too large to be based on random fluctuations

in student background characteristics alone.

          We begin with data on students from six successive cohorts in the 10 largest school

districts in North Carolina. We stratify the sample by student prior achievement, as measured by

the student’s average scores on 6th and 7th grade standardized math tests. We then reduce the

sample, using a procedure outlined below, to those district, cohort, and prior achievement decile

cells that exhibit significant variation in placement patterns across cohorts.

          Our model takes the form of conventional instrumental variables estimation. We estimate

several different two-stage models of the form:

          (1) Tidcs=c + d + s +   dcs +   idcs

          (2) Yidcs = c + d + s + β               dcs   + idcs

where Yidcs is the outcome of interest for student i in prior achievement decile d in cohort c

enrolled in school district s, d, c, and s are decile, cohort, and school district fixed effects,

Tidcs is a treatment indicator, where the treatment is taking Algebra I no later than 8th grade,

   dcs,   the instrument, is the decile-cohort-school district cell average of the treatment, and      dcs




                                                              8
is the predicted value obtained from equation (1) – and idcs and idcs are independent and

identically distributed error terms. Cohort fixed effects account for policy changes or other

contemporaneous effects that had an influence on all students in a cohort across the state, decile

fixed effects account for broad differences in outcome trajectories for students with differing

prior achievement, and school district fixed effects account for systematic policy and other

differences across districts. By using decile fixed effects rather than a linear control for test

score, we are able to account for potentially nonlinear effects of prior achievement on subsequent

outcomes.

        In effect, this estimation strategy associates across-cohort/decile/school district variation

in the propensity to take Algebra I by 8th grade with across-cohort/decile/school district variation

in the outcome of interest. We attribute a positive (or negative) effect to acceleration if students

subjected to a higher risk of earlier algebra than others in the same prior achievement decile and

district in another cohort exhibit better (or worse) subsequent outcomes of interest –

performance in Algebra I, passing that and the two following math courses, taking a math course

beyond Algebra II. We also examine the probability of repeating Algebra I. Because the

identifying variation in algebra timing is at the cohort-by-decile-by-school district level, we

cluster standard errors at that level.

        Equations (1) and (2) highlight a potentially serious criticism of our identification

strategy. By instrumenting for a student’s own placement experience with the average

experience of students in her cohort/decile/district cell, we risk replacing an individual-level

variable that is subject to concerns about unobservable factors with a cell-level average variable

that is subject to a different set of concerns about unobserved factors. For the approach to be

successful, we must have some confidence that differences in the cell averages reflect differences



                                                   9
in placement policy rather than differences in unobserved student characteristics. In order to

describe our strategy for attaining this degree of confidence, we must first describe our data in

greater detail.

III. Data

         We use student-level data for the 10 largest North Carolina school districts. Shown in

Figure 1, these districts are: Charlotte-Mecklenburg, Wake (containing Raleigh), Guilford

(Greensboro), Cumberland (Fayetteville), Winston-Salem/Forsyth, Gaston (Gastonia), Durham,

Union (Monroe), Johnston (Smithfield), and Cabarrus (Concord). Of these districts, three

(Gaston, Union, and Cabarrus) contain suburban overflow from Mecklenburg County, and

Johnston similarly contains some bedroom suburbs adjacent to Wake County. In order to study

students who experienced different policy regimes regarding the aggressiveness in placing

students in Algebra I by 8th grade, we use information for six successive cohorts of students,

beginning with those who were 7th graders for the first time in the fall of 1999 and ending with

those who arrived in 7th grade in the fall of 2004. Students in these cohorts who made normal

progress in school would have graduated from high school in the years 2005 to 2010, but we

track students whether or not they experienced normal grade progression.

         Our data represent longitudinally matched records on students derived from

administrative records housed in the North Carolina Education Research Data Center.5 When

evaluating the effect of taking Algebra I by 8th grade, we focus on those students enrolled in one

of our 10 districts in the year after they began 7th grade. We restricted the sample to students

with valid scores on the state’s standardized 6th and 7th grade mathematics end-of-grade

assessments. For each student, we averaged those two scores, to reduce possible concerns with

5
 The Data Center supplies unique identifying numbers that allow researchers to link student records in different data
sets while protecting the identities of individuals.

                                                         10
measurement error in test scores, and used that average to assign them to deciles in order to

stratify them by prior math performance.6 Students were assigned to districts based on their 8th

grade enrollment. We then tracked their progress through college-preparatory math courses using

information from the state’s end-of-course examinations in Algebra I, Geometry, and Algebra II.

         We employ several outcome measures based on students’ math achievement and course-

taking. Ideally, we would have estimated the impact of taking Algebra I by 8th grade on actual

knowledge gained, as measured by performance on the test designed for that course and on the

tests for subsequent math courses. The approach is frustrated, however, because some students

never take Algebra I, and many more never take the follow-up courses. These facts create two

sources of sample selection bias. The more serious one is that so many students never take

Geometry or Algebra II. If we were to use as outcome measures the scores on the tests for those

two courses, we would have to restrict ourselves to those select students brave or accomplished

enough to take the courses at all. To avoid the obvious selection bias that would invite, we adopt

as our outcome measure simply whether or not students passed those courses, an outcome we can

measure for all students given that those who do not take a course by definition cannot pass it.

The second source of selection bias arises in analyzing the end-of-course test score in Algebra I.

Because we can observe performance only for those students who actually take the course, our

analysis may lead us to overstate the negative effects of the acceleration policy. That outcome

will occur to the extent that a policy of accelerating students into 8th grade algebra correlates

with efforts to expand the set of students ever taking algebra, causing marginally-performing

students to be swept into the sample only during years of acceleration. To deal with this second

selection problem, we estimate alternative models using quantile regression methods. For the

6
  If a student took Algebra I before 8th grade, the fact was noted, and the student was included with students who
took Algebra I by 8th grade. If the student took it in a different district from his or her 8th grade district, he was
dropped from the sample.

                                                           11
quantile regressions, we impute test scores for non-algebra takers, under the presumption that

those students who do not take the course would have scored below the median conditional on

their observed characteristics (Neal and Johnson 1997).

        In contrast to our analysis of Charlotte-Mecklenburg (CLV 2012) – where we had direct

evidence that that district had undertaken an explicit policy of placing more 8th graders in algebra

classes – we have little documentary proof for the districts studied in the current paper of formal

policy directives about offering algebra to 8th graders. Moreover, as noted above, our

identification strategy will yield biased results to the extent that across-cell variation in

placement patterns reflects across-cell variation in unobservables rather than policy. Our

strategy for distinguishing policy-induced variation from random fluctuations in placement

patterns attributable to student unobservables rests on the assumption that there is no reason to

expect systematic variation in unobservables across cohorts. If all variation in mean unobserved

characteristics across cohorts is idiosyncratic, then we can use standard statistical tests to

determine whether the degree of observed variation is too large to be explained by idiosyncratic

factors alone. In practice, we use two rounds of statistical tests. The first is a simple Chi-

squared test for significant variation in placement patterns across cohorts within a district/decile

cell. The second is an F-test for significant residual variation in placement patterns after

controlling for observed student characteristics.

        To appreciate the need for the first of these exclusions, consider the bar graphs in Figures

2 to 4. These graphs show the percentage of students (grouped by quintile rather than decile, for

ease of presentation) who took Algebra I by 8th grade in five selected districts. For example,

Figure 2, which tracks middle schoolers who took Algebra I in Charlotte-Mecklenburg, clearly

illustrates the effects of that district’s bold algebra acceleration policy. Successive cohorts in the



                                                    12
first three quintiles experienced a marked jump, then drop, in the risk of taking Algebra I by 8th

grade. In contrast, there was almost no change over the period for students in the highest quintile

– almost all of whom took algebra by 8th grade. Figure 3, for Wake County, reveals a very

different pattern, with virtually no change over time in the treatment of students in the bottom

three quintiles.

           The Chi-squared tests for the 100 decile-district subsamples test the null hypothesis that

the probability of taking algebra for those students remained the same for all six cohorts – i.e.,

that any observed variation is attributable to random fluctuation rather than any systematic

change in policy.7 For 35 of the 100 subsamples, we could not at the 5% level of confidence

reject the hypothesis of no difference in probability across the six cohorts, leading us to exclude

those cells from our sample.8 For example, none of the bottom seven deciles in Wake County

showed significant variation across cohorts, reflecting the near uniformity that is evident in the

pattern of bars for the bottom three quintiles in Figure 3. For Charlotte-Mecklenburg, the lack of

variation in the top quintile shown in the figure turns out to reflect a lack of variation primarily in

the top decile alone, so we excluded that decile. In contrast, for Durham, the hypothesis of no

variation could be rejected for all 10 deciles, a result that is not surprising, considering the

patterns evident in Figure 4.

            The second set of tests eliminates decile-district subsamples for which student

characteristics appear to explain a significant portion of the variation in algebra-taking across the

cohorts. For our entire sample of students, we estimated a linear probability model regressing an

indicator for 8th grade Algebra I placement on gender, year of birth, categorical variables for

race/ethnicity, free lunch status, and parental education, as well as fixed effects for cohort,


7
    Note that seven of the decile-district subsamples had no students who had taken Algebra I by 8th grade.
8
    The p-values from the Chi-squared tests are shown in Appendix Table A1.

                                                           13
decile, district, and all their interactions. For each of the 100 decile-district subsamples, we

performed an F-test for the hypothesis that the cohort fixed effects were equal.9 For six decile-

district subsamples that had not previously been excluded by our first test of variation, we were

unable to reject this hypothesis, leaving us with 59 remaining decile-district subsamples,

containing a total of 124,505 students.10

         For this trimmed sample, Table 1 shows, by district, the number of students and the

means and standard deviations of our measure of prior achievement, as well as four of our main

outcome measures. As noted above, we sorted students into deciles of prior math achievement,

based on the average of each student’s 6th and 7th grade standardized end-of-grade math scores.

The remaining four variables are measures of outcomes and are all based on the state’s

mandatory end-of-course tests . In addition to the score on the Algebra I end-of-course exam, we

also track whether students took and passed that course and the two follow-on courses –

Geometry, and Algebra II.11 Owing to our exclusion of designated decile-district subsamples, the

two largest districts, Charlotte-Mecklenburg and Wake County, contribute fewer students to the

final sample than the third largest district, Guilford. The average student characteristics reflect

the deciles that remained after trimming. The averages for Wake and Cabarrus, which had most

or all of their lowest seven deciles excluded, reflect the characteristics of their remaining

relatively high-scoring students. The mean for Charlotte-Mecklenburg, in contrast, shows the

effects of having some of its highest deciles dropped. Within each of the districts, the average


9
  The p-values for these F-tests are shown in Appendix Table A2.
10
   The excluded decile-district subsamples are identified Appendix Table A3.
11
   Our definition of a passing grade on the Algebra I and Algebra II end-of-course tests is based on the proficiency
standard in place for most of the years in our sample, which was roughly equal to the 20th percentile of the statewide
distribution for both tests. In 2007, the state adopted stricter grading standards on both end-of-course tests, placing
the passing threshold closer to the 40th percentile of the statewide distribution. By using a uniform standard based
on a specific point in the distribution, we assume that there is no meaningful change in the statewide distribution of
Algebra I or Algebra II test scores over time. As there is no substantial shift in standards on the Geometry EOC test,
no comparable adjustment is necessary.

                                                          14
rate of passage for Algebra I by 10th grade is higher than those for Geometry by 11th and Algebra

II by 12th.

        Before turning to estimates of the effect of taking Algebra by 8th grade, we summarize

the correlates of our four main outcome measures. Table 2 presents estimates based on four OLS

regressions explaining the four measures – the student’s performance on the first Algebra I end-

of-course test and the three binary indicators for taking and passing Algebra I, Geometry, and

Algebra II, as described above. These results should not be assigned a causal interpretation, as

they make use of observational variation in algebra timing, which presumably correlates with

unobserved determinants of math achievement. The table reports estimated coefficients on an

indicator for taking Algebra I by 8th grade as well as cohort, district fixed effects, and decile

fixed effects. Most noteworthy are the coefficients for taking algebra by the 8th grade. They

demonstrate beyond any reasonable doubt that, although students who take algebra in middle

school tend to perform poorly on the algebra end-of-course test, they are more likely than other

students to take and pass Algebra I, Geometry, and Algebra II. They are more than 5 percentage

points more likely than other students to take and pass Geometry, and the differences are even

greater for the two algebra courses.

        As for other correlates of taking algebra in middle school, the regression reveals few

statistically significant differences by cohort. By district, Wake County, the omitted one,

consistently bests most of the others, reflecting in part its more affluent makeup. The decile

indicators have the expected pattern, with all coefficients increasing monotonically through the

first eight deciles. Not surprisingly, the best predictor of math achievement is prior math

achievement.




                                                  15
IV. The Causal Effects of 8th Grade Algebra

        Following the approach we take in CLV (2012), we employ instrumental variables

methods to estimate the causal impact of taking algebra by 8th grade. As described in section II

above, we used fitted values from a first stage regression (1) as an instrument for the likelihood

that a student of cohort c, whose prior achievement puts her in decile d, and whose residence

assigns her to school district s, will be put into an Algebra I class by 8th grade. Because we have

excluded all students who were in decile-district subsamples for which this likelihood of taking

algebra by 8th grade either did not vary significantly over time or for which across-cohort

variation could be attributed to student characteristics, we can view the remaining students as

facing exogenously varying probabilities of receiving this treatment, with those probabilities

being entirely a function of year of birth, that is, of the cohort into which the student found

herself in 7th grade.

        We implemented three variants of instrumental variables estimation. First, we estimated

simple two-stage least squares, for both equations explaining the score on the Algebra I test and

the linear probability models explaining course passage. Second, we used binomial probit as an

alternative to the 2SLS linear probability models because the latter, while producing coefficients

easy to interpret in terms of probabilities, do not conform to the necessary distributional

assumptions in either the first or second stage. Third, we applied a quantile regression version of

I.V. using imputation methods to deal with sample selection in the students who take Algebra I.

Basic Results

        Table 3 reports instrumental variables estimates applying to students at large, with none

of the interactions we focus on below. The first equation employs IVQR estimation, with

imputed test scores for students not taking Algebra I at all. The other equations use as outcomes



                                                 16
taking and passing the three math courses, with a two-stage least squares and binomial probit

used for each of those outcomes. Each model controls for prior achievement (based on 6th and 7th

grade end-of-grade math tests), cohort and district fixed effects, and the predicted value of

Algebra I enrollment by 8th grade derived from first-stage equations.

        The estimated equations paint a largely negative picture. Students who were enrolled in

years when their districts were more aggressive about teaching Algebra I to 8th graders scored

lower on their end-of-course test (some 37% of a standard deviation lower) and were less likely

to take and pass Geometry by 11th grade by some 6.6 percentage points ( based on the 2SLS

model). Nor were they more likely to take and pass Algebra II by 12th grade; in fact the 2SLS

model implies that they were a little less likely to. The only ray of sunshine in these results

comes from the probability of passing Algebra I itself. We take this positive finding to be a direct

consequence of the opportunity an early algebra class affords a student who does not pass the

course the first time around to retake it. These findings closely mirror those we obtained in our

earlier analysis of Charlotte-Mecklenburg.12

Effects by Prior Achievement

         Analyzing outcomes in 10 different districts provides us an opportunity to examine

heterogeneity across the student population in the effects of taking algebra by 8th grade. It is

especially important to determine whether there are differences by prior achievement, since

much of the discussion about the advisability of teaching algebra to 8th graders concerns middle

schoolers’ readiness for the course. Few would dispute that at least some 8th graders are ready to

take algebra. The question is, how many? To address this question, we estimated equations of the


12
  In CLV (2012, Table 4), for example, the estimated coefficient in the corresponding IVQR equation is -0.324***,
compared to the -0.374*** in the current paper. The estimated coefficients in the 2SLS equations in the previous
paper are 0.069**, -0.095***, and -0.002 for Algebra I, Geometry and Algebra II, respectively, compared to the
0.091***, -0.066***, and -0.026* in Table 3 of the current paper.

                                                       17
form shown in Table 3 with interactions by quintile of prior achievement. These are presented in

Table 4b. For ease of interpretation, we have dropped the bivariate probit specifications and

added a 2SLS specification for the Algebra I test score, the estimates from which may well be

subject to sample selection bias, as noted above.

       The most striking set of estimates is for the effect of passing Geometry. The estimated

coefficients make it clear that the overall negative effect of taking algebra by 8th grade comes

entirely from the deleterious effects on students in the lowest three prior-year achievement

quintiles. For those students – occupying the middle and bottom portions of the distribution –

algebra by 8th grade reduces by at least 8 percentage points the chance that a student will take

and pass geometry by 11th grade. For students in the top quintile, however, taking algebra by 8th

grade increases the chance of success in geometry. For students in the fourth quintile, there is no

effect one way or the other. As for passing Algebra I, something of a U-shaped effect is evident.

We interpret the large positive coefficient in the lowest quintile to be an enabling effect: for

those most likely to struggle in algebra the best shot at passing the course eventually is to start

early. The effects on Algebra I test scores are negative for all students. The RFQR estimates,

which impute poor performance to those with missing test scores in a quantile regression model,

show that performance by students in quintiles 2 and 3 is harmed the most and that by students at

the top is harmed the least. As for passing Algebra II, the faintly negative effect observed in the

overall effects shows up in the Table 4b estimates only in the second quintile, and with a point

estimate suggesting a decline of 4 percentage points. For Algebra II it is impossible to reject the

hypothesis that all the quintile coefficients are equal.




                                                  18
Effects by Other Characteristics

       We estimated three additional models with interactions for three other student

characteristics: gender, free lunch status, and parental education. Taken together, these models

yield several quite unexpected results. The gender interactions are shown in Table 5. Holding

constant their previous math achievement, boys score lower than girls do and are less likely to

pass the three math courses. The interaction with algebra by 8th grade is positive, implying the

negative effects of early algebra are more pronounced among girls. This implies that the gender

gap is much more pronounced among students who do not take algebra by 8th grade. The

percentage point gap in passage rates separating boys and girls is 5.1 for those who did not take

algebra by 8th grade but only 0.6 for those who did. For Algebra II the corresponding gender

gaps are 6.8 and 3.0 percentage points. The estimated coefficients for Algebra I test scores tell a

similar story: boys are lagging behind girls in high school math, but the gap is smaller among

those who took algebra in middle school.

       Table 6 reports interaction effects for free and reduced-price lunch, a common but

imperfect proxy for low income. Unsurprisingly, subsidized lunch receipt associates with poorer

academic outcomes overall. Interaction terms indicate that the effects of algebra acceleration are

more pronounced among disadvantaged students in some cases, but not others. Students on free

and reduced lunch suffer a more pronounced negative effect on standardized Algebra I test

scores, but more encouraging results on all other outcomes. The positive effect of acceleration on

Algebra I passage is stronger among subsidized lunch recipients. For passing Geometry and

Algebra II, the penalty associated with taking algebra in middle school was partially or wholly

erased for those getting free and reduced price lunch. This puzzling pattern might result from

tracking practices in high schools. Students who do not take Algebra I in middle school face a



                                                 19
mathematics placement decision in high school, with options including the college-preparatory

sequence beginning with Algebra I as well as other options. Disadvantaged students, for a

variety of reasons, may be more likely to choose or be steered into less rigorous tracks in high

school. Completing Algebra I in middle school, by contrast, clearly marks a student as being

selected for the college preparatory track, even if the student’s performance in the course is

relatively poor.

        The last set of interactions is summarized in Table 7, where the characteristic of interest

is parental education, specifically, whether either parent had a bachelor’s degree or more. Not

surprisingly, students with college-educated parents did better than others on every one of our

outcome measures. Interaction terms show that the children of highly educated parents appear

relatively impervious to the effects of algebra acceleration – both positive and negative. Results

are consistent with the view that highly educated parents buffer the impacts of education

policies.

        The effects of algebra acceleration are clearly heterogeneous. Generally speaking,

students who begin in a relatively advanced position – perhaps thanks to their family

background, or to their rate of learning in earlier grades – appear to suffer no long term effects

when steered towards taking the course in 8th rather than 9th grade. The story differs for students

who begin at an educational disadvantage. Altogether, patterns indicate that a policy of

mandating 8th grade algebra for all students runs the risk of exacerbating educational inequalities

in the high school years, with the possible exception of disadvantaged student for whom

acceleration implies a possible track switch into college-preparatory coursework.

V. Taking Calculus and Other Advanced Math Courses

        As articulated by Walston and McCarroll (2011) above, one of the strongest selling



                                                 20
points for teaching algebra to more 8th graders is the increased opportunities it should provide for

students to take courses beyond Algebra II, including calculus. Ideally, we would have liked to

analyze the effect of taking algebra in middle school on students’ enrollment and success in these

more advanced math courses. However, North Carolina has no end-of-course tests for these

advanced math courses like those it mandates for Algebra I and II and Geometry. The only

information on enrollment in these courses is a relatively new data set summarizing student

transcripts, which just covers 7th grade cohorts beginning with 2002/03. The restriction to just

three age cohorts deals a significant blow to our identification strategy, which relies upon the

existence of variation in placement patterns across cohorts that is too large to be explained by

idiosyncratic factors. As a result, we abandon that strategy here and focus on a form of bounds

analysis, presenting simple statistics with clearly signed biases. This strategy can yield

informative results in certain circumstances, such as when documenting that the upper bound on

a coefficient with a clear upward bias is small.

       Figure 6 shows the share of two groups of students, by level of prior achievement, who

took calculus by 12th grade: those who had taken Algebra I by 8th grade and those who had not.

Not surprisingly, taking calculus was more common among students in the algebra-by-8th grade

group. There are two reasons for this difference. One is a causal inference: taking algebra early

places students in a superior position to proceed to calculus. The other reason is that the two

groups are different: even conditional on 6th and 7th grade performance, early algebra-takers are

likely to be more promising students in ways not captured by test scores alone. We therefore

expect simple comparisons such as the ones shown here to be affected by positive selection bias.

The difference between the rates of calculus-taking, shown by the vertical distance between the

curves, is therefore an upper bound on the effect of a policy to teach Algebra I in middle school.



                                                   21
In the lower half of the prior achievement distribution, this gap is small, suggesting that, for a

majority of students, taking Algebra I in middle school is not going to have a big impact on the

probability of taking calculus in high school. For students near the median in middle school,

access to Algebra I in 8th grade raises the chances of taking calculus in high school by at most 10

percentage points. Note that some students manage to take calculus even after waiting to take

Algebra I until high school, presumably because they take two math courses simultaneously in

one or more years. Not until we get into the top quintile of students (by prior achievement) is the

raw difference in rates of calculus-taking as much as 20 percentage points. In short, arguments to

accelerate algebra on the grounds that it significantly enables high school calculus-taking are

best applied to high-performing students, and not moderate or low performers. 13

VI. Repeating Algebra I

         The last consequence of teaching algebra in middle school that we trace is a negative one:

repeating the first algebra course. We have seen that one consequence of the practice is lower

performance on the Algebra I end-of-course test. Although taking the course in middle school

does indeed boost the chance of passing it eventually, for many students passing the course

requires taking it more than once. Here we look directly at repeating as an outcome of the push

to teach algebra in middle school.


13
   A stronger case can be made for the enabling effect of accelerating algebra on the opportunity to take pre-calculus
courses. Comparisons similar to that shown in Figure 6 between students who did and did not take Algebra I in 8th
grade indicate larger differences in the share of students who took at least one pre-calculus course, including
analytical geometry and courses entitled “pre-calculus.” Compared to those in the previous graph, these lines are
farther apart, suggesting an upper bound net enabling effect amounting to almost 20 percentage points at the middle
of the prior achievement distribution and more than 40 percentage points at the 90th percentile. Although the
comparisons shown in Figure 6 suggest that moving algebra to 8th grade is unlikely to increase the share of students
who take calculus in high school, except for the top students, there does appear to be some real scope for an enabling
effect to operate for pre-calculus courses. The pre-calculus courses included in these latter comparisons were math
course numbered 2031(Analytical Geometry), 2070 (Pre-Calculus), and 2071 (IB Math Methods I). The findings are
quite similar if we define pre-calculus more broadly, in include in addition math course numbered 2041
(Trigonometry), 2054 (Integrated Math IV), 2065 (Probability and Statistics), 2066 (AP Statistics, 2070), and 2078
(Math HL I IB).


                                                         22
       In this case, we expect a negative bias in simple estimates. Early algebra takers are

positively selected and should therefore be less disposed to negative outcomes such as retaking.

Any simple comparison will therefore likely understate the effect of acceleration on the

propensity to retake the course.

       Using axes like the previous two figures, Figure 7 shows the percentage of students, by

prior achievement level, who had to repeat Algebra I. As expected, this share tends to be smaller

for students with higher prior math achievement. That said, the students who took Algebra I by

8th grade were more likely to repeat the course. For students at the 20th percentile score, for

example, the early algebra takers were more than 20 percentage points more likely to repeat the

course. Given the expected bias in these estimates, for roughly the bottom half of the

distribution, the effect of taking Algebra I by 8th grade is at least a 20 percentage point increase

in the risk of repeating the course. For the median student, and all those below, acceleration

appears to be more likely to lead to course repetition than to calculus.

VII. Conclusion

       This paper examines a widely-espoused policy in math education: getting more students

to take algebra in 8th grade, rather than waiting until 9th grade, when most students have

traditionally taken the first course in algebra. Offering algebra early allows students more time in

high school to take advanced math courses, but critics complain that most students are not ready

for algebra in 8th grade. In a prior paper we examined the effect of early algebra, using data

mainly from the Charlotte-Mecklenberg Schools, a district that had pursued a well-documented

policy to place more students into early algebra in the early 2000’s. We found that some of the

concerns raised by critics appear to be valid. In particular we found that students who were

pushed to take algebra by 8th grade performed less well in subsequent math courses, especially



                                                 23
geometry, as they progressed through high school. That study is limited, however, because the

effects we obtained apply only to those students actually affected by the Charlotte-Mecklenburg

policy shift. To see how generalizable these estimates are, in the current paper we extend the

analysis to the 10 largest North Carolina school districts. This expansion allows us to enrich the

analysis and explore a wider range of effects. In particular we are able to estimate effects for

high-performing students – who were not affected by the Charlotte-Mecklenburg policy shift –

and to examine heterogeneous impacts by the student’s race, and by the income and education

status of the student’s parents.

        Following the same basic methodology as in the earlier paper, we identify the effects of

accelerating algebra by using data on multiple cohorts of students disaggregated by their prior

math achievement and exploiting the fact that shifts in the timing of algebra occur at different

times in different districts to different deciles of students. Our aim is to assess the effects of

variations in school policies and practices that manifest themselves in differing rates with which

otherwise similar students are assigned to take Algebra I in middle school. We examine three

kinds of possible effects on students: on their performance on the state’s mandatory test

administered to all Algebra I students; on how well they succeed in passing Algebra I, Geometry

and Algebra II; and on whether they took courses beyond Algebra II, including calculus.

        Our estimation strategy is designed to yield estimates that reflect causation, not simply

correlation. Since assignment of any student to take algebra in 7th or 8th grade is likely to depend

on numerous student-level factors, any attempt to assess the effect of early assignment to algebra

based on observational, within-cohort-and-district variation will inevitably be subject to omitted

variable, or selection, bias. We therefore use instrumental variables estimation. The large number

of districts used in this study means that a wider range of students were subjected to shifts in



                                                   24
algebra placement policy over time. As in our previous study, we use this variation to assess the

impact of algebra timing on student outcomes. We infer that a policy shift has occurred in those

circumstances where the across-cohort variation in Algebra I placement patterns is too large to

be based on random fluctuations in student background characteristics alone. We use data on

students from six successive cohorts in the 10 districts, stratifying the sample by students’ prior

achievement, as measured by each student’s average scores on 6th and 7th grade standardized

math tests. We then reduce the sample to those district and prior achievement decile cells that

exhibit significant variation in placement patterns across cohorts.

       As in our previous paper, we find that the overall effect of taking algebra by 8th grade is

to increase the probability that students will pass Algebra I by 10th grade, but to depress their

performance on the Algebra I test and decrease the likelihood they will pass Geometry by 11th

grade. In addition, we find significant heterogeneity in effects. The most important form of

heterogeneity we observe is based on prior achievement. We find that the harmful effects are

almost entirely confined to students in the bottom 60% of the prior achievement distribution,

lending support to the argument of critics that only the best prepared students are ready to take

algebra in 8th grade. Other sources of heterogeneity are less predictable. As might be expected,

girls do better on our math outcomes, as do those not receiving free lunch and those with college

educated parents. But the interactions with early algebra were anything but expected. Boys were

harmed less by taking algebra early. Students on free lunch, while being harmed more by early

algebra on Algebra I test scores, actually were harmed less by other measures. And for students

with college-educated parents the effect of early algebra had varying effects but in general these

differences did little to affect their overall superior performance.

       For two other outcomes, we are not able to use the instrumental variables approach,



                                                  25
because of limited data. We therefore offer estimates in the spirit of a “bounds” analysis. The

first outcome is taking calculus and other advanced math courses. This outcome is important

because a prime argument for moving algebra to 8th grade is that it opens up for students the

opportunity to take more advanced coursework in mathematics during high school. For calculus

taking, we compared students who did and did not take algebra I by 8th grade. The differences

reflect the course and selection. Our bounds analysis suggests that there can be little effect in the

bottom half of the prior achievement distribution because so few students take calculus, whether

or not they took algebra in 8th grade. It is only in the top fifth that the differences are as great as

20 percentage points. As for repeating Algebra I, all of the action is at the bottom of the prior

achievement scale, the potential effects are quite large. For those students at or near the bottom,

taking Algebra I early increases the likelihood of re-taking the course by at least 20 percentage

points.

          As is the case with our previous study of accelerated algebra, it is important to end with a

caveat emphasizing at least one conclusion that cannot be drawn from our work. The present

paper, like our previous study focusing on Charlotte-Mecklenberg, addresses a policy of

changing the timing of the conventional first course in algebra. We ask whether it was a good

idea to take the existing Algebra I course and increase the number of 8th graders taking it. We

cannot address the effects of proposals that would take concepts from algebra and introduce them

to students in earlier grades to an extent not previously done, that is, a thorough-going reform of

the mathematics curriculum. Regarding the desirability of such a reform, our research is silent.




                                                   26
References
Clotfelter, Charles T., Helen F. Ladd, and Jacob L. Vigdor (2012).”The Aftermath of
Accelerating Algebra: Evidence from a District Policy Initiative.” NBER Working Paper18161,
June.


Dulaney, Chuck, “Should Students Take Algebra in Middle School?” (1996) Eyes on Evaluation,
Evaluation and Research Department, Wake County Public School System, April;
http://www.wcpss.net/evaluation-
research/reports/earlier_years/9608students_algebra_midsc.pdf, 6/17/12.


Moses, Bob. (1995). “Algebra, The New Civil Right,” in Carole Lacampagne, William Blair, and
Jim Kaput (eds.) The Algebra Initiative Colloquium: Papers Presented at a Conference on
Reform in Algebra. Washington: U.S. Department of Education, Office of Educational Research
and Improvement, May.


Loveless, Tom. (2008) The Misplaced Math Student: Lost in Eighth-Grade Algebra.
Washington: Brookings Institution Brown Center Report on American Education, September.


National Mathematics Advisory Panel. (2008). Foundations for Success: The Final Report of the
National Mathematics Advisory Panel. U.S. Department of Education. Washington, DC.


Pope, Devin G., and Justin R. Sydnor. 2010. "Geographic Variation in the Gender Differences in
Test Scores." Journal of Economic Perspectives, 24(2): 95–108.

Rampey, Bobby D., Gloria S. Dion, and Patricia L. Donahue. 2009. The Nation's Report
Card: Trends in Academic Progress in Reading and Mathematics 2008, April.
http://nces.ed.gov/nationsreportcard/pubs/main2008/2009479.asp#section5, 6/17/12.

Schmidt, W.H. (2004). “A Vision for Mathematics.” Educational Leadership, 61(5): 6–11.


Schoenfeld, Alan. (1995) “Report of Working Group 1.” in Carole Lacampagne, William Blair,
and Jim Kaput (eds.) The Algebra Initiative Colloquium: Papers Presented at a Conference on
Reform in Algebra. Washington: U.S. Department of Education, Office of Educational Research
and Improvement, May.


Walston, J. and J.C. McCarroll (2010) “Eighth Grade Algebra: Findings from the Eighth-Grade
Round of the Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K).”

                                              27
National Center for Education Statistics Publication 2010-016.




                                               28
List of Figures and Tables


Figures
1.Map of NC with districts shown
Bar charts before exclusions, demonstrating differences
2.CMS
3.Wake
4.Forsyth
5.Durham
6.Taking Calculus: Algebra by 8th versus Algebra after 8th
7.Repeating Algebra I: Algebra by 8th , Algebra in 9th, and Algebra After 9th


Tables
1.Sample Sizes and Selected Summary Statistics, After Trimming
2a, 2b Correlates of Math Success: OLS Estimates (a=districts; b=deciles)
3.IV Estimates of the Impact of Acceleration into Algebra I by 8th Grade
4.Quitile Interaction Effects
5.Gender Interaction Effects
6.Free/Reduced Price Lunch Interaction Effects
7.Parental Education Interaction


Appendix Tables
A1. Chi-squared Tests for Variation in Risk for Algebra I
A2. F-tests for Unexplained Variation in Risk for Algebra I
A3. Decile-district Subsamples Excluded
A4. Sample Sizes and Selected Summary Statistics, Before Trimming




                                               29
  Figure 1. North Carolina Ten Largest Districts



                                 W-S/Forsyth                    Durham

                                               Guilford


                                                                         Wake



                                                                                Johnston
                            Cabarrus
               Gaston




    Charlotte-Mecklenburg

                                                          Cumberland
                            Union




Figure 2. Probability of Taking Algebra by 8th Grade,
              Charlotte-Mecklenburg




                                          30
Figure 3. Probability of Taking Algebra by 8th Grade, Wake




Figure 4. Probability of Taking Algebra by 8th Grade, Forsyth




                           31
              Figure 5. Probability of Taking Algebra by 8th Grade, Durham




             Figure 6. Taking Calculus: Algebra by 8th versus Algebra after 8th


                                 Taking Calculus by Year 5
     .8
Percentage
 .4  .2
     0  .6




              0             20            40             60            80            100
                   Quantiles (based on 6th and 7th grade standardized math scores)

                  % Taking Calculus by Year 5 Conditional on Taking Algebra by 8th Grade
                                             32
                  % Taking Calculus by Year 5 Conditional on Taking Algebra after 8th Grade
                 Figure 7. Repeating Algebra I: Algebra by 8th , Algebra in 9th,
                                     and Algebra After 9th


                                      Re-Taking Algebra
     1
Percentage
 .6  .4
     .2
     0 .8




             0              20            40             60            80            100
                   Quantiles (based on 6th and 7th grade standardized math scores)

                       % Repeating Algebra after Taking Algebra by 8th Grade

                       % Repeating Algebra after Taking Algebra in 9th Grade

                       % Repeating Algebra after Taking Algebra after 9th Grade




                                                 33
                                          Table 1. Samples Sizes and Selected Summary Statistics, After Trimming


                                      District         Average 6th and 7th                                                      Pass             Pass Algebra
School                Largest                                                       Algebra I        Pass Algebra I                                                      N
                                     Enrollmen              Grade                                                            Geometry             II by 12th
Districts              City                                                        Test Scores       by 10th Grade                                                    (Sample)
                                         t             EOG Math Scores                                                     by 11th Grade            Grade
                                                              1.052                    1.013
Wake                  Raleigh          141,194                                                              93.1                  84.5                 84.0            21,367
                                                            (0.711)                   (0.828)
                                                             -0.306                   -0.408
CMS                  Charlotte         134,121                                                              57.1                  35.1                 41.3            24,512
                                                            (0.900)                   (0.932)
                                                              0.021                   -0.224
Guilford            Greensboro          71,079                                                              73.2                  48.3                 55.0            25,691
                                                            (0.994)                   (1.029)
                                                              0.051                   -0.026
Cumberland          Fayetteville        53,264                                                              66.0                  44.0                 47.4            14,697
                                                            (0.819)                   (0.899)
                      Winston                                 0.395                    0.234
Forsyth                                 51,526                                                              74.9                  57.4                 59.8            10,798
                      Salem                                 (1.019)                   (1.056)
                                                              0.912                    0.765
Union                 Monroe            39,200                                                              93.6                  80.9                 80.1             4,878
                                                            (0.744)                   (0.807)
                                                              0.067                    0.067
Johnston             Smithfield         32,063                                                              70.9                  39.3                 42.5             3,928
                                                            (0.721)                   (0.721)
                                                             -0.210                   -0.259
Durham                Durham            31,867                                                              56.3                  33.5                 46.7             8,688
                                                            (1.005)                   (0.965)
                                                              0.700                    0.500
Gaston                Gastonia          32,169                                                              86.4                  60.6                 60.7             5,322
                                                            (0.781)                   (0.850)
                                                              1.170                    1.072
Cabarrus              Concord           28,127                                                              97.6                  93.1                 90.4             3,107
                                                               (0.470)                (0.686)
Note: The sample in each district covers the decile groups not excluded by tests of variability across cohorts. Each is restricted to students observed in the district during the
year after their first year in 7th grade that can be assigned to a decile based on 6th and 7th grade math test scores.. The district enrollment totals were obtained from
http://www.ncpublicschools.org/fbs/accounting/data/ and are shown for the school year 2009-2010. Means and standard deviations are reported for test scores, sample proportions
for all other variables. All test scores have been standardized.




                                                                                       34
              Table 2: Correlates of Math Success Measures: OLS Estimates

Independent variable            Algebra I    Pass Algebra   Pass Geometry    Pass Algebra
                               Test Scores     I by 10th     by 11th grade     II by 12th
                                                 grade                           grade
Enrolled in Algebra I by 8th -0.0850***       0.137***        0.0519***       0.0866***
Grade                          (0.021)          (0.012)         (0.006)         (0.006)
              th
Year entered 7 grade
(2000 omitted)                  0.0505          0.0232          0.0154         0.0262*
   2001                        (0.027)          (0.013)        (0.012)         (0.012)
                                0.0300          0.0113         0.00727         0.0148*
   2002
                               (0.027)          (0.008)        (0.011)         (0.006)
                              -0.00155         0.0254*         0.00990         0.00274
   2003
                               (0.025)          (0.010)        (0.012)         (0.006)
                              -0.00410         0.00177         0.00223         0.00489
   2004
                               (0.025)          (0.008)        (0.013)         (0.008)
                               0.0758*        -0.0544**         0.0140         0.00432
   2005
                               (0.029)          (0.020)        (0.012)         (0.008)
School District
(Wake omitted)                  -0.344***    -0.0539***      -0.0605***      -0.0680***
  Mecklenburg                     (0.024)       (0.009)         (0.012)         (0.009)
                                -0.374***      -0.00202       -0.0372**        -0.032**
   Guilford
                                  (0.021)       (0.008)         (0.012)         (0.010)
                                -0.211***    -0.0387***      -0.0495***       -0.072***
   Cumberland
                                  (0.017)       (0.009)         (0.010)         (0.009)
                                -0.264***       -0.0159       -0.0338**       -0.048***
   Forsyth
                                  (0.019)       (0.009)         (0.011)         (0.010)
                                -0.158***     0.0315***          0.012          0.00498
   Union
                                  (0.023)       (0.007)         (0.007)         (0.007)
                                 -0.0314        -0.0186       -0.091***       -0.120***
   Johnston
                                  (0.031)       (0.019)         (0.020)         (0.017)
                                -0.316***    -0.0516***       -0.075***         -0.0137
   Durham
                                  (0.018)       (0.009)         (0.015)         (0.010)
                                -0.230***      -0.00696       -0.108***       -0.131***
   Gaston
                                  (0.017)       (0.012)         (0.022)         (0.021)
                               -0.0692***     0.0333***       0.0226**         0.0216**
   Cabarrus
                                  (0.014)       (0.007)         (0.007)         (0.007)

Average of 6th and 7th grade
math test score decile
(lowest omitted)                0.266***      0.157***        0.0330***       0.0856***
   Second lowest                 (0.030)       (0.022)          (0.003)         (0.008)



                                              35
                                       0.495***           0.319***             0.104***             0.177***
    Third lowest                        (0.031)            (0.027)              (0.006)              (0.008)

                                       0.709***           0.458***             0.200***             0.280***
    Fourth lowest                       (0.032)            (0.023)              (0.011)              (0.014)

                                       0.954***           0.590***             0.364***             0.403***
    Fifth lowest                        (0.028)            (0.018)              (0.009)              (0.007)

                                       1.129***           0.646***             0.493***             0.499***
    Sixth lowest
                                        (0.043)            (0.018)              (0.022)              (0.016)
                                       1.416***           0.711***             0.656***             0.600***
    Seventh lowest
                                        (0.044)            (0.018)              (0.011)              (0.015)
                                       1.717***           0.741***             0.776***             0.699***
    Eighth lowest
                                        (0.033)            (0.021)              (0.008)              (0.008)
                                       2.084***           0.735***             0.837***             0.744***
    Ninth lowest
                                        (0.033)            (0.022)              (0.009)              (0.009)
                                       2.683***           0.695***             0.837***             0.749***
    Highest
                                        (0.033)            (0.021)              (0.014)              (0.014)
N                                       113738             124505               124505               124505
Adjusted R2                              0.720              0.485                0.571                 0.442
Note: Standard errors, corrected for clustering at the decile-cohort-district level, in parentheses. Algebra I test
score is taken from the student’s first test administration. Course passage for Algebra I and Algebra II is defined
as obtaining a standardized test score at or above the 20th percentile of the statewide distribution. Course passage
for Geometry is defined as obtaining an achievement level at or above 3 on the test. Grade-retained students are
kept with their original cohort. District fixed effects exist but are not shown in this table.
*** denotes a coefficient significant at the 0.1% level, ** the 1% level, * the 5% level.




                                                          36
                    Table 3: Instrumental Variable Estimates of the Impact of Acceleration into Algebra I in 8th Grade

                            Algebra I Test Score         Pass Algebra I by 10th grade         Pass Geometry by 11th grade           Pass Algebra II by 12th grade

                             IVQR w/imputation               2SLS                BP                2SLS                BP               2SLS                 BP
Independent variable

Enrolled in Algebra I              -0.374***               0.091***           0.400***          -0.066***           -0.152**           -0.026*            -0.038
by 8th Grade                         (0.006)                (0.021)            (0.086)            (0.014)            (0.056)           (0.012)            (0.046)

N                                   113,738                 124,505           124,505            124,505            124,505            124,505            124,505
Adjusted R2                                                  0.484                                0.564                                 0.436
Note: Standard errors, corrected for clustering at the decile-cohort-district level, in parentheses. Algebra I test score is taken from the student’s first test
administration. Course passage for Algebra I and Algebra II is defined as obtaining a standardized test score at or above the 20th percentile of the statewide
distribution. Course passage for Geometry is defined as obtaining an achievement level at or above 3 on the test. Grade-retained students are kept with their original
cohort. All models control for average 6th and 7th grade math test score decile, cohort and district fixed effects, and instrument for Algebra I enrollment by 8th grade
using an indicator representing the probability of taking Algebra I by 8th grade within your decile-cohort-district cell. Columns headed “2SLS” are estimated by two-
stage least squares; columns headed “BP” are estimated by bivariate probit. Column headed “IVQR w/imputation” applies the Neal and Johnson (1996) method of
imputing poor performance for 10,767 non-Algebra I-takers and estimating using the Chernozhukov and Hansen (2005) method.
*** denotes a coefficient significant at the 0.1% level, ** the 1% level, * the 5% level.




                                                                                37
                    Table 4a: Quintile Interaction Effects of the Impact of Acceleration into Algebra I in 8th Grade

                                                                                     Pass Algebra I             Pass Geometry              Pass Algebra II
                                         Algebra I Test Score
                                                                                      by 10th grade              by 11th grade              by 12th grade
Independent
                                     OLS                QR w/imputation                    OLS                        OLS                        OLS
variable
Quintile 1 Student *
                                 -0.183***                   0.028***                   0.192***                    0.0202*                   0.0935***
Enrolled in Algebra
                                   (0.035)                    (0.002)                    (0.018)                    (0.009)                     (0.008)
I by 8th Grade
Quintile 2 Student *
                                 -0.197***                   -0.156***                  0.140***                      0.016                    0.089***
Enrolled in Algebra
                                   (0.036)                     (0.001)                   (0.014)                     (0.011)                    (0.015)
I by 8th Grade
Quintile 3 Student *
                                 -0.185***                   -0.160***                  0.091***                     0.0249                    0.108***
Enrolled in Algebra
                                   (0.031)                     (0.001)                   (0.012)                     (0.015)                    (0.013)
I by 8th Grade
Quintile 4 Student *
                                  -0.098**                   -0.046***                  0.075***                   0.0767***                  0.0903***
Enrolled in Algebra
                                   (0.030)                     (0.001)                   (0.006)                     (0.007)                    (0.009)
I by 8th Grade
Quintile 5 Student *
                                    0.058                    0.136***                   0.130***                   0.0736***                  0.0721***
Enrolled in Algebra
                                   (0.037)                    (0.001)                    (0.027)                     (0.007)                    (0.006)
I by 8th Grade
N                                  113,738                    124,505                    124,505                    124,505                    124,505
Adjusted R2                         0.721                      0.376                      0.425                      0.572                      0.443
Note: Standard errors, corrected for clustering at the decile-cohort-district level, in parentheses. Algebra I test score is taken from the student’s first test
administration. Course passage for Algebra I and Algebra II is defined as obtaining a standardized test score at or above the 20th percentile of the statewide
distribution. Course passage for Geometry is defined as obtaining an achievement level at or above 3 on the test. Grade-retained students are kept with their
original cohort. All models control for average 6th and 7th grade math test score decile, cohort and district fixed effects. The main effect is divided into five
interaction effects by quintile. Column headed “QR w/imputation” applies the Neal and Johnson (1996) method of imputing poor performance for 10,767 non-
Algebra I-takers and estimating using the quantile regression method.
*** denotes a coefficient significant at the 0.1% level, ** the 1% level, * the 5% level.




                                                                               38
           Table 4b: Instrumented Quintile Interaction Effects of the Impact of Acceleration into Algebra I in 8th Grade

                                                                                       Pass Algebra I             Pass Geometry               Pass Algebra II
                                         Algebra I Test Score
                                                                                        by 10th grade              by 11th grade               by 12th grade
Independent                                                    RFQR
                                     2SLS                                                   2SLS                        2SLS                        2SLS
variable                                                    w/imputation
Quintile 1 Student *
                                  -0.479***                   -0.240***                   0.221***                   -0.108***                    -0.0627
Enrolled in Algebra
                                    (0.080)                     (0.015)                    (0.037)                     (0.031)                    (0.048)
I by 8th Grade
Quintile 2 Student *
                                  -0.456***                   -0.397***                  0.0921***                   -0.081***                    -0.0401*
Enrolled in Algebra
                                    (0.034)                     (0.006)                    (0.022)                     (0.012)                     (0.016)
I by 8th Grade
Quintile 3 Student *
                                  -0.429***                   -0.398***                    0.0356*                   -0.085***                    -0.0174
Enrolled in Algebra
                                    (0.034)                     (0.006)                    (0.015)                     (0.018)                    (0.020)
I by 8th Grade
Quintile 4 Student *
                                  -0.324***                   -0.260***                   0.0462**                     -0.0129                     -0.015
Enrolled in Algebra
                                    (0.048)                     (0.006)                    (0.014)                     (0.018)                     (0.017)
I by 8th Grade
Quintile 5 Student *
                                  -0.306***                   -0.140***                   0.096***                    0.0687**                      0.011
Enrolled in Algebra
                                    (0.092)                     (0.010)                    (0.022)                     (0.026)                     (0.023)
I by 8th Grade
N                                   113738                     124505                      124505                      124505                     124505
Adjusted R2                          0.712                      0.376                       0.424                       0.568                      0.436
Note: Standard errors, corrected for clustering at the decile-cohort-district level, in parentheses. Algebra I test score is taken from the student’s first test
administration. Course passage for Algebra I and Algebra II is defined as obtaining a standardized test score at or above the 20th percentile of the statewide
distribution. Course passage for Geometry is defined as obtaining an achievement level at or above 3 on the test. Grade-retained students are kept with their
original cohort. All models control for average 6th and 7th grade math test score decile, cohort and district fixed effects, and instrument for Algebra I enrollment
by 8th grade using an indicator representing the probability of taking Algebra I by 8th grade within your decile-cohort-district cell. Columns headed “2SLS” are
estimated by two-stage least squares. Column headed “RFQR w/imputation” applies the Neal and Johnson (1996) method of imputing poor performance for
10,767 non-Algebra I-takers and estimating using the Chernozhukov and Hansen (2005) method.
*** denotes a coefficient significant at the 0.1% level, ** the 1% level, * the 5% level.




                                                                                39
            Table 5: Instrumented Gender Interaction Effects of the Impact of Acceleration into Algebra I in 8th Grade

                                                                                       Pass Algebra I             Pass Geometry               Pass Algebra II
                                         Algebra I Test Score
                                                                                        by 10th grade              by 11th grade               by 12th grade
Independent                                                    RFQR
                                     2SLS                                                   2SLS                        2SLS                        2SLS
variable                                                    w/imputation
Enrolled in Algebra               -0.416***                   -0.398***                   0.0695**                  -0.0678***                  -0.0447***
I by 8th Grade                      (0.028)                     (0.011)                    (0.022)                    (0.014)                     (0.013)

                                  -0.064***                   -0.118***                  -0.051***                  -0.0159***                   -0.068***
Male
                                    (0.009)                     (0.005)                    (0.006)                    (0.004)                      (0.007)
Enrolled in Algebra
                                     0.014                    0.070***                    0.045***                     0.0042                    0.0379***
I by 8th Grade
                                    (0.021)                    (0.008)                     (0.007)                     (0.006)                     (0.011)
* Male
N                                   113738                     124505                      124505                      124505                     124505
Adjusted R2                          0.710                      0.377                       0.485                       0.564                      0.439
Note: Standard errors, corrected for clustering at the decile-cohort-district level, in parentheses. Algebra I test score is taken from the student’s first test
administration. Course passage for Algebra I and Algebra II is defined as obtaining a standardized test score at or above the 20th percentile of the statewide
distribution. Course passage for Geometry is defined as obtaining an achievement level at or above 3 on the test. Grade-retained students are kept with their
original cohort. All models control for average 6th and 7th grade math test score decile, cohort and district fixed effects, and instrument for Algebra I enrollment
by 8th grade using an indicator representing the probability of taking Algebra I by 8th grade within your decile-cohort-district cell. Columns headed “2SLS” are
estimated by two-stage least squares. Column headed “RFQR w/imputation” applies the Neal and Johnson (1996) method of imputing poor performance for
10,767 non-Algebra I-takers and estimating using the Chernozhukov and Hansen (2005) method.
*** denotes a coefficient significant at the 0.1% level, ** the 1% level, * the 5% level.




                                                                                40
   Table 6: Instrumented Free/Reduced Lunch Interaction Effects of the Impact of Acceleration into Algebra I in 8th Grade

                                                                                     Pass Algebra I            Pass Geometry              Pass Algebra II
                                        Algebra I Test Score
                                                                                      by 10th grade             by 11th grade              by 12th grade
Independent                                                  RFQR
                                    2SLS                                                  2SLS                       2SLS                       2SLS
variable                                                  w/imputation
Enrolled in Algebra              -0.330***                  -0.315***                   0.0467*                  -0.0765***                 -0.0534***
I by 8th Grade                     (0.034)                    (0.012)                   (0.019)                    (0.018)                    (0.015)

On Free/Reduced                 -0.0752***                  -0.141***                 -0.0835***                 -0.0831***                  -0.103***
Lunch                             (0.011)                     (0.006)                   (0.007)                    (0.010)                     (0.010)
Enrolled in Algebra
I by 8th Grade                   -0.124***                  -0.039***                  0.0884***                   0.0308*                   0.0621***
* On Free/Reduced                  (0.020)                    (0.010)                    (0.010)                   (0.014)                     (0.013)
Lunch
N                                  113738                     124505                     124505                     124505                     124505
Adjusted R2                         0.714                      0.378                      0.485                      0.567                      0.439
Note: Standard errors, corrected for clustering at the decile-cohort-district level, in parentheses. Algebra I test score is taken from the student’s first test
administration. Course passage for Algebra I and Algebra II is defined as obtaining a standardized test score at or above the 20th percentile of the statewide
distribution. Course passage for Geometry is defined as obtaining an achievement level at or above 3 on the test. Grade-retained students are kept with their
original cohort. Free/Reduced Lunch is defined as having ever been observed as receiving a free or reduced-price lunch during the students’ enrollment in NC.
All models control for average 6th and 7th grade math test score decile, cohort and district fixed effects, and instrument for Algebra I enrollment by 8th grade
using an indicator representing the probability of taking Algebra I by 8th grade within your decile-cohort-district cell. Columns headed “2SLS” are estimated by
two-stage least squares. Column headed “RFQR w/imputation” applies the Neal and Johnson (1996) method of imputing poor performance for 10,767 non-
Algebra I-takers and estimating using the Chernozhukov and Hansen (2005) method.
*** denotes a coefficient significant at the 0.1% level, ** the 1% level, * the 5% level.




                                                                              41
     Table 7: Instrumented Parent Education Interaction Effects of the Impact of Acceleration into Algebra I in 8th Grade

                                                                                     Pass Algebra I            Pass Geometry              Pass Algebra II
                                        Algebra I Test Score
                                                                                      by 10th grade             by 11th grade              by 12th grade
Independent                                                  RFQR
                                    2SLS                                                  2SLS                       2SLS                       2SLS
variable                                                  w/imputation
Enrolled in Algebra              -0.547***                  -0.358***                   0.128***                 -0.0955***                   -0.0375*
I by 8th Grade                     (0.030)                    (0.010)                    (0.022)                   (0.014)                     (0.016)

Parent with College                0.021*                    0.159***                   0.077***                  0.0534***                  0.0869***
Degree or More                     (0.009)                    (0.004)                    (0.006)                    (0.008)                    (0.009)
Enrolled in Algebra
I by 8th Grade
                                  0.202***                   0.028**                  -0.0512***                  0.0456***                     0.020
* Parent with
                                   (0.024)                   (0.008)                    (0.010)                     (0.012)                    (0.015)
College Degree or
More
N                                  113737                     124504                     124504                     124504                     124504
Adjusted R2                         0.712                      0.378                      0.487                      0.567                      0.441
Note: Standard errors, corrected for clustering at the decile-cohort-district level, in parentheses. Algebra I test score is taken from the student’s first test
administration. Course passage for Algebra I and Algebra II is defined as obtaining a standardized test score at or above the 20th percentile of the statewide
distribution. Course passage for Geometry is defined as obtaining an achievement level at or above 3 on the test. Grade-retained students are kept with their
original cohort. Parental education is defined as the highest level of education achievement by the more educated parent during the period in which the student
was observed. Completion of a four year college or graduate degree is necessary to be included in the category “Parent with College Degree or More”.
Community College or Trade School does not qualify. All models control for average 6th and 7th grade math test score decile, cohort and district fixed effects,
and instrument for Algebra I enrollment by 8th grade using an indicator representing the probability of taking Algebra I by 8th grade within your decile-cohort-
district cell. Columns headed “2SLS” are estimated by two-stage least squares. Column headed “RFQR w/imputation” applies the Neal and Johnson (1996)
method of imputing poor performance for 10,767 non-Algebra I-takers and estimating using the Chernozhukov and Hansen (2005) method.
*** denotes a coefficient significant at the 0.1% level, ** the 1% level, * the 5% level.




                                                                              42
                      A1. Chi-squared Tests for Variation in Risk for Algebra I



             Bottom   Decile   Decile   Decile   Decile    Decile   Decile    Decile   Decile    Top
             Decile     2        3        4        5         6        7         8        9      Decile
Wake          0.339   0.547    0.857    0.154    0.048     0.141    0.788     0.044    0.017    0.000
CMS           0.028   0.000    0.000    0.000    0.000     0.000    0.000     0.000    0.000    0.744
Guilford      0.000   0.000    0.000    0.000    0.000     0.000    0.000     0.000    0.000    0.000
Cumberland    0.261   0.000    0.000    0.000    0.000     0.000    0.000     0.001    0.000    0.000
Forsyth       0.634   0.004    0.000    0.057    0.727     0.030    0.063     0.000    0.000    0.000
Union          N/A     N/A     0.465    0.683    0.024     0.158    0.003     0.006    0.003    0.000
Johnston       N/A    0.070    0.039    0.007    0.308     0.003    0.281     0.004    0.069    0.148
Durham        0.000   0.000    0.000    0.000    0.000     0.000    0.000     0.019    0.000    0.000
Gaston        0.565   0.664    0.487    0.045    0.050     0.025    0.067     0.249    0.000    0.002
Cabarrus       N/A     N/A      N/A      N/A     0.640     0.755    0.424     0.003    0.000    0.035




                                                  43
                    A2. F-tests for Unexplained Variation in Risk for Algebra I


           Bottom     Decile    Decile    Decile   Decile    Decile    Decile     Decile   Decile    Top
           Decile       2         3         4        5         6         7          8        9      Decile
Wake        0.001     0.000     0.000     0.001    0.000     0.000     0.000      0.000    0.000    0.000
CMS         0.000     0.000     0.001     0.000    0.000     0.084     0.078      0.000    0.000    0.000
Guilford    0.000     0.000     0.000     0.000    0.000     0.000     0.000      0.000    0.000    0.000
Cumberland 0.000      0.000     0.000     0.000    0.001     0.449     0.000      0.004    0.003    0.000
Forsyth     0.000     0.000     0.000     0.000    0.000     0.000     0.000      0.000    0.000    0.000
Union       0.314     0.001     0.000     0.000    0.000     0.116     0.000      0.242    0.000    0.000
Johnston    0.000     0.000     0.001     0.000    0.000     0.000     0.000      0.000    0.000    0.000
Durham      0.000     0.000     0.000     0.000    0.000     0.175     0.000      0.000    0.000    0.000
Gaston      0.000     0.000     0.000     0.634    0.000     0.004     0.000      0.004    0.000    0.000
Cabarrus    0.000     0.000     0.000     0.000    0.299     0.000     0.000      0.000    0.000    0.000




                                                   44
                            A3. Decile-district Subsamples Excluded


             Bottom   Decile   Decile    Decile   Decile    Decile    Decile   Decile   Decile    Top
             Decile     2        3         4        5         6         7        8        9      Decile
Wake           X        X        X         X                 X          X
CMS                                                          X          X                          X
Guilford
Cumberland     X                                              X
Forsyth        X                           X           X                X
Union          X        X         X        X                  X                  X
Johnston       X        X                              X                X                 X        X
Durham                                                        X
Gaston         X        X         X        X                            X        X
Cabarrus       X        X         X        X           X      X         X




                                                  45
                            A4. Sample Sizes and Selected Summary Statistics, Before


School      Largest    District    Average 6th and 7th    Algebra I    Pass Algebra I     Pass     Pass Algebra      N
Districts    City     Enrollment        Grade            Test Scores   by 10th Grade    Geometry    II by 12th    (Sample)




                                                           46
                                                        EOG Math Scores                                                    by 11th Grade             Grade

                                                                 0.369                 0.514
Wake                   Raleigh           141,194                                                            78.6                 63.0                 65.1             40,978
                                                                (0.989)               (0.984)
                                                                 0.067                -0.090
CMS                   Charlotte          134,121                                                            68.2                 47.2                 52.2             35,117
                                                                (1.046)               (1.053)
                                                                 0.021                -0.224
Guilford             Greensboro          71,079                                                             73.2                 48.3                 55.0             25,691
                                                                (0.994)               (1.029)
                                                                -0.138                -0.143
Cumberland           Fayetteville        53,264                                                             60.3                 39.4                 42.9             19,048
                                                                (0.894)               (0.919)
                       Winston                                   0.056                -0.035
Forsyth                                  51,526                                                             66.9                 47.0                 50.9             17,731
                       Salem                                    (1.010)               (1.026)
                                                                 0.292                 0.351
Union                  Monroe            39,200                                                             79.2                 60.3                 60.9             10,119
                                                                (0.951)               (0.893)
                                                                 0.336                 0.336
Johnston             Smithfield          32,063                                                             72.8                 46.8                 49.7             9,267
                                                                (0.911)               (0.911)
                                                                -0.183                -0.246
Durham                 Durham            31,867                                                             58.4                 34.5                 48.1             11,114
                                                                (0.968)               (0.939)
                                                                 0.071                 0.106
Gaston                Gastonia           32,169                                                             67.0                 40.9                 42.2             12,953
                                                                (0.937)               (0.894)
                                                                 0.223                 0.342
Cabarrus              Concord            28,127                                                             78.4                 59.1                 58.5             8,573
                                                                (0.903)               (0.940)
Note: In each district, sample is restricted to students observed in the district during year 1 that can be assigned to a decile based on 6th and 7th grade math test scores. The
district enrollment data has been obtained from http://www.ncpublicschools.org/fbs/accounting/data/ and is shown for the school year 2009-2010. Mean and standard deviation
reported for test scores, sample proportion for all other variables. All test scores have been standardized.




                                                                                       47
