                                NBER WORKING PAPER SERIES




                INFORMATION PERCOLATION IN SEGMENTED MARKETS

                                           Darrell Duffie
                                         Semyon Malamud
                                          Gustavo Manso

                                        Working Paper 17295
                                http://www.nber.org/papers/w17295


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                     August 2011




The research of S. Malamud was supported in part by NCCR FINRISK, Project A5. Duffie is at the
Graduate School of Business, Stanford University and is an NBER Research Associate. Malamud
is at Swiss Finance Institute at EPF Lausanne. Manso is at the Sloan School of Business, MIT. We
are grateful for research assistance from Xiaowei Ding, Michelle Ton, and Sergey Lobanov, and for
discussion with Daniel Andrei, Luciano I. de Castro, Julien Cujean, Eiiricho Kazumori, and Phil Reny.
Malamud gratefully acknowledges financial support by the National Centre of Competence in Research
“Financial Valuation and Risk Management” (NCCR FINRISK).The views expressed herein are those
of the authors and do not necessarily reflect the views of the National Bureau of Economic Research.¸˛¸

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2011 by Darrell Duffie, Semyon Malamud, and Gustavo Manso. All rights reserved. Short sections
of text, not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including © notice, is given to the source.
Information Percolation in Segmented Markets
Darrell Duffie, Semyon Malamud, and Gustavo Manso
NBER Working Paper No. 17295
August 2011
JEL No. D53,D83,G14

                                            ABSTRACT

We calculate equilibria of dynamic double-auction markets in which agents are distinguished by their
preferences and information. Over time, agents are privately informed by bids and offers. Investors
are segmented into groups that differ with respect to characteristics determining information quality,
including initial information precision as well as market “connectivity,” the expected frequency of
their trading opportunities. Investors with superior information sources attain strictly higher expected
profits, provided their counterparties are unable to observe the quality of those sources. If, however,
the quality of bidders’ information sources are commonly observable, then, under conditions, investors
with superior information sources have strictly lower expected profits.


Darrell Duffie                                     Gustavo Manso
Graduate School of Business                        MIT
Stanford University                                Sloan School
Stanford, CA 94305-5015                            manso@mit.edu
and NBER
duffie@stanford.edu

Semyon Malamud
Swiss Finance Institute @ EPFL
Quartier UNIL-Dorigny, Extranef 213
CH - 1015 Lausanne, Switzerland
semyon.malamud@epfl.ch
1    Introduction

We calculate equilibria of dynamic double-auction markets in which agents are distin-
guished by their preferences and information. As in an opaque over-the-counter market,
agents gather information over time from the bids and offers of their counterparties. We
characterize the effect of segmentation of investors into groups that differ by their initial
information endowment or by their “connectivity,” which depends on the expected fre-
quency with which they trade with other investors, and the quality of the information
they obtain through their counterparties’ bids. More informed and better connected
agents attain strictly higher expected future profits, provided they are able to disguise
the characteristics determining the quality of their information. If, however, the charac-
teristics determining the quality of information of the bidders are commonly observable,
then investors that are better connected or have better initial information quality can
attain strictly lower expected future trading profits, under stated conditions.
      We model N classes of agents that are distinguished by their preferences for the
asset to be auctioned, by the expected rates at which they have trading opportunities
with each of other classes of agents, and by the quality of their initial information about
a random variable Y , which determines the ultimate utilities of the agents for the asset.
Over time, a particular agent of class i meets other agents at a sequence of Poisson arrival
times with mean arrival rate λi . At each meeting, a counterparty of class-j is selected
with probability κij . The two agents are given the opportunity to trade one unit of the
asset in a double auction.
      Based on their initial information and on the information gathered from bids in
prior auctions with other agents, the two agents typically assign different conditional
expectations to Y . Because the preference parameters are commonly observed by the
two agents participating in the auction, it is common knowledge which of the two agents
is the prospective buyer and which is the prospective seller. Trade occurs on the event
that the price β bid by the buyer is above the seller’s offer price σ, in which case the
buyer pays σ to the seller. This double-auction format is known as the “seller’s price
auction.”
      We provide technical conditions under which the double auctions have a unique
equilibrium in undominated strategies. We show how to compute the offer price σ and
the bid price β, state by state, by solving an ordinary differential equation. These prices
are strictly monotonically decreasing with respect to the seller’s and buyer’s conditional
expectations of Y , respectively. The bids therefore reveal these conditional expectations,


                                             1
which are then used to update priors for purposes of subsequent auctions. The technical
conditions that we impose in order to guarantee the existence of such an equilibrium also
imply that this particular equilibrium uniquely maximizes expected gains from trade in
each auction and, consequently, total welfare.
      Because our strictly monotone double-auction equilibrium fully reveals the bidders’
conditional beliefs for Y , we are able to explicitly calculate the evolution over time of the
cross-sectional distribution of posterior beliefs of the population of agents, by extending
the results of Duffie and Manso (2007) and Duffie, Giroux, and Manso (2008) to N classes
of investors. We can calculate the Fourier transforms of the cross-sectional distributions
of posterior beliefs of investors in each of the N different classes at each time t as the
solution of a N-dimensional Riccati ordinary differential equation in t. We can solve this
equation and then invert the transforms. In order to characterize the solutions, we also
extend the Wild summation method of Duffie, Giroux, and Manso (2008) to directly
solve the evolution equation for the cross-sectional distribution of beliefs.
      The double-auction equilibrium characterization, together with the characteriza-
tion of the dynamics of the cross-sectional distribution of posterior beliefs of each class
of agents, permits a calculation of the expected lifetime utility of each class of agent,
including the manner in which utility depends on the class characteristics determining
information quality, namely the precision of the initial information endowment and the
connectivity of that agent. Whether an agent profits from better information quality
is shown to depend on whether auction counterparties are able to pin down the quality
of that agent’s sources of information. Under specified conditions, well informed agents
may prefer that the quality of their information be less precisely determined. An im-
plication is that investors in over-the-counter markets that trade more actively (thus
gathering more information from counterparty bids and offers) or have better fundamen-
tal research, may prefer to obscure the quality of their information in order to avoid the
impact of adverse selection. By doing so, they may increase the probability that they
can execute a trade, or better the price execution of their trades. For example, a highly
informed investor might prefer to trade anonymously through a proxy, such as a broker,
even at a fee. (We do not, however, model proxy trading.)
      Although in some cases adverse selection causes investors with superior information
to attain lower expected profits, we also show that if gains from trade are sufficiently large
and additional technical conditions are satisfied, then investors with superior information
always attain higher expected profits. In particular, if the gains from trade are large
enough to offset losses stemming from adverse selection, then investors prefer to have

                                              2
the characteristics that determine the quality of their information to be publicly observed.
        Finally, we investigate whether investors with similar preference parameters would
engage in trading with the sole purpose of obtaining more information from their coun-
terparties. In functioning over-the-counter markets such as those for government bonds,
the informational advantage of handling more trades is sometimes said to lead dealers to
narrow quoted bid-ask spreads in order to increase counterparty contacts. We show that
investors with similar preferences parameters may indeed enter certain types of “swap”
agreements in order to reveal information to each other.


2       Related Literature

A large literature in economics and finance addresses learning from market prices of
transactions that take place in centralized exchanges.1 Less attention, however, is given
to information transmission in over-the-counter markets. Private information sharing
is typical in functioning over-the-counter markets for many types of financial assets,
including bonds and derivatives. In these markets, trades occur at private meetings in
which counterparties offer prices that reveal information to each other, but not to other
market participants.
        Wolinsky (1990), Blouin and Serrano (2001), Duffie and Manso (2007), Golosov,
Lorenzoni, and Tsyvinski (2008), Duffie, Giroux, and Manso (2008), and Duffie, Mala-
mud, and Manso (2009a,b) are among the few studies that have investigated the issue of
learning in over-the-counter markets. The models of search and random matching used
in these studies are unsuitable for the analysis of the effects of segmentation of investors
into groups that differ by connectivity and initial information quality. Here, we are able
to study these effects by allowing for classes of investors with distinct preferences, initial
information quality, and market connectivity.
        In our model, whenever two agents meet, they have the opportunity to participate
in a double auction. Chatterjee and Samuelson (1983) are among the first to study
double auctions. The case of independent private values has been extensively analyzed by
Williams (1987), Satterthwaite and Williams (1989), and Leininger, Linhart, and Radner
(1989). Kadan (2007) studies the case of correlated private values. We extend these
previous studies by providing conditions for the existence of a unique strictly monotone
equilibrium in undominated strategies of a double auction with common values. Bid
    1
    See, for example, Grossman (1976), Grossman and Stiglitz (1980), Wilson (1977), Milgrom (1981),
Pesendorfer and Swinkels (1997), and Reny and Perry (2006).



                                                3
monotonicity is natural in our setting given the strict monotone dependence on the asset
payoff of each agent’s ex-post utility for a unit of the asset. Strictly monotone equilibria
are not typically available, however, in more general double auctions with a common
value component, as indicated by, for example, Reny and Perry (2006).
        Our paper solves for the dynamics of information transmission in partially seg-
mented over-the-counter markets. Our model of information transmission is also suit-
able for other settings in which learning is through successive local interactions, such as
bank runs, knowledge spillovers, social learning, and technology diffusion. For example,
Banerjee and Fudenberg (2004) and Duffie, Malamud, and Manso (2009) study social
learning through word-of-mouth communication, but do not consider situations in which
agents differ with respect to connectivity. In social networks, agents naturally differ with
respect to connectivity. DeMarzo, Vayanos, and Zwiebel (2003), Gale and Kariv (2003),
Acemoglu, Dahleh, Lobel, and Ozdaglar (2008), and Golub and Jackson (2009) study
learning in social networks. Our model provides an alternative tractable framework to
study the dynamics of social learning when different groups of agents in the population
differ in connectivity with other groups of agents.
        The conditions provided here for fully-revealing double auctions carry over to a
setting in which the transactions prices of a finite sample of trades are publicly revealed,
as is often the case in functioning over-the-counter markets. With this mixture of pri-
vate and public information sharing, the information dynamics can be analyzed by the
methods2 of Duffie, Malamud, and Manso (2009b).


3       The Model

This section specifies the economy and characterizes equilibrium behavior. The following
section lays out special cases in which we are able to provide more insights.

3.1     The Double Auctions

A probability space (Ω, F , P) is fixed. An economy is populated by a continuum (a
non-atomic measure space) of risk-neutral agents who are randomly paired over time for
trade, in a manner that will be described. There are N different classes of agents that
differ according to the quality of their initial information, their preferences for the asset
to be traded, and the expected rate at which they meet each of other classes of agents
    2
    One obtains an evolution equation for the cross-sectional distribution of beliefs that is studied by
Duffie, Malamud, and Manso (2009b) for the case N = 1, and easily extended to the case of general N .


                                                   4
for trade. At some future time T , the economy ends and the utility realized by an agent
of class i for each additional unit of the asset is

                                        Ui = vi Y + v H (1 − Y ),

measured in units of consumption, for strictly positive constants v H and vi < v H , where Y
is a non-degenerate 0-or-1 random variable whose outcome will be revealed immediately
after time T .
       Whenever two agents meet at some particular time before T , they are given the
opportunity to trade one unit of the asset in a double auction. The auction format
allows (but does not require) the agents to submit a bid or an offer price for a unit of the
asset. (That agents trade at most one unit of the asset at each encounter is an artificial
restriction designed to simplify the model. One could suppose, alternatively, that the
agents bid for the opportunity to produce a particular service for their counterparty.)
Bids are observed by both agents participating in the auction. If an agent submits a
bid price that is higher than the offer price submitted by the other agent, then one
unit of the asset is assigned to that agent submitting the bid price, in exchange for an
amount of consumption equal to the ask price. Certain other auction formats would be
satisfactory for our purposes; we chose this format, known as the “seller’s price auction,”
for simplicity. Bids and offers in an auction are only observed by agents participating in
the auction.
       When a class-i and a class-j agent meet, their preference parameters vi and vj
are assumed to be commonly observable. Based on their initial information and on the
information that they have received from prior auctions held with other agents, the two
agents typically assign different conditional expectations to Y . From the no-speculative-
trade theorem of Milgrom and Stokey (1982), as extended by Serrano-Padial (2007) to
our setting of risk-neutral investors,3 the two counterparties decline the opportunity to
bid if they have identical preferences, that is, if vi = vj . If vi 6= vj , then it is common
knowledge which of the two agents is the prospective buyer (“the buyer”) and which is
the prospective seller (“the seller”). The buyer is of class j whenever vj > vi .
       The seller has an information set FS that consists of his initially endowed signals
relevant to the conditional distribution of Y , as well any bids and offers that he has
observed at his previous auctions. The seller’s offer price σ must be based only on (must
   3
     Milgrom and Stokey (1982) assume strictly risk-averse investors. Serrano-Padial (2007) shows that
for investors with identical preferences, even if risk-neutral, if the distributions of counterparties’ poste-
riors have a density, as here, then there is no equilibrium with a strictly positive probability of trade in
our common-value environment.

                                                      5
be measurable with respect to) the information set FS . The buyer, likewise, bids on the
basis of her information set FB . The prices (σ, β) constitute an equilibrium for a seller of
class i and a buyer of class j provided that, fixing β, the offer σ maximizes4 the seller’s
conditional expected gain,
                                                              
                            E (σ − E(Ui | FS ∪ {β}))1{σ<β} | FS ,                                (1)

and fixing σ, the bid β maximizes the buyer’s conditional expected gain
                                                           
                        E (E(Uj | FB ∪ {σ}) − σ)1{σ<β} | FB .                                    (2)

The seller’s conditional expected utility for the asset, E(Ui | FS ∪ {β})), once having con-
ducted a trade, incorporates the information FS that the seller held before the auction as
well as the bid β of the buyer. Similarly, the buyer’s utility is affected by the information
contained in the seller’s offer. The informational advantage conferred by more frequent
participation in auctions with well informed bidders is a key focus here.
       In Section 3.4, we demonstrate technical conditions under which there are equilibria
in which the offer price σ and bid price β can be computed, state by state, by solving
an ordinary differential equation, and are strictly monotonically decreasing with respect
to E(Y | FS ) and E(Y | FB ), respectively. This bid monotonicity is natural given the
strict monotone decreasing dependence on Y of Ui and Uj . Strictly monotone equilibria
are not typically available, however, in more general settings explored in the double-
auctions literature, as indicated by, for example, Reny and Perry (2006). Because our
strictly monotone equilibria fully reveal the bidders’ conditional beliefs for Y , we will be
able to explicitly calculate the evolution over time of the cross-sectional distribution of
posterior beliefs of the population of agents, by extending results in Duffie and Manso
(2007) and Duffie, Giroux, and Manso (2008). This, in turn, permits a characterization
of the expected lifetime utility of each type of agent, including the manner in which
utility depends on the quality of the initial information endowment and the “market
connectivity” of that agent.

3.2    Information Setting

Agents are initially informed by signals drawn from a common infinite pool of 0-or-1
random variables that are Y -conditionally independent.5 Each signal is received by at
   4
      Here, to “maximize” means, as usual, to achieve, almost surely, the essential supremum of the
conditional expectation.
    5
      To be more precise, there is a continuum of signals, indexed by a non-atomic measure space, say
[0, 1]. Almost every pair of signals is Y -conditionally independent.

                                                 6
most one agent. Each agent is initially allocated a randomly selected finite subset of
these signals. For almost every pair of agents, the numbers of signals received by each
of them is assumed to be independent of each other, and of the signals. (The number
of signals received by an agent is allowed to be deterministic.) The signals need not
have the same probability distributions. Without loss of generality, for any signal Z, we
suppose that
                              P(Z = 1 | Y = 0) ≥ P(Z = 1 | Y = 1).
       Whenever finite, we define the “information type” of an arbitrary finite set K of
random variables to be
                                       P(Y = 0 | K)       P(Y = 0)
                                 log                − log          ,                         (3)
                                       P(Y = 1 | K)       P(Y = 1)
the difference between the conditional and unconditional log-likelihood ratios. The con-
ditional probability that Y = 0 associated with the information type θ is thus
                                                       Reθ
                                           P (θ) =           ,                               (4)
                                                     1 + Reθ
where R = P(Y = 0)/P(Y = 1), and the information type of a collection of signals is
one-to-one with the conditional probability that Y = 0 given the signals. Proposition
3 of Duffie and Manso (2007) implies that whenever a collection of signals of type θ is
combined with a disjoint collection of signals of type φ, the type of the combined set of
signals is θ + φ. More generally, we will use the following result from Duffie and Manso
(2007).

Lemma 3.1 Let S1 , . . . , Sn be disjoint sets of signals with respective types θ1 , . . . , θn .
Then the union S1 ∪ · · · ∪ Sn of the signals has type θ1 + · · · + θn . Moreover, the type of
the information set {θ1 , θ2 , . . . , θn } is also θ1 + θ2 + · · · + θn .

       The Lemma has two key implications for our analysis. First, if two agents meet
and reveal all of their endowed signals, they both achieve posterior types equal to the
sum of their respective prior types. Second, for the purpose of determining posterior
types, revealing one’s prior type (or any random variable such as a bid that is strictly
monotone with respect to type) is payoff-equivalent to revealing all of one’s signals.
       An agent of class i is matched with other agents at each of a sequence of Poisson
arrival times with a mean arrival rate (intensity) λi > 0. At each meeting time, the
agent’s counterparty is randomly selected from the population of agents. The probability
that a class-j counterparty is selected is denoted κij . Without loss of generality for the

                                                     7
purposes of analyzing the evolution of information, we take κij = 0 whenever vi = vj ,
because of the no-trade result for agents with the same preferences. A primitive κ that
does not satisfy this property can without loss of generality be adjusted so as to satisfy
this property by conditioning, case by case, on the event that the agents matched have
vi 6= vj .
       As is standard in search models of markets, we assume that, for almost every pair of
agents, the matching times and the counterparties of one agent are independent of those
of the other. We do not show the existence of such a random-matching process, although
Duffie and Sun (2007) show the existence of a model with this random matching property
for a continuum-of-agents in a discrete-time setting, as well as the associated law of large
numbers for random matching on which we rely. Further, the limit behavior of the
discrete-agent matching models as the number of agents gets large is shown by Reminik
(2009) to coincide with the matching behavior on which we rely in our continuous-time
model.6
       In this random-matching setting, a given pair of agents that have been matched
will almost surely never be matched again nor will their respective lifetime sets of trading
counterparties overlap. Thus, equilibrium bidding behavior in the multi-period setting
is characterized by equilibrium bidding behavior in each individual auction, as described
above. Later, we will provide primitive technical conditions on the preference parame-
ters v H and vi , as well as the cross-sectional distribution of initially endowed information
types, that imply the existence of an equilibrium with strictly monotone bidding strate-
gies. In this setting, bids therefore reveal types. Lemma 3.1 and induction thus imply
that agents’ types add up from auction to auction. Specifically, an agent leaves any
auction with a type that is the sum of his type immediately before the auction and the
type of the other agent bidding at the auction. This fact now allows us to characterize
the dynamics of the cross-sectional evolution of posterior types.
   6
    See also Ferland and Giroux (2008). Taking G to be the set of agents, we assume throughout the
joint measurability of agents’ type processes {θit : i ∈ G} with respect to a σ-algebra B on Ω × G that
allows the Fubini property that, for any measurable subset A of types,
                             Z                          Z                
                                 P(θαt ∈ A) dγ(α) = E        1θαt ∈A dγ(α) ,
                             G                          G

where γ is the measure on the agent space. Sun (2006) provides a condition on B, which we assume,
that is consistent with the exact law of large numbers. InR our setting, if almost
                                                                                R every pair of types
from {θαt : α ∈ G} is independent, this law implies that E G 1θαt ∈A dγ(α) = G 1θαt ∈A dγ(α) almost
surely. Sun (2006) further proves the existence of a model with this property.




                                                  8
3.3    Evolution of Type Distributions

For each class i, we suppose that the initial cross-sectional distribution of types of the
class-i agents has some density ψi0 . We do not require that the individual class-i agents
have types with the same probability distribution. Nevertheless, our independence and
measurability assumptions imply the exact law of large numbers, by which the density
function ψi0 has two deterministic outcomes, almost surely, one on the event that Y = 0,
         H                                                L
denoted ψi0 , the other on the event that Y = 1, denoted ψi0 . That is, for any real
interval (a, b), the fraction of class-i agents whose type is initially between a and b is
                Rb H                                                        Rb L
almost surely a ψi0   (θ) dθ on the event that Y = 0, and is almost surely a ψi0 (θ) dθ on
                                                           H       L
the event that Y = 1. We make the further assumption that ψi0 and ψi0 have moment-
generating functions that are finite on a neighborhood of zero. Special cases satisfying
this condition are the basis for illustrative examples in Section 4.
                                                                               H       L
       The initial cross-sectional type densities in the high and low states, ψi0 and ψi0 ,
are related by the following.

Proposition 3.2 We always have7

                                         H
                                        ψi0 (x) = ex ψi0
                                                      L
                                                         (x) .                                        (5)

       Our objective now is to calculate, for any time t > 0, the cross-sectional density
ψit of the types of class-i agents. This cross-sectional density has (almost surely) only
two outcomes, one on the event Y = 0 and one on the event Y = 1, denoted ψitH and ψitL ,
respectively.
       Assuming that the asset auctions are fully revealing, which will be confirmed under
technical conditions, the evolution equation for the cross-sectional densities is
                                                    N
                 dψit                      X
                      = −λi ψit + λi ψit ∗     κij ψjt ,              i ∈ {1, . . . , N},             (6)
                  dt                       j=1


where ∗ denotes convolution. We offer a brief explanation of this evolution equation. The
first term on the righthand side captures the outward migration of agents of any given
information type θ, at rate λi ψit (θ), that is caused by a change to some other information
type due to information gathered at auctions, which occur at the total proportional rate
λi . Here, we use the law of large numbers, which almost surely equates the mean rate
   7         L                                                            H
                                                                  R
    Because ψi0 is a probability density, this result implies that R e−x ψi0 (x) dx = 1. In the Appendix,
                           H
we show that any density ψi0 satisfying this constraint can be realized as an initial cross-sectional type
density.


                                                    9
of change for each agent with the total population rate. The second term captures
the inward migration of agents of a given information type due to learning from bids
at auctions. The second term is easily understood by noting that auctions with class-j
counterparties occur at rate λi κij . At such an encounter, in a fully revealing equilibrium,
bids reveal the types of both agents, which are then added to get the posterior types of
each. A class-i agent of type θ is thus created if a class-i agent of some type φ meets a
class-j agent of type θ − φ. Because this is true for any possible φ, we integrate over φ
with respect to the population densities. Thus, the total rate of increase of the density
of class-i agents of type-θ agents due to the information released at auctions with class-j
agents is                     Z   +∞
                     λi κij            ψit (φ)ψjt (θ − φ) dφ = λi κij (ψi ∗ ψj )(θ).
                              −∞
Adding over j gives the second term on the righthand side of the evolution equation (6).
For the case N = 1, this evolution model is motivated in more detail, and solved, by
Duffie and Manso (2007) and Duffie, Giroux, and Manso (2008).
      Equation (6) can be solved in terms of the moment generating function of ψit or,
by the same calculation, the Fourier transform ψ̂it of ψit . We have
                                                     N
                 dψ̂it                      X
                       = −λi ψ̂it + λi ψ̂it     κij ψ̂jt ,              i ∈ {1, . . . , N},   (7)
                  dt                        j=1

using the fact that the Fourier transform of a convolution of two measures is the product
of their Fourier transforms. Now, (7) is a Riccati ordinary differential equation in t
for the N-dimensional vector ψ̂t (z) = (ψ̂1t (z), . . . , ψ̂N t (z)). We can solve this equation,
numerically if necessary, and then invert the transform to compute the type densities.
In special cases, we have an explicit solution, for example as follows.

Proposition 3.3 Suppose that N = n + m, with n classes of buyers, all with vi = v̄,
and with m classes of sellers, all with vj = v < v̄. Suppose that all classes have the
same mean contact rate λ. We assume that the class selection probability κij = kj for
buyer-to-seller contacts does not depend on the buyer class i, and likewise that κji = ki
for seller-to-buyer contacts. The initial type densities can vary across the n + m classes
without restriction. We let                           n
                                                      X
                                             φ1t =           ki ψit
                                                      i=1
and
                                                     n+m
                                                     X
                                           φ2t =             kj ψjt .
                                                     j=n+1


                                                     10
We calculate that
                                             e−λt (φ̂20 − φ̂10 )
                                                                                          φ̂10 e−φ̂10 (1−e
                                                                                                             −λt )
                  φ̂1t =
                              φ̂20 e−φ̂20   (1−e−λt )   − φ̂10 e−φ̂10   (1−e−λt )


                                             e−λt (φ̂20 − φ̂10 )
                                                                                      φ̂20 e−φ̂20 (1−e
                                                                                                         −λt )
                  φ̂2t =                                                                                         .
                      φ̂20 e−φ̂20        (1−e−λt )      − φ̂10 e−φ̂10   (1−e−λt )

We then have the solution
                                              ψ̂i0
                              ψ̂it   =               φ̂1t ,        1 ≤ i ≤ n,
                                              φ̂10
                                              ψ̂j0
                              ψ̂jt   =               φ̂2t ,        n + 1 ≤ j ≤ n + m.
                                              φ̂20


        For general N, λi , κij , and ψi0 , an alternative to inverting the transform ψ̂ is to
directly solve the evolution equation for the type distributions by extending the Wild
summation method of Duffie, Giroux, and Manso (2008). The Wild-sum representation
also allows us, in Section 4, to characterize expected auction profits in special cases. In
order to calculate the Wild-sum representation of type densities, we proceed as follows.
For an N-tuple k = (k1 , . . . , kN ) of nonnegative integers, let ait (k) denote the fraction
of class-i agents who by time t have collected (directly, or indirectly through auctions)
the originally endowed signal information of k1 class-1 agents, of k2 class-2 agents, and
so on, including themselves. This means that |k| = k1 + · · · + kN is the number of agents
whose originally endowed information has been collected by such an agent. To illustrate,
consider an example agent of class 1 who, by a particular time t has met one agent of
class 2, and nobody else, with that agent of class 2 having beforehand met 3 agents of
class 4 and nobody else, and with those class-4 agents not having met anyone before
they met the class-2 agent. The class-1 agents with this precise scenario of meeting
circumstances would contribute to a1t (k) for k = (1, 1, 0, 3, 0, 0, . . . , 0). We can view ait
as a measure on ZN
                 + , the set of N-tuples of nonnegative integers. By essentially the same
reasoning used to explain the evolution equation (6), we have
                                                                N
                                                                X
                       a0it   = −λi ait + λi ait ∗                     κij ajt ,             ai0 = δei ,             (8)
                                                                j=1

where
                                                                   X
              (ait ∗ ajt )(k1 , . . . , kN ) =                                                ait (l) ajt (k − l).
                                                     {l=(l1 ,...,lN ) ∈ ZN
                                                                         +   , |l|≤|k|}


                                                              11
Here, δei is the dirac measure placing all mass on ei , the unit vector whose i-th coordinate
is 1.

Theorem 3.4 There is a unique solution of (6), given by
                                       X                             ∗kN
                                                      ∗k1
                             ψit =           ait (k) ψ10  ∗ · · · ∗ ψN 0 ,                (9)
                                      k∈ZN
                                         +


       ∗n
where ψi0 denotes n-fold convolution.


        That (9) solves (6) follows from substitution and the use of (8). A complete proof
is given in the Appendix. The system (8) of equations for the discrete measures admits
a closed-form solution via the following recursive procedure. First, ai (0) = 0 for all i,
and, because the probability that a class-i agent has met nobody by time t is e−λi t , we
have
                                     ait (ei ) = e−λi t ai0 (ei ).

Thus, we have ai (k) for all k with |k| ≤ 1. Then, we can solve (8) inductively: Having
found ai (k) whenever |k| ≤ k, for some k, we calculate it for any k with |k| = k + 1 by
solving (8), using the fact that the right-hand side is an ODE for ai (k) that is linear in
ai (k) and otherwise involves ai (l) only for |l| ≤ k.
        The following result will be useful in Section 4.

Proposition 3.5 The measures ait are monotone increasing in time t and in the meeting
intensities λi , in the sense of first order stochastic dominance.

3.4     Double Auction Solution

Fixing a particular time t, suppose that a class-i and a class-j agent meet, and that the
prospective buyer is of class i (that is, vi > vj ). We now calculate their equilibrium
bidding strategies. Naturally, we look for equilibria in which the outcome of the offer σ
for a seller of type θ is S(θ) and the outcome of the bid β of a buyer of type φ is B(φ),
where S( · ) and B( · ) are some strictly monotone increasing functions on the real line.
In this case, if (σ, β) is an equilibrium, we also say that (S, B) is an equilibrium.
        We assume for the results in this section that whenever two agents are in contact,
each can observe all of the primitive characteristics, ψi0 , λi, κi , and vi , of the class of
the counterparty. In the following section, we consider variants of the model in which
the initial type density ψi0 , the mean trading rate λi of one’s counterparty, and the

                                                  12
probabilities κi = (κi1 , . . . , κiN ) that govern the distribution of the classes of matched
counterparties need not be observable.
       Given a candidate pair (S, B) of such bidding policies, a seller of type θ who offers
the price s has an expected increase in utility, defined by (1), of
                     Z +∞
                            (s − vj − ∆j P (θ + φ)) Ψi (P (θ), φ) dφ,                           (10)
                               B −1 (s)

where ∆j = v H − vj and where Ψi (P (θ), · ) is the seller’s conditional probability density
for the unknown type of the buyer, defined by

                                    Ψi (p, φ) = p ψitH (φ) + (1 − p) ψitL (φ).                  (11)

Likewise, from (2), a buyer of type φ who bids b has an expected increase in utility for
the auction of
                        Z    S −1 (b)                           
                                        vi + ∆i P (θ + φ) − S(θ) Ψj (P (φ), θ) dθ.              (12)
                        −∞

       The pair (S, B) therefore constitutes an equilibrium if, for almost every φ and
θ, these gains from trade are maximized with respect to b and s by B(φ) and S(θ),
respectively.
       The hazard rate hLit (θ) associated with ψitL is defined as usual by
                                                            ψitL (θ)
                                               hLit (θ) =            ,
                                                            GLit (θ)
                   R∞
where GLit (θ) =    θ
                            ψit (x) dx. That is, given Y = 1, hLit (θ) is the probability density for
the type θ of a randomly selected buyer, conditional on this type being at least θ. We
likewise define the hazard rate hH                       H
                                 it (θ) associated with ψit . We say that ψit satisfies the
hazard-rate ordering if, for all θ, we have hH         L
                                             it (θ) ≤ hit (θ).
       Because the property (5) is maintained under mixtures and convolutions, it follows
from (9) that (5) holds for all t ≥ 0. Therefore, the likelihood ratio ψitH (x)/ψitL (x) = ex is
always increasing. The appendix provides a proof of the following.

Lemma 3.6 For each agent class i and time t, the type density ψit satisfies the hazard-
rate ordering, hH         L                H         x L
                it (θ) ≥ hit (θ), and and ψit (x) = e ψit (x) . If, in addition, each signal
Z satisfies
                                 P(Z = 1 | Y = 0) + P(Z = 1 | Y = 1) = 1,                       (13)
then
                   ψitH (x) = ex ψitH (−x),          ψitL (x) = ψitH (−x),       x ∈ R.         (14)

                                                       13
The technical restriction (13) on signal distributions is somewhat typical of learning
models, for example those of Bikhchandani, Hirshleifer and Welch (1992) and Chamley
(2004, p. 24). We will now adopt this assumption as well as the following technical
regularity condition on initial type densities.

Standing Assumption: Any signal Z satisfies (13). Moreover, the initial type densities
are strictly positive and twice differentiable, with
                                                 d2 H
                                                       
                                 d H
                       Z
                           kx
                          e        ψ (x) +         ψ (x) dx < ∞                         (15)
                        R       dx i0           dx2 i0
                                        H
for any k < αi0 , where αi0 = sup{k : ψ̂i0 (k) < ∞}.

      The calculation of an equilibrium is based on the ODE, stated in the following
result, for the type V2 (b) of a buyer who optimally bids b. That is, V2 is the inverse B −1
of the candidate equilibrium bid policy function B.

Lemma 3.7 For any V0 ∈ R, there exists a unique solution V2 ( · ) on [vi , v H ) to the ODE
                                                        
     0         1     z − vi       1               1
   V2 (z) =                               + L              ,     V2 (vi ) = V0 .         (16)
            vi − vj v H − z hHit (V2 (z))   hit (V2 (z))
This solution, also denoted V2 (V0 , z), is monotone increasing in both z and V0 . Further,
limz→vH V2 (V0 , z) = +∞ . The limit V2 (−∞, z) = limV0 →−∞ V2 (V0 , z) exists. Moroever,
V2 (−∞, z) is continuously differentiable with respect to z.

      As shown in the proof of the next proposition, found in the appendix, the ODE (16)
arises from the first-order optimality conditions for the buyer and seller. The solution of
the ODE can be used to characterize equilibria in the double auction, as follows.

Proposition 3.8 Suppose that (S, B) is a continuous equilibrium such that S(θ) ≤ v H
for all θ ∈ R. Let V0 = B −1 (vi ) ≥ −∞. Then,

                                 B(φ) = V2−1 (φ),   φ > V0 .

Further, S(−∞) = limθ→−∞ S(θ) = vi and S(+∞) = limθ→−∞ S(θ) = v H . For any
θ, we have S(θ) = V1−1 (θ), where
                                 z − vi
                V1 (z) = log            − V2 (z) − log R ,     z ∈ (vi , v H ) .
                                 vH − z
Any buyer of type φ < V0 will not trade, and has a bidding policy B that is not uniquely
determined at types below V0 .

                                             14
      In our double-auction setting, welfare is increasing in the probability of trade con-
ditional on Y = 1. We are therefore able to rank the equilibria of our model in terms
of welfare, because, from the following corollary of Proposition 3.8, we can rank the
equilibria in terms of the probability of trade conditional on Y = 1.

Corollary 3.9 Let (S, B) be a continuous equilibrium with V0 = B −1 (vi ). Then S(φ) is
strictly increasing in V0 for all φ, while B(φ) is strictly decreasing in V0 for all φ > V0 .
Consequently, the probability of trade conditional on Y = 1 is strictly decreasing in V0 .

      Buyers and sellers bid more aggressively in equilibria with lower V0 . Thus, the
probability of trade conditional on Y = 1 and total welfare are strictly decreasing in V0 .
      We turn to the study of particular equilibria, providing conditions for the exis-
tence of equilibria in strictly monotone undominated strategies. We also give sufficient
conditions for the failure of such equilibria to exist. We focus on the welfare-maximizing
equilibria.
      From Proposition 3.8, the bidding policy B is not uniquely determined at types
below B −1 (vi ), because agents with these types do not trade in equilibrium. Nevertheless,
the equilibrium bidding policy B satisfying B(φ) = vi whenever φ < V0 weakly dominates
any other equilibrium bidding policy. That is, an agent whose type is below V0 and who
bids less than vi can increase his bid to vi , thereby increasing the probability of buying
the asset, without affecting the price, which will be at most the lowest valuation vi of
the bidder. An equilibrium in strictly monotone undominated strategies is therefore only
possible if V0 = −∞. We now provide technical conditions supporting the existence of
such welfare-maximizing equilibria.
      We say that a function g( · ) on the real line or the integers is of exponential type
α at +∞ if, for some constants c > 0 and γ > −1,

                                             g(x)
                                      lim          = c.                                  (17)
                                    x→+∞    xγ eαx
In this case, we write g(x) ∼ Exp+∞ (c, γ, α). We say that a family {gt : t ∈ [0, T ]} of
functions satisfies the condition gt (x) ∼ Exp+∞ (ct , γt , αt ) uniformly in t if the conver-
gence in (17) is uniform in t.
      The tail condition (17), which we will use as a technical regularity assumption
on type densities, arises naturally in information percolation models, as we show in the
following simple case, in which we also characterize the tail parameters α, c, and γ.



                                             15
Lemma 3.10 Suppose N = 1, and let λ = λ1 and ψt = ψ1t . The Laplace transform ψ̂t
of ψt is given by
                                                   e−λt ψ̂0 (z)
                                 ψ̂t (z) =
                                        1 − (1 − e−λt )ψ̂0 (z)
and ψt (x) ∼ Exp+∞ (ct , 0, −αt ), where αt is the unique positive number z solving
                                                      1
                                      ψ̂0 (z) =             ,
                                                   1 − e−λt
and where
                                                    e−λt
                                  ct =         d
                                                            .
                                  (1 − e−λt )2 dz ψ̂0 (αt )
Further, αt is monotone decreasing in t, with limt→∞ αt               =    0. Moreover, if ψ0 ∼
Exp(c0 , 0, α0 )), then ψt (x) ∼ Exp+∞ (ct , 0, −αt ) uniformly in t.

      The tail condition (17) also applies to the type density ψit in more general cases,
such as the multi-class example considered in Proposition 3.3, as shown in the Appendix.
We conjecture that the tail condition (17) holds for any of the information percolation
models considered in this paper, but we have not been able to prove this conjecture.
      The following proposition provides conditions for the existence of a unique welfare-
maximizing equilibrium in strictly monotone strategies, which are therefore fully re-
vealing. For this purpose, we define α∗ to be the unique positive solution to α∗ =
1 + 1/(α∗2α ), which is approximately 1.31. Our result depends in part on a sufficiently
            ∗



high level of
                                            vi − vj
                                         G(v) =      ,
                                            v H − vi
a measure of the relative gain from trade between buyers and sellers.

Proposition 3.11 Suppose that, for all i and t, there are αit , cit , and γit such that,
uniformly in t,
                              ψitH (x) ∼ Exp+∞ (cit , γit , −αit ).                        (18)
If αiT < 1, then there is no equilibrium associated with V0 = −∞. Suppose, however,
that αiT > α∗ and that, for all t,
                                  (αit + 1) log αit
                     −γit    <                         ,          if αit ≥ 2
                               log(αit + 1) − log αit
                                 log(αit2 − αit ) 2αit
                     −γit    <                         ,          if αit < 2.
                               log(αit + 1) − log αit
Then, if the gain from trade G(v) is sufficiently large, there exists a unique strictly
monotone equilibrium associated with V0 = −∞. This equilibrium is in undominated
strategies, and maximizes total welfare among all continuous equilibrium bidding policies.

                                                  16
      The technical regularity conditions of the proposition, combined with a sufficiently
large trading motive as measured by G(v), together guarantee that V2 (z) does not grow
too fast in z, leading V1 (z) to be monotone increasing, and thus allowing a welfare-
maximizing fully-revealing equilibrium in strictly monotone strategies. Under the condi-
tions of Proposition 3.11, there may be other equilibria in undominated strategies that
are associated with a finite V0 . The equilibrium with V0 = −∞, however, maximizes the
probability of trade conditional on Y = 1, uniquely so for t > 0, and consequently also
maximizes welfare.


4    Connectedness, Information Quality, and Profitability

We now study whether an agent with more precise initial information or with a higher
expected frequency of opportunities to gather information from trading attains higher
total expected future trading profits. We will also show, in an extension of our model
that allows an agent to hide his initial information quality or his expected frequencies
of auction observations with each of the other agent classes, whether this can increase
the agent’s expected trading profits, through the increased uncertainty of the agent’s
counterparties regarding the quality of the agent’s information. This is relevant in func-
tioning markets through the decision of an investor of whether to trade openly with a
given reputation for market connectedness, or whether to trade through proxy investors
whose quality of information is more uncertain, or through other indirect forms of trade
execution.
      For these purposes, we first need to characterize investors’ expected utilities. We
assume throughout this section the existence of a unique welfare-maximizing equilibrium
in strictly monotone bidding strategies for each time t < T , sufficient conditions for which
are given by Proposition 3.11. Our utility calculations are based throughout on these
equilibrium bidding strategies.
      The stochastic type process Θ of any particular class-i agent is a Markov process.
The transition distribution function of Θ is determined by the probability density of
Θt − Θs given Θs , for any times s and t > s. We let ρs,t ( · | Θs ) denote this conditional
density function, and calculate it as follows.

Lemma 4.1 We have

                     ρs,t (y | Θs ) = P (Θs )hH                       L
                                              s,t (y) + (1 − P (Θs ))hs,t (y),




                                                17
where, for K = H or K = L, the density hK
                                        s,t ( · ) satisfies, for each fixed s, the evolution
equation
                            d K                            X
                               hs,t = −λi hK         K
                                           s,t + λi hs,t ∗
                                                                  K
                                                             κij ψjt ,                                         (19)
                            dt                             j

with an initial condition at t = s given by the Dirac measure at 0. The Fourier transform
of hK
    s,t is                                                                                         !
                                                                     Z       t   X
                          ĥK
                            s,t = e
                                   −λi (t−s)
                                             exp λi                                        K
                                                                                     κij ψ̂jτ dτ       .       (20)
                                                                         s       j

We therefore have the solution
                                            ∞
                                                                                                   !∗k
                                                                             t
                                              1
                                            X                        Z           X
                      hK
                       s,t = e
                              −λi (t−s)
                                                                λi                        K
                                                                                     κij ψjτ dτ            .   (21)
                                              k!                         s       j
                                            k=0


The ODE (19) follows from an argument like that given for (6). The corresponding ODE
for ĥK
      s,t is linear, and thus has the solution (20). The solution (21) arises from the series
definition of the exponential function and the fact that multiplication on the Fourier side
corresponds to convolution for the inverse Fourier transform.
       The expected future profit at time t of this agent is
                                   "                                                                   #
                                       X X
                   Ui (t, Θt ) = E              κij πij (τk , Θτk )                                Θt ,
                                                    τk > t      j

where τk is this agent’s k-th auction time and πij (t, θ) is the expected profit of a class-i
agent of type θ entering an auction at time t with a class-j agent. Given our equilibrium
bidding functions (B, S) for such an auction, we can calculate πij (t, θ) in the obvious
way.8 Because our class-i agent enters auctions at Poisson times with an intensity of λi ,
we have                                 Z       T    Z
                  Ui (t, Θt ) = λi                           ρt,τ (θ − Θt | Θt ) πi (τ, θ) dθ dτ ,             (22)
                                            t            R
                  P
where πi (t, θ) =     j κij πij (t, θ).
       To this point, we have always assumed that whenever two agents are in contact,
each can observe all of the primitive characteristics, ψi0 , λi , κi , and vi , of the class i of the
counterparty. We now consider a variant of the model in which the initial type density
ψi0 , the mean trading rate λi , and the vector κi of counterparty selection probabilities are
not observable. These characteristics affect the quality of the counterparty’s information,
   8
                                                R +∞
    That is, for vi < vj we have πij (t, θ) = B −1 (S(θ)) (s − vi − ∆i P (θ + φ)) Ψi (P (θ), φ) dφ, and for
                            R S −1 (B(θ))                          
vi > vj we have πij (t, θ) = −∞           vi + ∆i P (θ + φ) − S(φ) Ψi (P (θ), φ) dφ.

                                                               18
and therefore affect bidding strategies. For this purpose, we assume for the remainder
of this section that two classes, say classes 1 and 2, have v1 = v2 , but may differ with
respect to λi and ψi0 , and moreover, that their counterparties may or may not be able
to distinguish between classes 1 and 2. In a setting in which this distinction cannot be
made, a class-j agent therefore assigns the probabilities κj1 /(κj1 +κj2) and κj2 /(κj1 +κj2)
of facing a class-1 and class-2 counterparty, respectively. We let π̂ij (t, θ) be the expected
profit of a class-i agent of type θ entering an auction at time t with a class-j agent, when
primitive characteristics ψi0 , λi , and κi are not observable.
      We isolate for utility comparison a particular class-1 agent with type process Θ1
and a particular class-2 agent with type process Θ2 . For simplicity, we assume that for
each class, the initial types of almost every pair of agents in the class are identically
and independently distributed given Y . It follows from the law of large numbers that
the probability distribution of the initial type Θ10 has a density equal to the cross-
sectional type density ψ10 of class 1, and likewise that Θ20 has the probability density
ψ20 . Because class-1 and class-2 agents are mutually indistinguishable from the viewpoint
of their counterparties, at any given auction they bid or offer according to a pooled bid
policy B and a pooled offer policy S.
      For the remaining results, we suppose that the initial Y -conditional type density
ψ10 of class-1 agents is that associated with receiving a random number of signals that
is identically distributed across class-1 agents, with a density p1 on the positive integers.
That is, p1 (k), also denoted p1k , is the probability of receiving k signals at time zero.
Class-2 agents are initially informed in the same manner, except that the probability
density of the number of signals that they receive is p2 . The signals given to each agent
are drawn at random from a common pool of signals whose joint distributions with Y
vary cross-sectionally so that the type of a randomly selected signal has some fixed Y -
conditional probability density f ( · ), with outcome f H ( · ) on the event Y = 0 and f L ( ·)
on the event Y = 1. Thus, for any positive integers m and n > m, receiving n signals
implies strictly better information precision than receiving m signals.
      We continue to let Ui (t, θ) denote the expected future profit of a class-i agent of
type θ at time t, in our usual setting of completely observable agent characteristics, and
we let Ûi (t, θ) denote the utility of a class-i agent in the alternative market setting, in
which the characteristics ψi0 , λi , and κij of class-1 and class-2 agents are not distin-
guishable. We now show that when one’s quality of information cannot be distinguished
by one’s counterparty, better quality information, whether due to a higher expected fre-
quency of trading encounters or to better initial information, increases total expected

                                              19
auction profits.
Theorem 4.2 If λ2 ≥ λ1 and if the initial type densities ψ10 and ψ20 are distinguished
by the fact that the density p2 of the number of signals received by class-2 agents has
first-order stochastic dominance over the density p1 of the number of signals by class-1
agents, then
                      E[ Û2 (t, Θ2t )]   E[ Û1 (t, Θ1t )]
                                        ≥                   , t ∈ [0, T ].           (23)
                             λ2                  λ1
The inequality (23) holds strictly if, in addition, λ2 > λ1 or if p2 has strict dominance
over p1 .
      The comparison (23) implies that the utility advantage of class-2 agents holds even
after adjusting for their higher expected frequency of auction opportunities. The intuition
is that class-2 investors are expected to be more informed than class-1 investors at any
point in time, either because, in expectation, they will learn more in auctions than class-
1 investors or because they are initially better informed than class-1 investors. Because
class-2 investors cannot be distinguished from class-1 investors by their counterparties,
the class-2 investors attain higher total expected profits than class-1 investors.
      The previous result shows that better informed and better connected investors
have strictly higher expected trading profits if they are able to hide the characteristics
determining the quality of their information. This stands in contrast to a fully-revealing
rational expectations equilibrium, in which investors cannot profit from their private
information. In our decentralized market, it takes time for prices to converge to the
rational expectations price and investors can thus profit from their superior information
in early trades.
      Up to this point, we compared expected profits when investors are able to hide
the characteristics determining the quality of their information. We next show that if
investors must trade openly with respect to their connectivity and initial information
quality, then having better initial information and more opportunities to collect infor-
mation from trades can in some cases lead to lower expected trading profits.
      For the remainder of this section, we further restrict our economy so as to allow
a total of N = 3 classes of agents. We assume that v1 = v2 ≡ v̄ > v3 , so that the only
trades are those in which class-3 agents sell to class-1 or class-2 agents.
      The next example describes a situation in which better informed buyers have a
lower utility than worse informed buyers, provided that the characteristics determin-
ing their information quality are commonly observable. An analogous example can be
obtained based on a comparison of the matching intensities λi , as in Theorem 4.2.

                                            20
Example 4.3 Suppose that κ1 = κ2 and λ1 = λ2 , so that classes 1 and 2 differ only
with respect to their initial cross-sectional type densities ψ10 and ψ20 . In particular, we
suppose that the number of initial signals received by class-2 investors has first-order
dominance over the number received by class-1 investors such that

                      H                 e3x             L         H
                     ψ10 (x) = 12               ,      ψ10 (x) = ψ10 (−x),
                                     (1 + ex )5
and
                                        H     H     H
                                       ψ20 = ψ10 ∗ ψ10 .
                                                         H
Moreover, we assume that the seller’s type distribution ψ30 corresponds to a distribution
sufficiently close in total-variation norm to the convex combination of Dirac measures
given by
                                (1 + e−A )−1 e−A δ−A + δA ,
                                                         
                                                                                                 (24)
for a constant A. Taking v3 = 0, v1 = v2 = 1.6, and A = 1, the conditions for
the existence of our double auction equilibria are satisfied and we have E[ π13 (0, θ)] =
0.38331, E[ π23 (0, θ)] = 0.37232, E[ π̂13 (0, θ)] = 0.38150, and E[ π̂23 (0, θ)] = 0.40038.
Therefore, by continuity, there exists a sufficiently small time horizon T such that, for
any time t,

  E[ U 2 (t, Θ2t )] < E[ Û1 (t, Θ1t )] < E[ U1 (t, Θ1t )] < E[ Û2 (t, Θ2t )],   t ∈ [0, T ].   (25)


      Class-3 investors face greater adverse selection from class-2 counterparties than
from class-1 counterparties, given the relative information precision of the class-2 in-
vestors. In order to mitigate this increased adverse selection, class-3 investors tend to
bid more conservatively when facing class-2 investors, if they can distinguish them, thus
lowering the expected profit to a class-2 investor. On the other hand, in order to benefit
from completing a sale on the event Y = 1, class-3 investors must bid more aggressively
against class-2 investors than against class-1 investors whenever they believe that the
event Y = 1 is relatively likely. This aggressive bidding brings extra expected benefits
to class-2 investors conditional on the event Y = 1. In Example 4.3, the first effect
dominates the second, and class-2 investors attain lower expected profits than those of
class-1 investors, as stated by (25), when their information quality can be distinguished.
      In Example 4.3, if class-1 investors have the choice, they would prefer to operate
in a market in which the quality of counterparty information is revealed. In this situa-
tion, class-1 investors avoid the adverse selection problem of being pooled with class-2
investors.

                                                21
      Although Example 4.3 provides conditions under which better informed buyers
attain lower profits than worse informed buyers when their information quality can be
distinguished, the opposite can happen if the gain from trade is so large as to cause the
opportunity value of an exchange to dominate the adverse selection effect.
      In order to show this result, we introduce the following notation. For two densities
g1 and g2 on the real line, we say that g2 has a fatter right tail than g1 , and write
Tail(g1 ) ≺ Tail(g2 ), if gi ∼ Exp+∞ (ci , γi , −αi ) and if

                                            g2 (x)
                                     lim           = +∞.
                                    x→+∞    g1 (x)

This fatter-tail condition applies if either α2 < α1 or both α1 = α2 and γ2 > γ1 . The
weak version of this ordering is defined by writing Tail(g1 )  Tail(g2 ) if α2 ≤ α1 or if
both α1 = α2 and γ2 ≥ γ1 .
                                                                    H
      From this point, we assume that for each of classes 1 and 2, ψi0 satisfies an ex-
                          H
ponential tail condition ψi0 ∼ Exp+∞ (ci , γi , −αi ). For this, if the random number of
signals received by an agent is bounded, it suffices that the probability density f H of
the type of a single randomly selected signal, given Y = 0, satisfies an exponential tail
condition. This result is stated and proved as Appendix Lemma E.1, which also gives
an alternative sufficient condition for cases in which the random number of signals is not
bounded, but has a density with a tail “close to” that of the geometric distribution, in
a sense made precise in Lemma E.1.

Lemma 4.4 If the density p2 of the number of signals endowed to class-2 agents has
first-order stochastic dominance over the density p1 of the number of signals endowed to
                           H            H
class-1 agents, then Tail(ψ10 )  Tail(ψ20 ). Furthermore, if either

                          sup {k : p1k > 0} < sup {k : p2k > 0}

or if p1 (k) and p2 (k) are strictly positive for sufficiently large k, with

                                   p1 (k + 1)       p2 (k + 1)
                             lim              < lim            ,
                             k→∞     p1 (k)     k→∞   p2 (k)
           H            H
then Tail(ψ10 ) ≺ Tail(ψ20 ).


In this sense, being more informed means having fatter-tailed information types.



                                               22
Proposition 4.5 Suppose that κ1 = κ2 and λ1 = λ2 , so that classes 1 and 2 differ only
with respect to their initial cross-sectional type densities ψ10 and ψ20 . We also suppose
that the number of initial signals received by class-2 investors has first-order dominance
over the number received by class-1 investors, that
                                    α1t + 1
                                            > α3t ,     t ∈ [0, T ],
                                    α1t − 1
               H            H
and that Tail(ψ10 ) ≺ Tail(ψ20 ) (more informative tails for class-2 agents).9 Then, if the
gain-from-trade meaure G(v) is sufficiently large,

      E[ U 1 (t, Θ1t )] < E[ Û1 (t, Θ1t )] < E[ Û2 (t, Θ2t )] < E[ U2 (t, Θ2t )],   t ∈ [0, T ].

       The same two partially offsetting effects highlighted in the discussion after Example
4.3 continue to play a role here. The gain-from-trade measure G(v) can be made so large,
however, that the expected loss associated with a failure to exchange the asset dominates
the adverse-selection effect, allowing class-2 investors to attain higher profits than class-1
investors even when the determinants of information quality are commonly observed.
       Under the conditions of Proposition 4.5, class-1 investors prefer to be in a market
in which the quality of information is not revealed. Again, the adverse selection effect is
dominated by the loss-from-no-trade effect, reversing the result of Example 4.3.
       Analogous results can be obtained when agents differ only in terms of the mean
arrival rates of their opportunities to gather information from trading, as we show with
the next proposition.

Proposition 4.6 Suppose that κ1 = κ2 and λ1 < λ2 , and that class-1 and class-2 in-
vestors have the same initial information quality, that is, ψ10 = ψ20 . We further assume
the exponential tail condition ψitH ∼ Exp+∞ (cit , γit , −αit ) for all i and t, with α10 < 3,
                                                   α10 − 1
                                          α30 >            ,
                                                   3 − α10
and
                              α1t + 1
                                      > α3t , t ∈ [0, T ].
                              α1t − 1
If the gain-from-trade measure G(v) is sufficiently large, then for any time t we have
            E[ U2 (t, Θ2t )]   E[ Û2 (t, Θ2t )]   E[ Û1 (t, Θ1t )]   E[ U1 (t, Θ1t )]
                             >                   >                   >                  .
                  λ2                  λ2                  λ1                 λ1
  9
     In fact, this condition is “almost” unnecessary, in that we have already assumed that p2 has
                                                                             H             H
first-order dominance over p1 . With this dominance, it is enough for Tail(ψ10 ) ≺ Tail(ψ20  ) that
                                                                                             H
limk→∞ p1 (k + 1)/p1 (k) < limk→∞ p2 (k + 1)/p2 (k). As a substitute for the condition Tail(ψ10 ) ≺
       H
Tail(ψ20 ), it suffices that α1 = α2 , γ1 = γ2 , and c2 > c1 .

                                                  23
      Many of the results of this section can also be stated in the form of comparisons
of the conditional expected utilities, Ui (t, Θit ) and Ûi (t, Θit ). We avoid this for brevity.


5    Subsidizing Order Flow

So far, in meetings between agents i and j with vi = vj , no trade takes place. In
this section we investigate the possibility that agents with similar preference parameters
engage in trading with the sole purpose of obtaining more information about Y from their
counterparties. In functioning over-the-counter markets, such as those for government
bonds, the informational advantage of handling more trades is sometimes said to be a
sufficient advantage to cause dealers to narrow quoted bid-ask spreads in order to increase
counterparty contacts.
      Because of our continuum-of-agents assumption, an agent is indifferent to the
amount of information revealed to a counterparty, because this information has at most
an infinitesimal impact on that agent’s expected future terms of trade. We now describe
a simple mechanism that induces agents to strictly prefer to truthfully reveal information
to their counterparties. This mechanism can be interpreted as the trading of a contingent
claim.
      Suppose that upon meeting, two agents i and j with similar parameter preferences
can enter a “swap” agreement by which the amount

                               k (pj (t) − Y )2 − (pi (t) − Y )2 ,
                                                               


will be paid by investor i to investor j at time T , where pi (t) and pj (t) are real variables
reported by investors i and j at time t, and where k > 0 is a coefficient. The protocol
is that the players first negotiate the multiplier k, and then both agents simultaneously
submit their respective “reports” pi (t) and pj (t). Provided that k is strictly greater
than zero and that both agents have agreed to enter, in equilibrium player i optimally
submits a report pi (t) that is his or her conditional expectation of Y (or equivalently,
the conditional probability of the event Y = 1).
      For the above mechanism to induce truthful revelation of posteriors in each auction,
we must show that, at any particular meeting there exists some k > 0 such that both
agents are willing to enter the swap agreement voluntarily. Lemma G.1 in the appendix
shows that, keeping fixed the bidding policy of other investors in the economy, an investor
attains strictly higher profits if he learns information from another investor in a meeting.
Because this information gathering activity is not observable by other investors in the

                                               24
economy, it is a dominating strategy for investors to subsidize order flow with the purpose
of learning information from investors with similar preferences, as long as the cost of the
subsidy, although strictly positive, is sufficiently small. The net expected cost of the
subsidy can indeed be made arbitrarily small in each auction, so that the benefits in
terms of information gathering are greater than the costs in terms of the potential loss
to the counterparty. If, for example, we let k be the minimum of two coefficients ki > 0
announced by the two agents when they meet and before they enter the swap agreement,
then there is an equilibrium in which both agents select a small enough ki such that they
are willing to participate in the swap agreement.
      Therefore, there exists an equilibrium in which investors always subsidize order
flow with counterparties with similar preference parameters, and counterparties treat
investors as if they have been engaging in this activity.
      The ability to subsidize order flow may have a negative impact on investors ex-
pected profits. For example, under the conditions of Example 4.3, an investor attains
higher profits if he is less informed. However, as shown in this section, if investors have
the ability to subsidize order flow to get more information, they will engage in this be-
havior, and may thus end up with a lower profit than if they did not have the ability to
subsidize order flow.




                                            25
                                        Appendices

A     Information Percolation

Proof of Proposition 3.3. For simplicity, by abuse of notation, we omit everywhere
in this proof the superscript “H” on densities, writing ψt in place of ψtH , and so on.
      Passing to Laplace transforms and adding up the equations for ψ̂it over i and the
equation for ψ̂jt over j we get the system
                                    d
                                       φ̂1t = −λ φ̂1t + λ φ̂1t φ̂2t
                                    dt                                                                                       (26)
                                    d
                                       φ̂2t = −λ φ̂2t + λ φ̂1t φ̂2t .
                                    dt
Subtracting,
                                         φ̂1t − φ̂2t = e−λ t ν̂,
where ν̂ = φ̂10 − φ̂20 satisfies ν̂(0) = 0. That is, in this case φ̂1t converges exponentially
to φ̂2t . Thus,
                                 d
                                    φ̂1t = λ φ̂1t (−1 + φ̂1t − e−λt ν̂) .
                                 dt
Denote ξt = φ̂1t eλt . Then,
                                       d
                                          ξt = λe−λt ξt (ξt − ν̂).
                                       dt
Integrating, we get
                                          ξ      φ̂10 −ν̂(1−e−λt )
                                               =      e            .
                                        ξ − ν̂   φ̂20
That is,

                                                 e−λt (φ̂20 − φ̂10 )
             φ̂1t = e−λt ξˆt =                                                                φ̂10 e−φ̂10 (1−e
                                                                                                                 −λt )
                                                                                                                         .
                                  φ̂20 e−φ̂20   (1−e−λt )   − φ̂10 e−φ̂10         (1−e−λt )


On the other hand, integrating (26), we get
                                                                       Rt
                                       φ̂1t = φ̂10 e−λt eλ             0
                                                                            φ̂2s ds



and therefore
                                                    Rt                     φ̂1t
                                        e−λt eλ      0
                                                         φ̂2s ds
                                                                   =              .
                                                                        φ̂10
Similarly,
                                                    Rt                  φ̂2t
                                        e−λt eλ      0
                                                         φ̂1s ds
                                                                   =              .
                                                                        φ̂20

                                                            26
Thus, integrating the equation for the Laplace transform of ψit , we get
                                                   Rt                 ψ̂i0
                           ψ̂it = ψ̂i0 e−λt eλ      0
                                                        φ̂2s ds
                                                                  =          φ̂1t ,
                                                                      φ̂10
and similarly for ψjt .

Proof of Theorem 3.4.             Let the probability measures {ait (k) : k ∈ ZN
                                                                               +, i ∈
{1, . . . , N}} on ZN
                    + satisfy the system of ODEs:

                                                                  N
                                                                  X
                            a0it = −λi ait + λi ait ∗                   κij ajt
                                                                  j=1

or, coordinate-wise,
                                          N
           d                             X                            X
              ait (k) = −λi ait (k) + λi     κij                                          ait (l1 ) ajt(l2 ).
           dt                            j=1              {l1 , l2 ∈ ZN
                                                                      + : l1 +l2 = k}


Let
                                               X
                                   ψit =                ait (k)ψ0∗k ,
                                               k∈ZN
                                                  +

where
                                         def
                                         ∗k1            ∗kN
                                 ψ0∗k = ψ10  ∗ · · · ∗ ψN 0 .

The series is well defined and convergent because ait is a probability measure. Then,
      d             X d
         ψit   =          ait (k) ψ0∗k
      dt             N
                       dt
                   k∈Z+
                                                N
                                                                                                 !
                    X                           X                 X
               =           −λi ait (k) + λi             κij                 ait (l1 ) ajt (l2 ) ψ0∗k
                   k∈ZN
                      +
                                                j=1           l1 + l2 = k
                                                                                                             
                                  N
                                  X                X                                      X
               =   −λi ψit + λi          κij              ait (l1 ) ψ0∗l1  ∗                  ajt (l2 )ψ0∗l2 
                                   j=1          l1 ∈ZN                                  l2 ∈ZN
                                                     +                                       +

                                  N
                                  X
               =   −λi ψit + λi          κij ψit ∗ ψjt .
                                   j=1

Uniqueness follows by standard arguments.

Proof of Proposition 3.5.         Let f : Z+ → R be monotone increasing and bounded.
Let also Yit be a random variable (taking values in Z+ ) distributed with the measure ait .

                                                   27
By (8),
                                                                           N
      d X                                X                                 X
           ait (k) f (k)       =   −λi            ait (k) f (k) + λi               κij (ait ∗ ajt )(k) f (k)
      dt k                                  k                              j=1
                                                                  N
                                                                  X
                               =   −λi E[f (Yit )] + λi                 κij E[f (Yit + Yjt )]
                                                                  j=1
                                                              N
                                                              X
                               ≥ −λi E[f (Yit )] + λi                   κij E[f (Yit )] = 0,
                                                              j=1

and the stipulated monotonicity in time follows.
      Now, define (for the moment, formally), for p ∈ {1, . . . , N},
                                            (p)         ∂
                                           bit    =        ait .
                                                       ∂λp
Differentiating (formally) (8) with respect to λp , for i 6= p we get
                                 N                      N
   d (p)          (p)      (p)
                                X                      X        (p)                            (p)
      bit = − λi bit + λi bit ∗     κij ajt + λi ait ∗     κij bjt ,                          bi0 = 0,         (27)
   dt                           j=1                    j=1

and otherwise we get
                 N                                     N                      N
 d (p)          X                       (p)      (p)
                                                      X                      X        (p)
    bpt = apt ∗     κpj ajt − apt − λp bpt + λp bpt ∗     κpj ajt + λp apt ∗     κpj bjt , (28)
 dt             j=1                                   j=1                    j=1

                                     (p)
with the same initial condition bp0 = 0. This is a system of linear equations for the
          (p)       (p)
vector bt       = (bit ). Following standard arguments, for example those of Duffie, Manso
and Malamud (2009b), this equation indeed has a unique solution, which is a finite
measure, and this solution measure is indeed the derivative of bit with respect to λp .
      Denoting
                                            (p)             (p)
                                           cit    = eλi t bit ,
we get that
                            N                      N
     d (p)        λi t (p)
                           X                      X                    (p)                        (p)
        cit = λi e cit ∗       κij ajt + λi ait ∗     κij e(λi −λj )t cjt ,                      ci0 = 0,
     dt                    j=1                    j=1

and similarly for i = p.
                                                                             (p)
      Now, let us pass to the moment-generating functions ĉit and âit of these measures.
Define the matrix
                                         K̂(t) = (R̂ij (t)),

                                                      28
where
                                                                                N
                                                                                X
                                       (λi −λj )t
                       R̂ij (t) = κij e               λi âit + δij λi                κik âkt
                                                                                k=1

and let
                                                                   N
                                                                   X
                                          λp t
                                                                                        
                         α̂(t) = (δip ) e            âpt ∗              κpj âjt − âpt .
                                                                   j=1

Then, the system (27)-(28) is equivalent to the following system for the moment-generating
functions:
                             d (p)             (p)
                               ĉ  = K̂(t) ĉt + α̂(t).                                          (29)
                            dt t
Consider the fundamental solution Φ(t, τ ) to the equation
                       d
                          Φ̂(t, τ ) = K̂(t) Φ̂(t, τ ) ,                  Φ̂(t, t) = IN ×N .
                       dt
Then, the unique solution to (29) is given by
                                       Z t
                                (p)
                              ĉt =        Φ̂(t, τ ) α̂(τ ) dτ .
                                                 0

Once again, a standard argument implies that the matrix Φ̂(t, τ ) consists of moment
generating functions of measures Φij (t, τ ) that solve the system of equations
                      d
                         Φ(t, τ ) = K(t) ∗ Φ(t) ,                        Φ(t, t) = IdN ×N ,
                      dt
where IdN ×N has the Dirac measure δ0 for each diagonal element, and zero off-diagonal
elements. Since K(t) consists of positive measures, it follows (for example, from the
Euler scheme for constructing the solution) that Φ(t, τ ) is a matrix of positive measures.
Hence,                                                   Z     t
                           (p)              −λi t
                          bt     = diag(e            )             Φ(t, τ ) ∗ α(τ ) dτ.
                                                           0

Thus, for any monotone increasing bounded f : ZN   + → R,
                                                  Z tXX
 ∂ X                     X (p)
                                            −λi t
         ait (k) f (k) =   bit (k) f (k) = e              (Φij (t, τ ) ∗ αj (τ ))(k) f (k) dτ.
∂λp k                    k                         0 j  k

Let Z be a random variable with distribution Φij (t, τ ) (normalized, if necessary, to have
mass one) and let X be an independent variable whose distribution is
                                            N
                                            X
                                                         κpj ajt .
                                             j=1


                                                         29
      Then,
                    XX
                                    (Φij (t, τ ) ∗ αj (τ ))(k) f (k)
                     j      k
                                                                      N
                                                                                              !!
                            X                                         X
                =   eλp t                Φip (t, τ ) ∗   âpt ∗             κpj âjt − âpt        (k) f (k)
                                k                                     j=1
                =   E[f (Z + X + Ypt )] − E[f (Z + Ypt )] ≥ 0.

The claim follows.

      Proof of Lemma 3.6. First, we say that a pair (F H , F L ) of cumulative distri-
bution functions (CDFs) on the real line is amenable if

                                              dF L(y) = e−y dF H (y),                                          (30)

and symmetric amenable if

                                        dF L(y) = dF H (−y) = e−y dF H (y),                                    (31)

that is, if for any bounded measurable function g,
             Z +∞                Z +∞                Z                             +∞
                          L                    H
                   g(y) dF (y) =      g(−y) dF (y) =                                    e−y g(y) dF H (y).
              −∞                               −∞                                 −∞

      It is immediate that the sets of amenable and symmetric amenable pairs of CDFs
is closed under mixtures, in the following sense.

Fact 1. Suppose (A, A, η) is a probability space and F H : R×A → [0, 1] and F L : R×A →
[0, 1] are jointly measurable functions such that, for each α in A, (F H ( · , α), F L( · , α))
is an amenable (symmetric amenable) pair of CDFs. Then an amenable (symmetric
                                                         H        L
amenable) pair of CDFs is defined by (F , F ), where
                     Z                               Z
               H          H                    L
             F (y) =    F (y, α) dη(α),     F (y) =    F L (y, α) dη(α).
                                    A                                              A



      The set of amenable (symmetric amenable) pairs of CDFs is also closed under finite
convolutions.

Fact 2. Suppose that X1 , . . . , Xn are independent random variables and Y1 , . . . , Yn are
independent random variables such that, for each i, the CDFs of Xi and Yi are amenable

                                                             30
(symmetric amenable). Then the CDFs of X1 + · · · + Xn and Y1 + · · · + Yn are amenable
(symmetric amenable).

      For a particular signal Z with type θZ , let FZH be the CDF of θZ conditional on
Y = 0, and let FZL be the CDF of θZ conditional on Y = 1.

Fact 3. If (FZH , FZL ) is an amenable pair of CDFs and if Z satisfies (13), then (FZH , FZL)
is a symmetric amenable pair of CDFs.

In order to verify Fact 3, we let θ be the outcome of the type θZ on the event {Z = 1},
so that

                      P(Y = 0 | Z = 1)       P(Y = 0)       P(Z = 1 | Y = 0)
            θ = log                    − log          = log
                      P(Y = 1 | Z = 1)       P(Y = 1)       P(Z = 1 | Y = 1)
and let
                      P(Y = 0 | Z = 0)       P(Y = 0)       P(Z = 0 | Y = 0)
           θ̃ = log                    − log          = log
                      P(Y = 1 | Z = 0)       P(Y = 1)       P(Z = 0 | Y = 1)

be the outcome of the type θZ on the event {Z = 0} . Then,

                                     eθ − eθ+θ̃        eθ+θ̃ − eθ̃
                          FZH =                 1θ≤y +             1θ̃≤y                (32)
                                      eθ − eθ̃          eθ − eθ̃
and
                                 1 − eθ̃        eθ − 1
                            FZL =        1θ≤y +          1θ̃≤y .
                                eθ − eθ̃        eθ − eθ̃
The amenable property (5) is thus satisfied.
      If Z satisfies (13), −θ is the outcome of θZ associated with observing Z = 0, so

                                      eθ                1
                         FZH (y) =       θ
                                           1{θ ≤ y} +        1{ −θ ≤ y}
                                     1+e              1 + eθ
and
                                  1                  eθ
                         FZL (y) =     1 {θ ≤ y} +        1{ −θ ≤ y} .
                                1 + eθ             1 + eθ
These CDFs are each piece-wise constant, and jump only twice, at y = −θ and y = θ. We
let ∆F (y) = F (y) −limz↑y F (z). At y = −θ and y = θ, we have ∆FZH (−y) = e−y ∆FZH (y)
and ∆FZL (y) = ∆FZH (−y), completing the proof of Fact 3.

      Now, we recall that a particular agent receives at time 0 a random number, say
N, of signals, where N is independent of all else, and can have a distribution that

                                                31
depends on the agent. By assumption, although the signals need not have the same
joint distributions with Y , all signals satisfy (13). The type of the set of signals received
by the agent is, by Lemma 3.1, the sum of the types of the individual signals. Thus,
conditional on N, the type θ of this agent’s signal set has a CDF conditional on Y = 0,
denoted FNH , and a CDF conditional on Y = 1, denoted FNL , that are the convolutions of
the conditional distributions of the underlying N signals given Y = 0 and given Y = 1,
respectively. Thus, by Facts 2 and 3, conditional on N, (FNH , FNL ) is an amenable pair of
CDFs. Now, we can average these CDFs over the distribution of N to see by Fact 1 that
this agent’s type has CDFs given Y = 0 and Y = 1, respectively, that are amenable.
      Now, let us consider the cross-sectional distribution of agent types of a given class
i at time 0, across the population. Recall that the agent space is the measure space
(G, G, γ). Let γi denote the restriction of γ to the subset of class-i agents, normalized by
the total mass of this subset. Because of the exact law of large numbers of Sun (2006),
we have, almost surely, that on the event Y = 0, the fraction γi ({α : θα0 ≤ y}) of class-i
agents whose types are less than a given number y is
                                        Z
                                H
                               F (y) ≡     FαH (y) dγi(α),
                                            G

where FαH is the conditional CDF of the type θα0 of agent α given Y = 0. We similarly
define F L as the cross-sectional distribution of types on the event Y = 1. Now, by Fact
1, (F H , F L) is an amenable pair of CDFs. By assumption, these CDFs have densities de-
       H       L
noted ψi0 and ψi0 , respectively, for class i. The definition (31) of symmetric amenability
implies that
                             L         H          H
                            ψi0 (y) = ψi0 (−y) = ψi0 (y) e−y ,
as was to be demonstrated. That ψitH satisfies ψitH (−x) = e−x ψitH (x) = ψitL (x) for any
t > 0 now follows from the Wild sum solution (9) and from the fact that amenability
is preserved under convolutions (Fact 2) and mixtures (Fact 1). That the hazard-rate
ordering property is satisfied for any density satisfying (5) follows from the calculation
(suppressing subscripts for notational simplicity):
            R +∞ L             R +∞ H        (x−y)
                                                        R +∞ H
 GL (x)      x
                 ψ   (y) dy     x
                                    ψ   (y) e      dy    x
                                                             ψ (y) dy   GH (x)
         =                  =                         ≤               =         .
 ψ L (x)        ψ L (x)               ψ H (x)               ψ H (x)     ψ H (x)


Lemma A.1 For any amenable pair (F H , F L ) of CDFs, there exists some initial alloca-
tion of signals such that the initial cross-sectional type distribution is F H almost surely
on the event H = {Y = 0} and F L almost surely on the event L = {Y = 1}.

                                             32
Proof. Since                         Z                         Z
                                               L
                              1 =          dF (x) =                    e−x dF H (x),
                                       R                           R

it suffices to show that any CDF F H satisfying
                                  Z
                                     e−x dF H (x) = 1                                         (33)
                                           R

can be realized from some initial allocation of signals.
        Suppose that initially each agent is endowed with one signal Z, but X1 = P (Z =
1 | Y = 0) and X2 = P (Z = 1 | L) are distributed across the population according
                                                                                    H
to a joint probability distribution dν(x1 , x2 ) on (0, 1) × (0, 1) . We denote by Fdν the
corresponding type distribution conditioned on state H. The case when ν is supported
on one point corresponds to the case of identical signal characteristics across agents, in
which case F H = Fθ,Hθ̃ is given by (32). Furthermore, any distribution supported on two
points θ, θ̃ and satisfying (33) is given by (32). We will now show that any distribution
F H supported on a finite number of points can be realized. To this end, we will show
that any such distribution can be written down as a convex combination of distributions
of Fθ,Hθ̃ ,
                                                   X
                                         FH =               αi FθHi ,θ̃i .
                                                       i

In this case, picking
                                                   X
                                         dν =              αi δ(xi1 ,xi2 )
                                                   i

to be a convex combination of delta-functions with

                                     eθi − eθi +θ̃i                          1 − eθ̃
                            xi1 =                   ,              xi2 =              ,
                                      eθi − eθ̃i                             eθ − eθ̃
we get the required result.
        Fix a finite set S = {θ1 , . . . , θK } and consider the set L of probability distributions
with support S that satisfies (33). If we identify a distribution with the probabilities
p1 , . . . , pK assigned to the respective points in S, then L is isomorphic to the compact
subset of (p1 , . . . , pK ) ∈ RK
                                + , satisfying
                                X                          X
                                     pi = 1,                       e−θi pi = 1 .
                                 i                         i

Because this compact set is convex the Krein-Milman Theorem (see Krein and Milman
(1940)) implies that it coincides with the convex hull of its extreme points. Thus, it

                                                    33
suffices to show that the extreme points of this set coincide with the measures, supported
on two points. Indeed, pick a measure π = (p1 , . . . , pK ), supported on at least three
points. Without loss of generality, we may assume that p1 , p2 , p3 > 0. Then, pick an
ε > 0 such that
                                     e−θ1 − e−θ3             e−θ1 − e−θ2
                  p1 ± ε > 0 , p2 ± ε −θ3        > 0 , p3 ± ε −θ3        > 0.
                                     e − e−θ2                e − e−θ2
Then, clearly,
                                                        1 +
                                             π =          (π + π − )
                                                        2
with
                                         e−θ1 − e−θ3           e−θ1 − e−θ2
                                                                                              
              ±
          π       =       p1 ± ε , p2 ± ε −θ3        , p 3 ± ε             , p4 , . . . , pK       .
                                         e − e−θ2              e−θ3 − e−θ2
By direct calculation, π + and π − correspond to measures in L. Thus, all extreme points
of L coincide with measures, supported on two points and the claim follows.
       Now, clearly, for any measure F H satisfying (33) there exists a sequence FnH of
measures, supported on a finite number of points, converging weakly to F H . By the
just proved result, for each FiH there exists a measure dνi on (0, 1) × (0, 1), such that
FiH = Fdν
       H
          i
            . By the Helly Selection Theorem (Gut (2005), p. 232, Theorem 8.1), the set
of probability measures on (0, 1) × (0, 1) is weakly compact and therefore there exists
a subsequence of νi converging weakly to some measure ν. Clearly, F H = FνH and the
proof is complete.


B      ODE and Equilibrium

Proof of Lemma 3.7. By the assumptions made, the right-hand side of equation (16)
is Lipschitz-continuous, so local existence and uniqueness follow from standard results.
To prove the claim for finite V0 , it remains to show that the solution does not blow up
for z < v H . By Lemma 3.6,
                                              1                    1
                                                         ≥                    ,
                                         hH
                                          it (V2 (z))         hLit (V2 (z))

and therefore
                                                                                  
                                      1       z − vi        1               1
                      V20 (z)   =                                   + L
                                  vi − vj v H − z hH    it (V2 (z))   hit (V2 (z))
                                                      H
                                                                                                       (34)
                                        1           v − vi
                                ≤ H                                 .
                                  hit (V2 (z)) (vi − vj ) (v H − z)


                                                         34
That is,
                        d                             v H − vi
                           (− log GH (V2 (z))) ≤                      .
                        dz                       (vi − vj ) (v H − z)
Integrating this inequality, we get
                                             v H − vi    v H − vi
                                        
                              GH (V0 )
                       log                 ≤          log H       .
                             GH (V2 (z))     vi − vj     v −z
That is,
                                                                     vvH−v
                                                                         −vi
                                                         vH − z
                                                     
                                                                       i       j
                         GH (V2 (z)) ≥ GH (V0 )                                        ,
                                                         v H − vi
or equivalently,
                                                                      vvH−v
                                                                         −vi
                                                                                           
                                                            H
                                                     
                                                          v −z             i       j
                      V2 (V0 , z) ≤ G−1
                                     H
                                        GH (V0 )                                          .
                                                          v H − vi

Similarly, we get a lower bound
                                                                      vvH−v
                                                                         −vi
                                                                                       
                                                           H
                                                     
                                                         v −z              i       j
                      V2 (V0 , z) ≥ G−1
                                     L
                                        GL (V0 )                                      .       (35)
                                                         v H − vi

The fact that V2 is monotone increasing in V0 follows from a standard comparison theorem
for ODEs (for example, (Hartman (1982), Theorem 4.1, p. 26). Furthermore, as V0 →
−∞, the lower bound (35) for V2 converges to
                                              vvH−v
                                                  −vi
                                                       
                                    H
                                  v −z
                                                 i  j
                             G−1
                               L      H
                                                       .
                                     v − vi

Hence, V2 stays bounded from below and, consequently, converges to some function
V2 (−∞, z). Since V2 (V0 , z) solves the ODE (16) for each V0 and the right-hand side of
(16) is continuous, V2 (−∞, z) is also continuously differentiable and solves the same ODE
(16).

Proof of Proposition 3.8.          Suppose that (S, B) is a strictly increasing continuous
equilibrium and let V1 (z), V2 (z) be the corresponding (strictly increasing and continuous)
inverse functions defined on the intervals (a1 , A1 ) and (a2 , A2 ) respectively, where one or
both ends of the intervals may be infinite.
        The optimization problems for auction participants are
                               Z +∞
              max fS (s) ≡ max        (s − vj − ∆j P (θ + φ)) Ψi (P (θ), φ) dφ                  (36)
                 s            s    V2 (s)


                                                35
and                                    Z   V1 (b)                           
            max fB (b) ≡ max                        vi + ∆i P (θ + φ) − S(θ) Ψj (P (φ), θ) dθ.   (37)
             b                    b     −∞

First, we note that the assumption that A1 ≤ v H implies a positive trading volume.
Indeed, by strict monotonicity of S, there is a positive probability that the selling price
is below v H . Therefore, for buyers of sufficiently high type, it is optimal to participate
in trade.
      In equilibrium, it can never happen that the seller trades with buyers of all types.
Indeed, if that were the case, the seller’s utility would be
                       Z
                           (s − vj − ∆j P (θ + φ)) Ψi (P (θ), φ) dφ,
                              R

which is impossible because the seller can then attain a larger utility by increasing
s slightly. Thus, a1      ≥ a2 . Furthermore, given the assumption S ≤ v H , buyers of
sufficiently high types find it optimal to trade with sellers of arbitrarily high types. That
is, A2 = supθ B(θ) ≥ supθ S(θ) = A1 . Thus,

                                            A2 ≥ A1 > a1 ≥ a2 .

Let θl = V2 (a1 ), θh = V2 (A1 ). (Each of these numbers might be infinite if either
A2 = A1 or a2 = a1 .) By definition, V1 (a1 ) = −∞, V1 (A1 ) = +∞. Furthermore, fB (b) is
locally monotone increasing in b for all b such that

                              vi + ∆i P (V1(b) + φ) − S(V1 (b)) > 0.

Further, fB (b) is locally monotone decreasing in b if

                              vi + ∆i P (V1(b) + φ) − S(V1 (b)) < 0.

Hence, for any type φ ∈ (θl , θh ), B(φ) solves the equation

                              vi + ∆i P (V1 (B(φ)) + φ)) = B(φ).

Letting B(φ) = z ∈ (a1 , A1 ), we get that

                                      vi + ∆i P (V1(z) + V2 (z)) = z .                           (38)

Now, as φ ↑ θh , we have B(φ) ↑ A1 and therefore V1 (B(φ)) ↑ +∞. Thus,

                 A1 = lim B(φ) = lim (vi + ∆i P (V1 (B(φ)) + φ))) = v H ,
                       φ↑θh                    φ↑θh


                                                          36
and similarly, a1 = vi
        We now turn to the first-order condition of the seller. Because V2 is strictly in-
creasing and continuous, it is differentiable Lebesgue-almost everywhere by the Lebesgue
Theorem (see, for example, Theorem 7.2 of Knapp (2005), p. 359). Let X ⊂ (a2 , A2 ) be
the set on which V20 exists and is finite. Then, for all θ ∈ V1 (X) the first-order condition
holds for the seller. For a seller of type θ, because the offer price s affects the limit of the
integral defining the seller’s utility (10) as well as the integrand, there are two sources
of marginal utility associated with increasing the offer s: (i) losing the gains from trade
with the marginal buyers, who are of type B −1 (s)), and (ii) increasing the gain from
every infra-marginal buyer type φ. At an optimal offer S(θ), these marginal effects are
equal in magnitude. This leaves the seller’s first-order condition

 Gi (P (θ), V2(S(θ))) = V20 (S(θ)) S(θ) − vj − ∆j P (θ + V2 (S(θ))) Ψi (P (θ) , S(θ)), (39)
                                                                   


where                                        Z    +∞
                               Gi (p, x) =             Ψi (p, y) dy.
                                              x
Letting z = S(θ), we have θ = V1 (z) and hence
              Gi (P (V1(z)), V2 (z))
                                     = V20 (z) z − vj − ∆j P (V1 (z) + V2 (z)) .
                                                                              
                                                                                           (40)
              Ψi(P (V1 (z)), V2 (z))
Now, if V2 (z) were not absolutely continuous, it would have a singular component and
therefore, by the de la Valée Poussin Theorem (Saks (1937), p.127) there would be a
point z0 where V20 (z0 ) = +∞. Let θ = V1 (z0 ). Then, S(θ) cannot be optimal because
there will an inequality < in (39) and therefore there will always be an incentive to
deviate. Thus, V2 (z) is absolutely continuous and, since the right-hand side of (40) is
continuous and (40) holds almost everywhere in (a2 , A2 ), identity (40) actually holds for
all z ∈ (a2 , A2 ).
        Now, using the first order condition (38) for the buyer, we have
                                                       ∆j             vi − vj H
 z − vj − ∆j P (V1(z) + V2 (z)) = z − vj −                (z − vi ) = H      (v − z). (41)
                                                       ∆i             v − vi
Furthermore, (38) implies that

                        R eV1 (z)+V2 (z)      z − vi                          z − vi
P (V1 (z)+V2 (z)) =                        =          ⇔ V 1 (z)+V 2 (z) = log        − log R .
                      1 + R eV1 (z)+V2 (z)   v H − vi                         vH − z
That is,
                                         z − vi
                          V1 (z) = log          − V2 (z) − log R .
                                         vH − z

                                              37
Therefore,
                                             z−vi
                                    e−V2 (z) vH −z                  (z − vi )e−V2 (z)
              P (V1(z)) =                                 =                                .
                                1+     e−V2 (z) vz−v i
                                                  H −z        v H − z + e−V2 (z) (z − vi )

Using the fact that ΨLi (V2 (z)) = e−V2 (z) ΨH
                                             i (V2 (z)), we get


      Ψi (P (V1 (z)), V2 (z))   =      P (V1 (z)) ΨH                                     L
                                                    i (V2 (z)) + (1 − P (V1 (z))) Ψi (V2 (z))
                                              (z − vi ) e−V2 (z)
                                =                                        ΨH (V2 (z))
                                       v H − z + e−V2 (z) (z − vi ) i
                                                    (v H − z) e−V2 (z)
                                           + H                                  ΨH (V2 (z))
                                               v − z + e−V2 (z) (z − vi ) i
                                                 v H − vi
                                =        H           −V    (z)
                                                                         ΨLi (V2 (z)) .
                                       v −z + e          2     (z − vi )

Similarly,

     Gi (P (V1(z)), V2 (z)) = P (V1(z)) GH                              L
                                         i (V2 (z)) + (1 − P (V1 (z))) Gi (V2 (z))
                                    (z − vi )e−V2 (z) GH              H       L
                                                       i (V2 (z)) + (v − z) Gi (V2 (z))
                                                                                                (42)
                                =                                                       .
                                                 v H − z + e−V2 (z) (z − vi )

Consequently,

   Gi (P (V1 (z)), V2 (z))   P (V1 (z)) GH                                  L
                                         i (V2 (z)) + (1 − P (V1 (z))) Gi (V2 (z))
                           =
   Ψi(P (V1 (z)), V2 (z))    P (V1 (z)) ΨH                                  L
                                         i (V2 (z)) + (1 − P (V1 (z))) Ψi (V2 (z))
                             (z − vi )e−V2 (z) GH                  H       L
                                                 i (V2 (z)) + (v − z) Gi (V2 (z))
                           =
                                              (v H − vi ) ΨLi (V2 (z))
                                                                                          
                               H       −1                     1           H         1
                           = (v − vi )        (z − vi ) H             + (v − z) L            .
                                                        hi (V2 (z))            hi (V2 (z))

Thus, by (41), the ODE (40) takes the form

                              Gi (P (V1 (z)), V2 (z))
 V20 (z) =                                                               
           Ψi (P (V1(z)), V2 (z)) z − vj − ∆j P (V1(z) + V2 (z))
                                                                           
             H       −1                    1              H           1                 1
         = (v − vi )       (z − vi ) H             + (v − z) L                  vi − vj
                                     hi (V2 (z))                 hi (V2 (z)) vH −v (v H − z)
                                                                                      i
                                                             
              1       z − vi        1                 1
         =                                   + L                , z ∈ (a1 , A1 ) = (vi , v H ).
           vi − vj    v H − z hH i (V 2 (z))   h  i (V 2 (z))

Consequently, V2 (z) solves (16). By Lemma 3.7, V2 (v H ) = +∞. Thus A2 = v H and the
proof is complete.


                                                     38
Proof of Corollary 3.9.            By Proposition 3.8, V2 (V0 , z) is monotone increasing in V0 .
Consequently, B = V2−1 is monotone decreasing in V0 . Similarly,
                                              z − vi
                         V1 (V0 , z) = log           − V2 (V0 , z) − log R
                                              vH − z
is monotone decreasing in V0 and therefore S = V1−1 is monotone increasing in V0 .
       In order to prove Proposition 3.11, we will need the following auxiliary result

Lemma B.1 Suppose that B, S : R → (vi , v H ) are strictly increasing and that their
inverses V1 and V2 satisfy

                                 vi + ∆i P (V1 (z) + V2 (z)) = z.

Suppose further that V20 (z) solves (16) for all z ∈ (vi , v H ). Then (B , S) is an equilibrium.


Proof. Recall that the seller maximizes
                          Z +∞
                fS (s) =        (s − vj − ∆j P (θ + φ)) Ψi (P (θ), φ) dφ.                      (43)
                                  V2 (s)

To show that S(θ) is indeed optimal, it suffices to show that fS0 (s) ≥ 0 for s ≤ S(θ)
and that fS0 (s) ≤ 0 for s ≥ S(θ) . We prove only the first inequality. A proof of the
second is analogous. So, let s ≤ S(θ) ⇔ V1 (s) ≤ θ. Then,

 fS0 (s) = V20 (s) (−s + vj + ∆j P (θ + V2 (s))) Ψi (P (θ), V2 (s)) + Gi (P (θ), V2(s))
                                                                                           
             0                                                                1
         = V2 (s)Ψi (P (θ), V2 (s)) −s + vj + ∆j P (θ + V2 (s)) + 0                           .
                                                                   V2 (s)hi (P (θ), V2 (s))
By Lemma 3.6,
                                                     1
                                              hi (p, V2(s))
is monotone increasing in p. Therefore, by (40),
            1                                  1
                             ≥                                    = s − vj − ∆j P (V1(s) + V2 (s)).
 V20 (s) hi (P (θ), V2(s))       V20 (s) hi (P (V1(S)), V2 (s))
Hence,

 fS0 (s)   ≥    V20 (s) Ψi(P (θ), V2(s))
                  × (−s + vj + ∆j P (θ + V2 (s)) + s − vj − ∆j P (V1 (s) + V2 (s))) ≥ 0,

because θ ≥ V1 (s) .

                                                    39
      For the buyer, it suffices to show that
                            Z V1 (b)
                                                             
            fB (b) = max             vi + ∆i P (θ + φ) − S(θ) Ψj (P (φ), θ) dθ                (44)
                          b     −∞

satisfies fB0 (b) ≥ 0 for b ≤ B(φ) and fB0 (b) ≤ 0 for b ≥ B(φ) . That is,

         vi + ∆i P (φ + V1 (b)) − S(V1 (b)) = vi + ∆i P (φ + V1 (b)) − b ≥ 0

for b ≤ B(φ), and the reverse inequality for b ≥ B(φ). For b ≤ B(φ), we have φ ≥ V2 (b)
and therefore

             vi + ∆i P (φ + V1 (b)) − b ≥ vi + ∆i P (V2(b) + V1 (b)) − b = 0,

as claimed. The case of b ≥ B(φ) is analogous.


C    Exponential Tails

Lemma C.1 The Laplace transform ψ̂itH (k) is monotone increasing in k for each i and
all t ≥ 0.

Proof. Using the identity ψitH (−x) = e−x ψitH (x), we get
                                           Z 0                     Z +∞
   d H
                  Z
                         kx H                        kx H
    ψ̂ (k) =          x e ψit (x) dx =            x e ψit (x) dx +      x ekx ψitH (x) dx
  dk it             R                         −∞                    0
                  Z +∞
             =           x (1 − e−x ) ekx ψitH (x) dx > 0.
                      0



      Lemma 3.10 is a direct consequences of the following result, which also gives the
exponential tail property for ψitH .

Proposition C.2 (Exponential tails) Let k = α(t) be the unique solution to
                                   H                                     H
                      φ̂H       −φ̂10 (k) (1−e   −λt )
                                                         = φ̂H       −φ̂20 (k) (1−e   −λt )
                        10 (k) e                             20 (k) e


satisfying mini∈{1,2} φH
                       i0 (α(t)) ≤ (1 − e
                                         −λt −1
                                            ) . Then, for all t in (0, T ],

                              ψitH ∼     Exp+∞ (ci (t) , 0 , −α(t))
                                                                                              (45)
                           d H
                            ψ ∼          Exp+∞ (−α(t) ci (t), 0, −α(t)),
                          dx it

                                                         40
with10

                                        e−λt ψ̂i0
                                               H
                                                  (α(t)) (φ̂H      H
                                                            10 − φ̂20 )(α(t))
       ci (t) =                                                              H           .
                   φ̂H  (α(t))  d
                                   (1 − e−λt )(φ̂H (k) − φ̂H (k)) − log φ̂10 (k) |
                     10        dk                 10         20               φ̂H   k = α(t)
                                                                                            20


Furthermore, these exponential tails are uniform in t if (45) holds for t = 0.


Proof. Since the functions φ̂10 (k) and φ̂20 (k) are analytic in k in the stripe
                                                                         
             H := <k ∈ −             min       αi0 − 1,       min      αi0 ,
                                         i ∈ { 1, ..., n+m}                i ∈ {1, ..., n+m}


it follows directly from their definitions that the functions φ̂1t (k) and φ̂2t (k) are mero-
morphic in k for k ∈ H.
         Let

                  T = {t > 0 : ∃k > 0 : φ̂10 (k) = φ̂20 (k) = (1 − e−λt )−1 } .

By analyticity, T is at most countable. For any t ∈ T , define

                      α(t) = min{k : φ̂10 (k) = φ̂20 (k) = (1 − e−λt )−1 }

and
                               dm 
                                                                                                     
           n(t) = max l ≥ 0 :      φ̂ 10 (k) − φ̂ 20 (k)   |k=α(t) = 0,                          m≤l       .
                              dk m

For any t 6∈ T , let α(t) be the unique solution to

                         φ̂10 (k) e−φ̂10 (k) (1−e
                                                    −λt )
                                                            = φ̂20 (k) e−φ̂20 (k) (1−e
                                                                                         −λt )




and let
               n
   n(t) = max l ≥ 0 :
           dm              −φ̂10 (k)(1−e−λt )             −φ̂20 (k)(1−e−λt )
                                                                                                     o
                 φ̂ 10 (k) e                   − φ̂ 20 (k)e                     | k = α(t) = 0, m ≤ l  .
          dk m
  10
     For the case in which φ̂Hi0 (α(t)) = (1−e
                                               −λt −1
                                                  ) for i = 1, 2, both the numerator and the denominator
of ci (t) are zero, so the stated formula must be understood as a limit as k ↑ α(t). In this case,
                                                         H
                                                  e−λt ψ̂i0 (α(t))
                           ci (t) =                                             .
                                                1 d
                                      (1 − e ) 2 dk φ̂20 (k) + φ̂H
                                            −λt        H
                                                                  10 (k)  |k=α(t)




                                                            41
By Lemma C.1, φ̂i0 (k) is monotone increasing in k. Thus, either φ̂10 (k) and φ̂20 (k) hit
the level (1 − e−λt )−1 together, in which case we are in the set T , or one of them crosses
this level earlier than the other. The function x 7→ xe−x(1−e
                                                                                  −λt )
                                                                                          is monotone increasing
for x < (1 − e−λt )−1 , and monotone decreasing for x > (1 − e−λt )−1 . Hence, when k
reaches the level α(t),
        d            −φ̂10 (k) (1−e−λt )
                                                        d            −φ̂20 (k) (1−e−λt )
                                                                                           
            φ̂10 (k) e                      |k=α(t) and      φ̂20 (k) e                      |k=α(t)
       dk                                               dk
have opposite signs, implying that n(t) = 0.
        First, consider some t ∈ T . By assumption,
                                                      1       dn(t)+1                        
            φ̂20 (α(t)) − φ̂10 (α(t)) ≈                                 φ̂ 20 (k) − φ̂ 10 (k)   |k=α(t) .
                                                 (n(t) + 1)! dk n(t)+1
Similarly, a direct calculation shows that, for any smooth function f such that

                              f 0 ((1 − e−λt )−1 ) = 0,       f 00 ((1 − e−λt )−1 ) 6= 0,

we have
                                                      1
           f (φ̂20 (k)) − f (φ̂10 (k)) ≈                     (k − α(t))n(t)+2 f 00 ((1 − e−λt )−1 )ξk ,
                                                 (n(t) + 1)!
where
                      dn(t)+1                                 1 d                        
             ξk =              φ̂ 20 (k) − φ̂ 10 (k)   | k=α(t)       φ̂ 20 (k) + φ̂ 10 (k)   |k=α(t) .
                     dk n(t)+1                                  2 dk
In our case,

               f (x) = x e−x(1−e
                                        −λt )
                                                ⇒ f 00 ((1 − e−λt )−1 ) = −(1 − e−λt )−1 e−1 .

Thus, the leading term of the asymptotic behavior at k = α(t) is given by

                                                    e−λt ψ̂i0 (α(t))                   1
                    ψ̂it    ∼                                                              .
                           k↑α(t)
                                    (1 − e−λt ) 21 dk
                                                    d
                                                        φ̂20 (k) + φ̂10 (k) |k=α(t) α(t) − k

Similarly, for t 6∈ T ,

                                  e−λt ψ̂i0 (α(t)) (ψ̂20 − ψ̂10 )(α(t)) e−φ̂10 (α(t)) (1−e )
                                                                                             −λt

    ψ̂it     ∼                                                                                             .
           k↑α(t)    d
                        φ̂ H
                              (k) e−φ̂H
                                      10 (k) (1−e
                                                  −λt )
                                                        − φ̂    (k) e−φ̂20 (k) (1−e−λt ) |        (α(t) − k)
                    dk     10                                20                            k=α(t)


By Theorem 3.4, we can write
                                                  X                         ∗kN
                                                                 ∗k1
                                        ψit =           ait (k) ψ10  · · · ψN 0
                                                    k


                                                           42
and ait (k) = 0 if k1 = 0. Thus,
                                                  ψit = ψi0 ∗ ζ,

with
                                       def                    ∗(k1 −1)
                                             X                                         ∗kN
                                    ζ =            ait (k) ψ10                  · · · ψN 0 .
                                              k

Then,
                                                                 ψ̂it
                                                    ζ̂ =                .
                                                              ψ̂i0
By Theorem 3.4, ζ is the density of a probability measure. A Tauberian Theorem
(Proposition 1 in Aramaki (1983))11 implies that, for any ε > 0,
                                      Z y
                                  def
                           X(y) =          eε+α(t) x ζ(x) dx
                                                        −∞

satisfies the asymptotic
                                             X(y) ∼ c̃i (t) ε−1 eεy ,

where
                                                                 ci (t)
                                              c̃i (t) =                          .
                                                             ψ̂i0 (α(t))
Thus,12
                  Z                                 Z
   ψit (x) =        ψi0 (x − y) ζ(y) dy =         ψi0 (x − y) e−(α(t)+ε) y dX(y)
                ZR                            R
                                                                                 
                     −(α(t)+ε)y           d
              =     e           X(y)        ψi0 (x − y) + (α(t) + ε)ψi0 (x − y) dy          (46)
                  R                      dx
                                                                                      
                                                          d
                            Z
                 −(α(t)+ε)x      (α(t)+ε)y
              = e               e          X(x − y)         ψi0 (y) + (α(t) + ε)ψi0 (y) dy.
                              R                          dy

Therefore, by the Lebesgue dominated convergence theorem,
                                                                          
             ψit (x)                          d
                        Z
                            α(t)y −1
       lim           =     e     ε c̃i (t)      ψi0 (y) + (α(t) + ε)ψi0 (y) dy .                                       (47)
      x→+∞ e−α(t)x       R                   dy

But
                                                                          Z                           
                           d                                                          d α(t)y
        Z
              α(t)y
              e              ψi0 (y) + α(t)ψi0 (y)          dy =                        (e    ψi0 (y))       dy = 0,
          R               dy                                                R        dy
  11
     In fact, we could have directly used Ikehara’s Tauberian Theorem (see, for example, Theorem 4.2 of
Korevaar (2004), p.124). However, we appeal to the higher order version of Ikehara’s Theorem to show
that our result does not depend on the fact that n(t) = 0.
  12
     We note that αi (0) > αi (t), and therefore the boundary terms arising from integration by parts
vanish for sufficiently small ε.

                                                            43
and therefore
                           ψit (x)
                                                   Z
                       lim −α(t)x = c̃i (t)                eα(t)y ψi0 (y) dy = ci (t) .
                      x→+∞ e                           R
The asymptotic behavior of
                              d                     d
                                             Z
                                ψit (x) =             ψi0 (x − y) ζ(y) dy
                             dx                R   dx
is proved analogously. The fact that the tails are uniform follows from a standard proof
of the Tauberian Theorem (see the proof of Proposition 1 of Aramaki (1983)).13



Corollary C.3 Let α∗ be as in Proposition 3.11. Suppose that
                                                                                !
                            1                max{φ̂H            H
                                                   10 (α∗ ) , φ̂20 (α∗ )}
                        T <   log                                                      .
                            λ            1 − max{φ̂H            H
                                                   10 (α∗ ) , φ̂20 (α∗ )}

Then, there exists an A > 0 such that, for any
                                           vi − vj
                                                    > A,
                                           v H − vi
there exists a unique continuous equilibrium. By contrast, if
                                                                               !
                              1               min{φ̂H          H
                                                    10 (1) , φ̂20 (1)}
                          T >   log                                                ,
                              λ             1 − min{φ̂H          H
                                                      10 (1) , φ̂20 (1)}

then there exist no continuous equilibria.


D      Proof of Proposition 3.11

Proof of Proposition 3.11.            It follows from Proposition 3.8 and Lemma B.1 that a
strictly monotone equilibrium in undominated strategies exists if and only if there exists
a solution V2 (z) to (16) such that V2 (vi ) = −∞ and
                                            z − vi
                            V1 (z) = log           − V2 (z) − log R
                                            vH − z
is monotone increasing in z and satisfies V1 (vi ) = −∞ , V1 (v H ) = +∞. Furthermore,
such an equilibrium is unique if the solution to the ODE (16) with V2 (vi ) = −∞ is
unique.
  13
    In fact, Subhankulov (1976) (Theorem 5.1.2, p. 196) establishes strong bounds on the tails that can
be used to determine the exact speed of convergence to exponential tails.


                                                   44
      Fix a t ≤ T and denote for brevity α = αit , γ = γit , c = cit . Let also

                                            g(z) = e(α+1) V2 (z) .

Then, a direct calculation shows that V2 (z) solves (16) with V2 (vi ) = −∞ if and only
if g(z) solves

    g 0(z)
                                                                                           (48)
                                                                                    
            α+1             z − vi            1                         1
    = g(z)                                                  + L                        ,
           vi − vj          v H − z hH
                                     i ((α + 1)
                                               −1 log g(z))  hi ((α + 1)−1 log g(z))

with g(vi) = 0. By assumption and Lemma 3.6,

                     hH               γ (α+1)V
                      i (V ) ∼ ci |V | e               and hLi (V ) ∼ ci |V |γ eαV         (49)

as V → −∞ because GH,L
                   i   (V ) → 1. Hence, the right-hand side of (48) is continuous and
the existence of a solution follows from the Euler theorem. Therefore, when studying
the asymptotic behavior of g(z) as z ↓ vi , we can replace hH      L
                                                            i and hi by their respective
asymptotics (49).
      Indeed, let us consider

                                               1       z − vi           1
                 g̃ 0 (z) = (α + 1) g̃(z)
                                            vi − vj    v − z c ((α + 1) log 1/g̃)γ g̃
                                                        H              −1
                                                                 !                         (50)
                                           1
                             +                                 ,
                               c((α + 1) log 1/g̃)γ g̃ α/(α+1)
                                        −1



with the initial condition g̃(vi ) = 0. We consider only values of z sufficiently close to
vi , so that log g̃(z) < 0.
      It follows from standard ODE comparison arguments and the results below that
for any ε > 0 there exists a z̄ > vi such that

                                   g(z)       g 0 (z)
                                         −1 + 0       −1 ≤ ε                               (51)
                                   g̃(z)      g̃ (z)

for all z ∈ (vi , z̄) . The assumptions of the Proposition guarantee that the same asymp-
totics hold for the derivatives of the hazard rates, which implies that the estimates
obtained in this manner are uniform.
      First, we will consider the case of general (not necessarily large) vi − vj and show
that, when α < 1, g(z) decays so fast as z ↓ vi that V1 (z) cannot remain monotone
increasing.

                                                      45
      At points in the proof, we will define suitable positive constants denoted C1 , C2 ,
C3 , . . . without further mention.
      Denote
                                                (α + 1)γ+1
                                        ζ =                  .                         (52)
                                                c (vi − vj )
Then, we can rewrite (50) in the form
                                                                           
                          0           ζ                 z − vi      1/(α+1)
                        g̃ (z) =                               + g̃           .        (53)
                                 (log 1/g̃)γ            vH − z
From this point, throughout the proof, without loss of generality, we assume that vi = 0.
Furthermore, after rescaling if necessary, we may assume that v H − vi = 1. Then, the
same asymptotic considerations as above imply that, when studying the behavior of g̃
as z ↓ vi , we may replace v H − z ≈ v H − vi in (50) by 1.
      Let A(z) be the solution to
                              Z A(z)
                        z =          ζ −1 (− log x)γ x−1/(α+1) dx .
                                   0

A direct calculation shows that
                  Z z
              def                                         α+1
       B(z) =         ζ −1 (− log x)γ x−1/(α+1) dx ∼ ζ −1     (− log z)γ z α/(α+1) .
                   0                                       α
Conjecturing the asymptotics

                              A(z) ∼ K (− log z)γ(α+1)/α z (α+1)/α                     (54)

and substituting these into B(A(z)) = z, we get
                                                            (γ+1)(α+1)
                                          α+1        α            α
                                K = ζ      α                               .
                                                    α+1
Standard considerations imply that this is indeed the asymptotic behavior of A(z). It is
then easy to see that
                                          α+1
                          A0 (z) ∼ K          (− log z)γ(α+1)/α z 1/α .                (55)
                                           α
By (53),
                                               ζ
                                 g̃ 0 (z) ≥           g̃ 1/(α+1) .
                                          (log 1/g̃)γ
Integrating this inequality, we get g̃(z) ≥ A(z). Now, the factor (log 1/g̃)γ is asymptot-
ically negligible as z ↓ vi . Namely, for any ε > 0 there exists a C1 > 0 such that
                                            ζ
                  C1 g̃ 1/(α+ε+1) ≥                g̃ 1/(α+1) ≥ C1−1 g̃ 1/(α−ε+1) .
                                       (log 1/g̃)γ

                                                    46
Thus,                                                       0
                                                      α−ε
                                              (g̃)   1+α−ε        ≥ C2 .

Integrating this inequality, we get that
                                                                     α−ε+1
                                       g̃(z) ≥ C3 (z − vi )           α−ε        .              (56)

Let
                                         l(z) = B(g̃(z)) − z .

Then, for small z, by (54),

         l0 (z) = g̃ 0(z) ζ −1 (− log g̃)γ g̃ −1/(α+1) − 1
                                                          
                         ζ            z            1/(α+1)
                =              γ    H
                                              + g̃           ζ −1 (− log g̃)γ g̃ −1/(α+1) − 1
                  (log 1/g̃)       v −z
                       z        1
                =                                                                               (57)
                  1 − z g̃ 1/(α+1)
                       z              1
                =
                  1 − z (A(l(z) + z))1/(α+1)
                       z            1
                ≤                               ,
                  1 − z (A(l(z)))1/(α+1)

where we have used the fact that l(z) ≥ 0 because h(0) = 0 and l0 (z) ≥ 0. Integrating
this inequality, we get that, for small z,

                                       l(z) ≤ C4 z 2(α−ε)/(α−ε+1) .

Hence, for small z,

            g̃(z) = A(l(z) + z) ≤ A((C4 + 1)z 2(α−ε)/(α−ε+1) ) ≤ C5 z 2−ε .                     (58)

Let C(z) solve
                                C(z)                                        z
                                                                                 x
                           Z                                        Z
                                                     γ
                                       (− log x) dx = ζ                             dx .
                            0                                           0       1−x
A calculation similar to that for the function A(z) implies that

                                       C(z) ∼ C6 (− log z)γ z 2                                 (59)

as z → 0. Integrating the inequality
                                                             ζ       z
                                       g̃ 0(z) ≥                  γ
                                                                         ,
                                                         (− log g) 1 − z

                                                           47
we get that
                                            g̃(z) ≥ C(z).
Let now α < 1. Then, (58) immediately yields that the second term in the brackets in
(50) is asymptotically negligible and, consequently,

                            ζ       z                  (1 + ε) ζ   z
                                 γ
                                         ≤ g̃ 0 (z) ≤           γ
                                                                                                   (60)
                       (log 1/g̃) 1 − z               (log 1/g̃) 1 − z
holds for sufficiently small z. Integrating this inequality implies that

                                 C(z) ≤ g̃(z) ≤ (1 + ε) C(z).

Now, (60) implies that

                       (1 − ε) 2 C(z)z −1 ≤ g̃ 0(z) ≤ 2 (1 + ε) C(z) z −1

for sufficiently small z.14
       Using the asymptotics (49) and repeating the same argument implies that g(z)
also satisfies these bounds. (The calculations for g are lengthier and omitted here.)
       Now,
                                        g 0 (z)              2
                         V20 (z) =                ≥ (1 − ε)     z −1 .
                                     (α + 1) g(z)           α+1
Therefore,
                                            1
                                V10 (z) =         − V20 (z) < 0
                                        z (1 − z)
for sufficiently small z. Thus, V1 (z) cannot be monotone increasing and the equilibrium
does not exist.
       Let now α > 1. We will now show that there exists a unique solution to (48) with
g(0) = 0. Since the right-hand side loses Lipschitz continuity only at z = 0, it suffices to
prove local uniqueness at z = 0. Hence, we need only consider the equation in a small
neighborhood of z = 0. (It is recalled that we assume vi = 0.)
       As above, we prove the result directly for the ODE (50), and then explain how the
argument extends directly to (48).
       Suppose, to the contrary, that there exist two solutions g̃1 and g̃2 to (50). Define
the corresponding functions l1 and l2 via li = B(g̃i ) − z. Both functions solve (57).
Integrating over a small interval [0, l], we get
                     Z x
                            z                1                       1
 |l1 (x) − l2 (x)| ≤                             1/(α+1)
                                                         −                        dz . (61)
                      0 1 − z (A(l1 (z) + z))              (A(l2 (z) + z))1/(α+1)
  14
    We are using the same ε in all of these formulae. This can be achieved by shrinking if necessary the
range of z under consideration.

                                                  48
Now, we will use the following elementary inequality: There exists a constant C6 > 0
such that
                                                  C6 (a − b)
                            a1/α − b1/α ≤      (α−1)/α
                                                                                          (62)
                                              a        + b(α−1)/α
for a > b > 0. Indeed, let x = b/a and β = 1/α. Then, we need to show that

                            (1 + x1−β ) (1 − xβ ) ≤ C6 (1 − x)

for x ∈ (0, 1) . That is, we must show that

                              x1−β − xβ ≤ (C6 − 1) (1 − x).

By continuity and compactness, it suffices to show that the limit
                                             x1−β − xβ
                                       lim
                                       x→1     1−x
is finite. This follows from L’Hôpital’s rule.
      By (54) and (55), we can replace the function A(z) in (61) by its asymptotics (54)
at the cost of getting a finite constant in front of the integral. Thus, for small z,

   |l1 (x) − l2 (x)|
           Z x
                   ((− log(l1 + z))γ (l1 + z))1/α − ((− log(l2 + z))γ (l2 + z))1/α        (63)
    ≤ C7        z                                                                  dz .
            0        ((− log(l1 + z))γ (l1 + z))1/α ((− log(l2 + z))γ (l2 + z))1/α
By (62),

     |((− log(l1 + z))γ (l1 + z))1/α − ((− log(l2 + z))γ (l2 + z))1/α |
                    |(− log(l1 + z))γ (l1 + z) − (− log(l2 + z))γ (l2 + z)|               (64)
      ≤ C6                                                                           .
             ((− log(l1 + z))γ (l1 + z))(α−1)/α + ((− log(l2 + z))γ (l2 + z))(α−1)/α
Now, consider some γ > 0. Then, for any sufficiently small a > b > 0, a direct calculation
shows that

       0 < (log(1/a))γ a − (log(1/b))γ b ≤ ((log(1/a))γ + (log(1/b))γ ) (a − b).

If, instead, γ ≤ 0, then the function a 7→ (log(1/a))γ a is continuously differentiable at
a = 0, and hence

                    0 < (log(1/a))γ a − (log(1/b))γ b ≤ C8 (a − b) .

Since α > 1, the same calculation as that preceding (60) implies that

               A(z) ≤ g̃i (z) = A(z + li (z)) ≤ (1 + ε) A(z) , i = 1 , 2

                                              49
for sufficiently small z.
      Thus,

                ((− log(l1 + z))γ (l1 + z))1/α − ((− log(l2 + z))γ (l2 + z))1/α
                  ((− log(l1 + z))γ (l1 + z))1/α ((− log(l2 + z))γ (l2 + z))1/α
                                                 1
                    ≤ C9 |l1 (z) − l2 (z)| ((α+1)/α)−ε                                                                     (65)
                                           z          !
                                                               1
                    ≤ C9       sup |l1 (z) − l2 (z)|       ((α+1)/α)−ε
                             z ∈ [ 0, ε̄ ]               z

for z ∈ [0, ε̄]. Thus, (63) implies that
                                                                                !Z
                                                                                              x
                                                                                                           1
          |l1 (x) − l2 (x)| ≤ C10            sup |l1 (z) − l2 (z)|                                z                   dz
                                            z ∈ [0,ε̄]                                    0           z ((α+1)/α)+ε
                                                                                                                           (66)
                                             α−1
                                                 −ε
                              = C11 (ε̄)      α           sup |l1 (z) − l2 (z)|
                                                         z ∈ [0,ε̄]

for all l ≤ ε̄. Taking the supremum over l ∈ [0, ε̄], we get
                                                                  α−1
                                                                      −ε
                 sup |l1 (z) − l2 (z)| ≤ C11 (ε̄)                  α        sup |l1 (z) − l2 (z)| .
                z ∈ [0,ε̄]                                                 z∈[0,ε̄]

                                       α−1
                                           −ε
Picking ε̄ so small that C11 (ε̄)       α       < 1 immediately yields that l1 = l2 on [0, ε̄] and
hence, since the right-hand side of (50) is Lipschitz continuous for z l 6= 0, we have l1 = l2
for all z by a standard uniqueness result for ODEs.
      The fact that the same result holds for the original equation (48) follows by the
same arguments as above.
      It remains to prove the last claim, namely the existence of equilibrium for suffi-
ciently large vi − vj . By Proposition 3.8, it suffices to show that
                                                    1
                              V10 (z) =                   − V20 (z) > 0                                                    (67)
                                                z (1 − z)
for all z ∈ (0, 1) provided that vi − vj is sufficiently large.
      It follows from the proof of Lemma 3.6 that
                                 1                               1     
                    −1                                −1
                  GL (1 − z)  (vi −vj )
                                          ≤ V2 (z) ≤ GH (1 − z) (vi −vj )
                                                                            .

Thus, as vi − vj ↑ +∞, V2 (z) converges to −∞ uniformly on compact subsets of [0, 1).
By assumption,
                               1              1                                1                       1
                        lim             =       ,                 lim                         =           .
                     V →+∞ hH
                            i (V   )          α                 V →+∞ hL
                                                                       i (V           )               α+1

                                                           50
Thus, as z ↑ 1,
                                              1         1         1
                           V20 (z) ∼                        <          .
                                         α (vi − vj ) 1 − z   z(1 − z)
Fixing a sufficiently small ε > 0, we will show below that there exists a threshold W
such that (67) holds for all vi − vj > W and all z such that V2 (z) ≤ −ε−1 . Since,
by the assumptions made, 1/hH             L
                            i (V ) and 1/hi (V ) are uniformly bounded from above for
V ≥ −ε−1 , it will immediately follow from (16) that (67) holds for all z with V2 (z) ≥ −ε−1
as soon as vi − vj is sufficiently large.
      Thus, it remains to prove (67) when V2 (z) ≤ −ε−1 . We pick an ε so small that we
can replace the ODE (48) by (50) when proving (67). That is, once we prove the claim
for the “approximate” solution g̃(z), the actual claim will follow from (51).
      Let
                                                ζ             def
                               g̃(z) =                γ
                                                        f (z) = δ f (z).
                                            (− log ζ)
Then, (48) is equivalent to the ODE
                                           γ                               
         0                  log(1/ζ)              z     1/(α+1)       1/(1+α)
        f (z) =                                      +δ         f (z)           .          (68)
                    log(1/ζ) + log(1/f (z))      1−z
As vi − vj → +∞, we get that ζ, δ → 0. Let
                             Z z
                         def       x
                  f0 (z) =              dx = − log(1 − z) − z .
                              0 1−x

Using bounds analogous to that preceding (60), it is easy to see that

                     lim       f (z) = f0 (z) ,             lim       f 0 (z) = f00 (z),
                  vi −vj →+∞                             vi −vj →+∞


and that the convergence is uniform on compact subsets of (0, 1). Fixing a small ε1 > 0,
we have, for z > ε1 ,
                                                            g̃ 0(z)
                    lim       V20 (z)   =       lim
                  vi −vj →∞                   vi −vj →∞ (α + 1)g̃(z)

                                                            f 0 (z)
                                        =         lim
                                              vi −vj →∞ (α + 1)f (z)

                                                    f00 (z)
                                        =
                                              (α + 1)f0 (z)
                                                                  z
                                        =                                        .
                                              (α + 1) (1 − z) (− log(1 − z) − z)
We then have
                               d2                       1
                                  2
                                    (− log(1 − z)) =          ≥ 1.
                               dz                    (1 − z)2

                                                    51
Therefore, by Taylor’s formula,
                                                                      1 2
                                     − log(1 − z) − z ≥                 z .
                                                                      2
Hence,
                                     z                     2       1
                                                       ≤                .
                    (α + 1) (1 − z) (− log(1 − z) − z)   α + 1 z(1 − z)
Therefore (67) holds for large vi − vj because α > 1. This argument does not work as
z → 0 because f (0) = f0 (0) = 0. So, we need to find a way to get uniform upper bounds
for f 0 (z)/f (z) when z is small. By the comparison argument used above, and picking ε1
sufficiently small, since our goal is to prove inequality (67), we can replace 1 − z by 1 in
(68).
        In this part of the proof, it will be more convenient to deal with g̃ instead of f. By
the above, we may replace g̃ by the function g1 solving
                                            ζ        
                                                           1/(1+α)
                                                                   
                           g10 (z)   =                z + g1         .
                                       (− log(g1 ))γ
Let                                                    z           γ
                                                                    1
                                                  Z
                                 d(z) =                        log       dx ,
                                                   0                x
             −1
D(z) = d (z), and k(z) = D(g1 (z)). Then, we can rewrite the ODE for g1 as

                     k 0 (z) = ζ z + (D(k(z)))1/(α+1)
                                                                      
                                                                          ,         k(0) = 0.

Define L(z) via
                                 Z       L(z)
                                                (D(x))−1/(α+1) dx = z,
                                     0
and let
                                                                 1 2
                             φ(z) = L(ζ z) +                       ζ z ≥ L(ζz).
                                                                 2
Then, by the monotonicity of D(z),

φ0 (z) = ζ L0 (ζz) + ζ z = ζ z + (D(L(ζz)))1/(α+1)                                ≤ ζ (z + (D(φ(ζz)))1/(α+1) ),
                                                                              


By a comparison theorem for ODEs (for example, Hartman (1982), Theorem 4.1, p.
26),15 we have
                     k(z) ≥ φ(z) ⇔ g1 (z) = D(k(z)) ≥ D(φ(z)) .                                            (69)
  15
    Even though the right-hand side of the ODE in question is not Lipschitz continuous, the proof of
this comparison theorem easily extends to our case because of the uniqueness of the solution, due to
(66).

                                                           52
Therefore, since the functions x(− log x)γ and xα/(α+1) (− log x)γ are monotone increasing
for small x, we have
                           g 0 (z)
  (1 + α) V20 (z) =
                           g(z)
                                  g10 (z)
                   ≤ (1 + ε)
                             (α + 1) g1(z)
                                                                                           (70)
                       (1 + ε)ζ z            (1 + ε)ζ
                   =                γ
                                       + α/(α+1)
                     g1 (− log g1 )       g1     (− log g1 )γ
                                  (1 + ε)ζ z                      (1 + ε)ζ
                   ≤                              γ
                                                    +         α/(α+1)
                                                                                       .
                           D(φ(z)) (− log D(φ(z)))    D(φ(z))         (− log D(φ(z)))γ
Thus, it suffices to show that

              ζ z2                            ζz
                           γ
                             +         α/(α+1)
                                                                < (1 − ε)(1 + α)
    D(φ(z)) (− log D(φ(z)))    D(φ(z))         (− log D(φ(z)))γ
for some ε > 0, and for all sufficiently small z and ζ. Now, a direct calculation similar
to that for the functions A(z) and C(z) implies that

                                         d(z) ∼ z (− log z)γ

and therefore that
                                        D(z) ∼ z (− log z)−γ .

Thus, it suffices to show that

                                ζ z2
            φ(z) (− log φ)−γ (− log(φ(z) (− log φ)−γ ))γ
                                                  ζz                                       (71)
                      +                 −γ α/(α+1)
                         (φ(z) (− log φ) )         (− log(φ(z) (− log φ)−γ ))γ
                  < (1 − ε)(1 + α).

Leaving the leading asymptotic term, we need to show that

               ζ z2                   ζz
                    +                                    < (1 − ε)(1 + α) .
               φ(z)   (φ(z))α/(α+1) (− log(φ(z)))γ/(α+1)
We have                z
                                                    α + 1 α/(α+1)
                  Z
                           (D(x))−1/(α+1) dx ∼           z        (− log z)γ/(α+1) .
                   0                                  α
Therefore                                          (α+1)/α
                                             α
                               L(z) ∼           z              (− log z)−γ/α .
                                            α+1

                                                     53
Hence, we can replace φ(z) by
                                 (α+1)/α
                     def     α                              1
               φ̃(z) =         ζz          (− log(ζz))−γ/α + ζ z 2 .
                           α+1                              2
Let
                                                             ζ z2
                                    x =                                            .
                                                (ζz)(α+1)/α (− log(ζz))−γ/α
Then,
 ζ z2                                ζz
           +
 φ̃(z)          (φ̃(z))α/(α+1)     (− log(φ̃(z)))γ/(α+1)
                                                               γ/(α+1)
                                   1                 − log(ζz)                                           x
           =                             α/(α+1)                        +                            α+1                .
                           α+1                       −  log φ̃
                                                                                               α
                     α       α
                                  + 0.5x                                                       α+1
                                                                                                        α
                                                                                                                 + 0.5x
                    α+1

We have
                                                         (α+1)/α                                                        !
                                                     α
      log(φ̃)   =    log(ζ z) + log                                  (ζz)1/α (− log(ζz))−γ/α + 0.5 z
                                                    α+1
                ≤    log(ζz)

for small ζ, z. Furthermore, for any ε > 0 there exists a δ > 0 such that
                        (α+1)/α
                      α
                                   (ζz)1/α (− log(ζz))−γ/α ≥ (ζz)1/(α−ε)
                    α+1
for all ζz ≤ δ. Hence,
                                         α−ε    − log(ζz)
                                              ≤           ≤ 1
                                        α−ε+1    − log φ̃
for all sufficiently small ζ, z. Consequently, to prove (70) it suffices to show that

                                                 sup χ(x) < 1 + α,
                                                 x>0

where
                                                  1                                        x
                χ(x) =                               α/(α+1) Aα +                     α+1                 ,
                                         α+1                                   α
                                   α       α
                                                + 0.5x                         α+1
                                                                                          α
                                                                                               + 0.5x
                                  α+1

with                                                   (         γ/(α+1)         )
                                                             α
                                   Aα = max                                   ,1       .
                                                            α+1
Let                                                               α+1
                                                             α       α
                                                K =                       .
                                                            α+1

                                                            54
Then,
                                 0.5 Aα α        1                    K
                  χ0 (x) = −                       (2α+1)/(α+1)
                                                                +             .
                                  α + 1 (K + 0.5x)                (K + 0.5x)2
Thus, χ0 (x∗ ) = 0 if and only if
                                                                        !α+1
                                                                 K
                                      K + 0.5x∗ =            0.5 Aα α
                                                                               ,
                                                               α+1

which means that                                   α+1         !             α+1
                                               2                         α        α
                                x∗ = 2                     −1                          .
                                               Aα                       α+1
Then,
   χ(x∗ )
                           1                                         x∗
    =                               α/(α+1) Aα +                α+1
                   α+1                                     α
             α       α
                          + 0.5x∗                          α+1
                                                                    α
                                                                          + 0.5x∗
            α+1
                                                                                 α+1              α+1   (72)
                                 1                                        2 A2 α       −1      α
                                                                                              α+1
                                                                                                       α

    =                                  α/(α+1)
                                               Aα +
      ((2/Aα )α+1 (α/(α + 1))(α+1)/α )              (2/Aα )α+1 (α/(α + 1))(α+1)/α
       α                          α+1
        Aα     α+1                     Aα               Aα+1
    =                Aα + 2 − 2                  = 2 + αα .
         2       α                      2               2 α
There are three candidates for x that achieve a maximum of χ, namely x = 0, x = +∞,
and x = x∗ , which is positive if and only if Aα < 2.
        If γ ≥ 0, then Aα = 1, so x = 0 and x = +∞ satisfy the required inequality as
soon as α > 1, whereas χ(x∗ ) < α + 1 if and only if α > α∗ , where
                                                                1
                                           α∗ = 1 +                  .
                                                              α∗ 2α∗
A calculation shows that α∗ ∈ (1.30, 1.31).
        If γ < 0, then
                                          (α + 1) Aα
                                χ(0) =               ,               χ(+∞) = 2,
                                              α
and this gives the condition Aα < α. If Aα > 2, that is, if
                                                                log 2
                                      −γ > (α + 1)                        ,
                                                           log((α + 1)/α)
then we are done. Otherwise, we need the property
                                Aα+1
                                 α                  log ((α2 − α) 2α)
                          2 +        < α + 1 ⇔ −γ <                   .
                                2α α                 log((α + 1)/α)

                                                       55
By assumption, ψit ∼ Exp+∞ (cit , γit , −αit ) uniformly if t. Thus, the arguments above
imply that a lower bound for vi − vj that is sufficient to guarantee the existence of
equilibrium for each fixed t can be chosen, independent of t.

E     Proofs of Section 4

Everywhere in the sequel, we assume for simplicity that R = 1.
        Proof of Theorem 4.2. The expected utility of a seller of class i ∈ {1, 2} of a
trade with a class-3 buyer is
                        Z TZ
                   1               H            L
                     λi          (ψiτ (z) + ψiτ   (z)) Π(τ, z, Sτ (z)) dz dτ
                   2     t    R
                              Z TZ
                        1                H
                     = λi              ψiτ (z) (1 + e−z ) Π(τ, z, Sτ (z)) dz dτ,
                        2      t    R

where

        Π(τ, z, S) = P (z)(S − v H )GH                                    L
                                     3τ (V2τ (S)) + (1 − P (z)) (S − v1 )G3τ (V2τ (S)).


Let f H be the probability density of a single signal, so that
                                             ∞
                                             X
                                   H
                                  ψi0    =         pik (f H )∗k , i = 1, 2.
                                             k=1

Substituting these expansions into (9), we get that
                                                                 ∗k
                                X
                                                      ∗k2
                       ψit =          ãit (k) f ∗k1 ψ30  · · · ψN 0N−1 ,
                                        k∈ZN−1
                                           +


                            N −1
where the measures ãit on Z+    satisfy the system of equations
                                                                N
                                                                X
                              ã0it   = −λi ãit + λi ãit ∗           κij ãjt ,                (73)
                                                                 j=1

but with the initial conditions (ãi0 )(k, 0, . . . , 0) = pik and (ãi0 )(0, k2, . . . , kN −1 ) = 0.
Then, the same argument as in the proof of Proposition 3.5 implies that the measure ã2t
dominates ã1t is the sense of first-order stochastic dominance. Therefore, it suffices to
show that
   Z
      (1 + e−z ) Π(τ, z, Sτ (z)) ((f H )∗k1 ∗ (ψ30
                                                H ∗k2          H ∗kN−1
                                                   ) · · · ∗ (ψ0N )        )(z − x) dz
    R Z
                                                                                                 (74)
                                                               ∗k2
   =      (1 + e−z−x ) Π(τ, z + x, Sτ (z + x)) ((f H )∗k1 ∗ ψ30              H ∗kN−1
                                                                   · · · ∗ (ψ0N )     )(z) dz
          R


                                                      56
is monotone increasing in k = (k1 , . . . , kN ).
      To show the latter, it suffices to prove that
                Z
                   (1 + e−x−y−z ) Π(τ, x + y + z, Sτ (x + y + z)) ζ(z) dz
                   R                                                                        (75)
                                                     −x−y
                                       > (1 + e                ) Π(τ, x + y, Sτ (x + y)),

for any x, y and any probability density ζ satisfying (14).
      Now, by the optimality of S, we have that

               Π(τ, x + y + z, Sτ (x + y + z)) ≥ Π(τ, x + y + z, Sτ (x + y)),

and the inequality is strict for all z 6= 0. Therefore,
 Z
    (1 + e−x−y−z ) Π(τ, x + y + z, Sτ (x + y + z)) ζ(z) dz
   R Z

 >       (1 + e−x−y−z ) Π(τ, x + y + z, Sτ (x + y)) ζ(z) dz
     ZR                 
 =       (1 + e−x−y−z ) P (x + y + z)(Sτ (x + y) − v H )GH  3τ (V2τ (Sτ (x + y)))
       R
                                                                        
                                                  L
      + (1 − P (x + y + z)) (Sτ (x + y) − v1 )G3τ (V2τ (Sτ (x + y))) ζ(z) dz
                                              Z
 = (Sτ (x + y) − v )G3τ (V2τ (Sτ (x + y))) (1 + e−x−y−z ) P (x + y + z)ζ(z) dz
                    H     H
                                               RZ

      + (Sτ (x + y) − v1 )GL3τ (V2 (Sτ (x + y))) (1 + e−x−y−z ) (1 − P (x + y + z))ζ(z) dz .
                                                           R
                                                                                            (76)
                                                               −x
The claim follows now from the identities (1 + e )P (x) = 1,

                                  (1 + e−x )(1 − P (x)) = e−x ,

and                          Z                   Z
                                  ζ(z) dz =           e−z ζ(z) dz = 1.
                              R                   R


Proof of Lemma 4.4. We have
                                                 ∞
                                                          pik (fˆH )k (s).
                                                 X
                                    H
                                  ψ̂i0 (s)   =
                                                 k=1

Standard results (for example, Korevaar (2004), Theorem 15.3, p. 30) imply that

                                               c Γ(γ + 1)
                                     fˆH (s) ∼            .
                                               (α − s)γ+1

                                                     57
Suppose first that16
                    def                                     def
               K1 = sup {k : p1k > 0} < K2 = sup {k : p2k > 0} < ∞.

Then,
                                             pi Ki (c Γ(γ + 1))Ki
                                    ψ̂iH   ∼                      .
                                                (α − s)Ki (γ+1)
Therefore (using, for example, Korevaar (2004), Theorem 15.3, p. 30)

                                              pi Ki (c Γ(γ + 1))Ki
                                     ci =
                                                 Γ(Ki (γ + 1))

and
                                γi = Ki (γ + 1) − 1 , αi = α.

The claim follows.
        If K1 = K2 = ∞, we have

                                   inf{s : ψ̂iH (s) = ∞} = αi ,

where αi is the unique positive number s solving
                                                                   pik
                                       fˆH (s) = lim                       ,
                                                       k→∞        pi k+1
and therefore α1 > α2 .


Lemma E.1 If f H ∼ Exp+∞ (c, 0, −α) and if there is a finite maximum number N(i)
of signals that an agent of class i receives with strictly positive probability, then ψi0 ∼
Exp+∞ (ci0 , N(i) − 1 , −α), where

                                   pi N (i) cN (i)
                           ci0 =                   ,        γi0 = N(i) − 1.
                                   (N(i) − 1)!

Alternatively, suppose that the moment generating function of f H is finite on (−, ) for
some  > 0 and that for some positive constants r < 1 and R > 1, we have

                                           pik Rk − 1 = O(r k ).                      (77)

Then, ψi0 satisfies an exponential tail condition.
 16
      The case of sup {k : p2k > 0} = ∞ is analogous.



                                                       58
      Condition (77) implies that, asymptotically in k, the probability of receiving k
signals is close to geometric in k, in a particularly tight sense.

Proof. The second claim follows by the Tauberian arguments used in the proof of
Proposition C.2.
      For the first claim, it suffices to show that

                           (f H )∗k ∼ Exp+∞ (ck /((k − 1)!) , k − 1 , −α).

We will prove this by induction in k. The case of k = 1 follows by the assumption on f H .
Suppose that we have proved the claim for some positive integer k; we will now prove it
for k + 1. Let φ = (f H )∗k . We use the decomposition
                                   Z A     Z +∞ 
                        H
                  (φ ∗ f )(x) =           +        φ(x − y) f H (y) dy.
                                                  −∞       A

Now, we fix an ε > 0 and pick some constant A so large that
                                             f H (y)
                                                     ∈ (1 − ε, 1 + ε)
                                             c e−αy
for all y > A. Then,
                              R +∞
                                  A
                                          φ(x − y) f H (y) dy
                                  R +∞                           ∈ (1 − ε, 1 + ε)
                              c       A
                                           φ(x − y) e−αy dy
for all x. Changing variables, applying L’Hôpital’s rule, and using the induction hypoth-
esis, we get
                 R +∞                                             R x−A
                     A
                           φ(x − y) e−αy dy         φ(z) e−α(x−z) dy  −∞
           lim                              =            lim
         x→+∞               xk e−αx    x→+∞          xk e−αx
                                             R x−A
                                                    φ(z) eαz dz
                                    = lim −∞
                                       x→+∞          xk
                                             φ(x − A)eα(x−A)                  (78)
                                    = lim
                                       x→+∞        k xk−1
                                             ck (x − A)k−1 e−α(x−A) eα(x−A)
                                    = lim
                                       x→+∞              k! xk−1
                                         k
                                       c
                                    =      .
                                       k!
Now, using the Lebesgue dominated convergence theorem and the induction hypothesis,
we get                RA
                              φ(x − y) f H (y) dy                          A
                                                                               φ(x − y) H
                                                                      Z
                         −∞
               lim                                =             lim                      f (y) dy
               x→+∞            xk−1 e−αx                     x→+∞         −∞   xk−1 e−αx
                                                                               A
                                                                                                      (79)
                                                                  k
                                                             c
                                                                           Z
                                                        =                           eαy f H (y) dy.
                                                          (k − 1)!             −∞


                                                        59
Consequently,
            ck+1           (f H )∗(k+1) (x)            (f H )∗(k+1) (x)           ck+1
 (1 − ε)         ≤ lim inf                  ≤ lim  sup                  ≤ (1 + ε)      ,
             k!       x→+∞     xk e−αx            x→+∞     xk e−αx                 k!
and the claim follows because ε > 0 is arbitrary.

Proof of Proposition 4.5. It will follow from the results below that it suffices to prove
the result for a single auction at time zero. For a strictly positive time t, for i = 1 and
i = 2,
                                        ψit ∼ Exp(cit , γ(t) , −α(t)),
with γ(t), α(t) and with c2t > c1t . It follows that the monotonicity result holds for any
auction at any time t > 0. Indeed, it follows directly from (7) that
                                                            ψ̂20
                                                  ψ̂2t =           ψ̂1t .
                                                            ψ̂10
Therefore,
                                                       ψ̂20 (α(t))
                                         c2t = c1t     > c1t ,
                                           ψ̂10 (α(t))
because p1 ≺f osd      p2 and Lemma C.1 together yield, for all k > 0,

                                                 ψ̂10 (k) < ψ̂20 (k).

         In order to prove Proposition 4.5, we will need a detailed analysis of the asymptotic
behavior of Si (y) as G(v) → ∞. Let
                                                       (α + 1)γ+1
                                                 ζ =                 .
                                                        c (v̄ − v3 )
Here, we consciously suppress indices for α, γ and c. Namely, if the information type
is not hidden, (c, γ, α) = (ci , γi , αi ). If the information type is hidden, we will have
(c, γ, α) = (κ2 c2 , γ2 , α2 ) if Tail(ψ10 ) ≺ Tail(ψ20 ), and we have (c, γ, α) = (κ1 c1 +
κ2 c2 , γ2 , α2 ) if (γ1 , α1 ) = (γ2 , α2 ) .
         As in the proof of Proposition 3.11, we define
                                                             ζ             def
                          g(z) = e(α+1)V2 (z) =                    γ
                                                                     f (z) = ε f (z) .
                                                         (− log ζ)
Then, as we have shown in the proof of Proposition 3.11, we may assume that, for large
G(v),
                                                 γ                                      
    0                     log(1/ζ)                        z − v̄
  f (z) =                                                        + ε1/(α+1) f (z)1/(1+α)       ,   f (v̄) = 0.
                   log(1/ζ) + log(1/f (z))               vH − z
                                                                                                          (80)

                                                           60
See (68). Furthermore, as G(v) → ∞, we have ζ, ε → 0 ,

                                         lim          f (z) = f0 (z),
                                       G(v)→∞

where
                                            v H − v̄
                                             H
                       f0 (z) = (v − v̄) log H       − (z − v̄),
                                            v −z
and the convergence is uniform on compact subsets of [v̄, v H ).
        From this point, for simplicity we take the case γi = 0 for all i. The general case
follows by similar but lengthier arguments. Hence, we assume that f solves
                                               z − v̄
                             f 0 (z) =                + ε1/α+1 f 1/(α+1) .                             (81)
                                              vH − z
Since the solution f (z) to (81) is uniformly bounded on compact subsets of [v̄, v H ), by
integrating (81) we find that

                          0 ≤ f (z) − f0 (z) = O(ε1/(α+1) (z − v̄)),

uniformly on compact subsets of [v̄, v H ) . Furthermore, f0 (z) ≤ C1 (z − v̄)2 , uniformly
on compact subsets of [v̄, v H ) . Substituting these bounds into (81), we get
                                       Z z
                               1/(α+1)
    f (z) − f0 (z) ≤ C2 ε                  (ε1/α+1 (z − v̄) + (z − v̄)2 )1/(α+1) dz
                                                 v̄
                                   1/(α+1)                       2
                      ≤     C3 ε             (z − v̄) (ε1/(α+1) (z − v̄)1/(α+1) + (z − v̄)2/(α+1) ).

Let now
                                                             ε1/α+1 α
                           l(z) = f (z)α/(α+1) −                      (z − v̄) .
                                                              α+1
Then,
                                    α                          ε1/α+1 α
                          l0 (z) =     f 0 (z) f −1/(α+1) −
                                  α+1                            α+1
                                    α                 z − v̄
                                =
                                  α + 1 ε1/α+1 α
                                                                   1/α                               (82)
                                            α+1
                                                   (z  − v̄) + l(z)
                                        α     z − v̄
                                ≤                     .
                                      α + 1 (l(z))1/α
Integrating this inequality, we get
                                                        1
                                             l(z) ≤       (z − v̄)2 ,
                                                        2
and therefore
                        f (z) ≤ C4 ((z − v̄)2 + ε1/α (z − v̄)(α+1)/α ) .                               (83)

                                                        61
Consequently,
                                                                  1/(α+1)
                  eV2 (z) = ε1/(α+1) f0 (z) + o(ε1/(α+1) (z − v̄))

uniformly on compact subsets of [v̄, v H ) . Therefore,
                                                 
                                       1                 1
                  lim V2 (z) −               log ε =        log f0 (z),
                  ε→0              α+1                  α+1

uniformly on compact subsets of (v̄, v H ).
      Now, since V2 → −∞ uniformly on compact subsets of [v̄, v H ),
                                               z − v̄
                              V1 (z) = log            − V2 (z)
                                              vH − z
converges to +∞, uniformly on compact subsets of (v̄, v H ) . Pick an η > 0 and let ε be
so small that V2 (v̄ + ε) > K for some very large K. Then, for all θ < K we have that

                     v̄ < S(θ) < S(K) < S(V2 (v̄ + ε)) = v̄ + ε.

Thus, S(θ) converges to v̄ uniformly on compact subsets of [−∞, +∞) (with −∞ in-
cluded). Furthermore,
                                   
                         1                       z − v̄    1             def
       lim V1 (z) +         log ε       = log    H
                                                        −     log f0 (z) = M(z)
       ε→0              α+1                     v −z      α+1

uniformly on compact subsets of (v̄, v H ). Let M̂ (z) = M −1 (z). We claim that
                                                   
                                           1
                        lim S θ −              log ε = M̂ (θ) ,                      (84)
                        ε→0             α+1
                                                        1
                                                               
uniformly on compact subsets of R. Indeed, S θ − α+1      log ε is the unique solution to
the equation in y given by
                                                    1
                                θ = V1 (y) +           log ε .
                                                   α+1
Since the right-hand side converges uniformly to the strictly monotone function M( · ),
this unique solution also converges uniformly to M̂ (θ). Furthermore,

         v̄ + ∆i P (V1 (z) + V2 (z)) = z ⇔ v̄ + ∆i P (θ + V2 (S(θ))) = S(θ)

implies that
                                                            
                          1                             S − v̄               1
             V2 S θ −        log ε        = log                      −θ +       log ε
                         α+1                           vH − S               α+1

                                              62
and therefore
                                                                                  !
                          1                      1                      M̂ (θ) − v̄
        V2 S θ −             log ε            −     log ε → log                               − θ.
                         α+1                    α+1                    v H − M̂ (θ)
       We have
                                                                                             
                                                      z − v̄
           M(z) = log                                                      1/(αi +1)  .
                                                                                      
                                                             
                                                         H
                              (v H − z) (v H − v̄) log vvH −z
                                                           −v̄
                                                                 − (z − v̄)

Now, for z ≈ v̄,
              H                                               2
              v − v̄               z − v̄      z − v̄   1 z − v̄
         log           = − log 1 − H        ≈ H       +               ,                              (85)
              vH − z              v − v̄      v − v̄    2 v H − v̄
and therefore
                                                                                         
                                     −1          H         αi − 1               z − v̄
                Mi (z) ≈ (1 + α)          log(2(v − v̄)) +        log                                (86)
                                                           αi + 1              v H − v̄
as z → v̄. Consequently, as θ → −∞, we have
                                                            α+1
                                      M̂ (θ) ∼ v̄ + K e α−1 θ

for some constant K = K(α).

       By continuity,17 it suffices to prove Proposition 4.5 for a single auction at time
zero. For brevity, we omit the index 0 in this proof. For example, we write “ψi ” for ψi0 .
       We use the notation uH,L
                            i   for the pair of expected utilities of a class-i investor in
an auction held at time zero, conditional on Y = 0 and Y = 1, respectively.18
                     Z            Z V1,i (Bi (x))
             H,L          H,L
            ui    =     ψi (x)                    ({v H , v̄} − Si (y)) ψ3H,L(y) dy dx
                                    −∞
                     ZR
                  =     ψ3H,L (y) ({v H , v̄} − Si (y)) GH,L i  (V2,i (Si (y))) dy
                      R
                     Z
                  =     ψ3H,L (y) ({v H , v̄} − Si (y)) dy
                      R Z                                                                            (87)
                      −      ψ3H,L (y) ({v H , v̄} − Si (y)) FiH,L(V2,i (Si (y))) dy
                           R               Z
                        H
                  = ({v , v̄} − v̄) +          ψ3H,L (y) (v̄ − Si (y)) dy
                         Z                  R

                      −      ψ3H,L (y) ({v H , v̄} − Si (y)) FiH,L(V2,i (Si (y))) dy ,
                                R
  17
     Because the exponential tails are uniform, it will follow that the convergence proved below is also
uniform in time.
  18
     Here, S1 (y) and S2 (y) are different if and only if information type is not hidden.

                                                     63
where Fi = 1 − Gi . Let us first study the asymptotic behavior of the term
                            Z
                                ψ3H,L (y) (v̄ − Si (y)) dy
                                           R

as G(v) → ∞. We have
          Z
              ψ3H,L (y) (v̄ − Si (y)) dy
            R
                                                                                                          (88)
                                  1                             1
              Z
                    H,L
          =       ψ3       y−          log εi    v̄ − Si y −        log εi    dy .
                R              αi + 1                        αi + 1
Since, by assumption, ψ3H,L ∼ Exp+∞ (c3 , γ3 , −{α3 , α3 + 1}), we get
                                                             
                −1 −{α3 ,α3 +1}/(αi +1) H,L        1
           lim c3 ε                    ψ3    y−         log εi = e−{α3 ,α3 +1} y .
           ε→0                                  αi + 1
By (84),                                                         
                                                  1
                            v̄ − Si y −               log εi          → v̄ − M̂i (y) .
                                               αi + 1
In order to conclude that
                                                                            
                                      1                              1
                       Z
          −α3 /(αi +1)     H
    lim ε                 ψ3 y −           log εi     v̄ − Si y −        log εi    dy
    ε→0                 R         αi + 1                          αi + 1
                            Z                                                                                   (89)
                       = c3    e−α3 y (v̄ − M̂i (y)) dy,
                                    R

and that
                                                                              
                          1                                          1
     Z
         L
        ψ3 y −                log εi       v̄ − Si y −                   log εi        dy = o(εα3 /(αi +1) ),
      R                αi + 1                                     αi + 1
we will show that the integrands
                                                                                                     
                 −α3 /(αi +1) H                    1                                        1
        I(y) = ε             ψ3 y −                    log εi       v̄ − Si y −                 log εi
                                                αi + 1                                   αi + 1
and                                                                                                
               −(α3 +ε)/(αi +1)                  1                                        1
           ε                      ψ3L    y−          log εi     v̄ − Si y −                   log εi
                                              αi + 1                                   αi + 1
have an integrable majorant. Then, (89) will follow from the Lebesgue dominated con-
vergence theorem.
      We decompose the integral in question into three parts, as
              Z 1 log ε             Z A                  Z +∞
                1+α
                        I1 (y) dy +          I2 (y) dy +       I3 (y) dy,
                                                     1
                       −∞                                 log ε                   A
                                                   1+αL


and prove the required limit behavior for each integral separately. To this end, we will
need to establish sharp bounds for S(θ) and V2 (θ).

                                                          64
Lemma E.2 Let L(θ, ε) be a function such that

                                     lim      L(θ, ε) = 0.
                                   θ→−∞,ε→0


We have                                       
                                    1
                         S θ−          log ε        ≤ v̄ + C1 L(θ, ε)                 (90)
                                   α+1
for all sufficiently small ε > 0 and sufficiently small θ if and only if
                    1
                       log f (v̄ + L(θ, ε)) − log(L(θ, ε)) ≤ C2 − θ .                 (91)
                   α+1
If (90) holds, we have
                                     
                            1                      log ε
            V2 S θ3 −          log ε        ≤            + C3 + log L(θ, ε) − θ.      (92)
                           α+1                     1+α

Proof. Applying V1 to both sides of (90) and using the fact that V1 is strictly increasing,
we see that the desired inequality is equivalent to
                                    1
                              θ−       log ε ≤ V1 (v̄ + L) .
                                   α+1
Now,
            1              z − v̄             1              z − v̄   1
V1 (z) +       log ε = log H      − V2 (z) +     log ε = log H      −   log f (z) .
           α+1            v −z               α+1            v −z α+1
The claim follows because we are in the regime when v H − z is uniformly bounded away
from zero.
       Furthermore,
                                                                   
                          log ε                            S − v̄
                        −       + V2 (S) = log                          − θ.          (93)
                          1+α                             vH − S

If θ is bounded from above, S is uniformly bounded away from v H , and hence
                                  
                            S − v̄
                     log             − θ ≤ C4 + log(S − v̄) − θ.
                           vH − S

The claim follows.

Lemma E.3 Suppose that ε > 0 is sufficiently small. Then, for
                                             1
                                      θ≥        log ε,                                (94)
                                            α+1

                                              65
we have                                           
                                       1                                   α+1
                             S θ−         log ε            ≤ v̄ + C5 e α−1 θ ,                 (95)
                                      α+1
and for
                                                  1
                                          θ ≤        log ε,                                    (96)
                                                 α+1
we have that                                
                                  1                                    1         α
                        S θ−         log ε       ≤ v̄ + C6 ε (α+1)(α−1) e α−1 θ .              (97)
                                 α+1


Proof. By Lemma E.2, inequality (97) is equivalent to
       1                       1         α                     1         α
          log f (v̄ + C6 ε (α+1)(α−1) e α−1 θ ) − log(C6 ε (α+1)(α−1) e α−1 θ ) ≤ −θ + C7 .    (98)
      α+1
Under the condition (96),

                   max (z − v̄)2 , ε1/α (z − v̄)(α+1)/α         = ε1/α (z − v̄)(α+1)/α
                      
                                                                                               (99)

for
                                                       1           α
                                     z = C8 ε (α+1)(α−1) e α−1 θ .

Hence, by (83),
                                  f (z) ≤ C9 ε1/α (z − v̄)(α+1)/α .

Consequently,
         1                       1         α
                                                                1         α
                                                                                
            log f (v̄ + C6 ε (α+1)(α−1) e α−1 θ ) − log C6 ε (α+1)(α−1) e α−1 θ
        α+1                                                                            
                              1                   1    α                1
            ≤ C10 +                  log ε +               θ +                    log ε
                         (α + 1) α               α α−1         (α + 1)(α − 1)                 (100)
                                                           
                         α                   1
                 −            θ +                     log ε
                        α−1         (α + 1)(α − 1)
            = −θ + C10 ,

and (97) follows.
        Similarly, when θ satisfies (94), a direct calculation shows that

                        max (z − v̄)2 , ε1/α (z − v̄)(α+1)/α           = (z − v̄)2
                           
                                                                                              (101)

for
                                                             α+1
                                        z = v̄ + C5 e α−1 θ .


                                                  66
Therefore, by (83),
           1                   α+1                α+1
              log f (v̄ + C5 e α−1 θ ) − log(C5 e α−1 θ )
          α+1
                                                                                                                     (102)
                                                    2         α +1
                                       ≤ C11 +            θ −      θ = −θ + C11 ,
                                                  α−1         α−1
and (95) follows.


Lemma E.4 If
                                                                 α+1
                                                                     > α3 ,
                                                                 α−1
then
        1
                log ε                                                                      
                                              1                                     1
  Z
       α+1
                        ψ3H,L    θ−              log ε        v̄ − S θ −               log ε        dθ = o(εα3 /(α+1) ) .
   −∞                                        α+1                                   α+1


Proof. By (96), since ψ3H,L is bounded, we get
                     1
                          log ε                                                                   
                                                        1                                 1
                Z
                    α+1
                                    ψ3H,L     θ−           log ε            v̄ − S θ −       log ε         dθ
                  −∞                                   α+1                               α+1
                                     1
                              Z
                                    α+1
                                          log ε         1         α
                ≤ C12                             ε (α+1)(α−1) e α−1 θ dθ                                            (103)
                                −∞
                              α − 1 (α+1)(α−1)
                              1         1            α
                                               + (α+1)(α−1)
                = ε (α+1)(α−1)      ε
                                  α
                = o(εα3 /(α+1) ) .



Lemma E.5 If
                                                                 α+1
                                                                     > α3 ,
                                                                 α−1
then
                                A                                                                      
                                                             1                                 1
                          Z
                    α
                    3
                 − α+1
       lim ε                                 ψ3H     θ−         log ε            v̄ − S θ −       log ε         dθ
       ε→0                     1
                                     log ε                  α+1                               α+1
                              α+1
                                                                                                                     (104)
                                      Z      A
                          = c3                    (v̄ − M̂ (θ)) e−α3 θ dθ
                                          −∞

and
          A                                                                               
                                           1                                       1
      Z
                        ψ3L    θ−             log ε              v̄ − S θ −           log ε        dθ = o(εα3 /(α+1) ).
           1
          α+1
                log ε                     α+1                                     α+1


                                                                       67
Proof. By assumption, as x → ∞,

                                         ψ3H (x) ∼ c3 e−α3 x .

The claim follows from (84) and (94), which provides an integrable majorant.
      The same argument implies the following result.

Lemma E.6 We have
               Z +∞                                            
            α3
         − α+1       H          1                         1
   lim ε            ψ3 θ −          log ε     v̄ − S θ −     log ε    dθ
   ε→0          A             α+1                        α+1
                    Z +∞                                                                               (105)
               = c3      (v̄ − M̂(θ)) e−α3 θ dθ
                             A

and
          +∞                                                          
                            1                               1
      Z
               ψ3L    θ−       log ε     v̄ − S θ −            log ε            dθ = o(εα3 /(α+1) ) .
      A                    α+1                             α+1

      Finally, to complete the proof, it suffices to show that the term
            Z
                ψ3H,L (y) ({v̄, v H } − Si (y)) FiH,L(V2,i (Si (y))) dy = o(εα3 /(α+1) )               (106)
                R

in (87) is negligible for large G(v) As G(v) → +∞, we have V2,i (Si (y))                           →    −∞.
Furthermore, as x → −∞,
                                                    ci
                                 FiH,L (x) ∼                 ex {αi +1,αi } .
                                               {αi + 1, αi }
The claim then follows by essentially the same arguments used above. Special care is
only needed because (v H − S)−1 blows up as θ ↑ +∞.
      By (93),
                                                                               αi +1
                                     1                                    S − v̄ −θ
               FiH    V2 S θ −          log ε            ≤ C13 ε                 e             .
                                    α+1                                  vH − S
Thus, to get an integrable majorant, it would suffice to have a bound

                                        v H − S ≥ C14 e−βθ ,

for some β > 0 and for a sufficiently large θ. By the argument used in the proof of
Lemma E.2, it suffices to show that for sufficiently large θ,
                        1
                           log f (vH − C14 e−βθ ) ≤ C15 + (β − 1) θ .
                       α+1

                                                    68
Now, it follows from (81) that

                                                              v H − v̄
                                   f 0 (z) ≤ f (z)1/(α+1) +            .
                                                              vH − z
Since, for sufficiently small ε, f (z) is uniformly bounded away from zero on compact
subsets of (v̄, v H ], we get

                             d
                                (f (z)α/(α+1) ) ≤ C16 (1 + (v H − z)−1 ),
                             dz
for some K > 0 when z is close to v H . Integrating this inequality, we get

                                f (z)α/(α+1) ≤ C17 (1 − log(v H − z)).

Consequently,
                            1
                              log f (vH − C14 e−βθ ) ≤ C18 log θ
                          α+1
if θ is sufficiently large. Hence, the required inequality holds for any β > 1 with a
sufficiently large C14 . Pick a β so that (β − 1)(α + 1) < α3 . Then we get that, for
sufficiently large θ,
                                                    
                                           1
                   FiH       V2 S θ −         log ε           ≤ C19 e(β−1)(α+1)θ ,
                                          α+1

and the claim follows.

      Thus, the unconditional expected utility of agent i is approximately
                                             Z
                        H          α3 /(α+1)
                  0.5 (v − v̄) − εi            (M̂i (θ) − v̄) e−α3 θ dθ .
                                                       R

For the case in which the information characteristics of classes 1 and 2 are not hidden,
we need to consider two sub cases. If α1 > α2 , then, since ε1 and ε2 differ from each
other by a constant proportion, sending G(v) to infinity leads to
                     Z                                         Z
         α3 /(α1 +1)                   −α3 θ       α3 /(α2 +1)
        ε1             (M̂1 (θ) − v̄) e      dθ > ε2             (M̂2 (θ) − v̄) e−α3 θ dθ,
                        R                                           R


and the claim follows. If, instead, α1 = α2 but c1 < c2 , we get that ε1 > ε2 and M̂1 = M̂2 ,
so the claim also follows in this case.
      The case in which information characteristics are hidden is handled analogously.




                                                  69
F    Proof of Proposition 4.6

First, we note that the evolution equations
                                         d
                                            ψ̂it = λi ψ̂it (−1 + ψ̂3t )
                                         dt
imply that
                                                                                        !λ2 /λ1
                                                        Rt                       ψ̂1t
                       ψ̂2t = ψ̂20 e−λ2 t eλ2            0    ψ̂3τ dτ
                                                                        = ψ̂20                    .
                                                                                 ψ̂10
Since, by assumption, ψit ∼ Exp+∞ (cit , γit , −αit ), we immediately get (see, for example,
Korevaar (2004), Theorem 15.3, p.30) that α1t = α2t and that
                                                                cit Γ(γit + 1)
                                     ψ̂it (k)          ∼                        .
                                                      k↑α1t     (αit − k)γit +1
This immediately yields that
                                                     λ2
                                 γ2t + 1 =              (γ1t + 1) ⇒ γ2t > γ1t .
                                                     λ1
Consequently, Tail(ψ1t ) ≺ Tail(ψ2t ) . It follows from the proof of Proposition 4.5 that
the required result holds for any positive t > 0, provided that v̄ − v3 is larger than some
t-dependent threshold.
        Thus, it remains to show the required inequality, comparing auction expected util-
ities, over a sufficiently small time interval [0, t]. Thus, from now on, we will assume that
T is sufficiently small. Furthermore, we will provide a proof only for the case in which
the information characteristics are not hidden. The case of unobservable information
characteristics is handled analogously.
        We have
                                             T
                                1
                                     Z           Z
           λ−1                                          H
                                                           (θ) πiH (τ, θ) + ψiτ
                                                                             L
                                                                                (θ) πiL(τ, θ) dθ dτ.
                                                                                             
            i    E[Ui (Θi0 )] =                        ψiτ
                                2        0       R

Here,
                                   d K       K        K     K
                                    ψ = −λi ψiτ + λi ψiτ ∗ ψ3τ                                         (107)
                                  dτ iτ
for K = H or K = L, and
                                     Z   V1,i (Bi (τ,z))
                  πiH,L (τ, z)   =                                                    H,L
                                                             ({v H , v̄} − Si (τ, y))ψ3τ  (y) dy .
                                     −∞

By assumption,
                                                      H,L    H,L
                                                     ψ10  = ψ2,0 .

                                                               70
Therefore V2,i (0, z) is also independent of i, and we will omit the index i in what follows.
        We denote
                                         Z
                                              H
                                                 (θ) πiH (τ, θ) + ψiτ
                                                                   L
                                                                      (θ) πiL (τ, θ) dθ.
                                                                                    
                       Πi (τ ) =             ψiτ
                                         R

It follows from (107) that, for small τ,

                          K                                   K
                         ψi,τ = (1 − λi τ ) ψ0i + λi τ ψi0 ∗ ψ30 + o(τ ).

Consequently,19
                             Z
                                      H
                                         (θ) πiH (τ, θ) + ψi0
                                                           L
                                                              (θ) πiL(τ, θ) dθ
                                                                           
  Πi (τ ) = (1 − λi τ )              ψi0
                                 R

                        Z
                                 (ψi0 ∗ ψ30 )H (θ) πiH (τ, θ) + (ψi0 ∗ ψ30 )L (θ) πiL(τ, θ) dθ + o(τ ) .
                                                                                           
              + λi τ
                         R
                                                                                                    (108)
The argument used in the proof of Theorem 4.2 implies that for small τ ,
          Z
              (ψi0 ∗ ψ30 )H (θ) πiH (τ, θ) + (ψi0 ∗ ψ30 )L (θ) πiL (τ, θ) dθ
                                                                         
           R      Z                                                                                 (109)
                          H
                            (θ) πiH (τ, θ) + ψi0
                                              L
                                                 (θ) πiL (τ, θ) dθ.
                                                               
               >       ψi0
                             R

Thus, in order to complete the proof, it remains to show that, for small τ ,
                Z
                     H
                        (θ) π2H (τ, θ) + ψ20L
                                               (θ) π2L (τ, θ) dθ
                                                             
                    ψ20
                  R      Z                                                                          (110)
                                H
                                  (θ) π1H (τ, θ) + ψ10  L
                                                          (θ) π1L (τ, θ) dθ.
                                                                        
                     >        ψ10
                                     R

        As above, for simplicity, we use the normalization v̄ = 0, v H = 1. As in the proof
of Proposition 3.11, let
                                             gi (τ, z) = e(α+1)V2,i (τ,z) ,

where
                                                   def
                                                α = α10 = α20 .

Let also
                                                          d
                                             wi(z) =        gi (τ, z) |τ =0 .
                                                         dτ
  19
     The o(τ ) term is a measure and therefore, when integrating against it, the result requires additional
justification. This is supplied by using the bounds derived in the proof of Proposition 4.5.


                                                          71
It follows from the proof of Proposition 3.1120 that this derivative is well-defined and we
can differentiate (50) to obtain

                                                      z GH                  GL0 (V2,i (τ, z))
                                                                                               
d                           1                               0 (V2 (0, z))
   wi (z) = (α + 1)w(z)                                                   +
dz                      (v̄ − v3 )                  1 − z ψ0H (V2 (0, z))   ψ0L (V2,i (τ, z))
   (α + 1) g(0, z)                 z
 +                               H
                                                 ×
       (v̄ − v3 )       (1 − z)(ψ0 (V2 (0, z)))2
                                                                      
      d H                        H                   −1               −1
          G     (V2 (0, z)) − ψ0 (V2 (0, z)) (α + 1) wi (z)g(0, z)         ψ0H (V2 (0, z))
     dτ 0
                                                                                        !
                         d                       d
 − GH
    0 (V2 (0, z))          ψ H (V2 (0, z)) +       ψ H (V2 (0, z)) (α + 1)−1 w(z)g(0, z)−1
                        dτ 0                    dV 0
                                                                         
            d L                      L                   −1              −1
 +           G (V2 (0, z)) − ψi0 (V2 (0, z)) (α + 1) wi (z)g(0, z)
           dτ 0
                                                                                            !!
   GL0 (V2 (0, z))
                            
                         d L                     d L
 − L                       ψ (V2 (0, z)) +         ψ (V2 (0, z)) (α + 1)−1 wi (z)g(0, z)−1      ,
   ψ0 (V2 (0, z))       dτ 0                    dV 0
                                                                                            (111)
with w(0) = 0. This is a linear ODE. Solving it, we obtain
                                   Z z R
                                         z
                           w(z) =      e y χ(x)dx µi (y) dy,
                                                      0

where
                                                 z GH                  GL0 (V2 (0, z))
                                                                                        
                         1                             τ (V2 (0, z))
      χ(z) = (α + 1)                                                 +
                     (v̄ − v3 )                1 − z ψ0H (V2 (0, z))   ψ0L (V2 (0, z))
                 1                     z
        −                                                 ×
              v̄ − v3   (1 −     z)(ψ0H (V2 (0, z)))2
                                                                                                  (112)
                                                           d H
            (ψ0H (V2 (0, z)))2    +   GH
                                       0 (V2 (0, z))        ψ (V2 (0, z))
                                                          dV 0
                                                                                     !
                                                                    d
        + (ψ0L (V2 (0, z)))−2 (ψ0L (V2 (0, z)))2 + GL0 (V2 (0, z))    ψ L (V2 (0, z))
                                                                   dV 0
  20
     This claim follows from implicit function theorem if we rewrite the required ODE as an integral
equation and use the arguments from the proof of Proposition 3.11.




                                                              72
is independent of i and where
                    (α + 1) g(0, z)                    z
         µi(z) =                                                           ×
                       (v̄ − v3 )         (1 −   z)(ψ0H (V2 (0, z)))2

            −λi GH       H    H               H
                                
                 0 + λi G0 ∗ ψ30 (V2 (0, z)) ψ0 (V2 (0, z))

                                                                           !
         − GH                  H       H               H
                                                         
            0 (V2 (0, z)) −λi ψ0 + λi ψ0 ∗ ψ30 (V2 (0, z))                                                           (113)


         + (ψ0L (V2 (0, z)))−2      −λi GL0 + λi GL0 ∗ ψ30
                                                        L
                                                                       (V2 (0, z))ψ0L (V2 (0, z))
                                                                   

                                                                          !!
         − GL0 (V2 (0, z)) −λi ψ0L + λi ψ0L ∗ ψ30 (V2 (0, z))
                                                      L
                                                        
                                                                                .

By definition,
                      d                        wi (z)      def
                        V2,i (τ, z)|τ =0 =                 = Wi (z) .         (114)
                     dτ                    (α + 1) g(0, z)
For brevity, we use the notation g(z) = g(0, z), S(z) = S(0, z), and B(z) = B(0, z).
      We have
                                d
                                  V1,i (τ, z)|τ =0 = − Wi (z).
                               dτ
Therefore, differentiating the identity

                                          V1,i (τ, Si (τ, z)) = z,

we get
   d                       Wi (S(z))
     Si (τ, z)|τ =0 =    d
  dτ                     dz
                            (V1 )(S(z))
                                                           Wi (S(z))                                                 (115)
                    =                                                                                          .
                               1                              S(z)        1                          1
                         S(z)(1−S(z))
                                        − (v̄ − v3 )−1       1−S(z) hH (V2 (S(z)))
                                                                                       +       hL (V2 (S(z)))

Differentiating the identity
                                                            Si (τ, z)
                              V2,i (Si (τ, z)) = log                    − z
                                                          1 − Si (τ, z)
with respect to τ , we get
     d
       (V2,i (Si (τ, z))) |τ =0
    dτ
                                         Wi (S(z))                                                    1
     =                                                                                                       .
               1
                        − (v̄ − v3 )−1      S(z)        1
                                                                   +            1              S(z) (1 − S(z))
         S(z)(1−S(z))                      1−S(z) hH (V2 (S(z)))          hL (V2 (S(z)))
                                                                                                                     (116)

                                                     73
Therefore,
    Z                            
  d        H,L       H,L
          ψ0 (z) πi (τ, z)dz |τ =0
 dτ     R
          Z                                                               
      d          H                        H                     H,L
  =            Gi (V2,i (τ, Si (τ, y))({v , v̄} − Si (τ, y)) ψ3τ (y)dy |τ =0
     dτ      R
                                                             Wi (S(y))
        Z
  = −      ψ0H,L (V2 (S(y)))                                                                               
                                     1                    −1    S(y)        1                    1
         R
                               S(y)(1−S(y))
                                            −  (v̄ − v3 )      1−S(y) hH (V2 (S(y)))
                                                                                     +     hL (V2 (S(y)))
              1                           H,L
     ×                 ({1, 0} − S(y)) ψ30    (y) dy
       S(y) (1 − S(y))
                                                          Wi (S(y))
       Z
     −    GH,L
             0 (V2 (S(y)))                                                                                 
                                  1                    −1    S(y)        1                       1
        R
                            S(y)(1−S(y))
                                         −  (v̄ − v3 )      1−S(y) hH (V2 (S(y)))
                                                                                  +        hL (V2 (S(y)))
        H,L
     × ψ30  (y) dy
       Z
     +     GH,L
             0 (V2 (S(y))) ({1, 0} − S(y))
            R
                                                                !
                   H,L             H,L
                                             X        H,L
     × λ3        −ψ30  (y)    +   ψ30    ∗       κ3k ψk0  (y)       dy
                                             k
  def
   = π̃iH,L .
                                                                                                      (117)
We now define
                                         1 H
                                           (π̃i + π̃iL ) .
                                             π̃i =                                                    (118)
                                         2
In order to prove (110), it remains to show that

                                                     π̃2 > π̃1 .

As in the proof of Proposition 4.5, we assume for simplicity that γi = 0 for all i (that is,
no power tails). Recall also that, by assumption, ψ10 = ψ20 . Hence, (c1 , α1 ) = (c2 , α2 ) =
(c, α).
         We will use the same bounds and asymptotic results that were derived in the proof
of Proposition 4.5.
         Let us first understand the behavior of Wi (z) as G(v) → ∞. We have
                                                      1
                                         V2 (z) ≈        log(ε f0 (z)).
                                                     α+1
Therefore,

                g(0, z)   ≈   e(α+1)V2 (z) ∼ ε f0 (z)
                              c e{α+1,α} ( α+1 log(ε f0 (z))) = c ε{α+1,α}/(α+1) f0 (z){α+1,α}/(α+1) ,
                                            1
        ψ0H,L (V2 (z))    ∼

                                                         74
and
                   d H,L
                     ψ0 (V2 (z)) ∼ c {α + 1, α} e{α+1,α} ( α+1 log(ε f0 (z)))
                                                            1

                  dV                                                                                    (119)
                                 = c {α + 1, α} ε{α+1,α}/(α+1) f0 (z){α+1,α}/(α+1) ,
and
                                                    1       c
                                                         =     ε.
                                                 v̄ − v3   α+1
Therefore,

      χ(z)
                                         z GH                  GL0 (V2 (0, z))
                                                                                 
                    1                          0 (V2 (0, z))
      = (α + 1)                                              +
                (v̄ − v3 )             1 − z ψ0H (V2 (0, z))   ψ0L (V2 (0, z))
              1                   z
      −                          H
           v̄ − v3 (1 − z)(ψ0 (V2 (0, z)))2                                                             (120)
                                                                    
                  H            2      H             d H
          × (ψ0 (V2 (0, z))) + G0 (V2 (0, z))        ψ (V2 (0, z))
                                                   dV 0
                                                                                       !
                                                                      d
          + (ψ0L (V2 (0, z)))−2 (ψ0L (V2 (0, z)))2 + GL0 (V2 (0, z))    ψ L (V2 (0, z))
                                                                     dV 0
                                                                        
                        z       1                  1
       = cε                           +    α/(α+1)
                      1 − z c ε f0(z)   cε         f0 (z)α/(α+1)
                c                    z                         2
                                                                                      
           −       ε                              (c ε f0 (z))   + (α + 1) c ε f0 (z)
               α+1           (1 − z)(c ε f0 (z))2
                                                                                                 !      (121)
                                                                               
                 α/(α+1) α/(α+1) −2      α/(α+1) α/(α+1) 2      α/(α+1) α/(α+1)
           + (cε        f0      )    (cε        f0      ) + cαε        f0

              1
       =         ε1/(α+1) f0 (z)−α/(α+1) + O(ε) .
           α+1
        For simplicity, we assume that α30 6= α. (If α30 = α, then power tails will appear.
The analysis is in that case analogous, but technically more involved.) We then have, as
x → −∞,
                                         Z
           (ψ0H   ∗    H
                      ψ30 )(x)     =            ψ0H (x − y) ψ30
                                                             H
                                                                (y) dy
                                         (R
                                           c e(α+1)x ψ̂30
                                                        H
                                                          (α)         ,      α < α30
                                   ∼                                                   ≡ d e(β+1) x ,
                                           c30 e(α30 +1)x ψ̂0H (α30 ) ,      α > α30

where                                     (
                                               H
                                           (cψ̂30
                                          def     (α), α) ,                  α < α30
                                 (d, β) =
                                           (c30 ψ̂0H (α30 ), α30 ) ,         α > α30

                                                           75
and where we have used the fact that

                                       ψ̂ H (k) = ψ̂ H (−k − 1).

In this case,
                                                                         1               1
(GH   H          H        H         H
  0 ∗ψ30 )(x) − G0 (x) = F0 (x) − (F0 ∗ψ30 )(x)                   ∼         c e(α+1)x −     d e(β+1) x .
                                                             x↓−∞       α+1             β+1

Thus, in complete analogy with (120),

                (α + 1) g(0, z)                  z
  µi(z) =
                   (v̄ − v3 )       (1 −   z)(ψ0H (V2 (0, z)))2

                        −λi GH       H    H               H
                                            
                 ×           0 + λi G0 ∗ ψ30 (V2 (0, z)) ψ0 (V2 (0, z))

                                                                                          !
                       − GH                  H       H                 H
                                                                         
                          0 (V2 (0, z)) −λi ψ0 + λi ψ0 ∗ ψ30 (V2 (0, z))                                     (122)


                 + (ψ0L (V2 (0, z)))−2                           L
                                             −λi GL0 + λi GL0 ∗ ψ30             (V2 (0, z))ψ0L (V2 (0, z))
                                                                            

                                                                                         !!
                       − GL0 (V2 (0, z)) −λi ψ0L + λi ψ0L ∗ ψ30 (V2 (0, z))
                                                                      L
                                                                        



                               z
  ∼ c ε2 f0 (z)
                      (1 − z) (c ε f0 (z))2
                                                                                     
                            1                  1       (β+1)/(α+1)        (β+1)/(α+1)
            ×        λi          c ε f0(z) −       dε              f0 (z)               c ε f0(z)
                          α+1                β+1
                                                                            !
                     − λi d ε(β+1)/(α+1) f0 (z)(β+1)/(α+1) − c ε f0(z)
                                                                         


       + (c εα/(α+1) f0 (z)α/(α+1) )−2
                                                                     
                     1 α/(α+1)            α/(α+1)   1 β/(α+1) β/(α+1)
           × λi         cε         f0 (z)         −   dε     f0         c (ε f0(z))α/(α+1)
                     α                              β
                                                               !!
                − λi d (ε f0(z))β/(α+1) − c (εf0(z))α/(α+1)
                                                             

                    z
  = − λi b                ε(β+1)/(α+1) f0 (z)(β−α)/(α+1) + o(ε(β+1)/(α+1) ) ,
                (1 − z) c
                                                                                                             (123)


                                                     76
where                             (
                                defd,                           α30 < α
                              b =       H
                                   c (ψ̂30 (α) − 1) ,           α30 > α
is a positive constant.
       Therefore,
            Z z R
                   z
  wi (z) =       e y χ(x)dx µi (y) dy
              0
                                 Z z                                                        (124)
                (β+1)/(α+1)                 y
                                                  f0 (y)(β−α)/(α+1) dy + o ε(β+1)/(α+1) .
                                                                                       
         ≈ −ε               λi b
                                  0     (1 − y) c

Therefore,
                    Wi (z) = − ε(β−α)/(α+1) λi X(z) + o ε(β−α)/(α+1) ,
                                                                    

with                                     Rz      y
                                 def      0   (1−y) c
                                                        f0 (y)(β−α)/(α+1) dy
                          X(z) = b                                             .
                                                   (α + 1)f0 (z)
Since f0 (z) = log(1 − z)−1 − z, a direct calculation shows that
                                                           2(β−α)
                                        X(z) ∼ C1 z          α+1




as z ↓ 0, and that X(z) is bounded when z ↑ 1.




                                                  77
            Now,

                                                                   W (S(y))
Z
        ψ0H (V2 (S(y)))                                             i                                              
                                    1                                 S(y)         1                      1
    R
                              S(y)(1−S(y))
                                                − (v̄ − v3 )−1       1−S(y) hH,L (V2 (S(y)))
                                                                                               +   hL (V2 (S(y)))
                           1                         H,L
                ×                   ({1, 0} − S(y)) ψ30  (y) dy
                    S(y) (1 − S(y))
        Z
 =              ψ0H,L (V2 (S(y − (α + 1)−1 log ε))) Wi(S(y − (α + 1)−1 log ε))
            R

                                                        1
                ×
                      S(y − (α +        1)−1   log ε)(1 − S(y − (α + 1)−1 log ε))
                                  S(y − (α + 1)−1 log ε)                      1
                        − (v̄ − v3 )−1
                                1 − S(y − (α + 1) log ε) h (V2 (S(y − (α + 1)−1 log ε)))
                                                  −1           H,L

                                                   !!−1
                                   1                        H,L
               + L                      −1
                                                           ψ30  (y − (α + 1)−1 log ε) dy
                   h (V2 (S(y − (α + 1) log ε)))
                                      !{α+1,α}
                         M̂ (y)                                       1
                 Z
 ∼ cε{1,α/(α+1)}                  e−y          Wi (M̂ (y))
                   R  1 − M̂ (y)                             M̂ (y)(1 − M̂(y))
                                                                                                 !!−1
                     −1        M̂ (y)           1                             1
          − (α + 1) cε                                α+1 +                                α
                             1 − M̂(y) c ε M̂ (y) e−y             c εα/(α+1) 1−M̂M̂(y)(y) e−y
                                                               1−M̂ (y)
                          {α30 ,α30 +1}/(α+1)    −{α30 ,α30 +1}y
                × c30 ε                         e               dy
                                                               !{α+1,α}
                                                M̂ (y)
                                    Z
                (α30 +β+1)/(α+1)
 ∼ −cε                                                   e−y                λi X(M̂ (y))
                                        R   1 − M̂ (y)
                                                                                        !−1
                                1           1 e(α+1)y (1 − M̂ (y))α
                ×                        −                                                     c30 e−{α30 ,α30 +1}y dy,
                     M̂ (y) (1 − M̂ (y))   α+1      (M̂ (y))α
                                                                                                                        (125)
where, by arguments used in the proof of Proposition 4.5, this asymptotic relationship
holds provided that α < 3 and 2(α + 1)/(α − 1) > α30 .




                                                                78
        Similarly,

                                                                Wi (S(y))
 Z
       GH
        0 (V2 (S(y)))                                                                                          
                                   1                               S(y)        1                      1
   R
                             S(y)(1−S(y))
                                               − (v̄ − v3 )−1     1−S(y) hH (V2 (S(y)))
                                                                                          +    hL (V2 (S(y)))
        H
     × ψ30 (y) dy
    Z
  =   GH0 (V2 (S(y − (α + 1)
                            −1
                               log ε)))
        R

                                                                                        1
        × Wi (S(y − (α + 1)−1 log ε))
                                                        S(y − (α +      1)−1 log ε)(1   − S(y − (α + 1)−1 log ε))
                             S(y − (α + 1)−1 log ε))                    1
              − (v̄ − v3 )−1
                           1 − S(y − (α + 1) log ε)) h (V2 (S(y − (α + 1)−1 log ε))))
                                            −1           H

                                              !!−1
                              1                       H
           + L                      −1
                                                     ψ30 (y − (α + 1)−1 log ε)) dy
               h (V2 (S(y − (α + 1) log ε))))
                                                                                          (126)
                           1
  Z
∼     Wi (M̂ (y))
    R              M̂(y)(1 − M̂ (y))
                                                                                            !!−1
                              M̂ (y)           1                            1
          − (α + 1)−1 cε                            α+1 +                             α
                            1 − M̂(y) c ε M̂ (y) e−y              α/(α+1)     M̂ (y)  −y
                                                               cε           1−M̂ (y)
                                                                                     e
                                                             1−M̂ (y)
            α30 /(α+1)         −α30 y
       ×ε                c30 e            dy
                                                                                                                !−1
                                                         1          1 e(α+1)y (1 − M̂(y))α
                  Z
 ∼ εα30 /(α+1)           Wi (M̂ (y))                             −
                     R                         M̂(y) (1 − M̂(y))   α+1      (M̂ (y))α
       × c30 e−α30 y dy
                                 Z
         (α30 +β−α)/(α+1)
 ∼ −ε                                    λi X(M̂ (y))
                                     R
                                                                                 !−1
                         1          1 e(α+1)y (1 − M̂ (y))α
       ×                         −                                                       c30 e−α30 y dy,
             M̂ (y) (1 − M̂ (y))   α+1      (M̂(y))α
                                                                                                                      (127)
                                                                            (α30 +β−α)/(α+1)
and the corresponding term for L state is of order o(ε                                         ) provided that α < 3
and
                             α+1              α−1
                                    > α30 >         .
                             α−1              3−α
Gathering all the terms from (117), we get that the terms (125) are asymptotically
negligible. Furthermore, for the terms (126), the senior term comes from the state H-




                                                             79
contribution, and is given by
                             Z
            (α30 +β−α)/(α+1)
       λi ε                    X(M̂ (y))
                                         R
                                                             (α+1)y                  α
                                                                                         !−1                   (128)
                        1             1 e                             (1 − M̂ (y))              −α30 y
         ×                         −                                                           ce        dy.
               M̂ (y) (1 − M̂ (y))   α+1                           (M̂(y))α

It follows from the proof of Proposition 3.11 that the comparison V10 (z) > 0 for large
v̄ − v3 is equivalent to

                                 1                         1 e(α+1)y (1 − M̂ (y))α
                                                      −                            > 0.
                    M̂ (y) (1 − M̂ (y))                   α+1      (M̂ (y))α

The claim follows.


G     Proofs of Section 5

Lemma G.1 Suppose that an agent of type θ decides to exchange information with
another agent. Then, his future expected profit will be strictly larger than if he does not
exchange information.

Proof. Let the other agent’s type density, conditional on state Y = 0, be ψ H (z). Then,
if the agent decides to exchange information, his unconditional type distribution is

             P (θ)ψ H (z − θ) + (1 − P (θ))ψ L(z − θ) = P (θ) (1 + e−z ) ψ H (z − θ).

Let also Π(τ, z) be the agent’s profit at time τ, given that his type at time τ is equal to
z. Then, if he does not exchange information, his expected utility is
                         Z T Z
                   P (θ)        hH (t, τ, z − θ) (1 + e−z ) Π(τ, z) dz dτ,
                                     t           R

where hH,L (t, τ, z − θ) is his type density at time τ given his type θ at time t and where
we have used the identity

    P (θ) hH (t, τ, z − θ) + (1 − P (θ)) hL(t, τ, z − θ) = P (θ) (1 + e−z ) hH (t, τ, z − θ) .

If he does decide to exchange information, the same argument implies that his expected
utility is                   Z       T       Z
                     P (θ)                       (hH ∗ ψ H )(z − θ) (1 + e−z ) Π(τ, z) dz dτ
                                 t           R


                                                              80
Thus, it suffices to show that
  Z                                        Z
        H      H               −z
     (h ∗ ψ )(z − θ) (1 + e ) Π(τ, z) dz ≥   hH (t, τ, z − θ) (1 + e−z ) Π(τ, z) dz .
    R                                                  R

But,
              Z
                    (hH ∗ ψ H )(z − θ) (1 + e−z ) Π(τ, z) dz
                  R
                         Z Z
                      =          hH (t, τ, z − θ − x) ψ H (x) (1 + e−z ) Π(τ, z) dx dz
                        Z R   R               Z
                             H
                      =     h (t, τ, y − θ)      ψ H (x) (1 + e−x−y ) Π(τ, x + y) dx dy,
                         R                   R

where we have used the change of variables z − x = y. Thus, it suffices to show that
               Z
                  ψ(x) (1 + e−x−y ) Π(τ, x + y) dx > (1 + e−y ) Π(τ, y).
                    R

This inequality follows from (75).




                                                 81
                                    References

Acemoglu, Daron, Munther A. Dahleh, Ilan Lobel, Asuman Ozdaglar. 2008. “Bayesian
Learning in Social Networks.” MIT Working Paper.

Aramaki, Junichi. 1983. “Complex Powers of a Class of Pseudodifferential Operators
and their Applications.” Hokkaido Mathematics Journal 12: 199-225.

Banerjee, Abhijit, and Drew Fudenberg. 2004. “Word-of-Mouth Learning.” Games and
Economic Behavior 46: 1-22.

Bikhchandani, Sushil, David Hirshleifer and Ivo Welch. 1992. “A Theory of Fads,
Fashion, Custom, and Cultural Change as Informational Cascades.” The Journal of
Political Economy 100: 992-1026.

Blouin, Max, and Roberto Serrano. 2001. “A Decentralized Market with Common
Values Uncertainty: Non-Steady States.” Review of Economic Studies 68: 323-346.

Chatterjee, Kalyan, and William Samuelson. 1983. “Bargaining Under Incomplete In-
formation.” Operations Research 31: 835-851.

Chamley, Christophe. 2004. Rational Herds: Economic Models of Social Learning.
Cambridge University Press. Cambridge UK.

DeMarzo, Peter, Dmitri Vayanos, and Jeffrey Zwiebel. 2003. “Persuasion Bias, Social
Influence, and Unidimensional Opinions.” Quarterly Journal of Economics 118: 909-
968.

Duffie, Darrell, and Gustavo Manso. 2007. “Information Percolation in Large Markets.”
American Economic Review Papers and Proceedings 97: 203-209.

Duffie, Darrell, Gaston Giroux, and Gustavo Manso. 2010. “Information Percolation.”
American Economic Journal: Microeconomics 2: 100-111 .

Duffie, Darrell, Semyon Malamud, and Gustavo Manso. 2009a. “Information Percolation
with Equilibrium Search Dynamics.” Econometrica 77: 1513-1574.

Duffie, Darrell, Semyon Malamud, and Gustavo Manso. 2009b. “The Relative Contri-
butions of Private Information Sharing and Public Information Releases to Information
Aggregation.” Journal of Economic Theory 145: 1574-1601.

                                         82
Duffie, Darrell, and Yeneng Sun. 2007. “Existence of Independent Random Matching.”
Annals of Applied Probability 17: 386-419.

Ferland, René, and Gaston Giroux. 2008. “Law of Large Numbers for Dynamic Bar-
gaining Markets,” Journal of Applied Probability 45: 45-54.

Gale, Douglas, and Shachar Kariv. 2003. “Bayesian Learning in Social Networks.”
Games and Economic Behavior 45: 329-346.

Golosov, Michael, Guido Lorenzoni, and Aleh Tsyvinski. 2008. “Decentralized Trading
with Private Information.” MIT Working Paper.

Golub, Benjamin and Matthew O. Jackson. 2010. “Naive Learning in Social Networks
and the Wisdom of Crowds.” American Economic Journal: Microeconomics 2: 112-149.

Grossman, Sanford. 1976. “On the Efficiency of Competitive Stock Markets Where
Traders Have Diverse Information.” Journal of Finance 31: 573-585.

Grossman, Sanford and Joseph Stiglitz. 1980. “On the Impossibility of Informationally
Efficient Markets.” American Economic Review 70: 393-408.

Gut, Allan. 2005. Probability: A Graduate Course, Springer. New York.

Kadan, Ohad. 2007. “Equilibrium in the Two-Player, k-Double Auction with Affiliated
Private Values.” Journal of Economic Theory 135: 495-513.

Knapp, Anthony. 2005. Basic Real Analysis, Birkhäuser. Boston.

Korevaar, Jacob. 2004. Tauberian Theory: A Century of Developments, Birkhäuser.
Heidelberg.

Krein, Mark and David Milman. 1940. “On Extreme Points of Regular Convex Sets,”
Studia Mathematica 9: 133-138.

Leininger, Wolfgang, Peter Linhart, and Roy Radner. 1989. “The Sealed-Bid Mechanism
for Bargaining with Incomplete Information.” Journal of Economic Theory 48: 63-106.

Milgrom, Paul. 1981. “Rational Expectations, Information Acquisition, and Competitive
Bidding.” Econometrica 50: 1089-1122.


                                          83
Milgrom, Paul, and Nancy Stokey. 1982. “Information, Trade and Common Knowledge,”
Journal of Economic Theory 26: 17-27.

Pesendorfer, Wolfgang and Jeroen Swinkels. 1997. “The Loser’s Curse and Information
Aggregation in Common Value Auctions.” Econometrica 65: 1247-1281.

Remenik, Daniel. 2009. “Limit Theorems for Individual-based Models in Economics and
Finance,” Stochastic Processes and their Applications 119: 2401-2435.

Reny, Philip and Motty Perry. 2006. “Toward a Strategic Foundation for Rational
Expectations Equilibrium.” Econometrica 74: 1231-1269.

Saks, Stanislaw. 1937. Theory of the integral. Hafner, New York.

Satterthwaite, Mark and Steven Williams. 1989. “Bilateral Trade with the Sealed Bid
k-Double Auction: Existence and Efficiency.” Journal of Economic Theory 48: 107-133.

Serrano-Padial, Ricardo. 2007. “On the Possibility of Trade with Pure Common Values
under Risk Neutrality.” University of Wisconsin-Madison Working Paper.

Subhankulov, Magalim Akramovich 1976. Tauberian Theorems with Remainder. Nauka,
Moscow (In Russian).

Sun, Yeneng. 2006. “The Exact Law of Large Numbers via Fubini Extension and
Characterization of Insurable Risks, ” Journal of Economic Theory 126: 31-69.

Williams, Steven. 1987. “Efficient Performance in Two Agent Bargaining.” Journal of
Economic Theory 41: 154-172.

Wilson, Robert. 1977. “Incentive Efficiency of Double Auctions.” The Review of Eco-
nomic Studies 44: 511-518.

Wolinsky, Asher. 1990. “Information Revelation in a Market With Pairwise Meetings.”
Econometrica 58: 1-23.




                                         84
