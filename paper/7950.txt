                                              




                            
                           
                           


                                           
                                            !"# 
                                           $%&$'( (


                                         "& )*&+,-.
                                 /*011%%%!#&!"&)1**&1%+,-.


                                                           
                                     2.-./ 3
                                       #& $)4 .5267
                                            "#&5...




         !"#$% & 
    '    (  ' ()   '*  +  $

,-.+ /+0. 1$ 0* 2( ($3((4%$    '
&0  &   4 0+5   & (  +   %' (( 0
 ( 4,  04%   $
                  
                       
     !   "" "#  
$%&   $ !'()*
+  ,***
$ !-.* -/0 1,.
                                    $%#%


          " 2  #  " "3 4      2   
 56           "56   2     56
 "7      576   2         " 3
   " ! 8    "     "    2  #   
                "   2        "     
$     "  2# 9  5$96!


  !                                           ! 
:                                          :     
;2  # -                                       ;2  # -   331 2
..,<!)(                                          /.).   =
-  1<*</'                                         1 2-(,<('3).**


" "#  
:     
  ";2  #
)'( 7 
  "-(0/*)
1     Introduction


    The problem of evaluating the eÂ®ectiveness of a social program or a \treatment" is a central
problem in social science and medicine. The problem of selection bias potentially arises in any
evaluation. Individuals observed participating in a program or receiving treatment often possess
diÂ®erent characteristics than an average person. Evaluating the economic return to a program
requires accounting for the non-random assignment of individuals into the treated and untreated
states.


    One popular approach for dealing with selection bias, introduced in Gronau (1974) and Heck-
man (1976), is to specify a latent index model which relates the rule for assigning individuals
to treatment to the potential treatment outcomes. The latent index has the interpretation of
the expected net utility derived from receiving treatment; individuals participate in a program
if net utility is positive (or non-negative) and do not participate if net utility is negative. This
approach is based on assumptions about error distributions and allows for dependence between
the errors in outcome and choice equations. While computationally convenient, this approach has
been criticized for its reliance on distributional assumptions and lack of robustness to departures
from normality (Goldberger (1983) and Paarsch(1984), and later work by Glynn, Laird and Rubin
(1986)).


    In response to these criticisms, recent analysts have adopted a more robust approach and have
attempted to identify and estimate various treatment parameters without imposing strong distri-
butional assumptions (see, for example, the LATE analysis of Imbens and Angrist (1994)). While
these methods are free of parametric distributional assumptions, they typically estimate only one
treatment parameter and are quite limited in the range of policy questions they can answer (Heck-
man and Vytlacil (2000b)). Further, the assumptions imposed in LATE analysis are actually
equivalent to those required to specify a nonparametric selection model (Vytlacil (1999)).


    This paper uses a latent variable framework to unite the recent treatment eÂ®ect literature with
the classical selection bias literature. We obtain simple closed-form expressions for four treatment


                                                 1
parameters of interest: the Average Treatment EÂ®ect (ATE), the eÂ®ect of Treatment on the
Treated (TT), the Local Average Treatment EÂ®ect (LATE) (Imbens and Angrist (1994)), and the
Marginal Treatment EÂ®ect (MTE) (Heckman (1997), Heckman and Vytlacil (1999, 2000a-b)). Our
analysis is motivated by the observation that despite the recent advances in Â°exible estimation of
selection models (see, for example, Ahn and Powell (1993)), simple two-step correction procedures
continue to dominate applied work on this topic (see, e.g. Tunali (2000)).


  Since robustness of estimates to maintained distributional assumptions is an important problem,
we present closed-form solutions for the four treatment parameters for non-normal models using
Â°exible speciÂ¯cations for the selection equation, allowing the error terms to follow a trivariate
Student-tv distribution. For these generalized selection models, we derive closed-form expressions
for the various treatment parameters and show how they can be consistently estimated by two-step
methods. This simple generalization allows for considerable departures from normality, and thus
oÂ®ers an alternative to the standard selection model without increasing the computational burden.


  The performance of the techniques developed in this paper are evaluated in Monte Carlo ex-
periments. These simulations reveal the Â°exibility of our approach and assess the performance
of a widely used model selection procedure due to Amemiya (1980). Using the NLSY data, we
investigate the role of self-selection into higher education and its impact on estimated returns to
schooling.


  The plan of this paper is as follows. In the next section, we present a general model of poten-
tial outcomes, and deÂ¯ne and interpret the various treatment parameters within it. In Section
3, expressions for these parameters are derived assuming fully parametric speciÂ¯cations for the
outcome and selection equations. We obtain results for the textbook selection model, and for
generalizations of this model which yield simple closed-form solutions. In Section 4, results from
some Monte Carlo experiments are presented. We report that when selection bias is an empirically
important problem, the Amemiya model selection procedure is eÂ®ective. When selection is not
a feature of the data, it is not eÂ®ective but all models produce essentially the same estimates
of treatment parameters. Section 5 estimates various average gains in post-schooling earnings



                                                2
through the receipt of some form of college education. Using data from the National Longitudinal
Survey of Youth (NLSY) we present point estimates of ATE, TT, LATE and MTE. The paper
concludes with a summary in Section 6.




2     Treatment Parameters in a Canonical Model


    Consider a model of potential outcomes:

                                          Y 1 = XÂ¯ 1 + U 1                                      (1)

                                          Y 0 = XÂ¯ 0 + U 0

                                          DÂ¤ = ZÂµ + U D :

The Â¯rst two equations denote outcome equations in two possible \states" or \sectors" (college or
non-college in our paper). Without loss of generality, we assume that the Â¯rst state indexed by the
\1" superscript represents the treated state and the \0" superscript denotes the untreated state.
Each agent is observed in only one state, so that either Y 1 or Y 0 is observed for each person,
but the pair (Y 1 ; Y 0 ) is never observed for a given person. What we would like to recover is
information about various expected gains from the receipt of treatment, where the gain is denoted
by Â¢ Â´ Y 1 Â¡ Y 0 :


    Let D(Z) denote the observed treatment decision, where D(Z) = 1 denotes receipt of treatment
and D(Z) = 0 denotes nonreceipt. The variable DÂ¤ is a latent variable which generates D(Z)
according to a threshold crossing rule,

                            D(Z) = 1[DÂ¤ (Z) Â¸ 0] = 1[ZÂµ + U D Â¸ 0];                             (2)

where 1[A] is the indicator function which takes the value 1 if the event A is true and the value
0 otherwise. In an extension of the Roy (1951) model, DÂ¤ = Y 1 Â¡ Y 0 Â¡ C, where C represents
the cost of participating in the treated state, so that agents choose to receive treatment if the
gain from participating in the program minus costs is non-negative. We also deÂ¯ne the following
counterfactual choice variables. For any z which is a potential realization of Z, we deÂ¯ne the


                                                 3
variable D(z) = 1[zÂµ Â¸ U D ]. D(z) indicates whether or not the individual would have received
treatment had her value of Z been externally set to z, holding her unobserved U D constant. We
require an exclusion restriction and denote by Zk some element of Z which is not contained in
X. By varying Zk , we can manipulate an individual's probability of receiving treatment without
aÂ®ecting potential outcomes. Finally, we assume (U D U 1 U 0 ) is independent of X and Z.


  Letting Y denote observed earnings,

                                     Y = DY 1 + (1 Â¡ D)Y 0 :                                    (3)

This model has been called the switching regression model of Quandt (1972), Rubin's model (Rubin
1978), or the Roy model of income distribution (Roy (1951), Heckman and HonorÂ¶e (1990)).1 To
illustrate how a model of this type can be applied to evaluate an interesting policy question,
consider the problem of estimating the return to a college education. In this case, Y represents
log earnings, Y 1 denotes the log earnings of college graduates and Y 0 denotes the log earnings of
those not selecting into higher education. The latent index maps people into either the \college"
(or treated) state and the \no-college" (or untreated) state. To estimate the return to college, we
might estimate the expected college log wage premium for given characteristics X; E(Y 1 Â¡Y 0 j X):2
In general, given the model described by (1) and (2), we would like to have methods for estimating
various average gains to program participation. In this paper, we examine four such treatment
parameters, which measure possibly diÂ®erent average gains to the receipt of treatment. These
four parameters are the Average Treatment EÂ®ect (ATE), the eÂ®ect of Treatment on the Treated
(TT), the Local Average Treatment EÂ®ect (LATE), and the Marginal Treatment EÂ®ect (MTE).           3




  The Average Treatment EÂ®ect (ATE) is deÂ¯ned as the expected gain from participating in the
program for a randomly chosen individual. As before, we let Â¢ Â´ Y 1 Â¡ Y 0 denote the gain from
program participation, and note that the average treatment eÂ®ect conditional on X = x can be
expressed as:

                           ATE(x) = E(Â¢ j X = x) = x(Â¯ 1 Â¡ Â¯ 0 ):                               (4)

The average treatment eÂ®ect evaluated at the random variable X is ATE(X). This deÂ¯nes the
treatment parameter as a function of the characteristics X. We can obtain unconditional estimates

                                                4
by integrating (4) over the distribution of X,
                                     Z                           n
                                                              1X
                    ATE = E(Â¢) =          ATE(X)dF (X) Â¼         ATE(xi );                      (5)
                                                              n
                                                                i=1

where n is sample size. A conceptually diÂ®erent parameter is the eÂ®ect of Treatment on the Treated
(TT). This is the average gain from treatment for those that actually select into the treatment:

          TT(x; z; D(z) = 1) = E(Â¢ j X = x; Z = z; D(z) = 1)                                    (6)

                                = x(Â¯ 1 Â¡ Â¯ 0 ) + E(U 1 Â¡ U 0 j U D Â¸ Â¡zÂµ; X = x; Z = z)

                                = x(Â¯ 1 Â¡ Â¯ 0 ) + E(U 1 Â¡ U 0 j U D Â¸ Â¡zÂµ);

where the third equality follows from the assumption that (U D U 1 U 0 ) is independent of (X; Z).
The value of the Treatment on the Treated parameter evaluated at the random variables (X; Z)
is TT(X; Z; D(Z) = 1). As with ATE, we can obtain an unconditional estimate by integrating
over the joint distribution of X and Z for those who actually receive treatment. Letting nt be the
number of observations with Di = 1, TT can be approximated as follows:

                       TT = E(Â¢jD(Z) = 1)                                                       (7)
                            Z
                          =   TT(X; Z; D(Z) = 1)dF (X; ZjD(Z) = 1)
                                    n
                                 1 X
                            Â¼         Di T T (xi ; zi ; D(zi ) = 1):
                                 nt
                                    i=1

The Local Average Treatment EÂ®ect (LATE) of Imbens and Angrist (1994) estimates an average
gain to program participation without explicitly specifying a latent variable framework or imposing
a distributional assumption.4 LATE is deÂ¯ned as the expected outcome gain for those induced to
receive treatment through a change in the instrument from Zk = zk to Zk = zk0 . The variable Zk is
assumed to aÂ®ect the treatment decision (is contained in Z in (1)), but not to aÂ®ect the outcomes
Y 1 and Y 0 . Below and throughout this paper, we deÂ¯ne the LATE parameter as a change in the
index from ZÂµ = zÂµ to ZÂµ = z 0 Âµ, where z 0 Âµ > zÂµ and z and z 0 are identical except for their kth
coordinate. Because of the latent index structure in (1) and (2), we can equivalently deÂ¯ne the
treatment parameters in terms of the propensity score, P (Z) = 1 Â¡ FU D (Â¡ZÂµ), where FS denotes




                                                  5
the cdf of the random variable S. The LATE parameter is deÂ¯ned as follows:

 LATE(D(z) = 0; D(z 0 ) = 1; X = x) = E(Â¢ j D(z) = 0; D(z 0 ) = 1; X = x)                            (8)

                                       = x(Â¯ 1 Â¡ Â¯ 0 ) + E(U 1 Â¡ U 0 j Â¡z 0 Âµ Â· U D Â· Â¡zÂµ; X = x)

                                       = x(Â¯ 1 Â¡ Â¯ 0 ) + E(U 1 Â¡ U 0 j Â¡z 0 Âµ Â· U D Â· Â¡zÂµ);

where the third equality follows from the assumption that (U D U 1 U 0 ) is independent of (X; Z).
There are two ways to deÂ¯ne the unconditional version of LATE. First, consider
                                          Z
                              0
            E(Â¢jD(z) = 0; D(z ) = 1) =       LATE(D(z) = 0; D(z 0 ) = 1; X)dF (X)                    (9)
                                                      n
                                                 1X
                                         Â¼             LATE(D(z) = 0; D(z 0 ) = 1; xi ):
                                                 n i=1

The parameter E(Â¢jD(z) = 0; D(z 0 ) = 1) corresponds to the treatment eÂ®ect for individuals who
would not select into treatment if their vector Z was set to z but would select into treatment
if Z was set to z 0 . An alternative deÂ¯nition of the unconditional version of LATE is as follows.
Let Z 0 (Z) equal Z but with the kth element replaced by zk . Let Z 1 (Z) equal Z but with the
kth element replaced by zk0 . In this notation the second deÂ¯nition of the unconditional version of
LATE,
                                             Z
           0               1
 E(Â¢jD(Z (Z)) = 0; D(Z (Z)) = 1) =                LATE(D(Z 0 (Z)) = 0; D(Z 1 (Z)) = 1; X)dF (X; Z)
                                                  n
                                             1X
                                        Â¼          LATE(D(Z 0 (zi )) = 0; D(Z 1 (zi )) = 1; xi ):   (10)
                                             n i=1

This parameter corresponds to the treatment eÂ®ect for individuals who would not select into
treatment if the kth component of the Z vector is set to zk (all other components of Z unchanged)
but would select into treatment if the kth component of the Z vector is set to zk0 (all other
components of Z unchanged).


  The Marginal Treatment EÂ®ect (MTE) (Heckman (1997), Heckman and Smith (1998), Heckman
and Vytlacil (1999, 2000a-b)) is the treatment eÂ®ect for individuals with a given value of U D ,

                 MTE(x; uD ) = E(Â¢jX = x; U D = uD )                                                (11)

                                = x(Â¯ 1 Â¡ Â¯ 0 ) + E(U 1 Â¡ U 0 j U D = uD ; X = x)

                                = x(Â¯ 1 Â¡ Â¯ 0 ) + E(U 1 Â¡ U 0 j U D = uD )

                                                      6
where the third equality follows from the assumption that (U D U 1 U 0 ) is independent of X.
Evaluation of the MTE parameter at low values of uD averages the outcome gain for those with
unobservables making them least likely to participate, while evaluation of the MTE parameter
at high values of uD is the gain for those individuals with unobservables which make them most
likely to participate. Since X is independent of U D , the MTE parameter unconditional on observed
covariates can be written as
                                  Z                             n
                            D                                1X
                     MTE(u ) =        MTE(X; uD )dF (X) Â¼       MTE(xi ; uD ):
                                                             n
                                                               i=1
The MTE parameter can also be expressed as the limit form of the LATE parameter,

 lim LATE(x; D(z) = 0; D(z 0 ) = 1) = x(Â¯ 1 Â¡ Â¯ 0 ) + lim0 E(U 1 Â¡ U 0 j Â¡z 0 Âµ Â· U D Â· Â¡zÂµ; X = x)
zÂµ!z0 Âµ                                                    zÂµ!z Âµ

                                        = x(Â¯ Â¡ Â¯ ) + E(U Â¡ U 0 j U D = Â¡z 0 Âµ)
                                               1       0       1


                                        = MTE(x; Â¡z 0 Âµ):

Thus the MTE parameter measures the average gain in outcomes for those individuals who are
just indiÂ®erent to the receipt of treatment when the zÂµ index is Â¯xed at the value Â¡uD .


    The four parameters deÂ¯ne diÂ®erent average gains to program participation if U D is not (mean)
independent of U 1 Â¡U 0 but the four parameters are identical if U D is mean independent of U 1 Â¡U 0
conditional on X = x. In this paper, we derive closed-form solutions and simple estimators
for these four parameters given certain distributional assumptions for the error terms. These
expressions enable researchers to obtain estimates of the various treatment eÂ®ects using simple
methods.




3     Simple Expressions for the DiÂ®erent Treatment Parameters


    This section derives expressions for ATE, TT, LATE, and MTE as given in (4) - (11) us-
ing two diÂ®erent assumptions regarding the distribution of the unobservables. Estimates of the
treatment parameters can be obtained by using the output from a two-step procedure. We begin
with the textbook selection model5 and then present Â°exible non-normal models that possess the
computational simplicity of the normal model.

                                                   7
3.1   Results for the \Textbook" Model



We Â¯rst present expressions for the textbook normal model:
                           2 D 3         0 2                  31
                              U                  1 Â¾1D Â¾0D
                           4 U 1 5 Â» N @0; 4 Â¾ 1D Â¾21 Â¾10 5A :
                              U0               Â¾ 0D Â¾ 10 Â¾ 20
The variance parameter in the selection equation is normalized to unity without loss of generality.
For all of the values of the parameters, ATE reduces to the form given in (4). Under the normality
assumption, the expression for Treatment on the Treated (TT) is:
                                                                             Ã(zÂµ)
                     TT(x; z; D(z) = 1) = x(Â¯ 1 Â¡ Â¯ 0 ) + (Â½1 Â¾1 Â¡ Â½0 Â¾0 )         ;
                                                                             Â©(zÂµ)
where Â½i Â´ Corr(U i ; U D ); i = 0; 1: Under the normalization that the variance of the disturbance
term in the selection equation is unity, Â½i Â¾i = Â¾iD : As previously noted, under independence
between U D and (U 1 Â¡U 0 ) all treatment parameters are the same. Thus, if Cov(U 1 Â¡U 0 ; U D ) = 0,
or Â½1 Â¾1 = Â½0 Â¾0 , Treatment on the Treated reduces to ATE in (4). In this case, people are not
selecting into program on the basis of their unobserved (by the econometrician) gain, and all the
treatment parameters reduce to ATE. If Cov(U 1 Â¡ U 0 ; U D ) > 0, then TT > ATE: If this condition
is true, people are selecting into treatment on the basis of their idiosyncratic gain to treatment,
and thus the gain from program participation for those observed in the treated state will exceed
the gain for the average person. Also note that as zÂµ ! 1, TT ! ATE. In this case, the
probability of receiving treatment is one given the observable characteristics Z = z and thus there
is no selection problem. In this case, the conditioning information D = 1 is redundant given the
characteristics Z = z and thus the two parameters in (4) and (6) are equal.


  Using standard results (see e.g. Cramer (1946) or Johnson, Kotz and Balakrishnan (1992)), the
LATE parameter can easily be derived using the fact that if (y; z) Â» N(Â¹y ; Â¹z ; Â¾y ; Â¾z ; Â½) and b > a
                                                     Âµ               Â¶
                                                       Ã(Â®) Â¡ Ã(Â¯)
                       E(y j a Â· z Â· b) = Â¹y + Â½Â¾ y                    ;
                                                       Â©(Â¯) Â¡ Â©(Â®)
where Â® = (a Â¡ Â¹z )=Â¾z , Â¯ = (b Â¡ Â¹z )=Â¾z , so

         LATE(x; D(z) = 0; D(z 0 ) = 1) = E(Y1 Â¡ Y0 j x; zÂµ < U D < z 0 Âµ))
                                                                           Ã(z 0 Âµ) Â¡ Ã(zÂµ)
                                        = x(Â¯ 1 Â¡ Â¯ 0 ) + (Â½1 Â¾1 Â¡ Â½0 Â¾0 )                  :     (12)
                                                                           Â©(z 0 Âµ) Â¡ Â©(zÂµ)

                                                  8
The Marginal Treatment EÂ®ect

               MT E(x; uD ) = x(Â¯ 1 Â¡ Â¯ 0 ) + E(U 1 Â¡ U 0 jU D = uD )

                                 = x(Â¯ 1 Â¡ Â¯ 0 ) + E(U 1 jU D = uD ) Â¡ E(U 0 jU D = uD )

                                 = x(Â¯ 1 Â¡ Â¯ 0 ) + (Â½1 Â¾1 Â¡ Â½0 Â¾ 0 )uD :

It is the limit form of LATE,    6

                                                                 Â·      Â¸
                D            1       0                   Ã(Â¡uD ) Â¡ Ã(t)
      MT E(x; u ) = x(Â¯ Â¡ Â¯ ) + (Â½1 Â¾ 1 Â¡ Â½0 Â¾ 0 ) lim                                (13)
                                                  t!Â¡uD Â©(Â¡uD ) Â¡ Â©(t)
                                                       "Â¡                Â¢          #
                       1   0                              Ã(Â¡uD ) Â¡ Ã(t) =(Â¡uD Â¡ t)
                  = x(Â¯ Â¡ Â¯ ) + (Â½1 Â¾ 1 Â¡ Â½0 Â¾ 0 ) lim
                                                  t!Â¡uD (Â©(Â¡uD ) Â¡ Â©(t)) =(Â¡uD Â¡ t)

                     = x(Â¯ 1 Â¡ Â¯ 0 ) + (Â½1 Â¾ 1 Â¡ Â½0 Â¾ 0 )uD :

Evaluating MTE when uD is large corresponds to the case where the average outcome gain is
evaluated for those individuals with unobservables making them most likely to participate, (and
conversely when uD is small). When uD = 0, MTE = ATE as a consequence of the symmetry of
the normal distribution. We next consider non-normal models.



3.2   Extensions to Non-Normal Models



   We Â¯rst note that the trivariate normal case presented in the previous section can be generalized
by exploiting the natural Â°exibility of the selection equation. In the latent variable framework, the
selection rule assigns people to the treated state (Di = 1) provided UiD Â¸ Â¡Zi Âµ: This is equivalent
to setting Di = 1 when J(UiD ) Â¸ J(Â¡Zi Âµ) for some strictly increasing function J:7


  Suppose that U D Â» F , where F is an absolutely continuous distribution function which can
be non-normal. For simplicity assume symmetry of U D about zero so that F (Â¡a) = 1 Â¡ F (a).
                                                                                         ~D Â´
This model trivially maps into an equivalent model where the normal results apply. DeÂ¯ne U
JÂ© (U D ); and let JÂ© (u) Â´ Â©Â¡1 F (u): Clearly, JÂ© is left-continuous and strictly increasing and
                                                                              ~ D , is easily
JÂ© (Â¡u) = Â¡JÂ© (u) given the assumed symmetry of F . The transformed variable, U
seen to be a standard normal random variable. Thus, the original model in (1) is equivalent to


                                                     9
the transformed model:

                                          Y 1 = XÂ¯ 1 + U 1

                                          Y 0 = XÂ¯ 0 + U 0                                                 (14)
                                                          ~D
                                         DiÂ¤Â¤ = JÂ© (ZÂµ) + U

                                                       ~D ; U 1 ; U 0 ]0 is trivariate normal so we
where we now assume that the transformed error vector [U
can again use the normal framework. We thus obtain the following selection-corrected conditional
mean functions:

                                                                             Ã (JÂ© (zÂµ))
                     E(Y 1 j D(Z) = 1; X = z; Z = z) = xÂ¯ 1 + Â½1 Â¾ 1                     ;                (15a)
                                                                                F (zÂµ)

and

                                                                              Ã (JÂ© (zÂµ))
                     E(Y 0 j D(Z) = 0; X = x; Z = z) = xÂ¯ 0 Â¡ Â½0 Â¾0                       ;               (15b)
                                                                              1 Â¡ F (zÂµ)

and obtain the treatment parameters:8

                                                                             Ã (JÂ© (zÂµ))
                  T T (x; z; D(z) = 1) = x(Â¯ 1 Â¡ Â¯ 0 ) + (Â½1 Â¾1 Â¡ Â½0 Â¾ 0 )               ;                 (16)
                                                                                F (zÂµ)


                                                                         Ã (JÂ© (z 0 Âµ)) Â¡ Ã (JÂ© (zÂµ))
   LAT E(x; D(z) = 0; D(z 0 ) = 1) = x(Â¯ 1 Â¡ Â¯ 0 ) + (Â½1 Â¾1 Â¡ Â½0 Â¾0 )                                 ;    (17)
                                                                             F (z 0 Âµ) Â¡ F (zÂµ)

and

                       MT E(x; uD ) = x(Â¯ 1 Â¡ Â¯ 0 ) + (Â½1 Â¾1 Â¡ Â½0 Â¾ 0 )JÂ© (uD ):                           (18)

If F = Â©, we obtain the normal model presented in Section 3.1. This model trivially generalizes
the trivariate normal model and is applicable if there is concern that the errors in the selection
equation are non-normal. All the parameters necessary for estimation of the treatment parameters
for given x and z can be consistently estimated using a standard two-step procedure.


  A less straightforward generalization can be achieved if we follow Lee (1982, 1983) and allow
the error terms in (1) or (14) to be jointly distributed according to the Student-tv distribution.
By varying the degrees of freedom parameter, v, he produces a Â°exible class of models which
can depart quite signiÂ¯cantly from the textbook normal case. Since many of these parameters

                                                     10
are deÂ¯ned in terms of the tail behavior of the error terms, the family of tv distributions oÂ®ers
a very attractive and potentially more appropriate class of models for the treatment parameters
than those implied by the benchmark normal model, especially since wage data tend to be fat
tailed (see e.g. Lydall (1968)).9 We are able to obtain closed-form expressions for the various
treatment parameters in the Student-tv case, and can also estimate these expressions using output
from simple two-step procedures.


  Let tv (Â¹; -) denote the multivariate Student-tv density function with mean Â¹, scale matrix -
(variance equal to [v=(v Â¡ 2)]-Â¡1 ) and v degrees of freedom.10 We retain the notation used to
deÂ¯ne the covariance matrix for the normal model, and parameterize the scale matrix - in the
same fashion. Finally, let tv denote the standardized univariate Student tv density with mean 0
and scale parameter equal to 1, and let Tv denote the associated cdf. To obtain expressions for
the treatment parameters and derive the appropriate two-step estimators, we need to evaluate the
truncated mean E(U D j U D > Â¡u) when U D has a univariate tv distribution. As shown in RaiÂ®a
and Schlaifer (1961) if U D Â» tv ,
                                                        Âµ            Â¶
                                 D        D                 v + u2       tv (u)
                           E(U       jU       > Â¡u) =                           ;   v > 1:                             (19)
                                                             vÂ¡1         Tv (u)
   Using this result, now derive the treatment parameters for the more general model. To ensure
     ~ D has a tv density in the general case when U D Â» F , we deÂ¯ne JTv (u) Â´ TvÂ¡1 (F (u)); again
that U
                                                                                  ~ D ; U 1 ; U 0 ]0
noting that JTv (Â¡u) = Â¡JTv (u): We then assume that for this transformed model, [U
has a trivariate tv (0; -) density. Given (19), we obtain the selection-corrected conditional mean
functions:
                                                              Â·Âµ                     Â¶Âµ                      Â¶Â¸
                                                                   v + [JTv (zÂµ)]2         tv (JTv (zÂµ))
      E(Y 1 j D(Z) = 1; X = x; Z = z) = xÂ¯ 1 + Â½1 Â¾1                                                              ;   (20a)
                                                                       vÂ¡1                     F (zÂµ)
and
                                                              Â·Âµ                      Â¶Âµ                     Â¶Â¸
          0                                       0                v + [JTv (zÂµ)]2           tv (JTv (zÂµ))
      E(Y j D(Z) = 0; X = x; Z = z) = xÂ¯ Â¡ Â½0 Â¾0                                                                  :   (20b)
                                                                       vÂ¡1                    1 Â¡ F (zÂµ)
For convenience in notation, deÂ¯ne the following function:
                                        Âµ                Â¶
                                          v + [JTv (u)]2
                              g(u; v) Â´                    tv (JTv (u)):
                                              vÂ¡1
In this notation, the following expressions for the three treatment eÂ®ects are easily derived:11
                                                                                    g(zÂµ; v)
                   T T (x; z; D(z) = 1) = x(Â¯ 1 Â¡ Â¯ 0 ) + (Â½1 Â¾1 Â¡ Â½0 Â¾0 )                   :                         (21)
                                                                                     F (zÂµ)

                                                        11
                                                                           g(z 0 Âµ; v) Â¡ g(zÂµ; v)
      LAT E(x; D(z) = 0; D(z 0 ) = 1) = x(Â¯ 1 Â¡ Â¯ 0 ) + (Â½1 Â¾1 Â¡ Â½0 Â¾0 )                          :   (22)
                                                                            F (z 0 Âµ) Â¡ F (zÂµ)


                     MT E(x; uD ) = x(Â¯ 1 Â¡ Â¯ 0 ) + (Â½1 Â¾1 Â¡ Â½0 Â¾0 )JTv (uD ):                        (23)

For a given function F , the Student-tv case converges to the case previously analyzed as v ! 1,
since the tv density and cdf approach the normal for large v and thus the term in parentheses in
the deÂ¯nition of g(u; v) approaches one as v ! 1: The diÂ®erence in the expressions for the various
treatment parameters across the normal and Student-tv cases is determined by the diÂ®erence in
the selection correction terms. In the textbook normal model, these are the well-known Mills ratio
terms, while in the Student-tv case, these terms take the form g(zÂµ; v)=F (zÂµ) and g(zÂµ; v)=(1 Â¡
                                              ~D j U
F (zÂµ)): Figure 1 plots the truncated means E(U    ~ D > Â¡J(u)). The plots are labeled in the

Â¯gure according to how J and the outcome variables are constructed. The Â¯rst argument refers
                                                       ~ D , while the second argument following
to the distribution assigned to the outcome errors and U
the \/" refers to the choice of link function (i.e., the J function). In the \normal / normal" case,
J(u) = JÂ© (u) = Â©Â¡1 Â©(u) = u; and the truncated mean reduces to the standard Mills ratio term:
                                                          Â¡1
Ã(u)=Â©(u): In the tv=2 / normal case, J(u) = JTv=2 (u) = Tv=2 (Â©(u)); and the truncated mean
reduces to the expression used in (15a) and (15b).


The general models are quite Â°exible; the tv=2 (or other low values v) results can depart quite
signiÂ¯cantly from the benchmark normal case and could produce treatment parameter estimates
which are quite diÂ®erent from those obtained using normal errors. For large v, the results obtained
are quite similar to those obtained for the normal case, as expected. In the following subsection,
we present consistent estimators of the parameters of the models.



3.3   Estimation



A general recipe for obtaining two-step estimators of the various treatment parameters is as follows:



  1. Obtain ^
            Âµ from a binary choice model using F as the distribution of U D .


                                                  12
    2. Compute the appropriate selection correction terms evaluated at ^Âµ. In the classical normal
       selection model, these terms are Ã(Zi ^Âµ)=Â©(Zi ^Âµ) when Di = 1, and Ã(Zi ^Âµ)=(1 Â¡ Â©(Zi ^Âµ)) when
       Di = 0: For the generalized models, the corresponding terms to be used are in (15a-b) or
       (20a-b).

    3. Run treatment-outcome-speciÂ¯c regressions (for the groups fi : Di = 1g and fi : Di = 0g)
       with the inclusion of the appropriate selection-correction terms obtained from the previous
       step.

             ^0; Â¯
    4. Given Â¯   ^ 1 ; Â½1^Â¾1 and Â½0^Â¾0 obtained from step 3 and ^Âµ from step (1), use these parameter

       estimates to obtain point estimates of the treatment parameters for given X, Z, and Z 0 .12
       Standard errors can be obtained using the Delta method or the parametric bootstrap, as
       discussed below in Section 5.




4     Monte Carlo Simulations


    In this section we assess the performance of a simple model selection procedure and also assess
the performance of our treatment parameter estimators under correct and incorrect model spec-
iÂ¯cation. We obtain sampling distributions of the estimators of diÂ®erent treatment parameters
using both generated normal and Student-tv data. We show that the diÂ®erent models discussed
in Section 3 can give diÂ®erent estimates of the various treatment eÂ®ects. Further, we demonstrate
the intuitively plausible result that our ability to correctly diÂ®erentiate among competing models
is increasing in the sample size and the degree of selectivity in the model.


    The model that we employ in the experiments below is a basic selection model with few covari-
ates, given as follows:

                                       Y 1 = Â®1 + Â®2 + U 1                                        (24)

                                       Y 0 = Â®1 + U 0

                                       DÂ¤ = Âµ0 + Âµ1 Z + U D :                                     (25)



                                                  13
We generate the data by setting Â®1 = 2; Â®2 = 1, Âµ0 = 0, Âµ 1 = 1, and Z Â» N(0; 1): With this
structure, the average treatment eÂ®ect is Â®2 = 1: For the Â¯rst experiment we obtain a data set with
1,500 observations by drawing the error term vector from a trivariate normal distribution. Given
these draws, we determine the individuals' treatment choice, and given this choice, calculate the
observed value of y. For each simulated data set, we estimate the Marginal Treatment EÂ®ect and
Treatment on the Treated for various values of Z and uD . To introduce selection bias, the data are
drawn such that Â½1D = :95, Â½0D = :1, We choose Var(U 1 ) = Var(U 0 ) = :4, normalize Var(U D ) = 1,
and set the unidentiÂ¯ed correlation coeÂ±cient between Y 1 and Y 0 equal to 0. New data sets are
drawn 1,000 times given the speciÂ¯cation and parameter values above, and for each iteration,
values for the above treatment parameters are obtained and stored. Sampling distributions of
these treatment parameters are then estimated by kernel smoothing the resulting 1,000 parameter
estimates. Results obtained from the true model (the normal model) are compared with those
obtained using the misspeciÂ¯ed, heavy-tailed trivariate t2 model in Figures 2 and 3.


  In Figures 2 and 3, we see that the sampling distributions are centered around the correct
values when the normal model is appropriate while the heavy-tailed t2 misses the mark, and often
places extremely small weight near the true values. Although not shown in the two Â¯gures, the
degree of discrepancy between the normal and t2 models increases as the parameter of interest
moves farther into the tail of the distribution. For example, if the parameter of interest is MTE
with uD = 2; then the distribution of MTE associated with the t2 model places virtually no
mass on the correct values. In Figures 4 and 5, the same experiment is run, except the data are
generated from a trivariate t4 distribution. We then compare results from the true t4 model to
those obtained from the misspeciÂ¯ed normal model. Again we see that the true model outperforms
the misspeciÂ¯ed model, and the normal results generally place small mass around the true value.
Thus for parameters of interest such as TT and MTE, which are deÂ¯ned in the tails, the normal
and Student-tv results can give quite diÂ®erent predictions. Given this result, it is of some interest
to present a way for choosing among competing models.


  A simple model selection procedure (given equal numbers of parameters across the various
models) is to obtain estimates of the selection-corrected conditional mean functions for a variety



                                                 14
of competing models and then select the one which minimizes the sum of squared residuals (SSR).
This approach to model selection chooses the model whose conditional mean function provides
the best Â¯t to the observed data (Amemiya, (1980)). Formally, we choose the model m which
minimizes the criterion:
                  n
                  X
                        [(yi Â¡ Di m(X                           ^ i ; Zi j Di = 0)]2 ;
                                  ^ i ; Zi j Di = 1) Â¡ (1 Â¡ Di )m(X
                  i=1

      ^ i ; Zi j Di = 1) corresponds to the estimated selection-corrected conditional mean
where m(X
                                   ^ i ; Zi j Di = 0) corresponds to this conditional mean function
function in the treated state, and m(X
in the untreated state.


  Several Monte Carlo experiments were conducted to examine the performance of this model
selection procedure. We generated 1,000 data sets of sizes 50, 250, 500 and 1,000 and determined
the probability of choosing the correct model for each sample size. These results are presented in
Figure 6. The data are generated from a normal distribution, and we carry along the t2 model as
a competitor to the normal model. The experiments are repeated for three diÂ®erent correlation
structures, each depicting varying degrees of the importance of selection bias.


  The performance of the proposed model selection procedure improves with the sample size n,
and also with the degree of selectivity in the model. With little role for selection bias, it is diÂ±cult
to diÂ®erentiate among the models, even with a fairly large sample size. However, distinguishing
among the models may not be important in this case, since our treatment parameter estimates will
be similar in the absence of selection bias, and controlling for self-selection may not be important
to the evaluation of the given program. The results displayed in Figure 6 also suggest that one
can assess the degree of conÂ¯dence about the ability to diÂ®erentiate among the competing models
by investigating the empirical importance of selectivity. When selectivity is most important, the
models discussed here will give diÂ®erent estimates of the treatment parameters. It is reassuring
that our Monte Carlo analysis suggests that we can diÂ®erentiate among these models using our
MSE criterion given a reasonable sample size. When selectivity is not an important feature of the
data, treatment parameter estimates across these models will be similar, and thus the problem of
model selection is not important. For intermediate cases, where one is not conÂ¯dent about the
ability to choose among competing models, yet estimates of the treatment parameters diÂ®er across

                                                   15
the models, one could place bounds on the treatment parameter estimates within the Â°exible class
of models described in this paper.




5     The Returns to College


We next present estimates of the return to some form of college education using our Â°exible scheme.
The problem of selection bias has long been recognized as important in assessing the returns to
education (see, for example Willis and Rosen (1979)). We seek to provide robust yet simple
estimates for various returns to schooling while controlling for self-selection into higher education.
Data are taken from the National Longitudinal Survey of Youth (NLSY). In our analysis, Y 1
denotes the log of 1991 hourly earnings for those individuals completing at least 13 years of
schooling by 1991, and Y 0 is the log of hourly wages for those with 12 or fewer years of schooling.
The sample is restricted to white males who are not enrolled in school in the current year and
report hourly earnings between $1 and $100. Observations are also deleted when other explanatory
variables used in the analysis are missing, resulting in a Â¯nal sample of 1,230 observations.


    The variables in X include an intercept, two indicators for residence in the Northeast and
South,13 potential labor market experience and its square,14 an indicator for residence in an urban
area, the local unemployment rate in 1990, and a measure of \ability" denoted as g. This ability
measure is constructed from the 10 component tests of the ASVAB (Armed Services Vocational
Aptitude Battery) provided in the NLSY. Since people vary in age at the time of the test, each
component test is Â¯rst regressed on age. The residuals from this regression are then standardized,
and g is deÂ¯ned as the Â¯rst principal component of the standardized residuals.15 We choose
a parsimonious speciÂ¯cation for the variables in the selection equation (Z), which includes an
intercept, g, indicator variables denoting if the respondent's mother and father attended college,
an indicator for residence in an urban area at age 18 and number of siblings. The last variable
serves as our exclusion restriction and is assumed to aÂ®ect the college entry decision without
aÂ®ecting post-schooling earnings.16




                                                 16
  We obtain estimates of the four treatment parameters discussed in this paper using a variety of
models. These include the \textbook" normal model, Student-tv models with a logit link function,
and Student-tv models with a Tv link function. For the Student-tv cases, results are obtained for
v 2 f2; 3; 4; 5; 6; 8; 12; 24g: For small values of v, results could potentially be quite diÂ®erent from
those obtained from the normal model.


  Point estimates of the Average Treatment EÂ®ect (ATE) are obtained by averaging the conditional
treatment eÂ®ects (given X) over the sample distribution of characteristics, as in equation (5). For
Treatment on the Treated, point estimates are obtained as in (7) by averaging over the joint
distribution of characteristics (given X and Z) for the subsample that actually selects into college.
To estimate LATE, we average over the joint distribution of characteristics after setting the number
of siblings variable in Z = z equal to four, and equal to 0 in Z = z 0 (this is the second form of
the unconditional LATE parameter previously discussed). This estimates the average college
log wage premium for persons induced to attend college when the number of siblings has been
lowered from four to zero. Finally, for each value of U D , we construct the Marginal Treatment
EÂ®ect parameter not conditioning on observable characteristics by averaging MTE(X; uD ) over
the sample distribution of X characteristics. We plot the resulting Marginal Treatment EÂ®ect
(MTE) parameter over values of U D from -3 to 3 in Figure 7. Point estimates of the treatment
parameters are scaled by the diÂ®erence in average years of schooling across the college and no-
college groups (Â¼ 3:8) to estimate the return to schooling. Large sample standard errors of the
estimated treatment parameters are computed using the parametric bootstrap.17


  Point Estimates of ATE, TT and LATE across the alternative models are presented in Table
1 of the appendix. We Â¯rst see that the receipt of some form of college education tends to raise
the hourly wage of a randomly selected person by 6-9 percent. For those who actually select into
college, the results are lower, ranging from 2.8-4 percent. Point estimates of LATE are similar to
ATE, and range from 5.3-7.9 percent. The similarity between LATE and ATE results from the fact
that the change from 4 to 0 siblings does not signiÂ¯cantly alter the propensity score, and thus this
treatment parameter is very similar to the Average Treatment EÂ®ect. Figure 7 presents a plot of
the MTE over the interval [-3,3] across a variety of models. As the degrees of freedom parameter



                                                  17
increases, the estimated MTE tends to approach what is obtained from the benchmark normal
case. Further, the average treatment eÂ®ects are obtained for the special cases where uD = 0. The
upward slope of the plots indicates that those individuals with unobservables making them least
likely to attend college receive the highest percent increase in hourly wages, due to a negative
selection eÂ®ect. For the best-Â¯tting normal model, we test and reject (with a t-statistic equal to
-2.1) the hypothesis of a constant MTE Cov(U D ; U 1 Â¡ U 0 ) = 0, and conclude that selection is
an important feature of this data. Marginal entrants get lower returns than those who precede
them in attending college. Similar results are reported in Carneiro, Hansen, Heckman and Vytlacil
(2000). The methods used here are easily implemented and can be applied to robustly estimate
or bound a variety of policy-relevant average gains to program participation in the presence of
selectivity bias.




6     Conclusion


     This paper presents simple expressions for the parameters often used to evaluate the eÂ®ec-
tiveness of a given program or treatment: the Average Treatment EÂ®ect (ATE), the eÂ®ect of
Treatment on the Treated (TT), the Local Average Treatment EÂ®ect (LATE), and the Marginal
Treatment EÂ®ect (MTE). These expressions were obtained for the \textbook" selection model,
and also for generalizations of this model which enable departures from normality. The appeal
of our approach is that practitioners can obtain consistent estimates of these parameters using a
two-step estimator or a simple generalization of that estimator.


    The modern approach to program evaluation focuses on the estimation of narrowly deÂ¯ned
parameters without having to impose strong distributional assumptions. The approach adopted in
this paper permits estimation of a variety of policy-relevant parameters as well as estimation of the
four treatment eÂ®ects listed above, rather than one or the other parameters featured in the recent
treatment eÂ®ect literature. We provide generalized yet computationally simple alternatives to the
often-used and often criticized normal model. The approach presented in this paper maintains the
Â°exibility of the structural model in terms of the number of parameters which we can estimate,


                                                 18
while relaxing the dependence on normality assumptions.


  The methods presented in this paper are applied to estimate the returns to a college education.
Using data from the NLSY, we obtain point estimates of ATE, TT, LATE, and MTE using both
the two-step procedure and generalized two-step methods. The results suggest that for the Â°exible
class of models analyzed, a college education raises hourly wages from 6-9 percent for a randomly
selected person, and between 2.8-4 percent for those actually selecting into higher education.




                                               19
7      Derivation of MTE: Student-tv Case


     Using the notation of Section 3.2, let JTv (x) = TvÂ¡1 (F (x)): Note the following results:

                                                                                   f(x)
                    t0v (x) = Â¡(v + 1)x(v + x2 )Â¡1 tv (x) and JT0 v (x) =                   :       (A-1)
                                                                               tv (JTv (x))

The last statement follows by noting

                                            Tv (JTv (x)) = F (x):

By the chain rule,

                              @Tv (JTv (x))   @Tv (JTv (x)) @JTv (x)
                                            =                        = f(x);
                                   @x          @JTv (x)       @x

so

                                           @JTv (x)       f(x)
                                                    =              :
                                             @x       tv (JTv (x))

Consider limzÂµ!z 0 Âµ LATE(D(z) = 0; D(z 0 ) = 1; X = x),

                                                           g(z 0 Âµ; v) Â¡ g(zÂµ; v)
                     x(Â¯ 1 Â¡ Â¯ 0 ) + (Â½1 Â¾1 Â¡ Â½0 Â¾0 ) lim0
                                                    zÂµ!z Âµ F (z 0 Âµ) Â¡ F (zÂµ)
                                                            (g(z 0 Âµ; v) Â¡ g(zÂµ; v))=(z 0 Âµ Â¡ zÂµ)
                 = x(Â¯ 1 Â¡ Â¯ 0 ) + (Â½1 Â¾1 Â¡ Â½0 Â¾0 ) lim0
                                                    zÂµ!z Âµ    (F (z 0 Âµ) Â¡ F (zÂµ))=(z 0 Âµ Â¡ zÂµ)
                                                    @g(zÂµ; v)=@zÂµ
                 = x(Â¯ 1 Â¡ Â¯ 0 ) + (Â½1 Â¾1 Â¡ Â½0 Â¾0 )                  ;
                                                        f(zÂµ)

since the limits exist and equal the derivatives of g (with respect to its Â¯rst argument) and F .
With g(zÂµ; v) deÂ¯ned as below(20), it follows that

                @g(zÂµ; v)   v + JT2v (zÂµ) @tv (JTv (zÂµ)) 2JTv (zÂµ) @JTv (zÂµ)
                          =                             +                    tv (JTv (zÂµ)):
                  @zÂµ          vÂ¡1             @zÂµ        vÂ¡1        @zÂµ

Substituting the two results in (A-1) above and canceling terms, and using the relationship between
MTE and the limit of the LATE parameter, we obtain

                          MT E(x; uD ) = x(Â¯ 1 Â¡ Â¯ 0 ) + (Â½1 Â¾1 Â¡ Â½0 Â¾0 )JTv (uD );

as claimed.



                                                      20
References

 [1] Ahn, Hyungtaik and James Powell, \Semiparametric Estimation of Censored Selection Models
    with a Nonparametric Selection Mechanism," Journal of Econometrics 58 (1993), 3-29.

 [2] Amemiya, Takeshi, \Selection of Regressors," International Economic Review 21 (1980),
    331-354.

 [3] Amemiya, Takeshi, Advanced Econometrics (Cambridge: Harvard University Press, 1985).

 [4] Carneiro, Pedro, Karsten Hansen, James Heckman and Edward Vytlacil, \Marginal Treat-
    ment EÂ®ects and the Returns to Schooling," forthcoming, 2000.

 [5] Cawley, John, Karen Coneely, James Heckman and Edward Vytlacil, \Cognitive Ability,
    Wages, and Meritocracy," in Devlin, Bernie, Stephen E. Fienberg, Daniel P. Resnick and
    Kathryn Roeder, (eds.), Intelligence, Genes and Success: Scientists Respond to the Bell Curve
    (New York: Springer, 1997), 178-192.

 [6] Cramer, Harold, Mathematical Methods of Statistics (Princeton: Princeton University Press,
    1946).

 [7] Glynn, Robert, Nan Laird and Donald Rubin, \Selection Models Versus Mixture Modeling
    with Nonignorable Nonresponse," in Wainer, Howard, (ed.), Drawing Inference from Self-
    Selected Samples (New York: Springer, 1986).

 [8] Goldberger, Arthur, \Abnormal Selection Bias," in Karlin, Samuel, Takeshi Amemiya and
    Leo Goodman, (eds.), Studies in Econometrics, Time Series, and Multivariate Statistics (New
    York: Academic Press, 1983).

 [9] Gronau, Reuben, \Wage Comparisons - A Selectivity Bias," Journal of Political Economy
    82:6 (1974), 1119-1143.

[10] Heckman, James, \The Common Structure of Statistical Models of Truncation, Sample Se-
    lection, and Limited Dependent Variables and a Simple Estimator for Such Models," Annals
    of Economic and Social Measurement 5 (1976), 475-492.



                                              21
[11] Heckman, James, \Instrumental Variables: A Study of Implicit Behavioral Assumptions Used
    in Making Program Evaluations," Journal of Human Resources 32 (1997), 441-462.

[12] Heckman, James and Bo HonorÂ¶e, \The Empirical Content of the Roy Model," Econometrica
    50 (1990), 1121-1149.

[13] Heckman, James and JeÂ®rey Smith, \ Evaluating the Welfare State," in Strom, S. (ed.),
    Econometrics and Economic Theory in the 20th Century: The Ragnar Frisch Centennial,
    Econometric Society Monograph Series (Cambridge: Cambridge University Press, 1998).

[14] Heckman, James and Edward Vytlacil, \Instrumental Variable Methods for the Correlated
    Random CoeÂ±cient Model: Estimating the Average Rate of Return to Schooling with the
    Return is Correlated with Schooling," Journal of Human Resources 33 (1998), 974-987.

[15] Heckman, James and Edward Vytlacil, \Local Instrumental Variables and Latent Vari-
    able Models for Identifying and Bounding Treatment EÂ®ects," Proceedings of the National
    Academy of Sciences 96 (1999), 4730-4734.

[16] Heckman, James and Edward Vytlacil, \The Relationship Between Treatment Parameters
    within a Latent Variable Framework," Economics Letters 66 (2000a), 33-39.

[17] Heckman, James and Edward Vytlacil, \Local Instrumental Variables," in Hsiao, C., K.
    Morimune, and J. Powell, (eds.), Nonlinear Statistical Inference: Essays in Honor of Takeshi
    Amemiya (Cambridge: Cambridge University Press, 2000b).

[18] Imbens, Guido and Joshua Angrist, \IdentiÂ¯cation and Estimation of Local Average Treat-
    ment EÂ®ects," Econometrica 62 (1994), 467-476.

[19] Johnson, Norman, Samuel Kotz and N. Balakrishnan, Continuous Univariate Distributions
    (New York: John Wiley and Sons, 1992).

[20] Johnston, John and John DiNardo, Econometric Methods (New York: Magraw-Hill, 1997).

[21] Lee, Lung-Fei, \Unionism and Wage Rates: A Simultaneous Model with Qualitative and
    Limited Dependent Variables," International Economic Review 19:2 (1979), 415{433.




                                              22
[22] Lee, Lung-Fei, \Some Approaches to the Correction of Selectivity Bias," Review of Economic
    Studies 49:3 (1982), 355-372.

[23] Lee, Lung-Fei, \Generalized Econometric Models With Selectivity," Econometrica 51:2
    (1983), 507-512.

[24] Lydall, Harold, The Structure of Earnings, (Oxford: Clarendon Press, 1968).

[25] Paarsch, Harry J., \A Monte Carlo Comparison of Estimators for Censored Regression Mod-
    els," Journal of Econometrics 24 (1984), 197-213.

[26] Quandt, Richard, \Methods for Estimating Switching Regressions," Journal of the American
    Statistical Association 67:338 (1972), 306-310.

[27] RaiÂ®a, Howard and Robert Schlaifer, Applied Statistical Decision Theory (Boston: Graduate
    School of Business, Harvard University, 1961).

[28] Roy, A. D., \Some Thoughts on the Distribution of Earnings," Oxford Economic Papers 3
    (1951), 135-146.

[29] Rubin, Donald, \Bayesian Inference for Causal EÂ®ects: The Role of Randomization," Annals
    of Statistics 6 (1978), 34-58.

[30] Tunali, Insan, \Rationality of Migration," forthcoming in International Economic Review
    (2000).

[31] Tobias, Justin L., \Three Essays on Bayesian Inference in Econometrics with an Application to
    Estimating the Returns to Schooling Quality," Ph.D. Dissertation, Department of Economics,
    University of Chicago (1999).

[32] Tobias, Justin L., \Are Returns to Schooling Really Concentrated Among the Most Able? A
    New Look at the Ability-Earnings and Ability-Schooling Relationships," UC-Irvine Depart-
    ment of Economics Working Paper (2000).

[33] Vytlacil, Edward, \Independence, Monotonicity, and Latent Variable Models: An Equivalence
    Result," working paper, University of Chicago (1999).



                                               23
[34] Willis, Robert and Sherwin Rosen, \Education and Self-Selection," Journal of Political Econ-
    omy 87:5 (1979), S7-36.




                                               24
Notes
   1 Amemiya  (1985) has classiÂ¯ed models of this type as generalized tobit models, and refers to
the model in (1) as the Type 5 tobit model.
   2 Other   applications which Â¯t directly into this model include Lee (1979) and Willis and Rosen
(1979).
   3 For
       a more general discussion of the parameters and the relationship among them, see Heckman
and Vytlacil (1999,2000a-b).
   4 The implications of the assumptions imposed in Imbens and Angrist (1994) which permit
estimation of the LATE parameter have been examined by Vytlacil (1999). Vytlacil shows that the
independence and monotonicity assumptions used by Angrist and Imbens imply a latent variable
speciÂ¯cation without parametric restrictions.
   5 Resultsfor this case were Â¯rst reported in Heckman and Vytlacil (2000b), although they
present a more general analysis and do not discuss how estimates of these parameters can be
obtained using simple two-step procedures.
   6 The   last line follows from L'Hopital's rule.
   7 Lee   (1982, 1983) uses this device.
   8 Henceforth,   we do not discuss the ATE expression. In all cases ATE(x) is x(Â¯ 1 Â¡ Â¯ 0 ):
   9 Thefat tail for wages arises, in part, from measurement errors in earnings and hours and
because wages are often deÂ¯ned by dividing earnings by hours.
  10 Of   course, the mean exists when v > 1 and the variance exists when v > 2:
  11 The  TT expression follows immediately from the result in (20). The LATE expression uses
this result and an argument similar to the one used to derive the LATE parameter in the textbook
normal case (see appendix). The expression for the MTE is derived in the appendix.
  12 Alternatively,   one could integrate over the distribution of the characteristics to obtain uncon-
ditional estimates.
  13 The   NLSY provides four regional variables - Northcentral, Northeast, South, and West.
  14 Potential   experience is deÂ¯ned as Age - Years of Schooling - 6.
  15 Formore on the construction and use of this ability measure, see Cawley et al. (1997) and
Tobias (1999).
  16 The number of siblings variable was found to be a signiÂ¯cant determinant of the college entry
decision, but was not signiÂ¯cant at the 5 percent level when included as a regressor in the outcome
equations for the college and no-college states. Other variables, such as distance to college, the
local unemployment rate at age 18 and a state-level tuition variable were also constructed and
investigated as potential instruments. These variables were found to have surprisingly little power
in explaining the college entry decision for this data and thus we selected number of siblings as


                                                      25
our instrument.
  17 See,for example, Johnston and DiNardo (1997). We obtain 500 draws from the asymptotic
distribution of the regression parameters, and evaluate the treatment eÂ®ects for each draw. Stan-
dard errors are computed as the standard deviation of the simulated values of the treatment
eÂ®ects.




                                               26
                              Table 1
Point Estimates and Standard Errors of Alternate Treatment Parameters
Outcome Errors / Link Function ATE TT                  LATE
        Normal/Normal            .092 .039              .079
         (SSR=345.25)            (.03) (.04)            (.03)
           tv=2 / Logit          .061 .036              .053
        (SSR = 346.09)           (.02) (.03)            (.02)
           tv=3 / Logit          .073 .035              .062
        (SSR = 345.79)           (.02) (.03)            (.02)
           tv=4 / Logit          .079 .035              .067
        (SSR = 345.61)           (.02) (.04)            (.03)
           tv=5 / Logit          .082 .034              .069
        (SSR = 345.51)           (.03) (.04)            (.03)
           tv=6 / Logit          .084 .034              .071
        (SSR = 345.44)           (.03) (.04)            (.03)
           tv=8 / Logit          .085 .034              .073
        (SSR = 345.36)           (.03) (.04)            (.03)
          tv=12 / Logit          .087 .034              .073
        (SSR = 345.29)           (.03) (.04)            (.04)
          tv=24 / Logit          .088 .033              .075
        (SSR = 345.23)           (.04) (.04)            (.03)
            tv=2 / tv=2          .067 .028              .058
        (SSR = 345.68)           (.03) (.04)            (.03)
            tv=3 / tv=3          .075 .030              .063
        (SSR = 345.56)           (.03) (.04)            (.03)
            tv=4 / tv=4          .079 .031              .066
        (SSR = 345.48)           (.03) (.04)            (.03)
            tv=5 / tv=5          .082 .032              .069
        (SSR = 345.43)           (.03) (.04)            (.03)
            tv=6 / tv=6          .084 .033              .070
        (SSR = 345.40)           (.03) (.04)            (.03)
            tv=8 / tv=8          .086 .034              .072
        (SSR = 345.36)           (.03) (.04)            (.03)
          tv=12 / tv=12          .088 .036              .075
        (SSR = 345.32)           (.03) (.04)            (.03)
          tv=24 / tv=24          .090 .037              .077
        (SSR = 345.29)           (.03) (.04)            (.03)




                                 27
