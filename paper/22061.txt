                              NBER WORKING PAPER SERIES




  DECENTRALIZED GOVERNANCE AND THE QUALITY OF SCHOOL LEADERSHIP

                                           Derek Laing
                                        Steven G. Rivkin
                                       Jeffrey C. Schiman
                                           Jason Ward

                                      Working Paper 22061
                              http://www.nber.org/papers/w22061


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                                     March 2016




This research was conducted in collaboration with the University of Chicago Consortium on
School Research. We thank Eva Halacheva for excellent research assistance and Abhijeet Singh
and seminar participants at Chicago Consortium for School Research, CES-Ifo and UIC for
valuable comments. This research is supported by a grant from the Smith-Richardson foundation.
The views expressed herein are those of the authors and do not necessarily reflect the views of the
National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2016 by Derek Laing, Steven G. Rivkin, Jeffrey C. Schiman, and Jason Ward. All rights
reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit
permission provided that full credit, including © notice, is given to the source.
Decentralized Governance and the Quality of School Leadership
Derek Laing, Steven G. Rivkin, Jeffrey C. Schiman, and Jason Ward
NBER Working Paper No. 22061
March 2016
JEL No. H11,H75,I21,I24,I28

                                          ABSTRACT

In response to widespread dissatisfaction with the schools, the 1988 Chicago School Reform Act
decentralized school governance by forming elected local school councils (LSCs) responsible for
principal hiring, evaluation, and contract renewal as well as other management functions.
Subsequent legislation outlined circumstances in which the district could reclaim authority from
the LSC, thereby limiting local control. This paper investigates the distribution of principal
effectiveness under a system in which there is uncertainty over the locus of decision-making
authority. We first establish the presence of significant variation in principal effectiveness based
on both an analysis of variance approach and the estimation of principal fixed effects. Teacher
survey responses support the findings based on the principal fixed effects, though the much
smaller magnitude of the analysis of variance estimates suggest that unobserved shocks inflate
many existing estimates of the variance in principal effectiveness. We next consider potential
differences in LSC behavior that contribute to the variation. Following Aghion and Tirole (1997)
we develop a model that highlights the tensions between formal and real authority and
incorporates potential differences in LSC capacity and incentives to maximize school quality.
Using proxies for managerial capacity and incentives we find evidence largely consistent with the
theory, showing that LSCs with higher management capacity and stronger incentives to raise
school quality experience larger gains in principal effectiveness following the end of contracts.



Derek Laing                                         Jeffrey C. Schiman
110F Eggers Hall                                    Department of Economics
Department of Economics                             University of Illinois at Chicago
Syracuse University                                 601 South Morgan Street
Syracuse, NY 13210                                  Chicago, IL 60607
dlaing@maxwell.syr.edu                              jschim2@uic.edu

Steven G. Rivkin                                    Jason Ward
Department of Economics                             Department of Economics
University of Illinois at Chicago                   University of Illinois at Chicago
601 South Morgan UH725 M/C144                       601 South Morgan Street
Chicago, IL 60607                                   Chicago, IL 60607
and NBER                                            jward28@uic.edu
sgrivkin@uic.edu
I. Introduction

        In response to a persistently high dropout rate and widespread dissatisfaction with the schools, the

1988 Chicago School Reform Act decentralized school governance by forming Local School Councils

(LSCs). LSCs are elected groups of parents, community members, and school personnel who are

responsible for the hiring, evaluation, and contract renewal decisions of principals, the school budget, and

other management functions. Supporters of the reform expected the greater knowledge and interest of

local decision-makers to elevate the quality of school leadership and management. In addition, the reform

had the potential to amplify the benefits of competition among attendance zones, although the low rate of

homeownership for many poor families with children in the schools would likely dampen any such effect.

        Yet there are reasons to question the benefits of decentralization. First, the interests of LSC

members may not align with those of school children and community members; such misalignment may

be more likely in neighborhoods with less participation in the political process. Second, development of

budgets, supervision of the principal (herself a member of the council), and the completion of other tasks

in a manner that improves principal and school quality likely require a range of skills which many LSC

members may lack, particularly those without a post-secondary degree or experience in a supervisory or

management role. Consequently, it is likely that decentralization will produce heterogeneous effects that

benefit some schools and not others and that the reform may be less beneficial in areas with a lower

capacity to manage and weaker incentives to improve the quality of schooling

        In an influential study, the Consortium on Chicago School Research surveyed LSC members

about a number of issues including capacity to govern and the principal evaluation process (Ryan et al.

1997). The responses suggested that although highly productive LSCs did exist, inequality in governance

practices led the decentralization reform to “produce highly varied outcomes across Chicago’s school

communities.” Differences in reported principal evaluation practices were particularly striking. Responses

suggested that just over half of LSCs had a formal evaluation process with explicit criteria the principal

had to meet during her contract, while many of the remaining councils had minimal or even no evaluation

procedures in place (Ryan et al. 1997).

                                                      2
        Nonetheless, the survey responses do not provide evidence on the extent to which LSCs improve

the quality of schools and school leaders. In fact, ongoing concerns that LSCs have not substantially

raised the quality of schools and school leadership, especially in high poverty areas, likely contributed to

subsequent legislation that restored some authority to the district. Over time, the district has assumed

control over principal evaluation, hiring, and renewal decisions in a growing number of schools, although

the majority of principals remain under the supervision of a local school council.

        In this paper, we use Chicago Public School administrative data and information on principal

contracts to investigate the distribution of principal effectiveness in a system of decentralized governance

with the potential for central authority intervention. We pay particular attention to heterogeneity in

managerial capacity and the incentives to maximize school quality in order to gain a better understanding

of the distributional consequences of decentralization.

        In the absence of differences in principal value added to achievement, neither LSC nor district

actions will influence the quality of school leadership in that dimension. Therefore, we first estimate the

variance of principal value added using two different approaches and use teacher survey responses to

provide supporting evidence. The analysis of variance estimates that account most extensively for

potential confounding factors indicate educationally and statistically meaningful differences that are

roughly one third as large as typical estimates of the variance in teacher effectiveness. Importantly, the

pattern of estimates suggests that time-varying factors tend to inflate variance estimates based on

principal fixed effects.

        We turn next to LSC decision-making and its relation to the distribution of principal quality.

Following Aghion and Tirole (1997) we develop a model of LSC behavior that highlights the tension

between formal and real authority in the district, incorporating potential variation in LSC managerial

capacity and incentives and the possibility the District CEO intervenes. We estimate the extent to which

LSC capacity and incentives relate to the change in principal effectiveness from one contract to the next

as well as the determinants of principal transitions in LSC managed schools including those where the



                                                      3
CEO intervenes. Our analysis reveals that LSCs with higher management capacity and stronger incentives

appear to experience larger average gains in principal effectiveness following the completion of contracts.

        The absence of information on contract offers and firings inhibits the identification of differences

in LSC personnel practices with respect to principal effectiveness. Although such information would be

valuable, the ultimate effect of the LSC on principal quality involves both the renewal decision and the

desirability of working in a given school for current and prospective principals of varying levels of

effectiveness. In contrast, CEO intervention represents a clear case of removal in response to poor

performance or some other transgression, though other steps, including school restructuring, often

accompany CEO interventions. Therefore, analyses of both voluntary and involuntary transitions must be

interpreted with care.

           Because our sample begins after the 1988 reform, we cannot identify the effect of

decentralization on the distribution of principal effectiveness. Persistently poor performance in many

schools precipitated the reform, so the continued presence of low-performing schools and questionable

personnel decisions does not constitute evidence the reform harmed the district. Rather, our aim is to

provide a better understanding of the nature of principal transitions under decentralization and the

efficacy of CEO interventions, enhancing the capacity to improve school governance and potentially

illuminating areas of weakness.



II. Data

        To describe the distribution of principal effectiveness and transition patterns we combine CPS

administrative data for the period 1993-4 to 2013-4 with US Census and American Community Survey

data, teacher survey responses, LSC election data, and information we collected on principal transitions

and contracts using public online documents from the proceedings of CPS Board of Education (BOE) and

LSC meetings. The administrative data contain extensive information on students including test scores,

attendance, demographic characteristics, special education status, eligibility for a subsidized or free lunch,

school attended, grade, and school characteristics. School switchers can be followed as long as they

                                                      4
remain in the district. We measure the socioeconomic status of the block group in which each student

lives using Census information on education levels and share of employed adults. Prior to 2010, the

measure is based on the 2000 Census while from 2010 forward it is based on the 2010 ACS.

        We also use the administrative data to construct a panel data set of principals that we merge by

school and year to the student data. Principals must be linked by name, as there is no unique ID number

that spans the period. Therefore, we take great care to account for name changes following marriage or

divorce, other name changes, and spelling or punctuation inconsistencies. The principal panel contains

almost 1,500 principals in over 700 schools.

        Principal contract approval records show BOE approval of principal selections by LSCs and BOE

ratification of principal employment contracts. The records include contract start and end dates and school

served. We also record any disciplinary action against a principal including remove and replace

resolutions initiated by the CEO as well as school designations including under transformation or

turnaround. In the case of remove and replace resolutions the LSC selected principal is removed and

replaced with a principal appointed by the CEO, and until stated otherwise the CEO assumes authority

over the hiring, evaluation, and contract renewal decisions of principals. Note that the data do not

distinguish between a decision not to offer another contract and a decision not to accept a new contract.

        The LSC election data contain the number of parent and community candidates and vote totals for

each biennial election from 2002 to 2012. We focus on parental candidates and develop a measure of

election voting intensity equal to the sum of votes cast for parent representatives divided by school

enrollment in the election year. Table 1 reports mean values of our intensity measure by quartiles of

parental socioeconomic status, revealing a strong, positive association between school average parental

SES and election voting intensity.

        Teacher responses to questions about their principals form the final component of the data. These

are available for a number of years, though the content of the survey changes over time. Teachers are

asked whether they agree or disagree to a series of statements, and we focus on the three statements that

seem particularly relevant to effects on value-added and appear in virtually all years of the data. The

                                                     5
teacher is asked if the principal (1) “makes clear to the staff his or her expectations for meeting

instructional goals”; (2) “communicates a clear vision for our school”; and (3) “carefully tracks student

academic progress.” We use responses to these questions to create a scale of principal effectiveness from

the teacher’s perspective that we relate back to our value-added estimates of principal effectiveness.

        The analysis focuses on principal transitions, and Table 2 reports the distribution of schools by

the number of principals during the sample period. Approximately 85 percent of schools experience at

least one transition in our sample while 41 percent experience three or more. Because some schools enter

and exit the sample either through new construction or through closure, we also present the distribution

limited to schools observed in all twenty years. In the sample of schools observed in all years, over 99

percent of schools experience at least one transition and 46 percent experience three or more.



III. The Variance in Principal Quality

        The measurement of principal value added and the variance of principal effectiveness share many

similarities but also some important differences with the estimation of teacher value added. On the one

hand, the residential location and school-choice decisions of families in combination with school

assignment policies and practices introduce substantial variation in student composition among schools

and classrooms that must be addressed in studies of both principals and teachers. On the other hand, the

widely discussed problems for the estimation of teacher value added associated with purposeful allocation

of students to classrooms and test measurement error are far less important in the case of principals given

the focus on school-wide performance and much larger number of test-takers in schools than classrooms. 1

However, the persistence of principal influences on the quality of instruction in the years after their

departure and the absence of comparisons within a school at a single point in time present serious hurdles

to the identification of principal effectiveness.




1
Kane et al. (2013), Chetty, Friedman, and Rockoff (2014), and Rothstein (2010) investigate the presence and
magnitude of biases introduced by nonrandom assignment to classrooms.

                                                        6
        A comparison with the dynamics of teacher effects illuminates the problems introduced by the

fact that many actions including teacher hiring, contract renewal decisions, mentoring and the

establishment of a school climate will persist beyond a principal’s tenure. In the case of teachers, many of

the longer-term effects are captured by lagged achievement measures for observations in later years, and

the teacher in the previous grade generally has little or no involvement with instruction in the current

year. Even if lagged test scores do not fully account for prior teacher effects due to the dynamics of

learning, it is possible to account directly for prior teacher effects in the model. 2 In the case of principals,

however, it is clear that prior achievement does not account for effects of decisions such as teacher hiring

that directly affect learning in future periods.

        The presence of a single principal in each school at any point in time rules out within school and

year comparisons. In contrast, teacher effects estimated on the basis of within school-year variation

account fully for any school-wide shocks regardless of whether they persist over time or affect learning in

a single year. Because the estimation of principal effects essentially involves the estimation of school

value added during a principal’s tenure, with perhaps controls for school resources and other factors not

under the control of the principal, care must be taken in the interpretation of such estimates.

        Similar to Branch, Hanushek, and Rivkin (2012), we estimate the variance in principal

effectiveness using two distinct approaches. In our first approach, we estimate a value-added specification

that includes principal-by-year fixed effects, which we use to calculate the variance in principal

effectiveness both overall and within schools. 3 We then use teacher survey responses to provide evidence

on the validity of the fixed-effect estimates, given the ambiguity introduced by the aforementioned

equivalence of principal-by-year and school-by-year effects.

        In our second approach, we take additional steps to mitigate bias introduced by unobserved time-

varying factors and the persistence of principal influences. This method identifies the variance directly on


2
  Rothstein (2010)shows a relationship between previous teacher quality and achievement even in a value-added
specification.
3
  The fixed-effect approach follows Bertrand and Schoar (2003), Grissom et al. (2012), Cannon, Figlio, and Sass
(2013), and Branch, Hanushek, and Rivkin (2012).

                                                        7
the basis of year-to-year fluctuations in achievement growth around principal transitions. Essentially the

year-to-year fluctuations within principal spells capture shocks that affect achievement, and larger

fluctuations in value added around transitions would identify the effects of differences in principal

effectiveness.

        Importantly, recent evidence in Miller (2013) reveals a systematic decrease in value added in the

year prior to the arrival of a new principal. This may reflect a reduction in principal health, effort, or

authority over the school or the impacts of other factors associated with the decision to leave a principal

position. Therefore, we estimate specifications that exclude the years immediately surrounding transitions

in both our approaches. Because of the possibility that value added in the first year might be inflated by a

recovery from the achievement dip in the final year, we must exclude both the last and first years of

spells. Note that by focusing on years away from transitions we can account better for persistence,

unobserved school trends, and the confounding effects of potentially large shocks that coincide with

principal changes.

IIIa. Fixed Effect Estimates of Principal Effectiveness

        In our first approach we estimate the following specification,

    (1) 𝐴𝑖𝑔𝑠𝑡 = 𝑓(𝐴𝑖𝑔𝑠,𝑡−1 ) + 𝑿𝑖𝑔𝑠𝑡 + 𝑺𝑠𝑔𝑡 + 𝛿𝑔𝑡 + 𝜃𝑝𝑡 + 𝜀𝑖𝑔𝑠𝑡

where current achievement for student 𝑖 in grade 𝑔 in school 𝑠 in year 𝑡 (𝐴𝑖𝑔𝑠𝑡 ) equals a cubic function of

prior-year achievement𝑓(𝐴𝑖𝑔𝑠,𝑡−1 ), a vector of student controls (𝑿𝑖𝑔𝑠𝑡 ) including race, sex, special

education status, and whether or not the student is new to a school, a vector of school-level controls

(𝑺𝑠𝑔𝑡 ) including school-grade-year averages of the student control variables as well as enrollment and

parental SES, a principal-by-year fixed effect (𝜃𝑝𝑡 ), and a random error term (𝜀𝑖𝑔𝑠𝑡 ). Regressions also

include a full set of year-by-grade indicators (𝛿𝑔𝑡 ) to account for test and other policy changes.

        Year-to-year changes in value-added that occur during a principal’s tenure are captured by the

principal-by-year fixed effect (𝜃𝑝𝑡 ). Of course, estimates of the principal-by-year fixed effects combine

the true principal effect with any other fixed or time-varying influence not accounted for in the regression.


                                                       8
Because of the likely presence of unobserved school influences not captured by prior achievement, we

also compute variance estimates based on deviations from the school average of the principal-by-year

fixed effects. This eliminates all variation in principal effectiveness between schools.

        The top row of Table 3 reports estimates of the overall (left column) and within school (right

column) standard deviation of principal quality produced by averaging the principal-year effects over a

spell at a school. The more compelling within-school results suggest that a one standard deviation

increase in principal effectiveness raises school average test scores in a year by 0.078𝜎. To address the

possibility of an Ashenfelter’s dip in performance, we drop the last and first year of all spells and

recalculate the standard deviation. If a performance dip is present, we would expect the standard deviation

to decrease after removing the last and first years because we are removing extra, within-principal

variability around transitions. After dropping these two years, we find that the standard deviation does in

fact decline from 0.078 to 0.065.

        The estimates reveal substantial variation in principal effectiveness, as a one standard deviation

improvement in principal quality increases achievement by 0.065𝜎 on average for all children in the

school. Even if only half of the improvement persists in the long run, after 9 years (i.e. Kindergarten

through 8th grade) in an elementary school such an improvement would increase average achievement by

roughly 0.3𝜎.

        We turn now to the teacher survey responses and examine whether teachers rate higher-value

added principals more favorably. This would provide confirmatory evidence that the fixed effects do in

fact capture differences in principal contributions to achievement. Table 4 reports average value added by

the response to each statement, and the estimates reveal strongly positive and monotonic relationships

between estimated value added and teacher ratings for all three questions.

        In order to ensure that these results are not driven by other differences among schools, we use

factor analysis that accounts for the categorical nature of the responses to compute a teacher rating index

and then regress value added on the index in specifications with and without school fixed effects. The

coefficients in Table 5 reveal a strong relationship between value added and teacher ratings both overall

                                                      9
and within schools. This supports the belief that the estimates of principal effectiveness capture

differences in the contributions of principals to school quality, even if the fixed effects also capture time-

varying shocks that inflate estimates of variance.

IIIb. Principal Turnover-Based Estimates

          Our second approach to estimate the variation in principal effectiveness uses a method similar to

Rivkin, Hanushek, and Kain (2005) and extended to principals by Branch, Hanushek, and Rivkin (2012)

and Coelli and Green (2012). Importantly, we take additional steps to account for persistent and not

persistent time-varying shocks, performance dips in the transition years, and the persistence of principal

effects on school quality. To illustrate the approach we draw heavily on Branch, Hanushek, and Rivkin

(2012):

          Equation (2) relates the average gain in achievement (current score minus prior year score) in
          school s, in year y as an additive function of principal quality (θ), the quality of other school and
          community factors including student composition not under the control of the principal (γ), a
          school fixed effect (δ), and the school by year average error that includes unobserved student
          influences:


                  (2)       ∆Asy = θ sy + γ sy + δ s + υ sy

          Consider the difference between successive years y and y’ in average gain in achievement. This
          eliminates all school effects that do not vary across the two years, leaving only year-to-year
          differences in principal quality, other school influences and other unobserved time-varying
          factors as determinants of the difference in achievement gain. Squaring this difference yields a
          natural characterization of the observed achievement differences between years as a series of
          terms that reflect the variances and covariances of the principal and school effects plus a catchall
          component e that includes all random error and cross product terms between principal and other
          year specific effects.


                        ( ∆A − ∆A =) θ
                                          2        2          2                     2        2
                  (3)      s
                            y
                                    s
                                     y'
                                              s
                                               y
                                                       + θ sy ' − 2θ sy θ sy ' + γ sy + γ sy ' − 2γ sy γ sy ' + e


          Taking the expectation of Equation 3 and assuming principals are drawn from common
          distributions at each school over the restricted time period of the observations yields:


                                                                   10
                         �����
                             𝑦   ������
                                     𝑦′ 2    2     2                2     2
                   (4) 𝐸(∆𝐴  𝑠 − ∆𝐴𝑠 ) = 2 �𝜎𝜃𝑠 − 𝜎𝜃 𝑦 𝜃 𝑦′ � + 2 �𝜎𝛾𝑠 − 𝜎𝛾 𝑦 𝛾 𝑦′ � + 𝐸(𝑒𝑠 )
                                                         𝑠   𝑠               𝑠   𝑠



        where σ θ2s ( σ γ2s ) is the variance of principal quality (other school influences) in school s and

        𝜎𝜃2𝑦 𝜃𝑦′ (𝜎𝛾2𝑦𝛾 𝑦′ ) is the covariance in principal quality (other school influences) across
           𝑠   𝑠     𝑠 𝑠

        years.(Branch, Hanushek, and Rivkin 2012)


        As Branch, Hanushek, and Rivkin (2012) describe, the three primary assumptions for this

approach are “1) the effect of a principal is fixed (no change over time); 2) principals are drawn from a

common distribution during this time period; and 3) principal turnover is orthogonal to other school

changes that affect achievement gain.” If satisfied, the within-school variance in principal effectiveness

can be uncovered from comparisons between annual fluctuations in achievement gains around transitions

and fluctuations within the tenure of a single principal. Absent a transition, the covariance in principal

quality between years y and y’ equals the variance given the assumption that principal quality remains

constant. By comparison, if the principal changes between years 𝑦 and 𝑦’, the covariance equals zero

within schools given the assumption that principals are drawn from a common distribution.

        Consequently, if principal turnover is orthogonal to other changes that affect achievement gains,

the within school variance in principal quality can be identified from a regression of the squared

difference in average gains on a dummy variable indicating that the school had a different principal in

years 𝑦 and 𝑦’. Specifically, the parameter on the principal turnover dummy variable equals two times the

within school variance in principal quality under these assumptions. Annual achievement gain

fluctuations in years without a leadership change capture differences resulting from both random and

systematic changes.

        As noted above, the systematic value-added decline in the final year of a spell means that

variance estimates that include this year do not strictly capture fixed differences in principal skill or

effectiveness. Therefore, some specifications exclude the final year of a departing principal’s tenure in a

school and also the first year of the incoming principal’s tenure, since the average gain in the first year


                                                        11
may be inflated by the dip in the prior year. Exclusion of these years also mitigates bias introduced by

additional turbulence associated with a transition.

        Excluding these years increases the gap around transitions from one to three years, and this has

two potentially offsetting effects on the estimates. One the one hand, measurement error that increases

achievement and therefore achievement gain in year 𝑦 will tend to decrease achievement gain in year

𝑦 + 1, because the positive error in year 𝑦 will tend to decrease the difference between achievement in

years 𝑦 + 1 and 𝑦. This, in turn, will tend to amplify the squared difference in gains based on adjacent-

year comparisons. Therefore, in specifications that use adjacent years to compute squared differences in

gains within spells but nonadjacent years to compute squared differences in gains across transitions, such

measurement error will tend to attenuate the estimates.

        On the other hand, underlying achievement trends would tend to amplify differences computed

over longer periods. This would likely increase the squared difference calculations around transitions

based on gains three years apart relative to those within spells based on adjacent years and therefore

introduce upward bias into the estimate of the variance. Consequently the direction of bias cannot be

signed a priori, and computations across transitions and within spells should be comparable in terms of

distance between years. Note that this restriction substantially decreases the sample size and therefore

reduces the precision of the estimates.

        Table 6 reports coefficients on the transition indicator for a series of specifications that differ

according to whether or not the first and last years of spells are included and the number of years between

calculations within a principal spell. The final column reports the estimate for the preferred specification

in which squared differences both across transitions and within spells come from gains that are three years

apart, and the estimate is slightly smaller than that from the specification that includes all observations,

though it just misses significance at the 10 percent level.

        The three estimates from specifications that exclude the first and last years are consistent with

both measurement error induced attenuation bias in specifications that use adjacent-year differences

within spells and unobserved trends that introduce upward bias in specifications that calculate squared

                                                      12
differences within spells across fewer than three years. First, the insignificant estimate of 0.0015 in

Column 2 based on adjacent year calculations within principal spells that likely amplify the effects of

measurement error is much smaller than the estimate of 0.0037 in Column 3 based on differences two

years apart. Second, the Column 4 estimate of 0.0029 based on within spell differences calculated across

the same three years as the differences across transitions is smaller than 0.0037, consistent with the notion

that widening the gap tends to increase the counterfactual variance. Taken as a whole the results highlight

the importance of using non-adjacent years and the same size gaps both across transitions and within

spells.

          Not surprisingly and similar to the pattern found in Branch et al. (2012), the Column 4 estimate of

the standard deviation in principal effectiveness of 0.0383 is roughly half as large as those produced by

the direct estimates of principal fixed effects. It is likely that the true magnitude lies somewhere between

the two estimates.

          Although the estimates of the standard deviation based on the principal fixed effects may be

inflated by changes over time in other factors, the turnover estimate makes the quite strong and unrealistic

assumption of fixed principal effects within spells. Not only is the principal’s influence likely to grow

over time as more of the teachers hired, school practices adopted, and climate reflect the work of the

incoming principal, principals may improve as they gain a better understanding of how to lead a school.

Regardless, even the smaller estimates are educationally significant in magnitude, as they suggest an

improvement of almost 0.2 𝜎 in average achievement from 9 years of attendance at an elementary school

with a one 𝜎 more effective principal, assuming that half of the annual effect persists.



IV. School Reforms and the Structure of School Governance in Chicago

          Two institutions are charged with the task of overseeing Chicago's public schools: the Board of

Education (BOE), which is headed by a chief-education officer (CEO), and Local School Councils




                                                      13
(LSCs). 4 These LSCs—one for each public school in the city—were introduced as part of the landmark

1988 Chicago School Reform Act. This Act shifted much authority including the hiring and evaluation of

the principal away from the BOE to the LSC. 5

         Each LSC includes the principal of the school together with a periodically elected membership

that includes teachers, parents, and other interested members of the community with each constituency

holding a fixed number of seats on the council. Importantly, the self-interests of LSC members may

diverge from the welfare of the students. For example, a parent member could push for reallocation

toward her child; a member of the Council could attempt to influence the hiring process to favor a friend

or relative; and, of course, the school principal—a key player in each LSC—may use her position on the

council to further her career

         With the potential hazards of decentralization in mind, the 1995 Chicago School Reform

Amendatory Act gave the mayor the right to appoint a Public Schools CEO and restored elements of the

decision-making authority to the BOE. In particular, the 1995 amendment gave the CEO the authority to

remove and replace a principal under certain circumstances including persistent low achievement.

         Using the terminology developed in Aghion and Tirole(1997), the 1995 Act endowed the BOE

with all of the formal authority concerning the administration of each the city's public schools. It gave the

CEO the right to place a public school on probation. Once on probation, the principal has one year to

remedy performance issues. If the principal fails to do so, the CEO has the power to assume control over

decisions regarding the school principal—authority that otherwise rests with an LSC. Furthermore, the

CEO can, in effect, dissolve the current LSC by mandating that new elections be held. In addition, she has

the power to close educational programs, and she even has the power to shut down a school and then




4
  In fact, there are three institutions, if one includes the Office of the Mayor. The BOE is under the direct formal
control of the Mayor. Nevertheless, in practice, the role of the Office of the Mayor is limited to setting the annual
school budget, appointing the CEO, and appointing members to the BOE. In particular, it has delegated all of its real
authority in the practical business of running the CPS to the BOE and by extension the CEO.
5
  Haney (2011) offers a valuable discussion of the 1995 Chicago School Reform Amendatory Act.


                                                         14
reopen it by hiring new staff altogether or by selectively rehiring some of those who were dismissed from

the school in question. 6 In each of these cases the BOE assumes real as well as formal authority.

        Despite the considerable formal power possessed by the Board, the real authority concerning the

practical day-to-day business of running the vast majority of the city's public schools rests with local

school councils. Here, the economic substance of real authority is that the LSC is responsible for

selecting the principal, renewing the principal's contract, determining the allocation of the budget, and

crafting a School Improvement Plan. Although the CEO effectively rubber stamps the majority of LSC

principal contract decisions, the process of monitoring and the possibility of intervention constrain LSC

and principal behavior.



V. Model of LSC Behavior

        Next, we construct a model that draws on Aghion and Tirole (1997) and is designed to capture the

salient features of the Chicago public school system (CPS) as they pertain to principal effectiveness and

transitions. We begin with a description of the environment and then describe the behavior of LSCs and

potential variation by capacity and election pressure.

V.a. The Environment

        We first describe the technology that governs school quality, the objectives of each LSC, the

means whereby the CEO monitors the schools and the determinants of its decision of whether to overrule

the LSC. Subsequently, we consider the relationship between the CEO and the LSCs.

V.a.1. Technology

        We envisage a school as a production function that takes the following as its primary inputs:

students, the labor of the principal, teachers, and staff, together with other resources, such as the quality of



6
  An illustration of the institutional mechanics underlying the practical process whereby the CEO removes a school
principal is given in 01-0822-AR11. This document also provides the guidelines used for the replacement of
principals of those schools on probation. See http://www.cpsboe.org/content/actions/2001\_08/01-0822\-AR11.pdf
(accessed 3 September 2014). Further description is provided here:
http://www.ilga.gov/legislation/ilcs/fulltext.asp?DocName=010500050K34-8.3 (accessed 16 May 2015).

                                                        15
the library, buildings, and other educational capital. A school uses these inputs to produce educational

value added, as measured by school quality, 𝑞. 7

         For the moment, put to one side issues pertaining to the quality of the administrative decisions

made by an LSC or the principal. Consider a school with a resource endowment 𝑘. We assume potential

value added, 𝑄�, is given by

         (5)               𝑄� = 𝐹 (𝑥; 𝑘) = 𝑥 ∙ 𝑘.

The term 𝑥 ∈ [0,1] is an index that captures the (endogenous) efficacy with which the resource

endowment available to the school, 𝑘, is allocated to the production of educational value added. The case

in which 𝑥 = 1 corresponds to the highest possible potential value added, which we denote 𝑄�𝑚 ≡

𝐹 (1; 𝑘) = 𝑘.

         As will be clear later, the allocation of resources, 𝑥, plays an important role in our analysis. In

anticipation, we assume each LSC also has an independent interest over the way resources are allocated

within the school and, as a result, its preferences over 𝑥 may be not fully aligned with the goal of

maximizing value added, 𝑄. The main economic substance of this structure is that it generates a potential

conflict between the interests of the CEO and the LSC. In settings with less voting intensity/participation

or low capacity to govern, the principal likely plays a more dominate role in resource allocation which

may or may not ameliorate the potential conflict. Next, we consider the issue of authority and control.

         Let θ ∈ [0, 1] represent the given managerial or organizational capacity/quality of the institution

that exercises real authority over the running of a specific public school. If the school is administered by

an LSC, θ is a reduced-form measure of the LSC’s overall managerial capacity. In practice, it depends

jointly on the abilities of its members and, most important, the ability of the current school principal. This



7
  In practice, practice, each school draws the large part of its student body from the geographic community in
which it is located. This, in conjunction with the widespread socioeconomic disparities across Chicago’s
neighborhoods, induces considerable variation in the composition of students who attend it. Therefore, certain
neighborhoods draw students primarily from high income households and others draw them from economically
challenged ones, especially those with high recent immigrant populations. To provide a veracious measure of value
added by a school in general and assay the effectiveness of the principal in particular, it is necessary to control for
these factors, which we do in the subsequent empirical analysis.

                                                          16
is because the organizational structure is one in which the principal is a member—often the most

influential member—of the LSC. This renders challenging the task of explicitly modeling the link

between abilities of the committee members and the efficacy of the committee itself: one of the primary

functions of the LSC is assaying the performance of the school principal, and the principal herself has

considerable indirect influence over the assessment of her performance by virtue of her membership of

the LSC. 8

          We assume that actual value added by the school, denoted 𝑄, depends on the managerial quality

parameter, 𝜃, and potential value added, 𝑄�,according to

          (6)                 𝑄 = 𝜃 ∙ 𝑄�.

          We can think of 𝜃 as an 𝑋-efficiency parameter a la Leibenstein: The effectiveness with which a

given set of inputs are used to produce outputs. Here, 𝜃 = 1 corresponds to the frictionless ideal that

represents the perfect management of resources. For intermediate cases of 𝜃, the term (1 − 𝜃) ∗ 𝑞�

represents the degree of 𝑋-inefficiency—the loss of value added resulting from poor administrative

decisions.

          Next, we consider the determinants of 𝜃 for each of the city’s schools. To this end, consider a

public school that is administered by a LSC. We assume the managerial quality of those schools

controlled by LSCs, 𝜃, is distributed on the support [𝜃0 , 1] according to the distribution function 𝐺(𝜃),

with mean 𝜃̅ ∈ [𝜃0 , 1], where 𝜃0 > 0 represents some minimal managerial capacity. 9

          To capture the potential benefits of decentralized local control, we assume that those public

schools over which the Board of Education exercises real authority each have an organizational capacity

𝜃𝐵 ∈ (0, 𝑀], where 𝑀 < 1. Though simple, this formulation is rich enough to capture, on the one hand,

8
  Indeed, these concerns are the primary motivation for our use of a stochastic representation of the educational value-added
production technology, described shortly. This approach allows us to adopt an agnostic approach concerning the explicit link
between the abilities of the LSC committee members and the overall managerial capacity of the LSC. More specifically, it is
inconsequential (to our model) whether the LSC’s capacity, θ, is governed by the strength of the weakest link (the ability of the
least able member), the sum of the parts (the simple sum of ability members), or some more complicated sub- or super-modular
function of these abilities.
9
  We can think of 𝜃 as a stochastic representation of technology, similar to that proposed in Eaton and Kortum(2002). The lower
bound 𝜃0 ensures that for all vaues of 𝑥 and 𝑘,𝑄 ≥ 𝜃0 ∙ 𝑥 ∙ 𝑘 > 0 , thereby ensuring no school is so bad as to generate zero value
added.

                                                               17
the potential benefits of decentralization, 𝜃𝐵 ≤ 𝑀 < 1, and, on the other, the possibility that some schools

would benefit by having important decision making rights taken away from the LSC and assigned to the

CEO, 𝜃0 < 𝜃𝐵 .

        In what follows, it is convenient to work with the intensive form of educational value added. That

is, value added per dollar of resource endowment, 𝑘. Therefore, let 𝑞� ≡ 𝑄�/𝑘 denote potential educational

value added per dollar and let 𝑞 ≡ 𝑄/𝑘 denote actual educational value added per dollar. Therefore

equation (5) becomes

(7)    𝑞� = 𝐹(𝑥; 𝑘)/𝑘 = 𝑥,

and (6) becomes

(8)    𝑞 = 𝜃 ∙ 𝑞� ≤ 1.

In the interest of brevity, in what follows we refer to the intensive measure, 𝑞, as educational value added

and to 𝑄 as aggregate educational value added by the school, as we do for 𝑞� and 𝑄� – their potential value

added counterparts.

        The principal advantage of using the intensive forms of the value-added measures is that they

allow for meaningful comparisons of relative performance, in view of the realistic and practical

heterogeneity in resource endowments that are available to different schools in the city. More specifically,

consider two schools, 𝑖 ∈ {0,1}, with endowments 𝑘0 < 𝑘1 . It may well be the case that total value added
                                                                                                𝑄
is greater in the latter school than in the former, 𝑄0 < 𝑄1 . Nevertheless, if, for example, 𝑞0 = 0 = 1 > 𝑞,
                                                                                                 𝑘
                                                                                                 0


then school 𝑖 = 0 has attained the greatest possible output with the resources available to it, whereas

school 𝑖 = 1 has not.

V.a.2. Preferences

        Consider first, the various LSC's that control Chicago's public schools. We assume the objectives

of each LSC are described by the following utility function of the representative committee member:

        (7)              𝑉 = 𝑣(𝑞, 𝑐),




                                                     18
where 𝑞 is the value added by the school under its control, and 𝑐 ≡ 1 − 𝑥 represents the consumption-

equivalent value arising from the distortion in the allocation of resources, as measured by 1 − 𝑥. We

assume 𝑣𝑞 > 0, lim𝑞→0 𝑣𝑞 = ∞,𝑣𝑐 ≥ 0, and that 𝑞 and 𝑐 are substitutes.

         With the inclusion of 𝑐 in the utility function, each LSC has a direct interest over the manner in

which resources are allocated. For instance, as one of its members, the principal may lobby the LSC to

renew his or her contract, despite the fact that another candidate would be better suited for the position

and so generate greater value added. Alternatively, a committee member may lobby in favor of hiring a

friend or relative to fill an open position.

         Despite its simplicity, this framework is rich enough to capture the cases of greatest interest to us.

If 𝑣𝑐 = 0, then the LSC purely is interested in maximizing school quality. Alternatively, if 𝑣𝑐 > 0, there

is an imperfect alignment of the preferences of the LSC with its core (stated) mission of maximizing the

quality of the school. Most important, this misalignment of incentives potentially creates a conflict of

interest between the objectives of the LSC and those of the Board, an issue we consider shortly.

         Finally, if the CEO assumes authority over school governance, we normalize the LSC's utility to

zero and, for simplicity, assume the Board eliminates any transparent allocative distortions by setting

𝑥 = 1.

V.a.3. Monitoring and the Information Structure

         Monitoring depends upon both the timing of information and actions and the structure of

information. Assume the timing of events within a given period is as follows: (1) At the beginning of a

period, each LSC chooses the values of 𝑐 and 𝑞; (2) these choices generate a noisy signal of school

performance, 𝑠; (3) the CEO monitors each LSC with probability 𝑚 ∈ (0,1), and observes the

performance signal, 𝑠, for those schools that are monitored; (4) on the basis of signal, 𝑠, the CEO decides

whether to intervene in the affairs of the LSC; (5) the election for LSC seats is held; (6) the events just

described occur in negligible time. During the remainder of the period, the LSC members derive utility




                                                      19
𝑣(𝑞, 𝑐) provided that neither the LSC members lose the election nor the CEO intervenes in LSC affairs.

Otherwise, the LSC derives (normalized) zero utility, 𝑣0 = 0.

     Assumption 5.1 describes the information structure. 10


Assumption 5.1 (Information)

(a) The performance signal, 𝑠, is observed by members of the local community

(b) The signal, 𝑠, depends on actual educational value added, 𝑞, and a random disturbance 𝑧 ≥ 0

according to 𝑠 = 𝑞 ∗ 𝑧. The value of 𝑧 is governed by an 𝑖. 𝑖. 𝑑 draw from the exponential distribution:

𝑧~1 − exp[−𝑧/𝜆].

(c) Each LSC knows its own managerial capacity, 𝜃. Furthermore, the distributions, signal generating

process, and technological relationships are common knowledge

         Part (a) is the root of the inherent informational advantage of decentralized versus centralized

control: the community is aware of substantive issues pertinent to its own well-being, whereas the CEO

only becomes privy to this information through an imperfect monitoring process.

         The posited exponential distribution implies the disturbance 𝑧 has a mean 𝜆 and variance 𝜆2. The

parameter 𝜆 governs the informativeness of the signal, 𝑠, and lower values of 𝜆 reflect greater

informational content. The expected value of the signal, 𝑠̅, generated by a school with quality 𝑞 is

𝑠̅(𝑞) = 𝑞 ∗ 𝜆. Each LSC recognizes the expected value of 𝑠 depends positively on actual value added, 𝑞,

of the school under its control. The significance of this fact is that the LSC—through its choice of 𝑐—can

influence 𝑠 and so the likelihood that the CEO will intervene. Hence each LSC faces a non-trivial

decision concerning the choice of 𝑐. On the one hand, it derives a direct benefit from 𝑐 and, on the other,

it has an incentive to temper its choice of 𝑐 because it can reduce the likelihood the CEO will abrogate its

power.




10
  Our results would hold for any distribution function for the disturbance, that satisfies the monotone-likelihood
ratio property; the exponential distribution considered here, obviously is a particularly tractable member of this
family.

                                                          20
          If the actual quality of the school in question is 𝑞, Assumption 5.1 implies that, if monitored, the

probability the LSC will lose its authority is 1 − exp[−𝑠̂ /(𝑞 ∗ 𝜆)], for this is the probability that 𝑠 falls

below the critical threshold, 𝑠̂ . As a corollary, the probability that the LSC retains its real authority is

exp[−𝑠̂ /(𝑞 ∗ 𝜆)].Those schools that are not monitored and those that are monitored—but for which the

observed performance signal, 𝑠, exceeds the threshold, 𝑠̂ —are deemed satisfactory, and the CEO

delegates the real authority over decision making to the LSC. 11

          Even if the incumbent LSC survives the CEO’s monitoring process with its authority intact, the

next hurdle it face is the mandated electoral process. The probability it survives the re-election process is

𝜇̂ (𝑠, 𝜌), where ρ indexes the intensity of local political involvement. We assume this is increasing and

concave in the observed performance of the school under its stewardship, 𝑠, with 𝜇̂ (0, 𝜌) = 0 and

𝜇̂ (1, 𝜌) = 1. In addition, we suppose that 𝜇̂ (. ) exhibits a single crossing property, in which for each 𝜌

there is a unique 𝑠(𝜌) such that 𝜇̂ 𝜌 > 0 if 𝑠 > 𝑠(𝜌); 𝜇̂ 𝜌 < 0 if 𝑠 < 𝑠(𝜌); and 𝑠(𝜌)𝜌 > 0. This formulation

captures in the simplest way that a community with a high level of involvement demands high

performance for their LSC (i.e. 𝑠(𝜌)𝜌 > 0) and the notion that the electoral process runs both ways.

Specifically, an already outstanding incumbent LSC (𝑠 > 𝑠(𝜌)) is more likely to be re-elected the greater

the degree of involvement, 𝜌, whereas exactly the opposite is true for a substandard one (𝑠 < 𝑠(𝜌)).

V.b. The Behavior of the LSC

          We assume that at the beginning of the period, the Committee chooses feasible values of 𝑥 and 𝑐

to maximize its expected utility. The structure of the model offers a parsimonious framework for studying

the behavior of LSCs. Although formally a static problem, the sequence of events is such that the

Committee anticipates that its choices of 𝑐 and 𝑞 have subsequent consequences for its well-being.




11
  In practice, there are significant costs incurred by the CEO whenever she exercises her formal authority by overruling the
decisions made by a given LSC that temper her office’s behavior. First, if the LSC’s managerial capacity exceeds the Board’s,
then (all else equal) centralized control results in a direct efficiency loss because the LSC has the greater of the two managerial
capacities. Second, she must devote scarce resources to managing newly acquired schools—in particular, costs in evaluating the
school principal and deciding whether to terminate his or her contract. Finally, because each LSC is an elected body, there is a
potential political cost incurred should her behavior run counter to the community’s wishes.

                                                                21
         Given that 𝑠 = 𝑞 ∗ 𝑧 and 𝑧~1 − exp[−𝑧/𝜆], 𝑠 ~ (1/𝑞) ∗ exp[−𝑠/𝜆𝑞]. Therefore the ex ante

probability the LSC anticipates surviving the re-election contest is 𝑢 = ∫ 𝜇̂ (𝑠, 𝜌) exp[−𝑠/(𝜆𝑞)] 𝑑𝑠 ≡

𝜇(𝑞; 𝜌). Since the LSC’s normalized payoff in the event of CEO intervention is zero, its expected payoff,

denoted 𝑉�(𝑞, 𝑐; 𝑠̂ , 𝑚), is

         (8)                   𝑉�(𝑞, 𝑐; 𝑠̂ , 𝑚) = 𝜇(𝑞; 𝜌) ∗ 𝜎(𝑞; 𝑠̂ , 𝑚 ) ∗ 𝑣(𝑞, 𝑐),

where 𝜎(𝑞; 𝑠̂ , 𝑚 ) ≡ (1 − 𝑚 ) + 𝑚 ∗ (exp[−𝑠̂ /(𝑞 ∗ 𝜆)]) is the probability that the LSC survives the

CEO’s monitoring process, with its control rights intact. The term (1 − 𝑚) is the probability it is not

monitored, and 𝑚 ∗ exp(−𝑠̂ /(𝑞 ∗ 𝜆)] is the probability that it is monitored but retains its control rights

because it generates a performance measure, 𝑠, that exceeds the given threshold 𝑠̂ .

         By using the constraints 𝑞 = 𝜃 ∗ 𝑥 and 𝑐 = 1 − 𝑥, each LSC's problem takes the simple form

(9)                𝑉(𝑠̂ , 𝑚, 𝜃) ≡ max𝑐,𝑞∈[0,1] 𝑉�(𝑞, 𝑐; 𝑠̂ , 𝑚, 𝜌)

                               1
                   s.t.,       𝜃
                                   ∗𝑞+𝑐 ≤1

         By expressing the problem in this manner, it is immediate from inequality (9) that 1/𝜃 is the

(implicit) price of school quality 𝑞 in terms of foregone 𝑐. It follows from this that, well-managed

schools—those with a high 𝜃—face a lower effective price of providing school quality than do poorly

managed ones. Since both 𝑐 and 𝑞 are valued by the LSC, the resource constraint binds at the optimum.

Therefore we can use this constraint to write the LSC's problem in terms of school quality alone.

                                                                                𝑞
(10)               𝑉(𝑠̂ , 𝑚, 𝜃) ≡ max𝑞∈[0,1] {𝜋(𝑞; 𝑠̂ , 𝑚, 𝜌) ∗ 𝑣 �𝑞, 1 − �𝜃��}

Assuming an interior solution, the optimal choice of 𝑞, denoted 𝑞∗ = 𝑞(𝑠̂ , 𝑚, 𝜃, 𝜌), is governed by the

following first-order condition:

(11)               0 ≡ �𝜋 ∗ 𝑣𝑞 + 𝜋𝑞 ∗ 𝑣� − (𝜋 ∗ 𝑣𝑐 )/𝜃,

where subscripts represent partial derivatives and the FOC is evaluated at the maximum.

         The first term in square brackets in equation (11), is the marginal benefit of an increase in school

quality 𝑞. More specifically, provided it survives with its authority intact, which occurs with probability


                                                              22
𝜋, the LSC derives a direct benefit from the increase in school quality valued at 𝑣𝑞 at the margin.

Furthermore, an increase in 𝑞 raises the probability that the LSC does indeed survive to see another day

by 𝜋𝑞 , which in turn allows it to derive utility, 𝑣.

        The term −(𝜋 ∗ 𝑣𝑐 )/𝜃 represents the marginal cost of raising school quality, 𝑞, in terms of

foregone 𝑐. Again, the committee survives (CEO intervention and the electoral process) with probability

𝜋 and (provided it does) suffers a marginal loss in utility of 𝑣𝑐 /𝜃 from the increase in 𝑞. For the reasons

just described, those schools that are most effectively managed—their managerial ability, 𝜃, is high—bear

lower cost, in terms of foregone 𝑐, than do poorly managed schools. Finally, it follows immediately from

equation (11) that if 𝑣𝑐 = 0, then 𝑐 ∗ = 0: If an LSC values only school quality, it will not distort the

resource allocation of the school under its stewardship.

        In what follows, let 𝑞∗ = 𝑞(𝑠̂ , 0, 𝜃0 ) > 0 denote the value added by the school confronted with

the least auspicious of circumstances: the given LSC is not monitored (and so has no fear the CEO will

intervene based on its performance), and it possesses the lowest possible managerial capacity, 𝜃0 . (Since

𝑚 = 0, 𝑞0∗ is independent of 𝑠̂ .) The expected signal generated by such a school is 𝑠0 = 𝑞0∗ /𝜆. Consider

Condition 1 where we assume that the performance threshold, 𝑠̂ , satisfies 𝑚/(1 − 𝑚) > [𝑠̂ − 𝑠̅0 ] ∗

exp[(𝑠̂ /𝑠̅0 )]. Given our technological assumptions, the maximum expected performance signal is

𝑠̅(1) = 1/𝜆. In essence, Condition 1 ensures that the threshold 𝑠̂ is not set so high that every school—

including the best of the best—expected that it would be taken over in the event it were monitored.



Proposition 5.1 (The Optimal Behavior of LSC's)]

Letting𝑞∗ and 𝑐 ∗ = 1 − 𝑞∗ /𝜃 denote the Committee's optimal choices, we show
     ∗
(a) 𝑞𝑚 > 0, 𝑞𝑠̂∗ > 0, 𝑞𝜆∗ > 0, 𝑞𝜌∗ ≶ 0, and (b) 𝑞𝜃∗ > 0, 𝑐𝜃∗ < 0

Proof: All proofs are presented in an Appendix available from the authors.

Part (a), describes the impact of the effect of the joint threats on the behavior of the LSC that, on the one

hand, the CEO will intervene and exercise her real and formal authority, and on the other the LSC may


                                                        23
not win re-election. A greater audit probability, 𝑚, or a tougher performance standard, 𝑠̂ ,induces the LSC

to raise the school's performance level, 𝑞∗ , to reduce the likelihood the CEO will intervene in its affairs.

The effect of an increase in community participation, 𝜌, is theoretically ambiguous. In particular, a high

performing LSC that anticipates it will draw 𝑠 > 𝑠 (𝜌) (the single crossing point threshold) anticipates

that a marginal increase in 𝜌 only will increase the probability of its re-election. As a result, it anticipates

it can marginally increase 𝑐, thereby marginally reducing performance, 𝑞, and still survive re-election. An

increase in 𝜆 corresponds to an increase in the informativeness of the signal, 𝑠; it results in an increase in

quality, since it is easier for the CEO to distinguish good from bad performance.

        One implication of the threat effect just described is that it is insufficient to evaluate the overall

effectiveness of the CEO by examining just the change in performance of those schools in which she

intervenes directly (for example, via a before-and-after comparison of each school’s performance). More

specifically, even were this set of schools to experience little discernable improvement in performance,

the prospect of intervention by the CEO and the LSC's fear of the loss of its control rights may already

have increased substantially the performance of each school in the city. Another implication of the threat

effect is that it reduces the extent of any room for the ex post observed improvement of any school under

the management of a new school principal after being taken over and reorganized by the CEO.

        Part (b) of the Proposition describes the effect of the LSC's own managerial capacity 𝜃 on the

value added by the school under its control. The fact that better managed schools have higher value

added, 𝑞𝜃∗ perhaps is not too surprising. The interesting part of the Proposition is that 𝑐𝜃∗ < 0—or

equivalently 𝑥𝜃∗ > 0. Therefore, a greater managerial capacity, 𝜃, raises school quality directly (because

𝑞 = 𝜃 ∗ 𝑥) and indirectly because the LSC responds to its own intrinsic higher ability by choosing a better

resource allocation. Of course, this means that poorly managed schools generate a low educational value

added because they are poorly managed and because they respond in part to their own ineffectiveness by

pursuing goals other than maximizing quality as captured by the term 𝑐 ∗. In other words, they respond to




                                                       24
their inherent low managerial capacity, 𝜃, by substituting away from the relatively high cost provision of

quality, 𝑞, toward 𝑐.



VI. Empirical Analysis of LSC Heterogeneity

        The formal model provides the structure under which we evaluate how LSC and CEO decisions

affect principal quality as measured by value added. The initial empirical analysis examines the

relationship between principal quality following a contract event and proxies for LSC capacity and

pressure to focus on school quality. Given the uncertainty in quality at the time of hiring, more effective

LSCs would be expected to make better contract renewal decisions with respect to realized principal

performance and the observed trajectory of school quality. In addition, a change in political participation

would be expected to induce a larger change in school quality for a more effective LSC; as effectiveness

approaches zero behavioral responses lead to little perceptible effect. Finally, the model highlights the

uncertainty in the effect of political participation. Note that these regressions control for principal

effectiveness prior to the end of the contract.

        Estimates of the relationships between the changes in effectiveness and LSC characteristics

combine the effects of principal transitions initiated by the principal, transitions initiated by the LSC,

CEO interventions and contract renewals. Therefore the subsequent component of the analysis examines

the relationship between the probability of a specific transition and principal effectiveness prior to the

contract event using multinomial logit. We classify transitions into three types of contract events: contract

renewal (48.8%), principal departure during or at the end of the contract (48.2%), and principal removal

by the CEO (3%).

        The absence of information on contract offers limits the analysis, as LSC decisions not to renew

and principal decisions not to return are indistinguishable. Nevertheless, the estimates provide

information on the relationship between the LSC characteristics and the net effect of contract offer and

acceptance decisions. Moreover, CEO removals of a principal do not suffer from the same ambiguity as

LSC decisions. However, when the CEO intervenes and removes the principal they may also change other

                                                      25
aspects of the school. Therefore, comparisons of principal effectiveness prior to a CEO intervention to

effectiveness prior to a transition at a school managed by an LSC must be interpreted with care.

        The analysis requires proxies for both capacity and pressure, and we use census block group

average parent SES computed over students in the school as the proxy for LSC capacity and election

participation intensity as the proxy for awareness of school performance. Based on information from the

US Census and American Community Survey, the SES index is a function of adult education and adult

employment in managerial positions. In the case of the SES index, we assume that formal education

elevates the capacity to comprehend information on school performance, and white collar occupations

enhance the capacity to manage and supervise. In the case of the voting intensity measure, we assume that

higher intensity reflects higher awareness of and interest in school performance.

        SES and voting intensity are likely related to factors that affect achievement, raising the

possibility that they influence principal value added directly. Yet because we focus on the change in

principal effectiveness following a contract event and the principal transitions conditional on

performance, we believe that they provide valid proxies for factors that affect LSC capacity and behavior.

Moreover, the inclusion of variables that capture changes in demographic characteristics has virtually no

effect on the SES or voting intensity coefficients.

        Table 7 illustrates the joint distribution of SES and voting intensity. Although the table shows

that the fraction in the top voting intensity quartile is much higher for the schools in the top SES quartile

than for the others, there is substantial variation in voting intensity in all SES quartiles.

        Table 8 reports estimates of the relationship between the change in principal effectiveness

following a contract event and both SES and voting intensity using the following specification:

(12)    Δ𝐸𝑠1,2 = 𝛼 + 𝛾𝐿𝑆𝐶𝑠1′ + 𝛽𝑆𝐸𝑆𝑠1′ + Δ𝑿1,2       2
                                           𝑠 + 𝛿𝑦 + 𝜀𝑠


where the change in principal effectiveness (effectiveness under contract 2 minus effectiveness under

contract 1) is a function of LSC voter intensity (𝐿𝑆𝐶𝑠1′ ) and parental SES (𝑆𝐸𝑆𝑠1′ ), each measured in the

nearest year prior to the end of the contract, a vector measuring the change in student demographics and



                                                       26
school characteristics between the first and second contract (Δ𝑿1,2
                                                                𝑠 ), year fixed effects (𝛿𝑦 ), and a random


error. The change in principal effectiveness following the contract event equals VA measured during the

2nd year following the contract event minus VA measured during the second year of the initial contract

period prior to the event. Note that the second specification includes the interaction between SES and

voting intensity and the third specification also adds the interaction between voting intensity and

effectiveness in order to examine potential heterogeneity in the responsiveness to voter participation by

initial principal effectiveness as suggested by the theory.

        The estimates in Table 8 support the predictions of a positive relationship between the change in

principal effectiveness and both capacity and incentives. Both the SES and voter intensity coefficients in

the left column are positive and significant at the 10 percent level despite the small sample size.

Moreover, the interaction term coefficient in the middle column is consistent with the notion that higher

capacity amplifies effects of voting intensity. However, the prediction that the effect of voter intensity

should weaken with initial principal effectiveness is not supported by the estimates reported in Column 3.

Rather, the interaction term is positive although not significant.

        Principal productivity is likely to change through two primary channels: hiring and contract

renewal. Because most new principals were not previously principals in CPS, it is difficult to evaluate the

hiring decision. Therefore we focus on principal transitions out of a school and investigate whether

systematic differences between the probability of exiting and principal effectiveness emerge by both SES

and LSC election participation. To do so, we estimate the following multinomial specification,

(13)             𝐶𝑂𝑁𝑇𝑅𝐴𝐶𝑇𝑝𝑠𝑡′ = 𝛼 + 𝑓�𝐸𝑝𝑠𝑡 � + 𝑓�𝐸𝑝𝑠𝑡 � ∗ 𝑆𝐸𝑆𝑠𝑡 + 𝑓�𝐸𝑝𝑠𝑡 � ∗ 𝐿𝑆𝐶𝑝𝑠𝑡 + 𝜀𝑝𝑠𝑡′

where 𝐶𝑂𝑁𝑇𝑅𝐴𝐶𝑇𝑝𝑠𝑡′ measures how the contract ends for principal 𝑝 in school 𝑠 at time 𝑡′ and takes on

three values: renewal (omitted category), exit, and removal by CEO. The basic specification reported in

Column 1 models the contract event as a function of principal effectiveness during the contract 𝑓�𝐸𝑝𝑠𝑡 �,

the interaction of effectiveness and socioeconomic status of the parents 𝑓�𝐸𝑝𝑠𝑡 � ∗ 𝑆𝐸𝑆𝑠𝑡 , the interaction

of effectiveness and the voting intensity in the election nearest the end of the contract 𝑓�𝐸𝑝𝑠𝑡 � ∗ 𝐿𝑆𝐶𝑝𝑠𝑡 ,


                                                      27
and an error 𝜀𝑝𝑠𝑡′ . Column 2 adds the interaction between voting intensity and parental SES and the full

three-way interaction between SES, voting intensity and effectiveness.

        The coefficients in the top panel of Table 9 reveal a strong, negative relationship between

principal value added prior to the contract event and the probability of exiting that appears to strengthen

as parental SES increases but weaken as voting intensity increases. Inclusion of the triple interaction in

the third column strengthens the negative effect of SES on the relationship between effectiveness and the

probability of exit at lower but not higher levels of participation.

        The bottom panel of Table 9 reveals a negative though only marginally significant relationship

between value added and the probability of leaving by CEO removal relative to continuation. CEO

removals comprise only three percent of outcomes, and given the inclusion of interaction terms the

imprecision of the estimates is not a surprise. Nonetheless, the magnitude of the main effect suggests that

moving from the 90th to the 10th percentile of the effectiveness distribution roughly doubles the

probability if the values of voting intensity and SES are set to zero; the difference is much larger for

schools near the middle of the SES and intensity distributions.



VI. Conclusions

        The devolution of authority over principals to local school councils constituted a major change in

the structure of school governance. Whether this had a substantial effect on the distribution of principal

effectiveness depends on both the underlying variance and the extent to which LSC heterogeneity

amplified or contracted the existing distribution at the time of the reform.

        The results reveal meaningful differences in principal effectiveness, confirming the importance of

the LSC responsibility over principal hiring and contract renewal. Not only is there significant variation in

principal effects that is strongly correlated with teacher survey responses regarding principal

performance, but an analysis of variance approach based on principal turnover that goes to great extent to

account for time-varying school differences and the dynamics of principal effects also shows substantial

variation in principal effectiveness.

                                                      28
        The analysis of LSC effects on the distribution of principal quality provides evidence consistent

with the notion that higher LSC management capacity improves decision-making and principal

effectiveness. There is also evidence of larger improvement in principal effectiveness following the end

of a contract in schools with higher voter participation and SES.

        The results provide reason to be concerned that decentralization may generate smaller

improvements and may even harm schools serving the least advantaged students in terms of parental SES

and election participation. Given the strong negative associations between school poverty and both SES

and voter intensity, this suggests that decentralization may be least beneficial for some of the highest

poverty schools.




                                                     29
Bibliography

Aghion, Philippe, and Jean Tirole. 1997. “Formal and Real Authority in Organizations.” SSRN Scholarly
        Paper ID 3743. Rochester, NY: Social Science Research Network.
        http://papers.ssrn.com/abstract=3743.
Bertrand, Marianne, and Antoinette Schoar. 2003. “Managing With Style: The Effect Of Managers On
        Firm Policies.” The Quarterly Journal of Economics 118 (4): 1169–1208.
Branch, Gregory F., Eric A. Hanushek, and Steven G. Rivkin. 2012. “Estimating the Effect of Leaders on
        Public Sector Productivity: The Case of School Principals.” NBER Working Paper 17803.
        National Bureau of Economic Research, Inc. http://ideas.repec.org/p/nbr/nberwo/17803.html.
Cannon, Sarah, David Figlio, and Tim Sass. 2013. “Principal Quality and the Persistence of School
        Policies.” Working Paper.
        http://www2.gsu.edu/~tsass/pdfs/Cannon%20Figlio%20Sass%20persistence%20of%20school%2
        0policies%20jan%204%202013%20-%20clean.pdf.
Chetty, Raj, John N. Friedman, and Jonah E. Rockoff. 2014. “Measuring the Impacts of Teachers I:
        Evaluating Bias in Teacher Value-Added Estimates.” American Economic Review 104 (9): 2593–
        2632. doi:10.1257/aer.104.9.2593.
Coelli, Michael, and David A. Green. 2012. “Leadership Effects: School Principals and Student
        Outcomes.” Economics of Education Review 31 (1): 92–109.
Eaton, Jonathan, and Samuel Kortum. 2002. “Technology, Geography, and Trade.” Econometrica 70 (5):
        1741–79. doi:10.1111/1468-0262.00352.
Haney, Leviis. 2011. “The 1995 Chicago School Reform Amendatory Act and the Cps Ceo: A Historical
        Examination of the Adminstration of Ceos Paul Vallas and Arne Duncan.” Dissertations,
        January. http://ecommons.luc.edu/luc_diss/62.
Kane, T. J., D. F. McCaffrey, T Miller, and D. O. Staiger. 2013. “Have We Identified Effective Teachers?
        Validating Measures of Effective Teaching Using Random Assignment.” MET Project Research
        Paper, Bill & Melinda Gates Foundation. http://ies.ed.gov/ncee/wwc/quickreview.aspx?sid=221.
Miller, Ashley. 2013. “Principal Turnover and Student Achievement.” Economics of Education Review 36
        (C): 60–72.
Rivkin, Steven G., Eric A. Hanushek, and John F. Kain. 2005. “Teachers, Schools, and Academic
        Achievement.” Econometrica 73 (2): 417–58.
Rothstein, Jesse. 2010. “Teacher Quality in Educational Production: Tracking, Decay, and Student
        Achievement.” The Quarterly Journal of Economics 125 (1): 175–214.
Ryan, Susan, Anthony S. Bryk, Gudelia Lopez, Kimberly P. Williams, Kathleen Hall, and Stuart
        Luppescu. 1997. “Charting Reform: LSCs—Local Leadership at Work.” Consortium on Chicago
        School Research.




                                                  30
                                               Table 1
                           Average Voting Intensity in LSC Election Cycles
                                by Quartile of Socioeconomic Status

                          Quartile of                           Average Voting
                          Socioeconomic Status                     Intensity
                            1st(Lowest)                              0.84
                            2nd                                      0.82
                            3rd                                      0.92
                            4th(Highest)                             1.60

                          Note. The quartile of socioeconomic status is based on
                          Census measures of education levels and share of adults
                          employed in managerial positions in the census block group
                          where each student lives. Prior to 2010, the measure is
                          based on the 2000 Census while from 2010 on it is based on
                          the 2010 ACS. Higher quartiles of socioeconomic status
                          indicate higher status. Voting intensity is calculated as the
                          number of votes cast for parents running for an LSC seat
                          divided by total school enrollment. Therefore, voting
                          intensity may exceed 1.




                                             Table 2
                The Distribution of Principal Transitions Experienced by Schools

                                                          Number of Principal Transitions
                                                          0     1       2       3      4+               Total
Share of schools (observed in any years)                14.63 18.75 25.71 21.59 19.31                   100%

Share of schools (observed in all years)                 0.68     20.95 32.43 26.01 19.94               100%

Note. The estimates are based on a school-level sample of all available schools (704 in total) between 1993-94
and 2013-14 schools years.




                                                       31
                           Table 3
Estimates of the Standard Deviation of Principal Effectiveness
 Based on Regressions with Principal by Year Fixed Effects

𝜎 of average effectiveness during entire
principal spell                                          0.110        0.078

𝜎of average effectiveness dropping last
and first years of spell                                 0.098        0.065

Removes school average                                     N            Y

Notes. All regressions control for student race, sex, special education status,
and socioeconomic status of the student’s block group, whether the student
is new to the school, school-grade averages of these characteristics, share of
grade repeaters, school enrollment, and year-by-grade fixed effects.




                                      32
                                                          Table 4
 Average Principal Value Added, by Teacher Responses to Survey Questions on the Principal


                                                                            Teacher Response
                                                    Strongly                                                     Strongly
                                                                          Disagree             Agree
                                                    Disagree                                                      Agree

The principal…
     Makes clear expectations                        -0.025                -0.017              -0.008              0.002
     Communicates clear vision                       -0.025                -0.018              -0.006              0.002
     Tracks student progress                         -0.023                -0.015              -0.007              0.003

Notes. Here we plot average value added by teacher’s responses to a series of questions about their principal, asked in 11 of
the years between 1994 and 2013. Teachers are asked if the principal “makes clear to the staff his or her expectations for
meeting instructional goals”; (2) “communicates a clear vision for our school”; and (3) “carefully tracks student academic
progress.”




                                                          Table 5
                    Relationship between Teacher Ratings and Estimated Principal
                                            Value Added

                                                                                (1)                 (2)
                Teacher’s principal rating index                            0.017***            0.013***
                                                                             (0.002)             (0.002)

                School fixed effect                                             N                    Y
                Notes. We regress estimated principal value added on an index of teacher’s rating of their
                principal. The index is based on responses to the three questions in Table 4. Each regression
                controls for school averages of student race, sex, special education, enrollment, share new
                students, parental SES, and year effects. Both regressions are based on 4,004 school-year
                level observations. Standard errors clustered by school are in parentheses. * p<0.10, **
                p<0.05, *** p<0.001




                                                              33
                                               Table 6
               School Fixed Effect Estimates of the Variance in Principal Effectiveness

                                                       (1)               (2)               (3)               (4)
Coefficient on principal transition                 0.0034**           0.0015           0.0037**           0.0029
indicator                                           (0.0015)          (0.0022)          (0.0019)          (0.0019)

Standard deviation                                    0.0414           0.0276            0.0429            0.0383

Exclude last and first years of spell                   N                 Y                 Y                  Y
Number of years between observations                   n.a.               1                 2                  3
within spells

Number of School-Year Observations                    8,514             6,139             5,062             4,141

Notes. The regressions correspond to the approach described in section IIIb. Principal Turnover Based Estimates.
The outcome is the squared difference in test scores between t and t-n, where n is the number of years between
observations, and the principal transition variable is an indicator equal to one if there is a new principal in year t.
The regressions also control for the squared difference in student race, sex, special education, and mobility, school
enrollment, and parental SES. Standard errors clustered by school are in parentheses. * p<0.10, ** p<0.05, *** p<0.001




                                                       Table 7
                      Distribution of Voting Intensity Conditional on Parental SES

                                      Quartiles of Voting Intensity
            Quartiles of              1st                       4th             All      Observations
            Parental SES           (Lowest) 2nd        3rd   (Highest)
              1st (Lowest)           0.32     0.25 0.24        0.19            1.00           318
              2nd                    0.23     0.29 0.32        0.16            1.00           312
              3rd                    0.26     0.29 0.23        0.22            1.00           320
              4th (Highest)          0.18     0.17 0.21        0.44            1.00           308

               Observations           314       317      314        313                      1,258




                                                          34
                                      Table 8
 The Effects of Parental SES and Voting Intensity in LSC Elections on the Change in
                               Principal Effectiveness

                                                                             (1)             (2)                 (3)
Parental SES                                                              0.0074*          0.0013              0.0016
                                                                         (0.0043)         (0.0047)            (0.0048)
Voting intensity                                                          0.0067*          0.0024              0.0017
                                                                         (0.0038)         (0.0045)            (0.0045)
Prior contract VA                                                        0.309***         0.308***            0.280***
                                                                          (0.046)          (0.046)             (0.060)
Voting intensity*prior contract VA                                            -               -                0.0249
                                                                                                              (0.0341)
Parental SES*voting intensity                                                             0.0051**            0.0047**
                                                                                          (0.0024)            (0.0024)

Sample size                                                                 767               767                767

Notes. We measure principal effectiveness as the change in value added from 𝑡 + 1 to 𝑡 + 2 from the first contract to the
second contract. LSC managerial capacity is measured by parental SES, which captures the share of adults working
managerial jobs in each student’s home census block. The strength of LSC incentives is measured by the voting intensity
during the election (i.e. total number of votes cast divided by school enrollment). Both capacity and incentives are
measured during the end of the previous contract. Each regression controls for the principal effectiveness at the same point
during the previous contract, the change in school average demographics and program characteristics, and year fixed
effects. Standard errors clustered by school are in parentheses. * p<0.10, ** p<0.05, *** p<0.001




                                                            35
                                 Table 9
Multinomial Logit Estimates of the Effects of Principal Effectiveness, SES,
and Voter Intensity on the Probability of a Principal Transition in an LSC
        Managed School and the Probability of a CEO Removal

                                                                             Relative to Continuation
                                                                          (1)                    (2)
Left Mid or End of Contract
    Value Added                                                       -3.619***                 -3.567***
                                                                        (0.795)                   (0.798)
    Voting Intensity                                                   0.170***                     0.120
                                                                        (0.057)                   (0.074)
    Parental SES                                                          0.023                     0.028
                                                                        (0.080)                   (0.097)
    Value Added*Voting Intensity                                        0.982**                     0.712
                                                                        (0.461)                   (0.467)
    Value Added*Parental SES                                             -1.021                  -2.326**
                                                                        (0.745)                   (0.959)
    Voting Intensity*Parental SES                                           -                      -0.007
                                                                                                  (0.043)
    Value Added*Voting Intensity*Parental SES                               -                     0.902**
                                                                                                  (0.410)
Left by CEO Removal
    Value Added                                                         -4.025*                   -4.443
                                                                        (2.372)                   (2.740)
    Voting Intensity                                                     -1.420                   -1.461
                                                                        (1.182)                   (1.089)
    Parental SES                                                         -0.295                   -0.590
                                                                        (0.641)                   (0.919)
    Value Added*Voting Intensity                                         -4.792                   -4.207
                                                                        (3.691)                   (3.707)
    Value Added*Parental SES                                             -3.100                   -4.143
                                                                        (3.936)                   (4.342)
    Voting Intensity*Parental SES                                           -                      0.668
                                                                                                  (0.877)
    Value Added*Voting Intensity*Parental SES                               -                      1.834
                                                                                                  (3.006)

Sample Size                                                              1,104                     1,104

Notes. The outcome takes on three possible values related to how the principal’s contract ends. We compare
principals who leave mid or end contract and those who leave by CEO removal to those who have their contract
renewed (the base outcome). Each regression also controls for school averages of student race, sex, special
education, enrollment, and share new students. Standard errors clustered by school are in parentheses. * p<0.10,
** p<0.05, *** p<0.001




                                                      36
