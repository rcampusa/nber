                                NBER WORKING PAPER SERIES




                         SUSTAINING COOPERATION:
            COMMUNITY ENFORCEMENT VS. SPECIALIZED ENFORCEMENT

                                          Daron Acemoglu
                                         Alexander Wolitzky

                                        Working Paper 21457
                                http://www.nber.org/papers/w21457


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                     August 2015




For helpful comments, we thank Nageeb Ali, Glenn Ellison, Matt Jackson, David Levine, Dilip Mookherjee,
Juuso Toikka, and seminar participants at Bonn, BU, Cambridge, Essex, the Canadian Institute for
Advanced Research, and the Stanford Institute for Theoretical Economics. The views expressed herein
are those of the authors and do not necessarily reflect the views of the National Bureau of Economic
Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2015 by Daron Acemoglu and Alexander Wolitzky. All rights reserved. Short sections of text, not
to exceed two paragraphs, may be quoted without explicit permission provided that full credit, including
© notice, is given to the source.
Sustaining Cooperation: Community Enforcement vs. Specialized Enforcement
Daron Acemoglu and Alexander Wolitzky
NBER Working Paper No. 21457
August 2015
JEL No. C73,D72,D74

                                             ABSTRACT

We introduce the possibility of direct punishment by specialized enforcers into a model of community
enforcement. Specialized enforcers need to be given incentives to carry out costly punishments. Our
main result shows that, when the specialized enforcement technology is sufficiently effective, cooperation
is best sustained by a “single enforcer punishment equilibrium,” where any deviation by a regular
agent is punished only once, and only by enforcers. In contrast, enforcers themselves are disciplined
(at least in part) by community enforcement. The reason why there is no community enforcement following
deviations by regular agent is that such actions, by reducing future cooperation, would decrease the
amount of punishment that enforcers are willing to impose on deviators. Conversely, when the specialized
enforcement technology is ineffective, optimal equilibria do punish deviations by regular agents with
community enforcement. The model thus predicts that societies with more advanced enforcement technologies
should rely on specialized enforcement, while less technologically advanced societies should rely on
community enforcement. Our results hold both under perfect monitoring of actions and under various
types of private monitoring.


Daron Acemoglu
Department of Economics, E18-269D
MIT
77 Massachusetts Avenue
Cambridge, MA 02139
and CIFAR
and also NBER
daron@mit.edu

Alexander Wolitzky
Department of Economics
Massachusetts Institute of Technology
50 Memorial Drive
Cambridge, MA 02142-1347
wolitzky@mit.edu
1    Introduction

Throughout history, human societies have used a variety of means and practices to foster pro-social
behavior among their members. Prominent among these is decentralized community enforcement,
where deviations from cooperative behavior are discouraged by the threat of withholding future co-
operation, or even the threat of the widespread collapse of cooperation throughout society. A large
literature in the social sciences, especially in game theory, provides conceptual foundations for this
type of enforcement. In small groups, where an individual’s behavior can be accurately observed
by other members of the community, the threat of exclusion or punishment is a powerful means of
supporting cooperation (Axelrod, 1984, Fudenberg and Maskin, 1986, Ostrom, 1990, Greif, 2006).
In large groups, where information about past behavior is more limited, cooperation can be sup-
ported by “contagion” strategies, which trigger the spread of non-cooperative behavior following
a deviation (Kandori, 1992, Ellison, 1994). Furthermore, several prominent examples, such as the
cooperative arrangements among the medieval Maghribi traders and their overseas agents (Greif,
1993) and the norms of behavior and compensation between ranchers and landowners in twen-
tieth century Shasta County, California (Ellickson, 1990) demonstrate the practical feasibility of
decentralized community enforcement.
    In modern societies, however, the basis of cooperative behavior is rather di¤erent. Major
transgressions are not directly punished by neighbors, nor do they trigger a contagion toward non-
cooperative behavior throughout society. Instead, they are directly punished by specialized law
enforcers, including the police, the courts, and other state and non-state institutions. Indeed,
following Thomas Hobbes and Max Weber, most social scientists view this type of specialized
enforcement as desirable, as well as inevitable both in societies with full-‡edged states and in those
with less developed proto-states (Johnson and Earle, 2000, Flannery and Marcus, 2012). Yet,
there exists little formal modeling of the foundations of such specialized enforcement. The goal of
this paper is to develop one model of specialized enforcement, and to compare the performance of
specialized enforcement and community enforcement in supporting cooperation.
    We consider a model of cooperation within a group of agents. In our baseline model, regular
citizens (“producers”) randomly match with each other, as well as with “specialized enforcers”
assigned to monitor their relationships. Each producer chooses a level of cooperation (e.g., a
contribution to a local public good or an investment in a joint project), which is costly for her
but generates bene…ts for her partners (both the other producers with whom she matches and
the enforcers who monitor them). Absent the threat of direct or indirect punishment, a producer
would choose zero cooperation. In this model, cooperation can be supported by contagion strategies
as in Kandori (1992) and Ellison (1994), where a deviation from pro-social behavior triggers the
withdrawal of cooperation throughout the entire community. Cooperation can alternatively be


                                                  1
supported by specialized enforcement— in which enforcers directly punish producers who deviate—
provided that enforcers can be given the proper incentives to behave in this way.1 And cooperation
can also be supported by any number of other strategies, as is typical in repeated games. Our
question then is not what kinds of strategies can support some cooperation, but rather what
strategies support the maximum possible level of cooperation at a …xed discount factor.
       Our simplest and sharpest results apply under perfect monitoring, where each agent observes
the entire past history of behavior. In this case, we establish a simple condition on the e¤ectiveness
of the specialized enforcement (direct punishment) technology under which the maximum level
of cooperation is sustained by a simple form of specialized enforcement— single enforcer punish-
ment strategies— wherein all punishment for producer deviations takes place instantaneously and
is carried out by enforcers, and there is no contagion or withholding of future cooperation. In our
baseline setting, enforcers are incentivized to undertake such costly punishments because, unlike
deviations by the producers themselves, deviations by enforcers trigger contagion among the pro-
ducers.2 Conversely, when direct punishments are ine¤ective, the maximum level of cooperation
is maintained by community enforcement. The model thus predicts that— for example— societies
with more advanced technology in both production and punishment should rely on specialized
enforcement, while less technologically advanced societies should rely on community enforcement.
       The form of our specialized enforcement equilibrium can be viewed as a stylized representation
of modern state-society relations. Enforcers’ incentives come from the fact that they themselves
bene…t from societal cooperation (either directly or, in an extension, because the revenues that pay
their salaries are generated by such cooperation), and societal cooperation depends on citizens’trust
in the integrity of the law enforcement apparatus. If this trust is damaged because the enforcers
representing the state deviate from their expected course of behavior, societal cooperation collapses,
and it is the prospect of such a collapse that incentivizes enforcers.
       The optimality of single enforcer punishment strategies in our model may appear surprising, as
one might have conjectured that it would be better to combine specialized enforcer punishments
with decentralized community enforcement: if both direct punishment and the withdrawal of coop-
eration are bad for producers, why not use both to provide incentives? The intuition for this result
helps highlight the novel economic mechanism at the heart of our paper. Adding decentralized
punishment— for example, some degree of contagion— to a given level of specialized punishment
would indeed improve producers’incentives for cooperation. And yet, crucially, it would also erode
the incentives of enforcers to undertake direct punishment: enforcers are willing to undertake costly
   1
     In practice, another important problem is ensuring that enforces do not use their access to violence to expropriate
others. At the level of abstraction of our model, this is similar to the problem of convincing enforcers to choose the
appropriate level of punishment in response to transgressions.
   2
     We also show that when enforcers can be directly punished by other enforcers, their deviations trigger both direct
punishment and the temporary withholding of cooperation by producers.



                                                           2
punishments today only because of the future reward of continued societal cooperation. Hence, if
a deviation by a producer also triggered partial or full contagion, then this implicit reward for
enforcers would be diminished, undermining the power of enforcer punishments. This reasoning
thus identi…es a novel— and in our setting, quite powerful— cost of decentralized punishment: its
negative impact on the extent and e¢ cacy of specialized punishment.
       The role of specialized punishment by enforcers and the tradeo¤ between community enforce-
ment and specialized enforcement generalize beyond the perfect monitoring case. First, we show
that for a fairly general class of information structures (including the possibility that each individ-
ual only observes play in her own past matches), single enforcer punishment strategies outperform
pure contagion when either the punishment technology is su¢ ciently e¤ective or the discount factor
is su¢ ciently large. Because pure contagion is optimal in this environment without the enforcers
(Wolitzky, 2013), this result immediately implies that the optimal equilibrium must rely on en-
forcers to some extent (though we do not completely characterize the optimal equilibrium in this
more general environment).
       Second, we establish that when individuals observe behavior in their partners’ most recent
matches, single enforcer punishment strategies form an optimal equilibrium unless the group can
somehow bene…t from the imperfections in the monitoring structure in this setting. While we show
by example that this is in fact possible in general, we also provide two natural settings in which
single enforcer punishment strategies are indeed optimal. First, this is the case if enforcers are
better informed than producers.3 Second, single enforcer punishment strategies are also optimal
under an additional stability requirement, which postulates that a single deviation by any single
individual is not su¢ cient to start contagion. We …nd this requirement attractive because it captures
another potential cost of decentralized community enforcement: the danger of contagion being
triggered accidentally by trembles or mistaken observations. Indeed, many accounts of cooperation
in societies with weak or absent states, such as Lewis’s (1994) study of Somalia, emphasize how
small transgressions can start major feuds, or even all-out tribal wars. Such accidental contagion
would also be triggered in our model under community enforcement if producers trembled with a
small probability. Under enforcer punishments, however, a similarly costly contagion can occur only
if both individual producers tremble and an enforcer trembles in response. This makes accidental
contagion much less likely under enforcer punishments.
       We also consider one main extension of our model, where we allow producers to directly
exclude— or ostracize— each other from the bene…ts of cooperation, while continuing to provide
bene…ts to enforcers. This extension softens the key tradeo¤ in our model between withdrawing
future cooperation from deviators and using the promise of future cooperation to give enforcers
   3
    The superior information of enforcers here might result from communication with producers, or from the enforcers’
being organized in some institution, such as a law enforcement agency.



                                                         3
incentives to punish. Nonetheless, the optimal arrangement in this setting either remains single
enforcer punishment strategies or becomes a combination of these strategies with the short-term
ostracism of deviant producers, thus establishing that the simple structure of optimal equilibria is
largely preserved in the presence of ostracism.
    Our paper is related to several di¤erent lines of research. First, we build on the literature
on community enforcement in repeated games, pioneered by Kandori (1992) and Ellison (1994),
by introducing costly punishments into this literature. Recent contributions to this literature
include Takahashi (2010), Deb (2012), and Deb and González-Díaz (2014). Most closely related
to our paper are Wolitzky (2013) and Ali and Miller (2014a), which provide conditions under
which contagion strategies support the maximum level of cooperation at a …xed discount factor in
repeated cooperation games without costly punishments. In contrast, we show that introducing
the possibility of costly punishments can radically change the structure of the optimal equilibrium
from contagion strategies to single enforcer punishment strategies.
    Several other papers in this literature emphasize various weaknesses of contagious strategies.
Jackson, Rodriguez-Barraquer, and Xu (2012) note that contagion strategies violate a renegotiation-
proofness condition, and focus instead on equilibria in which social breakdowns are contained
following a deviation. Lippert and Spagnolo (2010) and Ali and Miller (2014b) show that conta-
gion strategies discourage communication about past deviations, and argue for equilibria involving
temporary exclusion or ostracism. These papers do not consider specialized enforcers, and more
generally they do not investigate optimal equilibria in settings where contagion strategies are sub-
optimal.4
    Second, our paper is also related to the literature on optimal penal codes in general repeated
games (Abreu, 1988, see Mailath and Samuelson, 2006, for a survey), especially the “stick-and-
carrot” equilibria of Abreu (1986). In particular, our single enforcer punishment equilibria o¤er
the “stick” of specialized punishment for producers and the “carrot” of continued cooperation
for enforcers. However, while in Abreu (1986) stick-and-carrot equilibria are only optimal within
the class of strongly symmetric equilibria (i.e., under the restriction that play is symmetric at all
histories), we show that single enforcer punishment equilibria are globally optimal in our model
under perfect monitoring, and we also extend this result to certain classes of imperfect private
monitoring. Among other works in related environments, Padro-i-Miquel and Yared (2012) consider
stick-and-carrot equilibria in a political economy model, and Goldlücke and Kranz (2012) show that
stick-and-carrot equilibria are generally optimal in repeated games with transfers.
    Third, our work connects to the literature on the economic foundations of the enforcement
of laws and norms. Early contributions to this literature, including Ostrom (1990), Greif (1989,
  4
    A paper involving a form of ostracism that does resemble direct punishment is Hirshleifer and Rasmusen (1989).
They show that this behavior may support cooperation in the …nitely repeated prisoner’s dilemma.



                                                        4
1993), Milgrom, North and Weingast (1990), Greif, Milgrom and Weingast (1994), and Fearon and
Laitin (1996), focused on informal enforcement supported by “reputation” and various ostracism-
like arrangements. Dixit (2007) surveys and extends these early frameworks. A particularly relevant
contribution by Greif (1994) distinguishes between the “private order”institutions of the Maghribi
traders and the “public order” institutions of the rival Genoese traders— which resemble, respec-
tively, our community enforcement and specialized enforcement equilibria— and argues that public
order institutions proved more e¢ cient as the scope for trade expanded in the late medieval period.
Acemoglu and Jackson (2014) analyze the converse problem to the one in this literature: studying
how social norms can constrain the e¤ectiveness of laws that ban certain types of behavior. Ace-
moglu and Verdier (1998) study how law enforcers matched with pairs of producers can be used to
incentivize e¤ort, but must also be discouraged from corruption. Another closely related paper is
due to Levine and Modica (2014), who study the problem of designing a specialized enforcement
technology to sustain group cooperation and emphasize the tradeo¤ between providing insu¢ cient
incentives for cooperation and expending excessive e¤ort in punishment.
    Finally, to the extent that enforcer punishment strategies may be viewed as a type of formal
enforcement, our paper relates to the literature on the e¢ ciency of formal versus informal enforce-
ment of norms and contracts. Theoretical contributions include Kranton (1996) and Kali (1999).
Empirical studies of reputation-based contract enforcement include Fafchamps (1996), Clay (1997),
Woodru¤ (1998), McMillan and Woodru¤ (1999), and Johnson, McMillan, and Woodru¤ (2002).
    The rest of the paper is organized as follows. Section 2 presents the model. Section 3 presents
our main result on the optimality of specialized enforcement under perfect monitoring. Section 4
discusses various modeling issues. Section 5 presents our results with private monitoring. Section
6 extends the model to allow for ostracism. Section 7 concludes. Omitted proofs and additional
results are included in the Appendix.


2     Model

We …rst introduce the basic environment and information structure, and then de…ne the key con-
cepts of contagion strategies and single enforcer punishment strategies.

2.1   Environment

There is a population of (k + l) n players, with k; l; n    1. Out of the (k + l) n players, kn of them
are producers (or “citizens”) and ln of them are enforcers (or “police”). Denote the set of producers
by C, the set of enforcers by P , and the set of all players by N . In every period t = 0; 1; 2 : : :, the
players break into n matches uniformly at random, where each match consists of k producers and
l enforcers. Denote the match containing player i by Mi .


                                                    5
       The following two-stage game is played simultaneously in each match M . The game is a version
of the prisoner’s dilemma among the producers, with the possibility of costly punishment by the
enforcers.

   1. Cooperation Stage: Each producer i in match M chooses a level of cooperation xi 2 R+ before
         observing the identities of the other players in M .5 The vector (i; xi )i2M \C is then perfectly
         observed by all players in M . Choosing cooperation level xi costs xi for player i, and bene…ts
         every other player k 6= i in M by f (xi ), where f : R+ ! R+ is an increasing, concave,
         bounded, and di¤erentiable function satisfying f (0) = 0.

   2. Punishment Stage: Each enforcer j 2 M then chooses a level of punishment yji 2 R+ for each
         producer i 2 M \ C. The vector (j; i; yji )j2M \P;i2M \C is perfectly observed by all players in
         M . Choosing punishment level yji costs yji for player j, and hurts player i by g (yji ), where
         g : R+ ! R+ is an increasing, concave and di¤erentiable function satisfying g (0) = 0.6 We
         refer to g as the specialized enforcement technology.

       Thus, producer i’s stage game payo¤ is
                                       X                                 X
                                                  f (xi0 )      xi                 g (yji ) ;
                                    i0 2Mi \Cni                         j2Mi \P


and enforcer j’s stage game payo¤ is
                                                  X
                                                             (f (xi )    yji ) :
                                              i2Mj \C


Note that playing xi = 0 (“shirking”) is myopically optimal for producer i, and playing yji = 0 for
all i 2 Mj \ C (“failing to punish”) is myopically optimal for enforcer j. Thus, only the shadow
of future interactions can give producers incentives to cooperate, or give enforcers incentives to
punish.
       For some secondary results, we also consider a variation with “money burning,” in which pro-
ducers (resp., enforcers) are also allowed to publicly destroy some of their own utility at the same
time that they choose their level of cooperation (resp., punishment). The only di¤erence between
this type of money burning and cooperation (resp., punishment) is that cooperation (resp., punish-
ment) also bene…ts (resp., hurts) other players. We explicitly indicate below which of our results
involve the possibility of money burning.
   5
     We refer to the feature that producers act without knowing their partners’identities as partial anonymity. This
assumption plays an important role in our results, as we discuss further in Section 4.
   6
     The assumption that f is bounded is stronger than necessary and can be replaced by the mild assumptions that
(1) limx!1 (k 1) f (x) x = 1, and (2) there exists x0 2 R+ such that lg 1 kf (x)                x < 0 for all x > x0 .
These assumptions hold if, for example, g 0 is bounded and f satis…es the Inada condition limx!1 f 0 (x) = 0.


                                                                6
       We refer to the pair         (i; xi )i2M \C ; (j; i; yji )j2M \P;i2M \C   as the outcome of match M .
Throughout the paper, we maintain the assumption that players perfectly observe the outcomes of
their own matches, while varying players’information about the outcomes of other matches. With
perfect monitoring, players observe the outcomes of all matches at the end of each period. We
also consider two di¤erent versions of private monitoring— detailed below— where players have less
information about what goes on outside their own matches. In all versions of the model, we let hti
denote a generic history of player i’s at the beginning of period t, where we omit the subscript in
the perfect monitoring case. The trivial initial history is denoted by h0 . We also denote a generic
strategy of player i’s by      i.   For example, if player i is a producer, then         i   hti 2    (R+ ) denotes
player i’s mixed action at history        hti .
       Players maximize expected discounted payo¤s with common discount factor . The solution
concept with perfect monitoring is subgame perfect equilibrium (SPE). The solution concept with
private monitoring is weak perfect Bayesian equilibrium (PBE), with the additional requirement
that the equilibrium assessment is derived from a common conditional probability system (Myerson,
1991).7
       Note that the assumptions that f and g are concave imply that there is a technological advantage
to spreading out both cooperation and punishments over time. Nevertheless, we will show that,
while optimal equilibria do spread cooperation over time, they do not spread punishments over
time. Instead, optimal equilibria either do not use punishments at all or concentrate them in a
single period.

2.2      Contagion Strategies and Single Enforcer Punishment Strategies

Given a path of play of the repeated game, let xti denote producer i’s level of cooperation in period
t, and let
                                                                 1
                                                                 X
                                                  Xit = (1   )        xt+
                                                                       i
                                                                 =0

denote producer i’s present discounted level of cooperation starting in period t. From the perspec-
tive of a given equilibrium of the game, xti and Xit are (possibly degenerate) random variables. We
refer to the quantity E Xi0 jh0 as player i’s average level of cooperation in a given equilibrium.
We say that an equilibrium is the most cooperative one if it simultaneously achieves the highest
value of E Xi0 jh0 for every player i among all equilibria (with the solution concept of SPE for
the perfect monitoring version and PBE for the private monitoring version); and we call the corre-
sponding value of E Xi0 jh0 the maximum level of cooperation. Note that, by concavity of f , the
   7
    Another approach would have been to discretize the action space and use sequential equilibrium. This would
lead to the same results, except that with discrete actions the equilibria we characterize would be only approximately
rather than exactly optimal.



                                                             7
most cooperation equilibrium is also the optimal equilibrium in terms of utilitarian social welfare if
producers choose constant levels of cooperation on path, punishments are not used on path, and the
maximum level of cooperation is below the …rst-best level, xF B , given by (k + l    1) f 0 xF B = 1.
This is indeed the main case of economic interest, as the main problem in most settings is provid-
ing su¢ cient incentives for cooperation rather than avoiding excessive levels of cooperation. If, on
the other hand, the maximum level of cooperation is above xF B , we will focus on equilibria with
cooperation level xF B .
   Our main concern is whether optimal equilibria are based on punishment by enforcers (special-
ized enforcement) or the withdrawal of future cooperation by producers (community enforcement).
An extreme form of community enforcement, where enforcers are completely inactive, is given by
contagion strategies.

De…nition 1 A contagion (or grim trigger) strategy pro…le is characterized by a cooperation level
x 2 R+ and is represented by the following 2-state automaton:
   Producers have two states, normal and infected. Producers play xi = x in the normal state and
play xi = 0 in the infected state. Producers start in the normal state, and permanently transition
to the infected state if they observe the outcome of a match (including their own) in which some
producer i0 2 C plays xi0 6= x.
   A contagion strategy pro…le involves no punishment by enforcers.

   On the other hand, an extreme form of specialized enforcement, where there is no withdrawal of
future cooperation at all following a deviation, is given by what we call “single enforcer punishment
strategies.”With these strategies, a producer who deviates is immediately punished by the enforcers
in her match. Following this single punishment, everyone returns to her “normal” behavior next
period. If however an enforcer fails to punish a producer deviation, then this triggers contagion,
and eventually all producers choose xi = 0.

De…nition 2 A single enforcer punishment strategy pro…le is characterized by a cooperation level
x and a punishment level y, and is represented by the following 2-state automaton:
   All players have two states, normal and infected. Play in the two states is as follows:
   Normal state: Producer i plays xi = x. If all producers i 2 Mj \ C play xi = x, then enforcer j
plays yji = 0 for all i 2 Mj \ C. If instead some producer i 2 Mj \ C plays xi 6= x, then enforcer j
plays yji = y for one of the producers i 2 Mj \ C who played xi 6= x— choosing arbitrarily if more
than one producer i played xi 6= x— and plays yji0 = 0 for all i0 2 Mj \ Cni.
   Infected state: Players always take action 0 (producers never cooperate; enforcers never punish).
   Players start in the normal state, and permanently transition to the infected state if they observe
the outcome of a match (including their own) in which some producer i plays xi 6= x and some
enforcer j 2 Mi \ P then plays yji0 6= y for all i0 2 Mj \ C.

                                                  8
        With perfect monitoring, everyone transitions to the infected state simultaneously under single
enforcer punishment strategies (or contagion strategies). With private monitoring, transitions to
the infected state follow a more general process of contagion, described below. Note that we have
speci…ed that if two producers deviate simultaneously, the corresponding enforcer is supposed to
punish one of them.8
        Note also that under both contagion and single enforcer punishment strategies, punishments
are not used on path and producers choose constant levels of cooperation. This implies that
whenever a contagion equilibrium or a single punishment equilibrium sustains the maximum level
of cooperation, it is also the optimal equilibrium in terms of utilitarian social welfare (provided
that, as noted above, this maximum level of cooperation is below the …rst-best level).


3        Perfect Monitoring

We now characterize the most cooperative equilibrium under perfect monitoring.
        Let (x ; y ) be the greatest solution to the following system of equations:

                                             x     = lg (y ) ;
                                             y     =             kf (x ) :
                                                        1

Intuitively, x and y are the greatest levels of cooperation and punishment that can be sustained
with single enforcer punishment strategies. With these strategies, a producer who deviates gains
at most x (her cost of e¤ort) and loses lg (y ) (the cost of being punished at level y by l en-
forcers), while an enforcer who deviates gains at most y and loses                1   kf (x ) (the future bene…t
of cooperation at level x from k producers).
        Similarly, let x
                       ^ be the greatest solution to the equation

                                                 x
                                                 ^ = (k         1) f (^
                                                                      x) :

Intuitively, x
             ^ is the greatest level of cooperation that can be sustained with contagion strategies.
        Finally, de…ne the parameter
                                                   (k 1) n
                                            m               2 [0; 1] :
                                                   (kn 1) l
Note that m depends only on the number of producers and enforcers in the population, and not on
the production and punishment technologies f and g or the discount factor .
        Our main result for the perfect monitoring version of the model is the following:
    8
    The alternative speci…cation where simultaneous deviations are ignored would work just as well with perfect
monitoring, but it would lead to some complications with private monitoring, where a single deviation at an earlier
history could lead two producers to shirk simultaneously at a later history where some players are still in the normal
state.


                                                            9
Theorem 1 With perfect monitoring,

   1. If g 0 (y)       m for all y 2 R+ , then the single enforcer punishment strategy pro…le with co-
         operation level x and punishment level y is the most cooperative equilibrium. In addition,
         for every x     x , the single enforcer punishment strategy pro…le with cooperation level x and
         punishment level y =     1   kf (x) is a SPE.

   2. For all " > 0, there exists          > 0 such that if g 0 (y) <         for all y 2 R+ , then the contagion
         strategy pro…le with cooperation level x
                                                ^ attains within " of the maximum level of cooperation.

       The …rst part of Theorem 1 is the most important: single enforcer punishment strategies attain
the maximum level of cooperation whenever the specialized enforcement technology, g, is su¢ -
ciently e¤ective.9 The intuition for this result is instructive. To give a producer the strongest
possible incentive to cooperate, her continuation payo¤ after a deviation must be made as low as
possible. Ideally, her continuation payo¤ would be reduced in two ways: enforcers would punish
her, and other producers would refuse to cooperate with her. However, enforcers are only willing
to exert e¤ort in punishing the deviator if they are subsequently rewarded with cooperation from
the producers. Since cooperation bene…ts both producers and enforcers, there is no way for pro-
ducers to reward enforcers for punishing the deviant producer without also providing bene…ts for
the deviator herself.10 Society must then choose between incentivizing enforcers to punish devi-
ators by subsequently restoring cooperation (single enforcer punishment strategies), or giving up
on enforcer punishments and instead providing incentives by withdrawing cooperation following a
deviation (contagion strategies).
       We can quantify the tradeo¤ between incentivizing enforcers to undertake punishment and
incentivizing producers directly by withdrawing cooperation as follows. Consider a history following
a producer deviation. The direct e¤ect of reducing another producer’s level of cooperation at such a
                                                                    k 1 0                      k 1
history by one unit is to reduce the deviator’s payo¤ by           kn 1 f (x)   units (here   kn 1   is the probability
that the deviator matches with a given producer in any period). This e¤ect increases on-path
incentives for cooperation. This direct e¤ect is however countered by the indirect e¤ect of reducing
the maximum level of punishment an enforcer is willing to impose on the deviator. In particular,
reducing the producer’s level of cooperation by one unit reduces the amount of punishment each
                                                  1 0                    1
enforcer can be induced to provide by             n f (x)   units (as    n   is the probability that the enforcer
in question matches with a given producer in any period), and each unit of reduced punishment
increases the deviator’s payo¤ by lg 0 (y) (as the deviator is punished by l enforcers). Thus, the
   9
     The relevance of the observation that any cooperation level below x can also be supported in a single enforcer
punishment equilibrium is simply that such equilibria remain optimal even when x is above xF B .
  10
     In Section 6, we study how the structure of the optimal equilibrium changes if we allow for ostracism : the practice
of excluding deviators from the bene…ts of cooperation.



                                                            10
                                                                                  l 0     0
indirect e¤ect of reducing on-path incentives for cooperation is                  n f (x)g (y).     Consequently, the
overall impact of withdrawing producer cooperation following a deviation on on-path producer
                                                        (k 1)n
incentives is negative if and only if g 0 (y)           (kn 1)l   = m. Therefore, if g 0 (y)          m for all y, it is
better not to reduce a producer’s level of cooperation after another producer has deviated, instead
relying on enforcer punishments and returning to full cooperation following these punishments.11
       In addition to showing that community enforcement should not be used (if g 0 (y)                     m for all y),
part 1 of Theorem 1 shows that a deviator should only be punished by enforcers once. This might
come as a surprise, since enforcers observe producers’identities at the point where they decide how
much to punish, and therefore have the ability to punish a deviator over and over again for the
same transgression. Yet, such behavior would be strictly suboptimal: the deviator would not be
willing to return to working during such an extended phase of punishment, and her continuation
payo¤ from being punished once and then returning to work is just as low as her continuation payo¤
from being punished repeatedly while shirking (and in fact it is strictly lower, as the deviator’s own
future cooperation can be used to give enforcers additional incentives to punish her).
       The proof of Theorem 1 (in Appendix A) also shows that if g 0 (y) is strictly greater than m for
all y, then the single enforcer punishment strategy pro…le with cooperation level x and punishment
level y is essentially the unique most cooperative equilibrium. Speci…cally, any equilibrium that
supports cooperation level x for each producer must have the following features:

   1. Each producer i plays xi = x at every on-path history.

   2. If a single producer i deviates to xi = 0 at an on-path history, she is punished at level y ,
         and the path of play then returns to all producers’playing x forever.

   3. If a single producer i deviates to xi = 0 at an on-path history and an enforcer j 2 Mi \ P
         deviates to yji = 0, then all producers stop cooperating forever.

   4. The path of continuation play where all producers play x forever is always supported by
         the threat of punishment at level y — which in turn is always supported by the threat of all
         producers’withdrawing cooperation— even when this continuation path starts at an o¤-path
         history.12

       Theorem 1 holds whether or not money burning is available. In addition, when money burning
is available, the lower bound on g 0 in part 1 of the theorem is tight:
  11
     The derivative condition g 0 (y) m for all y 2 R+ can also be weakened to the slope condition g(ff(x))   (^
                                                                                                                  g(y)
                                                                                                               x) y
                                                                                                                         m
for all y f (x), where x is de…ned as the greatest level of cooperation ever played in any SPE.
  12
     There are, however, other equilibria which support cooperation level x and di¤er from single punishment strate-
gies in various inessential ways. For example, equilibrium play after multiple simultaneous deviations can be speci…ed
arbitrarily, and there is some ‡exibility in specifying play after deviations to actions that are less tempting than xi = 0
and yji = 0.


                                                            11
Proposition 1 With perfect monitoring, if g 0 (y) < m for all y 2 R+ and money burning is
available, then single enforcer punishment strategies are not optimal.

    Proposition 1 shows that, if g 0 (y) < m for all y, then optimal equilibria must involve some form
of community enforcement (at least when money burning is available), meaning that deviations will
be punished not only by specialized enforcement but also by the withholding of future cooperation
(see Section 6). In the extreme case where g 0 (y) is close to 0 for all y, the second part of Theorem
1 shows that pure contagion strategies are approximately optimal.13
    However, there is a sense in which Proposition 1 overstates the case for hybrid forms of com-
munity enforcement. If a social planner has the option to decide whether some agents should
become either specialized enforcers or producers who contribute to societal cooperation, she may
prefer to forgo the limited increase in the level of cooperation that these enforcers a¤ord and also
consequently choose a simpler form of community enforcement. The next theorem establishes that,
when a social planner has such a choice and the specialized enforcement technology is not highly
e¤ective, the optimal arrangement is to forgo the presence of enforcers and rely on pure contagion
strategies.

Theorem 2 Suppose a social planner can choose k and l (along with an equilibrium) subject to
k + l = s to maximize utilitarian social welfare. Then, assuming the maximum level of cooperation
is below the …rst best level, if
                                                (                     )
                                                              1
                                 g 0 (y)   min m;     1
                                                                          for all y 2 R+                            (1)
                                                      n   +   1   s

then the social planner would prefer to have all agents become producers (i.e., set k = s) and support
cooperation using contagion strategies.

    Thus, except when         is very large (in which case the right-hand side of (1) goes to 0), in much
of the region covered by Proposition 1, pure contagion is the optimal arrangement that accounts
for the social cost of allocating individuals to enforcement roles.
    Finally, we emphasize that Theorem 1 and Proposition 1 show that single enforcer punishment
equilibria are optimal if the specialized enforcement technology g is su¢ ciently e¤ective, and that
community enforcement is optimal if this technology is ine¤ective. These conclusions are inde-
pendent of the production technology f : improvements in the production technology increase the
greatest level of cooperation that can be sustained in both single enforcer punishment equilibria
   13
      It is clear that contagion/grim trigger strategies would be optimal in the current model without the enforcers,
or equivalently if g (y) = 0 for all y. Given this, the second part of Theorem 1 is not very surprising. However, note
that the assumption that g 0 (y)        for all y does allow g to be unbounded, so this result is not completely trivial
(for example, it would not be true for Nash equilibrium rather than SPE).



                                                          12
and contagion equilibria in the same manner, so improvements in the production technology can-
cel out when comparing the two kinds of equilibria. An interesting implication is that, provided
the e¢ ciency of production and punishment technologies are positively related across di¤erent
societies, Theorem 1 predicts that societies with more advanced technology should rely on sin-
gle enforcer punishment strategies, while societies with less advanced technology should rely on
contagion strategies.


4     Discussion of Model Assumptions

Before turning to the private monitoring version of the model, we brie‡y discuss several of our
underlying assumptions, indicating how our results and their interpretation do or do not depend
on the various assumptions.

4.1   Assumptions about the Role of Enforcers

Enforcers can only punish producers: We have assumed that enforcers can punish producers but not
other enforcers. Changing this assumption by also letting enforcers punish each other would change
very little about our results. Speci…cally, one would rede…ne single enforcer punishment strategies
to specify that, if an enforcer fails to punish a deviant producer in period t, then in period t + 1
there is no production and the deviant enforcer is punished, while cooperation resumes in period
t + 2. With this modi…ed de…nition, Theorem 1 applies verbatim, with the sole modi…cation that
the formula for y changes from    1   kf (x ) to   1    (kf (x ) + (l   1) g (y )). (The formula for x
as a function of y remains lg (y ).) See the Appendix for a formal statement and proof.
    Thus, our comparison between community and specialized enforcement as means of sustaining
cooperation by producers is robust to letting enforcers punish each other. All that changes is
that now the enforcers themselves are incentivized by a mix of withdrawn cooperation and direct
punishment, rather than by the breakdown of cooperation alone.
    An alternative way of extending the model along these lines would be to introduce a hierarchy
of enforcers with K levels, where “level 1” enforcers can punish producers, “level 2” enforcers can
punish level 1 enforcers, and so on. The structure of single enforcer equilibria also extends to
this setting in a natural way, where each enforcer is incentivized by the threat of punishment from
enforcers one level up, and the top-level enforcers are incentivized by the threat of contagion among
producers. This variant gives a more realistic model of modern state-society relations: cooperation
throughout society does not break down the moment a low-level policeman fails to do his job, but
only if this is followed by a breakdown of enforcement at all higher levels.
    Partial Anonymity: In our baseline model, producers choose how much to cooperate before
observing their partners’identities, while identities are revealed before enforcers act. Our results


                                                   13
also apply exactly if, instead, players are completely anonymous and their identities are never
revealed. We prefer our baseline assumptions because they emphasize that, even though enforcers
have the ability to identify and punish a deviator repeatedly, the optimal equilibrium involves only
a single round of punishment.
   On the other hand, the assumption that players are anonymous at the cooperation stage plays
an important role in our analysis. Without this assumption, it may be possible to exclude a
deviator from future cooperation without also excluding the enforcers who punished her, which
would let deviators be punished more harshly. In Section 6, we discuss an extension where the use
of ostracism makes this type of selective exclusion possible.
   This assumption of partial anonymity could also be replaced by one of several alternatives.
In Section 5, we introduce the notion of non-discriminatory strategies, in which an individual’s
behavior does not depend on her partners’identities, except insofar as this is informative of past
play. The point of our partial anonymity assumption is to guarantee that strategies are non-
discriminatory, and all our perfect monitoring results can be derived by replacing partial anonymity
with the requirement that strategies are non-discriminatory. We also note that the strongly sym-
metric strategies of Abreu (1986) (which impose symmetric play at all histories), are necessarily
non-discriminatory, so without anonymity single enforcer punishment equilibria are also optimal
in the class of strongly symmetric equilibria. Finally, as we discuss in Section 6, single enforcer
punishment equilibria are also optimal even without anonymity when n = 1.
   Separate roles for producers and enforcers: We have assumed that only some agents have the
ability to cooperate, and that other, distinct agents have the ability to punish. This implies
that the worst continuation play for enforcers is the withdrawal of cooperation, while the best
continuation play for enforcers is the most cooperative equilibrium path itself. Both of these
features are needed for stick-and-carrot equilibria to be optimal, and to take the simple form of single
enforcer punishment equilibria. If all agents could both cooperate and punish, then the mechanics
of the model would be closer to those of Abreu (1986). As in Abreu, stick-and-carrot equilibria
would remain optimal under the assumption of strong symmetry, while globally optimal equilibria
would be more complex. Thus, our assumption that some agents specialize in cooperation while
others specialize in punishment is a deviation from standard models in a direction that contributes
to both realism and tractability.

4.2   Assumptions about Payo¤s

Public goods versus bilateral cooperation: We have assumed that the bene…ts of cooperation are
“non-excludable” within a match, and thus have the ‡avor of a public good (but see Section 6
below). An alternative model without this ‡avor is the following: players match in pairs, and
do not observe whether their partner is a producer or an enforcer until the end of the period.

                                                  14
Thus, cooperation bene…ts only one’s (unique) partner, and, at the time she chooses her level of
cooperation, a producer does not know whether she is matched with another producer (whom she
could pro…tably cheat) or an enforcer (who would punish her if she cheated). All of our results
readily translate to this slightly modi…ed setup.
    Enforcer payo¤ s: In addition to the public good and anonymous bilateral cooperation interpre-
tations of our model, a third way to motivate why enforcers’payo¤s depend on producers’levels of
                                                                                    P
cooperation is to assume that the enforcers can impose a tax on the producers’output i2C f (xi )
of up to some maximum rate          < 1, with the proceeds split equally among themselves. If an
enforcer’s failure to punish a deviant producer leads to contagion, each enforcer’s future bene…ts
then decline because the tax revenues that determine their payo¤s dry up.
    Enforcer misbehavior: In our model, enforcer misbehavior takes the form of enforcers’not un-
dertaking costly punishments following a deviation by a producer. Though this is an important
consideration in some settings (e.g., motivating law enforcement to pursue powerful individuals or
to refuse bribes from law-breakers), an equally salient concern is enforcers’misusing their positions
to expropriate citizens. Introducing this type of misbehavior need not materially complicate our
analysis, because our equilibrium construction is already based on giving enforcers the strongest
possible incentives to carry out costly punishments. Therefore, if expropriating citizens is as observ-
able as is failing to carry out punishments, then the same construction that maximizes enforcers’
incentives to punish will minimize their incentives to expropriate.
    The specialized enforcement technology: The specialized enforcement technology g measures
how much disutility an enforcer must incur to impose a given level of disutility on a producer. This
is not to be interpreted as, say, the level of sophistication of a society’s instruments of torture, which
after all were remarkably advanced even in primitive societies. Rather, it should be interpreted as
the cost— and the risk— to enforcers of undertaking the entire process of investigating, pursuing,
apprehending, and punishing deviators. This cost was presumably much greater in early societies—
where the weapons, technology, and organization available to law enforcement and to criminals were
much closer to each other— than it is today.


5    Private Monitoring

The perfect monitoring version of our model has the advantage of bringing out our main insights
on the optimal structure of specialized enforcement in a particularly simple way. Yet, perfect mon-
itoring is generally not a satisfactory assumption for studying community enforcement, as one of
the main motivations for analyzing these settings is to understand how groups can sustain coop-
eration when individuals have limited information about each other’s past behavior. We therefore
turn to the question of whether single enforcer punishment equilibria remain optimal under private


                                                    15
monitoring. Our answer is nuanced but generally positive: single enforcer punishment equilibria
still outperform contagion equilibria in a wide range of private monitoring environments, and in
some environments they remain optimal among all equilibria satisfying some natural conditions.
     More speci…cally, we …rst provide conditions under which single enforcer punishment equilib-
ria outperform contagion equilibria under general network monitoring, where players observe the
outcomes of their own matches, as well as possibly the outcomes of some other random matches
in the population. We then consider a setting with observable last matches, where a player ob-
serves the outcomes of her own matches and the outcome of each of her current partner’s most
recent matches. This informational assumption is inconsistent with players’remaining completely
anonymous at the point where producers take actions, so it sometimes gives players more informa-
tion than does the perfect monitoring model of Section 3. With this information structure, single
enforcer punishment strategies continue to sustain the same level of cooperation as with perfect
monitoring, which implies that they must remain globally optimal unless it is possible to sustain
more cooperation with observable last matches than with perfect monitoring. While we show that
this is in fact possible, we also establish that single enforcer punishment equilibria continue to be
optimal either if enforcers are perfectly informed (which may be a consequence of their organiza-
tion in an information-sharing institution, such as a police force), or if we impose a requirement of
stability in the face of individual trembles.

5.1    General Network Monitoring

The setting considered here is one of general network monitoring (Wolitzky, 2013). At the end of
each period t, a monitoring network Lt = (li;j;t )i;j2N        N,   li;j;t 2 f0; 1g is drawn independently
                                                           2
from a …xed probability distribution          on f0; 1gjN j . We assume that Pr         (li;j;t )i;j2N   N   =
Pr     l   (i); (j);t i;j2N N   for any permutation    : N ! N , so the distribution over networks is
invariant to relabeling the players. Player i perfectly observes the outcome of match M0 if and
only if li;j;t = 1 for some j 2 M0 . Otherwise, player i observes nothing about the outcome of match
M0 . Assume that li;i;t = 1 with probability one, so players always observe the outcome of their
own matches. We analyze the performance of contagion strategies and single enforcer punishment
strategies in this setting.
     With contagion strategies, let dt be the expected number of producers who become infected
within t periods of a producer deviation. (See the Appendix for a formal de…nition.) Intuitively,
dt is the expected number of producers who have observed a producer who has observed a pro-
ducer who. . . has observed the deviator within t periods. It follows from standard arguments
(e.g., Wolitzky, 2013) that the greatest level of cooperation that can be sustained with contagion




                                                      16
strategies, x
            ^, is given by the greatest solution to
                                                    1
                                                    X
                                                          t    k 1
                                   x
                                   ^ = (1       )                  (dt   1) f (^
                                                                               x) :
                                                              kn 1
                                                    t=0

    With single enforcer punishment strategies, let qt be the expected number of producers who
become infected within t periods of an unpunished producer deviation. (Again, see the Appendix
for details.) Note that a player now becomes infected only if both a producer and an enforcer in a
match she observes are already infected, as only then does she see a producer’s failure to cooperate
go unpunished. Infection therefore spreads more slowly with single enforcer punishment strategies
than with contagion strategies, and in particular qt is always less than dt . We will show that an
upper bound on the greatest level of cooperation and punishment that can be sustained with single
enforcer punishment strategies is given by the greatest solution to

                                            x       = lg (y ) ;
                                                      X1
                                                           t1
                                            y       =           qt f (x ) :
                                                            n
                                                          t=0

We also show that the resulting strategy pro…le is indeed part of a PBE whenever x is su¢ ciently
high (which holds, for example, if         is su¢ ciently high).14
    We can now inspect the formulas for x
                                        ^ and x and make some basic observations about the
relative performance of contagion and single enforcer punishment strategies. First, when the spe-
cialized enforcement technology is more e¤ective (i.e., g is steeper), single enforcer punishment
equilibria have an advantage over contagion strategies. Second, to the extent to which dt is strictly
greater than qt , contagion strategies have an advantage. Third, as both dt and qt converge to kn
as t ! 1, this advantage of contagion strategies vanishes when                        is close to 1. Indeed, single
enforcer punishment strategies have a clear advantage when                    is close to 1, owing to the (1        )
term in the de…nition of x
                         ^. This term re‡ects the fact that with contagion strategies, a producer
who chooses x = 0 forever can only lose the future bene…t of others’cooperation once, while with
single enforcer punishment strategies, a producer who shirks forever is punished in every period,
and each punishment is calibrated so as to be as costly for the enforcer as losing all future bene…ts
of cooperation would be. Presumably, optimal equilibria in this setting would take advantage of
enforcers’ ability to punish while also providing incentives for spreading information faster than
   14
      To see why such a condition is required, consider the incentives of a producer in the infected state who …nds
herself with the belief that all of the other producers in her match are in the normal state, while exactly one of the
enforcers in her match is in the infected state. If this producer works, she avoids being punished at level y by each
the l 1 enforcers in her match in the normal state, but also avoids triggering contagion (because, if she shirked, the
infected enforcer’s failure to punish her would trigger contagion). When x is su¢ ciently high, this new incentive
for cooperation coming from the desire to avoid triggering contagion is necessarily less than the incentive coming
from being punished at level y by the lth enforcer. In this case (but not otherwise), the fact that the producer is
indi¤erent between working and shirking on path implies that she prefers to shirk when one enforcer is infected.


                                                              17
single enforcer punishment strategies. As providing incentives for strategic communication of this
kind is beyond the scope of this paper, we content ourselves with comparing the performance of
single enforcer punishment strategies and contagion strategies.
       The next theorem formalizes this comparison. The …rst part shows that, when the specialized
enforcement technology is su¢ ciently e¤ective, single enforcer punishment equilibria support more
cooperation than do contagion equilibria. The second part establishes that the same conclusion
holds when the discount factor           is su¢ ciently high.

Theorem 3 With general network monitoring,

   1. There exists g such that if g 0 (y)        g for all y 2 R+ then single enforcer punishment strategies
         form a PBE strategy pro…le and support greater cooperation than contagion strategies.

   2. Assume that limy!1 g (y) = 1.15 Then there exists                       such that if             then single en-
         forcer punishment strategies form a PBE strategy pro…le and support greater cooperation than
         contagion strategies.

       We also note that comparing single enforcer punishment equilibria and contagion equilibria is
not as ad hoc at it might seem, as there is a sense in which contagion equilibria are optimal among
all equilibria in which enforcers never punish. In particular, Wolitzky (2013) shows that under
general network monitoring without enforcers, contagion strategies attain the maximum level of
cooperation (provided that the realized monitoring network is observable). Thus, whenever single
enforcer punishment equilibria outperform contagion equilibria, they outperform any equilibrium
that does not somehow rely on the enforcers.16

5.2      Observable Last Matches

We now turn to the second of the two private monitoring environments we consider: the observable
last matches setting. This is the setting where players observe only the outcomes of their own
matches and their current partners’most recent matches.
  15
      The resulting asymmetry between the functions f and g is not essential for this result. If the assumption that f
is bounded is relaxed, as discussed in footnote 6, the result still holds as long as limx!1 f 0 (x) < 1=l (k 1), which
is consistent with f = g and limy!1 g (y) = 1.
   16
      However, recall that our notion of optimality is in terms of supporting a higher level of cooperation. As we
have emphasized, this notion corresponds to optimality in terms of utilitarian social welfare if this maximum level
of cooperation is below the …rst-best level, but not necessarily otherwise. This caveat is especially important for high
discount factor results like part 2 of Theorem 3, as for very high discount factors both the most cooperative single
enforcer punishment equilibrium and the most cooperative contagion equilibrium are sure to involve an ine¢ ciently
high level of cooperation, so whichever supports a higher level of cooperation will actually be worse in terms of welfare.
Thus, the main point of Theorem 3 is not that single enforcer punishment strategies outperform contagion strategies
in the ! 1 limit per se, but rather that they outperform contagion strategies for moderately high discount factors
where the maximum level of cooperation may still be below the …rst-best level.




                                                           18
5.2.1     Single Enforcer Punishment Equilibria and Contagion Equilibria

We start with a benchmark result, which establishes that both single enforcer punishment equilibria
and contagion equilibria do exactly as well with observable last matches as they do with perfect
monitoring. In particular, any comparison between single enforcer punishment equilibria and con-
tagion equilibria with observable last matches is exactly the same as in the perfect monitoring
case.
   As in the previous section, existence of a single enforcer punishment equilibrium requires an
additional condition. In particular, let x
                                         ~ be the greatest solution to x
                                                                       ~ = l (k     1) f (~
                                                                                          x).

Theorem 4 With observable last matches,

  1. If x       x
                ~, then the single enforcer punishment strategy pro…le with cooperation level x and
        punishment level y is a PBE strategy pro…le. Furthermore, x is an upper bound on the level
        of cooperation in any single enforcer punishment equilibrium.

  2. The contagion strategy pro…le with cooperation level x
                                                          ^ is a PBE strategy pro…le. Furthermore,
        x
        ^ is an upper bound on the level of cooperation in a contagion equilibrium.

   The intuition for this result is simple. Contagion following a producer deviation with contagion
strategies, or following an enforcer deviation with single enforcer punishment strategies, spreads
more slowly under private monitoring than under perfect monitoring. Nevertheless, the implications
for the deviating agent’s payo¤s are the same as with perfect monitoring, because, when all agents
observe the behavior in their partners’last match, the deviator herself always starts su¤ering the
consequences of contagion immediately.

5.2.2     Informed Enforcers

Theorem 4 shows that single enforcer punishment equilibria can sustain as much cooperation with
observable last matches as with perfect monitoring. The question remains whether it is possible to
sustain more cooperation with observable last matches than with perfect monitoring, or alterna-
tively if single enforcer punishment equilibria remain globally optimal with observable last matches
(when g 0 (y)    m for all y). In the next subsection, we will see that the former possibility can some-
times arise. However, we now show that, when enforcers have superior information to producers
(i.e., have …ner information sets), single enforcer punishment equilibria are indeed globally optimal,
under a simple equilibrium re…nement in the spirit of anonymity. In particular, we consider the sit-
uation with informed enforcers, where enforcers perfectly observe all past actions, while producers
have more limited information.
   The following condition is in the spirit of the partial anonymity assumption of Section 2:


                                                   19
Non-Discrimination For every producer i, complete history of play ht , and pair of players j; k
         such that Mjt = Mkt , we have
                                   h                            i
                          Eht+1        i   ht+1
                                            i   jht
                                                    ; i 2 M t+1
                                                            j     = Eht+1   i   ht+1
                                                                                 i   jht ; i 2 Mkt+1 :
                             i                                        i



       That is, the distribution over producer i’s period-t + 1 actions is independent of whether i
matches with j or k in period t + 1. This requirement is only imposed for players j and k who are
themselves matched at period t, so that producer i’s behavior can depend on the outcomes of the
period-t matches she observes, but not on which members of those matches she …nds herself matched
with in period t + 1. Non-discrimination thus says that a producer’s behavior cannot depend on
her partners’identities, except insofar as this is informative about past play. As noted in Section
4, partial anonymity implies non-discrimination. Both single enforcer punishment strategies and
contagion strategies are clearly non-discriminatory.

Theorem 5 Suppose that producers observe their partners’last matches and enforcers are perfectly
informed. If g 0 (y)       m for all y, then single enforcer punishment strategies with cooperation level
x and punishment level y sustain the maximum level of cooperation among all non-discriminatory
equilibria.17

       To provide intuition for this result, let us …rst revisit the case of perfect monitoring. An
explanation for why single enforcer punishment equilibria are optimal with perfect monitoring is
that reducing producer j’s level of cooperation at a history ht+1
                                                              j , after producer i deviates at history
hti and is punished by enforcer k, has a direct positive e¤ect on producer i’s on-path incentives for
cooperation at history hti of

                                            k 1               h              i
                                                Pr ht+1
                                                    j   jht
                                                          i E  f 0
                                                                   x t+1 t+1
                                                                     j  jhj    ;
                                           kn 1

and has a indirect negative e¤ect of

                                 l h                 i h               i
                                   E Pr ht+1
                                         j   jht
                                               k jht
                                                   i  E  f 0
                                                             x t+1 t+1
                                                               j  jhj    E g 0 (~
                                                                                y) ;
                                 n

for some random variable y~. If monitoring is perfect, or if enforcers always have …ner information
than civilians, then we have
                                                         h              i
                                            Pr ht+1 t         t+1 t   t
                                                j jhi = E Pr hj jhk jhi ;                                          (2)

                                                                                             (k 1)n
so the indirect e¤ect outweighs the direct e¤ect whenever g 0 (y)                     m =    (kn 1)l   for all y. This
explains why single enforcer punishment equilibria are optimal with perfect monitoring (Theorem 1)
  17
       Wth informed enforcers, single enforcer punishment strategies constitute a PBE strategy pro…le even if x < x
                                                                                                                  ~.


                                                             20
or with private monitoring with informed enforcers (Theorem 5). On the other hand, if monitoring
is private and enforcers may not have …ner information than civilians, then (2) may fail, and the
di¤ering beliefs of enforcers and civilians may be exploited to provide stronger on-path incentives
than are possible in single enforcer punishment equilibria. We construct an example with these
features in the next subsection.

5.2.3     A Counterexample: Graduated Punishments

In this section, we show by example that when (2) is not satis…ed, it may be possible to support
greater cooperation under private monitoring than public monitoring and thus improve on single
enforcer punishment equilibria. Interestingly, such greater cooperation is supported by graduated
punishments, identi…ed by Ostrom (1990) as an important tool for sustaining cooperation under
imperfect information. The intuition here is di¤erent from Ostrom’s, however: the advantage of
graduated punishments in the current setting is that it takes time to build up di¤erences in beliefs
among individuals, and these di¤ering beliefs can then be exploited to provide harsher punishments
than are possible with perfect monitoring.
   Let n = k = 2 and l = 1. Thus, there are two enforcers and four producers, and every period
they randomly split into two groups, each consisting of one enforcer and two producers. Assume
that players observe the outcome of their own matches, and that producers— but not enforcers— in
addition observe the outcome of each of their partner’s most recent match. This informational edge
for the producers is for simplicity; in the Appendix, we sketch a more complicated example without
this feature. To complete the description of the physical environment of the example, assume that
            p
f (x) = 100 x, g (y) = y, and = :1. These parameters satisfy our condition for single enforcer
punishment equilibria to be optimal under perfect monitoring (g 0 (y)       m for all y).
   As we have seen, the highest level of cooperation that can be sustained with single enforcer
                                                                     p
punishment strategies, x , is given by x = g 1 2f (x ) = 1 :1:1 2 100 x , or x     493:8272.
   In contrast, we now construct an equilibrium that sustains a cooperation level of (exactly)
493:830. We call it the “three strikes and you’re out” (3SYO) equilibrium.

   Producers’ strategies:

        On path: play x1 .

        If you play x < x1 : play x2 for one period, then go back to x1 .

        If you play x0 < x2 in the period after after playing x < x1 , and you are monitored by the
        same producer in both of these periods, but you are monitored by di¤erent enforcers: play
        x3 for one period, then go back to x1 . Otherwise, go back to x1 immediately. (We de…ne
        x1 ; x2 ; x3 below.)

                                                   21
        If you see the same producer play x < x1 , then x0 < x2 , and then x00 < x3 , or if you are seen
        following such a sequence by the same producer, or if you see a producer play x < x1 and see
        the corresponding enforcer fail to punish her: play 0 forever.


   Enforcers’ strategies:

        If you see a unique producer play x < x1 , punish her at level y. Do not punish anyone if you
        see two producers deviate.

        If you fail to punish a producer who plays x < x1 , or if you see the same producer take actions
        below x1 three times in a row, stop punishing forever.


   Intuitively, the key di¤erence between the single enforcer punishment equilibrium and the 3SYO
equilibrium is that with the latter, if a producer shirks three times in a row and is monitored by
the same producer but di¤erent enforcers, then after the third time she shirks she is “punished”
both by the enforcer (who punishes at level y, as usual), and by the other producer (who shirks
forever, as in a contagion equilibrium). The reason why the enforcer is willing to punish at level
y even though the other producer is about to start shirking is that he does not realize that this is
what is happening: he has seen the deviator shirk at most once before, so when he sees her shirk
again, he thinks this is at most the second straight time she has shirked. He is then certain that
the deviator (and the other producer) will return to cooperation in the next period if he punishes,
while contagion will start if he does not punish, so he has an incentive to punish. Thus, the 3SYO
equilibrium exploits the belief di¤erence between enforcer and producer at such a history to punish
a deviator with both direct punishment and contagion. The reason why this “extra punishment”at
an o¤-path history allow us to sustain more cooperation on-path is as follows. If a producer can be
punished “extra hard”after she shirks three times, then she can be asked to work extra hard after
she shirks twice. Similarly, if she has to work extra hard after she shirks twice, then she can also
be asked to work harder after she shirks once. Finally, if she has to work harder after she shirks
once, then she can also be induced to work harder on path.
   Formally, we establish the following result in the Appendix:

Proposition 2 The 3SYO strategy pro…le is an equilibrium when x1 = 493:830, x2 = 494:102, x3 =
502:058, and y = 493:828. Consequently, single enforcer punishment equilibria are not optimal.

5.2.4     Stability

We conclude our treatment of the model with private monitoring by providing another reason why
single enforcer punishment equilibria may be optimal under private monitoring, even when (2) is

                                                   22
not satis…ed. In particular, we show that single enforcer punishment equilibria are optimal among
all equilibria satisfying a simple 1-period stability re…nement. While the argument is simple, we
believe that it is potentially important in light of empirical accounts of how small transgressions
can lead to large societal breakdowns in the absence of centralized law enforcement (e.g., Lewis,
1994).
         To de…ne this notion of stability, we restrict attention to deterministic strategy pro…les, de…ned
                          t are degenerate random variables for all i; j; t.18
as pro…les where xti and yji

De…nition 3 A deterministic equilibrium satis…es Stability if, whenever a single player i deviates
                                                                                              2ft+1;:::g
at an on-path history in period t, play returns to the equilibrium path xi ; yji                           in period
                                                                                             i2C;j2P
t + 1.

         Note that if all players “trembled” with probability " when choosing their actions, then an
equilibrium that fails to satisfy Stability is knocked o¤ its equilibrium path in each period with
probability on the order of ", while an equilibrium that satis…es Stability is knocked o¤ path with
probability of order at most "2 . In this sense, equilibria that satisfy Stability are more robust to
trembles than are equilibria that fail to satisfy this condition.

Theorem 6 With observable last matches, the single enforcer punishment strategy pro…le with
cooperation level x and punishment level y is the most cooperative deterministic equilibrium sat-
isfying Stability.

         Note that, unlike Theorem 1, Theorem 6 does not require the assumption that g 0 (y)               m for all
y to establish that single enforcer punishment strategies are optimal. This is because community
enforcement strategies always violate Stability, regardless of g.


6         Ostracism

An important way in which many groups sustain cooperation among their members in practice is
ostracism, or the exclusion of deviators alone from the bene…ts of societal cooperation (Ostrom,
1990, Ellickson, 1991, Greif, 1993, 2006). The main model analyzed so far does not allow ostracism,
because it is not technologically feasible to exclude some players from the bene…ts of cooperation
without excluding everyone. When cooperation corresponds to directed actions (such as simple
favors or investments in a bilateral project) rather than providing public goods, such exclusion
becomes a possibility. To study how ostracism interacts with specialized enforcement, we now
consider a variant of our baseline model in which producers can exclude one another other from the
    18
     Equivalently, a determinstic strategy pro…le is a pro…le of pure strategies that do not condition on the match
realizations.


                                                        23
bene…ts of cooperation. We consider both a version of the model where we retain the assumption
of partial anonymity and a version where we relax it.
   The main message of this section is that our results generalize to an environment that incorpo-
rates ostracism. This is despite the fact that producers’ability to ostracize each other while still
cooperating with enforcers works against the tradeo¤ underlying our main model, as now a deviant
producer can be directly punished by enforcers while simultaneously facing the withdrawal of coop-
eration from other producers. Furthermore, the structure of optimal equilibria in this environment
is quite interesting: producers’ ability to use ostracism makes the conditions for single enforcer
punishment equilibria to be optimal more restrictive in an intuitive way, and when pure single en-
forcer punishments are not optimal, optimal equilibria simply combine single enforcer punishments
with ostracism.

6.1    Anonymous Ostracism

We …rst consider the perfect monitoring version of our model with the modi…cation that players have
the ability to ostracize each other: when producer i chooses her level of cooperation xti , she can also
choose to exclude one or more of the other producers and enforcers in Mit from the bene…ts of this
cooperation. In this subsection, this choice must be made subject to our usual partial anonymity
requirement. That is, a producer cannot discriminate which other producers and enforcers in her
match she wishes to ostracize, as she does not observe their identities (for example, if she decides
to ostracize one producer, then one of the other producers is chosen at random to be the recipient
of this ostracism). If in period t producer i ostracizes some player j but not player k, then player
j receives 0 bene…t from player i’s cooperation, while player k receives bene…t

                                            (1     ) f xti

for some    2 [0; 1]. Thus, the parameter     measures the e¢ ciency cost of employing ostracism: if
  = 1 then, as in our main model, producer i cannot provide any bene…t to player k without also
bene…ting player j, while if   = 0 then player i can completely exclude player j from the bene…ts of
her actions without reducing the bene…t to player k. Note that the        = 1 case corresponds to our
main model with the possibility of money burning, as when         = 1 “cooperating” while ostracizing
anyone is equivalent to burning money.
   We will show that in this version of our model, single enforcer punishment plus anonymous
ostracism (SEPAO) strategies may be optimal. Formally, a SEPAO strategy pro…le is character-
ized by a cooperation level x and punishment level y, and is represented by the following 4-state
automaton, with normal, infected, other-ostracism and self-ostracism states. Play in these states
is as follows:


                                                  24
      Normal state: Producer i plays xi = x and does not ostracize anyone. If all producers i 2 Mj \C
play xi = x— or if multiple producers i 2 Mj \ C play xi 6= x— then enforcer j plays yji = 0 for all
i 2 Mj \ C. If instead a unique producer i 2 Mj \ C plays xi 6= x, then enforcer j plays yji = y
and plays yji0 = 0 for all i0 2 Mj \ Cni.
      Infected state: Players always take action 0.
      Self-ostracism state: Producer i plays xi = x and does not ostracize anyone.
      Other -ostracism state: Producer i plays xi = x and ostracizes all other producers in her match
(so her cooperation only bene…ts the enforcers). Enforcers play exactly as in the normal state.
      As usual, all players starts in the normal state. In the normal state or the self- or other-ostracism
state, all players transition to the normal state unless a unique producer i plays xi 6= x. If producer
i plays xi 6= x and all enforcers j 2 Mi \ P play yji = y, player i transitions to the self-ostracism
state and all other players transition to the other-ostracism state. If producer i plays xi 6= x and
some enforcer j 2 Mi \ P plays yji 6= y, all players transition to the infected state. The infected
state is absorbing.
      Note that under these SEPAO strategies, enforcer behavior and state transitions are conditioned
only on each producer’s level of cooperation and not on her choice of whom to ostracize. This does
not cause incentive problems for producers, since, given her level of cooperation, a producer is
indi¤erent as to whether or not she ostracizes anyone. For example, when            = 1 and producer i is
in the self-ostracism state, producer i cooperates at level x while each other producer burns x utils.
      Let x and y be the greatest solution to the following system of equations:

                                     x = lg (y) + (k 1) f (x) ;
                                                   nk 1
                                     y =                     kf (x) :
                                           1         nk

Intuitively, x and y are the greatest levels of cooperation and punishment that are sustainable in
single enforcer punishment plus anonymous ostracism strategies. In particular, a producer who
deviates gains x and loses lg (y) + (k           1) f (x) (one period of punishment plus one period of
lost cooperation), while an enforcer who fails to punish a deviating producer gains y and loses
           nk 1
 1          nk       kf (x) (all future bene…ts of cooperation, noting that bene…ts from all but one
producer next period are only (1           ) f (x) instead of the usual f (x)).
      We show the following result:

Theorem 7 With anonymous perfect monitoring, when ostracism is available,

                     m
     1. If g 0 (y)       for all y 2 R+ , then the single enforcer punishment strategy pro…le with cooper-
        ation level x and punishment level y is the most cooperative equilibrium.



                                                      25
                  m
  2. If g 0 (y)       for all y 2 R+ , then the SEPAO strategy pro…le with cooperation level x and
      punishment level y is the most cooperative equilibrium.

   Theorem 7 makes two main points. First, the necessary condition for pure single enforcer
punishment strategies to be optimal becomes more restrictive when ostracism is more e¤ective: in
particular, the lower bound of m from Theorem 1 must simply be scaled up by 1 . Second, when the
converse condition is satis…ed, a version of single enforcer punishment equilibria remain optimal,
but now these strategies must be combined with ostracism.
   In addition to showing how our results change with , Theorem 7 is of independent interest in
demonstrating conditions under which strategies involving ostracism are optimal. While numerous
empirical and case studies have argued for the practical importance of ostracism for sustaining
cooperation (e.g., Ostrom, 1990), only a few game theoretic models identify ostracism strategies
as having particularly good properties: to the contrary, in most models of cooperation in groups,
ostracism strategies do no better than contagion strategies. Two notable exceptions are Lippert and
Spagnolo (2011) and Ali and Miller (2014b), who study community enforcement games with private
monitoring and show that ostracism can have advantages over contagion in terms of providing
incentives for communication about others’past behavior. In contrast, Theorem 7 concerns a setting
with perfect information— where there is no need for communication— and shows that ostracism
strategies can be essentially uniquely optimal.
   Finally, it is also the case that SEPAO strategies can still support cooperation level x under
private monitoring with observable last matches. Thus, with observable last matches, the compar-
ison between single enforcer punishment strategies and SEPAO strategies is exactly the same as
under perfect monitoring.

6.2   Non-Anonymous Ostracism with n = 1

As we have emphasized at several points throughout the paper, letting producers observe their
partners’identities at the time they take actions could substantially complicate the analysis. When
n = 1, however, this would be completely immaterial, as producers know their partners’identities
anyway. (For example, in the n = 1 case of our baseline model, single enforcer punishment strategies
remain optimal when g 0 (y)    m for all y, even without “anonymity.”) In this section, we show that
when we introduce targeted ostracism into the model without anonymity in the n = 1 case, the
structure of optimal equilibria is essentially identical to that under anonymity, except that now it
is possible to avoid ostracizing innocent producers.
   We now de…ne a single enforcer punishment plus non-anonymous ostracism (SEPNAO) strategy
pro…le as a pro…le characterized by a cooperation level x and punishment level y, and represented
by the following k + 2-state automaton:


                                                  26
     Normal state and infected state: Same as with SEPAO strategies.
     i-ostracism state (one for each i 2 C): Producer i plays xi = x and does not ostracize anyone.
Producer i0 6= i plays xi0 = x and ostracizes player i only. Enforcers play exactly as in the normal
state.
     Play starts in the normal state. In the normal state or one of the ostracism states, all players
transition to the normal state unless a unique producer i plays xi 6= x. If producer i plays xi 6= x
and all enforcers j 2 Mi play yji = y, play transitions to the i-ostracism state. If producer i plays
xi 6= x and some enforcer j 2 Mi \ P plays yji 6= y, play transitions to the infected state. The
infected state is absorbing.

Theorem 8 With non-anonymous perfect monitoring and n = 1, when ostracism is available,

                    m
    1. If g 0 (y)       for all y 2 R+ , then the single enforcer punishment strategy pro…le with cooper-
         ation level x and punishment level y is the most cooperative equilibrium.

                     m
    2. If g 0 (y)        for all y 2 R+ , then both the SEPAO and SEPNAO strategy pro…les with
         cooperation level x and punishment level y sustain the maximum level of cooperation.

     Thus, perhaps surprisingly, with non-anonymous perfect monitoring and n = 1, SEPAO strate-
gies (which ostracize innocent producers as well as the deviator) remain optimal, but SEPNAO
strategies (which only ostracize the deviator) perform equally well. In particular, whether innocent
producers are ostracized or not is irrelevant for on-path incentives for cooperation: all that matters
is whether the deviator herself is ostracized, and this is possible whether or not players are anony-
mous. Nonetheless, SEPNAO strategies seem to more closely resemble ostracism as it is used in
practice, so it is interesting to note that these strategies can indeed be optimal. Most importantly,
the same forces that make specialized enforcement optimal remain operational even in the presence
of the ability to ostracize speci…c individuals.


7     Conclusion

This paper introduces a framework for comparing community (private-order) and specialized
(public-order) enforcement of pro-social behavior. The key feature of our approach is that we
endogenize specialized enforcement by requiring that enforcers have an incentive to carry out the
punishment of deviators. Thus, we require that both community and specialized enforcement are
ultimately based on “reputation.”
     Our main results turn on a novel tradeo¤: the withdrawal of future cooperation following a
transgression has a positive direct e¤ect on citizens’ incentives to cooperate, but also a negative



                                                     27
indirect e¤ect coming through the erosion of enforcers’ incentives to punish. Whenever the spe-
cialized enforcement technology is either uniformly e¤ective or uniformly ine¤ective, this tradeo¤
is optimally resolved by going to either the extreme of pure community enforcement (where spe-
cialized enforcers are completely inactive) or pure enforcer punishments (where the future path of
cooperation is completely una¤ected by producers’ transgressions). Yet, the threat of contagion
does play a role even under pure enforcer punishments, as it is precisely this threat that gives
enforcers the necessary incentives to carry out punishments. A further implication of our analysis
is that community enforcement is more likely to emerge in less technologically advanced societies,
while societies with more advanced technologies should rely on specialized enforcement.
   The framework introduced in this paper could be developed in several promising directions.
First, our analysis takes the number of specialized enforcers in society as given (except brie‡y
in Theorem 2). As we have characterized optimal equilibria for any number of producers and
enforcers, endogenizing the number of enforcers in our model is conceptually straightforward. Such
an exercise would bear some resemblance to the “guns versus butter” tradeo¤ present in classic
models of “anarchy” such as Skaperdas (1992), Grossman and Kim (1995), Hirshleifer (1995), and
Bates, Greif, and Singh (2002), and one could further extend the framework in that direction by
allowing “guns”to be used for expropriating others as well as enforcing cooperation. Nevertheless,
because of the role of specialized enforcers in sustaining cooperation, the insights of this analysis
are likely to be di¤erent from those of existing models of anarchy.
   Second, in a specialized enforcement equilibrium, the enforcers in our model can be interpreted
as either a proto-state institution or a non-state institution, such as a ma…a. Several scholars,
including Tilly (1985), have argued that states evolve out of— or are, in fact, a form of— the private
provision of law enforcement. An important question here is when we expect specialized enforcers
to organize in a single institution rather than multiple collectives. While some of our results bear on
this question (for example, the results of Section 5.2.2 on optimal equilibria when all enforcers share
information with each other), many other interesting questions could be addressed in future work.
These include the costs of ma…a-like organizations as opposed to states, as well as the dynamics of
the process by which proto-states may be transformed into state institutions.
   Third, another reason why specialized enforcement may be preferable to community enforcement
is the presence of noisy observations, whereby cooperative actions may appear as noncooperative.
As brie‡y discussed in Section 5.2.4, such noise may make contagion-like strategies prohibitively
costly. An analysis of the framework presented here under such richer information structures is an
interesting and important area for future work.
   Finally, we have only brie‡y touched on the role of communication and other private actions
in supporting specialized enforcement. It would be interesting to analyze more systematically how
specialized enforcement (or, more generally, laws) impact the incentives of citizens to cooperate not

                                                  28
only with each other but also with state institutions themselves.


Appendix: Omitted Proofs
Proof of Theorem 1
Optimality of Single Enforcer Punishment Strategies when g 0 (y)                                                  m for all y

It is straightforward to see that a single enforcer punishment strategy pro…le with cooperation level
x        x and punishment level y =        1    kf (x) is a SPE: In the normal state, a producer who deviates
saves an e¤ort cost of at most x and receives punishment lg (y) = lg                                   1       kf (x) , which is weakly
greater than x by the de…nition of x and the concavity of f and g. Similarly, in the normal state
an enforcer who deviates saves a cost of at most y and loses future bene…ts of cooperation worth

1        kf (x)    y. Finally, incentives in the infected state are trivial.
         The main part of the theorem is thus showing that x is an upper bound on each producer’s
level of cooperation in any SPE when g 0 (y)                         m for all y. We break the proof into several steps.
         De…nitions and Preliminary Observations:
         Fixing a SPE      = ( i )i2N , let u be the in…mum continuation payo¤ of any producer starting
from the punishment stage at any history. In addition, let supp                                    i       ht denote the support of
producer i’s action at history ht , and let

                                X=             sup                  (1        ) xti + E Xit+1 jht ; xti
                                      i;ht ;xti 2supp   i   (ht )


be the supremum expected present discounted level of cooperation ever taken by any producer at
any history.
         A preliminary observation is that u >                       1 and X < 1. To see this, note that, as f is
bounded and an enforcer’s minmax payo¤ is 0, there is a …nite upper bound y 2 R+ on the level
of punishment that an enforcer is ever willing to use in equilibrium.19 Since a producer always has
the option of taking action 0 at cost 0, this implies that u                                 lg (y) >           1. Given that there is
a …nite lower bound on u, it follows that there is a …nite upper bound on the level of cooperation
that a producer is ever willing to choose in equilibrium, so in particular X < 1.
         Producer Incentive Compatibility:
         A necessary condition for producer i not to deviate to playing xi = 0 at history ht is that, for
    19
         By the same argument leading to (A2) below, one such upper bound is limx!1                        1
                                                                                                               kf (x).




                                                                         29
all xti 2 supp    i       ht ,
                                                   2                                           3
                                     1
                                     X                    X
                  (1             )            E4                 f xt+
                                                                    j                  jht ; xti 5   (1      ) xti    E Xit+1 jht ; xti
                                     =0            j2Mit+ \Cni
                                         2                              3
                                              X
                  (1             )E4                     f xtj jht 5 + u;
                                          j2Mit \Cni


where Mit+ denotes player i’s period-t + match (which is a random variable from the perspective
of period t). This is a necessary condition because the left-hand side is an upper bound on player
i’s equilibrium continuation payo¤ (as it assumes she is never punished in equilibrium), while the
right-hand side is a lower bound on player i’s continuation payo¤ if she deviates (as it assumes she
gets her lowest possible continuation payo¤).20 Note that the distribution of xtj does not depend on
           hP                         i   hP                   i
xti , so E      t
             j2M \Cni f  x t jht ; xt = E
                           j        i           t
                                             j2M \Cni f x t jht , and we can rewrite this necessary
                                                          j
                      i                                                       i

condition as
                                                                                       2                                         3
                                                                        1
                                                                        X                        X
    (1     ) xti + E Xit+1 jht ; xti                       (1       )              E4                       f xt+1+
                                                                                                               j         jht ; xti 5   u:   (A1)
                                                                         =0              j2Mit+1+    \Cni


    Using Enforcer Incentive Compatibility to Bound u:
             t denote enforcer k’s punishment action toward player i in period t (which, like xt , is
    Letting yki                                                                                i
a random variable), a necessary condition for enforcer k not to deviate to playing yki = 0 at history
ht is                                                            2                                             3
                                                         1
                                                         X                    X
                                                                 6                                              7
                                              t
                                             yki                E4                          f xt+1+
                                                                                               j            jht 5 :                         (A2)
                                                          =0            j2Mkt+1+       \C

This is a necessary condition because an enforcer’s minmax payo¤ is 0, while her equilibrium
                                      P1        hP                           i
                                                                    t+1+   t    t , as this is
continuation payo¤ is at most (1  )      =0   E     j2M t+1+
                                                             \C f x j    jh    yki
                                                                                                 k

her continuation payo¤ if she does not punish anyone other than player i in period t and never
punishes anyone after period t.
    Now, producer i’s continuation payo¤ at the punishment stage at history ht is at least
                                     2                          3                            2                              3
                                             X                                                       X
                 (1         )E4                           t
                                                       g yki jht 5 + (1                 )E4                   f xt+1
                                                                                                                 j   jht 5 + u;
                                     k2Mit \P                                                  j2Mit+1 \Cni


as a producer always has the option of playing xi = 0 in period t + 1. Therefore, there exist a
  20
     Technically, both expectations in this expression should also be conditioned on the event j 2 Mit+ \ Cni.
However, because identities are concealed at the point where producers choose their actions, the distribution of xt+
                                                                                                                  j
conditional on this event equals its unconditional distribution. We therefore omit this conditioning throughout the
proof.



                                                                                  30
producer i and a history ht such that
                                     2                                        3                       2                           3
                                             X                                                                X
             u      (1         )E4                       t
                                                      g yki jht 5 + (1                        )E4                      f xt+1
                                                                                                                          j   jht 5 + u;
                                      k2Mit \P                                                        j2Mit+1 \Cni

                                     hP     i    hP                           i
                                       t jht + E                    t+1      t . In particular, by
or equivalently u                E
                          k2Mit \P g yki                 t+1
                                                     j2Mi \Cni f  x j     jh
                                              hP                            i
                                                                t+1+
(A2) and the observation that the quantity E    j2M t+1+ \C f xj        jht is the same for all
                                                                                              k

k 2 P , we have
                   0                 2                                                      31            2                               3
                         1
                         X                       X                                                                X
                    B               6                                                      7C
      u          lg @              E4                          f xt+1+
                                                                  j                    jht 5A + E 4                       f xt+1
                                                                                                                             j   jht 5 :           (A3)
                          =0             j2Mkt+1+         \C                                               j2Mit+1 \Cni


     Bounding X when g 0 (y)                     m:
     Suppose that        g 0 (y)     m for all y 2 R+ . We argue that (A3), together with the de…nition of X,
implies that
                                             u        lg                      kf X          + (k          1) f X :                                 (A4)
                                                               1
To see this, note that, by the de…nition of X, for every producer j, history ht+1 , and level of
cooperation xt+1
             j   2 supp                  j    ht+1 , we have

                                                          1
                                                                                  1
                                                                                  X      h                i
                                     xt+1
                                      j                           X                        t+2+
                                                                                        E xj      t+1 t+1
                                                                                                jh ; xj     :                                      (A5)
                                                      1
                                                                                  =0


Next, if in computing the right-hand side of (A3) we replace the random variable                                                      j       ht+1 with
 j   ht+1 + " for some constant " > 0 (i.e., shift                                      j   ht+1 up by " realization-by-realization), the
derivative of the resulting expression with respect to " equals
                                     0                        2                                               31
      l h 0 t+1    i                                                                                                     k 1 h 0 t+1    i
                                                 1
                                                 X                        X
                        B                                  6                                                  7C
        E f xj  jht g 0 @                                 E4                            f xt+1+
                                                                                           j              jht 5A +           E f xj  jht :
      n                                                                                                                 kn 1
                                                 =0               j2Mkt+1+ \C
                                                                                                                                                   (A6)
As g 0 (y)       m for all y, this derivative is non-positive for all j and ht+1 . Hence, a lower bound on
the right-hand side of (A3) is obtained by setting xt+1
                                                    j   equal to its upper bound in (A5) for all j.
The resulting lower bound equals
                          0          hP                                              P1            h                     i     i 1
                                 E           j2Mkt+1 \C  f                1
                                                                              X         =0       E xt+2+
                                                                                                     j      jht+1 ; xt+1   jht
                        lg @                            P
                                                                      1         hP                                   ij          A
                                                      2  1                                             t+2+        t
                                                 +                =0          E    j2M t+2+     \C f  xj        jh
                                                                                            k
                          2                                                                                        ! 3
                                     X                        1
                                                                                  1
                                                                                  X           h                  i
                   + E4                          f                 X                        E xt+2+ jht+1 ; xt+1 jht 5 :
                                                                                                  j                j                               (A7)
                                                          1
                               j2Mit+1 \Cni                                        =0



                                                                                   31
We next derive an upper bound on the argument of g in (A7). Letting
                                                                             1
                                                                             X          h            i
                                        Xj ht+1 = (1                     )             E xt+2+
                                                                                          j    jht+1
                                                                                                       ;
                                                                             =0

by the concavity of f and Jensen’s inequality we have
                           hP                                            P1     h                       i     i
                                                             1                      t+2+     t+1 ; xt+1     t
                       E     j2Mkt+1+         \C f          1    X
                                                                 hP      =0   E   x j      jh
                                                                                                  i j
                                                                                                          jh
                                            2 P 1                                     t+2+      t
                                    +               =0        E   j2Mkt+2+ i\C f xj h         jh
          hP                                                                     2      P                                                                 i
                                        1
      E        j2Mkt+1+    \C f     1          X            Xj ht+1     jht + 1 E          j2M t+2+ \C f Xj h
                                                                                                                t+1                                    jht :
                                                                                                                  k


                                                                                                                                           2
                                                                                            1
Next, again by the concavity of f , the maximum of f                                    1            X       Xj ht+1              +1           Ef Xj ht+1
over Xj ht+1           X is attained at Xj ht+1 = X for all j and ht+1 . This gives an upper bound on
                                                                                       2
                                                        1
the argument of g in (A7) of kf                     1            X       X        +1        kf X =            1       kf X . On the other hand,
                             2                                                                                                    !        3
                                      X                          1
                                                                                 1
                                                                                 X              h                                i
                           E4                       f                X                      E xt+2+
                                                                                               j    jht+1 ; xt+1
                                                                                                             j                        jht 5
                                                             1
                                j2Mit+1 \Cni                                      =0
                             2                                                                  3
                                      X                          1
                           E4                       f                X                 X 5 = (k               1) f X :
                                                             1               1
                                j2Mit+1 \Cni


Combining these observations, we see that (A7) is lower-bounded by                                                                    lg       1   kf X          +
 (k    1) f X . This yields (A4).
   We can now complete the proof of the main part of the theorem. Combining (A1) and (A4),
we have, for every player i, history ht , and level of cooperation xti 2 supp                                                i   ht ,

          (1        ) xti + E Xit+1 jht ; xti
                                                                                                         2                                                 3
                                                                                            1
                                                                                            X                     X
          lg            kf X                   (k       1) f X + (1                    )                 4                       f xt+1+           jht ; xti 5
                                                                                                                                    j
                1
                                                                                                =0       j2Mit+1+ \Cni

          lg            kf X                   (k       1) f X + (k                    1) f X = lg                       kf X                  :
                1                                                                                                 1

As X = supi;ht ;xti 2supp            t
                                 i (h )
                                          (1        ) xti + E Xit+1 jht ; xti , we have X                               lg       1     kf X         . By the
de…nition of x , this implies that X                             x . Finally, as E Xi0 jh0                        X, we have E Xi0 jh0                       x .
Thus, x is an upper bound on each player’s maximum equilibrium level of cooperation.

Near-Optimality of Contagion Strategies when g 0 (y) is Small

It is straightforward to see that the contagion strategy pro…le with cooperation level x
                                                                                       ^ is a SPE. It
remains to show that, for all " > 0, there exists                                 > 0 such that x
                                                                                                ^ + " is an upper bound on each

                                                                             32
player’s maximum level of cooperation whenever g 0 (y) <                           for all y.
   By (A3), the de…nition of X, and Jensen’s inequality, we have

                                             u         lg                 kf X         :                                     (A8)
                                                            1

Combining (A1) and (A8) yields that, for every player i, history ht , and level of cooperation
xti 2 supp   i   ht ,


                   (1      ) xti + E Xit+1 jht ; xti        lg              kf X            + (k       1) f X :
                                                                      1

Again by the de…nition of X, whenever g 0 (y) <                       for all y we have

                                       X                kl + (k             1) f X :
                                                 1

Recall that x
            ^ = (k           1) f (^
                                   x). In addition, since (k                 1) f (x)        x is concave and crosses 0 from
above at x = x
             ^, there exists         > 0 such that (k                 1) f 0 (^
                                                                              x)   <1           . Hence, as f is concave, for all
" > 0 we have

                 kl + (k         1) f (^
                                       x + ")                             kl + (k          1)         x) + "f 0 (^
                                                                                                   f (^          x)
         1                                                   1
                                                                                                              1
                                                                          kl + (k          1)      f (^
                                                                                                      x) + "
                                                             1                                                (k 1)
                                                                                                               1
                                                     = x
                                                       ^ + " (1              )+             kl      f (^
                                                                                                       x) + "            :
                                                                                    1                          (k 1)

For su¢ ciently small        > 0, this is less than x
                                                    ^ + ". Thus,                   1       kl + (k       1) f (x)     x crosses 0
to the left of x
               ^ + ", so X       ^ + ". Finally, as E Xi0 jh0
                                 x                                           X, we have E Xi0 jh0               x
                                                                                                                ^ + ". Therefore,
x
^ + " is an upper bound on each player’s maximum equilibrium level of cooperation.

Proof of Proposition 1

When money burning is available, the model is almost identical to the model of Section 6 in the
  = 1 case, and the conclusion of the proposition follows from the conclusion of Theorem 7 when
  = 1. The sole di¤erence between the models is that is that the model with money burning lets a
producer cooperate and burn money simultaneously. The proof of Theorem 7 is una¤ected by this
possibility, so Proposition 1 follows from the proof of Theorem 7.

Proof of Theorem 2

Per-match social welfare with k producers per match and on-path cooperation x is
k ((s   1) f (x)        x). Thus, assuming that the maximum level of cooperation is below the …rst


                                                                 33
best level, a su¢ cient condition for setting k = s to maximize social welfare is that the maximum
(per producer) level of cooperation is maximized at k = s. The maximum level of cooperation when
k = s is given by the solution to x
                                  ^ = (s                                       x). On the other hand, if k < s and g 0 (y)
                                                                         1) f (^                                                        m for
all y, then by Theorem 7 the maximum level of cooperation (even if money burning is available) is
given by the solution to
                                                                                   2
                                   x = (s        k) g        f (x) +                   kf (x) + (k           1) f (x) :                   (A9)
                                                         n                    1

Thus, the planner prefers that all agents become producers if (A9) is maximized at k = s. In turn,
a su¢ cient condition for this is that the derivative of the right-hand side of (A9) with respect to k
is non-negative for all x. This derivative equals
                                                 2                        2                                      2
          (s     k) g 0           f (x) +            kf (x)                       f (x)   g       f (x) +            kf (x) + f (x) :
                              n              1                       1                        n              1

As the …rst term is positive, a su¢ cient condition for the whole derivative to be positive is f (x)
                     2
                                                                                                     1
g   nf   (x) +   1       kf (x) for all x, or, letting z = f (x), z                           g      n   +   1   k z for all z. Since k     s,
                                                                 1
a su¢ cient condition for this is z                      g       n   +    1       s z for all z. Finally, since g (0) = 0, a su¢ cient
                                     1
condition is g 0 (y)              1
                                    +1   s
                                             for all y. Hence, if (1) holds then the planner prefers that all agents
                                  n
become producers.

Theorem 1 when Enforcers Can Punish Each Other

When enforcers can punish each other, consider the following modi…ed de…nition of single enforcer
punishment strategies: On path, producers cooperate at level x . If a producer deviates, all
enforcers in her match punish her at level y , and play returns to the equilibrium path next
period. If instead an enforcer j deviates, then in the next period all producers shirk, all enforcers
matched with j next period punish him at level y , and j himself randomly punishes one of his
partners at level         1       (kf (x ) + (l          1) g (y )) (or alternatively he burns this level of utility, if money
burning is allowed). Finally, let (x ; y ) be greatest solution of the system of the equations

                                             x       = lg (y ) ;
                                             y       =                   (kf (x ) + (l        1) g (y )) :
                                                             1

Proposition 3 When enforcers can punish other enforcers, Theorem 1 applies verbatim with this
modi…ed de…nition of single enforcer punishment strategies.

Proof (sketch). Start with the …rst part of the theorem: optimality of single enforcer punishment
strategies when g 0 (y)              m for all y. It is straightforward to check that the above strategy pro…le is a


                                                                                  34
SPE, so it remains to show that x                      is an upper bound on each producer’s level of cooperation in any
SPE. The argument is similar to the proof of Theorem 1. In particular, …xing a SPE                                   = ( i )i2N ,
let y be the greatest action in the support of any enforcer’s equilibrium strategy at any history.
As an enforcer can always take action 0,                             (l    1) g (y) is now a lower bound on each enforcer’s
equilibrium continuation payo¤ at any history. Equation (A2) (“enforcer incentive compatibility”)
then becomes
                                               2                                     3
                                   1
                                   X                    X
                                               6                                       7
                    y                     t
                                              E4                   f xt+1+
                                                                      j            jht 5 +        (l   1) g (y) :
                                                                                             1
                                    =0             j2Mkt+1+   \C


Carrying the new      1       (l         1) g (y) term throughout the proof of Theorem 1, we obtain the bounds

                                              X           lg (y) ;
                                               y                     kf X + (l         1) g (y) :
                                                          1

By de…nition of (x ; y ), this implies that X                             x . Thus, x         is an upper bound on each player’s
maximum level of cooperation, as desired.
   For the second part of the theorem (near-optimality of contagion strategies when g 0 (y) is small),
note that if g 0 (y) <            for all y then

                  y                       kf X + (l            1) g (y)                  kf X + (l       1) y ;
                              1                                                1

or equivalently y         1          (l 1)     kf X . We then obtain the bound


                                    X                                      kl + (k           1) f X :
                                                   1          (l     1)

                 kl
As lim   !0 1     (l 1)       = 0 for all              < 1, this bound su¢ ces for the result, by the same argument as
in the proof of Theorem 1.

Proof of Theorem 3

There are two steps. First, we derive a su¢ cient condition for single enforcer punishment strategies
with cooperation level x and punishment level y to form a PBE strategy pro…le (Lemma 1). We
then show that, under the conditions of the theorem, this su¢ cient condition is satis…ed, and single
enforcer punishment strategies support greater cooperation than contagion strategies.
   To state the su¢ cient condition for existence, we require some notation. De…ne the set D ( ; t; i)




                                                                          35
recursively by

                     D ( ; t; i) = ; if          t;
                D (t + 1; t; i) = C \ fj : 9k 2 N such that lj;k;t = 1 and k 2 Mi g ;
                                      (                                       )
                                               j : 9k; k 0 2 C such that
                D ( + 1; t; i) = C \                                            if    t + 1:
                                         lj;k; = 1 and k 0 2 Mk \ D ( ; t; i)

Under contagion strategies, if producer i deviates in period t, then D ( ; t; i) is the set of producers
in the infected phase in period . Note that the probability distribution of D ( ; t; i) is the same as
the probability distribution of D (          t)        D(         t; 0; 1) for all i 2 C and        t. Let dt   E [jD (t)j].
     Similarly, de…ne the set Q ( ; t; i) recursively by

     Q ( ; t; i) = ; if           t;
Q (t + 1; t; i) = fj : 9k 2 N such that lj;k;t = 1 and k 2 Mi g ,
                  (                                                                      )
                                       j : 9k; k 0 ; k 00 2 N such that
Q ( + 1; t; i) =                                                                           if                       t + 1:
                     lj;k; = 1, k 0 2 Mk \ C \ Q ( ; t; i) , k 00 2 Mk \ P \ Q ( ; t; i)

Under single enforcer punishment strategies, if producer i deviates in period t and the corresponding
enforcer j 2 Mi fails to punish her, then Q ( ; t; i) is the set of players in the infected phase in period
 . Note that the probability distribution of Q ( ; t; i) is the same as the probability distribution of
Q(      t)      Q(      t; 0; 1) for all i and             t. Let qt    E [jQ (t) \ Cj].
     Finally, de…ne the set Z ( ; t; i) by

                       Z ( ; t; i) = ; if             t;
                  Z (t + 1; t; i) = fj : 9k 2 N such that lj;k;t = 1 and k 2 Mi g ;
                                    (                                       )
                                             j : 9k; k 0 2 N such that
                  Z ( + 1; t; i) =                                            if    t + 1:
                                       lj;k; = 1 and k 0 2 Mk \ D ( ; t; i)

The set Z ( ; t; i) is the set of “infected”players in period                if an infection process starts in period t
in match Mi and spreads through both producers and enforcers (rather than only through producers,
as is the case with contagion strategies). Let Z (t)                   Z (t; 0; i) and zt      E [Z (t) \ C].
     Note that the distribution of jD (t)j …rst-order stochastically dominates the distribution of
jQ (t) \ Cj, as for every realization of the monitoring technology there are more infected producers
with contagion strategies than with single enforcer punishment strategies. Similarly, the distribution
of jZ (t) \ Cj …rst-order stochastically dominates the distribution of jD (t)j. In particular, zt                     dt
qt for all t.




                                                                36
   The formulas for x
                    ^ and x as functions of dt and qt are given in the text. In addition, let
                                                1
                                                X
                                                      t    k 1
                               x
                               ~ = l (1     )                  (zt   1) f (~
                                                                           x) :
                                                          kn 1
                                                t=0

Thus, if l = 1, then x
                     ~ is the greatest level of cooperation that could be sustained with contagion
strategies if contagion spread through the process Z (t) rather than D (t). Otherwise, x
                                                                                       ~ is the level
of cooperation that could be sustained when the bene…ts of cooperation lost through contagion are
scaled up by a factor of l.
   Our su¢ cient condition for existence is as follows:

Lemma 1 If x         x
                     ~, then the single enforcer punishment strategy pro…le with cooperation level x
and punishment level y is a PBE strategy pro…le.

Proof. Let the o¤-path beliefs be that any zero-probability action is viewed as a deviation, rather
than a response to an earlier deviation. We check sequential rationality …rst in the normal state
and then in the infected state.
   Given our speci…cation of o¤-path beliefs, whenever a player is in the normal state, she believes
that all of her opponents are also in the normal state. Hence, playing xi = x is optimal for
producers, as deviating can save a cost of at most x but incurs a punishment of lg (y ) = x . In
addition, if an enforcer deviates when he is supposed to play yji = 0, this incurs an instantaneous
cost but yields no future bene…t. Finally, if an enforcer deviates when he is supposed to play
                                                                            P
yji = y , this saves a cost of at most y and leads to lost future bene…ts of 1
                                                                             t=0
                                                                                 t1
                                                                                  n qt f (x ) y .
   It remains to consider players’incentives in the infected state. For enforcers, note that whenever
an enforcer is in the infected state, he believes that at least k producers are also in the infected state
(namely, the producers with whom he was matched in the period when he became infected). As
these producers will never cooperate, deviating from yji = 0 to yji = y (which is the only tempting
                                                                                P
deviation) incurs a cost of y and yields future bene…ts worth strictly less than 1 t=0
                                                                                       t1
                                                                                        n qt f (x ) <
x . So enforcers’o¤-path play is optimal.
   Finally, for a producer i in period t, the only tempting deviation is to xi;t = x . If every enforcer
in Mit is in the normal state, then every player enters period t + 1 in the same state regardless of
producer i’s choice of xi;t . Hence, in this case, producer i is indi¤erent between playing xi;t = 0
(and incurring a punishment of lg (y ) = x ) and playing xi;t = x . On the other hand, suppose
at least one enforcer in Mit is in the infected state. If there is also at least one other producer
j 2 Mit n fig in the infected state, then again every player enters period t + 1 in the same state
regardless of xi;t , and in this case producer i strictly prefers playing xi;t = 0 to playing xi;t = x
(as now playing xi;t = 0 incurs a punishment of at most (l           1) g (y )). The remaining case is when
at least one enforcer in Mit is in the infected state, but all other producers j 2 Mit n fig are in the

                                                          37
normal state. In this case, producer i can slow the spread of contagion by playing xi;t = x , and
we must verify that she does not have an incentive to do so.
   To see this, let r denote the number of producers who do enter the infected state by period
when producer i plays xi; = 0 for all          2 ft; : : : ; g, but do not enter the infected state by period
  when producer i plays xi;t = x and xi; = 0 for all               2 ft + 1; : : : ; g. The di¤erence between
producer i’s continuation payo¤ from playing xi;t = x as opposed to xi;t = 0 (and subsequently
                                       P
playing xi; = 0) is then equal to (1  ) 1=0 kn   k 1
                                                    1 E [r ] f (x ). As producer i may be punished
for playing xi;t = 0 by at most l       1 enforcers (as we are assuming that at least one of her enforcers
is infected), to show that playing xi;t = 0 is optimal, it su¢ ces to show that

                                                             1
                                                             X     k 1
                        x        (l    1) g (y ) + (1    )             E [r ] f (x ) :                         (A10)
                                                                  kn 1
                                                             =0

We will show below that E [r ]            z for all . This will imply (A10) because, recalling
                     P1        k 1
that x~ = l (1     )    =0    kn 1 z f (~
                                        x) by de…nition, the fact that x       x
                                                                               ~ implies that x
          P1      k 1
l (1    )   =0   kn 1 z f (x ), and then E [r ]       z for all implies that this lower bound ex-
               P1        k 1
ceeds l (1   )    =0    kn 1 E [r ] f (x ). Finally, the fact that x = lg (y )   x
                                                                                 ~ also implies that
                 P1        k 1
g (y ) (1      )     =0   kn 1 z f (x ), so we have (A10).
   We now show that E [r ]            z for all . For any subset of players S             N , de…ne Q ( ; t; S) by

      Q ( ; t; S) = ; if        <t
      Q (t; t; S) = S
                    (                                                                                 )
                                                j : 9k; k 0 ; k 00 2 N such that
 Q ( + 1; t; S) =                                                                                         if     t:
                            lj;k; = 1; k 0 2 Mk \ C \ Q ( ; t; S) ; k 00 2 Mk \ P \ Q ( ; t; S)

Note that if Q  ~ 3 i is the set of infected players at the beginning of period t, then when i plays
                                                                                                      ~ ,
xi;t0 = 0 for all t0 2 ft; : : : ; g the set of infected players at the beginning of period is Q ; t; Q
while when i plays xi;t = x and xi;t0 = 0 for all t0 2 ft + 1; : : : ; g the set of infected players at the
beginning of period is Q ; t + 1; Q t + 1; t; Qn  ~ fig [ fig . Hence,


                  r =       Q          ~ nQ
                                  ; t; Q                             ~ fig [ fig
                                                ; t + 1; Q t + 1; t; Qn                     \C :

We show that, for all      > t and for every subset of players S 3 i,

                   Q ( ; t; S) nQ ( ; t + 1; Q (t + 1; t; Sn fig) [ fig)           Z ( ; t; fig) :             (A11)

This implies that E [r ]        E [jZ ( ; t; i)j \ C] = z , completing the proof.




                                                        38
      The proof of (A11) is by induction on . For the                           = t + 1 case, we have

Q (t + 1; t; S) nQ (t + 1; t + 1; Q (t + 1; t; Sn fig) [ fig) = Q (t + 1; t; S) n (Q (t + 1; t; Sn fig) [ fig) ;

which is clearly contained in Z (t + 1; t; fig). Suppose now that (A11) holds for some                                   > t. We
then have
                     Q ( ; t; S)          Q ( ; t + 1; Q (t + 1; t; Sn fig) [ fig) [ Z ( ; t; fig) ;

so

            Q ( + 1; t; S) = Q ( + 1; ; Q ( ; t; S))
                                    Q ( + 1; ; Q ( ; t + 1; Q (t + 1; t; Sn fig) [ fig) [ Z ( ; t; i)) :

On the other hand,

      Q ( + 1; t + 1; Q (t + 1; t; Sn fig) [ fig) = Q ( + 1; ; Q ( ; t + 1; Q (t + 1; t; Sn fig) [ fig)) :

Hence,

                          Q ( + 1; t; S) nQ + 1; t + 1; Q (t + 1; t; Sn fig) [ fig
                          Q ( + 1; ; Q ( ; t + 1; Q (t + 1; t; Sn fig) [ fig) [ Z ( ; t; i))
                          nQ ( + 1; ; Q ( ; t + 1; Q (t + 1; t; Sn fig) [ fig)) ;

and this set is clearly contained in Z ( + 1; ; Z ( ; t; fig)) = Z ( + 1; t; fig). Thus, (A11) holds
for    + 1, so by induction it holds for all            > t.
      We now complete the proof of Theorem 3. Recall that x
                                                          ~                                x
                                                                                           ^. Thus, by Lemma 1, to show that
single enforcer punishment strategies form a PBE strategy pro…le and support greater cooperation
than contagion strategies, it su¢ ces to show that x                        x
                                                                            ~.
                                                                          P1          t1
      For the …rst part of the theorem, note that lg                           t=0     n qt f   (x)     x is concave and crosses 0
from above at x = x . Therefore,

                                            1
                                                               ! 1
                                            X       1           X
                                                                               t1
                                   lg 0           t
                                                      qt f (x )                      qt f 0 (x ) < 1:
                                                    n                           n
                                            t=0                      t=0

                                                               n
Thus, if g 0 (y)     g for all y then f 0 (x ) <         lg
                                                              P1      t
                                                                          qt
                                                                               . As f is increasing, concave, and bounded,
                                                               t=0
f 0 (x ) is positive, non-increasing, and goes to 0 as x ! 1. Hence, x ! 1 as g ! 1. On the
other hand, x
            ~ is …nite and independent of g, so if g is su¢ ciently high then x > x
                                                                                  ~.
      For the second part, as zt can never exceed kn, x
                                                      ~ is bounded from above by the greatest solution
to x = l (k      1) f (x), which is …nite as f is bounded. On the other hand, limt!1 qt = kn, so if


                                                               39
                                        P1       t1
limy!1 g (y) = 1 then lim      !1 lg       t=0    n qt f   (x)       x = 1 for all x > 0. Hence, x , the greatest
           P1 t 1
root of lg   t=0 n qt f (x)      x, goes to in…nity as               ! 1.

Proof of Theorem 4

For single enforcer punishment strategies, the proof is similar to the proof of Lemma 1, with the
following di¤erences:
   First, the reason why punishments of up to                    1   kf (x ) = y are incentive compatible for
enforcers is that, if an enforcer in the normal state deviates when he is supposed to play yji = y ,
he then loses all future bene…ts of cooperation (recall that a player in the normal state believes
that all of her opponents are also in the normal state). To see this, note that his partners in the
next period will observe his deviation and will therefore play xi = 0, and— since the enforcer will
then be in the infected state— he will play yji = 0. Hence, his partners in the period after next will
also play xi = 0, and so on.
   Second, for a producer in the infected state, the only tempting deviation is to xi = x . This is
clearly unpro…table if all of her enforcers are in the normal state, as it incurs a cost of lg (y ) = x
and does not a¤ect her continuation payo¤. If instead at least one of her enforcers is in the infected
state, then it is unpro…table because the fact that x                  x
                                                                       ~ implies that x         l (k     1) f (x ), and
therefore x       (l   1) g (y ) + (k      1) f (x ).
   The proof for the contagion strategies is simpler and is omitted.

Proof of Theorem 5

For existence, the only di¤erence from the proof of Theorem 4 is that, with informed enforcers,
whenever a producer is in the infected state she believes that every enforcer in her match is also in
the infected state. The condition that x             x
                                                     ~ is thus no longer required.
   The proof that x is an upper bound on each producer’s level of cooperation with informed
enforcers follows the proof of Theorem 1, with one key additional step. In particular, if we follow
the proof of Theorem 1 while conditioning on private rather than public histories where appropriate,
as well as conditioning on the realizations of the matching technology, we arrive at the following
analogue of inequality (A3):
                           2 0                                                                       1   3
                                1                            h                                   i
                           6 B X                 X                                                C 7
              u         lE 4g @                            E f xt+1+
                                                                j               jhtk ; j 2 Mkt+1+ A jhti 5
                                  =0       j2Mkt+1+ \C
                           2                                                3
                                 X
                       + E4                f xt+1
                                              j   jhti ; j 2 Mit+1 5 :
                            j2Mit+1 \Cni




                                                           40
(Here, htk is the private history of the enforcer k in match Mit , which equals ht as enforcers are per-
fectly informed.) As enforcers are perfectly informed, and thus in particular have …ner information
than producers, we have
                     h                                  i       h      h                                               i i
                             t+1
          Eht+1              j     ht+1
                                    j   jht
                                          i ; j 2 M t+1
                                                    i     = Eht  Eht+1
                                                                                        t+1
                                                                                        j         ht+1
                                                                                                   j   jht
                                                                                                           ; j 2 M t+1
                                                                                                                   i    jhti :
                j                                                                 j



By non-discrimination,
                               h                              i         h                                              i
                                   t+1
                    Eht+1          j     ht+1
                                          j   jht
                                                  ; j 2 M t+1
                                                          i     = Eht+1
                                                                                        t+1
                                                                                        j         ht+1
                                                                                                   j   jht
                                                                                                           ; j 2 M t+1
                                                                                                                   k     :
                         j                                                        j



Hence, we have
                                       2 0                                                                            1 3
                                           1                                 h                                       i
                                      6 B X                  X                                                        C t7
                u                  lE 4g @                                  E f xt+1+
                                                                                 j                jht ; j 2 Mkt+1+    A jhi 5
                                                =0    j2Mkt+1+ \C
                                       2 2                                                    3       3
                                  6 6             X                                 7 7
                              + E 4E 4                       f xt+1
                                                                j   jht ; j 2 Mkt+1 5 jhti 5 :                                      (A12)
                                              j2Mkt+1 \Cni


     For any producer j 6= i and any history ht+1
                                              j , replacing                                   j      ht+1
                                                                                                      j   with       j   ht+1
                                                                                                                          j   + " in the
right-hand side of (A12) and di¤erentiating with respect to " yields
                                                                  2 0                                                                        1   3
         l  h                            i                                   1
                                                                             X           X              h                                i
                                                         6 0B                                                                             C 7
           E f 0 xt+1 t+1
                  j jhj                      Pr ht+1 t
                                                 j jhi E 4g @                                          E f xt+1+
                                                                                                            j            jht ; j 2 Mkt+1+ A jhti 5
         n
                                                                                 =0   j2Mkt+1+ \C

          k 1 h 0 t+1 t+1 i
     +        E f xj jhj    Pr ht+1 t
                                j jhi :
         kn 1

The assumption that g 0 (y)                     m for all y implies that the derivative is non-positive for all ht+1
                                                                                                                 j .
Thus, a lower bound on (A12) is obtained by setting xt+1
                                                     j   equal to its upper bound in (A5) for all j,
as in the proof of Theorem 1. The remainder of the argument is identical to the proof of Theorem
1.

Proof of Proposition 2

Start with incentive compatibility for the enforcers. Whenever an enforcer is asked to punish, he
believes that cooperation will return to x1 forever if he punishes, while contagion will start if he
fails to punish. Thus, his incentive compatibility condition is

                                                                  :1             p
                                   y            2f (x1 ) =                  2 100 493:830              493:8286:
                                         1                    1        :1

So he is willing to punish at level y = 493:828 whenever he sees a producer deviation.

                                                                            41
       Now turn to incentive compatibility for the producers. We start with incentives to exert e¤ort
x1 , x2 , and x3 , rather than deviating and choosing e¤ort 0.
       If a producer shirks when she is supposed to play x3 , she is punished at level y and starts
                                    1
contagion with probability          3   (while returning to her equilibrium payo¤ of f (x1 ) x1 with probability
2                                                     2
3 ).    Her contagion payo¤ is at most                3f   (x1 ), as this would be her payo¤ if the contagion never
reached the other two producers and she was never punished in the future. Thus, a su¢ cient
condition for incentive compatibility here is
                                                                                   p                 !
                                          2                        :1           100 493:830
       x3   y+        f (x1 )   x1          f (x1 )    = 493:828 +                             493:830     502:0584:
                 3                        3                        3                 3

So x3 = 502:058 is incentive compatible.
       If a producer shirks when she is supposed to play x2 , she is punished at level y and faces the
additional “punishment”of having to play x3 rather than x1 when matched with the same producer
partner tomorrow. Thus, her incentive compatibility condition is

                                                                     :1
                     x2   y+        (x3     x1 ) = 493:828 +            (502:058    493:830)   494:1023.
                                3                                     3

So x2 = 494:102 is incentive compatible.
       Finally, if a producer shirks when she is supposed to play x1 , she is punished at level y and
also has to play x2 rather than x1 tomorrow with probability 31 . Thus, her incentive compatibility
condition is

                                                                     :1
                     x1   y+        (x2     x1 ) = 493:828 +            (494:102    493:830)   493:8371:
                                3                                    3

So x1 = 493:830 is incentive compatible.
       We also have to check a couple more incentive compatibility conditions. In particular, we have
to show that a producer does not want to deviate to playing x1 rather than x2 or x3 (which avoids
direct punishment but still risks starting contagion); and we have to show that a producer is willing
to go through with contagion (x = 0) when she is supposed to.
       A su¢ cient condition for playing x3 rather than x1 when x3 is called for is:

                                                               f (x1 )
                                          x3    x1                         x1      8:2304:
                                                           3      3

As x3       x1 = 8:228, this is satis…ed.
       A su¢ cient condition for playing x2 rather than x1 when x2 is called for is:

                                               x2     x1           (x3   x1 )   0:2743
                                                               3



                                                                    42
As x2   x1 = 0:272, this is also satis…ed.
   As for the incentives to carry out contagion, note that the only reasons to work today are to
avoid punishment and to encourage others to work in the future. Working today makes enforcers
less likely to enter the contagion phase (i.e., stop punishing), which is bad for producers. So an
upper bound on the present value of reduced punishments from working is the value of reducing
punishments in the current period only. As at least one other producer is also in the contagion
                                                       2
phase, this value of reduced punishments is at most    3y   (as enforcers do not punish when both
producers shirk). Finally, working can prevent another producer from entering the contagion phase
only if this is the third straight time that the same matches have realized, and the two infected
producers are in di¤erence matches. In this case, the other producer in the other match will get
infected no matter what in the current period, so working keeps at most one other producer out of
                                                              1
the contagion phase. An upper bound on the value of this is   3   f (x1 ). Hence, a su¢ cient condition
for carrying out contagion is
                                          f (x1 ) 2
                                   x1            + y    403:2930:
                                             3    3
Since x1 = 493:830, carrying out contagion is incentive compatible.
   We now describe how the example would have to be modi…ed if enforcers also observed the
outcomes of their partners’most recent matches. The reason why some modi…cation is needed is
that the counterexample rests on there being some history where, if a producer shirks, the other
producer in her match knows that this is the third straight time she has shirked, while the enforcer
does not. If enforcers observe the outcomes of their partners’last histories, then a “three strikes
and you’re out” strategy pro…le is not enough to generate such a history. For example, if we label
the two enforcers A and B, if a producer’s match history is ABA then enforcer A will see that she
shirked three times in a row.
   To restore the counterexample, consider a “…ve strikes and you’re out” strategy pro…le, where
contagion starts only if a producers shirks …ve times in a row and her match history for the …rst
four matches is either AABB or BBAA. With such a match history, the …fth enforcer the producer
meets surely will not know that she shirked …ve times in row.

Proof of Theorem 6

Single enforcer punishment strategies are clearly deterministic and satisfy Stability. It remains
only to show that x is an upper bound on each player’s maximum level of cooperation in any
deterministic equilibrium satisfying Stability.
   Under Stability, a necessary condition for producer i not to have a pro…table one-shot deviation




                                                  43
                                                                                                                2f0;1;:::g
in period t in a deterministic equilibrium with equilibrium path xi ; yji                                                    is
                                                                                                             i2C;j2P

                            2                                    3
               1
               X                     X                                   1
                                                                         X
                          E4                    f     xt+
                                                       j
                                                                 5              xt+
                                                                                 i
                =0              j2Mit+ \Cni                               =0
                     2                                     3                    2                           3
                            X                                        1
                                                                     X                   X                           1
                                                                                                                     X
                 E4                     t
                                     g yki jxti = 05 +                         E4                f xt+
                                                                                                    j
                                                                                                            5                     xt+1+
                                                                                                                                   i    ;
                          k2Mit \P                                   =0         j2Mit+ \Cni                            =0


or equivalently                                             2                                  3
                                                                     X
                                                xti    E4                     t
                                                                           g yki jxti = 05 :                                                 (A13)
                                                               k2Mit \P

Next, under Stability, (A2) becomes
                                                                     2                                3
                                                      1
                                                      X                    X
                                                                6                                     7
                                        t
                                       yki                     E4                        f xt+1+
                                                                                            j         5:                                     (A14)
                                                      =0             j2Mkt+1+       \C


Let x = supi;t xti , and note that x < 1 as in the proof of Theorem 1. Combining (A13) and (A14)
then yields x        lg     1    kf (x) . By de…nition of x , this implies that x                           x . Hence, x is an upper
bound on each player’s maximum equilibrium level of cooperation.

Proof of Theorem 7

It is straightforward to see that the SEPAO strategy pro…le with cooperation level x and punishment
level y is a SPE: a producer who deviates gains at most x and loses g (y) + (k                                                    1) f (x), while
                                                                                               nk 1
an enforcer who deviates gains at most y and loses                                       1      nk         kf (x). (More precisely, a
producer’s incentive compatibility constraint in the normal or ostracism phase is (k                                              1) f (x) x
                                                       2
(1     ) ((k    1) f (x)         lg (y))        x+          (k       1) f (x), or x          lg (y) + (k        1) f (x), which holds by
de…nition of x.) Similarly, the single enforcer punishment strategy pro…le with cooperation level x
and punishment level y remains a SPE when ostracism is possible. The main part of the theorem
is showing that x (resp., x) is an upper bound on each producer’s level of cooperation in any SPE
                 m                    m
when g 0 (y)          (resp.,             ) for all y. The argument is parallel to the proof of Theorem 1.
     Fix a SPE        = ( i )i2N , and let u and X be de…ned as in the proof of Theorem 1. As in the
proof of Theorem 1, a necessary condition for producer i not to deviate to playing xi = 0 at history
ht is that, for all xti 2 supp            i   ht ,
                                                                                    2                                              3
                                                                         1
                                                                         X                   X
       (1      ) xti + E Xit+1 jht ; xti                (1           )          E4                      f xt+1+
                                                                                                           j           jht ; xti 5      u:
                                                                          =0         j2Mit+1+    \Cni




                                                                          44
For each producer i and player j, let
                         8                                                                                   9
                         >
                         <              xti if i does not ostracize anyone in period t                       >
                                                                                                             =
               ~tij =
               x             (1        ) xti if i ostracizes someone other than j in period t                    :
                         >
                         :                                                                                   >
                                                                                                             ;
                                                         0 if i ostracizes j in period t

Then, arguing as in the proof of Theorem 1, a necessary condition for enforcer i not to deviate to
playing yik = 0 in period t is
                                                             2                                3
                                                1
                                                X                    X
                                   t
                                  yik                      E4                     ~t+1+
                                                                                f x ji     jht 5 :
                                                    =0            j2Mit+1+ \C


Furthermore, again as in the proof of Theorem 1,
              0               2                                            31       2                                3
                    1
                    X                   X                                                  X
               B              6                                            7C
     u      lg @             E4                            ~t+1+
                                                         f x jk        jht 5A + E 4                     ~t+1
                                                                                                      f xji  jht 5 :     (A15)
                    =0            j2Mkt+1+          \C                                j2Mit+1 \Cni

                                            m
    Bounding X when g 0 (y)                     :
                                  m
    Suppose that g 0 (y)               for all y. We claim that, for any distribution over xj , the right-hand
side of (A15) is minimized when producer j never ostracizes anyone. If                                   > t + 1, then this is
immediate, as if producer j ostracizes anyone the only e¤ect of this on the right-hand side of (A15)
               ~jk . If instead
is to decrease x                            = t + 1, then ostracizing player i increases the right-hand side of
(A15) by
                                                                         k 1
                                            l (g (a)        g (b))           f xt+1
                                                                                j   ;                                    (A16)
                                                                        kn 1

for some numbers a and b that di¤er by                        1
                                                              n    f xt+1
                                                                      j   . In particular, (A16) is no less than

                                            l                                    k 1
                                      inf            f xt+1
                                                        j   g 0 (y)                  f xt+1
                                                                                        j   :
                                   y2R+     n                                   kn 1
                     m
Hence, if g 0 (y)        for all y, then ostracizing player i increases the right-hand side of (A15) by
a positive number, so the right-hand side of (A15) is minimized when producer j never ostracizes
another producer. A similar argument shows that the right-hand side of (A15) is minimized when
producer j never ostracizes an enforcer, so the right-hand side of (A15) is minimized when producer
                                                                                                  m
j never ostracizes anyone. Given this observation, the fact that g 0 (y)                                m for all y implies that
a lower bound on the right-hand side of (A15) is obtained by setting xt+1
                                                                      j   equal to its upper bound
in (A5) for all j, as in the proof of Theorem 1. As in the proof of Theorem 1, this implies (A4),
and combining (A1) and (A4) then implies that x is an upper bound on each player’s maximum
equilibrium level of cooperation.
                                            m
    Bounding X when g 0 (y)                     :

                                                                      45
                                             m                                                                                m
       Suppose now that g 0 (y)                  for all y. The converse of the argument for the g 0 (y)                          case
then implies that the right-hand side of (A15) is minimized when each producer j 6= i ostracizes
all of the producers (but none of the enforcers) in period t + 1 and never ostracizes anyone in
periods        > t + 1, while producer i herself never ostracizes anyone. This gives a lower bound on
the right-hand side of (A15) of
                                        0  hP                                         i 1
                                                                              t+1   t
                                         E      t+1
                                             j2Mk h \C  1     1fj6=ig  f    x j   jh
                           u      lg @    P1         P                     t+1+
                                                                                        i A;                                  (A17)
                                       +         E                   f   x         jh t
                                                           t+1+
                                             =1        j2M       \C    k
                                                                           j


where 1f g denotes the indicator function. By de…nition of X, concavity of f , and Jensen’s inequality,
this implies the following:21

                                                                   nk 1
                                         u        lg                                kf X     :                                (A18)
                                                         1           nk

Combining (A1) and (A18), we have, for every player i, history ht and level of cooperation xti 2
supp      i   ht ,

              (1      ) xti + E Xit+1 jht ; xti
                                                                                    2                                             3
                                                                               1
                                                                               X             X
                               nk 1                                                 4
              lg                                  kf X        + (1         )                           f xt+1+
                                                                                                          j         jht ; xti 5
                      1          nk
                                                                               =0     j2Mit+1+ \Cni

                               nk 1
              lg                                  kf X        + (k         1) f X :
                      1          nk

As X = supi;ht ;xti 2supp          t
                               i (h )
                                        (1       ) xti + E Xit+1 jht ; xti , it follows that

                                                       nk 1
                           X      lg                                   kf X         + (k     1) f X :
                                             1           nk

By de…nition of x, this implies that X                       x. Finally, as E Xi0 jh0            X, we have E Xi0 jh0                 x.
Thus, x is an upper bound on each player’s maximum equilibrium level of cooperation.

Proof of Theorem 8

It is straightforward to see that the SEPAO strategy pro…le with cooperation level x and punishment
level y remains a SPE with non-anonymous perfect monitoring. In addition, the argument that
SEPNAO strategy pro…le with cooperation level x and punishment level y is also a SPE is identical,
because each player faces the same incentives at every history (whether or not an innocent producer
  21
       More speci…cally, by the concavity of f and Jensen’s inequality, if the right-hand side of (A17) is less than
 lg      1
                   nk 1
                    nk
                          kf X          and Xjt+1      X, then it must be that Xjt+2 > X.            As Xj    X for all       by the
                                                                                                       nk 1
de…nition of X, it follows that the right-hand side of (A17) is not less than           lg       1      nk
                                                                                                               kf X       .



                                                                  46
i0 is ostracized in the i-ostracism state a¤ects her payo¤s in that state, but not her incentives).
Finally, the argument that x (resp., x) is an upper bound on each producer’s level of cooperation
                          m             m
in any SPE when g 0 (y)       (resp.,       ) for all y is essentially the same as in the anonymous case.
In particular, the key way in which anonymity is used in the proof of Theorem 7 (or Theorem 1)
is that expectations of producers’ levels of cooperation need not be conditioned on their realized
matches. When there is only one match, this is always the case.


References
 [1] Abreu, Dilip. “Extremal equilibria of oligopolistic supergames.” Journal of Economic Theory
     39 (1986): 191-225.

 [2] Abreu, Dilip. “On the theory of in…nitely repeated games with discounting.”Econometrica 56
     (1988): 383-396.

 [3] Acemoglu, Daron, and Matthew O. Jackson. “Social norms and the enforcement of laws.”
     mimeo, 2014.

 [4] Acemoglu, Daron, and Thierry Verdier. “Property rights, corruption and the allocation of
     talent: A general equilibrium approach.” Economic Journal 108 (1998): 1381-1403.

 [5] Ali, S. Nageeb, and David A. Miller. “Enforcing cooperation in networked societies.” mimeo,
     2014a.

 [6] Ali, S. Nageeb, and David A. Miller. “Ostracism.” mimeo, 2014b.

 [7] Axelrod, Robert. The Evolution of Cooperation, Basic Books, 1984.

 [8] Bates, Robert, Avner Greif, and Smita Singh. “Organizing violence.” Journal of Con‡ict
     Resolution 46 (2002): 599-628.

 [9] Clay, Karen. “Trade without law: private-order institutions in Mexican California.” Journal
     of Law, Economics, and Organization 13.1 (1997): 202-231.

[10] Deb, Joyee. “Cooperation and Community Responsibility: A Folk Theorem for Repeated
     Matching Games with Names,” mimeo, 2012.

[11] Deb, Joyee, and Julio González-Diaz. “Community Enforcement beyond the Prisoner’s
     Dilemma,” American Economic Review, Forthcoming (2014).

[12] Dixit, Avinash. “Trade expansion and contract enforcement.” Journal of Political Economy
     111 (2003): 1293-1317.

[13] Dixit, Avinash K. Lawlessness and economics: alternative modes of governance. Princeton
     University Press, 2007.

[14] Ellickson, Robert C. Order without law: How neighbors settle disputes. Harvard University
     Press, 2009.

[15] Ellison, Glenn. “Cooperation in the prisoner’s dilemma with anonymous random matching.”
     Review of Economic Studies 61 (1994): 567-588.


                                                    47
[16] Fafchamps, Marcel. “The enforcement of commercial contracts in Ghana.”World Development
     24 (1996): 427-448.

[17] Fearon, James D., and David D. Laitin. “Explaining interethnic cooperation.” American Po-
     litical Science Review 90 (1996): 715-735.

[18] Flannery, Kent, and Joyce Marcus. The creation of inequality: how our prehistoric ancestors
     set the stage for monarchy, slavery, and empire. Harvard University Press, 2012.

[19] Fudenberg, Drew, and Eric Maskin. “The folk theorem in repeated games with discounting or
     with incomplete information.” Econometrica 54 (1986): 533-554.

[20] Goldlücke, Susanne, and Sebastian Kranz. “In…nitely repeated games with public monitoring
     and monetary transfers.” Journal of Economic Theory 147 (2012): 1191-1221.

[21] Greif, Avner. “Reputation and coalitions in medieval trade: evidence on the Maghribi traders.”
     Journal of Economic History 49 (1989): 857-882.

[22] Greif, Avner. “Contract enforceability and economic institutions in early trade: The Maghribi
     traders’coalition.” American Economic Review (1993): 525-548.

[23] Greif, Avner. “Cultural beliefs and the organization of society: A historical and theoretical
     re‡ection on collectivist and individualist societies.”Journal of Political Economy 102 (1994):
     912-950.

[24] Greif, Avner. Institutions and the path to the modern economy: Lessons from medieval trade.
     Cambridge University Press, 2006.

[25] Greif, Avner, Paul Milgrom, and Barry R. Weingast. “Coordination, commitment, and en-
     forcement: The case of the merchant guild.” Journal of Political Economy (1994): 745-776.

[26] Grossman, Herschel I., and Minseong Kim. “Swords or plowshares? A theory of the security
     of claims to property.” Journal of Political Economy 103 (1995): 1275-1288.

[27] Hirshleifer, David, and Eric Rasmusen. “Cooperation in a repeated prisoners’ dilemma with
     ostracism.” Journal of Economic Behavior & Organization 12.1 (1989): 87-106.

[28] Hirshleifer, Jack. “Anarchy and its breakdown.” Journal of Political Economy 103 (1995):
     26-52.

[29] Jackson, Matthew O., Tomas Rodriguez-Barraquer, and Xu Tan. “Social capital and social
     quilts: Network patterns of favor exchange.” American Economic Review 102.5 (2012): 1857-
     1897.

[30] Johnson, Allen W. and Timoty Earle. The evolution of human societies: from foraging group
     to agrarian state. Stanford University Press, 2000.

[31] Johnson, Simon, John McMillan, and Christopher Woodru¤. “Courts and relational contracts.”
     Journal of Law, Economics, and Organization 18 (2002): 221-277.

[32] Kali, Raja. “Endogenous business networks.” Journal of Law, Economics, and Organization
     15 (1999): 615-636.

[33] Kandori, Michihiro. “Social norms and community enforcement.” The Review of Economic
     Studies 59 (1992): 63-80.

                                                48
[34] Kranton, Rachel E. “Reciprocal exchange: a self-sustaining system.”American Economic Re-
     view 86 (1996): 830-851.

[35] Levine, David K. and Salvatoe Modica, “Peer discipline and incentives within groups,”mimeo.

[36] Lewis, Ioan M. Blood and Bone: The Call of Kinship in Somali Society, Red Sea Press, 1994.

[37] Lippert, Ste¤en, and Giancarlo Spagnolo. “Networks of relations and word-of-mouth commu-
     nication.” Games and Economic Behavior 72 (2011): 202-217.

[38] Mailath, George J., and Larry Samuelson. Repeated games and reputations. Oxford. Oxford
     University Press 2006.

[39] McMillan, John, and Christopher Woodru¤. “Inter…rm relationships and informal credit in
     Vietnam.” Quarterly Journal of Economics 114 (1999): 1285-1320.

[40] Milgrom, Paul R., and Douglass C. North. “The role of institutions in the revival of trade:
     The law merchant, private judges, and the champagne fairs.”Economics & Politics 2.1 (1990):
     1-23.

[41] Myerson, Roger B. Game theory. Harvard University Press, 1991.

[42] Ostrom, Elinor. Governing the commons: The evolution of institutions for collective action.
     Cambridge University Press, 1990.

[43] Padró i Miquel, Gerard, and Pierre Yared. “The Political Economy of Indirect Control.”Quar-
     terly Journal of Economics 127 (2012): 947-1015.

[44] Skaperdas, Stergios. “Cooperation, con‡ict, and power in the absence of property rights.”
     American Economic Review 82 (1992): 720-739.

[45] Takahashi, Satoru. “Community enforcement when players observe partners’past play.”Jour-
     nal of Economic Theory 145 (2010): 42-62.

[46] Tilly, Charles. “War making and state making as organized crime” in Bringing the State
     Back In, Peter B. Evans, Dietrich Rueschemeyer, Theda Skocpol eds. Cambridge: Cambridge
     University Press, 1985.

[47] Wolitzky, Alexander. “Cooperation with network monitoring.”Review of Economic Studies 80
     (2013): 395-427.

[48] Woodru¤, Christopher. “Contract enforcement and trade liberalization in Mexico’s footwear
     industry.” World Development 26.6 (1998): 979-991.




                                              49
