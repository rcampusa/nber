                                 NBER WORKING PAPER SERIES




                  QUANTILE REGRESSION UNDER MISSPECIFICATION,
                 WITH AN APPLICATION TO THE U.S. WAGE STRUCTURE

                                            Joshua Angrist
                                         Victor Chernozhukov
                                         Iván Fernández-Val

                                         Working Paper 10428
                                 http://www.nber.org/papers/w10428


                       NATIONAL BUREAU OF ECONOMIC RESEARCH
                                1050 Massachusetts Avenue
                                  Cambridge, MA 02138
                                       April 2004




We thank David Autor, Gary Chamberlain, George Deltas, Jinyong Hahn, Jerry Hausman, Roger Koenker,
and Art Lewbel for helpful discussions, and seminar participants at BYU, the University of Michigan,
Michigan State University, the Harvard-MIT Econometrics Workshop, the University of Toronto, the
University of Illinois at Urbana- Champaign, and the 2004 Winter Econometric Society Meetings for
comments. The views expressed herein are those of the author(s) and not necessarily those of the National
Bureau of Economic Research.

©2004 by Joshua Angrist, Victor Chernozhukov, and Iván Fernández-Val. All rights reserved. Short sections
of text, not to exceed two paragraphs, may be quoted without explicit permission provided that full credit,
including © notice, is given to the source.
Quantile Regression under Misspecification, with an Application to the U.S. Wage Structure
Joshua Angrist, Victor Chernozhukov, and Iván Fernández-Val
NBER Working Paper No. 10428
April 2004
JEL No. J31, C13, C14
                                        ABSTRACT


Quantile regression(QR) fits a linear model for conditional quantiles, just as ordinary least

squares (OLS) fits a linear model for conditional means. An attractive feature of OLS is that it

gives the minimum mean square error linear approximation to the conditional expectation

function even when the linear model is misspecified. Empirical research using quantile

regression with discrete covariates suggests that QR may have a similar property, but the exact

nature of the linear approximation has remained elusive. In this paper, we show that QR can be

interpreted as minimizing a weighted mean-squared error loss function for specification error.

The weighting function is an average density of the dependent variable near the true conditional

quantile. The weighted least squares interpretation of QR is used to derive an omitted variables

bias formula and a partial quantile correlation concept, similar to the relationship between partial

correlation and OLS. We also derive general asymptotic results for QR processes allowing for

misspecification of the conditional quantile function, extending earlier results from a single

quantile to the entire process. The approximation properties of QR are illustrated through an

analysis of the wage structure and residual inequality in US Census data for 1980, 1990, and

2000. The results suggest continued residual inequality growth in the 1990s, primarily in the

upper half of the wage distribution and for college graduates.

Joshua Angrist                   Victor Chernozhukov                Iván Fernández-Val
MIT                              MIT                                MIT
Department of Economics          Department of Economics            Department of Economics
50 Memorial Drive                50 Memorial Drive                  50 Memorial Drive
Cambridge, MA 02142-1347         Cambridge, MA 02142-1347           Cambridge, MA 02142-1347
and NBER                         vchern@mit.edu                     ifern12@mit.edu
angrist@mit.edu
1        Introduction

The Quantile Regression (QR) estimator, introduced by Koenker and Bassett (1978), is an
increasingly important empirical tool, allowing researchers to fit parsimonious models to an
entire conditional distribution. Part of the appeal of quantile regression derives from a natural
parallel with conventional ordinary least squares (OLS) or mean regression.                     Just as OLS
regression coefficients offer convenient summary statistics for conditional expectation functions
(CEF), quantile regression coefficients can be used to make easily interpreted statements about
conditional distributions. Moreover, unlike OLS coefficients, QR estimates capture changes in
distribution shape and spread, as well as changes in location.
        An especially attractive feature of OLS regression estimates is their robustness and inter-
pretability under misspecification of the CEF. In addition to consistently estimating a linear
CEF, OLS estimates provide the minimum mean square error (MMSE) linear approximation to
a CEF of any shape. The MMSE interpretation of OLS is emphasized by Chamberlain (1984)
and Goldberger (1991), while an average derivative interpretation of OLS features in Angrist
and Krueger (1999). This robustness property – i.e., the fact that OLS provides a meaningful
and well-understood summary statistic for multivariate conditional expectations under almost
all circumstances – undoubtedly contributes to the primacy of OLS regression as an empirical
tool.       In view of the possibility of interpretation under misspecification, modern theoretical
research on regression inference typically also allows for misspecification when deriving limiting
distributions (see, e.g., White, 1980).
        While QR estimates are as easy to compute as OLS regression coefficients, an important
difference between OLS and QR is that most of the theoretical and applied work on QR postu-
lates a true linear model for conditional quantiles. This raises the question of whether and how
QR estimates can be interpreted when the linear model for conditional quantiles is misspecified
(for example, QR estimates at different quantiles may imply conditional quantile functions that
cross). One interpretation for QR under misspecification is that it provides the best linear pre-
dictor for a response variable under asymmetric loss. This interpretation is not very satisfying,
however, since prediction under asymmetric loss is typically not the object of interest in em-
pirical work (see, e.g., Koenker and Hallock, 2001).1 Empirical research on quantile regression
with discrete covariates suggests that QR may have an approximation property similar to that
of OLS, but the exact nature of the linear approximation has remained an important unresolved
    1
        An exception is the forecasting literature; see, e.g., Giacomini and Komunjer (2003).



                                                           1
question (cf. Chamberlain, 1994, p. 181).
   The first contribution of this paper is to show that QR can be interpreted as the best linear
predictor (BLP) for the conditional quantile function (CQF) using a weighted mean-squared
error loss function, much as OLS regression provides a MMSE fit to the CEF. The implied
QR weighting function can be used to understand which, if any, parts of the distribution of
regressors contribute disproportionately to a particular set of QR estimates. We also show how
the weighted mean-square error interpretation can be used to interpret QR coefficients as partial
quantile correlation coefficients and to develop an omitted variable bias formulae for QR.
   A second contribution is to develop a distribution theory for the entire QR process that
applies under misspecification of the conditional quantile function. The approach developed
here has two advantages over current practice. First, we do not assume that the true quantile
function is linear. Second, some of the regularity conditions that would be required for a fully
nonparametric approach, such as multiple differentiability of the quantile function in regressors
and continuity of regressors, are not needed. Our analysis of the QR process extends the
results of Chamberlain (1994) and Hahn (1997), who derived the basic variance formula for a
particular quantile under misspecification. See also Koenker and Machado (1999), Gutenbrunner
and Jureckova (1992), and Gutenbrunner, Jureckova, Koenker, Portnoy (1993), who develop
inference procedures based on QR processes for the linear location shift model and linear Pitman
deviations from this model.
   An important consequence of our analysis is that the currently used inference tools on the
QR process, such as those in Koenker and Machado (1999), are not robust to misspecification.
This is because the limit distribution of the QR process is not distribution-free under misspeci-
fication. Moreover, Khmaladzation techniques, as in Bai (1998) and Koenker and Xiao (2002),
cannot restore the distribution-free nature of the limit theory in this case. We therefore suggest
alternative methods that provide valid inference for the QR process under misspecification.
   The approximation theorems and other theoretical ideas in the paper are illustrated with an
analysis of wage data from the 1980, 1990, and 2000 U.S. censuses. The analysis here is motivated
by similar studies in labor economics, where quantile regression has been widely used to model
changes in the wage distribution (see, e.g., Buchinsky, 1994 and Autor, Katz, and Kearney,
2004 for the US; Gosling, Machin, and Meghir, 2000, for the UK; Abadie, 1997, for Spain, and
Machado and Mata, 2003, for Portugal). In particular, we show that quantile regression, while
an inexact model for conditional quantiles, gives a good account of the relevant stylized facts.
An appealing feature of quantile regression in this context is that quantile regression coefficients


                                                 2
can be used directly to describe “residual inequality,” i.e. the spread in the wage distribution
conditional on the variables included in the quantile regression model.         Attempts to model
residual wage inequality have been of major substantive importance to labor economists since
Juhn, Murphy, and Pierce (1993).
    The paper is organized as follows. Section 2 introduces assumptions and notation and
presents the main approximation theorems, followed by an empirical illustration. Section 3
provides the inference theory for QR processes under misspecification. Section 4 presents addi-
tional empirical results on the evolution of residual inequality using data from the 1980, 1990,
and 2000 censuses. Section 5 concludes with a brief summary.


2     Interpreting QR Under Misspecification

2.1   Notation and Framework


Given a continuos response variable Y and a d × 1 regressor vector X, we are interested in
the (population) conditional quantile function (CQF) of Y given X. The conditional quantile
function is defined as:
                               Qτ (Y |X) ≡ inf {y : FY (y|X) ≥ τ },                              (1)

where FY (y|X) is the distribution function for Y conditional on X, with associated conditional
density fY (y|X). The CQF can also be defined as the solution to the following minimization
problem (assuming integrability throughout where needed):

                             Qτ (Y |X) ≡ arg min E [ρτ (Y − q(X))] ,                             (2)
                                               q(X)

where ρτ (u) = (τ − 1(u ≤ 0))u and the minimum is over the set of measurable functions of X.
This is a potentially infinite-dimensional problem if covariates are continuous, and can be very
high-dimensional even with discrete X. It may nevertheless be possible to capture important
features of the CQF using a linear model. This motivates linear quantile regression.
    The Koenker and Bassett (1978) linear quantile regression (QR) estimator solves the follow-
ing population minimization problem:
                                                £              ¤
                               β(τ ) ≡ arg min E ρτ (Y − X 0 β) .                                (3)
                                            β∈Rd

If q(X) is in fact linear, the QR minimand will find it (just as if the CEF is linear, OLS regression
will find it). More generally, QR provides the best linear predictor for Y under the asymmetric


                                                   3
loss function, ρτ . As noted in the introduction, however, prediction under asymmetric loss
is rarely the object of empirical work. Rather, the conditional quantile function is of intrinsic
interest. For example, labor economists are often interested in comparisons of conditional deciles
as a measure of how the spread of a wage distribution changes conditional on covariates, as in
Katz and Murphy (1992) and Juhn, Murphy, and Pierce (1993). Thus, we would like to establish
the nature of approximation that QR provides.


2.2     The QR Approximation Property


Our principal theoretical result is that the population QR vector minimizes a weighted sum
of squared specification errors.           This is easiest to show using notation for a quantile-specific
specification error and for a quantile-specific residual. For a given quantile τ , we define the QR
specification error as:
                                          ∆τ (X, β) = X 0 β − Qτ (Y |X).                              (4)

Similarly, let ²τ be a quantile-specific residual, defined as the deviation of the response variable
from the conditional quantile of interest:

                                               ²τ = Y − Qτ (Y |X),                                    (5)

with conditional density f²τ (e|X) at ²τ = e. The following theorem shows that QR is the
weighted least squares approximation to the unknown CQF.

Theorem 1 (Approximation Property) Suppose that (i) the conditional density fY (y|X)
exists a.s., (ii) Qτ (Y |X) is uniquely defined by (2), and (iii) β(τ ) is uniquely defined by (3).
Then
                                               £                      ¤
                              β(τ ) = arg min E wτ (X, β) · ∆2τ (X, β) ,                            (P1)
                                                β∈Rd

where
                               Z    1
             wτ (X, β) =                (1 − u)f²τ (u∆τ (X, β)|X) du                                  (6)
                                0
                               Z    1               ¡                                 ¢
                          =             (1 − u) · fY u · X 0 β + (1 − u) · Qτ (Y |X)|X du > 0.        (7)
                                0

   This result says that the population QR coefficient vector β(τ ) minimizes the expected
weighted mean squared approximation error, i.e. the square of the difference between the true
CQF and the linear approximation, with weighting function wτ (X, β). The weights involve an
integral in either the conditional density of the quantile residual, or, by a change of variables using

                                                        4
Y = Qτ (Y |X)+ ²τ , the conditional density of the response variable. The latter representation
shows the weighting function to be given by the average density of the response variable over
a line from the point of approximation, X 0 β, to the true conditional quantile, Qτ (Y |X). Pre-
multiplication by the term (1 − u) in the integral results in more weight being applied at points
on the line closer to the true CQF.
    We refer to the function wτ (X, β) as defining importance weights, since this function de-
termines the importance the QR minimand gives to points in the support of X for a given
distribution of X. In addition to the importance weights, the probability distribution of X also
determines the ultimate weight given to different values of X in the least squares problem. To
see this, note that we can also write the QR minimand as
                                           Z
                          β(τ ) = arg min wτ (x, β) · ∆2τ (x, β) dP (x),                      (8)
                                      β∈Rd

where P (x) is the CDF of X (with associated probability or density function p(x)). Thus, the
overall weight varies in the distribution of X according to

                                         wτ (x, β) · p(x).                                    (9)

    The sense in which QR approximates a nonlinear CQF can be seen for an empirical wage
equation in Figure 1. This figure plots an estimate of the CQF for log-earnings given education
for the 0.10, 0.25, 0.50, 0.75 and 0.90 quantiles, using data for US-born black and white men
aged 40-49 from the 1980 census (see Appendix for details concerning data). Here we take
advantage of the discreteness of the schooling variable and the large census sample to compare
QR estimates with the true (sample) CQF evaluated at each point in the support of X.           In
addition to the dots plotting Qτ (Y |X) against X, the figure also shows the (solid) QR regression
line.
    To compare the consequences of combined importance- and histogram-weighting, as in The-
orem 1, to a weighting scheme using the X histogram only, the figure also shows a graphical
representation of a minimum distance (MD) estimator suggested by Chamberlain (1994). The
MD estimator is the sample analog of the vector β̃(τ ) solving
                                £                    ¤           £          ¤
              β̃(τ ) = arg min E (Qτ (Y |X) − X 0 β)2 = arg min E ∆2τ (X, β) .               (10)
                          β∈Rd                                   β∈Rd


In other words, β̃(τ ) is the slope of the linear regression of Qτ (Y |X) on X, weighted only by
the probability distribution of X, p(x). The dashed line in the figure has the slope determined
by Chamberlain’s estimator. Note that unlike QR, the MD estimator relies on the ability to

                                                5
nonparametrically estimate Qτ (Y |X) in a nonparametric first step.                    This is facilitated here
by the discreteness of X and our large census samples, but would otherwise require additional
restrictions and regularity conditions. Chamberlain (1994) observes that, in general, the MD
estimator is likely to be attractive only when X is low dimensional and the sample size is large.
      For every quantile, the QR and MD regression lines are remarkably close, supporting the
conclusion reached in Theorem 1 – that QR is a weighted MD approximation to the unknown
CQF – and suggesting the extra weighting by the importance weights wτ (x, β) does not induce
big differences between MD and QR. In fact, for some quantiles, the MD and QR lines are
not discernible different. Under either weighting scheme, the linear fits appear to describe the
actual conditional quantiles reasonably well.
      By way of comparison and to provide a visual standard for the goodness of fit of QR to the
CQF, the figure also incorporates a panel illustrating the fit of an OLS regression line to the
CEF. This panel (bottom, right position in the figure) shows points on the CEF plotted as
dots, along with the dashed OLS regression line and the solid generalized least squares (GLS)
regression line. To compute the GLS slope, E[Y |X] was regressed on X, weighted by the inverse
of the conditional variance of Y given X. The OLS fit to the CEF is similar to the QR fit to
the CQF at the median. The estimated median QR and OLS regression slopes are also similar,
at 6.39 and 6.98 in percentage terms. Panel A of Table 1 reports the slopes of the lines plotted
in each panel of Figure 1.
      To further investigate the nature of the QR weighting function in the schooling example,
Figure 2 plots wτ (x, β(τ ))p(x) against the regressor X. The solid line in the figure shows the
product wτ (x, β(τ ))p(x), along with the histogram of education, p(x), the weights used in the
Chamberlain MD estimator. The figure also shows normalized kernel density estimates of the
importance weights, wτ (x, β(τ )), plotted with a dashed line.2 Consistent with the comparison
of estimators in Figure 1, the importance weights are reasonably flat for the quantiles considered
here, so that most of the variation in the overall weighting function comes from the X histogram.
As in Figure 1, Figure 2 again includes an analogous panel for mean regression and the CEF. The
CEF analog of the QR importance weights is the inverse of V [Y | X], since the latter plays the
role of importance-weighting in GLS estimation. Here too, the importance weighting function
is reasonably flat.
  2
      See Appendix B for a detailed description of the procedure used for kernel density estimation of the weights.




                                                         6
2.3      Conditional Density as Primary Determinant of Importance Weights


What features of the joint distribution of Y and X determine the theoretical shape of the
importance weighting function for QR? Suppose initially that the linear model for conditional
quantiles is correct, so the approximation error is zero and ∆τ (X, β(τ )) = 0. In this case, the
weighting function when evaluated at β = β(τ ) simplifies to

                                  wτ (X, β(τ )) = 1/2 · fY (Qτ (Y |X)|X) ,                                    (11)

i.e., the weights are proportional to the conditional density of the response variable at the
relevant conditional quantile. More generally, for response data with a smooth conditional
density around the relevant quantile, we have for β in the neighborhood of β(τ ):
                                                                                       ¯ ¯
       wτ (X, β) = 1/2 · fY (Qτ (Y |X)|X) + rτ (X), where |rτ (X)| ≤ 1/6 · |∆τ (X, β)| ¯f¯0 ¯ .               (12)

Here, rτ (X) is a remainder term and the density fY (y|X) has a first derivative in y bounded
a.s. by a constant, denoted f¯0 .3 This argument demonstrates that we can in most cases think of
the density weights 1/2 · fY (Qτ (Y |X)|X) as being the primary determinant of the importance
weights.4 This interpretation applies when the degree of misspecification is modest or the
variability of conditional density fY (y|X) in y near the true CQF is not substantial.
       For the empirical example considered in this section, the weighting function wτ (X, β(τ ))
and the density-based approximation are remarkably close. This can be seen in Figure 3, which
plots estimates of both importance and density weights constructed using a kernel method. The
previous argument suggests there are two reasons for this: the approximation error ∆τ (X, β(τ ))
is mostly small and the conditional density fY (y|X) does not vary much in y near the true
quantiles. The figure also shows that both the weighting function and its first order approxima-
tion are fairly stable, suggesting that the conditional density of y is stable across the levels of
X at each quantile.
   3
                                                                   R1
     The remainder term is |rτ (X)| = wτ (X, β) − 12 · f²τ (0|X) = 0 (1 − u)(f²τ (u · ∆τ (X, β)|X) − f²τ (0|X))du ≤
                   R1
|∆τ (X, β)| · f¯0 · 0 (1 − u) · u · du = 61 · |∆τ (X, β)| · f¯0 .
   4
     Powell (1994, p. 2473) notes that an efficient weighted QR estimator (in the sense of attaining the relevant
semiparametric efficiency bound) is obtained by weighting the original Koenker and Bassett QR minimand by
f²τ (0|X). Since the variance of the sample analog of Qτ (Y |X) is proportional to 1/f²2τ (0|X), Powell’s estimator
is equivalent to a GLS (efficient) estimator for conditional quantiles under correct specification. The first order
asymptotic equivalence of the GLS fit and Powell’s estimator under correct specification is noted by Knight (2002).




                                                        7
2.4       Partial Quantile Correlation


The least squares interpretation of QR has a practical payoff in that we can use it to develop a
regression-decomposition scheme and an omitted variables bias formula for QR. The idea here
is to express each QR coefficient as a coefficient in a bivariate LS projection of the unknown
CQF on each regressor, after the effects of other regressors have been “partialled out.” Since
these derivations rely on least-squares algebra, a pre-requisite for the development of this de-
composition is a version of the LS approximation property with weights that are fixed in the
optimization problem. This version of the QR minimand is given in the theorem below.

Theorem 2 (Iterative Approximation Property) Under the conditions of Theorem 1, QR
coefficients satisfy the equation
                                                     £                    ¤
                                    β(τ ) = arg min E w̃τ (X) · ∆2τ (X, β) ,                                (P2)
                                               β∈Rd

where
                                       Z
                                      1 1
                       w̃τ (X) =          f² (u · ∆τ (X, β(τ ))|X) du                                        (13)
                                      2 0 τ
                                       Z
                                      1 1 ¡                                    ¢
                                =         fY u · X 0 β(τ ) + (1 − u)Qτ (Y |X)|X du.                          (14)
                                      2 0

       Theorem 2 differs from Theorem 1 in that the weights are defined ex post, i.e., they are defined
using the solution vector to the QR problem. Theorem 2 complements Theorem 1 in that it
characterizes the QR coefficient as a fixed point to an iterated minimum distance approximation.5
The relationship between the weighting functions in Theorems 1 and 2 is analogous to the
relationship between the weights used to compute a continuously updated GMM Estimator and
the corresponding iterated estimator (see Hansen, Heaton, and Yaron, 1996).
       The weighting function w̃τ (X) is again related to the conditional density of the dependent
variable.      In particular, for a response variable with smooth conditional density around the
relevant quantile, we have
                                                                                          ¯ ¯
                                                          rτ (X)| ≤ 1/4 · |∆τ (X, β(τ ))| ¯f¯0 ¯ ,
       w̃τ (X) = 1/2 · fY (Qτ (Y |X)|X) + reτ (X), where |e                                                  (15)
   5
       In other words, given weights defined in terms of β(τ ), the solution to the weighted minimum distance
approximation is β(τ ). It is easy to show that this fixed point property defines β(τ ) uniquely whenever β(τ ) is
the the unique solution to the original QR problem.




                                                        8
where reτ (X) is a remainder term and the density fY (y|X) has a first derivative in y bounded
a.s. by a constant, denoted f¯0 .6 When either ∆τ (X, β(τ )) or f¯0 is small,

                                                          1
                                 w̃τ (X) ≈ wτ (X, β(τ )) ≈ fY (Qτ (Y |X)|X),                                     (16)
                                                          2

so the approximate weighting function is the same as before when the QR coefficient vector is
evaluated at its solution value.
         Partial quantile correlation is defined with regard to a partition of the regression vector into
a variable, X1 , and the remaining d − 1 variables X2 , along with the corresponding partition of
the QR coefficients. Thus,

                                   X = [X1 , X20 ]0 ,    β(τ ) = (β1 (τ ), β2 (τ )0 )0 .                         (17)

We can now decompose Qτ (Y |X) and X1 using orthogonal projections onto X2 weighted by
w̃τ (X), just as can be done for weighted least squares mean regression:

                Qτ (Y |X) = X20 πQ + qτ (Y |X), such that E[w̃τ (X) · X2 · qτ (Y |X)] = 0,                       (18)

                       X1 = X20 π1 + V1 , such that E[w̃τ (X) · X2 · V1 ] = 0.                                   (19)

In this decomposition, qτ (Y |X) and V1 are residuals created by a weighted linear projection
of the CQF, Qτ (Y |X), and X1 on X2 , respectively, using w̃τ (X) as weight.7 Then, standard
mathematics for least squares gives
                                                  £                             ¤
                               β1 (τ ) = arg min E w̃τ (X) (qτ (Y |X) − V1 β1 )2 ,                               (20)
                                               β1

and also
                                                 £                             ¤
                              β1 (τ ) = arg min E w̃τ (X) (Qτ (Y |X) − V1 β1 )2 .                                (21)
                                              β1

This shows that β1 (τ ) can be interpreted as the “partial quantile correlation coefficient” in
the sense that it can be obtained from a regression of the CQF, Qτ (Y |X), on X1 , once we have
partialled out the effect of X2 . Both the partialling-out and second-step regressions are weighted
by the QR weighting function.
         Figure 4 shows partial quantile correlation plots for the effect of schooling on wages, adjusting
for the effect of a quadratic function of potential experience.8 For this example the sample age
     6
                                                                       R1
        The remainder term is |erτ (X)| = w̃τ (X) − 21 · f²τ (0|X) = 12 0 (f²τ (u · ∆τ (X, β(τ ))|X) du − f²τ (0|X))du ≤
                             R1
1
2
    · |∆τ (X, β(τ ))| · f¯0 · 0 u · du = 14 · |∆τ (X, β(τ ))| · f¯0 .
      7
        Thus, πQ = E [w̃τ (X)X2 X20 ]−1 E [w̃τ (X)X2 Qτ (Y |X)] and π1 = E [w̃τ (X)X2 X20 ]−1 E [w̃τ (X)X2 X1 ].
      8
        Potential experience is defined in the standard way as age - years of schooling - 6.


                                                           9
range is extended to 30-54 to increase the range of variation of potential experience, and the
sample is restricted to white men.9 The points in the figure correspond to the scatterplot of
the partial residuals of the CQF of log-earnings and schooling for the 0.10, 0.25, 0.50, 0.75 and
0.90 quantiles, i.e. qτ (Y |X) plotted against V1 ; while the solid line represents the partial QR
slope. In this example, the partial CQF of log-earnings given schooling looks to be close to
linear for every quantile. The dashed line is a counterfactual QR with the same slope as for
schooling without controls. As for conventional least squares estimates (see bottom right panel),
the omission of experience causes downward bias in the coefficient of schooling for every quantile,
since experience and schooling are negatively correlated and experience raises wages.


2.5      Omitted Variables Bias

The previous discussion suggests we can use a reasoning process much like that for OLS when
analyzing omitted variables bias in the context of QR. Here we use the least squares interpre-
tation of QR to construct formal relationship between “long” QR coefficients and “short” QR
coefficients. In particular, suppose we are interested in a quantile regression with explanatory
variables X = [X10 , X20 ]0 , but X2 is not available, e.g. ability in the wage equation. We run QR
on X1 only, obtaining the coefficient vector

                                     γ1 (τ ) = arg min E[ρτ (Y − X10 γ1 )].                              (22)
                                                       γ1

The long regression coefficient vectors are (β1 (τ ), β2 (τ )), defined by

                          (β1 (τ )0 , β2 (τ )0 )0 = arg min E[ρτ (Y − X10 β1 − X20 β2 )].                (23)
                                                       β1 ,β2

Finally, it is useful to define a remainder term

                                       Rτ (X) = Qτ (Y |X) − X10 β1 (τ ),                                 (24)

equal to the residual of the CQF, given both X1 and X2 , not explained by the linear function
of X1 in the long QR. If the CQF is linear, then Rτ (X) = X20 β2 (τ ).
      The following theorem describes the relationship between γ1 (τ ) and β1 (τ ).

Theorem 3 (Long and Short Coefficients) Suppose that the conditions of Theorem 1 hold
and γ1 (τ ) is uniquely defined by (22). Then, 1.

                                   γ1 (τ ) = arg min E[w̃τ∗ (X) · ∆2τ (X, γ1 )],                         (25)
                                                  γ1

  9
      The inclusion of black men complicates estimation of the weights and CQF because of small cells.


                                                            10
where ∆τ (X, γ1 ) = X10 γ1 − Qτ (Y |X), ²τ = Y − Qτ (Y |X), and
                                                    Z   1
                                                1
                                   w̃τ∗ (X)   =             f²τ (u · ∆τ (X, γ1 (τ ))|X)du .                        (26)
                                                2   0

2. If E[w̃τ∗ (X) · X1 X10 ] is invertible, γ1 (τ ) = β1 (τ ) + B1 (τ ), where

                               B1 (τ ) = E[w̃τ∗ (X) · X1 X10 ]−1 E[w̃τ∗ (X) · X1 Rτ (X)].                          (27)

         As with OLS short and long calculations, the omitted variables formula in this case shows the
short QR coefficients to be equal to the corresponding long QR coefficients plus the coefficients
in a weighted projection of omitted effects on included variables. While the parallel with OLS
seems clear, there are two complications in the QR case. First, the effect of omitted variables
appears through the remainder term, Rτ (X). In practice, it seems reasonable to think of this
as being approximated by the omitted linear part, X20 β2 (τ ). Second, the regression of omitted
variables on included variables is weighted by w̃τ∗ (X), while for OLS it is unweighted.10


3         Large Sample Properties of QR and Robust Inference Under
          Misspecification

In this section, we study the consequences of misspecification for large sample inference on the
quantile regression process
                                        n
                                   1X
                 β̂(τ ) = arg min     ρτ (Yi − Xi0 β), τ ∈ T ≡ closed subinterval of (0, 1).                       (28)
                              β∈Rd n
                                      i=1

The QR process β̂(•), viewed as a function of the probability index τ , is a regression general-
ization of the quantile processes and quantile-quantile plots used in univariate and two-sample
treatment control problems, cf. Doksum (1974). To see this, suppose the regressor is a dummy
for receiving a treatment, denoted D, so we have X = (1, D)0 . Then, the components of the
quantile regression process β̂(•) = (β̂1 (•), β̂2 (•))0 measure easily interpreted quantities. In par-
ticular, the intercept β̂1 (•) measures the quantile function in the control group, and the slope
β̂2 (•) measures the quantile treatment effect (as a function of the probability τ ). When the
regressors are continuous, β̂2 (•) measures the quantile treatment effect as a response to a unit
    10
         Note that the omitted variables bias formula derived here can be used to determined the bias from measure-
ment error in regressors, by identifiying the error as the omitted variable. For example, classical measurement
error is likely to generate an attenuation bias in QR as well as OLS estimates.               We thank Arthur Lewbel for
pointing this out.


                                                                 11
change in the treatment. Under misspecification, the QR slope process, β̂2 (•), should be inter-
preted as approximating the quantile treatment effect, while β̂1 (•) approximates the quantile
function in the control group, in the sense stated in Theorem 1.
   Previous studies of the QR process β̂(•) focused on the linear location or scale shift mod-
els, or Pitman deviations from these models. See especially Koenker and Machado (1999),
Gutenbrunner and Jureckova (1992), Gutenbrunner, Jureckova, Koenker, Portnoy (1993). The
first purpose of this section is to extend previous limit theory for the QR process to allow for
misspecification of any type. The second purpose is to analyze the consequences of misspecifica-
tion for currently used inference tools, and derive inference procedures that remain valid under
misspecification.


3.1   Basic Large Sample Properties


The following conditions are used to insure consistency:

A.1 (Yi , Xi , i ≤ n) are iid on the probability space (Ω, F, P ) for each n.

A.2 The conditional density fY (y|X = x) exists P -a.s.

A.3 E kXk < ∞, and for all τ ∈ T , β(τ ) defined to solve
                                         £                      ¤
                                       E (τ − 1{Y ≤ X 0 β(τ )})X = 0                       (29)

      is the unique solution in Rd .

Theorem 4 (Consistency of QR Process) Under conditions A.1-A.3,

                                       sup kβ̂(τ ) − β(τ )k = op (1).                      (30)
                                       τ ∈T

   The following additional conditions are imposed to obtain asymptotic normality:

A.4 The conditional density fY (y|X = x) is bounded and uniformly continuous in y, uniformly
      in x over the support of (Y, X).

A.5 J(τ ) ≡ E fY (X 0 β(τ )|X)XX 0 is positive definite and finite for all τ , and E kXk2+² < ∞
      for some ² > 0.




                                                    12
Theorem 5 (Gaussianity of QR Process) Under A.1-A.5, we have that

                    √ ³            ´        n
                                         1 X¡                     ¢
                J(•) n β̂(•) − β(•) = − √     • − 1{Yi ≤ Xi0 β(•)} Xi + op (1)
                                          n
                                                        i=1

converges weakly to a tight zero mean Gaussian process z(•), in the space of bounded function
`∞ (T ), where z(•) is defined by its covariance function Σ(τ, τ 0 ) ≡ E {z(τ )z(τ 0 )0 }, where
                                 ¡     ©             ª¢ ¡ 0   ©               ª¢
                 Σ(τ, τ 0 ) = E [ τ − 1 Y < X 0 β(τ )    τ − 1 Y < X 0 β(τ 0 ) XX 0 ].             (31)

When the model is correctly specified, i.e. Qτ (Y |X) = X 0 β(τ ), then

                           Σ(τ, τ 0 ) = Σ0 (τ, τ 0 ) ≡ [min(τ, τ 0 ) − τ τ 0 ] · E [XX 0 ].        (32)

In general, Σ(·, ·) 6= Σ0 (·, ·).

    The proof of this result (in the appendix) is of independent interest, since it does not rely on
either convexity arguments, which are not applicable for the process case, or explicit chaining
arguments, which are case-specific and therefore difficult to establish for all QR problems (see
e.g. Portnoy, 1991). In contrast, the proof relies primarily on the fact that the functional class
{1{Y ≤ X 0 β}, β ∈ Rd } is Donsker. Thus, the theorem easily extends to a wide range of cases
where a uniform central limit theorem holds for this functional class. In particular, extensions
to strong, uniformly mixing, and various Markovian data are immediate.
    Theorem 5 allows for misspecification and imposes little structure on the underlying con-
ditional quantile function Qτ (Y |X). For example, smoothness of Qτ (Y |X) in X, which is
needed to pursue the fully nonparametric estimation approach, is not needed. Theorem 5
also has important consequences for general inference on the QR process, since it implies that
(EXX 0 )−1 Σ(τ, τ 0 ) is not proportional to the covariance function of the standard d-dimensional
Brownian bridge [min(τ, τ 0 ) − τ τ 0 ] · I, unlike in the correctly specified case, where

                               (EXX 0 )−1 Σ0 (τ, τ 0 ) = [min(τ, τ 0 ) − τ τ 0 ] · I,              (33)

which in turn implies that the conventional inference methods developed in Koenker and Machado
(1999) do not apply under misspecification. Moreover, the problem of a nonstandard covariance
function cannot be alleviated by the Khmaladzation techniques implemented in Koenker and
Xiao (2002). We therefore rely on Theorem 5 to develop general inference methods on the QR
process that are robust to misspecification.
    An important though previously known corollary of Theorem 5 is that the conventional
standard errors used for basic pointwise inference are not robust to misspecification. This follows

                                                         13
from the fact that the covariance kernel Σ(τ, τ 0 ) generally differs from Σ0 (τ, τ 0 ). In particular,
we have:

Corollary 1 (Finite-Dimensional Limit Theory) Under A.1-A.5, for a finite collection
                                                          √
τk ∈ T , k = 1, ..., K, the regression quantile statistics n(β̂(τk )−β(τk )) are asymptotically jointly
normal, with asymptotic variance given by J(τk )−1 Σ(τk , τk )J(τk )−1 and asymptotic covariance
between the k-th and l-th subsets equal to J(τk )−1 Σ(τk , τl )J(τl )−1 . Under correct specification
Σ(·, ·) is replaced with Σ0 (·, ·) in these expressions.

   Chamberlain (1994) and Hahn (1997) give this result for a single quantile, that is for a given
       √                   d  ¡                                      ¢
τ ∈ T , n(β̂(τ ) − β(τ )) −→ N 0, V (τ ) ≡ J −1 (τ )Σ(τ, τ )J −1 (τ ) .11 Under correct specification
the variance formula simplifies to V0 (τ ) ≡ J −1 (τ )τ (1 − τ )E [XX 0 ]J −1 (τ ). Hence commonly re-
ported estimates of V0 (τ ) are inconsistent for V (τ ) under misspecification except for the median,
i.e. τ = 0.5. (In this case, the two formulae coincide because [τ − 1{Y ≤ X 0 β(τ )}]2 = 1/4 =
τ (1 − τ ) for τ = 0.5). Also, since the difference between V0 (τ ) and V (τ ) is

                  (1 − 2τ ) · J(τ )−1 · E ((1{Y ≤ X 0 β(τ ) − 1{Y ≤ Qτ (Y |X)}) · XX 0 ) · J(τ )−1 ,   (34)

we have that, for the same degree of misspecification, the difference grows as we move away
from the median and it can be positive or negative depending on the sign of specification error
and its correlation with the elements of XX 0 . For example, if X is one-dimensional and Y
is positive, then for τ < 1/2 the difference between V (τ ) and V0 (τ ) will be positive if the
corresponding conditional quantile is lower than the linear approximation for higher absolute
values of the regressor, and negative otherwise, i.e. if the conditional quantile is above the linear
approximation for these values.
       Table 1 illustrates these basic implications by reporting estimates of the schooling coefficients
and their asymptotic standard errors, using the two alternative formulae V0 (τ ) and V (τ ), for the
empirical example considered in the previous section. Panel A reports QR and OLS coefficients
from regressions of log-earnings on schooling for the 1980, 1990 and 2000 census samples, while
Panel B presents the same schooling coefficients from a model that also controls for race and a
quadratic function of potential experience. The standard errors were estimated using equations
(44)-(46), below. The alternative estimates of the standard errors are fairly close, with the
biggest differences for tail quantiles (0.10 and 0.90). Here, the commonly reported standard
error is biased downwards since, for the high levels of schooling where misspecification is more
severe, the conditional quantile is below the linear approximation for the 0.10 quantile, while it
is above the linear approximation for the 0.90 quantile.
  11
       See also Kim and White (2002).


                                                         14
3.2      Simultaneous (Uniform) Inference

An alternative to pointwise inference is Kolmogorov-type uniform inference on the QR pro-
cess. Uniform inference provides a parsimonious strategy for the study of changes in an entire
response distribution. Here we derive robust uniform confidence regions that allow us to si-
multaneously test, in the Scheffé sense, a variety of potentially multi-faceted hypotheses about
conditional distributions without compromising significance levels. Examples include specifica-
tion tests (omission of variables), stochastic dominance, constant treatment effects, and changes
in distribution.
       Of course, a finite number of quantile regression coefficients are always estimated in prac-
tice. Nevertheless, it is still convenient to treat the quantile-specific estimates as realizations
of a stochastic process rather than as a large vector of parameters. To see this, consider the
construction of joint confidence intervals for, say, d = 2 of the coefficients from a quantile regres-
sion, estimated at K = 20 different quantiles (i.e., increments of .05). The number of variance
and covariance terms to be estimated is dK(dK + 1)/2 = 820. The functional limit result in
Theorem 5 allow us to avoid this high-dimensional estimation problem.12 This approach also
leads to a convenient graphical inference procedure, illustrated below.
       The simplest use of the quantile regression process is to test linear hypotheses of the form:

                                   H0 : R(τ )0 β(τ ) = r(τ ) for all τ ∈ T .                                   (35)

For example, we might want to test whether the coefficient corresponding to the variable j is
zero over the whole quantile process, i.e. whether

                                           βj (τ ) = 0 for all τ ∈ T .                                         (36)

This corresponds to R(τ ) = [0, ..., 1, ...0]0 with 1 in the j − th position and r(τ ) = 0. Similarly,
we may want to construct uniform or simultaneous confidence intervals for parameters or for
linear functions of parameters of the form

                                     R(τ )0 β(τ ) − r(τ )     for all τ ∈ T .                                  (37)

The following corollaries facilitate both hypotheses testing and the construction of confidence
intervals in this framework:
  12                                                                           √
    Formally, this is because the empirical quantile regression process n(β̂(•) − β(•)) asymptotically behaves
                       √
continuously, so that n(β̂(•)−β(•)) is approximately equivalent to a large finite collection of regression quantiles
√
  n(β(τk ) − β(τk )), k = 1, ..., K, for a suitably fine grid of quantile indices TK = {τk , k = 1, ..., K} ⊂ T .


                                                        15
Corollary 2 (Kolmogorov Statistic) Under the conditions of Theorem 5, and (35), for any
V̂ (τ ) = V (τ ) + op (1) uniformly in τ ∈ T ,
                              ¯h                i−1/2 √ ³                    ´¯¯
                              ¯
                              ¯      0
                   Kn = sup ¯ R(τ ) V̂ (τ )R(τ )       n R(τ ) β̂(τ ) − r(τ ) ¯¯ →d K,
                                                              0
                                                                                                              (38)
                         τ ∈T

where |x| denotes the sup norm of a vector, i.e. |x| = maxj |xj |, and K is a random variable
with an absolutely continuous distribution, defined as
                                  ¯£                  ¤−1/2                     ¯
                                  ¯                                             ¯
                          K ≡ sup ¯ R(τ )0 V (τ )R(τ )      R(τ )0 J(τ )−1 z(τ )¯ .                           (39)
                                   τ ∈T

Corollary 3 (General Uniform Inference) Then, for κ(α) denoting the α-quantile of K and
κ̂(α) any consistent estimate of it,
                         n√ ¡                    ¢                         o
                 lim P     n R(τ )0 β(τ ) − r(τ ) ∈ Ibn (τ ), for all τ ∈ T = 1 − α,                          (40)
                n→∞

where
              h        ¯                         √ ³                             ´¯            i
                       ¯                                                          ¯
    Ibn (τ ) = u(τ ) : ¯[R(τ )V̂ (τ )R(τ )0 ]−1/2 n R(τ )0 β̂(τ ) − r(τ ) − u(τ ) ¯ ≤ κ̂(1 − α) .             (41)


   For example, when R(τ )0 β(τ ) − r(τ ) is scalar, we have
                                    h                                                                 i
                                                                    κ̂(1−α)[R(τ )V̂ (τ )R(τ )0 ]1/2
                      Ibn (τ ) =        R(τ )0 β̂(τ )   − r(τ ) ±              √
                                                                                  n
                                                                                                          .   (42)

The critical values κ̂(α) can easily be obtained by subsampling in cross-sectional applications of
the sort considered here. Let I1 , ..., IB be B randomly chosen subsamples of (Yi , Xi , i ≤ n) of
size b, where b → ∞, b/n → 0, B → ∞ as n → ∞. First, compute the test statistic for each
subsample
                               ¯h                   i−1/2 √       ³                   ´¯
                               ¯                                                  b ) ¯¯,
                  KIj ,b = sup ¯ R(τ )0 V̂ (τ )R(τ )       bR(τ )0 βbIj ,b (τ ) − β(τ                         (43)
                            τ ∈T

where βbIj ,b (τ ) is the QR estimate using subsample Ij . Then, define κ
                                                                        b(α) as the α-quantile of
the subsampling sequence {KI1 ,b , ..., KIB ,b }. If recomputation of quantiles is not desirable, one
           √
can replace b(βbIj ,b (τ ) − β(τ
                             b )) by its first order approximation, which is a re-centered one-step
                           ˆ )−1 √1 P
           bI ,b (τ ) = −J(τ
estimator: A                                              0b
             j                     b   i∈Ij (τ − 1(Yi ≤ Xi β(τ ))Xi .


Corollary 4 (Consistent κ
                        b(α)) The estimator κ
                                            b(α), described above, is consistent for κ(α).

   As noted above, in practice we replace the continuum of quantile indices T by a finite-
grid TKn , where the distance between adjacent grid points goes to zero as n → ∞. Since the


                                                             16
inference processes considered are stochastically equicontinuous, this replacement does not affect
the asymptotic theory.
      To make previous inference methods operational, we also need uniformly consistent estima-
tors for the components of the variance formulae:
                                     n
                               1X
              Σ̂(τ, τ 0 ) =      (τ − 1{Yi ≤ Xi0 β̂(τ )})(τ 0 − 1{Yi ≤ Xi0 β̂(τ 0 )}) · Xi Xi0 ,       (44)
                               n
                                    i=1
                                                        n
                               £                   ¤ 1X
             Σˆ0 (τ, τ 0 ) =                    0   0
                                   min(τ, τ ) − τ τ ·     Xi Xi0 ,                                     (45)
                                                      n
                                                        i=1
                                    n
                 ˆ ) =           1 X
                 J(τ                  1{|Yi − Xi0 β̂(τ )| ≤ hn } · Xi Xi0 ,                            (46)
                               2nhn
                                          i=1

where hn is such that hn → 0 and h2n n → ∞.13 The next result establishes the uniform
consistency of these estimators.

Corollary 5 The estimators shown in equations (44)-(46) are uniformly consistent in (τ, τ 0 ) if
EkXk4 < ∞.

      Figure 5 illustrates uniform inference in our empirical example. The figure shows robust
pointwise and uniform 95% confidence intervals for the schooling coefficient β̂(•) from quantile
regressions of log-earnings on schooling, race and a quadratic function of experience, using data
from the 1980, 1990 and 2000 censuses. The horizontal lines indicate the corresponding OLS
estimates. The uniform bands were obtained by subsampling using 200 repetitions (B = 200)
with subsample size b = 5n2/5 , and a grid of quantiles TKn = {.1, .15, ..., .9}.14
      The figure suggests the returns to schooling were low and essentially flat across quantiles
in 1980, (except for τ > .85, where they shift up), a finding similar to Buchinsky’s (1994)
using Current Population Surveys (CPS) for this period.                 On the other hand, the returns
increased sharply and became more heterogeneous in 1990 and especially in 2000, a result we
also confirmed in the CPS. Since the uniform confidence bands do not contain a horizontal line,
we can reject the hypothesis of homogeneous returns to schooling for 1990 and 2000. Moreover,
the uniform band for 1990 does not overlap with the 1980 band, suggesting a marked and
statistically significant change in the relationship between schooling and the conditional wage
distribution in this period.15 A variety of other hypotheses regarding the returns to schooling
can similarly be tested using Figure 5. Note also that the uniform bands are not much wider than
 13
    Following Koenker (1994), we use Hall and Sheather’s (1988) rule setting hn = c · n−1/3 .
 14
    Chernozhukov (2002) discusses subsampling for QR inference in greater detail.
 15
    Using Bonferoni bounds, our graphical test that looks for overlap in two 95% confidence bands has a sig-


                                                        17
the corresponding pointwise bands due to the high correlation between individual coefficients in
the QR process.


4     Estimates of Changing Residual Inequality

One of the most significant and widely-studied developments in the American economy in the
last three decades is the changing wage structure. The broad pattern has been one of increasing
inequality, as measured by either the variance or the gap between upper and lower quantiles of
the wage distribution. For example, Katz and Autor (1999) note that the 90-10 ratio (i.e. the
ratio of the .9 and .1 quantiles) increased by 25 percent from 1979 to 1995. Wage inequality
appears to have continued to increase since 1995, though the recent inequality trend is less
clear-cut due in part to changes in the way US wage data are collected (Lemieux, 2003).
    The increase in wage inequality is typically described as arising in two ways: increasing wage
differentials associated with observed worker characteristics such as education and experience,
and increased dispersion conditional on these characteristics.            The first, known as “between-
group inequality,” has increased as a consequence of changes in the distribution of characteristics,
and especially changes in the economic returns to these characteristics. For example, increases
in the economic return to schooling have been an important factor working to increase overall
wage dispersion. The second, known as within-group or “residual inequality,” is – by definition
– not directly linked to changes in the distribution of covariates or their returns, though increases
in residual inequality are sometimes said to reflect increasing returns to “unobserved skills” (as
in Juhn, Murphy, and Pierce, 1993).
    An appealing feature of quantile regression as a tool for understanding wage inequality is that
QR coefficients can easily be used to construct a measure of within-group or residual inequality.
To see this, note that if we approximate Qτ (Y |X) by X 0 β(τ ), with log wages as the dependent
variable, then the within-group τ to τ 0 ratio is provided by X 0 [β(τ )−β(τ 0 )]. This fact highlights
a key difference between quantile regression and mean regression: a ceteris paribus increase in
an OLS regression coefficient increases a variance-based measure of between-group inequality,
without changing within-group inequality as measured by the residual variance.                  In contrast,
a ceteris paribus increase in any non-central quantile, τ, increases within-group inequality as
measured by the spread from the τ to 1 − τ quantiles.
nificance level of approximately 10% (1 − .952 ). A test with exactly 5% size can be obtained by constructing
confidence bands for the difference in estimated quantiles across years, again using the procedure outlined in
section 3.2.


                                                     18
4.1      The QR Summary Picture

Our goal in this brief empirical section is to use linear QR to measure changing residual in-
equality in the 1980, 1990, and 2000 censuses. To mitigate the impact of changes in labor force
participation, we continue to focus on a prime-age sample consisting of US-born white and black
men aged 40-49.
      Figure 6 provides a compact QR-generated summary of the evolution of residual inequality
from 1980 through 2000. The figure plots the averaged (across covariates) conditional quantiles
of earnings, as predicted from a QR model controlling for schooling, race, and a quadratic
function of potential experience. The leftmost panel shows the unconditional quantiles, i.e., the
marginal earnings distribution; the middle panel conditions on covariate means for each year;
the third panel fixes the covariate means at their 1980 values.16 Each panel shows quantiles for
the three census years, plotted using a line-width determined by the uniform inference bands for
fitted values derived from our QR estimates of the quantile process. To facilitate a comparison
of inequality while holding location fixed, the line for each year is centered at median earnings
for that year.
      The largest shift in unconditional distributions occurred between 1980 and 1990, primarily
in the lower half of the earnings distribution.            This shift is statistically significant, as can be
seen from the fact that the bands for these two years do not overlap. A comparison of Panels B
and C with Panel A shows the residual distribution shifting more smoothly than the marginal
distribution. This is because conditioning smooths out some of the heaping commonly found in
survey-based earnings data. Panel B shows a clear increase in residual inequality from 1980 to
1990, with a continuing increase from 1990 to 2000. An interesting feature of the latter increase,
however, is that it appears to have occurred only in the upper half of the wage distribution.
Below the median, the conditional quantiles for 1990 and 2000 overlap. Panel C shows a similar
pattern when the covariate distribution is held fixed. Autor, Katz, and Kearney (2004) report
a similar asymmetry in their analysis of CPS data, with virtually all inequality growth in the
1990s in the upper half of the wage distribution.


4.2      Accuracy of the QR Picture

While Figure 6 provides a useful distillation of the QR results, we are especially interested in
whether the linear QR model accurately captures key features of changing residual inequality in
this period, both overall and for specific groups. The large census data sets allow us to compare
 16
      Panel C uses a slightly different schooling recode to maximize comparability; see the appendix for details.


                                                         19
QR estimates with the corresponding non-parametric estimates of the CQF. Paralleling the
analysis of 1980 census data in the previous section, we begin our analysis of changing residual
inequality by assessing the quality of the QR fit to the CQF for 1990 and 2000 census data.
Figures 7 and 8 show the QR fit to the CQF in both census data sets, for a model where the sole
regressor is years of schooling. As for 1980, the fit is reasonably good at all quantiles, though
somewhat worse at the .75 and .9 quantiles than lower down, especially for 2000. Again, the
corresponding QR coefficient estimates are reported in Panel A of Table 1.
   The figures also compare the QR regression line to the Chamberlain MD line, obtained from
a histogram-weighted fit of the linear model to the CQF. Again, as for 1980, the MD and QR
lines are almost indistinguishable, suggesting the importance weights are flat and/or the true
CQF is not too far from linear. More evidence on the nature of the weighting function can be
seen in Figures 9 and 10, which plot importance weights and histogram weights, and Figures 11
and 12, which plot the importance weights and density weights. These figures establish that
the conditional density of Y given X, and hence the QR importance weights, are indeed fairly
flat at all quantiles and in both years.
   To assess the performance of QR as a tool for measuring residual inequality, Table 2 reports
alternative inter-quantile spreads constructed from the CQF and QR. Panel A reports estimates
for the whole sample, averaged using the sample distribution of the covariates. This panel shows
an important overall increase in wage inequality, which cannot be totally explained by changes
in the distribution of and returns to the covariates. The QR 90-10 spread tracks the CQF 90-10
spread remarkably well; the latter runs from 1.20 to 1.43, while QR implies a 90-10 spread
ranging from 1.19 to 1.45 in the model that controls for schooling, race and experience. Results
are equally good for the inter-quartile range and the two-half-spreads, and for the model that
only controls for schooling.   The asymmetry of residual inequality growth since 1990 can be
seen by comparing the change in the 90-50 and 50-10 spreads.
   The evolution of residual inequality for specific schooling groups provides a more stringent
test of the QR approach. Panels B and C of Table 2 report results from a model that includes
schooling with and without potential experience and race, evaluated for specific schooling groups.
The 90-10 spread based on the CQF for high school graduates (12 years of schooling) moves from
1.09 in 1980 to 1.26 in 1990 to 1.29 in 2000, when race and experience are included. QR fitted
values similarly show an increase from 1.17 in 1980 to 1.31 in 1990 and 1.32 in 2000. Thus, like
the CQF for high school graduates, QR shows an increase in residual inequality of around .14
in the first decade, with essentially no change in the second. The results are similar without



                                               20
controlling for race and experience. The evolution of the inter-quartile range appears to have
been broadly similar to that of the 90-10 spread for the high school group.
   While residual inequality grew little for high school graduates in the 1990s, college graduates
(16 years of schooling) saw a substantial increase in wage dispersion. This echoes Autor, Katz,
and Kearney’s (2004) comparison of college and high school graduates using the CPS. Again,
QR captures the essential features of this pattern remarkably well. The 90-10 spread estimated
from the CQF for college graduates increased from 1.26 to 1.44 in the 1980s and then to 1.55 in
the 1990s. The corresponding QR estimates imply an increase from 1.19 to 1.38 in the 1980s,
and then to 1.57 in the 1990’s. The QR estimates also capture about two-thirds of the growth
in residual inequality over the entire period for the other spreads considered.             The ability of
QR to track these changes seems especially impressive given the changes (detailed in the data
appendix) in the underlying schooling variable across censuses.


4.3     QR-based measures of inequality


As with variance-based measures of dispersion, we can use quantile spreads and their QR approx-
imations to provide convenient summary measures of residual inequality. A natural measure al-
ready discussed is the inter-quantile range: IQRτ,τ 0 [Y |X] ≈ X 0 β(τ )−X 0 β(τ 0 ) = X 0 [β(τ )−β(τ 0 )],
where τ is some high index, for example 90%, and τ 0 is some low index, for example 10%. A
summary or typical measure of residual inequality is the median IQR,
                                  ©               ª       ©                       ª
                    RIτ,τ 0 = M ed IQRτ,τ 0 [Y |X] ∼= M ed X 0 β(τ ) − X 0 β(τ 0 ) .                  (47)

On the other hand, a reasonable measure of between-group inequality can be given by the
inter-quantile range of the conditional median:

                        BIτ,τ 0 = IQRτ,τ 0 {M ed[Y |X]} ∼
                                                        = IQRτ,τ 0 {X 0 β(1/2)},                      (48)

which measures the variation in the central location of the conditional distribution.
   To grade the relative importance of within and between-group inequality, we can define the
following “residual-to-total” ratio and its QR approximation:
                                         £        ©            ª¤2
                                           M ed IQRτ,τ 0 [Y |X]
               RTRτ ,τ 0   =   £    ©               ª¤2 £                     ¤2                      (49)
                                M ed IQRτ,τ 0 [Y |X]   + IQRτ,τ 0 {M ed[Y |X]}

                           ∼                 [M ed {X 0 β(τ ) − X 0 β(τ 0 )}]2
                           =                                      £                      ¤2 .         (50)
                               [M ed {X 0 β(τ ) − X 0 β(τ 0 )}]2 + IQRτ,τ 0 {X 0 β(1/2)}


                                                    21
         The RTR measure can be motivated by an analogy to traditional analysis of variance models,
where the ratio of residual to total variance is “1 − R2 ”, i.e.

                                                     E{V [Y |X]}
                                                                        .                                           (51)
                                              E{V [Y |X]} + V {E[Y |X]}

RTR replaces standard deviation with inter-quantile range as a measure of dispersion and means
with medians as a measure of location. In fact, in the classical normal location-shift model,
Y = X 0 β + U, the two measures coincide (this is the reason why the squares are present in the
definition of RTR), but they would be different in general.17 RTR is nonnegative by construction
and satisfies the natural restrictions

                                                    0 ≤ RTRτ ,τ 0 ≤ 1.                                              (52)

RTR necessarily equals 1 if Y is independent of X (no between-group inequality) and equals 0
when conditional dispersion is zero (no within-group inequality).
         Table 3 compares ANOVA and quantile-based estimates of between-group inequality, within-
group inequality, and the relative importance of within-group inequality for both a non-parametric
and a linear model of log-earnings that includes schooling, race and potential experience as co-
variates. QR and CQ-based measures are generally closer for within-group inequality than for
between-group inequality. Both QR and CQ-based measures suggest a sharp increase in within-
group and between-group inequality, especially in the upper tail. For example, RI90,50 and
BI90,50 grew much faster than RI50,10 and BI50,10 . On the other hand, there is no clear trend
in the relative importance of within-group inequality. For example, the QR-based RTR90,10
go from 80% to 81% between 1980 and 1990, and then back to 78% in 2000. Some of these
general trends are also captured by the standard ANOVA-based measures, but the latter does
not capture the asymmetric changes in the upper and lower tails.


5         Summary and conclusions

We have shown how linear quantile regression provides a weighted least squares approximation
to an unknown and potentially nonlinear conditional quantile function, much as OLS provides
a least squares approximation to a nonlinear CEF. The QR approximation property leads to
partial quantile plots and an omitted variables bias formula, analogous to standard specification
tools for OLS.
    17
         An alternative choice for the denominator is the marginal interquantile range Qτ (Y ) − Qτ 0 (Y ). However, this
leads to a relative measure that can exceed 1.


                                                             22
   A natural question raised by the relationships explored here is the sensitivity of QR to
changes in sample design. Unlike a postulated-as-true linear model, the nature of the QR
approximation changes in stratified samples. Of course, an OLS regression line has this feature
as well. Like the OLS approximation to a nonlinear CEF, the nature of the weights underlying
the QR approximation to a nonlinear CQF change as the histogram of X changes (though
not otherwise, since the importance weights are a function of X). The role played by the QR
weighting scheme seems like an empirical, application-specific question. In practice, it may be
of interest to use stratification weights to improve the linear QR fit for subpopulations of special
interest. This is a topic we plan to explore in future work.
   While misspecification of the CQF functional form does not affect the usefulness of QR, it
does have implications for inference. We have presented a misspecification-robust distribution
theory for the QR process. This provides a foundation for uniform confidence intervals and a
basis for global tests of hypotheses about distribution. The interpretation of such tests is more
subtle, however, when the assumption of correct specification is dropped. The results of a global
test may change as the nature of the QR approximation changes.
   Finally, we used the tools here to describe the wage distribution in three censuses, proposing
summary measures of between and within-group inequality. For the most part, linear QR cap-
tures the evolution of the conditional wage distribution remarkably well. Of particular interest
is the finding that the growth of within-group inequality between 1990 and 2000 is largely due to
an expansion of the upper half of the conditional wage distribution and the growing inequality
in the wage distribution of college graduates. Traditional regression-based inequality measures
miss these developments.




                                                23
A       Appendix: Proofs

A.1     Proof of Theorem 1.
We have that
                                         β(τ ) = arg min E[ρτ (Y − X 0 β)].                                        (53)
                                                          β∈Rd

Then, we can subtract E[ρτ (Y − Qτ (Y |X))], without affecting the optimization, because it does not
depend on β and is finite by condition (ii):

                         β(τ ) = arg min {E[ρτ (Y − X 0 β)] − E[ρτ (Y − Qτ (Y |X))]} .                             (54)
                                       β∈Rd

Write

             E [ρτ (²τ − ∆τ (X, β))] − E [ρτ (²τ )]
             = E [(τ − 1{²τ < ∆τ (X, β)}) (²τ − ∆τ (X, β))] − E [(τ − 1{²τ < 0}) ²τ ]
                                                                                                                   (55)
             = E [(1{²τ < ∆τ (X, β)} − τ ) ∆τ (X, β)] − E [(1{²τ < ∆τ (X, β)} − 1{²τ < 0}) ²τ ] .
               |               {z                   } |                   {z                 }
                                   I                                                               II

Now, write

                          I = E [(1{²τ < ∆τ (X, β)} − τ )∆τ (X, β)]
                            (a)
                             = E [E [(1{²τ < ∆τ (X, β)} − τ )|X] ∆τ (X, β)]
                            = E [[F²τ (∆τ (X, β)|X) − F²τ (0|X)] ∆τ (X, β)]
                                 ·µZ 1                                ¶         ¸                                  (56)
                            (b)
                            =E          f²τ (u∆τ (X, β)|X)∆τ (X, β)du ∆τ (X, β)
                                        0
                                  ·µZ       1                                 ¶                ¸
                            (c)
                             =E                 f²τ (u∆τ (X, β)|X)du              ∆2τ (X, β)
                                        0

where (a) is by the law of iterated expectations, (b) is by condition (i) (a.s. existence of conditional
density), and (c) is by linearity of the integral. Similarly,

                   II = E [1{²τ ∈ [0, ∆τ (X, β)]} · |²τ |] + E [1{²τ ∈ [∆τ (X, β), 0]} · |²τ |]
                                                                                                                   (57)
                       = E [1{uτ ∈ [0, 1]} · uτ · |∆τ (X, β)|]

where
                                       uτ ≡ ²τ /∆τ (X, β)           if ∆τ (X, β) 6= 0,
                                                                                                                   (58)
                                                 uτ ≡ 1             if ∆τ (X, β) = 0.
    Next, note that for the case ∆τ (X, β) 6= 0

                           fuτ (u|X) · du = f²τ (u∆τ (X, β)|X) · |∆τ (X, β)| · du, so                              (59)

                                                                 ·Z      1                     ¸
             E[1{uτ ∈ [0, 1]}uτ |X] · |∆τ (X, β)|          =                 ufuτ (u|X)du · |∆τ (X, β)|            (60)
                                                                     0
                                                                 ·Z      1                              ¸
                                                           =                 uf²τ (u∆τ (X, β)|X)du · ∆2τ (X, β).   (61)
                                                                     0


                                                               24
For cases when ∆τ (X, β) = 0

                                       E[1{uτ ∈ [0, 1]}uτ |X] · |∆τ (X, β)| = 0.                        (62)

Thus, it follows that

                II = E [1{uτ ∈ [0, 1]}uτ |∆τ (X, β)|] = E [E[1{uτ ∈ [0, 1]}uτ |X] |∆τ (X, β)|]
                       ··Z 1                         ¸          ¸                                       (63)
                                                         2
                   =E        uf²τ (u∆τ (X, β)|X)du · ∆τ (X, β) .¥
                             0


A.2     Proof of Theorem 2.
We have to prove that β(τ ) that solves

                                             β(τ ) = arg min E[ρτ (Y − X 0 β)],                         (P1)
                                                               β∈Rd

is equal to β ∗ (τ ) that solves
                                                          £                    ¤
                                      β ∗ (τ ) = arg min E w̃τ (X) · ∆2τ (X, β) .                       (P2)
                                                           β∈Rd

The FOC for program (P2) is given by

                                              eτ (X) ∆τ (X, β ∗ (τ )) X] = 0,
                                         2 E [w                                                         (64)

where
                                                           Z   1
                                                       1
                                   w̃τ (X)         =               f²τ (u · ∆τ (X, β(τ ))|X) du.        (65)
                                                       2   0

The FOC for program (P1) is given by

                                    I 0 = E [(1{²τ < ∆τ (X, β(τ ))} − τ ) X] = 0,                       (66)

which by calculations similar to those in (56) can be written as
                             (a)
                          I 0 = E [E [(1{²τ < ∆τ (X, β(τ ))} − τ ) |X] · X]
                             = E [(F²τ (∆τ (X, β(τ ))|X) − F²τ (0|X)) · X]
                                  ·µZ 1                                       ¶    ¸
                             (b)                                                                        (67)
                             =E          f²τ (u∆τ (X, β(τ ))|X)∆τ (X, β(τ ))du · X
                                         0
                                     ·µZ       1                           ¶                  ¸
                             (c)
                             =E                    f²τ (u∆τ (X, β(τ ))|X)du ∆τ (X, β(τ )) · X
                                           0

where (a) is by the law of iterated expectations, (b) is by a.s. existence of conditional density, and (c) by
linearity of the integral. By the definition of w
                                                eτ (X)

                                       I 0 = 2 E [w
                                                  eτ (X) ∆τ (X, β(τ )) X] = 0.                          (68)

Finally, note that this is precisely the FOC for program (P2).
    Both program (P1) and program (P2) are convex. (P1) has unique solution β(τ ) by assumption, which
means it uniquely solves the FOC. Hence since the (P1) and (P2) have the same first order condition, it
follows that β ∗ (τ ) = β(τ ) uniquely solves the FOC for both programs. ¥.

                                                                      25
A.3     Proof of Theorem 3.
Taking claim 1 as given, claim 2 is immediate:

                     γ1 (τ )     = E [w̃τ∗ (X)X1 X10 ]−1 E [w̃τ∗ (X)X1 (X10 β1 (τ ) + Rτ (X))]                 (69)
                                 =    β1 (τ ) + E [w̃τ∗ (X)X1 X10 ]−1 E [w̃τ∗ (X1 ) X1 Rτ (X)] .               (70)

It remains to prove claim 1. The first order condition of the quantile regression of Y on X1 in the
population is given by
                                         E [(1{Y ≤ X10 γ1 (τ )} − τ ) X1 ] = 0,                                (71)

or for ²τ = Y − Qτ (Y |X) and ∆τ (X, γ1 (τ )) = X10 γ1 (τ ) − Qτ (Y |X),

                                       E [(1{²τ ≤ ∆τ (X, γ1 (τ ))} − τ ) X1 ] = 0.                             (72)

This can be rewritten as

                               E [E[1{²τ ≤ ∆τ (X, γ1 (τ ))} − 1{²τ ≤ 0}|X1 ] X1 ] = 0,                         (73)

since P {²τ ≤ 0|X1 } = E[P {²τ ≤ 0|X1 , X2 } |X1 ] = E[τ |X1 ] = τ. Write
                                                       (a)
  E[1{²τ ≤ ∆τ (X, γ1 (τ ))} − 1{²τ ≤ 0}|X1 ] = E[E[1{²τ ≤ ∆τ (X, γ1 (τ ))} − 1{²τ ≤ 0}|X]|X1 ]
                                                       = E[[F²τ (∆τ (X, γ1 (τ ))|X) − F²τ (0|X)]|X1 ]
                                                           ·µZ 1                                            ¶ ¯ ¸
                                                       (b)                                                    ¯
                                                       =E         f²τ (u∆τ (X, γ1 (τ ))|X) ∆τ (X, γ1 (τ ))du ¯X1
                                                                0
                                                           ·µZ 1                             ¶               ¯ ¸
                                                       (c)                                                   ¯
                                                       =E         f²τ (u∆τ (X, γ1 (τ ))|X)du ∆τ (X, γ1 (τ ))¯X1 ,
                                                                0
                                                                                                               (74)

where (a) is by the law of iterated expectations, (b) is by a.s. existence of conditional density, and (c)
                                                   R1
                                       eτ∗ (X) = 12 0 f²τ (u∆τ (X, γ1 (τ ))|X)du, we can rewrite the previous
by linearity of the integral. Defining w
first order condition as
                                             eτ∗ (X) ∆τ (X, γ1 (τ ))|X1 ] · X1 ] = 0,
                                     2 E [E [w                                                                 (75)

or, by the law of iterated expectations

                                              eτ∗ (X) ∆τ (X, γ1 (τ )) · X1 ] = 0.
                                         2 E [w                                                                (76)

Finally, note that this is precisely the first order condition for the program

                               γ1 (τ ) = arg min E[w̃τ∗ (X) · (X10 γ1 − Qτ (Y |X))2 ].¥                        (77)
                                             γ1 ∈Rd1


A.4     Notation for Proofs of Theorems 4 and 5
We use the following empirical processes in the sequel, for W ≡ (Y, X)
                                        n                                       n
                                     1X                                 1 X
            f 7→ En [f (W )] ≡             f (Wi ), f 7→ Gn [f (W )] ≡ √       (f (Wi ) − E [f (Wi )]).        (78)
                                     n i=1                               n i=1

                                                             26
                                  h      i                              Pn
If fb is an estimated function, Gn fb(W ) denotes                 √1
                                                                    n     i=1 (f (Wi )   − E [f (Wi )])f =fb. Other basic nota-
tion and stochastic convergence concepts, such as weak convergence in the space of bounded functions,
stochastic equicontinuity, Donsker classes, and Vapnik-C̆ervonenkis (VC) classes, are used and defined as
in van der Vaart (1998).


A.5       Proof of Theorem 4
Observe that, for each τ in T , β̂(τ ) minimizes

                                 Qn (τ, β) ≡ En [ρτ (Y − X 0 β) − ρτ (Y − X 0 β(τ ))] .                                   (79)

Define
                                 Q∞ (τ, β) ≡ E [ρτ (Y − X 0 β) − ρτ (Y − X 0 β(τ ))] .                                    (80)

By A.2 and A.3, Q∞ (τ, β) is uniquely minimized at β(τ ) for each τ in T .
                                                                         Rv
   Since by Knight’s identity ρτ (u − v) − ρτ (u) = −(τ − 1{u < 0})v + 0 [1{u ≤ s} − 1{u ≤ 0}]ds, we
have, by setting u = Y − X 0 β(τ ) and v = X 0 (β − β(τ )), that

        ρτ (Y − X 0 β) − ρτ (Y − X 0 β(τ )) = −(τ − 1{Y ≤ X 0 β(τ )})X 0 (β − β(τ ))
                                              Z X 0 (β−β(τ ))                                                             (81)
                                            +                 [1{Y ≤ X 0 β(τ ) + s} − 1{Y ≤ X 0 β(τ )}]ds.
                                                    0
                                           d
Thus, it follows that for any β ∈ R

                        |Q∞ (τ, β)| ≤ 2 · E|X 0 (β − β(τ ))| ≤ 2 · EkXk · kβ − β(τ )k < ∞.                                (82)

We can also show that for any compact set B

                         Qn (τ, β) = Q∞ (τ, β) + op∗ (1), uniformly in (τ, β) ∈ T × B.                                    (83)

This statement is true pointwise by the Khinchin LLN. The uniform convergence follows because

                           |Qn (τ 0 , β 0 ) − Qn (τ 00 , β 00 )| ≤ C1 · |τ 0 − τ 00 | + C2 · kβ 0 − β 00 k,               (84)

where
                            C1 = 2 · EkXk · sup kβk < ∞ and C2 = 2 · EkXk < ∞.                                            (85)
                                                   β∈B

Hence the empirical process (τ, β) 7→ Qn (τ, β) is stochastically equicontinuous, which implies the uniform
convergence.
    Consider a collection of closed balls BM (β(τ )) of radius M and center β(τ ), and let βM (τ ) = β(τ ) +
δM (τ ) · v(τ ), where v(τ ) = (v1 (τ ), ..., vd (τ ))0 is a direction vector with unity norm kv(τ )k = 1 and δM (τ )
is a positive scalar such that δM (τ ) ≥ M . Then uniformly in τ ∈ T ,
                 M                                        (a)
                                                                    ∗
                        (Qn (τ, βM (τ )) − Qn (τ, β(τ ))) ≥ Qn (τ, βM (τ )) − Qn (τ, β(τ ))
                δM (τ )
                                                                (b)
                                                                          ∗                                               (86)
                                                                ≥ Q∞ (τ, βM (τ )) − Q∞ (τ, β(τ )) + op∗ (1)
                                                                (c)
                                                                > ²M + op∗ (1),

                                                                 27
                                                           ∗
for some ²M > 0, where (a) follows by convexity in β, for βM (τ ) on the line connecting βM (τ ) and β(τ ),
(b) follows by the uniform convergence established in (83), (c) follows by the assumption that β(τ ) is the
unique minimizer of Q∞ (β, τ ) uniformly in τ ∈ T . Hence for any M > 0, the minimizer β̂(τ ) must be
within M from β(τ ) uniformly for all τ ∈ T , with probability approaching to one. That is, we have that
for any M > 0, kβ̂(τ ) − β(τ )k ≤ M uniformly for all τ ∈ T with probability approaching to one. ¥


A.6       Proof of Theorem 5
First, by the computational properties of β̂(τ ), for all τ ∈ T , cf. Theorem 3.3 in Koenker and Bassett
(1978):                                                            µ              ¶
                              ° h                     i°             supi≤n kXi k
                              °                        °
                              °En ϕτ (Y − X 0 β̂(τ ))X ° ≤ const ·                  ,                                    (87)
                                                                          n
where ϕτ (u) = τ − 1{u < 0}. Note that EkXi k2+² < ∞ implies supi≤n kXi k = op∗ (n1/2 ), since
                    µ                  ¶
                                                                             2+²
                                   1/2
                   P sup kXi k > n       ≤ nP (kXi k > n1/2 ) ≤ nEkXi k2+² /n 2 = o(1).                                  (88)
                        i≤n

Hence uniformly in τ ∈ T ,
                                         h                      i     ³     ´
                                       En ϕτ (Y − X 0 β̂n (τ ))X = op∗ n−1/2 .                                           (89)

   Second, (τ, β) 7→ Gn [ϕτ (Y − X 0 β) X] is stochastically equicontinuous over B × T , where B is any
compact set, with respect to the L2 (P ) pseudometric
                                          r h                                                                    i
                                                                                                             2
             ρ((τ 0 , β 0 ), (τ 00 , β 00 )) ≡ max      E (ϕτ 0 (Y − X 0 β 0 ) Xj − ϕτ 00 (Y − X 0 β 00 ) Xj )       ,   (90)
                                            j∈1,...,d

for j ∈ 1, ..., d indexing the components of the vector X. This is because the functional class F =
{1{Y ≤ X 0 β}, β ∈ B} is a VC subgraph class and hence also Donsker class, with envelope 2. Hence
the functional class T − F is also Donsker with envelope equal 2, by Theorem 2.10.6 in Van der Vaart
and Wellner (1996). The product of T − F with X also forms a Donsker class with a square integrable
envelope 2 · maxj∈1,..d |X|j , by Theorem 2.10.6 in Van der Vaart and Wellner (1996). The stochastic
equicontinuity then is a part of being Donsker.
   The uniform consistency supτ ∈T kβ̂(τ ) − β(τ )k = op∗ (1) implies
                                 ³                      ´¯¯
                            sup ρ (τ, b(τ )), (τ, β(τ )) ¯¯       = op∗ (1),                                             (91)
                                     τ ∈T                              b(τ )=β̂(τ )

and therefore by stochastic equicontinuity of (τ, β) 7→ Gn [ϕτ (Y − X 0 β) X] we have that
                 h                    i
               Gn ϕτ (Y − X 0 β̂(τ ))X = Gn [ϕτ (Y − X 0 β(τ ))X] + op∗ (1), uniformly in τ .                            (92)

   In order to show (91) note that for f¯ denoting the upper bound on fY (y|X = x), application of the




                                                                28
Hölder’s inequality, a Taylor expansion and Cauchy-Schwarz inequality, give the series of inequalities:
           ³                      ´
     sup ρ (τ, b(τ )), (τ, β(τ ))
     τ ∈T
                    r h                                                     i
                                                                          2
     = sup max          E (ϕτ (Y − X 0 b(τ )) Xj − ϕτ (Y − X 0 β(τ )) Xj )
        τ ∈T j∈1,...,d
               µµ ·                                             ¸¶² ³ h          i´2 ¶ 2(2+²)
                                                                                          1
                                                         2(2+²)
                             0                  0                            2+²
     ≤ sup max   E |ϕτ (Y − X b(τ )) − ϕτ (Y − X β(τ ))|    ²
                                                                   · E |Xj |
        τ ∈T j∈1,...,d                                                                                                          (93)
                                                                                ²
                                                                                       ³                 ´ 2+²
                                                                                                            1
                                         0                          0                              2+²
     ≤ sup max (E |1{Y ≤ X b(τ )} − 1{Y ≤ X β(τ )}|)                         2(2+²)
                                                                                      · E |Xj |
        τ ∈T j∈1,...,d
          ¡ ¯                         ¯¢ ²                   1
     ≤ sup E ¯f¯ · X 0 (b(τ ) − β(τ ))¯ 2(2+²) · (EkXk2+² ) 2+²
        τ ∈T
                  ³ ¡         ¢1/2                   ´ 2(2+²)
                                                          ²

     ≤ const · sup f¯ · EkXk2      · kb(τ ) − β(τ )k          ,
                τ ∈T

where the second inequality follows by binomiality of |ϕτ (Y − X 0 b(τ )) − ϕτ (Y − X 0 β(τ ))|. Then, eval-
                  b )
uating at b(τ ) = β(τ
                         ³                 ´¯¯                                                                 ²
               sup ρ (τ, b(τ )), (τ, β(τ )) ¯¯                     ≤ const · sup kβ̂(τ ) − β(τ )k 2(2+²) = op∗ (1),             (94)
               τ ∈T                                 b(τ )=β̂(τ )             τ ∈T


by uniform convergence and ² > 0.
    Third, by a Taylor expansion, uniformly in τ ∈ T
                                     ¯                                              ¯
                                     ¯                                              ¯
                 E [ϕτ (Y − X 0 β)X] ¯                  = E [fY (X 0 b(τ )|X)XX 0 ] ¯                       (β̂(τ ) − β(τ )),   (95)
                                             β=β̂(τ )                                      b(τ )=β ∗ (τ )


where β ∗ (τ ) is on the line connecting β̂(τ ) and β(τ ) for each τ . β̂(τ ) is uniformly consistent by Theorem
4, hence β ∗ (τ ) is also uniformly consistent. Thus by A5, i.e. the uniform continuity and boundedness of
the mapping y 7→ fY (y|x), uniformly in x over the support of X, it follows that
                                          ¯
                                          ¯
                 E [fY (X 0 b(•)|X)XX 0 ] ¯                      = E [fY (X 0 β(•)|X)XX 0 ] +o(1) in `∞ (T ).                   (96)
                                                  b(•)=β ∗ (•)     |           {z       }
                                                                               J(•)
                                                                   ¯
                                                                   ¯
Indeed, by A5 for any compact K, E [fY (X 0 b(•)|X)XX 0 1{X ∈ K}] ¯               = E [fY (X 0 β(•)|X)XX 0 1{X ∈ K}]+
                                                                 ¯   b(•)=β ∗ (•)
                                                                 ¯
o(1). Then, for K c = Rd \K, E [fY (X 0 b(•)|X)XX 0 1{X ∈ K c }] ¯        and E [fY (X 0 β(•)|X)XX 0 1{X ∈ K c }]
                                                                      ∗               b(•)=β (•)
can be made arbitrarily small in large samples. This follows by setting the set K sufficiently large and
using EkXX 0 k < ∞ and fY (X 0 β(•)|X) < f¯ a.s.
    Fourth, since

                             the left hand side (lhs) of (89) = lhs of (95)+ n−1/2 lhs of (92),                                 (97)

we have by using (96)
                         ³           ´                                        µ       °             °¶
                              −1/2                                                    °b            °
                   op∗ n                 =   J(•)(β̂(•) − β(•)) + op∗             sup °β(τ ) − β(τ )°                           (98)
                                                                                τ ∈T

                                             +n−1/2 Gn [ϕ• (Y − X 0 β(•))X] + op∗ (n−1/2 ) in `∞ (T ).

                                                                        29
Since mineig (J(τ )) > λ > 0, uniformly in τ ∈ T
                         °                                            °
                         °                                            °
                    sup °n−1/2 Gn [ϕτ (Y − X 0 β(τ ))X] + op∗ (n−1/2 )°
                    τ ∈T
                                       °                         ¡                    ¢°
                                       °                                               °
                               = sup °J(τ )(β̂(τ ) − β(τ )) + op∗ sup kβ̂(τ ) − β(τ )k °                       (99)
                                      τ ∈T                              τ ∈T

                                   ≥ (λ + op∗ (1)) · sup kβ̂(τ ) − β(τ )k.
                                                    τ ∈T

    Fifth, by the stated assumptions, the mapping τ 7→ β(τ ) is continuous. In fact, it is continuously dif-
ferentiable, since by the implicit function theorem, for β(τ ) defined as solution to E [(τ − 1{Y ≤ X 0 β})X] =
0, we have that dβ(τ )/dτ = J(τ )−1 E [X] . Hence τ 7→ Gn [ϕτ (Y − X 0 β(τ )) X] is stochastically equicon-
tinuous over T by continuity of the mapping τ 7→ β(τ ) for the pseudo-metric given by ρ(τ 0 , τ 00 ) ≡
ρ((τ 0 , β(τ 0 )), (τ 00 , β(τ 00 ))). Then, stochastic equicontinuity of τ 7→ Gn [ϕτ (Y − X 0 β(τ ))X] and ordinary
CLT imply that
                                    Gn [ϕ• (Y − X 0 β(•))X] ⇒ z(•) in `∞ (T ),                                (100)

where z(•) is a Gaussian process with covariance function Σ(•, •) specified in the statement of Theorem
5. Therefore, the lhs of (99) is Op (n−1/2 ), implying
                                             √
                                        sup k n(β̂(τ ) − β(τ ))k = Op∗ (1).                                   (101)
                                        τ ∈T

    Finally, by (99)-(101)
                    √
                        n(β̂(•) − β(•)) = −J −1 (•)Gn [ϕ• (Y − X 0 β(•))] + op∗ (1) in `∞ (T )
                                                                                                              (102)
                                        ⇒ J −1 (•) · z(•) in `∞ (T ). ¥

A.7     Proof of Corollaries
Proof of Corollary 1. The result is immediate from the definition of weak convergence in `∞ (T ). ¥
Proof of Corollary 2. The result follows by the continuous mapping theorem in `∞ (T ). ¥
Proof of Corollary 3. The result is immediate from Corollary 2. ¥
Proof of Corollary 4. The result is immediate from Politis, Romano and Wolf (1999), Theorem 2.2.1
and Corollary 2.4.1, for the case when the rescaling matrices are known. For the case when the matrices
are consistently estimated the proof follows by an argument similar to the proof of Theorem 2.5.1 in
Politis, Romano and Wolf (1999). Finally, we also need that K has an absolutely continuous distribution.
This result follows from Theorem 11.1 in Davydov, Lifshits, and Smorodina (1998). ¥
Proof of Corollary 5. Note that this corollary is not covered by the results in Powell (1986) or
                                             ˆ ), because their proofs apply only pointwise in τ ,
Buchinsky and Hahn (1998) for consistency of J(τ
whereas we require a uniform result.
    First, recall that
                                          h                                   i
                                ˆ ) = 1 En 1{|Yi − Xi0 β̂(τ )| ≤ hn } · Xi Xi0 .
                                J(τ                                                                           (103)
                                     2hn
We will show that
                                   ˆ ) − J(τ ) = op∗ (1) uniformly in τ ∈ T .
                                   J(τ                                                                        (104)

                                                           30
                      h                i
              ˆ ) = En fi (β̂(τ ), hn ) , where fi (β, h) = 1{|Yi −X 0 β| ≤ h}·Xi X 0 . Next, for any compact
Note that 2hn J(τ                                                   i              i

set B and positive constant H, the functional class {fi (β, h), β ∈ B, h ∈ (0, H]} is a Donsker class with
square integrable envelope by Theorem 2.10.6 in Van der Vaart and Wellner (1996), since this is a product
of a VC class {1{|Yi − Xi0 β| ≤ h}, β ∈ B, h ∈ (0, H]} and a square intergrable random matrix Xi Xi0
(recall EkXi k4 < ∞ by assumption). Therefore, (β, h) 7→ Gn [fi (β, h)] converges to a Gaussian process
in `∞ (B × (0, H]), which implies that
                                                 °                               °
                                                 °                               °
                                     sup         °En [fi (β, h)] − E [fi (β, h)] ° = Op∗ (n−1/2 ).                           (105)
                                β∈B,0<h≤H

Letting B be any compact set that covers ∪τ ∈T β(τ ), this implies
                             ° h                 i                ¯              °
                             °                                                   °
                         sup °En fi (β̂(τ ), hn ) − E [fi (β, h)] ¯β=β̂(τ ),h=hn ° = Op∗ (n−1/2 ).                           (106)
                        τ ∈T
                                              h                i                                     ¯
                                      ˆ ) = En fi (β̂(τ ), hn ) and noting that 1/2hn ·E [fi (β, h)] ¯ b
Hence (104) follows by using that 2hn J(τ                                                                         =
                                                                                                       β(τ ),h=hn
J(τ ) + op (1) by an argument similar to that used in (96) and the assumption h2n n → ∞.
    Second, we can write
                                                         h                                    i
                                         Σ̂(τ, τ 0 ) = En gi (β̂(τ ), β̂(τ 0 ), τ, τ 0 )Xi Xi0 ,                             (107)

where gi (β 0 , β 00 , τ 0 , τ 00 ) = (τ − 1{Yi ≤ Xi0 β 0 })(τ 0 − 1{Yi ≤ Xi0 β 00 }) · Xi Xi0 . We will show that

                               Σ̂(τ, τ 0 ) − Σ(τ, τ 0 ) = op∗ (1) uniformly in (τ, τ 0 ) ∈ T × T .                           (108)

Note that {gi (β 0 , β 00 , τ 0 , τ 00 ), (β 0 , β 00 , τ 0 , τ 00 ) ∈ B × B × T × T } is Donsker and hence a Glivenko-Cantelli
class, for any bounded set B. Indeed, Fβ = {1{Yi ≤ Xi0 β}, β ∈ B} is a VC class, and hence is Donsker.
Then, T − Fβ is also a bounded Donsker class with envelope 2, by Theorem 2.10.6 in Van der Vaart and
Wellner (1996). Next, the product of two bounded classes (T − Fβ ) × (T − Fβ ) is a bounded Donsker
class with envelope 4, by Theorem 2.10.6 in Van der Vaart and Wellner (1996). Last, the product of a
bounded Donsker class with a square integrable random matrix XXi0 gives a Donsker class, by Theorem
2.10.6 in Van der Vaart and Wellner (1996).
    This implies that uniformly in (β 0 , β 00 , τ 0 , τ 00 ) ∈ (B × B × T × T )

                          En [gi (β 0 , β 00 , τ 0 , τ 00 )Xi Xi0 ] − E [gi (β 0 , β 00 , τ 0 , τ 00 )Xi Xi0 ] = op∗ (1).    (109)

By inspection, E [gi (β 0 , β 00 , τ 0 , τ 00 )Xi Xi0 ] is continuous in (β 0 , β 00 , τ 0 , τ 00 ) over (B × B × T × T ). Letting B
cover ∪τ β(τ ), continuity and (109) imply (108).
    A similar argument applies to Σ̂0 (τ, τ 0 ) .¥



B       Appendix: Estimating the QR Weighting Function
We calculate the importance weights using equation (7). The integral was estimated with a grid of 101
                                                                                                  b )),
                                                        b τ (Y |X)) and the QR approximation (X 0 β(τ
points between the non-parametric estimates of the CQF (Q


                                                                       31
for each cell of the covariates X. This gives rise to the following discrete approximation formula for the
importance weights
                      101
                      X                    µ                                                  ¶
     w      b )) = 1
     bτ (x, β(τ           (1 −
                               u − 1 b u − 1 0b
                                    ) · fY       · x β(τ ) + (1 −
                                                                  u−1 b
                                                                       ) · Qτ (Y |X = x)|X = x .          (110)
                  101 u=1       100          100                   100

We used kernel density estimates of fY (y|X = x) with a Gaussian kernel and bandwidth (h) determined
by
                  "q                                                                          #
                                                     IQR 0.25,0.75 [Y − b τ (Y |X = x)|X = x]
                                                                        Q
        m = min               b τ (Y |X = x)|X = x],
                     V ar[Y − Q                                                                 ,         (111)
                                                                       1.349

                                                               0.9 · m
                                                        h=             .                                  (112)
                                                                n1/5
This bandwidth choice is optimal in the sense that it minimizes mean integrated square error with
Gaussian data and a Gaussian kernel (Silverman, 1986). The density weights were calculated similarly.
Sampling weights were used in the estimation of conditional densities for the 2000 census sample.
      To calculate weights for partial quantile correlation, w
                                                             eτ (X), we also use a discrete approximation of
the average density of the response variable representation. In particular, we have
                            101        µ                                                 ¶
               c         1 X 1 b u − 1 0b                     u−1 b
               w
               eτ (x) =           · fY       · x β(τ ) + (1 −     ) · Qτ (Y |X = x)|X = x ,               (113)
                        101 u=1 2        100                  100

where the conditional densities are estimates using the same kernel method as for the importance weights.



C       Appendix: Sampling Weights
In order to take into account the weighted structure of the census 2000 sample, the estimators for the
components of the variance formulae in Table 1 were modified as follows
                                     n
                       0         1X 2
                  Σ̂(τ, τ ) =         w · (τ − 1(Yi ≤ Xi0 β̂(τ ))(τ 0 − 1(Yi ≤ Xi0 β̂(τ 0 )) · Xi Xi0 ,   (114)
                                 n i=1 i
                                                                n
                                                             1X 2
                 Σ̂0 (τ, τ ) =   [min(τ, τ 0 ) − τ τ 0 ] ·        w · Xi Xi0 ,                            (115)
                                                             n i=1 i
                                       n
                    ˆ ) =          1 X
                    J(τ                   wi · 1(|Yi − Xi0 β̂(τ )| ≤ hn ) · Xi Xi0 .                      (116)
                                 2nhn i=1

where wi are the sampling weights (normalized to add to n). Other calculations involving the 2000 sample
use sampling weights in the standard way.



D       Appendix: Data
The data were drawn from the 1% self-weighting 1980 and 1990 samples, and the 1% weighted 2000
sample, all from the IPUMS website (Ruggles et al., 2003). The sample for most of the calculations

                                                                32
consists of US-born black and white men with age 40-49 with at least 5 years of education, with positive
annual earnings and hours worked in the year preceding the census, and with nonzero sampling weight.
Individuals with imputed values for age, education, earnings or weeks worked were also excluded from
the sample. After this selection process, the final sample sizes were 65,023, 86,785 and 97,397 for 1980,
1990 and 2000.
    The log-earnings variable is the average log weekly wage and was calculated as the log of the reported
annual income from work divided by weeks worked in the previous year. Annual income is expressed in
1989 dollars using the Personal Consumption Expenditures Price Index.
    The education variable for 1980 corresponds to the highest grade of school completed, coded as
follows:
                         Years of schooling   Highest grade of school completed
                                 5            5th grade of Elementary School
                                 6            6th grade of Elementary School
                                 7            7th grade of Elementary School
                                 8            8th grade of Elementary School
                                 9            9th grade of High School
                                 10           10th grade of High School
                                 11           11th grade of High School
                                 12           12th grade of High School
                                 13           1st year of College
                                 14           2nd year of College
                                 15           3rd year of College
                                 16           4th year of College
                                 17           5th year of College
                                 18           6th year of College
                                 19           7th year of College
                                 20           8th or more year of College
For the purposes of Figure 5 and most of the empirical work, years of schooling for 1990 and 2000 censuses




                                                   33
were imputed from categorical schooling variables as follows:

           Years of schooling   Educational attainment
                   8            5th, 6th, 7th, or 8th grade
                   9            9th grade
                   10           10th grade
                   11           11th or 12th grade, no diploma
                   12           High school graduate, diploma or GED
                   13           Some college, but no degree
                   14           Completed associate degree in college, occupational program
                   15           Completed associate degree in college, academic program
                   16           Completed bachelor’s degree, not attending school
                   17           Completed bachelor’s degree, but now enrolled
                   18           Completed master’s degree
                   19           Completed professional degree
                   20           Completed doctorate

For the purposes of Panel C in Figure 6, we modify this slightly, coding 5th-8th grade as 8 and 2-3 years
in college as 14 in 1980, and coding the categories associate college degree, occupational program, and
associate degree, academic program, as 14 in 1990. These changes generate schooling variables with the
same range and points of support in all 3 years.



References
 [1] Abadie, A. (1997): “Changes in Spanish Labor Income Structure during the 1980’s: A Quantile
    Regression Approach,” Investigaciones Economicas XXI(2), pp. 253-272.

 [2] Andrews, D. and D. Pollard (1994): “An Introduction to Functional Central Limit Theorems for
    Dependent Stochastic Processes,” International Statistical Review 62(1), pp. 119-132.

 [3] Angrist, J. and A. Krueger (1999): “Empirical Strategies in Labor Economics,” in O. Ashenfelter
    and D. Card (eds.), Handbook of Labor Economics, Volume 3. Amsterdam. Elsevier Science.

 [4] Autor, D., L.F. Katz and M.S. Kearney (2004): ”Inequality in the 1990s: Revising the Revisionists,”
    MIT Department of Economics, mimeo, March 2004.

 [5] Bai, J. (1998): “Testing Parametric Conditional Distributions of Dynamic Models,” preprint.

 [6] Buchinsky, M. (1994): “Changes in the US Wage Structure 1963-1987: Application of Quantile
    Regression,” Econometrica 62, pp. 405-458.

 [7] Buchinsky, M. and J. Hahn (1998): “An Alternative Estimator for the Censored Quantile Regression
    Model,” Econometrica 66, no. 3, pp. 653-671.


                                                   34
 [8] Chamberlain, G. (1984): “Panel Data,” in Z. Griliches and M. Intriligator (eds.), Handbook of
    Econometrics, Volume 2. North-Holland. Amsterdam.

 [9] Chamberlain, G. (1994): “Quantile Regression, Censoring, and the Structure of Wages,” in C. A.
    Sims (ed.), Advances in Econometrics, Sixth World Congress, Volume 1. Cambridge University Press.
    Cambridge.

[10] Chernozhukov, V. (2002): “Inference on the Quantile Regression Process, An Alternative,” Unpub-
    lished Working Paper 02-12 (February), MIT (www.ssrn.com).

[11] Doksum, K. (1974): “Empirical Probability Plots and Statistical Inference for Nonlinear Models in
    the Two-Sample Case,” Annals of Statistics 2, pp. 267-277.

[12] Davydov, Yu. A., M. A. Lifshits and N. V. Smorodina (1998): Local properties of distributions of
    stochastic functionals. Translated from the 1995 Russian original by V. E. Nazaı̆kinskiı̆ and M. A.
    Shishkova. Translations of Mathematical Monographs, 173. American Mathematical Society, Provi-
    dence, RI.

[13] Giacomini, R. and Komunjer, I. (2003): “Evaluation and Combination of Conditional Quantile
    Forecasts,” Working Paper 571, Boston College and California Institute of Technology, 06/2003.

[14] Goldberger, A. S. (1991): A Course in Econometrics. Harvard University Press. Cambridge, MA.

[15] Gosling, A., S. Machin and C. Meghir (2000): “The Changing Distribution of Male Wages in the
    U.K.,” Review of Economic Studies 67, pp. 635-666.

[16] Gutenbrunner, C. and J. Jurečková (1992): “Regression Quantile and Regression Rank Score Process
    in the Linear Model and Derived Statistics,” Annals of Statistics 20, pp. 305-330.

[17] Gutenbrunner, C., J. Jurečková, R. Koenker, and S. Portnoy (1993): “Test of Linear Hypotheses
    Based on Regression Rank Scores,” Journal of Nonparametric Statistics 2, pp. 307-331.

[18] Hahn, J. (1997): “Bayesian Bootstrap of the Quantile Regression Estimator: A Large Sample Study,”
    International Economic Review 38(4), pp. 795-808.

[19] Hall, P., and S. Sheather (1988): “On the Distribution of a Studentized Quantile,” Journal of the
    Royal Statistics Society B 50, pp. 381-391.

[20] Hansen, L.-P. , J. Heaton and A. Yaron (1996): “Finite-Sample Properties of Some Alternative
    GMM Estimators,” Journal of Business and Economic Statistics 14(3), pp. 262-280.

[21] Juhn, C., K. Murphy and B. Pierce (1993): “Wage Inequality and the Rise in Return to Skill,”
    Journal of Political Economy 101, pp. 410-422.

[22] Katz, L. and D. Autor (1999): “Changes in the Wage Structure and Earnings Inequality,” in O.
    Ashenfelter and D. Card (eds.), Handbook of Labor Economics, Volume 3A. Elsevier Science. Ams-
    terdam.


                                                  35
[23] Katz, L. and K. Murphy (1992): “Changes in the Relative Wages, 1963-1987: Supply and Demand
    Factors,” Quarterly Journal of Economics 107, pp. 35-78.

[24] Kim T.H., and H. White (2002): “Estimation, Inference, and Specification Testing for Possibly
    Misspecified Quantile Regressions,” in Advances in Econometrics, forthcoming.

[25] Knight, K. (2002): “Comparing Conditional Quantile Estimators: First and Second Order Consid-
    erations,” Mimeo. University of Toronto.

[26] Koenker, R. (1994): “Confidence Intervals for Regression Quantiles,” in M.P. and M. Hušková (eds.),
    Asymptotic Statistics: Proceeding of the 5th Prague Symposium of Asymptotic Statistics. Physica-
    Verlag, Heidleverg.

[27] Koenker, R. and G. Bassett (1978): “Regression Quantiles,” Econometrica 46, pp. 33-50.

[28] Koenker, R. and K. Hallock (2001): “Quantile Regression,” Journal of Economic Perspectives 15(4),
    pp. 143-156.

[29] Koenker, R., and J. A. Machado (1999): “Goodness of Fit and Related Inference Processes for
    Quantile Regression,” Journal of the American Statistical Association 94(448), pp. 1296-1310.

[30] Koenker, R. and Z. Xiao (2002): “Inference on the quantile regression process,” Econometrica 70,
    no. 4, pp. 1583–1612.

[31] Lemieux, T. (2003): “Residual Wage Inequality: A Re-examination,” Mimeo. University of British
    Columbia, June.

[32] Machado, J. A. and J. Mata (2003): “Counterfactual Decomposition of Changes in Wage Distribu-
    tions using Quantile Regression,” Mimeo. Universidade Nova de Lisboa.

[33] Politis, D. N., J. P. Romano and M. Wolf (1999): Subsampling. Springer-Verlag. New York.

[34] Portnoy, S. (1991): “Asymptotic behavior of regression quantiles in nonstationary, dependent cases”
    Journal of Multivariate Analysis 38, no. 1, pp. 100-113.

[35] Powell, J. (1986): “Symmetrically Trimmed Least Squares Estimation for Tobit Models,” Econo-
    metrica 54, no. 6, pp. 1435-1460.

[36] Powell, J. (1994): “Estimation of Semiparametric Models,” in R.F. Engle and D.L. McFadden (eds.),
    Handbook of Econometrics, Volume IV. Amsterdam. Elsevier Science.

[37] Ruggles, S. and M. Sobek et al. (2003): Integrated Public Use Microdata Series: Version 3.0. Min-
    neapolis: Historical Census Project. University of Minesota.

[38] Silverman, B. W. (1986): Density Estimation for Statistics and Data Analysis. Chapman & Hall.
    London.

[39] Van der Vaart, A. W. (1998): Asymptotic Statistics. Cambridge University Press. Cambridge, UK.


                                                   36
[40] Van der Vaart, A. W. and J. A. Wellner (1996): Weak Convergence and Empirical Processes. With
    Applications to Statistics. Springer Series in Statistics. Springer-Verlag. New York.

[41] White, H. (1980): “Using Least Squares to Approximate Unknown Regression Functions,” Interna-
    tional Economic Review 21(1), pp. 149-170.




                                                   37
                                        Table 1: Human capital earnings function:
                                 Estimates of schooling coeﬃcients and standard errors (%)

                  Desc. Stats.                     Quantile Regression Estimates                     OLS Estimates
Census    Obs.    Mean    SD            0.1        0.25         0.5         0.75         0.9        Coeﬀ.   Root MSE

                                                   A. Without controls

                                       7.48         7.13       6.39          6.56       7.42          6.98
 1980    65,023    6.40   0.67        (0.223)     (0.078)     (0.067)      (0.069)     (0.100)      (0.080)      0.63
                                      [0.239]     [0.081]     [0.067]      [0.070]     [0.110]      [0.087]

                                       10.04        9.57       8.93          9.23       11.59         9.78
 1990    86,785    6.46   0.69        (0.130)     (0.119)     (0.075)      (0.108)     (0.169)      (0.082)      0.64
                                      [0.135]     [0.121]     [0.075]      [0.107]     [0.178]      [0.087]

                                       9.80        10.57       11.05        11.89       15.51        11.71
 2000    97,397    6.50   0.75        (0.201)     (0.129)     (0.109)      (0.115)     (0.624)      (0.092)      0.69
                                      [0.208]     [0.133]     [0.109]      [0.115]     [0.669]      [0.113]

                           B. Controlling for race and quadratic function of potential experience

                                       7.35         7.35       6.83          7.01       7.91          7.20
 1980    65,023    6.40   0.67        (0.190)     (0.120)     (0.099)      (0.104)     (0.145)      (0.120)      0.63
                                      [0.199]     [0.123]     [0.099]      [0.106]     [0.153]      [0.127]

                                       11.15       10.96       10.62        11.08       13.69        11.36
 1990    86,785    6.46   0.69        (0.274)     (0.123)     (0.104)      (0.149)     (0.252)      (0.117)      0.64
                                      [0.285]     [0.126]     [0.104]      [0.148]     [0.263]      [0.122]

                                       9.16        10.49       11.13        11.95       15.73        11.44
 2000    97,397    6.50   0.75        (0.195)     (0.120)     (0.126)      (0.134)     (0.385)      (0.117)      0.69
                                      [0.204]     [0.122]     [0.126]      [0.134]     [0.401]      [0.141]

Notes: US-born white and black men aged 40-49. Standard Errors in parentheses. Standard Errors robust to mispecification
in brackets. Sampling weights used for 2000 Census.
                  Table 2: Comparison of CQF and QR-based Interquantile Spreads

                                                              Interquantile Spread
                                      90-10                 75-25              90-50             50-10
Census    Obs.      Controls    CQ            QR         CQ       QR        CQ       QR   CQ             QR

                                                     A. Overall

                      No       1.20           1.20       0.56     0.56    0.51     0.52   0.69           0.68
 1980    65,023
                      Yes      1.20           1.19       0.56     0.55    0.52     0.51   0.68           0.67

                      No       1.37           1.36       0.65     0.65    0.61     0.61   0.76           0.75
 1990    86,785
                      Yes      1.35           1.35       0.64     0.64    0.60     0.61   0.75           0.74

                      No       1.45           1.45       0.71     0.70    0.68     0.69   0.77           0.76
 2000    97,397
                      Yes      1.43           1.45       0.70     0.68    0.67     0.70   0.76           0.75

                                        B. High School Graduates

                      No       1.10           1.20       0.51     0.57    0.42     0.51   0.67           0.69
 1980    25,020
                      Yes      1.09           1.17       0.52     0.55    0.44     0.50   0.65           0.67

                      No       1.27           1.33       0.64     0.66    0.51     0.56   0.76           0.77
 1990    22,837
                      Yes      1.26           1.31       0.63     0.64    0.52     0.55   0.74           0.76

                      No       1.32           1.34       0.68     0.67    0.60     0.61   0.72           0.73
 2000    25,963
                      Yes      1.29           1.32       0.66     0.66    0.59     0.60   0.70           0.72

                                          C. College Graduates

                      No       1.25           1.19       0.60     0.54    0.58     0.55   0.67           0.64
 1980     7,158
                      Yes      1.26           1.19       0.59     0.53    0.61     0.54   0.65           0.64

                      No       1.49           1.40       0.68     0.64    0.69     0.67   0.77           0.73
 1990    15,517
                      Yes      1.44           1.38       0.66     0.63    0.70     0.66   0.74           0.72

                      No       1.57           1.57       0.73     0.72    0.75     0.78   0.82           0.78
 2000    19,388
                      Yes      1.55           1.57       0.74     0.71    0.75     0.80   0.80           0.78

Notes: US-born white and black men aged 40-49. Average measures calculated using the distribution
of the covariates in each year. The covariates are schooling (controls = No) or schooling, race and a
quadratic function of experience (controls = Yes). Sampling weights used for 2000 Census.
         Table 3: Measures of Between-group (Model) and Within-group (Residual)
                Inequality and Linear (Quantile) Regression Approximations

                                     Quantile-based Measures                     ANOVA
                       90-10           75-25         90-50         50-10       Cond. OLS
Census     Obs.      CQ    QR        CQ    QR     CQ     QR      CQ    QR      Mean  Fit

                                   A. Between-group Inequality

 1980     65,023     0.60   0.59     0.15   0.23   0.35   0.32   0.25   0.27     0.24   0.23

 1990     86,785     0.63   0.65     0.33   0.35   0.37   0.41   0.27   0.24     0.28   0.27

 2000     97,397     0.66   0.75     0.51   0.43   0.42   0.53   0.24   0.22     0.30   0.29

                                   B. Within-group Inequality

 1980     65,023     1.14   1.17     0.52   0.54   0.49   0.51   0.65   0.66     0.63   0.63

 1990     86,785     1.32   1.35     0.62   0.63   0.57   0.59   0.73   0.75     0.63   0.64

 2000     97,397     1.38   1.41     0.67   0.67   0.64   0.66   0.73   0.75     0.68   0.69

             C. Relative Importance of Within-group Inequality (RTR and 1-R2 )

 1980     65,023      78     80       93    85     65     72     87     86       87      88

 1990     86,785      81     81       78    76     71     68     88     90       84      85

 2000     97,397      82     78       63    71     70     61     90     92       84      85

Notes: US-born white and black men aged 40-49. Measures calculated in a model that includes
schooling, race and experience. Relative measures calculated as the square of Panel B divided
by the sum of the square of Panel A and the square of Panel B. Sampling weights used for 2000
census.
                                    A. tau = 0.10                                               B. tau = 0.25




               7.0




                                                                              7.0
                            CQ                                                          CQ
                            KB QR                                                       KB QR

               6.5




                                                                              6.5
                            C QR                                                        C QR
               6.0




                                                                              6.0
Log-earnings




                                                               Log-earnings
               5.5




                                                                              5.5
               5.0




                                                                              5.0
               4.5




                                                                              4.5
                       5            10               15   20                        5           10               15   20

                                         Schooling                                                   Schooling



                                    C. tau = 0.50                                               D. tau = 0.75
               8.0




                                                                              8.0
                            CQ                                                          CQ
                            KB QR                                                       KB QR
               7.5




                                                                              7.5
                            C QR                                                        C QR
               7.0




                                                                              7.0
Log-earnings




                                                               Log-earnings
               6.5




                                                                              6.5
               6.0




                                                                              6.0
               5.5




                                                                              5.5




                       5            10               15   20                        5           10               15   20

                                         Schooling                                                   Schooling



                                    E. tau = 0.90                                                    F. mean
               8.5




                                                                              8.0




                            CQ                                                          CEF
                            KB QR                                                       WLS
               8.0




                                                                              7.5




                            C QR                                                        OLS
               7.5




                                                                              7.0
Log-earnings




                                                               Log-earnings
               7.0




                                                                              6.5
               6.5




                                                                              6.0
               6.0




                                                                              5.5




                       5            10               15   20                        5           10               15   20

                                         Schooling                                                   Schooling




                     Figure 1: CQF and CEF in 1980 Census (US-born white and black men aged 40-49).
                     Panels A - E plot the Conditional Quantile Function, Koenker and Basset’s Quantile
                     Regression fit and Chamberlain’s Minimum Distance fit for weekly log-earnings given
                     years of schooling. Panel F plots the Conditional Expectation Function (CEF),
                     Weighted LS fit and OLS fit for weekly log-earnings given years of schooling.
                          A. tau = 0.10                                       B. tau = 0.25




          0.6




                                                               0.6
                     QR weigths                                          QR weights
                     Imp. weights                                        Imp. weights

          0.5




                                                               0.5
          0.4




                                                               0.4
Weight




                                                      Weight
          0.3




                                                               0.3
          0.2




                                                               0.2
          0.1




                                                               0.1
          0.0




                                                               0.0
                5          10               15   20                  5         10               15   20

                                Schooling                                           Schooling



                          C. tau = 0.50                                       D. tau = 0.75
          0.6




                                                               0.6
                     QR weights                                          QR weights
                     Imp. weights                                        Imp. weights
          0.5




                                                               0.5
          0.4




                                                               0.4
Weight




                                                      Weight
          0.3




                                                               0.3
          0.2




                                                               0.2
          0.1




                                                               0.1
          0.0




                                                               0.0




                5          10               15   20                  5         10               15   20

                                Schooling                                           Schooling



                          E. tau = 0.90                                             F. mean
          0.6




                                                               0.6




                     QR weights                                          WLS weights
                     Imp. weights                                        1/V[Y|X]
          0.5




                                                               0.5
          0.4




                                                               0.4
Weight




                                                      Weight
          0.3




                                                               0.3
          0.2




                                                               0.2
          0.1




                                                               0.1
          0.0




                                                               0.0




                5          10               15   20                  5         10               15   20

                                Schooling                                           Schooling




         Figure 2: Weighting Functions in 1980 Census (US-born white and black men aged 40-49).
         Panels A-E plot the histogram of years of schooling, QR weighting function and importance
         weighting function for QR’s of log-earnings on years of schooling. Panel F plots the
         histogram of years of schooling, WLS weighting function and inverse of the conditional
         variance for the linear regression of log-earnings on years of schooling.
                             A. tau = 0.10                                         B. tau = 0.25




         0.20




                                                                  0.20
                       Imp. weights                                          Imp. weights
                       Den. weights                                          Den. weights

         0.15




                                                                  0.15
Weight




                                                         Weight
         0.10




                                                                  0.10
         0.05




                                                                  0.05
         0.00




                                                                  0.00
                  5           10               15   20                   5          10               15   20

                                   Schooling                                             Schooling



                             C. tau = 0.50                                         D. tau = 0.75
         0.20




                                                                  0.20
                       Imp. weights                                          Imp. weights
                       Den. weights                                          Den. weights
         0.15




                                                                  0.15
Weight




                                                         Weight
         0.10




                                                                  0.10
         0.05




                                                                  0.05
         0.00




                                                                  0.00




                  5           10               15   20                   5          10               15   20

                                   Schooling                                             Schooling



                             E. tau = 0.90
         0.20




                       Imp. weights
                       Den. weights
         0.15
Weight

         0.10
         0.05
         0.00




                  5           10               15   20

                                   Schooling




                Figure 3: Importance and Density Weights in 1980 Census (US-born white and black
                men aged 40-49).
                                         A. tau = 0.10                                                                 B. tau = 0.25




                   0.5 1.0




                                                                                                    1.0
                                                                                                    0.5
Residuals of CQF




                                                                                 Residuals of CQF

                                                                                                    0.0
                   -0.5




                                                                                                    -0.5
                   -1.5




                                                            Partial CQF                                                                   Partial CQF




                                                                                                    -1.0
                                                      -     With Experience                                                         -     With Experience
                                                      -     Without Experience                                                      -     Without Experience
                   -2.5




                                                                                                    -1.5
                             -10    -5            0              5          10                             -10    -5            0              5          10

                                   Residuals of Schooling                                                        Residuals of Schooling



                                         C. tau = 0.50                                                                 D. tau = 0.75
                   1.0




                                                                                                    1.0
                   0.5




                                                                                                    0.5
Residuals of CQF




                                                                                 Residuals of CQF
                   0.0




                                                                                                    0.0
                   -0.5




                                                                                                    -0.5


                                                            Partial CQF                                                                   Partial CQF
                   -1.0




                                                                                                    -1.0



                                                      -     With Experience                                                         -     With Experience
                                                      -     Without Experience                                                      -     Without Experience
                   -1.5




                                                                                                    -1.5




                             -10    -5            0              5          10                             -10    -5            0              5          10

                                   Residuals of Schooling                                                        Residuals of Schooling



                                         E. tau = 0.90                                                                    F. mean
                   1.0




                                                                                                    1.0
                   0.5




                                                                                                    0.5
Residuals of CQF




                                                                                 Residuals of CEF
                   0.0




                                                                                                    0.0
                   -0.5




                                                                                                    -0.5




                                                            Partial CQF                                                                   Partial CQF
                   -1.0




                                                                                                    -1.0




                                                      -     With Experience                                                         -     With Experience
                                                      -     Without Experience                                                      -     Without Experience
                   -1.5




                                                                                                    -1.5




                             -10    -5            0              5          10                             -10    -5            0              5          10

                                   Residuals of Schooling                                                        Residuals of Schooling




Figure 4: Partial Quantile Correlation Plots in 1980 Census (US-born white men aged 30-54).
Panels A-E plot the Partial Conditional Quantile Function and Partial QR fit of log-earnings on
years of schooling, controlling for a quadratic function of experience. The dashed line has the
same slope as a QR line of log-earnings on years of schooling without controlling for experience.
Panel F plots the Partial Conditional Expectation Function and Partial OLS fit of log-earnings
on years of schooling, controlling for a quadratic function of experience. The dashed line has
the same slope as a OLS line of log-earnings on years of schooling without controlling for
experience.
                                          A. 1980                                                             B. 1990                                                          C. 2000



                                       95% Robust Uniform CI                                               95% Robust Uniform CI                                            95% Robust Uniform CI
                            16         95% Robust Pointwise CI                                             95% Robust Pointwise CI                                          95% Robust Pointwise CI




                                                                                                16




                                                                                                                                                                 16
                            14




                                                                                                14




                                                                                                                                                                 14
Schooling Coefficient (%)




                                                                    Schooling Coefficient (%)




                                                                                                                                     Schooling Coefficient (%)
                            12




                                                                                                12




                                                                                                                                                                 12
                            10




                                                                                                10




                                                                                                                                                                 10
                            8




                                                                                                8




                                                                                                                                                                 8
                                 0.2      0.4      0.6   0.8                                         0.2      0.4      0.6   0.8                                      0.2      0.4      0.6   0.8

                                       Quantile Index                                                      Quantile Index                                                   Quantile Index



                                 Figure 5: Schooling coeﬃcients in 1980, 1990 and 2000 censuses (US-born white and black men aged 40-49). Panels
                                 A, B and C plot the Quantile Process for the coeﬃcient of schooling in the QR of log-earnings on years of schooling,
                                 race and a quadratic function of experience, and 95% robust pointwise and uniform confidence intervals for 1980, 1990
                                 and 2000, respectively. Uniform bands obtained by subsampling using 200 repetitions with subsample size b = 5n2/5 .
                                 The horizontal lines correspond to the OLS estimates of the schooling coeﬃcient.
                               A. Without Controls                                B. With controls (at covariate means)                   C. With controls (at 1980 covariate means)



                              1980                                                         1980                                                        1980
                              1990                                                         1990                                                        1990
                              2000                                                         2000                                                        2000
               0.5




                                                                           0.5




                                                                                                                                         0.5
Log earnings




                                                            Log earnings




                                                                                                                          Log earnings
               0.0




                                                                           0.0




                                                                                                                                         0.0
               -0.5




                                                                           -0.5




                                                                                                                                         -0.5
                        0.2          0.4      0.6    0.8                             0.2          0.4      0.6   0.8                             0.2          0.4      0.6   0.8

                                 Quantile Index                                               Quantile Index                                              Quantile Index

                      Figure 6: Unconditional quantiles and conditional quantiles of log-earnings in 1980, 1990 and 2000 censuses (US-born white
                      and black men aged 40-49). Distributions are centered at median earnings for each year. Panel A plots 95 % uniform bands
                      for unconditional quantiles. Panels B and C plot 95% uniform bands for the QR approximation to the conditional quantile
                      function given schooling, race and a quadratic function of experience. In Panel B covariates are evaluated at sample mean
                      values for each year and schooling is coded using IPUMS categories for each year. In Panel C covariates are evaluated at
                      sample mean values for 1980 and schooling is recoded using 2000 IPUMS categories.
                                    A. tau = 0.10                                                    B. tau = 0.25




               7.0




                                                                                   7.0
                            CQ                                                               CQ
                            KB QR                                                            KB QR

               6.5




                                                                                   6.5
                            C QR                                                             C QR
               6.0




                                                                                   6.0
Log-earnings




                                                                    Log-earnings
               5.5




                                                                                   5.5
               5.0




                                                                                   5.0
               4.5




                                                                                   4.5
                       8    10      12       14      16   18   20                        8   10      12       14      16   18   20

                                         Schooling                                                        Schooling



                                    C. tau = 0.50                                                    D. tau = 0.75
               8.0




                                                                                   8.0
                            CQ                                                               CQ
                            KB QR                                                            KB QR
               7.5




                                                                                   7.5
                            C QR                                                             C QR
               7.0




                                                                                   7.0
Log-earnings




                                                                    Log-earnings
               6.5




                                                                                   6.5
               6.0




                                                                                   6.0
               5.5




                                                                                   5.5




                       8    10      12       14      16   18   20                        8   10      12       14      16   18   20

                                         Schooling                                                        Schooling



                                    E. tau = 0.90                                                         F. mean
               8.5




                                                                                   8.0




                            CQ                                                               CEF
                            KB QR                                                            WLS
               8.0




                                                                                   7.5




                            C QR                                                             OLS
               7.5




                                                                                   7.0
Log-earnings




                                                                    Log-earnings
               7.0




                                                                                   6.5
               6.5




                                                                                   6.0
               6.0




                                                                                   5.5




                       8    10      12       14      16   18   20                        8   10      12       14      16   18   20

                                         Schooling                                                        Schooling




                     Figure 7: CQF and CEF in 1990 Census (US-born white and black men aged 40-49).
                     Panels A - E plot the Conditional Quantile Function, Koenker and Basset’s Quantile
                     Regression fit and Chamberlain’s Minimum Distance fit for weekly log-earnings given
                     years of schooling. Panel F plots the Conditional Expectation Function (CEF),
                     Weighted LS fit and OLS fit for weekly log-earnings given years of schooling.
                                    A. tau = 0.10                                                    B. tau = 0.25




               7.0




                                                                                   7.0
                            CQ                                                               CQ
                            KB QR                                                            KB QR

               6.5




                                                                                   6.5
                            C QR                                                             C QR
               6.0




                                                                                   6.0
Log-earnings




                                                                    Log-earnings
               5.5




                                                                                   5.5
               5.0




                                                                                   5.0
               4.5




                                                                                   4.5
                       8    10      12       14      16   18   20                        8   10      12       14      16   18   20

                                         Schooling                                                        Schooling



                                    C. tau = 0.50                                                    D. tau = 0.75
               8.0




                                                                                   8.5
                            CQ                                                               CQ
                            KB QR                                                            KB QR
               7.5




                                                                                   8.0
                            C QR                                                             C QR
               7.0




                                                                                   7.5
Log-earnings




                                                                    Log-earnings
               6.5




                                                                                   7.0
               6.0




                                                                                   6.5
               5.5




                                                                                   6.0




                       8    10      12       14      16   18   20                        8   10      12       14      16   18   20

                                         Schooling                                                        Schooling



                                    E. tau = 0.90                                                         F. mean
               8.5




                                                                                   8.0




                            CQ                                                               CEF
                            KB QR                                                            WLS
               8.0




                                                                                   7.5




                            C QR                                                             OLS
               7.5




                                                                                   7.0
Log-earnings




                                                                    Log-earnings
               7.0




                                                                                   6.5
               6.5




                                                                                   6.0
               6.0




                                                                                   5.5




                       8    10      12       14      16   18   20                        8   10      12       14      16   18   20

                                         Schooling                                                        Schooling




                     Figure 8: CQF and CEF in 2000 Census (US-born white and black men aged 40-49).
                     Panels A - E plot the Conditional Quantile Function, Koenker and Basset’s Quantile
                     Regression fit and Chamberlain’s Minimum Distance fit for weekly log-earnings given
                     years of schooling. Panel F plots the Conditional Expectation Function (CEF),
                     Weighted LS fit and OLS fit for weekly log-earnings given years of schooling.
                         A. tau = 0.10                                            B. tau = 0.25




          0.6




                                                                   0.6
                     QR weigths                                               QR weights
                     Imp. weights                                             Imp. weights

          0.5




                                                                   0.5
          0.4




                                                                   0.4
Weight




                                                          Weight
          0.3




                                                                   0.3
          0.2




                                                                   0.2
          0.1




                                                                   0.1
          0.0




                                                                   0.0
                8   10    12        14     16   18   20                  8   10    12        14     16   18   20

                               Schooling                                                Schooling



                         C. tau = 0.50                                            D. tau = 0.75
          0.6




                                                                   0.6
                     QR weights                                               QR weights
                     Imp. weights                                             Imp. weights
          0.5




                                                                   0.5
          0.4




                                                                   0.4
Weight




                                                          Weight
          0.3




                                                                   0.3
          0.2




                                                                   0.2
          0.1




                                                                   0.1
          0.0




                                                                   0.0




                8   10    12        14     16   18   20                  8   10    12        14     16   18   20

                               Schooling                                                Schooling



                          E. tau = 0.90                                                 F. mean
          0.6




                                                                   0.6




                     QR weights                                               WLS weights
                     Imp. weights                                             1/V[Y|X]
          0.5




                                                                   0.5
          0.4




                                                                   0.4
Weight




                                                          Weight
          0.3




                                                                   0.3
          0.2




                                                                   0.2
          0.1




                                                                   0.1
          0.0




                                                                   0.0




                8   10    12        14     16   18   20                  8   10    12        14     16   18   20

                               Schooling                                                Schooling




         Figure 9: Weighting Functions in 1990 Census (US-born white and black men aged 40-49).
         Panels A-E plot the histogram of years of schooling, QR weighting function and importance
         weighting function for QR’s of log-earnings on years of schooling. Panel F plots the
         histogram of years of schooling, WLS weighting function and inverse of the conditional
         variance for the linear regression of log-earnings on years of schooling.
                         A. tau = 0.10                                            B. tau = 0.25




          0.6




                                                                   0.6
                     QR weigths                                               QR weights
                     Imp. weights                                             Imp. weights

          0.5




                                                                   0.5
          0.4




                                                                   0.4
Weight




                                                          Weight
          0.3




                                                                   0.3
          0.2




                                                                   0.2
          0.1




                                                                   0.1
          0.0




                                                                   0.0
                8   10    12        14     16   18   20                  8   10    12        14     16   18   20

                               Schooling                                                Schooling



                         C. tau = 0.50                                            D. tau = 0.75
          0.6




                                                                   0.6
                     QR weights                                               QR weights
                     Imp. weights                                             Imp. weights
          0.5




                                                                   0.5
          0.4




                                                                   0.4
Weight




                                                          Weight
          0.3




                                                                   0.3
          0.2




                                                                   0.2
          0.1




                                                                   0.1
          0.0




                                                                   0.0




                8   10    12        14     16   18   20                  8   10    12        14     16   18   20

                               Schooling                                                Schooling



                          E. tau = 0.90                                                 F. mean
          0.6




                                                                   0.6




                     QR weights                                               WLS weights
                     Imp. weights                                             1/V[Y|X]
          0.5




                                                                   0.5
          0.4




                                                                   0.4
Weight




                                                          Weight
          0.3




                                                                   0.3
          0.2




                                                                   0.2
          0.1




                                                                   0.1
          0.0




                                                                   0.0




                8   10    12        14     16   18   20                  8   10    12        14     16   18   20

                               Schooling                                                Schooling




         Figure 10: Weighting Functions in 2000 Census (US-born white and black men aged 40-49).
         Panels A-E plot the histogram of years of schooling, QR weighting function and importance
         weighting function for QR’s of log-earnings on years of schooling. Panel F plots the
         histogram of years of schooling, WLS weighting function and inverse of the conditional
         variance for the linear regression of log-earnings on years of schooling.
                          A. tau = 0.10                                              B. tau = 0.25




         0.20




                                                                    0.20
                    Imp. weights                                               Imp. weights
                    Den. weights                                               Den. weights

         0.15




                                                                    0.15
Weight




                                                           Weight
         0.10




                                                                    0.10
         0.05




                                                                    0.05
         0.00




                                                                    0.00
                8   10     12       14      16   18   20                   8   10     12       14      16   18   20

                                Schooling                                                  Schooling



                          C. tau = 0.50                                              D. tau = 0.75
         0.20




                                                                    0.20
                    Imp. weights                                               Imp. weights
                    Den. weights                                               Den. weights
         0.15




                                                                    0.15
Weight




                                                           Weight
         0.10




                                                                    0.10
         0.05




                                                                    0.05
         0.00




                                                                    0.00




                8   10     12       14      16   18   20                   8   10     12       14      16   18   20

                                Schooling                                                  Schooling



                          E. tau = 0.90
         0.20




                    Imp. weights
                    Den. weights
         0.15
Weight

         0.10
         0.05
         0.00




                8   10     12       14      16   18   20

                                Schooling




           Figure 11: Importance and Density Weights in 1990 Census (US-born white and black
           men aged 40-49).
                          A. tau = 0.10                                              B. tau = 0.25




         0.20




                                                                    0.20
                    Imp. weights                                               Imp. weights
                    Den. weights                                               Den. weights

         0.15




                                                                    0.15
Weight




                                                           Weight
         0.10




                                                                    0.10
         0.05




                                                                    0.05
         0.00




                                                                    0.00
                8   10     12       14      16   18   20                   8   10     12       14      16   18   20

                                Schooling                                                  Schooling



                          C. tau = 0.50                                              D. tau = 0.75
         0.20




                                                                    0.20
                    Imp. weights                                               Imp. weights
                    Den. weights                                               Den. weights
         0.15




                                                                    0.15
Weight




                                                           Weight
         0.10




                                                                    0.10
         0.05




                                                                    0.05
         0.00




                                                                    0.00




                8   10     12       14      16   18   20                   8   10     12       14      16   18   20

                                Schooling                                                  Schooling



                          E. tau = 0.90
         0.20




                    Imp. weights
                    Den. weights
         0.15
Weight

         0.10
         0.05
         0.00




                8   10     12       14      16   18   20

                                Schooling




           Figure 12: Importance and Density Weights in 2000 Census (US-born white and black
           men aged 40-49).
