                                NBER WORKING PAPER SERIES




                            MAXIMUM LIKELIHOOD ESTIMATION
                              OF LATENT AFFINE PROCESSES

                                            David S. Bates

                                         Working Paper 9673
                                 http://www.nber.org/papers/w9673


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                      May 2003




I am grateful for comments on earlier versions of this paper from Luca Benzoni, Michael Chernov, Frank
Diebold, Garland Durham, George Jiang, Michael Johannes, George Tauchen, and Chuck Whiteman, and
from seminar participants at Colorado, Iowa, and NYU. The views expressed herein are those of the authors
and not necessarily those of the National Bureau of Economic Research.

©2003 by David S. Bates. All rights reserved. Short sections of text not to exceed two paragraphs, may be
quoted without explicit permission provided that full credit including ©notice, is given to the source.
Maximum Likelihood Estimation of Latent Affine Processes
David S. Bates
NBER Working Paper No. 9673
May 2003
JEL No. C1

                                            ABSTRACT

This article develops a direct filtration-based maximum likelihood methodology for estimating the

parameters and realizations of latent affine processes. The equivalent of Bayes' rule is derived for

recursively updating the joint characteristic function of latent variables and the data conditional upon

past data. Likelihood functions can consequently be evaluated directly by Fourier inversion. An

application to daily stock returns over 1953-96 reveals substantial divergences from EMM-based

estimates: in particular, more substantial and time-varying jump risk.



David S. Bates
Henry B. Tippie College of Business
University of Iowa
Iowa City, IA 52242-1000
and NBER
david-bates@uiowa.edu
                “The Lion in Affrik and the Bear in Sarmatia are Fierce,
        but Translated into a Contrary Heaven, are of less Strength and Courage.”

                                    Jacob Zeigler; translated (1555) by Richard Eden


While models proposing time-varying volatility of asset returns have been around for thirty
years, it has proven extraordinarily difficult to estimate the parameters of the underlying
volatility process, and the current volatility level conditional on past returns. It has been
especially difficult to estimate the continuous-time stochastic volatility models that are best
suited for pricing derivatives such as options and bonds. Recent models suggest that asset
prices jump and that the jump intensity is itself time-varying, creating an additional latent
state variable to be inferred from asset returns.


The problem of estimating unobserved and time-varying volatility and jump risk from stock
returns is an example of the general problem of inferring latent variables from observed data.
Currently, three approaches are commonly used for such state space problems:
   1) analytically tractable specifications, such as Gaussian or regime-switching models;
 2)    derivatives-based methods that infer latent variables’ realizations directly from prices
       of bonds or options; and
   3) simulation methods.


Each approach has had some difficulties when applied to the problem of estimating stochastic
volatility parameters and realizations. The few analytically tractable state space models
available appear to be somewhat poor approximations of the relationship between stock
returns and underlying volatility. The joint evolution of asset prices and volatility is not
Gaussian, nor does volatility take on only a finite number of discrete values. Nevertheless,
some papers have attempted to use such models as approximations for volatility evolution
and estimation. Ruiz (1994) and Harvey, Ruiz, and Shephard (1994) have explored the
Kalman filtration associated with Gaussian models, while Fridman and Harris (1998)
essentially use a constrained regime-switching model with a large number of states as an
approximation to an underlying stochastic volatility process.
                                               2

Derivatives-based methods such as Pearson and Sun (1994) and Pan (2002) eliminate the
latency of underlying state variables, thereby permitting direct estimation of state variable
processes. However, such methods place considerable faith in market participants’ ability
to assess the values of latent state variables, as well as considerable faith in the pricing
models used.


Simulation methods are currently the most actively researched approach for estimating
discrete- and continuous-time stochastic volatility processes. Provided the model and
parameters are correct, simulated data should possess roughly the same moments as the
actual data – thereby permitting estimation of model parameters by a GMM procedure. At
present, there is an extraordinary diversity of proposed moment conditions: Simulated
Method of Moments of Duffie and Singleton (1993), empirical characteristic functions
(Singleton, 2001), and spectral method of moments, to name a few. While such approaches
can estimate process parameters, they are not especially suited to the filtration problem of
estimating latent variable realizations.


One currently popular simulation method is the “Efficient Method of Moments” approach
of Gallant and Tauchen (2001). That approach derives moment conditions from an auxiliary
discrete-time model, simulates sample paths from the hypothesized continuous-time process
for given parameter estimates via Monte Carlo, and then chooses those parameters that best
match the moment conditions. Estimating the latent volatility realizations requires an
additional “reprojection” step of identifying an appropriate rule for inferring volatility from
past returns, given the observed relationship between the two series in the many simulations.
The particle filter approach is another simulation methodology that is also receiving
considerable attention currently.1


This article explores an alternate recursive maximum likelihood methodology applicable
whenever the (discrete-time) data and the latent variable(s) have an affine joint characteristic
function conditional upon the latent variable. The major innovation is to work almost
entirely in the transform space of characteristic functions, rather than working with
probability densities. I derive the equivalent of Bayes’ rule for updating the characteristic


       1
        See Johannes, Polson, and Stroud (2002), and the references therein.
                                                3

function of the latent variable conditional upon observed data. Given this and the affine
structure, recursively updating the conditional characteristic function of the data is
straightforward. The probability densities necessary for maximum likelihood estimation can
then be evaluated numerically by Fourier inversion.


The approach can be viewed as an extension of the Kalman filtration methodology used with
Gaussian state space models – which indeed are included in the class of affine processes. In
Kalman filtration, the multivariate normality of the data and latent variable(s) is exploited
to update the estimated mean x̂ t * t and variance Pt * t of the latent variable realization
conditional on past data. Given normality, the conditional distribution of the latent variable
is fully summarized by those moment estimates, while the associated moment generating
function is of the simple form Gt * t(ψ) ' exp[x̂t * t ψ % ½ Pt * t ψ 2 ] . My approach generalizes
the recursive updating of Gt * t(ψ) to other affine processes that lack the analytic conveniences
of multivariate normality.


The approach is limited at present to affine processes, whether discrete- or continuous-time.
However, the affine class of processes is a broad and interesting one, and is extensively used
in pricing bonds and options. In particular, jumps in returns and/or in the state variable can
be accommodated, whereas simulation methods can have difficulty with rare events.
Furthermore, some recent interesting expanded-data approaches also fit within the affine
structure; e.g., the intradaily “realized volatility” used by Andersen, Bollerslev, Diebold, and
Ebens (2001), or the use of implicit variances from options. Finally, some discrete-time non-
affine processes can be re-expressed as affine processes after appropriate data
transformations; e.g., the log stochastic volatility model examined inter alia by Harvey, Ruiz,
and Shephard (1994) and Jacquier, Polson, and Rossi (1994).


A further advantage of the approach relative to moment-based simulation methods is that
filtered estimates of the latent state variable are directly obtained from the recursive updating
of the conditional characteristic function, while the precision of the estimate can also be
easily estimated. Furthermore, the filtration algorithm can be examined more directly than
the “kitchen sink” regression approach used in EMM reprojection. In particular, it is possible
to directly compare the filtration with those used in GARCH volatility assessments. Finally,
                                               4

the approach is a direct maximum likelihood approach using observed data, obviating the
estimation of an auxiliary discrete-time model.


Section 1 below derives the basic algorithm for arbitrary affine processes. Section 2 runs
diagnostics, using a simplified discrete-time affine stochastic volatility process and simulated
data. Section 3 provides estimates of some affine continuous-time stochastic volatility/jump-
diffusion models previously estimated by Andersen, Benzoni and Lund (2002) and Chernov,
Gallant, Ghysels, and Tauchen (2002). For direct comparison with EMM-based estimates,
I use the Andersen et al data set of daily S&P 500 returns over 1953-1996, which were
graciously provided by Luca Benzoni. Section 4 concludes.
                                                           5

1. Recursive evaluation of likelihood functions for affine processes
Let yt denote an (L × 1) vector of variables observed at date t . Let x t represent an (M × 1)
vector of latent state variables affecting the dynamics of yt . The following assumptions are
made:
  1)    z t / ( y t , x t ) is assumed to be Markov;
  2) the latent variables x t are assumed stationary; and
  3) the characteristic function of zt%τ conditional upon z t is exponentially affine in the
        latent variables x t :
                                          iΦN yt%τ % i ψNxt%τ
            Fy, x (i Φ, iψ; z t ) / E e                         * zt
                                                                                            (1)
                                 ' exp[C(τ; iΦ, i ψ; y t ) % D(τ; iΦ, i ψ; y t )N x t ] .
For simplicity, I will focus on the most common case of one data source and one latent
variable:    L ' M ' 1 . Generalizing to higher-dimensional data and/or multiple latent
variables is theoretically straightforward, but numerically more complex.


Equation (1) is satisfied by the general class of affine processes. The best-known example
of this class is the Gaussian state-space system discussed in Hamilton (1994, Ch. 13), for
which the conditional density function p( zt%1 * z t ) is multivariate normal. As described in
Hamilton, a recursive structure exists in this case for updating the conditional Gaussian
densities of x t over time based upon observing y t . Given the Gaussian structure, it suffices
to update the mean and variance of the latent x t , which is done by Kalman filtration.


More general affine processes typically lack analytic expressions for the conditional density
functions needed in maximum likelihood estimation. Their popularity for bond and option
pricing models lies in the ability to compute those quantities numerically from characteristic
functions. In essence, the characteristic function is the Fourier transform of the probability
density function, while the density function is the inverse Fourier transform of the
characteristic function. Using the notation G(Φ) for the moment generating function and
G(iΦ) for the characteristic function, the latter is:
                                      G (iΦ) / E e iΦ y
                                                                                            (2)
                                                      m
                                                  '       e iΦ y p( y) dy
                                                                6


                                                      m
                                                 1
                                p( y) '                   G(i Φ) e &iΦ y dΦ .               (3)
                                              2π




The existence of analytic solutions for the moment generating and characteristic functions
then gets the problem halfway to a solution. Distribution functions and option prices can also
be evaluated from the characteristic function by Fourier inversion.


It is also possible to numerically evaluate joint density functions by Fourier inversion:

                                         mm
                                  1
                    p(x, y) '                    Fx, y(i ψ, iΦ) e &i ψ x & iΦ y dψ dΦ .     (4)
                                 (2π)2

The following key proposition indicates that characteristic functions for conditional
distributions can be evaluated from a partial inversion of F.

Proposition 1. Let
                         Fx, y(i ψ, iΦ) / E e i ψ x % iΦ y
                                                                                            (5)
                                                     mm
                                             '             e i ψ x % iΦ y p(x, y) dx dy

be the joint characteristic function of the random variables (x, y) . The characteristic
function of x conditional upon observing y is

                                                          m&4
                                                 1         4
                                                               Fx, y(i ψ, i Φ) e &iΦ y dΦ
                                                 2π
                       Gx * y(i ψ ; y) '                                                    (6)
                                                                     p( y)

where

                                                 m&4 x, y
                                         1            4
                            p( y) '                 F (0, i Φ) e &iΦ y dΦ                   (7)
                                         2π


is the marginal density of y.


Proof: By Bayes’ law, the conditional characteristic function Gx * y can be written as

                                                      m
                           Gx * y(i ψ; y) '               e i ψ x p(x * y) dx

                                                        1                                   (8)
                                                      p( y) m
                                              '               e i ψ x p(x, y) dx .


Fx, y(C, i Φ) is therefore the Fourier transform of Gx * y(C, y) p( y) :
                                                          7


                                               m
                        Fx, y(i ψ; i Φ) '          e iΦ y [ Gx * y(i ψ, y) p( y)] d y
                                                                                                         (9)
                                               mm
                                           '         e iΦ y % iψx p(x, y) dx d y .


Consequently, Gx * y(i ψ; y) p( y) is the inverse (Φ, y) Fourier transform of Fx, y(iψ, i Φ) ,
yielding (6) above.                                                                                        

                                                                                                iψxt
Let Y t / { y1, . . ., y t} be the data observed up through date t. Define Gt * s(i ψ) / E [e          *Y s ]
as the characteristic function (CF) of the latent variable x t conditional upon observing Y s .
Given Proposition 1 and the affine structure, the filtered CF G t | t (i ψ) can be recursively
updated as follows:


Step 0: At time t ' 0 , initialize G t * t (i ψ) ' G 0 * 0(i ψ) at the CF of the unconditional density
of the latent variable. From equation (1), this has an analytic solution of the form
                           G0 * 0(i ψ) ' exp[ C(τ ' 4, Φ ' 0, i ψ) ] .                                  (10)



Step 1: Given G t | t , the joint characteristic function of next’s period’s z t % τ ' { yt % τ xt % τ }
conditional on data observed through date t can be evaluated by iterated expectations,
exploiting the special structure of affine characteristic and moment generating functions
given in (1) above:
                                                        iΦ yt%τ % i ψ x t%τ
                      Fy, x * t (iΦ, i ψ) ' Et E e                            * xt

                                          ' Ee
                                                    C(τ; iΦ, i ψ) % D(τ; iΦ, i ψ) x t
                                                                                        * Yt            (11)

                                          ' e C(τ; iΦ, i ψ) Gt * t [D(τ; iΦ, i ψ) ] .



Step 2: The conditional density function of next period’s datum yt % τ conditional upon data
observed through date t can be evaluated by Fourier inversion of its characteristic function:
                                           1 4
                                          2 π m&4
                                                                       &i Φ yt%1
                      p( yt%1 * Y t ) '           Fy, x * t (i Φ, 0) e           dΦ .                   (12)
                                                              8

Step 3: Using Proposition 1, the conditional characteristic function of next period’s latent
variable is

                                          m&4
                                     1      4                             &i Φ yt%τ
                                                 Fy, x * t (i Φ, i ψ) e               dΦ
                                     2π
              Gt% τ * t% τ (i ψ) '
                                                       p( yt%τ * t )
                                                                                                                     (13)

                                          m&4
                                     1     4                                   C(τ; iΦ, i ψ) & i Φ yt%τ
                                                Gt * t [ D(τ; iΦ, i ψ)]e                                  dΦ
                                     2π
                               '                                                                               .
                                                               p( yt%τ * t )


Step 4: Repeat steps 1-3 for subsequent values of t. Given underlying parameters θ , the
likelihood function used in maximum likelihood estimation is L(Y T *θ) ' k p( yt % 1 * Y t , θ) .
                                                                                                               T&1

                                                                                                               t'0


Gt * t(i ψ) is the time-t prior characteristic function of the latent variable xt , while Fy, x * t in
equation (11) is the time- t joint prior CF for ( yt%1 , xt%1 ) . Step 3 is the equivalent of
Bayesian updating for characteristic functions, and yields the posterior CF of latent xt%1 --
which is also the time- (t % 1) prior CF for the next time step. The equivalent steps for
updating moment generating functions and the associated conditional density functions are
given in Table 1. For notational simplicity, a standardized time gap τ ' 1 is used, and the
dependency of C and D on the time gap is suppressed. However, the algorithm can easily
cope with irregular time gaps.


Filtered estimates of next period’s latent variable realization and the accompanying precision
can be directly computed from derivatives of the moment generating function Gt% 1 * t% 1(ψ)
in (13):
                                 x̂ t%1 * t%1 ' Gt%1 * t%1N(0)

                                Pt%1 * t%1 / Vart%1 (xt%1 )                                                          (14)
                                                                             2
                                                ' Gt%1 * t%1O(0) & x̂t%1 * t%1 .
                                                    9

I.B Implementation
The recursion in (10) - (13) indicates that for a given conditional characteristic function
Gt * t (i ψ) of latent xt and an observed datum yt%τ , it is possible to compute an updated CF
Gt%τ * t%τ (i ψ) that fully summarizes the filtered distribution of latent xt%τ . To implement the
recursion, it is necessary to temporarily store the entire function Gt * t(i ψ) in some fashion.
This is an issue of approximating functions -- a subject extensively treated in Press et al
(1992, Ch. 5) and Judd (1998, Ch.6). Using atheoretic methods such as splines or Chebychev
polynomials, it is possible to achieve arbitrarily precise approximations to Gt * t(i ψ) .


However, it may not be easy to impose the appropriate shape restrictions that insure a given
atheoretic approximating function Ĝt * t(i ψ) is indeed a legitimate characteristic function. A
simple illustration of potential pitfalls arises with the symmetric Edgeworth distribution, with
unitary variance and an excess kurtosis of κ4 . The associated density and characteristic
functions are
                                             κ4
                           p(x) ' 1 %             (x 4 & 6 x 2 % 3) n(x)
                                             24
                                                                                                (15)
                                         2              κ4
                         G(i ψ) ' e &½ ψ      1 %            ψ4
                                                        24
where n(x) is the standard normal density function. The Edgeworth distribution requires
κ4 # 4 to preclude negative probabilities. And yet it is not obvious from inspecting G(i ψ)
that κ4 ' 4 is a critical value, and that using an approximating function equivalent to a
numerical value of κ̂4 ' 4.005 would generate invalid densities.


To avoid such potential problems, it appears safer to use approximating characteristic
functions of latent realizations that are generated directly from distributions with known
properties. As the recursion in (10) - (13) is just Bayesian updating, any legitimate
approximate prior characteristic function Ĝt * t (i ψ) from a known distribution will generate
a legitimate posterior characteristic function Ĝt%τ * t%τ (i ψ) .         In particular, mixtures of
distributions are a standard method of approximating arbitrary distributional forms. The
applications below use the gamma distribution, to enforce nonnegativity constraints on the
latent stochastic volatility realizations. Mixtures of gammas will be explored in future
extensions if necessary.
                                                            10

2. A Monte Carlo examination of the approach
To illustrate the approach and to test the accuracy of the approximating functions, the
following simplified discrete-time stochastic volatility process for log-differenced asset
prices was simulated:
                                yt%1 - N [0, Vt ∆t ]
                                                                                              (16)
                                d V ' (α & β Vt ) dt % σ V dW

with asset returns and variance shocks assumed independent. This process is the affine
equivalent of the benchmark discrete-time stochastic volatility model studied by Harvey,
Ruiz, and Shephard (1994), Jacquier, Polson and Rossi (1994), and Kim, Shephard and Chib
(1998). Rather than the conditionally Gaussian AR(1) process for log volatility of those
papers,2 however, the square-root process for volatility implies a noncentral chi-squared
transition density in discrete time:
               2 Vt%1                  4α 2 Vt &β ∆t                       σ2
                        * V t - χ2        ,   e                  for Κ /      1 & e &β ∆t .   (17)
                 Κ                     σ2   Κ                              2β

Given the assumed conditional independence of volatility increments and asset returns, the
joint conditional characteristic function in (1) above takes the separable form
                                     iΦ yt%1 % i ψ Vt%1
      Fy, V (iΦ, iψ * Vt ) / E e                          * Vt

                                        2α                            e &β∆t i ψ              (18)
                           ' exp &         ln(1 & i Κ ψ) % &½ Φ2 ∆t %            Vt .
                                        σ2                            1 & iΚψ


The unconditional density of V0 has a gamma distribution, with associated characteristic
function
                                                                     &v0
                                     G0 * 0(i ψ) ' (1 & i κ0 ψ)                               (19)




       2
            For a discrete-time log volatility process, the data transformation
zt% 1 / ln * yt% 1 & E( yt% 1) * generates an affine state space system in z and log volatility for
which this article’s methodology can be used. The square-root variance process (16) is used
instead as a simple discrete-time approximation to the continuous-time affine specifications
examined below.
                                                      11

for v0 / 2 α /σ2 and κ0 ' σ2 / 2 β . The unconditional mean and variance of V0 are
                          2
κ0 v0 ' α / β and κ0 v0 ' (α / β) (σ2 / 2β) , respectively.


The simplest approximating function in subsequent periods to assume a gamma distribution:
                                                                    &v t
                                      Ĝt * t(i ψ) ' (1 & i κt ψ)          .                  (20)

This approximation is exact for t ' 0 , and imposes appropriate nonnegativity constraints for
t > 0 . The density is summarized at each date t by the parameter pair (κt , vt ) . Furthermore,
updated estimates (κ t%1 , v t%1 ) can be generated from the moment conditions from equations
(13) and (14):
                                 κt%1 vt%1 ' V̂ t%1 * t%1
                                           ' Gt%1 * t%1N(0)
                                  2                                                           (21)
                                 κt%1 vt%1 ' Vart%1 (Vt%1)
                                                                       2
                                          ' Gt%1 * t%1O(0) & V̂t%1 * t%1 .

Further details are in the appendix. The resulting updated approximation Ĝt%1 * t%1(ψ) /
               &vt%1
(1 & κt%1 ψ)           matches the first and second moments of the true Gt%1 * t%1(ψ) computed from
(13) for different values of ψ , and is therefore comparable to a second-order Taylor
approximation.


This approximation methodology somewhat resembles that of Ruiz (1994) and Harvey, Ruiz,
and Shephard (1994). The HRS approach assumes an approximate Gaussian distribution for
log absolute returns, and uses Kalman filtration to update the mean and variance of log
volatility. The HRS approach is consistent, but efficiency is reduced by the fact that the
distribution of log absolute returns is poorly approximated by the Gaussian distribution.
Here, the exact distributional properties of observed data are used in (13) when updating the
posterior conditional mean and variance of the latent variable. Approximation enters in the
specification of the prior density for latent variance, which affects the relative weights of the
data and the prior.
                                              12

2.B. Simulations
Data were simulated based upon the stochastic volatility estimates of Andersen, Benzoni and
Lund (2002) from daily data over 1953-1996: α '.0438 , β ' 3.2508 , and ∆t ' 1 / 252 , in
annualized units. Andersen et al (henceforth ABL) estimated the average annualized
variance at (0.116)2 , while variance shocks mean-revert with an estimated half-life of 2.56
months. The volatility of volatility parameter was set to σ ' 4α / 5 ' .187 , instead of the
ABL estimate of .185. This produces an integer number (five) of degrees of freedom for the
noncentral χ2 density in (17), permitting exact Monte Carlo generation of noncentral χ2
shocks from the sum of squared normal shocks.


The initial variance V0 was independently drawn from the unconditional gamma density for
                                                         T&1
each sample path, and 1000 variance sample paths {Vt}t ' 0 were independently generated for
various values of T . Normally distributed log-differenced returns were generated given the
variance realizations. The parameters θ̂ ' {α̂, β̂, σ̂} for each set of returns were estimated
by maximizing the likelihood function described above, with true parameter values used as
starting values. For comparison, the parameters θ̂V were also estimated by direct maximum
                                                   T&1
likelihood conditional upon observing the {Vt}t ' 0 sample path, using the noncentral χ2
transition densities and initial gamma distribution.


Table 2 summarizes the results. The estimation methodology is consistent, with the
estimated bias (average bias rows) for all parameters and parameter transformations
decreasing with longer data samples. The fastest convergence is for the average variance
α / β and the volatility of variance parameter σ . The slowest is for the parameter β that
determines serial correlation and the associated half-life estimates; some bias remains even
for 48 years’ of data. Those biases reflect in magnified fashion the small-sample biases for
a persistent series that would exist even if the V(t) series were directly observed, as
illustrated in the second set of β̂ estimates.3 Here, of course, the values of that series must
be inferred from noisy returns data, which almost doubles the magnitude of the bias.




          3
           See Nankervis and Savin (1988) and Stambaugh (1999) for a discussion of these
biases.
                                               13

The estimation procedure for the parameters of the latent stochastic variance process
performs surprisingly well. Squared daily returns are very noisy signals of daily latent
variance, and yet the RMSE of returns-based parameter estimates is typically less than
double that of estimates conditioned on actually observing the underlying variance.
Furthermore, parameter estimates for α and β are highly correlated with the estimates
conditional on directly observing V(t) data.


An interesting exception is the volatility of variance estimator σ̂ . Were V(t) data observed,
its volatility parameter σ would be pinned down quite precisely even for relatively small data
sets; e.g., a RMSE of .004 on a data set of 1000 observations. By contrast, when {V(t)} must
be inferred from noisy stock returns, the imprecision of the V̂t * t estimates increases the
RMSE of the σ̂ estimate tenfold.


2.C Filtration
Figures 1 and 2 illustrate the accuracy of the volatility filtration Et Vt conditional upon
using the true parameters, for the first 1000 observations (four years) of a generated sample
of 12,000 observations. Since the conditional distribution of latent variance Vt is gamma (or
scaled χ2 ), the conditional distribution of latent volatility has a scaled χ distribution, with
noncentral moments
                                                n/2
                                    n          κt     Γ(νt % ½)
                            E    Vt * Y t '                       ,                        (22)
                                                      Γ(νt )

where Γ(C) is the gamma function.


The volatility estimate begins at the unconditional mean of 11.0% at time 0, but converges
rapidly towards the true value as returns are observed. Changes in the filtered volatility
perforce lag behind changes in the true volatility, since the filtered estimate is inferred from
past squared returns. The absolute divergence is typically less than 4%, but is occasionally
larger. To put this error in perspective: a volatility estimate (towards the end of the sample)
of 11% when the true volatility is 16% is a substantial error from an option pricing
perspective. The magnitude of this error reflects the low informational content of squared
daily returns for estimating latent volatility and variance.
                                               14

A key issue is whether the filtered gamma densities are indeed reasonably accurate
approximations to the true conditional distributions of latent variances. On simulated data,
this can be directly assessed by examining the frequency with which Vt realizations fall
within the quantiles of the conditional Vt * t gamma distributions. The realized frequencies
over a run of 12,000 observations indicate the gamma approximation is indeed accurate :
              Quantile p:                    .05    .10    .25    .5     .75    .90    .95
                ˆ
              Prob[V(t)  < V̂p(t) * It ] :   .043   .090   .243   .492   .743   .897   .951


where V̂p(t) is the filtered gamma quantile with lower tail probability p at time t.
Consequently, there appears to be no need to use more complicated approximating functions
such as a mixture of gammas.
                                              15

3. Estimates from stock index returns
There is a growing body of work on the estimation of continuous-time affine and non-affine
stochastic volatility/jump models for stock market returns by simulation methods. Three
recent contributions are Andersen, Benzoni, and Lund (2002), Chernov, Gallant, Ghysels,
and Tauchen (2002), and Eraker, Johannes, and Polson (2000). The first two papers
(henceforth ABL and CGGT, respectively) use the SNP/EMM methodology of Gallant and
Tauchen for daily stock index returns over 1953-96 and 1953-99, respectively. Eraker et al
use Bayesian MCMC methods for daily S&P returns over 1980-99, as well as NASDAQ
returns over 1985-99. Included among the affine specifications considered in those papers
is the following continuous-time affine model:

                      dS / S ' (µ0 % µ1 V & λt k ) dt % V dW % (e γ & 1) d N

                         dV '      (α & β V ) dt % σ V dWV
           Corr[dW, dWV ] ' ρ                                                             (23)
             Prob[dN ' 1] ' (λ0 % λ1 V ) dt

                          γ - N[γ, δ2 ]


where k ' exp[γ % ½ δ2 ] & 1 . The latter two papers also examine the interesting affine
specification in which there are jumps in latent variance that may be correlated with stock
market jumps.


This article uses the 11,076 daily S&P 500 returns over 1953 through 1996 that formed the
basis for Andersen, Benzoni and Lund’s (2002) EMM/SNP estimates.4 I will not repeat the
data description in that article, but two comments are in order. First, Andersen et al
prefiltered the data to remove an MA(1) component that may be attributable to
nonsynchronous trading in the underlying stocks. Second, there were three outliers that
created some numerical difficulties for likelihood evaluation: the -22% stock market crash
of October 19, 1987, the 7% drop on September 26, 1955 that followed reports of President
Eisenhower’s heart attack, and the 6% mini-crash on October 13, 1989. Details of computing
probability densities for such outliers are given in the appendix, as is the functional form of


       4
        I am indebted to Luca Benzoni for providing the data.
                                               16

the joint likelihood function.


The first three columns of Table 3 present estimates of the stochastic volatility model without
jumps (SV) from Chernov et al, Andersen et al, and the methodology of this paper.5 As
discussed in CGGT, estimating the parsimonious stochastic volatility model without jumps
creates conflicting demands for the volatility mean reversion parameter β and the volatility
of volatility parameter σ . Extreme outliers such as the 1987 crash can be explained by
highly volatile volatility that mean-reverts within days, whereas standard volatility
persistence suggest lower volatility of volatility and slower mean reversion. In CGGT’s
estimates, the former effect dominates; in ABL’s estimates, the latter dominates.


My estimates are affected by both phenomena, but matching the volatility persistence clearly
dominates. While constraining σ to the CGGT estimate of 1.024 substantially raises the
likelihood of the outliers in 1955, 1987, and 1989, this is more than offset by likelihood
reductions for the remainder of the data. The overall log likelihood falls from 39,234 to
39,049 – a strong rejection of the constraint with an associated P-value less than 10&16 . And
although the CGGT data set includes a few outliers in 1997-99 that are not in the ABL data
set used here, the likelihood impact per outlier of a larger σ̂ seems insufficient to explain the
difference in results.6


Although my stochastic volatility parameter estimates are qualitatively similar to those of
ABL on the same data set, there are substantial differences. In particular, I estimate a higher
volatility of volatility (.315 instead of .197) and faster volatility mean reversion (half-life of
1.4 months, instead of 2.1 months). The estimate of the average annualized level of variance
is also higher: (.125)2 , rather than (.112)2 . The estimates of the correlation between
volatility and return shocks are comparable. The substantial reduction in log likelihood of
the six ABL parameter estimates is strongly significant statistically, with a P-value of

       5
        The ABL estimates are from their Table IV, converted to an annualized basis.
       6
        It is possible the difference in estimates is attributable to how different specifications
of the SNP discrete-time auxiliary model interact with outliers. ABL specify an EGARCH-
based auxiliary model to capture the correlation between return and volatility shocks. CGGT
use a GARCH framework, and capture the volatility-return correlation through terms in the
Hermite polynomials.
                                                   17

9 × 10&16 . It appears that the two-stage SNP/EMM methodology used by Andersen et al
generates a objective function for parameter estimation that is substantially different from
my maximum likelihood methodology.


As found in the earlier studies, adding a jump component substantially improves the overall
fit. As indicated in the middle three columns of Table 2, I estimate a more substantial, less
frequent jump component than previous studies: three jumps every four years, of average size
-1.0% and standard deviation 5.2%. As outliers are now primarily explained by the jump
component, the parameters governing volatility dynamics parameters are modified: σ drops,
and the half-life of volatility shocks lengthens. The divergence of parameter estimates from
the ABL estimates is again strongly significant statistically.


Bates (2000) showed that a volatility-dependent jump intensity component λ1Vt helps
explain the cross-section of stock index option prices. Some time series evidence for the
specification was provided in Bates and Craine (1999), while Eraker et al (2000) found
stronger empirical support. In contrast to the results in ABL, the final two columns of Table
2 indicate that jumps are indeed more likely when volatility is high. The hypothesis that λ1
= 0 is rejected at a P-value of 5 × 10&8 . The time-invariant jump component λ0 ceases to be
statistically significant when λ1 is added.


Standard maximum likelihood diagnostics dating back to Pearson (1933) can be used to
assess model specification. As in Bates (2000), I use the normalized transition density

                                zt%1 ' N &1 [CDF( yt%1 * Y t , θ̂) ]                     (24)

where N &1 is the inverse of the cumulative normal distribution function, and the cumulative
distribution function CDF is evaluated from the conditional characteristic function by Fourier
inversion given parameter estimates θ̂ . Under correct specification, the z’s should be
independent and identical draws from a normal distribution. The approach is equivalent to
a standard Qq plot of the CDF realizations; the additional inverse normal transformation
usefully highlights outliers.


The histogram of normalized returns in Figure 3 indicates the SVJ1 model fits most returns
quite well. A major remaining outlier is, however, the 1987 crash, which is interpreted as
                                              18

a five standard deviation draw from a jump-contingent normal distribution with standard
deviation 3.9%, and has a z-score of -5.52. As z-scores less than -5 should be observed only
once every 14,000 years, that single 1987 outlier constitutes substantial evidence against the
model.


To address this issue, an additional stochastic volatility/jump model is estimated in which
jumps in log-differenced prices are drawn from a mixture of normals. The resulting
estimates for the stochastic volatility component are roughly unchanged; the jump parameters
become
                                                     N [ .001, (.029)2 ] with prob. .982
 Prob[dN ' 1 ] ' 133.44 Vt ,        ln (1 % k˜ ) -                                       (25)
                                                     N [&.222, (.007)2 ] with prob. .018

The conditional distribution of daily returns is approximately a mixture of three normals:
normal daily volatility that varies stochastically over a range of .2% - 1.8%, infrequent
symmetric jumps with a larger standard deviation of 2.9% and time-varying arrival rate that
averages 1.85 jumps per year, and an extremely infrequent crash corresponding to the 1987
outlier. Log likelihood rises from 39,309.51 to 39,317.81 -- an improvement almost entirely
attributable to a better fit for the 1987 crash. Correspondingly, the z-score on that day drops
in magnitude, to a more plausible value of -3.50. The increase in log likelihood has a
marginal significance level of .0008 under a likelihood ratio test, given 3 additional
parameters.


3.B. Filtration
Figure 4 illustrates the filtered estimates of latent volatility Vt from the SVJ1 model, and
the difference between SVJ1 and SV volatility estimates. Those estimates are generally
almost identical, except following large positive or negative stock returns. For instance, the
1955 and 1987 crashes have much more of an impact on volatility assessments under the SV
model than under the jump models.


Figure 5 illustrates the typical impact of asset returns on volatility assessments, using the
“news impact curves” Et%1 Vt%1 & Et Vt%1 employed by Hentschel (1995) when assessing
GARCH models. The volatility estimates were computed from the conditional moments of
                                                  19

latent variance,7 using the second-order Taylor approximation
                                                          1 Var[V ]
                           E V . E [V ] 1 &                         .                       (26)
                                                          8 E[V ]2

The estimates were calibrated from a median volatility day (October 14, 1960) with a
volatility estimate of 11.4%, and initial filtered gamma distribution parameters
(κt , vt ) ' (.00229, 5.89) .


All news impact curves are tilted, with negative returns having a larger impact on volatility
assessments than positive returns. All models process the information in small asset returns
similarly. The most striking result, however, is that taking jumps into account implies that
volatility updating becomes a non-monotonic function of the magnitude of asset returns.
Under the SVJ0 model, large moves indicate a jump has occurred, which totally obscures any
information in returns regarding latent volatility for moves in excess of seven standard
deviations. Under the SVJ1 model, the large-move implication that a jump has occurred still
contains some information regarding volatility, given jump intensities are proportional to
latent variance. Neither case, however, resembles the U- and V-shaped GARCH news
impact curves estimated by Hentschel (1995).


Even the SV filtration is not necessarily compatible with GARCH filtrations. In the
stochastic volatility model, the standard deviation of the volatility prior varies stochastically
over time over a range of 1 - 4%, in a fashion that is correlated with but not fully summarized
by the volatility estimate Et Vt . The relative weighting of the information in asset returns
and the volatility prior therefore changes over time in a fashion that cannot be captured by



       7                                                                                       2
        The mean and variance of Vt%1 * t can be derived from those of Vt * t ( κt vt and κt vt ,
respectively) using the moments of the non-central χ2 conditional transition density and the
relationships
                      Et (Vt%1 ) ' Et [E( Vt%1 * Vt ) ]
                    Vart (Vt%1 ) ' Et [Var (Vt%1 * Vt ) ] % Vart [E(Vt%1 * Vt ) ].
                                                                2
The mean and variance of Vt%1 * t%1 are κt%1 vt%1 and κt%1 vt%1 respectively, updated from
(κt , vt ) conditional on the observed asset return using the algorithm in (11) - (13).
                                                20

GARCH specifications. It is an open question as to whether this variable weighting improves
volatility and variance assessments relative to GARCH estimates, and whether it outweighs
the constraints imposed by the affine SV model on the functional form of the news impact
curve. As discussed by Hentschel, GARCH specifications can be quite flexible regarding
that functional form.


The number of jumps on any given day is also a latent variable that can be inferred from
observed returns. It is shown in the appendix that the joint conditional distribution of log-
differenced asset prices and the number of jumps            ∆ N / N(t%1) & N(t) has an affine
                                                                      i ξ ∆ Nt%1
specification. The characteristic function G∆ N (i ξ *Yt%1 ) / E [e                * yt%1 , Y t ] can therefore
be evaluated by Proposition 1.


While it is possible to evaluate the daily probability that n jumps occurred by Fourier
inversion     of   G∆N ,    it   is   simpler    to   estimate        the          number       of    jumps:
E[∆ Nt%1 * Yt%1 ] ' G∆ NN(0 * Yt%1 ) . At the daily horizon, ∆ N is essentially binomial, and the
estimated number of jumps is approximately the probability that a jump occurred.
Unsurprisingly from Figure 6, large moves are attributed to jumps and small moves are not.
Intermediate moves of roughly three to five times the estimated latent standard deviation
imply a small probability that a jump occurred. It is the accumulation of these small jump
probabilities for the moderately frequent intermediate-sized moves that underpin the overall
estimate of jump intensities; e.g., .744 jumps per year in the SVJ0 model.


4. Conclusions and extensions
This article has presented a new methodology for estimating continuous-time affine
processes on discrete-time data: both parameter values and latent variable realizations.
Somewhat unexpectedly, the parameter estimates of an affine stochastic volatility/jump
process on the data set of Andersen, Benzoni and Lund (2002) data base are significantly
different from the ABL estimates. In particular, I find 1) a generally higher volatility of
volatility, 2) a more substantial jump component, and 3) strong support for the hypothesis
that jumps are more likely when volatility is high.


My methodology differs substantially from the SNP/EMM methodology used by Andersen
et al, so the source of divergence is not immediately apparent. It appears that the SNP/EMM
                                               21

methodology may be quite sensitive to precisely how the auxiliary discrete-time SNP model
is specified -- especially in the presence of infrequent large outliers such as the 1987 crash.
Chernov et al (2002) find very different estimates from Andersen et al for the stochastic
volatility model, for a similar data set but a different auxiliary model. My methodology does
not require an auxiliary discrete-time model. The resulting SV estimates are between the two
sets of EMM-based estimates, but are substantially closer to those of Andersen et al.


This article has focused on classical maximum likelihood estimation. However, the recursive
likelihood evaluation methodology presented here can equally be used in Bayesian analysis,
when combined with a prior distribution on parameter values.


More recent research into volatility dynamics has focused on the additional information
provided by alternate data sources: high-low ranges, “realized” intradaily variances, and
implicit variances from option prices. The latter two approaches definitely possess the
requisite affine structure, and can therefore be handled within this framework. For instance,
the joint characteristic function of asset returns, latent variance, and integrated variance has
an exponentially affine form

                                                                    mτ ' t
                                                                      t%1
         Fy, V, V (iΦ, i ψ, i ξ) / E exp iΦ yt%1 % i ψ Vt%1 % i ξ            Vτ dτ   * Vt
                                                                                             (27)
                              ' exp C(iΦ, i ψ, i ξ) % D(iΦ, i ψ, i ξ) Vt

that can be identified by solving the relevant Feynman-Kac partial differential equation.


Such expanded-data approaches are feasible, but are numerically more complex. For
instance, extracting the characteristic function of latent Vt%1 * t%1 from observed ( yt%1, Vt%1 )
requires bivariate integration. Furthermore, it appears from Alizadeh, Brandt and Diebold
(2002) and Andersen, Bollerslev, Diebold and Ebens (2001) that the additional data are
sufficiently informative about latent variance that single-factor models no longer suffice.
The complexities of using additional data sources in conjunction with multi-factor models
of latent variance will therefore be explored in future research.
                                                     22

                                                Appendix
A.1 Joint moment generating functions from continuous-time affine processes
Let
                                                          Φ sT % ψ VT % ξ NT
          F( Φ, ψ, ξ * st , Vt , Nt , t ) / Et [ e                             * st , Vt , Nt ]   (A.1)


be the joint moment generating function of the future variables z T / (sT , VT , NT )
conditional upon observing z t today, where st is the log asset price, Vt is the instantaneous
variance, and Nt is the number of jumps that have occurred. Since F is a conditional
expectation, changes in F are unpredictable:
                                  Et dF( C * st , Vt , Nt , t ) ' 0 .                             (A.2)

Expanding this by the jump-diffusion generalization of Itô’s lemma yields the backwards
Kolmogorov equation that F must solve for a given stochastic process. For the affine
processes in this article, the solution is exponentially affine in the state variables:
        F (Φ , ψ , ξ * st , Vt , Nt , τ )
                                                                                                  (A.3)
                     ' exp [ Φ st % ξ Nt % C (τ ; Φ , ψ , ξ ) % D (τ ; Φ , ψ , ξ ) Vt ]

for τ / T & t .


By Itô’s lemma, the stochastic volatility/jump-diffusion in equation (23) implies a log asset
price evolution of the form
         ds ' [µ0 % (µ1 & ½ ) V & (λ0 % λ1 V ) k ] dt %                    V dW % γ d N
                                                                                                  (A.4)
         dV ' (α & β V ) dt % σ V dWv


where Cov(dW, dWv ) ' ρ dt , Nt is a Poisson counter with jump intensity λ0 % λ1Vt , γ is
                                                            2
normally distributed N[γ, δ2 ], and k / e γ % ½ δ & 1 .                 The corresponding backwards
Kolmogorov equation for F is
            Fτ ' [µ0 % (µ1 & ½ ) V & (λ0 % λ1 V ) k ]Fs % ( α & β V ) FV
                                                      2
                  % ½ V ( Fs s % 2 ρ σv Fs V % σv FV V )                                          (A.5)
                  % (λ0 % λ1 V ) E [ F(C * s % γ, N % 1, V ; τ) & F ]
                                              23

which is solved subject to the boundary condition

                  F( Φ, ψ, ξ * s, V, N; τ ' 0) ' e Φ s % ψ V % ξ N.                            (A.6)

Plugging (A.3) into (A.5) yield a recursive system of ordinary differential equations that
C(τ; C) and D(τ; C) must solve, subject to the boundary conditions C(0; Φ, ψ, ξ) ' 0 and
D(0; Φ, ψ, ξ) ' ψ . The resulting solutions are:
                                                     2
                                                         Φ2
                       E(Φ , ξ ) ' e ξ % γ Φ % ½ δ            & (1 % k Φ)                      (A.7)


                                      ατ
    C (τ ; Φ, ψ, ξ ) ' µ0 Φ T &            ( ρ σ Φ & β & γ ) % λ0 τ E(Φ, ξ )
                                      σ2
                                                                                               (A.8)
          2α                            1 & e γτ                    2α
        &    ln 1 % ½ (ρ σv Φ & β & γ )                           &    ln [ 1 & Κ(Φ, ξ ) ψ ]
          σ2                               γ                        σ2

                               &2 ( µ 1 & ½ ) Φ & Φ²                           Λ(Φ, ξ ) ψ
       D(τ ; Φ, ψ, ξ ) '                                             %
                                                 1%e          γτ             1 & Κ(Φ, ξ ) ψ    (A.9)
                            ρσΦ & β % γ
                                                 1 & e γτ


       γ '      (ρ σ Φ & β ) 2 & 2 σ2 [ ½ Φ2 % ( µ 1 & ½ ) Φ ] % λ1 E(Φ, ξ )                   (A.10)



                                                              2
                                             e γτ % 1
                                                                   & 1
                                             e γτ & 1
                      Λ(Φ, ξ ) '                                                               (A.11)
                                                                         2
                                        e γτ % 1   β & ρσΦ
                                                 %
                                        e γτ & 1       γ

                                                     σ2
                       Κ(Φ, ξ) '                                         .
                                        e γ τ%1                                                (A.12)
                                      γ         % β & ρσΦ
                                        e γ τ&1
                                                          24

The moment generating functions underlying the marginal transition densities of sT , VT , and NT
are of course given by F(Φ, 0, 0 * C ) , F(0, ψ, 0 * C) , and F(0, 0, ξ * C) , respectively.8


Given (A.3), the joint moment generating function of log-differenced prices
y / ∆ s ' ln(St % ∆ t / St ) , number of jumps ∆ N / Nt % ∆t & Nt , and future variance Vt%τ
conditional upon observing Vt is
       Fy, V, ∆N (Φ , ψ, ξ * Vt , ∆ t ) ' exp [ C (∆ t ; Φ , ψ, ξ ) % D (∆ t ; Φ , ψ, ξ) Vt ].   (A.13)

The case of ξ … 0 is used only for inferences about the occurrences of jumps. In variance
filtration and maximum likelihood estimation, ξ is set to zero and the joint transform in
equation (1) is
                     Fy, V (Φ , ψ * Vt , ∆ t ) ' Fy, V, ∆N (Φ , ψ, 0 * Vt , ∆ t ) .              (A.14)

As discussed above and illustrated in Table 1, the joint conditional characteristic function of
( yt%1 , Vt%1 ) conditional upon data Y t observed through time t is

                 Fy, V * t (iΦ , i ψ * Y t ) ' e C(iΦ, i ψ, 0; ∆ t) Gt * t[D(iΦ, i ψ, 0; ∆ t)]   (A.15)


                           ψV t
where Gt * t (ψ) / E e            * Y t is the conditional moment generating function of Vt . As
discussed in Section 2, this is approximated by the gamma MGF Ĝt * t (ψ) / &vt ln(1 & κt ψ) .


A.2 Filtration
Density evaluation and variance updating involves three numerical integrations at each date
t. The density is evaluated by Fourier inversion of (A.15):
                                            1 4
                                           2 π m&4
                                                                        &i Φ yt%1
                       p( yt%1 * t ) '             Fy, V * t [i Φ, 0] e           dΦ .           (A.16)

                                          n
The noncentral moments Et%1 [Vt%1 ] are evaluated by taking analytic derivatives of equation
(13) with respect to ψ :9


   8
    For Φ ' ξ ' 0 , γ ' β , Λ(0, 0) ' e &βτ , and Κ(0, 0) ' ½ σ2 (1 & e &βτ ) / β .
   9
   Numerical derivatives are also feasible, but reduce the accuracy of the numerically
computed log likelihood gradient used in maximum likelihood estimation..
                                                             25


                                                   /0
                         MnGt % ∆ t * t % ∆ t(ψ)
                                                    00
              n
      Et%1 [Vt%1 ]
                                                     0ψ'0
                     '
                                      n
                                 Mψ

                                                                             /0
                                             n
                                          4 M Fy, V * t [i Φ, ψ]
                                                                              00
                             1
                       2 π p( yt%1 * t) m&4
                                                                                      &i Φ yt%1
                                                                                    e           dΦ                  (A.17)
                                                                               0ψ'0
                     '
                                                   Mψ n

                                                                                          /0
                                             n C(iΦ, ψ)
                                          4 M e         Gt * t [D(iΦ, ψ)]
                                                                                           00
                             1
                       2 π p( yt%1 * t) m&4
                                                                                                   &i Φ yt%1
                                                                                                 e           dΦ .
                                                                                            0ψ'0
                     '
                                                        Mψ n

These moments were then used in equations (14) to update next period’s conditional moment
generating function Gt % 1 * t % 1(ψ) .


For each integral, an upper limit Φmax was computed analytically for which truncation error
would be less than ε ' 10&10 . The integral was then computed numerically to 10&10
accuracy using IMSL’s adaptive DQDAG integration routine over (0, Φmax ) .


A.3 Inferring jumps
A similar procedure was used to infer whether a jumps occurred on a given day. From
(A.13), the prior joint characteristic function of ( yt%1, ∆ Nt%1 ) conditional on data through
date t is

               Fy, ∆ N * t (iΦ , i ξ * Y t ) ' e C(iΦ, 0, iξ ; ∆ t) Gt * t[D(iΦ, 0, i ξ ; ∆ t)] .                   (A.18)


Proposition 1 can then be invoked to compute the ex post characteristic function
                                                            iξ ∆ Nt%1
                              G∆ N * t % 1(i ξ) / E [e                  * yt%1, Y t ] .                             (A.19)


The ex post moments of the number of jumps E [(∆Ñt%1)n * Yt%1 ] can be computed
analogously to the approach in (A.17). In particular, since the number of jumps on a given
day is approximately a (0, 1)                      binomial variable, the estimated number of jumps
E [∆ Ñt%1 * Yt%1 ] is approximately the probability that a jump occurred on date t % 1 . Since
the analytic derivatives of (A.18) with respect to ξ are messy, numerical derivatives of
(A.19) were used.
                                                           26


A.4 Outliers
For extreme outliers, p( y) takes on near-zero values (e.g., 2 × 10&22 for the 1987 crash
under the SV model), creating underflow problems for the numerical integration in (A.17).
For such outliers, a scaled density function can be evaluated more accurately. The Fourier
                                                                           (
transform of the scaled density function e a y p( y () of the standardized return
y ( / yt%1 / V̂t*t ∆ t is

         m
                  (                    (                    (
             [e a y p( y () ] e iΦ y dy ' E e (a % iΦ) y

                                                           (a % iΦ) y
                                             ' E exp
                                                                V ∆t                                            (A.20)

                                                           a % iΦ                            a % iΦ
                                             ' exp C                 ,0         Gt * t D                ,0
                                                            V ∆t                                 V ∆t

so the scaled density can be computed by Fourier inversion:


                                             a % iΦ                            a % iΦ
                                 m
             (              1                                                                           (
        e a y p( y ( )'              exp C            ,0        Gt * t D                ,0       e &iΦ y dΦ .   (A.21)
                            2π
                                              V ∆t                              V ∆t

                                                                                   (         (
The density of observed data is then p( y) ' e &a y [e a y p( y ( ) ] / V̂t * t ∆ t .                              The
transformation is the Fourier transform equivalent of importance sampling for low-
probability events in Monte Carlo integration. Similar transformations can be used when
updating the moments of latent variance in (A.17).


No transformation was necessary for * y ( * < 6 , leaving only three observations for which
numerical integration was occasionally problematic: the crashes of 1955, 1987, and 1989.
How fast tail probabilities fall off depends on the model: rapidly for the stochastic volatility
model, slower for jump models. With only three outliers, it was simplest to set the parameter
a on a case by case basis:
       SV:         a = 2 for the 1955 and 1989 crashes, a = 4 for the 1987 crash;
       SVJ0, SVJ1: a = 1 for the 1987 crash, 0 otherwise;
       SVJ2:       a = 0 always.

Experimentation confirmed that density evaluations are insensitive to the precise value of a.
                                            27

                                       References

Alizadeh, Sassan, Michael W. Brandt, and Francis X. Diebold (2002). “Range-based
Estimation of Stochastic Volatility Models.” Journal of Finance 57, 1047-1091.

Andersen, Torben G., Luca Benzoni, and Jesper Lund (2002). “An Empirical Investigation
of Continuous-Time Equity Return Models.” Journal of Finance 57, 1239-1284.

Andersen, Torben G., Tim Bollerslev, Francis X. Diebold, and Heiko Ebens (2001). “The
Distribution of Stock Return Volatility.” Journal of Financial Economics 61, 43-76.

Bates, David S. (2000). “Post-'87 Crash Fears in the S&P 500 Futures Option Market.”
Journal of Econometrics 94, 181-238.

Bates, David S. and Roger Craine (1999). “Valuing the Futures Market Clearinghouse's
Default Exposure During the 1987 Crash.” Journal of Money, Credit, and Banking 31,
248-272.

Chernov, Mikhail, A. Ronald Gallant, Eric Ghysels, and George Tauchen (2002).
“Alternative Models for Stock Price Dynamics.” Journal of Econometrics, forthcoming.

Eraker, Bjorn, Michael Johannes, and Nicholas G. Polson (2000). “Evidence for and the
Impact of Jumps in Volatility and Returns.” University of Chicago working paper.

Fridman, Moshe and Lawrence Harris (1998). “A Maximum Likelihood Approach for Non-
Gaussian Stochastic Volatility Models,” Journal of Business and Economic Statistics 16,
284-291.

Gallant, A. Ronald and George Tauchen (2001). “Simulated Score Methods and Indirect
Inference for Continuous-Time Models.” University of North Carolina working paper.

Hamilton, James D. (1994). Time Series Analysis, Princeton, NJ: Princeton University Press.

Harvey, Andrew, Esther Ruiz, and Neil Shephard (1994). “Multivariate Stochastic Variance
Models.” Review of Economic Studies 61, 247-264.

Hentschel, Ludger (1995). “All in the Family: Nesting Symmetric and Asymmetric GARCH
Models.” Journal of Financial Economics 39, 71-104.

Jacquier, Eric, Nicholas G. Polson, and Peter E. Rossi (1994). “Bayesian Analysis of
Stochastic Volatility Models.” Journal of Business and Economic Statistics 12, 1-19.
                                           28

Johannes, Michael, Nicolas Polson, and Jonathan Stroud (2002). “Nonlinear Filtering of
Stochastic Differential Equations with Jumps.” Columbia working paper, October.

Kim, Sanjoon, Neil Shephard, and Siddhartha Chib (1998). “Stochastic Volatility:
Likelihood Inference and Comparison with ARCH Models.” Review of Economic Studies
65, 361-393.

McCullagh, Peter (1994). “Does the Moment-Generating Function Characterize a
Distribution?” The American Statistician 48, 208.

Nankervis, J. C. and N. E. Savin (1988). “The Exact Moments of the Least-Squares
Estimator for the Autoregressive Model: Corrections and Extensions.” Journal of
Econometrics 37, 381-388.

Pearson, K. (1933). “On a Method of Determining whether a Sample of Size n Supposed to
have been Drawn from a Parent Population Having a Known Probability Integral has
Probably been Drawn at Random.” Biometrika 25, 379-410.

Press, William H., Saul A. Teukolsky, William T. Vetterling, and Brian P. Flannery (1992).
Numerical Recipes in FORTRAN: The Art of Scientific Computing, 2nd edition. Cambridge:
Cambridge University Press.

Ruiz, Esther (1994). “Quasi-Maximum Likelihood Estimation of Stochastic Volatility
Models,” Journal of Econometrics 63, 289-306.

Stambaugh, Robert F. (1999). “Predictive Regressions.” Journal of Financial Economics
54, 375-421.
Table 1: Fourier inversion approach to computing likelihood functions
Let
                                        Φ y % ψ xt%1
               F(Φ, ψ ; yt , xt ) / E [e t%1         * yt , xt ]
                                  ' exp[ C(Φ, ψ ; yt ) % D(Φ, ψ , yt) xt ]
be the (analytic) joint moment generating function of ( yt%1, xt%1 ) conditional upon knowing
( yt , xt ) . Let
                                                                   ψ xt
                                               Gt * s (ψ) / E e           * Ys

be the moment generating function (MGF) of xt conditional on observing data
Y s ' { y1, . . ., ys} . Its initial value G0 * 0(ψ ) ' E [exp(ψ x0) ] (the unconditional MGF of x0 )
has an analytic solution. For a given parameter vector θ, subsequent MGF’s Gt * t and the
likelihood function can be updated via the following recursion:

                     Densities                              Associated moment generating functions
 Conditional density p(xt * t )                                                       Gt * t (ψ)
 Joint density of datum and next                                                                   Φ yt%1 % ψ x t%1
 period’s latent variable                                      Fy, x * t (Φ, ψ) ' Et E e                              * xt
                                                                                              C(Φ, ψ) % D(Φ, ψ) x t
     p( yt% 1, x t% 1 * t )                                                        ' Ee                                  * Yt

           m
       '       p( yt% 1 , xt%1 * xt ) p(xt * t) d xt                               ' e C(Φ, ψ) Gt * t [D(Φ, ψ) ]


                                         Conditional density evaluation
                                                    1 4
                                                   2 π m&4
                                                                                &i Φ yt%1
                               p( yt%1 * t ) '             Fy, x * t [i Φ, 0] e           dΦ


 Updated conditional density of
                                                                                      m&4
                                                                                         4                               &i Φ yt%1
                                      x                                          1
                                                                                             Fy, x *t(i Φ, ψ) e                      dΦ
                        p( yt%1, xt%1 *t%t)1                                     2π
    p(x t% 1 * t % 1) '                                   Gt% 1 * t% 1 (ψ) '
                          p( yt%1 * t)                                                             p( yt%1 * t )



                                                                                                              /0
                                                                                      Mn Gt% 1 * t% 1 (ψ)
                                                                                                               00
                                                                 n
               Noncentral moments of xt% 1 :               E [ xt%1   * t% 1 ] '
                                                                                                                0 ψ' 0
                                                                                                   n
                                                                                             Mψ
Table 2. Estimates on simulated data.
log-differenced returns: yt%1 - N [0, Vt ∆t ] , for ∆ t ' 1 / 252 (one day).
Variance innovations: d V ' (α & β Vt ) dt % σ V dW

1000 sample paths were simulated for data sets of 1,000 - 12,000 days; roughly 4 - 48 years of daily
data. Parameters were estimated by maximum likelihood conditional on observed returns only (first
columns), and conditional on also observing the latent variance realizations (last columns). All
parameters are in annualized units except the half-life of variance shocks HL / 12 ln 2 / β , which
is in months.

Average: Avg(θ̂) ; avg. bias: Avg(θ̂ & θ) ; std. error: Var(θ̂) / 1000 ; RMSE: Avg[(θ̂ & θ)2] .
Corr is the correlation Corr(θ̂, θ̂V ) between the two sets of parameter estimates.

                       Estimates θ̂ from returns only           Estimates θ̂ V if latent variance Vt
              T                                                          were observed
            (days)    α       β        σ       α/β      HL       α      β          σ      α/β    HL
                                                       (mths)                                  (mths)
True value:          0.044    3.25 0.187 0.116           2.56   0.044   3.25 0.187 0.116        2.56
Average: 1000        0.065    4.98   0.196    0.115      2.25   0.055   4.26   0.187   0.116    2.22
Average: 2000        0.053    4.06   0.190    0.116      2.37   0.049   3.74   0.187   0.116    2.40
Average: 4000        0.049    3.65   0.187    0.116      2.45   0.047   3.50   0.187   0.116    2.47
Average: 8000        0.047    3.48   0.185    0.116      2.48   0.046   3.39   0.187   0.116    2.50
Average: 12000       0.046    3.41   0.185    0.116      2.50   0.045   3.34   0.187   0.116    2.52
Avg bias: 1000       0.021    1.73    0.008   -0.001    -0.31   0.012   1.01   0.000   -0.001   -0.34
Avg bias: 2000       0.010    0.81    0.003   -0.001    -0.19   0.005   0.49   0.000    0.000   -0.16
Avg bias: 4000       0.005    0.40   -0.001    0.000    -0.11   0.003   0.25   0.000    0.000   -0.09
Avg bias: 8000       0.003    0.23   -0.002    0.000    -0.08   0.002   0.14   0.000    0.000   -0.05
Avg bias: 12000      0.002    0.16   -0.002    0.000    -0.06   0.001   0.09   0.000    0.000   -0.04
std.error: 1000      0.001    0.11   0.001    0.000      0.05   0.001   0.06   0.000   0.000    0.03
std.error: 2000      0.001    0.06   0.001    0.000      0.03   0.000   0.04   0.000   0.000    0.02
std.error: 4000      0.000    0.03   0.001    0.000      0.02   0.000   0.02   0.000   0.000    0.02
std.error: 8000      0.000    0.02   0.000    0.000      0.01   0.000   0.02   0.000   0.000    0.01
std.error: 12000     0.000    0.02   0.000    0.000      0.01   0.000   0.01   0.000   0.000    0.01
 RMSE:       1000    0.043    3.41   0.046    0.013      1.49   0.022   1.82   0.004   0.013    0.89
 RMSE:       2000    0.023    1.85   0.030    0.010      0.91   0.013   1.13   0.003   0.010    0.69
 RMSE:       4000    0.013    1.07   0.020    0.007      0.69   0.008   0.74   0.002   0.007    0.50
 RMSE:       8000    0.008    0.70   0.014    0.005      0.47   0.005   0.49   0.001   0.005    0.36
 RMSE:      12000    0.007    0.56   0.012    0.004      0.40   0.004   0.39   0.001   0.004    0.29
  Corr:      1000     0.62    0.63    0.13     0.95      0.53
  Corr:      2000     0.64    0.68    0.09     0.97      0.68
  Corr:      4000     0.62    0.71    0.15     0.97      0.71
  Corr:      8000     0.60    0.71    0.10     0.98      0.70
  Corr:     12000     0.61    0.71    0.12     0.98      0.69
Table 3: Model estimates, and comparison with results from Chernov et al (2002) and
Andersen et al (2002). New estimates in bold; other estimates and associated standard errors (in
parentheses) from Chernov et al (2000) and Andersen et al (2002).
Model:
                  dS / S ' (µ0 % µ1 V & λt k ) dt % V dW % (e γ & 1) d N
                        dV '      (α & β V ) dt % σ V dWV
           Corr[dW, dWV ] ' ρ, Prob[dN ' 1] ' (λ0 % λ1 V ) dt, γ - N[γ, δ2 ]
Chernov et al (CGGT) have an additional latent variable for the conditional mean.
Data: ABL and Bates: Daily S&P 500 returns, 1953 - 1996, 11,076 observations, prefiltered.
        CGGT: Daily DJIA returns, 1953 - July 16, 1999; 11,717 observations.
All parameters in annualized units except the variance half-life HL ' 12 ln 2 / β , which is in months.

                         SV                      SVJ0, λ1 ' 0              SVJ1, λ1 … 0
            CGGT       ABL     Bates      CGGT      ABL       Bates   ABL     Bates Bates
    µ0                 .051     .026                 .037      .028   .037     .040      .040
                      (.032)   (.025)              (.045)     (.027) (.095) (.025) (.025)
    µ1                 2.58     3.70                 4.02      3.89   4.03     3.09      3.09
                      (2.82)   (1.98)              (3.89)     (2.19) (5.77) (2.16) (2.16)
     α      1.283      .051     .093       .044      .047      .063   .047     .061      .061
                      (.010)   (.011)              (.013)     (.009) (.017) (.008) (.008)
     β    137.87       3.93     5.94       2.79     3.70       4.38   3.70     4.25      4.25
           (.17)       (.81)    (.81)      (.54)   (1.08)      (.70) (1.71)    (.59)     (.59)
    σ     1.024        .197     .315       .207      .184      .244   .184     .237      .237
          (.030)      (.018)   (.018)      (.02)   (.019)     (.016) (.019) (.015) (.015)
    ρ      -.199       -.597    -.579     -.483     -.620      -.612  -.620    -.611     -.611
          (.000)      (.045)   (.031)      (.10)   (.067)     (.031) (.086) (.031) (.031)
    α / β .096         .114     .125       .125     .113       .120   .113     .119      .119
                               (.004)                         (.004)          (.004) (.004)
    HL       0.06      2.12     1.40       2.98     2.25       1.90   2.25     1.96      1.96
             (.00)     (.44)    (.19)      (.58)    (.66)      (.31) (1.04)    (.27)     (.27)
    λ0                                     1.70     5.09       .744   5.09               .000
                                                    (.43)     (.217) (7.18)             (.000)
    λ1                                                                 .70     93.4      93.4
                                                                    (488.0) (33.4) (33.4)
     γ                                     -.030            -.010              -.002     -.002
                                          (.002)           (.010)             (.006) (.006)
     δ                                     .008    .012     .052      .012     .039      .039
                                          (.001)  (.001)   (.009)    (.001) (.008) (.008)
    ln L             39,192.4a 39,233.9          39,238.0 39,294.8 39,238.0a 39,309.5 39,309.5
                                                         a


a
ABL log likelihoods were evaluated using the ABL parameter estimates and data, and this paper’s
methodology.
 25%


 20%                                   Vt


 15%

              Et Vt
 10%


   5%                                                               SDt     Vt


   0%
         0                 250                 500                 750                1000


Figure 1: Actual and filtered volatility estimates from simulated data, and standard
deviation of filtered estimates.

   6%
   4%

   2%

   0%

  -2%

  -4%

          0                250                 500                 750                1000
Figure 2: Volatility filtration error Et Vt & Vt , and associated [5%, 25%, 75%, 95%]
quantiles. 50% of the errors should fall in the dark gray area; 90% in the dark and light gray
areas.
  0.12



  0.10



  0.08



  0.06



  0.04



  0.02



  0.00
         -4       -3        -2         -1        0         1          2         3         4



Figure 3: Distribution of normalized asset returns N &1[CDF( yt%1 * It )] from the stochastic
volatility/jump model SVJ1, and the theoretical normal equivalents. Not shown on the
graph: one outlier (out of 11,076 observations) with a z-value of -5.52.
   30%
                                                   Et Vt * SVJ1
   20%

   10%

     0%

  -10%
              SVJ1 - SV
  -20%
           53      58       63      68       73      78       83      88       93

Figure 4: Filtered volatility estimate Et Vt from the stochastic volatility/jump model
SVJ1, and divergence from SV volatility estimates.
                                   6%
   SD revision




                                                                                     SV
                                                                                     S V J0
                                   2%                                                S V J1



                 -8      -4               0                4               8
                                  -2%
                      Asset return z, in S D units


Figure 5: News impact curves for various models. The graph shows the revision in assessed
conditional standard deviation, (Et%1 & Et ) Vt%1 , conditional upon observing an standardized
asset return of magnitude z ' yt%1 / Vt * t ∆ t .
