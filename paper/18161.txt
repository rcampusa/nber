                                NBER WORKING PAPER SERIES




                     THE AFTERMATH OF ACCELERATING ALGEBRA:
                     EVIDENCE FROM A DISTRICT POLICY INITIATIVE

                                         Charles T. Clotfelter
                                           Helen F. Ladd
                                          Jacob L. Vigdor

                                        Working Paper 18161
                                http://www.nber.org/papers/w18161


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                      June 2012




We gratefully acknowledge the support of the Institute for Education Sciences and American Institutes
for Research through the Center for the Analysis of Longitudinal Data in Education Research. We
thank seminar participants at Notre Dame, the APPAM annual meeting, the CALDER annual research
conference, the Federal Reserve Bank of New York, the University of Illinois-Chicago, and the Association
for Education Finance and Policy annual meeting as well as Dan Goldhaber, Nora Gordon, Henry
Levin, and Gary Solon for helpful comments. Kyle Ott and Alexandra Oprea provided outstanding
research assistance. The views expressed herein are those of the authors and do not necessarily reflect
the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2012 by Charles T. Clotfelter, Helen F. Ladd, and Jacob L. Vigdor. All rights reserved. Short sections
of text, not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including © notice, is given to the source.
The Aftermath of Accelerating Algebra: Evidence from a District Policy Initiative
Charles T. Clotfelter, Helen F. Ladd, and Jacob L. Vigdor
NBER Working Paper No. 18161
June 2012
JEL No. I21,J24

                                                 ABSTRACT

In 2002/03, the Charlotte-Mecklenburg Schools in North Carolina initiated a broad program of accelerating
entry into algebra coursework. The proportion of moderately-performing students taking algebra in
8th grade increased from half to 85%, then reverted to baseline levels, in the span of just five years.
We use this policy-induced variation to infer the impact of accelerated entry into algebra on student
performance in math courses as students progress through high school. Students affected by the acceleration
initiative scored significantly lower on end-of-course tests in Algebra I, and were either significantly
less likely or no more likely to pass standard follow-up courses, Geometry and Algebra II, on a college-preparatory
timetable. Although we also find that the district assigned teachers with weaker qualifications to Algebra
I classes in the first year of the acceleration, this reduction in teacher quality accounts for only a small
portion of the overall effect.


Charles T. Clotfelter                                    Jacob L. Vigdor
Sanford Institute of Public Policy                       Terry Sanford Institute of Public Policy
Box 90245 Duke University                                Duke University
Durham, NC 27708                                         Durham, NC 27708
and NBER                                                 and NBER
charles.clotfelter@duke.edu                              jacob.vigdor@duke.edu

Helen F. Ladd
Sanford School of Public Policy
Box 90245 Duke University
Durham, NC 27708
hladd@duke.edu
1. Introduction

         In 2008, the California State Board of Education voted to require all students to enroll in

Algebra by 8th grade.1 This policy initiative, yet to be actually implemented, represents the

culmination of a decades-long movement toward offering algebra instruction before the

traditional high school years.2 Nationally, the proportion of eighth-grade students enrolled in

algebra doubled between 1988 and 2007 (Perie, Moran and Lutkus, 2005; Walston and

McCarroll 2010), reaching rates over 50% in three states and the District of Columbia.3 The

movement to offer algebra instruction before high school has been inspired in large part by

correlational research documenting significant differences in later-life outcomes between those

students who enroll in algebra by 8th grade and those who do not.

         Correlation need not imply causation, and it is unclear whether accelerated algebra

enrollment – particularly when not accompanied by complementary curriculum reform in earlier

grades – yields positive or negative effects (Loveless, 2008). This paper provides a quasi-

experimental estimate of the causal impact of accelerating the introduction of algebra

coursework. We analyze a policy initiative introduced in one of the nation’s best-performing

large school districts, Charlotte-Mecklenburg Schools (CMS) in North Carolina, in 2002/03.4

This initiative led students at many points in the initial math achievement distribution to take

Algebra I earlier than they would have before the initiative. After maintaining the acceleration

1 This vote came at the urging of then-governor Arnold Schwarzenegger, who referred to algebra as “the key that
unlocks the world of science, innovation, engineering, and technology. See “California to Require Algebra Taught
in 8th Grade,” USA Today, July 11, 2008; Eddy Ramirez, “8th-Grade Algebra Requirement in California Gets
Sidelined,” U.S. News and World Report, December 29, 2008. Even before this vote, the state led the nation with
59% of all 8th grade students enrolled in Algebra (Loveless, 2008).
2
  See, for example, Usiskin (1987), who cites Japan’s success in teaching algebra to 7th graders. In this paper, we
use the term algebra to refer generically to a content area in mathematics and Algebra I to refer to the course
traditionally taken at the beginning of a college-preparatory math sequence in North Carolina public schools. We
similarly distinguish between Geometry courses and the content area known as geometry.
3
  In 2007, early algebra-taking rates exceeded 50% in California, Maryland, Utah, and the District of Columbia
(Loveless, 2008).
4
  Charlotte-Mecklenburg ranked first among the set of large American school districts with district-specific reports
from the National Assessment of Educational Progress (NAEP) in terms of 4th grade mathematics scores for all test
administrations between 2003 and 2009.
                                                          2
policy for two years, the district reversed course, reverting almost entirely to its previous

placement pattern.5 We use the across-cohort variation in placement patterns created by these

abrupt shifts in policy to infer the impact of acceleration, by comparing students with similar

initial math achievement who were subjected to different placement policies solely on the basis

of their age cohort.

         We examine whether acceleration increased the likelihood that students would stay on

track to pass three college-preparatory math courses – Algebra I, Geometry, and Algebra II –

within six years of beginning seventh grade. Students who do so also meet the North Carolina

State Board of Education’s minimum standards for a college-preparatory course of study.6 We

use standardized end-of-course tests designed by the state to assess performance in each course,

rather than the grade assigned by the course instructor.7

         Our results indicate that Charlotte-Mecklenburg’s acceleration initiative worsened the

Algebra I test scores of affected students and reduced their likelihood of progressing through a

college-preparatory curriculum. Moderately-performing students who were accelerated into

Algebra I in 8th grade scored one-third of a standard deviation worse on the state end-of-course

exam, were 10 percentage points less likely to pass Geometry by the end of 11th grade, and were

neither more nor less likely to pass Algebra II by the end of 12th grade, compared to otherwise

similar students in seventh-grade cohorts that were not subjected to the policy. Similar patterns




5
  As discussed below, the clear negative effects of acceleration may explain why the district reversed course.
6
  The State Board of Education permits a student to substitute a more advanced mathematics course – one using
Algebra II as a prerequisite – for Geometry, or an alternative course sequence labeled Integrated Math I, II, and III
in the state’s official curriculum guide. In practice, the full Integrated Math sequence was not offered by any school
in CMS during the period of study. Note also that admission to the 16-campus University of North Carolina system
for most of the cohorts in our study required additional coursework beyond Algebra II. Thus completion of the
three-course sequence was neither necessary nor sufficient for college admission. Nonetheless, failure to pass
Algebra II effectively guaranteed that a student would not meet state standards for college-readiness.
7
  The state mandates that at least of the course grade in one of these courses be based on the end-of-course score.
See GreatSchools, “Testing in North Carolina,” http://www.greatschools.org/students/local-facts-resources/435-
testing-in-NC.gs, 1/11/12.
                                                          3
are observed among higher-performing students accelerated into Algebra I in 7th grade, and

among lower-performing students accelerated into Algebra I in 9th grade.

        These negative effects could be attributable to transition costs – including the need to

staff an unusually large number of Algebra I courses during the year of acceleration – which

might be expected to dissipate over time. We consider this possibility by examining the

evolution of Algebra I teacher qualifications during the acceleration period, and by considering

the experience of a second North Carolina district, Guilford County, which enacted a similar

acceleration policy and did not reverse it. We conclude that transition costs can explain at most a

small proportion of the overall effect; the main mechanism appears to reflect the opportunity cost

of skipping a year’s worth of pre-algebra mathematics.

        These results directly contradict prior correlational research, thereby casting considerable

doubt on the wisdom of teaching algebra to low-to-moderately performing students in 8th grade.

Although it is undeniable that students who take algebra early tend to do better in subsequent

math courses, this correlation arises because it is usually the strongest students who take algebra

early. Once this selection bias is eliminated, the remaining causal effect of accelerating the

conventional first course of algebra into earlier grades, in the absence of other changes in the

math curriculum, is never positive and in some cases significantly negative. We caution that our

results apply to the impact of varying the timing of the conventional first course in algebra,

holding math instruction in the early grades constant. It is quite possible that more

thoroughgoing reform of the math curriculum, by way of promoting readiness for algebra by 8th

grade, could well prove beneficial.8




8
  See, for example, Burris, Heubert and Levin (2006), who show significant positive effects of a math curriculum
reform that began the acceleration process in 6th grade. Schoenfeld (1995) advocates spreading the teaching of
algebraic concepts throughout the K-12 years.
                                                         4
2. Origins of the Algebra Acceleration Movement

        As suggested by the brief history sketched above, accelerating algebra instruction into

middle school has been promoted as a strategy for improving the mathematics achievement and

college-readiness of American high school students. Nationwide, the proportion of 13-year-olds

enrolled in algebra courses rose from 16% in 1988 to 29% in 2004 (Perie, Moran, and Lutkus,

2005). Among students in the nationally representative Early Childhood Longitudinal Survey

Kindergarten cohort, just over one-third were enrolled in either algebra or a more advanced math

course in 2006/07, when most of the cohort was in 8th grade (Walston and McCarroll, 2010). As

noted above, there is significant variation from this average across jurisdictions.

        This early algebra movement has been bolstered in part by unwarranted causal

interpretation of correlational research. Eighth grade students enrolled in algebra consistently

outscore their counterparts on 8th grade standardized math tests (Walston and McCarroll, 2010).

By the time they reach 12th grade, early algebra-takers have completed more years of advanced

math and attain higher scores on 12th grade math assessments (Smith, 1996). Other research has

documented higher achievement outcomes among students who enroll in algebra at any point in

their secondary school career (Dossey et al., 1988; Gamoran and Hannigan, 2000). Ma (2005a;

2005b) reports that taking algebra in 8th grade is associated with the greatest improvement in

math skills among the lowest-achieving students – particularly those below the 65th percentile of

the 7th grade math distribution. To date, no study has attempted to address concerns regarding

selection into early algebra on the basis of unobserved characteristics.9

        That is not to say there have been no doubters. Concerns about the reliability of previous

studies have provoked a backlash against accelerating algebra into middle school. Opponents of

accelerated algebra argue that too many students enter the course unprepared for advanced work

9
 Ma (2005b), for example, reports that only 4% of students below the 65th percentile of the 7th grade math
distribution are placed in algebra by 8th grade.
                                                         5
and may in fact fall behind their peers who had originally enrolled in less rigorous coursework.

Loveless (2008) documents the poor math performance of some students enrolled in the course

by 8th grade, and he notes the inattention to the problem of selection in prior work justifying the

push to offer algebra in middle school. The Loveless report itself, however, provides no

evidence on the causal question of whether early placement in algebra promotes or retards

mathematics achievement.10 The poorly-performing students he cites may have performed just

as poorly in a more traditional 8th grade math course. An empirical assessment of the effects of

accelerating the first algebra course requires comparison with a counterfactual scenario:

otherwise identical students who take algebra on a traditional schedule.



3. Conceptual Framework

3.1 Algebra timing, mathematics skills, and labor productivity

        From an economic perspective, algebra skills can be valued for two basic reasons. First,

algebra skills may contribute directly to labor productivity.11 Second, algebra skills might serve

as inputs into the production of higher-order mathematical knowledge, which in turn may affect

productivity. It is because of this second function that algebra is sometimes called a “gateway”

to higher mathematics. These two effects on productivity can be summarized in this expression:

(1) y = y(a(ta), h(a, th)),

where y is a measure of productivity, a is a measure of algebra skill, h is a measure of higher-

order mathematical skill, and ta and th measure the amount of time devoted to the study of

algebra and higher-order topics, respectively. All three functions in equation (1) are presumed to

be nondecreasing in their arguments. If students are expected to complete their human capital

10
   Allensworth et al. (2009) provide evidence that a broad multi-subject curricular reform emphasizing placement in
college-preparatory coursework in Chicago high schools led to no significant improvement in test scores or college
entry rates.
11
   Beyond improving labor productivity and earnings, math skills may also increase utility by promoting better
consumption decisions by boundedly-rational agents (Benjamin, Brown, and Shapiro, 2006).
                                                         6
investment by a specific age, the case for accelerating entry into algebra is clear: initiating

algebra earlier allows more time for instruction in both algebra and higher-order topics, thereby

unambiguously increasing productivity.

          Things get more complicated when we introduce the possibility that both algebra and

higher-order math skills rely on the degree to which students have mastered lower-order topics in

mathematics. Consider the formulation:

(2) y = y(l(tl), a(l, ta), h(a, l, th))

where l and tl represent lower-order mathematical skill and the time devoted to learning these

skills, respectively. While we did not introduce an explicit time constraint in our initial

formulation, it makes sense here to assume a fixed amount of time available between school

entry and the end of human capital investment. In this formulation, the opportunity cost of

accelerating introduction to algebra is clear. Indeed, the question of algebra timing reduces to a

matter of how much time to allocate to lower-order subjects. The belief that students enter

algebra too late is equivalent to an argument that too much time is devoted to lower-order subject

matter.

          Equation (2) implies that the optimal allocation of time across mathematical topics

depends on a number of relationships: the relative importance of lower-order skills in the

production of higher-order skills, the marginal impact of time on skill acquisition, and the

relative importance of various types of mathematical skill on productivity. A proposal to

reallocate time away from lower-order skills makes the most sense if lower-order skills are

relatively unimportant in the production of algebra and higher-order skills, and if lower-order

skills are similarly unimportant determinants of productivity.




                                                  7
3.2 The opportunity cost of acceleration

        What kinds of topics are short-changed when algebra is accelerated? To get an idea,

Table 1 describes the key competencies that North Carolina’s standard course of study

establishes for several pre-algebra courses, ranging from 7th Grade Math to Introductory Math,

the course prescribed for students who do not take Algebra I upon entry into high school.12

        The similarity in course objectives across 7th and 8th grade math, and the high school

introductory math course, suggests the possibility of diminishing returns in lower-order

mathematics instruction. The objectives of 8th grade math and Introductory Math are nearly

identical, suggesting that the high school course largely repeats subject matter for students who

did not master it the first time around. Furthermore, the distinctions between 7th and 8th grade

math objectives are minor; eighth graders, for example, are expected to perform computations

with irrational numbers whereas in seventh grade computation with rational numbers is

sufficient.13

        Although a perusal of these stated objectives suggests that pre-algebra courses are

incremental if not redundant, it is possible that many students need repeated exposure to this

subject matter. It is interesting to note, furthermore, that each of the middle-grades math courses

includes significant attention to geometry. Computation of volume and surface area is a key

component of the 7th grade curriculum, and the Pythagorean theorem is mentioned specifically in

the 8th grade curriculum. Both topics also appear in the high school Introductory Math course,

and both relate directly to subjects covered in the state’s official Geometry curriculum, which

focuses in part on right triangles, problems involving surface area and volume, and elementary

proof-writing.



12
   These competencies form the basis for standardized End-of-Grade tests in mathematics conducted since the early
1990s.
13
   A rational number is one that can be expressed as the ratio of two integers.
                                                        8
        Algebra I acceleration is not the only curricular reform designed to improve mathematics

achievement in states around the country. California’s Math A and New York’s Stretch Regents

curriculum exemplify reforms that target the quality of pre-algebra instruction rather than the

timing of algebra coursetaking (White 1995; White et al. 1996; Gamoran et al. 1997).14

Although evidence on the effectiveness of these programs is inconclusive (White et al 1996;

Gamoran et al, 1997), these alternatives may offer promising avenues to improve achievement in

the event that accelerating algebra is judged not to be worth the cost of forgone pre-algebra

instruction (Burris et al. 2006).

        Although relevant to the question of optimal time allocation, the larger question of which

math subjects have the strongest effects on productivity is beyond the scope of our empirical

analysis. In one study pertinent to this issue, Rose and Betts (2004) analyze transcript data from

the High School and Beyond dataset, using straightforward methods to address concerns about

self-selection into higher-order courses. This study suggests that the labor market return to

higher-order coursework is greater than the return to coursework at the level of introductory

algebra or geometry.



4. Data and Methodology

4.1 Setting

        Our analysis makes use of data on students enrolled in the Charlotte-Mecklenburg

Schools (CMS), provided by the North Carolina Education Research Data Center. During the

period covered by our analysis, CMS was the largest school district in North Carolina, and one of

the 25 largest in the United States, serving over 100,000 students. The district is racially diverse;

in 2002/03, the first year of implementation for the Algebra acceleration program we study, 44%
14
  Math A is a high school curriculum used in certain districts used to transition lower achieving students to a
college-preparatory algebra and geometry curriculum. The Stretch Regents program permits students to take New
York State’s rigorous Regents curriculum at a slower pace. See Gamoran (1997) for further description.
                                                        9
of all students were black, 8% were Hispanic, and 4% Asian. About 40% of the district’s

students participated in the federal free and reduced price lunch program, slightly above the state

average.

         Charlotte-Mecklenburg has a strong reputation for mathematics performance. The

district’s fourth grade students ranked first among 18 major school districts in the 2009 National

Assessment of Educational Progress (NAEP) math assessment. It was the only district in this

group with 4th grade math scores significantly higher than the national average. To put this high

performance in context, however, we note that CMS has a larger share of middle class students

than do most large school districts because it is a large county-wide district that includes both

suburban and urban neighborhoods.15

         Beginning around 2002/03, CMS adopted an unusually aggressive policy to accelerate

placement of middle and high school students in Algebra I.16 The district not only broke from its

past patterns of course-taking but also diverged dramatically from policies followed by most

other districts in North Carolina. By all appearances, there were two precipitating factors that

accounted for Charlotte-Mecklenburg’s aggressive approach. First, the state of North Carolina

had increased from three to four the number of math courses required for admission to the

University of North Carolina system. Second, the district’s then superintendent strongly

believed as a matter of pedagogy that algebra should be offered to many, if not most, students in

middle school, rather than waiting until they are in high school. Later described as “a bear on

getting middle school kids in eighth grade to learn Algebra I,” this superintendent announced at

the beginning of the 2001/02 year that his goal would be to increase to 60% the portion of

15
  Ranked by performance of students eligible for federal school lunch subsidies, CMS placed 4th among the 18
districts. Nonetheless, CMS presents a case of algebra acceleration in a large urban district with relatively strong
math performance.
16
  Although we have found no written statement of Charlotte-Mecklenburg’s policy, its existence and influence have
been substantiated by contemporaneous reporting and the recollection of administrators who worked in the system at
the time of implementation.
                                                          10
students in the district who were proficient in Algebra I by the end of eighth grade, as indicated

by scoring at level 3 or above on the state’s end-of-course test.17

         Several other policy changes transpired in CMS during the period of our study. The

districted ceased busing students to desegregate schools in 2002, and implemented a public

school choice plan, incorporating a lottery system for oversubscribed schools the same year

(Hastings, Kane, and Staiger 2005, 2006a, 2006b; Hastings et al. 2007; Deming et al. 2011;

Vigdor 2011). These changes may have led to systematic declines in instructional quality for

African-American and other disadvantaged students (Jackson 2009) that may have confounded

the effects of accelerating algebra in CMS. As we detail below, however, we obtain very similar

results from an analysis of a similarly-timed algebra initiative in North Carolina’s third-largest

school district which did not simultaneously change its busing policy.

         Figure 1 summarizes information on algebra-taking patterns in CMS for five age cohorts

included in this study. It is based on a longitudinal sample of students described in more detail

below.18 For each student, we record the year in which he or she first takes North Carolina’s

end-of-course test in Algebra I.19

         The initial cohort enrolled in 7th grade for the first time in 2000/01, two years prior to the

initiative to accelerate algebra. For this cohort, rates of algebra-taking by 8th grade were high

17
   Educate!, September 16, 2001, p. 5. As evidence of the superintendent’s focus on increasing the number of middle
school students taking algebra, one informant described how he ordered middle school principals to overhaul
schedules after the school year had commenced in order to increase the number of middle school students in algebra
classes. In an interview after he stepped down as CMS superintendent, Eric Smith stated, “The middle school math
piece was the gatekeeper and it is the gatekeeper. It's the definition of what the rest of the child's life is going to
look like academically, not just through high school but into college and beyond. If they make it into algebra one,
the likelihood of getting into the AP class and being successful on the SAT and having a vision of going on to
college is dramatically enhanced. And so our pressure to make sure that kids were given that kind of access to upper
level math in middle school was a critical component of our overall district strategy.” 17
http://www.pbs.org/makingschoolswork/dwr/nc/smith.html, 4/5/11.
18
   Note that all analyses reported in this paper “undo” effects of grade retention by comparing students only to those
in their entering cohort. To be precise, therefore, our analyses study not the impact of taking Algebra I by 8th grade,
but the effect of taking the course within two years of beginning seventh grade.
19
   More precisely, we present the year in which a student first appears as a data point in the Algebra I EOC test file.
A small number of students appear in the dataset but do not have a valid test score. These students are excluded
from analyses using test scores as a dependent variable below, but are included in analyses of subsequent course-
taking.
                                                         11
relative to the national average for high-performing students, but low for low-performing

students. Ninety-seven percent of CMS students in the top quintile of the statewide 6th grade

math score distribution were enrolled in Algebra I by 8th grade, compared to 75% of top quintile

8th graders nationwide, as recorded in the 2009 NAEP assessment (Walston and McCarroll

2010). By contrast, only 3% of CMS students in the lowest 6th grade math quintile had enrolled

in Algebra I by 8th grade, compared to 13% in the national NAEP data.

        The next entering cohort experienced a very different pattern. The rate of early algebra-

taking shifted dramatically at lower points in the distribution. For students around the median,

the likelihood of taking algebra by 8th grade increased from 51% to 85%. For students in the

second-lowest quintile, the rate increased from 18% to 63%. Even in the lowest quintile of the

6th grade math distribution, the rate of Algebra I taking rose to 15%.20

        Just two years after the push to accelerate algebra started, however, the district reversed

course. By the time the cohort that entered 7th grade in 2004/05 had reached middle school,

assignment patterns had reverted to levels below those in the 2000/01 cohort, except in the top

quintile, where a modest amount of acceleration remained in place. This rapid reversal of the

acceleration policy provides us with the first means of distinguishing acceleration effects from

the effects of resegregation and school choice.

        Figure 2 shows that the acceleration policy involved more than pushing students into

Algebra I in 8th grade. For certain students, the likelihood of taking Algebra I by 7th grade also

increased substantially over time. In the 2000/01 cohort, half of top quintile students, 9% of

second quintile students, and 2% of middle quintile students took Algebra I as 7th graders. In the


20
  Our data are derived from end-of-course test records, which may not accurately measure the number of students
assigned to take Algebra I in a given year. Students may withdraw from the course in advance of test
administration, for example. There is some evidence that the rate of withdrawal rose in 2002/03 along with the rate
of course-taking. In that year, an administrative count of course enrollment in Algebra I for CMS enumerates over
900 students for whom we have no test score record. In most other years, the discrepancy between the two sources
of enrollment data is small. We discuss potential implications of this pattern below.
                                                        12
top quintile, the rate of 7th grade Algebra I enrollment rose monotonically, reaching 76% by

2005. In the next highest quintile, the 7th grade Algebra I-taking rate rose to nearly 40% in 2004

before retreating somewhat.

       For students in the lowest two quintiles of 6th grade math test scores, the acceleration

policy had its biggest effect in an increased propensity to take Algebra I by 9th grade. Figure 3

shows a peak among students entering 7th grade in 2000/01, who would have entered 9th grade in

2002/03 – the first year of the acceleration initiative – under normal rates of academic progress.

Over 70% of lowest-quintile students in this cohort had taken Algebra I by 9th grade. But by the

time the 2004/05 cohort came through, only just over a third of students in the bottom quintile

were getting this treatment. Similar fluctuations occurred in the fourth and middle quintiles.



4.2 Data and Sample Selection

       Our data are derived from North Carolina Education Research Data Center longitudinal

records on students who entered 7th grade between 2000/01 and 2004/05 and were “at risk” for

exposure to Charlotte-Mecklenburg Schools’ algebra policy by virtue of being enrolled in that

system in the year under study. For example, when evaluating the impact of exposure to Algebra

I in 8th grade, we focus on those students enrolled in CMS the year after they begin 7th grade.

We restricted the sample to students with valid scores on the state’s standardized 6th grade

mathematics assessment in order to stratify them by prior math performance. We then tracked

progress through college-preparatory math courses using the state’s end-of-course (EOC)

examinations in Algebra I, Geometry, and Algebra II. The size of our sample varies across




                                                13
specifications; in the analysis of acceleration into 8th grade algebra it includes a total of 35,339

students across five age cohorts.21

         By design, the sample includes some individuals who are never observed as enrolling in

Algebra I in our dataset. Thus our analysis may, for some students, confound the effect of

accelerating algebra with the effect of taking it at all. But excluding non-algebra takers from the

analysis might lead us to overstate the negative effects of the acceleration policy, to the extent

the CMS policy change expanded the overall pool of Algebra I takers. In such a scenario,

marginally-performing students would be included in the sample only in the acceleration period.

Results obtained with a sample restricted to “ever-takers” confirms the existence of this bias. 22



4.3 Identification Strategy

         Our estimation strategy takes advantage of the significant policy changes that took place

in Charlotte-Mecklenburg over just a few years. We exploit these changes to estimate local

average treatment effects for taking Algebra I by the time students reach a certain grade. We

begin by examining the effect of taking the course by 8th grade, and we then turn to the effects of

accelerating Algebra I into 7th grade or 9th for students at different points in the initial

achievement distribution. The estimated treatment effects are “local” to that set of students

subjected to differing treatment status across cohorts within our six-cohort sample. For example,


21
   Some of the students included in our sample may exit the dataset because they leave the CMS system, to attend a
different public district, a private or charter school. If such students complete Geometry or Algebra II coursework,
we will incorrectly code them in our analysis. Due to differences in student ID coding between CMS and other
North Carolina districts, we are unable to satisfactorily track students who transfer to a different district or to a
charter school. Moreover, given data limitations it is impossible for us to distinguish a student who attrits from one
who persists without taking EOC exams. This poses a problem for our analysis only to the extent to which transfer
behavior correlates with algebra acceleration, conditional on decile and cohort effects. If parents respond to the
decline in mathematics performance associated with algebra acceleration by switching to a different school district,
we may in fact overstate our results. Note that we are similarly unable to identify students who drop out of school;
since students cannot pass EOC exams after dropping out, however, they are not miscoded.
22
   For example, two-stage least squares analysis of the impact of enrollment in Algebra I by 9th grade using only a
sample of ever-takers produces a coefficient of -1.36, more than twice the value of the estimate provided in the first
column of Table 6 below.
                                                          14
our estimate of the effect of taking Algebra I by 8th grade applies primarily to students in the

middle of the initial test score distribution given that students at the top of the distribution

virtually always take Algebra I by 8th grade, while those at the bottom rarely do.23

         Our basic estimation strategy is a version of differences-in-differences: we compare the

outcomes of students stratified into deciles of initial ability level, as measured by 6th grade math

scores, across cohorts. In order to implement this strategy in a manner that produces local

average treatment effects, we use instrumental variable estimators. The outcome equation is of

the form:

(4) yidc = c + d + Tidc + idc

where yidc is the outcome of interest for student i belonging to initial achievement decile d in

cohort c, c and d are cohort and decile fixed effects, Tidc is an indicator for whether the student

received the treatment – in this case, taking Algebra I by a certain point in their career – and idc

is an independent and identically distributed error term. Cohort fixed effects account for policy

changes or other contemporaneous effects that apply to all students in a cohort, while decile

fixed effects account for broad differences in outcome trajectories for students with differing

initial ability. The use of decile effects rather than a linear control for test score allows us to

account for potentially nonlinear effects of initial ability on later outcomes.

         Prior work in this literature has often estimated single equations along the lines of (4),

arguing that controls for prior achievement adequately correct for unobserved determinants of

the outcome that also correlate with the treatment indicator, implying that  is an unbiased




23
  Our results may have some bearing on the most prominent algebra policy debate, regarding California’s initiative
to require 8th grade algebra. Note, however, that this initiative is most relevant for the bottom 40% of the math
ability distribution in that state, since the rate of 8th grade algebra-taking is already close to 60%. Our estimate of
the effect of 8th grade algebra acceleration pertains more directly to students towards the middle of the ability
distribution. Our results on accelerating low-performing students into 9th grade algebra may provide some
additional insight as to the effects of acceleration in that subset of the population.
                                                          15
estimate of the true treatment effect. To assess this argument, we present OLS estimates of

equation (4) for comparison with our preferred IV results below.

       In our preferred specifications, we address the endogeneity of assignment to an

accelerated algebra class by estimating the first stage equation:

                   10   5
(5) Tidc = c + d +  dc + idc
                  d 1 c 1



where c and d are cohort and decile fixed effects, the dc terms are cohort-by-decile fixed

effects, and idc is a second error term. Predicted values of equation (5) are then used in place of

actual treatment status in equation (4). Effectively, the estimation strategy associates across-

cohort-and-decile variation in the propensity to take Algebra I by a certain grade level with

across-cohort-and-decile variation in the outcome of interest. We attribute a positive (negative)

effect to acceleration if students subjected to a higher probability of earlier algebra than others in

the same initial ability decile in another cohort exhibit superior (inferior) performance in Algebra

I and subsequent math courses. Because the identifying variation in algebra timing is at the

cohort-by-decile level, we cluster standard errors at that level.

       In principle, we would like to estimate the impact of early progression to Algebra I on

performance in that course and subsequent math topics. This goal is complicated by the fact that

many students in our sample never take Algebra I, let alone any follow-up course. Thus, any

effort to estimate the impact of Algebra I timing on performance in that course, in Geometry, or

in Algebra II must contend with a sample selection problem-- namely, that we can observe

performance only for those students who actually take those courses.

       Table 2 illustrates the potential severity of the selection problem, by comparing the

progress of students in two cohorts. Consider first the cohort of CMS students who entered 7th

grade in 2000/01 and took Algebra I for the first time the following year. Because this cohort


                                                  16
arrived before the district’s accelerated algebra push, only 32% of them took Algebra I in 8th

grade. About 93% of them passed the EOC test in the subject, and 85% of them progressed

immediately to Geometry the next year. Most of the non-progressing students retook Algebra I

as 9th graders. About 78% of the 8th grade Algebra I takers in this first cohort took the Algebra II

EOC two years later, and 90% took the Algebra II EOC by the time they would ordinarily have

graduated from high school.

         In contrast, among students entering 7th grade in 2002/03, the first year of the

acceleration initiative, a much higher share, almost half, took Algebra I in 8th grade. The weaker

average quality of this group shows up in lower pass rates. Only 70% of them proceeded to

Geometry the following year, only 64% completed the three-course sequence by the end of 10th

grade, and just 80% finished the sequence by the time they would ordinarily have graduated.24

This worsening record of course completion for the accelerated cohort, presumably caused by the

exit of many lower-performing students, would leave a comparatively strong group of students to

take subsequent courses. The likely result, therefore, would be a positive bias on estimates of the

effect of acceleration on Geometry or Algebra II test scores.

         Table 2 also shows that the overall rate of “ever” taking Algebra I is nearly identical in

the two cohorts. While this might suggest that the acceleration policy had little effect on the

marginal probability of taking Algebra I and only affected timing, recall that members of the

2000/01 cohort would have been exposed to the acceleration initiative as 9th graders. Additional




         24
             The attrition problem illustrated in Table 2 is even more severe among students who take Algebra I at a
later point in time. For students first taking the Algebra I EOC as ninth graders in 2002/03, 66% proceed to take the
Geometry EOC the following year, and 54% take the Algebra II EOC the year after that. Interestingly, this progress
is excessive in relation to the group’s pass rate on the initial Algebra I exam, which is only 48%. These summary
statistics clearly associate the acceleration policy with lower course passage and progression rates. Such a pattern
could conceivably be explained entirely by selection patterns, however. Our IV procedure promises to directly
compare the performance of marginal students assigned to different courses.

                                                         17
analysis of later cohorts who progressed through high school after the acceleration had ended

reveals significantly lower rates of ever-taking.25

         Rather than attempt to estimate a selection-correction model, or use any other procedure

to account explicitly for the selection of marginal students out of the sample of course-takers, we

adopt two strategies. Our first strategy is to redefine our outcome variables such that they are

theoretically observed for all students, whether they enroll in a course or not. Specifically, we

analyze whether students attain a passing grade on a mathematics end-of-course test soon enough

to keep them on track to complete Algebra II within six years of beginning seventh grade.26

Students who never take a course are coded as not having passed that course.

         Because both the outcome and treatment variables are binary, the most appropriate means

of simultaneously estimating equations (4) and (5) is by bivariate probit. In such a case, both yidc

and Tidc can be thought of as latent variables, with the observed binary outcome dependent on

whether the latent variable exceeds a particular value. For ease of interpretation, we also present

two-stage least-squares results.

         Our second strategy for addressing selection into the sample of math course takers

applies to specifications estimating the effect of acceleration on Algebra I test scores, which are,

by definition, unobserved for students who never enroll in Algebra I. We adopt a strategy

derived from Neal and Johnson (1996). We assume that students who never enroll in Algebra I

would have received a test score that was below-average conditional on observables. Under this

25
   Specifically, in the 2004/05 cohort 83.8% of all students in our sample are counted as “ever-takers.” While the
proportion has declined only modestly overall, the decline is more pronounced in the lower deciles of the 6th grade
math distribution.
26
   Our definition of a passing grade on the Algebra I and Algebra II EOC tests is based on the proficiency standard
in place for most of the years in our sample, which was roughly equal to the 20th percentile of the statewide
distribution for both tests. In 2007, the state adopted stricter grading standards on both EOC tests, placing the
passing threshold closer to the 40th percentile of the statewide distribution. By using a uniform standard based on a
specific point in the distribution, we assume that there is no meaningful change in the statewide distribution of
Algebra I or Algebra II test scores over time. As there is no substantial shift in standards on the Geometry EOC test,
no comparable adjustment is necessary. In alternative specifications, we also analyzed the propensity to pass
mathematics courses within a fixed number of years after first taking Algebra I. Results do not vary substantively
across specifications.
                                                         18
assumption, we impute a very low test score for these students, and estimate models based on the

Chernozhukov and Hansen (2007) Instrumental Variable Quantile Regression (IVQR)

estimator.27 Following Neal and Johnson’s logic, when estimating quantile regression the exact

value of the dependent variable need not be observed, so long as it can be safely assumed to be

below the relevant quantile.



5. Results

         We present the results of three related interventions – accelerating certain students into

Algebra I in 7th, 8th, or 9th grade – on Algebra I test scores and indicators for whether students

pass Algebra I, Geometry, or Algebra II on a timetable that will permit them to complete the

sequence by the time they would ordinarily graduate from high school. To set the stage, Table 3

presents the results of simple OLS specifications examining the basic relationship between

Algebra I timing and the four outcomes. These estimates should not be interpreted as causal

effects, even though they include indicators that restrict comparison to students in the same

decile of the 6th grade math test distribution. Even conditional on decile, earlier assignment to

algebra in the cross-section is likely to be correlated with unobserved determinants of math

achievement. Note also that we make no effort here to impute test scores for students who never

take Algebra I, leading to a second source of bias in the estimates.28

         Consistent with earlier studies, our OLS specifications associate earlier placement in

Algebra I with better outcomes. Students who complete Algebra I by 8th grade score 0.18

27
   Specifically, we impute standardized test scores of -4 for non-test takers. This procedure may yield biased results
to the extent that some students without test scores have omitted data for reasons other than failure to take the
course, e.g. transfer into a private school. We report the results of 2SLS specifications, which avoid imputation
problems but introduce sample selection concerns, in footnotes below.
28
   Students who never take Algebra I would presumably earn lower scores on the test if they did, and would also
presumably be less likely to take the course by 8th grade. Note that in addition to students who never take Algebra I,
the test score equation excludes approximately 250 students who appear in EOC test records with a missing value
for the score. These students are included in specifications which impute scores for non-takers below, and are
treated equivalently to non-takers. The EOC data also contain records for students who are coded as exempt from
testing. We exclude these students from all specifications.
                                                         19
standard deviations better on the end-of-course test and are significantly more likely to attain

passing scores on higher-level math exams on a college-preparatory schedule. The probability of

completing the college preparatory sequence, equal to about 50% in our entire sample, is 21

percentage points higher among students who complete Algebra I by 8th grade, conditional on 6th

grade math test decile. Interpreted naively, the apparent advantage associated with early access

to algebra is equivalent to the predicted impact of raising a student’s 6th grade math test score by

more than two deciles in the distribution. To reiterate our previous argument, however, these

OLS estimates, like many prior estimates in the literature, are very likely to be contaminated by

selection bias.



5.1 The impact of 8th grade algebra on moderately-performing students

         We focus primarily on the effects of offering Algebra I in 8th grade to moderately-

performing students, after which we discuss the estimated effects of the other acceleration

patterns in CMS. Table 4 shows instrumental variable estimates of the impact of taking Algebra I

by 8th grade.29 These estimates include IVQR estimates, with imputed test scores for non-

Algebra takers, for models analyzing variation in test scores and two-stage least squares as well

as bivariate probit results for the three binary outcomes. Each model controls for 6th grade test

score decile and cohort fixed effects, and uses a set of cohort-by-decile fixed effects as

instruments. The instruments rely on across-cohort variation in the probability of students in a

given decile taking Algebra I by a specific point in time. First stage results uniformly indicate a

sufficient amount of variation to assuage potential concerns about weak instruments.30



29
   Technically, the dependent variable measures whether a student has taken the Algebra I EOC exam within two
years after beginning 7th grade.
30
   When estimated by 2SLS without imputation, the first stage of the Algebra I test score regression yields an F-
statistic on excluded instruments of 46.0 with a p-value less than 0.0001. The first-stage regressions across all IV
specifications are similar to one another, but the F-statistics vary slightly with changes in sample.
                                                          20
         In three cases out of four, the results contrast starkly with the basic patterns revealed in

our OLS analysis and previous research. Accelerated students score 32% of a standard deviation

lower on their Algebra I end-of-course tests and are significantly less likely to pass courses in

Geometry on a college-preparatory schedule.31 Two-stage least squares estimates indicate that

accelerated students are 10 percentage points less likely to pass the Geometry EOC test within

five years of beginning 7th grade, and are neither more nor less likely to pass Algebra II within

six years.32 Bivariate probit results indicate similarly large effects: a student with a 50% chance

of passing Geometry by the time he or she completes high school at baseline is estimated to have

only a 39% chance of completion if accelerated into Algebra I in 8th grade.33

         The two-stage least squares estimate of the impact of acceleration on passing Algebra I is

positive and statistically insignificant; the bivariate probit coefficient is likewise positive but not

significant. Given that the acceleration apparently reduces students’ Algebra I test scores, the

positive point estimates on passing the course (within four years of beginning 7th grade) suggest

that students retake the test and pass it the second time around. This pattern is consistent with

the basic information in Table 2, which indicates that retaking Algebra I became more

commonplace in the wake of the acceleration initiative. In sum, these results show that cohorts

exposed to Algebra I on the accelerated schedule implemented by Charlotte-Mecklenburg fared

no better, and sometimes significantly worse, in subsequent math courses. This finding is
31
   Estimation by 2SLS, without imputing test scores for non-takers, yields a slightly larger coefficient. Given that
acceleration coincided with an increase in the overall taking rate, this is the expected pattern if marginal Algebra
takers are negatively selected on unobservables. In additional specifications, we examined the effect of algebra
acceleration on the 8th grade end-of-grade mathematics test, which is administered to all 8th grade students regardless
of course enrollment. We found no significant effects, suggesting that any gain to 8th graders from enrolling in
Algebra I are offset by weaker mastery of non-algebraic subjects covered on the EOG test.
32
   The lack of significant impacts in Algebra II may seem incongruous given the Geometry results, given that the
former is usually considered a prerequisite for the latter. Data confirm that CMS often promoted students to Algebra
II when they had failed to receive a passing score on the Geometry exam.
33
   Probit regressions utilize the standard normal distribution to derive predicted probabilities. Individual coefficients
indicate the change in Z-score associated with a one-unit change in the corresponding variable. This change in Z-
score can be converted into a change in predicted probability by first specifying a baseline probability. In general, a
given probit coefficient yields the largest predicted change in probability for individuals with predicted probabilities
near 50% at baseline. Note that the overall probability of passing Geometry for CMS students in our sample is
48.5%. Summary statistics for all dependent variables appears in Appendix Table A1.
                                                          21
consistent with the hypothesis that, by taking Algebra I earlier, these students ended up having

insufficient grounding in pre-algebraic math.34



5.2 The impact of accelerating Algebra I for high and low achievers

         Mirroring Table 4, Tables 5 and 6 examine the impact of accelerating high-performing

students into Algebra I in 7th grade and low-performing students into Algebra I in 9th grade,

respectively. Table 5 omits results for specifications examining whether students pass Algebra I

by 10th grade; the success rate among students subjected to acceleration into Algebra I in 7th

grade is sufficiently high that there is almost no variation in the outcome available to analyze.35

         Accelerated placement into Algebra I in 7th grade was applied primarily to students in the

top two quintiles of the 6th grade math score distribution. Results in Table 5 indicate that the

students receiving this accelerated treatment experienced a decline in Algebra I EOC test scores

comparable to the declines experienced by their counterparts accelerated into Algebra I in 8th

grade.36 Point estimates in course completion specifications differ across the two-stage least

squares and bivariate probit specifications. Bivariate probit results suggest no significant impact

of acceleration on Geometry passage, and a positive significant effect on Algebra II pass rates.

The case for offering Algebra I to high-achieving students in 7th grade thus appears to be

stronger than the case for offering the course to moderate-performers in 8th grade. When

interpreting the bivariate probit results, one must bear in mind that the baseline success rate




34
   In additional specifications not reported here, we find that the negative effects of acceleration on the likelihood of
passing Algebra II are twice as large for boys as for girls. We find a smaller differential effect on Algebra I test
scores and no significant gender differential on other outcomes.
35
   These specifications, available on request, indicate a significant negative effect of acceleration on the propensity
to pass Algebra I by 10th grade. We infer that this effect reflects particularly negative effects on middle-decile
students placed in 7th grade Algebra.
36
   In this case, estimation of the test score regressions by 2SLS rather than IVQR yield a negative coefficient of
nearly four times greater magnitude. This suggests a significant problem of attrition of lower-performing students
from the sample in years where acceleration was not applied to higher-performing students.
                                                           22
among high-performing students is very high, implying that large probit coefficients translate

into relatively small actual effects on predicted probabilities of success.

        At the other end of the spectrum, students accelerated into Algebra I in 9th grade, drawn

primarily from the lowest two deciles of the 6th grade math test distribution, show strong signs of

negative impact. In this group, acceleration is associated with a half-standard deviation decline

in Algebra I EOC scores, significant reductions in the likelihood of passing Geometry, and only

weak evidence of any positive impact. A student with a 50% chance of passing Geometry by

11th grade at baseline is estimated to have a 40% chance if accelerated. The likelihood of

passing Algebra II by 12th grade is higher in the bivariate probit specification, with marginal

significance that is not replicated in the two-stage least squares specification.

        Virtually all CMS students affected by the acceleration initiative exhibited poorer

Algebra I performance as a result. Students with high initial achievement appear to have

suffered only modest subsequent adverse effects, if any. Lower-performing students, even those

placed in Algebra I in the 9th grade rather than the 10th, appear to suffer a significant reduction in

the likelihood of passing Geometry on a college-preparatory timetable. The time path of the

policy, showing the district reversed acceleration for low- and moderately-performing students

but maintained it at the high end, suggests that the district may well have correctly perceived the

pattern of effects.



6. Robustness checks

        These results are derived from a fairly strong identification strategy. We exploit variation

in cohort exposure to acceleration across deciles, as well as the differential actions taken by CMS

after 2004 – maintaining acceleration for some types of students but reversing course for others.

As noted above, however, Charlotte-Mecklenburg undertook other significant policy changes at

                                                  23
the same time as the algebra initiative. Replacing its former practice of busing for racial balance

with a school choice plan could potentially have affected the math performance of some

students.

         To assess this threat to validity, we perform both verification and falsification tests. For

verification, we evaluate an Algebra I placement policy change undertaken by another major

North Carolina school district during the time period covered by our analysis. In these

verification tests, we use two-stage estimators identical to that employed in the analysis of

patterns in CMS.37

         As a falsification test, we examine test score patterns in districts that did not appear to

adopt any significant policy change over this time period, to see if the patterns observed in

Charlotte-Mecklenburg show up, which should not be the case if our estimates for CMS are

indeed the result of the district’s algebra policy. Here we use a two-sample instrumental

variable estimator.38 The first stage is estimated using data from CMS. In the second stage of

this procedure, using data from one of three other districts, we replace information regarding a

student’s Algebra I placement with a variable measuring the likelihood that a student in the same

state test score decile and cohort would be placed in Algebra I by a certain point in time had that

student been enrolled in CMS. This application of two-sample instrumental variables analysis is

nonstandard, in the sense that we do not expect the procedure to produce significant results. In

theory, the instrumental variable is irrelevant in the second sample, and therefore predicted

values based on the instruments should not be correlated with outcomes. When analyzing end-




37
   In this alternative district, we incorporate one additional cohorts’ worth of data, for students entering 7th grade in
1999/2000. This cohort is not available for analysis for CMS because of coding anomalies in that district in the
1999/2000 school year.
38
   Since the bivariate probit model requires observations to be identical in both equations, our falsification tests
exclusively use two-sample-two-stage least squares estimators (Inoue and Solon, 2010). Standard errors are
computed using the method of Murphy and Topel (1985).
                                                            24
of-course test scores, we use a reduced-form version of the IVQR procedure applied to the two-

sample setting.



6.1 Verification test: Guilford County

        The Guilford County school system is the state’s third largest, serving the cities of

Greensboro and High Point as well as surrounding areas. Figure 4 shows that Guilford pursued a

policy of acceleration on a similar timetable to CMS. A student’s likelihood of completing

Algebra I by 8th grade increased substantially between the 2001 and 2002 cohorts. Guilford’s

acceleration was actually more dramatic than that in CMS. Lowest-quintile students in the 2004

cohort were placed in Algebra I in 8th grade at a rate of 36%, twice the maximum rate observed

for that quintile in CMS. Rates of Algebra I placement by 8th grade peaked at 78% in the next-

lowest quintile, and in the middle quintile exceeded 90%. In contrast with CMS, which had

reverted to baseline by the time the 2005 cohort entered 7th grade, Guilford’s acceleration is still

quite apparent in this last cohort.

        Table 7 shows the results of IVQR, two-stage least-squares, and bivariate probit estimates

of the effect of 8th grade Algebra I acceleration in Guilford County. Results here are similar to

those in CMS in many respects. The estimated impact of acceleration on Algebra I EOC test

scores is statistically significant, negative, and slightly larger than the point estimate obtained in

CMS. Two-stage least-squares estimates suggest that acceleration raised the likelihood of

passing Algebra I by 10th grade, though the bivariate probit coefficient is insignificant. Effects

on passing Geometry and Algebra II are uniformly negative and significant. The negative effect

on Geometry passage resembles CMS results, but the Algebra II results present a contrast. This

may reflect the tendency for CMS to promote students to Algebra II even in cases where they did

not first pass Geometry.

                                                  25
         Generally speaking, then, the Guilford results lend support to the conclusion that

accelerating low-to-moderately-performing students into Algebra I in 8th leads to at best

negligible and at worst persistent negative effects on mathematics performance. The Guilford

results particularly assuage the concern that the CMS patterns might reflect the impact of the

nearly-simultaneous cessation of racial busing and move toward school choice. The similarity of

coefficients in CMS and Guilford also factor into our discussion of transitory and permanent

causal mechanisms below.



6.2 Falsification tests

         A proper falsification tests looks for (spurious) evidence of treatment effects in a sample

that was not exposed to the treatment. In this context, we examine the relative performance of

students in the 6th grade test score deciles and cohorts that would have been subjected to

acceleration had they enrolled in CMS, but who attended different districts.

         To ensure this is a valid test, we must first verify that students in other districts were not

in fact exposed to the acceleration policy, or to any other simultaneous initiative affecting the

same deciles in the same cohorts. Table 8 shows that this is in fact a debatable point in two of

the three cases considered here. The results depicted here are derived from individual-level

probit equations of the form:

(6) Tidc   d   c   T̂dcCMS  idc

where Tidc is an indicator for whether student i in cohort c and decile d completed Algebra I by

the end of 8th grade, and T̂dcCMS is the treatment rate for students in the same cohort and decile in




                                                   26
CMS.39 If there were no relationship between placement patterns in student i’s district and those

in CMS, we would expect the coefficient β to be indistinguishable from zero.

         Table 8 presents estimates of β using three alternate school districts. In only one of three

cases – Winston-Salem/Forsyth (WSF) – do we fail to reject the hypothesis that the estimate

equals zero. In Wake County, which is now the state’s largest district, the coefficient is negative

and significant, indicating that the cohort/decile cells subjected to acceleration in CMS were

subjected to deceleration in Wake. In Cumberland County – the state’s fifth-largest district,

serving the Fayetteville area – the estimate of β is in fact larger in absolute value than in Wake

and significant at a similar level.

         As a result of this evidence, we are not fully confident that Wake or Cumberland serve as

valid falsification tests.40 Nonetheless, in Table 9 we report the results of the proposed two-

sample procedure for all three counties.

         The first column of results examines Algebra I test score patterns in the three alternate

districts, using a reduced-form two-sample version of quantile regression with instrumental

variables. Standard errors in these models are underestimated, but based on our experience with

Murphy-Topel (1985) adjustment in later models, we anticipate that adjustment would not alter

the conclusions. The significant negative effects recorded in CMS and Guilford County are not

present here. In fact, the Wake and Cumberland coefficients are statistically significant and

opposite in sign to the CMS result – consistent with the observations in Table 8 above. The

Winston-Salem/Forsyth point estimate is roughly one-tenth the magnitude of the CMS

coefficient and statistically insignificant. These findings support our conclusion from the CMS




39
   Standard errors in these equations are estimated using the Huber-White method for clustering at the cohort/decile
level.
40
   Estimating equation (6) for Guilford County, which by comparison of Figures 1 and 4 appear to have pursued
similar acceleration policies, yields a positive coefficient.
                                                         27
patterns that accelerated students scored significantly worse on the Algebra I EOC exam than

observationally similar counterparts who were not accelerated.

         The remaining columns check the course passage outcomes in the falsification districts.

The general pattern in CMS – weak positive effects for Algebra I, stronger negative effects for

Geometry, and no effects for Algebra II – are not present in any of the comparison districts. In

Winston-Salem/Forsyth, the district that comes closest to being a “true” falsification test, point

estimates are uniformly insignificant. In Cumberland County, which showed the strongest

evidence of subjecting cohorts to the opposite of their counterparts in CMS, point estimates are

universally positive and significant – another indication that deceleration, rather than

acceleration, is most conducive to improving longer-run math performance. Wake County

exhibits a negative significant coefficient only in the Algebra I specification, which does not

match up with CMS results.



7. Potential causal mechanisms

         As noted above, one explanation for our finding that early exposure to Algebra I was

detrimental to students in CMS is that the acceleration caused students to miss important pre-

algebra course material.41 Another explanation is that the district’s need for additional capacity

in Algebra I caused it to sacrifice instruction quality. In the first year of the acceleration

initiative, the district needed to offer algebra instruction to an unusually large group of students –

the last un-accelerated cohort and the first accelerated cohort. Between 2001/02 and 2002/03,

the number of CMS students taking the Algebra I EOC exam increased from under 9,000 to over


41
  In unreported specifications, we find that acceleration had no significant impact on 8th grade end-of-grade test
scores, which all students are expected to take even if they enroll in Algebra I in 8th grade. This suggests that any
negative effects of acceleration on knowledge of non-algebraic concepts are offset by deeper knowledge of algebraic
concepts. We also find no effect of acceleration into 7th grade algebra on 8th grade EOG scores, which would rule
out a “disillusionment” mechanism whereby a negative experience in early testing leads students to reduce their
investment in acquiring new math skills.
                                                         28
11,000. It is important to distinguish between the two alternative explanations for the exposed

cohorts’ observed poor performance – insufficient pre-algebra grounding or decline in

instruction quality.42 The insufficient pre-algebra explanation would imply that a permanent

shift to accelerated algebra would generate the same types of results we observe in Charlotte-

Mecklenburg’s brief policy experiment. In contrast, if the negative impacts are the result of a

temporary fall in instruction quality, the apparent cost of acceleration would be confined to the

phase-in period.43

          The increased demand for Algebra I instruction could have affected the quality of

instruction in many respects. Administrators could have responded by boosting class sizes, by

assigning less-qualified teachers to the course, or by reallocating highly-qualified instructors

away from the subjects they would otherwise teach. Table 10, which tracks the number and

qualifications of Algebra I teachers in CMS over time, shows that administrators avoided the

first type of response. Between 2002 and 2003, the number of Algebra I teachers increased by

roughly 25%, and the number of sections taught per teacher increased by 16%, with no increase

in class size. In fact, the mean class size for Algebra I was slightly smaller in 2003 than it was in

2002.44



42
   Algebra acceleration might invoke a third causal mechanism when it involves placing moderately-performing
students in the same classroom as high-performing students. In such a scenario, the high-performing students might
witness a decline in instruction quality because their teachers must modify their curriculum or pedagogy to
accommodate lower performers. Such a mechanism would actually lead us to understate the negative impact of
accelerating algebra. Students enrolled in early algebra at baseline serve as a control group in our difference-in-
difference identification strategy; any negative effect of the treatment on this group would be miscategorized as an
exogenous trend in our analysis. As our data do not permit the definitive sorting of Algebra I students into
classrooms within schools, we have little opportunity to investigate peer effects.
43
   Although the transition to the accelerated steady-state could have been accomplished in a single year, in practice
enrollments persisted at an elevated level for several years. This reflects the increased rate of Algebra I retaking
occasioned by the drop in performance documented above. The post-acceleration steady state might therefore result
in a permanently higher level of Algebra I enrollment.
44
   Of course, the effect of class size on student learning in secondary schools is uncertain. Experimental evidence
drawn from the early grades suggests that the beneficial effects of small class sizes dissipate rapidly as students age
(Krueger, 1999). On the other hand, survey data indicates that math teachers in secondary schools adopt different
practices in smaller classes (Betts and Shkolnik, 1999). There has been at least one experimental study of the impact
of class size on performance in high school algebra, but the results were statistically inconclusive (Jensen, 1930).
                                                         29
        Table 10 also shows a noticeable decline in teacher quality, as proxied by teacher

qualifications from 2002 to 2003. The average experience of Algebra I teachers, weighted by

enrollment in sections taught, declined from 10.8 years to 8.8 years in 2003. Nearly one-third of

Algebra I students were taught by a teacher with less than three years’ experience in 2003, up

from under a quarter the year before. Licensure test score information, which is available only

for a subsample of teachers, indicates a decline in credentials as well, both on general and

subject-specific tests.

        Table 11 shows the time allocation of teachers who taught at least one Algebra I section

in 2003 and who were also tracked in the state’s personnel system in the prior year. In the

acceleration year, instructors of Algebra I spent less than half of their time teaching that specific

course. The remainder of math teaching time was divided among both less- and more-advanced

courses, ranging from pre-algebra to courses beyond Algebra II. A comparison with teaching

patterns in the prior year reveals that teachers responsible for increasing the district’s Algebra I

capacity did so primarily by teaching fewer sections of pre-algebra, as well as teaching fewer

other subjects including language arts and science. The proportion of time these teachers

devoted to pre-algebra declined dramatically, whereas the proportion of time they devoted to

higher-level subjects held steady or increased. Presuming that administrators tend to assign more

qualified math teachers to higher-level courses, this pattern supports the general impression that

the acceleration was accomplished by shifting less-qualified teachers into Algebra I.

        Could this substitution of less-qualified teachers explain the entire acceleration effect?

Students assigned to novice teachers have been repeatedly shown to exhibit poorer test score

performance than their peers assigned to veterans (Boyd et al. 2008; Clotfelter, Ladd and Vigdor

2007, 2010; Rivkin, Hanushek, and Kain 2005). Suppose that the novice-veteran differential

was 15% of a standard deviation – an estimate at the very high end of the distribution observed

                                                 30
in recent studies. Exposing 8.5% of students to novices would then yield a prediction that test

scores would decline by just over 1% of a standard deviation – a tiny fraction of the test score

effects reported in Tables 4, 5, and 6 above. Additional effects might accrue to the extent that

teacher experience levels decline marginally at other points in the distribution. Most estimates in

the literature suggest, however, that the returns to experience beyond the first few years are

relatively small.

        Many studies of the effect of teachers on student test scores conclude that the observed

credentials of teachers do not readily translate into measures of teacher effectiveness. These

studies typically infer quality on the basis of “value-added” scores, derived from teacher fixed

effects in longitudinal models of student achievement growth.45 Some of these studies report

that the difference between a high-performing and low-performing teacher might be as high as a

full student-level standard deviation (Rivkin, Hanushek, and Kain, 2005; Rockoff 2004).

        To assess the hypothesis that the adverse acceleration effects reported in this study

primarily represent a decline in teacher “value-added,” note that in our test score specifications

point estimates indicate effect sizes of up to half a standard deviation. Such an effect could be

accomplished only if acceleration were accompanied by a substantial substitution of very low-

performing teachers for very high-performing teachers. The data presented in Tables 10 and 11

indicate that 72% of Algebra I sections offered in the acceleration year were taught by a set of

individuals who also led 62% of such sections in the prior year. This discussion implies that the




45
   We are unable to consistently compute “value-added” scores for the Algebra teachers in our sample for a number
of reasons. As indicated above, a substantial number of Algebra teachers have no prior experience. As indicated in
Table 11, Algebra teachers spend no more than one-third of their time teaching that course, and their performance in
other courses is difficult or impossible to assess with test scores. Assessment of performance as a Geometry
instructor is complicated by selection into the course; assessment of performance as a middle school math instructor
is rendered impossible by the absence of student-teacher links in the North Carolina administrative data for middle
school classrooms.
                                                        31
reduction in teacher quality required to explain the estimated adverse acceleration effect is too

large to be plausible. 46

        A comparison of results derived from CMS and Guilford County specifications yields

further evidence that transitory mechanisms explain little of what we observe. In CMS, the rapid

reversal of the acceleration policy implies that roughly half of accelerated students received their

treatment in the phase-in period, when instruction quality may have been compromised. In

Guilford, by contrast, the treatment was offered for a longer period of time, implying that a

smaller proportion of students received it in a transition year. Were transitory mechanisms

largely responsible for the effect, we would expect to see point estimates closer to zero in

Guilford County. As noted above, however, the point estimates are, if anything, more negative

in Guilford County than in CMS.

        Thus, although we find strong evidence that CMS accommodated the surge in Algebra I

enrollment associated with the 2003 acceleration by calling upon teachers with weaker

credentials, the implied reduction in teacher quality is far too small to explain away the entire

negative effect of acceleration on Algebra I test scores. Hence, we interpret our findings in light

of the conceptual model presented above, namely that accelerating students into algebra is

undesirable for many students because it shortens the time for them to master the skills they need

to succeed in algebra and in subsequent math courses.



8. Conclusion

        Algebra is often described as a “gateway” to higher-level mathematics. Because of the

largely hierarchical nature of mathematics instruction, however, the gateway label could equally

46
  Suppose that the set of “new” Algebra I teachers were drawn entirely from the bottom tail of the value-added
distribution, with scores of -0.5. Suppose further that the teachers who cease teaching Algebra I after 2002 were
drawn exclusively from the top tail of the value-added distribution, with scores of 0.5. Assuming the average
quality of teachers leading Algebra I sections in both 2002 and 2003 remained the same, the anticipated effect on
Algebra I test scores would be -0.23 standard deviations, smaller than any observed test score effect.
                                                        32
well be applied to a range of pre-algebra courses, geometry, or any other math subject in the

hierarchy. Moreover, policy makers have often incorrectly interpreted the strong positive

correlation between the timing of Algebra and later outcomes as implying that failure of students

to take the course before high school adversely affects their subsequent ability to enroll in the

higher level math courses needed for college. That interpretation is incorrect because selection

problems make it inappropriate to conclude that the observed correlation reflects a causal

relationship. Our empirical evidence, based on a clear policy intervention affecting nearly the

entire distribution of students in one of the nation’s largest school districts avoids the selection

bias, and shows that early administration of Algebra I – when not preceded by broader reform of

the entire math curriculum – significantly worsens performance in that course and in Geometry,

the typical follow-up course.

        Our results imply, for example, that California’s proposed initiative to increase the

proportion of students taking introductory algebra in 8th grade from 59% to 100%, absent any

wholesale reform in pre-algebra math courses, would worsen rather than improve the college-

readiness of affected students. Our results also cast doubt on assignment practices in school

districts such as the District of Columbia, in which 4th grade math performance is significantly

worse than in CMS, according to NAEP assessments, yet 8th grade algebra placement is the

norm.

        We must be more cautious, however, in evaluating the impact of the past expansion of

enrollment in 8th grade algebra from one-sixth to one-third of the nation’s students over the past

few decades. Presumably, the students affected by this expansion were drawn largely from the

top two quintiles of the math achievement distribution. As Figure 1 shows, our identifying

variation comes almost entirely from students at lower points in the achievement distribution.




                                                  33
Assessing the impact of placing higher-achieving students in algebra in 8th grade would require

observing policy variation within that group.

       The optimal rate for taking algebra by 8th grade is undoubtedly greater than zero. Indeed,

our results indicate that the increase in Algebra I taking among 7th graders in CMS has had no

significant adverse long-term effects. Our evidence also suggests that the optimal rate of 8th

grade algebra-taking, in a population equivalent to that in CMS, is at or below the observed

baseline rate around 50%.

       More generally, this evaluation illustrates the hazards of basing policy initiatives on

simple correlational evidence, without first taking steps to assess the validity of causal

interpretation.



References
Allensworth, E., T. Nomi, N. Montgomery, and V.E. Lee (2009) “College Preparatory
Curriculum for All: Academic Consequences of Requiring Algebra and English I for Ninth
Graders in Chicago.” Educational Evaluation and Policy Analysis v.31 pp.367-391.
Benjamin, D.J., S.A. Brown, and J.M. Shapiro (2006) “Who is ‘Behavioral’? Cognitive Ability
and Anomalous Preferences.” Unpublished manuscript.
Betts, J.R. and J.L. Shkolnik (1999) “The Behavioral Effects of Variations in Class Size: The
Case of Math Teachers.” Educational Evaluation and Policy Analysis v.21 pp.193-213.
Boyd, D., H. Lankford, S. Loeb, J. Rockoff, and J. Wyckoff (2008) “The Narrowing Gap in New
York City Teacher Qualifications and its Implications for Student Achievement in High-Poverty
Schools.” Journal of Policy Analysis and Management v.25 pp.793-818.
Burris, C.C., J.P. Heubert, and H.M. Levin (2006) “Accelerating Mathematics Achievement
Using Heterogeneous Grouping.” American Educational Research Journal v.43 pp.103-134.
Chernozhukov, V. and C. Hansen (2005) “An IV Model of Quantile Treatment Effects.”
Econometrica v.73 pp.245-261.
Clotfelter, C.T., H.F. Ladd, and J.L. Vigdor (2007) “Teacher Credentials and Student
Achievement: Longitudinal Analysis with Student Fixed Effects.” Economics of Education
Review v.26 pp.673-82.
Clotfelter, C.T., H.F. Ladd and J.L. Vigdor (2010) “Teacher Credentials and Student
Achievement in High School: A Cross-Subject Analysis with Student Fixed Effects.” Journal of
Human Resources v.45 pp.655-681.
                                               34
Deming, D.J., J.S. Hastings, T.J. Kane, and D.O. Staiger (2011) “School Choice, School Quality
and Postsecondary Attainment.” National Bureau of Economic Research Working Paper #17438.
Dossey, J.A., I.V.S Mullis, M.M. Lindquist, and D.L. Chambers (1988) The Mathematics Report
Card. Are We Measuring Up? Trends and Achievement Based on the 1986 National
Assessment. Princeton: Educational Testing Service.
Gamoran, A. (1997) “Curriculum Change as a Reform Strategy: Lessons from the United States
and Scotland.” Teachers College Record v.98 pp.608-628.
Gamoran, A. and E. Hannigan (2000) “Algebra for Everyone? Benefits of College Preparatory
Mathematics for Students with Diverse Abilities in Early Secondary School.” Educational
Evaluation and Policy Analysis v.22 pp.241-254.
Gamoran, A., A.C. Porter, J. Smithson, and P.A. White (1997) “Upgrading High School
Mathematics Instruction: Improving Learning Opportunities for Low-Achieving, Low-Income
Youth.” Educational Evaluation and Policy Analysis v.19 pp.325-338.
Hastings, J.S., T.J. Kane, and D.O. Staiger (2005) “Parental Preferences and School
Competition: Evidence from a Public School Choice Program.” National Bureau of Economic
Research Working Paper #11805.
Hastings, J.S., T.J. Kane, and D.O. Staiger (2006a) “Gender and Performance: Evidence from
School Assignment by Randomized Lottery.” American Economic Review v.95 n.2 pp.232-236.
Hastings, J.S., T.J. Kane, and D.O. Staiger (2006b) “Preferences and Heterogeneous Treatment
Effects in a Public School Choice Lottery.” National Bureau of Economic Research Working
Paper #12145.
Hastings, J.S., T.J. Kane, D.O. Staiger, and J.M. Weinstein (2007) “The Effects of Randomized
School Admissions on Voter Participation.” Journal of Public Economics v.91 pp.915-937.
Inoue, A. and G. Solon (2010) “Two-Sample Instrumental Variables Estimators.” Review of
Economics and Statistics v.92 pp.557-561.
Jackson, C.K. (2009) “Student Demographics, Teacher Sorting, and Teacher Quality: Evidence
from the End of School Desegregation.” Journal of Labor Economics v.27 pp.213-256.
Jensen, M.B. (1930) “The Influence of Class Size Upon Pupil Accomplishment in High-School
Algebra.” Journal of Educational Research v.21 pp.337-356.
Krueger, A.B. (1999) “Experimental Estimates of Education Production Functions.” Quarterly
Journal of Economics v.114 pp.497-532.
Loveless, T. (2008) “The Misplaced Math Student: Lost in Eighth-Grade Algebra.” Brookings
Institution Brown Center Report on American Education, September.
Ma, X. (2005a) “Early Acceleration of Students in Mathematics: Does It Promote Growth and
Stability of Growth in Achievement Across Mathematical Areas?” Contemporary Educational
Psychology v.30 pp.439-460.


                                              35
Ma, X. (2005b) “A Longitudinal Assessment of Early Acceleration of Students in Mathematics
on Growth in Mathematics Achievement.” Developmental Review v.25 pp.104-131.
Murphy, K.M. and R.H. Topel (1985) “Estimation and Inference in Two-Step Econometric
Models.” Journal of Business and Economic Statistics v.3 pp.370-379.
Neal, D. and W. Johnson (1996) “The Role of Premarket Factors in Black-White Wage
Differences.” Journal of Political Economy v.104 pp.869-95.
Perie, M., R. Moran and A.D. Lutkus (2005) “NAEP 2004 Trends in Academic Progress: Three
Decades of Student Performance in Reading and Mathematics.” National Center for Education
Statistics Publication 2005-464.
Rivkin, S.G., E.A. Hanushek, and J.F. Kain (2005) “Teachers, Schools, and Academic
Achievement.” Econometrica v.73 pp.417-458.
Rockoff, J.E. (2004) “The Impact of Individual Teachers on Student Achievement: Evidence
from Panel Data.” American Economic Review v.94 n.2 pp.247-252.
Rose, H. and J. Betts (2004) “The Effect of High School Courses on Earnings.” Review of
Economics and Statistics v.86 pp.497-513.
Schoenfeld, A. (1995) “Report of Working Group 1.” in C. Lacampagne, W. Blair, and J. Kaput
(eds.) The Algebra Initiative Colloquium: Papers Presented at a Conference on Reform in
Algebra. Washington: U.S. Department of Education, Office of Educational Research and
Improvement.
Smith, J. (1996) “Does an Extra Year Make Any Difference? The Impact of Early Access to
Algebra on Long-Term Gains in Mathematics Attainment.” Educational Evaluation and Policy
Analysis v.18 pp.141-53.
Usiskin, Z. (1987) “Why Elementary Algebra Can, Should and Must Be an Eighth-Grade Course
for Average Students.” Mathematics Teacher v.80 pp.428-438.
Vigdor, J.L. (2011) “School Desegregation and the Black-White Test Score Gap.” In G.J.
Duncan and R.J. Murnane, eds., Whither Opportunity? Rising Inequality, Schools, and
Children’s Life Chances. New York: Russell Sage Foundation.
Walston, J. and J.C. McCarroll (2010) “Eighth Grade Algebra: Findings from the Eighth-Grade
Round of the Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K).”
National Center for Education Statistics Publication 2010-016.
White, P.A. (1995) Math Innovations and Classroom Practice: Upgrading of the Math
Curriculum at the High School Level. Madison, WI: Consortium for Policy Research in
Education.
White, P.A., A. Gamoran, J. Smithson, and A.C. Porter (1996) “Upgrading the High School
Mathematics Curriculum: Math Course-Taking Patterns in Seven High Schools in California and
New York.” Educational Evaluation and Policy Analysis v.18 pp.285-307.



                                             36
         Table 1: North Carolina Standard Course of Study Competency Goals (2003)
Course                        Competency Goals
                              Understand and compute with rational numbers.
                              Understand and use measurement involving two- and three-
                              dimensional figures.
7th Grade Math                Understand and use properties and relationships in geometry.
                              Understand and use graphs and data analysis.
                              Demonstrate an understanding of linear relations and fundamental
                              algebraic concepts.

                              Understand and compute with real numbers.
                              Understand and use measurement concepts.
8th Grade Math                Understand and use properties and relationships in geometry.
                              Understand and use graphs and data analysis.
                              Understand and use linear relations and functions.

                              Understand and compute with real numbers.
                              Use properties and relationships in geometry and measurement
Introductory Mathematics
                              concepts to solve problems.
(High School pre-Algebra)
                              Understand and use graphs and data analysis.
                              Understand and use linear relations and functions.

                              Perform operations with numbers and expressions (exponents,
                              polynomials).
                              Describe geometric figures in the coordinate plane.
Algebra I
                              Collect, organize, and interpret data with matrices and linear
                              models.
                              Use relations and functions to solve problems.
Source: North Carolina, NC Standard Course of Study, 2003.
http://www.ncpublicschools.org/curriculum/mathematics/scos/2003/k-8/index, 1/12/12.




                                              37
                  Table 2: Progression of math courses for two CMS cohorts
                                                           2000/01 cohort           2002/03 cohort
                                                             (n=7,386)                (n=8,477)
                                          th
Proportion of cohort taking Algebra I in 7 grade               10.1%                    15.5%
Proportion of cohort taking Algebra I in 8th grade              31.9                     46.6


Proportion of cohort ever observed taking Algebra I                 87.8                  87.4

Conditional on taking Algebra I in 8th grade:                        92.7                  80.6
   Proportion passing Algebra I EOC test in 8th grade
   Proportion enrolled in Geometry in 9th grade                      84.9                  69.7
                                            th
   Proportion passing Geometry EOC in 9 grade                        66.4                  46.2
   Proportion enrolled in Algebra II in 10th grade                   78.2                  63.8
   Proportion passing Algebra II EOC in 10th grade                   67.7                  49.5
   Proportion enrolled in Algebra II by 12th grade                   89.8                  79.6
                                                                  th
Note: Cohorts are defined by the year in which they first enter 7 grade. For purposes of
analysis in this paper, grade-repeating students are re-assigned to their original cohort.




                                                 38
               Table 3: Correlates of Math Success Measures: OLS Estimates
Independent variable           Algebra I    Pass Algebra Pass Geometry Pass Algebra
                              Test Scores     I by 10th     by 11th grade  II by 12th
                                                grade                        grade
                           th
Enrolled in Algebra I by 8     0.176***       0.239***        0.141***     0.210***
Grade                           (0.037)        (0.011)         (0.013)      (0.010)
Year entered 7th grade (2000
omitted)
  2001
                                        -0.071*          -0.033***             -0.059***            -0.057***
    2002                                (0.036)            (0.009)               (0.014)              (0.011)
                                      -0.108***          -0.028***             -0.053***            -0.074***
    2003                                (0.035)            (0.009)               (0.014)              (0.011)
                                       -0.086**           -0.016**             -0.046***            -0.055***
    2004                                (0.035)            (0.008)               (0.013)              (0.009)
                                         0.062              0.013                -0.020              -0.026**
    2005                                (0.048)            (0.011)               (0.013)              (0.010)

6th grade math test score
decile (lowest omitted)
                                       0.235***           0.169***             0.036***              0.067***
    Second lowest
                                        (0.050)            (0.018)              (0.012)               (0.011)
                                       0.423***           0.286***             0.087***              0.134***
    Third lowest                        (0.056)            (0.019)              (0.016)               (0.015)
                                       0.587***           0.400***             0.145***              0.213***
    Fourth lowest                       (0.047)            (0.018)              (0.019)               (0.014)
                                       0.801***           0.473***             0.269***              0.290***
    Fifth lowest                        (0.045)            (0.023)              (0.017)               (0.015)
                                       0.982***           0.509***             0.388***              0.385***
    Sixth lowest                        (0.043)            (0.021)              (0.018)               (0.015)
                                       1.219***           0.547***             0.532***              0.460***
    Seventh lowest
                                        (0.050)            (0.019)              (0.018)               (0.014)
                                       1.523***           0.566***             0.666***              0.564***
    Eighth lowest
                                        (0.053)            (0.020)              (0.019)               (0.015)
                                       1.839***           0.576***             0.758***              0.617***
    Ninth lowest
                                        (0.055)            (0.021)              (0.017)               (0.015)
                                       2.463***           0.573***             0.816***              0.663***
    Highest
                                        (0.057)            (0.021)              (0.018)               (0.016)
N                                       32,020             35,339               35,339                35,339
Adjusted R2                              0.606              0.423                0.499                 0.392
Note: Standard errors, corrected for clustering at the decile-cohort level, in parentheses. Algebra I test score is
taken from the student’s first test administration. Course passage is defined as obtaining a standardized test score
at or above the 20th percentile of the statewide distribution for Algebra I and Algebra II, and as obtaining the
state’s official passing score in Geometry. Grade-retained students are kept with their original cohort.
*** denotes a coefficient significant at the 1% level, ** the 5% level, * the 10% level.


                                                          39
                    Table 4: Instrumental Variable Estimates of the Impact of Acceleration into Algebra I in 8th Grade
                        Algebra I Test Score   Pass Algebra I by 10th grade    Pass Geometry by 11th grade     Pass Algebra II by 12th grade

Independent variable    IVQR w/imputation          2SLS             BP             2SLS             BP            2SLS             BP


Enrolled in Algebra I        -0.324***            0.069**          0.046        -0.095***       -0.295***        -0.002           0.057
by 8th Grade                   (0.027)            (0.030)         (0.098)         (0.025)         (0.091)        (0.023)         (0.090)

N                               35,339              35,339          35,339           35,339         35,339            35,339         35,339
Adjusted R2                                          0.407                            0.474                           0.372
Note: Standard errors, corrected for clustering at the decile-cohort level, in parentheses. Algebra I test score is taken from the student’s
first test administration. Course passage is defined as obtaining a standardized test score at or above the 20th percentile of the statewide
distribution for Algebra I and Algebra II, and as obtaining the state’s official passing score in Geometry. Grade-retained students are kept
with their original cohort. All models control for 6th grade math test score decile and cohort fixed effects, and instrument for Algebra I
enrollment by 8th grade using a set of decile-by-cohort indicators. Columns headed “2SLS” are estimated by two-stage least squares;
columns headed “BP” are estimated by bivariate probit. Column headed “IVQR w/imputation” applies the Neal and Johnson (1996)
method of imputing poor performance for 3,319 non-Algebra I-takers and estimating using the Chernozhukov and Hansen (2005) method.
*** denotes a coefficient significant at the 1% level, ** the 5% level, * the 10% level.




                                                                     40
                    Table 5: Instrumental Variable Estimates of the Impact of Acceleration into Algebra I in 7th Grade
                        Algebra I Test Score           Pass Geometry by 11th grade                     Pass Algebra II by 12th grade

Independent variable    IVQR w/imputation              2SLS                     BP                     2SLS                     BP


Enrolled in Algebra I        -0.274***                -0.067*                  0.066                   0.055                  0.228**
by 7th Grade                   (0.028)                (0.038)                 (0.119)                 (0.034)                 (0.112)

N                               37,180                  37,180                   37,180                  37,180                   37,180
Adjusted R2                                              0.459                                            0.353
Note: Standard errors, corrected for clustering at the decile-cohort level, in parentheses. Algebra I test score is taken from the student’s
first test administration. Course passage is defined as obtaining a standardized test score at or above the 20th percentile of the statewide
distribution for Algebra I and Algebra II, and as obtaining the state’s official passing score in Geometry. Grade-retained students are kept
with their original cohort. All models control for 6th grade math test score decile and cohort fixed effects, and instrument for Algebra I
enrollment by 8th grade using a set of decile-by-cohort indicators. Columns headed “2SLS” are estimated by two-stage least squares;
columns headed “BP” are estimated by bivariate probit. Column headed “IVQR w/imputation” applies the Neal and Johnson (1996)
method of imputing poor performance for 4,612 non-Algebra I-takers and estimating using the Chernozhukov and Hansen (2005) method.
*** denotes a coefficient significant at the 1% level, ** the 5% level, * the 10% level.




                                                                      41
                    Table 6: Instrumental Variable Estimates of the Impact of Acceleration into Algebra I in 9th Grade
                        Algebra I Test Score   Pass Algebra I by 10th grade    Pass Geometry by 11th grade     Pass Algebra II by 12th grade

Independent variable    IVQR w/imputation          2SLS             BP             2SLS             BP            2SLS             BP


Enrolled in Algebra I        -0.553***            -0.017          -0.044        -0.191***         -0.262*        -0.016          0.280*
by 9th Grade                   (0.035)            (0.076)         (0.101)         (0.040)         (0.155)        (0.029)         (0.161)

N                               33,553              33,553          33,553           33,553          33,553           33,553         33,553
Adjusted R2                                          0.380                            0.480                            0.401
Note: Standard errors, corrected for clustering at the decile-cohort level, in parentheses. Algebra I test score is taken from the student’s
first test administration. Course passage is defined as obtaining a standardized test score at or above the 20th percentile of the statewide
distribution for Algebra I and Algebra II, and as obtaining the state’s official passing score in Geometry. Grade-retained students are kept
with their original cohort. All models control for 6th grade math test score decile and cohort fixed effects, and instrument for Algebra I
enrollment by 8th grade using a set of decile-by-cohort indicators. Columns headed “2SLS” are estimated by two-stage least squares;
columns headed “BP” are estimated by bivariate probit. Column headed “IVQR w/imputation” applies the Neal and Johnson (1996)
method of imputing poor performance for 2,316 non-Algebra I-takers and estimating using the Chernozhukov and Hansen (2005) method.
*** denotes a coefficient significant at the 1% level, ** the 5% level, * the 10% level.




                                                                      42
                         Table 7: Verification Test using District with Similar Acceleration Policy (Guilford Co.)
                        Algebra I Test Score   Pass Algebra I by 10th grade    Pass Geometry by 11th grade     Pass Algebra II by 12th grade

Independent variable           2SLS                2SLS             BP             2SLS             BP            2SLS             BP


Enrolled in Algebra I        -0.415***           0.109***          0.138         -0.067**       -0.359***       -0.077***       -0.305***
by 8th Grade                   (0.011)            (0.027)         (0.145)         (0.029)         (0.137)         (0.024)         (0.109)

N                               25,831              25,831          25,831           25,831         25,831            25,831         25,831
Adjusted R2                      0.597               0.348                            0.462                            0.322
Note: Standard errors, corrected for clustering at the decile-cohort level, in parentheses. Algebra I test score is taken from the student’s
first test administration. Course passage is defined as obtaining a standardized test score at or above the 20th percentile of the statewide
distribution for Algebra I and Algebra II, and as obtaining the state’s official passing score in Geometry. Grade-retained students are kept
with their original cohort. All models control for 6th grade math test score decile and cohort fixed effects, and instrument for Algebra I
enrollment by 8th grade using a set of decile-by-cohort indicators. Columns headed “2SLS” are estimated by two-stage least squares;
columns headed “BP” are estimated by bivariate probit. Column headed “IVQR w/imputation” applies the Neal and Johnson (1996)
method of imputing poor performance for 1,520 non-Algebra I-takers and estimating using the Chernozhukov and Hansen (2005) method.
*** denotes a coefficient significant at the 1% level, ** the 5% level, * the 10% level.




                                                                      43
                Table 8: Assessing the Validity of Falsification Tests
                           Dependent variable: Enrollment in Algebra I by 8th grade
                                Wake               Forsyth               Cumberland
                               County               County                 County
Independent variable          (Raleigh)        (Winston-Salem)          (Fayetteville)
Proportion of CMS
students in same              -0.437**               0.365                -0.700**
cohort/decile who take         (0.201)              (0.353)                (0.341)
Algebra I by 8th grade
N                              35,076               15,192                 16,074
Note: Equations are estimated by probit and include cohort and decile fixed effects.
Standard errors, corrected for clustering at the cohort/decile level, in parentheses.
** denotes a coefficient significant at the 5% level.




                                          44
                    Table 9: Falsification Tests using Three Alternate Districts
                th
Coefficient on 8                                     Dependent Variable
grade Algebra I-        Algebra I test     Pass Algebra I      Pass Geometry      Pass Algebra II
                                                  th                  th
taking rate in same          score          by 10 grade         by 11 grade         by 12th grade
decile/cohort, CMS
in:
Wake County               0.213***            -0.049**             -0.034              -0.006
N=35,076                   (0.006)             (0.022)             (0.025)             (0.027)
Forsyth County               0.084              -0.044             -0.028               0.009
N=15,192                   (0.031)             (0.037)             (0.038)             (0.041)
Cumberland County           -0.036             0.104**            0.093**            0.126***
N=16,074                   (0.054)             (0.041)             (0.040)             (0.044)
Note: Standard errors in parentheses. Test score equation estimated using a reduced-form
instrumental variable quantile procedure; standard errors unadjusted. Remaining equations
estimates by TS2SLS, with standard errors computed using the Murhpy-Topel (1985) method, as
applied to two-sample two-stage least squares by Inoue and Solon (2010).
*** denotes a coefficient significant at the 1% level, ** the 5% level, * the 10% level.




                                              45
             Table 10: Algebra Teacher Characteristics by School Year, Charlotte-Mecklenburg Schools
                                  1999/2000      2000/01        2001/02       2002/03      2003/04           2004/05
Number of Unique Teachers              183          222           198           249          228               228
Number of Sections per Teacher        2.038        1.905         2.051         2.378        2.232             2.031
Number of Students per Teacher        43.71        40.68         43.90         49.01        47.84             43.36
Enrollment-weighted mean characteristics
  Years of Experience                 11.23        10.56         10.82         8.768        9.895              10.52
  2 or Fewer Years’ Experience      20.99%        26.85%        23.10%        31.57%       24.91%             27.14%
  General Licensure Scores            0.217        0.183         0.138         0.097        0.217              0.100
    Number of Teachers with            165          192           171           214          195                203
    General Scores
   Math Licensure Scores               0.639         0.603          0.539         0.453         0.417          0.333
    Number of Teachers with              33            42            35             58            48             42
    Math Scores
Note: Licensure test scores are standardized to have mean zero and standard deviation one for teachers taking the same
test in the same year.




                                                             46
    Table 11: Teacher Time Allocation in Charlotte-Mecklenburg Schools, 2001/02-2002/03

                                               2002/03                          2001/02
Subject Areas                         Teacher                        Teacher
                                                      Percentage                     Percentage
                                      Sections                       Sections

Mathematics                             961              79.1%         838                72.9%

   Pre-Algebra & Lower Level            198              16.3%         393                34.2%

   Algebra I                            428              35.2%         251                21.8%

   Geometry                              66              5.4%           58                5.0%

   Algebra II & Higher Level             79              6.5%           62                5.4%

   Other Mathematics                    190              15.6%          74                6.4%

Language                                163              13.4%         201                17.5%

Science                                  34              2.8%           48                4.2%

Social Studies                           26              2.1%           31                2.7%

Other Subjects                           31              2.5%           31                2.7%

Total Observations                      1215             100%         1149                100%

Note: Sample consists of teachers assigned to at least one section of Algebra I in 2002/03 who
also appear in CMS course assignment records for 2001/02. “Other Mathematics” includes
Technical Math I & II, Discrete Math, Integrated Math I & II, and Special Topics in
Mathematics. “Other Subjects” includes computer science, health and physical education,
vocational education, non-classroom activities (such as SAT preparation) and miscellaneous.




                                                 47
 100%

  90%

  80%

  70%

  60%                                                                             2000/01
                                                                                  2001/02
  50%
                                                                                  2002/03
  40%                                                                             2003/04
                                                                                  2004/05
  30%

  20%

  10%

   0%
           Quintile 1   Quintile 2    Quintile 3        Quintile 4   Quintile 5


Figure 1: Probability of taking Algebra I by 8th grade, by 6th grade math test score quintile and
year entering 7th grade, Charlotte-Mecklenburg Schools.




                                                   48
 100%

  90%

  80%

  70%

  60%                                                                             2000/01
                                                                                  2001/02
  50%
                                                                                  2002/03
  40%                                                                             2003/04
                                                                                  2004/05
  30%

  20%

  10%

   0%
           Quintile 1   Quintile 2    Quintile 3        Quintile 4   Quintile 5


Figure 2: Probability of taking Algebra I by 7th grade, by 6th grade math test score quintile and
year entering 7th grade, Charlotte-Mecklenburg Schools.




                                                   49
 100%

  90%

  80%

  70%

  60%                                                                             2000/01
                                                                                  2001/02
  50%
                                                                                  2002/03
  40%                                                                             2003/04
                                                                                  2004/05
  30%

  20%

  10%

   0%
           Quintile 1   Quintile 2    Quintile 3        Quintile 4   Quintile 5


Figure 3: Probability of taking Algebra I by 9th grade, by 6th grade math test score quintile and
year entering 7th grade, Charlotte-Mecklenburg Schools.




                                                   50
 100%

  90%

  80%

  70%
                                                                                  1999/00
  60%
                                                                                  2000/01
  50%                                                                             2001/02
                                                                                  2002/03
  40%
                                                                                  2003/04
  30%                                                                             2004/05

  20%

  10%

   0%
           Quintile 1   Quintile 2    Quintile 3        Quintile 4   Quintile 5


Figure 4: Probability of taking Algebra I by 8th grade, by 6th grade math test score quintile and
year entering 7th grade, Guilford County Schools.




                                                   51
                  Table A1: Summary Statistics for Dependent Variables
School District       Algebra I test Pass Algebra I Pass Geometry Pass Algebra II
                           scores        by 10th grade      by 11th grade     by 12th grade
CMS                        -0.093
                                             72.1%              47.0%            51.9%
                          (1.053)
Wake County                 0.520
                                             81.4%              63.0%            65.3%
                          (0.987)
Guilford County           -0.226
                                             77.1%              48.1%            54.7%
                          (1.029)
Forsyth County            -0.046
                                             71.7%              46.2%            49.9%
                          (1.032)
Cumberland                -0.143
                                             65.1%              39.4%            43.2%
County                    (0.920)
Note: In each district, sample is restricted to those students observed consistently for a
period of 6 years beginning in 7th grade, and who take Algebra I at some point during this
period. Mean and standard deviation reported for test scores, sample proportion for all
other variables.




                                                52
