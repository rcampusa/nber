                            NBER WORKING PAPER SERIES




                 TREATMENT EFFECTS WITH MULTIPLE OUTCOMES

                                       John Mullahy

                                    Working Paper 25307
                            http://www.nber.org/papers/w25307


                    NATIONAL BUREAU OF ECONOMIC RESEARCH
                             1050 Massachusetts Avenue
                               Cambridge, MA 02138
                                  November 2018




I am grateful to Domenico Depalo, Paddy Gillespie, Hyunseung Kang, Chuck Manski, and
participants in presentations at Queen's University Belfast, the University of Bergamo, the
University of Chicago, and the University of Wisconsin-Madison for helpful comments,
suggestions, and guidance on the literature. Partial support was provided by the Robert Wood
Johnson Foundation (Evidence for Action Grant 73336), and by the UW-Madison Center for
Demography and Ecology (NICHD grant P2CHD047873). The views expressed herein are those
of the author and do not necessarily reflect the views of the National Bureau of Economic
Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2018 by John Mullahy. All rights reserved. Short sections of text, not to exceed two
paragraphs, may be quoted without explicit permission provided that full credit, including ©
notice, is given to the source.
Treatment Effects with Multiple Outcomes
John Mullahy
NBER Working Paper No. 25307
November 2018
JEL No. C18,D04,I1

                                          ABSTRACT

This paper proposes strategies for defining, identifying, and estimating features of treatment-
effect distributions in contexts where multiple outcomes are of interest. After describing existing
empirical approaches used in such settings, the paper develops a notion of treatment preference
that is shown to be a feature of standard treatment-effect analysis in the single-outcome case.
Focusing largely on binary outcomes, treatment-preference probability treatment effects (PTEs)
are defined and are seen to correspond to familiar average treatment effects in the single-outcome
case. The paper suggests seven possible characterizations of treatment preference appropriate to
multiple-outcome contexts. Under standard assumptions about unconfoundedness of treatment
assignment, the PTEs are shown to be point identified for three of the seven characterizations and
set identified for the other four. Probability bounds are derived and empirical approaches to
estimating the bounds—or the PTEs themselves in the point-identified cases—are suggested.
These empirical approaches are straightforward, involving in most instances little more than
estimation of binary-outcome probability models of what are commonly known as composite
outcomes. The results are illustrated with simulated data and in analyses of two microdata
samples. Finally, the main results are extended to situations where the component outcomes are
ordered or categorical.


John Mullahy
University of Wisconsin-Madison
Dept. of Population Health Sciences
787 WARF, 610 N. Walnut Street
Madison, WI 53726
and NBER
jmullahy@facstaff.wisc.edu
1. Introduction
         Obtaining a clear picture of the effect of a treatment or intervention on a single outcome of
interest can be daunting. Familiar challenges include treatment-effect heterogeneity, confounded or
endogenous      treatment   assignment,   and   generalization   from   experimental   to   population
circumstances. Many now-familiar strategies to mitigate the estimation biases that can arise from
such challenges have been developed, and still more are evolving.1
         The challenges proliferate when multiple outcomes are of interest. Even if the obstacles
noted above are absent, the simple notion of what is meant by "a treatment effect" is no longer
obvious when two or more outcomes are of concern. This paper's main goals are to develop an
integrated framework for understanding treatment effects with multiple outcomes, to determine
how features of the population distribution of such treatment effects might be identified, and to
suggest empirical approaches to learning from data about these features.


Multiple Outcomes
         The existing literature on treatment effects (TEs) offers only limited guidance for
understanding multiple outcomes. Abadie and Cattaneo, 2018, note that "in practice, researchers
may be interested in a multiplicity of treatments and outcomes," but then conduct their analysis
treating both treatment (their W) and outcome (their Y) as scalar random variables. Athey and
Imbens, 2017, recognize explicitly multiple-outcome contexts, but do so largely with regard to
multiple-testing problems.2 Manski and Tetenov, 2018, consider optimizing clinical trial sizes when
multiple outcomes are of interest. Athey et al., 2016, assess how multiple surrogate outcomes can
inform understanding of treatment effects.
         Such limited scope is unfortunate as considerations of multiple outcomes arise broadly in
empirical work. In health and clinical research multiple outcomes are often commonplace when
measuring some population's health status or health behaviors, or when attempting to understand
their determinants. Buttorff et al., 2017, consider how chronic conditions vary across the U.S. adult
population. Hoynes et al., 2015, explore how public policies affect multiple infant-health outcomes.
Ludwig et al., 2011 and 2013, use data from the Moving to Opportunity experiment to assess how
residential changes affect physical and mental health outcomes. Pesko et al., 2016, consider how
regulations may affect use of cigarettes, e-cigarettes, and nicotine replacement therapy.


1
    See Imbens and Wooldridge, 2009, for a valuable review.
2
 While some research has considered TEs in multiple-treatment contexts (e.g. Angrist and Imbens,
1995), this is unrelated to the multiple-outcome contexts considered here. That said, Appendix B
considers briefly extensions of this paper's results to contexts involving more than two treatments.




                                                   1
         Multiple outcomes are also frequently involved in studies of clinical populations.3 Prominent
in cardiovascular and diabetes research, for instance, are clinical trials that focus on multiple
outcomes such as mortality, stroke, myocardial infarction, and hospital readmission, often
aggregated into composite outcomes (e.g. Look AHEAD Research Group, 2013; Parving et al.,
2012; Rosenfield et al., 2016).4 Beyond serving as primary or secondary outcomes in such clinical
research, multiple outcomes are often studied in the form of treatment-specific adverse events. For
example, Parving et al., 2012, report the rates of 21 adverse events potentially affecting subjects in
the two arms of their study of diabetes treatments. In some instances a study may examine a single
primary outcome and a single adverse event or safety outcome, as such examining data having a
multiple-outcome character. In their study of transcatheter mitral-valve repair, for instance, Stone
et al., 2018, focus on hospitalization for heart failure within 24 months of follow-up as their
primary outcome and device-related complications at 12 months as their main safety outcome.
         Healthcare quality measurement is another research and policy area where consideration of
multiple outcomes is of central interest. For example Cebul et al., 2011, consider how clinical
practices' electronic health record use is related to four measures of care-process quality and five
measures of patient outcomes (see also IOM, 2006, and Shwartz et al., 2015).
         Beyond health and health care, considerations of multiple outcomes arise in contexts as
diverse as welfare and poverty (e.g. multiple deprivations, Nolan and Whelan, 2010), education
(e.g. school accountability, Loeb and Figlio, 2011; teacher quality, Jackson, 2018), nutrition (e.g.
food security, Coleman-Jensen et al., 2018), finance (e.g. financial-institution soundness, FDIC,
1997), and many others.
         For the most part the wide array of data structures mentioned in the preceding paragraphs
falls within this paper's scope. While the strategies proposed here will not necessarily be suited for
understanding treatment effects related to all multiple-outcome contexts they will likely be
applicable to many, even if the study of such outcomes has not traditionally been approached in
the manner suggested below. While in many instances the focus of a multiple-outcomes analysis
will be on subjects whose relevant outcomes at a point in time are summarized by an M-component
vector, the analytics described here accommodate other multiple-outcome contexts. For example,
the M outcomes may also be a univariate outcome characterizing each subject over M time
periods,5 or an M'-dimension outcome for each subject over T time periods with T×M ' = M , i.e.

3
    See Manski, 2018, for an assessment of medical decisionmaking under uncertainty.
4
    Composites are considered in section 5 and in an in-progress companion paper (Mullahy, 2018b).
5
 For example, in their study of treatments for episodic migraine Stauffer et al., 2018, use a binary
"migraine headache day" outcome, a univariate outcome measured daily over the follow-up period.




                                                   2
multiple-outcome panel data (see also footnote 26). The key in any case is that outcomes can be
imagined arising under alternative treatments, interventions, or policies.


Understanding Treatment Effects with Multiple Outcomes—Existing Approaches
          Given such outcome data some questions naturally arise, perhaps most prominent being:
How does one conceptualize a TE, or perhaps a set of TEs, when studying multiple outcomes?
          To provide context for the paper's main analysis, suppose one observes M binary outcomes
y = ⎡⎢ y1,…, yM ⎤⎥ and a vector of covariates x = ⎡⎢ x T, x oth ⎤⎥ , where x T measures exogenous scalar
     ⎣           ⎦                                 ⎣             ⎦
treatment and x oth are other exogenous covariates. 6 With such data at least three analytical

strategies for estimation of average treatment effects (ATEs) have been prominent in practice.
        In the first,7 separate ATEs are estimated for each of the M components y m of y based on

estimates of some parametric or nonparametric probability model


             (              )
          Pr y m = 1 x = p m (x) ,   m=1,…,M.                                                (1)


Strategies like this result in estimates of M separate ATEs.8
                                                        M
          A second approach9 treats the sum sy = ∑ m=1 w m y m as a continuous, ordered, or count

outcome, and considers parametric or nonparametric models for its conditional mean


          E ⎡⎢sy   x ⎤⎥ = µ s (x)                                                            (2)
             ⎣        ⎦


and/or conditional probability structure




6
    The notation will be formalized in sections 2 and 3.
7
 See, e.g., Sarma et al., 2015. Only sometimes are multiple testing issues addressed; see Romano et
al., 2010, and Dmitrienko and D'Agostino, 2018.
8
    That the effects may be heterogeneous due to x oth and to unobservables is in general an
important consideration but one that will be ignored in this paper.
9
  See, e.g., Dodge et al., 2014, Hanssen et al., 2014, Jackson, 2018, Khan et al., 2008, Siebert et al.,
2016, and Walitt et al., 2016, for a sampling of approaches that have been used. These include
linear and ordered-outcome regression, count-data models (e.g. Poisson, negative binomial), and
others. Note that the weighted-sum construct includes approaches like principal components.




                                                    3
             (        )
          Pr sy = n x = ps (n, x) .                                                       (3)


This approach might yield a single ATE estimate or a set of ATE estimates across the values of n.
          A third approach10—one that will be seen in section 5 to be of particular interest in this
                                                                          (      )
paper—is in essence a coarsening of sy into a binary outcome, i.e. 1 sy ≥ t , where t is some

relevant threshold or cut point. Binary measures like this are encountered often in health and
clinical research as one form of so-called composite outcomes. Two important cases are t=1 ("any")
and t=M ("all"). 11 To understand such outcomes analysts typically specify and estimate some
parametric or nonparametric conditional probability model


             (        )
          Pr sy ≥ t x = pc (x)                                                            (4)


on which estimates of ATEs are based.12,13
          To anticipate some of what follows, it is useful to consider specifically how one would use
ATE estimates like those described in the preceding paragraphs to arrive at a conclusion that one
treatment ( x T ) is "better than" or "preferable to" a comparator treatment ( x T ' ). When an

approach like (1) is used, the analyst must consider how to draw a conclusion or inference from M
separate estimates that have been obtained. When an approach like (2) is used, the analyst may
determine that any particular conclusion about treatment superiority could depend on the manner
in which the outcomes are weighted (or on the fact that they are implicitly weighted the same
when all the w m are the same). When an approach like (4) is used, the analyst might recognize

that conclusions depend on the particular threshold that is selected. The strategies pursued in this
paper will be seen, for the most part, to circumvent these concerns.

10
     See, e.g., Geronimus et al., 2006, and Fleishman et al., 2014.
11
  Many of the studies summarized in the previous subsection use some form of composite outcome
(see U.S. FDA, 2017, Mullahy, 2018b, and the discussion in this paper's section 5).
12
     A fourth approach is to consider simultaneously the entire portfolio of outcomes y, model its
                                     ( )
joint probability structure Pr y x , and estimate ATEs corresponding to some or all of its 2M

                          (      )
particular values Pr y = q x . Investigation of this approach is underway.

13
  In each of the cases described here the ATE would often be estimated by something akin to the
difference between the estimated conditional-on-x probability or moment model evaluated at two
different values of x T and then averaged over x oth .




                                                     4
This Paper's Strategy
       The paper's main strategy is to adapt for and adopt in multiple-outcome settings an
underappreciated interpretation of familiar ATEs from the single-outcome context. While not
typically invoked, this interpretation turns out to be fundamental to standard ATE definitions in
the single-binary-outcome case. It is generalized here to provide a unified framework for considering
population treatment effects when multiple outcomes are considered.
       For any M≥1, the approach suggested here results in population-level statements about
TEs akin to how ATEs in the single-outcome context summarize individual TEs across a
population. It will be shown that the TE parameter proposed here, termed a treatment-preference
probability treatment effect, or PTE, is essentially no different in the multiple-outcome and single-
outcome contexts except that—under unconfounded treatment assignment—the PTE is point
identified in the single-outcome case whereas in the multiple-outcome case some characterizations
permit point identification while for others only partial or set identification is possible.
       The approach proposed here for the multiple-outcome case has several attractive features.
Except for a benchmark case that is developed as a link to some existing empirical practice, this
paper's strategies require neither any across-outcome measurement comparability14 nor any relative
weighting of the outcomes; indeed, no equal or differential weighting of the outcomes is implied.
More generally, the approach proposed here requires no aggregation of outcomes per se. If inference
is of concern (the paper's focus is largely on definition and identification, although see footnote 37),
no issues of multiple testing arise since the relevant parameters are ultimately scalar. Finally, once
the relevant parameters are point or set identified computation is straightforward in most
instances, with empirical computation generally requiring nothing more than specification and
estimation of binary-outcome probability models (defined and discussed in section 5).
       A cost of this approach is that decisionmakers must adopt one or more characterizations of
treatment preference, an exercise akin to specifying what loss or value function is germane for the
decision at hand. Seven such characterizations are suggested here, although others are imaginable.
It is shown in section 2 that a particular notion of treatment preference is implied in considerations
of ATEs in the single-outcome case. As such the demand that the decisionmaker adopt such a
standard in the multiple-outcome case does not seem unreasonable even though, because of its
simplicity, the decisionmaker is not explicitly confronted with such a decision when M=1.
       While the focus here is largely on empirical issues the paper's emphases on treatment


14
  Comparability of measures in the binary-outcome case might seem, and indeed might be, trivially
satisfied (although see footnote 20). Such considerations are more salient in the ordered-outcome
cases considered in section 7.




                                                    5
preference necessitate consideration of the nature of preferences in multiple-outcome settings. At a
practical level the considerations involve determining what outcomes matter to decisionmakers (e.g.
patients or patient-provider teams, a fundamental concern in efforts to deliver high-value health
care; see Lynn et al., 2015; Manski, 2018). At a theoretical level, the framework proposed by
Manski, 2004, provides essential guidance for considering treatment preference for outcomes of
arbitrary dimension. The particular notions of treatment preference described in section 3 are
offered to be both potentially reasonable characterizations of what outcomes might actually
concern decisionmakers as well as simple enough to serve as the basis of treatment-effect definitions
that can be described and implemented empirically in a straightforward manner.


Plan for This Paper
       Section 2 reviews treatment-effect analysis in the single-outcome context and develops a
notion of treatment preference that is seen to be a feature, albeit one not typically recognized, of
standard treatment-effect analysis in the one-outcome case. Using this idea, treatment-preference
probability treatment effects (PTEs) are defined and are seen to correspond to familiar average
treatment effects in the single-outcome case. In section 3 the focus turns to multiple-outcome
settings. Focusing on binary outcomes, seven characterizations of treatment preference appropriate
to multiple-outcome contexts are proposed, their corresponding probabilities and PTEs are derived,
and the seven characterizations are compared and contrasted. Under standard assumptions about
unconfoundedness of treatment assignment, section 4 shows that the corresponding PTEs are point
identified for three of the characterizations and set identified for the other four, for which cases
bounds are derived. Section 5 considers empirical approaches to bounds estimation, or the PTEs
themselves in the point-identified cases. The results are illustrated with simulated data and, in
section 6, in analyses of two microdata samples. Section 7 generalizes the binary-outcome case to
consider treatment effects with multiple ordered outcomes, and suggests how that framework might
be used to address some questions involving multiple continuous outcomes. Section 8 summarizes.
While a fair amount of elementary probability algebra is used to derive results, the paper's main
ideas as well as their empirical implementation turn out to be quite straightforward.
       Ultimately if this paper accomplishes nothing more than stimulating readers to reassess
their approaches to understanding multiple outcomes and how treatments and interventions effect
them, it will have served some valuable purpose.


2. Treatment Preference and Treatment Effects with One Outcome
       This section reviews standard TE analytics for the one-outcome case when the potential
outcomes are binary, and then considers an interpretation of this setting's ATE that provides the
foundation for the analysis of multiple-outcome treatment effects considered subsequently.


                                                   6
Potential Outcomes, Treatment Preference, and Treatment Effects When M=1
        The setup is standard for M=1. There are two possible treatments, Tj and Tk , one of

which will be assigned or administered. The treatments' features are summarized in observable
vectors x j and x k , which often have just one element. A single (M=1) potential outcome, y j or

y k , is observed given treatment Tj or Tk . y• is the generic y j or y k . Y = ⎡⎢ y j, y k ⎤⎥ denotes the
                                                                                 ⎣           ⎦
1×2 vector of potential outcomes, only one of which will be observed. The TE is k y j .
                                                                                     y    −

        Until section 7 the focus is on binary 15 outcomes, with 1 and 0 indicating "bad" (e.g.
unhealthy) and "good" (e.g. healthy) outcomes, respectively. 16 As such TE ∈ {−1, 0,1} . Let

treatment preference be characterized simply as preferring a "good" outcome to a "bad" outcome.
Using "C" to denote this characterization of treatment preference, Tj is preferred to Tk ( Tj ≻C Tk )
if TE = −1 , Tk is preferred to Tj ( Tk ≻C Tj ) if TE = 1 , and the preference is neutral ( Tj ∼C Tk )

if TE = 0 .17 This obvious point about treatment preference plays a central role in what follows.
       The probability structure of the binary potential-outcome data is summarized in exhibit 1's
contingency table, in which the π•• and π• denote joint and marginal probabilities:


                                                 Exhibit 1
                                                            yj

                                                 0               1
                                 0              π00              π10         1 − πk
                    yk
                                 1              π01              π11           πk

                                               1 − πj            πj             1


From this information the ATE can be expressed in three equivalent ways:


         ATE = E ⎡⎢ y k − y j ⎤⎥ = π k − π j = π01 − π10 .                                     (5)
                  ⎣            ⎦

15
  Section 7 considers the case of ordered outcomes. Brief considerations of continuous outcomes
appear in several places in what follows.
16
 For concreteness, in health contexts one might think of "bad" binary outcomes along the lines of
mortality, chronic illness diagnosis or onset, 30-day readmission, substance abuse, etc.
17
     It will become evident in section 3 why the "C" subscript—indicating a particular
characterization of "bad" and "good" outcomes—is used alongside the preference indicator ( " ≻C " ).




                                                        7
Treatment-Preference-Probability Treatment Effects
      When conceiving an ATE with binary outcomes it is natural to focus on the difference in
marginal means or marginal probabilities, π k − π j in (5). For this paper's purposes, however, the

rightmost expression in (5), π01 − π10 , plays the central role. In light of the treatment-preference

                                               (                   )           (             )
characterization noted above, π01 = Pr y j = 0 ∧ y k = 1 and π10 = Pr y j = 1 ∧ y k = 0 , correspond

                                                                           (       )
respectively to the probabilities that Tj is preferred to Tk ( Pr Tj ≻C Tk ) and that Tk is preferred

            (         )
to Tj ( Pr Tk ≻C Tj ).18 These are henceforth called "treatment-preference" probabilities. Thus the

ATE (5) can be expressed as the difference in treatment-preference probabilities,


                          (        )       (
          ATE j≻k,C = Pr y j ≻C y k − Pr y k ≻C y j .  )                                         (6)


From ATEs to PTEs
         While the expression in (6) is algebraically little more than one summary of the information
in exhibit 1, it is of fundamental importance for this paper's main goals. Specifically, the difference
in treatment-preference probabilities expressed in (6) is the basis of the paper's strategy for
characterizing population-level treatment effects when M>1, an idea developed in section 3. It is
proposed that, for any M, such treatment effects can be meaningfully defined by the difference in
treatment-preference probabilities as in (6), given some suitable characterization C • of what it
means for one treatment to be preferred to another, i.e. Tj ≻C• Tk and Tk ≻C• Tj . When M=1 and

the outcomes are binary there is only one logical characterization of treatment preference, as
suggested above. When M>1, however, there is no single unambiguous characterization of what it
means for one treatment to be preferred to another.
         For any M≥1 and any characterization of treatment preference, the events Tj ≻C• Tk and

                                   (               )           (       )
Tk ≻C• Tj have probabilities Pr Tj ≻C• Tk and Pr Tk ≻C• Tj , whose difference in turn defines a

treatment-preference-probability treatment effect, or "PTE":


                          (            )
          PTE j≻k,C• = Pr Tj ≻C• Tk − Pr (Tk ≻C• Tk ) ,                                          (7)


where the subscript " j ≻ k " signifies the ordering of the minuend and subtrahend in (7). That is, it


18
     Note that the preference "events" Tj ≻C Tk and Tk ≻C Tj are stochastic as they depend on Y.
Standard notation is used: " ∧ " denotes "and" (intersection), " ∨ " denotes "or" (union).




                                                           8
is suggested that quantity used to summarize individual-level TEs across the population is the
PTE, regardless of M. As such the sign and magnitude of PTE j≻k,C• are proposed as standards for

assessing treatment success, clinical significance, etc., for any value of M. Its interpretation is
natural since it is exactly the familiar ATE in cases where M=1 and the outcomes are binary.
                                                           (           )
       Rather than writing out repeatedly Pr Tj ≻C• Tk , the shorthand Pj≻k,C• will be used

henceforth.19 As such,


        PTE j≻k,C• = Pj≻k,C• − Pk≻j,C• .                                                                 (8)


When M=1 the PTE (8) is identical to the ATE (6). 20 When M>1 the task is to determine
decision-relevant characterizations C • of what is meant by "treatment preference" since
comparisons of vector outcomes is less straightforward than comparison of scalar outcomes. Yet
once C • is selected to characterize treatment-preference and define a corresponding PTE, the
problem of defining a treatment effect in the M-dimension context is reduced to decisionmaking in
a one-dimension context. The paper turns now to formal development of this idea.

19
  For M=1 essentially the same idea can be applied to continuously distributed univariate
outcomes—e.g. measures where "larger" corresponds to "better" like survival time—for which
             (       )                                                             (       )
Pj≻k,C• = Pr y j > y k (Mullahy, 2018a). Since there are no ties, Pr y j > y k = 1 − Pr y k > y j so (         )
that PTE j≻k,C• = 2Pj≻k,C• −1 . Mapping continuous outcomes into binary representations when
M>1 (e.g., Alkire and Foster, 2010) permits analyses to be conducted within this paper's
framework albeit at the cost of potential information waste. See section 7 for additional discussion.
20
  Endowing a nominal- or ordinal-scale binary-outcome measure with ratio- or interval-scale
properties may be questionable when computing quantities like an ATE. The restriction to the
particular  {0,1} measure is easily loosened: Let the two                  possible outcome values be arbitrary

values {a, b} and rewrite the vector of joint probabilities as             ⎡π , π , π , π ⎤ . Then
                                                                           ⎣⎢ aa ab ba bb ⎦⎥

        ATE = E ⎡⎢ y k − y j ⎤⎥ =
                 ⎣            ⎦     ( b − a ) × (π k − π j )   =   (b − a)×(πab − πba ),
a rescaled version of the ATE in (5). Whether the notion of an ATE is meaningful in such a
binary-outcome context may depend on an application's structure and decisionmaker's objectives.
Note that the ATE's expression in terms of π k − π j arises from the ATE's averaging of the
outcomes, not as a direct assertion of what constitutes a population-level TE. Yet without
appealing at all to an ATE one might simply assert that π k − π j or, equivalently, PTE j≻k,C• is an
appropriate TE; this circumvents concerns about measurement properties of the binary outcomes
and whether these may or shouldn't lend themselves to numerical averaging as in (5).




                                                           9
3. Treatment Preference and Treatment Effects with Multiple Outcomes
           The previous section showed that when M=1 it is straightforward to characterize what it
means for one treatment to be preferred to another and to define—at least conceptually—the
probability of such preference. Observation of the single outcome arising under each of the
treatments      reveals—at    least   conceptually—the    relevant   information.   Considerations     of
identification are taken up in sections 4 and 5, but in anticipation it is useful to note that when
M=1 Pj≻k,C and Pk≻j,C will not generally be point identified even under the best circumstances—
e.g. unconfounded treatment assignment—although the PTE j≻k,C they define would be.

           With multiple outcomes a first-order concern not arising when M=1 is how to determine
whether one treatment is preferred to another from a comparison of the M>1 potential outcomes
arising from competing treatments. This issue has attracted surprisingly little attention in the
health evaluation literature, particularly since samples containing and studies using data on
multiple health outcomes are commonplace. While the empirical literature has handled ad hoc such
data structures in a variety of ways (as noted in section 1), consideration of how to conceive of
treatment preference and treatment effects in the multiple-outcome case is largely absent.
           This section explores such issues and offers a set of criteria or characterizations by which
one might assess the extent to which one treatment is preferred to another when treatments result
in M>1 outcomes of interest. Not surprisingly matters are more complicated when M>1, but
managing such complications should be a small price to pay for an integrated structure within
which questions about multiple-outcome treatment effects can be explored.


Definitions
      For M≥1 let y j = ⎡⎢ y j,1 … y j,M ⎤⎥ and yk = ⎡⎢ y k,1 … y k,M ⎤⎥ be M-vectors of binary potential
                            ⎣             ⎦           ⎣                ⎦
                      ⎡         ⎤
outcomes, and let Y = ⎢ y j, yk ⎥ ( 1×2M ). y• denotes the generic version of either y j or yk .21 Let
                      ⎣         ⎦
Pr (Y ) and Pr (y• ) denote the joint and joint-marginal probabilities of the potential outcomes. Let

       {                          }
Q = q q m ∈ {0,1}, m = 1,…, M be the set of all 2M possible values of the potential outcomes y• .

For arbitrary vectors a and b let a > b denote element-by-element strict inequality ( a m > b m for
all m, or weak monotonicity) and let a ≥ b denote element-by-element weak inequality with at
least one strict inequality (strong monotonicity). In what follows the y• are assumed to have a


21
     The components of the y• are considered fixed, but their particular specification is a key
consideration in practice. For example, much effort is devoted to defining core outcome measures
and standardized outcome sets (Porter et al., 2016; Williamson et al., 2017). See Mullahy, 2018b.




                                                    10
                                                                       (                  )
"multivariate" but not "multinomial" structure; that is, for all m Pr y•,m = 1 y•,−m = 0 ≠ 1 , where

y•,−m denotes y• without its m-th element. Boldface fonts denote vectors.

        Using various characterizations C • of treatment preference, the main objective here is to
define the treatment preferences, Tj ≻C• Tk and Tk ≻C• Tj , the corresponding treatment-preference
probabilities, Pj≻k,C• and Pk≻j,C• , and the implied PTE j≻k,C• as in (8) that, in the multiple-

outcome context, correspond to those quantities described in section 2 for M=1. After these
definitions are provided, the discussion compares the properties of the various characterizations.22
While the characterizations offered are hopefully both intuitive and reasonable, two considerations
might be noted: first, other reasonable characterizations can be advanced; second, any standard for
what it means for Tj to be preferred to Tk should be linked ideally to decisionmakers' values.


Characterization 1 (C1)
          An intuitively obvious way to compare y j and yk when M>1 is to consider the events
yk ≥ y j and y j ≥ yk . In this instance there is no single standard—i.e. no particular value(s) of the
y• —defining a "good" or "bad" outcome. Instead the focus is on the set of inequality relationships
that may obtain between y j and yk across the 22M possible values of Y. In light of how "good"
and "bad" are defined for each of the M component outcomes, yk ≥ y j may be a reasonable and
natural characterization of Tj being preferred to Tk (and symmetrically, y j ≥ yk a reasonable
characterization of Tk being preferred to Tj ).
          Formally Tj is preferred to Tk by characterization C1, denoted Tj ≻C1 Tk , if and only if
yk ≥ y j . In essence this corresponds to standard formal notions of strongly monotonic (decreasing)
preferences. It follows that the probability that Tj is preferred to Tk under C1 is


                      (        )
          Pj≻k,C1 = Pr yk ≥ y j ,                                                             (9)



22
     An obvious way to conceive of treatment preference is via treatment-specific utility. That is, one
might consider a utility function V (…) and the expected utilities associated with treatments Tj

and Tk , EU• = ∑ y ∈Q V (y• )×Pr (y• ) , where Q is the set of all 2M possible outcomes. Under
                          •


expected utility, Tj ≻C,EU Tk when EU j > EUk . Specifying V (…) determines how the elements of
the y• are weighted; see Manski and Tetenov, 2018, for an example with M=2.




                                                   11
where this probability is necessarily defined from the full joint probability Pr (Y ) . Define

         {
Yj≻k,C1 = Y yk ≥ y j   }                         (                 )
                           so that Pj≻k,C1 = Pr Y ∈ Yj≻k,C1 . As such # Yj≻k,C1 = 3M − 2M (oeis.org,

A001047), so that there are 22M − 2 3M − 2M  (           ) values among the 2        2M
                                                                                          possible values of Y for

which Tj ∼C1 Tk . The PTE corresponding to (9) is


                                                 (
       PTE j≻k,C1 = Pj≻k,C1 − Pk≻j,C1 = Pr yk ≥ y j            )        (        )
                                                                   − Pr y j ≥ yk .                         (10)


Characterization 2 (C2)
       Characterization C2, which turns out to be a special case of C1, specifies that a "good"
outcome is one where y• = 0 whereas a "bad" outcome is any outcome where y• ≠ 0 . That is, a

treatment failure or bad outcome is one where at least one bad component outcome occurs. As
such, Tj ≻C2 Tk if and only if y j = 0 ∧ yk ≠ 0 , that is, when Tj results in no bad component
outcome while Tk results in at least one bad component outcome. It follows that


                    (
       Pj≻k,C2 = Pr y j = 0 ∧ yk ≠ 0     )                                                                 (11)


For C2 a neutral treatment preference occurs when y j = 0 ∧ yk = 0 or when y j ≠ 0 ∧ yk ≠ 0 .

                {                    }
Define Yj≻k,C2 = Y y j = 0, yk ≠ 0 . Then # Yj≻k,C2 = 2M −1 so that 22M − 2 2M −1 values of Y (        )
result in Tj ∼C2 Tk . The PTE corresponding to (11) is


                                                     (
       PTE j≻k,C2 = Pj≻k,C2 − Pk≻j,C2 = Pr y j = 0 ∧ yk ≠ 0             )        (
                                                                            − Pr y j ≠ 0 ∧ yk = 0 .)       (12)


Characterization 3 (C3)
       The third characterization considered here, C3, is the mirror image of C2 and is also a
special case of C1. Here a "good" outcome is one where y• ≠ 1 while a "bad" outcome occurs when
y• = 1 . That is, a "bad" outcome under C3 is one where all component outcomes are "bad"; if any
component is not "bad" then the overall outcome is "good." Thus Tj ≻C3 Tk if and only if
y j ≠ 1 ∧ yk = 1 , that is, when Tj results in at least one "good" component outcome while Tk

results in no "good" component outcome. It follows that


                    (
       Pj≻k,C3 = Pr y j ≠ 1 ∧ yk = 1     )                                                                 (13)



                                                          12
A neutral treatment preference with C3 occurs when y j = 1 ∧ yk = 1 or when y j ≠ 1 ∧ yk ≠ 1 .

                 {                   }
Define Yj≻k,C3 = Y y j ≠ 1, yk = 1 . Then as with C2 # Yj≻k,C3 = 2M −1 so that 22M − 2 2M −1               (    )
values of Y result in Tj ∼C3 Tk . The PTE corresponding to (13) is


                                                    (                 )        (
        PTE j≻k,C3 = Pj≻k,C3 − Pk≻j,C3 = Pr y j ≠ 1 ∧ yk = 1 − Pr y j = 1 ∧ yk ≠ 1 .                 )   (14)


Characterization 4 (C4)
       C4 is the union of C2 and C3. There is no single "good" or "bad" outcome. Rather treatment
                                                                          (              )       (
preference is determined as Tj ≻C4 Tk if and only if either y j = 0 ∧ yk ≠ 0 or y j ≠ 1 ∧ yk = 1 .              )
Tj ≻C4 Tk if Tj results in no "bad" component outcome while Tk results in at least one "bad"
component outcome, or if Tk results in all "bad" component outcomes while Tj results in at least

one "good" component outcome. For health outcomes, C4 means "perfect" health is better than
"imperfect" health and partially "imperfect" health is better than completely "imperfect" health.
Thus


                     ((                   ) (
        Pj≻k,C4 = Pr y j = 0 ∧ yk ≠ 0 ∨ y j ≠ 1 ∧ yk = 1 .     ))                                        (15)


Neutral treatment preference occurs if y j = yk = 0 or y j = yk = 1 or if neither y j nor yk is in

{0,1} . Let

        Yj≻k,C4 =    {Y (y = 0 ∧ y
                          j          k      ) (
                                         ≠ 0 ∨ y j ≠ 1 ∧ yk = 1  )}   = Yj≻k,C2 ∪ Yj≻k,C3 .              (16)



# Yj≻k,C4 = 2M+1 − 3 so that 22M − 2M+2 + 6 among the 22M possible values of Y result in
Tj ∼C4 Tk . The PTE corresponding to (15) is


                                                     ((                ) (
        PTE j≻k,C4 = Pj≻k,C4 − Pk≻j,C4 = Pr y j = 0 ∧ yk ≠ 0 ∨ y j ≠ 1 ∧ yk = 1             ))   −
                                                                                                         (17)
                                                  Pr ((y j ≠ 0 ∧ yk = 0) ∨ (y j = 1 ∧ yk ≠ 1))


Characterization 5 (C5)
       C5 is the intersection of C2 and C3. A "good" outcome occurs when y• = 0 while a "bad"
outcome occurs when y• = 1 . Treatment preference is determined as Tj ≻C5 Tk if and only if


                                                        13
y j = 0 ∧ yk = 1 . That is, Tj ≻C5 Tk if and only if Tj results in no "bad" component outcome while
Tk results in all "bad" component outcomes. With binary outcomes this is equivalent to yk > y j ,

corresponding to weakly monotonic preferences. For health outcomes, C5 suggests that "perfect"
health is better than "worst possible" health, and otherwise does not adjudicate. Here


                      (                )
          Pj≻k,C5 = Pr y j = 0 ∧ yk = 1 .                                                 (18)


A neutral treatment preference under C5 occurs in all cases except y j = 0 ∧ yk = 1 . Define


          Yj≻k,C5 =   {Y y j = 0 ∧ yk = 1}   = Yj≻k,C2 ∩ Yj≻k,C3 .                        (19)



# Yj≻k,C5 = 1 so that 22M − 2 values of Y result in Tj ∼C5 Tk . The PTE corresponding to (18) is


                                                  (                  )   (           )
          PTE j≻k,C5 = Pj≻k,C5 − Pk≻j,C5 = Pr y j = 0 ∧ yk = 1 − Pr y j = 1 ∧ yk = 0 .    (20)


Characterization 6 (C6)
          C6 is a generic characterization that will be seen to have important commonalities with
characterizations C2 and C3 when considerations of identification are raised in sections 4 and 5.
Define the set Z ⊂ Q and its complement in Q as Zc . For C6 "good" outcomes are those where
y• ∈ Z while "bad" outcomes occur when y• ∈ Zc .23 As such, treatment preference is determined as


23
     C6 is offered to encompass various multiple-outcome settings encountered in practice. In applied
health research, criteria beyond ones based simply on Z = {0} or Zc = {1} are used to define
composite outcomes (U.S. FDA, 2017). Consider two such cases. In the first a "good" outcome is
one where no more than z<M component outcomes are "bad", i.e. a "bad" outcome requires at least
z+1 "bad" component outcomes (e.g., metabolic syndrome (M=5, z=2); U.S. NHLBI, 2018); which
particular component outcomes are "bad" doesn't matter, only that at least z+1 of them are. In the
second a "bad" outcome is one where w particular component(s) and at least z other components be
"bad", otherwise the outcome is "good" (e.g., DSM-V narcolepsy (M=4, w=1, z=1); Ruoff and Rye,
2016). In the extreme, w components may represent outcomes particularly important to a
decisionmaker so that a "good" outcome is any outcome where these w outcomes are "good" (akin to
"essential factors," Färe and Svensson, 1980). Treatment preference depends here only on the
essential component(s) (i.e. z=0); in effect M=w. This encompasses so-called primary and
secondary outcomes (U.S. FDA, 2017). In technology evaluations (e.g. RCTs) outcomes are
sometimes prioritized as primary or secondary and the technology is deemed successful if the
                                                                                           (cont.)


                                                      14
Tj ≻C6(Z) Tk if and only if y j ∈ Z ∧ yk ∈ Zc . Thus,



                              (
        Pj≻k,C6(Z) = Pr y j ∈ Z ∧ yk ∈ Zc .            )                                                                            (21)



A neutral treatment preference under C6 occurs when y j ∈ Z ∧ yk ∈ Z or when y j ∈ Zc ∧ yk ∈ Zc .

                         {                            }
Define Yj≻k,C6(Z) = Y y j ∈ Z ∧ yk ∈ Zc . The PTE corresponding to (21) is



    PTE j≻k,C6(Z) = Pj≻k,C6(Z) − Pk≻j,C6(Z) = Pr y j ∈ Z ∧ yk ∈ Zc      (                           )              (
                                                                                                        − Pr y j ∈ Zc ∧ yk ∈ Z .    )      (22)


Outcome Counts: A Benchmark Characterization (C0)
      Each of the characterizations C1-C6 provides an unambiguous basis for comparing the
outcome vectors y j and yk , and does so in a way that relates treatment preference to a particular

interpretation of what it means for one binary vector to be element-by-element "better" than
another. Some potentially relevant characterizations of treatment preference, though, will not be
based on such vector relationships. One such characterization is both obvious—since its empirical
counterparts are encountered frequently in applications—and provides a benchmark against which
properties and implications of other characterizations might be assessed.
       Specifically, with M>1 binary outcomes a prominent data-aggregation or dimension-
reduction approach used in practice is based on the count of "bad" outcomes (see Khan et al., 2008,
                                           M
for one example). Let s j = ∑ m=1 y j,m and likewise define sk . Like C1, characterization C0 does
not involve a particular standard for y• of what constitutes a "good" or "bad" outcome, but relies
on a comparison of s j and sk wherein Tj ≻C0 Tk if and only if sk > s j . It follows that



                          (
        Pj≻k,C0 = Pr sk > s j .      )                                                                                              (23)




(cont.)
primary outcomes are all "good" regardless of the secondary components' outcomes. For illustration,
let M=3, w=1, and z=1. With y•,1 being the essential component, the two scenarios correspond to

            ⎣{       ⎦ ⎣           ⎦ ⎣          ⎦ ⎣    }     ⎦    {⎡⎢⎣1,1, 0⎤⎥⎦ , ⎡⎢⎣1, 0,1⎤⎥⎦ , ⎡⎢⎣0,1,1⎤⎥⎦ , ⎡⎢⎣1,1,1⎤⎥⎦} , and
       Z = ⎡⎢0, 0, 0⎤⎥ , ⎡⎢1, 0, 0⎤⎥ , ⎡⎢0,1, 0⎤⎥ , ⎡⎢0, 0,1⎤⎥ , Zc =

           ⎣ {      ⎤
                    ⎦ ⎣
                         ⎡        ⎤
                                  ⎦ ⎣
                                       ⎡       ⎤
                                               ⎦ ⎣
                                                    ⎡       ⎤
                                                            ⎦ ⎣  } Zc = {⎡⎢⎣1,1, 0⎤⎥⎦ , ⎡⎢⎣1, 0,1⎤⎥⎦ , ⎡⎢⎣1,1,1⎤⎥⎦} .
       Z = ⎢0, 0, 0⎥ , ⎢1, 0, 0⎥ , ⎢0,1, 0⎥ , ⎢0, 0,1⎥ , ⎡⎢0,1,1⎤⎥ ,
           ⎡
                                                                    ⎦




                                                                        15
                     {           }
Define Yj≻k,C0 = Y sk > s j . # Yj≻k,C0 = 22M−1 −
                                                             (2M−1)!
                                                             M!(M−1)!
                                                                           ; (2M)! (M!)2 values of Y result in

Tj ∼C0 Tk .24 The PTE corresponding to (23) is


                                                    (         )
          PTE j≻k,C0 = Pj≻k,C0 − Pk≻j,C0 = Pr sk > s j − Pr s j > sk . (        )                   (24)


Comparing the Treatment-Preference Characterizations
          The treatment-preference characterizations are summarized in exhibit 2.


                             Exhibit 2: Summary of Tj ≻C• Tk Characterizations

                                                             Tj ≻C• Tk

                               C0                                 sk > s j

                               C1                              yk ≥ y j

                               C2                        y j = 0 ∧ yk ≠ 0

                               C3                        y j ≠ 1 ∧ yk = 1

                               C4             (y j = 0 ∧ yk ≠ 0) ∨ (y j ≠ 1 ∧ yk = 1)
                               C5                        y j = 0 ∧ yk = 1

                               C6                        y j ∈ Z ∧ yk ∈ Zc


          Using the definitions of the Yj≻k,C• above, it is straightforward to show that for M>2


                       ⎧⎪ Y          ⎫⎪
                        ⎪ j≻k,C2      ⎪⎪
          Yj≻k,C5   ⊂ ⎪⎨               ⎬ ⊂ Yj≻k,C4 ⊂ Yj≻k,C1 ⊂ Yj≻k,C0                              (25)
                        ⎪⎪ Y           ⎪⎪
                         ⎪⎩ j≻k,C3      ⎪⎭


(for M=2 Yj≻k,C0 = Yj≻k,C1 = Yj≻k,C4 ). C1 is more restrictive than C0 (for M>2) since the set of
events yk ≥ y j is a subset of all events for which sk > s j . In turn C2 and C3 are more restrictive
than C1 since inequalities yk ≥ y j with y j = 0 or with yk = 1 are a subset of all possible yk ≥ y j
inequalities (as for C1); C2 and C3 are more restrictive than C4 since Yj≻k,C4 = Yj≻k,C2 ∪ Yj≻k,C3 .
Similarly C4 is more restrictive than C1 since all Y in Yj≻k,C4 satisfy yk ≥ y j but some Y with


24
     See oeis.org, entries A000346 and A000984.




                                                        16
yk ≥ y j are not in Yj≻k,C4 . C5 is more restrictive than either C2 or C3 since it is the intersection
of those characterizations. C2-C5 are all special cases of the yk ≥ y j inequalities that define C1. C2

and C3 are special cases of C6.


                      Exhibit 3: Y Values Relevant in C2-C5 Characterizations
                                                                    yj
                                        yj = 0               yj ≠ 0 ∧ yj ≠ 1             yj = 1

                 yk = 0                  Y0,0                      Y∼,0                   Y1,0

       yk    yk ≠ 0 ∧ yk ≠ 1             Y0,∼                      Y∼,∼                   Y1,∼

                 yk = 1                  Y0,1                      Y∼,1                   Y1,1


In exhibit 3's cells the Y•,• represent sets of Y values corresponding to the particular margin

                        {                    }
definitions (e.g. Y0,0 = Y y j = 0 ∧ yk = 0 ). Thus Tj ≻C• Tk is determined by:


       C2:     y j = 0 ∧ yk ≠ 0 ,                          i.e. Y ∈ Y0,∼ ∪ Y0,1
       C3:     y j ≠ 1 ∧ yk = 1 ,                          i.e. Y ∈ Y0,1 ∪ Y∼,1

       C4:     (y j = 0 ∧ yk ≠ 0) ∨ (y j ≠ 1 ∧ yk = 1) ,   i.e. Y ∈ Y0,∼ ∪ Y0,1 ∪ Y∼,1

       C5:     (y j = 0 ∧ yk = 1) ,                        i.e. Y ∈ Y0,1


If one imagines the entries in the exhibit as a 3×3 array, then C2-C5 are different ways of
asserting that outcomes represented in its lower off-diagonal elements are ones where Tj ≻C• Tk .

       Ignoring for the moment C0 and C6, another perspective recognizes that C1 and C5 bracket
C2, C3, and C4 in the sense that C1 is defined by weakest possible vector inequality yk ≥ y j while
C5 is defined by the the strictest vector inequality yk > y j . C2, C3, and C4 fall in-between, more

structured than C1 but less stringent than C5. Since C1 and C5 correspond to strongly and weakly
monotone preference structures, C2-C4 are thus special cases of strongly monotone preferences. For
illustrative purposes table 1 shows relationships among the C • for M=3.


                                           [table 1 about here]




                                                     17
          From (25) it follows that25

                                           ⎧⎪ P            ⎫⎪
                                            ⎪ j≻k,C2        ⎪⎪
          Pj≻k,C0 ≥ Pj≻k,C1 ≥ Pj≻k,C4   ≥ ⎪⎨                 ⎬ ≥ Pj≻k,C5 ,                  (26)
                                            ⎪⎪ P             ⎪⎪
                                             ⎪⎩ j≻k,C3        ⎪⎭


with weak inequalities accommodating the possibility that the probabilities of the particular joint
events that define the differences among the Yj≻k,C• sets may be zero.
          Finally since Pj≻k,C• , PTE j≻k,C• , or both might be of interest in particular contexts, the

following section considers identification of each.


4. Identifying Pj≻k,C• and PTE j≻k,C•

          The treatment-preference probabilities discussed in section 3 are defined by features of the
full joint distribution Pr (Y ) . As such, while point identifying one or more of the Pj≻k,C• and the

corresponding PTEs may be desirable, this will not always be possible. Nonetheless, partial or set
identification is generally possible so long as the joint marginals Pr (y• ) are identified, and for

three of the characterizations described in the previous section point identification of the
PTE j≻k,C• is possible. This section explores these identification questions.

          The standard sense of identification is used here, i.e. that the parameters of interest are
uniquely determined by the (joint) distribution of observable/observed data (Hansen, 2018, section
2.33). This conveys notions of both conceptual (population) as well as empirical (sample)
identification. Treatment assignment is assumed exogenous, i.e. unconfoundedness is assumed, so
point or set identification of this paper's key parameters is broadly straightforward: using analog
principles, features of conditional-on-treatment distributions of observed outcomes will generally
suffice to estimate consistently the corresponding features of treatment-specific potential-outcome
distributions. It is assumed that the joint marginals Pr (y• ) are knowable and accessible, which will

typically be the case. 26 If covariates beyond treatment-status indicators are relevant, they are
assumed to be benign and can innocuously condition probability statements.
          With unconfounded treatment assignment, Pr (y• ) will generally be nonparametrically


25
                                                  (         { })         (
     It can be shown that Pj≻k,C2 ! Pj≻k,C3 as Pr yk ∉ 0,1 ! Pr y j ∉ 0,1 .  { })
26
  Note that the empirical joint marginals may be obtained from two arms of a randomized trial or
even from two separate samples (e.g. repeated cross sections, synthetic cohorts). The key in any
case is that the samples represent the same population, however that population be defined.




                                                      18
                                                 !
identified and estimable from observable data as Pr y x = x          (           •
                                                                                     ) (section 5). As seen below this will
typically suffice to set identify Pj≻k,C• and Pk≻j,C• , and then estimate bounds thereon. It is also
shown that point identification of the PTE j≻k,C• is possible for C2, C3, and C6.


Probability Bounds: General Results and Results for M=1
          The approach described by Boole, 1854 (chapter XIX), and others27 is used to determine the
probability and PTE bounds. In general Boole's upper bounds (UB) and lower bounds (LB) are
straightforward to derive given knowledge of the joint marginal probabilities. For the most part the
required bounds will be seen to be those on conjunction probabilities ("intersection," "and").28
          To illustrate, consider first the M=1 case discussed in section 2. With reference to exhibit 1,
                          (               )
consider Pj≻k,C = Pr y j = 0 ∧ y k = 1 = π01 . (The results are shown here for Pj≻k,C• ; switching

subscripts gives the results for Pk≻j,C• .) While π01 cannot be point identified it can be bounded by
using the identified marginal distribution probabilities π j and π k as


              (
          UB Pj≻k,C   )          { (          )
                          = min Pr y j = 0 , Pr (y k = 1)    }                   {
                                                                     = min 1 − π j, π k        }                (27)

and
              (
          LB Pj≻k,C   )          { (          )
                          = max Pr y j = 0 + Pr (y k = 1) −1, 0              }             {
                                                                                 = max π k − π j, 0 .  }        (28)


For nondegenerate cases the UB is always informative (i.e. less than one) while the LB may or may
not be informative (i.e. exceed zero).29
        Even though Pj≻k,C and Pk≻j,C are not themselves point identified, the corresponding

27
  Although such bounds are often referred to as Fréchet or Fréchet-Hoeffding bounds, Boole's 1854
treatise was published before either Fréchet or Hoeffding was born.
28
     For N events e n jointly distributed in the population as Pr (e1 ∧ …∧ eN ) , the general result is

                  (              )            {
           UB Pr (e1 ∧ …∧ eN ) = min Pr (e1 ),…, Pr (eN )                }   ≥ Pr (e1 ∧ …∧ eN ) ≥

                                        max   {∑   N
                                                   n=1
                                                       Pr   (en ) − (N −1), 0}                     (
                                                                                         = LB Pr (e1 ∧ …∧ eN )  )
29
     For the M=1 continuous-outcome case discussed in footnote 19, the bounds on the PTE
2Pr (y1 > y0 ) −1 are (using notation in Mullahy, 2018a, eq. (21)):

              (                   )
          UB 2Pr (y1 > y0 ) −1 = 1 − 2D10         and            (
                                                        LB 2Pr (y1 > y0 ) −1 = 2D01 −1     )


                                                        19
PTE j≻k,C is point identified by the ATE in (6) under unconfounded treatment assignment, i.e.


          PTE j≻k,C = Pj≻k,C − Pk≻j,C = π01 − π10 = π k − π j = E ⎡⎢ y k − y j ⎤⎥ .          (29)
                                                                   ⎣            ⎦


Bounding (Set Identification of) Pj ≻k,C• and Pk ≻ j,C• with M>1

          For M>1, consider first C2, C3, C5, and C6 as these characterizations' preference-
probability and PTE bounds are straightforward to obtain. For these C • there are only two
marginal events to consider in obtaining bounds on the treatment-preference probabilities. Using
(11), (13), (18), and (21), for each of these C • the marginal events represent the "good" and "bad"
outcomes corresponding to each treatment. Thus,


             (        )       { ( )
          UB Pj≻k,C2 = min Pr y j = 0 ,1 − Pr (yk = 0)       }                               (30)

          LB (Pj≻k,C2 ) = max {Pr (y j = 0) − Pr (yk = 0), 0}                                (31)

          UB (Pj≻k,C3 ) = min {1 − Pr (y j = 1), Pr (yk = 1)}                                (32)

          LB (Pj≻k,C3 ) = max {Pr (yk = 1) − Pr (y j = 1), 0} .                              (33)

          UB (Pj≻k,C5 ) = min {Pr (y j = 0), Pr (yk = 1)}                                    (34)

          LB (Pj≻k,C5 ) = max {Pr (y j = 0) + Pr (yk = 1) −1, 0} .                           (35)

          UB (Pj≻k,C6(Z) ) = min {Pr (y j ∈ Z), Pr (yk ∈ Zc )}                               (36)

             (          )        { (         )     (        )
          LB Pj≻k,C6(Z) = max Pr y j ∈ Z + Pr yk ∈ Zc −1, 0 .        }                       (37)


Exhibit 3 allows one to visualize how the quantities (30)-(37) bound Pj≻k,C• for C2, C3, and C5.

                                                                     (   )        (   )
Note that for both C2 and C3 one of the lower bounds LB Pj≻k,C• or LB Pk≻j,C• will necessarily

be positive while the other will be zero (assuming no ties).
          Since it is defined by a disjunction of conjunctions one approach to computing bounds on
Pj≻k,C4 involves, in essence, bounding the bounds. Several approaches could be used along these

lines, not all of which will result in identical numerical results (see footnote 32 below).30 For the LB



30
     Corresponding to footnote 28, Boole's upper and lower bounds for probabilities Pr (e1 ∨ …∨ eN )
of disjunctions of possibly non-disjoint events or sets e n are:

                                                                                                 (cont.)


                                                       20
a direct approach based on this idea gives


          (             )       { { (               )                 }           {
       LB Pj≻k,C4 = max max Pr y j = 0 − Pr (yk = 0), 0 , max Pr (yk = 1) − Pr y j = 1 , 0     (           ) }} .    (38)



           (            )
For UB Pj≻k,C4 reference to exhibit 3 suggests an alternative approach that generally gives a

bound at least as tight if not tighter than Boole's generic UB, specifically:31


                (           )    { (           )                          (           )
          UB Pj≻k,C4 = min Pr y j = 0 + Pr (yk = 1), 1 − Pr y j = 1 , 1 − Pr (yk = 0) .            }          (39)



Each term in braces in (39) is a legitimate UB, so the best UB is the smallest of the three.
          For C2-C5 note that only the probabilities involving the joint marginal distributions
evaluated at 0 and/or 1 are required to define the bounds since in each instance the treatment-
preference characterization is binary (C2 and C3) or based on two binary characterizations (C4 and
C5). For C6 the relevant probabilities in (36) and (37) are the sums of the probabilities of the
elements of the particular Z and Zc definitions being used, i.e. Pr (y• ∈ Z) = ∑ q∈Z Pr (y• = q) .

          Computation is more complicated for C0 and C1, for which each treatment-preference
probability is the sum of the probabilities of disjoint events. Unlike C2-C6 wherein "good" and
"bad" outcomes are defined by particular values of the y• , C0 and C1 rely on comparisons across
                                                                                                       (2M−1)!
all 22M values of Y to determine treatment preference; as noted earlier, 22M−1 −                                  values of
                                                                                                       M!(M−1)!

Y correspond to Pj≻k,C0 , while 3M − 2M values of Y correspond to Pj≻k,C1 . Bounding these

probabilities entails computing the relevant upper and lower bounds at each such Y value and then
aggregating those bounds in some manner across relevant values of Y. As discussed by Boole, 1854


(cont.)

                (                 )
          UB Pr (e1 ∨ …∨ eN ) = min            {∑       N
                                                          (en ),1} ≥
                                                        n=1
                                                            Pr            Pr (e1 ∨ …∨ eN ) ≥

                                            max {Pr (e1 ),…, Pr (eN )}                (
                                                                          = LB Pr (e1 ∨ …∨ eN )    )
31
     In the notation of exhibit 3, the set whose probability is to be bounded is Y0,∼ ∪ Y0,1 ∪ Y∼,1 . The
expression in (39) thus translates to

              { (
       min Pr Y0,0 ∪ Y0,∼ ∪ Y0,1      )         (                     )       (
                                          + Pr Y0,1 ∪ Y∼,1 ∪ Y1,1 , Pr Y0,0 ∪ Y∼,0 ∪ Y0,∼ ∪ Y∼,∼ ∪ Y0,1 ∪ Y∼,1 ,        )
                    (
               Pr Y0,∼ ∪ Y∼,∼ ∪ Y1,∼ ∪ Y0,1 ∪ Y∼,1 ∪ Y1,1        )}


                                                                 21
(chapter XIX), to avoid double-counting aggregation is more complicated than simply adding up
the respective upper and lower bounds of the Pr (Y ) across the relevant Y. Although the C0 and

C1 bounds are computable, simple representation as in (30)-(39) is not possible. See Appendix A.
       For C0 and C1 it should also be noted that computation of the bounds using the joint
marginal distributions at the relevant y• values requires that each of these joint marginal

probabilities be identified by the available data. While in principle not a concern for identification,
empirical implementation may encounter sparse data where some—or, in the case of large M,
possibly many—of the joint outcomes are not observed in the sample. Empirically these would be
zero-probability events by method-of-moments or analog principles (see section 5).32
       Finally, with reference to (26) note that a legitimate LB on any of the terms in the
inequality chain will be a legitimate LB on any terms leftward of that term, whereas a legitimate
UB on any of the terms in the inequality chain will be a legitimate UB on any terms rightward of
that term. In some instances this result may be helpful as a computational shortcut.


Point and Set Identification of the PTE j ≻k,C•
       Once the bounds on Pj≻k,C• and Pk≻j,C• are defined for any of the C • it is straightforward

to obtain bounds on the corresponding PTEs as:


           (           )       (       )     (
        UB PTE j≻k,C• = UB Pj≻k,C• − LB Pk≻j,C•      )                                         (40)

and
           (           )       (      )      (
        LB PTE j≻k,C• = LB Pj≻k,C• − UB Pk≻j,C• .    )                                         (41)


       While (40) and (41) hold generally, for C2, C3, and C6 point identification of PTE j≻k,C• is

possible given knowledge of Pr (y• ) at 0 (C2), at 1 (C3), or over Z (C6). Referring to exhibit 1,

note that for C2 1(y• ≠ 0) plays the same role as does y• when M=1, for C3 1(y• = 1) plays that

                   (       )
role, and for C6 1 y• ∈ Zc plays that role. Thus, analogous to E ⎡⎢ y k − y j ⎤⎥ in (5) one has for C2
                                                                  ⎣            ⎦



32
  Actual computation of the UBs and LBs may result in bounds that do not obey the ordering
relationships in (26). While the respective probabilities must obey the ordering in (26), formulae
used to compute those bounds are not necessarily so ordered since in some cases there are multiple
legitimate ways to compute the bounds. Obtaining tightest bounds in such cases would require a
search across the set of legitimate bounds; such considerations are beyond this paper's scope.




                                                    22
          E ⎡⎢1(yk ≠ 0) −1 y j ≠ 0 ⎤⎥ = E ⎡⎢ 1 −1(yk = 0) − 1 −1 y j = 0 ⎤⎥
             ⎣            (       ) ⎦      ⎣
                                               (                 )          ⎦
                                                                             (           (        ))
                                           ⎡
                                           ⎣  (         )      ⎤
                                      = E ⎢1 y j = 0 −1(yk = 0)⎥
                                                               ⎦
                                            ( (                          )
                                      = Pr y j = 0 ∧ yk = 0 + Pr y j = 0 ∧ yk ≠ 0    (                          ))   −
                                                                                                                             (42)
                                              (Pr (y j = 0 ∧ yk = 0) + Pr (y j ≠ 0 ∧ yk = 0))
                                               (                ) (
                                          = Pr y j = 0 ∧ yk ≠ 0 − Pr y j ≠ 0 ∧ yk = 0                       )
                                          = Pr (Tj ≻C2 Tk ) − Pr (Tk ≻C2 Tj )                    = PTE j≻k,C2


while symmetrically for C3 and C6 (skipping the middle steps used in (42)):


                          (      )             (            )
          E ⎡⎢1(yk = 1) −1 y j = 1 ⎤⎥ = Pr Tj ≻C3 Tk − Pr Tk ≻C3 Tj
             ⎣                      ⎦                                    (                   )   = PTE j≻k,C3                (43)

and
            ⎡
            ⎣
              (       ) (          ⎤
                                      )            (                 )
          E ⎢1 yk ∈ Zc −1 y j ∈ Zc ⎥ = Pr Tj ≻C6(Z) Tk − Pr Tk ≻C6(Z) Tj
                                   ⎦
                                                                                 (                     )   = PTE j≻k,C6(Z)     (44)


Thus even though their component probabilities Pj≻k,C• and Pk≻j,C• are not separately point
identified, the PTE j≻k,C• are point identified for C2, C3, and C6. This is because their outcome-

probability structures are essentially the same binary one seen in exhibit 1. It does not appear that
the PTE j≻k,C• can be point identified for C0, C1, C4, and C533 so set identification must suffice.34


Signing PTE j ≻k,C•

        Among the questions of concern to a decisionmaker, a prominent one might be the sign of a
particular PTE j≻k,C• and whether the data are sufficiently informative to determine that one


33
     PTE j≻k,C4 + PTE j≻k,C5 is point identified since PTE j≻k,C4 + PTE j≻k,C5 =PTE j≻k,C2 + PTE j≻k,C3 .
However it is not obvious that such a quantity is likely to be of much interest.
34
     Based on (2), a different TE one might consider with outcomes s j and sk is sk − s j . With

unconfounded treatment assignment the ATE E ⎡⎢sk − s j ⎤⎥ is identifiable. However, since it is defined
                                                ⎣       ⎦
by s j and sk this ATE elicits the same concerns about across-outcome measurement comparability
and (implied) weighting as does PTE j≻k,C0 . These notwithstanding, estimation of regression

models E ⎡⎢sy x = x j ⎤⎥ and E ⎡⎢sy x = x k ⎤⎥ as in (2) can be used to consistently estimate E ⎡⎢sk − s j ⎤⎥ .
          ⎣            ⎦        ⎣            ⎦                                                   ⎣          ⎦




                                                            23
treatment is unambiguously superior or not inferior to another. With PTE point identification (C2,
C3, and         C6)     this   is       trivial. When    only    set       identification     is   possible, knowing           that
      (             )                   (            )
LB PTE j≻k,C• > 0 or UB PTE j≻k,C• < 0 suffices to sign that PTE, up to sampling error.

          Two figures illustrate what is involved for some specific cases. Figure 1a shows for the case
of C2 the gains from point versus set identification when the question of interest concerns the sign
                                                                       (         )
of PTE j≻k,C2 . In the figure, all combinations of Pr y j = 0 and Pr (yk = 0) below the 45-degree

line are consistent with PTE j≻k,C2 ≥ 0 . Alternatively, determining whether PTE j≻k,C2 ≥ 0 by

                                    (            )
reference to whether LB PTE j≻k,C2 ≥ 0 relies on only those combinations of the Pr (y• = 0) that

figure into the LB computation in (31). These combinations are shown in the darker shaded area.
          Figure 1b depicts the combinations of the Pr (y• = 0) consistent with LB PTE j≻k,C5 = 0 ,            (           )
            (              )
using LB PTE j≻k,C2 from figure 1a as a baseline reference. Since the C5 bounds involve the

marginal probabilities at both 0 and 1, the picture is drawn holding the Pr (y• = 1) at specific

values (shown in the figure's legend) and then tracing out the Pr (y• = 0) combinations consistent

            (              )
with LB PTE j≻k,C5 = 0 at those values. Combinations of the Pr (y• = 0) southeast of the

                                                                                     (
positively-sloped line segments are ones where the C2 and C5 LB PTE j≻k,C• are strictly positive.      )

                                                [figures 1a and 1b about here]


A Parametric Example
          To see how the bounds described above perform numerically, true probabilities and
corresponding bounds are computed under several different assumptions about the degree of cross-
component correlation of the elements of Y and about the PTE magnitudes. The calculations

                                                           (               )
assume that the y• have elements y•,m = 1 y*•,m > 0 with Y* ∼ MVN ⎡⎢ µ j, µ k ⎤⎥ , R . For all m
                                                                   ⎣           ⎦                   (               )
                                            (    )                         ( (           ))
µ j,m = Φ−1 (.1) , so that Pr y j,m = 1 = .1 . µ k,m = Φ−1 Pr y k,m = 1 , with Pr y k,m = 1 = .2 and       (           )
     (          )
Pr y k,m = 1 = .5 giving "small" and "large" TEs, respectively. R is a 2M×2M correlation matrix
with all off-diagonal elements equal to ρ , which is either 0 or .5 in this exercise. The results for
M=2, M=3, and M=4 are displayed in tables 2a-2c.35 In each cell appears the true joint probability
(which would be unknowable from observable data) as well as the corresponding LB and UB
(which under unconfoundedness would be identifiable in applications from the joint marginal

35
     The probabilities are generated using Mata's mvnormal simulator in Stata's version 15.1.




                                                                24
probabilities) or, in the case of the PTE j≻k,C• for C2 and C3, the point-identified true values.


                                       [tables 2a, 2b, 2c about here]


       Several results are noteworthy. First, as a consequence of the particular parameters
                                   (          )          (     )
specified for this exercise the LB Pj≻k,C• and LB Pk≻j,C• are the same for C0, C1, C2, and C4.

Also, in light of the discussion in the previous subsection, note that in some instances the
   (           )
LB PTE j≻k,C• exceed zero so that one can conclude that the PTE is positive even though its

specific magnitude is not identifiable. Finally, unlike the probability orderings among the Pj≻k,C•
and Pk≻j,C• from (26), there is no such necessary ordering among the PTE j≻k,C• . So while all the

results in tables 2a-2c numerically satisfy


                                                       ⎪⎧⎪ PTE           ⎪⎫⎪
                                                    ≥ ⎪⎨                   ⎪⎬ ≥ PTE
                                                                j≻k,C2
        PTE j≻k,C0 ≥ PTE j≻k,C1 ≥ PTE j≻k,C4                                        j≻k,C5
                                                                                           ,   (45)
                                                         ⎪⎪ PTE             ⎪⎪
                                                          ⎪⎩    j≻k,C3       ⎪⎭


this is not a general result but owes rather to the particular probability structures assumed here.


5. Estimating Bounds using Composite Outcomes Measures
What Are Composite Outcomes?
       Composite outcomes or endpoints are used widely as health status measures in clinical
evaluations, and are particularly prominent in studies involving cardiovascular disease outcomes.
For example, in a recent three-arm clinical trial comparing cardiovascular health effects of different
Mediterranean diets, the primary outcome studied by Estruch et al., 2018, is "a composite of
myocardial infarction, stroke, and death from cardiovascular causes." Occurrence of any or all of
the three outcomes over the study period indicates treatment failure while experiencing none of the
three implies treatment success. While particular components vary across studies, the Estruch et
al. approach is typical. Indeed composite-outcome measures are used broadly in clinical and social
science research even though such measures might not actually be dubbed composite outcomes in a
particular study's report. For instance, a standard measure of chronic obstructive pulmonary
disease (COPD) is the presence of emphysema and/or chronic bronchitis. While this corresponds
formally to a composite outcome, COPD is often not explicitly referred to as such.
       One might define a composite outcome in various ways (U.S. FDA, 2017). In a typical




                                                    25
application there is a set36 of M>1, often binary, components outcomes across which the composite
outcome is deemed to be a success or represent a "good" outcome only when all of its components
are "good" outcomes. Defined thusly, composite outcomes have an all-or-nothing character.
       As is standard, let the observed outcome data be determined by the potential outcomes and
the assigned treatment as


              (        )
       y = 1 x = x j × y j + 1( x = x k ) × yk ,                                           (46)


where x denotes a k-vector of exogenous covariates characterizing treatment that will take on one
of two possible values, x j or x k , corresponding to the treatments Tj and Tk . For immediate

                                                                     (
purposes it suffices to consider a generic scalar composite outcome 1 y ∈ Zc   ) where as above Z ⊂ Q
is a set containing particular values of y that correspond to a "good" outcome.


Using Composite Model Estimates to Compute Bounds and Point-Identified PTEs
       Recall from section 1 and eq. (4) that one general approach to estimation in the presence of
multiple outcomes is to define some measure that effectively collapses an M-dimension outcome
into a one-dimension outcome. This common empirical strategy is relevant for purposes at hand.
Specifically in this case one specifies and estimates a parametric or nonparametric composite-
outcome conditional probability model


          (        )
       Pr y ∈ Z x = pc (x) .                                                               (47)


With unconfounded treatment assignment (exogenous x), estimation of (47) yields

       !
          (                )
       Pr y ∈ Z x = x• → Pr (y• ∈ Z)                                                       (48)


Recall the bounds for treatment-preference characterizations C2-C5 derived in section 4. For these
characterizations the corresponding UBs and LBs are defined in terms of the estimands in (48),
                                  {}
each for Z = {0} and/or Z = 1 . As such, for C2-C5 standard estimation of particular composite-
                         c


outcome models yields the information required to estimate the bounds on Pj≻k,C• and PTE j≻k,C•


36
  While M=3 or M=4 are common, there are interesting cases where M is as small as two or much
larger than four.




                                                   26
so long as treatments are assigned exogenously. Such estimates also provide the information to
point identify the PTEs for C2 and C3 as described in section 4. (Note that the composite-outcome
PTEs for a "good" outcome Z = {0} (i.e. C2) and a "bad" outcome Z = 1 (i.e. C3) correspond to
                                                                 c
                                                                                                     {}
the boldface entries in tables 2a-2c.) While such composite-outcome model estimates may be of
interest in their own right in capturing some notions of "treatment effect"—perhaps explaining their
prominence in applications—a previously unappreciated attribute is that they provide information
essential to point identify or set identify PTEs of the sort proposed here.
          For C0 and C1, the same basic ideas apply although a potentially large number of Z
definitions may be required to estimate the components of the bounds (see section 4). Beyond the
algebraic complexities involved in computation of these bounds, a practical issue is whether the
                                                               !
                                                                                     (
available data are sufficiently rich to yield useful estimates Pr y ∈ Z x = x• for each Z defining an )
estimand (48) that is, in turn, involved in such computations. In particular, note that the
estimated probabilities associated with particular Z that are not represented in the available data
equal zero by method-of-moments or analog principles.37


6. Two Empirical Examples
Moving to Opportunity
          Data from the prominent Moving to Opportunity (MTO) experiment provide an illustrative

37
     While inference is not a main concern here, it might be noted that for the point-identified PTEs
nonparametric inference is straightforward. Letting I•,• be observation index sets defined in an

obvious manner, analog PTE estimates for C2 ( Z = {0} ) and C3 ( Zc = {1} ) are given by

          !
          PTE j≻k,C• =     1
                         # I2,k   ∑ n∈I   2,k
                                                (   )
                                                1 yn ∈ Zc −     1
                                                              # I2,j   ∑ n∈I   2,j
                                                                                         (
                                                                                     1 yn ∈ Zc   )
                       #
                             (
                     = Pr y ∈ Zc       x = x ) − Pr (y ∈ Z
                                                 #
                                                     k
                                                              c
                                                                          )
                                                                  x = x j = p•,k − p•,j

with the corresponding binomial variance estimates given by

                                   (
                           p•,j 1 − p•,j         )
                                           p•,k 1 − p•,k (        )
          ! !
             (           )
          var PTE j≻k,C• =
                               # I•,j
                                         +
                                               # I•,k
                                                         .


                                                           !
Large-sample results can be used to compute CIs from these var (…) . With set identification
inference is also possible but more complicated (see Imbens and Manski, 2004, and Chernozhukov
et al., 2013). Imbens and Manski, 2004, note that "researchers face a substantive choice whether to
report intervals that cover the entire identification region or intervals that cover the true
parameter value with some fixed probability…Which CI is of interest depends on the application."




                                                             27
example. These data and the experiment's results are reported in Ludwig et al., 2011 and 2013. The
experiment consisted of two intervention groups and a control group, but for simplicity only the
low-poverty voucher and control groups are considered here. The public-use "pseudo-individual"
sample, consisting of N=3,273 observations and described at www.nber.org/mtopuf, is used here.
After deleting observations with missing data the remaining sample contains N=2,120 subjects,
N=1,178 in the intervention group ( Tj ) and N=942 in the control group ( Tk ).

       Two exercises are conducted here. In the first, M=2 with binary outcomes obesity
(BMI≥40) and diabetes (HbA1c≥6.5); these were the outcomes considered in Ludwig et al., 2011.
In the second, M=4 with binary outcomes obesity, diabetes, hypertension (SBP≥140 and/or
DBP≥90), and depression (DSM-IV major depressive episode in the past year); this is a subset of
the outcomes considered in Ludwig et al., 2013. The results are summarized in table 3a. For these
data the bounds on the set-identified PTEs are seen to be rather broad, and in no instance
unambiguously informative about the sign of any of the PTEs. For C2 the point-identified
PTE j≻k,C2 indicate a positive (i.e. beneficial) effect of the intervention for both the M=2 and M=4

outcome definitions, whereas for C3 the results of the treatment are less clear.


                                        [table 3a about here]


Multiple Chronic Conditions
       A sample of N=887,309 adults ages 18-64 from the 2011, 2013, and 2015 Behavioral Risk
Factors Surveillance System (BRFSS) surveys is used to explore the determinants of adult chronic-
condition outcomes. The observed outcomes y are seven binary chronic-condition indicators:
cardiovascular disease, arthritis, depression, chronic lower-respiratory disease, cancer, diabetes, and
kidney disease. For this exercise an age "treatment" and a schooling "treatment" are considered
separately (for purposes of this brief illustrative exercise the paper won't dwell on whether
unconfoundedness is reasonable here). For age, Tj and Tk correspond to ages 18-44 and ages 45-
64; for schooling, Tj and Tk correspond to not being versus being a college graduate.

       The estimated bounds are reported in table 3b. The age PTEs for C2-C4 all suggest
unambiguously younger age as the preferred treatment, while for C0 and C1 the width of the PTE
bounds interval exceeds one. For the schooling PTEs, all the bound intervals straddle zero, while
the point-identified results for C2 and C3 suggest college graduation as the preferred treatment.38

38
  Stata code and data used to generate the results in tables 2a-3b and figure 1 are available in a
1.6MB .zip file, https://uwmadison.box.com/temo.zip. The readme file in the main directory
provides details.




                                                  28
                                            [table 3b about here]


7. Treatment-Preference Characterizations, Probabilities, and PTEs with Multiple
   Ordered Outcomes
       Instead of binary outcome measurement suppose each component of the y• is measured in

an ordered, categorical manner. That is, each of the M components can assume one of G possible
values in   {0,1,…,G −1} .   39
                                  In keeping with the ordering used previously, larger values of the

components of the y• correspond to increasingly undesirable outcomes. One prominent example in

a health-outcome context is the EQ-5D system describing M=5 dimensions of health: mobility, self-
care, usual activities, pain/discomfort and anxiety/depression (Devlin et al., 2018). The specific
dimensions are measured in G=3 (EQ-5D-3L) or G=5 (EQ-5D-5L) ordered levels. Among other
uses, EQ-5D data provide the foundation for a variety of health-related quality of life measures.
                                        5
Determining values associated with the 3 = 243 (3L) or 55 = 3125 (5L) possible health states
described by EQ-5D is a major aspect of EQ-5D-related research.40


Treatment-Preference Characterizations
       Analysis of treatment-preference and PTEs for ordered outcomes can proceed along
essentially the same lines as with binary outcomes, albeit with a few additional considerations. Let
C • * denote characterizations of treatment preference relevant in a multiple ordered-outcome
context. While various characterizations might be proposed only variants of the C •
characterizations already examined are considered here. Specifically let C0*, C1*, C2*, and C6*
correspond exactly to C0, C1, C2, and C6 as defined earlier. C3 is redefined to be C3* wherein
                         (                 ) (            )
Tj ≻C3* Tk if and only if y j ≠ (G − 1) ∧ yk = (G − 1) , where G is an M-vector whose elements all

equal G. That is, in C3* a "good" outcome is one where not all components are at their worst
possible levels while a "bad" outcome is one where each component is at its worst possible level.
                                                          (            ) (                        )
C4* is defined such that Tj ≻C4* Tk if and only if y j = 0 ∧ yk ≠ 0 ∨ y j ≠ (G − 1) ∧ yk = (G − 1) ,

and C5* is defined such that Tj ≻C5* Tk if and only if y j = 0 ∧ yk = (G −1) . The sets Yj≻k,C•* and


39
  Of course the binary case considered heretofore is just the special case G=2. Only for notational
simplicity is it assumed that each component assumes the same number of possible categorical
values; the logic of what follows in no way relies on this.
40
  Another example is the Apgar score, used for assessment of neonates' health (American Academy
of Pediatrics, 2006; Hoynes et al., 2015). Apgar scores use M=5 components measured across G=3
categories with larger values representing better health.




                                                     29
Yk≻j,C•* are defined in an obvious manner consistent with their definitions in section 3.

          Apart from C0* these characterizations do not require across-component measurement
comparability for coherence. That is, any particular value among the G categories of (say) the m-
th and m'-th components of y j and yk need not represent equivalence between those components.

Since C1*-C6* rely only on element-by-element comparisons between each of the M components of
the y j and yk but not on comparisons across the M components of each y• , the M components' G

categories may be measured in any manner deemed relevant. For C1*-C6* each component's
measure can be changed from            {0,…,G −1}       to different values   {v0,m,…, vG−1,m } ;   the same

probability and PTE results obtain if the ordering of the v• respects the {0,…,G −1} ordering
and if references to 0 and G-1 in the C2*-C5* definitions become references to v0,m and vG−1,m .
          With C0*, however, the sums s j and sk entail some degree of cross-component

comparability just as when the the y• are binary. Whether it is reasonable to endow what are

essentially ordered component outcomes with interval- or ratio- scale properties will depend on an
application's particulars. In any event the summands defining s j and sk are typically apples and

oranges. While it may sometims be frowned upon, computing indexes, scores, or scales from sums
of unlike components—whether the components are binary or ordered—is longstanding practice in
psychometric and clinical settings. Without defending this approach it is discussed here as a
benchmark because of its prominence in such fields: despite its apples-oranges character the
approach is used widely and sometimes rationalized explicitly.41
          For concreteness table 4 provides an example of the C • * characterizations for M=2 and
G=3. There are G2M = 81 possible values of the 1×4 vector of potential outcomes Y. Of these 81
possible values, 31 correspond to values of Y for which Tj ≻C•* Tk for at least one of the C • * .


                                                [table 4 about here]


Bounding P                 and PTE               with Multiple Ordered Outcomes
                j ≻k,C•∗             j ≻k,C•∗

          Once a particular C • * has been selected, conceptualizing Pj≻k,C•* , Pk≻j,C•* , and
PTE j≻k,C•* and computing their corresponding bounds proceeds in essentially the same manner as

in the binary case. The relevant joint probabilities are determined and the observed data are
consulted to estimate the corresponding probability and PTE bounds. The same probability

41
     Kahneman, 2011, chapter 21, offers an interesting assessment of such measurement issues.




                                                        30
ordering as described in (26) obtains here for Pj≻k,C•* with reference to C • * instead of C • .

       As before identification depends on the assumption of unconfounded or exogenous
treatment assignment. Analogous to the binary case, Pj≻k,C•* is point identified for C2*, C3*, and

C6*. As G increases the number of possible Y outcomes grows rapidly. However, in deriving the
relevant UBs and LBs (or point-identified PTEs), the concern is not with the entire Y vector but
rather with the particular y• whose probabilities enter the bound definitions. As noted earlier, the

relevant joint marginal probabilities may be technically identified even though small empirical cell
sizes may be of concern regarding the data's ability to deliver useful estimates. To frame these

                                           {
issues, define the sets J j≻k,C•* = y j y j ∈ Yj≻k,C•*          }                  {              }
                                                                    and K j≻k,C•* = yk yk ∈ Yj≻k,C•* . Table 5

displays for several values of M and G the number of elements in the sets Yj≻k,C•* and J j≻k,C•* .
# J j≻k,C•* and, symmetrically, # K j≻k,C•* increase rapidly with G and with M.


                                                [table 5 about here]


Some Implications for Multiple Continuous-Outcome Measures
       Suppose the component outcomes in the y• are measured continuously. Such measurements

can be coarsened into G ordered, categorical measures, sometimes known as interval measurement:

                                               ⎧⎪                       ⎫⎪
                 ⎪⎧⎪ 0         ⎪⎫⎪               ⎪
                                                      (
                                                ⎪⎪ −∞, t          ⎤
                                                             0,m ⎥⎦
                                                                         ⎪⎪
                                                                          ⎪⎪
                   ⎪             ⎪⎪              ⎪
        y j,m = ⎪⎨ !
         coarse
                                  ⎬ ↔ y j,m ∈ ⎪⎨           !               ⎪⎬ ,                       (49)
                   ⎪⎪             ⎪⎪             ⎪⎪                         ⎪⎪
                    ⎪⎪⎩ G −1       ⎪⎪⎭            (
                                                  ⎪⎪ t(G−2),m , ∞
                                                   ⎪⎪
                                                                    )        ⎪⎪
                                                                              ⎪⎪
                                                    ⎩                          ⎭


where the tg,m are component-specific thresholds or cut points.

       Once coarsened, PTEs for the ycoarse
                                     j,m    can be considered using the strategies discussed

above. Selecting a useful degree of coarsening (G) involves trading off information loss against
computational complexity. It might be noted that coarsened continuous measures are in fact used
in multiple-outcome applications. Two examples are composite-outcome component failure times
coarsened to binary N-month survival indicators, and continuously-measured allostatic load
components coarsened to binary threshold-crossing indicators (Gruenwald et al., 2006).42


42
 Though bounds computation may be challenging, one might tackle directly analysis of continuous
multiple outcomes in, say, a multivariate-normal framework. Using coarsened continuous outcomes
                                                                                         (cont.)


                                                           31
8. Summary
       This paper has suggested strategies for defining, identifying, and estimating treatment
effects in contexts where understanding determinants of multiple outcomes is the goal. Notions of
treatment preference and their corresponding probability structures and PTEs have been proposed
as organizing principles within which questions regarding multiple outcomes might be integrated
and pursued. While the paper has suggested seven characterizations of treatment preference
appropriate to multiple-outcome contexts, more can be imagined and this should prove a useful
research agenda. Regardless of the preference characterization chosen for a particular analysis, that
choice should be made before the data are revealed: Scientific fairness forbids "preference mining."
       In at least three other areas future research might prove valuable. First is the extension to
the multiple-outcome case of methods to handle confounded or endogenous treatment assignment.
Second is a consideration in multiple-outcome contexts of strategies to enhance the informativeness
of set identification, i.e. tighten the bounds (e.g. Frandsen and Lefgren, 2018, Manski and Pepper,
2000). Third is the fundamental consideration of why in applications outcome vectors are specified
in the manner they are, i.e. how do particular specifications of Y or y• more or less well describe

the outcomes that actually matter to decisionmakers.
       Returning in closing to a statement from section 1, it is hoped this paper has stimulated
readers to assess with new perspectives their approaches to understanding multiple outcomes and
their determinants. If the paper accomplishes only this, it will have served some valuable purpose.


Acknowledgments
       I am grateful to Domenico Depalo, Paddy Gillespie, Hyunseung Kang, Chuck Manski, and
participants in presentations at Queen's University Belfast, the University of Bergamo, the
University of Chicago, and the University of Wisconsin-Madison for helpful comments, suggestions,
and guidance on the literature. Partial support was provided by RWJF Evidence for Action Grant
73336 and by the UW-Madison Center for Demography and Ecology under NICHD grant
P2CHD047873.




(cont.)
discards some information and can itself present computational challenges, but it is conceptually
straightforward and readily accommodates nonparametric identification and estimation.




                                                 32
References
Abadie, A. and M.D. Cattaneo. 2018. "Econometric Methods for Program Evaluation." Annual
   Review of Economics 10: 465-503.
Alkire, S. and J. Foster. 2010. "Counting and Multidimensional Poverty Measurement." Journal of
   Public Economics 95: 476-487.
American Academy of Pediatrics, Committee on Fetus and Newborn; American College of
   Obstetricians and Gynecologists and Committee of Obstetric Practice. 2006. "The Apgar
   Score." Pediatrics 117: 1444-1447.
Angrist, J.D. and G.W. Imbens. 1995. "Two-Stage Least Squares Estimation of Average Causal
   Effects in Models with Variable Treatment Intensity." Journal of the American Statistical
   Association, 90: 431–442.
Athey, S. et al. 2016. "Estimating Treatment Effects using Multiple Surrogates: The Role of the
   Surrogate Score and the Surrogate Index." arXiv:1603.09326v2 [stat.ME].
Athey, S. and G.W. Imbens. 2017. "The Econometrics of Randomized Experiments." Handbook of
   Economic Field Experiments 1: 73-140.
Boole, G. 1854. An Investigation of the Laws of Thought, of Which are Founded the Mathematical
   Theories of Logic and Probabilities. London: Walton and Maberly.
Buttorff, C. et al. 2017. Multiple Chronic Conditions in the United States. RAND Corporation,
   Report TL-221-PFCD.
Cebul, R.D. et al. 2011. "Electronic Health Records and Quality of Diabetes Care." NEJM 365: 825-
   833.
Chernozhukov, V. et al. 2013. "Intersection Bounds: Estimation and Inference." Econometrica 81:
   667-737.
Coleman-Jensen, A. et al. 2018. Household Food Security in the United States in 2017. Washington:
   USDA, Economic Research Service.
Devlin, N.J. et al. 2018. "Valuing Health-Related Quality of Life: An EQ-5D-5L Value Set for
   England." Health Economics 27: 7-22.
Dmitrienko, A. and R.B. D'Agostino. 2018. "Multiplicity Considerations in Clinical Trials." NEJM
   378: 2115-2122.
Dodge, K.A. et al. 2014. "Impact of Early Intervention on Psychopathology, Crime, and Well-being
   at Age 25." American Journal of Psychiatry 172: 59-70.
Estruch, R. et al. 2018. "Primary Prevention of Cardiovascular Disease with a Mediterranean Diet
   Supplemented with Extra-Virgin Olive Oil or Nuts." NEJM 378: e34(1)-e34(14).
Färe, R. and L. Svensson. 1980. "Congestion of Production Factors." Econometrica 48: 1745-1753.
Fleishman, J.A. et al. 2014. "Screening for Depression Using the PHQ-2: Changes over Time in
   Conjunction with Mental Health Treatment." Agency for Healthcare Research and Quality


                                               33
   Working Paper No. 14002.
Frandsen, B.R. and L.J. Lefgren. 2018. "Partial Identification of the Distribution of Treatment
   Effects with an Application to the Knowledge Is Power Program (KIPP)." NBER w.p. 24616.
Geronimus, A.T. et al. 2006. "'Weathering' and Age Patterns of Allostatic Load Scores Among
   Blacks and Whites in the United States." American Journal of Public Health 96: 826-833.
Gruenwald, T.L. et al. 2006. "Combinations of Biomarkers Predictive of Later Life Mortality."
   PNAS 103: 14158–14163.
Hansen,   B.   2018.   Econometrics     (January,     2018,   version).   www.ssc.wisc.edu/~bhansen/
   econometrics/
Hanssen, D.J. et al. 2014. "Physical, Lifestyle, Psychological, and Social Determinants of Pain
   Intensity, Pain Disability, and the Number of Pain Locations in Depressed Older Adults." Pain
   155: 2088-2096.
Hoynes, H. et al. 2015. "Income, the Earned Income Tax Credit, and Infant Health." AEJ
   Economic Policy 7: 172-211.
Imbens, G.W. and C.F. Manski. 2004. "Confidence Intervals for Partially Identified Parameters."
   Econometrica 72: 1845-1857.
Imbens, G.W. and J.M. Wooldridge. 2009. "Recent Developments in the Econometrics of Program
   Evaluation." Journal of Economic Literature 47: 5-86.
Institute of Medicine. 2006. Performance Measurement: Accelerating Improvement. Washington:
   The National Academies Press.
Jackson, C.K. 2018. "What Do Test Scores Miss? The Importance of Teacher Effects on Non–Test
   Score Outcomes." Journal of Political Economy 126: 2072–2107.
Khan, N. et al. 2008. "Effect of prescription drug coverage on health of the elderly." Health Services
   Research 43: 1576-1597.
Kahneman, D. 2011. Thinking, Fast and Slow. New York: Farrar, Straus and Giroux.
Loeb, S., and D. Figlio. 2011. "School Accountability." in E. A. Hanushek et al., Eds. Handbook of
   the Economics of Education, Vol. 3. San Diego: North Holland.
Look AHEAD Research Group. 2013. "Cardiovascular Effects of Intensive Lifestyle Intervention in
   Type 2 Diabetes." NEJM 369:145-154.
Ludwig, J. et al. 2011. "Neighborhoods, Obesity, and Diabetes—A Randomized Social Experiment."
   NEJM 365: 1509-1519.
Ludwig, J. et al. 2013. "Long-Term Neighborhood Effects on Low-income Families: Evidence from
   Moving to Opportunity." American Economic Review Papers and Proceedings 103: 226-231.
Lynn, J. et al. 2015. "Value-Based Payments Require Valuing What Matters to Patients." JAMA
   314: 1445-1446.
Manski, C.F. 2004. "Statistical Treatment Rules for Heterogeneous Populations." Econometrica 72:


                                                 34
   1221–1246.
Manski, C.F. 2018. "Reasonable Patient Care under Uncertainty." Health Economics 27: 1397-1421.
Manski, C.F. and J.V. Pepper. 2000. "Monotone Instrumental Variables: With an Application to
   the Returns to Schooling." Econometrica 68: 997-1010.
Manski, C.F. and A. Tetenov. 2018. "Trial Size for Near-Optimal Choice between Surveillance and
   Aggressive Treatment: Reconsidering MSLT-II." Working Paper, Northwestern University.
Mullahy, J. 2018a. "Individual Results May Vary: Inequality-Probability Bounds for Some Health-
   Outcome Treatment Effects." Journal of Health Economics 61: 151-162 .
Mullahy, J. 2018b. "The Anatomy of Composite Health Outcomes." (in progress).
Nissen, S.E. et al. 2016. "Cardiovascular Safety of Celecoxib, Naproxen, or Ibuprofen for Arthritis."
   NEJM 375: 2519-2529.
Nolan, B. and C.T. Whelan. 2010. "Using Non-Monetary Deprivation Indicators to Analyze
   Poverty and Social Exclusion: Lessons from Europe?" Journal of Policy Analysis and
   Management 29: 305-325.
Parving, H.-H. et al. 2012. "Cardiorenal End Points in a Trial of Aliskiren for Type 2 Diabetes."
   NEJM 367: 2204-2213.
Pesko, M.F. et al. 2016. "The Effect of Potential Electronic Nicotine Delivery System Regulations
   on Nicotine Product Selection." Addiction 111: 734-744.
Porter, M.E. et al. 2015. "Standardizing Patient Outcome Measures." NEJM 374: 504-506.
Romano, J.P et al. 2010. "Multiple Testing." in The New Palgrave Dictionary of Economics, Online
   Edition. London: Palgrave Macmillan.
Rosenfield, K. et al. 2016. "Randomized Trial of Stent versus Surgery for Asymptomatic Carotid
   Stenosis." NEJM 374: 1011-1020.
Ruoff, C. and D. Rye. 2016. "The ICSD-3 and DSM-5 Guidelines for Diagnosing Narcolepsy:
   Clinical Relevance and Practicality." Current Medical Research and Opinion 32: 1611-1622.
Sarma, S. et al. 2015. "The Effect of Leisure-Time Physical Activity on Obesity, Diabetes, High BP
   and Heart Disease among Canadians: Evidence from 2000/2001 to 2005/2006." Health
   Economics 24: 1531-1547.
Shwartz, M. et al. 2015. "Composite Measures of Health Care Provider Performance: A Description of
   Approaches." Milbank Quarterly 93: 788-825.
Siebert, S. et al. 2016. "Characteristics of Rheumatoid Arthritis and Its Association with Major
   Comorbid Conditions: Cross-sectional Study of 502 649 UK Biobank Participants." RMD Open
   doi: 10.1136/rmdopen-2016-000267.
Stauffer, V.L. et al. 2018. "Evaluation of Galcanezumab for the Prevention of Episodic Migraine—
   The EVOLVE-1 Randomized Clinical Trial." JAMA Neurology: 75: 1080-1088.
Stone, G.W. et al. 2018. "Transcatheter Mitral-Valve Repair in Patients with Heart Failure."


                                                 35
   NEJM DOI: 10.1056/NEJMoa1806640.
U.S. Federal Deposit Insurance Corporation. 1997. Uniform Financial Institutions Rating System.
   FDIC Statements of Policy. Washington: FDIC (Retrieved September 27, 2018, at
   www.fdic.gov/ regulations/laws/rules/5000-900.html).
U.S. Food and Drug Administration. 2017. Multiple Endpoints in Clinical Trials—Guidance for
   Industry. USDHHS/FDA CBER/CDER.
U.S. National Heart, Lung, and Blood Institute. 2018. "Metabolic Syndrome." www.nhlbi.nih.gov/
   health-topics/metabolic-syndrome (retrieved Oct. 16, 2018).
Walitt, B. et al. 2015. "The Prevalence and Characteristics of Fibromyalgia in the 2012 National
   Health Interview Survey." PLoS One doi: 10.1371/journal.pone.0138024.
Williamson, P.R. et al. 2017. "The COMET Handbook: version 1.0." Trials 18: 280.




                                               36
Appendix A: Computing Bounds on Pj≻k,C1 and Pj≻k,C0
          This appendix considers approaches to computing lower and upper bounds on Pj≻k,C1 . The
same basic logic can be used to obtain bounds on Pj≻k,C0 , so those details will not be considered
here. In either case the results for bounds on Pk≻j,C• follow symmetrically. Combined, these bounds
can then be used to obtain bounds on the corresponding PTE j≻k,C• as in section 4.

          Using the notation of section 3, (10) can be written as
                              (
          Pj≻k,C1 = Pr yk ≥ y j            )          (
                                               = Pr Y ∈ Yj≻k,C1            )   =     ∑ Y∈Y         j≻k,C1
                                                                                                            Pr (Y ) .                       (A.1)

This follows since the events Y ∈ Yj≻k,C1 are disjoint events. The computations for UB Pj≻k,C1                                                (           )
          (           )
and LB Pj≻k,C1 are more complicated than those for C2-C5 shown in section 4. Well-defined

bounds can be obtained, although they may or may not turn out to be informative.


Computing Upper Bounds on Pj ≻k,C1

        From Boole's general approach, an upper bound on the probability of the union of N
arbitrary and possibly non-disjoint events e n is given by
               ⎛ ⎛ N             ⎞⎞
          UB ⎜⎜⎜Pr ⎜⎜∪ n=1 e n ⎟⎟⎟⎟⎟⎟ = min
               ⎝ ⎝               ⎠⎠            {∑   N
                                                    n=1
                                                        Pr    (en ),1} .                                                                    (A.2)

To be useful, information on the marginal probabilities Pr (e n ) must be available. This general
approach can be used to compute a legitimate upper bound on Pj≻k,C1 as

      (
  UB Pj≻k,C1      )
                            ⎧
                            ⎪⎛
                      = min ⎨⎜⎜∑ Y∈Y
                            ⎩⎝
                            ⎪
                            ⎪       j≻k,C1
                                                          { ( )
                                           min Pr y j , Pr (yk )
                                                                                            ⎫
                                                                                   }⎞⎟⎟⎟⎠,1⎪⎬⎪⎪⎭   ≥ min      {∑    Y∈Yj≻k,C1           }
                                                                                                                                Pr (Y ),1 .       (A.3)

This follows since the 3M − 2M events Y ∈ Yj≻k,C1 that jointly define Pj≻k,C1 , though themselves

mutually disjoint, are not fully observable. As such their respective upper bounds
              (           )        { ( )                  }
          UB Pr (Y ) = min Pr y j , Pr (yk ) , for each Y ∈ Yj≻k,C1 ,                                                                       (A.4)

are required to determine an overall UB Pj≻k,C1 .         (           )
          However (A.4) will generally result in an unnecessarily large UB Pj≻k,C1 . Drawing on                          (          )
Boole (1854, chapter XIX), if any single marginal event probability Pr (y• ) appears more than once

in the sum SY = ∑ Y∈Y
                                  j≻k,C1
                                               { ( )                  }
                                           min Pr y j , Pr (yk ) in the RHS of (A.3) then that sum should be

                                                !
redefined as a different sum, say SY , that includes that particular marginal event probability as a




                                                                       37
summand only once, thus resulting in a smaller (i.e. tighter) upper bound.43
          Such considerations are relevant here since the probabilities of the marginal events y• for
each Y ∈ Yj≻k,C1 may appear multiple times in SY . Consider for concreteness the seven cells in the

C1 column of table 1 corresponding to the seven Y events that involve the marginal event

      ⎣      ⎦                                                                                 ( )
yk = ⎡⎢1,1,1⎤⎥ (rows 1-7 of the table). If Pr (yk ) is less than the corresponding Pr y j for two or
                                                                                      !
more of those seven events then that Pr (yk ) should appear only once as a summand in SY .
                                             !
                                                                   (        )
Indeed, that Pr (yk ) will appear in the sum SY that defines UB Pj≻k,C1 either exactly once (if it

is smaller than any one or more of the seven corresponding Pr (y j ) ) or not at all (if it is larger than

all the corresponding Pr (y j ) ).

          Thus to compute the UB, let
                        { ( )
           a Y = min Pr y j , Pr (yk )} = UB(Pr (Y)) , for each Y ∈ Yj≻k,C1 .                        (A.5)

Define AY = {a Y     } , A• = {y• Pr (y• ) ∈ AY } . Importantly the standard definition        of a set as a

collection of distinct objects44 is used in defining A j and Ak . Then, supposing there are no ties

            ( )
where Pr y j = Pr (yk ) ,45
                            ⎧⎪⎛                                 ⎞ ⎫⎪
              (       )      ⎪⎪⎩⎝ j  j
                                                ( )
           UB Pj≻k,C1 = min ⎨⎜⎜∑ y ∈A Pr y j + ∑ y ∈A Pr (yk )⎟⎟⎟,1⎬ .
                                                  k  k          ⎠ ⎪⎪⎭
                                                                                                     (A.6)



Computing Lower Bounds on Pj ≻k,C1

                                                                                    (      )
          In the general case where events may or may not be disjoint an LB Pj≻k,C1 is given by

              (       )
           LB Pj≻k,C1 = max Y∈Y
                                   j≻k,C1
                                            {max {Pr(y ) + Pr(y ) −1, 0}} .
                                                       j        k
                                                                                                     (A.7)

When the events Y are known to be disjoint a lower bound at least as tight if not tighter than
(A.7) is obtained as
              (       )
           LB Pj≻k,C1 = ∑ Y∈Y
                                 j≻k,C1
                                               { ( )                 }
                                          max Pr y j + Pr (yk ) −1, 0 .                              (A.8)

          Given the particular structure of the outcomes examined here, however, a still-tighter LB is
possible to obtain without requiring any additional assumptions. The motivation for this approach

43
  Discerning this result from Boole's mid-nineteenth-century prose was, for the author of this paper
at least, a challenging exercise.
44
     Formally {2, 2,1, 3} and {b, c, a, c} are not sets but {2,1, 3} and {b, c, a } are.
45
     Ties can be handled at the cost of additional computations.




                                                           38
is that in applications—particularly where M is large—it may be found that all the summands
       { ( )                    }
max Pr y j + Pr (yk ) −1, 0 in (A.8) are zero thus resulting in the uninformative LB Pj≻k,C1 = 0 .    (         )
          To circumvent this, note that there are 2M+1 − 3 events Y in Yj≻k,C1 where y j = 0 or
                                                       A                      A
yk = 1 or both; let this subset of Yj≻k,C1 be denoted Yj≻k,C1 . For the Y in Yj≻k,C1 the
                                                                                   A
corresponding inequality events yk ≥ y j can be aggregated across the elements of Yj≻k,C1 to define

two      disjoint   sets       A1
                              Yj≻k,C1   {
                                      = Y y j = 0 ∧ yk ≠ 0           }     and    A2
                                                                                 Yj≻k,C1     {              }
                                                                                         = Y y j ≠ 0 ∧ yk = 1       with
 A1        A2        A                  A1
Yj≻k,C1 ∪ Yj≻k,C1 = Yj≻k,C1 (note that Yj≻k,C1 coincides with Yj≻k,C2 ). In the M=3 example, for
                                       A1                                            A2
instance, in the C1 column of table 1 Yj≻k,C1 corresponds to rows 1 plus 8-13 while Yj≻k,C1

corresponds to rows 2-7. The LBs on the probabilities of these aggregated events are

             ( (     A1
          LB Pr Y ∈ Yj≻k,C1    ))    ( (
                            = LB Pr y j = 0 ∧ yk ≠ 0       ))
                                 = max {Pr (y j = 0) + Pr (yk ≠ 0) −1, 0}                                  (A.9)

                                 = max {Pr (y j = 0) − Pr (yk = 0), 0}

          LB (Pr (Y ∈ Yj≻k,C1
                       A2
                              )) = LB(Pr(y j ≠ 0 ∧ yk = 1))
                                 = max {Pr (y j ≠ 0) + Pr (yk = 1) −1, 0}                                  (A.10)

                                 = max {Pr (yk = 1) − Pr (y j = 0), 0}

Thus

             (
          LB Pj≻k,C1   )        ( (     A1
                           = LB Pr Y ∈ Yj≻k,C1          ))           ( (  A2
                                                             + LB Pr Y ∈ Yj≻k,C1    ))   +
                                                                                                           (A.11)
                               ∑ Y∈Y  j≻k,C1
                                               A
                                             \Yj≻k,C1        { ( )
                                                        max Pr y j + Pr (yk ) −1, 0  }
The formulation in (A.11) will be no smaller than (A.8) but in some instances will be larger, i.e.
the bound in (A.11) will be at least as tight as the bound in (A.8).46




46
     It should be noted that aggregations other than those used to define e1 and e2 are possible and
potentially more informative. The particular e1 and e2 aggregations described here were selected
because they are informative with respect to the data structures described in section 4 and
summarized in tables 2a-2c.




                                                                39
Appendix B: Treatment-Preference Characterizations, Probabilities, and PTEs with
  Multiple Binary Outcomes and More than Two Treatments
          The relevant comparison of multiple treatment outcomes sometimes involves more than two
treatments. In a study of diet-related cardiovascular disease prevention Estruch et al., 2018,
consider three alternative treatments: Mediterranean diet supplemented with extra-virgin olive oil;
Mediterranean diet supplemented with mixed nuts; and control diet (advice to reduce dietary fat).
Nissen et al., 2016, compare in a three-arm trial the cardiovascular safety profiles of celecoxib,
ibuprofen, and naproxen for patients with osteoarthritis or rheumatoid arthritis.47 In both studies,
composite cardiovascular endpoints are of primary interest.
          This appendix considers briefly extensions of the results in sections 3 and 4 to such
treatment settings, focusing on the three-treatment case for simplicity. Extending the treatment
preference characterizations from section 3 to the three-treatment case is largely straightforward.


Treatment Preference and PTEs with More than Two Treatments
          To show the results generically, let j, k, ℓ ∈ {0,1, 2} , j ≠ k ≠ ℓ ≠ j , index the three distinct
treatments, Tj, Tk , and Tℓ , and corresponding potential outcomes, y j, yk , and yℓ , so that the
                                         ⎡           ⎤
1×3M vector of potential outcomes is Y = ⎢ y j yk yℓ ⎥ . Characterizations C •+ correspond to the
                                         ⎣           ⎦
C • in defined in section 3:
                              ((            ) (
          Pj≻{k,ℓ},C0+ = Pr Tj ≻C0 Tk ∧ Tj ≻C0 Tℓ         ))
                                                                                                        (B.1)
                         = Pr ((sk > s j ) ∧ (sℓ > s j ))

          Pj≻{k,ℓ},C1+   = Pr ((Tj ≻C1 Tk ) ∧ (Tj ≻C1 Tℓ ))
                                                                                                        (B.2)
                         = Pr ((yk ≥ y j ) ∧ (yℓ ≥ y j ))

          Pj≻{k,ℓ},C2+   = Pr ((Tj ≻C2 Tk ) ∧ (Tj ≻C2 Tℓ ))
                                                                                                        (B.3)
                         = Pr ((y j = 0) ∧ (yk ≠ 0) ∧ (yℓ ≠ 0))

          Pj≻{k,ℓ},C3+   = Pr ((Tj ≻C3 Tk ) ∧ (Tj ≻C3 Tℓ ))
                                                                                                        (B.4)
                         = Pr ((y j ≠ 1) ∧ (yk = 1) ∧ (yℓ = 1))

          Pj≻{k,ℓ},C4+   = Pr ((Tj ≻C4 Tk ) ∧ (Tj ≻C4 Tℓ ))
                                                                                                        (B.5)
                         = Pr (((y j = 0) ∧ (yk ≠ 0) ∧ (yℓ ≠ 0)) ∨ ((y j ≠ 1) ∧ (yk = 1) ∧ (yℓ = 1)))


47
     See Mullahy, 2018a (p. 158) for a related discussion in the M=1 case with continuous outcomes.




                                                          40
                            ((            ) (
          Pj≻{k,ℓ},C5+ = Pr Tj ≻C5 Tk ∧ Tj ≻C5 Tℓ        ))
                                                                                                              (B.6)
                        = Pr ((y j = 0 ∧ yk = 1) ∨ (y j = 0 ∧ yℓ = 1))

          Pj≻{k,ℓ},C6(Z) = Pr ((Tj ≻C6(Z) Tk ) ∧ (Tj ≻C6(Z) Tℓ ))
                       +

                                                                                                              (B.7)
                                  ((                 ) (
                           = Pr y j ∈ Z ∧ yk ∈ Zc ∨ y j ∈ Z ∧ yℓ ∈ Zc          ))
In (B.1)-(B.7), P                  is shorthand for "the probability that treatment Tj is preferred to both
                    j≻{k,ℓ},C•+

treatment Tk and treatment Tℓ given characterization C •+ ." Analogous to (26) it can be shown

that
                                                                  ⎪⎧⎪ P                  ⎪⎫⎪
                                                                    ⎪ j≻{k,ℓ},C2+          ⎪
          Pj≻{k,ℓ},C0+ ≥ Pj≻{k,ℓ},C1+ ≥ Pj≻{k,ℓ},C4+            ≥ ⎨                        ⎬ ≥ Pj≻{k,ℓ},C5+   (B.8)
                                                                    ⎪⎪ P           +
                                                                                           ⎪⎪
                                                                     ⎪⎪⎩ j≻{k,ℓ},C3         ⎪⎪⎭
          How to characterize PTEs in these cases is not immediately evident. Specifically, given the
characterizations of treatment preference C •+ , what are the relevant comparators or contrasts? In
the two-treatment case the appropriate contrast is obvious, but when three or more treatments are
involved several options might reasonably be considered.48 Two possible PTE definitions based on
(B.1)-(B.7) are discussed here, but others might certainly be considered; in any event the
specification of any particular PTE should be tied to the evaluation question or treatment decision
at hand.
          In the first the PTE is defined by the difference between any of (B.1)-(B.7) and the
probability that both Tk and Tℓ are preferred to Tj given characterization C •+ . This latter

probability is given by
                             ((           ) (
          P{k,ℓ}≻j,C•+ = Pr Tk ≻C• Tj ∧ Tℓ ≻C• Tj ,        ))                                                 (B.9)

so that
          PTEA
             j≻{k,ℓ},C•+           ((         ) (                 ))      ((
                         = Pr Tj ≻C• Tk ∧ Tj ≻C• Tℓ − Pr Tk ≻C• Tj ∧ Tℓ ≻C• Tj            ) (            ))   (B.10)
                            = Pj≻{k,ℓ},C•+ − P{k,ℓ}≻j,C•+

The second PTE definition is given by the difference between any of (B.1)-(B.7) and the
probability that Tk and/or Tℓ is preferred to Tj under C • . This latter probability is

             ((            ) (
          Pr Tk ≻C• Tj ∨ Tℓ ≻C• Tj       ))                                                                   (B.11)

so that
                                                ((               ) (
          PTEBj≻{k,ℓ},C•+ = Pj≻{k,ℓ},C•+ − Pr Tk ≻C• Tj ∨ Tℓ ≻C• Tj                 ))                        (B.12)

48
     For instance, Nissen et al., 2016, consider pairwise comparisons.




                                                            41
Bounds on Treatment-Preference Probabilities and PTEs
          With three or more treatments, computing bounds for the C0+ and C1+ characterizations
is quite complicated and won't be pursued here. For C2+ − C6+ the bounds are straightforward to
derive and, under unconfoundedness, estimate. These are derived here for C2+ but the same logic
applies directly for C3+ (a mirror image of C2+ ), C5+ , C6+ , and (with a bit more algebra) for
C4+ . (Unlike the two-treatment setting, the PTEs for C2+ , C3+ , and C6+ are no longer point
identified.)
                                                                           ((      )
          From (B.3), the probability to be bounded is Pr y j = 0 ∧ (yk ≠ 0) ∧ (yℓ ≠ 0) . Using)
Boole's general results, it follows that

               (              )        { ( )
          UB Pj≻{k,ℓ},C2+ = min Pr y j = 0 , Pr (yk ≠ 0), Pr (yℓ ≠ 0)         }               (B.13)
                                  = min {Pr (y j = 0),1 − Pr (yk = 0),1 − Pr (yℓ = 0)}

and

               (              )        { ( )
          LB Pj≻{k,ℓ},C2+ = max Pr y j = 0 + Pr (yk ≠ 0) + Pr (yℓ ≠ 0) − 2, 0           }     (B.14)
                                  = max {Pr (y j = 0) − (Pr (yk = 0) + Pr (yℓ = 0)), 0}

Whether the LBs are informative and, if so, how such information could be used to discern the
preferred treatment are, of course, relevant questions in applications.49 In practice one can compute
these bounds for the permutations of j, k, ℓ based (as in section 5) on estimates of the composite-

                                   (               )
outcome probabilities Pr y = 0 x = x• under unconfoundedness assumptions and given observed

                          (            )
outcome data y = 1 x = x j y j + 1(x = x k ) yk + 1(x = x ℓ ) yℓ .

          Bounds on the PTEs defined in (B.10) and (B.12) follow from (B.13)-(B.14) and from
bounds on the subtrahends in (B.10) and (B.12). The latter are:

                      (                 (( )   )
          UBA = UB P{k,ℓ}≻j,C2+ = UB y j ≠ 0 ∧ (yk = 0) ∧ (yℓ = 0)       )                    (B.15)
                                  = min {1 − Pr (y j = 0), Pr (yk = 0), Pr (yℓ = 0)}

          LBA = LB (P{k,ℓ}≻j,C2 ) = LB ((y j ≠ 0) ∧ (yk = 0) ∧ (yℓ = 0))
                                           +
                                                                                              (B.16)
                                 = max {Pr (yk = 0) + Pr (yℓ = 0) − Pr (y j = 0) −1, 0}




49
     For any of the j, k, ℓ arrangements, it is straightforward to see that at most one of the three LBs,

       { (         ) (                                 ) }
max Pr y j = 0 − Pr (yk = 0) + Pr (yℓ = 0) , 0 , can be nonzero.




                                                             42
                     ( ((               ) (
        UBB = UB Pr Tk ≻C2 Tj ∨ Tℓ ≻C2 Tj           )))
                                                                                                (B.17)
                      {
             = min Pr (yk = 0) + Pr (yℓ = 0),1 − Pr y j = 0  (           )}
                     ( ((              ) (
        LBB = LB Pr Tk ≻C2 Tj ∨ Tℓ ≻C2 Tj          )))
                                                                                                (B.18)
                      {      {                           }
             = max max Pr (yk = 0), Pr (yℓ = 0) − Pr y j = 0 , 0     (        ) }
It follows that:

           (                     ) { ( )                                        }
        UB PTEAj≻{k,ℓ},C2+ = min Pr y j = 0 ,1 − Pr (yk = 0),1 − Pr (yℓ = 0) − LBA              (B.19)

        LB (PTE    A
                   j≻{k,ℓ},C2+   ) = max {Pr(y = 0) − (Pr(y = 0) + Pr(y = 0)), 0} − UB
                                              j                  k                  ℓ       A
                                                                                                (B.20)

        UB (PTE    B
                   j≻{k,ℓ},C2+   ) = min {Pr(y = 0),1 − Pr(y = 0),1 − Pr(y = 0)} − LB
                                              j                  k                      ℓ   B
                                                                                                (B.21)

        LB (PTE    B
                   j≻{k,ℓ},C2+   ) = max {Pr(y = 0) − (Pr(y = 0) + Pr(y = 0)), 0} − UB
                                              j                  k                  ℓ       B
                                                                                                (B.22)

All terms in these bounds can be identified and estimated given estimates of the relevant
composite-outcome joint probabilities.




                                                          43
                (             )
 Figure 1a: Pr y j = 0 and Pr (yk = 0) Combinations Consistent with PTE j≻k,C2 ≥ 0 —

                                                                          (
  Point Identification (light and dark shading) and LB PTE j≻k,C2 ≥ 0 (dark shading)         )
                                          1




                        Pr(yk = 0)



                                         1/3




                                          0
                                                                              2/3                1
                                                             Pr(yj = 0)




            (             )
Figure 1b: Pr y j = 0 and Pr (yk = 0) Combinations Consistent with LB PTE j≻k,C2 = 0                 (   )
                    (                )
       and LB PTE j≻k,C5 = 0 at Selected Values of Pr y j = 1 and Pr (yk = 1) (         )

                              1



                              .8
                                                                                        C2


                              .6
                                                                                        C5:
           Pr(yk = 0)                                                                   Pr(yj=1)=.2
                                                                                        Pr(yk=1)=.4
                              .4

                                                                                        C5:
                                                                                        Pr(yj=1)=.1
                              .2                                                        Pr(yk=1)=.2



                              0
                                           .2   .4      .6          .8              1
                                                Pr(yj = 0)




                                                      44
       Table 1: Comparison across C • of Y Values Consistent with Tj ≻C• Tk , M=3

      (22 of 22M = 64 possible Y values correspond to Tj ≻C• Tk for at least one C • )


                                                      Tj ≻C• Tk
     Y = ⎡⎢ y j yk ⎤⎥
          ⎣         ⎦
                        C0           C1          C2               C3       C4            C5

1    [ 0 0 0111]         ⦁           ⦁            ⦁               ⦁        ⦁             ⦁

2    [1 0 0111]          ⦁           ⦁                            ⦁        ⦁

3    [ 01 0111]          ⦁           ⦁                            ⦁        ⦁

4    [ 0 01111]          ⦁           ⦁                            ⦁        ⦁

5    [11 0111]           ⦁           ⦁                            ⦁        ⦁

6    [1 01111]           ⦁           ⦁                            ⦁        ⦁

7    [ 011111]           ⦁           ⦁                            ⦁        ⦁

8    [000100]            ⦁           ⦁            ⦁                        ⦁

9    [000010]            ⦁           ⦁            ⦁                        ⦁

10   [0 0 0 0 01]        ⦁           ⦁            ⦁                        ⦁

11   [ 0 0 011 0]        ⦁           ⦁            ⦁                        ⦁

12   [0 0 0101]          ⦁           ⦁            ⦁                        ⦁

13   [ 0 0 0 011]        ⦁           ⦁            ⦁                        ⦁

14   [1 0 011 0]         ⦁           ⦁

15   [ 01 011 0]         ⦁           ⦁

16   [10 0101]           ⦁           ⦁

17   [ 0 011 01]         ⦁           ⦁

18   [ 01 0 011]         ⦁           ⦁

19   [ 0 01 011]         ⦁           ⦁

20   [ 0 0111 0]         ⦁

21   [010101]            ⦁

22   [1 0 0 011]         ⦁




                                            45
          Table 2a: Pj≻k,C• , Pk≻j,C• and PTE j≻k,C• : True Values and Boole Bounds, M=2
     (Cell Entries: True Probability {LB, UB}; PTE j≻k,C• are Point Identified for C2 and C3)


    ρ       (        )
          Pr y k,m = 1   C•          Pj≻k,C•                   Pk≻j,C•            PTE j≻k,C•

                         C0    .30    {.17, .36}        .12     {0, .19}    .17      {-.02, .36}
                         C1    .30    {.17, .36}        .12     {0, .19}    .17      {-.02, .36}
                         C2    .29    {.17, .36}        .12     {0, .19}             .17
                .2
                         C3    .04    {.03, .04}        .01     {0, .01}             .03
                         C4    .30    {.17, .36}        .12     {0, .19}    .17      {-.02, .36}
                         C5    .03    {0, .04}          .01     {0, .01}    .03      {-.01, .04}
    0
                         C0    .65    {.56, .93}        .05     {0, .19}    .60      {.37, .93}
                         C1    .65    {.56, .93}        .05     {0, .19}    .60      {.37, .93}
                         C2    .61    {.56, .75}        .05     {0, .19}             .56
                .5
                         C3    .25    {.24, .25}        .01     {0, .01}             .24
                         C4    .65    {.56, .75}        .05     {0, .19}    .60      {.37, .75}
                         C5    .20    {.06, .25}        .003    {0, .01}    .20      {.05, .25}
                         C0    .23    {.15, .45}        .07     {0, .17}    .17      {-.02, .45}
                         C1    .23    {.15, .45}        .07     {0, .17}    .17      {-.02, .45}
                         C2    .20    {.15, .31}        .05     {0, .17}             .15
                .2
                         C3    .07    {.06, .09}        .02     {0, .03}             .06
                         C4    .23    {.15, .31}        .07     {0, .17}    .17      {-.02, .31}
                         C5    .04    {0, .09}          .005    {0, .03}    .03      {-.03, .09}
   .5
                         C0    .60    {.50, .80}        .01     {0, .17}    .58      {.33, .80}
                         C1    .60    {.50, .80}        .01     {0, .17}    .58      {.33, .80}
                         C2    .51    {.50, .67}        .01     {0, .17}             .50
                .5
                         C3    .31    {.30, .33}        .004    {0, .03}             .30
                         C4    .60    {.50, .67}        .01     {0, .17}    .58      {.33, .67}
                         C5    .22    {.17, .33}        .004    {0, .03}    .22      {.13, .33}

(cont.)




                                                   46
(cont.)

Note to table 2a: For m=1,…,M the calculations assume that: the y j and yk M-vectors have

elements           (
           y j,m = 1 y*j,m > 0 )   ,           (         )
                                       y k,m = 1 y*k,m > 0   ,    with
                                                                              ⎡         ⎤        ⎛⎡          ⎤ ⎞
                                                                         Y* = ⎢ y*j y*k ⎥ ∼ MVN ⎜⎜ ⎢ µ j µ k ⎥ , R⎟⎟⎟ ;
                                                                              ⎢⎣        ⎥⎦       ⎝⎣          ⎦ ⎠
                               (         )                       ( (        ))
µ j,m = Φ−1 (.1) , so that Pr y j,m = 1 = .1 ; µ k,m = Φ−1 Pr y k,m = 1 , with the specific values given
in the table; and R is a 2M×2M correlation matrix with all off-diagonal elements equal to ρ .

   (        )              (            )
Pr y k,m = 1 = .2 and Pr y k,m = 1 = .5 represent "small" and "large" TEs, respectively. LBs for

Pj≻k,C• for C2 and C3, shown in bold, correspond to corresponding point-identified PTE j≻k,C• . For
all entries UB>True Probability>LB, although these strict inequalities may be obscured by
rounding.




                                                       47
       Table 2b: Pj≻k,C• , Pk≻j,C• and PTE j≻k,C• : True Values and Boole Bounds, M=3
   (Cell Entries: True Probability {LB, UB}; PTE j≻k,C• are Point Identified for C2 and C3)


  ρ       (
       Pr y k,m = 1)   C•           Pj≻k,C•                    Pk≻j,C•            PTE j≻k,C•

                       C0     .38    {.22, .49}        .15      {0, .27}    .23      {-.05, .49}
                       C1     .37    {.22, .49}        .15      {0, .27}    .23      {-.05, .49}
                       C2     .36    {.22, .49}        .14      {0, .27}             .22
              .2
                       C3     .01    {.01, .01}        .001     {0, .001}            .01
                       C4     .36    {.22, .49}        .14      {0, .27}    .22      {-.05, .49}
                       C5     .01    {0, .01}          .001     {0, .001}   .01      {-.001, .01}
  0
                       C0     .76    {.60, 1}          .04      {0, .27}    .72      {.33, 1}
                       C1     .73    {.60, 1}          .04      {0, .27}    .69      {.33, 1}
                       C2     .64    {.60, .73}        .03      {0, .13}             .60
              .5
                       C3     .13    {.12, .13}        .001     {0, .001}            .12
                       C4     .67    {.60, .85}        .03      {0, .13}    .64      {.48, .85}
                       C5     .09    {0, .13}          .0001    {0, .001}   .09      {-.001, .13}
                       C0     .29    {.17, .44}        .07      {0, .22}    .22      {-.05, .44}
                       C1     .28    {.17, .44}        .07      {0, .22}    .21      {-.05, .44}
                       C2     .22    {.17, .39}        .05      {0, .22}             .17
              .2
                       C3     .04    {.03, .05}        .01      {0, .02}             .03
                       C4     .25    {.17, .39}        .06      {0, .22}    .19      {-.05, .39}
                       C5     .01    {0, .05}          .001     {0, .02}    .01      {-.02, .05}
  .5
                       C0     .70    {.53, .95}        .01      {0, .22}    .69      {.31, .95}
                       C1     .68    {.53, .95}        .01      {0, .22}    .68      {.31, .95}
                       C2     .54    {.53, .75}        .01      {0, .22}             .53
              .5
                       C3     .24    {.23, .25}        .002     {0, .02}             .23
                       C4     .65    {.53, .75}        .01      {0, .22}    .64      {.31, .75}
                       C5     .12    {.03, .25}        .00001 {0, .02}      .12      {.02, .25}

Note: See note to table 2a.




                                                  48
        Table 2c: Pj≻k,C• , Pk≻j,C• and PTE j≻k,C• : True Values and Boole Bounds, M=4
   (Cell Entries: True Probability {LB, UB}; PTE j≻k,C• are Point Identified for C2 and C3)


  ρ       (
       Pr y k,m = 1)   C•            Pj≻k,C•                    Pk≻j,C•              PTE j≻k,C•

                       C0     .44     {.25, .59}        .16      {0, .34}     .28       {-.10, .59}
                       C1     .42     {.25, .59}        .15      {0, .34}     .26       {-.10, .59}
                       C2     .39     {.25, .59}        .14      {0, .34}               .25
              .2
                       C3     .002    {.002, .002}      .0001    {0, .0001}             .002
                       C4     .39     {.25, .59}        .14      {0, .34}     .25       {-.10, .59}
                       C5     .001    {0, .002}         .0004    {0, .0001}   .001      {-.0001, .002}
  0
                       C0     .83     {.59, .99}        .04      {0, .11}     .80       {.48, .99}
                       C1     .75     {.59, .99}        .03      {0, .11}     .72       {.48, .99}
                       C2     .62     {.59, .66}        .02      {0, .06}               .59
              .5
                       C3     .06     {.06, .06}        .0001    {0, .0001}             .06
                       C4     .64     {.59, .72}        .02      {0, .06}     .62       {.53, .72}
                       C5     .04     {0, .06}          .00001 {0, .0001}     .04       {-.0001, .06}
                       C0     .34     {.19, .53}        .08      {0, .26}     .26       {-.07, .53}
                       C1     .30     {.19, .53}        .07      {0, .26}     .24       {-.07, .53}
                       C2     .24     {.19, .44}        .05      {0, .26}               .19
              .2
                       C3     .03     {.02, .03}        .004     {0, .01}               .02
                       C4     .26     {.19, .44}        .06      {0, .26}     .21       {-.07, .44}
                       C5     .004    {0, .03}          .0001    {0, .009}    .004      {-.01, .03}
  .5
                       C0     .76     {.54, 1}          .01      {0, .26}     .75       {.28, 1}
                       C1     .73     {.54, 1}          .01      {0, .26}     .72       {.28, 1}
                       C2     .55     {.54, .74}        .01      {0, .20}               .54
              .5
                       C3     .19     {.19, .20}        .001     {0, .01}               .19
                       C4     .67     {.54, .80}        .01      {0, .21}     .66       {.33, .80}
                       C5     .07     {0, .20}          .0000003 {0, .009}    .07       {-.01, .20}

Note: See note to table 2a.




                                                   49
         Table 3a: Estimated Bounds on Pj≻k,C• , Pk≻j,C• , and PTE j≻k,C• —MTO Sample
         ( Tj is intervention, Tk is control; PTE j≻k,C• is point identified for C2 and C3);


                             M=2                                                 M=4
                      (Obesity, Diabetes)                    (Obesity, Diabetes, Depression, Hypertension)
C•
         Pj≻k,C•            Pk≻j,C•         PTE j≻k,C•          Pj≻k,C•         Pk≻j,C•         PTE j≻k,C•

C0      {.02, .62}          {0, .59}        {-.57, .62}        {.02, .85}     {.004, .95}       {-.93, .85}

C1      {.02, .62}          {0, .59}        {-.57, .62}        {.02, .85}     {.004, .95}       {-.93, .85}

C2      {.01, .37}          {0, .36}             .01           {.02, .23}       {0, .21}           .02

C3      {.02, .13}          {0, .10}             .02            {0, .03}       {.004 .03}         -.004

C4      {.02, .49}          {0, .46}        {-.44, .49}        {.02, .26}     {.004, .24}       {-.22, .25}

C5       {0, .13}           {0, .10}        {-.10, .13}         {0, .03}        {0, .03}        {-.03, .03}




     Table 3b: Estimated Bounds on Pj≻k,C• , Pk≻j,C• , and PTE j≻k,C• —BRFSS Sample (M=7)
           (Age and Schooling treatments; PTE j≻k,C• is point identified for C2 and C3)


                              Age                                              Schooling
                     ( Tj =18-44; Tk =45-64)                   ( Tj =Not college grad.; Tk =college grad.)
C•
          Pj≻k,C•            Pk≻j,C•        PTE j≻k,C•          Pj≻k,C•          Pk≻j,C•        PTE j≻k,C•

C0        {.29, 1}          {0, .64}           {-.35, 1}        {0, .89}        {.05, 1}         {-1, .84}

C1       {.29, .97}         {0, .56}        {-.26, .97}         {0, 75}        {.05, .88}       {-.88, .70}

C2       {.29, .51}         {0, .22}             .29            {0, .32}       {.05, .37}          -.05

C3     {.0005, .001}       {0, .0001}           .0005          {0, .0002}    {.0003, .0005}       -.0003

C4       {.29, .51}         {0, .22}        {.08, .51}          {0, .32}       {.05, .37}       {-.37, .26}

C5      {0, .0006}         {0, .0001}    {-.0001, .0006}       {0, .0002}      {0, .0005}     {-.0005, .0002}




                                                        50
     Table 4: Comparison across C • * of Y Values Consistent with Tj ≻C• Tk , M=2, G=3

      (31 of G2M = 81 possible Y values correspond to Tj ≻C• Tk for at least one C • * )


                                                       Tj ≻C•* Tk
      Y = ⎡⎢ y j yk ⎤⎥
           ⎣         ⎦
                         C0*         C1*          C2*           C3*        C4*             C5*
1       [0 0 01]          ⦁           ⦁            ⦁                        ⦁
2       [0 0 0 2]         ⦁           ⦁            ⦁                         ⦁
3       [0010]            ⦁           ⦁            ⦁                         ⦁
4       [ 0 011]          ⦁           ⦁            ⦁                         ⦁
5       [0 012]           ⦁           ⦁            ⦁                         ⦁
6       [0020]            ⦁           ⦁            ⦁                         ⦁
7       [0 0 21]          ⦁           ⦁            ⦁                         ⦁
8       [0 0 22]          ⦁           ⦁            ⦁                ⦁        ⦁              ⦁
9       [010 2]           ⦁           ⦁
10      [ 0111]           ⦁           ⦁
11      [ 011 2]          ⦁           ⦁
12      [0120]            ⦁
13      [0121]            ⦁           ⦁
14      [0122]            ⦁           ⦁                             ⦁        ⦁
15      [0 212]           ⦁           ⦁
16      [0 2 21]          ⦁
17      [0 222]           ⦁           ⦁                             ⦁        ⦁
18      [10 0 2]          ⦁
19      [1 011]           ⦁           ⦁
20      [1012]            ⦁           ⦁
21      [10 2 0]          ⦁           ⦁
22      [10 21]           ⦁           ⦁
23      [10 2 2]          ⦁           ⦁                             ⦁        ⦁
24      [111 2]           ⦁           ⦁
25      [11 21]           ⦁           ⦁
26      [11 2 2]          ⦁           ⦁                             ⦁        ⦁
27      [12 2 2]          ⦁           ⦁                             ⦁        ⦁
28      [2012]            ⦁
29      [2 0 21]          ⦁           ⦁
30      [20 22]           ⦁           ⦁                             ⦁        ⦁
31      [2122]            ⦁           ⦁                             ⦁        ⦁




                                             51
                    Table 5: # Yj≻k,C•* and # J j≻k,C•* for M ∈ {2, 3, 4,5} and G ∈ {2, 3, 4}


                                                                    G
                                   2                                3                                  4

                       G2M     # Yj≻k,C•* # J j≻k,C•*   G2M     # Yj≻k,C•* # J j≻k,C•*    G2M      # Yj≻k,C•* # J j≻k,C•*

              C0*                       5         3                     31         8                    106          15
              C1*                       5         3                     27         8                       84        15
              C2*                       3         1                      8         1                       15         1
        2                 16                               81                               256
              C3*                       3         3                      8         8                       15        15
              C4*                       5         3                     15         8                       29        15
              C5*                       1         1                      1         1                        1         1
              C0*                      22         7                  294          26                  1758           63
              C1*                      19         7                  189          26                    936          63
              C2*                       7         1                     26         1                       63         1
        3                 64                              729                              4096
              C3*                       7         7                     26        26                       63        63
              C4*                      13         7                     51        26                    125          63
              C5*                       1         1                      1         1                        1         1
M
              C0*                      93        15                2727           80                 28722          255
              C1*                      65        15                1215           80                  9744          255
              C2*                      15         1                     80         1                    255           1
        4                256                             6561                             65536
              C3*                      15        15                     80        80                    255         255
              C4*                      29        15                  159          80                    509         255
              C5*                       1         1                      1         1                        1         1
              C0*                   386          31               25048          242                466136        1023
              C1*                   211          31                7533          242                 98976        1023
              C2*                      31         1                  242           1                  1023            1
        5               1024                            59049                            1048576
              C3*                      31        31                  242         242                  1023        1023
              C4*                      61        31                  483         242                  2045        1023
              C5*                       1         1                      1         1                        1         1

    (cont.)




                                                         52
(cont.)

Note to table 5: The general formulae on which this table's entries are based are:

          # Yj≻k,C0* : See oeis.org A000346, A212730, A213465 for the basic idea.
                                     M
                      (
          # Yj≻k,C1* : .5G (G + 1) )     − GM

          # Yj≻k,C2* and # Yj≻k,C3* : GM −1

          # Yj≻k,C4* : 2GM − 3

          # J j≻k,C0* , # J j≻k,C1* , # J j≻k,C3* , and # J j≻k,C4* : GM −1


Not displayed in the table, # K j≻k,C•* is the same as # J j≻k,C•* for C0*, C1*, and C4* but
switches with # J j≻k,C•* between C2* and C3*.




                                                      53
