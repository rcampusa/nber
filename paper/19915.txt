                                NBER WORKING PAPER SERIES




            THE DYNAMIC EFFECTS OF EDUCATIONAL ACCOUNTABILITY

                                           Hugh Macartney

                                        Working Paper 19915
                                http://www.nber.org/papers/w19915


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                     February 2014




I would like to thank Robert McMillan, Aloysius Siow and Carlos Serrano for their guidance and support
throughout this project. Thanks also to Gustavo Bobonis, Branko Boskovic, Raj Chetty, Damon Clark,
Stephen Coate, Elizabeth Dhuey, Amy Finkelstein, Kirabo Jackson, Sacha Kapoor, Steven Lehrer,
Joshua Lewis, Parag Pathak, Uros Petronijevic, Petra Todd, Trevor Tombe, Jacob Vigdor, and conference
and seminar participants for their helpful suggestions. Remote access to the data for this study was
generously provided by the North Carolina Education Research Data Center (NCERDC). I gratefully
acknowledge financial support from the CLSRN Fellowship and the Royal Bank Graduate Fellowship
in Public and Economic Policy. All remaining errors are my own. The views expressed herein are
those of the author and do not necessarily reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2014 by Hugh Macartney. All rights reserved. Short sections of text, not to exceed two paragraphs,
may be quoted without explicit permission provided that full credit, including © notice, is given to
the source.
The Dynamic Effects of Educational Accountability
Hugh Macartney
NBER Working Paper No. 19915
February 2014
JEL No. D82,I21,J33,M52

                                            ABSTRACT

This paper provides the first evidence that value-added education accountability schemes induce dynamic
distortions. Extending earlier dynamic moral hazard models, I propose a new test for ratchet effects,
showing that classroom inputs are distorted less when schools face a shorter horizon over which they
can influence student performance. I then exploit grade span variation using rich educational data
to credibly identify the extent of dynamic gaming, finding compelling evidence of ratchet effects based
on a triple-differences approach. Further analysis indicates that these effects are driven primarily by
effort distortions, with teacher reallocations playing a secondary role.


Hugh Macartney
Department of Economics
Duke University
239 Social Sciences Building
Box 90097
Durham, NC 27708
and NBER
hugh.macartney@duke.edu
            The Dynamic Effects of Educational Accountability

                                          Hugh Macartney
                                     Duke University and NBER


       Against a backdrop of chronic underperformance in education, policymakers have in-
creasingly embraced reforms that hold educators more accountable for the academic perfor-
mance of their students. Such accountability measures have included standardized testing,
publishing results that are comparable across schools and, more recently, providing high-
powered incentives for both teachers and schools by awarding bonus pay if test scores exceed
a specified target.
       The way accountability targets are constructed is of particular interest from an incen-
tive design perspective. Simple proficiency-based schemes, such as the one used under the
2001 federal No Child Left Behind Act, set performance targets that are independent of
student, teacher or school measures past or present. The problem with such schemes is
well known: they incentivize schools to focus on marginal students at the expense of non-
marginal ones.1 In contrast, more refined value-added schemes provide incentives to focus
on students throughout the distribution, by conditioning targets on prior scores to adjust for
heterogeneity in education inputs. As a result of this desirable feature, such sophisticated
schemes have become increasingly popular, having been implemented in Arizona, California,
Colorado, Florida, North Carolina, South Carolina and Texas, among others.2
       This paper is the first to draw attention to an important potential dynamic distor-
tion arising from these more refined schemes. In particular, targets that depend on lagged
achievement become manipulable with time, as raising effort under such a scheme not only
affects the likelihood of exceeding the current target but also determines the target that
follows. Given the implication that a strong performance today makes it more difficult to
   1
     Instances of gaming at the margin include redirecting resources from untested to tested subjects by
school principals (Ladd and Zelli (2002)), exempting disadvantaged students from testing (Cullen and Reback
(2006)), ‘teaching to the distribution’ of students (Neal and Schanzenbach (2010)), and overt cheating (Jacob
and Levitt (2003)).
   2
     Both types of high-powered schemes have tended to result in improved educational outcomes, as evi-
denced by research evaluating both broad definitions of accountability and specific performance-contingent
systems (see Carnoy and Loeb (2002), Lavy (2002, 2009), Hanushek and Raymond (2005), Figlio and Kenny
(2007), Dee and Jacob (2011), and Muralidharan and Sundararaman (2011)).



                                                     1
reap a bonus tomorrow, teachers may become less responsive to the reform than they would
be in the absence of dynamic considerations – an instance of the so-called ‘ratchet effect.’
     To shed light on the extent to which these dynamic distortions matter in practice, I first
extend prior ratchet effect models to a finite-horizon setting and allow the choice variable
to determine both contemporaneous and future output (in addition to targets). The classic
theory work in the area, notably Weitzman’s seminal 1980 paper, features workers who make
effort choices facing an infinite horizon, where targets depend on earlier output. The theory
yields the intuitive prediction that agents should identically suppress effort in every period,
yet it is not amenable to empirical testing since the prediction is difficult to distinguish
from the counterfactual in which targets are independent of prior output or agents behave
as though they are (the static case).
     Recasting the dynamic incentive problem in a finite-horizon context yields a new test
for ratchet effects that is clearly distinguishable from the static counterfactual. The model I
set out involves a single effort-making body, setting effort in light of the prevailing incentives.
It is intended to capture key aspects of the particular incentive scheme I consider: the North
Carolina accountability system established in 1996. Under that scheme, all teachers and the
principal at a school receive a monetary bonus if the school meets specified growth targets
in student achievement, where those targets condition on the average prior test scores of
students. This dependence implies that students contribute to the school aggregate target
only as long as they remain in the school, thereby determining the finite horizon faced by
the school principal, which in turn affects the extent of the dynamic gaming. As the horizon
becomes shorter, the downside associated with high performance is mitigated since there are
fewer future periods in which the target will be raised, and so teacher effort will tend to be
increased.
     The theory lends itself naturally to empirical testing, given that the principal’s horizon
is captured by the grade span of the school. The fact that I observe multiple grade-span
configurations (in particular, K-5, K-6 and K-8) in North Carolina suggests a viable and
transparent identification strategy: Comparing teacher behavior in a particular grade across
schools with different grade spans, the model implies that schools serving fewer future grades
should exert greater effort than those serving a greater number of future grades. For example,


                                                2
grade five teachers at K-5 schools are predicted to exert a higher level of effort than their
K-8 or K-6 counterparts, since the negative externality that a K-5 school imposes on a 6-8
school through high performance in grade five would be internalized by a K-8 or K-6 school.
Moreover, the theory predicts that the effort disparity between any two configurations should
be increasing in the shared grade.
     To assess the strength of such distortions empirically, one could simply compare grade
five scores across different configurations, though this would be unsuitable if schools with
different grade spans differed along unobserved dimensions, such as the degree to which par-
ents invest in their children’s education. A difference-in-differences approach, which makes
this comparison across configurations both before and after the accountability reform was
implemented, would control for any time-invariant differences. Instead, I adopt a more so-
phisticated triple-differences estimation strategy to detect the predicted dynamic pattern
through student scores. This accounts for differentially trending unobservables by compar-
ing the difference-in-differences estimates across grades (for instance, grade five versus four).
Ratchet effects are then identified under the plausible assumption that unobservables do not
differentially trend over time and by grade across configurations.
     Applying this triple-differences approach, my analysis reveals substantial distortions
across K-5 and K-8 schools – between 4.7 and 5.9 percent of a standard deviation in the
grade five score in favor of K-5 schools. The analogous distortion for the comparison between
K-5 and K-6 schools is between 3.9 and 5.6 percent of a standard deviation in the grade five
score. To place these effects into context, the literature suggests that teachers account for
between 8 and 15 percent of a standard deviation in test scores (see Rivkin et al. (2005),
Rothstein (2010), and Chetty et al. (2011)). My findings are consistent with the predictions
of the model – that effort and scores will be higher at schools with shorter horizons and that
the disparity between shorter- and longer-horizon schools will be increasing in the grade.
Moreover, the results are obtained without having to make overly-restrictive identifying
assumptions.
     While I take my results as reflecting differences in teacher effort, I am able to assess
a rival dynamic gaming mechanism, whereby teachers are re-sorted across grades by the
school principal according to their teaching ability. Using data on teacher-grade assign-


                                               3
ments, I present direct evidence of such re-allocations and then decompose the estimated
dynamic gaming effects according to whether the associated teachers have been re-assigned
to a different grade or not in any prior post-reform year. My findings indicate that, while
teacher sorting by principals is important, differential effort is likely to be the primary chan-
nel though which such gaming occurs, as it accounts for more than half of the total estimated
ratchet effect.3
       This study of ratcheting behavior is relevant to a broad class of incentive schemes
that condition on the prior decisions of agents in order to account for heterogeneity in in-
puts.4 These include systems that evaluate absolute and relative performance alike where,
in contrast to absolute performance systems, relative variants feature targets which are de-
termined by multiple agents in the system (for instance, bonus receipt for heterogeneous
workers competing against each other in a tournament would be determined by their per-
formance relative to others, as well as their prior output). My estimates demonstrate that
there is a clear tradeoff when conditioning targets: while efficiency is increased as agents
are held less accountable for factors beyond their control, nontrivial distortions are likely to
arise when future targets can be manipulated. The theoretical conditions I derive suggest a
way forward: dynamic distortions can be reduced by lowering the target at the cost of some
static efficiency, a finding that policymakers should be cognizant of when designing incentive
schemes.5
       The rest of the paper is organized as follows: The next section presents a simple theo-
retical model of dynamic gaming that yields the main insight used subsequently to estimate
dynamic distortions. Section II describes the data, presenting stylized facts regarding the
   3
      A secondary contribution of this paper is the identification of time-varying classroom effects at the
configuration-grade level, such as teacher effort and re-allocation, using raw score data in concert with
features of the underlying incentive environment. Notably, in the former case, I am able to do so without
relying on generally poor proxies for effort. This builds upon an established literature concerning the inference
of time-invariant teacher effects, often referred to as teacher ability or quality, from such data (see Kane and
Staiger (2001, 2008), Todd and Wolpin (2003, 2007), McCaffrey et al. (2004), and Rothstein (2010)).
    4
      There is a small empirical literature measuring ratchet effects outside of education. Cooper et al. (1999)
and Charness et al. (2010) provide evidence of these effects within a simple experimental environment.
Additionally, Allen and Lueck (1999) and Parent (1999) present suggestive observational evidence using
cross-sectional variation and, in the latter case, without information on the nature of high-powered pay or
targets.
    5
      Ultimately, the optimal target will depend on the long-run effects of the distortions. This is a difficult
but potentially important issue to address given the persistence of teacher effects established in Chetty et
al. (2011). A careful exploration of it remains for future investigation.


                                                       4
aggregate impact of the North Carolina incentive reform. Section III outlines the empirical
strategy; and Section IV reports the main results, along with robustness checks. Section
V then explores the mechanisms underlying the estimated dynamic effects, and Section VI
concludes.


                                       I.   A Stylized Model

To develop intuition as to the possible workings of the ratchet effect in a setting where
the horizon is finite and of varying length, I extend the dynamic moral hazard literature,
particularly the strand which explores ratcheting behavior when the planner commits to a
suboptimal incentive scheme with a well-specified revision procedure (see Weitzman (1980),
Holmstrom (1982) and Keren et al. (1983)).6 Guided by the institutional details of the
educational accountability system implemented throughout North Carolina in the 1996-97
school year,7 the theory yields a new insight concerning the identification of ratchet effects,
in addition to several testable predictions for the empirical investigation that follows.
     The model has features in common with several existing papers, but it is most eas-
ily motivated by building upon the seminal work of Weitzman (1980), which predicts the
emergence of ratchet effects when performance today determines bonus receipt today and
tomorrow.8 In Weitzman’s model, a fixed linear incentive scheme rewards agents based on
the difference between a current output measure yt and the target αyt−1 , which is an ad-
justed prior measure. The adjustment parameter α dictates how much the principal (in the
‘principal-agent’ sense) must reward agents, conditional on current and prior output as well
as the linear payment scheme reward parameter b. To see this, consider an agent’s problem
at time t: Given the scheme and a convex cost of output C(·), the agent’s objective is given
by
   6
     See also Freixas et al. (1985), Lazear (1986), Baron and Besanko (1987), Gibbons (1987), Laffont and
Tirole (1988), and Kanemoto and Macleod (1992), which consider the ratchet effect under mechanisms with
limited or no commitment.
   7
     See Appendix A.1 for additional detail on the reform.
   8
     A ratchet effect arises if the high-powered target for the next period depends on the output level in the
current period. If this is the case, then any contemporaneous increase in productivity results in a one-time
heightened benefit, but also permanently raises the bar for future monetary rewards, causing agents to adjust
their behavior in response.




                                                      5
                                              ∞
                                              X
                                    max             δ t [b(yt − αyt−1 ) − C(yt )]
                                   {yt }∞
                                        t=0
                                              t=0


which leads to the first-order conditions b(1 − δα) = C 0 (yt ), ∀ t. Comparing this to the
condition without dynamic considerations, b = C 0 (yt ), ∀ t, which occurs if the target is α
instead of αyt−1 , the ratchet effect leads workers to underperform if δα > 0.9 Intuitively,
as α increases, the next period target rises when contemporaneous output is unchanged,
which results in lower pay in the following period. Therefore, the marginal benefit of output
decreases as α increases, which results in a lower optimal level of output, given the same
marginal cost. This effect is magnified as future periods are discounted less by the agent
(higher δ).
       While the basic idea of Weitzman (1980) is contained in the model I set out, my for-
mulation differs in two key respects. First, as previously noted, I consider ratchet effects in
a finite-period setting, reflecting the fact that school-level targets depend on the prior test
scores of students in North Carolina who do not attend the same school forever. Second,
output in the model depends on inputs in the current period and all prior periods according
to a production function with an evolving educational capital stock, described more fully
in the next subsection.10 This means that even if the target does not depend on the prior
score, the current choice will still affect all future output levels. I now describe the model in
greater detail and use it to develop testable predictions.


I.A.    The Environment

Agents and Actions

Given that the incentive scheme under the accountability reform consists of grade-specific
targets for each school, it is natural to focus on school principals as agents in the model. The
principal is assumed to observe the test scores associated with each teacher and to be able to
   9
      By definition, the inter-temporal depreciation rate δ is positive, while the target α will also be positive
if it is derived by regressing a current positive measure on a smaller positive prior one (as in my empirical
application, for example).
   10
      The period-specific ‘capital’ stock measures each student’s ability to learn in the given period. It depends
on the innate ability of the student and all of the educational inputs that she has faced prior to that point
in time, appropriate given the cumulative nature of the education process.


                                                           6
calculate the school-level target, a relatively straightforward exercise since the target is equal
to a given coefficient α multiplied by the prior score. Using this information, she coordinates
the actions of all teachers through monitoring and (potentially) sanctions to maximize the
school’s payoff. I abstract away from intra-school incentives in the model.11
       Let there be S schools, indexed by s ∈ {1, . . . , S}, and let the grade within a particular
school be referenced by g ∈ Gc = {0, . . . , Gc }, where Gc is the last grade served by schools
with grade configuration c, normalized so that g = 1 is the first grade with high-powered
incentives attached.12 In any given year t, each school s with a finite horizon dictated by its
configuration c chooses a set of effort levels {escgt }g∈Gc . Each choice escgt is an input in the
production of educational achievement for students and is selected from the set of continuous
effort levels according to the school’s payoff.


Inputs and Production Technology

For simplicity, I assume that there is a single representative subject, abstracting away from
the two tested subjects used in practice in North Carolina.13 At the end of every year t, a
test is written in this subject by all students in school s, generating average test scores for
each school-grade pair. These scores are denoted by yscgt and are taken to be a measure of
educational output for the relevant group of students and the representative teacher for that
grade.
       In general, education is inherently cumulative, with learning in each period building
upon what came before. I capture this using the concept of ‘educational capital,’ defining it
to be the stock of skills and knowledge a student has accumulated up to a given time for the
purpose of learning. It reflects the idea that inputs to learning, such as the student’s raw
intelligence and the contributions of her teachers, have a lasting impact on her capacity to
  11
     This modeling choice is made to focus on the core idea of ratcheting behavior. It assumes that the
principal is capable of perfectly coordinating her teachers. If this were not the case, then ratchet effects
would be weakened.
  12
     For example, given that the receipt of the bonus in North Carolina depends on the scores for grades
three through eight, g = 0 corresponds to grade two and g = Gc = 3 corresponds to grade five for a K-5
school (while I do not focus on earlier low-stakes grades here, grade one would be represented by g = −1
in this case). For a 6-8 school, there is no grade for which g = 0, as it represents grade five at a different
school. Thus, g ∈ Gc = {1, 2, 3} for such middle schools.
  13
     The representative subject assumption can be made without loss of generality, since the dependence of
bonus receipt on composite measures implies that dynamic effects will be manifested in both scores.


                                                      7
learn in the future. As these prior inputs are not directly observed, I summarize the prior
end-of-grade educational capital which students begin grade g with using the prior score,
yscg−1t−1 .
      Given this definition, I model the score yscgt as depending on the effort escgt exerted
by the representative teacher for the school-grade pair, the ability of the teacher ascgt , the
prior end-of-grade educational capital for current grade g students yscg−1t−1 , and a grade-
school-year shock uscgt . Teacher effort and shocks are treated as common to all students
within a classroom – a reasonable assumption given that the average outcome for each grade
is what matters for satisfying the school-level target. In addition, teacher effort is modeled
exclusively as the representative teacher’s contribution to the average score of her students,
meaning that I abstract away from multiple tasks, such as devoting effort to disciplining
students. I also consider the effect of teacher effort to be permanent so that it affects the
subsequent score in the same way as educational capital. In general, let the student’s score
in school s, grade configuration c, grade g and time t be given by

                            yscgt = H(yscg−1t−1 , escgt , ascgt ) + uscgt ,

which potentially allows for teacher effort and the capital stock of the average student to
interact in the production of learning. To develop intuition and make the identification strat-
egy that follows more transparent, I focus on a linear specification – a standard assumption
made in the educational literature. Under the linear technology, the score is given by

(1)                        yscgt = γyscg−1t−1 + escgt + ascgt + uscgt .


Incentives and Preferences

Suppose, as is the case for the North Carolina reform, that the planner selects an incentive
scheme that rewards teachers at a school with a monetary bonus b if the school-level score
exceeds the target. Given that there are average scores yscgt and targets ŷscgt ≡ αyscg−1t−1
for each grade within the school, this award criterion is equivalent to the sum of the scores
exceeding the sum of the targets across grades.
      The choice of effort for each grade g and time t depends on the probability of receiving
the monetary bonus b and the convex cost C(·) of the effort that is exerted. Therefore, the

                                                  8
payoff function for an infinitely-lived school s serving Gc grades at time t is

                  ∞                      Gc                                               Gc
                           ( "                                                   !#                         )
                  X                      X                                                X
(2)      Usct =         δ t−1 b 1 − Fc         ((α − γ)yscg−1t−1 − escgt − ascgt )    −         C(escgt )
                  t=1                    g=1                                              g=0


where Fc (·) is the cdf of the sum of grade-specific shocks ( G
                                                             P c
                                                              g=1 uscgt ≡ Gc ūsct ), and the

benefit portion of the payoff function arises from the probability of receiving the bonus
P r[ G
    P c             PGc                                                             PGc
        g=1 yscgt >   g=1 ŷscgt ], which (using equation (1)) is equivalent to P r[ g=1 uscgt >
PGc
   g=1 ((α − γ)yscg−1t−1 − escgt − ascgt )].



I.B.    Optimal Effort Levels

Given the technology in equation (1), the problem for school s at time t is to choose the
stream of effort levels {{escgt }g∈Gc }∞
                                       t=1 to maximize the objective in equation (2). Defining
          PGc
Πsct ≡ − g=1 (escgt + ascgt + (γ − α)yscg−1t−1 ) and assuming a quadratic cost function
C(e) = d2 e2 , the first-order conditions that govern these choices are given by
                  
                   f (Π ) + δ(γ − α) PGc −g−1 δ i γ i f (Π            for 1 ≤ g < Gc
      d                 c  sct               i=0        c   sct+1+i )
         escgt =                                                                      ,
      b            f (Π )
                        c  sct                                         for g = Gc

where the second term on the right hand side of the equation for 1 ≤ g < Gc is the dis-
tortion due to dynamic gaming, fc (·) is the pdf of G
                                                   P c
                                                    g=1 uscgt and fc (Πsct ) represents the

school-specific static incentives for period t in the absence of a ratchet effect.14 While these
conditions cannot be used to solve for each optimal effort level explicitly, they do allow the
relationship between effort levels in consecutive grades to be characterized.
       For the remainder of this subsection, I assume that δ > 0, γ > 0 and the high-powered
target coefficient exceeds the growth rate of the score (α > γ).15

Lemma 1 Effort is weakly increasing in the grade g.
  14
     Static incentives affect the degree to which teacher effort matters at the margin for receiving a bonus
contemporaneously. They are generated by target imperfections, such as the scheme failing to account for
transitory shocks and grade-to-grade differences in teacher ability.
  15
     The predictions that follow would be reversed if target growth is outpaced by score growth (γ > α).
Based on the empirical results in this paper and related structural work, I do not believe this to be the case.




                                                         9
Proof: Using the preceding conditions, observe that the difference between effort levels in
consecutive grades is escgt − escg−1t =        bδ
                                               d
                                                  (α   − γ)δ Gc −g γ Gc −g fc (Πsct+1+Gc −g ) for 2 ≤ g ≤ Gc .
fc (·) ≥ 0 then implies that escgt ≥ escg−1t for 2 ≤ g ≤ Gc (with a strict inequality holding if
fc (Πsct+1+Gc −g ) > 0).

As the effort choice affects a larger number of future targets and the targets grow at a faster
rate than the score (α > γ), teachers are increasingly penalized for exerting higher effort.
Thus it is optimal to select a lower level of effort as the horizon increases (g is further away
from the final grade offered Gc ). For similar reasons, the converse is also true: effort is
weakly decreasing in g if target growth is outpaced by score growth (α < γ).
       To compare grade g outcomes for two different grade structure types, closed-form so-
lutions for effort cannot be derived from the general first-order conditions. Thus, I provide
intuition for the empirical analysis that follows by making an additional simplifying assump-
tion that the incentive scheme is linear, in which case, the nonlinear Π terms drop away,
leaving only ratchet effects that differ according to the school configuration and leading to
expressions that are analytically tractable.16 The conditions become
                       h                               i
                       b 1 + δ(γ − α) PGc −g−1 δ i γ i    for 1 ≤ g < Gc
                         d                  i=0
                ecg =                                                     .
                       b                                  for g = G
                              d                                                    c



Proposition 1 Assuming that initial educational capital stock and teacher ability are iden-
tical across two school configurations c and c0 , such that one school serves a greater number
of grades (Gc0 > Gc ), the test score for any particular grade g will be greater at the school
serving fewer grades (ycg > yc0 g , ∀ g ∈ Gc ).

Proof: For some positive integer κ, consider arbitrary grade structures, with Gc = G and
Gc0 = G + κ > Gc . Let us first compare the effort choices between these two types for grade
g ∈ Gc , where Gc is the set of grades served by a school with configuration c.
     If g = G, then ecG = db and ec0 G = db 1+δ(γ−α) κ−1
                                                     P      i i
                                                                 
                                                        i=0 δ γ , which means that ecG > ec0 G

from the stated assumptions. If 1 ≤ g < G, then ecg = db 1 + δ(γ − α) G−g−1
                                                                           P         i i
                                                                                          
                                                                               i=0  δ  γ    and
  16
     Such an assumption is made for expositional convenience and is not necessary for the propositions that
follow. They continue to hold under a nonlinear scheme if relatively mild assumptions are imposed concerning
the correlation of shocks and similarity of target imperfections across grades (details available upon request).

                                                        10
ec0 g = db 1+δ(γ −α) G+κ−g−1       δ i γ i . Since G+κ−g−1       δ i γ i = G−g−1          δ i γ i + G+κ−g−1
                                         
                                                                                                               δiγ i >
                       P                           P                         P                       P
                          i=0                        i=0                          i=0                 i=G−g
PG−g−1 i i                                                                                                   b
                                                                                                               
    i=0    δ γ , using the stated assumptions,      we   have   ecg   >  e c 0 g . If g = 0, then ecg =
                                                                                                             d
                                                                                                                δ(γ −
α) i=0 δ γ and ec0 g = db δ(γ − α) G+κ−1
     PG−1 i i                                             
                                                     δ i γ i , given that there is no contemporaneous
                                             P
                                               i=0

benefit to exerting effort in the untested grade g = 0. Since G+κ−1
                                                                                   P              i i
                                                                                                        PG−1 i i
                                                                                      i=0      δ   γ  =   i=0 δ γ +
PG+κ−1 i i          PG−1 i i
    i=G    δγ >       i=0 δ γ , using the stated assumptions, we have ec0 > ec0 0 . Therefore,

ecg > ec0 g , ∀ g ∈ Gc .
      Given the assumptions about initial educational capital stock and teacher ability, let
kc0 = k0 , ∀ c (where kc0 is defined to be the capital stock in grade g = 1), and acg = ag , ∀ c.
Assuming that the shock at the average school of each type c is zero (ucg = 0), the test score
for any type c school is ycg = γ g+1 k0 + gi=0 γ g−i ai + gi=1 γ g−i eci .
                                         P               P

      Since ecg > ec0 g , ∀ g ∈ Gc , it should be immediate from the preceding expression that
ycg > yc0 g , ∀ g ∈ Gc , which is the desired result.

      To interpret Proposition 1, consider the following example of a pair of typical K-5 and K-
8 schools in North Carolina. Using the notation of the model, the K-5 and K-8 schools serve
Gc = 3 and Gc0 = 6 grades with high-powered incentives attached, respectively. As shown
in the proof, the first-order conditions imply that the dynamic distortion for a particular
grade is always smaller for the school with the shorter horizon, which is the K-5 school in
this case. Intuitively, K-8 schools always have a greater number of future grades to consider
when determining their effort decision in grades three, four or five. Figure A.1 illustrates
this comparison, where the effort level at the K-5 school is higher than at the K-8 school
for each grade shared by the two configurations. Combined with the assumptions stated in
Proposition 1, this pattern in effort also holds for test scores, which is illustrated in Figure
A.2. An analogous result holds for a comparison between K-5 and K-6 schools.

Proposition 2 Under the stated assumptions of Proposition 1 and assuming δγ < 1, the
positive difference between ycg and yc0 g is increasing in g, ∀ g ∈ Gc .

Proof: Recall from the proof of Proposition 1 that G+κ−g−1
                                                                           PG−g−1 i i
                                                                   δiγ i =
                                                        P
                                                          i=0               i=0    δ γ + ρκg ,
              PG+κ−g−1 i i
where ρκg ≡ i=G−g δ γ . If δγ < 1, then ρκg is increasing in g, since each term in the
sum is less than one and is raised to a power that is decreasing in g. Thus, G+κ−g−1   δiγ i −
                                                                            P
                                                                               i=0
PG−g−1 i i
  i=0    δ γ is increasing in g, which means that ecg − ec0 g is increasing in g, ∀ g ∈ Gc .

                                                         11
Therefore, under the same assumptions of Proposition 1, ycg − yc0 g is increasing in g, ∀ g ∈
Gc .

        Using the same comparison of K-5 and K-8 schools, Proposition 2 implies that distor-
tions diminish at a faster rate for K-5 schools when moving from one grade to the next
higher grade. Combining Propositions 1 and 2, the score differential between K-5 and K-8
schools is predicted to be positive in favor of the former type for each shared grade, and this
difference should be greatest for grade five – this result is reflected in Figure A.2 and is the
main hypothesis to be tested empirically.17
        With the preceding theoretical predictions in hand, I now turn to the data used in my
empirical analysis.


                            II.    Data and Descriptive Statistics

II.A.     Description

To determine whether conditioning targets on prior scores leads to distortions of effort across
grades, I utilize a rich longitudinal data set provided by the North Carolina Education
Research Data Center (NCERDC). This includes information on North Carolina students,
teachers and schools for the years 1994 through 2005.18,19 Given that the accountability
reform took effect in 1997, I refer to 1994, 1995 and 1996 as pre-reform years, and 1997
through 2005 as post-reform years. The data set contains yearly standardized test scores
for each student in mathematics and reading from grades two to eight.20 These scores are
comparable across time and grades through the use of a developmental scale.21 Using this
  17
      Given the general nonlinear first-order conditions at the beginning of this subsection, it is clear that
the dynamic gaming effects are attenuated by lowering the target coefficient α toward the growth rate γ.
Indeed, they are eliminated altogether if the planner sets α = γ. Intuitively, such a target coefficient no
longer punishes teachers in future for exerting higher effort today. However, there is a tradeoff associated
with implementing this prescription for eliminating the distortions, as the first-order static effects of the
scheme are potentially weakened when the target becomes easier to satisfy.
  18
     See Appendix B.1 for greater detail on the available data.
  19
     For expositional convenience, I refer to academic years using the calendar year in which they end. For
instance, 1994 refers to the 1993-94 school year.
  20
     What are referred to as ‘grade two’ tests are administered in September of the grade three year. All
other tests are administered in May or June of the school year.
  21
     Each point on the developmental scale is designed to measure the same amount of learning, regardless
of the grade to which the score corresponds.


                                                     12
scale and unique encrypted identifiers, the progress of individual students can be tracked
over their educational careers. The data set also links students to their teacher and school
in each year for grades three through eight.
       In addition to student scores, the data provide extensive student, teacher and school
characteristics. For the purposes of this study, the most important student observables are
parental education, ethnicity, and exceptionality classifications. With regard to teachers,
the relevant characteristics are the score on the test used to obtain a teaching license and
the number of years of teaching experience. The data set also contains information on the
location for each school, using five classifications ranging from a large city to a rural area,
the proportion of students eligible for a free or reduced-price lunch, the number of years that
the principal has been in charge of a given school, the number of classes by grade offered by
a school, and – especially relevant for this study – each school’s grade configuration.
       Descriptive statistics for the variables of interest are presented in Table 1. Student
scores and characteristics are presented at the student level from 1994 to 2005, while teacher
and school statistics are averaged at the school level over the same period. As expected from
the developmental scale, the mean combined math and reading score is increasing in the
grade. In addition, with the exception of the gain from grade six to seven, the rate of growth
is decreasing in the grade, so that students gain the most in grade four, followed closely by
grade five. Students with parents who possess a high school diploma and no post-secondary
education account for 42 percent of the sample, while those who have not obtained a high
school degree make up 10 percent. Parents with a diploma from a trade school or community
college account for a further 20 percent of the sample, and 28 percent of parents have been
granted a 4-year college or graduate degree. Nearly two-thirds of North Carolina students
are white in the sample, while slightly less than 30 percent are black, which is significantly
higher than the national average and also higher than the state average for North Carolina.22
In the data set, the average teacher has about 13 years of teaching experience, the school-
level average percentage of students qualifying for a free lunch is 38 percent, and the average
number of classes in grades three through five at all school configurations is 3.5.
  22
    According to a 2009 estimate by the U.S. Census Bureau, approximately 13 percent and 22 per-
cent of the U.S. and North Carolina populations respectively, are identified as being black (source:
http://quickfacts.census.gov/qfd/states/37000.html ).


                                                13
                                   Table 1 – Descriptive Statistics

          Variable                                     Mean        St. Dev.            Min           Max
          Combined Test Score:
            Grade 3                                      291.5            18.8           215           345
            Grade 4                                      303.3            18.3           229           357
            Grade 5                                      314.7            16.9           234           368
            Grade 6                                      322.2            18.8           254           376
            Grade 7                                      331.2            18.0           261           386
            Grade 8                                      337.6            18.4           271           395
          Student - Parental Education:
             No High School                               0.10            0.30              0             1
             High School Graduate                         0.42            0.49              0             1
             Trade School                                 0.09            0.28              0             1
             Community College                            0.11            0.32              0             1
             4-Year College                               0.22            0.42              0             1
             Graduate Degree                              0.06            0.23              0             1
          Student - Ethnicity:
             White                                        0.64            0.48              0             1
             Black                                        0.28            0.45              0             1
             Other                                        0.08            0.27              0             1
          Student - Exceptionality:
             Learning Impairment                          0.12            0.32              0             1
             No Special Label                             0.74            0.44              0             1
             Gifted                                       0.14            0.35              0             1
          School:
             Prop. Free Lunch Eligible                    0.38            0.20             0           0.99
             Principal Tenure in School†                   3.3             2.2             1             11
             Classes Per Grade (Gr. 3-5)†                  3.5             1.4             1             13
             Teacher Experience†                          12.6             6.0             0             42
             Teacher Licensure Test Score†                0.00            0.55         -3.42           3.20
              Locale   -   Large City                     0.06            0.23              0             1
              Locale   -   Mid-Size City                  0.21            0.41              0             1
              Locale   -   Large Suburban                 0.05            0.21              0             1
              Locale   -   Mid-Size Suburban              0.13            0.34              0             1
              Locale   -   Small Town & Rural             0.55            0.50              0             1
            Note: Student statistics are averaged across all students from 1994 to 2005, while teacher and
            school statistics are averaged at the school level over the same period († indicates no data for
            1994). School location and student categories are both mutually exclusive and exhaustive.



    As for the distribution of schools by grade structure, there are 849 K-5 schools, 97 K-8
schools, 102 6-8 schools and 104 K-6 schools in the sample. These tallies are approximate,
as a subset of schools open, close or switch configuration during the period of study. The
K-5, K-8 and K-6 counts are 661, 78 and 36 respectively for those that do not switch at any
point during the period of interest. The strong decline in K-6 schools comparing the less
and more restrictive samples can be attributed to the fact that many of those open in the


                                                          14
pre-reform period switched to a K-5 configuration early in the post-reform period. Given
the relatively small number of K-6 schools that do not switch, one would expect diminished
statistical power when analyzing gaming behavior using K-5 and K-6 schools. This should
be kept in mind when interpreting the results.
        An initial inspection of the data shows that K-8 and K-6 schools are observably differ-
ent from their K-5 counterparts. For instance, K-8 and K-6 schools are disproportionately
located in rural areas, while K-5 schools tend to be found more in urban and suburban
areas.23 This is important since students at rural schools tend to be more economically
disadvantaged, as measured by greater participation in the free lunch program, tend to have
parents with lower educational attainment, and are less likely to be black. Given the over-
representation of the two comparison configurations (K-8 and K-6) in rural areas, controlling
for the school’s locale in the analysis is therefore likely to be important.


II.B.     The Impact of the Reform

As a starting point, it is instructive to see which patterns emerge in the data. There are
three features that are particularly interesting. The first relates to whether the reform had
a positive effect on scores overall. Evidence presented in Figure 1 suggests that it did, which
is in keeping with the objective of policymakers. It shows density plots of first-differenced
student scores by grade, for grades two through five, using scores that are adjusted for
observable characteristics.24 The mean of each distribution is positive, reflecting the fact
that the average post-reform score is greater than its pre-reform counterpart.
        The second notable feature of the data apparent in Figure 1 is that the growth in scores
is monotonically increasing in the grade, which is the type of dynamic pattern predicted by
the theoretical model. Moreover, growth in the average grade two score is nearly zero and
is certainly much lower than is observed for the higher grades. Although it is not a focus
of my econometric strategy, the model would predict that the effort in this untested grade
  23
      For the full sample, approximately 396 K-5, 87 K-8 and 71 K-6 schools are located in rural areas. For
the subsample of schools that do not switch grade configuration, the counts are 297, 69 and 30.
   24
      Across school-grade pairs, the average score in the pre- and post-reform period is regressed on controls,
such as parental education and ethnicity, and the difference between the residuals before and after the reform
is computed for each pair. Density plots are then formed for each grade using these differences. A similar
pattern holds using test scores without controls (see Figure A.3).



                                                      15
    Figure 1 – Density of First-Differenced Scores By Grade (With Controls)




                           .15
                           .1
                 Density
                           .05
                           0




                                 -10   0                   10                 20   30
                                           1st Difference (Post-Pre) of Score

                                                     Gr. 5             Gr. 4
                                                     Gr. 3             Gr. 2




should be as low as possible to reduce the target for grade three, given that there is no
contemporaneous benefit of exerting effort in grade two. The corresponding distribution is
consistent with this prediction.
     The third interesting feature is that the effect of the reform was not uniform across
school configurations. Figure A.4 decomposes the grade five score by school configuration,
plotting the density and means (given by the vertical lines) of the first-differenced grade five
score for K-5, K-6 and K-8 schools, respectively. Recall from Proposition 1 that, controlling
for differences in the initial educational capital of students and teacher ability, the school with
a shorter grade horizon will have a higher test score than one with a longer horizon. Using
the pre-reform period as a baseline and conditioning on student and school characteristics,
the figure reveals evidence consistent with this proposition. In particular, the mean for K-5
schools is higher than the mean for either K-6 or K-8 schools, which are the main comparisons
of interest (there are an insufficient number of observations to compare K-6 and K-8 schools).
With this suggestive evidence in hand, I now set out my basic econometric strategy to test
for ratchet effects formally.




                                                       16
                                     III.    Empirical Strategy

The theoretical analysis draws attention to a method for identifying ratchet effects using
variation in the horizon a school faces. In particular, Proposition 1, which states that the
average score will be higher in a given grade at a school serving fewer grades, is testable under
the assumption that schools with different grade configurations are otherwise identical. For
several reasons, the condition that grade spans are exogenous is unlikely to be satisfied in
practice. I briefly discuss why this is the case, before detailing my strategy for dealing with
unobserved differences across schools.
       Owing to a variety of historical factors, the popularity of different elementary school
grade configurations has waxed and waned over time, potentially leading such configurations
to be non-randomly represented in the current population of schools.25 As a result, there is
ample reason to believe that a disparity in scores between two schools with different horizons
reflects more than just differential ratchet effects. For instance, the distribution of student
ability may differ across K-5, K-6 and K-8 schools. If this is the case, then each configura-
tion may be associated with a different initial level of educational capital in the production
process, leading to disparities in subsequent scores regardless of whether incentives vary
according to the school’s horizon. Similarly, if the quality of teachers, surrounding neighbor-
hood characteristics or educational resources differ by school type, variation in scores across
grade configurations may be incorrectly interpreted as evidence of dynamic gaming.
       To isolate the variation in scores that may arise from dynamic incentives, I begin by
considering a difference-in-differences approach, using pre-reform scores as a baseline to
control for unobserved factors that vary across different grade spans. In order to compare
the grade five score between K-5 and K-8 schools, for example, I would simply construct the
difference-in-differences score
  25
     In the early twentieth century, K-8 schools were the dominant structure in the United States. In an effort
to ease the transition between elementary and secondary school and alleviate enrollment pressures arising
from immigration flows, K-6 and junior high schools became more prevalent as the century progressed. In the
1960s, research indicating that students were maturing earlier caused policymakers to shift grade six from
K-6 schools to the junior high structure, leading to the creation of K-5 and 6-8 configurations. However,
transitionary middle schools began to fall out of favor in the 1980s and 1990s as the large institutions were
perceived to be inadequately serving their students. Later research, including survey evidence by Juvonen
et al. (2004) and empirical analyses by Alspaugh (1998), Hanushek et al. (2004) and Rockoff and Lockwood
(2010), also suggested that a higher number of school transitions was deleterious to student development.


                                                      17
               ∆∆yK5−K8,5,post−pre = (yK5,5,post − yK5,5,pre ) − (yK8,5,post − yK8,5,pre ) .

Such an approach adjusts for both pre-existing disparities and shared changes (common
trends) between school configurations in inputs and the production process. If incentives
are the only time-varying factor leading to differential changes over time and the underlying
technology is linear, then the technique will produce an unbiased estimate of the dynamic
gaming distortion.
       Although the former assumption is significantly less restrictive than simply controlling
for observable characteristics, the strategy remains susceptible to differentially trending vari-
ables which are unrelated to incentives. For example, if families sort across neighborhoods
or teachers sort across schools, then the composition of educational production inputs might
evolve over time. My initial strategy accounts for this possibility by conditioning on ob-
served student, teacher and school controls Xsgt prior to computing difference-in-differences
estimates. As there are many such estimates to consider, I first estimate the equation
                                                C X
                                                X
                                    0
(3)                      yscgt =   Xsgt β   +              (φc,g,pre + φc,g,post ) + εscgt
                                                c=1 g∈Gc


where each φ is an interacted indicator variable that adjusts the score for every combination
of grade, school type and period.26 In essence, each fixed effect is a score for a particular
school configuration and grade in the pre- or post-reform period, adjusted for the vector of
observable controls.
       Upon estimating equation (3), I use F-tests of the relevant φ coefficients to recover
difference-in-differences estimates of the adjusted score for each grade. For instance, the
estimate comparing grade g scores between K-5 and K-8 schools is

(4)             ΦK5−K8,g,post−pre ≡ (φK5,g,post − φK5,g,pre ) − (φK8,g,post − φK8,g,pre ) .

If unobserved trends are common across grade configurations, then ΦK5−K8,g,post−pre > 0
satisfies the criterion for dynamic gaming behavior as in Proposition 1.
       Despite the merits of the proposed difference-in-differences strategy, differentially trend-
  26
    The results do not appreciably change when allowing for control coefficients to vary by grade (βg ) or
including school-level fixed effects.


                                                       18
ing unobservables may bias the estimates. Potential areas of concern include demand-side
sorting by households or teachers across schools of different grade configuration27 and supply-
side changes in the distribution of school configurations over time.28 One approach for ad-
dressing the supply-side issue is to restrict the difference-in-differences analysis to the subset
of schools that maintain the same grade configuration during the period of interest, which I
do in the following section. However, assuming schools compete with each other locally, se-
lection bias may persist due to the competitive effects of schools that switch on non-switching
ones.29
       The most robust way to address the preceding identification issues is to employ a triple-
differences approach. Given that difference-in-differences estimates can be computed for
every grade that is shared by any two school configurations, a triple difference can be formed
using the difference between such estimates for any two grades. For instance, the estimate
comparing grade four and five scores between K-5 and K-8 schools is

(5)                  ΦK5−K8,5−4,post−pre = ΦK5−K8,5,post−pre − ΦK5−K8,4,post−pre ,

where the difference-in-differences estimates ΦK5−K8,5,post−pre and ΦK5−K8,4,post−pre are defined
by equation (4).
       Such an analysis controls for time-invariant effects and shared trends between config-
urations, but also accounts for differentially trending unobservables as long as their effect
is grade-invariant. If one believes that household and teacher sorting and evolving school
competition do not affect scores differentially by configuration and grade, then remaining
demand- or supply-side selection bias is addressed by the triple-differences approach. A
finding of ΦK5−K8,5−4,post−pre > 0 is interpreted as satisfying the criterion for dynamic gam-
  27
     Since K-6 and K-8 schools are predominantly found in rural areas, upward bias would result if shifting
economic conditions cause low-ability households to differentially sort into rural areas. Differential changes
in unobserved district salary schedules might also lead to bias from teacher sorting.
  28
     As discussed in Section II, North Carolina policymakers increasingly shifted toward the K-5/6-8 model
during the post-reform period. If the schools were systematically selected for this transition based on
unobserved determinants of performance, bias might result. Given that the data indicates switching K-8
schools have a lower score than those that do not switch, the direction of such bias is likely downward.
  29
     To see why, consider a district with two K-8 schools, one of which is underperforming, and the other,
high-performing. If the underperforming one converts to a K-5 school and such a configuration is more
desirable than a K-8 one, then the new school may attract some higher ability students from the previously
high-performing K-8 school, resulting in upward-biased estimates.



                                                     19
ing behavior as in Proposition 2, which predicts that the magnitude of dynamic distortions
is increasing in the grade. I now turn to the difference-in-differences and triple-differences
estimates to determine whether the data are consistent with ratcheting behavior.


                                        IV.   Results

Figures 1 and A.4 already provided preliminary evidence consistent with dynamic gaming. I
now analyze these effects in a more formal way empirically. In particular, I estimate equation
(3) under three different specifications, depending on the components of the control vector
Xsgt . These specifications are defined in Table A.1, where the coefficients of each regressor
are reported. Specification (1) uses the raw score without controls, while specification (2)
includes student characteristics (such as the ethnicity of students, the education of their
parents and their exceptionality classification), the school-level proportion of students who
are eligible for the free lunch program and controls for the locale of the school. Specification
(3) then adds the licensure test score of each student’s teacher.
     All coefficients are significant and of the expected sign. A higher combined test score
in mathematics and reading is associated with students who are white, who have parents
with a more advanced education and who are labeled as being exceptional. For specification
(3) in particular, the predicted score for a student with a parent who possesses a four-year
college degree is 8.0 scale points higher than if the highest educational attainment of either
parent is a high school diploma, which in turn is 6.8 points higher than if neither parent
has finished high school. A black student is also predicted to have a score that is 8.4 points
lower than a non-black student. These are large differences, as the standard deviation of the
grade five score reported in Table 1 is 16.9 developmental points. The score is also positively
related to students attending a school with a lower free lunch participation rate and those
with teachers who scored higher on their licensing test. In the case of free lunch, a decrease
of one standard deviation in the participation rate at a school is associated with an average
increase of one developmental point.
     For specifications (1) through (3) in Table A.1 and grades three through five, I transform
the relevant fixed effects from equation (3) into first-difference, difference-in-differences and
triple-differences estimates, as in equations (4) and (5). The results for K-5 and K-8 schools,

                                               20
and K-5 and K-6 schools are reported in Table 2. In every case, the difference between pre-
and post-reform scores for a specific configuration is positive and significant, consistent with
the descriptive evidence. Using specification (3), the pre-to-post gain in grade five scores for
K-5, K-8 and K-6 schools is 8.8, 7.3 and 5.9 developmental scale points, respectively. The
analogous gains in grade four scores are 7.5, 7.1 and 5.6 points and in grade three scores are
6.8, 6.7 and 4.9 points.30 This highlights the fact that score growth increases with the grade
regardless of the school’s grade configuration.31
       The more interesting results with regard to ratchet effects are the difference-in-differences
and triple-differences estimates. For the comparison between K-5 and K-8 schools, the
difference-in-differences estimates reported in Table 2 are statistically indistinguishable from
zero for each grade when no observable controls are included. However, after introduc-
ing controls, the grade five estimates are positive and significant, which is consistent with
Proposition 1.32 That is, controlling for trending observables and the pre-reform outcome,
the school with the shorter grade horizon (K-5) has a higher score. Moving on to the pre-
ferred triple-differences strategy, the corresponding estimates are positive and significant
across all three specifications when comparing grade five to four and positive but smaller for
the comparison between grades four and three when including controls. These results are in
line with Proposition 2.
       The magnitude of dynamic distortions suggested by the difference-in-differences and
triple-differences estimates is substantial. Comparing K-5 and K-8 schools, the differential
effect of the scheme is estimated to be between 1.46 and 1.53 developmental scale points
for grade five, depending on the control-based specification used. This is equivalent to an
effect that is between 8.6 and 9.1 percent of a standard deviation in the grade five score.
For the triple differences estimates, the effect is estimated to be between 0.80 and 0.99 scale
points for the grade five to four comparison (or between 4.7 and 5.9 percent of a standard
deviation in the grade five score). The analogous difference-in-differences estimate for the
comparison between K-5 and K-6 schools is between 1.71 and 2.84 scale points, while the
  30
     Counterintuitively, gains are always lowest for K-6 schools. This reflects selection bias arising from K-6
schools disproportionately switching to a different configuration. This issue is addressed in Table 3.
  31
     Given that the standard deviation of the score is larger in grade three and four than in grade five (see
Table 1), this pattern becomes even more pronounced when adjusting for variation in scores.
  32
     The estimates for grades three and four are also positive, but not significantly so.


                                                      21
                                            Table 2 – Main Results

                                              c = K5 vs. c 0 = K8                     c = K5 vs. c 0 = K6
            Specification:                   (1)            (2)            (3)        (1)            (2)            (3)
            Grade 5 DinD
              Φc,5,post−pre                 9.01∗∗∗ 9.51∗∗∗ 8.77∗∗∗                  9.01∗∗∗ 9.51∗∗∗ 8.77∗∗∗
                                           (0.22)         (0.15)         (0.14)     (0.22)         (0.15)         (0.14)
                                                    ∗∗∗            ∗∗∗        ∗∗∗            ∗∗∗            ∗∗∗
              Φc 0 ,5,post−pre              8.41           7.98           7.31       7.30           6.76           5.92∗∗∗
                                           (0.36)         (0.29)         (0.31)     (0.45)         (0.29)         (0.32)
                                                                   ∗∗∗        ∗∗∗            ∗∗∗            ∗∗∗
              Φc−c 0 ,5,post−pre            0.60           1.53           1.46       1.71           2.75           2.84∗∗∗
                                           (0.43)         (0.33)         (0.34)     (0.52)         (0.33)         (0.35)

            Grade 4 DinD
              Φc,4,post−pre                 7.76∗∗∗ 8.10∗∗∗ 7.52∗∗∗                  7.76∗∗∗ 8.10∗∗∗ 7.52∗∗∗
                                           (0.19)         (0.13)         (0.14)     (0.19)         (0.13)         (0.14)

              Φc 0 ,4,post−pre              7.96∗∗∗ 7.50∗∗∗ 7.05∗∗∗                  6.29∗∗∗ 6.02∗∗∗ 5.62∗∗∗
                                           (0.43)         (0.36)         (0.42)     (0.51)         (0.33)         (0.37)

              Φc−c 0 ,4,post−pre           -0.20           0.60           0.47       1.47∗∗∗ 2.08∗∗∗ 1.89∗∗∗
                                           (0.47)         (0.38)         (0.45)     (0.56)         (0.36)         (0.40)

            Grade 3 DinD
              Φc,3,post−pre                 7.21∗∗∗ 7.48∗∗∗ 6.79∗∗∗                  7.21∗∗∗ 7.48∗∗∗ 6.79∗∗∗
                                           (0.20)         (0.15)         (0.16)     (0.20)         (0.15)         (0.16)

              Φc 0 ,3,post−pre              7.26∗∗∗ 7.27∗∗∗ 6.74∗∗∗                  5.96∗∗∗ 5.92∗∗∗ 4.94∗∗∗
                                           (0.46)         (0.40)         (0.41)     (0.48)         (0.33)         (0.38)

              Φc−c 0 ,3,post−pre           -0.05           0.21           0.04       1.25∗∗         1.55∗∗∗ 1.85∗∗∗
                                           (0.51)         (0.43)         (0.45)     (0.53)         (0.36)         (0.41)

            Triple Differences
              Φc−c 0 ,5−4,post−pre          0.80∗∗         0.93∗∗∗ 0.99∗∗            0.24           0.66∗∗         0.95∗∗∗
                                           (0.38)         (0.34)         (0.44)     (0.31)         (0.27)         (0.36)

              Φc−c 0 ,4−3,post−pre         -0.15           0.39           0.42       0.22           0.53           0.04
                                           (0.38)         (0.41)         (0.47)     (0.33)         (0.34)         (0.44)
            Note: For each specification defined in Table A.1 and according to grade, this table reports first-
            differences, difference-in-differences and triple-differences estimates constructed from joint F-tests
            of the interaction dummies included in the regression. Standard errors adjusted for clustering at
            the school level are reported in parentheses.
                ∗∗∗ Significant at the 1 percent level.
                 ∗∗ Significant at the 5 percent level.




analogous triple-differences estimate is between 0.66 and 0.95 scale points (or between 3.9
and 5.6 percent of a standard deviation in the grade five score).33
       To the extent that the effect of supply-side changes in the distribution of school config-
urations is differential by configuration and grade, Table 3 reports difference-in-differences
  33
     Placing these results in context, a child of a college-educated parent is predicted to score 45.1 percent
of a standard deviation in the grade five score higher than one whose parent does not have a college degree.
In addition, the score increase that would occur by lowering poverty in a school (as measured by free lunch
participation) by one standard deviation would be 6.2 percent of a standard deviation in the grade five score.


                                                                    22
                       Table 3 – Restricted-Sample Robustness Check

                                               c = K5 vs. c 0 = K8                c = K5 vs. c 0 = K6
            Specification:                         (1)            (3)                (1)            (3)
            All Schools in Sample
              Φc−c 0 ,5,post−pre                 0.60            1.46∗∗∗            1.71∗∗∗        2.84∗∗∗
                                                (0.43)          (0.34)             (0.52)         (0.35)
                                                                                            ∗∗∗
              Φc−c 0 ,4,post−pre                -0.20            0.47               1.47           1.89∗∗∗
                                                (0.47)          (0.45)             (0.56)         (0.40)
                                                                                            ∗∗
              Φc−c 0 ,3,post−pre                -0.05            0.04               1.25           1.85∗∗∗
                                                (0.51)          (0.45)             (0.53)         (0.41)


              Φc−c 0 ,5−4,post−pre               0.80∗∗          0.99∗∗             0.24           0.95∗∗∗
                                                (0.38)          (0.44)             (0.31)         (0.36)

              Φc−c 0 ,4−3,post−pre              -0.15            0.42               0.22           0.04
                                                (0.38)          (0.47)             (0.33)         (0.44)

            Stable Config Only
              Φc−c 0 ,5,post−pre                 0.76∗           1.36∗∗∗           -0.18           1.51∗∗∗
                                                (0.44)          (0.38)             (0.64)         (0.56)

              Φc−c 0 ,4,post−pre                -0.67           -0.30              -1.10           0.69
                                                (0.47)          (0.48)             (0.77)         (0.69)

              Φc−c 0 ,3,post−pre                -0.78           -0.51              -0.72           0.86
                                                (0.53)          (0.53)             (0.84)         (0.91)


              Φc−c 0 ,5−4,post−pre               1.43∗∗∗         1.66∗∗∗            0.92           0.83
                                                (0.40)          (0.51)             (0.60)         (0.59)

              Φc−c 0 ,4−3,post−pre               0.11            0.21              -0.39          -0.18
                                                (0.43)          (0.54)             (0.65)         (0.92)

            Note: For the specification without any and with full controls, this table reports robustness
            checks for the difference-in-differences and triple-differences estimates by comparing the full
            sample results with all schools (top panel) to those for the subsample of schools that maintain
            a stable grade configuration over the period of interest (bottom panel). As before, the esti-
            mates are constructed from joint F-tests of the interaction dummies included in the regression.
            Standard errors adjusted for clustering at the school level are reported in parentheses.
               ∗∗∗ Significant at the 1 percent level.
                ∗∗ Significant at the 5 percent level.
                 ∗ Significant at the 10 percent level.




and triple-differences results for the full sample of schools and for the subsample of schools
that maintain their grade configuration throughout the pre- and post-reform periods. Under
the subsample restriction, the grade five difference-in-differences estimate with controls di-
minishes only slightly for the comparison between K-5 and K-8 schools and more so for the
K-5 and K-6 comparison. This makes the former and latter estimates statistically indistin-
guishable from each other. However, each estimate is still separately significant. The grade
five to four triple-differences estimates change more substantially across specifications, with

                                                           23
those for the K-5 and K-8 comparison increasing in significance and rising to between 1.43
and 1.66 scale points, and those for the K-5 and K-6 comparison becoming insignificant but
remaining positive for schools with a stable configuration. Thus, the sign and significance of
the difference-in-differences and triple-differences estimates are consistent with the dynamic
gaming hypothesis, under both the full sample and the restricted subsample.34


IV.A.     Falsification Exercise

The primary remaining threats to validity concern the implementation of other educational
reforms in North Carolina during the period of analysis. These include the introduction of
charter schools to compete with conventional public schools in 1998,35 student accountability
in 2001,36 and the federal No Child Left Behind Act in 2003. If any of these reforms affect
North Carolina public school scores non-randomly by school configuration, then the estimates
might be erroneously interpreted as evidence of dynamic gaming. In particular, charter
school competition that is concentrated in districts with a larger proportion of K-5 schools
could result in upward-biased estimates. Upward bias would similarly result if the effects of
student accountability were more pronounced in K-5 schools.
       To determine whether alternative reforms are driving my results, I carry out a falsi-
fication exercise where I counterfactually assume that the accountability reform began in
a year other than 1997. The results of this exercise are reported in Table 4. The grade
five difference-in-differences and grade five to four triple-differences estimates are noticeably
largest in the actual year of the reform for the K-5 and K-8, and K-5 and K-6 comparisons.
The counterfactual point estimates in 1998 are smaller than in 1997, while the estimates in
2001 and 2003 are substantially and significantly smaller than the 1997 ones.37 Therefore,
  34
      To lend further credence to the main dynamic gaming interpretation, I explore how the estimates of the
ratchet effect evolve over time in Appendix C.1. In Table A.3, I am also able to show that the dynamic
gaming effects are most pronounced for mathematics test scores, which is in keeping with the findings of
multiple prior studies showing teachers have a greater effect on mathematics than on reading scores (see, for
instance, Rivkin et al. (2005)).
   35
      From Bifulco and Ladd (2006), 27 charter schools began operating in 1998, with the number growing to
67 by 2002.
   36
      Fifth grade (and third grade, beginning in 2002) students were required to satisfy a specified performance
threshold to advance to the next grade. Fruehwirth (2013) provides additional detail on this reform.
   37
      The negative estimates for 2002 onward reflect the dynamic effect in reverse, as the strong post-period
effects are counterfactually attributed to the pre-period instead.



                                                      24
                                  Table 4 – Falsification Exercise

                                            K5 vs. K8                                 K5 vs. K6
           Estimate:                Φ5,post−pre Φ5−4,post−pre               Φ5,post−pre Φ5−4,post−pre
           Year of Reform
             1996                       0.91∗∗          1.08∗∗                   1.05∗            0.24
                                       (0.39)          (0.52)                   (0.57)           (0.60)

             1997                      1.36∗∗∗         1.66∗∗∗                   1.51∗∗∗         0.83
                                       (0.38)          (0.51)                   (0.56)           (0.59)

             1998                       1.03∗∗∗         0.99∗∗                   1.18∗∗           0.16
                                       (0.37)          (0.50)                   (0.56)           (0.58)

             1999                       0.55            0.82                     0.70            -0.01
                                       (0.37)          (0.50)                   (0.56)           (0.58)

             2000                       0.06            0.42                     0.21            -0.41
                                       (0.37)          (0.50)                   (0.56)           (0.58)

             2001                      -0.23            0.03                    -0.08            -0.80
                                       (0.37)          (0.50)                   (0.56)           (0.58)

             2002                      -0.25           -0.41                    -0.11            -1.25∗∗
                                       (0.38)          (0.50)                   (0.56)           (0.58)

             2003                      -0.21           -1.11∗∗                  -0.06            -1.95∗∗∗
                                       (0.38)          (0.50)                   (0.56)           (0.58)

             2004                      -0.76∗∗         -0.98∗∗                  -0.62            -1.81∗∗∗
                                       (0.38)          (0.50)                   (0.56)           (0.58)

             2005                      -1.82∗∗∗        -0.85∗                   -1.67∗∗∗         -1.69∗∗∗
                                       (0.38)          (0.52)                   (0.57)           (0.60)

           Note: This table presents the results of a falsification exercise where the reform is assumed to
           be first introduced in a year other than the actual one (1997 (1996-97 school year) in bold). For
           each counterfactual year (and the actual one), difference-in-differences and triple-differences
           estimates are reported, which are constructed from joint F-tests of the interaction dummies
           included in the regression with full controls (specification (3)) for the subsample of schools
           that do not switch configuration during the period of analysis. Standard errors adjusted for
           clustering at the school level are reported in parentheses.
              ∗∗∗ Significant at the 1 percent level.
               ∗∗ Significant at the 5 percent level.
                 ∗ Significant at the 10 percent level.




the dynamic effects that I have uncovered are robust to the implementation of additional
policies during the period of interest.


                                                V.   Mechanisms

To clearly motivate the identification strategy, the stylized model focused on the monitoring
and coordination of teacher effort by principals as the exclusive channel for dynamic gaming
to occur, setting aside alternative mechanisms for the sake of simplicity. Yet a perfectly
plausible and leading rival hypothesis is that principals re-allocate teachers across grades to

                                                          25
maximize their school’s payoff, altering teacher ability (rather than effort) across classrooms.
With a slight modification to accommodate the discrete nature of such a decision, the impli-
cations for within-school teacher sorting are analogous to those for effort: school principals
are predicted to shift teachers with greater teaching ability to higher grades. Understanding
the extent to which the estimated dynamic gaming effects are due to differences in teacher
effort or changes in the grade assignments of teachers is crucial for successfully refining the
incentive scheme to account for ratcheting behavior. Moreover, appealing to non-score vari-
ation can provide additional support for the dynamic gaming hypothesis. Before analyzing
the two primary channels for such gaming in detail,38 it is worth briefly discussing two ways
in which the strength of the dynamic effects arising from them might be affected.
       Whether teachers respond to the school-level incentives in a decentralized way or their
effort is centrally coordinated through the principal, it would be reasonable to expect that
the dynamic gaming effect would be more pronounced for schools with fewer teachers per
grade.39 On the other hand, while a greater number of classes might lead to more free riding,
such a situation would also allow greater flexibility for a principal engaging in teacher re-
allocation across grades. Thus, as the number of classes increases, the dynamic gaming effect
is expected to be attenuated under an effort-based channel and strengthened under a sorting-
based channel. On balance, the evidence lends support for the former channel. Dividing the
difference-in-differences and triple-differences effects according to schools with a small and
large number of tested classes per grade, Table A.4 shows that the point estimates are larger
for the smaller classification in all cases and significantly so for the difference-in-differences
estimates.
       School-specific principal tenure may also potentially affect the extent of dynamic gam-
ing that occurs through the coordination of effort and re-sorting of teachers by principals.
Decomposing the difference-in-differences and triple-differences effects according to whether
  38
     One might argue that the shifting of non-teacher-based resources across grades is a potentially important
third channel. While I do not possess data on all such inputs, I am able to observe class size and can rule
out changes in it from driving the main results: all difference-in-differences and triple-differences estimates
using class size (rather than test scores) as the dependent variable are insignificant, though of the expected
negative sign. These results are available upon request.
  39
     In the former case, the free rider problem results in an effect that diminishes as the number of teachers
in a school increases. In the centralized latter case, the principal might find it more difficult to coordinate
over a greater number of teachers.



                                                      26
the school principal is new to the school or more established, Table A.5 reveals that the point
estimates for principals with more than one year of school-specific experience are larger than
for those without school-specific experience. Although this difference is not statistically sig-
nificant, owing to the large standard errors, this evidence is at least suggestive that the
dynamic gaming response by school principals is greater when their information set about
teachers is more complete.
     Returning to the primary mechanisms of interest, within-school teacher re-allocation
stands apart from differential effort in that it is directly observed in the data. While this en-
ables a decomposition of the difference-in-differences and triple-differences effects by channel
(which I turn to shortly), it also allows for an analysis of teacher re-allocation by quality,
to determine if the re-sorting that occurs is consistent with the dynamic gaming hypothesis.
Such an investigation depends on the existence of a reliable measure of teacher quality which
can be matched to a high proportion of teachers in the post-reform period. As 1998 is the
first year in which school principals could have plausibly dynamically gamed the system
through teacher re-allocation, I compute fixed effects for each teacher in 1997 and use them
to analyze teacher re-sorting in 1998 only.40
     Table 5 reports the results of the re-allocation analysis by teacher quality. Defining a
high (h) and low (l) quality teacher as possessing a fixed effect that is above and below the
median, respectively, I compute the change in assigned grade (∆g) from 1997 to 1998 for each
group and the difference between them.41 I perform this calculation for the entire sample of
teachers and a variety of teacher experience cutoffs. Across all teachers, there is statistically
no difference between the re-allocation of high and low quality teachers. However, in line with
the idea that more entrenched teachers may be more likely to resist re-sorting, striking results
emerge when limiting the analysis to teachers with fewer than thirteen years of experience.
   40
      Given that the accountability reform was introduced in June of 1996 after allocation decisions had been
made for 1997, it is unlikely that teacher re-sorting for dynamic gaming purposes occurred prior to 1998.
Although using fixed effects from 1997 is not ideal, as they may reflect some early dynamic distortions of
effort, it is a reasonable approximation that maximizes the number of teachers for whom teaching quality
and re-allocation can jointly be observed (note that score data is missing for grades five through eight in
1996 and the match rate using analogous 1995 quality measures or later post-reform years is substantially
lower).
   41
      For example, ∆g would equal 1 if a teacher was reassigned to grade five from four (or four from three)
and 0 if not reassigned. Other transitions are calculated analogously.




                                                     27
                        Table 5 – Teacher Sorting by Quality (1998)
                                                           h           l            h−l           h−l
             Gr. Scale Difference:                       ∆g97        ∆g97         ∆g97          ∆g97
                                                        (all tch)   (all tch)     (all tch)    (∆g 6= 0)

             Years of Experience x
                1 ≤ x ≤ 12                             0.019        -0.021        0.040∗∗       0.27∗∗
                                                      (0.013)       (0.013)       (0.019)      (0.12)

                all x                                  0.006        -0.004        0.010         0.08
                                                      (0.007)       (0.008)       (0.010)      (0.08)

                1≤x≤3                                  0.051∗       -0.034        0.085∗∗       0.48∗∗
                                                      (0.029)       (0.025)       (0.038)      (0.21)

                4≤x≤6                                 -0.008        -0.032        0.025         0.14
                                                      (0.020)       (0.021)       (0.029)      (0.21)

                7≤x≤9                                  0.018        -0.043∗       0.061∗        0.45∗
                                                      (0.024)       (0.025)       (0.035)      (0.26)
                                                                              ∗
                10 ≤ x ≤ 12                            0.010         0.060        -0.049        -0.30
                                                      (0.031)       (0.034)       (0.045)      (0.34)

             Note: Observations are at the teacher level and include only those teaching at K-5 schools
             that maintain their grade configuration from 1997 to 1998. Teacher quality measures are
             constructed from teacher fixed effects in a regression of test scores in 1997 on the prior
             ones in 1996 and set of covariates, including parental education, student ethnicity and
             student exceptionality. A high quality teacher (h) is then defined as possessing a fixed
             effect that is above the median, while a low quality teacher (l) possesses one that is below
             the median. The difference in grade scale (∆g) measures the change in grade and allows
             for changes in classes taught even if the teacher teaches multiple classes across different
             grades. Standard errors are reported in parentheses.
                  ∗∗ Significant at the 5 percent level.
                   ∗ Significant at the 10 percent level.




Relative to their low quality counterparts, high quality teachers are re-sorted up the grade
distribution and the effect is statistically significant: of those teachers who switch grades,
the average effect is an increase of about three tenths of a grade. Decomposing the relatively
inexperienced teachers into four three-year intervals of experience reveals that the results
are driven by teachers who have taught for one to three years and seven to nine years: in
each case, reassigned high quality teachers are significantly moved up by nearly half a grade
when compared to their low quality counterparts. The lack of a significant result for teachers
who have taught for four to six years is particularly interesting, given that tenure is granted
in the fourth year of teaching in North Carolina and tenure could make teachers relatively
more difficult to re-sort as they gain bargaining power.
     In light of the direct evidence of re-allocation in 1998, I now decompose the difference-in-
differences and triple-differences effects to establish the comparative importance of the effort
and sorting channels. In particular, I construct such effects using the subset of teacher-year


                                                         28
observations corresponding to teachers who have not been reassigned to teach a new grade in
any prior post-reform period (∆g = 0) and those who have in at least one prior post-reform
period (∆g 6= 0).42 In the former case, any dynamic gaming effects should exclusively be
due to differential teacher effort, while effects for the latter case are expected to arise from
a combination of differential effort and re-allocation.

                            Table 6 – Decomposing the Dynamic Effects

             A. Estimates for K5-K8 Comparison
                                            Unadjusted for Share                  Adjusted for Share
                                         Φ5,post−pre Φ5−4,post−pre            Φ5,post−pre Φ5−4,post−pre
                                                      ∗∗           ∗
             ∆g = 0                           1.14            1.34                 0.60∗∗          0.71∗
                                             (0.53)          (0.71)               (0.28)         (0.37)

             ∆g 6= 0                          1.13∗           1.49∗                0.53∗           0.70∗
                                             (0.63)          (0.87)               (0.30)         (0.41)

             Total Effect                      —               —                   1.13∗∗          1.41∗∗
                                                                                  (0.46)         (0.55)

             B. Estimates for K5-K6 Comparison
                                            Unadjusted for Share                  Adjusted for Share
                                         Φ5,post−pre Φ5−4,post−pre            Φ5,post−pre Φ5−4,post−pre
             ∆g = 0                           1.42∗∗          1.05                 0.76∗∗          0.56
                                             (0.67)          (0.74)               (0.36)         (0.39)

             ∆g 6= 0                          1.94∗∗          0.96                 0.91∗∗          0.45
                                             (0.78)          (0.76)               (0.36)         (0.35)

             Total Effect                      —               —                   1.67∗∗∗         1.01
                                                                                  (0.61)         (0.62)

             Note: This table presents difference-in-differences and triple-differences estimates for teachers
             who have not been reassigned to teach a new grade in any prior post-reform period (∆g = 0)
             and those who have in at least one prior post-reform period (∆g 6= 0). To facilitate such an
             analysis, only teachers whose work history spans the years 1997 through the year of observation
             are included. The estimates are constructed from joint F-tests of the interaction dummies
             (pre/post period × type × grade × grade change classification) included in the regression with
             full controls (specification (3)) for the subsample of schools that do not switch configuration
             during the period of analysis. Owing to the institutional details of the reform, the pre- and
             post-reform period is respectively defined as 1995 through 1996 and 1998 through 2005. Both
             unadjusted effects that indicate the magnitude of dynamic gaming within each group of teachers
             and effects that are adjusted for the share of each group in the overall sample are reported.
             The latter estimates sum to the effect across both groups, which is reported in the third row.
             Standard errors adjusted for clustering at the school level are reported in parentheses.
                ∗∗∗ Significant at the 1 percent level.
                  ∗∗ Significant at the 5 percent level.
                   ∗ Significant at the 10 percent level.




       Table 6 presents the results of the decomposition, both within each group (∆g = 0 and
  42
   I do not exploit pre-reform teacher quality measures for this decomposition, since they do not exist for
a majority of post-reform teacher observations.


                                                            29
∆g 6= 0) using variation in group proportions across schools (the “Unadjusted for Share”
effects) and across groups by conditioning on the share of each in the sample to produce
effects which sum to the total effects for all teachers (the “Adjusted for Share” effects).
Comparing K-5 to both K-8 and K-6 schools, the evidence is consistent with the effort and
sorting mechanisms being important. For the comparison between K-5 and K-8 schools,
the unadjusted triple-differences estimates are positive and significant for both groups and
the point estimates are slightly larger for the ∆g 6= 0 group (although not significantly
so). Moreover, while neither of the positive triple-differences estimates are significant for
the comparison between K-5 and K-6 schools (which is in keeping with earlier findings),
the difference-in-differences estimates are both positive and significant, with a slightly larger
point estimate found once again for the ∆g 6= 0 group. A larger point estimate for this group
accords with intuition, as it reflects both dynamic gaming channels rather than the single
one for ∆g = 0.
     Under the more restrictive pre- and post-reform definitions, the difference-in-differences
and triple-differences estimates across all teachers (found in the “Total Effect” row of each
panel) are similar to those for the full sample. Focusing on the preferred triple-differences
results which are significant for the comparison between K-5 and K-8 schools, the adjusted-
for-share estimates reveal that each group accounts for half of the total dynamic gaming
effect. Given that the effort channel is expected to account for the entire ∆g = 0 estimate
and a portion of the ∆g 6= 0 estimate, this suggests that differential effort is a key driver of
dynamic gaming and potentially the primary channel through which it occurs, while teacher
re-allocation is likely an important secondary channel.


                                      VI.   Conclusion

A broad class of incentive schemes condition on prior outcomes to compensate for heteroge-
neous inputs. While increased efficiency is likely to result from such a design, these schemes
make it possible for agents to manipulate future targets by distorting contemporaneous de-
cisions. Credible empirical estimates of these distortions are scarce and no previous studies
have explored this issue in an education context, where conditioning accountability targets
on prior performance has become increasingly prevalent.

                                               30
     A primary reason for this state of affairs is that existing theoretical analyses do not
provide a clear prediction as to where one might look for such dynamic effects – an im-
portant element in forming a plausible identification strategy. In this paper, I developed a
novel test for these distortions in an educational setting by reformulating the prior dynamic
moral hazard theory to accommodate ratchet effects with finite horizons and human capital
accumulation. This extension produces a viable research design where ratchet effects are
identified from variation in the horizons schools face, as captured by the school grade span.
     Using a triple-differences strategy to account for differentially trending unobservables
across schools, I found substantial evidence of such effects, with distortions ranging between
3.9 and 5.9 percent of a standard deviation in the grade five score. Several robustness checks
lend credence to my dynamic gaming interpretation of the results. Exploiting additional data
on teacher-grade assignments, I also provided insight into the mechanisms that generate
the estimated effects. The evidence indicates that they are likely to be driven primarily
by distortions in classroom effort, with re-sorting of teachers across grades serving as an
important secondary channel.
     Given the substantial stakes often associated with incentive schemes in education and
more generally, it is important that policymakers are cognizant of the nontrivial distortions
that can arise when future targets are manipulable. I proposed an alternative target that
eliminates these distortions by sacrificing a portion of the efficiency gained through con-
ditioning on preceding outcomes. This provides a foundation for designing a more refined
scheme that achieves an optimal balance between accounting for variation in inputs and
limiting dynamic gaming, a subject I plan to pursue in future work.




                                             31
                                     References

Allen, Douglas W., and Dean Lueck. 1999. “Searching for Ratchet Effects in Agricul-
 tural Contracts.” Journal of Agricultural and Resource Economics, 24(2): 536–552.

Alspaugh, John W. 1998. “Achievement Loss Associated with the Transition to Middle
 School and High School.” Journal of Educational Research, 92(1): 20–25.

Baron, David P., and David Besanko. 1987. “Commitment and Fairness in a Dynamic
 Regulatory Relationship.” Review of Economic Studies, 54(3): 413–436.

Bifulco, Robert, and Helen F. Ladd. 2006. “The Impacts of Charter Schools on Student
  Achievement: Evidence from North Carolina.” Education Finance and Policy, 1(1): 50–90.

Carnoy, Martin, and Susanna Loeb. 2002. “Does External Accountability Affect Stu-
 dent Outcomes? A Cross-State Analysis.” Educational Evaluation and Policy Analysis,
 24(4): 305–331.

Charness, Gary, Peter Kuhn, and Marie-Claire Villeval. 2010. “Competition and
 the Ratchet Effect.” National Bureau of Economic Research Working Paper 16325.

Chetty, Raj, John N. Friedman, and Jonah E. Rockoff. 2011. “The Long-Term Im-
 pacts of Teachers: Teacher Value-Added and Student Outcomes in Adulthood.” National
 Bureau of Economic Research Working Paper 17699.

Cooper, David J., John H. Kagel, Wei Lo, and Qing Liang Gu. 1999. “Gaming
 Against Managers in Incentive Systems: Experimental Results with Chinese Students and
 Chinese Managers.” American Economic Review, 89(4): 781–804.

Cullen, Julie Berry, and Randall Reback. 2006. “Tinkering Toward Accolades: School
 Gaming Under a Performance Accountability System.” National Bureau of Economic Re-
 search Working Paper 12286.

Dee, Thomas S, and Brian Jacob. 2011. “The impact of No Child Left Behind on student
 achievement.” Journal of Policy Analysis and Management, 30(3): 418–446.

Fabrizio, Louis Michael. 2006. “The Creation and Evolution of North Carolina’s ABCs
  Accountability Program and the Impact of No Child Left Behind-A Case Study.” N.C.
  State University Doctoral Dissertation.

Figlio, David N., and Lawrence W. Kenny. 2007. “Individual Teacher Incentives and
  Student Performance.” Journal of Public Economics, 91(5): 901–914.

Freixas, Xavier, Roger Guesnerie, and Jean Tirole. 1985. “Planning Under Incomplete
  Information and the Ratchet Effect.” Review of Economic Studies, 52(2): 173–191.

Fruehwirth, Jane Cooley. 2013. “Identifying Peer Achievement Spillovers: Implications
  for Desegregation and the Achievement Gap.” Quantitative Economics, 4(1): 85–124.



                                          32
Gibbons, Robert. 1987. “Piece-Rate Incentive Schemes.” Journal of Labor Economics,
 5(4): 413–429.
Hanushek, Eric A., and Margaret E. Raymond. 2005. “Does School Accountability
 Lead to Improved Student Performance?” Journal of Policy Analysis and Management,
 24(2): 297–327.
Hanushek, Eric A., John F. Kain, and Steven G. Rivkin. 2004. “Disruption Versus
 Tiebout Improvement: The Costs and Benefits of Switching Schools.” Journal of Public
 Economics, 88(9): 1721–1746.
Heneman, Herbert G. 1998. “Assessment of the Motivational Reactions of Teachers to a
 School-Based Performance Award Program.” Journal of Personnel Evaluation in Educa-
 tion, 12(1): 43–59.
Holmstrom, Bengt. 1982. “Design of Incentive Schemes and the New Soviet Incentive
 Model.” European Economic Review, 17(2): 127–148.
Jacob, Brian A., and Steven D. Levitt. 2003. “Rotten apples: An Investigation of
  the Prevalence and Predictors of Teacher Cheating.” Quarterly Journal of Economics,
  118(3): 843–877.
Juvonen, Jaana, Vi-Nhuan Le, Tessa Kaganoff, Catherine H. Augustine, and
  Louay Constant. 2004. Focus on the Wonder Years: Challenges Facing the American
  Middle School. Santa Monica, CA:RAND Corporation.
Kanemoto, Yoshitsugu, and W. Bentley MacLeod. 1992. “The Ratchet Effect and
 the Market for Secondhand Workers.” Journal of Labor Economics, 10(1): 85–98.
Kane, Thomas J., and Douglas O. Staiger. 2001. “Improving School Accountability
 Measures.” National Bureau of Economic Research Working Paper 8156.
Kane, Thomas J., and Douglas O. Staiger. 2002. “The Promise and Pitfalls of Using
 Imprecise School Accountability Measures.” Journal of Economic Perspectives, 16(4): 91–
 114.
Kane, Thomas J., and Douglas O. Staiger. 2008. “Estimating Teacher Impacts on Stu-
 dent Achievement: An Experimental Evaluation.” National Bureau of Economic Research
 Working Paper 14607.
Keren, Michael, Jeffrey Miller, and James R. Thornton. 1983. “The Ratchet: A
 Dynamic Managerial Incentive Model of the Soviet Enterprise.” Journal of Comparative
 Economics, 7(4): 347–367.
Ladd, Helen F. 2001. “School-based Educational Accountability Systems: The Promise
  and the Pitfalls.” National Tax Journal, 54(2): 385–400.
Ladd, Helen F., and Arnaldo Zelli. 2002. “School-Based Accountability in North
  Carolina: The Responses of School Principals.” Educational Administration Quarterly,
  38(4): 494–529.

                                          33
Laffont, Jean-Jacques, and Jean Tirole. 1988. “The Dynamics of Incentive Contracts.”
  Econometrica, 56(5): 1153–1175.

Lavy, Victor. 2002. “Evaluating the Effect of Teachers’ Group Performance Incentives on
  Pupil Achievement.” Journal of Political Economy, 110(6): 1286–1317.

Lavy, Victor. 2009. “Performance Pay and Teachers’ Effort, Productivity, and Grading
  Ethics.” American Economic Review, 99(5): 1979–2011.

Lazear, Edward P. 1986. “Salaries and Piece Rates.” Journal of Business, 59(3): 405–431.

McCaffrey, Daniel F, J. R. Lockwood, Daniel Koretz, Thomas A. Louis, and
 Laura Hamilton. 2004. “Models for Value-Added Modeling of Teacher Effects.” Journal
 of Educational and Behavioral Statistics, 29(1): 67–101.

Muralidharan, Karthik, and Venkatesh Sundararaman. 2011. “Teacher Performance
 Pay: Experimental Evidence from India.” Journal of Political Economy, 119(1): 39–77.

Neal, Derek, and Diane Whitmore Schanzenbach. 2010. “Left Behind by Design:
 Proficiency Counts and Test-Based Accountability.” Review of Economics and Statistics,
 92(2): 263–283.

Parent, Daniel. 1999. “Methods of Pay and Earnings: A Longitudinal Analysis.” Industrial
 and Labor Relations Review, 53(1): 71–86.

Rivkin, Steven G., Eric A. Hanushek, and John F. Kain. 2005. “Teachers, Schools,
 and Academic Achievement.” Econometrica, 73(2): 417–458.

Rockoff, Jonah E., and Benjamin B. Lockwood. 2010. “Stuck in the Middle: Impacts
 of Grade Configuration in Public Schools.” Journal of Public Economics, 94(11): 1051–
 1061.

Rothstein, Jesse. 2010. “Teacher Quality in Educational Production: Tracking, Decay,
 and Student Achievement.” Quarterly Journal of Economics, 125(1): 175–214.

Todd, Petra E., and Kenneth I. Wolpin. 2003. “On the Specification and Estimation of
 the Production Function for Cognitive Achievement.” Economic Journal, 113(485): F3–
 F33.

Todd, Petra E., and Kenneth I. Wolpin. 2007. “The Production of Cognitive Achieve-
 ment in Children: Home, School, and Racial Test Score Gaps.” Journal of Human capital,
 1(1): 91–136.

Weitzman, Martin L. 1980. “The Ratchet Principle and Performance Incentives.” Bell
 Journal of Economics, 11(1): 302–308.




                                          34
Appendices
                   A.    The North Carolina Accountability Policy

A.1.    Background

Stemming from legislation ratified in June 1996 and implemented in 1997 (the 1996-97 school
year),43 North Carolina’s high-stakes accountability system consists of monetary rewards for
outperformance of a composite school-level growth target.44 Performance is measured by
norm-referenced end-of-grade reading and mathematics tests taken by students in grades
three through eight beginning in 1993. Under the scheme, if the difference between the
composite realized growth ∆yst and expected growth target ∆b
                                                           yst for school s in year t is
positive, then the principal and all teachers at the school each receive additional compen-
sation of $750; otherwise, they do not. If the school exceeds a further target that is set 10
percent higher than the expected growth target, then the bonus is increased to $1,500.45
       It is worth briefly elaborating on how the composite realized growth and target growth
for a school are calculated. Both the school-level realized growth ∆yst and expected growth
target ∆b
        yst are composites of their respective subject- and grade-specific counterparts. The
composite realized growth for each school is equal to the mean of all pertinent subject-grade
scores for that school (each one itself averaged across the students in that subject-grade
pair), weighted according to the historical standard deviation of all scores for each subject-
  43
      Ratification and implementation occurred following a pilot phase in 1996 covering ten districts con-
taining 63 schools (about 4 percent of all primary and middle schools in North Carolina), and after a
similar accountability system was put in place in the Charlotte-Mecklenburg district for the same school
year. Both of these were supplanted by the state-wide reform, which was expanded in 1998 to encompass
high school students as well. Prior to 1996, and for all other schools in 1996, a low-stakes accountability
environment was in place, consisting of published district and then school report cards (see Fabrizio (2006)
and Ladd (2001) for greater detail on the historical underpinnings of state testing and reporting in North
Carolina). Basic information about the North Carolina ABCs of Public Education (which stands for strong
Accountability, teaching the Basics and focusing on local Control) is found in an electronic brochure at
http://www.ncpublicschools.org/docs/accountability/reporting/abc/2005-06/abcsbrochure.pdf
and a copy of a more detailed timeline is available in Appendix A of Fabrizio (2006).
   44
      In general, accountability schemes tend to be implemented at the school level. This may be motivated
from an incentive design standpoint, given that the yearly variation in transitory processes that Kane and
Staiger (2002) highlight will be magnified when scores are averaged across a smaller group of students.
   45
      A teacher with 13 years of experience and a bachelor’s degree made about $30,000 in 1998. Thus, $1,500
is approximately equal to 5 percent of yearly pay or 60 percent of monthly pay.




                                                    35
                     z
grade in the state (σgt , where z ∈ {r, m} denotes the subject).46 The composite school-level
growth target is aggregated in an analogous way, using pertinent subject-grade targets with
the same weightings.
       The underlying grade-specific expected growth targets for reading and mathematics are
calculated for each student using her prior performance according to the following formulae:

        rigst = α̂0g + α̂1g (risg−1t−1 − r̄g−1t−1 + misg−1t−1 − m̄g−1t−1 ) + α̂2g (risg−1t−1 − r̄g−1t−1 )
       ∆b

    b igst = β̂0g + β̂1g (risg−1t−1 − r̄g−1t−1 + misg−1t−1 − m̄g−1t−1 ) + β̂2g (misg−1t−1 − m̄g−1t−1 )
   ∆m

       rigst ≡ rbigst − risg−1t−1 , ∆m
where ∆b                             b igst ≡ m
                                              b igst − misg−1t−1 ; rigst and migst are the average
reading and math scores for student i in school s, grade g and year t; r̄gt and m̄gt are the
average reading and math scores across all schools in the state for grade g in year t;47 and the
grade-specific coefficients α̂0g , α̂1g , α̂2g , β̂0g , β̂1g and β̂2g are given. The coefficients are estimated
from score data in 1993 and 1994 by regressing the actual score gain in 1994 for reading
or mathematics on the lagged reading and mathematics scores according to the preceding
formulae and are fixed at these values for all subsequent years through 2005.48 Using lagged
school-specific scores along with the fixed coefficients and state average lagged scores, the
expected growth targets (or gains) are calculated for every grade in a school for each year
beginning in 1997.
       The first component of each expected gain (α̂0g or β̂0g ) is the mean expected gain across
all schools in the state for grade g. The second component is the sum of the demeaned prior
performance in both subjects and is treated as a proxy for average student ability in the
school. The third component is the demeaned prior performance in the subject for which the
expected gain is being calculated, and is used as a correction for mean reversion. Consider,
for instance, schools that had above-average scores in both reading and math; they would be
  46
      The standard deviations are calculated using score data in 1995 and these fixed values are used in all
future years through 2005.
   47
      As with the statewide subject-grade standard deviations, the state means (r̄g−1t−1 and m̄g−1t−1 ) are
fixed over time using the score data in 1995.
   48
      Specifically, using t = 1994, α̂0 , α̂1 and α̂2 are obtained from the first equation, while β̂0 , β̂1 and β̂2 are
obtained from the second one. In 2001, these reduced-form coefficients were then updated for grade three
only. I have verified that this recipe produces the coefficients used by the North Carolina accountability
scheme by independently implementing it. I also extended the analysis to all pre- and post-reform years,
finding that the reduced-form targets are highly dependent on the reference year that is selected.



                                                          36
expected to outperform an average school due to having a more able student body, but their
expected performance would be attenuated by the tendency for atypical scores to correct
toward the state average over time.49
       In essence, the North Carolina incentive scheme uses one year of prior school perfor-
mance to proxy for all prior inputs. It also attempts to exploit the disparity between reading
and math scores to control for any component of the prior score that does not contribute
permanently to a child’s learning in the future. Given the structure of the North Carolina
approach, there are several reasons why targets may be too easy or difficult to satisfy, stem-
ming from the fact that the combined prior reading and math scores are not exclusively the
result of student ability. These include differences between prior and current teacher ability
and/or school resources, and any transitory effect that is misinterpreted as a permanent one
since it influences both subjects. They are undesirable aspects of the reform, since teachers
are then held accountable for an outcome that they do not fully control. That said, my
econometric strategy for uncovering ratcheting behavior does not depend on the existence
of such contemporaneous inefficiencies.
       While the 1996 North Carolina accountability reform is not without its flaws, there
are several elements that make it well-suited for detecting evidence of dynamic gaming
behavior. First, it features a high-powered school-level reward scheme that conditions targets
on student prior scores to account for heterogeneity in students, teachers and resources, all of
which are predicted to be key ingredients in generating ratchet effects within schools. Survey
evidence lends credence to this idea.50 Moreover, the program is long-standing, having
dispensed over $870 million in pecuniary payments to educators through 2005 (Fabrizio
(2006)),51 so that any dynamic distortions would have had time to manifest themselves.


  49
      Kane and Staiger (2002) highlight the importance of year-to-year transitory shocks in determining scores.
Ideally, an incentive scheme would not hold teachers accountable for factors that were out of their control. It
is therefore notable that North Carolina policymakers made an effort to correct for mean-reverting processes.
   50
      Referring to the 1995-96 scheme in Charlotte-Mecklenburg that has strong similarities to the North
Carolina accountability program that followed, Heneman (1998) reports that very few teachers agreed with
the statement: “We can continue to meet ever-higher student achievement goals in the future.” This suggests
that they were thinking about dynamic consequences when the program was introduced.
   51
      Only minor changes were made to the program prior to a more substantial overhaul in 2006, which
explains why my investigation into dynamic gaming does not extend beyond 2005. Despite the changes to
the reform in 2006, the salient features that are necessary for such gaming to occur remain in place, as the
targets continue to be at the school level and depend on student prior scores.


                                                      37
                                                 B.   Data

B.1.   Available Data

The student-level data extends from 1993 to 2011.52 However, the reform was substantially
altered in 2006 (as reflected by the double horizontal separator in the graphical representation
of the data by year and cohort below) and data for 1993 cannot be linked with later years.
Data for 1996 are also missing for grades five through eight, but I am able to overcome this
limitation for grades five through seven in 1996 by using the prior year scores for grades six
through eight in 1997. School-level characteristics are then imputed for grade five students
in 1996 who attend a 6-8 middle school in 1997, by constructing composite K-5 feeder schools
from the K-5 schools that feed each 6-8 school in 1998.

                                                       Cohort
             Year    1    2   3    4    5    6    7    8    9   10   11   12   13   14   15   16
             1993    4    3    -   -    -    -    -    -    -   -    -    -    -    -    -    -
             1994    5    4   3    -    -    -    -    -    -   -    -    -    -    -    -    -
             1995    6    5   4    3    -    -    -    -    -   -    -    -    -    -    -    -
             1996    -    -   -    4    3    2    -    -    -   -    -    -    -    -    -    -
             1997    -    -   6    5    4    3    2    -    -   -    -    -    -    -    -    -
             1998    -    -   7    6    5    4    3    2    -   -    -    -    -    -    -    -
             1999    -    -   8    7    6    5    4    3    2   -    -    -    -    -    -    -
             2000    -    -   -    8    7    6    5    4    3   2    -    -    -    -    -    -
             2001    -    -   -    -    8    7    6    5    4   3    2    -    -    -    -    -
             2002    -    -   -    -    -    8    7    6    5   4    3    2    -    -    -    -
             2003    -    -   -    -    -    -    8    7    6   5    4    3    2    -    -    -
             2004    -    -   -    -    -    -    -    8    7   6    5    4    3    2    -    -
             2005    -    -   -    -    -    -    -    -    8   7    6    5    4    3    2    -
             2006    -    -    -   -    -    -    -    -    -   8    7    6    5    4    3    2
             2007    -    -    -   -    -    -    -    -    -   -    8    7    6    5    4    3
             2008    -    -    -   -    -    -    -    -    -   -    -    8    7    6    5    4
             2009    -    -    -   -    -    -    -    -    -   -    -    -    8    7    6    5
             2010    -    -    -   -    -    -    -    -    -   -    -    -    -    8    7    6
             2011    -    -    -   -    -    -    -    -    -   -    -    -    -    -    8    7




  52
    With respect to score data, although second editions of the tests for elementary students in mathematics
and reading were introduced in 2001 and 2003, respectively, state psychometricians use equating studies to
not only ensure comparability across grades but years as well.


                                                      38
                        C.   Discussion of Additional Results

C.1.   Evolution of Dynamic Effects

Exploiting the abundance of post-reform data, Table A.2 reports the difference-in-differences
and triple-differences estimates for three post-reform periods of equal duration. The evidence
indicates that the disparity evolves as one might expect if principals and teachers initially
require time to acclimate to the new incentive environment. In particular, comparing either
K-5 and K-8, or K-5 and K-6 schools, the estimates for 1997-1999 are smaller than the
analogous ones for 2000-2002, and statistically so in the difference-in-differences case.




                                              39
                    Table A.1 – Regression Specifications

Dependent Variable: Combined Mathematics and Reading Score
Specification:                                 (1)                   (2)                   (3)
Student - Parental Education:
  No High School                                                  -17.36∗∗∗             -17.29∗∗∗
                                                                    (0.15)               (0.16)
  High School Graduate                                            -10.55∗∗∗             -10.45∗∗∗
                                                                    (0.13)               (0.14)
  Trade School                                                      -5.78∗∗∗             -5.60∗∗∗
                                                                    (0.13)               (0.13)
  Community College                                                 -6.62∗∗∗             -6.55∗∗∗
                                                                    (0.13)               (0.13)
  4-Year College                                                    -2.51∗∗∗             -2.45∗∗∗
                                                                    (0.10)               (0.10)

Student - Ethnic - Black                                            -8.53∗∗∗             -8.44∗∗∗
                                                                    (0.10)               (0.10)

Student - Exceptionality:
  Learning Impairment                                             -13.23∗∗∗             -13.22∗∗∗
                                                                    (0.09)               (0.10)
                                                                           ∗∗∗
  Gifted/Exceptional                                               16.65                 16.71∗∗∗
                                                                    (0.09)               (0.09)

Prop. Free Lunch Eligible                                           -5.24∗∗∗             -4.83∗∗∗
                                                                    (0.35)               (0.36)
Teacher Licensure Test Score                                                              0.62∗∗∗
                                                                                         (0.06)
                                                     ∗∗∗                   ∗∗∗
Constant                                     283.3                 349.1                 348.9∗∗∗
                                              (0.8)                  (0.2)                (0.2)

School Locale Controls?                        No                    Yes                   Yes
R2                                            0.338                 0.664                 0.670
Observations                               6,130,308             5,318,520             4,499,997
Note: This table defines three specifications according to the components included in the con-
trol vector of the main estimating equation (equation (3)) and reports the coefficient for each
component. All specifications include interaction dummies (pre/post period × type × grade),
which are used to construct the first-differences, difference-in-differences and triple-differences
estimates reported in Table 2. The analysis is conducted for the years 1994 through 2005, with
the number of observations declining as regressors with missing values are added. Standard
errors adjusted for clustering at the school level are reported in parentheses.
   ∗∗∗ Significant at the 1 percent level.




                                                40
               Table A.2 – A Closer Look at the Post-Reform Period

                                          c = K5 vs. c 0 = K8                          c = K5 vs. c 0 = K6
Post-reform definition:              97-99         00-02           03-05          97-99           00-02          03-05
                                          ∗               ∗∗∗              ∗∗∗                             ∗∗∗
  Φc−c 0 ,5,post−pre                 0.73           1.66           2.04            0.68            2.40           1.60∗∗
                                    (0.41)         (0.46)         (0.46)          (0.44)          (0.85)         (0.71)
                                          ∗∗∗             ∗∗∗              ∗∗
  Φ  c−c 0 ,5−4,post−pre             1.59           1.93           1.45            1.08            1.19           0.17
                                    (0.52)         (0.57)         (0.63)          (0.65)          (0.74)         (0.71)
Note: This table reports difference-in-differences and triple-differences estimates constructed from joint F-tests of
the interaction dummies included in the regression with full controls (specification (3)) for the subsample of schools
that do not switch configuration during the period of analysis. The nine-year post-reform period is subdivided
into three equal three-year periods when constructing the interaction dummies to analyze the evolution of the
dynamic gaming effect. Standard errors adjusted for clustering at the school level are reported in parentheses.
   ∗∗∗ Significant at the 1 percent level.
    ∗∗ Significant at the 5 percent level.
     ∗ Significant at the 10 percent level.




             Table A.3 – Supporting Evidence - Breakdown by Subject

                                              c = K5 vs. c 0 = K8                c = K5 vs. c 0 = K6
        Subject:                             M +R                 M              M +R                 M
                                                    ∗∗∗                  ∗∗∗                ∗∗∗
           Φc−c 0 ,5,post−pre                   1.36             1.02               1.51              1.13∗∗∗
                                              (0.38)            (0.27)             (0.56)            (0.42)
           Φc−c 0 ,4,post−pre                 -0.30              -0.33              0.69              0.57
                                              (0.48)            (0.30)             (0.69)            (0.46)
           Φc−c 0 ,3,post−pre                 -0.51              -0.51              0.86              0.76
                                              (0.53)            (0.33)             (0.91)            (0.58)

           Φc−c 0 ,5−4,post−pre                 1.66∗∗∗          1.35∗∗∗            0.83              0.56
                                              (0.51)            (0.33)             (0.59)            (0.39)

        Note: This table compares difference-in-differences and triple-differences estimates for the com-
        bined score (mathematics and reading, or M + R) to those for mathematics (M ). The estimates
        are constructed from joint F-tests of the interaction dummies included in the regression with full
        controls (specification (3)) for the subsample of schools that do not switch configuration during
        the period of analysis. The coefficient for reading is simply the difference between the Φ for M +R
        and M . Standard errors adjusted for clustering at the school level are reported in parentheses.
           ∗∗∗ Significant at the 1 percent level.




                                                            41
               Table A.4 – Coordination/Free-Riding Effects

                                  c = K5 vs. c 0 = K8                      c = K5 vs. c 0 = K6
Classes per grade:                S            L           S−L            S               L    S−L
                                       ∗∗∗                          ∗            ∗∗
  Φc−c 0 ,5,post−pre            2.06          0.53          1.52         2.16          0.38     1.78∗
                              (0.62)         (0.69)        (0.92)       (0.84)        (0.61)   (0.96)
  Φc−c 0 ,5−4,post−pre          2.16∗∗∗       1.74          0.42         1.27          0.06     1.21
                              (0.75)         (1.59)        (1.86)       (0.85)        (1.19)   (1.57)
Note: This table presents difference-in-differences and triple-differences estimates for schools with a
small (S) and large (L) number of classes per grade, and the difference between the two (S − L). The
estimates are constructed from joint F-tests of the interaction dummies (pre/post period × type ×
grade × below/above 25th percentile of the number of classes per grade) included in the regression
with full controls (specification (3)) for the subsample of schools that do not switch configuration
during the period of analysis. A small number of classes per grade is defined to be three (the
25th percentile) or fewer. Standard errors adjusted for clustering at the school level are reported in
parentheses.
   ∗∗∗ Significant at the 1 percent level.
    ∗∗ Significant at the 5 percent level.
     ∗ Significant at the 10 percent level.




             Table A.5 – School-Specific Principal Experience

                                   c = K5 vs. c 0 = K8                   c = K5 vs. c 0 = K6
No. of years:                  >1             1              ∆          >1            1         ∆
   Φc−c 0 ,5,post−pre           1.40∗∗        1.07∗          0.32        1.64∗∗        1.75∗     -0.11
                               (0.67)        (0.65)         (0.92)      (0.79)        (0.93)    (1.08)
   Φc−c 0 ,5−4,post−pre         2.55∗∗∗       1.16           1.40        1.37          0.54      0.83
                               (0.81)        (0.78)         (1.09)      (0.92)        (1.05)    (1.38)
Note: This table presents difference-in-differences and triple-differences estimates for schools with
principals who have two or more years of school-specific experience (> 1) and those who are new to
the school (1), and the difference between the two (∆). The estimates are constructed from joint
F-tests of the interaction dummies (pre/post period × type × grade × established/new principal)
included in the regression with full controls (specification (3)) for the subsample of schools that do
not switch configuration during the period of analysis. Standard errors adjusted for clustering at the
school level are reported in parentheses.
   ∗∗∗ Significant at the 1 percent level.
    ∗∗ Significant at the 5 percent level.
     ∗ Significant at the 10 percent level.




                                                      42
Table A.6 – Descriptive Statistics for 1998 Re-sorting Analysis

Variable                                   Mean         St. Dev.          Min        Max
Transitions:
   All Teachers                              0.079           0.270            0          1
   FE97: Above Median                        0.066           0.248            0          1
   FE97: Below Median                        0.081           0.273            0          1
Gr. Scale Difference (∆g)                     0.00            0.36           -2          2
Quality Measure (1997 FE):
   Above Median                               0.52            0.50            0          1
   Below Median                               0.48            0.50            0          1
 Note: Observations are at the teacher level and include only those teaching at K-5 schools
 that maintain their grade configuration from 1997 to 1998. The 1997 fixed effect quality
 measure is constructed using contemporaneous and prior scores, as well as demographic
 data.




                                            43
          Figure A.1 – A Comparison of Effort Between K-5 and K-8 Schools


                                                                                               myopic baseline
effort




                                                                                               infinite horizon

               (3)           (4)          (5)                                                   K-5
               (3)           (4)          (5)           (6)           (7)          (8)          K-8
                                                grade

         Assuming that the target coefficient exceeds the natural growth rate (α > γ), this diagram
         contrasts the effort levels by grade for two different grade spans (as implied by the first-
         order conditions). This is done to illustrate how differing horizons affect the effort level for
         a particular grade. In the final period, there is no future horizon to take into consideration.
         Thus, the effort level coincides with what would be chosen if agents were fully myopic.
         As the number of future grades increase, the effort response diminishes. In the limit, it is
         attenuated to the infinite horizon level of Weitzman (1980).




                                                        44
    Figure A.2 – A Comparison of Scores Between K-5 and K-8 Schools

score




                    (3)                       (4)                       (5)               K-5
                    (3)                       (4)                       (5)               K-8
                                           grade
   Given the effort disparities predicted when α > γ, this diagram provides an example of
   what the scores might look like by grade for two different grade spans that are identical
   in inputs. When comparing the scores across grade spans, two features should be evident.
   First, the score disparity is positive in favor of the school with the shorter horizon (K-
   5); second, the score disparity is increasing in the grade. These patterns are implied,
   respectively, by Propositions 1 and 2.




                                               45
Figure A.3 – Density of First-Differenced Scores By Grade (Without Controls)




                      .15
                      .1
            Density
                      .05
                      0




                            -20   -10           0            10            20   30
                                        1st Difference (Post-Pre) of Score

                                                 Gr. 5             Gr. 4
                                                 Gr. 3             Gr. 2




                                                    46
Figure A.4 – Grade Five Distribution of First-Differenced Scores By Grade Span


                                                 Grade 5
             .1
             .08
               .06
          Density
        .04  .02
             0




                     -10              0                      10                       20
                                    (1st Difference (Post-Pre) of Score)

                                                 K-5              K-6
                                                 K-8


       This figure plots the density and means (given by the vertical lines) of the first-
       differenced grade five score by school configuration. As predicted by Proposition 1,
       K-5 schools have a higher mean than K-6 or K-8 schools. While it seems that the
       gain is lowest for K-6 schools, the K-6 and K-8 means are not statistically different
       from each other, since fewer K-6 observations lead to reduced power. In addition, the
       distribution of gains reflects selection bias arising from K-6 schools disproportionately
       switching to a new configuration, which I explicitly control for in Table 3.




                                                  47
