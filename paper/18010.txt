                                NBER WORKING PAPER SERIES




                        MEASURING TEST MEASUREMENT ERROR:
                               A GENERAL APPROACH

                                           Donald Boyd
                                         Hamilton Lankford
                                           Susanna Loeb
                                          James Wyckoff

                                        Working Paper 18010
                                http://www.nber.org/papers/w18010


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                      April 2012




We gratefully acknowledge support from the National Science Foundation and the Center for Analysis
of Longitudinal Data in Education Research (CALDER). Thanks also to Dale Ballou, Daniel McCaffrey
and Jeffery Zabel for their helpful comments. The authors are solely responsible for the content of
this paper. The views expressed herein are those of the authors and do not necessarily reflect the views
of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2012 by Donald Boyd, Hamilton Lankford, Susanna Loeb, and James Wyckoff. All rights reserved.
Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided
that full credit, including © notice, is given to the source.
Measuring Test Measurement Error: A General Approach
Donald Boyd, Hamilton Lankford, Susanna Loeb, and James Wyckoff
NBER Working Paper No. 18010
April 2012
JEL No. I21

                                               ABSTRACT

Test-based accountability including value-added assessments and experimental and quasi-experimental
research in education rely on achievement tests to measure student skills and knowledge. Yet we know
little regarding important properties of these tests, an important example being the extent of test measurement
error and its implications for educational policy and practice. While test vendors provide estimates
of split-test reliability, these measures do not account for potentially important day-to-day differences
in student performance.

We show there is a credible, low-cost approach for estimating the total test measurement error that
can be applied when one or more cohorts of students take three or more tests in the subject of interest
(e.g., state assessments in three consecutive grades). Our method generalizes the test-retest framework
allowing for either growth or decay in knowledge and skills between tests as well as variation in the
degree of measurement error across tests. The approach maintains relatively unrestrictive, testable
assumptions regarding the structure of student achievement growth. Estimation only requires descriptive
statistics (e.g., correlations) for the tests. When student-level test-score data are available, the extent
and pattern of measurement error heteroskedasticity also can be estimated. Utilizing math and ELA
test data from New York City, we estimate the overall extent of test measurement error is more than
twice as large as that reported by the test vendor and demonstrate how using estimates of the total
measurement error and the degree of heteroskedasticity along with observed scores can yield meaningful
improvements in the precision of student achievement and achievement-gain estimates.


Donald Boyd                                            Susanna Loeb
The Center for Policy Research                         524 CERAS, 520 Galvez Mall
University of Albany                                   Stanford University
135 Western Ave.                                       Stanford, CA 94305
Albany, NY 12222                                       and NBER
donboyd5@gmail.com                                     sloeb@stanford.edu

Hamilton Lankford                                      James Wyckoff
School of Education, ED 317                            Curry School of Education
University at Albany                                   University of Virginia
State University of New York                           P.O. Box 400277
Albany, NY 12222                                       Charlottesville, VA 22904-4277
hamp@albany.edu                                        wyckoff@virginia.edu
       Recent educational policies such as test-based accountability, teacher evaluation and

experimental and quasi-experimental research in education rely on achievement tests as an

important metric to assess student skills and knowledge. Yet we know little regarding the

properties of these tests that bear directly on their use and interpretation. For example, evidence

is often scarce regarding the extent to which standardized tests are aligned with educational

standards or the outcomes of interest to policymakers or analysts. Similarly, we know little about

the extent of test measurement error and the implications of such error for educational policy and

practice. While test vendors provide estimates of reliability, these estimates capture only one of a

number of different sources of error.

       This paper focuses on test measurement error and demonstrates a credible approach for

estimating the overall extent of error. For the tests we analyze, the measurement error is at least

twice as large as that indicated in the technical reports provided by test vendors. Such error in

measuring student performance results in measurement error in the estimation of teacher

effectiveness, school effectiveness and other measures based on student test scores. The

relevance of test measurement error in assessing the usefulness of measures such as teacher

value-added or schools’ adequate yearly progress often is noted but not addressed, due to the

lack of easily implemented methods for quantifying the overall extent of measurement error.

This paper demonstrates a technique for estimating the total measurement error and provides

evidence of the importance of doing so

       Thorndike (1951) articulates a variety of factors which can result in a test score being a

noisy measure of student achievement. Technical reports produced by test vendors provide

information regarding test measurement error as defined in classical test theory and the IRT

framework. For both, the focus is on the measurement error associated with the test instrument




                                                 1
(e.g., randomness in the selection of test items and the raw-score to scale-score conversion). This

information is useful, but provides no information regarding the measurement error from other

sources (e.g., students having particularly good or bad days).

           Reliability coefficients based on the test-retest approach using parallel test forms is

recognized in the psychometric literature as the gold standard for quantifying measurement error

from all sources. Students take alternative, but parallel (i.e., interchangeable), tests on two or

more occurrences sufficiently separated in time so as to allow for the “random variation within

each individual in health, motivation, mental efficiency, concentration, forgetfulness,

carelessness, subjectivity or impulsiveness in response and luck in random guessing”1 but

sufficiently close in time that the knowledge, skills and abilities of individuals taking the tests are

unchanged. However, there are relatively few examples of this approach to measurement error

estimation in practice, especially in the analysis of student achievement tests used in high-stakes

settings.

           Rather than analyzing the consistency of student test scores over occurrences, the

standard approach used by test vendors is to divide the test taken at a single point in time into

what is hoped to be parallel parts. Reliability measured with respect to the consistency (i.e.,

correlation) of students’ scores across these parts only accounts for the measurement error

resulting from the random selection of a set of test items from the relevant population of items.

As Feldt and Brennan (1989) note, this approach “frequently present[s] a biased picture” in that

“reported reliability coefficients tend to overstate the trustworthiness of educational

measurement, and standard errors underestimate within-person variability.” The problem is that

measures based on a single test occurrence ignore potentially important day-to-day differences in

student performance.
1
    Feldt and Brennan (1989).


                                                     2
         In this paper we show that there is a credible approach for measuring the overall extent of

test measurement error that can be applied in a wide variety of settings. Estimation is

straightforward and only requires estimates of the correlation or covariance of test scores in the

subject of interest at several points in time (e.g., the correlations between third-, fourth- and fifth-

grade math scores for one cohort of students).2 Note that student-level test-score data is not

needed, provided that estimates of test-score correlations or covariances are available. Our

approach generalizes the test-retest framework to allow for either growth or decay in the

knowledge, skills and abilities of students between the test administrations as well as variation

across tests in the extent of measurement error. Utilizing the estimated test-score covariance or

correlation matrix and a few assumptions regarding the structure of student achievement growth,

it is possible to estimate the overall extent of test measurement error and decompose the variance

of test scores into the part attributable to real differences in academic achievement and the part

attributable to measurement error.

         In the following section we briefly introduce generalizability theory, a framework for

characterizing multiple sources of test measurement error, and show how the total measurement

error is reflected in the covariance structure of observed test scores. This is followed by an

explanation of our statistical approach. In turn, we report estimates of the overall extent of

measurement error associated with New York State assessments in math and English language

arts (ELA) and how the extent of test measurement error varies across ability levels. We

conclude with a summary and a brief discussion of ways in which information regarding the




2
  As discussed below, it is necessary that the underlying knowledge one is attempting to measure is measurable
using a vertical scale. However, each test instrument employed need only be measured on an interval scale. The
interval scales can differ as long as they are linear transformations of the underlying vertical scale (even if this linear
transformation is unknown).


                                                            3
extent of test measurement error can be informative in analyses related to educational practice

and policy.

                                 1.0 Defining Test Measurement Error

        From the perspective of classical test theory, an individual’s observed test score is the

sum of two components: the true score representing the expected value of test scores over some

set of test replications, and the residual difference, or random error, associated with test

measurement error.3 Generalizability theory, which we draw upon here, extends test theory to

explicitly account for multiple sources of measurement error.4

        Consider the case where a student takes a test consisting of a set of tasks (e.g., questions)

administered at a particular point in time. Each task, t, is assumed to be drawn from some

universe of similar conditions of measurement with the student doing that task at some point in

time. The universe of possible occurrences is such that the student’s knowledge/skills/ability is

the same for all feasible times. Here students are the object of measurement and are assumed to

be drawn from some population. As is typical, we assume the numbers of students, tasks and

occurrences that could be observed are infinite. The case where each pupil, i, might be asked to

complete each task at each of the possible occurrences is represented by i X t X o where the

symbol “ X ” is read “crossed with.”

        Let Sito represent the ith student’s score on task t carried out at occurrence o, which can

be decomposed using the random-effects specification in Equation 1.

                                    Sito  i t o it io to   ito (1)




3
 Classical test theory is the focus of many books and articles. For example, see Haertel (2006).
4
 See Brennan (2001) for a detailed development of Generalizability Theory. The basic structure of the framework is
outlined in Conbach, Linn, Brennan and Haertel (1997) as well as Feldt and Brennan (1988).


                                                        4
The universe score of a student,  i    i , equals the expected value of Sito over the universe of

generalization, here the universes of possible tasks and occurrences. The universe score is

comparable to the true score as defined in classical test theory. In our case,  i measures the

student’s underlying academic achievement, e.g., ability, knowledge and skills. The  ’s

represent a set of uncorrelated random effects which, along with  ito and the student’s universe

score, sum to Sito . Here t and  o , respectively, reflect the random effect, common to all test-

takers, associated with scores for a particular task and a particular occurrence differing from the

population mean,  . it reflects the fact that a student might do especially well or poorly on a

particular task.  io is the measurement error associated with a student’s performance not being

temporally stable even when his or her underlying ability is unchanged (e.g., a student having a

particularly good or bad day, possibly due to illness or fatigue).  to reflects the possibility that

the performance of all students on a particular task might vary across occurrences.  ito reflects

the three-way interaction and other random effects. Even though there are other potential sources

of measurement error, we limit the number here to simplify the exposition.5

        The observed score for a particular individual completing a task will differ from the

individual’s universe score because of the components of measurement error shown in Equation

2. In turn, the measurement error variance decomposition for a particular student and a single

task is shown in Equation 3.

                              ito   Sito  i   t  o  it   po to   ito        (2)

                  2 ito    2  t    2  o    2  it    2 io    2 to    2  ito    (3)



5
 As noted above, Thorndike (1951, p. 568) provides a taxonomy characterizing different sources of measurement
error. The above framework also can be generalized to reflect students being grouped within schools and classrooms
and there being common random components of measurement error at those levels.


                                                               5
Now consider a test defined in terms of its timing (occurrence) and the NT tasks making up the

examination. The student’s actual score, SiT , will equal  i iT as shown in Equation 4, where

iT is a composite measure reflecting the errors in test measurement from all sources.6

                SiT   t Sit NT    i  o  io   t t  it  to   ito  NT   i  iT (4)

The variance of iT for student i equals

2   2  o    2  io    2  t    2  it    2  to    2  ito  / NT .
     iT




                                        2.0 Test-Score Covariance Structure

           We generalize the notation in Equation 4 to allow for multiple tests, for exposition here

assumed to be in multiple grades. In Equation 5 Sij is the ith student’s score on a test for a

                                                      Sij   ij  ij     (5)

particular subject taken in the jth tested grade.7  ij is the ith student’s true academic achievement

in that subject and grade. We drop subscript “T’ to simplify notation, but maintain that a

different test in a single occurrence is given in each grade and period. ij is the corresponding

test measurement error from all sources, where Eij  0 . Allowing for the possibility of


heteroskedasticity across grades and students, Eij2  2ij . Let  2 j equal 2ij for all pupils in


the homoskedastic case or, more generally, the mean value of 2ij for the universe of students in




6
    Here we represent the score as the mean over the set of test items. An alternative would be to employ SiT   t Sit ,
e.g., the number of correct items.
7
  In general, time intervals between tests need not be annual nor constant. For example, from a randomized control
trial one might know test-score correlations for tests administered at the start and end of the experiment as well as a
test given at some point during the experiment.


                                                                 6
grade j. The  in Equation 1 being uncorrelated implies that Eijik  0,  j  k and

Eij ik  0, j, k .

         Using vector notation, Si   i i where Si   Si1 Si 2                    SiJ  ,  i   i1  i 2     iJ  , and

i  i1 i 2     iJ  for the first (j=1) through the Jth tested grades8. Equation 6 defines  (i ) to

be the auto-covariance matrix for the ith student’s observed test scores.  is the auto-covariance

matrix for the universe scores in the population of students. i is the diagonal matrix with the

measurement-error variances across grades for the ith student (e.g.,  2ij ) on the diagonal.


(i )  E  Si  ESi  Si  ESi    E  i  E i  i  E ii        E (ii' )
                                                                   

        i11 i12              i1J      11  12              1J      2i ,1        0               0 
                                                                                                                 
               i 22            i 2 J       22              2 J    0            2               0 
        i 21                           21                                              i ,2
                                                                                                                        i
                                                                                                        0 
                                                                       
        iJ 1 iJ 2            iJJ     J 1  J 2              JJ     0
                                                                                           0       0      2i ,J 


(6) For the population of all students, 2 j  E2ij and   E(i)     where  is the

diagonal matrix with 21 , 22 ,..., 2 J on the diagonal. Note that  (i ) differs from (i ') only

because of possible heteroskedastic measurement error across test-takers.

         For a variety of reasons, researchers and policymakers are interested in the

decomposition of the overall variance of observed scores for students in a particular grade,  jj ,

into the variance in universe scores across the student population,  jj , and the measurement-error

variance;  jj   jj   2 j . The corresponding generalizability coefficient, G j   jj  jj , measures

the portion of the total variation in observed scores that is explained by the variance of universe
8
 For example, the third grade might be the first tested grade. To simplify exposition, we often will not distinguish
between the ith grade and the ith tested grade, even though we will mean the latter. Again, the assessments need not
be annual; the situation might be one in which several tests are given during a particular year.


                                                             7
scores. The reliability coefficient is the comparable measure in classical test theory. This

measure implies the characterization of  shown in Equation 7.

                         11 12 13                 11 G1     12             13        
                             22 23                         22 G2             23        
                                                                                           (7)
                                 33                                          33 G3       
                                                                                           
                                                                                           

 can be estimated using its empirical counterpart    i Si Si' N S where N S is the number

of students for whom test scores are observed.9

         Let  jk represent the correlation between the universe scores in grades j and k;

 jk   jk      jj  kk . This notation along with Equation 7 yields the test-score correlation matrix

 shown in Equation 8. Note that the presence of test measurement error (e.g., G j  1 ) implies


                                             1      G1G2 12      G1G3 13       G1G4 14        
                    1 r12        r13                                                           
                                                     1          G2G3  23      G2G4  24       
                        1         r23                                                           (8)
                                                                   1           G3G4 34
                                 1                                                             
                                                                                 1             
                                                                                               
                                                                                                

that each correlation of test scores is smaller than the correlation of the corresponding universe

scores (e.g., rjk   jk ). In contrast,  jk   jk , j  k , so that estimates of the off-diagonal

elements of the covariance matrix   (i.e., ˆ ij ) directly imply estimates of the off-diagonal

elements of  in Equation 7, i.e., ˆij . However, we are primarily interested in separate estimates


9
 This corresponds to the case where one or more student cohorts are tracked through all J grades, a key assumption
being that the values of the  jk are constant across the cohorts. A subset of the  jk can be estimated when the
scores for individual students only span a subset of the grades included; a particular  jk can be estimated provided
one has test score data for students in both grades j and k. For example,  j , j 1 , j  1,2,3 can be estimated using
test-score data for first-, second- and third-grade students in year-one and the same students in the next grade a year
later.


                                                            8
of the universe-score and measurement-error variances, both of which enter the diagonal

elements of   . Test-score data can be used to estimate the  jk , but these estimates by

themselves are not sufficient to infer estimates of the  jj and G j .

         Assuming nothing more than one of the structures typically maintained by researchers

estimating models of student achievement growth, the parameters in Equation 7 characterizing

the covariance of universe scores (i.e., the  jk ) can be expressed as functions of a smaller set of

elemental parameters (e.g.,  22 frequently is a function of  11 and other elemental parameters).

Taking advantage of such structure, estimates of the  jk can be used to infer estimates of these

elemental parameters, including  11 and G j . In general, the structure maintained needs to imply

that the values of at least J of the parameters on the right-hand side of Equation 7 are implied by

the values of the remaining parameters.10 In a similar way, the representation of  in Equation 8

can be used to estimate the G j ; the structures of underlying growth models imply restrictions on

the structure of the  jk so that test-score correlations can be used to infer estimates of the

underlying parameters and the G j . The central point of our paper is that these methods allow the

overall extent of test measurement error to be easily estimated.

         Our estimation strategy is closely linked to frameworks laid out by Joreskog (1971, 1978)

and Abowd and Card (1989). Abowd and Card develop a framework for studying the covariance

structure of individual- and household-level earnings, hours worked and other time-series

variables. Their approach falls within the general framework for the analysis of covariance

structures developed by Joreskog (1978). Joreskog (1971) employs the kernel of this approach to

10
  Suppose m parameters on the right-hand side of (7) are known functions of the elemental parameters. If m  J ,
the number of moments, J ( J  1) / 2 , will equal or exceed the number of elemental parameters,  J ( J  3) / 2   m ,
one needs to estimate.


                                                            9
analyze the covariance of congeneric tests. In classical test theory, the set of K tests

Sik   ik  ik , k  1, 2,      , K , is said to be congenetric if the true scores,  ik , are such that there

is a common  i where  ik  0k  1k i , k , i ; here the true scores across tests are perfectly

correlated. We consider the case where the  ik need only be correlated to some degree,

following some systematic pattern. This is a generalization of both the test-retest approach and

the somewhat more general framework of Joreskog (1971) for estimating the extent of test

measurement error and falls within his general approach for the analysis of covariances

(Joreskog, 1978).

                                                  3.0 Estimation Strategy

                                                    3.1 General Approach

           We assume that academic achievement, measured by universe scores, is cumulative:

                                         ij   j 1 i , j 1  ij        (9)

This first-order autoregressive structure models student attainment in grade j as depending upon

the level of knowledge and skills in the prior grade11 possibly subject to decay (if  j 1  1 )

where the rate of decay can differ across grades. A key assumption is that decay is not complete,

as would be the case if  j  0 .  j   for all j is a special case. The further simplification

 j  1 is maintained in many value-added analyses. ij is the gain in student achievement in

grade j, gross of any decay. 12

           For empirical growth models to actually measure growth in the underlying achievement

of students, the test(s) used to measure achievement must reflect a single interval scale, meaning

11
     Todd and Wolpin (2003) discuss the conditions under which this will be the case.
12
     In the special case where  j  1 ,  ij is the student’s gain in achievement while in grade j. However, we will refer
to  ig as the student’s achievement gain even when  j  1 .



                                                                        10
that "equal-sized gains at all points on the scale represent the same increment of learning".13 For

example, the tests used to estimate  i1 ,  i 2 ,                      in Equation 9 must all reflect a common vertical

scale. As discussed by Ballou (2009): (1) the underlying assumptions regarding test items and

test takers needed to assure interval scaling are quite restrictive, (2) those employing test scores

in empirical work typically cannot test those assumptions and (3) descriptive statistics for tests of

venders claiming their tests are vertically scaled often have properties that bring into question

whether this is actually the case. A set of exams not being vertically scaled could be the result of

the knowledge and skills being tested not being measurable on a single interval scale. However,

the lack of vertical scaling instead could be the result problems in test construction.

              The prevalence of questions regarding whether test scales are the same across grades and

years explains why analysts often standardize test scores by grade and year to have zero means

and unit standard deviations. Empirical analysis employing standardized scores can only provide

information regarding the movements of students within the achievement distribution from grade

to grade. Fortunately, our approach need only employ test-score correlations. Thus, the

individual tests each need to reflect an interval scale, but the scales can differ from grade to

grade.14 Whether or not the tests are vertically scaled, the extent of test measurement error for the

individual tests, as measured by the G j , can be inferred. After first considering situations in

which tests are vertically scaled, we discuss the more general and simpler approach that can be

employed even when the tests are not necessarily vertically scaled.

              Equation 9 can be used to infer Equation 10, which shows that each  ij reflects the

      ij  ij   j 1i , j 1   j 1 j 2i , j 2     ( j 1 j 2    j ( s 1)i , j ( s 1) )  ( j 1 j 2    j  s i , j  s ) (10)


13
  Ballou (2009).
14
  One can think of the underlying model corresponding to the case where actually achievement across grades falls
on the same interval scale, but the tests instruments employed need not have that property.


                                                                          11
accumulation of decayed values of prior ij . As is true in other time-series models, one can

assume that the sum in Equation 10 extends back to an infinite past (i.e., s   ). A more

attractive alternative in our application is to assume that the pertinent time-series for each student

begins at a specified point in time (e.g., when she first enters school or the grade in which she is

first tested) and employ initial conditions to measure the knowledge and skills of each student at

that point in time (e.g.,  i , j  s for student i where j  s is the starting point). These initial

conditions together with Equation 10 and the statistical structure of the ij determine the


dynamic pattern of universe scores reflected in the parameterization of   E ( i  i' ) and  .

        Two approaches can be used to characterize the statistical structure of the ij . One

approach is to fully specify the relationship of achievement gains across grades. For example, in

one specification discussed in Appendix A, we assume that ij  i   ij where i is a student-

level random effect and  ij is white noise. An alternative approach is to assume nothing more

than that the joint distribution of i, j 1 and  ij is such that the conditional mean E (i, j 1 |  ij ) is

a linear function of  ij . Because of its simplicity and generality, we focus on the reduced-form

framework. Several structural models are discussed in Appendix A.

                                                3.2 A Reduced-Form Model

        Note that i , j 1  E i , j 1 |  ij   ui , j 1 where ui , j 1  i , j 1  E i , j 1 |  ij  and E ui , j 1 ij  0 .

The assumption that such conditional mean functions are linear in parameters is at the core of

regression analysis. We go a step further and assume that E i , j 1 |  ij  is a linear function of  ij ,

or more generally that such a linear relationship is a reasonably good approximation;




                                                                   12
E i , j 1 |  ij   a j  b j  ij where a j and b j are parameters.15 For example,  ij and i , j 1 having a

bivariate normal distribution is sufficient, but not necessary, to assure linearity in  ij . In

particular, if the random variables  i 0 , i1 , i 2 ,             , ij , i , j 1 ,       are multivariate normal,

 ij , i , j 1 , i , j  2 ,    will also be multivariate normal, since  ij is a linear function of

 i 0 , i1 , i 2 ,         , ij , as shown in Equation 10. For this distribution,


                                                           
E i , j 1 |  ij   Ei , j 1  Cov  ij ,i , j 1   jj  ij  E ij  , which is linear in  ij .

               The assumption of linearity implies that i , j 1  a j  b j  ij  ui , j 1 . This along with

 i , j 1   j ij  i , j 1 implies that  i , j 1  a j  c j ij  ui , j 1 where c j   j  b j ; a student's universe

score in grade j+1 is a linear function of the universe score in the prior grade. This implies that

 j 1, j 1  c 2j  jj   u , as well as that  j , j 1  c j jj ,  j , j  2  c j 1 c j jj and, more generally,
                                   j 1




 j , j  s  c j ( s 1) c j ( s 2)   c j jj . These equations along with Equation 7 imply the moments shown

in Equation 11 where  j 1, j 1  c 2j  jj   u j1 . This structure follows from only assuming that


                                                                                                     
E  i , j 1  ij is a linear function of  ij (e.g.,  i , j 1   j ij  i , j 1 and E i , j 1  ij             is a linear

function of  ij ).

        11 12 13 14                              11 G1         c1 11              c2 c1 11   c3c2 c1 11               
            22 23 24                                            22 G2                c2 22      c3c2 22                 
                                                                                                                              
             33 34                                                                 33 G3       c3 33                       (11)
                                                                                                                              
                    44                                                                               44 G4                  
                                                                                                                           




15
                                                                                                
     This linear specification is a first-order Taylor series approximation of E i , j 1 |  ij .        

                                                                  13
           When test-score data for students span J grades, the parameters of the reduced-form

covariance structure will include the 2 J parameters  11 , c1 , c2 ,          , cJ 1 , G1 , G2 ,     , GJ and either

 u2 ,  u2 , ,  u2 or a smaller number of parameters that imply the values of  u2 , ,  u2 (e.g.,
  2    3         J                                                                               2         J




 u2   u2 , j ). As an example of how such parameters can be estimated, suppose that G j  G
   j




and that test-score data for J=3 grades yields estimates of 11 , 12 , 13 , 22 , 23 , and 33 . The

corresponding moment conditions are shown in Equation 12. Substitution of the ˆ jk for  jk and

manipulation of the six moments yields the estimators for the elemental parameters shown in

(13). As is the case here, a few back-of-the-envelope calculations often can yield estimates of the

overall extent of test measurement error.

               11 12 13   11 G        c1 11                  c2 c1 11            
                              
                    22 23        (c1  11   u ) G
                                        2           2
                                                                c2 (c1  11   u )
                                                                      2         2         
                                                                                          (12)
                      33                          [c22c12 11  (c22  1) u2 ] G 

                          ˆ13          ˆ ˆ
                     cˆ2           Gˆ  12 23                 ˆ11  ˆ11Gˆ
                          ˆ12          ˆ13ˆ 22
                                                                                                (13)
                          ˆ
                     cˆ1  12      ˆ  ˆ 22Gˆ  c ˆ
                                     2              2
                                                    1 11      ˆ  (ˆ 33  c ˆ 22 )Gˆ
                                                                2               2
                                                                                2
                          ˆ11       u1                         u2




           This example illustrates that an estimate of the covariance of observed test scores

together with assumptions regarding the structure of student achievement growth are sufficient to

estimate the variance(s) of test measurement error from all sources, as well as the variances in

universe scores measuring the dispersion in student achievement in each tested grade. In general,

this is possible if student achievement is to some extent cumulative (e.g., 1  0 ) and one has an

estimate of  -- the covariance matrix for a sequence of exams measuring student achievement

over time (e.g., math test scores of students in three consecutive grades). Achievement being

cumulative implies that the universe score variances enter expressions characterizing the off-


                                                         14
diagonal elements of   . For instance,  11 enters the expressions for 12   12 and 13   13

shown in Equation 12. Thus, estimates of the  jk , j  k , can be used to infer estimates of the

universe score variances. In turn, the extent of test measurement error can be inferred utilizing

the diagonal elements of   (e.g., 11   11 G1 ).

              A similar, but simpler, approach can be employed whether or not the tests utilized are

vertically scaled, provided that each is interval scaled. The reduced-form model

 i , j 1  a j  c j ij  ui , j 1 and the formulae in Equation 11 imply the following empirical

relationships:  i*, j 1   j , j 1 ij*  ui*, j 1 where ui*, j 1  ui , j 1    j 1, j 1 , E ij* ui*, j 1  0 and  ij* and  i*, j 1

are standardized universe scores having correlation  j , j 1  c j  jj  j 1, j 1 (e.g.,

12  c1  11 /  22 ). In addition,  j , j  2   j , j 1  j 1, j  2 (e.g.,

13  c2 c1  11 /  33  c1  11 /  22 c2  22 /  33  12 23 ),  j , j 3   j , j 1  j 1, j  2  j  2, j 3 , etc.. This

structure along with Equation 8 implies the moment conditions in Equation 14, where rjk is the


       r12    r13   r14   r15       G1G2 12            G1G3 12  23       G1G4 12  23 34     G1G5 12  23 34  45       
                                                                                                    G2 G5  23 34  45
                                                                                                                                  
              r23   r24   r25                            G2 G3  23          G2 G4  23 34                                    
                    r34   r35                                                 G3G4 34               G3G5 34  45
                                                                                                                                  
                                                                                                                                       (14)
                                                                                                                               
                          r45                                                                           G4 G5  45
                                                                                                                                  
                                                                                                                               
                                                                                                                              


test-score correlation for grades j and k . Because G1 and 12 only appear as a multiplicative

pair, the two parameters cannot be identified separately, but 12*  G1 12 can. The same is true

for  J* 1, J  GJ  J 1, J where J is the last grade for which one has test scores. After substituting

the expressions for 12* and  J* 1, J , the Nm  J  J  1 / 2 moments in Equation 14 are functions

of the N  2J  3 parameters in   G2 G3                             GJ 1 12* 23       J 2, J 1  J* 1, J  , which can be


                                                                         15
identified provided that J  4 . With one or more additional parameter restriction (e.g.,

G1  G2  G3 or 23  34 ), J  3 is sufficient for identification.

                Whether the moment conditions in Equations 11 or 14 are employed in estimation, the

parameters can be estimated using a minimum-distance estimator. For example, suppose the

elements of the column vector r ( ) are the moment conditions on the right-hand-side of

Equation 14, after having substituted the expressions for 12* and  J* 1, J . With r̂ representing the

corresponding vector of N m test-score correlations for a sample of students, the minimum-

distance estimator is argmin [rˆ  r ( )]'  [rˆ  r ( )] where  is any positive semi-definite

matrix.16 We employ the identity matrix so that ˆ MD  argmin [rˆ  r ( )]' [rˆ  r ( )] .17,18 The

estimated generalizability coefficients, in turn, can be used to infer estimates of the pre-

normalized universe-score variance, ˆ jj  Gˆ j ˆ jj , as well as the measurement-error variances

2   jj (1  G j ) G j  (1  G j )  jj and 2*  1  G j .19
   j                                                       j



                                                    3.3 Additional Points

                Before turning to our empirical analysis, consider six important points. First, noted in the

introduction, the test-retest approach is a commonly-discussed, but infrequently-employed,

            P
16
     If   B  B0 and Rank[ B0 r ( )  ]  N ,  is locally identified. In the case of a strict equality, the parameters
are exactly identified with rˆ  r (ˆ ) implicitly defining the estimator, which is the same for all  . See Cameron
and Trivedi (2005).
17
   ˆ MD , the equally-weighted minimum-distant estimator is consistent, but less efficient than the estimator
corresponding to the optimally chosen  . However,             ˆ MD   does not have the finite-sample bias problem that arises
from the inclusion of second moments. See Altonji and Segal (1996).
18
   r̂ having the limit distribution NS  rˆ  r0  d N[0,V (ˆ )] implies that the variance of the minimum-distance
estimator is V ˆ MD   [Q ' Q]1 Q ' V (ˆ ) Q [Q ' Q]1 where Q is the matrix of derivatives     Q  r ( )  .
19
     Sij   ij  ij implies that Sij*   jj  jj  ij*  ij  jj  G j  ij*  ij* where the normalized test- and universe-
scores having unit variances. It follows that 1  G j  2* and, in turn, 2*  1  G j .
                                                                  j                   j




                                                                      16
method for estimating the overall extent of test measurement error. To see that this approach is a

special case of our framework, consider the subset of elements in Equation 14 shown in (15),

initially focusing on the first equation. The test-retest approach requires that (i) the time between

                    r12  G1G2 12      r13  G1G3 12 23        r23  G2G3  23 (15)

the test and retest is sufficiently short that the skills and knowledge of those tested are unchanged

so that 12  1 and (ii) the tests are administered under identical conditions so that the overall

extent of measurement error is the same for the two tests (e.g., G1  G2 ). Under these conditions,

the first equation in (15) reduces to r12  G ; the estimated correlation of scores from the two tests

is an estimate of the generalizability (reliability) coefficient for the tests. Joreskog (1971)

maintains the assumption that the universe scores are perfectly correlated but allows the extent of

measurement error to differ across the tests. (In this case the expressions in (15) imply that

G1  r12 r13 r23 , G2  r12 r23 r13 , and G3  r13 r23 r12 .) Our approach goes meaningfully further in

allowing the universe-score correlations to be less than one and different between test pairs.

       Second, to estimate the overall extent of measurement error for a population of students

one only needs descriptive statistics of scores on each test and test-score correlations, an

attractive feature of our approach. However, additional inferences are possible when student-

level test-score data are available.

       Third, our approach is applicable whether the measurement-error variance is constant

across students in each grade (i.e., 2  2 , i ) or there is heteroskedasticity, where 2 is
                                        ij     j                                                    j



the mean variance for the population of students (i.e., 2  E2 ). In the latter case, it is
                                                             j          ij



possible to explore the extent and pattern of heteroskedasticity, provided one has student-level

test scores. Consider the case where   G2 G3 G4      12*  23 34         has been estimated. The



                                                    17
relationship  i*, j 1   j , j 1 ij*  ui*, j 1 for the standardized universe scores  ij* and  i*, j 1 implies that

 u2  *           1   2j , j 1 .20 Note that Sij*  G j  ij*  ij* and, in turn,  ij*  ( Sij*  ij* )                                                       G j . These
      i , j 1




expressions imply that Si*, j 1   j , j 1 G j 1 G j Sij*  G j 1 ui*, j 1  i*, j 1   j , j 1 G j 1 G j ij* . It

follows that the variances of the expressions before and after the equality are also equal, which

implies that 2*
                             i , j 1
                                                                                                
                                          2j , j 1 G j 1 G j 2*  V Si*, j 1   j , j 1 G j 1 G j Sij*  G j 1 1   2j , j 1 .
                                                                                ij
                                                                                                                                                                                 
                   To provide some needed structure, suppose that  2*   i  2* ; the ratio of a student's
                                                                                                                              ij                   j




measurement-error variance to the population mean variance is constant across grades. If so,

Equation 16 follows, which suggests that  can be estimated for a group of students, C, having

the same (unknown) value C , as shown in Equation 17.21 Rather than grouping students based

upon one or more observed attributes, student-level values of  i can be estimated using a

regression approach described below where we estimate the extent to which  i varies with the

level of student achievement.


                                          i 
                                                                                                                     
                                                   V Si*, j 1   j , j 1 G j 1 G j Sij*  G j 1 1   2j , j 1 
                                                                                                                                                                   (16)
                                                                    2
                                                                         *
                                                                          , j 1
                                                                                             2
                                                                                               j , j 1   G   j 1   G j  2*
                                                                                                                                   j




                                                                                                                           Gˆ
                                                                                                                          2
                                                            Si*, j 1  ˆ j , j 1 Gˆ j 1 Gˆ j Sij*                                  j 1   1  ˆ  2
                                                                                                                                                        j , j 1
                                   ˆC        1
                                                                                                                                                                    (17)
                                              NC
                                                   i C                    ˆ2     *
                                                                                     , j 1
                                                                                                               
                                                                                                ˆ 2j , j 1 Gˆ j 1 Gˆ j ˆ2*             j




                   The reduced-form framework provides a useful tool for estimating the extent of test

measurement error from all sources. Estimation is straightforward and the key assumptions



20
     This follows because E ui , j 1 ij  0 implies that E ui*, j 1 ij*  0 .
21
     The formula in (16) only maintains that  i for each student is constant across grades j and j+1. The formula easily
can be generalized to reflect  i being constant across more than two adjacent grades.


                                                                                                          18
                                                                                                
underlying the empirical model (i.e.,  i , j 1   j ij  i , j 1 with  j  0 and E i , j 1  ij       is a linear

function of  ij ) appear to be quite reasonable. A fourth point is that the assumptions need not be

accepted as an article of faith; together they imply that  i , j 1 is a linear function of  ij (i.e.,

 i , j 1  a j  c j ij  ui , j 1 where E  ij ui , j 1  0 ), which can be tested utilizing test-score data, as

demonstrated below.

         The fifth point is that even though the following empirical analysis utilizes the reduced-

form model, our general approach is not dependent on this particular specification. One can carry

out empirical analyses employing fully-specified statistical structures for the ij . A variety of

specifications can be employed, provided the specifications imply covariance structures where

the number of moment conditions are sufficient to estimate the number of parameters, including

the generalizability coefficients. The estimation strategy for the structural approach is the same

as above, the only difference being that the moment conditions employed will include the full set

of structural parameters, not a subset of the structural parameters and a set of reduced-form

parameters. We discuss the structural approach and alternative model specifications in more

detail in Appendix A.

         Finally, the parameters entering the covariance structure can be estimated without

specifying the distributions of  ij and ij . However, additional inferences are possible when one

assumes particular functional forms and has student-level test scores. When needed, we assume

that  ij and ij are normally distributed. When ij is either homoskedastic or heteroskedastic

with  2ij not varying with the level of ability,  ij and Sij will be bivariate normal, implying that


the conditional distribution of  ij given Sij will be normal with moments E  ij Sij                 

                                                            19
                                            
(1  Gij )  j  Gij Sij and V  ij Sij  (1  Gij ) jj where  j  E ij  ESij and Gij   jj                                       jj    2ij .
                      
Here E  ij Sij is the Bayesian posterior mean of  ij given Sij – the best linear unbiased


                                                                                   
predictor (BLUP) of the student's actual ability. V  ij Sij and easily computed Bayesian

confidence (credible) intervals can be employed to measure the precision of the BLUP estimator

for each student.

          When the extent of test measurement error systematically varies across ability levels (i.e.,

ij   j ( ij ) ) – as is the case in our application – the normal density of ij is g j ij  ij                                        
                      
 ij 2 ( ij )  ( ij ) where  ( ) is the standard-normal density. The joint density of  ij and
              j             j




                                       
ij is h j ij , ij   g j ij  ij f j ( ij ) 
                                                                1
                                                         j ( ij )  jj
                                                                                                     
                                                                           ij  2j ( ij )  ( ij   j )                       
                                                                                                                               jj which is


not bivariate normal, due to ij being a function of  ij . (In this case Sij is a mixture of normal


random variables.) The conditional density of  ij given Sij is h j  Sij   ij , ij  k j  Sij  . Here


                                                                           
k j  Sij    h j  Sij   ij , ij  d ij   g j Sij   ij  ij f j ( ij ) d ij is the density of Sij . Given any
                                                 

                                                



particular function  2ij   2j ( ij ) , this integral can be calculated using Monte Carlo integration


with importance sampling; k j  Sij    m1 g j Sij   mj
                                                        M *
                                                               
                                                              mj
                                                               *
                                                                                           M where  mj
                                                                                                      *
                                                                                                         , m  1, 2,                    , M , is a

sufficiently large set of random draws from the distribution f j ( ij ) . Similarly, the posterior

mean ability level given any particular score is E  ij Sij                       
                   m1  mj* g j  Sij   mj*  mj*  . Also, P  ij  a Sij                                                                 
        1                                                                                            1
                                                                                                                                  *
                                                                                                                       g j Sij   mj   *
                                                                                                                                       mj
                       M
                                                                                                                                           is
k   j
         
        Sij M                                                                                k   j
                                                                                                      
                                                                                                     Sij M     *
                                                                                                              mj a




                                                                   20
the cumulative posterior distribution of  ij which can be used to infer Bayesian confidence

intervals (i.e., credible intervals). For example, the 80 percent credible interval is (L, U) such that

                       
P L   ij  U Sij =0.80. Here we choose the lower- and upper-bounds corresponding to the


                                                               
values of a such that P  ij  a Sij  0.10 and P  ij  a Sij  0.90 .22     
                                              4.0 An Empirical Application

           We estimate the parameters in the reduced-form model employing moments defined in

terms of the correlations of scores on the third- through eighth-grade New York State math and

ELA tests for the cohort of New York City students who were in the third grade in the 2004-

2005 school year. Students making normal grade progression were in the eighth grade in 2009-

2010. The exams, developed by CTB-McGraw Hill, are aligned to the New York State learning

standards and are given to all registered students, with limited accommodations and exclusions.

Table 1 reports descriptive statistics for the cohort of students studied. Correlations for ELA and

Math are shown below the diagonals in Tables 3 and 4.23

                                             4.1 Testing Model Assumptions




22
     A common alternative is to define the credible/confidence interval to be the narrowest interval (L, U) for which
                                                         
P L   ij  U Sij  0.80 . In the computation of P  ij  a Sij         we employ estimates of  , , and the
                                                                                                  j
                                                                                                      2
                                                                                                      j

parameters in the function 2j ( ij   ) , but do not adjust the formula for P   a S  to account for this imprecision.
                                                                                  ij    ij
23
   There are a nontrivial number of missing test scores. For example, consider the percent of students having scores
in the data for a particular grade but missing score for the next grade. The percentage of missing scores in the
following grade averages seven percent across grades in each subject. The extent to which this is a problem depends
upon the reasons for the missing data. There is little problem if scores are missing completely at random. (See Rubin
(1987) and Schafer (1997).) However, this does not appear to be the case for the NY tests. In particular, we find
evidence that students having missing scores typically score relatively low in the grades where scores are present.
The exception is that there are some missing scores for otherwise high-scoring students who skip the next grade. To
avoid statistical problems associated with this systematic pattern of missing scores, we impute values of missing
scores using SAS Proc MI. The Markov Chain Monte Carlo procedure is used to impute missing-score gaps (e.g., a
missing fourth grade score for a student having scores for grades three and five). This yielded an imputed database
with only monotone missing data (e.g., scores included for grades three through five and missing in all grades
thereafter). The monotone missing data were then imputed using the parametric regression method.


                                                               21
           We first explore whether the data is consistent with the assumptions which imply that

E  i , j 1 |  ij  is a linear function of  ij . While the two assumptions are sufficient to assure the

linearity of E  i , j 1 |  ij  , it is this linearity that implies the structure of correlations shown in

(14). It is fortunate that we are able to assess whether E  i , j 1 |  ij  is in fact linear.

           The lines in Figures 1 and 2 are empirical, nonparametric estimates of the function

E  Si , j 1 | Sij  for ELA and math, respectively, showing how the observed scores of students in

the eighth grade are related to scores in the prior grade. The bubbles with white fill show the

actual combinations of observed seventh- and eighth-grade scores; the area of each bubble

reflects the relative number of students with that score combination.

           The dark bubbles toward the bottoms of Figures 1 and 2 show the IRT standard errors of

measurement (SEMs) for the seventh grade tests (in reference to the right vertical axis) reported

in the test technical reports.24 Note that the extent of measurement error associated with the test

instrument is meaningfully larger for both low and high scores, reflecting the nonlinear mapping

between raw and scale scores. Each point of the standard errors of measurement plot corresponds

to a particular scale score as well as a corresponding raw score; movements from one dot to the

next (left to right) reflect a one-point increase in the raw score (e.g., one additional question

being answered correctly), with the scale-score change shown on the horizontal axis. For

example, starting at an ELA scale score of 709, a one point raw-score increase corresponds to a

20 point increase in the scale score to 729. In contrast, starting from a scale score of 641, a one

point increase in the raw score corresponds to a two point increase in the scale score. This

varying coarseness of the raw- to scale-score mappings – reflected in the varying spacing of


24
     CTB/McGraw-Hill (2006, 2007, etc.).


                                                        22
points aligned in rows and columns in the bubble plot – explains why the reported scale-score

standard errors of measurement are substantially higher for both low and high scores. Even if the

variance were constant across the range of raw scores – as assumed in classical test theory used

to produce the reliability coefficient estimates in the technical reports – the same would not be

the case for scale scores.

         The fitted nonparametric curves in Figures 1 and 2, as well as very similar results for

other grades, provide strong evidence that E  Si , j 1 | Sij  is not a linear function of Sij . Even so,

this does not contradict our assumption that E  i , j 1 |  ij  is a linear function of  ij ; test measure

error can explain E  Si , j 1 | Sij  being S-shaped even when E  i , j 1 |  ij  is linear in  ij . It is not

measurement error per se that implies E  Si , j 1 | Sij  will be an S-shaped function of Sij ;

E  Si , j 1 | Sij  will be linear in Sij if the measurement-error variance is constant (i.e.,


2  2 , i ). However, E  Si , j 1 | Sij  will be a S-shaped function of Sij when ij is
   ij    j



heteroskedastic with ij   j ( ij ) having a U-shape (e.g., the SEM patterns shown in Figures

1 and 2). The explanation and an example are included in Appendix B.

         Appendix B also includes a discussion of how information regarding the pattern of test

measurement error can be used to obtain consistent estimates of the parameters in a

corresponding polynomial specification of E  i , j 1 |  ij  . We utilize this approach to eliminate

the inconsistency of the parameter estimates associated with the measurement error reflected in

the SEMs reported in the technical reports. Even though this does not eliminate any




                                                          23
inconsistency of parameter estimates resulting from other sources of measurement error, we are

able to adjust for the meaningful heteroskedasticity reflected in the reported SEMs.25

             Results from using this approach to analyze the NY test data are shown in Figures 3 and

4 for ELA and math, respectively. As an example, consider graph (d) in either figure. The

thicker, S-shaped curve corresponds to the OLS estimation of Si 5 regressed on Si 4 using a cubic

specification. We employ a third-order polynomial because it is the lowest-order specification

that can capture the general features of the nonparametric estimates of E  Si , j 1 | Sij  in Figures 1

and 2. The dashed line is a cubic estimate of E  i , j 1 |  ij  obtained using the approach described

in Appendix B to avoid parameter-estimate inconsistency associated with that part of test

measurement error reflected in the SEMs reported in the technical reports. For comparison, the

straight line is the estimate of E  i , j 1 |  ij  employing this approach and a linear specification.

Across the grade-pair graphs, it is striking how close the consistent cubic estimates of

E  i , j 1 |  ij  are to being linear.26 Overall, the assumption that E  i , j 1 |  ij  is a linear function

of  ij appears to be quite reasonable in our application.

                                                          4.2 Estimated Model

             Parameter estimates for the reduced-form model and their standard errors are reported in


25
  As discussed below, how the reported SEMs vary with the level of ability is quite similar to our estimates of how
the standard deviations of the measurement-error from all sources vary with ability. If true, by accounting for the
heteroskedasticity in the measurement error associated with the test instrument, we are able to roughly account for
                                                                                                                
the effect of heteroskedasticity, increasing our confidence in the estimated curvature of E  i , j 1 |  ij for each grade
and subject. At the same time, not accounting for other sources of measurement error will result in the estimated
                                                              
cubic specification generally being flatter than E  i , j 1 |  ij .  
26
                                     
     The cubic estimates of E  i , j 1 |  ij    in the graphs might be even closer to linear if we had accounted for all
measurement error. This was not done to avoid possible circularity; one could question results where the estimates
of the overall measurement-error variances are predicated maintaining linearity and the estimated variances are then
                                           
used to assess whether E  i , j 1 |  ij is in fact linear.



                                                                      24
Table 2. First consider how well the estimated models fit the observed score correlations. The

empirical correlations for ELA and math, respectively, are shown below the diagonals in Tables

3 and 4. The predicted correlations implied by the estimated models are above the diagonals. To

evaluate goodness of fit, consider the absolute differences between the empirical and predicted

correlations. The average, and average percentage, absolute differences for ELA are 0.001 and

one-fifth of one percent, respectively. For math, the differences are 0.003 and one-half of one

percent. Thus, the estimated reduced-form models fits the New York data quite well.

       Returning to Table 2, the estimated generalizability coefficients for math are

meaningfully larger than those for ELA, and the estimates for ELA are higher in some grades

compared to others. These differences are of sufficient size that one could reasonably question

whether they reflect underlying differences in the extent of test measurement error. Instead the

pattern could reflect estimation error or a fundamental shortcoming of our approach, or both.

Fortunately, we can compare these estimates to the reliability measures reported in the technical

reports for the New York tests, to see whether the reliability coefficients differ in similar ways.

The top two lines in Figure 5 marked with squares show the reported reliability coefficients for

math (solid line) and ELA (dashed line). The lower two lines marked with diamonds show the

generalizability coefficient estimates reported in Table 2. It is not surprising that the estimated

generalizability coefficient are smaller than the corresponding reported reliability coefficients, as

the latter statistics do not account for all sources of measurement error. However, consistencies

in the patterns are striking. The differences between the reliability and generalizability

coefficients vary little across grades and subjects, averaging 0.117. Reflecting this result, the

generalizability coefficient estimates for math are higher than those for ELA, mirroring

corresponding difference between the reliability coefficients reported in the technical reports.




                                                 25
Also, in each subject the variation in the generalizability coefficient estimates across grades

closely mirrors the corresponding across-grade variation in the reported reliability coefficients.

This is especially noteworthy given the marked differences between math and ELA in the

patterns across grades.

        The primary motivation for this paper is the desire to estimate the overall extent of

measurement error motivated by concern that the measurement error in total is much larger than

that reported in test technical reports. The estimates of the overall extent of test measurement

error on the NY math exams, on average, are over twice as large as that indicated by the reported

reliability coefficients. For the NY ELA tests, the estimates of the overall extent of measurement

error average 130 percent higher than that indicated by the reported reliability coefficients. The

extent of measurement error from other sources appears to be at least as large as that associated

with the construction of the test instrument.

        Estimates of the variances in actual student achievement can be obtained employing

estimates of the overall extent of test measurement error together with the test-score variances.

Universe-score variance estimates for our application are reported in column (3) of Table 5. It is

also possible to infer estimates of the variances of universe-score gains shown in column (6).

Because these values are much smaller than the variances of test-score gains, the implied

generalizability coefficient estimates in column (7) are quite small, especially for ELA.

        Estimation of the overall extent of measurement error for a population of students only

requires descriptive statistics of scores for each test and test-score correlations. However,

additional inferences are possible when student-level test-score data are available. In particular,

student-level data and the formula in Equation 16 can be used to estimate  j ( i )  2 ( i ) 2
                                                                                           j            j



characterizing how the variance of measurement error varies with student ability. For example,



                                                   26
for grade pairs 4-5 and 6-7 we compute ˆ i for each student and grade pair using Equation 16.

Assuming that a student's mean (normalized) universe score across the grade pair,  i* , is the

relevant measure of ability in  j ( i ) ,  i* can be estimated using a student's average normalized

test score for the adjacent grades, Si* . Here we estimate  j ( i* ) employing a fourth-order

polynomial. However, regressing ˆ i on Si* would yield inconsistent parameter estimates as a


                                                                                           
result of Si* measuring  i* with error. If ik  E ( i* )k Si* , k  1, 2,3, 4 , were know for each

student, consistent estimates of polynomial parameters could be obtained by regressing ˆ i on

i1 , i 2 , i 3 , and i 4 .27 The problem is that computation of ik requires knowledge of  j ( i* ) –

the function we are trying to estimate.

              This circularity suggests the following iterative solution. (1) Obtain an initial estimate of

the parameters in  j ( i* ) by regressing ˆ i on Si* . (2) Use the estimated function ˆ j ( i* ) to

compute estimates of the ik , i.e., ˆik .28 (3) Regress ˆ i on ˆi1 , ˆi 2 , ˆi 3 , and ˆi 4 to obtain an

updated estimate of ˆ j ( i* ) . Steps two and three can be repeated until estimates of the

polynomial parameters converge (a dozen or so repetitions in our analyses). In this way we

estimate how the variance of measurement error from all sources varies across the range of

universe scores; ˆ2 ( i )  ˆ j ( i ) ˆ2  ˆ j ( i ) (1  Gˆ j ) ˆ jj .
                             j                          j




              The solid lines in Figures 6 and 7 are our estimates of ˆ ( i ) . The dashed lines show the
                                                                                                       j



IRT SEMs reported in the test technical reports for the grade. The shapes of the two curves in

27
     For example, see the discussion of the "structural least squares" polynomial estimator in Kukush et. al (2005) .
28
     Extending the approach for computing E  ij Sij                   discussed above,
                    
ˆik  E  ij  Sij  k j  Sij  M 
                 k
                                     
                                          1
                                                m1   mj* 
                                                  M              k
                                                                              *
                                                                      Sij   mj 2j ( mj
                                                                                          *
                                                                                                      *
                                                                                             )  j ( mj ).



                                                                              27
each graph indicate that our estimates of how the overall measurement-error standard deviations

vary over the range of universe scores is very similar to the patterns reported in the technical

reports. These results together with those shown in Figure 5 are striking. Our estimates of the

overall extent of measurement error, as expected, are systematically higher than those associated

with the test instrument. The estimated standard deviation of the overall measure error for each

test varies over the range of abilities in a way quite similar to the pattern seen for the reported

IRT SEMs. In addition, as shown in Figure 5, the variation in generalizability coefficient

estimates across grades mirror across-grade differences in the reliability coefficients and the

differences between the math and ELA generalizability coefficient estimates mirror the

corresponding differences between the reported math and ELA reliability coefficients. These

similarities do not prove the accuracy of our technique for estimating the overall extent of test

measurement error, but they do greatly increase our confidence that the technique is able to

identify at times subtle differences in the extent of measurement error.

              4.3 Inferences Regarding Universe Scores and Universe Score Gains

       Observed test scores typically are used to directly estimate students' abilities and ability

gains. More precise estimates of universe scores and/or universe-score gains for individual

students can be obtained employing the observed scores along with the parameter estimates in

Table 2 and the estimated measurement-error heteroskedasticity measured by ˆ ( i ) . As an
                                                                                     j




                                                                                
example, the solid S-shaped line in Figure 8(a) shows the values of Eˆ  ij Sij for fifth-grade

ELA. Results for grades five and seven math are shown in Figure 9. Results for both subjects in

other grades are quite similar. Referencing the 45o straight line, the estimated posterior-mean

ability levels for higher-scoring students are substantially below the observed scores while

predicted ability levels for low-scoring students are above the observed scores. This Bayes


                                                  28
"shrinkage" is largest for the highest and lowest scores due to the estimated pattern of

measurement-error heteroskedasticity. The dashed lines show 80-percent Bayesian credible

(confidence) bounds for ability conditional on the observed score. For example, the BLUP of the

universe-score for fifth-grade students scoring 775 in ELA is 731, 44 point below the observed

score. We estimate that 80 percent of students scoring 775 have universe scores in the range 717-

                                       
747; P 717.1 ij  747.2 Sij  775  0.80 . In this case, the observed score is 28 points higher

than the upper bound of the 80-percent credible interval. Midrange scores are somewhat more

informative, reflecting the smaller standard deviation of test measurement error. For an observed

score of 650, the estimated posterior mean and 80 percent Bayesian confidence interval are 652

and (639,665), respectively. The credible bounds for a 775 score is 15 percent larger than that for

a score of 650.

        As Figures 8 and 9 make clear, utilizing test scores to directly estimate students' abilities

is problematic for high- and, to a lesser extent, low-scoring students. To explore further, consider

the root of the expected mean squared errors (RMSE) associated with estimating student ability

using (i) observed scores and (ii) estimated posterior mean abilities conditional on observed

scores.29 In the case of the fifth-grade math exam shown in Figure 9(a), the RMSE associated

                     
with using Eˆ  ij Sij to estimate students' abilities is 15.5 scale-score points. In contrast, the

RMSE associated with using Sij is 18.4, 19 percent larger. The magnitude of this difference is


                                  
meaningful given that Eˆ  ij Sij differs little from Sij over the range of scores for which there

are relatively more students. Over the range of actual abilities between 620 and 710 in Figure



29
  The expected values are computed using Monte Carlo simulation and assuming our parameter estimates are
correct.


                                                     29
                             
9(a), the RMSE for Eˆ  ij Sij and Sij are 15.5 and 15.6, respectively. For ability levels below

620 the RMSEs are 16.8 and 21.8, respectively, the latter being 30 percent larger. For students

                                                                              
whose ability levels are greater than 710, the RMSE of employing Eˆ  ij Sij to estimate  ij is

14.4, smaller than the overall RMSE for this estimator. In contrast, the RMSE associated with

using Sij to estimate  ij is 31.3 for students whose actual abilities are greater than 710 -- over


                                                         
twice as large as the corresponding RMSE for Eˆ  ij Sij . By estimating the overall extent and

pattern of test measurement error from all sources, it is possible to compute estimates of universe

scores that have statistical properties superior to those corresponding to merely using the

observed scores of students as estimates of their ability levels.

       Turning to the measurement of ability gains, the solid S-shaped curve in Figure 10 shows

the posterior-mean universe-score change in math between grades five and six conditional on the

observed score change. Again, the dashed lines show 80-percent credible bounds. For example,

among students observed to have a 40-point score increase between the fifth and sixth grades,

their actual universe score changes are estimated to average 13.5. Eighty-percent of all students

having a 40-point score increase are estimated to have actual universe score changes falling in

the interval -1.1 to 27.4. It is noteworthy that for the full range of score change shown (  50

points), the 80-percent credible bounds include there actually being no change in ability.

       Note that there are many different combinations of scores that yield a given change in

observed scores; a score increase from 590 to 630 implies a 40-point change as does an increase

from 710 to 750. Figure 10 corresponds to the case where one knows the score change but not




                                                  30
the pre- and post-scores.30 However, for a given score change, the mean universe-score change

and credible bounds will vary across known score levels because of the pattern of measurement

error heteroskedasticity. For example, Figure 11 shows the posterior-mean universe score change

and credible bounds conditional on particular combinations of scores that correspond to a 40-

point increase. For example, students scoring 710 on the grade-five exam and 750 on the grade-

six exam are estimated to have a 10.2 point universe-score increase on average, with 80 percent

of such students having actual changes in ability in the interval (-12.4, 31.0). (Note that a 40

point score increase is relatively large in that the standard deviation of the score change between

the fifth- and sixth-grades is 26.0.) For students having a 40-point score increase, there actually

being no change in ability falls outside the credible bounds only when the score in grade five is

approximately between 615 and 658.

               A striking result in Figure 11 is that the posterior mean universe-score change,

Eˆ  6   5 S5 , S6   Eˆ  6 S5 , S6   Eˆ  5 S5 , S6  , is substantially smaller than the corresponding

observed-score change, warranting further explanation. Again consider

Eˆ  6   5 S5  710, S6  750   10.3 . Figure 12 illustrates why this is substantially smaller in



30
                                                                                                                                                                   
     The joint density of  ij , i , j 1 ,ij , and i , j 1 is h j  ij , i , j 1 ,ij ,i , j 1  g j ij  ij g j 1 i , j 1  i , j 1 f ( ij , i , j 1 ) .
With    j 1   j and D  S j 1  S j     j 1   j , the joint density of  ij ,  ,ij , and D is
                                                 
h j  ij , ij   ,ij , D    ij . Integrating over  ij and ij yields the joint density of  and D ;

                                           D                                                    
                          
z  , D                   g   j 1
                                                      ij    i , j 1 f 2 ( ij    ij ) g j ij  ij f 1 ( ij ) dij d ij where f 1 ( ij ) is the marginal
                    

density of  ij and f ( i , j 1  ij ) is the conditional density of  i , j 1 given  ij . This integral can be computed using
                                          2



                                                                        
z  , D   1 J   j 1 g j 1 D    ij*  ij*   f 2 ( ij*    ij* ) where ( ij* ,ij* ), j  1, 2,
                                   J
                                                                                                                                                       , J , is a sufficiently large
number of draws from the joint distribution of ( ij ,ij ) . In turn, the density of the posterior distribution of  given

                                                                                                   
D is z  D   z  , D  / l  D  where l  D   1 J   j 1 g j 1 D   i*, j 1   ij*  ij*  i*, j 1 is the density of D . The
                                                                                       J
                                                                                                                                                        
cumulative posterior distribution is P   a S   1 J l ( D)   *                                                 *
                                                                                                           i , j 1  ij  a
                                                                                                                                                                           
                                                                                                                                g j 1 D   i*, j 1   ij*  ij*  i*, j 1 . Finally, the

posterior mean ability given D is E  D   1 J l ( D)   j 1 
                                                                                               J
                                                                                                      *
                                                                                                       i , j 1           *
                                                                                                                            ij    g  D 
                                                                                                                                     j 1         *
                                                                                                                                                  i , j 1     
                                                                                                                                                              *
                                                                                                                                                              ij
                                                                                                                                                                   *
                                                                                                                                                                   ij
                                                                                                                                                                        *
                                                                                                                                                                        i , j 1   .

                                                                                           31
magnitude compared to the 40-point increase in score. First, Eˆ ( 6 S6  750)  733.0 is 17 points

below the observed score due to the Bayes shrinkage toward the mean 6  667.8 .

Eˆ  6 S5  710, S6  750   729.9 is even smaller; because S6 is a noisy estimate of  6 and  5 is

correlated with  6 , the value of S5 provides information regarding the distribution of  6 that

goes beyond the information gained by observing S6 . Note that E  6 S5 , S6  would equal


E ( 6 S6 ) if either 2 6  0 or 56  0 . Eˆ  6 S5 , S6  is less than Eˆ ( 6 S6 ) because S5 is

substantially below S6 . Similar logic holds for the fifth grade. Eˆ ( 5 S5  710)  707.5 is less than

710 because the latter is substantially above 5 . However, Eˆ ( 5 S5 , S6 )  719.6 is meaningfully

larger than Eˆ ( 5 S5 )  707.5 and larger than S5  710 , reflecting that S6  750 is substantially

larger than S5 . In summary, among New York City students scoring 710 on the fifth-grade math

exam and 40 points higher on the sixth grade exam, we estimate the mean gain in ability is little

more than one-forth as large as the actual score change; Eˆ  6 S5 , S6   Eˆ  5 S5 , S6  

729.9  719.6  10.3 . The importance of accounting for the estimated correlation between ability

levels in grades five and six is reflected in the fact that the mean ability increase would be two

and one-half times large were the ability levels uncorrelated,

Eˆ  6 S6   Eˆ  5 S5   733.0  707.5  25.5 .

                                               5.0 Conclusion

        In this paper we show that there is a credible and feasible approach for estimating the

total extent of test measurement error utilizing estimates of the empirical correlation or

covariance matrix for three or more interval-scaled tests. The scales can differ across the tests




                                                       32
provided that they are linear transformations of an underlying common vertical scale that need

not be known. Our approach maintains relatively unrestrictive assumptions regarding the

structure of student achievement growth. We assume that academic achievement is cumulative

following a first-order autoregressive process;  ij   j 1 i , j 1  ij where there is at least some

persistence (i.e.,  j 1  0 ) and the possibility of decay (  j 1  1 ), which can differ across grades.

Even though derivations would be more complicated, one could employ some other structure

(e.g., a second-order autoregressive process). With  ij   j 1 i , j 1  ij , an additional assumption

is needed regarding the stochastic properties of ij . A reduced-form specification is employed in

the paper and, to illustrate the generality of the approach, three examples of fully specified

structural models are outlined in Appendix A,

          Our approach is a meaningful generalization of the test-retest method, providing a useful,

more generally applicable tool for estimating the extent of test measurement error from all

sources. Estimation is straightforward and the key assumptions underlying the empirical model

                                                             
(i.e.,  i , j 1   j ij  i , j 1 with  j  0 and E i , j 1  ij      is a linear function of  ij ) appear to be

quite reasonable. Furthermore, these assumptions imply that  i , j 1 is a linear function of  ij

which can be tested.

          Estimation of the overall extent of measurement error for a population of students only

requires computed test-score descriptive statistics and correlations. However, when student-level

test-score data are available, one can explore the extent and pattern of measurement error

heteroskedasticity. Results for New York make clear that heteroskedasticity can be important in

that variation in the extent of test measurement error across ability levels is quite large.




                                                                  33
       The overall extent of test measurement error can be estimated without specifying

particular functional forms for the distribution of either abilities or test measurement error.

However, by maintaining standard assumptions (e.g., normality), one can make inferences

regarding universe scores and universe score gains. In particular, for a student with a given score,

                                                                                      
the Bayesian posterior mean and variance of  ij given Sij , E  ij Sij and V  ij Sij are easily

computed where the former is the best linear unbiased predictor (BLUP) of the student's actual

ability. Similar statistics for test score gains can also be computed. We show that using the

observed score as an estimate of a student's underlying ability can be quite misleading for

relatively low- or high-ability students. However, this is not the case when the posterior mean is

employed.

       Estimates of the overall extent of test measurement error have a variety of uses that go

                                                                                     
beyond merely assessing the reliability of various assessments. Employing E  ij Sij , rather
than Sij , to estimate  ij is one example. Another is the computation of effect sizes where the

magnitudes of the effects of different causal factors can be judged relative to either the standard

deviation of ability or the standard deviation of ability gains. Bloom et al. (2008) discuss the

desirability of taking into account the dispersion of ability or ability gains rather than test scores

or test-score gains but note that analysts often have little if any information regarding the extent

of test measurement error.

       As demonstrated above, the same types of data researchers often employ to estimate how

various factors affect educational outcomes can be used to estimate the overall extent of test

measurement error. Based on the variance estimates shown in columns (1) and (3) of Table 5, for

the tests we analyze effect sizes measures relative to the standard deviation of ability will be ten

to 18 percent larger than effect sizes measured relative to the standard deviation of test scores. In


                                                  34
cases where it is pertinent to judge the magnitudes of effects in terms of achievement gains,

effect sizes measured relative to the standard deviation of ability gains will be two to over three

times larger compared to those measured relative to the standard deviation of test-score gains.

           Another use of the estimated extent of test measurement error pertains to the common

practice of entering student test scores as right-hand-side variables in regression equations, as is

often done in value-added modeling. A concern is that the measurement error associated with the

prior tests can bias other coefficient estimates. However, any such problem can be avoided by

employing E  ij | Sij  rather than S ij as a proxy for ability in the regression.31 Doing so has a

second benefit. Even if the dependent variable in such a regression is a linear function of ability,

a problem of nonlinearity is introduced when S ij is used to proxy ability. This problem arises

when E  ij | Sij  is a nonlinear function of S ij , as we demonstrate in our application. In an effort

to deal with this issue, one could include the square and cube of S ij in the regression. However,

the problem can be avoided by employing Eˆ  ij | Sij  rather than S ij in the regression.

           Finally, by estimating the extent and pattern of test measurement error one can assess the

precision of a variety of measures that are computed based upon test scores. These include

indicators of student proficiency (e.g., AYP), teacher- and school-effect estimates and

accountability measures more generally. As we have shown, it is possible to measure the

reliability of such measures as well as employ the estimated extent of test measurement error to

calculate more accurate measures, information which should be employed in policy applications

based on student achievement tests.

           Overall, this paper has both methodological and substantive implications.

Methodologically it shows that the full extent of test measurement error can be estimated without

31
     See Sullivan (2001).


                                                    35
employing the costly test-retest strategy. Substantively, it shows that the overall measurement

error is substantially greater than reported split-test measurement error and this difference

suggests that much empirical work has been underestimating the effect sizes of interventions

(e.g., programs or teachers) that affect student learning.




                                                 36
                                          References

Aaronson, Daniel, Lisa Barrow, and William Sander. 2007. “Teachers and Student Achievement
  in the Chicago Public High Schools.” Journal of Labor Economics 25(1): 95–135.
Abowd, J.M. and D. Card (1989) “On the Covariance Structure of Earnings and Hours
  Changes,” Econometrica 57(2), 411-445.
Altonji, J.G. and L.M. Segal (1996) "Small Sample Bias in GMM Estimation of Covariance
   Structures," Journal of Business and Economic Statistics 14, 353-366.
Ballou, D. (2002) “Sizing Up Test Scores,” Education Next 2(2), 10-15.
Baltagi, B. H. (2005) Econometric Analysis of Panel Data, West Sussex, England: John Wiley &
  Sons, Ltd.
Bloom, H.S., C.J. Hill, A.R. Black and M.W. Lipsey (2008) "Performance Trajectories and
   Performance Gaps as Achievement Effect-Size Benchmarks for Educational Interventions,"
   Journal of Research on Educational Effectiveness (1) 289-328.
Brennan, R. L. (2001) Generalizability Theory, New York: Sprnger-Verlag.
Cameron, A.C. and P.K. Trivedi (2005) Microeconometrics: Methods and Applications, New
  York: Cambridge University Press.
Carlin, B. P. and T. A. Louis (1996) Bayes and Empirical Bayes Methods for Data Analysis,
  Boca Raton: Chapman & Hall/CRC.
Conbach, L.J., R.L. Linn, R.L. Brennan and E.H. Haertel (1997) "Generalizability Analysis for
  Performance Assessments of Student Achievement or School Effectiveness," Educational and
  Psychological Measurement, 57(3), 373-399.
CTB/McGraw-Hill (2006) “New York State Testing Program 2006: Mathematics, Grades 3-8:
  Technical Report”, Monterey, CA.
CTB/McGraw-Hill (2007) “New York State Testing Program 2007: Mathematics, Grades 3-8:
  Technical Report”, Monterey, CA.
Feldt, L. S. and R. L. Brennan (1989) “Reliability,” in Educational Measurement 3rd ed., New
   York: American Council on Education.
Goldhaber, D. and E. Anthony (2007) “Can Teacher Quality Be Effectively Assessed? National
  Board Certification as Signal of Effective Teaching,” The Review of Economics and Statistics
  89(1), 134-150.
Goldhaber, D., and M. Hansen. 2010 “Assessing the Potential of Using Value-Added Estimates
  of Teacher Job Performance for Making Tenure Decisions.” CALDER working paper.
Haertel, E. H. (2006) “Reliability,” in Educational Measurement, fourth edition, R. L. Brennan,
  ed., Praeger.
Hill, C., H. Bloom, A. Black, M. Lipsey, “Empirical Benchmarks for Interpreting Effect Sizes in
   Research” MDRC Working Paper, July 2007.




                                               37
Koedel, Cory, and Julian R. Betts. 2007. “Re-Examining the Role of Teacher Quality in the
  Educational Production Function.” Working Paper 0708. University of Missouri, Department
  of Economics.
Kukush, A., H. Schneesweiss and R. Wolf (2005) "Relative Efficiency of Three Estimators in a
  Polynomial Regression with Measurement Errors," Journal of Statistical Planning and
  Inference 127, 179-203.
Lee, W. C., R. L. Brennan and M. J. Kolen (2000) “Estimators of Conditional Scale-Score
  Standard Errors of Measurement: A Simulation Study,” Journal of Educational Measurement
  37(1), 1-20.
McCaffrey, D. F., J. R. Lockwood, D. Koretz, T. A. Louis and L Hamilton (2004) “Models for
  Value-Added Modeling of Teacher Effects,” Journal of Educational and Behavioral Statistics
  29(1), 67-101.
McCaffrey, Daniel F., Tim R. Sass, J. R. Lockwood, and Kata Mihaly. 2009. “The Intertemporal
  Variability of Teacher Effect Estimates.” Education Finance and Policy 4(4):572–606.
Rogosa, D.R. and J. B. Willett (1983) “Demonstrating the Reliability of Difference Scores in the
  Measurement of Change,” Journal of Educational Measurement 20(4) 335-343.
Rubin, D. B. (1987) Multiple Imputation for Nonresponse in Surveys, New York: J. Wiley &
  Sons.
Sanders, W. and J. Rivers (1996) “Cumulative and Residual Effects of Teachers on Future
  Student Academic Achievement,” working paper, University of Tennessee Value-Added
  Research and Assessment Center.
Sanford, E. E. (1996) “North Carolina End-of-Grade Tests: Reading Comprehension,
  Mathematics,” Technical Report #1. Division of Accountability/Testing, Office of Instruction
  and Accountability Services, North Carolina Department of Public Instruction.
Schafer, J. L. (1997) Analysis of Incomplete Multivariate Data, London: Chapman & Hall.
Shen, W. and T. A. Louis (1998) “Triple-goal Estimates in Two-Stage Hierarchical Models,”
  Journal of the Royal Statistical Society 60(2), 455-471.
Sullivan, D. G. (2001) “A Note on the Estimation of Linear Regression Models with
   Heteroskedastic Measurement Errors,” Federal Reserve Bank of Chicago working paper WP
   2001-23.
Thorndike, R. L. (1951) “Reliability,” in Educational Measurement, E.F. Lindquist, ed.,
  Washington, D.C.: American Council on Education.
Todd, P.E. and K.I. Wolpin (2003) "On the Specification and Estimation of the Production
  Function for Cognitive Achievement," The Economic Journal 113, F3-F33.
Wright, S. P. and W. L. Sanders ( ) “Decomposition of Estimates in a Layered Value-Added
  Assessment Model,” Value-Added Assessment




                                               38
                      Table 1
          Descriptive Statistics for Cohort
                 ELA                       Math
                   standard                  standard
           mean deviation            mean deviation
Grade 3   626.8      37.3            616.5     42.3
Grade 4   657.9      39.0            665.8     36.0
Grade 5   659.3      36.1            665.7     37.5
Grade 6   658.0      28.8            667.8     37.5
Grade 7   661.7      24.4            671.0     32.5
Grade 8   660.5      26.0            672.2     31.9
             N = 67,528                N = 74,700



     Table 2 Correlation and Generalizability
      Coefficient Estimates, New York City
     Parameters+          Math             ELA
          34*           0.8144           0.8369
                        (0.0016)         (0.0016)
           45           0.9581           0.9785
                        (0.0012)         (0.0013)
          56            0.9331           0.9644
                        (0.0011)         (0.0012)
          67            0.9647           0.9817
                        (0.0011)         (0.0012)
          78
           *
                         0.8711           0.8168
                        (0.0013)         (0.0013)

          G4             0.8005           0.7853
                        (0.0024)         (0.0025)
          G5             0.8057           0.7169
                        (0.0020)         (0.0018)
          G6             0.8227           0.7716
                        (0.0019)         (0.0019)
          G7             0.8284           0.7184
                        (0.0020)         (0.0019)
     + The parameter subscripts here correspond to the
     grade tested. For example, 34
                                  *
                                     is the correlation of
     universe scores of students in grades three and four




                           39
                        Table 3 Correlations of Scores on the NYS ELA Examinations
                           in Grades Three Through Eight (Computed values below
                                    the diagonal and fitted-values above)

                             Grade 3         Grade 4        Grade 5          Grade 6              Grade 7            Grade 8
              Grade 3                        0.7416         0.6934           0.6937               0.6571             0.6332
              Grade 4        0.7416                         0.7342           0.7346               0.6958             0.6705
              Grade 5        0.6949           0.7328                         0.7173               0.6794             0.6548
              Grade 6        0.6899           0.7357         0.7198                               0.7309             0.7044
              Grade 7        0.6573           0.6958         0.6800           0.7303                                 0.6923
              Grade 8        0.6356           0.6709         0.6514           0.7050                  0.6923


                        Table 4 Correlations of Scores on the NYS Math Examinations
                           in Grades Three Through Eight (Computed values below
                                     the diagonal and fitted-values above)

                             Grade 3         Grade 4        Grade 5         Grade 6              Grade 7            Grade 8
              Grade 3                        0.7286         0.7003          0.6603               0.6393             0.6119
              Grade 4        0.7286                         0.7694          0.7254               0.7023             0.6722
              Grade 5        0.6936          0.7755                         0.7597               0.7355             0.7039
              Grade 6        0.6616          0.7248         0.7592                               0.7964             0.7623
              Grade 7        0.6480          0.6998         0.7323           0.7944                                 0.7929
              Grade 8        0.6091          0.6685         0.7077           0.7643               0.7929



Table 5: Variances of Test Scores, Test Measurement Error, Universe Scores, Test-Score Gains,
 Measurement Error for Gains, and Universe Score Gains and Generalizabiltity Coefficient for
                               Test-Score Gain, ELA and Math
           (1)       (2)         (3)              (4)       (5)      (6)           (7)

 ELA        S2
              j
                    ˆ2
                        j
                                 ˆ jj  Gˆ j  S2          ˆ 2S
                                                                     j
                                                                          ˆ 2
                                                                                   j
                                                                                        ˆ 2
                                                                                                 j
                                                                                                         Gˆ j  ˆ 2        ˆ 2S
                                                 j                                                                       j        j

grade 7   1520.8   326.5            1194.3                  763.8         695.3         68.4                      0.090
grade 6   1303.0   368.8             934.2                  646.2         558.9         87.3                      0.135
grade 5   832.1    190.0             642.1                  407.4         357.6         49.8                      0.122
grade 4   595.1    167.6             427.5
 Math
grade 7   1297.6   259.0            1038.6                  661.9         532.8         129.1                     0.195
grade 6   1409.5   273.8            1135.7                  677.9         523.8         154.1                     0.227
grade 5   1409.5   250.0            1159.5                  527.8         431.0          96.8                     0.183
grade 4   1054.9   181.0             873.9



                                                       40
Figure 1: Nonparametric Regression of Grade 8 ELA Scores on Scores in Grade 7,
           Bubble Graph Showing the Joint Distribution of Scores and
              Standard-Error of Measurement for 7th Grade Scores

                              800                                                         200

                              775                                                         180
                                                                                          160
                              750




                                                                                                    reported SEM for grade 7
                                                                                          140
                              725
           grade 8 score




                                                                                          120
                              700                                                         100

                              675                                                         80
                                                                                          60
                              650
                                                                                          40
                              625
                                                                                          20
                              600                                                         0
                                    600   625   650   675   700   725   750   775   800
                                                        grade 7 score




Figure 2: Nonparametric Regression of Grade 8 Math Scores on Scores in Grade 7,
           Bubble Graph Showing the Joint Distribution of Scores and
              Standard-Error of Measurement for 7th Grade Scores

                              800                                                         200

                              775                                                         180
                                                                                          160
                                                                                                reported SEM for grade 7




                              750
                                                                                          140
                              725
              grade 8 score




                                                                                          120
                              700                                                         100

                              675                                                         80
                                                                                          60
                              650
                                                                                          40
                              625                                                         20
                              600                                                         0
                                    600 625     650 675     700 725     750 775 800
                                                        grade 7 score




                                                             41
                            Figure 3: Cubic Regression Estimates of E  Si , j 1 | Sij  as well as consistent
                                 estimates of cubic and linear specifications of E  i , j 1 |  ij  , ELA

                    (a) Fifth and fourth grade scores                                             (b) Sixth and fifth grade scores
        775                                                                           775
        750                                                                           750

        725                                                                           725

        700                                                                           700
score




                                                                              score
        675                                                                           675

        650                                                                           650

        625                                                                           625

        600                                                                           600
              600     625      650    675    700       725    750     775                   600     625   650    675    700    725   750   775
                                      prior score                                                                prior score

          cubic             "consistent" cubic         "consistent" linear

                    (c) Seventh and sixth grade scores                                            (d) Eigth and seventh grade scores
                                                                                      775
        775

        750                                                                           750

        725                                                                           725

        700                                                                           700
                                                                              score
score




        675                                                                           675

        650                                                                           650

        625                                                                           625

        600                                                                           600
              600     625      650     675       700    725     750     775                 600     625    650   675    700    725   750   775
                                       prior score                                                               prior score




                                                                         42
                         Figure 4: Cubic Regression Estimates of E  Si , j 1 | Sij  as well as consistent
                                  estimates of cubic and linear specifications of E  i , j 1 |  ij  , Math

                    (a) Fifth and fourth grade scores                                       (b) Sixth and fifth grade scores
        775                                                                     775

        750                                                                     750

        725                                                                     725

        700                                                                     700




                                                                       score
score




        675                                                                     675

        650                                                                     650


        625                                                                     625


        600                                                                     600
              600     625   650   675 700        725     750    775                   600     625    650   675 700        725    750   775
                                  prior score                                                              prior score

                                   unadjusted cubic                                                        unadjusted cubic
                                   "consistent" cubic                                                      "consistent" cubic
                                   "consistent" linear                                                     "consistent" linear


                    (c) Seventh and sixth grade scores                                      (d) Eigth and seventh grade scores
        775                                                                     775


        750                                                                     750


        725                                                                     725


        700                                                                     700
score




                                                                        score




        675                                                                     675


        650                                                                     650

        625                                                                     625

        600
                                                                                600
              600     625   650    675     700     725    750    775
                                                                                      600      625   650    675    700     725   750   775
                                   prior score
                                                                                                            prior score




                                                                      43
                                            Figure 5: Generalizability and Reliability Coefficient
                                          Estimates for New York Math and ELA Exams by Grade
generalizability coefficient   0.95


                               0.90

                                                                                             ELA Feldt-Raju Alpha
                               0.85
                                                                                             Math Feldt-Raju Alpha
                                                                                             ELA - G
                               0.80
                                                                                             Math - G

                               0.75


                               0.70
                                      4              5     grade    6              7




                                                                    44
Figure 6: Standard Errors of Measurement Reported in Technical Reports (dashed lines) and
              Estimated Using the Reduced-Form Model, ELA by Grade Pairs
                                            (a) grade four                                                               (b) grade five
                          50                                                                           50




                                                                                measuerment error SE
   measuerment error SE



                          40                                                                           40

                          30                                                                           30

                          20                                                                           20
                          10                                                                           10
                          0                                                                             0
                               575   600   625   650   675    700   725   750                               575   600   625   650   675   700   725   750
                                           level of achievement                                                         level of achievement

                                             (c) grade six                                                              (d) grade seven
                          50                                                                           50
   measuerment error SE




                                                                                measuerment error SE
                          40                                                                           40
                          30                                                                           30
                          20                                                                           20
                          10                                                                           10
                          0                                                                            0
                               575   600   625   650    675   700   725   750                               575   600   625   650   675   700   725   750
                                           level of achievement                                                         level of achievement


Figure 7: Standard Errors of Measurement Reported in Technical Reports (dashed lines) and
          Estimated Using the Reduced-Form Model, Mathematics by Grade Pairs
                                            (a) grade four                                                               (b) grade five
                          50                                                                           50
   measuerment error SE




                                                                                measuerment error SE




                          40                                                                           40
                          30                                                                           30
                          20                                                                           20
                          10                                                                           10
                          0                                                                             0
                               575   600   625   650   675    700   725   750                               575   600   625   650   675   700   725   750
                                           level of achievement                                                         level of achievement

                                             (c) grade six                                                              (d) grade seven
                          50                                                                           50
   measuerment error SE




                                                                                measuerment error SE




                          40                                                                           40
                          30                                                                           30
                          20                                                                           20
                          10                                                                           10
                          0                                                                            0
                               575   600   625   650    675   700   725   750                               575   600   625   650   675   700   725   750
                                           level of achievement                                                         level of achievement
                                                                           45
                                                        Figure 8
                             Estimated Posterior Mean Ability Level Given the Observed Score
                             and 80-Percent Bayesian Confidence Bounds, Grades 5 and 7 ELA
                              (a) grade five                                                   (b) grade seven
           800                                                               800

           775                                                               775

           750                                                               750

           725                                                               725
actual ability




                                                            actual ability
           700                                                               700

           675                                                               675

           650                                                               650

           625                                                               625

           600                                                               600
                             450 degree line                                               450 degree line
           575                                                               575
                 575 600 625 650 675 700 725 750 775 800                           575 600 625 650 675 700 725 750 775 800
                               observed score                                                    observed score

                                                         Figure 9
                                Estimated Posterior Mean Ability Level Given the Observed
                          Score and 80-Percent Bayesian Confidence Bounds, Grades 5 and 7 Math
                              (a) grade five                                                   (b) grade seven
            800                                                          800

            775                                                          775

            750                                                          750

            725                                                          725
                                                            actual ability
actual ability




            700                                                          700

            675                                                          675

            650                                                          650

            625                                                          625

            600                                                          600
                                                                                            450 degree line
                          450 degree line
            575                                                          575
                  575 600 625 650 675 700 725 750 775 800                      575 600 625 650 675 700 725 750 775 800
                               observed score                                                     observed score

                                                            46
                                 Figure 10
 Estimated Posterior Mean Change in Ability Given the Change in Observed
     Score and 80-Percent Credible Bounds, Grades 5 and 6 Mathematics
                                                        50
                                                        40
                                                        30

                                  change in ability '   20
                                                        10
                                                        0
                                                 -10
                                                 -20
                                                 -30
                                                 -40
                                                 -50
                                                             -50 -40 -30 -20 -10 0 10 20 30 40 50
                                                                            change in score




                                 Figure 11
Estimated Posterior Mean Change in Ability for the Observed Scores in Grades
  Five and Six Mathematics for S6 - S5 = 40 and 80-Percent Credible Bounds


                           50
                           40
     change in ability '




                           30
                           20
                           10
                            0
                           -10
                           -20
                                 575                     600     625   650 675 700       725   750   775
                                                                         grade 5 score




                                                                           47
                                        Figure 12
Example Showing Posterior means for a Forty-Point Score Increase, Grades 5 & 6 Mathematics

                   S5  710                                                                  S6  750


700               S5  710              720                 730                 740                750
                  710
 E( 5 S5 )  707.5 E( 5 S5 , S6 )  719.6 E ( 6 S5 , S6 )  729.9   E ( 6 S6 )  733.0




                                                 48
                                                           APPENDIX A

         We illustrate the structural approach for estimating the overall extent of test measurement

error using three alternative specifications for ij in  ij   j 1 i , j 1  ij , each of which fully

specifies the covariance structure of achievement gains across grades.

         Before considering particular specifications, note that for any specification of ij ,

 12  Cov( i1 , i 2 )  Cov( i1 , 1 i1  i 2 )  1  11  Cov( i1 ,i 2 )  1  11  12 and, in general,

 jk  Cov( ij , ik )  Cov( ij ,  k 1 i ,k 1  ik )   k 1  j ,k 1  jk , for k > j, where  jk  Cov( ij ,ik ) .

These recursive equations imply the structure of  shown in Equation A1 and the moment

conditions in Equation A2. Equation A3 also holds (e.g.,  22  12  11  21 12   2 ).                              2




     11 12 13 14                     11 G1         1 11   12     2 12   13      3 13   14        
         22 23 24                                      22 G2          2 22   23      3 23   24        
                                                                                                                  
          33 34                                                        33 G3         3 33   34                 (A1)
                                                                                                                  
                 44                                                                            44 G4            
                                                                                                               


                                      11   11 G1
                                      12  1 11  12
                                      13   2 1 11   2 12  13
                                      14  3  2 1 11  3  2 12  3 13  14

                                      22   22 G2
                                      23   2 22  23
                                      24  3  2 22  3 23  24                          (A2)


                                      33   33 G3
                                      34  3 33  34

                                      44   44 G4


                     jj  V ( ij )  V (  j 1 i , j 1  ij )   j21  j 1, j 1  2 j 1 j 1, j   2 . (A3)
                                                                                                                j




                                                                     1
This covariance structure follows from only assuming  ij   j 1 i , j 1  ij . We consider three

specifications for ij , each of which implies formulae for  jk and  2 . In each case, we utilize a j




random variable  ij having the following properties: Cov( ij ,  ik )  0 j  k , V ( ij )   2 ,

Cov(ij ,  i , j  m )  0 m  0 , and Cov( ij ,  i , j  m )  0 m  0 .32

            Model 1 is the relatively simple, but frequently employed, specification ij  i   ij

where i is a student-level random effect with V ( i )   2 . It follows that 2  V (ij )   2   2
                                                                                                                    j



and Cov(ij ,ik )  Cov(i   ij , i   ik )   2 , j  k . Here the variance of student

achievement gains gross of any decay is constant across grades.

            Model 2 is the specification ij  i, j 1   ij where 0    1 . Note that Cov(ij ,i , j 1 ) 

Cov(ij , ij   i , j 1 )   2j and, more generally, Cov(ij ,i , j  m )   m 2j m  0 .

            Model 3 is the moving average ij   ij  1 i, j 1   2 i, j 2 . It follows that

V (ij )  (1  12  22 ) 2   2 is constant across grades. Note that Cov(ij , i , j 1 )  1 (1  2 ) 2 ,


Cov(ij ,i , j 2 )  2 2 and Cov(ij ,i , j  m )  0 m  3 .

            The three models differ in the degree to which the achievement gains of students are

persistent over time, as shown in (A4). The expression for Model 2 is obtained through iterative

                                  Model 1:        ij   ij  i
                                  Model 2: ij   ij   i, j 1   2 i, j 2  i, j 3 (A4)
                                  Model 3: ij   ij  1 i, j 1   2 i, j 2




32
     We allow for the possibility that the mean of  i , j , say E i , j   j , is nonzero and varies across grades. This
generalizes the specification E i , j  0, j , E i , j ,  i , k  0 j  k , E i ,  i , j  0 j , and E i , j ,  i , k  0 k  j . Note
that the value of V ( ij )   2 can vary across the three models.

                                                                       2
substitution. There is no diminution in the persistence of the ij over time in Model 1;

Cov(ij ,i, j  m )   2 is constant regardless of the grade span (i.e., for all m). The covariance of
                          i



ij and i , j  m in Model 2 diminishes as m increases; Cov(ij ,i , j  m )   m 2 m  0 . Even so,
                                                                                               j




Cov(ij ,i , j  m ) is greater than zero for all grade spans. In Model 3 there is no memory for spans


of three grades or larger; Cov (ij , ij 1 )  1 (1  2 ) 2 , Cov(ij , ij  2 )  2 2 and

Cov(ij ,i, j m )  0, m  3 . Memory would be limited to adjacent grades if 1  0 but 2  0 and

there would be no persistence if 1  2  0 . Even though there is no memory in Model 3 across

spans exceeding two grades, any pattern is possible for the first two years, as the values of 1


and  2 are not restricted. For example, if 1   and  2   2 , the first three terms on the right

hand side of the equations for Models 2 and 3 in (A4) would be identical. As a group, the three

models include a wide range of possibilities. However, the estimation strategy discussed below

can be extended to other specifications for ij as well. We largely focus on Model 1 to illustrate

the structural approach to estimation.

         The specification ij  i   ij in Model 1 implies a relatively simple structure for the

 jk . For example, 1k  1 , k and  2  1 1   2 . In general,  jk  Cov( ij ,ik )

 Cov( ij , i )   j where  j  Cov( ij ,ik )  Cov(  j 1 i , j 1  i   ij , i   ik ) 

 j 1 j 1   2 . Thus, the value of  jk follows from the values of 1 , 2 , ,  j 1 , 1 , and  2 .

This structure, 2   2   2 , and Equations A2 and A3 imply the moment equations in (A5)
                      j



and (A6), where the formulae for  jj , j  1, in (A6) can be used to eliminate  jj in (A5).

Estimation of the remaining parameters is relatively a straightforward.


                                                            3
                11   11 G1  0
                12  1  11  1  0
                13   2 1  11  (  2  1) 1  0
                14  3  2 1  11  (  3  2   3  1) 1  0
                15   4 3  2 1  11  (  4  3  2   4  3   4  1) 1  0


                22   22 G2  0
                23   2  22  [ 1 1   2 ]  0
                24  3  2  22  (  3  1)[ 1 1   2 ]  0                     (A5)
                25   4 3  2  22  (  4  3   4  1)[ 1 1   2 ]  0


                33   33 G3  0
                34  3  33  [  2 1 1  (  2  1) 2 ]  0
                35   4 3  33  (  4  1)[  2 1 1  (  2  1) 2 ]  0


                44   44 G4  0
                45   4  44  [ 3  2 1 1  ( 3  2  3  1) 2 ]  0

                55   55 G5  0


                 22  12 11  21  1   2   2
                 33   22 22  2  2 1  1  (2 2  1) 2   2                              ( A6)
                 44  32 33  2 3  2 1 1  (23  2  23  1) 2   2
                 55   42 44  2  4 3  2 1 1  (2 4  3  2  2 4  3  2 4  1) 2   2

        Suppose that the values of ˆ ij have been estimated employing student test scores

spanning J grades (i.e., i, j  1, 2,..., J ). Let ˆ c represent a column vector made up of the

Nm  J ( J  1) / 2 moment equations following the structure in (A5) with ˆ ij substituted for ij

and the formulae in (A6) substituted for  jj , j  1 . Here ˆ c is a function of the N p  2 J  3



                                                            4
parameters in    11  1  2  2 1  2    J 1 G1 G2   GJ  , which can be estimated using the

generalized-method-of-moments estimator described toward the end of Section 3.2.

        In background analysis we estimated the three structural models and found that estimates

of all three specifications yielded predicted covariance structures that fit the covariance of test

scores well, with little evidence that any one was a superior specification. Important given the

motivation for this paper, the estimated patterns of test measurement error are quite robust across

the three structural models and the reduced-form model discussed in the paper.




                                                    5
                                                                      Appendix B

         As noted in the paper, measurement error can, but need not, result in E  Si , j 1 | Sij  being

a nonlinear function of Sij even when E  i , j 1 |  ij  is linear in  ij . It is not measurement error

per se that implies the nonlinearity, as E  Si , j 1 | Sij  is linear in Sij if the measurement-error is


homoskedastic (i.e., 2  2 , i ). However, E  Si , j 1 | Sij  is nonlinear in Sij when
                        ij    j



E  i , j 1 |  ij  is linear but ij is heteroskedastic with the extent of measurement error varying


with the ability level (i.e., ij   j ( ij ) ). When  j ( ij ) is U-shaped, as in Figures 1 and 2,


E  Si , j 1 | Sij  is an S-shaped function of Sij . An explanation and example follow.

         Consider the case where  ij                                                          
                                                             N (  j ,  2j ) , E  i , j 1 |  ij  0  1 ij and Sij   ij  ij .

Note that  i , j 1  0  1 ij  ij with E ij ij  0 so that Si , j 1  0  1Sij  1ij  i , j 1  ij . In


                                                                                               
turn, E Si , j 1 Sij  0  1Sij  1E ij Sij since both E ij Sij and E i , j 1 Sij are zero. In                  
the homoskedastic case ( 2  2 ), ij and Sij are bivariate normal, as shown in (B-1),
                            ij    j



                                       2
                     
implying that E ij Sij            
                                      2
                                             j
                                                 2       S   ij     j   1  G j  Sij   j  where G j   2j          2
                                                                                                                                  j          
                                                                                                                                         2 j .
                                       j             j




                                                           2                       2   
                                  ij              0    j                       j  
                                               N  ,                                             (B-1)
                                                             2
                                                                                2  2  
                                  Sij            j  
                                                           j                    j     j 




                                 
It follows that E Si , j 1 Sij  0  1 1  G j   j  1G j Sij is linear in Sij .

         As discussed in the paper, Sij and ij are not bivariate normal when the extent of


measurement error varies across ability levels (i.e., ij   j ( ij ) ). Similar to the way

                                                                            6
                                                                                 m1 ij  ij                  
                                                                  1
               
E  ij Sij can be computed, E ij Sij                  k   j
                                                                   
                                                                  Sij M
                                                                                   M
                                                                                                      2j ( mj
                                                                                                              *             *
                                                                                                                 )   j ( mj ) where


 ( ) is the standard-normal density, k j  Sij  is the score density and  mj
                                                                             *
                                                                                is a random draw from


                                                                                             
the distribution of  ij . In this way, we can compute E Si , j 1 Sij  0  1Sij  1E ij Sij . For                        
example, suppose that  ij           N (670,30) and ij                                  
                                                                       N 0, 2 ( ij ) with  n ( ij )   o   ( ij   j ) 2


and  n j  E j  n ( ij )   o   2j  15 . (These assumptions are roughly consistent with the

patterns found for the NYC test scores.) The three cases shown in Figure B.1 differ with respect

to the degree of heteroskedasticity: the homoskedastic case (  o  15 and   0 ), moderate

heteroskedasticity (  o  12 and   0.00333                     ) and a more extreme heteroskedasticity

(  o  3 and   0.01333                                              
                                   ). Values of E Si , j 1 Sij for the three cases are shown in Figure B.2.


                   
E Si , j 1 Sij is linear in the homoskedastic case and the degree to which E Si , j 1 Sij is S-                         
shaped depends upon the extent of this particular type of heteroskedasticity.

                                                                                      
           Knowing that the observed S-shape patterns of E Si , j 1 Sij can be consistent with   
E  i , j 1 |  ij  being linear in  ij is useful, but of greater importance is whether E  i , j 1 |  ij  is in

fact linear for the tests of interest. This can be explored employing the cubic specification

 i , j 1  0  1 ij  2 ij2  3 ij3  i , j 1 where 2  3  0 implies linearity. Substituting

Sij   ij  ij and regressing Si , j 1 on Sij would yield biased parameter estimates. However, if


                       
ik  E ( i* )k Si* , k  1, 2,3, 4 , were know for each student, regressing Si , j 1 on

i1 , i 2 , i 3 , and i 4 would yield consistent estimates.33


33
     See the discussion of the "structural least squares" estimator in Kukush et. al (2005) .
                                                                   7
                                                      
           Computing the ik  E ( i* ) k Si* , k  1, 2,3, 4 , for each student requires knowledge of

the overall extent and pattern of measurement error. It is the lack of such knowledge that motives

                                                                                   
this paper. However, we are able to compute ˆik  Eˆ ( i* )k Si* accounting for the meaningful

measurement-error heteroskedasticity reflected in the reported SEMs34, even though this does not

                                                                                            
account for other sources of measurement error. Computation of Eˆ ( i* ) k Si* also requires an 
estimate of  2j which can be obtained by solving for ˆ2j implicitly defined in


                                                              
ˆ2j  ˆ S2 j  ˆ2 j  ˆ S2 j   2   f  ˆ j , ˆ2j d . We solve for ˆ2j iteratively by computing


                                                     1
                                                           2  mj*  .
                                                           M
ˆ S2 j   2   f  ˆ j ,  2j d  ˆ S2 j                          Here the integral
                                                       M   m



    f                        
     2
                      ˆ j ,  2j d is computed using Monte Carlo integration with importance sampling

            *
where the  mj                                                                         
               are random draws from the distribution N ˆ j ,  2j and  2j is an initial estimate


of  2j . This yielded an updated value of  2j which can be used to repeat the prior step.


Relatively few iterations are needed for converge to the fixed-point – our estimate of  2j The


estimate ˆ2j allows us to compute values of ˆik and, in turn, regress Sij +1 on


ˆi1 , ˆi 2 , ˆi 3 , and ˆi 4 .



.




34
  Because SEM values are reported for a limited set of scores, a flexible functional form for 2   was fit to the
reported SEM. This function was then used in computation of moments.
                                                                   8
                              Figure B.1
Examples Showing Different Degrees of Heteroskedastic Measurement Error

                                 100
       SD of measurement error
                                 80


                                 60                                                                                 Extent of
                                                                                                                    heteroskedasticity:
                                                                                                                           none
                                 40
                                                                                                                           moderate
                                                                                                                           more extreme
                                 20


                                   0
                                       550     575     600   625   650    675      700      725   750   775   800
                                                                   prior ability/skills



                                                         Figure B.2
                                        How the Relationship Between E  Si Si  and Si
                                             Varies with the Degree of Heteroskedasticity
                                  800

                                  775

                                  750

                                  725

                                  700
                         score




                                  675

                                  650

                                  625

                                  600

                                  575

                                  550
                                         550         575     600   625       650          675     700   725    750       775      800

                                                                                   prior score
                                   Extent of heteroskedasticity:           none            moderate      more extreme          actual




                                                                                   9
