                                 NBER WORKING PAPER SERIES




                          ECONOMICS, HISTORY, AND CAUSATION

                                            Randall Morck
                                            Bernard Yeung

                                         Working Paper 16678
                                 http://www.nber.org/papers/w16678


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                     January 2011




We are grateful for helpful comments from Walter Friedman, Luigi Zingales, and three anonymous
referees. Partial financial support from the Social Sciences and Humanities Research Council is gratefully
acknowledged The views expressed herein are those of the authors and do not necessarily reflect the
views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2011 by Randall Morck and Bernard Yeung. All rights reserved. Short sections of text, not to exceed
two paragraphs, may be quoted without explicit permission provided that full credit, including © notice,
is given to the source.
Economics, History, and Causation
Randall Morck and Bernard Yeung
NBER Working Paper No. 16678
January 2011
JEL No. C01,C21,C31,G0,M2,N0

                                              ABSTRACT

Economics and history both strive to understand causation: economics using instrumental variables
econometrics and history by weighing the plausibility of alternative narratives. Instrumental variables
can lose value with repeated use because of an econometric tragedy of the commons bias: each successful
use of an instrument potentially creates an additional latent variable bias problem for all other uses
of that instrument – past and future. Economists should therefore consider historians’ approach to
inferring causality from detailed context, the plausibility of alternative narratives, external consistency,
and recognition that free will makes human decisions intrinsically exogenous.


Randall Morck
Faculty of Business
University of Alberta
Edmonton, AB T6G 2R6
CANADA
and NBER
randall.morck@ualberta.ca

Bernard Yeung
National University of Singapore
Mochtar Riady Building
15 Kent Ridge Drive
BIZ 1, Level 6, #6-19
Singapore 119245
bizdean@nus.edu.sg
1.      History, Econometrics, and Economics
Economics and history have not always got on. Lazear’s (2000) advice that all social scientists adopt
economists’ toolkit evoked a certain scepticism, for mainstream economics repeatedly misses major
events, notably stock market crashes (Fischer 1933), and rhetoric can be mathematical as easily as
verbal (McClosky 1985). Written by winners (Orwell 1944), biased by implicit assumptions (McLuhan
1962); and innately subjective (Derrida 1967); history can also be debunked (Ford 1922, pp. 43-4).
Fortunately, each is learning to appreciate the other. Business historians increasingly use tools from
mainstream economic theory (Lamoreaux, Raff, and Temin 2007); and economists display increasing
respect for the methods of mainstream historians (Chandler, 1962; Wilkins 1970; Hertner and Jones
1986; Jones 2005; and many others). Each field has infirmities, but also strengths. We propose that
their strengths usefully complement each other in untangling the knotty problem of causation.
          This complementarity is especially useful to economics, where establishing what causes
what is often critical to falsifying a theory. Popper (1934) argues that scientific theory advances by
successive falsifications, and makes falsifiability the distinction between science and philosophy.
Economics is not hard science, but nonetheless gains hugely from a now nearly universal reliance on
empirical econometric tests to invalidate theory. Edward O. Wilson (1998, p. 47) puts it more
bluntly: “Everyone’s theory has validity and is interesting. Scientific theories, however, are
fundamentally different. They are designed specifically to be blown apart if proved wrong; and if so
destined, the sooner the better.” Demonstrably false theories are thus pared away, letting
theoreticians focus on as-yet unfalsified theories, which include a central paradigm the mainstream
of the profession regards as tentatively true (Kuhn 1976). The writ of empiricism is now so broad
that younger economists can scarcely imagine a time when rhetorical skill, rather than empirical
falsification, decided issues and the simplest regression was a day’s work with pencil and paper.
          But such was once the case. Relying on common sense, Malthus writes “Population, when
unchecked, increases in a geometrical ratio. Subsistence increases only in an arithmetical ratio.”
Edgeworth (1881), relying on introspection, affirms a gender-specific “capacity for pleasure’ (p. 77)
and “a nice consiliance between the deductions of the utilitarian principle and the disabilities and
privileges which hedge around modern womanhood (p. 79)”. Galbraith (1967, p. 36), relying on a
keen intellect, declares that “competitors of General Motors are especially unlikely to initiate price
reductions that might provoke further and retributive price cutting. … Everyone knows that the
survivor of such a contest would not be the aggressor but General Motors.” And a little data can
make things worse, not better, for Cold War era editions of Samuelson’s textbook, Economics
features graphs of Soviet GNP surpassing US GNP by the 1980s, or 1990s at the latest, (Levy and
Peart 2009).
          These indisputably great economists wrote as they did because their introspection, common
sense, intellects, and observations shaped their thoughts. Rhetorical flourish usefully prevented their
economics from lapsing into a treatment for insomnia, but what these old masters did was not
science, but something closer to history. For historians, too, weave common sense, introspection,
intellect, and historical records into narratives that explain the past and illuminate the present.
          Their work added much to economics. Edgeworth, Samuelson, Walras, and Leontief brought
algebraic clarity to elegant narratives spun by Smith, Mills, Voltaire, and Marx; and the combination
was genuinely powerful. But so are folk tales, like Rudyard Kipling’s (1902) “Just So” Stories, which
relate how the camel got his hump, how the leopard got his spots, and so on. Good narratives are
compelling, socially edifying, and plausible explanations of why things are “just so.” The critic al
difference is evidence.
          This lesson is now so deeply accepted that one seldom sees an economic theory article
without valid econometric evidence, or at least a compelling survey of supportive empirical
evidence. This is an unmitigated blessing. Empirical observation has pushed extremists towards the
centre, for the data undermine both Marxism and perfect markets. The 21st century Left
contemplates a toilet-trained capitalism, (Krugman 2007; Sachs 2006, Stiglitz 2006); and the 21st
century Right frets over entrenched oligarchs (Rajan and Zingales 2004), the potential importance of

                                                  1
fiscal policy (Feldstein 2009) and the optimal design of government (Buchanan 2003). Frenzied cries
to abandon either markets or government can still be heard elsewhere on university campuses, but
rarely amid economists. Our debates remain passionate, but are far more clinical and data-driven
than before computers and mass storage ushered in the Age of Data.
         But economics is more than econometrics; it is an ongoing interplay of theory and evidence.
Kuhn (1962) argues that science establishes paradigms – structural theories of what causes what –
that remain valid as long as they are not inconsistent with extant empirical evidence. The
overwhelming success of econometrics in fundamentally altering the way economists think and
debate attracts attention, and therefore critics. Speaking for many of these, Fischer Black (1982)
blasts econometrics for confusing “correlation with causation” and econometricians for terminology
that propounds that confusion. Black’s attack hit hard, and endogeneity bias, previously but one of
many potential econometric problems, became “the” econometric problem.
         Thus rattled, economists returned to history, searching for tools with which to cultivate
better econometrics. An assortment of econometric techniques based on instrumental variables
became “the” response to Black’s critique. Economists often look to history for instrumental
variables: factors determined long ago that cannot possibly “be caused” by things going on today. If
paths of causation can be traced through such factors, the direction of causality can be inferred.
         This technique is very powerful where it can be applied – for example in natural experiments
(Diamond and Robinson 2010). However, econometrically useful natural experiments are few and
far between, so economists often make do with iffier instrumental variables techniques. We argue
that strict limitations on the validity of instrumental variables greatly limit their utility, and that
repeated use of the same instrumental variables in related economic contexts undermines their
validity in an econometric tragedy of the commons. However, we believe that economists might find
other ways of establishing causality by recognizing history as more than a tool shed for instrumental
variables. History provides contextual details, plausibility tests, external consistency checks, and a
role for free will. Though not proof of causation, correlation is a smoking gun; and history can often
supply sufficient circumstantial evidence to convict.

2.      The Problem of Causation
Economics is not the only place where correlation and causation get confused. Causality is a problem
everywhere. For instance, physicians observe more heart attacks in people who are more obese and
thus argue that obese people should diet to reduce the danger of heart failure. But is this really so?
Perhaps people with weak hearts need more body fat, and dieting would worsen the danger of a
heart attack. Or perhaps an unknown chronic viral infection causes both heart attacks and body fat
accumulation, and dieting would only hide a cosmetic symptom of the virus while leaving it free to
attack the heart.
         Medical science infers causality with double blind randomized trials. Equally obese people
must be randomly assigned to either a treatment group or control group. People in the treatment
group are put on a calorie restricted diet and people in control group are fed equally unpalatable
food, designed to be indistinguishable from diet.
         Assignment to groups must be utterly random. A caring physician might put patients she
thought in dire danger of heart attacks in the treatment group, but that would spoil the test. If more
dieters than control patients subsequently die of heart attacks, she cannot tell whether dieting killed
them or prevented even more from dying. But if the assignment were utterly random, any difference
in the death rates can be credited to (or blamed on) the treatment.
         Second, neither the patients nor the physicians running the test may know who is in what
group. People who know they have lost weight might act differently, or physicians might treat them
differently, and either difference might cause difference in outcomes between the two groups.
Dieting must be the only difference between the two groups, otherwise some other unknown factor
might be the true cause of any difference in outcomes between the two groups.



                                                  2
          But if the test was done right, the difference between the treatment group patients’ old and
new diets “caused” any difference in heart attack rates between the treatment group and the
control group. Such a difference-in-difference test allows a causal inference: putting obese patients
on the diet prevents heart attacks.
          Double blind randomized trials are rare in economics. The divisions of Germany and Korea
into capitalist and socialist halves might qualify as a test of socialism versus capitalism. The Iron
Curtain arguably randomly assigned Germans to East and West Germany, and the Demilitarized Zone
arguably did the same to Koreans. Prior to the late 1980s, neither set of leaders, nor even Paul
Samuelson, could divine the victor in the Cold War, so neither the citizens nor the economic policy
makers on either side knew which was getting a treatment and which was getting a placebo.
          Can we then conclude that different economic systems caused the differences in living
standards evident by the late 1980s? Perhaps ... But the Red Army seized northern Korea because
the Japanese left an industrial infrastructure there, so the division was not truly random. The
“treatment” might have been endogenous. Northern Koreans were more accustomed to factory
work than their agrarian southern compatriots; but West Germany inherited a more comprehensive
industrial base than did East Germany. East and West Germany differed in other ways. For example,
what became East Germany was mainly Protestant in 1945, while the future West Germany held a
substantial Roman Catholic minority. Perhaps religious traditions, a latent factor, really caused of
any difference in economic prosperity.
          Wherever genuinely randomized and double blind trials occur, they are extremely useful.
For example, Godley (2010) shows that Eastern European Jews who moved to London and New York
at the turn of the century subsequently exhibited very different levels of entrepreneurship. To the
extent that the allocation of Jews to the two cities was random, this becomes a natural experiment
on how environment differences affect entrepreneurship. Likewise, Henry and Miller (2009)
compare Barbados and Jamaica – Caribbean island nations with similar social, political, and
economic institutions at independence, but with different development policies thereafter. To the
extent that their policy differences were random happenings, this natural experiment on how
economic policies affect economic outcomes.
          Unfortunately, such natural experiments are decidedly rare, so much causal inference in
economics can be shaky. For example, economies with dynamic financial systems grow faster (King
and Levine 1993). Establishing this correlation is a useful exercise per se: the exercise immediately
falsifies any theories that imply a negative correlation or no correlation. But too many theories
remain on the table. Does a dynamic financial system cause rapid growth; or does rapid growth
supercharge a country’s financial system? Or does a predominantly Protestant population, for
example, cause both? This is more than an academic question, but multilateral financial institutions
poured much money and effort into creating stock markets in post-socialist “transition” economies
during the 1990s. Only if stock markets “cause” growth was this well spent.
          Black’s (1982) critique made economists and econometricians, in particular, keenly aware of
the tenacious problems surrounding causal inferences. An arsenal of sophisticated techniques and
penetrating insights has been deployed. However, impressive as they are, especially on a case-by-
case basis, their limitations remain binding at a more general and collective level - as we argue
below.

3.      Rummaging through the Tool Shed of History
The great strength of the natural sciences is their basis in experiments in controlled laboratory
conditions. Randomized controlled experiments, usually on undergraduate subjects, can expose
regularities in human behaviour that usefully restrict the set of admissible theories (Camerer 2010);
and the use of subjects in developing economies promises further insights but also raises new
problems (Deaton 2010).
        But many of the deepest questions in economics concern whole nations and the dealings
between them. The reader is invited to devise a controlled experiment to check whether or not

                                                  3
bigger stock markets cause faster GDP growth. Electorates are disappointingly sceptical about letting
economists use economies as laboratories to test unproven theories. And even when a theory is
tested – say Keynesian economics in the Great Depression or Supply Side economics in the 1980s –
we are rarely able to randomize or organize proper control samples. Economists can only look on
with envy as a chemist fills two test tubes with the same reagent, treats one with a substance of
interest, and notes the result.
         The best economists can usually do in such circumstances is to find a useful natural
experiment. Nature occasionally treats two otherwise identical groups differently in a way that
resembles what economists would have done had they been allowed to run a controlled
experiment. Such a natural experiment lets economists identify the causal effect of that treatment
by measuring differences between the groups – first before and then after nature ran the
experiment. The “difference in these differences” is plausibly caused by the different way nature
treated the two groups.
         Diamond and Robinson (2010) present several examples of such natural experiments that
demonstrate the power of the technique. But they also warn that such cases are rare; and that
apparent natural experiments can be invalidated by subtle initial differences between the groups, or
by additional perturbations that affected them differently.
         For example, consider an economist searching for a natural experiment to ascertain the
effect of a government policy with implications for the validity of an economic theory. Suppose the
policy affects some people or firms more heavily than others. If the economist can sort the subjects
in a way somewhat reminiscent of having randomly selected treatment and control groups, and then
observe events unfold, causal inference is possible. The problem is finding a sorting mechanism that
distinguishes heavily affected from lightly affected subjects in a way reminiscent of the
randomization in medical trials. The groups must be identical in all other ways: the only permissible
difference between them is that the policy weighs heavily on some and lightly on others.
         The favoured solution to this sorting problem is instrumental variables. This set of
econometric techniques encompasses estimation using instrumental variables (IV) regressions,
simultaneous equations (SE), generalized method of moments (GMM), and scores of related
procedures. Though widely used, all these techniques are methodologically profoundly problematic.
At least one valid instrumental variable must be found for each variable of interest in the estimation,
and the criteria for validity are gruelling. These are:

3.1     Endogeneity and Exogeneity
A valid instrument must vary only in response to exogenous factors, that is factors determined by
nature, God, or people whose actions do not depend on the dependent variable in the model. In the
medical trial, a random assignment of patients to the two groups served as an exogenous way of
distinguishing observations. An instrument also sorts observations by some criterion that is
unaffected by the dependent variables the economist would test.
         Economists often look to history here. For instance, countries’ colonial histories and legal
systems were shaped centuries ago, and so cannot be affected by their current economic
performance. While instruments are sometimes taken from geography, linguistics, or other fields,
economists seem happiest when rummaging about for instruments in history.
         But does the arrow of time really make things so simple? Tobin (1970) stresses that
economics differs fundamentally from the natural sciences because people’s economic decisions
depend on their expectations of future events; while the actions of pendulums, atoms, and planets
do not. This teleological quality at the very heart of economic theory means that the future “causes”
the present in economics. For example, shareholders’ expectations about future dividends
determine a stock’s price today. Can such temporal ricochets affect the flow of history in general?
         Let us explore colonial origin. If British, French, Spanish, and Portuguese colonies were
scattered randomly throughout the world, colonial heritage would qualify as an exogenous
instrument. But France lost Canada in 1759 and abandoned the colony in 1763, demanding instead


                                                  4
the sugar island Guadeloupe as the price of a peace treaty with Britain. British government officials
disproportionately chose to make and defend claims of sovereignty over territories with agricultural
potential; France, Spain, and Portugal for the most part did not.
        Is a British colonial heritage then the “cause” of Canada’s agricultural exports? Is a French
colonial heritage the cause of Guadeloupe’s economic dependency? Perhaps; but Britain and France
deliberately colonized places with certain characteristics, like physicians choosing patients with
certain characteristics for their trials and thereby invalidating the initial randomization. How do we
know that Canada’s agricultural potential didn’t cause it to end up under British suzerainty? Such
questions may be answerable, but their asking demonstrates that historical variables, even very
deep ones, are not a priori exogenous.
        Careful researchers must thus work hard to validate their exogeneity assumptions. One
approach is a careful reading of the historical record surrounding the data used to construct the
instrumental variable (e.g. Banerjee and Iver 2010). A non-random initial difference between
subjects might become evident over time; and another perturbation might affect different subjects
differently. Either could confound the natural experiment into presenting a false picture of what
causes what.

3.2     Weakness and Strength
A valid instrument must be strongly correlated with the treatment. Economists generally cannot
randomly assign observations to treatment and control groups; the instrument must do this. For
example, an economist might be interested in how comparable worth wage laws affects
unemployment, but is worried that unemployment might also affect a country’s labor laws. The
economist therefore rummages about in history for an instrument and, let us suppose, selects the
longitude of each country’s capital city.
        This variable might meet the endogeneity criterion above, but it is no good as an instrument
unless it correlates strongly with the treatment. After all, its purpose is to randomly allocate
countries to the treatment group, those with comparable worth laws, and the control group, those
without such laws. Longitude can hardly do this if it is uncorrelated with the presence of those laws.
        Stock and Watson (2007) ascertain that instrumental variables achieving a joint F statistic
below ten in a regression explaining the relevant treatment variable may have a weak instruments
problem. Though they provide techniques for using weak instruments nonetheless in certain
situations, failure to pass a weak instruments test generally consigns otherwise commendably
instrumental variables to the dustbin of econometrics.
        Dismayed at longitude failing this test, the persevering economist might rummage further
and, after a hundred or so tries, find the cosine of mean squared 1880s rainfall correlating with a
dummy for comparable worth laws (p < 1%). Unfortunately, a variable, even a serenely exogenous
one, that correlates with the treatment only incidentally, and after days of rummaging through the
tool shed, is really merely a selected reflection of the treatment variable itself. Any endogeneity
problems that afflict the original variable afflict its reflection too.
        Searching for false positives is no way to uncover strong instruments. We do not charge
economists with rifling through history for Type II errors (Weimer 1986), but worry that editors and
referees tempt authors by demanding they force causally circular data into inappropriate square
instrumental variables econometrics.
        Weak instrument problems are especially likely to arise if the data are noisy – that is,
observed imperfectly. For example, a highly acclaimed and carefully done study by Acemoglu et al.
(2001) uses mortality rates of early colonial settlers as an instrumental variable to sort countries by
propensity to establish property rights protecting institutions. If settlers were initially randomly
distributed across colonies, and property rights protecting institutions were in greater demand
where more settlers survive, this variable qualifies as exogenous. Nonetheless, a well-articulated
debate between Abouy (2008) and Acemoglu et al (2005, 2006) about the accuracy of historical



                                                  5
mortality rates demonstrates how data uncertainties can create a weak instruments problem even if
the instrument is plausibly exogenous.

3.3     Latency and Blatancy
A valid instrument must not be thrown off by latent factors. The increasing popularity of historical
variables as instruments makes this a growing problem.
         There are many importance cases where colonial origin, legal system origin, religious history,
settler mortality, and the like are arguably exogenous and are correlated with treatment variables of
interest. For example, accepting that a country’s legal system’s origin cannot be caused by its
current financial dynamism, suppose an economist finds highly significantly more dynamic financial
systems in Common Law countries. She rightly uses legal origin as an instrument for financial
development; that is, she uses legal origin as an exogenous criterion for sorting countries in a way
that also ends up sorting them by financial development. Then she can test whether the Common
Law countries, which have more dynamic financial sectors purely by dint of having Common Law
legal systems, grow faster than otherwise identical countries that lack dynamic financial systems
purely by dint of lacking Common Law legal systems. If she includes appropriate control variables, so
the countries truly are otherwise identical, this is arguably a valid test, and she can conclude with a
straight face that financial development causes growth.
         Now suppose another economist want to see if agricultural productivity causes economy
growth, and finds the latter variable also correlating highly with legal origin. The second economist,
using legal origin as an instrument, regresses economic growth on agricultural productivity; and,
finding a significant coefficient, concludes that agricultural productivity causes growth.
         This, unfortunately, does not fly. The second economist should have read the literature – in
particular, the first economist’s paper. He knows financial development matters in this setting, and
has a latent variable problem in his regressions unless he includes that variable too. Moreover,
publication of the second economist’s paper means the first economist’s article is no longer
convincing as regards causality. She now has a latent factor problem, for she failed to control for
agricultural productivity, an endogenous variable that the second economist proved to be
important. The key point here is that each subsequent paper that reuses an instrument in a shared
context contributes an additional latent factor problem to all the existing studies.
         Tragically, commonly used instrumental variables lose value with overuse. This because the
instrumental variables are non-exclusionary, the first economist to use an instrument cannot prevent
others from using it too; and because instrumental variables can be rivalrous, each successive use
potentially compromises the instrument’s validity in every previous and subsequent use. Absent a
comprehensive multinational agreement enforcing their patenting, instrumental variables are
stymied by a classic Tragedy of the Commons (Hardin 1968).

3.4     An Econometric Tragedy of the Commons
The requirements of exogeneity, strength (no weak instruments problems), and blatancy (no latent
factor problems) severely limit the supply of valid instrumental variables. This leads to their
recycling. Each individual study may look econometrically rigorous – its instruments exogenous and
strong. But authors of literature reviews, who must evaluate the collective contributions of many
such studies, cannot but doubt the validity of each study given the others.
        Economists have long stressed internal consistency. An economist generally may not begin a
proof assuming a logarithmic utility function and then switch to a constant elasticity of substitution
(CES) utility function part way through.1 But even the best economics journals have no problem


1
 Logarithmic utility assumes a subject’s utility (hedonic pleasure) from consuming C to be a function of the
                                                                                   1-a
form U = a log(C)., while constant elasticity of substitution utility assumes U = C /(1-a). The two are
equivalent if a is 1, but not otherwise. Economic theorists often choose a functional form to make the algebra
easier; however results based one form often do not follow if another is used instead.

                                                      6
with logarithmic utility in one article and CES in the next, even if each article is utterly devastated by
the assumption used in the other.
         This lack of concern for external consistency is a challenge to theorists, but a disaster for
empirical economics when issues of causation arise. An effect that is blatantly significant in one
study is necessarily potentially latently significant in all others that explore the same economic
questions, and probably in studies that examine many related economic questions too. Individual
articles can sustain a veneer of consistency, but the collective literature cannot.
         A Tragedy of the Commons has led to an overuse of instrumental variables and a depletion
of the actual stock of valid instruments for all econometricians. Each time an instrumental variable is
shown to work in one study, that result automatically generates a latent variable problem in every
other study that has used or will use the same instrumental variable, or another correlated with it, in
a similar context. We see no solution to this. Useful instrumental variables are, we fear, going the
way of the Atlantic cod.

4.      Learning from Repeating History
Fortunately, there are ways we can learn about causation from history without rummaging for
instrumental variables. A prime example of this is the event studies of financial economics. A second
is Granger causality (G-causality) tests, widely used by macroeconomists.

4.1     Event Studies
Event studies (Campbell et al. 1997, c. 4) are perhaps the most direct test for causality available to
economists. For example, a financial economist who wanted to see if comparable worth laws add
value to firms might identify the precise dates on which each US state with such laws first
announced them. If the value of a portfolio containing the stocks of all the firms operating in the
announcing state rises significantly relative to the value of a portfolio containing all other stocks on
each such event date, the financial economist is on passably solid ground inferring that comparable
worth “causes” increased firm values.
         The power of event studies lies in repetition of history. If each of a large collection of
economically similar event corresponds to similar patterns in the data, we can infer that something
significant is happening. In this example, each state’s announcement repeats the event, and if each
repetition is associated with a similar relative stock value hike for the firms in the affected state, a
pattern is evident and causality can be inferred.
         An inference of causality is justified by Ockham’s Razor: that the legal reform causes stock
prices to change is reasonable because the reverse is manifestly implausible. For stock price hikes to
cause the laws, state legislators would have to patiently monitor the ticker tape until a day when the
stocks of firms in their state, and only those stocks, rise; and then burst forth with news of new labor
laws.
         However, even here, we must beware of latent factors. For example, if states tend to adjust
their minimum wages whenever they adopt comparable worth laws, the minimum wage might be
causing the stock price changes.
         Also, insignificance in an event study cannot prove an absence of causation, for economic
decision-makers’ expectations of the future again come into play. If Iowa’s adoption of comparable
worth labour laws were all but assured months ahead of their actual unveiling, the unveiling would
not move stock prices. Investors would long ago have adjusted their expectations about the
dividends of Iowan firms, and little or nothing would happen when those expectations were realized.
         The event study technique is thus weakened by investors’ collective learning. But learning is
usually incomplete – as long as some probability of history following an alternative path remains
non-zero until the event actually occurs, event study can be informative about causality. Moreover,
many interesting economic phenomena are fundamentally amenable to perfect prediction by
neither econometricians nor the people they model (Nelson 1972; Roll 1986; Diebold 1998;


                                                    7
Caballero 2010; and others). The unfolding of history reveals new information and human ingenuity
creates innovations – neither, by definition, is predictable; yet both are central to economics.

4.2     Granger Causality Tests
Something akin to an event study is sometimes econometrically feasible in panel data. Granger
(1969) causality tests exploit a definition of causal relationships between random variables proposed
by Wiener (1956): one variable "Granger-causes" (or "G-causes") another if a forecast of the second
variable based only on its past values is made significantly more accurate by using past values of the
first variable as well.
          In practice, these forecasts are almost always linear regressions, so the test is really about
one variable “G-causing” another if a regression of the latter variable on its own past values and past
values of the former variable has a significantly higher R2 than a regression of the latter variable on
its own past values alone.
          For the test to be valid, both variables must be stationary – they must not have a common
trend. Trends are removed by taking first differences, second differences, or if necessary, even
higher order differences, until a panel of stationary data are obtained. This is reasonable, for if one
variable causes another, changes in the first variable presumably also cause changes in the second.
          Like other tests of causality, this approach requires that the economist worry about latent
factors, for if a third variable “causes” both of the variables being tested for Granger causality, a
false positive can result. And, as with event studies, an absence of evidence of causality is not
evidence of its absence.
          Granger causality tests are perhaps uniquely vulnerable to the fundamental teleology of
economic theory. If central bankers adjust the money supply based on their expectations of future
GDP growth, a Granger causality test might erroneously show the money supply “causing” GDP
growth. Because economics is about people’s decision making under uncertainly, expectations about
the future cause present decisions. If those expectations turn out to be correct in general (Muth
1961), the future can seem to cause the past.
          Event studies are less vulnerable to this critique because stock prices can be observed at
very high (daily and intraday) frequency and, if announcement times are sufficiently precise,
Ockham’s razor can cut away alternative causality scenarios. For example, firms usually announce
major strategic decisions after the stock exchange closes for the day. An event study of firms’
announcements of diversifying takeovers finding their stock price the next day significantly below
the closing price just prior to these announcements is consistent with diversification causing
shareholders to revise downwards their estimates of the firm’s value. Reverse causality would entail
CEOs, foreseeing stock price drops, deciding to announce diversifying takeovers. This is not
impossible, but it is implausible. Economic theory provides many reasons for diversification to
destroy value, but no reasons for CEOs to act as reverse causality would demand.
          However, Granger causality can work where event studies do not. Event studies can be
impractical if the variable of interest is observed only at a low frequency (quarterly or annually) and
a long enough time series to permit meaningful statistical tests does not exist. Moreover, if the
variables of interest exhibit sluggish adjustments or are obscured by substantial noise, as many
macroeconomic variables and product prices can be, Granger causality tests can fail to detect bona
fide causal relationships.


5.      Implausibly Deniable Causality
Absence of evidence of a given direction of causation is not evidence of its absence, and is certainly
not evidence of causation in the reverse direction. Neither instrumental variables regressions, nor
event studies, nor Granger causality tests can assert an absence of causal connection. That a
negative cannot be proven is an epistemological truism, but that doesn’t prevent economists from
trying (Summers and Stambough 1986).


                                                   8
         Statistical insignificance in an event study does not mean the events definitively do not
cause changes in stock prices. The event dates might be insufficiently precise, or stock prices might
be too volatile to detect the signal reliably, or investors might have expected the event with
sufficient probability that its price impact was negligible. Granger causality tests can also be muddied
by the timing of expectations revisions, by noisy data, and by insufficiently long or excessively
persistent panel data.
         An absence of significance in an instrumental variables framework likewise does not mean
an absence of causality. The instrument may not be strong enough, latent variables may lie hidden in
the statistical background, or the effect may be obscured by the noise. Even more importantly, an
absence of significance in an instrumental variables framework does not imply reverse causality.
Proving reverse causality requires specifying a regression that represents the reverse causality,
complete with its own control variables and exogenous strong instruments for its endogenous right-
hand side variables.

6.      Dusting off History
History ought to be intrinsically interesting to economists. Economics seeks to explain patterns in the
progress of individuals and collectives – communities, corporations, and nations. History documents
the past that generated economists’ datasets, and so ought to arouse economists’ intellectual
curiosity. But we propose that the study of history offers economics much more.
         History provides context – an intensity of information around a few observations – and this
can sometimes be as useful as a large dataset. A good example of this is Alfred Chandler’s (1962)
Strategy and Structure: Chapters in the History of American Industrial Enterprise. This work lays out,
in intricate detail, the inner workings of DuPont, General Motors, Sears, and Standard Oil as they
adopted a new corporate structure that he dubs the M-form The degree of detail, based on careful
documentation of how key decisions came to be make, shows that the corporations’ strategies must
determine their structures, not the converse. These observations continue to shape studies of
business strategy, and much recent work also applies Chandler’s strategy for ascertaining patterns of
causality. For example, Jones and Khanna (2006), surveying the business history literature, point
out how historical information on early European multinationals illuminate underlying causes of
their diversification and development into business groups.
         Historical studies have a collective methodology: external consistency matters. History
subjects competing narratives to ongoing tests of plausibility, and this narrative format forces an
external consistency. To sustain credibility, a good historical narrative must connect the “dots” of all
relevant historical events with causal links. And while historians debate the importance of individuals
as opposed to impersonal forces, history is more amenable to the concept of free will than is
neoclassical economics; and causality is far more interesting if there is free will. In sum, we believe
more attention to history offers economists more defensible arguments about causality.

6.1     The Importance of Context
Economics strives for simplification that reveals underlying causal principles. The detail and
contextualization favoured by historians complicates economists’ models. While some historians can
be accused of excessively imaginative reconstruction of causality and deliberately biased searches
for historical evidence supporting their favoured narratives, economists are hardly immune to
mistaken musings and confirmation bias. But historians’ purpose is, first and foremost, a sustained
effort to reveal causality. That shared purpose makes history intrinsically interesting to economists.
         Historical studies about economic and financial events offer chronological sagas of unfolding
developments. They link outcomes to events, reactions to actions, and (perhaps most importantly to
economists) historically consequential errors to critical decision-makers’ private preferences and
incomplete information. History is composed of narratives that “connect the dots” in causal terms.




                                                   9
         History, unlike economics, pays great attention to external consistency. Historians’
narratives gain credibility by their finesse at connecting all the dots. This attention to context can be
illuminating.
         For example, Germany and Japan are “bank-based” economies: their big businesses rely on
banks for capital and seldom issue new shares onto their stock markets. In contrast, Anglo-Saxon
countries are “stock market-based” economies: their big companies rely extensively on share issues
to finance growth, and long-term bank loans are markedly less important. An econometrician would
correctly detect no indication that one system causes higher living standards than the other.
However, an historian might dissent. Both Japan and Germany industrialized in the late 19th and
early 20th century, and both were stock-market-based economies in their high growth decades
(Fohlin 2005; Morck and Nakamura 2007). Banks rose to dominance amid Japan’s post-war
reconstruction (Morck and Nakamura 2005) and under Germany’s National Socialist government
(Fohlin 2005), though Bismarck began shifting German regulations towards favoring banking much
earlier (Mitchie 2008). Indeed, that any major economy has ever industrialized successfully without
a large stock market is unclear (Rajan and Zingales 2003)2.
         This example highlights the importance of path dependence. Germany and Japan both had
to finance costly large-scale post-war reconstruction, and both used vastly expanded banking
systems to finance this. Path dependence tends to undermine assumptions of ergodicity, the
premise that time-series and cross-section variation are statistical substitutes. In this case, the cross-
section is silent, but a few historical observations are informative.
         By putting their current financial systems in context, history gives economists a better
understanding of their data. The detailed economic histories of Japan and Germany are case studies,
not data. But their wealth of detail provides a context in which to evaluate broader hypotheses and
disentangle the effects of path dependence. For example, Haber’s (2010) comparative description of
the development of banking in the US, Brazil, and Mexico does precisely this. The value of
descriptive history in addressing these sorts of issues is surveyed in Jones and Khanna (2006), and
reiterated in Morck and Yeung (2007). In this way, a few observations – perhaps even just one – can
provide an intensity of information that allows inferences even a large dataset might not reveal.

6.2     Competing Narratives and Ockham’s Razor
Such exercises are useful to economics because the uncovering of previously unknown historical
evidence and the unfolding of current events into the tapestry of history provide ongoing tests of
competing narratives. Ockham’s razor shapes the tapestry: narratives rendered less plausible fall
away before narratives rendered more plausible.
        History thus has its own way of ascertaining validity. An historical narrative must be logical
and backed by evidence. Historians construct, modify, extend, and prune their narratives to maintain
internal and external consistency. Sometimes this reinforces established narratives; other times it
leads to their replacement by another narrative in a process, much as new paradigms overturn old
ones in the sciences (Kuhn 1962). In both cases, old paradigms can be tenacious, and perhaps hang
on longer than they should. Indeed, really major changes must often await a new generation of
scholars, with less human capital invested in the old paradigm. Thus Samuelson’s famous quip:
“funeral by funeral, economics does make progress” (Wilson 1998, p. 52). This happens in sciences
too: quantum mechanics took over physics not because many physicists changed their minds, but
because old physicists retired and young physicists found the new paradigm convincing (Kragh
2002). Evolution took even longer to become the central paradigm of biology (Larsen 2004).
Economic theories of monopoly, macroeconomics, and individual choice, to name but a few, have
undergone similar transformations, and some of these may well have required funerals, or at least
retirements, to take hold. History can sometimes help the upstarts, as e.g., with the economics of
multinational firms where historians show that US students of multinationals that European
2
 Even communist China has established stock markets. Their contribution towards that country’s further
development remains to be seen.

                                                    10
companies as far back into the nineteenth century had been enthusiastic multinational investors as
their US counterparts in the twentieth century. (Wilken 1970, 1974; Hertner and Jones 1986; Jones
2005; and others). Similarly, Chandler’s (1962) pioneering work on the importance of economies of
scale and scope dominated the field for a generation, but the data ultimately led Scranton (1997) to
showcases the persistent importance of specialized production, alongside mass production, in
propelling US industrialization in the late 19th and early 20th centuries. Chandler’s finding that US,
UK, German and Japanese firms progressed from family control to the stewardship of professional
managers likewise caused a generation of economists to view this as the baseline paradigm of
business everywhere. This too was qualified by historical work showing those four countries to be
atypical, and demonstrating that ongoing family-control over large business empires continues to be
the norm in most countries (Morck 2005). Yet another example is the broad influence of Ford’s
(1922) philosophy of management until business historians entered the debate (Tolliday and Zeitlin
1987).
          The credibility of each narrative depends not only on its ability to “connect the dots”
between past events, but also to explain new dots that arise from archaeological digs, previously
forgotten archives, and the unfolding of history from current events. These tests are not
econometric, but they are powerful nonetheless. Narratives that were once deeply compelling can
be cast aside when they fail to connect important dots. For example, the narrative of Western
colonialism civilizing the benighted savages of Africa and Asia could not connect the dots of two
World Wars, and is now itself an historical curiosity.
          The connecting of such dots can be every bit as painstaking as the careful assembly of a large
econometric database. For example, Engerman and Fogel (1974) assemble historical data on slaves
in the American south, and argue that their owners took good care of their property to maintain its
value, as economic theory would predict. A spirited dispute followed over the quality of their
historical data (Fogel 2003; Gutman 2003).
          A powerful example of historians connecting causal dots is Kindleberger’s (1978) historical
analysis of financial manias, panics, and crashes. Kindleberger sets out detailed histories of each
major financial crisis from the advent of modern stock markets in the early 1600s to the 1970s. He
distils from these histories a common trajectory that each crisis follows: an economic dislocation
that creates genuine economic profit opportunities, an inrush of capital to fund these, a popular
demand for deregulation to allow broader participation, a continued capital inflow after the profit
opportunities are exhausted, manic episodes of capital chasing illusory high returns from stock
markets to commodities to real estate, a crash, and a popular fury with financiers that usually
heralds tough new regulations – which persist until the next cycle. The neat obedience of all
subsequent financial crises to Kindleberger’s (1978) thesis enhances its credibility. Alternative
narratives based on stock market efficiency have fallen aside, and Kindleberger’s remains the
“narrative to beat”.

6.3     A Broad-Minded Consistency
History is a correspondence between individuals, generations, and eras, in which one writer cannot
easily ignore the scrawls of the others. The last point in particular contrasts starkly with economists’
precise attention to the internal consistency of every article, rather than external consistency
between studies. Above, we stressed that using a variable on both the left-hand side and right-hand
side of OLS regressions seriously bothers economists if done within an article; but not if a few pages
of references, a title, and an abstract intervene. This narrow-minded consistency is more than an
econometric problem.
         Our reading of the literature suggests that historians can be more broad-minded about
consistency. More respect for history would, we think, promote a long-overdue regard for external
consistency across studies in economics. Good historians connect the dots across broad patterns of
human endeavour. Even historians focused on a relatively narrow national or temporal band must



                                                  11
connect facts in geography to facts in politics, climate history, psychology, and (of course)
economics. This expanse of context is rare in economics.
         For example, development economics was long founded on the premise that poor countries
were basically like the United State, but poorer (Lal 2000). This perspective justified massive foreign
aid. When this effort succumbed to widespread corruption, attention turned to structural reforms
designed to make developing countries more like poor versions of the United States, so that future
aid initiatives might find better traction. This drastically oversimplifies a complicated field of
economics, but we believe the simplification captures something essential: a lack of concern for
external consistency.
         Historians studying the problem of persistent poverty provide more context, and this lets
them expose interesting patterns that can be checked for consistency across many similar historical
events. For example, Haber (1997), writing on Latin America, chronicles episodes of aborted
industrialization, and discerns a pattern: the region’s elites are enriched by industrialization, but fear
losing control should institutions ever develop fully. Haber et al (2008) and North et al. (2009) draw
from the histories of many countries to document patters that consistently distinguish
developmental successes stories from developmental failures.
         While such economic historians rely on econometric evidence where it is credible, their
narratives do not rely fundamentally on F-tests or likelihood ratios. Their claim to legitimacy is that
they start from detailed information-rich case studies, connect the dots to discern plausible patterns
of causality, and demonstrate a generality to these patterns by demonstrating a broader external
consistency with collected previous works.

6.4     Taking Free Will Seriously
Economics was deeply affected by the philosophy of causal determinism, which the natural sciences
embraced throughout the 19th century. That philosophy is most famously espoused by Laplace
(1814) thus,

       “We may regard the present state of the universe as the effect of its past and the
        cause of its future. An intellect which at a certain moment would know all forces that
        set nature in motion, and all positions of all items of which nature is composed, if
        this intellect were also vast enough to submit these data to analysis, it would
        embrace in a single formula the movements of the greatest bodies of the universe
        and those of the tiniest atom; for such an intellect nothing would be uncertain and
        the future just like the past would be present before its eyes.”

For this intellect, dubbed “Laplace’s demon”, every event is a cog in a mechanical chain stretching
back to the beginning of the universe.
         The neoclassical synthesis of the 1870s, which still largely defines microeconomic theory,
drew heavily from the physics of the time (Mirowski 1991) and presents human beings as part of this
cosmos. Human beings are causally deterministic utility maximizing machines, whose decisions are
fully determined by their predefined preferences and budget constraints, which are fully determined
by a mechanical chain stretching back into the depths of time. In such a world, causation is both
simple and uninteresting, for nothing is exogenous except the prime mover who set the clockwork
moving eons ago. Yet, this analytical framework came to guide causal interpretations of inputs,
changes, and outputs in the econometrics of the Age of Data.
         In truth, economists have never really accepted causal determinism. Even the most
committed neo-classicists contemplate exogenous interventions: Acts of God, and even policy
changes, that somehow originate outside such rows of dominos, and that send deterministic rows of
utility maximizing human decisions toppling down alternative paths.
         Physics long ago abandoned causal determinism; indeed, quantum mechanics left it no
choice by adding intrinsic uncertainty to time and space. This, in turn, freed philosophy to


                                                   12
contemplate human free will. Economics hardly noticed these changes. Yet if free will exists, human
decisions must be exogenous in the deepest philosophical meaning of the term, and the origins of all
economically interesting causal chains of events.
        Historians have long argued about the importance of individuals, as opposed to
deterministic forces. If free will matters, individuals are important. The cognitive processes,
emotions, compulsions, and desires within human decision makers are the ultimate causes of the
phenomena economists study.
        History records autobiographical and biographical information that can tell us what people
were thinking, worried about, or pursuing when they did what they did. Perhaps economists might
investigate these records to see what they reveal about what caused key decision makers to decide
as they did. Fundamental advances in understanding phenomena like entrepreneurship can emerge
from ascertaining the constraints, knowledge, motives, and cognitive processes of key decision-
makers (Casson 1993; Casson et al. 2005).
        Cognitive dissonance and other behavioural biases surely cause people to misremember
such things ex post, and even to lie about them deliberately. But the historical record contains real
time archives that can occasionally reveal the sometimes uncomplimentary motives that caused
particular chains of events to unfold. Of course, archives can be biased, deliberately manipulated, or
released selectively, and careful business historians are alert for this; but archives can also upend
aged decision-makers sanitized accounts (Cox and Wallace 2002).

7.      Conclusion
We conclude that Black’s critique of econometrics, his entirely reasonable argument that correlation
is not causation, may well have been taken too seriously by economists. As Tufte (2003) equally
reasonably points out, "Correlation is not causation but it sure is a hint." More precisely, correlation
is a necessary, but not sufficient, condition for causation. This makes tests for correlations in
economic data important. Econometric tests for causality may well be much less useful, for they can
often be extraordinarily difficult to do well. The progress of economics may well be better served by
careful and reliable tests for correlations than by flawed tests asserting or denying causality
         How then can economists ascertain what causes what? Here we conclude economists might
make better use of history. History is far more than a tool shed for instrumental variables. History is
filled out with nuances that contextualize events. History is composed of competing narratives that
must “connect the dots” or lose credibility. History records autobiographical and biographical
information that can tell us what people were thinking, worried about, or pursuing when they did
what they did. History is a correspondence between individuals, generations, and eras, in which one
writer cannot easily ignore the scrawls of the others.
         Popper (1934), and especially Lakatos (1976), argue that science progresses by the
successive falsification of whole theories, not individual hypotheses. This is why a broader respect
for external consistency is needed if economics is ever to gain acceptance as a science. This is also
why economics must come to grips with the fact that its observations are usually context-
dependent. Statistical tests for causality are obviously useful once a theory has been enunciated,
but contextualized observation is more often the source of the broad pictures and frameworks that
coalesce into the theories we test – in science (Feyerabend 1975) and economics (Khanna and Jones
2006). Indeed, Adam Smith (1976) built his theories, arguably the basis of the whole of modern
economics, around detailed qualitative observations of the workings of a pin factory.
         Econometrics has served economists well, and continues to do so. But it cannot answer
every question, and has especially intractable problems with many questions of causation. We do
not call for any unwinding of past work; but for a reinvestment in history so that the complimentary
relationship between statistical analysis and historical investigation we describe above can step in
where econometrics falters.
         There is a natural complementary that benefits both economists and historians; but we (as
rational and self-interested economists) perceive primarily the benefits to our field. Economics as a

                                                  13
discipline has standardized a powerful methodology, which may indeed be useful in other fields
(Lazear 2000; Lamoreaux, Raff, and Temin 2007). Relying on theories of constrained optimization
and equilibrium, tempered by behavioural regularities and the availability of information, economics
builds empirically falsifiable statements and guides the collection and interpretation of historical
information. Some of these statements are readily amenable to econometric tests, but others –
especially those about one thing causing another – are more difficult to test. We argue that
economists can in turn look to history for help here. Economists already make use of repetitions of
history in the forms of event studies and Granger causality tests. But economists might also gain
insights about causality by attending to details of context, weighing the plausibility of competing
narratives, assessing external consistency, and studying the constraints, motives, and recollections
of key decision-makers – either directly or through archives. All of these methodologies surely also
have their problems too. But we believe them to be lesser than the difficulties inherent in using
instrumental variables methods to assess causation in many important settings.


References
Acemoglu, Daron, Simon Johnson and James Robinson 2001, “The Colonial Origins of Comparative
          Development: An Empirical Investigation,” The American Economic Review, Vol. 91, No. 5, December,
          1369-1401.
Acemoglu, Daron, Simon Johnson and James Robinson , 2005, A Response to Albouy’s “A Reexamination Based
          on Improved Settler Mortality Data,” mimeo, (March).
Acemoglu, Daron, Simon Johnson and James Robinson. 2006. Reply to the Revised (May 2006) version of David
          Albouy’s “The Colonial Origins of Comparative Development: An Investigation of the Settler Mortality
          Data.”
Albouy, David. 2008. The Colonial Origins of Comparative Development: An Investigation of the Settler
          Mortality Data. National Bureau of Economic Research working paper #14130.
Banerjee, Abhijit and Lakshmi Iver. 2010. Colonial land tenure, electoral competition and public goods in India.
          In Jared Diamond and James A. Robinson, eds. Natural Experiments of History. Harvard University
          Press, Cambridge MA, c. 6.
Black, Fischer. 1982. The Trouble with Econometric Models. Financial Analysts Journal 38(2)29-37.
Buchanan, James. 2003. Public Choice: The Origins & Development of a Research Program. Center for the
          Study of Public Choice at George Mason University.
Caballero, Ricardo. 2010. Macroeconomics after the Crisis: Time to Deal with the Pretence-of-Knowledge
          Syndrome. MIT Department of Economics Working Paper No. 10-16
Camerer, Colin. 2010. Behavioral Game Theory: Experiments in Strategic Interaction. Princeton University
          Press.
Campbell, John, Andrew Lo and A. Craig MacKinlay. 1997. The Econometrics of Financial Markets. Princeton
          University Press.
Casson, Mark, Bernard Yeung, Anuradha Basu, and Nigel Wadeson, eds. 2006. Oxford Handbook of
          Entrepreneurship, Oxford University Press, Oxford: England.
Casson, Mark. 1993. Entrepreneurship in D. R. Henderson (ed). The Fortune Encyclopaedia of Economics, New
          York: Warner Book.
Chandler, Alfred D. 1962. Strategy and Structure, MIT Press: Cambridge, MA.
Cox, Richard and David Wallace, eds.2002. Archives and the Public Good: Accountability and Records in
          Modern Society. Westport CT: Quorum Books.
Deaton, Angus. 2010. Instruments, Randomization, and Learning about Development, Journal of Economic
          Literature, 48 (June) 424-455.
Derrida, Jacques. 1967. De la Grammatologie. Paris: Les Éditions de Minuit
Diamond, Jared and James A. Robinson, eds. 2010, Natural Experiments of History, Harvard University Press,
          Cambridge MA.
Diebold, Francis. 1998. The Past, Present & Future of Macroeconomic Forecasting. Journal of Economic
          Perspectives 12(2)175-192.
Edgeworth, Francis. 1881. Mathematical psychics: an essay on the application of mathematics to the moral
          sciences. C. Keegan, Paul & Co. London.


                                                      14
Engerman, Stanley and Robert Fogel. 1974. Time on the Cross: The Economics of American Negro Slavery.
          Boston: Littel Brown & Co.
Feldstein, Martin. 2009. Rethinking the Role of Fiscal Policy. American Economic Review 99(2)556-59.
Feyerabend, Paul. 1975. Against Method: Outline of an Anarchistic Theory of Knowledge. London: NLB.
Fogel, Robert. 2003. The Slavery Debates, 1952-1990: A Retrospective . Baton Rouge: Louisiana State
          University Press.
Fohlin, Caroline, 2005. The History of Corporate Ownership & Control in Germany. In: Morck RK (ed.) A History
          of Corporate Governance around the World: Family Business Groups to Professional Managers.
          University of Chicago Press, pp. 223-277.
Ford, Henry (with Samuel Crowther). 1922. My Life and Work. Garden City NY: Garden City Publishing.
Godley, Andrew, 2001. Jewish Immigrant Entrepreneurship in New York and London 1880-1914: Enterprise
          and Culture. Palgrave Macmillan, 2001.
Granger, Clive. 1969. Investigating causal relations by econometric models & cross-spectral methods.
          Econometrica 37, 424-438.
Gutman, Herbert. 2003. Slavery and the Numbers Game: A Critique of 'Time on the Cross. Champaign IL:
          University of Illinois Press.
Haber, Stephen H. 2010. Politics Banking, and economic Development: Evidence from New World Economies.
          In Diamond, Jared and James A. Robinson, eds. Natural Experiments of History, Harvard University
          Press, Cambridge MA, c. 3.
Haber, Stephen H., 1997. How Latin America fell behind: essays on the economic histories of Brazil & Mexico,
          1800-1914. Stanford University Press.
Haber, Stephen, Douglass North & Barry Weingast. 2008. Political institutions & financial development.
          Stanford University Press.
Hardin, Garrett. 1968. The Tragedy of the Commons. Science 162(3859)1243 – 1248.
Hertner, Peter., and Geoffrey Jones, 1986., Multinationals: Theory and History. Gower Publishing Company
          Ltd., Hauts: England.Henry, Peter, and Conrad Miller, 2009, Institutions versus Policies: A Tale of Two
          Islands American Economic Review: Papers & Proceedings, 99:2, 261–267
Jones, Geoffrey and Tarun Khanna, 2006, Bringing History (back) into International Business, Journal of
          International Business Studies, vol. 37. Pp. 453-468.
Jones, Geoffrey, 2005. Multinationals and Global Capitalism, frm the Nineteenth to the Twenty First Century,
          Oxford University Press
Kindleberger, Charles, 1978. Manias, Panics & Crashes. Basic Books, New York.
Kragh,Helge. 2002. Quantum generations: A history of physics in the twentieth century. Princeton University
          Press.
Krugman, Paul. 2007. The Conscience of a Liberal. W.W. Norton & Co.
Kuhn, Thomas. 1962. The Structure of Scientific Revolutions. University of Chicago Press.
Lal, Deepak. The Poverty of "Development Economics”. MIT Press.
Lamoreaux, Naomi R., Daniel M. G. Raff, and Peter Temin. 2007. Economic Theory and Business History, Ch. 3,
          The Oxford Handbook of Business History, Geoffrey Jones and Jonathan Zeitlin, eds., Oxford University
          Press, Oxford UK.
Laplace, Pierre-Simon. 1814. Essai philosophique sur les probabilities. (Frederick Truscott & Frederick Emory,
          trans. 1951. A Philosophical Essay on Probabilities, Dover).
Larson, Edward. 2004. Evolution: The Remarkable History of a Scientific Theory. Random House Modern
          Library.
Latsis, Spiro, ed. Method and Appraisal in Economics. Cambridge University Press.
Lazear, Edward, 2000.Economic Imperialism. Quarterly Journal of Economics, February, 99-146.
Levy, David & Sandra Peart. 2009. Soviet Growth & American Textbooks. Economics Dept., George Mason
          University working paper.
McClosky, Dierdre. 1985. The Rhetoric of Economics. University of Wisconsin Press.
McLuhan, Marshall. 1962. The Gutenberg Galaxy : The Making of Typographic man. University of Toronto
          Press.
Michie, Ranald. 2008. The Global Securities Market: A History. Oxford University Press.
Mirowski, Philip. 1991. More Heat than Light: Economics as Social Physics, Physics as Nature's Economics.
          Cambridge University Press.
Morck, Randall & Masao Nakamura. 2007. Business Groups & the Big Push: Meiji Japan's Mass Privatization &
          Subsequent Growth. Enterprise & Society 8 3, 543-601


                                                       15
Morck, Randall, and Bernard Yeung, 2007. History in perspective: comment on Jones and Khanna ‘Bringing
           history (back) into international business, Journal of International Business Studies, 38 357-360.
Morck, Randall, ed. 2005. A History of Corporate Governance around the World: Family Business Groups to
           Professional Managers. University of Chicago Press.
Muth, John. 1961. Rational Expectations & the Theory of Price Movements. Econometrica 29 315–35
Nelson, C. R. 1972.The Prediction Performance of the F.R.B.-M.I.T.-Penn Model of the U.S. Economy. American
           Economic Review 62 902-17.
North, Douglass, John Wallis & Barry Weingast.2009. Violence & Social Orders. Cambridge University Press.
Popper, Carl. 1934. Logik der Forschung. Vienna: Springer.
Rajan, Raghuram & Luigi Zingales. 2003. The Great Reversals: The Politics of Financial Development in the
           Twentieth Century. Journal of Financial Economics 69 1, 5-50.
Rajan, Raghuram & Luigi Zingales. 2004. Saving capitalism from the capitalists. Princeton University Press.
Roll, Richard, 1988. R-Squared. Journal of Finance 43 3, 541-66.
Sachs, Jeffrey. 2005. The End of Poverty: Economic Possibilities for Our Time. New York: Penguin.
Samuelson, Paul. 1948-1980. Economics: An Introductory Analysis. New York. McGraw-Hill.
Scranton, Philip. 1997. Endless Novelty: Specialty Production and American Industrialization, 1865 – 1925.
           Princeton University Press: Princeton, New Jersey.
Smith, Adam. 1776. An inquiry into the nature and causes of the wealth of nations. London: Strahan & Cadell.
Stiglitz, Joseph. 2006. Making Globalization Work. W.W. Norton & Co.
                                                                        nd
Stock, James & Mark Watson. 2010. Introduction to Econometrics, 2 ed. Addison Wesley.
Summers, Lawrence & Robert Stambaugh. 1986. The Does the Stock Market Rationally Reflect Fundamental
           Values. Journal of Finance 41(3) 591-603.
Tobin, James. 1970. Money & Income: Post Hoc Ergo Propter Hoc? Quarterly Journal of Economics 84(2)301-
           17.
Tolliday, Steven and Jonathan Zeitlin, eds. 1987. The Automobile Industry and Its Workers: Between Fordism
           and Flexibility Comparative analysis of developments in Europe, Asia, and the United States from the
           late 19th century to the mid-1980s. St. Martin's Press, New York.
Tufte, Edward. 2003. The Cognitive Style of PowerPoint. Graphics Press.
Weimer, David. 1986. Collective delusion in the social sciences: Publishing incentives for empirical abuse.
           Review of Policy Research 5(4) 705–8.
Wiener, Norbert. 1956 The theory of prediction. In. E. F. Beckenbach, ed. Modern Mathematics for Engineers I.
           New York: McGraw-Hill.
Wilkins, Mira. 1970. The Emergence of Multinational Enterprise. Cambridge, MA: Harvard University Press.
Edward O. Wilson. 1998. Consilience: the Unity of Knowledge.




                                                      16
