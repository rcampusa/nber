                                NBER WORKING PAPER SERIES




    MEASURING THE LABOR MARKET AT THE ONSET OF THE COVID-19 CRISIS

                                         Alexander W. Bartik
                                          Marianne Bertrand
                                              Feng Lin
                                           Jesse Rothstein
                                             Matt Unrath

                                        Working Paper 27613
                                http://www.nber.org/papers/w27613


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                       July 2020




Prepared for the Brookings Papers on Economic Activity conference on June 25, 2020. We thank
Justin Germain, Nicolas Ghio, Maggie Li, Salma Nassar, Greg Saldutte and Manal Saleh for
excellent research assistance. We are grateful to Homebase (joinHomebase.com), and particularly
Ray Sandza and Andrew Vogeley, for generously providing data. We also thank David
Gilbertson for tabulations of Kronos data. Caroline Buckee and Victor Chernozhukov provided
extremely valuable comments as discussants. We thank Lucas Finamor for pointing out a coding
error in an early version of these analyses. The views expressed herein are those of the authors
and do not necessarily reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2020 by Alexander W. Bartik, Marianne Bertrand, Feng Lin, Jesse Rothstein, and Matt Unrath.
All rights reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit
permission provided that full credit, including © notice, is given to the source.
Measuring the labor market at the onset of the COVID-19 crisis
Alexander W. Bartik, Marianne Bertrand, Feng Lin, Jesse Rothstein, and Matt Unrath
NBER Working Paper No. 27613
July 2020
JEL No. E24,E32,J2,J63

                                           ABSTRACT

We use traditional and non-traditional data to measure the collapse and partial recovery of the
U.S. labor market from March to early July, contrast this downturn to previous recessions, and
provide preliminary evidence on the effects of the policy response. For hourly workers at both
small and large businesses, nearly all of the decline in employment occurred between March 14
and 28. It was driven by low-wage services, particularly the retail and leisure and hospitality
sectors. A large share of the job losses in small businesses reflected firms that closed entirely,
though many subsequently reopened. Firms that were already unhealthy were more likely to close
and less likely to reopen, and disadvantaged workers were more likely to be laid off and less
likely to return. Most laid off workers expected to be recalled, and this was predictive of rehiring.
Shelter-in-place orders drove only a small share of job losses. Last, states that received more
small business loans from the Paycheck Protection Program and states with more generous
unemployment insurance benefits had milder declines and faster recoveries. We find no evidence
that high UI replacement rates drove job losses or slowed rehiring.

Alexander W. Bartik                                 Jesse Rothstein
University of Illinois at Urbana-Champaign          Goldman School of Public Policy and
1407 W. Gregory Road                                 Department of Economics
214 David Kinley Hall                               University of California, Berkeley
Urbana, IL 61821                                    2607 Hearst Avenue #7320
abartik@illinois.edu                                Berkeley, CA 94720-7320
                                                    and NBER
Marianne Bertrand                                   rothstein@berkeley.edu
Booth School of Business
University of Chicago                               Matt Unrath
5807 South Woodlawn Avenue                          Goldman School of Public Policy
Chicago, IL 60637                                   University of California, Berkeley
and NBER                                            2607 Hearst Avenue #7320
marianne.bertrand@chicagobooth.edu                  Berkeley, CA 94270-7320
                                                    unrath@berkeley.edu
Feng Lin
University of Chicago
1126 E. 59th Street
Chicago, IL 60637
fenglin2@uchicago.edu



Ongoing data updates are available at:
https://irle.berkeley.edu/labor-market-impacts-of-covid-19-on-hourly-workers-in-small-and-medium-sized-
businesses-four-facts-from-homebase-data-2/
Introduction

        The COVID-19 pandemic hit the U.S. labor market with astonishing speed. The week
ending March 14, 2020, there were 250,000 initial unemployment insurance claims -- about 20%
more than the prior week, but still below January levels. Two weeks later, there were over 6 million
claims. This shattered the pre-2020 record of 1.07 million, set in January 1982. At this writing,
claims have been above one million for seventeen consecutive weeks, cumulating to nearly 50
million. The unemployment rate shot up from 3.5 percent in February to 14.7 percent in April, and
the number of people at work fell by 25 million.
        The United States’ labor market information systems are not set up to track changes this
rapid. 3 The primary official measures of the state of the labor market are two monthly surveys, the
Current Population Survey (CPS) of households and the Current Employment Statistics (CES)
survey of employers. Each collects data about the second week of the month. In 2020, an enormous
amount changed between the second week of March and the second week of April.
        In this paper, we attempt to describe the labor market in what may turn out to be the early
part of the COVID-19 recession, compare the labor market downturn to previous recessions, and
provide some evidence on the policies enacted in response to the downturn. We combine data from
the traditional government surveys with non-traditional data sources, particularly daily work
records compiled by Homebase, a private sector firm that provides time clocks and scheduling
software to mostly small businesses. We link the Homebase work records to a survey answered by
a subsample of Homebase employees. We supplement the Homebase data with data on firms with
more than 100 employees from Kronos, another private sector firm providing time clock,
scheduling, and other services. We use the Homebase and Kronos data to measure the high-
frequency timing of the March-April contraction and the gradual April-early July recovery. We
use CPS and Homebase data to characterize the workers and businesses most affected by the crisis.
And we use Homebase data as well as data on physical mobility from SafeGraph, based on
electronic tracking of mobile phones, to measure the effects of state shelter-in-place orders and




3
  In response to the limitations of traditional data sources, the Census Bureau started Household Pulse and Business
Pulse surveys to provide higher frequency data on changes in the labor market and for small businesses. These surveys
provide very useful information, but only started on April 23rd and 27th respectively.




                                                                                                                   1
other policies (in particular, the Paycheck Protection Program and unemployment insurance
generosity) on employment patterns from March to early July.
       We are not the only ones studying the labor market at this time. Allcott et al. (2020), Alon
et al. (2020), Cajner, et al (2020a [this volume]; 2020b), Chetty et al. (2020), Cortes and Forsythe
(2020), Dey et al. (2020), Goolsbee and Syverson (2020), Gupta et al. (2020), Khan et al. (2020),
Kurmann et al. (2020), Lin and Meissner (2020), and Mongey et al. (2020) all conduct exercises
that are related to ours. There are surely many others that we do not cite here. Our goal is neither
to be definitive nor unique, but merely to establish basic stylized facts that can inform the policy
response to, and future research on, the crisis.
       The paper proceeds as follows. Section I describes our data sources. Section II provides an
overview of the labor market collapse and subsequent partial recovery. In Section III, we explore
who was affected by the collapse, investigating characteristics of workers that predict being laid
off in March and April, then being reemployed thereafter. Section IV uses event study models to
examine the effects of non-pharmaceutical interventions (i.e., shelter-in-place and stay-at-home
orders) on hours worked in the Homebase data and on physical mobility. Section V examines the
impacts of the roll-out of unemployment insurance expansions at the state level and of the
Paycheck Protection Program on Homebase hours. We conclude in Section VI.

Section I. Data

       We rely on three primary sources to measure the evolution of the labor market during the
first half of 2020, supplementing with additional measures that provide context.
       First, we use the Current Employment Statistics (CES) survey of employers, the source of
official employment counts, to track industry-level employment changes at a monthly frequency.
Second, we use the Current Population Survey (CPS), a monthly survey of about 60,000
households that is the source of the official unemployment rate. Respondents are asked each month
about their activities during the week containing the 12th of the month. The most recent available
data are from the June survey. By matching interviews with the same households in consecutive
months, we identify workers who were employed in March but not in April, or who were out of
work in April or May but re-employed in May or June.
       We combine these official data sources with daily data from a private firm, Homebase,
which provides scheduling and time clock software to tens of thousands of small businesses that




                                                                                                  2
employ hundreds of thousands of workers across the U.S. and Canada. The time clock component
of the Homebase software measures the exact hours worked each day for each hourly employee at
the client firms. Employers are identified by their industry and location.
           Homebase’s customers are primarily small firms in food and drink, retail, and other sectors
that employ hourly workers (see Appendix A). The time clock data largely cover hourly workers
within those firms. The Homebase subpopulation is highly relevant to the current moment, as the
pandemic seems to have most affected the industries and small businesses that form the Homebase
clientele. Indeed, we show that the employment collapse was much more dramatic in the
Homebase sample than in the labor market as a whole.
           When analyzing the Homebase data, we focus on U.S.-based firms that were already
Homebase clients before the onset of the pandemic. We define a base period as the two weeks
from January 19 to February 1, and scale hours in subsequent weeks as a fraction of hours worked
during this period. 4 We consider a firm to have shut down if in any week (Sunday-Saturday) it had
zero hours reported by all of its hourly workers, and to have reopened if, following a shut down,
it again appears with positive hours.
           We supplement the Homebase data with information from a survey of workers. Survey
invitations were sent starting May 1 to everyone who had signed into the Homebase software as a
user since February 2020. We use survey responses received by July 7, matched to the
administrative records for the same workers, and we limit to workers with positive hours in the
base period and only one Homebase client employer since January 19, 2020. Among the roughly
430,000 workers meeting this description, approximately 1,700 (0.4%) responded to our survey.
Despite the low response rate, Appendix Table B1 shows that the survey respondents are roughly
representative of all Homebase workers on the (limited set of) dimensions on which we can
compare them. However, survey respondents are somewhat positively selected on hours worked
at the Homebase employer (Appendix Figure B1) and hence may be more representative of the
“regular” workforce at these employers. Appendix Table B2 summarizes demographic
characteristics for survey respondents.




4
    We exclude from all analyses any individual daily observations with more than 20 reported hours.




                                                                                                       3
Section II. Overview of the Labor Market Collapse

         Between February and April 2020, the unemployment rate (not seasonally adjusted) spiked
by 10.6 percentage points, reaching 14.4%, while the employment rate fell by over 9 percentage
points. These two-month changes were roughly 50% larger than the cumulative changes over more
than two years in the respective series in the Great Recession. In sharp contrast to past recessions,
the February-April unemployment increase was entirely driven by increases in the share of workers
who expected to be recalled to their former positions; the share who were looking for new jobs
shrunk slightly. The temporary layoff share of the unemployed has never previously exceeded 30
percent, but rose to nearly 80 percent in April. 5 Employment and unemployment recovered a small
amount in May, but remain in unprecedented territory.
         The usual labor market categories are not well suited to pandemic conditions, and the
official unemployment rate has understated the amount of joblessness. The share who were
employed but not at work grew by 3.3 percentage points. The Bureau of Labor Statistics believes
much or all of this increase derives from misclassification of people who should have been counted
as on temporary layoff; if they had been classified that way, the unemployment rate in April would
have been 19.2% instead of 14.4% (BLS 2020c). Similarly, labor force non-participation rose, with
many of the new non-participants saying that they wanted jobs but were not actively looking for
work or were not available to take jobs. It seems likely that many of these were kept out of work
by the pandemic and would otherwise have been counted as unemployed. If they had been included
as well, the adjusted unemployment rate would have been well above 20%.
         Monthly statistics are inadequate to understanding the rapidity of the labor market collapse.
Figure 1 plots daily total hours worked at Homebase’s client firms. We also plot three lower-
frequency comparisons: weekly counts of shifts worked by hourly workers at larger firms (>100
employees) as measured in data collected by Kronos, another similar firm that serves larger
employers; payroll employment from the CES; and monthly household employment from the CPS.




5
  Hedin, Schnorr, and von Wachter (2020) use administrative records from the California unemployment insurance
system to explore the characteristics of unemployment insurance applicants. They find that over 90% of new claimants
in late March reported that they expected to be recalled to their prior jobs, up from around 40% in February. The share
expecting recalls gradually declined after late March, to around 70% at the end of May, but this nevertheless indicates
that many of the job losses may not be permanent, and is consistent with the increase in temporary layoffs measured
by the CPS.




                                                                                                                     4
In all four series, we report employment measures relative to a base period in late January. 6 Total
hours worked at Homebase firms fell by approximately 60% between the beginning and end of
March, with the bulk of this decline in the second and third weeks of that month. The nadir seems
to have been around the second week of April. Hours then grew slowly and steadily through mid
June. They made up about half of the lost ground by the third week of June, but then fell back
again slightly in late June and early July. 7
         The time pattern for larger firms in the Kronos data is more muted but quite similar in
shape. The most rapid decline in employment occurred in the last two weeks of March, the nadir
of employment occurred in the second week of April, and firms recovered a little more than 50%
of their employment losses by the third week of June. The lower-frequency CES and CPS data are
also consistent with these patterns, with the employment trough in April in both series and a
roughly 50 percent recovery by June. The most notable difference between the series is the
magnitude of the overall employment decline, around 18 percent in the CES and CPS, 35 percent
in the Kronos sample, and 60 percent in the Homebase data. As we discuss below, this likely
reflects a combination of differences in industry coverage and firm size, with the smaller firms in
food, drink, and retail that are the bulk of Homebase clients experiencing the most severe
employment declines during this downturn.

Section III. Who Are the Unemployed? Who Are the Rehired?

In this section we explore the distribution of the job losses across industries, firms, and workers.

Subsection III.A. Industry

         Figure 2 uses CES data to show the two-month decline in employment from February to
April, by major industry. The service sector, and particularly its low-wage segment, experienced
by far the largest drop in employment. In leisure and hospitality, which includes restaurants and
hotels, employment fell by nearly half between February and April. Other services, which include
repair and maintenance services, personal and laundry services, and services to private households,



6
  The base period is January 19-February 1 in the Homebase data, January 20-February 2 in the Kronos data, and
January in the CES and CPS data.
7
  There are clear day-of-week effects in the Homebase data as well: Homebase employment is lower on weekends
than on weekdays since the onset of the crisis, relative to the day-of-week pattern in the base period. These reductions
are largest in the holiday weeks of Easter, Memorial Day, and the Fourth of July.




                                                                                                                      5
were the second most impacted, with more than 20% of employment lost by April. Workers
employed in retail trade were also disproportionately exposed. 8
         Figure 2 also shows the cumulative decline in employment between November 2007 and
January 2010. Job loss in 2020 was about 50% larger than in the whole of the Great Recession,
and the sectoral composition was quite different. Construction and durable goods manufacturing
declined the most in the Great Recession, while low-wage services were relatively insulated.

Subsection III.B. Firm Closings and Reopenings

         An advantage of Homebase data over the CPS, beyond its high frequency, is that it enables
us to link workers to their employers. We use this link to separate the observed change in total
hours into three channels: firm shutdowns, layoffs, and cuts in hours. We define a firm as having
fully shut down in a given week if the Homebase data records zero employees clocking in at that
firm during that week. Among firms that have not shut down, we count layoffs as the proportional
change in the number of workers with positive hours in a week, relative to the baseline. Last, we
define hours cuts as the reduction in average hours, relative to the baseline period, among workers
remaining employed at still operating firms. 9
         Figure 3 reports the percent change in hours each week since early February attributable to
these three channels. Except for the first week of the labor market collapse, 10 reductions in hours
per worker as defined above have accounted for a very minor part of the change in total hours at
Homebase businesses. Instead, the decline in total hours came primarily from firms that closed
entirely and from reductions in the number of workers at continuing firms. Layoffs accounted for
a larger share in March and shutdowns in April, but thereafter the two have had about the same
quantitative impact on “missing hours.” 11



8
  Appendix Figure C1 shows monthly changes in 2020. Consistent with Figure 1, employment recovered somewhat
in May and June, with the recovery concentrated in the same sectors that saw the largest declines.
9
  Some firms that appear to us to have shut down may have retained some non-hourly workers who do not use the
Homebase software to track their time, so should properly be classified as layoffs at continuing firms.
10
   We conjecture that the large role for hours reductions in this week is an artifact created by mid-week layoffs or firm
closings. When workers stop working in the middle of a week, our method counts that as a reduction in weekly hours
that week and as a layoff or firm closing the following week. Consistent with this, Appendix Figure C4 shows that the
distribution of workers’ hours fell that week but returned to normal the following week and has been quite stable
through the year to date.
11
   Appendix Figure C5 shows firm exits using a stricter definition that counts firms as exiting only if they do not
return by mid-July. In 2018 and 2019, about 2 percent of firms exited Homebase each month. In March 2020, about
15 percent exited. After early April, the exit rate was similar to prior years.




                                                                                                                       6
       We next use the Homebase data to assess the role of firm reopenings in the (partial)
recovery. Of the roughly 42,000 unique firms in our baseline sample, about half shut down for at
least one week by April 4. About 70 percent of these firms have reopened for at least a week after
that date (though 10 percent have since closed again). In Appendix Figure C2, we report the
distribution of hours at ever-closed businesses through July 11, as a share of total baseline hours
at these businesses. In the most recent week, total hours at these firms remain close to 60 percent
below their baseline level. About two-thirds of these missing hours are attributable to businesses
that remain closed; the remainder reflects businesses that have reopened at a reduced scale. Of the
roughly 40 percent of hours that have been regained, a vast majority has come from rehiring of
workers that had been employed by the business prior to the shutdown. However, the share
attributable to new hires has been slowly trending up over time, reaching almost a quarter by the
week of July 5-11. It is worth noting that Homebase firms have high turnover rates even in good
times; in fact, the share of hours being worked by new hires is lower in 2020 than over similar
periods in 2018 and 2019 (see Appendix Figure C3).
       The Homebase data also allow us to investigate which businesses were more likely to shut
down as well as take an early look into which firms are most likely to make it through the crisis.
We consider two employer characteristics: size, defined as the employer’s total number of unique
employees in the Jan 19-Feb 1 base period, and growth rate, which we define as the change in the
number of employees between January 2019 and January 2020 divided by the average of the
beginning and end-point levels, a ratio that is bounded between -2 and 2.
       Figure 4 reports marginal effects from logit models for the likelihood of the firm shutting
down by April 4, and, for firms that did, for the likelihood of re-opening by July 11, controlling
for state and industry fixed effects. Larger firms were much less likely to shut down than smaller
firms. Conditional on having shut down, larger firms are also somewhat more likely to have re-
opened by mid July, though this is not statistically significant. Most interesting is how the
likelihood of shutting down and re-opening is predicted by employer growth between January
2019 and January 2020. Businesses that were struggling pre-COVID have much increased odds of
shutting down during the COVID crisis and of remaining closed. Three non-mutually exclusive
explanations are that these businesses might have been particularly low on cash and unable to
withstand the shock (Bartik et al., 2020); that they may have been de-prioritized by banks when




                                                                                                 7
they applied for PPP funding; or that the COVID crisis sped up the pruning of some of less
productive businesses in the economy (Barrera, Bloom, and Davis, 2020).

Subsection III.C. Worker-Level Job Loss and Re-Hiring

       We next explore which workers are most likely to lose their jobs and subsequently be
rehired, using both CPS and Homebase data. We estimate multivariate logit models that include a
range of worker characteristics as predictors, along with fixed effects for states and major industry
groupings. Our first model, in columns 1-2 of Table 1, includes all CPS respondents who worked
in March and takes as the outcome the absence of work in April, while the second, in columns 3-
4, is estimated on those not working in April and May and takes work in the following month as
the outcome of interest.
       The analysis reveals systematic differences across socio-demographic groups in the
likelihood of having stopped work in April. We see a strong U-shaped pattern in age for job loss.
Workers who are over 65 years old (or 16 to 25, respectively) were 14 (8) percentage points more
likely to exit work in April than otherwise similar workers aged 26-37. There is also a strong
education gradient: Workers without high school degrees were 11 percentage points more likely
to have stopped working in April than otherwise similar college graduates. Black, Asian, and
Hispanic workers were, respectively, 4.8, 5.4, and 1.7 percentage points more likely to exit work
in April than otherwise similar white workers. Finally, married individuals were less likely to lose
jobs and women were more likely to do so. We do not observe systematic differences based on
parental status, for either men or women.
       These inequities in the distribution of job loss were for the most part not offset by re-hiring
in May or June. In particular, older workers, Black and Asian workers, single workers, and women,
each more likely to lose their jobs in April, were also less likely to start work again in May or June.
On the other hand, there is no clear education gradient in re-hiring.
       The remaining columns of Table 1 repeat the analyses of job loss and rehiring, now using
the Homebase data. We link the administrative records on hours worked to the worker survey,
which provides demographic information. We define layoff and rehiring somewhat differently,
thanks to the higher frequency data: a worker is counted as leaving work if he or she worked in
the base period in January but had at least one week with zero hours between March 8 and April
25; then, for these workers, we classify as re-hired those who returned to work and recorded
positive hours at some point after April 18. Note that we do not distinguish in these definitions



                                                                                                     8
between firms that closed entirely and workers who were laid off from continuing firms, nor
similarly between re-hires at reopening vs. continuing firms.
       Perhaps unsurprisingly, given the small sample size, few of the estimated effects are
statistically significant. However, a few patterns emerge. We see a much higher likelihood of
layoff among those without a high school degree and much lower likelihood among those in
managerial positions. We also see that workers with children were relatively spared from layoffs.
In addition, while Hispanic workers are less likely to be laid off, we also see that, as in the CPS
data, Black workers are notably less likely to be rehired.
       The survey data we collected also allow us to understand more fully the experiences and
expectations of the Homebase workers. Twenty-one percent of the sample reported having
experienced a layoff because of COVID, while 31 percent report having been furloughed and 21
percent report hours reductions. Less than 10 percent report having made a decision to not work
or work less, with most of those saying it was to protect themselves or their family members from
exposure to the virus. Less than 10 percent of the workers whose hours and employment status
were negatively impacted by COVID report being paid for any of the hours that they are not
working. Among these negatively impacted workers, nearly 60 percent report that their employers
encouraged them to file for unemployment insurance. This was notably higher (77%) among laid-
off workers than among furloughed workers (66%) or workers who experienced reduced hours
(35%). Fifty-two percent of workers that have been laid off report that their employer has
expressed a desire to hire them back. Among workers that have been negatively impacted by
COVID, only about a quarter report looking for work. The modal reason for not searching is an
expectation of being rehired; only 7 percent attribute their lack of job search to financial
disincentives to work. Among the people that expected to be rehired (when the surveys were
conducted, largely in early May), the modal expected rehire date was June 1 (33 percent), followed
by July 1 (26 percent).
       Respondents were also asked if they would return to their employer if offered the
opportunity. Three quarters of respondents said they would go back. Job satisfaction is an
important correlate of this response. For example, 80% of workers who strongly agreed with the
statement “I liked my manager” would plan to go back if asked, compared with 67% who only
somewhat agreed with this statement. Also, 89% of workers who strongly agreed with “I was




                                                                                                 9
satisfied with my wages” would plan to go back to their prior employer if asked, compared to 67%
who only somewhat agreed with this statement.
       In the final columns of Table 1, we assess how expectations about rehiring relate to the
likelihood of being rehired (defined as above). We re-estimate the logit for re-hiring, limiting the
sample to those who were out of work at the time of the survey and adding an indicator for
expecting to be rehired. Workers who believed it was likely they would be rehired were 36
percentage points more likely to be rehired subsequently than were otherwise similar workers in
the same industry and state who believed a rehiring was unlikely. These results indicate that
workers had access to predictive information about the odds of a maintained firm-worker match
that may have helped at least some of them better manage through what was otherwise a period of
massive disruption and uncertainty. The converse of this, though, is that the workers who have not
yet been rehired disproportionately consist of those who never expected to be, making it less likely
that further recovery will lead to additional rehiring.

Section IV. Evaluating Non-Pharmaceutical Interventions

       Many firm closures were closely coincident with state closure orders and other non-
pharmaceutical interventions, and policy has generally proceeded on the assumption that many
firms will reopen when these orders are lifted. It’s not evident, however, that firms closed or remain
closed only because of government policy. Closures reflected increased awareness about the threat
posed by COVID-19, and consumers, workers, and firms might have responded to this information
with or without government orders. Following closings, many businesses may have been
permanently damaged and may not reopen even when conditions improve. Moreover, insofar as
consumer behavior rather than state orders is the binding constraint on demand for firm services,
the mere lifting of an order may not be enough to restore adequate demand.
       In this section, we study the relationship between state labor market outcomes and so-called
“shelter-in-place” and “stay-at-home” orders (which we refer to collectively as “shut-down
orders”) that restrict the public and private facilities that people can visit to essential businesses
and public services. This type of intervention is both the most prominent of the non-pharmaceutical
interventions and the one that may have the largest direct effects on economic activity. We test the
importance of these directives on firms’ hours choices, as captured by the Homebase data. We use
event study models, using both contrasts between states that did and did not implement shut-down




                                                                                                   10
orders and variation in the timing of these orders to identify the effect of orders on hours worked.
We also estimate event studies of the effect of the lifting of public health orders, which need not
be symmetric to the effect of imposing them.
          Stay-at-home and reopen orders are sourced directly from government websites. 12 We
define a stay-at-home order as any order that requires residents to stay at home or shelter in place.
Orders that conveyed COVID-related guidelines but did not require residents to shelter in place
(e.g., coronavirus.utah.gov 2020), are excluded. In states that had stay-at-home orders, we define
reopen orders as the first lifting of any of the shut-down related restrictions on business activities,
and time them to the effective date. 13 Appendix Figure C6 shows the number of states with active
shut-down orders between the start of March and the present. California was the first state to
impose a shut-down order, on March 19. The number of active orders then rose quickly, reaching
44 in early April. It was stable for about three weeks, then began to decline as some states started
to re-open in late April and early May. By June 1, all states had reopened.
          Stay-at-home orders can reduce employment simply by prohibiting non-essential workers
from going to work. They can also have indirect effects operating through consumer demand,
which may relate to public awareness of COVID-19, willingness of consumers to visit businesses,
and COVID-19 caseloads. Consequently, we supplement our event study analysis of hours data
from Homebase with data on mobility, which captures in part the willingness of customers to visit
businesses in person. We measure overall mobility using SafeGraph data on visits to public and
private locations between January 19 and July 11, 2020, including only locations that recorded
positive visits during our base period, January 19-February 1. We normalize the raw count of visits
by the number of devices that SafeGraph sees on each day to control for the differences in the
count of visits related to SafeGraph’s ability to track devices, then rescale relative to the base
period.
          We estimate event-study models of the effect of shut-down and reopen orders (considered
separately) on log hours worked from Homebase and log SafeGraph visits. 14 Each outcome is


12
   They most commonly come from centralized lists of executive orders (see Illinois.gov 2020, for example), but in
some cases come from centralized lists of public health and COVID-related orders (e.g., New Mexico Department of
Health 2020).
13
   Results are similar when we define reopening as the lifting of the original shelter-in-place order.
14
   We do not formally estimate the interaction of the different outcomes, but simply estimate reduced-form effects of
orders on each. For examples of studies that do examine interactions among outcomes, see Chernozhukov, Kasahara,
and Schrimpf (2020) and Allcott et al. (2020).




                                                                                                                 11
measured at the state-by-day level. The shut-down model is estimated on data from February 16
to April 19, while the reopen order model is estimated on data from April 6 through July 11. We
regress each outcome on full sets of state and date fixed effects, state-specific trends, and a series
of “event time” indicators for days relative to the date of the order ranging from -7 (corresponding
to 7 days before the event) to the maximum observed in the data -- either +31 (corresponding to
31 days after the event) for shut-down orders or +82 (for 82 days after the event) for reopening
events.
          We report these results in Figure 5. 15 Panel A reports the event study estimates for the shut-
down (red) and reopen (blue) models, while Panel B reports the time-effects from these
specifications to aid interpretation of the magnitude of the event-study estimates in Panel A. Each
panel includes two sub-panels, one for each of our outcomes.
          Starting with the estimates for the relationship between shut-down orders and hours in the
first sub-panel of Panel A of Figure 5, we see that hours worked fell immediately following the
orders, stabilizing at a decline of roughly 12 log points by the third day after the shut-down order.
In our model for physical visits, we see an uptick in visits on the date of the shut-down
announcement, possibly reflecting trips to buy groceries or other supplies, followed by a sharp,
roughly 15 log point decline after the shut-down orders are implemented.
          Both hours and visits slowly recover after the shut-down order, returning to the level of
non-shut down states by about a month after the initial order. This may reflect adjustment of firms
or workers to the restrictions, reduced compliance, or reduced enforcement of restrictions after
they were put into place. The blue lines in Panel A of Figure 5 report results from the corresponding
specifications for reopen orders. We see that reopen orders have the opposite effect of shut-down
orders, with hours and visits rising 7 to 8 log points in the first week after the orders and growing
steadily thereafter. The estimates imply that the effects of shut-down orders, about 12 log points,
are erased by about 10 days after the orders are lifted.
          How should we interpret the magnitudes of the estimates in Panel A of Figure 5? One way
to think about them is to compare the estimates of the effects of shelter-in-place orders to the

15
   We have also re-estimated the event study models without state-specific trends; see Appendix Figure C7. An
implicit assumption of event study models is that in the absence of orders any differences among states would have
grown linearly with calendar time. We have also estimated weighted event studies (Ben-Michael, Feller, and Rothstein
2019) that rely on matching to identify control states with similar counterfactual trends. While traditional event study
models can be poorly behaved in the presence of heterogeneous treatment effects (Goodman-Bacon and Marcus 2020;
Callaway and Sant’Anna 2019), weighted event studies are not subject to this problem.




                                                                                                                    12
calendar date effects from the same specifications, which reflect other determinants of the
outcomes that are common to all states. Panel B of Figure 5 reports the calendar date effects from
the specifications reported in Panel A. The sample windows for the two models overlap for the
period April 6-19, and we show both, normalizing the reopen order estimates to align with the
layoff estimates on April 13.
         As expected given the results in Section 1 above, the calendar date effects show extremely
large reductions in hours (about 100 log points at the weekend trough and 60-75 log points on
weekdays) and visits in late March. These are much larger than the effects of the orders reported
in Panel A. The estimated effect of shut-down orders on log hours (log visits) is about one-sixth
(one-seventh) as large as the pure calendar time effects. These results imply that, at least in the
short-run, shut-down and reopen orders account for only a modest portion of the changes in labor
markets and economic activity during the crisis; the overall patterns have more to do with broader
health and economic concerns affecting product demand and labor supply rather than with shut-
down or reopen orders themselves. 16
         Two caveats are important to keep in mind when interpreting our finding that shut-down
and reopen orders play only a modest role in the labor market effects of COVID-19. First, shut-
down orders may have spillover effects on other states not captured in our model. In particular, the
first shut-down orders may have played a role in signalling the seriousness and potential risk
associated with COVID-19, even if subsequent shut-down orders had more muted effects. Second,
over longer time horizons, if shut-down orders reduce caseloads, this may result in labor market
improvements that counteract to some extent the negative effects that we estimate here.
Explorations of these more complicated medium- and long-run interactions of shut-down orders,
labor market activity, social distancing, and caseloads is beyond the scope of our analysis here.
Several papers, including Chernozhukov et al. (2020) and Allcott et al. (2020), have investigated
these interactions by combining treatment effect estimates like those here with epidemiological
and economic models that specify the relationships among our outcomes to estimate how the full
system responds over time to shut-down orders.


16
   Consistent with this interpretation, when we estimate event studies models that also include effects of school closing
events, which should not have had direct effects on small businesses but may have had a larger signaling value about
the importance of reducing contact, we find larger effects of these events (Appendix Figure C8). Nevertheless, even
the combined effect of shelter-in-place and school closing orders is no more than half as large as the pure calendar
time effects, and only about a third as large during the labor market trough in the second week of April.




                                                                                                                     13
Section V. Evaluating Economic Policy Responses

       The Coronavirus Aid, Relief, and Economic Security (CARES) Act was signed on March
27, with over $2 trillion allocated to a range of provisions aimed at supporting the labor market
and economy through the early stages of the crisis. In this section, we present descriptive evidence
regarding the relationship between two components of CARES, its enhancement of unemployment
benefits and the Paycheck Protection Program (PPP) loans to small businesses, and labor market
outcomes. While our analyses do not have strong causal designs, they are suggestive about the
likely short-run impacts.
       The CARES Act included many provisions aimed at expanding and enhancing
unemployment insurance benefits. Pandemic Unemployment Assistance (PUA) extended
unemployment benefits to independent contractors and others who did not have enough earnings
history to qualify for regular unemployment insurance, and Pandemic Emergency Unemployment
Compensation (PEUC) provided additional weeks of benefits for those whose regular benefits
have run out. A third major component is Federal Pandemic Unemployment Compensation
(FPUC), which adds $600 to every weekly unemployment benefit payment.
       The primary goal of these expansions was to aid workers who had been thrown out of their
jobs by the pandemic and the associated public health measures. By all accounts, they were
successful: Average personal income rose by an unprecedented amount in April, though this likely
masks important heterogeneity. But they also affect the labor market in two offsetting ways. First,
unemployment insurance plays a broadly stimulative effect, supporting consumption of displaced
workers (Ganong and Noel 2019, Rothstein and Valletta 2017) and thus demand for goods and
services. Second, enhancements and extensions of unemployment benefits may reduce the
incentive for displaced workers to search for work. This may slow re-hiring, and could even lead
to more job loss -- although workers who quit their jobs are not eligible for UI, workers who would
prefer to receive unemployment benefits than to remain on the job might persuade their employers
to implement layoffs rather than going into debt to keep the business open.
       These moral hazard concerns have focused on FPUC, which was controversial from the
start. The $600 amount was chosen to raise the UI replacement rate to around 100% for the average
U.S. worker. Because many workers, particularly those displaced in March and April, earn less
than the average, and because the FPUC payment did not vary with prior earnings, many workers
faced replacement rates well in excess of 100%. Ganong, Noel, and Vavra (2020) find that the



                                                                                                 14
median replacement rate is 134% and that 68% of workers unemployed in the past would have
qualified for replacement rates greater than 100% under FPUC. Anecdotally (e.g., Morath 2020),
some employers have reported that laid off workers have been unwilling to return to work, even
when businesses reopen, because this would mean a loss in income.
       We take two strategies for evaluating the effects of the expansions of UI under the CARES
Act. One uses across-state variation, and the other uses variation in the timing of the rollout of two
components of the CARES unemployment insurance expansions.
       We begin with the across-state comparison. Ganong et al. (2020) document wide variation
across states in unemployment insurance replacement rates under CARES, with a low median
replacement rate of 129% in Maryland and a high of 177% in New Mexico. We divide states into
four groups by the median replacement rate, following Ganong et al. (Figure 5 in their paper), and
investigate whether either the employment collapse or rehires vary across these groups. Variation
in the replacement rate comes from two sources: differences in state wage distributions, and
differences in the generosity of states’ pre-existing unemployment insurance benefit formulas.
Neither is random, so differences across states may capture other state characteristics that correlate
with these factors. We also explore estimates that control for Census division fixed effects, which
may capture some of the most important differences among states.
       Panel A of Figure 6 shows the time series of Homebase hours, relative to the late January
base period, for each of the four groups. The states with the lowest replacement rates saw the
steepest collapse of hours in March and the slowest recovery thereafter. This is the opposite of the
pattern one would expect if either were importantly driven by labor supply responses to UI
generosity, though as noted other differences across states may confound this estimate.
       We can use a similar strategy to develop descriptive evidence about the forgivable small
business loans provided under the Paycheck Protection Program (PPP). Like the UI programs, PPP
was rolled out very quickly and somewhat haphazardly. It relied on banks to disburse loans to their
existing customers, and banks varied in their preparedness to process applications quickly.
Moreover, the program was initially under-funded: Loan applications opened on April 3, and the
initial appropriation was exhausted by April 16. (Additional loans from a second round of PPP
funding started being provided on April 27.) There was substantial variability across areas in the
amount of loans processed during the short initial application window. We classify states into four
quartiles by the amount of PPP loans by April 16 for small firms (loans under $150K) in the retail




                                                                                                   15
and food and drink industries, divided by total payroll in small businesses in these industries in
March 2018. This ratio is over 160% larger in the top quartile of states than in the bottom. Again,
this variation is not random, as greater small business distress may have led to higher take-up of
PPP loans. But the very short, chaotic period between the opening of applications and the
exhaustion of funds suggest that some of the variation likely reflects idiosyncratic factors related
to existing banking relationships and bank preparation (and willingness) to handle the loans rather
than any response to pandemic conditions.
       Panel B of Figure 6 shows hours worked by the four PPP quartiles. The trough in hours is
lower in the states that received the least PPP money, and these states also saw slower recoveries
than states that received more funds. This is consistent with a protective effect of PPP loans.
However, a substantial gap is already apparent at the beginning of April, before the PPP loan
window opened, suggesting that other factors may confound this comparison.
       One factor that could confound the comparison is differences in the industry or worker mix
across states. To explore this, we turn again to logit models for job loss and rehiring, akin to those
reported earlier. Appendix Table C1 reports several estimates in both the CPS and the Homebase
data. Each model includes the controls listed in Table 1 as well as industry fixed effects, but we
replace the state fixed effects from those specifications with indicators for three of the four
quartiles of states by PPP volumes and by UI replacement rates. In even numbered columns, we
also add fixed effects for the nine census divisions, so that comparisons are only among nearby
states. Patterns are generally similar to what was seen in Figure 6. Higher PPP volumes are
associated with fewer layoffs; both higher PPP volumes and higher UI replacement rates are
associated with faster rehiring. Many of these effects cease to be statistically significant when we
include division fixed effects, but the directional pattern generally remains. There is no indication
that higher UI replacement rates accelerated job losses or slowed recovery.
       A second strategy for assessing the impact of UI benefits, though not PPP, is to exploit
differences in the rollout of benefit enhancements across states. While most of the current benefit
enhancements were authorized as part of the CARES Act and workers across the country became
eligible for them at the same time, the actual rollout of FPUC and PUA was staggered: States took
several weeks to reprogram computer systems to make the additional FPUC payments, and longer
to set up whole new application and eligibility determination processes for PUA. Claimants should
have received benefits that were retroactive to the beginning of the programs, but the liquidity




                                                                                                   16
benefits would not arrive until the payments were actually made, and it is plausible that any labor
supply response, which would have depended on knowledge of the program, did not fully manifest
until the payments actually appeared.
       Appendix Figure C9 shows event study plots for the two treatments’ effects on hours
worked. Both are estimated using a balanced sample of states and calendar dates, running from
February 16 to July 11, and include full sets of state, calendar time, and event time indicators. We
also control for the presence of an active stay-at-home order. We see little sign that hours changed
following the initiation of payments under either program. If anything, PUA might have had a very
small positive effect, the opposite of the decline in labor supply that concerned critics.

Section VI. Conclusion

       We are only in the very early stages of the economic recession induced by the COVID-19
pandemic, and much of its story remains to be written. Yet, data accumulated over the last four
months already illustrates some important facts and lays out important questions for future research
and suggests directions for policy responses.
       The labor market collapse triggered by the COVID-19 pandemic was unprecedented in its
speed, with the bulk of the job losses happening in a matter of just two weeks. As we show above,
there is little evidence that shut-down orders or school closures promulgated by states by
themselves played a major role in this collapse. Instead, crescendoing public health concerns in
the middle of March, and their subsequent implications for product demand in the “in-person”
sectors, appear to be the principal drivers.
       The labor market recovered quickly from mid-April through mid-June before plateauing
and beginning to decline again as the virus surged. The recovery, though very partial and
interrupted, allowed many workers to return to their prior places of employment within a few
months’ time. Nevertheless, many firms remain closed and many workers have not returned. It is
very likely, and the data we report already suggest, that the displaced workers that were left out
from this very early stage of the recovery will face a much steeper challenge reentering the labor
market. Firm-worker matches are going stale, and many of the former employers appear unlikely
to reopen. A second wave of closings, seemingly under way now, only elevates these concerns.
       The speed of the recession underscores the limitations of ad hoc policy responses, and the
importance of automatic programs. By the time the CARES Act passed on March 27, millions of




                                                                                                 17
workers had already been displaced, and tens of thousands of firms had already shuttered. It then
took several more weeks to implement the various CARES support provisions. Moreover, when
CARES was passed, many anticipated that the economic crisis would be short. The FPUC program
(the $600 supplement to UI benefits) was set to expire at the end of July, while PPP loans were
meant to support firms for only eight weeks. It now appears that the period of economic weakness
will last much longer, particularly as COVID-19 cases have begun rapidly rising again, and that
additional support will be needed. Policy responses with built-in triggers tied to economic
conditions could adjust flexibly and automatically to the evolving situation.
       The COVID-19 induced labor market collapse has also been unique in its sectoral
composition, hitting mainly (at least in this early stage) the low-wage services and retail sectors of
the economy. This is a sharp contrast with the recessions of the recent past, which have hit the
higher-paid construction and manufacturing sectors hardest. Furthermore, our data shows that
within these already low-wage sectors the least advantaged workers have been most negatively
affected. Both access to formal credit and the informal safety net (assets and savings, borrowing
from family and friends) are likely to be particularly weak for the young, less educated,
disproportionally non-white workers that have lost work since the pandemic hit. There is a high
risk that many in this group will experience deep distress, absent additional policy responses to
strengthen the formal safety net before labor demand recovers. In this regard, our evidence above
does not suggest any adverse effects of higher unemployment insurance replacement rates on the
speed of rehiring. This suggests that (as in the Great Recession; see Rothstein 2011) concerns
about moral hazard effects may be overstated, and that labor demand is the more important
determinant of employment outcomes thus far. Whether or not this pattern will hold when the
public-health risks of COVID-19 recede is also an important topic for future work.
       A central policy concern and question for future research is whether the long-term
economic losses associated with mass layoffs in the service and retail sectors, where turnover is
generally higher and workers may have less firm-specific human capital, will be as large as those
caused by mass layoffs in sectors such as manufacturing, where turnover is generally lower and
workers may have more firm-specific human capital.
       Another topic for future study concerns the concentration of job losses in businesses that
shut down entirely. An important fact that emerges from our early analysis is that firms that were
struggling prior to COVID were much more likely to shut down at the peak of the (first wave) of




                                                                                                   18
the pandemic and also much less likely to re-open during the recovery. This suggests a cleansing
effect of the recession, but the causes and consequences of this pattern remain to be determined. It
is possible that the delayed government response to expand support to small businesses played a
role, making it impossible for businesses that were already low on cash prior to COVID to build a
financial bridge until the PPP money became available. It is also possible that banks prioritized
healthier firms in their decision to extend PPP loans. The loan-level data that was recently released
masks the identity of small borrowers, but future research with identified data about loans to small
businesses may help in sorting out these hypotheses.
       Altogether, our findings show that this recession has differed sharply from other recent
downturns in its speed, the types of firms and workers it affected, workers’ beliefs about its
longevity and their likelihood of recall, as well as in the nature and size of the policy response.
Combining non-traditional sources with traditional labor market data has been key in
understanding and responding to the downturn so far, and will remain so as circumstances continue
to change rapidly going forward.




                                                                                                  19
References

Allcott, Hunt, Levi Boxell, Jacob Conway, Billy Ferguson, Matthew Gentzkow, and Benjamin
        Goldman (2020). “Economic and Health Impacts of Social Distancing Policies during the
        Coronavirus Pandemic.” May. https://dx.doi.org/10.2139/ssrn.3610422.
Alon, Titan, Matthias Doepke, Jane Olmstead-Rumsey, and Michele Tertilte (2020). “This Time
        It’s Different: The Role of Women’s Employment in a Pandemic Recession.” Working
        paper, July.
Barrero, Jose Maria, Nick Bloom, and Steven J. Davis (2020). “COVID-19 is also a reallocation
        shock.” Working paper, June 5.
Bartik, Alexander W., Marianne Bertrand, Zoë B. Cullen, Edward L. Glaeser, Michael Luca, and
        Christopher T. Stanton (2020). “How Are Small Businesses Adjusting to COVID-19?
        Early Evidence from a Survey.” Proceedings of the Natural Academy of Sciences 117 (30),
        July.
Ben-Michael, Eli, Avi Feller, and Jesse Rothstein (2019). “Synthetic controls and weighted event
        studies      with      staggered      adoption.”     Working       paper,       December.
        http://arxiv.org/abs/1912.03290
Bureau of Labor Statistics (2020a). “Commissioner's Statement on the Employment Situation
        News          Release.”       Economic          News       Release,          June         5.
        bls.gov/news.release/archives/jec_06052020.htm
Bureau of Labor Statistics (2020b). “Measuring the effects of the coronavirus (COVID-19)
        pandemic using the Current Population Survey.” https://www.bls.gov/covid19/measuring-
        the-effects-of-the-coronavirus-covid-19-pandemic-using-the-current-population-
        survey.htm
Bureau of Labor Statistics (2020c). “Frequently asked questions: The impact of the coronavirus
        (COVID-19) pandemic on the Employment Situation for April 2020.”
        https://www.bls.gov/covid19/employment-situation-covid19-faq-april-2020.htm
Chetty, Raj, John N. Friedman, Nathaniel Hendren, Michael Stepner, and the Opportunity Insights
        Team (2020). “How did COVID-19 and stabilization policies affect spending and
        employment? A new real-time economic tracker based on private sector data.” Working
        paper, June 17.
Cajner, Tomaz, Leland D. Crane, Ryan A. Decker, John Grigsby, Adrian Hamins-Puertolas, Erik
        Hurst, Christopher Kurz, and Ahu Yildirmaz (2020a). “The U.S. labor market during the
        beginning of the pandemic recession.” Working paper, June 14.
Cajner, Tomaz, Andrew Figura, Brendan M. Price, David Ratner, and Alison Weingarden (2020b).
        “Reconciling Unemployment Claims with Job Losses in the First Months of the COVID-
        19 Crisis.” Finance and Economics Discussion Series, Divisions of Research & Statistics
        and Monetary Affairs, Federal Reserve Board, Washington DC, July.
Callaway, Brantly and Pedro H.C. Sant’Anna (2019). “Difference-in-differences with multiple
        time periods.” Working paper, March 1.
Coronavirus.utah.gov       (2020).   Stay safe,       stay home directive (web                page).
        https://coronavirus.utah.gov/stay-at-home/. Accessed on June 21, 2020.
Cortes, Guido Matias and Eliza C. Forsythe (2020). “The Heterogeneous Labor Market Impacts
        of the Covid-19 Pandemic.” Upjohn Institute Working paper 20-327.
Dey, Matthew, Mark A. Loewenstein, David S. Piccone Jr., and Anne E. Polivka (2020).
        “Demographics, earnings, and family characteristics of workers in sectors initially affected




                                                                                                 20
         by COVID-19 shutdowns.” Monthly Labor Review, Bureau of Labor Statistics, June.
         https://doi.org/10.21916/mlr.2020.X
Ganong, Peter, and Pascal Noel (2019). “Consumer spending during unemployment: Positive and
         normative implications.” American Economic Review 109 (7): 2383-2424
Ganong, Peter, Pascal Noel, and Joseph Vavra (2020). “US unemployment insurance replacement
         rates during the pandemic.” Working paper, May 15.
Goodman-Bacon, Andrew and Jan Marcus (2020). “Using difference-in-differences to identify
         causal effects of COVID-19 policies.” Survey Research Methods 14(2), 153-158.
Goolsbee, Austin, and Chad Syverson (2020). “Fear, lockdown, and diversion: Comparing drivers
         of pandemic economic decline 2020.” NBER working paper no. 27432, June.
Gupta, Sumeha, Laura Montenovo, Thuy D. Nguyen, Felipe Lozano Rojas, Ian M. Schmutte,
         Kosali I. Simon, Bruce A. Weinberg, and Coady Wing (2020). “Effects of social distancing
         policy on labor market outcomes.” NBER working paper 27280, May.
Goldsmith-Pinkham, Paul, Elizabeth Pancotti, and Aaron Sojourner (2020). “Predicting Initial
         Unemployment        Insurance    Claims      Using    Google     Trends.”    April    3.
         https://paulgp.github.io/GoogleTrendsUINowcast/google_trends_UI.html
Hedin, TJ, Geoffrey Schnoor and Till von Wachter (2020). “California Unemployment Insurance
         Claims During the COVID-19 Pandemic.” California Policy Lab, June 11.
         https://www.capolicylab.org/california-unemployment-insurance-claims-during-the-
         covid-19-pandemic/#int-June%2011
Illinois.gov       (2020).    Executive      and     administrative    orders     (web     page).
         https://www2.illinois.gov/government/executive-orders. Accessed on June 21, 2020.
Kahn, Lisa, Fabian Lange, and David G. Wiczer (2020). “Labor demand in the time of COVID-
         19: Evidence from vacancy postings and UI claims.” NBER working paper 27016, April.
Kurmann, André, Etienne Lalé, and Lien Ta (2020). “The impact of COVID-19 on U.S.
         employment and hours: Real-time estimates with Homebase data..” Working paper, May.
         http://www.andrekurmann.com/hb_covid.
Lin, Zhixian, and Christopher M. Meissner (2020). “Health vs. wealth? Public health policies and
         the economy during COVID-19.” NBER working paper 27099, May.
Mongey, Simon, Laura Pilossoph, and Alex Weinberg (2020). “Which workers bear the burden of
         social distancing policies? NBER working paper 27085, May.
Morath, Eric (2020). “Coronavirus relief often pays workers more than work.” Wall Street Journal,
         April 28.
New Mexico Department of Health (2020). Public health orders and executive orders (web page).
         https://cv.nmhealth.org/public-health-orders-and-executive-orders/. Accessed on June 21,
         2020.
Rothstein, Jesse (2011). “Unemployment insurance and job search in the Great Recession.
         Brookings Papers on Economic Activity, Fall, 143-210.
Rothstein, Jesse, and Robert G. Valletta (2017). “Scraping by: Income and program participation
         after the loss of extended unemployment benefits.” Journal of Policy Analysis and
         Management, 36(4), 880-908.




                                                                                              21
Figure 1. The labor market collapse




Notes: The “Small Firms” series shows daily total hours worked across all firms in Homebase
data, as a fraction of average hours worked on the same day of the week in the January 19-February
1 base period. The sample includes firms (defined at the firm-industry-state-MSA level) that
recorded at least 80 hours in the base period. The “Large Firms” series shows weekly punches
(shifts) among hourly workers at firms with more than 100 employees, from Kronos data, as a
share of the average during the January 20-February 2 base period. “Payroll Employment” and
“Employees” series show monthly estimates from the official CES and CPS surveys, scaled as a
share of their January levels. Vertical bars mark the weekends containing Easter, Memorial Day,
and the Fourth of July.




                                                                                               22
Figure 2: Employment change in Great Recession and 2020, by sector




Notes: Payroll employment by industry or aggregate, from the official Current Employment
Statistics release. The first four categories are aggregates that include many of the remaining series.
Not seasonally adjusted.




                                                                                                    23
Figure 3: Hours changes at Homebase firms each week, relative to Jan 19-Feb 1, decomposed
into firm shutdowns, layoffs and hours reductions




Note: We decompose changes in total hours worked at Homebase firms that were active between
January 19 and February 1 into three sources: those due to firm closures, changes in the number
of workers at continuing firms, and changes in average hours among remaining workers. We
identify the contribution of firm closure by summing up baseline hours of firms that are shut down
(with zero recorded hours) each week. The contribution of headcount changes (layoffs) is the
proportionate change in the number of workers at continuing firms, multiplied by those firms’
hours during the baseline period. The contribution of changes in average hours is the proportionate
change in hours per worker at continuing firms, multiplied by baseline firm hours. Markers
indicate the cumulative net effect, combining all three. Lightly shaded bars mark the weeks
containing Easter, Memorial Day, and the Fourth of July.




                                                                                                24
Figure 4: Likelihood of firm closure and reopening by firm size and pre-crisis growth rate




Notes: Figure reports marginal effects and confidence intervals from two logit models, with state
fixed effects. In Panel A, the sample is all firms in the Homebase data, and the outcome is an
indicator for the firm shutting down (recording zero hours) for at least one week between March
8 and April 4. In Panel B, the sample is firms that shut down by April 4, and the outcome is an
indicator for subsequently reporting positive hours before July 11. Firm size is the number of
unique employees in the base period (Jan 19-Feb 1). The growth rate is the change in the number
of employees between January 2019 and January 2020, divided by the average of these two
periods. Specifications also include industry and state fixed effects. Marginal effects are evaluated
for a professional services firm in California with 0-10 employees in the base period and a growth
rate of -.5 to 0. N=24,872 for Panel A and N=12,013 for Panel B.




                                                                                                  25
Figure 5: Event study estimates of the effect of imposition and lifting of shelter-in-place
orders, with 95% confidence intervals




Notes: Samples for shutdown event studies consist of state-by-day observations from February 16
to April 19. Samples for the reopening event studies consist of state-by-day observations from
April 6 to July 11; states that never had shelter-in-place orders are excluded. Specifications include
full sets of state and calendar date effects, and state-specific trends. We exclude (normalize to zero)
the effects for event times less than -7. The shutdown calendar time effects are normalized to zero
on February 16. The reopening effects are normalized to align with the shutdown estimates on
April 13. Shaded areas show 95% confidence intervals for the event time effects.




                                                                                                    26
Figure 6: Hours trends by median UI benefit replacement rate and round 1 PPP amount,
Homebase data




Notes: UI replacement rates, expressed as percentages of weekly earnings, are from Ganong, Noel,
and Vavra (2020), Figure 5, and include CARES Act supplements to benefits. Washington, DC is
excluded, as Ganong et al. (2020) do not report UI data for it. For PPP graph, states are ranked by
the amount of PPP loans under $150,000 to firms in NAICS industries 44 and 72 (food and drink
and retail) approved on or before April 16, divided by the total payroll (in dollars) of
establishments under size 50 in these industries in 2018Q1, from the County Business Patterns
data. The first quartile has the smallest amount.




                                                                                                27
Table 1: Worker characteristics and job loss and rehiring in Current Population Survey and
Homebase samples




Notes: Each pair of columns reports marginal effects and standard errors from a separate logit
regression, controlling for 2-digit industry and state effects (not reported here). In the CPS sample,
the model for leaving work in April is limited to those who were at work in March; the model for
starting work in May or June is limited to those who were not working the prior month. The models
include gender-by-presence- of-children interactions; we report the marginal effects of children
separately for males and females. In the Homebase sample, the model for stopping work is for an
indicator for at least one week with zero hours between mid-March and late April, among those in
our sample with positive hours in late January who responded to the worker survey. The models
for starting work after stopping are for having positive hours in a subsequent week, among those



                                                                                                   28
with zero hours in a week; the final model limits to those who were not working at the time of the
survey. Marginal effects are evaluated for an unmarried, childless, male, white, non- Hispanic
individual age 26-37 with a high school diploma in a non-managerial occupation in the
professional and technical services industry in California. Bold effects are significant at the 5%
level.




                                                                                               29
            Appendix to “Measuring the labor market at the onset of the COVID-19 crisis”

        Alexander W. Bartik, Marianne Bertrand, Feng Lin, Jesse Rothstein, Matthew Unrath



Data

CPS
         We use data from the Current Population Survey public use microdata files for January
through June 2020.
         To ensure comparability over time, the labor force status questions in the CPS are
maintained unchanged from month to month. However, these questions were not designed for a
pandemic. 1 In ordinary times, people without jobs are counted as unemployed only if they are
available for work and actively engaged in job search, so someone who would like a job but is not
actively looking due to shelter-in-place rules would be counted as out of the labor force. Similarly,
the coding structure is not designed to measure workers who are sheltering at home due to public
health orders, individualized quarantines, or school closures. Consequently, beginning in March,
CPS surveyors were given special instructions (Bureau of Labor Statistics 2020c): people who had
jobs but did not work at all during the reference week as a result of quarantine or self-isolation
were to be coded as out of work due to “own illness, injury, or medical problem,” while those who
said that they had not worked “because of the coronavirus” were to be coded as unemployed on
layoff. Interviewers were also instructed to code as on temporary layoff people without jobs who
expected to be recalled but did not know when, a break from ordinary rules that limit the category
to those who expect to be recalled within six months. Despite this guidance, many interviewers
seem not to have followed these rules, and unusually large shares of workers were classified as
employed but not at work for “other reasons,” while the share coded as out of the labor force also
rose.




1
  The CPS is conducted via a combination of telephone and in-person interviews. In-person interviews were suspended
and two call centers were closed mid-way through data collection for the March survey, to avoid virus transmission.
Although the Census Bureau attempted to conduct the surveys by telephone, with surveyors working from home, the
response rate in March was about ten percentage points lower than in preceding months, and continued to fall in
subsequent months. While this may have impacted the accuracy of the survey, BLS’s internal controls indicate that
data quality is up to the agency’s standards.


                                                                                                                  i
         BLS added several new questions to the May CPS to better probe job loss due to the
pandemic (BLS 2020b). At this writing, results from these questions are not yet available.
         Our analyses focus on the distinction between employed at work and all other statuses, and
do not rely on the classification of those not working as furloughed, on leave, unemployed, or out
of the labor force.
         A last issue with the CPS concerns seasonal adjustment. Neither multiplicative nor additive
seasonal adjustment procedures are appropriate to an unprecedented situation. All CPS statistics
that we report are not seasonally adjusted.

Homebase

         In our analyses of Homebase data, we focus on Homebase’s clients as the unit of analysis.
In a few cases, a single client stretches across multiple geographic areas. We separate clients into
separate units for each industry, state, and metropolitan statistical area (MSA) in which the client
operates, and treat these units as “firms.”
         All of our analyses of Homebase data consider hours worked as a fraction of hours worked
in the base period, January 19-February 1. We construct aggregate hours indexes at the state or
industry level, separately for daily and weekly analyses. For daily analyses, we divide hours each
day after February 1 by average hours for the same day of the week in the base period. For weekly
analyses, we divide by average weekly hours during the base period.
         Figures A1-A3 present descriptive statistics for the Homebase data.
         We also rely on a survey we conducted of Homebase workers. Table B1 compares the
characteristics of survey responses with those of other Homebase workers who did not respond to
the survey invitation. Table B2 presents summary statistics for the survey responses. We restrict
the sample for this table and all analyses of the survey data to workers who were active users of
the Homebase platform during our late January base period and who have not worked at more than
one Homebase firm (as defined above) since January 19, 2020. Figure B1 shows the distribution
of hours worked during the base period for survey respondents and non-respondents, while Figure
B2 shows the time series of daily hours worked for the two groups.


Kronos




                                                                                                   ii
We obtained a tabulation of “punches” (daily sign-ins) from Kronos, a firm that offers time-clock
and payroll services similar to those provided by Homebase but serves larger businesses. The
tabulation reports the total number of shifts worked at firms with more than 100 employees who
use the Kronos time-and-attendance service.

Additional analyses

       We conducted a number of additional analyses that were not presented in the main paper.
       Figure C1 presents monthly employment by industrial sector or aggregate from the Current
Employment Statistics firm survey.
       Figure C2 shows the distribution of hours worked at Homebase firms, by week, limiting
attention to firms that shut down for at least one week by April 4. We divide the total base period
hours for each firm into four groups for each subsequent week w: Hours worked in the base period
by firms that are closed in week w, the difference between base-period and week-w hours for firms
that have positive hours in week w, hours worked in week w by workers who had worked with the
firm before it shut down, and hours worked in week w by workers who were new to the firm after
it shut down. These categories are mutually exclusive, and sum to the total base period hours.
       Figure C3 provides another look at turnover at Homebase firms. Here, we do not restrict to
firms that shut down, but instead measure the share of hours worked on each day by workers who
were with the firm in our late January base period. We also compute similar statistics for 2018 and
2019, defining similar base periods in those years.
       Figure C4 presents selected percentiles of the distribution of weekly hours among
Homebase workers with positive hours in each week.
       Figure C5 shows two views of firm survival in the Homebase data. The left panel shows
the share of firms that were active in the base period that also showed positive hours in each
subsequent week, both for 2020 and for comparable periods in 2018 and 2019. The right panel
shows the share of firms that were active in the base period and that had positive hours in or after
each subsequent week. A firm that shut down in week w but subsequently reopened would be
counted as surviving in week w in the right panel but not in the left.
       Figure C6 shows the number of states that were under a shelter-in-place order at each date.
We use the same definitions used in the text, counting a reopen order as ending the original shelter-
in-place order.



                                                                                                   iii
       Figure C7 presents an alternative specification for our event study estimates from Figure
5. Figure 5 included state-specific trends; we exclude them here. Note that the time effects
presented in the lower panel of Figure 5 were the sum of the pure calendar time effects and the
average of the state time trends; there is no such complication in Figure C7.
       Figure C8 presents a second alternative to the event study specification. Here, we
reincorporate the controls for state-specific trends, but also add a set of event time indicators where
the event is a school shutdown.
       Figure C9 presents an alternative specification for our analysis of PPP in Figure 6. There,
we classified states into quartiles by the amount of small-dollar loans awarded to businesses in
Homebase’s primary sectors of retail and food services. In C9, we instead rank states by the total
volume of PPP loans awarded, divided by total state payroll.
       Table C1 presents regression estimates from logit specifications like in Table 1. The state
fixed effects from those specifications are removed and replaced by sets of indicators for the state’s
PPP and UI replacement rate quartiles and, in columns 2 and 4, by census division fixed effects.
       Figure C10 illustrates the distribution across states of the timing of initial payments under
FPUC and the Pandemic Unemployment Assistance (PUA) program.
       Finally, Figure C11 presents event study estimates of the effect of each of those two events.




                                                                                                     iv
Appendix A. Representativeness of Homebase data
Figure A1: Firm Size Distribution of Homebase Firms




Notes: The full-time equivalent firm size is calculated by dividing total hours worked at the firm in
the two-week base period by 80.




                                                                                                   v
Figure A2: Industry Distribution of Homebase Firms




Notes: Industry coding is based on firm self reports.

Figure A3: Comparison of Homebase and BLS Data by Census Region




Notes: BLS data is employment counts by region from the Current Employment Statistics payroll
survey, and pertains to January 2020.




                                                                                           vi
Appendix B. Homebase worker survey data
Table B1: Characteristics of Homebase survey respondents




Note: The full sample is all workers who 1) worked at firms in our sample in our late January base
period and 2) have worked for only one firm since January 19, 2020. All were invited to participate
in the survey. Respondents are the subset of workers who responded to our survey.




                                                                                                vii
Table B2: Demographics of Matched Homebase Survey Respondents




Note: The table reports the demographics of survey respondents who 1) are active workers in
our base period and associated with firms in our sample and 2) have worked for only one firm
since January 19, 2020.




                                                                                               viii
Figure B1: Distribution of Base Period Hours for All Homebase Workers and for Survey
Respondents




Note: The full sample is all workers who 1) worked at firms in our sample in our late January base
period and 2) have worked for only one firm since January 19, 2020. Respondents are the subset
of workers who responded to our survey.




                                                                                                ix
Figure B2: Trends in Hours for Survey Respondents and Non-Respondents




Note: The full sample is all workers who 1) worked at firms in our sample in our late January base
period and 2) have worked for only one firm since January 19, 2020. Respondents are the subset
of workers who responded to our survey.




                                                                                                x
Appendix C. Additional results
Figure C1: Payroll employment by sector and month, 2020




Notes: Payroll employment by industry or aggregate, scaled relative to January 2020, from the
official Current Employment Statistics June 2020 release. The first four panels are aggregates
that include many of the remaining series. Not seasonally adjusted.




                                                                                                 xi
Figure C2: Distribution of hours, relative to Jan 19-Feb 1, among firms that shut down by
Apr 4




Notes: The sample consists of firms in our baseline Homebase sample that had at least one week
of zero recorded hours by April 4. We identify the firms that remain closed through each
subsequent week and sum their baseline hours (light blue). Among reopened firms, we distinguish
reductions in total hours relative to baseline (dark blue), hours worked by workers who were
employed at the firm before the firm shut down (golden) and hours worked by workers who had
not previously been seen at the firm (yellow).




                                                                                            xii
Figure C3: Share of hours by workers active in base period




Note: The share shown in the figure is the share of hours worked on a given day coming from
workers who appear in the Homebase data in the base period. The base period is two weeks at
the end of January; for 2018 it is 1/21-2/3, for 2019 it is 1/20-2/2, and for 2020 it is 1/19-2/1. Firms
included in the samples are those with at least 80 hours in the respective base period. The lines
for 2018 and 2019 are shifted leftward (by two days and one day, respectively) to align days of
the week with 2020.




                                                                                                     xiii
Figure C4: Distribution of hours worked by active workers in the week




Note: Series show percentiles of weekly hours in October 2019-June 2020, among workers with
positive hours that week. Hours are computed at the job level; a worker associated with multiple
firms creates multiple observations. The late March blip reflects onset of the coronavirus crisis;
also visible are the weeks containing Thanksgiving, Christmas and New Years, Memorial Day,
and July 4.




                                                                                               xiv
Figure C5: Share of firms with positive hours in or after a given week




Note: Panel A shows the share of firms present in the base period that show positive hours in
each week, while Panel B shows the share of firms with positive hours between the indicated
week and the week containing July 11. The base period for each series is two weeks at the end
of January; for 2018 it is 1/21-2/3, for 2019 it is 1/20-2/2, and for 2020 it is 1/19-2/1. Firms included
in the samples are those with at least 80 hours in the respective base period. The lines for 2018
and 2019 are shifted leftward (by two days and one day, respectively) to align the end of weeks
with 2020.




                                                                                                      xv
Figure C6: Timing of shelter-in-place and stay-at-home orders




This plot shows the number of states with active shelter-in-place or stay-at-home orders between
March 1st and mid-June 2020. We define orders as ceasing to be active on the first date that any
business activity restriction is lifted.




                                                                                             xvi
Figure C7: Event study estimates of the effect of imposition and lifting of shelter-in-place
orders without state-specific trends, with 95% confidence intervals




Notes: Samples for shutdown event studies consist of state-by-day observations from February
16 to April 19. Samples for the reopening event studies consist of state-by-day observations from
April 6 to July 11; states that never had shelter-in-place orders are excluded. Specifications
include full sets of state and calendar date effects. We exclude (normalize to zero) the effects for
event times less than -7. The shutdown calendar time effects are normalized to zero on February
16. The reopening effects are normalized to align with the shutdown estimates on April 13.
Shaded areas show 95% confidence intervals for the event time effects.




                                                                                                xvii
Figure C8: Event study estimates of the effect of shelter-in-place and school closing orders




Notes: We report estimates for a single event study model with two sets of event time indicators,
for days relative to shut-down orders and days relative to school closings, along with calendar
date effects, state fixed effects, and state-specific trends. Sample consists of state-by-day
observations from February 16 to April 19. We exclude (normalize to zero) the effects for event
times less than -7. The calendar time effects are normalized to zero on February 16. Shaded
areas show 95% confidence intervals for the event time effects. Dates of school closure are from
Education Week.




                                                                                             xviii
Figure C9: Hours trends by alternative measure of round 1 PPP amount, Homebase data




Notes: Figure reproduces Figure 6, using an alternative measure of PPP volumes. Here, states
are ranked by the total volume of PPP loans received by April 16, divided by non-farm payroll in
April 2019.




                                                                                              xix
Figure C10: Initiation of Pandemic Unemployment Assistance (PUA) and Federal
Pandemic Unemployment Compensation (FPUC) payments




                                                                               xx
Figure C11: Event-study estimates of effects of PUA and FPUC payment starts on hours
worked




Note: Panel PUA (respectively, FPUC) shows estimates from an event study model where the
event is the beginning of Pandemic Unemployment Assistance (respectively, Federal Pandemic
Unemployment Compensation) payments in the state. The sample is state-by-day observations
from 2/16-7/11. Each specification includes an indicator of active stay-at-home order, a full set
of state and calendar date effects, and all estimable event time effects. Event time -1 is
normalized to 0 for both types of UI, and event time -8 is also normalized to 0 for FPUC.




                                                                                              xxi
Table C1: Variation in layoff and rehire probabilities with PPP payouts and UI
replacement rates




Notes: Table reports marginal effects from logit specifications for job leaving and beginning of
work, using CPS (columns 1, 2, 5, 6) and Homebase data (3, 4, 7, 8). Samples, specifications
and controls are identical to those in Table 1 (first and second specifications), except that we
replace state fixed effects with indicators for three quartiles of the volume of PPP loans in a state,
as a share of state non-farm payroll in April 2019, three quartiles of the median unemployment
insurance replacement rate in the state (from Ganong, Noel, and Vavra, 2020), and, in even-
numbered columns, division fixed effects. Washington, DC is excluded, as Ganong et al. (2020)
do not report UI data for it.




                                                                                                  xxii
