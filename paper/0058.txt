                       NBER WORKING PAPER SERIES




                      A MONTE CARLO STUDY OF IO

                  ROBUST ALThRN'IVES TO LEAST SQUARES

                         REGRESSION ESTIMATION



                            Richard W. Hil1':
                            Paul W. Ho11and':

                        Working Paper No. 58



COIJER FESEARQ TER FOR EOONOtECS ND ANAGE\JT SCIENCE
          National Bureau of Economic Research, Inc.
                    575 Techno1oj Square
               Cambridge, Massachusetts 02139



                            September l97L


                     Preliminaxy: not for quotation
NBER working papers are distributed informally and in limited numbers for
corrurents only. They should not be quoted without written permission.

This report has not idergone the review accorded official NBER publications;
in particular, it has not yet been submitted for approval by the Board of
Directors.
NBER Computer Research Center. Research supported in part by National
Science Foundation Grant GJ_ll5LX3 to the National Bureau of Economic
Research, Inc.
                                 Abstract


We give some Monte Carlo results on the performance of two robust
alternatives to least squares regression estimation -- least absolute
residuals and the one-step "sine" estimator. We show hcw to scale
the residuals for the sine estimator to achieve constant efficiency
at the Gaussian across various choices of X-matrix and give soma
results for the contaniinated Gaussian distribution.
                                         Contents




1. Introduction and Notation .                                                                         1

2.   Creeping Inefficiency in the Gaussian Case                                                       II

     Monte Carlo Results for Contaminated Gaussian ErTors
.
3.                                                                                                    17

     Covariance Matrices for Rubust Regression Estimators                                             22

References                                                                                            25




                                         Figures

Figure 1—1. Scatter Plot of COL3 and COLL            for VDATA1

Figure   1-2. Scatter Plot of COL5 and COL6 for VDATA1                                                 5




                                         Tables

Table 1—1.   Final, Standardized Colurrns of         VflTA1                                            7

Table 1-2.   Matrix   of Intercorrelatjons for the Coluiins of                 VDATA1                  8

Table 1-3.   Eigenvaiues     of (1JflJ)T                                                              9

Table 2—i.   Inefficiency of LR and SIN1 in Gaussian                 Case for
             N:20, p=l,2,3,14,6                                                         -   . .     . 13
Table 2—2.   Inefficiency of SIN1 under          Gaussian   errors    using
             (2-2   as the definition of a, for p2 ,            ,S                      •   . . • 15

Table 3—1.   Inefficiency     of LAR and SIN1 with respect           to   IS     .      -   •   •   - 18
Table 3—2.   Ratio of iff() to if                 from Table 3-1                        -   . . • 20

Table 3—3.   Monte   Carlo   Estimates   of El       -      2
                                                                                        •   . .     • 21
Table 3_L4   Inefficiencies     of JAR and SIN1 for NL0                                              23
1.   Introduction and Notation
     In this paper we discuss soire preliminary results on the efficiency of
     two regression rrethods that have been suggested as robust alternatives
     to least squares. We assurre the usual linear rrcdel,
                                                                                       (1—1)

     where y and e are Nxl vectors, X is Nxp and                is pxl. In our Monte

     Carlo    study, e is a random vector with independent arid          identically

     distributed      coordinates from a density f(), where f is either the
     Gaussian or one of a selected family of scale contaminated Gaussian
     densities. Our ma.in interest is in the effect of f and X on the

     behavior of estimators of .              We   give sone Monte Carlo results on

     these effects in sections 2 and 3 and discuss an implication they

     have in section .

     Notation:     We denote the ordinary least squares estimator of by

            or 13. The two       alternatives      to LS which we studied are denoted by

     LAR (or          and SIN1 (or ).
             LIAR is the "least absolute residual" estimator so that            minimizes

                      I' -       x±
                                          .
                                                                                      (1-2)
                  1          J


     LIAR   has been studied extensively and goes by a variety of other naires
     -- least    lines, minimum absolute deviations (MAD), minimum sum of
     absolute errors (MSAE), least absolute deviations (LAD) and the
                                     —2—



minimum 1-norm estimator. The estimator SIN1 is the "1-step SIN
estimator starting from LAR" so that 6 is given by
                    T           -1 T                                         (1—3)
                        <> 9
where <w> is a diagonal rrtrix whose diagonal entries are given by


                            1          if   1
                        sin(r./a)
                             1         if O<r.< ia
          w.                                 1—                              (l_L)
              1
                                Ia
                        0              if r.>ira

In (1-n), r. is the i residual from the TAP fit, i.e.
                                                                             (1—5)
          F
and a is given by
          a       2.1 median (Ir.}                                           (16)

The SIN1 estimator is based on Andrews' "sine" estirrtor of location

(ANT) from    Andrews etal.[1972].       SIN1, as       used here, consists of
one step of iteratively reweighted least squares starting at tAR. The
weights are based on the LAR residuals and the particular choice of
 scale given in (1-6) is adapted from the one used in Andrews et al [1972]
for the location problem. One result of our study is a
rrDdification of (1-6) that appeaxe to be a rrdest irrprovement. We
view SIN1 as a sirr1e way to iirrove the LAR estintor and our
simulation results indicate that it usually is.
     In order to conpare LAR and SIN1 with each other and with LS across
various choices of X and f we use the fo11iing overall measure of the
inefficiency of 6 relative to
          iff(6)        EI(6_6112/EJI6LS_6t12
                                                    .                        (1-7)
                                  —3—



For an iithiased estimator (1-7) becomes:
            iff(8) =       Var(.) /       Var(6.)   .                  (1-8)
                —

                       j       J
                                      j
When   the number of regressor variables, p, equals 1 iff(6) reduces
to the reciprocal if the relative efficiency of 6 to 6. The
smaller the value of iff(3), the better 6 is relative to IS.
The X-rnatrix: All of the X-matrices used in our Monte Carlo study
are derived in various ways from a basic 20x6 matrix, VDATA1. First
we describe the construction of VDATA1 and then indicate hcxi the X-
matrices used is the study are derived from it.
       The 6 cohrns of VDATA1 were devided into 3 groups of 2. Coluriris
1 and 2 were chosen so that their scatter plot forrr a perfect square
centered about the origin. Thus the first two columis correspond to
variables like those in a designed experiment. Colurrris 3 arid   were

chosen to be roughly independent bivariate Gaussian. Their scatter
plot is given in Figure 1—1.
                       Figure 1-1 goes about here

       Coli.ris 5 and 6 were chosen to be roughly independent bivariate
variables with outliers. 'I\.o independent Cauchy samples of size 20
were drawn and then the largest observations in each sample was rrcved
in umtil they contributed 80 and 85% to the total sum of squares of
their columns, respectively. The scatter plot of columns 5 and 6
is given in Figure 1-2.
                       Figure 1-2 goes about here
                                  _Lf_




 C
 0
 4

      O 2$




      0.00




     -e 25




      —0.60      -0.40     -020          0.00     0.20   0.40    0.60
                                                                COL3


FIOUPE 1-1. SOLTrER PLOT OF 00L3 AND COL4 FOR VDATA1
                                 —5—

     0.50
C
0
L
b



     0.130




    -o.;o




    —1 I:n:1
                O   tiU               @40       0,0    13.80     1.00
                                                               COL5




FTGIJFE 1-2. SCATTER PLOT OF COL5 AND COL6 FOR VDTA1
                               —6—



After the   coluims of 'IDATA1 were selected each column was standardized
to have mean zero and iIiit sum of squares, i.e. (VDATA1)TVDATA1 is a
correlation matrix. In Table 1-1 we give the final, standardized columns
of VDATA1. In Table 1-2 we give the correlation matrix of the columns
of VDATA1. From Table 1-2 we see that the six columns of \TflTA1 are
all roly ohogonal. The eigenvalues of (VDAT)TVDATA1 are given
in Table 1-3. The ratio of the largest to the smallest eigenvalue (the
condition number of (\TDAT1)TVDATA1 )is 7J99.          The two outliers in
columns 5 arid 6 occur in ris 20      and   18 respectively of Tb1e 1-1.
              Tables 1-1, 1-2 arid 1-3 go about here
The various X-matrices we used were derived from VDATA1 in two basic
ways. Most of our results concern N20 and p<6. To vary p, we formed
an X-inatrix from the first p columns of VflATA1. Thus as we vary
the dimension of X we are also varying the kurtosis in the columns
of X -- this is important to remember in section 3. A few results
are also given for LQ•    We   wanted to have L0xp X-matrices that
were "sijriilar to" the 2Oxp ones we used. To do this we merely replicated
every row of VDATATL. This has the effect of producing a new Ox6
matrix whose singular value decomposition is identical to that of
VflATA1 except for the "basis" or U-matrix. The condition number and
the pattern of eigenvalues are unchanged.
Error Distributions:
After a preliminary examination of various error distributions, f (S),
we decided to use the simple 2-paraneter family of a mixture of a N(0,1)
                                 —7-.

                               TABLE   1-1
                  FINAL, STANDARDIZED OOLUMS OF VDATA1




ROW    COL1         COL2        COL3          COLI4       00L5       COL6

  1     0.2712      0.2712     —0.0453        0.0257     —0.0880      0.0288
  2     0.2712      0.1627      0.1092       —0.1268     —0.0509      0.0470
  3     0.2712      0.05142     0.14513       0.0963      0.01140     0.0682

  14    0.2712     —0.05'42    —0.1605        0.2977     —0.1065      0.0225

  5     0.2712     —0.1627      0.22142      —0.3618      0.21463     0.3193

  6     0.2712     —0.2712      0.0107        0.12146    —0.08114     0.01461

  7     0.1627     —0.2712      0.1937        0.1006     —0.0373      0.0583

  8     0.05142    —0.2712     —0.21435       0.3205     —0.1373      0.014014

  9    —0.05142    —0.2712     —0.00914      —0.14123    —0.0852      0.0228
 10    —0.1627      —0.2712     0.1382        0.14631    —0.0630     —0.0112

 11    —0.2712      —0.2712     0.0956        0.09814    —0.0489      0.0388
 12    —0.2712      —0.1627     0.0597       —0.1136     —0.0732      0.0327

 13    —0.2712      —0.0542    —0.0613       —0.1263     —0.091414    0.0303

 14    —0.2712       0.05142    0.1282        0.0598     —0.0680      0.0691

 15    —0.2712       0.1627    —0.0966       —0.0085      0.1387     —0.0672

 16    —0.2712       0.2712    —0.1060       —0.3819     —0.1340      0.0559

 17    —0.1627       0.2712     0.2013        0.0145     —0.0290      0.0966
 18    —0.0542       0.2712    —0.43214      —0.2083     —0.1520     —0.9198

 19     0.0542       0.2712     0.0914        0.0840     —0.0417     —0.0620

 20     0.1627       0.2712    —0.51486       0.0544      0.8917      0.0833
                                —8—
                              TABLE   1-2
        MATRIX OF INTERCORPELATIONS FOR fl COLUM'JS OF   VDATAJ.


ROW    OOL1        'COL2       00L3          COL4        00L5       COLE

  1    1.          0.          0.0573        O.JJ462     O.215      0.1576
  2    0.          1.         —0.2786       —0.2456      0.2382    —O.3034
  3    0.0573     —0.2786      1.            0.0'404   —0.3499      0.4818
  4    0,11462    —0.21456     0.04014       1.        —0.0297      Q•Q71414

  5    0.2150      0.2382     —0.3499       —0.0297      1.         0.2448
  6    0.1576     —0.3034      0.4818        0.0744      0.2448    1.




Matrix of intercorrelations for the co1uzs of VflATA1 (i.e. (VDATA1 )T VDATA1).
                                —9—


                               TABLE 1-3
                                             T
                  EII VALUES OF (V]DATAJ


  1        2             3                        5        6




O.2L14   O.62'4        0.821         1.068       1.L11   1.832
                                   — 10   —




density   with a N(0,k2) density. This is given by


                         (2)              e_U2/2     +   e 1/2 ()              (19)
             g(u)
                                                                       2
where 0<cL<l, and    l<k<.      These are denoted Cc w that CG3.01

indicates a choice of g where k3 and o. .01 . In all cases
the scale of f(u) was selected so that the errors had unit variance.
Thus

            f(u)         g ()
                                                                               (1-90)

where
            T2     1-a   +                                                     (1-11)

       Both of the estirrtors LAR and SIN1 are regression invariant
in the sense that if the vector of observed values y is transfonred
             (0)                 (0)
to y + X            for some           then        is transfonred to       +   (0)



This invariance implies that

            EJ-I2 E0HH2                                                        (1-12)

for any err-cr distribution. Hence all of our Monte Carlo results were
computed with the true value of set equal to 0
                                - II   —




2.   Creeping Inefficiency in the Gaussian Case
     One difference between LAR and SIN1 is the dependence of the latter
     on the choice of a residual scaling factor, a . Ig-ioring for the
     rrint the particular form of a in (1-6) it is clear that if a in
     (1-4) is very large then the w. are all near i.u-uity and     will be
     near the LS estimate. On the other hand, if a is very small, then
     the w. are all zero causing       to be iridefined. LAR like IS does
     not depend on a choice of scale for the residuals. The rrotivation
     for the choice of residual scaling given in (1-6) is its per-
     forrnance in the location case (pl) where Andrews et al. [1972]
     fouid it to be an effective irrprovelTent on the scale estimate based
     on the interquartile range. In the location case, (1-6) gives a
     as a multiple of the ndian absolute deviation from the redian
     and this is the scale analogue of the rrdian ——    see   Hanple [1973].
     One can irctivate (1—6) as fol1c.s.    If the initial LAR fit is
     reasonably good, then the absolute residuals {1r11} will behave
     approd.mately like a san1e from the half-Gaussian distribution.
     Matching the rrdian of this sanle to that of a half-Gaussian
     population leads to a scale estimate that is a multiple of the
     one given in (1—6). The choice of the multiplying factor depends on the
     weighting fiction (1-4) and a desired level of inefficiency at
     the Gaussian -— in the location case Andrews used a factor of 2.1
     and achieved an inefficiency of 1.07 at the Gaussian.
     Soie Monte Carlo Results: We estimated the covariance matrix of
        and    in the Gaussian case using the Monte Carlo "swindle"
     described in   Holland [1973], and 500 replications. In all cases,
                             — 12   —




N2O   and we varied p, the dirrnsion of the            X-matrix, over the range

1,2,3,,6 by    successively including the colurrns of VDATA1 as

described    in section 1.   Table      2-1   gives   the   resulting estijrted

inefficiences for LAR and SIN1 as a function of p.

                   Table 2-1 goes about here

      The estinated inefficiency of SIN1 for pl is 1.10 which
compares favorably with the value of 1.07 found in the Princeton
Pcbustness Study. When p3 the value of 1.17 for SIN1 is close
to the value 1.16 found byMdrews [1973] using a different
X-rnatrix.
      In Table 2-1 we see that SIN1 exhibits creeping inefficiency
in the sense that what is a hily efficient estimator for pl,
becorres progressively less efficient as p increases. While SIN1
is still better than LAR over this range of p, the systematic
increase suggests that for p7 SIN1 would be cease to be an
improvemant over LAR. On the other hand, LAR does not exhibit
this phenomanon. Instead, LAR becomes rrcre inefficient as the
effective sample size (N-p) increases. This is analogous to the
behavior of the madian which approaches its asymptotic variance
from below as N .        (See   Kendall and Stuart [1963], page 367).
      It is evident that the creeping inefficiency of SIN1 can be
avoided by adjusting the residual scaling factor, a, so that it
depends on p -- in particular, it should increase as p increases
to make        ucre closely approximate 6L5 in the Gaussian case.
This naturally suggests a simple degree of freedom type of correction of
                              — 13 -




                              TABLE    2-1
INEFfiCIENCY OF LAP. AND SIN1 IN GAUSSIAN CASE FOR N2O, p1 ,2,3, 4,6




        p           1          2              3                  6


                   1.63       1.63           1.57   1.54        1.47

                   1.10       1.12           1.17   1.23        1.32
                                  — 11+




    the form

                a                 (2.1 dian {Jr.J})                           (2—1)


We tried using (2-1) instead of (1-6) and it helped, but did not
eliminate the problem, nor did various similar adj ustirnts to a
using different multiplying factors.
    In rethinking the irtivation for using a in the location
case we realized that one feature of the LAR residuals is that
at least p of them must be identically zero. Hence the absolute
residuals from LAR do not look like a sanpie from the half-Gaussian
distribution. This suggests eliminating p—i of these zero
residuals and then conuting a as before, i.e.

                 2.1 xrdian {largest N-p+1 of the                       (2—2)


Table 2-2 gives the Monte Carlo estimates of the inefficiency

of SIN1 using (2—2) instead of (1-6) for                   It is clear

that this correction has been successful and the SIN1 estirrator

nu has an inefficiency at the Gaussian that is effectively

independent   of the dinension     of the X-rnatrix.


                    Table   2-2 goes about here

     The new residual scaling given by       (2—2) does not seem to

have seriously altered the behavior of SIN1 in         the non-Gaussian

case. For the CG5 .25 distribution and for p=6, our Monte Carlo
estimates of if f() for a given by (1—6) was .614 while for
a given by (2—2) it was .63 .         TsThi1e it may be useful to rrke a

rrüre thorough conparison than this we did not         and henceforth   all
                        — 15   —




                    TABLE   2-2
INEFFICIENCY OF SIN1 IN]R GAUSSIAN ERRORS USING
  (2—2) AS THE FINITION OF ,       FOR   p       2,'i,6




          p         2                        6

                   1.08        1.08      1.09
                             — 16 —




results given for   SIN1   use (2-2) for the residual scaling. In
the next section we give rrore results for the contaminated
Gaussian case.
                               — 17   —




3.   bnte Carlo Results for Contaminated Gaussian ErTors
     After some preliminary experimentation we decided to obtain
bnte Carlo estimates of the inefficiency of LAR and SIN1 under
CGka errcrs for three values of a (.1, .25, . 5), three values of k
(3,5,10) and three choices of X-matrix (the first two, the first
four and all six colurms of \rDATA1). The tbnte Carlo estimates for
these two estimators and twenty-seven situations are given in Table 3-1.
These bnte Carlo estimates used simple experimental sailing rather
than the contaminated-Gaussian version of the swindle described in
Holland [1973] and are based on 500 replications each.
                       Table 3-1 goes about here

     The nest obvious message in Table 3—1 is that, except for five
cases involving LAR, both LAR and SIN1 are improverrents, sometimes
substantial improvements, over LS. Furtherjire, except for four cases
where the percent of contamination is very high (50%) SIN1 does
improve upon LAR.
    In addition to these effects, there are at least 3 trends in Table 3-1
that should be mentioned. First, for each level of percent contamination
there is a systematic improvement in both LAR and SIN1 over LS as
the variance of the contaminating distribution increases. Thus the heavier
the tails of the error distribution the worse LS is and therefore the
more LAR and SIN1 can improve upon it. The second trend involves varying
the X-matrix for each error distribution. For SIN1 there is a systematic
increase in iff ( ) as the X-rnatrix includes more colunrs of VDATA1. This
is also true for LAR except for the GG3. 1 errors where the trend is
ant)iguoUS.   While this looks something like the creeping inefficiency
                                     - 18 -

                                    TABLE   3-1
              INEFFICIENCY OF LAR JJD SIN1 WITH RESPECT TO LS




k                        3                    5                10

          p       LAR        SIN1     EAR         SIN1   EAR        SIN1
          2       1.09       .78      .60         .44    .19        .13

.10       4       1.03       .80      .59         .47    .20        .15
          6       1.03       .87      .72         .60    .38        .33


          2        .87       .71      .42         .39    .15        .15
.25       4        .91       .78      .49         .47    .26        .25
          6        .96       .83      .69         .63    .45        .43


          2        .91       .81      .58         .63    .35        .146

.50       4       1.00       .87      .74         .75    .55        .62
          6      1.08        .94      .92         .87    .80        .79



Inefficiency of LAR and SIN1 with respect to IS. Monte Carlo estimates
(500   replications).
                                        — 19   —




 wefound in the Gaussian case, we suspect that it is mré due to the
 changing nature of the -matrix than the increase in its dimension.
 The first two columns of VflTAl form a balanced design matrix. The
 next two are still well behaved but are like a bivariate Gaussian
 sample. The last two coluirais have outliers (or high leverage points)
 and are not well behaved at all. The kurtosjs of the six colurrris of
 VflTA1 are      —1.65,—l.65,O.56,_0.30,9.76,11.53, respectively. Thus
 as we    incorporate rrore    columrs of      VDATA1   into the X-matrix we         increase

 the probability that a large error will be associated with a high leverage
 point. A large error associated with a high leverage point in X decreases
the improvement of SIN1 and LAR over LS.
        A third trend in Table 3-1 concerns the improvement of SIN1 over
tAR.     This is rrore   easily seen in Table 3-2          which    gives   the ratio,

ff (BL)/iff(8s). The biggest improvement                  occurs   in the lowest contamination
case and for the first         two   columns of VflTA1         as the   X-rnatrix.    In   the very
extreme case of CG1O .5, SIN1 actually degrades the performance of tAR.

                            Table 3-2 goes about        here
        Since SIN1 is a simple 1-step irrproveirent on LAR it might be hoped

that rrcre iterations would help it out. To test this we ran a auxiliary

experiment for the CG1O .10          case   and changed the number         of steps
sequentially      from 1 to 5. The value of the numerator of                           (i.e.

El   Isi1 J2) is given for each number of steps in Table 3-3. An exam-
ination of the individual        8   estirrates         they do change with
                                                   shows that

rrore   steps but as   we   see in Table 3-3 on the whole they do not improve.
                            Table 3-3 goes about here
        As   a final question we asked what is the effect of N? As described
                        — 20    —




                       TABLE 3-2
      RATIO OF iff(8s) TO           FROM   TABLE 31



k                           3                5        10


a         p

          2             1.40                1.36      1.146

.10       4             1.29                1.26      1.33
          6             1.214               1.20      1.15


          2             1.23                1.08      1.07
.25       14            1.17                1.014     1.04
          6             1.16                1.10      1.05


          2             1.12                 .92       .76
.50       14            1.15                 .99       .89
          6             1.15               1.08       1.01
                               — 21    —




                             TABLE 3-3
              NTE CARLO ESTIMATES OF Ej               -
                                                          f   2



                           Number of Steps


                   1           2                3                         5



E       t2        2.95        2.97             2.97               2.97   2.98




bnte Carlo estimates of E          -       2
                                                for   1 to 5 steps of iteratively

reweighted   least squares using (1-u) (227 replications)
                                    — 22   —




in section    1, we doubled the    size of our X-rnatrices by   replicating   each
rxyi. The inefficiences for LAR and SIN1 for 3 choices          of X-matrix

with NL0 and two error        distributions    (CG3.5 and CG1O.l) are given
in Table 3—4. These values are systematically smaller than the
corresponding ones in Table 3—i indicating that robustness is easier to
achieve when the sample size is larger.
                         Table 3-4 goes about here
4• Covariance Matrices for Robust Regression Estimators
       The results of Table 3-1 have an interesting        isvlication for a

class   of possible estimates of the covariance       matrix for robust regression

estimators.      Analogues to least squares as well as asymptotic theory
lead   to a covariance matrix for          of the form

                                   h2(XTX)l                                 (4-1)


where h2 is a multiplying factor that potentially depends on these

factors:

        (1) The estimator -—     for   iteratively reweighted least squares

       estimators like Sfl'l this would include the way the       weights   are

        fornd.

        (2) The error distribution.

        (3) The rrethod of scaling the residuals.

        (4) The desired level of inefficiency achieved at sorr standard

        distribution   (e.g. the Gaussian) -- in    the case of SIN1 this is

        about 1.08

        (5)   The X-matrix.
       The original hope was that all but (5) would matter except through
N and p,but Table 3—1 shows that this is not the case. If (4—1) holds
then
                                  — 23 —


                                 TABLE 314
            INEFflCICIES     OF LAR   J'D    SIN1 FOR NLO




                  CG3.5                                 CG1O.1

p          LAR            SIN1                    LAR            SIN1

2          .79             .72                    .18             .12
           .82             .75                    .18             .12
6        1.00              .86                    .25             .17


Inefficiencies   of LAR and SIN1 for N4O. Monte Carlo estintes
(500 rp1ications).
                                  — 2L —




          El l-l    2
                             h2 tr(XTX)    .                               (L_2)

But

          El   lsI      12    Var(f) tr(XTX)        tr(XTXY

since in all cases the errors were scaled to have Var(f)             1. Hence if
(l4l) holds then
          iff() h .                                                        (-3)
We observe that the results of section 2 indicate that in the Gaussian
case the residuals can be scaled to renove the effect of X on h2.
However, the results in Table 3-1 show that in general this is not possible.
It is evident that the dependence on X         is   not a simple function of N arid
p, and we suspect that at the very least some nasure of the average
kurtosis of the colims of X is involved in h2 if the form (-l) is to
give a reasonable        approximation to the covariance ntrix of          for
either LAR or SIN1 under a variety of types of error distributions.
Huber £1973 ] and Tukey [1973] propose rrre complex expressions for
these covariance ntrices which may obviate the necessity of nking h2
depend on X.
                                     — 25 —




      RFERENS


(1)   Aridrews, D.F., Bickel, P.J., Hampel, F.R., Huber, P.J., Rogers, W.H.
      and Tukey, J.W. [1972] Robust Estimates of Location, Princeton
      University Press, Princeton, N.J.

(2)   Andrews, D.F. [1973] "Sorr Monte Carlo Results on Robust/Resistant
      Regression." (unpublished).

(3)   Hample, F.R. [1973] "Robust Estimation: a condensed partial            survey"
      Z. Wahrscheinlichkejtstheorje verw. Geb. 27, 87-10k.

(4)   Holland,P.W. [1973] "Monte Carlo for robust            regression: the   swindle
      unmasked." NBER Working Paper No. 10.

(5)   Huber, P.J. [1973] "Robust regression: stotics, conjectures                  and
      Monte Carlo" Annals of Statistics 1, 799—821.

(6)   Kendall, M.G. arid   Stuart,   A. [1963] The Advanced Theory         of Statistics
      Vol. I 2 edition. Hafner, New York.
(7)   Tukey, J.W. [1973] "A way forward       for   robust   regression"   (unpublished).
