                             NBER WORKING PAPER SERIES




              DIRECTED ATTENTION AND NONPARAMETRIC LEARNING

                                      Ian Dew-Becker
                                    Charles G. Nathanson

                                     Working Paper 23917
                             http://www.nber.org/papers/w23917


                    NATIONAL BUREAU OF ECONOMIC RESEARCH
                             1050 Massachusetts Avenue
                               Cambridge, MA 02138
                                   October 2017




We appreciate helpful comments from Ben Hebert, Peter Klibanoff, Konstantin Milbradt, Mikkel
Plagborg-Müller, and seminar participants. Nathanson thanks the Guthrie Center for Real Estate
Research for financial support. The views expressed herein are those of the authors and do not
necessarily reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2017 by Ian Dew-Becker and Charles G. Nathanson. All rights reserved. Short sections of text,
not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including © notice, is given to the source.
Directed Attention and Nonparametric Learning
Ian Dew-Becker and Charles G. Nathanson
NBER Working Paper No. 23917
October 2017
JEL No. C14,D83,E21

                                         ABSTRACT

We study an ambiguity-averse agent with uncertainty about income dynamics who chooses what
aspects of the income process to learn about. The agent chooses to learn most about income
dynamics at the very lowest frequencies, which have the greatest effect on utility. Deviations of
consumption from the full-information benchmark are then largest at high frequencies, so
consumption responds strongly to predictable changes in income in the short-run but is closer to a
random walk in the long-run. Whereas ambiguity aversion typically leads agents to act as though
shocks are more persistent than the truth, endogenous learning here eliminates that effect.


Ian Dew-Becker
Kellogg School of Management
Northwestern University
2001 Sheridan Road
Evanston, IL 60208
and NBER
ian.dewbecker@gmail.com

Charles G. Nathanson
Kellogg School of Management
Northwestern University
2211 Campus Drive, Room 4479
Evanston, IL 60208-0898
nathanson@kellogg.northwestern.edu
                Directed attention and nonparametric learning
                              Ian Dew-Becker and Charles G. Nathanson

                                             September 19, 2017



                                                    Abstract
          We study an ambiguity-averse agent with uncertainty about income dynamics who chooses
      what aspects of the income process to learn about. The agent chooses to learn most about income
      dynamics at the very lowest frequencies, which have the greatest e¤ect on utility. Deviations
      of consumption from the full-information benchmark are then largest at high frequencies, so
      consumption responds strongly to predictable changes in income in the short-run but is closer
      to a random walk in the long-run. Whereas ambiguity aversion typically leads agents to act
      as though shocks are more persistent than the truth, endogenous learning here eliminates that
      e¤ect.

    A growing literature studies economic behavior in the face of model uncertainty, while at the
same time there is a large amount of recent work that studies optimal allocation of attention.1
Those two areas are obviously related: the economy is highly complex, so people are unlikely to
be able to understand all of it, and they must choose how to allocate their limited attention and
information processing abilities. Furthermore, information acquisition is not free, so we would not
necessarily expect people to be perfectly informed about everything.
    Surprisingly, though, there is little or no research that studies the implications of directed
attention in the face of model uncertainty.2 The contribution of this paper is to study the behavior
of an agent who allocates attention across di¤erent aspects of a model. We show that optimal
learning about model features has important and interesting implications for behavior. On the
one hand, it naturally leads to excess sensitivity of consumption to high-frequency components
of income, as observed empirically. At the same time, though, we show that optimally directed
attention drives the consumption policy closer to the optimum at lower frequencies than it would
be if model uncertainty were purely exogenous.
      Dew-Becker: Northwestern University and NBER; ian.dewbecker@gmail.com. Nathanson: Northwestern Uni-
versity; nathanson@kellogg.northwestern.edu. We appreciate helpful comments from Ben Hebert, Peter Klibano¤,
Konstantin Milbradt, Mikkel Plagborg-Møller, and seminar participants.
    1
      On model uncertainty, most revelant for us is recent work on consumption under model uncertainty, e.g. Hansen,
Sargent, and Tallarini (1999), Wang (2004, 2009), Luo (2008), Luo and Young (2010), but there is a large broader
literature. See Sims (2003), Veldkamp (2011), and many citations therein for work on directed attention.
    2
      There is substantial past work on directed learning (e.g. Van Nieuwerburgh and Veldkamp (2006), Peng and
Xiong (2006), Veldkamp (2006), and Barron and Ni (2008)), but we are not aware of work that examines the choice
of what part of a dynamic process to learn about.


                                                         1
      More concretely, we study the problem of an ambiguity averse agent who is uncertain about
the dynamics of an exogenous and untradeable income process. The key innovation compared to
past work on ambiguity aversion is that the agent acquires information that can reduce the degree
of ambiguity.
      The agent’s optimization has three phases. Conditional on a particular model of the world,
the agent has standard Bayesian expected utility.3 If the agent had a fully speci…ed probability
distribution over possible models for income, she could integrate across them, remaining a Bayesian.
Similar to the literature on robust control (e.g. Hansen and Sargent (2007)), we argue that such
behavior is implausible in the face of in…nite-dimensional uncertainty about income dynamics. We
therefore model the agent as ambiguity averse: among all su¢ ciently plausible models, she adopts
the one under which her expected consumption utility is the smallest (this is the second phase
of the optimization). This selection criterion ensures that the agent’s consumption decisions are
robust to uncertainty about the true model
      The third phase of the optimization is most important. The agent allocates attention to di¤erent
aspects of the income process, which allows her to endogenously limit the degree of ambiguity she
faces. When the agent pays more attention to a particular aspect of income, such as its low-
frequency behavior, she receives information about its true behavior along that dimension and the
set of plausible models narrows.
      We solve three phases of the optimization analytically and are therefore able to sharply establish
our main result: the agent directs almost all attention to the behavior of income at the lowest
frequencies (i.e. at long horizons). Because of this direction of attention, the agent’s model is
more accurate at lower frequencies than at higher frequencies. The agent learns in this manner
because the low-frequency dynamics of income matter more for expected consumption utility than
the high-frequency dynamics. By learning about low-frequency dynamics, the agent can deem many
painful income processes implausible and therefore avoid selecting them in the second phase of her
optimization.
      Using this intuitive result, we derive two key implications for the agent’s beliefs and behavior:

   1. At short horizons, the agent’s consumption growth is positively correlated with the predictable
        component of income growth. This comovement violates the permanent income hypothesis
        (Friedman (1957), Hall (1978)) but matches the extensive empirical evidence on the excess
        sensitivity of consumption to income (Jappelli and Pistaferri (2010), Kaplan and Violante
        (2014)). Because the agent fails to learn about the high-frequency characteristics of the
        income process, much of the predictable variation in income surprises her and therefore leads
        her to adjust her consumption.

   2. The agent neither over- nor under-extrapolates current shocks to income when forecasting
  3
    During this phase of the optimization, no dynamic learning about the model occurs. For boundedly rational
models of dynamic learning, see Abel, Eberly, and Panageas (2007, 2013), Wang (2009), Bansal and Shaliastovich
(2010), Hansen and Sargent (2010), Ju and Miao (2012), and Collin-Dufresne, Johannes, and Lochstoer (2015).



                                                      2
       long-run future income. This lack of bias results from two o¤setting forces in the agent’s
       optimization. Ambiguity aversion pushes her towards adopting an overly persistent model, as
       is typical in the literature on model selection under ambiguity aversion (Hansen and Sargent
       (2010, 2015), Bidder and Dew-Becker (2016)).4 But the agent’s extra attention to the low-
       frequency behavior of income undoes this bias, as her knowledge attenuates her fears of
       persistent income processes.

    What connects the two theoretical results is that high-frequency mistakes have minimal impli-
cations for lifetime utility, while low-frequency mistakes can have substantial e¤ects. That idea has
been suggested as an explanation for the excess sensitivity puzzle, and our model formalizes it.5
People cannot achieve perfection, so they choose to make mistakes that are minimally costly.
    After establishing these theoretical results, we explore them in a numerical example to quantify
the importance of directed attention in guiding beliefs and behavior. As a comparison, we study
the model adopted by the agent when she is restricted to allocate the same amount of attention to
each part of the spectrum. This “…xed-attention” model provides the optimal statistical …t of the
true spectrum and corresponds to the boundedly rational model studied by Fuster, Hebert, and
Laibson (2011). In addition to con…rming the theoretical results numerically, we …nd that attention
allocated to low frequencies is 80 times higher under directed attention than …xed attention.


1     Environment and information
We begin by laying out preferences. We then describe the space of income processes, and …nally
the structure of the uncertainty that the agents face.

1.1    Preferences
We study agents who solve a consumption-savings problem under ambiguity aversion over model
uncertainty. They face the following budget constraint.

Assumption 1 Financial wealth, Wt , follows the process

                                              Wt = RWt       1   + Yt   Ct                                           (1)

where Ct is consumption, Yt is income, and R is a …xed gross interest rate.

    We denote possible income processes f^.
    The agent’s preferences are represented by the following optimization.
   4
     A bias towards belief in overly persistent processes is present also in the boundedly rational frameworks of Fuster,
Hebert, and Laibson (2011) and Bordalo, Gennaioli, and Shleifer (2016).
   5
     See Cochrane (1989), Eichenbaum (2011), and Kueng (2016) for discussions of the small utility costs of excess
sensitity to transitory income shocks.



                                                           3
Assumption 2 Agents choose signal precision                  and a consumption policy C policy according to
                          "                              "1                                  #!#
                                                          X
                   max E G           max         min E               1 t
                                                                           exp (    Ct ) j f^    ;        (2)
                                 C policy f^2F (x; )
                                                         t=0

where E denotes the expectation operator and G is a strictly increasing function that will be de…ned
in equation (26) below. C policy is a typical consumption rule mapping current wealth, Wt , and the
income history, Y0 ; :::; Yt , to consumption, Ct . The optimization is subject to the budget constraint
(1) and a transversality condition.

   The inner max min pair represents ambiguity averse preferences similar to those of Gilboa and
Schmeidler (1989). The agent’s aim is to maximize discounted utility over consumption, where
is the coe¢ cient of absolute risk aversion and          the time discount factor.
    The source of uncertainty that the inner expectation applies to is the future realizations of
income. Conditional on a (functional) parameter f^, agents calculate expectations over income
realizations, and hence future consumption, using Bayes’rule.
    The parameter f^ is unknown. If people were Bayesian expected utility maximizers, they would
choose the consumption policy to maximize expected utility under a probability measure for f^.
That is, we would have
                                     Z       "   1
                                                                               #
                                                 X
                           max           E             1 t
                                                             exp (    Ct ) j f^ d     f^                  (3)
                          C policy
                                                 t=0


where d    f^ represents a probability density over models. f^, is a potentially in…nite dimensional
object. We therefore take the position that it is not reasonable to assume that people are able
to fully articulate a probability distribution over all possible values of f^ (the work of Hansen and
Sargent (2007) on robust control is motivated similarly).
   Instead, we model agents as ambiguity averse. They believe that f^ may fall into a set F (x; ),
where x is a set of signals about the true model that they receive, which have precision . The
consumption policy is chosen to maximize expected utility with the understanding that nature will
then select the least favorable value of f^ 2 F (x; ).
   The outer expectation is taken over possible realizations of the signals x. The agent chooses
the signal precisions,   , to maximize the expected outcome of the ambiguity-averse consump-
tion/savings problem. Intuitively, an agent that receives high-quality signals about income dynam-
ics will have a smaller set F (x; ), thus reducing the e¤ects of ambiguity. The function G is applied
to expected utility conditional on the signals for reasons that we discuss below.
    Note that if there were no model uncertainty, so that the true model f is known, then the agent is
                                                                                     P1         1 t exp (
solving a standard consumption-savings problem under CARA preferences: max E           t=0                      Ct ) .
Our analysis therefore ignores wealth e¤ects, but it is also more realistic than the assumption of
quadratic utility over consumption used in Hansen, Sargent, and Tallarini (1999), among others.


                                                         4
       Finally, it is also important to note that this is in certain regards a date-0 problem. Agents
receive signals about the income process once. They then choose an optimal consumption policy
that is meant to be robust to model uncertainty. We do not model how people update information
about the income process (f^) over time. That said, consumption is chosen fully dynamically in
that the policy conditions on the past histories of wealth and income.
       The remainder of this section de…nes more formally the various terms in assumption 2. We
then proceed to solve the three optimization problems in section 3 and examine their implications
in section 4.

1.2      Income
Assumption 3 Consumers face an exogenous and untradeable stochastic income stream, Yt , that
follows the process

                                           Yt = a (L) Yt      1   + b0 "t                                         (4)
                                           "t       i:i:d: N (0; 1)                                               (5)

where a (L) is a power series in the lag operator, L. We assume a (L) is such that Y is well behaved
(in particular, has a spectrum that is positive and bounded).6

       This is a standard baseline setup for time series models. While linearity and Gaussianity are
certainly restrictive assumptions, they are in line with the past work we build on.
       Much of our analysis will apply to the Wold representation,

                                                 Yt = b (L) "t ;                                                  (6)
                                                           b0
                                        where b (L)              :                                                (7)
                                                      1 La (L)
                                                                                    P1          j ).
The coe¢ cients in the power series b (L) are denoted bj (i.e. b (L) =               j=0 bj L          Throughout the
paper, we refer to models in the time domain in terms of b (L). Since the distribution of "t is …xed,
b (L) completely characterizes the statistical distribution of income. To be clear, though, the agent
forecasts the future using only the past history of income. The "t are not directly observable.
     Agents do not know the true income process. Alternative possible income processes are denoted
^b.7 Our focus is on uncertainty about the dynamics of income, rather than about the distribution of
   6
     The assumption that Yt is a linear Gaussian process is not necessary for most of the results. The critical
assumptions about the true income process are that it is second-order stationary and that it has a spectral density
that is …nite and bounded away from zero. The distribution of the innovations is largely irrelevant (though it is
important that it is …xed over time).
   7
     Agents forecast with ^b the same way they would with b,
                                         h         i X1
                                       Et Yt+n j ^b =   ^bn+k ^b (L)   1
                                                                           Yt   k                                 (8)
                                                       k=0




                                                        5
its innovations. The latter question is obviously also interesting, but our goal here is to understand
how consumption responds to changes in income, and how well people understand the di¤erence
between permanent and transitory dynamics. An interpretation of our analysis is that it derives
optimal attention to di¤erent aspects of income dynamics conditional on a choice having been made
about how much attention to pay overall to dynamics versus the distribution of income innovations.

1.3     Signals about the spectrum of income
The key type of uncertainty that agents face is over the model that drives income. The de…nitions
above are in the time domain, but our analysis examines a rotation, using the Fourier transform,
into the frequency domain. The Fourier transform is used in time series analysis because it or-
thogonalizes problems. In our setting, one way for an agent to model income is to estimate its
autocovariances (cov (Yt ; Yt   j )).   But estimates of autocovariances are in general correlated across
lags, and one must impose complicated restrictions to guarantee positive de…niteness, both of which
substantially complicate the analysis.
   Those issues do not arise in the frequency domain. In what we describe here, agents receive
signals about features of the income process that are mutually orthogonal and always generate
a positive de…nite covariance matrix for income. So a primary reason that we model agents as
learning in the frequency domain is that such learning represents acquiring information about
fundamentally independent aspects of the income process. We will show, though, that there is a
direct link between estimation in the frequency and time domains, so there is no deep restriction
on behavior; rather, the transform is used yield analytic and economically interpretable solutions.
   The next subsection de…nes the frequency transform. We then describe precisely how agents
acquire information about income dynamics. Last, we discuss the relationship between the infor-
mation scheme used here and those studied in models of rational inattention.

1.3.1    The Fourier transform and its distribution

The spectral density of the income process is de…ned as the Fourier transform of the autocovariances
and thus also fully represents income dynamics:
                                                 1
                                                 X
                                  exp f (!)            cos(!j) cov(Yt ; Yt   j ):                     (9)
                                                j= 1


(the notation f is used for the log spectrum because that is what maps most directly into utility).
As f is periodic, we restrict attention to the domain ! 2 [0; ]. There is a one-to-one mapping
between the spectral density and the autocovariances since they are a Fourier transform pair. One
simple interpretation of the spectrum is that it represents a variance decomposition for income in




                                                        6
terms of ‡uctuations at di¤erent frequencies:
                                                         Z
                                                     1
                                    var (Yt ) =                   exp (f (!)) d!:                            (10)
                                                           0

exp (f (!)) measures the contribution of ‡uctuations in income at frequency ! to the total variance
of income. The relative magnitude of f across frequencies determines the extent to which variation
in income is driven by low- versus high-frequency ‡uctuations. An AR(1) process with an autocor-
relation near 1 has a spectrum whose mass is isolated at low frequencies, whereas a process that
features reversals, such as xt = "t          (1=2) "t    1,    has a spectrum with mass concentrated at high
frequencies (those near ).
    As with b and ^b, f is the true log spectral density of income, while alternative hypothetical
spectra are denoted f^. The agent can construct forecasts of future income based on f^ since there
is a unique ^b associated with each f^ (Priestley (1981) section 10.1).
   The key feature of the spectrum for our purposes is that sample estimates of it are asymptotically
uncorrelated across frequencies:

Lemma 1 Denote the sample autocovariance of a mean-zero time series

                                                                      T
                                                                      Xj
                                                                  1
                                       v~j      (T       j)                 Yt+j Yt ;                        (11)
                                                                      t=1


and de…ne exp f~ (!) to be the sample analog of (9). Then as T ! 1,
                                                h                             i
                                               E f~ (!)               f (!)       !                          (12)
                                                                                        2
                    cov f~ (! 1 )   f (! 1 ) ; f~ (! 2 )          f (! 2 )        !         1 f! 1 = ! 2 g   (13)
                                                                                        6

for ! 2 [0; ], where   is Euler’s constant and 1 f g is the indicator function.

Proof. This result follows directly from Brillinger (1981) theorem 5.2.6.
   Lemma 1 shows why we study income dynamics in the frequency domain: the sample spectrum
yields an estimate of the true spectrum with errors that are asymptotically uncorrelated across
frequencies. In what follows, we assume people use the asymptotic approximation and treat the
spectral estimates as truly uncorrelated across frequencies.
   Intuitively, estimating the sample spectrum is not fundamentally di¤erent from estimating sam-
ple autocovariances – they are linear transformations of each other and hence contain the same
information. So in estimating the spectrum, people are e¤ectively learning about the properties of
income by directly calculating its autocovariances.




                                                              7
1.3.2    Information acquisition method

Information acquisition happens prior to the consumption policy being chosen; this step can be
thought of as happening behind a veil of ignorance, before realizations of the agent’s own income
history have occurred. We assume that people gather information by estimating the log spectrum on
observed income histories driven by the same model that will drive their own income. For example,
a person who knows they will become an economist might investigate the income histories that older
economists have received. These observations and calculations are costly, though, so we assume
that people are limited in the number of measurements of spectra (equivalently, calculations of
autocovariances) that they can undertake.
    More speci…cally, we assume that there is a large dataset available that reports the income
histories of many people, all of whom have the same parameters determining their income processes
(i.e. the same f and hence b), but di¤erent realizations (di¤erent "’s). To obtain information about
the log spectrum of income at some frequency ! j , the agent calculates the sample spectrum for                         j
of those income histories.
    Combining the central limit theorem with lemma 1 above, the mean of f~ (! j ) +                  across many
                                                                                                         2       1
income histories is asymptotically normally distributed with mean f (! j ) and variance                 6    j       (we
              2
ignore the   6    scaling in what follows). To represent limited information capacity, we assume that
the sum of the total calculations that an agent may perform across all frequencies is limited. That
   P
is, j j is limited (section 4.5 generalizes the constraint to allow for di¤erential information costs
across frequencies).8
    For technical reasons (to avoid in…nite information ‡ows, for example), we assume that the
agent gains information on the spectrum on the uniform discretization of [0; ] given by ! j = j=n
for j 2 f1; :::; ng and we take n as large. We scale the variances by d!                =n so that they can be
interpreted as the information density at each point.

Assumption 4 The agent receives signals fx (! j )gj=1;:::;n that are distributed as

                                                                       1
                                     x (! j )   N f (! j ) ; (! j )        =d!                                       (14)

where the errors are uncorrelated across frequencies. In choosing the precision of their signals,
agents face the constraint
                                                n
                                                X
                                                      (! j ) d!    :                                                 (15)
                                                j=1

    If   di¤ers across frequencies, that means that the agent calculated the sample spectrum for
more income histories at some frequencies than others. That is, they have many income histories
   8
     Note that in the interest of conserving e¤ort, an agent can calculate the spectrum most e¢ ciently by simply
calculating the squared Fourier transform of the income history itself –
                                                                       Pthat is numerically equivalent to taking the
Fourier transform of the sample autocovariances. The constraint on       j j is then a constraint on the number of
Fourier transforms the agent may calculate.



                                                         8
to examine, but for frequencies that they learn less about, they only estimate the spectrum using
a small number of them, and the e¤ort saved is allocated elsewhere.
   A natural statistical benchmark is for the agent to instead use equal information at all frequen-
cies –i.e. to calculate the entire spectrum for each income history –making no attention allocation
decision. In that case, the function   is constant across frequencies.
   The estimation scheme that we endow agents with is the standard nonparametric method for
estimating the spectrum. If agents knew the speci…c parametric form of the income process, e.g.
that it was an ARMA(p; q) for known p and q, then they could estimate it more e¢ ciently through
maximum likelihood. We instead leave their model uncertainty unstructured, which makes nonpara-
metric analysis based on the periodogram most natural. The lack of structure is in fact precisely
what delivers the independence across frequencies that will make our analysis tractable.

1.3.3    Relationship with rational inattention

Rational inattention provides an alternative and equally important interpretation of the information
structure. It is possible that complete information about the spectrum of income is available, but
agents have trouble processing it. Then the noise in the signals x (! j ) represents cognitive errors
that people make in interpreting the available information. The frequencies at which      is larger are
the ones the agent pays the most attention to.
   In terms of the literature, the signal structure we analyze is highly similar to that in Kacperczyk,
Van Nieuwerburgh, and Veldkamp (2016) in that agents receive signals with normally distributed
error and they are constrained by the total precision of the signals. This constraint is most natural
when each independent observation of the spectrum is equally costly to obtain. Sims (2003) proposes
an alternative constraint based on information ‡ow or entropy. In our setting, the total entropy
                 P
of the signals is nj=1 log ( (! j ) d!), so high-precision signals are relatively less costly under an
entropy constraint.
   That said, our setting is more restricted than the fully general rational inattention speci…cation:
the information the agents acquire is always independent across frequencies (which is motivated
by the fact that statistical estimates of the spectrum are independent across frequencies) and the
errors are Gaussian (motivated by the central limit theorem). In the most general form of the
models that Sims (2003) studies, those restrictions need not hold. However, they are commonly
imposed elsewhere, as in Kacperczyk, Van Nieuwerburgh, and Veldkamp (2016).

1.4     Priors and model plausibility
Agents measure the plausibility of models, and de…ne the set they worry about, F (x; ), based
on their signals and a prior. Given that the model space is in…nite-dimensional, it is di¢ cult to
imagine that a person would have a fully de…ned prior, though. People likely cannot place a formal
probability on every possible model, or even necessarily express a view about the relative likelihood
of all possible pairs of models. That fact motivates our use of ambiguity aversion, and it leads us


                                                  9
to specify prior beliefs as loosely as possible.
    We assume agents believe that the log spectrum is likely to be smooth in the sense that its
di¤erences across frequencies have limited variation. The smoothness prior is a belief in simplic-
ity: agents believe that spectra typically are smooth across frequencies, rather than ‡uctuating
wildly. Following Shiller (1973), Akaike (1979), and Kitagawa and Gersch (1984, 1996), the prior
is represented by a penalty on variability that is appended to the likelihood of the data.9 Given
assumption 4, the penalized log likelihood of the data given a model f^ is

                                n                                             n
                                                                                                                  !2
                             1X                           2                   X     f^ (! j )      f^ (! j   1)
    P L x j f^;      =          x (! j )      f^ (! j )       (! j ) d!                                                d! :   (16)
                             2                                            2                      d!
                               j=1                                            j=2
                         |                   {z                      }    |                     {z                       }
                                       Data likelihood                               Roughness penalty


P L x j f^;      depends on two factors: the log likelihood for normally distributed data and a term
encoding the belief in smoothness. Models are viewed as less plausible when they are rougher or
more complicated in the sense of having a larger average squared derivative. The most plausible
models have perfectly ‡at spectra – white noise – while the least plausible have highly variable
spectra.10;11
    The parameter            controls the strength of prior. For any …xed , as the signal precision grows
large, the smoothness penalty becomes irrelevant. One reason we include the smoothness prior is
that without it, f^ = x is the maximum-likelihood estimate, which would imply that f^ has in…nite
variation and would yield an inconsistent estimate of f , even as n ! 1 (Wahba (1980)).
    The smoothness prior also implies that when people have weak signals, they use simple and
smooth models. Complexity here only arises when people have a wealth of information. When
signals are more precise, so that           is large relative to , the roughness penalty is relatively less
important and the agent will consider more complex models.
    The penalized likelihood leads to the following assumption:

Assumption 5 Nature chooses the income process from the set
                                                n                                o
                                       F (x; ) = f^ : P L x j f^;               L                                             (17)

    In addition to the roughness penalty, we also assume that agents are able to express a prior
mean over possible models. In the absence of any information about the world, they believe the
   9
     The smoothness prior is often explicitly juti…ed as a belief in simplicity. In Shiller (1973), which is the …rst
application of such a prior, a justi…cation is that “[i]n most applications...the researcher will feel that...the lag
coe¢ cients should trace out a ‘smooth’ or ‘simple’ curve.” While Shiller’s (1973) smoothness prior is stated in the
time domain, those in Akaike (1979) and Kitagawa and Gersch (1985, 1989) are speci…ed in the frequency domain in
a manner almost identical to ours.
  10
     That white noise is treated as the most plausible is also sensible from an information theoretic perspective since
Gaussian white noise has the greatest Shannon entropy among all time series processes with a given variance.
  11
     An alternative way to penalize complexity in models would use the coe¢ cients of the ARMA representation. We
will see below, though, that the smoothness prior we impose here also ends up imposing smoothness on the AR and
MA coe¢ cients.


                                                              10
average spectrum is ‡at at f . This assumption is introduced so that it is possible for the agent
to calculate expectations for f^ prior to observing signals (i.e. the outer expectation operator in
assumption 2).
    At this point, all the basic terms in the preferences in assumption 2 have been de…ned. The
next section examines the three optimizations.


2     Solution
All three optimizations in the preferences –the consumption policy, nature’s choice of a model, and
the information decision –are analytically solvable. The solution is itself an important contribution
of the paper. There is little work that obtains closed-form solutions for optimal consumption under
model uncertainty and rational inattention, and the fact that the model can be solved when model
uncertainty and attention are themselves endogenous is even more surprising. We analyze the three
pieces of the optimization in turn.

2.1   Optimal consumption conditional on a model
The minimax theorem implies that the inner maximization and minimization in the preferences (2)
can be reversed. Intuitively, the operations represent a zero-sum game with a pure strategy Nash
equilibrium. We …rst solve for the optimal consumption given a model.

Lemma 2 The consumption policy that maximizes expected utility conditional on some ^b is

                                                                                1              1   ^b R    1 2   1 log   R
             Ct = (R      1) (Wt      1   + z^ (L) ^"t )                R           1    R                                 ;   (18)
                                                                    2                                             R      1

where z (L) is a lag polynomial with coe¢ cients
                                                                1
                                                                X
                                                                                (k j)^
                                                        z^j =               R        bk :                                      (19)
                                                                k=j


Expected utility from consumption is then
                                 "                1
                                                                                     #
                                                  X
                      max E                   1         t
                                                            exp (           Ct ) j ^b
                     C policy
                                                  t=0
                            1              2                                                          (1     ) log R
                                                    1                   1   ^b R        1 2
                 =              exp            R        1       R                             + log           +           :    (20)
                     1                    2                                                            1    R   R 1

    Lemma 2 provides two useful results. First, it shows that we obtain a standard consumption
function: agents consume the annuity value of …nancial plus human wealth, (R 1) (Wt 1 + z^ (L) ^"t ),
                                                             2
minus a precautionary saving term 2 R 1 1 R 1 ^b R 1 . The behavior of consumption thus
depends on beliefs about income dynamics through two channels. First, ^b a¤ects the riskiness of


                                                                        11
the income stream, and hence the amount of precautionary savings agents desire to hold. Second,
and more importantly, current consumption depends on beliefs about future income, which are
                                                                      P
driven by ^b. When ^b implies that income shocks are more persistent ( 1
                                                                       k=j R
                                                                             (k j)^
                                                                                  bk is larger)
consumption responds more strongly to the shocks. These are all standard results. Deviations
of the behavior of the agents in our model from the standard permanent-income predictions are
caused by deviations of their model, ^b, from the truth.
   Lemma 2 also characterizes optimized expected utility from consumption for a given income
                                                              2
process ^b. The only term that di¤ers across models is ^b R 1 , which measures the variance of
innovations to permanent income, and hence the variance of consumption growth. Utility is lower
when the variance of consumption growth is higher.
   The information structure laid out in the previous section refers entirely to the log spectrum,
but utility is derived in lemma 2 terms of the lag polynomial ^b. We link the two through the
following novel result.

Lemma 3 For a log spectrum f^ that is bounded from above and below, where ^b (L) is the associated
Wold representation,
                                                             Z
                                              1 2        1
                                   log ^b R         =               Z (!) f^ (!) d!;                              (21)
                                                               0
                                                                   1
                                                                   X
                                                                                      j
                                   where Z (!)          1+2              cos (!j) R       :                       (22)
                                                                   j=1


       Lemma 3 gives us a powerful result: log ^b R          1 2,   the statistic that determines expected utility
from consumption conditional on a model, is linear in the log spectrum. This result is the key novel
mathematical innovation in the paper that will allow us to solve the model analytically, and it is
likely useful in other contexts, since it is general result for NPV innovations.12
    Lemma 3 shows that utility is always decreasing in f^, which implies utility is decreasing in the
variance of income growth. Moreover, though, utility depends on di¤erent frequencies di¤erently,
according to the function Z. The frequency domain is useful here for showing how risk at di¤erent
frequencies drives utility. The left-hand panel of …gure 1 plots Z for an annual calibration with
R = 1:025. Z (!) > 0 for all !, it is bounded from above for R > 1, reaching its maximum at ! = 0,
and it is decreasing on (0; ). When R = 1, Z is equivalent to the Dirac delta function. The mass
of Z primarily lies on extremely low frequencies. So what matters for the agent’s utility, through
  12
    Lemma 3 does not appear to have been previously noted in the literature, and we are not aware of any direct
derivation from known results. It is a generalization of the Szeg½o–Kolmogorov formula for the innovation variance of a
time series. Speci…cally, ^b (0)2 is the innovation variance,
                                                       R      which the Szeg½o–Kolmogorov formula says is the geometric
mean of the spectrum. The equation ^b (1)2 = exp          (!) f (!) d! for the Dirac delta function is also well known.
So lemma 3 …lls in ^b (x)2 for x between 0 and 1.
  The innovation variance for the NPV of a time series arises naturally in many economic settings, such as the
consumption/savings problem here, equilibrium macroeconomic models (Hansen and Sargent (1980, 1981)), models
with generalized recursive preferences (Bidder and Dew-Becker (2016); Dew-Becker and Giglio (2016); Dew-Becker
(2016)), the q theory of investment, and Calvo-type price setting. The appendix provides a proof.



                                                          12
^b R   1 2,   is the variance of the most persistent components of income. Transitory ‡uctuations in
income do not pass into consumption. Rather, permanent income shocks change human wealth,
and thus consumption, hence reducing utility. These characteristics of the utility function and Z
are robust features of the model, as they do not depend on any sort of detailed calibration – the
only parameter a¤ecting Z is the gross interest rate.13

2.2     Nature’s minimization
Since ^b R        1 2
                is the only term in (20) that di¤ers across models, nature’s minimization problem
                                                                       R
in (2) is equivalent to choosing f^ from the set F (x; ) to maximize 0 Z ( ) f^ ( ) d . Nature’s
Lagrangian is                                     Z
                                              1
                                   min                    Z (!) f^ (!) d!               P L x j f^;            ;     (23)
                                 f^2F (x; )       0

where         is a Lagrange multiplier. We refer to the model that achieves the minimum in (23) as
fw   (!; x; ) :
     It is straightforward to solve for f w from the …rst-order conditions for the nature’s optimization.
The solution can be obtained most easily by creating vectors (in boldface) of the form f w (x; )
[f w (! 1 ; x; ) ; :::; f w (! n ; x; )]0 (recall that the frequencies ! j = j=n are the uniform discretization
of the interval [0; ] on which the agent receives signals and that we think of n as large). We de…ne
diag ( ) to be an operator that creates a matrix with its argument on the main diagonal and zeros
elsewhere.

Proposition 1 The model that solves (23) is

                                                                                   1
                            f w (x; ) = In    n           diag        1
                                                                          D                 diag           1
                                                                                                               Z+x   (24)

where In      n   is an n     n identity matrix and D is a di¤ erencing matrix of the form
                                              2                                             3
                                                      1     1     0                    0
                                              6                                             7
                                              6   1          2    1                         7
                                              6                                        ..   7
                                              6                           ..                7      2
                                      D       6   0         1      2           .        .   7 d!       :             (25)
                                              6                                             7
                                              6   ..             ..       ..                7
                                              4    .                .          .       0    5
                                                  0               0       1             1

     f w is a linear function of x and Z. The worst-case spectrum is higher at frequencies where                       is
smaller –there is more uncertainty about the spectrum –and where Z is larger –increases in the
  13
     The analysis so far has assumed income is stationary. That assumption has no e¤ects on our results. In the
presence of a unit root, the analysis applies to the …rst di¤erence of income. If g^ (L) is the Wold representation for
                                                                                                                  2
the …rst di¤erence of income, then ^b R 1 = g^ R 1 = 1 R 1 . The agent then can calculate log ^b R 1 by
                                                                                              1
using Lemma 3 applied to the log spectrum of income growth and subtracting log 1 R              . The loading of utility
on frequencies for the level of income is the same as for the …rst di¤erence.



                                                                  13
spectrum are more painful. Similarly, when                        is larger, so that the agent is more ambiguity-averse,
the worst-case model tilts more in the direction of Z.
       Before analyzing the implications of proposition 1 in detail, we …rst solve the agent’s optimal
to help frame the e¤ects of information choice on consumption behavior.

2.3       Optimal information choice
Consistent
 h          with
              i nature’ s decision, we assume that agents choose information so as to minimize
   w      1 2    1
                   R             w
E b R          =     0 Z (!) E [f (!; x; )] d!. The reason we choose that particular function to
minimize, beyond the fact that it is the measure of risk that drives utility, is that it can be calculated
under the incomplete prior that agents have. Recall that agents do not have a fully speci…ed prior
over f ; they only have a mean and a belief in smoothness. But since f w is linear in x, its mean is
well de…ned under those beliefs. So assuming agents minimize bw R                                  1 2   allows us to specify the
least informative prior possible –one that has only a mean.
       The assumption that information is chosen in order to minimize the expected riskiness of income
immediately yields a functional form for G:

Assumption 6

                                                                                                                     1
                    G (x)        log log          (1    R) ( R)1      R
                                                                          x + log 2        2
                                                                                               R 1       R   1
                                                                                                                             (26)

       While that function looks complicated, its purpose is that it yields a simple reduced-form version
of the preferences (2):
                            "                     Z                       #            "                                 #
                                              1                                                                  1 2
                   max E          min                  Z (!) f^ (!) d! = max E             min           ^b R                (27)
                                f^2F (x; )        0                                      ^b2B(x; )


where B denotes the set of valid ^b induced by F .14 That problem has a simple solution.

Proposition 2 The optimal information policy under the preferences (2) (and (27)) is

                                                    1=2                       1=2
                                (! j ) =                                                      Z (! j ) :                     (28)
                                           Shadow cost of info.     Ambiguity aversion     Utility weights

                                                                                           P
where       is the Lagrange multiplier on the information constraint,                          j   (! j )        .

       Recall that the function Z measures how the level of the log spectrum, f , a¤ects utility. Agents
optimally gather information exactly in proportion to Z, learning the most about the frequencies
that are most important for utility. In terms of the adversarial game with nature, the agent chooses
precision to constrain nature most at the frequencies that are potentially most painful. Since
                                                             2
  14
       Technically, B (x; ) =      ^b : P L x j log ^b ei!          L     subject to the additional restriction that ^b be a Wold
representation of some process.


                                                                   14
also controls the potential complexity of f w , the agent’s choice of               implies that models are most
complex where Z is highest –very low frequencies.
    While Z controls the shape of         ,   and       determine its scale. An increase in the available pre-
cision     lowers the Lagrange multiplier , leading to more precision at all frequencies.                    determines
the extent to which nature is constrained by the penalized likelihood, i.e. how ambiguity-averse
people are. Holding the shadow cost                of precision constant, a decrease in ambiguity-aversion
through       lowers the chosen precisions.
    To see the implication of proposition 2 for noise in the signals at each frequency, the right-hand
                                  1             1
panel of …gure 1 plots Z (!)          /   (!)       . The variance of the signals that the agents receive is a
simple function of frequency, rising smoothly as the frequency increases (it is an a¢ ne function of
cos (!)).
    Lemma 2 and propositions 1 and 2 give the complete analytic solution to the model. The
remainder of the paper analyzes the implications of the solution for the types of models that agents
optimally use and how those choices a¤ect observable consumption behavior.


3     Behavior of the model agents use
We have two relevant cases for . The utility-optimal information policy,                             (!), says that it is
proportional to Z (!), while the statistical benchmark is to set              (!) to equal a constant. We focus
on two key results for    fw   under those policies:

    1. Optimal learning eliminates excessive extrapolation: Without an optimal information
         ( ) policy, the worst-case model displays excessive persistence compared to the truth –people
         over-extrapolate shocks. But under optimal information ( ), that bias disappears.

    2. Agents make mistakes primarily about the transitory component of income: Under
         the optimal policy, agents use models that tend to deviate from the truth more at high than
         at low frequencies.

    This section derives those results theoretically and examines them in numerical simulations of
the model.

3.1      Optimal learning eliminates excessive extrapolation
Taking an expansion around an in…nite level of precision, the appendix derives the following …rst-
order approximation in the continuous limit of the problem (d! ! 0) for arbitrary :

                                                                1                   1
                       E [f w (!; x; )    f j f]          (!)       Z (!) +   (!)       f 00 (!) :                  (29)

    Equation (29) yields our …rst important result. In the statistical benchmark case where                            is
constant across frequencies,      fw   is biased in the direction of Z (!). Recall from …gure 1 that Z


                                                          15
is large at low frequencies and close to zero elsewhere. So under the statistical benchmark, the
worst-case model has excessively high power at low frequencies, which means that it implies is
more persistent than the truth (f ). That result is almost exactly what is obtained in Bidder and
Dew-Becker (2016), and is closely related to results in Hansen and Sargent (2010, 2016). Intuitively,
since highly persistent models lead to the lowest utility, the agent naturally fears them.
   Equation (29) also yields the more important part of the result, though, which is that under
the optimal policy,     , there is no systematic bias towards either under- or over-extrapolation.
Speci…cally, we have under the optimal policy

                                                                         1
                       E [f w (!; x;   )   f j f]    1=2 1=2
                                                               +   (!)       f 00 (!) :             (30)

Since     (!) / Z (!), the frequencies that are most important for utility are also the ones that
the agent learns the most about, thus constraining the worst-case model. The proportionality
completely cancels Z out of the bias, leaving just a constant.
   When f w deviates from f by only a constant, the two models have identical autocorrelations and
di¤er only in the conditional variances. For example (ignoring the e¤ects of f 00 for the moment; i.e.
for small ), if income follows an AR(1) process with persistence , then E [f w ] is the log spectrum
for an AR(1) also with persistence , but with innovations that have a greater variance.
   Equation (30) is a key result of the paper. It shows that endogenous learning can completely
eliminate overextrapolation. Intuitively, ambiguity averse agents tend to focus on models with
excessive persistence because they are associated with low utility. But that fact also causes them
to obtain the most information about those frequencies, thus entirely canceling out the e¤ect of
ambiguity.
   This result stands in con‡ict with recent work that argues that ambiguity aversion and informa-
tion processing constraints lead to overextrapolation. What we show here is that when people are
able to choose what aspects of income to learn about, they naturally focus on the low frequencies,
since those are most important for utility. But it is precisely that focus that then eliminates any
bias towards excessive extrapolation.

3.1.1     Numerical example

To make the result above more concrete, we consider a simple numerical example. Suppose income
is truly i.i.d. over time, Yt = "t , so that the true model has zero persistence. Since f 00 (!) = 0, the
second term in equations (29) and (30) is equal to zero. The left-hand panel of …gure 5 plots the true
(‡at) log spectrum f (!) along with the mean worst-case spectra under the optimal information
policy     and for the statistical benchmark in which is constant across frequencies (the calibration
                                                 P            P
is set so that they have equal total precision:    j  (! j ) = j ), which we denote with f w and
fFw , respectively. The …gure shows that f w is shifted up by a constant compared to f , while fFw
actually has a signi…cantly di¤erent shape, with a peak at low frequencies indicating persistence in
income.


                                                    16
       The right-hand panel of …gure 5 plots the impulse response functions (the b’s) associated with
the three models. Since income is truly i.i.d., bj = 0 for j               1 under the true model. Under the
optimal information policy with model uncertainty, the only thing that changes on average is that
b0 becomes larger –people fear a higher variance, but they do not on average act as though income
actually has any persistence. Under the statistical benchmark, though, there is clearly persistence
in income: the impulse response is consistently positive after the initial impact. Figure 5 thus
illustrates our …rst basic result. While ambiguity aversion and model uncertainty can often drive
agents to act as though income is excessively persistent, that result is delicate: it disappears when
people can allocate attention and information acquisition optimally.

3.2      Agents make mistakes about the transitory component of income
The primary mistakes in the agent’s worst-case model come from the term involving f 00 (!). That
part of the formula is driven by the agent’s smoothness prior. In the face of noisy data, agents
estimate the spectrum of income by smoothing information across frequencies. Since f w (!; x; )
is a convex combination of the data x local to !, it is biased upward when f 00 > 0 and downward
when f 00 < 0. Intuitively, if there is a narrow peak in f , a simple model will tend to smooth the
peak out, and thus be biased downward.
       In that sense, the agents also have a bias towards simplicity: they use models with smaller
variations across frequencies when they have less information.15 When the true spectrum is in fact
complex, in the sense that it has local peaks and troughs, the worst-case model will tend to make
mistakes in smoothing those peaks out. So the errors appear exactly where f 00 is large.
       Since the optimal information policy gives the agents noisier signals about the spectrum at high
frequencies, that is also where they make the largest smoothing errors. In (30), f 00 (!) is multiplied
               1
by       (!)       . So when precision is high, the term is scaled down and the worst-case spectrum tracks
the true spectrum closely. But when             is small –at high frequencies –agents do more smoothing
across frequencies and make larger mistakes.

3.2.1      Numerical example

To illustrate the errors caused by smoothing, we now consider a richer numerical example with
multiple peaks in the spectrum that we view as more realistic. The left-hand and middle panels
of …gure 5 plot the log spectrum of the data-generating process for income, while the right-hand
panel plots the impulse response of income to a shock, ". The calibration is chosen to have both
high-and low-frequency components. The high-frequency piece –which generates the middle peak
in the spectrum – is driven by the fact that a component of the shocks to income reverts: when
income rises higher by $1 today, it is lower on average by 50 cents over the next three periods. That
behavior can be caused by forces that shift income over time but have little e¤ect on total lifetime
  15
    That intuition can be formalized. It is possible to show that correlations in the estimated spectrum, f w (!; x; ),
are higher across frequencies, implying that complexity is lower, in regions where is smaller.



                                                          17
income. For example, many people overpay taxes during the year and then receive refunds (e.g.
Souleles (1999)). The low-frequency component of income –the left-hand peak in the spectrum –
comes from the fact that the impulse response is persistently positive in the later periods following
a shock. This represents a persistent component in income growth, and could come from variation
over time in the average growth rate of the economy or the performance of one’s employer.16
       We examine two speci…cations for               : the …rst is the optimum derived above,               , which is
proportional to Z (!); the second speci…cation is the statistical benchmark that sets                         (!) to be
constant at the mean of             :
                                                                         n
                                                                         X
                                             F              F        1
                                                 (! j ) =        n             (! j ) :                             (31)
                                                                         i=1

As in the previous example, the choice of the mean for                         F   implies that it has the exact same
information cost as          . Note, though, that since precision is the inverse of variance, the average
variance of the errors across frequencies is in fact much smaller under                    F   than under    .
       Figure 5 plots   fw   and   fFw   for the two-peak calibration. The two log spectra are rather di¤erent
from each other and the true model. f w matches f very well at the lowest frequencies, but it
does a poor job of matching the middle-frequency peak in f and also deviates substantially at
higher frequencies. fFw has the opposite behavior: it matches the middle-frequency peak and high-
frequency behavior well, and in fact matches f well at almost all frequencies, but it …ts relatively
poorly at low frequencies. That is exactly what the formulas predict: optimal learning,                          , causes
models to be relatively more accurate at low than high frequencies. Overall, though,                   fFw   has a much
better …t than     f w,   with a root mean squared error that is 42 percent smaller, due to the fact that
fFw    spreads information evenly across frequencies.
       The right-hand panel of …gure 5 plots the lag polynomials, b, bw , and bw
                                                                               F , associated with the log
spectra f , f w , and fFw , respectively. bw fails to match the short-run mean-reversion in the income
process, while the lag polynomial for the suboptimal information policy, bw
                                                                          F , does not, as predicted
by the analytic results. The …gure shows that the greater smoothness of f w also translates into
smoothness in the associated lag polynomial, and in particular errors in the transitory behavior of
income. But at longer lags, the …gure shows that the optimal policy performs better, giving a closer
…t to the persistent component of the impulse response function. Since it is the long-run part that
determines human wealth, and hence optimal consumption, it is optimal from an expected utility
perspective for agents to use models that …t the persistent component at the cost of missing the
transitory dynamics.
  16
     Technically, the impulse response function for income is equal to [1,-0.15,-0.3,-0.15,0,...] plus 0:04 exp ( 0:05j).
It is then scaled so that the standard deviation of consumption growth is 1.56 percent (when initial consumption is
equal to 1).
   As discussed above, n is intended to be taken as large – it is only used to avoid in…nities – so we set it to 4000.
                                                          1
  = 0:975 to represent an annual calibration, and R =        for simplicity. , , and are chosen in order to ensure
that the agents make non-trivial mistakes in modeling consumption and that the behavior is visibly di¤erent across
the two policies for . = 10 4 ; = 0:00075; = 405:83. The parameterization is meant to illustrate the qualitative
behavior of the model rather than match speci…c quantitative data.




                                                                18
4      Implications for observable consumption behavior
We now explore the implications of the results in the previous section for the observable behavior
of consumption.

4.1    Consumption function
The consumption function from (18) implies that consumption growth follows

                                              1                                               1 2 w             1 2
                     Ct =         1    R              bw R    1
                                                                  "w
                                                                   t+1 +          1   R          b      R             +    1
                                                                                                                                log R           (32)
                                                                           2
                                              1
           where "w
                  t+1            bw (L)           Yt ;                                                                                          (33)

       1    L is the …rst-di¤erence operator, and bw (L) is the Wold representation associated with
the worst-case model f w . In the case where agents use the true model, so that bw = b (i.e. under
complete information), the …ltered shocks, "w are equal to the true shocks, ", and consumption
follows a random walk with innovations equal to the innovation in the annuity value of the NPV of
future income, 1         R   1   b R      1       "t+1 . When the agent uses a model that di¤ers from the truth,
though,    "w
            t+1   is no longer an i.i.d. process and consumption growth is no longer uncorrelated over
time. That is, the agent’s estimated shocks, "w , are in general serially correlated, which leads to
(suboptimal) serial correlation in consumption growth.
    To better understand the implications of the worst-case model for the behavior of consumption
growth, we can write the log spectrum of consumption growth as

                                                             1 2 w                    2
                  f wC (!; x; ) = log              1     R        b    R   1
                                                                               ; x;           + f (!)       f w (!; x; ) :                      (34)

Just like the spectrum of income, f wC represents a variance decomposition, measuring what types
of ‡uctuations drive the overall variance of consumption growth. When the agent knows the true
model, f wC is perfectly ‡at, which means that consumption growth is uncorrelated over time and
the level of consumption is a random walk. But in general the agent does not know the true model.
For example, if the true spectral density has a peak at some frequency but the worst-case spectrum
does not, then f wC will inherit the same peak through the term f (!)                                                 f w (!; x; ). That is,
features of the income spectrum that the agent “ignores” in the sense that they do not appear in
f w are passed through to the spectrum of consumption growth.
    Using (34), we can immediately map the results in the previous subsections into the spectrum
of consumption growth. Speci…cally, for general information policies and for the optimal policy, we
have

                                                             1 2 w                    2                     1                           1
 E [f wC (!; x; ) j f ]           E log           1      R        b   R    1
                                                                               ; x;               (!)           Z (!)           (!)         f 00 (!)
                                                                                                                                                  (35)
                                                                                                                                                     ;
                                                             1 2 w                        2                                      1
E [f wC (!; x;      ) j f]        E log           1      R        b   R    1
                                                                               ; x;               1=2 1=2
                                                                                                                          (!)        f 00 (!) : (36)



                                                                      19
                                                                                                    1
Again, the information policies di¤er in two key ways. First, comparing the terms             (!)       Z (!)
        1=2 1=2
and               , there are no systematic deviations of consumption growth from white noise under
the optimal information policy. Under other policies, though, since people overextrapolate income
shocks, consumption is actually mean reverting in the long-run – there is a trough in f wC . Intu-
itively, overextrapolation causes people to consume more than they can a¤ord (more than human
wealth) following positive shocks. Eventually, then, they must reduce consumption, causing long-
run mean reversion. So the observable prediction of the model is that we actually should not
observe long-run mean reversion in consumption growth. By the same token, people should also
not underreact to shocks (as under rational inattention), which would lead to long-run persistence
in consumption growth.
                                                                                         1
   The second class of mistakes is the smoothing errors due to the term            (!)       f 00 (!). This
term says essentially that variation in the spectrum of income that the agent is not aware of passes
directly into consumption growth. When f 00 is negative, for example, there is a local peak in the
spectrum of income, and the spectrum of consumption growth then is also relatively high. Again,
these errors are scaled by the precision of signals. The model predicts that consumption should
track income relatively more closely –in the sense that their autocorrelations or impulse-responses
are the same – at high than low frequencies. That is, transitory variation in income, such as the
shifts in income over time studied by Souleles (1999), is predicted to pass directly into consumption.
We illustrate that behavior below in a numerical example.
   Compared to the behavior under the standard setup with no model uncertainty, our model gen-
erates, through limited information, excessive sensitivity of consumption to high-frequency shocks
to income. This result is not obtained, though, by appealing to some sort of irrationality; rather, it
arises simply from people optimally choosing to focus their attention on low frequencies. Endoge-
nous attention leads to our second di¤erence from the literature, which is that unlike other recent
work on model uncertainty (Fuster, Hebert, and Laibson (2012), Bidder and Dew-Becker (2016),
and Hansen and Sargent (2016)), the model does not predict excessive extrapolation of shocks. The
model predicts excess sensitivity to transitory variation in income, but in fact the correct sensitivity
to the permanent component.
   The model also has rather di¤erent predictions from rational inattention over state variables
(as opposed to rational inattention over model speci…cations), which suggest that they could be
tested against each other empirically. As discussed by Sims (2003), the most prominent prediction
of rational inattention is delayed reaction to shocks, due to the fact that people observe the shocks
imperfectly. If income rises permanently, Sims (2003) shows that in general people will take a
number of periods to fully realize that such a shock has occurred, meaning that consumption
responds slowly to permanent shocks to income. Here, on the other hand, agents respond rapidly
to permanent shocks because it is precisely the low-frequency part of income that they understand
best.
   Sims (2003) and Luo (2008) show that rational inattention can also generate excess sensitivity
of consumption to income shocks, but the e¤ects are calibration-speci…c and may be quantitatively


                                                   20
small (e.g. see the simulations in Sims (2003)). Intuitively, excess sensitivity arises because agents
are not able to distinguish permanent from transitory shocks. So to obtain high-frequency mistakes,
the rational inattention model must also predict low-frequency mistakes. In our model, though, the
prediction of optimal information acquisition is in fact that the same attention choice both induces
high-frequency mistakes and eliminates low-frequency mistakes. Furthermore, we see in the next
section that the high-frequency mistakes can be quantitatively large and realistic.17

4.2     Numerical example
We examine the behavior of consumption under the numerical simulation when income has both
transitory and persistent components. Figure 4 plots the log spectra of consumption growth under
the various models. f w provides a closer …t to the utility optimal consumption spectrum at all
frequencies. On the other hand, the statistical information policy produces a spectrum that is
‡atter – and closer to white noise – across most frequencies, but it has a very large peak at the
lowest frequencies. The key question, then, will be which type of deviation –low- or high-frequency
–is more relevant for utility.
      To see how the …tting errors a¤ect the behavior of consumption growth in the time domain,
the right-hand panel of …gure 4 plots the impulse response of the level of consumption to a unit
shock to "t (i.e. a true innovation, not a …ltered one) under the three consumption rules along with
the cumulative impulse response of income (multiplied by 1                   R   1   ). As we would expect, the
response of consumption under the full-information rule is ‡at: the permanent income hypothesis
holds, and the response of consumption is approximately equal to the cumulative increase in income.
The line for consumption under the optimal information policy shows that it inherits some of the
short-run mean-reversion in income, rising and falling in the …rst few periods. It does not include
the persistent component in income, though –consumption immediately jumps to approximately its
long-run level, but the ‡uctuates around that level excessively. So the consumption policy is “right”
in the long-run, but it is excessively sensitive to transitory variation in income in the short-run.
      The behavior of a person using the model f w is again notably di¤erent from one using fFw . The
latter model does a better job of eliminating high-frequency ‡uctuations in consumption, but at the
cost of inheriting the low-frequency behavior of income. The initial response of consumption under
fFw is too small, and consumption slowly drifts upward over the 80 periods of the IRF plotted here,
eventually overshooting. So the         F   policy, counter to what is observed empirically, eliminates the
sensitivity of consumption to transitory ‡uctuations in income, but causes consumption growth to
deviate from white noise at long horizons. This result argues that empirically,                    is a better de-
scription of consumption behavior than a setting where agents do not choose information optimally,
 F.

      Those results may also be observed in more standard time series regressions for consumption
growth. Table 1 below reports the coe¢ cients from simulated regressions of consumption growth on
 17
    It is also worth noting that the models in Sims (2003) and Luo (2008) can only be solved under quadratic utility,
whereas we are able to accommodate CARA preferences here.


                                                         21
the predictable and unpredictable components of income growth under the two information policies
and also under the full-information optimum.18

                     Information policy      Predictable income        Unpredictable income
                                             0.21                      0.95
                      F                      0.06                      0.74
                   Full-info. optimum 0                      0.92
            Table 1. Coe¢ cients from regressions of consumption growth on income growth

       The coe¢ cient from the regression of consumption growth on the predictable part of income is
of the same order of magnitude as the coe¢ cient on the unpredictable part under                     . The model
can thus replicate the empirical result that consumption responds strongly to predictable income
changes. That value is broadly consistent with the results of Parker (1999) and Souleles (1999), who
both …nd that consumption rises by approximately 0.5 percent following a 1-percent anticipated
increase in income.
       Under the statistical benchmark,      F,   on the other hand, that relationship is much weaker, with
the response to predictable income being, at 0.06, smaller by a factor of nearly 4. It is precisely
the fact that agents optimally (under             ) fail to learn about high-frequency features of the model
that causes them to overreact to predictable parts of income. Furthermore, note that the response
of consumption to true income shocks is far closer to the full-information optimum under                      than
under      F.    This again demonstrates that in many ways,              helps agents get long-run responses
right.
       An alternative way to examine the behavior of consumption in the time domain is to study
its autocorrelations. The left-hand panel of …gure 5 plots the autocorrelations of consumption
growth under          and   F.   Obviously under the full-information optimum, the autocorrelations
are zero. At short lags, the autocorrelations are higher under                   . Subsequently, though, the
autocorrelations are substantially lower –by nearly a factor of 10. The right-hand panel plots the
…rst autocorrelation of consumption growth over di¤erent spans. For a horizon denoted by n on
                         Pn 1         P
the x-axis, we plot corr   j=0  Ct+j ; nj=01 Ct n+j . So the …gure represents how consumption
growth is correlated over neighboring intervals of length n. Consistent with the left-hand panel,
for short intervals the correlations are higher under           than    F.    As we claimed above, though, the
…gure shows that consumption growth over long periods is substantially less autocorrelated under
   than     F.

       To summarize, this example con…rms the analytic results above that the optimal information
policy does a good job of generating consumption growth that is close to white noise in the long-run,
but that it causes consumption to be excessively sensitive to variation in income in the short-run.
It also shows that the model can generate the empirical result that consumption responds to
predictable variation in income.
  18
    Here we use the version of the model in which income is di¤erence-stationary. As discussed above, the results go
through identically in that case. The di¤erence is simply that then consumption and income have volatilities that
are of the same order of magnitude, as observed in the data.


                                                         22
4.3    Empirical evidence
Since the optimal information policy implies that people learn the most about low-frequency fea-
tures of the income process, it says that deviations of consumption growth from white noise should
be observed primarily at high frequencies. Speci…cally, if the agent’s model of income dynamics,
f w (!; x;   ), is ‡at at high frequencies, then any variation in the shape of the true spectrum passes
directly into consumption. The shape of the spectrum of f wC (!; x;       ) will typically be similar to
that of f (!) at high frequencies as the model predicts that people use simple (‡at) models there.
    Another way to build intuition for that prediction of the model is to note that high-frequency
shocks also have relatively small e¤ects on the net present value of income compared to more
persistent shocks (which is why the function Z is relatively small at high frequencies). So the model
essentially predicts that people spend excessively out of relatively small high-frequency increases
in income compared to the larger low-frequency shocks.
    Those predictions of the model are consistent with recent empirical evidence. Parker (1999)
and Souleles (1999) provide classic evidence on the response of consumption to predictable changes
in income due to the tax code (the cap on social security taxes and tax refunds, respectively).
The shocks studied in those papers essentially shift income over time, exactly as in our numerical
example. The results above show that consumption in the model does in fact respond to such
variation in income, and that it tracks predictable income variation strongly.
    Kaplan and Violante (2014; see references therein) review extensive evidence on the e¤ectiveness
of …scal stimulus payments, …nding that people tend to spend approximately 25 percent of these
transitory payments in the quarter that they are received, even though the standard frictionless
model would imply that they should spend a fraction near the level of the real interest rate (i.e.
less than 1 percent per quarter). Moreover, these responses occur even among people with high
incomes, who are less likely to be liquidity constrained (see also Kueng (2016)).
    Kaplan and Violante explain the empirical evidence by arguing that when people hold illiq-
uid assets, their consumption is excessively sensitive to transitory shocks because the bene…t of
smoothing is smaller than the cost of adjusting the stock of illiquid assets (e.g. housing). The in-
tuition behind our results is similar to theirs (and also that of Cochrane (1989)) in that our results
are also driven by the relatively small welfare bene…t of smoothing transitory shocks. We di¤er
in emphasizing the cost of learning about high-frequency dynamics, as opposed to assuming that
saving is costly. Kaplan and Violante (2016) note that their model is consistent with the …nding
of Hsieh (2003) that consumption seems to respond relatively more to small than to large income
shocks. That intuition is consistent with our argument that it is most natural for people to learn
about shocks that have large e¤ects on human wealth.
    While the key source of variation for Kaplan and Violante (2014) is the size of shocks to income,
for us it is their duration. Consumption mistakes should appear in response to short-duration shocks
in our setting, and the empirical research …nding violations of the permanent income hypothesis
typically studies transitory income shocks.


                                                   23
   Cochrane and Sbordone (1988) examine the joint relationship between aggregate consumption
and output at long horizons and …nd that consumption helps forecast future output growth, but
output does not help forecast consumption (nor do lags of consumption itself), implying that
consumption growth is approximately white noise at long horizons. In other words, our model
is consistent with the view that consumption growth may deviate from white noise and respond
excessively to income in the short-term, but at longer horizons it is well described as white noise.
   That implication requires aggregation, though, which is a nontrivial step. Since the consumption
function in our model is linear, it will have desirable aggregation properties, but the exact details
will depend on how income is driven by aggregate and idiosyncratic shocks at each frequency.
Aggregate empirical results are thus not an ideal test of the model. The most direct test would
be to measure the extent to which individual consumption growth is close to white noise over long
horizons.
   An alternative way to test the model, instead of examining consumption, would be to directly
ask people what they are willing to pay for information. If they are at the optimum                     , then
information is equally valuable at all frequencies. On the other hand, under the standard models of
ambiguity aversion without endogenous information acquisition, people would value low-frequency
information most highly and be willing to pay the most for it.

4.4     Relationship with the full-information optimal consumption rule
Our information-constrained agent uses a consumption rule that is suboptimal to the extent that
bw (L) di¤ers from b (L). bw is not chosen to directly generate a path for consumption that necessar-
ily maximizes realized utility; rather, ambiguity aversion causes it to be chosen to maximize utility
under a pessimistic probability measure. We now show, though, that the agent’s worst-case opti-
mization problem is closely related to an optimization that approximates the correct consumption
rule.

Remark 1 A second-order expansion of the Kullback–Leibler (KL) divergence between the full-
information rational expectations consumption process and that used by an agent with model f w
around the point f w = f is
                           Z   2
                       1                                                    2
  KL (f         w
            C; f C)                (Z (!)   1)2 + 2 R   1
                                                                1   R   1
                                                                                Z (!)2 (f w (!)   f (!))2 d!:
                      4    0                                2
                                                                                                          (37)

   The KL divergence is a likelihood-based measure of the deviation between the two random
processes (one interpretation is that it measures how likely one would be to reject the hypothesis
that consumption is driven by one process after observing data generated by the other). Squared
errors in the model f w are weighted by a quadratic function of Z (!). As long as R is close enough
to 1, this weighting function is strictly maximized at ! = 0, meaning that reducing the distance
between f w and f at low frequencies reduces the KL divergence the most. The optimization

                                                   24
problem that our agent solves involves minimizing squared errors in f w (!) weighted by                          (!), and
proposition 2 shows that         (!) / Z (!). The estimations of the agent and of someone minimizing
KL divergence both involve using the weights given by Z to put more emphasis on the precision of
the estimate at low frequencies.

4.5     Extension: frequency-dependent information costs
In the baseline model, assumption 4 implies that agents have equal ability to learn about all
frequencies. That assumption is most natural in the limited attention interpretation of the model,
and it can also be supported when agents can always income su¢ ciently long to measure any
frequency. A natural question, though, is how our results are changed when the cost of acquiring
information varies across frequencies.
   In this subsection, we consider the following alternative to the constraint in assumption 4:
                                             n
                                             X
                                                    (j) (! j ) d!                                                    (38)
                                             j=1


for some cost function . It does not appear possible to obtain a closed-form solution for optimal
attention,     , under general . However, in the special case where there is no smoothing across
frequencies – = 0 –there is an analytic solution:

                                                                           1=2    1=2   1=2
                           for     = 0,      (! j ) = Z (! j ) (! j )                         :                      (39)

(39) is a simple generalization of the result in the baseline case; the only di¤erence is that now
  (! j ) is decreasing in the cost of obtaining information at frequency ! j . If low frequencies are
more expensive to learn about than higher frequencies, then                      will have a less extreme tilt toward
low frequencies than in the baseline case.
   Recall our motivation for the learning framework in which agents get information about the
dynamics of income by examining income histories of other people. In order to have information
about a particular frequency !, an income history must have at least 2 =! periods (that is the
…rst periodogram ordinate; intuitively, one does not have any direct information about ‡uctuations
that last longer than the data sample). So if only some fraction F (!) of people have been alive for
at least 2 =! periods, then on average an agent must look at 1=F (!) histories in order to …nd one
that can inform them about frequency !.
   More speci…cally, suppose people die with a probability                  2 (0; 1) in every period. Then as long
as the birth rate is constant, the fraction of people who have been alive for at least k periods is
 k 1                              (2 =!) 1
       , implying that F (!) =               . A reasonable functional form for                   is therefore

                                                            1 (2 =!)
                                                   (!) =               :                                             (40)

As ! ! 0,     (!) ! 1, which means that in general this cost function will cause agents to learn less


                                                           25
                                                                  0
about low frequencies than in the baseline. However,                  (0) =   1, while Z 0 (0) = 0. So attention
should be increasing with frequency local to zero.
         We calibrate   = 0:975, corresponding to an annual death probability of 2 percent, which we
motivate as equivalent to people having a 50-year working life on average. The top panels of …gure
                                                                                  1=2
5 then plot the optimal information policies              / Z and          /Z           (normalized to have equal
integrals). Both lines again peak at low frequencies, but whereas                   peaks at frequency zero,
peaks at a slightly interior frequency. That peak comes at a frequency corresponding to cycles
lasting approximately 160 years, though. So while the function                  causes agents to learn less about
the very lowest frequencies, they still very much focus their attention on long-term cycles.
         To see how that change a¤ects our calibration, the bottom panels of …gure 5 plot the worst-case
spectra under various        policies now also including         (!).19 That policy leads to results between
the benchmark           and the constant       policy. At the very lowest frequencies, the              model does
not match the true spectrum as well as             , but it still does much better than         F.   At the middle
frequency peak and at higher frequencies, on the other hand, the policy                      does a better job of
matching the log spectrum than             but still worse than       F.

         This section therefore shows, as one might expect, that when low frequencies are more costly to
learn about, the main results are weakened somewhat. We continue to …nd that agents allocate the
most attention to low frequencies, just not to the very lowest –the peak is at an interior frequency,
but one corresponding to cycles lasting a century or more. The impact on the worst-case model is
to put it somewhere between that induced in the baseline optimum and that induced by the policy
that puts equal weight on all frequencies.


5         Conclusion
This paper studies how people can direct their attention to di¤erent features of a model. We
consider a nonparametric class of income processes and show precisely how agents optimally allocate
attention to the behavior of income at di¤erent frequencies. The utility maximizing policy is to pay
the most attention to the behavior of income at very low frequencies, and use a relatively simple
and inaccurate model at high frequencies.
         While there is extensive past work on learning, the innovation of this paper is to provide an
exactly solvable framework for studying how learning can be applied to di¤erent aspects of a model
of the world, as opposed to learning about state variables. The theory can be used to describe what
people pay attention to, what aspects of the world they try to model accurately and what they use
coarser approximations for, and the set of mistakes that people should be expected to make.
         We show that optimal learning implies people are most likely to make mistakes at high frequen-
cies, as those are the aspects of the income process least important for utility. Consistent with
    19
     For non-zero with varying across frequencies,           (!) / Z (!) (!) 1=2 is not technically the optimal policy
– it must be solved for numerically. We focus on the analytic case for the sake of simplicity. Furthermore, the
calibration in …gure 5 is set up so that the total precision under    is the same as that under    –they di¤er only in
how that precision is allocated across frequencies.


                                                         26
empirical evidence, the model implies that consumption tends to track transitory ‡uctuations in
income in the short-run, but at lower frequencies consumption growth is close to white noise (which
it would be under the full-information optimal policy). In other words, the consumption mistakes
that the empirical literature has documented are consistent with optimal learning.


References
Abel, Andrew B., Janice C. Eberly, and Stavros Panageas, “Optimal Inattention to the
    Stock Market,” The American Economic Review, 2007, 97 (2), 244–249.

    ,        , and     , “Optimal Inattention to the Stock Market with Information Costs and
    Transactions Costs,” Econometrica, 2013, 81 (4), 1455–1481.

Akaike, Hirotugu, “Smoothness Priors and the Distributed Lag Estimator.,” Technical Report,
    DTIC Document 1979.

Bansal, Ravi and Ivan Shaliastovich, “Con…dence Risk and Asset Prices,” The American
    Economic Review, 2010, 100 (2), 537–541.

Barron, John M. and Jinlan Ni, “Endogenous Asymmetric Information and International Eq-
    uity Home Bias: The E¤ects of Portfolio Size and Information Costs,”Journal of International
    Money and Finance, 2008, 27 (4), 617–635.

Bidder, Rhys and Ian Dew-Becker, “Long-Run Risk is the Worst-Case Scenario,” The Amer-
    ican Economic Review, September 2016, 106 (9), 2494–2527.

Bordalo, Pedro, Nicola Gennaioli, and Andrei Shleifer, “Diagnostic Expectations and
    Credit Cycles,” Working Paper, 2016.

Brillinger, David R., Time Series: Data Analysis and Theory, McGraw Hill, 1981.

Cochrane, John H., “The Sensitivity of Tests of the Intertemporal Allocation of Consumption
    to Near-Rational Alternatives,” The American Economic Review, 1989, 79 (3), 319–337.

        and Argia Sbordone, “Multivariate Estimates of the Permanent Components of GNP and
    Stock Prices,” Journal of Economic Dynamics and Control, 1988, 12(2–3), 255–296.

Collin-Dufresne, Pierre, Michael Johannes, and Lars A Lochstoer, “Parameter Learning
    in General Equilibrium: The Asset Pricing Implications,” The American Economic Review,
    2016, 106 (3), 664–698.

Dew-Becker, Ian, “How Risky is Consumption in the Long-run? Benchmark Estimates From a
    Robust Estimator,” Review of Financial Studies, 2017, 30 (2), 631–666.



                                                27
        and Stefano Giglio, “Asset pricing in the frequency domain: theory and empirics,”Review
    of Financial Studies, 2016, 29 (8), 2029–2068.

Eichenbaum, Martin, “Comment on “Natural Expectations, Macroeconomic Dynamics, and
    Asset Pricing”,”in “NBER Macroeconomics Annual 2011, Volume 26,”University of Chicago
    Press, 2011, pp. 49–60.

Friedman, Milton, A Theory of the Consumption Function, Princeton University Press, 1957.

Fuster, Andreas, Benjamin Hebert, and David Laibson, “Natural Expectations, Macroeco-
    nomic Dynamics, and Asset Pricing,” NBER Macroeconomics Annual, 2011, 26 (1), 1–48.

Gersch, Will and Genshiro Kitagawa, “Smoothness Priors Transfer Function Estimation,”
    Automatica, 1989, 25 (4), 603–608.

Hall, Robert E., “Stochastic Implications of the Life Cycle-Permanent Income Hypothesis: The-
    ory and Evidence,” Journal of Political Economy, 1988, 86 (6), 971–987.

Hansen, Lars Peter and Thomas J. Sargent, “Formulating and Estimating Dynamic Linear
    Rational Expectations Models,” Journal of Economic Dynamics and Control, 1980, 2, 7–46.

        and      , “A note on Wiener-Kolmogorov Prediction Formulas for Rational Expectations
    Models,” Economics Letters, 1981, 8 (3), 255–260.

     and         , “Fragile Beliefs and the Price of Uncertainty,”Quantitative Economics, 2010, 1(1),
    129–162.

        and      , “Sets of Models and Prices of Uncertainty,” 2015. Working paper.

    ,         , and Thomas D. Tallarini, “Robust Permanent Income and Pricing,” Review of
    Economic Studies, 1999, 66 (4), 873–907.

Hsieh, Chang-Tai, “Do Consumers React to Anticipated Income Changes? Evidence from the
    Alaska Permanent Fund,” The American Economic Review, 2003, 93 (1), 397–405.

Jappelli, Tullio and Luigi Pistaferri, “The Consumption Response to Income Changes,”Annual
    Review of Economics, 2010, 2, 479–506.

Ju, Nengjiu and Jianjun Miao, “Ambiguity, Learning, and Asset Returns,” Econometrica,
    2012, 80(2), 559–591.

Kacperczyk, Marcin, Stijn van Nieuwerburgh, and Laura Veldkamp, “A Rational Theory
    of Mutual Funds’Attention Allocation,” Econometrica, 2016, 84 (2), 571–626.

Kaplan, Greg and Giovanni L Violante, “A Model of the Consumption Response to Fiscal
    Stimulus Payments,” Econometrica, 2014, 82 (4), 1199–1239.

                                                  28
Kitagawa, Genshiro and Will Gersch, “A Smoothness Priors–State Space Modeling of Time
    Series with Trend and Seasonality,” Journal of the American Statistical Association, 1984, 79
    (386), 378–389.

     and       , “A smoothness priors long AR model method for spectral estimation,” IEEE
    transactions on automatic control, 1985, 30 (1), 57–65.

     and       , Smoothness Priors Analysis of Time Series, Springer Science & Business Media,
    1996.

Kueng, Lorenz, “Explaining Consumption Excess Sensitivity with Near-Rationality: Evidence
    from Large Predetermined Payments,” 2016. Working paper.

Luo, Yulei, “Consumption Dynamics under Information Processing Constraints,”Review of Eco-
    nomic Dynamics, 2008, 11 (2), 366–385.

     and Eric R. Young, “Risk-Sensitive Consumption and Savings Under Rational Inattention,”
    American Economic Journal: Macroeconomics, 2010, 2 (4), 281–325.

Parker, Jonathan A, “The Reaction of Household Consumption to Predictable Changes in Social
    Security Taxes,” The American Economic Review, 1999, 89 (4), 959–973.

Peng, Lin and Wei Xiong, “Investor Attention, Overcon…dence and Category Learning,”Journal
    of Financial Economics, 2006, 80 (3), 563–602.

Shiller, Robert J., “A Distributed Lag Estimator Derived from Smoothness Priors,” Economet-
    rica, 1973, pp. 775–788.

Sims, Christopher A, “Implications of Rational Inattention,” Journal of Monetary Economics,
    2003, 50 (3), 665–690.

Souleles, Nicholas S., “The Response of Household Consumption to Income Tax Refunds,” The
    American Economic Review, 1999, 89 (4), 947–958.

van Nieuwerburgh, Stijn and Laura Veldkamp, “Information acquisition and under-
    diversi…cation,” The Review of Economic Studies, 2010, 77 (2), 779–805.

Veldkamp, Laura L., “Information Markets and the Comovement of Asset Prices,” Review of
    Economic Studies, 2006, 73 (3), 823–845.

    , Information Choice in Macroeconomics and Finance, Princeton University Press, 2011.

Wahba, Grace, “Automatic Smoothing of the Log Periodogram,” Journal of the American Sta-
    tistical Association, 1980, 75 (369), 122–132.




                                                29
Wang, Neng, “Precautionary Saving and Partially Observed Income,”Journal of Monetary Eco-
    nomics, 2004, 51 (8), 1645–1681.

    , “Optimal consumption and asset allocation with unknown income growth,”Journal of Mon-
    etary Economics, 2009, 56 (4), 524–534.




                                              30
                                        Figure 1: Weighting function Z (!) and its multiplicative inverse

                                 Z(ω)                                                                              1/Z(ω)
     80                                                                             80




     70                                                                             70




     60                                                                             60




     50                                                                             50




31
     40                                                                             40




     30                                                                             30




     20                                                                             20




     10                                                                             10




      0                                                                              0
          20   10   6.7   5       4          3.3   2.9   2.5   2.2   2                     20    10    6.7   5       4          3.3   2.9   2.5   2.2   2
                              Cycle length                                                                       Cycle length
                                          Figure 2: Average estimated log spectra and IRFs for white-noise income
                                          Spectra                                                                                     IRFs
      -5                                                                                        0.025
                                                                           f                                                                                             b
                                                                           fw
                                                                            *
                                                                                                                                                                         bw
                                                                                                                                                                          *
                                                                           fw
                                                                            F
                                                                                                                                                                         bw
                                                                                                                                                                          F


     -5.5                                                                                        0.02




      -6                                                                                        0.015




     -6.5                                                                                        0.01




32
      -7                                                                                        0.005




     -7.5                                                                                           0




      -8                                                                                       -0.005
                     10             5                  3.3      2.5             2                       0   2      4      6      8      10     12     14     16     18        20
                                        Cycle length                                                                                 Periods
     Notes: In the left-hand panel, f is the true log spectrum of income (‡at), the line for f w is the average worst-case log spectrum under the optimal information
     policy, and the line for fFw is the average worse-case log spectrum under the statistical benchmark that yields equally precise signals at all frequencies. The
     right-hand panel plots the impulse response functions (Wold moving average representations) for income corresponding to the three log spectra.
                      Figure 3: Average estimated log spectra and IRFs with transitory and persistent components in income
                      Spectra (low freq.)                                       Spectra (all freq.)                          ×10-3            IRFs
     -7.8                                                     -7.6                                                      20
                                                   f                                                        f                                                     b
                                                   fw                                                       fw                                                    bw
                                                    *                                                        *                                                     *
                                                   fw                                                       fw                                                    bw
                                                    F                                                        F                                                     F
                                                              -7.8
      -8




                                                               -8                                                       15
     -8.2



                                                              -8.2

     -8.4



                                                              -8.4                                                      10

     -8.6


                                                              -8.6




33
     -8.8

                                                              -8.8                                                       5



      -9

                                                               -9



     -9.2
                                                              -9.2                                                       0




     -9.4
                                                              -9.4




     -9.6                                                     -9.6                                                      -5
               50       25         16.7     12.5        10               10       5          3.3      2.5        2           0       5         10         15           20
                         Cycle length                                              Cycle length                                              Periods
     Notes: The middle and left-hand panel correspond to the left-hand panel in …gure 2, except for a di¤erent value for the true spectrum, f . The right-hand
     panel here corresponds to the right-hand panel in …gure 2, but for this alternative example with an income process that has both persistent and transitory
     components.
                             Figure 4: Behavior of consumption with permanent and transitory income ‡uctuations
                             Log spectrum of consumption                                       ×10-4              IRFs of consumption
     -15.2                                                                                5
                                                                             f∆C

                                                                             fw
                                                                              *,∆C
                                                                             fw
                                                                              F,∆C
                                                                                         4.5

     -15.4


                                                                                          4




     -15.6
                                                                                         3.5




                                                                                          3
     -15.8




34
                                                                                         2.5



      -16
                                                                                          2




                                                                                         1.5
     -16.2




                                                                                          1


     -16.4

                                                                                         0.5                                                       b∆C

                                                                                                                                                   bw
                                                                                                                                                    *.∆C
                                                                                                                                                   bw
                                                                                                                                                    F,∆C
                                                                                                                                                   Income
     -16.6                                                                                0
             20   10   6.7       5       4          3.3    2.9   2.5   2.2           2         0       10   20   30       40        50   60   70            80
                                     Cycle length                                                                       Periods
                                        Figure 5: Persistence of consumption growth with transitory and persistent components in income
                                            Autocorrelations of consumption growth                                                              First autocorrelation of moving averages of consumption growth
                       0.06                                                                                                   0.3
                                                                                               τ*                                                                                                                     τ*
                                                                                                 F                                                                                                                      F
                                                                                               τ                                                                                                                      τ



                                                                                                                            0.25
                       0.04




                                                                                                                              0.2
                       0.02




                                                                                                                            0.15

                          0



                                                                                                                              0.1


                       -0.02




35
     Autocorrelation
                                                                                                          Autocorrelation
                                                                                                                            0.05



                       -0.04

                                                                                                                                 0




                       -0.06
                                                                                                                            -0.05




                       -0.08
                                                                                                                             -0.1




                        -0.1                                                                                                -0.15
                               0   5   10    15      20      25      30      35      40   45         50                              0      5       10       15      20      25      30      35       40         45         50
                                                             Lag                                                                                                  Length of moving average
     Notes: The left-hand panel plots the autocorrelations of consumption growth, corr( Ct ;                                Ct   1 ).    The right-hand panel plots the autocorrelation of moving
     averages, corr   j=0  Ct+j ; n j=0   Ct n+j , where n varies along the x-axis.
                    Pn 1         P 1
                                                  Figure 6: E¤ects of information cost varying across frequencies
                           Optimal information policies (low freq.)                                                   Optimal information policies (all freq.)
       9                                                                                          9
                                                                             τ*                                                                                        τ*
       8                                                                     τφ                   8                                                                    τφ


       7                                                                                          7

       6                                                                                          6

       5                                                                                          5

       4                                                                                          4

       3                                                                                          3

       2                                                                                          2

       1                                                                                          1

       0                                                                                          0
                     50             25                  16.7          12.5        10                            10             5                  3.3            2.5        2
                                         Cycle length                                                                              Cycle length




36
                                     Spectra (low freq.)                                                                        Spectra (all freq.)
     -7.8                                                                                       -7.6
                                                                             f                                                                                         f
                                                                              w                 -7.8                                                                    w
      -8                                                                     f                                                                                         f
                                                                              *                                                                                         *
                                                                             fw                                                                                        fw
                                                                              F                  -8                                                                     F
     -8.2                                                                    fw                                                                                        fw
                                                                              φ                                                                                         φ
                                                                                                -8.2
     -8.4
                                                                                                -8.4
     -8.6
                                                                                                -8.6
     -8.8
                                                                                                -8.8
      -9
                                                                                                 -9
     -9.2
                                                                                                -9.2

     -9.4                                                                                       -9.4

     -9.6                                                                                       -9.6
                     50             25                  16.7          12.5        10                            10             5                  3.3            2.5        2
                                         Cycle length                                                                              Cycle length
     Notes: The bottom panels of this …gure replicate the left and middle panels in …gure 3, but using the optimal information policy when information costs vary
     across frequencies, denoted . f w denotes the average worst-case log spectrum under that information policy.
A      Proof of lemma 2
From Dew-Becker (2016), the optimal consumption rule is

                                                              1               1   ^b R        1 2                                1 log     R
                  Ct = (R       1) Wt       1   +         R       1   R                               + z (L) ^"t                                        (1)
                                                      2                                                                               R    1
for a lag polynomial z (L). Dew-Becker (2016) also shows that
                               2                        3
                                     1
                                     X                                                                1
                            Et 4   1      j
                                            exp ( Ct+j )5 =                                               exp (          Ct )                            (2)
                                                j=0
                                                                                           1          R

(note that the probability measure for the expectation operator here is arbitrary) which implies
                 2                          3
                         X1
                                                              (1    )
        1
          log Et 4(1   )     j
                               exp ( Ct+j )5 =          1
                                                          log         + (R 1) Wt 1
                         j=0
                                                               1  R

                                                                                      1                   1    ^b R      1 2                   1 log   R
                                                                                  R       1       R                             + z (L) ^"t              :(3)
                                                                              2                                                                  R     1
The result in the text then immediately follows.


B      Proof of lemma 3
^b (L) is the Wold representation associated with the spectrum exp f^ (!) and is obtained through the canonical
 factorization of the spectrum (see Priestley (1981)). De…ne Fourier coe¢ cients of f^ as c^k ,
                                                  Z
                                                1
                                         c^k =         cos (!k) f^ (!) d!:                                  (4)
                                               2
    Given c^k , the coe¢ cients ^bk are constructed as
                                                                      0                                       1
                                                                                      1
                                                                                      X
                                            ^ (!)
                                            B             =   exp @c^0 =2 +                   c^j e   i!j A
                                                                                                                                                         (5)
                                                                                      j=1
                                                              Z
                                                ^bk       =        ^ (!) exp (i!k) d!
                                                                   B                                                                                     (6)

                  R            R
where from here on denotes 21                   .
   We can then obtain ^b R 1 ,
                                                1             Z                           1
                                                                                                                !
                                                X                                         X
                           ^b R     1
                                        =             R   m
                                                                  exp c^0 =2 +                  c^k e     i!k
                                                                                                                    ei!m d!:                             (7)
                                             m=0                                          k=1


    Consider the derivative of ^b R         1
                                                    with respect to c^k (k > 0),
                                                1             Z                           1
                                                                                                                    !
                       d^b R    1               X                                         X
                                                          m                                                   i!k
                                        =             R           exp c^0 =2 +                   c^k e                  ei!(m    k)
                                                                                                                                      d!                 (8)
                          d^
                           ck                   m=0                                       k=1
                                                X1
                                                          m^
                                        =             R    bm k                                                                                          (9)
                                                m=0
                                                  k^          1
                                        = R           b R         ;                                                                                     (10)


                                                                          1
where we use the fact that ^bm    k   = 0 for k > m. For k = 0,
                                                  1            Z                          1
                                                                                                                   !
                         d^b R    1               X                                       X                            1
                                                           m                                                 i!k
                                        =              R            exp c^0 =2 +                     c^k e               d!              (11)
                            d^
                             c0                  m=0
                                                                                                                       2
                                                                                          k=1
                                                  1^       1
                                        =           b R        :                                                                         (12)
                                                  2
We then have for k > 0
                                                       2
                                      d^b R 1
                                                           =        2^b R       1
                                                                                        R      k^
                                                                                                b R          1
                                                                                                                                         (13)
                                          d^
                                           ck
                                        ^              2
                                  d log b R 1                             k
                                                           =        2R                                                                   (14)
                                           d^
                                            ck
and
                                                                          1 2
                                                       d log ^b R
                                                                                =1                                                       (15)
                                                              d^
                                                               c0
(where we square ^b R 1 so that we are taking the log of a positive number). In other words, then,
          2
log ^b R 1 is linear in the c^k and depends only on them and possibly a constant. We can therefore write
                                                                1
                                                                            !
                                         2                      X
                              log ^b R 1   = cons + 2 c^0 =2 +      R k c^k                          (16)
                                                                                            k=1
                                                                           1
                                                                           X
                                                                                         jkj
                                                       = cons +                     R          c^k                                       (17)
                                                                          k= 1

for some unknown constant cons. Using the de…nition of c^k , we have
                             1
                             X                                 1
                                                               X                    Z
                                           jkj                                jkj
                                       R         c^k   =              R                 cos (!k) f (!) d!                                (18)
                            k= 1                           k= 1
                                                           Z X1
                                                                                                 jkj
                                                       =                   cos (!k) R                  f (!) d!                          (19)
                                                                   k= 1
                                                           Z
                                                       =           Z (!) f (!) d!;                                                       (20)

where
                                           1
                                           X                                            1
                                                                                        X
                                                                    jkj                                k
                           Z (!)                   cos (!k) R             =1+2                 R           cos (!k) :                    (21)
                                       k= 1                                             k=1

                                                                                                                              1 2
  Finally, note that if f (!) = 0, then the process is white noise with unit variance, so b R                                       = 1. That
immediately implies that the constant term is zero, yielding the desired result,
                                                      Z
                                                 2
                                      log ^b R 1 = Z (!) f^ (!) d!:                                                                      (22)




                                                                     2
C        Finding the worst-case spectrum
                  n         o
Nature chooses     f^ (! j ) to solve

                                  n
                                  X
     w
 ff (! j )g = arg max          Z (! j ) f^ (! j ) d!
                 ff^(!j )g j=1
                                                   n                                                                           n
                                                                                                                                                                    !2
                                               1   X                                       2                               1   X        f^ (! j )    f^ (! j   1)
                                                           x (! j )        f^ (! j )               (! j ) d!                                                             d!:
                                           2       j=1
                                                                                                                       2       j=2
                                                                                                                                                    d!
                                                                                                                                                                          (23)

    The …rst-order conditions for interior points (1 < j < n) are
                                                                          1
                      1                                                                   f w (! j+1 ) f w (! j )                       f w (! j )     f w (! j     1)
 0 = Z (! j ) +           (x (! j )    f w (! j )) (!) +                                                                                                                       :
                                                                        d!                          d!                                                d!
At the boundaries they are

                                                   1                                                           1   f w (! 2 ) f w (! 1 )
                  0       = Z (! 1 ) +                 (x (! 1 )        f w (! 1 )) (! 1 ) +                                                                              (24)
                                                                                                                            d! 2
                                                   1                                                           1    f w (! n ) f w (! n              1)
                  0       = Z (! n ) +                 (x (! n )         f w (! n )) (! n )                                                               :               (25)
                                                                                                                              d! 2
   We de…ne here vectors containing the various objects at the frequencies ! j using variables with no
                                                          0
subscript. For example,   [ (! 1 ) ; (! 2 ) ; :::; (! n )] . We can then write the …rst-order conditions as
                                                                   1                                           1
                                            0=Z+                       diag ( ) (x             f w) +              Df w ;                                                 (26)

where diag ( ) is a matrix with             on the diagonal and zero elsewhere and D is a di¤erencing matrix:
                                              2                                3
                                                   1 1      0    0         0
                                              6 1       2 1       0            7
                                              6                                7
                                              6                            .. 7
                                              6 0      1     2 1            . 7
                                           D 66 .
                                                                               7 d! 2 :
                                                                               7                                                                                          (27)
                                              6 ..              . ..
                                              6                            0 7 7
                                              4             0    1     2 1 5
                                                 0          0    0    1      1

The second-order condition is that
                                                                          diag ( ) + D                                                                                    (28)
is negative de…nite, i.e. that all of its eigenvalues are negative.
    The solution to nature’s optimization problem is then obtained by directly solving (26):
                                                                                      1
                                      fw   =       (diag ( )               D)             ( Z + diag ( ) x)                                                               (29)
                                                                              1                1                   1
                                           =           I      diag                    D              diag                  Z +x ;                                         (30)

where 1 here is an elementwise inverse of the vector . Since this is a linear problem, the solution is unique
as long as the matrix inverse exists.


D        Proposition 1
                                                                                  0
Consider a total derivative of (26) with respect to                                   at the point x = f :

                                            1                                         1                df w                1       df w
                                  0=            diag f             fw                     diag ( )          +                  D        :                                 (31)
                                                                                                       d 0                         d 0

                                                                                      3
                                 df w
We can then solve for            d 0:
                                                        df w                                                      1
                                                             =( D                   diag ( 0 ))                       diag f w                     f                                    (32)
                                                        d 0
Now the objective is to minimize
                                                                                                                                           X
                                                                                                                           1 2
                                      f   (! j )g =                   arg min log bw R                                           +                         (! j ) d!                    (33)
                                                                           f (! j )g
                                                                                                                                               j
                                                                                                                              X
                                                             =        arg min Z 0 f w d! +                                                (! j ) d!:                                    (34)
                                                                           f (! j )g
                                                                                                                                 j

The …rst-order condition for that problem is
                                                                                           df w
                                                                          0 = Z0                + 11                       n;                                                           (35)
                                                                                           d 0
                                                                                                                              df w
where 11   n   is a 1       n vector of ones. Inserting the formula for                                                       d 0        yields
                                                                                                         1
                                          0 = Z0 ( D                      diag (            0
                                                                                                ))           diag f w                    f + 11                     n                   (36)
                                                                                                                 1
                                              Z0 =               11   n diag           fw                f           ( D             diag (                0
                                                                                                                                                               )) :                     (37)
                                      w
Now we conjecture that f                      f is equal to a constant c multiplied by a column of ones. We then have

                                                        Z0        =             c      1
                                                                                           11        n   ( D               diag (          0
                                                                                                                                               ))                                       (38)
                                                                                   1       0
                                                                  =        c                 ;                                                                                          (39)

where the second line uses the fact that 11 n D = 01 n since the columns of D sum to zero.
   In order to con…rm that result, we must now show that when Z = c 1 , f w f = c1n                                                                                            1.   Inserting
Z = c 1 into (26) yields
                                                             1                 1                                                               1
                                          0= c                        +            diag (                ) f              fw +                         Df w :                           (40)

In order for it to be the case that f w                              f = c1n           1,       we must have
                                                         1                 1                                                         1
                                  0       =         c                          diag (                ) 1n         1c      +              D1n               1     f +c                   (41)
                                                         1                 1
                                          =         c                               c:                                                                                                  (42)

where the second line uses the fact that D1n                                   1    = 0n             1.      This is solved by
                                                                                     p
                                                                                                         =c                                                                             (43)

                                                                                                         1
                                                                          Z         =            c                                                                                      (44)
                                                                                                                  1=2
                                                                                    =           ( = )                      Z:                                                           (45)

We can then plug the value of                           into the equation for f w :
                                                                                                     1                                     1=2
                             fw       =         I            diag              1
                                                                                       D                      diag ( = )                               Z        1
                                                                                                                                                                        Z +x            (46)
                                                                               1                     1                     1=2       1=2
                                      =         I            diag                      D                     1n       1                    +x ;                                         (47)

                        1        1
where, as with              ,Z       is an elementwise inverse of the vector Z. It follows that
                                                                                                                       1                   1=2         1=2
                                     E [f w ]       =            I         diag                      1
                                                                                                             D                1n     1                              +f                  (48)
                                                                          1=2          1=2
                                                    =            1n   1                         + f;                                                                                    (49)

                                                                                                     4
                                                                                                                                    1           1
where the last line follows from the fact that the rows of I                                               diag                         D            sum to 1. To see why, note
that
                                   1       1                                                      1                                             1         2
                    I     diag        D      = I + diag                                                D+                  diag                      D        + :::                (50)
                        1
The rows of diag          D sum to zero, meaning that 1n 1 is an eigenvector with eigenvalue zero. When a
matrix is raised to a power, its eigenvectors are unchanged and its eigenvalues are raised to the same power,
meaning that 1n 1 remains an eigenvector with 0 the associated eigenvalue, and the rows sum to zero. Since
                                                     1     1
the rows of I sum to 1, the rows of I       diag       D     then do also.

D.1        Bias of f w (!; x; )
From above, the solution for the vector f w is
                                                                                                                           1
                                           f w (x; )             =         I         diag              1
                                                                                                               D                    diag             1
                                                                                                                                                          Z +x                     (51)
                                                                          0                                                          1
                                                                                     1
                                                                                     X                                           j
                                           f w (x; )             = @I +                           diag                 1
                                                                                                                               D A              diag            1
                                                                                                                                                                      Z +x         (52)
                                                                                     j=1
                                                                          0                                                    1
                                                                              1
                                                                              X                                            j
             f w (x; )      diag           1
                                                Z        x       = @                     diag              1
                                                                                                                   D A                  diag             1
                                                                                                                                                              Z +x :               (53)
                                                                               j=1

               1
Now scale          by c and divide both sides by c
                                                                                                                                            !
                                                                                                               1
     1 w                              1              1                                    diag                     D                                                   1
 c    f (x; =c)          diag              Z    c        x=                P1                                                           j           c diag                 Z + x : (54)
                                                                      +         j=2      cj   1
                                                                                                       diag                    1
                                                                                                                                    D

Since both sides are linear in x, we can take take the expectation and then the limit as c ! 0 to yield

                                    E [f w (x; =c)]                   f                            1                                        1
                                lim                                        = diag                          Z + diag                                 Df:                            (55)
                                c!0           c
In the limit as n ! 1, Df becomes f 00 .


E       Consumption and income forecasts
E.1        The behavior of consumption
From Dew-Becker (2016), consumption follows
                                                                                                                   1           1
                                   Ct       =       (R           1) Wt     1    + Zt          (R           1)                      log ( R)                                        (56)
                                                                                                           1           1
                                  Wt        = Wt             1   + Yt          Zt + (R             1)                      log ( R) ;                                              (57)

where
                                                                  1              1        1
                                          Zt = 1         R            Yt             R        log Et exp (                         Zt+1 ) :                                        (58)

We then have
                                                                               1                           1
                          Ct+1        = (R           1) Wt + Zt+1 (R 1)          log ( R)                                                                                          (59)
                          Ct+1        = (R           1) Wt + Zt+1 (R 1) Wt 1 Zt                                                                                                    (60)
                          Ct+1        = (R           1) (RWt 1 + Yt Ct ) + Zt+1 (R 1) Wt                                                             1        Zt                   (61)
                                                                                                                           1
                                          Ct+1 = (R               1) Yt + Zt+1                 RZt +                           log ( R) :                                          (62)



                                                                                     5
Now de…ne H as follows:
                                                                   1                   1           1
                            Zt              =        1     R           Yt                  R           log Et exp (                             Zt+1 )                                               (63)
                                                                               1
                            Ht                      Zt        1        R               Yt                                                                                                            (64)
                                                      1        1                                                                                        1
                            Ht              =             R        log Et exp                                  Ht+1 + 1                         R            Yt+1         :                          (65)

This de…nition yields
                                                                                       1                                                            1
                                Ct+1            = R                1       R               Yt              Zt + Zt+1 +                                   log ( R)                                    (66)
                                                                                                                       1                             1
                                                = Ht+1                     RHt + 1                             R             Yt+1 +                      log ( R) ;                                  (67)
with the recursion
                                        1
       h + h (L) "t     =    R 1 log Et exp                                                h + h (L) "t+1 + 1                                       R        1
                                                                                                                                                                     b (L) "t+1     j fw             (68)
                              0                                                                            1
                                   X1
                                                                                                                                                                                                 2
                        = R 1 @h +      hj + 1                                                 R   1
                                                                                                               bw
                                                                                                                j "t+1              j
                                                                                                                                        A         R          1
                                                                                                                                                                      h0 + 1      R     1
                                                                                                                                                                                            bw
                                                                                                                                                                                             0       (69)
                                                         j=1
                                                                                                                                                                 2

and solution
                                                                       1                                   1                     1
                                                hj        = R              hj+1 + R                                1        R           bw
                                                                                                                                         j+1                                                         (70)
                                                                                   1
                                                                           R                                                                1            2
                                                    h =                                    1
                                                                                                       h0 + 1                    R              bw
                                                                                                                                                 0                                                   (71)
                                                                       1           R           2
                                                                               1                               1                        1 2
                                                          =            R                   1       R                   bw R                                                                          (72)
                                                                                   2
                                                                           1                                                                        1
                                        Ct+1 = 1                   R               Yt+1 + Ht+1                              RHt +                       log R:                                       (73)
Now we can insert the formulas for the various objects:
                                                                                                                                1
                                                                                                                                X
                                        1
          Ct   =      1     R               b (L) "t+1 + (1                        R) h + h0 "w
                                                                                              t+1 +                                     (hj+1                Rhj ) "w
                                                                                                                                                                    t j +
                                                                                                                                                                                    1
                                                                                                                                                                                        log R        (74)
                                                                                                                                j=0
                                        1                                                                                   1
               =      1 R                   b (L) "t+1 + (1                        R) h + 1                            R            bw R             1
                                                                                                                                                                     bw  w
                                                                                                                                                                      0 "t+1                         (75)
                       1
                       X
                                                    1
                                    1       R            bw    w
                                                          j+1 "t j +
                                                                                           1
                                                                                               log R                                                                                                 (76)
                          j=0

                                        1                                                                                   1                                              b (L)
               =      1     R               b (L) "t+1 + (1                        R) h + 1                            R            bw R             1
                                                                                                                                                                     bw
                                                                                                                                                                      0          "t+1                (77)
                                                                                                                                                                          bw (L)
                        1
                        X
                                                    1              b (L)
                                    1       R            bw
                                                          j+1            "t                j   +               1
                                                                                                                   log R                                                                             (78)
                          j=0
                                                                  bw (L)


                                                1                                                                                       1                              b (L)
                      =         1           R           b (L) "t+1 + (1                        R) h + 1                         R               bw R             1
                                                                                                                                                                             "t+1                    (79)
                                                                                                                                                                      bw (L)
                                                     1                  b (L)
                                    1           R         bw (L)               "t+1 + 1 log R                                                                                                        (80)
                                                                       bw (L)
                                                1                        b (L)
                      =         1           R           bw R       1
                                                                                "t+1 + (1 R) h +                                                     1
                                                                                                                                                         log R:                                      (81)
                                                                        bw (L)
                                                                                                                       1                           b(L)
So consumption growth is equal to a constant plus 1                                                        R                bw R            1
                                                                                                                                                  bw (L) "t+1 .           The dynamic behavior of
                                                                                       w               1        b(L)
consumption growth is therefore determined by b                                                R               bw (L) .         The spectral density of consumption growth
is
                                                                                                               1 2          f (!)
                                                              f wC (!) = bw R                                                      :                                                                 (82)
                                                                                                                           f w (!)


                                                                                                   6
F     KL divergence for consumption process
We consider the relative entropy of consumption growth under the worst-case model compared to the true
model. If we have two models of consumption growth de…ned by their spectra and means, ff C (!) ; C g,
then the Kullback–Leibler divergence is
                          Z                                                  2
                             exp f wC (!)     exp f wC (!)      ( wC      C)
                                          log              d! +                :                  (83)
                             exp f C (!)      exp f C (!)        exp f C (0)
In our case, the ratio of the spectra is
                                                            1 2 exp f (!)
                     exp f wC (!)              bw R             exp f w (!)
                                       =                                                                                  (84)
                     exp f C (!)                   b (R )       1 2
                                                   Z
                                                                                                        exp f (!)
                                       =       exp    Z ( ) fw ( ) d                   exp ( f w (!))                 ;   (85)
                                                                                                        b (R   1 )2

and the di¤erence in the means is
                           w                            1                                   2             2
                               C       C   =     1 R 1 bw R 1
                                                    R                   b R 1       :                                     (86)
                                             2
So the KL divergence is, ignoring additive constants,
                                     Z                  Z
                                               w                          exp f (!)
                    KL = exp            Z ( )f ( )d        exp ( f w (!))          2 d!                                   (87)
                                                                          b (R 1 )
                                  Z              Z
                                + f w (!) d!       Z ( ) fw ( ) d                                                         (88)

                                                                     2                                2
                                           1                    1                     1 2         1 2
                                       R        2   1       R             bw R              b R
                                   +                                                                      :               (89)
                                                                    exp f   C   (0)
The derivative with respect to f w (m) is
                            Z
       dKL                                                     exp f (m)
                =      exp     Z ( ) f w ( ) d exp ( f w (m))           2                              (90)
     df w (m)                                                   b (R 1 )
                                   Z                  Z
                                                                           f (!)
                     +Z (m) exp      Z ( ) fw ( ) d      exp ( f w (!))          2 d! + 1   Z (m)      (91)
                                                                         b (R 1 )
                                            2          2           2         Z
                         R 12 1 R 1            bw R 1      b R 1
                     +2                                              exp       Z ( ) f w ( ) d Z (m) : (92)
                                          exp f C (0)
Evaluating at f w = f , we obtain dlfdKL
                                      w (m) jf w =f = 0, as we would expect. The second derivative is

                            Z
       d2 KL                                                       exp f (m)
              2   = exp        Z ( ) f w ( ) d exp ( f w (m))               2                                             (93)
     dlf w (m)                                                      b (R 1 )
                              Z
                                                                      exp f (m)
                         exp     Z ( ) f w ( ) d exp ( f w (m))                 2 Z (m)                                   (94)
                                                                       b (R 1 )
                                      Z                      Z
                              2                                                  exp f (!)
                      +Z (m) exp          Z ( ) fw ( ) d       exp ( f w (!))              2 d!                           (95)
                                                                                  b (R 1 )
                                     Z
                                                                             exp f (m)
                        Z (m) exp        Z ( ) f w ( ) d exp ( f w (m))                2                                  (96)
                                                                              b (R 1 )
                                                2           2             2          Z
                           R 12 1 R 1              bw R 1       b R 1
                                                                                                            2
                      +2                                                     exp       Z ( ) f w ( ) d Z (m)              (97)
                                             exp f C (0)
                                                2        Z                               2
                           R 12 1 R 1
                      +2                            exp     Z ( ) f w ( ) d Z (m) :                                       (98)
                              exp f C (0)

                                                                      7
Evaluating now at f w = f;
                                                                                                1 2
                d2 KL                             2         1               1
                                                                                2    b R                   2
                        2 jf w =f   =   (Z (m)   1) + 2 R
                                                                2
                                                                    1   R
                                                                                    exp f        (0)
                                                                                                       Z (m)        (99)
              dlf w (m)                                                                     C
                                                                                2
                                                  2         1               1               2
                                    =   (Z (m)   1) + 2 R           1   R           Z (m) :                        (100)
                                                                2
                                                                                                               2
So the weights across frequencies in the KL divergence are approximately a function of Z (!) .


References
Dew-Becker, Ian, “The pricing of economic risks under time-separable and recursive preferences,” 2016.
   Working paper.




                                                      8
