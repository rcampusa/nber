                  NBER WORKING PAPERS SERIES




         EMPIRICAL TESTING OF ASSET PRICING MODELS




                           Bruce N. Lehmann




                        Working Paper No. 4043




          NATIONAL BUREAU OF ECONOMIC RESEARCH
                   1050 Massachusetts Avenue
                     Cambridge, MA 02138
                         April 1992



Prepared for the New Palgrave Dictionazy of Money and Finance. Thanks are
due to Ravi Jagannathan, David Modest, Arthur Warga, and, especially,
Andrew Lo for many helpful comments. The usual disclaimer applies. This
paper is part of NBER's reseazxh program in Asset Pricing. Any opinions
expressed are those of the author and not those of the National Bureau of
Economic Research.
                                               NBER Working Paper #4043
                                               April 1992




           EMP[RICAL TESTING OF ASSET PRICING MODELS




                                  ABSTRACT



          This essay reviews the extensive literature on empirical testing of asset
pricing models. It briefly describes the kinds of asset pricing models typically
tested in the literature and explicates their econometric implications, both in
terms of the estimation of relevant parameters and tests of their implied
restrictions. Pertinent aspects of the available data on security prices and
macroeconomic variables are discussed as well. The essay concludes with the
examination of selected aspects of the current empirical state of asset pricing
theory.




                                              Bruce N. Lehmann
                                              Graduate School of International
                                               Relations and Pacific Studies
                                              University of California,
                                               San Diego
                                              La Jolla, CA 92093
                                              and NBER
       The content and style of both theoretical and empirical
research on the pricing of capital assets has changed
dramatically during the last three decades. Prior research in
finance typically involved valuation exercises for individual
securities considered in isolation—what would usually be
termed security analysis—using empirical principles derived
from corporate finance and financial accounting. Modern
theory emphasizes the implications of comovements among
security returns for the valuation that investors should place
on individual securities. Similarly, modem empirical research
has been largely devoted to the collection of facts regarding
regularities in security prices across assets and time with which
to confront the theory.
       Financial economics retained a sharp empirical focus
throughout this transition.        Empirical work is far more
prominent in finance than in other branches of economics. In
part, this reflects the availability of high quality data on many
relevant variables—stock prices, dividends, bond yields, and
the like. However, it is also a consequence of other factors like
the focus of earlier research on the valuation of actual
securities, the modern theoretical emphasis on models couched
in terms of potential observables, their practical usefulness,
                               1
and the ability to assess the success or failure of models by the
common measuring rod of financial profit and loss. Feedback
between theory and fact has led to much scientific progress in
the study of asset prices.
       This entry is devoted largely to the elucidation of the
methodological aspects of this successful interplay between
theoretical and empirical research. The next section describes
the kinds of asset pricing models typically tested in the
literature and sketches their econometric implications. The
subsequent section describes the methods used to estimate and
test models while the penultimate section discusses relevant
aspects of available data on security prices. The final section
surveys selected aspects of the current empirical state of asset
pricing theory and provides some brief concluding remarks.
                Modem Asset Pricing Theory
       That one can write a reasonably coherent self-contained
essay on empirical tests of asset pricing theory (as opposed to a
disjointed survey of loosely connected topics) is largely a
testament to the communalities among alternative models.
The central elements of modern theory are the specification of
the economic environment confronting investors and the twin
behavioral assumptions that investors exploit any arbitrage

                               2
opportunities and that they have rational expectations about
future prospects. This section describes the asset pricing models
that emerge in this setting.
        The principal environmental assumption is that
investors confront perfect markets—the absence of frictions like
taxes, transactions costs, and constraints on short sales. While
there are models that permit some frictions, they are often
either intractable or bear a striking resemblance to perfect
markets models. For example, tax-based or proportional
transactions cost asset pricing models often look like after-tax or
transactions cost adjusted versions of frictionless models.
        The central behavioral assumption is that of investor
rationality in two dimensions. The first dimension is the no
free lunch assumption—that security prices do not permit
investors to perceive any arbitrage opportunities. The premise
that rational investors would vigorously exploit any arbitrage
opportunities is the closest thing to physical force in financial
economics. Following RubinsteinU 976) and RossCl 978), the no-
arbitrage value of an arbitrary uncertain income stream is:

        1it   = E* [d1÷Q, I It]; Q >0 V t4 >0
where          represents income received from security i at time

                                 3
t+j, P is the price of a claim to this income stream, Qj is the

state price density (giving state prices per unit probability or
probability-adjusted shadow prices), the expectations operator
   • I 13 reflects probability beliefs, which need not be rational or

objective, held conditional on information available at time t
(i.e., J), and the information set and probability beliefs can differ
across investors. Different values of Q (which are generally
not unique in incomplete markets) are implied by different
probability beliefs.
       The second behavioral assumption is that investors
possess rational expectations or objective probability beliefs. In
these circumstances:

       1'i                          > 0 V t,j >0
             =; E [d÷1Q, I 1]; Q
where E[. 113 represents the population conditional expectation
of its argument so that EN' I 13 equals E*E. 1k] above. Behavioral

rationality in both dimensions is the defining characteristic of
the efficient markets hypothesis.
       Simple ideas underlie this abstract present value
relation. The set of strictly positive random variables Q,j exists

if it is not possible to form costless (zero net investment or self-
financing) portfolios that earn riskless positive profits. In terms

                                4
of conventional constructs like the means and variances of
returns, the pricing relation simply implies that investors face a
finite tradeoff between mean and variance.
       Straightforward translations of this relation yield
familiar models. For example, the stochastic assumption:
       E[dt+jQt,1 1k] = E[d1t+1 III] (1+rjY

yields the famous martingale model in which returns are
unpredictable save for their constant means. Similarly, Q is
the representative investor's marginal rate of substitution in
consumption between periods t and t+j adjusted for inflation in
most equilibrium models.
       In order to explicate the econometric implications of this
class of models, it is useful to translate the model into an
expression for single period returns.         Trivial algebraic
manipulation of the present value relation yields:
                       =
                                d+1
      E[R1+1 Q,i  I Ij              Qi 1k] =
                         Fflt+1
Some   empirical researchers work with prices and the general
present value relation or multiperiod returns but the bulk of
the literature studies single period returns. Accordingly, the
remainder of the essay will be confined to the analysis of
returns.
       It is also useful to rewrite these models in a more
                                  5
standard form—'beta' pricing models in which (conditional)
expected returns are linearly related to the (conditional)
coefficients (i.e., betas) from the regression of returns on
particular portfolios.                Following Hansen and
Jagannathan(1990), consider the projection:
            =    + O,i R÷1 +                              I I] = 0

where   R÷1—a portfolio based on the arbitrary menu of N
assets with return vector L÷i—replicates the risk/return
characteristics of Qi• The return R÷i provides a scale-free
proxy for Q. Portfolios like p have returns that are maximally
correlated with               and     weights proportional to
VarRB+i/IF1Cov[R+pQ1 I 13 (where Var[•] and Cov[•] denote
the variance and covariance of their arguments, respectively)
since E[R+jQi I 13 equals one. All portfolios z with returns
R+i uncorrelated with Qi and portfolio p have conditional
expected return E[Q,1 I iP.

        Accordingly,   Q satisfies the projection equation:
           = E[R÷1          —   E[R÷i-R÷jil]
                                               (RP+i-EERP+I 1 It])]

                        +CQt÷1
which provides an obvious identification of Wt,i and             O.
Rewriting the expected return relation in terms of portfolios p
and z yields:
                                  6
           =
                  zt+1 11k] pt+1 (Rpt+rEE1zt+i 11t1) +

                                             E[&pt÷ipt÷i'I lt] = Ept+i;

                      lpt+i = Cov[&+isRpt+i I I1/Var[R÷i 'It]
A portfolio p which implies a linear risk/return relation like
this is said to be conditionally mean-variance efficient. Two
restrictions are lost in the passage from a priori knowledge of
Qt,i to prespecification of Rpt+ i—the hypotheses that
E[Rzt+i I I] equals E[Qt,i I 1t] for all portfolios with returns
uncorrelated with Qt,j and that EERt+i lit1 equals
EEQt,i I It1[1-Cov(Rt+iQt,i I I)I. This occurs because the return
Rpt+i is scale-free like an index number.

       Asset pricing models differ in their specification of the
pricing operator Qt, and the replicating portfolios p and z.
When one exists, the riskless asset can usually replace portfolio
z. Table I lists a variety of mainstream asset pricing models,
their postulated risjc factors (i.e., sources of uncertainty
underlying Qt,t and the portfolio p that the model implies is
(conditionally) mean-variance efficient (i.e., generates a linear
risk/return relation). In this table, efficient means mean-
variance efficient (i.e., minimizes variance for a given mean
return).


                               7
                            Table 1
                        Postulated Risk
       Model               Factor(s)           Portfolio p

   Capital Asset
   Pricing Model                           Market Portfolio of
      (CAPM)          Aggregate Wealth      All Risky Assets
                       Common Factors
                       That Account for       Efficient
                           Systematic     Combination of
 Arbitrage Pricing    Correlation Among Factor Replicating
  Theory (APT)         Security Returns      Portfolios
                                              Efficient
                        Growth Rates of   Combination of
                        State Variables   Market and State
   Intertemporal           Including      Variable Hedge
  CAPM (ICAPM)        Aggregate Wealth       Portfolios
                                             Portfolio
                           Aggregate        Maximally
  Consumption-           Intertemporal    Correlated  With
   based CAPM           Marginal Utility  Marginal Utility
     (CCAPM)               Functional       Functional
                                             Portfolio
                                            Maximally
                        Instantaneous     Correlated With
                        Growth Rate of       Aggregate
Continuous Time            Aggregate       Consumption
     CCAPM              Consumption           Growth
                                             Efficient
                                          Combination of
                                            Market and
                                            Portfolios
                      Aggregate Wealth      Maximally
CAPM With Non-         and Non-Traded     Correlated With
 Traded Assets          Asset Returns    Non-Traded Assets
Related models include a variety of international CAPMs and
An's as well as linear after-tax models.

                               8
       Finally, it is worth noting an important limitation of
these models. Given observation of        or R+i and modest a
priori knowledge of the stochastic structure of returns, these
models make precise predictions about capital asset prices.
However, they make few predictions about quantities save for
those that impinge on Qu and for the trivial, and trivially false,

predictions of no trade or portfolio separation that arise under
representative investor assumptions. Good models of price
behavior might be poor models of quantity behavior and, in
particular, of the volume of trade, a problem that will occupy
future research.
                   Econometric Methods
       This no-arbitrage rational expectations asset pricing
model implies a tight link between the economic and
econometric characteristics of asset pricing theory. These asset
pricing relations imply that the (conditional) expected value of
         is unity for all assets satisfying the perfect markets
assumption if the underlying model is true.          Intuitively,
parameter estimation can proceed by analyzing sample
analogues of this moment condition, which should be close to
one in the neighborhood of the true parameter values.
Similarly, the joint hypotheses of perfect markets, market
                              9
efficiency, and the model for Qi can be tested by measuring the

proximity of these sample moment to unity.
        What remains is to formalize this intuition. The
remainder of this subsection discusses an important special
case—the zero beta CAPM and the corresponding problem of
testing the mean-variance efficiency of a given portfolio p. In
the zero beta CAPM, the model for returns is:
            =     + p1pt+14z)      +                     E[l+i-R Ic] =
                                           =                             =
                             Eft,11 lit]             Eft,1,+1c,1,+1' I

and   the unknown parameters are the expected return R of
portfolio z, the vector of individual security betas , and the
residual covariance matrix E1,. This time invariant beta pricing
model differs from the general no-arbitrage model in the time
invariance constraints placed on R, ,,               and    E1, and the
omission of the restrictions that R equals E[Qj I 'ti-I and that
       1k] equals E[Qi   I                     I li)].

       This model provides a useful illustration even for
multiple beta models like the APT or ICAPM or when portfolio
z is identified a priori as when a freely traded riskless asset is
assumed to exist. In these cases, simply interpret (i-D ) is the
vector of betas on a second factor (ignoring the link with ,) or
interpret all returns as excess returns over the observed riskless

                                 10
rate (so that R equals zero). The extension to the case of more
than two betas is straightforward. Similarly, the replacement of
portfolio p by variables like the growth rate of aggregate
consumption adds no new problems save for the need to
estimate the associated consumption risk premium.
       The passage from a priori spedfication of Qi to a priori
identification of portfolio p has greatly affected the focus of
empirical research. The principal predictions of this time
invariant beta pricing model are cross-sectional—that expected
asset returns are linearly related to asset betas. Consequently,
the empirical literature has focussed largely on the ability of
cross-sectional variation in betas to account for cross-sectional
variation in mean returns. To be sure, the model makes time
series predictions—that all serial correlation in returns is
mediated through R÷i or, as is commonly assumed, that
returns are unpredictable because              is assumed to be
unpredictable. Nevertheless, until recently, the literature has
concentrated on the question of whether these models can
explain relative asset prices and not the level of asset prices or
the market price of risk.
       This is not to say that the overall level of asset prices is

not an important research topic. The apparently high average
                              11
excess return on equity securities over the riskfree rate—the
market price of risk or equity premium—compared with the
predictions of equilibrium models is generally referred to as the

equity premium puzzle, although the extent of the puzzle
remains in doubt since the equity premium is measured very
imprecisely. Similarly, the apparently low return on nominally
riskless assets is also inexplicable in current equilibrium models
and is known as the riskfree rate puzzle. Still, relative asset
prices have been the main preoccupation of the asset pricing
literature.
       Many of the relevant econometric issues can be
illustrated geometrically for this time invariant beta pricing
model. Figure 1 depicts three loci: the mean-variance efficient
set (i.e., the set of all portfolios that minimize the variance of
returns at each level of mean return), the set of all portfolios
with returns orthogonal to the efficient portfolio p (i.e., the
vertical line through z*), and the set of minimum variance
portfolios with returns orthogonal to the inefficient portfolio p.
All moments can be interpreted as either sample or population
moments (or, for other purposes, as either conditional or
unconditional moments).


                              12
                          Figure 1
                                         Minimum Variance
Portfolios Orthogonal to p            Portfolios Orthogonal to p
Variance
                                         V
                                                      Efficient Set
                                       p           (Minimum Variance
                                              '*       Portfolios)




                                                            Mean


                              Estimation
           Figure 1 illustrates the basic principles of estimation in
  time invariant asset pricing models. When the means and
  variances in Figure 1 represent sample moments, the efficient
  set gives the set of portfolios that are mean-variance efficient in
  the sample (i.e., ex post) and portfolio p is the portfolio whose
  ex ante efficiency is in question. In these circumstances, there

  are numerous portfolios with returns uncorrelated with those
  of portfolio p in the sample—the set of minimum variance
  portfolios with returns orthogonal to those of p in the sample

                                 13
and all of the portfolios that lie inside this parabola. The mean
return of each of these portfolios provides a consistent estimate
of the zero beta rate R when portfolio p is ex ante efficient. In
other words, the parabola of minimum variance orthogonal
portfolios collapses to a line like z in large samples as p
converges to a point like p since the sample efficient frontier
converges to the population frontier.
       Neither sample minimum variance frontier can be
constructed when there are fewer time series observations than
assets. The resulting sample covariance matrix of returns (the
relevant second moments) is singular and, hence,
noninvertible. Put differently, there are many portfolios with
zero sample return variances in these circumstances. This
problem pervades empirical asset pricing research.
       The idea that one can estimate R with the average
return of a portfolio with weights based on sample moments
was crucial for the formulation of estimation and inference
procedures for linear asset pricing models. The portfolio
interpretation has a simple source. We may not observe
portfolio z but we typically observe or can estimate asset betas.
Methods for estimating R such as ordinary, weighted, or
generalized least squares are linear statistical procedures and,

                              14
hence, the least squares weights can be interpreted as portfolio
weights. This general idea facilitated the development of risk
premium estimators to cope with the small sample effects of a
variety of potential measurement errors. In addition, the
returns of these portfolios can be used to draw inferences about
risk premium estimates.
          Portfolio z is an econometrically special portfolio—its
mean return is the same as that produced by a generalized least
squares regression. To fix notation, let B denote the vector of
sample mean asset returns, let       denote their sample betas (i.e.,

the sample covariances of individual security returns with
those of portfolio p divided by the sample variance of portfolio
p), let     denote the sample covariance matrix of the residuals
from the regression yielding k1,1 let     denote the sample mean

return of portfolio p, let j. denote a suitably conformable vector
of ones, and let T denote the number of time series
observations on asset returns.          Cross-sectional regression
estimators r of the expected return R take the form:
             (i-k )'AQ-kR.)


where A is an arbitrary weighting matrix.
          The generalized least squares estimator of R is obtained


                                15
by replacing A with the inverse of the sample residual
covariance matrix Si,. This estimator is also the average return
of portfolio z in Figure 1.           However, calculation of this
estimator is not possible when N is greater than T. Other
estimators like ordinary and weighted least squares converge to
R in large samples when p is efficient but generally converge
to different numbers when p is inefficient. That is, in large
samples, the ordinary and weighted least squares portfolios lie
on the line above z for efficient portfolios like p and are
generally located at different points inside the parabola of
minimum variance orthogonal portfolios in Figure 1 for
inefficient portfolios like p.
       Portfolio z has a zero sample beta but will not have a
zero population beta except by random chance. Risk premium
estimates based on beta estimates suffer from the usual errors-
in-variables bias induced by measurement error in the sample
betas. Hence, the estimates of R obtained from ordinary,
weighted, and generalized least squares regressions are all
biased downward in finite samples, biases which do, however,
vanish in large samples. Two procedures have been employed
to mitigate this problem—grouping and measurement error
corrections.

                                 16
       Grouping is a standard statistical solution to the errors-
in-variables problem. Since Black, Jensen, and Scholes(1972)
and Fama and MacBeth(1973), it has been common practice to
form between ten and forty portfolios, often sorting by the
sample betas from a previous period to improve the precision
of the estimated zero beta rate. Portfolio betas have much
smaller sampling errors than individual security betas and,
hence, their use diminishes the errors-in-variables bias. The
advantage of this procedure is its simplicity and the cost is the
potential loss of information from grouping, particularly when
testing asset pricing models.
       An alternative approach involves attacking the
measurement error problem more directly. The potential
errors-in-variables bias in this estimator has three sources: the
covariance between the sampling error in           and (i-k ). the
difference between the sample variance of (i-k ) and the sample
variance of (i-l3) and potential dependence between the
sampling errors in both K and R and that in           Miller and

Scholes(1972) provide an excellent discussion of this general
problem in a related context.
       The first two potential sources of errors-in-variables bias
can be mitigated by using information on the sampling error in

                                17
estimated betas. In particular, we can estimate the variance of
the measurement error in sample betas under alternative
statistical assumptions and correct least squares estimators
accordingly. For example, (L-b                              is an
unbiased estimator of (L-tYA(1-j1).                    Similarly,
                                      is an unbiased estimator of

(s-j3)'AG1-.R) ignoring possible dependence between the
sampling errors in j and         on the one hand and       on the
other. Both bias corrections can be implemented given an
unbiased estimator of                      and the ratio of these
two bias-corrected quantities yields an approximately unbiased
estimate of R (ignoring Jensen's inequality). See Litzenberger
and Ramaswamy(l979), Shanken(1983), and Lehmann(1990) for
further details.
       The third potential bias arises from potential relations
among the sampling errors in R       and      The bias is usually

small given symmetric return distributions (like the normal)
which imply little dependence between first and second
moments. However, it can be quite serious when returns are
drawn from skewed distributions and is amplified when         is

replaced by other sample moments such as the variance of
returns, which is highly correlated with mean returns under
                            18
skewness. The distributions of the returns of individual equity
securities tend to be skewed sharply to the right while the
returns of diversified portfolios tend to be symmetrically
distributed so that grouping can mitigate this bias.
       Most of the literature has assumed that returns are
independently distributed over time and this suggests a simple
palliative. Since Fama and MacBeth(1973) and Black and
Scholes(1974), it has been common to estimate parameters like
    in one sample period and the returns of portfolio z in a
subsequent period. In a cross-sectional regression framework
with no measurement error corrections, this procedure takes
the form:

        'Zt+
                         ,
               (i-ia YAt(&+i-ktRt+i)
                       n-
                   'b IA(b
                   s-_

where all returns are for period t+1 and the subscript t on an

estimator means that it is based on data from period t and
earlier. The measurement errors in A and kpt are distributed
independently of subsequent returns when returns are
independently distributed over time. The expected return of
portfolio z can then be measured by the sample mean of the
actual portfolio returns R÷1 based on the estimates A and
Measurement error corrections can be applied as well.


                              19
       The actual returns of portfolio z can also be used to draw
inferences about R. In particular, a natural estimator of the
standard error of the mean return is the standard deviation of
the portfolio return divided by the square root of T. This
estimator is, in fact, biased in large samples even when returns
are independently distributed over time but the asymptotic bias
is seldom large in asset pricing applications. It provided an
operational procedure for inference at a time when
econometric theory was neither sufficiently well developed nor
understood to provide all of the necessary asymptotic theory.
       Consistent standard errors follow from now well-
known results from large sample theory. Let .)T@.-k) be a
random vector that converges in distribution to a normal
random vector with mean zero and covariance matrix A.
Suppose we are interested in estimating a function g() like a
risk premium. A natural estimator of g(.) is g(4). Under
suitable regularity conditions, 'ff(g ()-g(.)) converges in
distribution to a normal random variable with mean zero and
variance g'@)TAg'() where g'() is the first derivative of g(.).
The asymptotic variance can then be consistently estimated by
replacing g'()TAg'() with gI@)TDgt() where D is any
consistent estimator of A. Lehmann(1990) contains the relevant

                             20
expressions for the standard errors of risk premiums in linear
asset pricing models using this approach.
         Researchers have also studied maximum likelihood
estimators of zero beta rates assuming returns are normally and
independently distributed over time. Many of the intuitions
for the least squares estimator of the zero beta rate carry over to
the maximum likelihood estimator because it is linear in the
maximum likelihood estimator of the vector of asset betas.
Kandel(1986) provides a detailed discussion of the geometry of
the maximum likelihood estimator of the zero beta rate and
Shanken(1986) provides useful computational results.
         Zero beta rate and beta estimates can be viewed as
generalized method of moments estimates based on the
moment conditions Eft+iR÷11 = Eft+1] = Q. The general
problem of estimation and inference in. asset pricing models
can be cast in the generalized method of moments framework
of Hansen(1982). To fix matters, let Qu      be parameterized as

             where       is a vector of variables relevant for
determining       and p. is a qxl vector of unknown parameters

underlying the functional form for Q(.) (i.e.,     (p.E         In
addition, let zj be an m1xl vector of variables known at time t
(i.e.,          Finally, let k+(p) denote the m1xl vector
                              21
                                                            N
                    and let h+i(p.) be the M (i.e., the E m1)
                                                           i=1

vector obtained by stacking h1+ip) for i=1,. . .,N. In the special
case where .jt=&t V i, ht+1 (p.) is given by K+1Q,i Lx+)®ri
where 0 is the usual Kronecker product operator. Finally,
assume that h+1(p) possesses a nonsingular population
covariance matrix and that Eh÷1 (p.)] has full column rank.

       Following Hansen and Singleton(1982), the rational
expectations no-arbitrage asset pricing relation implies the
vector moment condition E[h÷i(p)] = 0. Save for the choice of
the appropriate variables and the functional form for Q( •), asset
pricing models implicitly prescribe the econometric methods
appropriate for their estimation—choose p. to set the average
value of h÷1(p) as close to zero as possible. Unfortunately, all

such sample moments cannot be simultaneously set to zero
when the number of nonredundant moment conditions M
exceeds the number of unknown parameters q.
       Accordingly, HansenU 982) has suggested the generalized
method of moments estimator t that minimizes the sample
quadratic form based on a sample of T observations on
    and g1:




                              22
        TIIT(PYWTh*); hT(P) =

given a positive definite weighting matrix WT converging in
probability to a positive definite limit W.
        Large sample inference for t is straightforward and
parallels the asymptotic standard error calculations sketched
above. Under suitable regularity conditions, Hansen(1982) has
shown that:
        .j±(-J -4N(2DT(PJST<&DT(&'); 5'r(p = Th[Uj(p)hWJ'];
                                    Dr(p) = ft-(pJWTh] 1h+W)WT
        V
where   —*   denotes   convergence in distribution. Consistent
standard error estimates can be calculated from this expression

by replacing p with x• Hansen(1982) showed that these standard
errors are robust to both conditional heteroskedasticity and
autocorrelation in large samples, a useful feature in the
presence of time-varying expected returns.
        Asymptotically, the optimal weighting matrix WT is
proportional to S'$pY1. When T exceeds M and returns are

independently distributed over time, the optimal weighting
matrix can be consistently estimated by:
                 r1T                T1
        WTC) =
                  tZ
                 Lt=i

                               23
where f    is any consistent estimate of a•   When returns are

serially dependent, WI can be estimated by any consistent
estimator of the spectral density of h(p.) at frequency zero. See
Hansen(1982) and Newey and West(1987) for further
discussion.

       However, this optimal weighting matrix generally
cannot be estimated when M is greater than T since the usual
estimators of Si'(g) are then singular and, hence, noninvertible.
Asymptotically less efficient choices for WT like the identity
matrix (which is analogous to ordinary least squares) or the
diagonal matrix consisting of the inverses of the sample
variances of j(L*) (which is analogous to weighted least
squares) can be employed instead. Alternatively, the N assets
underlying the moment conditions can be grouped into a
smaller number of portfolios and the number of moment
conditions (i.e., the number of information variables jt can be
limited so that the resulting weighting matrix is nonsingular.

                             Testing
       Figure 1 also illustrates the basic principles of mean-
variance efficiency tests.    If a portfolio is mean-variance
efficient like p, all of its associated zero beta portfolios which
cost a dollar have the same expected return as portfolio z.
                              24
Hence, all costless zero beta portfolios associated with p" have
zero mean returns. On the other hand, an inefficient portfolio
like p has associated zero beta portfolios that cost a dollar at all
levels of mean return. In Figure 1, this is the set of minimum
variance orthogonal portfolios and all of the portfolios that lie
inside this parabola. Consequently, costless zero beta portfolios
need not have zero expected returns when p is not
mean-variance efficient. Intuitively, mean-variance efficiency
tests ask whether particular costless zero beta portfolios have
zero expected returns.
       The algebraic embodiment of this intuition is
straightforward. Consider the unconditional expected return
relation for individual securities:
       E[Rj÷1] =   a, + (1-I3)R + PE[R+i1
The parameter Ujp      is   the expected return of the portfolio
formed by buying $1 of security i, selling short                 of
portfolio z, and selling short        of portfolio p. This portfolio

is costless (since the long position is financed by the short
positions) and has a zero beta (since the positions in portfolios p
and z hedge the beta risk). Accordingly, the expected return

of this zero net investment, zero beta portfolio should be zero if
p is an efficient portfolio. All such portfolios for each of the N

                                 25
securities should then have zero expected returns.
         In the absence of specific alternative hypotheses, a
statistician would naturally test the joint hypothesis that the N
         are all equal to zero against the vague alternative
hypothesis that some or all of them are nonzero. This
hypothesis has a simple portfolio interpretation: that all
portfolios of the costless zero beta portfolios with expected
return         have expected returns of zero. Such tests implicitly
search the N dimensional space of potential costless zero beta
portfolios for at least one with a nonzero expected return.
         To simplify matters, suppose that R is known as would
be the case if portfolio z were an observed riskless asset. Sample
mean returns then satisfy:
           =
             a1 + (1-b)R +
where       is the sample analogue of         If excess returns are

jointly normally and independently distributed over time, the
joint null hypothesis that the N a1's are all zero can be tested
with the T2 statistic:

       T
          a      '   —
                       T2(N,T-2)
               (RR)2
          1+s
where s, is the sample variance of the returns of portfolio p.
The product of (T-N-1)/NT and the T2 statistic follows an F
                                26
distribution with N and T-N-1 degrees of freedom. This is just
a standard F test for the hypothesis that the intercepts in a
multivariate regression are all equal to zero which is discussed
at some length in MacKinlay(1987) and Gibbons, Ross, and
Shanken(1989).
       Large values of            make large values of ap'Sjp
more probable, increasing the likelihood of rejection of the null
hypothesis of efficiency. The circumstances in which this
occurs also have a portfolio interpretation: ptjap is the
largest squared Sharpe ratio (i.e., ratio of squared mean to
variance) of all costless zero beta portfolios since all minimum
variance, zero net investment, zero beta portfolios have
weights proportional to Ej,sx.,. In the absence of a specific
alternative hypothesis, it makes sense to examine the costless
zero beta portfolio with the highest sample ratio of squared
mean to variance.
       This observation suggests that tSts against vague
alternatives will have low power unless portfolio p misprices
many securities. Put differently, .p'Ejap is smaller than
      divided by the smallest eigenvalue of E1,. Unless       is

nearly singular, apta1, will be small if the sum of squared
     is small. Unfortunately,            must be very large in

                             27
the presence of many assets to yield probable rejections since
the T2 statistic implicitly searches in N dimensions for costless
zero beta portfolios with nonzero mean returns.
       When the known value of R is replaced by a
generalized least squares version of r in the T2 statistic, the
estimated a's behave like the intercepts from the regression of
        on R+rR in large samples. Hence, the T2 statistic can
be used to test the null hypothesis of efficiency in large samples
after replacing N with N-I to allow for the degree of freedom
lost in the estimation of R. Shanken(1985,1986) argued
convincingly for the finite sample relevance of this asymptotic
approximation. Related tests like likelihood ratio tests have
poor finite sample properties, a fact documented in
Stambaugh(1982), Amsler and Schmidt(I985), and
MacKinlay(1 987).
       The transition from the zero beta CAPM to the general
model involves the passage from independently and identically
distributed to possibly serially correlated returns. The analysis
of tests of general asset pricing relations against vague
alternative hypotheses parallels that for the efficiency of
portfolio p. In the generalized method of moments framework
of Hansen(I982) and Hansen and Singleton(1982), the rational

                              28
expectations no-arbitrage asset pricing relation implies the
vector moment condition E[h+1(p)I = Q. When the optimal

generalized method of moments estimator of p. is employed
(i.e., when the weighting matrix WT is proportional to i)4),
the null hypothesis can be tested against the vague alternative

hypothesis             since:
                           V
       T frr(b'S *Y1 hT(r) —, 2(M-q)

in large samples.
       None of this testing apparatus is applicable when N or
M are greater than T. Since this is the case in financial market
data for most countries, one must either place arbitrary
restrictions on the asset menu or test asset pricing relations
against particular alternative hypotheses. In practice, the latter
option is generally taken in the literature.
       One common strategy is to group the available universe
of securities into a smaller number of portfolios. The asset
pricing model is then being tested against an alternative
hypothesis implicit in the choice of grouping variable. For
example, the implicit alternative hypothesis is that the a1's of
individual securities are systematically related to their betas
when researchers group stocks based on their estimated betas in
a previous period to facilitate estimation of zero beta rates.
                              29
Grouping characteristics employed in the literature include
firm size, dividend yield, price-earnings ratio, market-to-book
value, previous period returns, and residual risk. Curiously,
grouping strategies based on previous period a1, estimates—
which would yield powerful tests when a values persist—
generally have not been employed in the literature (see
LehmannU 988) for an exception). All of the testing apparatus
developed above can be applied so long as the number of
grouped portfolios or moment conditions is smaller than T.
        The other strategy is to test explicitly an asset pricing
relation against a specific alternative hypothesis. Such tests
involve estimating risk premiums for security characteristics
when theory predicts that the risk premiums are zero. For
example, if z is a vector of characteristics known at time t, the

mean-variance efficiency of portfolio p can be tested in the
expected return model:
        E[Rj+1]   = a + (1-131)R +          +

where   the null hypothesis is that equals zero. Similarly, the
parameter vector a in the generalized method of moments
framework can be expanded to include a vector of risk
premiums for &jt in the alternative model:
        E[(RI+IQi @÷p&-l)g iO

                               30
 where the asset pricing model can be tested with the large
sample 2 statistic for the hypothesis that equals zero. Neither
kind of test requires that T exceeds N or M.

        This approach permits the use of large cross-sections in
efficiency tests which can dramatically increase their power.
Large samples of securities make precise estimation of the
covariance between security returns and characteristics more
likely. However, researchers do often understate the pretest
bias associated with the choice of particular alternative
hypotheses, both in this strategy and in the grouping approach.
In statistical jargon, the size of the resulting tests is typically
overstated since the characteristics were chosen because of their
estimated correlations with returns. The issues associated with
•pretest bias and the size of tests is discussed extensively in Lo
and MacKinlay(1990). See Lehmann(1988) for an approach
which largely avoids this pretest bias.
       These specific alternative hypotheses take the form of
positing variables that help explain expected returns when
theory predicts they should not. In some cases, variables are
selected by considering what variables should account for
expected returns if the underlying assumptions of the asset
pricing model—no frictions, no arbitrage, rational expectations,

                              31
and the model for         or the identity of portfolio p—are false.

Nevertheless, the identification of nonzero risk premiums
associated with theoretically irrelevant variables seldom
suggests which of these joint hypotheses failed. In these
circumstances, researchers typically look in the direction of
improved models for Qi or portfolio p. Future research may
search more actively in other directions such as imperfect
liquidity (i.e., failure of the no frictions assumption) or
irrational beliefs (i.e., fads and fashions).
         Finally, the best estimation procedures under the null
hypothesis may not yield the most powerful tests under the
alternative hypothesis.        Similarly, particular alternative
hypotheses might reduce the efficiency of risk premium
estimators but potentially improve the power of the resulting
tests. Put differently, data choices greatly affect the power of
tests.

                               Data
         While   rational no-arbitrage models make sharp
predictions, they leave open several measurement issues and
data analytic choices. In particular, the preceding analysis took
the asset menu, the model for          or the a priori identification

of portfolio p (and, perhaps, portfolio z), and the information
                                32
variables ZjE ' as given. This section discusses questions about
regarding the measurement of the relevant economic
quantities as well as some pertinent features of U. S. data on
asset prices.
       Modern asset pricing relations tell researchers what to
measure—the state price density            or portfolio p. Particular

models even indicate how to measure these .quantities. For
example,          is   proportional to the growth rate of aggregate
consumption in the continuous time CCAPM and portfolio p is
the market portfolio of all risky assets in the CAPM.

       Data analysts always face the possibility that important
variables are measured with error and financial economists are
no exception. In linear models like the time invariant beta
pricing model or the continuous time CCAPM, classical
measurement error in Q,i or the return of portfolio p—that is,
mean zero measurement error uncorrelated with asset
returns—causes no problems in principle save for inefficiency
in the parameter estimates. For example, such errors in
measuring aggregate consumption growth do not bias estimates
of its covariances with asset returns, the relevant parameters
for this model.
       Roll's (1977) critique can be read as a belief that
                                 33
measurement error correlated with returns is likely to be the
rule rather than the exception in asset pricing applications. The
particular focus of Roll's critique—the zero beta CAPM—
implies that the market portfolio of all risky assets is mean-
variance efficient. Tests of the zero beta CAPM typically
examine whether proxies for the market portfolio such as
equally weighted or value weighted indices of New York and
American Stock Exchange stocks are mean-variance efficient.
These tests provide no information about the efficiency of the
market portfolio without a model linking the proxy and the
unobservable market portfolio. Put differently, measurement
error in aggregate wealth is likely to be correlated with asset
returns. Similar problems afflict consumption measures when
consumer durables yield unobservable consumption service
flows that are likely to be correlated with asset returns.
       There have been several responses to the Roll critique.
Two reactions are conventional. One is testing the robustness
of conclusions to the choice of proxies for portfolio p or
For example, it is common practice to use several proxies for

aggregate consumption growth in tests of the CCAPM.
Similarly, Stambaughçl982) tested the sensitivity of tests of the
CAPM to alternative proxies for the market portfolio. Second,

                               34
researchers are more careful in stating precisely what theory is
being tested. The literature now abounds with cautious
statements about testing a particular implementation of a
theory or testing the mean-variance efficiency of a particular
portfolio rather than the CAPM.
       More substantively, attention is now fixed on models
that provide a framework for measuring portfolio       p or Q.
Prior to the Roll critique, Jensen(1969) and Miller and
Scholes(1972) argued that CAPM tests using an equally-
weighted index of many assets as a proxy for the market
portfolio were joint tests of the CAPM and the hypothesis that
the CAPM residuals could be diversified away in large
portfolios (termed the single index market model). The APT
built on this notion of diversifiable risk since well-diversified
portfolios perfectly mimic the underlying common factors from
multiple factor models in large cross-sections, yielding an
obvious measurement strategy. Similarly, specific models have
been proposed linking consumer durable purchases to
consumption service flows.         In addition, Kandel and
Stambaugh(1987) and Shanken(1987) have shown how to test
the joint hypothesis that a given model is true and some proxy
for p has a given correlation with its true unobserved
                             35
counterpart.
       The choice of asset menu is less an option for the
researcher than a constraint imposed by the financial markets
that exist and the availability of data from them. The previous
section emphasized the problems that arise when N exceeds T.
A more serious problem is that many countries d.o not have
well-developed capital markets and even those that do contain
many assets that are not traded in an organized (and easily
recorded) fashion. A more complete theory of finance would
account for both the existence and absence of different financial
institutions across countries and assets but it is fair. to say that
such a theory is largely in the domain of future research.
       Hence, a major empirical issue is asset coverage. There
are data on many but not all assets in a few countries and
spottier coverage in other countries. For example, there is high
quality data on listed common stocks, government bonds, and
futures contracts in the U. S. and comparable data for shorter
periods in the United Kingdom and Japan. However, markets
for the easy trading of most capital assets simply do not exist in
most less developed countries and even the data for Common
Market countries is somewhat sketchy, although this may
change in the future. Some assets simply are not traded in
                               36
 liquid markets like corporate bonds, bank loans, human capital,
 and many forms of physical capital and real estate.
        Coverage and imperfect asset markets are often
 troublesome issues for equilibrium theories like the CAPM.
 They are frequently less problematic for no-arbitrage models
like the APT since such models typically apply to subsets of
assets that satisfy the perfect markets assumption even when
there are other assets that do not. Similarly, such problems can
often be avoided in equilibrium asset pricing models with
particular stochastic process assumptions. For example,
Grossman and Shillertl982) show that nontraded assets pose no
problems for the continuous time CCAPM when instantaneous
household consumption growth rates and asset returns jointly
follow diffusion processes.

       Another choice confronting the researcher is the choice
of observation interval. Except for continuous time models,
asset pricing models do not specify the decision intervals of
investors. Accordingly, there is no a priori reason to think that
investors make portfolio decisions on the daily, weekly,
monthly, or annual bases implicitly assumed in most empirical
applications. Jensen(1969) showed that the measurement
interval was irrelevant in time invariant beta pricing models
                              37
with are log-normal returns but temporal aggregation remains
a problem in more general settings. See Grossman, Melino,
and Shiller(1989) and Breeden, Gibbons, and Litzenberger(1989)
for a discussion of temporal aggregation issues in continuous
time asset pricing models.
       Researchers must also choose the instruments z1 that
facilitate estimation and testing of asset pricing models. Early
evidence suggested that past prices were not useful in
predicting asset returns and thus much of the literature did not
employ prior period instruments. There are now two kinds of

commonly employed instruments—security characteristics and
selected time series variables. While such variables are
sometimes suggested by particular asset pricing models or
alternative hypotheses, chosen instruments are generally the
result of extensive prior data searches.           See Lo and
MacKinlay(1 990) for further discussion.
       There are some stylized facts about the behavior of asset
returns that are important for both estimating and testing of
asset pricing relations. In particular, the returns of long-lived
assets like stocks and bonds are highly volatile in the short run.
In terms of the moments that are relevant for many asset
pricing models, this means that second moments like variances

                              38
and covariances are typically precisely estimated while mean
returns are usually estimated imprecisely, even over long time
periods. In addition, there are well-measured, predictable
changes in the short run volatility in asset returns which both
provide the opportunity to estimate models of conditional
heteroskedasticity and require appropriate inference
procedures.
       The imprecision of mean estimates suggests there may
be a huge cost to specifying portfolio p a priori when estimating
asset pricing relations. For example, an explicit model of
(without nonclassical measurement error) and identification of
R÷i with a measured riskless rate completely avoid the need
to estimate mean returns since                         I Ij equals
      I Ij[1-Cov(R+11Q1 I Ii)], which ought to be measured well

due to the volatility of asset returns. The covariance term is a
function of risk aversion parameters in most equilibrium
models and, hence, the resulting magnitude of estimated risk
aversion provides an additional check on the plausibility of the
model. In addition, the imprecision of mean estimates suggests
that power is likely to plague efficiency tests in the absence of a
priori knowledge of variables that are correlated with
population mean returns.

                              39
       The degree to which returns are predictable is important
for the estimation and testing of intertemporal asset pricing
models. Short run return predictability is generally both
economically small and precisely measured, although the
weekly returns of small firm portfolios exhibit substantial
autocorrelation. The evidence on long run return predictability
is considerably more controversial. The long run evidence
remains inconclusive in large part because much of it comes
from the Great Depression. Accordingly, precise estimation of
intertemporal asset pricing models with time varying expected
returns may be problematic even if they are true.
       Finally, prices are typically measured well in financial
market data while quantities are often measured poorly. For
example, most equilibrium models imply that          is a function

of the growth rate of aggregate consumption services while
consumption expenditures are the variable that is measured
with much error. In fact, the theory of finance is primarily a
theory of prices and not quantities partly because finance is data
driven and prices are the data that are well measured.
       High quality transactions data on stock and bond
transactions are becoming available for U. S., European, and
Japanese markets. Accordingly, theory and evidence regarding
                              40
 the volume of trade are central to the current research agenda
 in finance. This, too, is problematic since theories typically
 relate price fluctuations to the volume of informed trading and
 actual volume includes the trades of both informed and
uninformed investors. Hence, much current research links
volume and volatility on the hypothesis that volatility in large
part reflects the trading of informed investors.
                    Empirical Evidence
       This entry has provided a reasonably detailed
description of the methods employed to estimate and test asset
pricing theory. This section briefly describes the current
empirical status of some mainstream asset pricing models. The
discussion is brief on the hypothesis that the methodological
contributions described earlier are more lasting.
       The empirical literature on the CAPM went through
two distinct phases.       Early research concentrated on
methodological developments and the exploration of
alternative CAPM formulations. Later research revolved
around the discovery of numerous 'anomalies'—security
characteristics or calendar effects that helped explain average
security returns after controlling for risk with estimated
security betas. Perhaps accidentally, this second phase roughly
                             41
coincided with the publication of Roll's (1977) critique.
       There was little credible empirical evidence against the
CAPM in the early literature. Variables like dividend yield,
squared beta, and residual risk proved incapable of explaining
the mean returns of grouped equity portfolios after risk
adjustment using betas from an equally-weighted portfolio of
New York Stock Exchange stocks as a proxy for the market
portfolio. In fact, the main empirical observation was that the
zero beta rate R appeared to exceed the riskless rate, the value
predicted by the Sharpe-Lintner-Mossin version of the CAPM.
       Subsequently, substantial evidence against the CAPM
arose in the form of empirical anomalies. New variables like
firm size, price-earnings ratio, market-to-book value, and
previous period returns helped account for risk-adjusted equity
returns. Calendar effects—the January, week of the month, day
of the week, and hour of the day effects—proved hard to
rationalize in frictionless, no-arbitrage models in general and in
the CAPM in particular. New statistical procedures employing
individual securities instead of grouped portfolios found
significant dividend yield and residual risk effects. In addition,
the inclusion of small stocks amplified many of these effects.
       While empirical tests of the APT also went through
                              42
 several phases, a more useful distinction involves the nature of
 the empirical implementation. One class of implementations
 identifies factors from the covariance structure of returns using
statistical procedures like maximum likelihood factor analysis
or principal components. A second strategy is to prespecify the
factors a priori as either the growth rates of macroeconomic
variables or the returns of particular assets or portfolios, an
approach also susceptible to pretest bias. Finally, some studies
prespecify instead security characteristics presumed to reflect
the security correlations (i.e., betas) with the common factors.
What are called anomalies in the CAPM have recently become
'prespecified betas' in APi' implementations.
       Loosely speaking, APT models better account for
expected equity returns than CAPM implementations. There is
little evidence of pronounced dividend yield or residual risk
effects in the first two kinds of APT applications and the size
and price-earnings ratio effects are much smaller. Of course,
APT models that use security characteristics identified as CAPM
anomalies as prespecified betas provide only self-referential
'explanations' of CAPM anomalies. In addition, CAPM betas
seldom help explain average equity returns after APT risk
adjustments. Unlike the CAPM, the pricing intercepts in APT

                             43
applications are typically close to the riskiess rate.

        Finally, intertemporal and consumption-based models
have not provided a satisfactory account of mean equity
returns.     Such models typically fail simple tests—like
accounting for the cross-sectional variation in average industry
portfolio returns—that are easily passed by APT and CAPM
implementations. Similarly, consumption betas typically fail to
help explain cross-sectional variation in mean equity returns
after CAPM or APT-style risk adjustments. Intertemporal
models have not yet confronted the more rigorous challenge of
explaining the expected returns of small, high earnings yield,
zero dividend, high volatility firms. However, much of this
literature has focussed on the inability of equilibrium
intertemporal models to explain the equity premium and
riskfree rate puzzles, not on their ability to explain relative
equity prices.
       In fact, the distinctions among the CAPM, APT, and
intertemporal theories have blurred in practice. Quantitative
portfolio managers use multiple factor models irrespective of
the labels they attach to them. In academic applications, it is
now commonplace to assume that returns are generated by
some collection of factors which may be observed or
                               44
 unobserved and have time-varying or time invariant risk
premiums. These multifactor models are generally consistent
with most modem asset pricing models save for the question of
whether their residuals can be diversified away in large cross-

sections. Since empirical implementations typically employ
grouped portfolios, the cross-sectional diversifiability of the
residuals is not testable so that the distinction among models is
largely semantic.
       This is unsurprising—all multibeta models can be
collapsed into single beta representations. As shown in the
theory section, all rational no-arbitrage asset pricing models
imply the existence of a (conditionally) mean-variance efficient

portfolio.    Accordingly, much of the heat regarding the
comparative virtues and flaws of alternative models—which
occupied much of the literature in the 1970s—has largely
dissipated.
       More importantly, this observation suggests the
empirical utility of no-arbitrage models. They provide a useful
framework within which to organize and generate facts about
the covariation and variation of asset returns, facts that are
surely relevant for many plausible asset pricing models.
Similarly, different intuitions about the empirical failures of

                             45
asset pricing models can easily be incorporated into the no-
arbitrage framework. Accordingly, empirical research will
proceed on a broad front for the foreseeable future. Asset
pricing models, models for portfolio p or Q,1, will continue to
improve. In addition, researchers will explore the implications
of alternative models for beliefs (i.e., fads) and frictions (i.e.,
taxes, short sales constraints, and market microstructure issues).




                              46
                        Bibliography
Amsier, Christine F. and Peter Schmidt, 1985, "A monte carlo
       investigation of the accuracy of multivariate CAPM
       tests," Journal of Financial Economics 14, pp. 359-376.

Black, Fischer, Michael C. Jensen, and Myron Scholes, 1972,
       "The capital asset pricing model: some empirical tests"
       in Michael C. Jensen, ed., Studies in the Theory of
       Capital Markets (New York: Praeger).

— and Myron Scholes, 1974, 'The effects of dividend yield and
       dividend policy on common stock prices and returns,"
       Journal of Financial Economics 1, May, pp. 1-22.

Breeden, Douglas T., Michael R. Gibbons, and Robert H.
       Litzenberger, 1989, "Empirical tests of the consumption-
       oriented CAPM." Journal of Finance 44, pp. 231-262.

Chamberlain, Gary and Michael Rothschild, 1983, "Arbitrage
     and mean-variance analysis on large asset markets,"
       Econometrica 51, pp. 1281-1304.

Chan, K. C., 1988, "On the contrarian investment strategy,"
      Journal of Business 61, pp. 147-163.

Chen, Nai-fu, Richard W. Roll, and Stephen A. Ross, 1986,
      "Economic forces and the stock market," Journal of
      Business 59, pp. 383-403.

Connor, Gregory and Robert A. Korajczyk, 1988, "Risk and
     return in an equilibrium APT: application of a new test
     methodology," Journal of Financial Economics 2, pp.
      255-289.

De Bondt, Werner F. M. and Richard Thaler, 1985, "Does the
     stock market overreact?" Journal of Finance 40, pp. 793-
      805.




                             47
—, 1987, "Further evidence on investor overreaction and stock
      market seasonality," Journal of Finance 42, pp. 557-581.

Epstein, Larry G. and Stanley E. Zin, 1991, "Substitution, risk
       aversion, and the temporal behavior of consumption
       and asset returns: an empirical analysis," Journal of
       Political Economy 96, pp. 263-286.

Fama, Eugene F., 1970, "Efficient capital markets: a review of
      theory and empirical work," Journal of Finance 25, pp.
       383-417.

— and James D. MacBeth, 1973, "Risk, return, and equilibrium:
       empirical tests," Journal of Political Economy 81, pp.
       607-636.

— and C. William Schwert, 1977, "Asset returns and
       inflation," Journal of Financial Economics 5, pp. 115-146.

French, Kenneth R., 1980, "Stock returns and the weekend
       effect," Journal of Financial Economics 8, pp. 55-69.

Gibbons, Michael R., 1982, "Multivariate tests of financial
       models: a new approach," Journal of Financial
       Economics 10, pp. 3-28.

—, Stephen A. Ross, and Jay Shanken, 1989, "A test of the
       efficiency of a given portfolio," Econometrica 57, pp.
       1121-1152.

Grossman, Sanford J. and Robert J. Shiller, 1982, "Consumption
      correlatedness and risk measurement in economies
      with non-traded assets and heterogeneous
      information," Journal of Financial Economics 10, pp.
      195-210.

Grossman, Sanford J., Angelo Melino, and Robert J. Shiller,
     1987, "Estimating the continuous-time consumption-
     based asset pricing model," Journal of Business and
      Economic Statistics 5, pp. 31 5-327.
                              48
Hansen, Lars P., 1982, "Large sample properties of generalized
      method of moments estimators," Econometrica 50, pp.
        1029-54.

— and Kenneth J. Singleton, 1982, "Generalized instrumental
       variables estimation of nonlinear rational expectations
       models," Econometrica 50, pp. 1269-1286.

— and Kenneth J. Singleton, 1983, "Stochastic consumption,
    risk aversion, and the temporal behavior of asset
       returns," journal of Political Economy 91, pp. 249-265.

— and Ravi Jagannathan, 1989, "Implications of security
       market data for models of dynamic economies," journal
       of Political Economy 99, pp. 225-262.

Jegadeesh, Narasimhan, 1990, "Evidence of predictable behavior
      of security returns," journal of Finance 45, pp. 881-898.

Jensen, Michael C., 1969, "Risk, the pricing of capital assets, and
       the evaluation of investment portfolios," journal of
       Business 42, pp. 389-416.

Jobson, J. D. and Bob M. Korkie, 1982, "Potential performance
       and tests of portfolio efficiency," journal of Financial
       Economics 10, pp. 433-466.

Kandel, Shmuel, 1984, "The likelihood ratio test statistic of
     mean variance efficiency without a riskless asset,"
       Journal of Financial Economics 13, pp. 575-592.

—,   1986, "The geometry of the maximum likelihood estimator
       of the zero-beta return," Journal of Finance 41, pp. 339-
       346.

— and Robert F. Stambaugh, 1987, "On correlations and
       inferences about mean-variance efficiency," Journal of
       Financial Economics 18, pp. 61-90.
                              49
Lehmann, Bruce N., 1990, "Residual risk revisited," Journal of
       Econometrics 45, pp. 71-97.

—, 1988, "Mean-variance efficiency tests in large cross-
     sections," unpublished manuscript, Graduate School of
     Business, Columbia University.

—,   1990,   "Fads, martingales, and market efficiency," Ouarterly
       Journal of Economics 105, pp. 1-28.

— and David M. Modest, 1988, "The empirical foundations of
       the arbitrage pricing theory," Journal of Financial
       Economics 21, pp. 213-254.

Litzenberger, Robert and Krishna Ramaswamy, 1979, "The
      effects of personal taxes and dividends on capital asset
       prices," Journal of Financial Economics 7, Pp. 163-195.

Lo, Andrew W. and A. Craig MacKinlay, 1990, "Data snooping
      biases in tests of financial asset pricing models," Review
       of Financial Studies 3, pp. 431-467.

MacKinlay, Craig, 1987, "On multivariate tests of the CAPM,"
       Journal of Financial Economics 18, pp. 341-372.

Merton, Robert C., 1980, "On estimating the expected return on
      the market," Journal of Financial Economics 8, pp. 323-
       361.

Miller, Merton H. and Myron Scholes, 1972, "Rates of return in
       relation to risk: a reexamination of some recent
       findings" in Michael C. Jensen (ed.), Studies in tim
       Theory of Capital Markets (New York: Praeger).

Newey, Whitney and Kenneth West, 1987, "A simple, positive
       semi-definite, heteroskedasticity and autocorrelation
       consistent covariance matrix," Econometrica 55, 703-708.


                               50
 Roll, Richard W., 1977, "A critique of the asset pricing theory's
        tests—part 1: on past and potential testability of the
        theory," Journal of Financial Economics 4, pp. 129-176.

—,   1979,   "Testing a portfolio for ex ante mean variance
        efficiency" in Edwin E. Elton and Martin J. Gruber, eds.,
        Portfolio Theory, Twenty Five Years After (New York:
        North- Holland).

—,   1980,   "Orthogonal portfolios," Journal of Financial and
        Ouantitative Analysis 15, pp. 1005-1023.

—, 1985, "A note on the geometry of Shanken's CSR 12 test for
      mean-variance efficiency," journal of Financial
        Economics 14, pp. 349-358.

Rosenberg, B., Kenneth Reid, and Ronald Lanstein, 1985,
       "Persuasive evidence of market inefficiency," journal of
       Portfolio Management 12, pp. 9-16.

Ross, Stephen A., 1978, "A simple approach to the valuation of
       risky streams," journal of Business 51, pp. 1-40.

Rothschild, Michael, 1986, "Asset pricing theories' in Walter P.
       Heller, Ross M. Starr, and David A. Starrett, (eds.),
       Uncertainty, Information, and Communication: Essays
       in Honor of Kenneth 1. Arrow (Cambridge, England:
       Cambridge University Press).
Rubinstein, Mark, 1976, "The valuation of uncertain income
       streams and the pricing of options," Bell Journal of
       Economics and Management Science 7, pp. 407-425.

Shanken, Jay, 1983, "An asymptotic analysis of the traditional
      risk return model," School of Business Administration,
      University of California, Berkeley.

—, 1985, "Multivariate tests of the zero beta CAPM," Journal of
       Financial Economics 14, pp. 327-348.

                              51
—, 1986, "Testing portfolio efficiency when the zero beta rate is
       unknown," Journal of Finance 41, pp. 269-76.

—,   1987,"Multivariate proxies and pricing relations: living
       with the Roll critique," Journal of Financial Economics
       18, pp. 91-1 10.

Sharpe, William F., 1985, "Factor models, CAPMs, and the
       APT," Journal of Portfolio Management, pp. 21-25.

Singleton, Kenneth J., 1990, "Specification and estimation of
       intertemporal asset pricing models" in Benjamin
       Friedman and Frank Hahn (eds.), Handbook of
       Monetary Economics (Amsterdam: North-Holland).
Stambaugh, Robert F., 1982, "On the exclusion of assets from
       tests of the two-parameter model: a sensitivity
       analysis," Journal of Financial Economics 10, pp. 237-268.

Sweeney, Richard and Arthur D. Warga, 1986, "The pricing of
       interest rate risk: evidence from the stock market,"
       Journal of Finance 41, pp. 393-41 0.




                              52
