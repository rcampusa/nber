                                 NBER WORKING PAPER SERIES




                 HOLD-UP, ASSET OWNERSHIP, AND REFERENCE POINTS

                                               Oliver Hart

                                         Working Paper 13540
                                 http://www.nber.org/papers/w13540


                       NATIONAL BUREAU OF ECONOMIC RESEARCH
                                1050 Massachusetts Avenue
                                  Cambridge, MA 02138
                                      October 2007




I am grateful to John Moore for discussions on some of the elements of this paper, and to Bob Gibbons
and Birger Wernerfelt for many helpful conversations. I would also like to thank Mathias Dewatripont,
Florian Englmaier, Rob Gertner, Louis Kaplow, Josh Lerner, Bentley MacLeod, and Jeremy Stein
for useful comments, and to Georgy Egorov for excellent research assistance. Financial support from
the U. S. National Science Foundation through the National Bureau of Economic Research is gratefully
acknowledged. The views expressed herein are those of the author(s) and do not necessarily reflect
the views of the National Bureau of Economic Research.

© 2007 by Oliver Hart. All rights reserved. Short sections of text, not to exceed two paragraphs, may
be quoted without explicit permission provided that full credit, including © notice, is given to the source.
Hold-up, Asset Ownership, and Reference Points
Oliver Hart
NBER Working Paper No. 13540
October 2007
JEL No. D23,D86,K12

                                                ABSTRACT

We study two parties who desire a smooth trading relationship under conditions of value and cost
uncertainty. A rigid contract fixing price works well in normal times since there is nothing to argue
about. However, when value or cost is exceptional, one party will hold up the other , damaging the
relationship and causing deadweight losses as parties withhold cooperation. We show that a judicious
allocation of asset ownership can help by reducing the incentives to engage in hold up. In contrast
to the literature, the driving force in our model is payoff uncertainty rather than noncontractible investments.


Oliver Hart
Department of Economics
Littauer Center 220
Harvard University
Cambridge, MA 02138
and NBER
ohart@harvard.edu
1. Introduction


       This paper reexamines some of the themes of the incomplete contracts literature – in

particular, the hold-up problem and asset ownership – through a new theoretical lens, the idea

that contracts serve as reference points (see Hart and Moore (2008)). We consider a buyer and

seller who are involved in a (long-term) economic relationship where the buyer’s value and

seller’s cost are initially uncertain. For the relationship to work out the parties need to cooperate

in ways that cannot be specified in an initial contract. The buyer and seller face the following

trade-off. On the one hand they can write a flexible contract that attempts to index the terms of

trade – price – to the state of the world. However, to the extent that value and cost are not

objective, such a contract will lead to argument, aggrievement and shading; this in turn creates

deadweight losses. On the other hand the parties can write a (relatively) rigid contract, e.g., a

fixed price contract. A rigid contract has the advantage that there is less to argue about in

“normal” times, but the disadvantage that, if value or cost falls outside the normal range, one

party will have an incentive to engage in hold-up, i.e., to threaten to withhold cooperation unless

the contract is renegotiated. We suppose that hold-up transforms a friendly relationship into a

hostile one. The consequence is that the parties operate within the letter rather than the spirit of

their (renegotiated) contract, causing deadweight losses that are at least as great as those from

shading. However, even a hostile relationship is assumed to create more surplus than no trade,

and so, if value or cost has moved sufficiently far outside the normal range, hold-up will occur.

        We show that an appropriate allocation of asset ownership can mitigate hold-up (and

shading) costs. The idea is that, if the buyer (resp., the seller) owns key assets, then this

improves his outside opportunities, and so in states of the world where his value inside the

relationship is high, his value outside the relationship is also high. But this reduces the seller’s



                                                  2
(resp., the buyer’s) ability to engage in hold-up, which increases efficiency. One feature of our

approach is that, in contrast to much of the literature, it focuses on ex post rather than ex ante

inefficiencies. Indeed (noncontractible) ex ante investments play no role.

       It is useful to compare the current paper with the existing literature on asset ownership

and vertical integration: in particular, transaction cost economics (see, e.g., Williamson (1971)

and Klein et al. (1978)) and property rights theory (see, e.g., Grossman and Hart (1986) and Hart

and Moore (1990)). According to transaction cost economics, contracts between independent

parties are problematic because, given contractual incompleteness, deadweight losses will occur

as parties haggle over the ex post division of the quasi-rents. A key factor in determining

vertical integration decisions is the size of these quasi-rents. According to the property rights

literature, parties will bargain around the deadweight losses from haggling, but ex ante

investments will be distorted. A key factor determining vertical integration is the marginal

product of quasi-rents with respect to (noncontractible) ex ante investments. This paper

emphasizes a third factor: the variability of quasi-rents with respect to the state of the world; that

is, payoff uncertainty.

       We have both a theoretical and an empirical motivation for introducing a new factor into

the analysis. First, existing models, such as Grossman and Hart (1986) and Hart and Moore

(1990), have some foundational weaknesses. Second, these models seem to apply better to small

entrepreneurial firms than to large companies. Third, as the recent empirical survey by

Lafontaine and Slade (2007) shows, payoff uncertainty does seem to be an important determinant

of vertical integration (see particularly their Tables 1 and 14). Yet neither transaction cost

economics nor (present versions of) property rights theory stress payoff uncertainty per se. Our

hope is that the current model will not only aid in the interpretation of existing studies, but will




                                                  3
also stimulate new empirical work.

         Although most of the literature does not stress uncertainty, there is a small part that does.

Goldberg and Erickson (1987) in their study of long-term contracts between buyers and sellers of

petroleum coke find that these contracts are often indexed, and are shorter-term if the

environment is more volatile. In Sections 2 and 4 we argue that our model is consistent with

these observations. Our paper is close in spirit to Klein (1996).1 Klein, using the Fisher Body –

General Motors and Alcoa – Essex cases as motivating examples, argues that “hold-ups occur

when market conditions change sufficiently to place the relationship outside the self-enforcing

range.” Klein goes on to argue that integration can ameliorate this problem. However, Klein

does not formalize the costs of hold-up and does not explain what limits the self-enforcing range

of contracts.2

         While Klein’s analysis is mainly informal, Baker et al. (2002) provide a formal analysis

of (relational) contracts and hold-up in a world of uncertainty (see also Halonen (2002)). Baker

et al. use a standard property rights model and focus on ex ante rather than ex post inefficiencies.

They are concerned mainly with how relational contracts and asset ownership can help to

mitigate the underinvestment problem. In contrast our model stresses the role of non-relational

contracts and asset ownership in reducing the ex post inefficiency losses of hold-up (and

shading).

         The paper is organized as follows. In Sections 2 and 3 we lay out the model, focusing on

rigid or “simple” contracts. The model is very much in the spirit of Hart and Moore (2008)

(particularly Section III), but with the novelty that it includes the possibility of hold-up and

1
  See also Klein and Murphy (1997) and Klein (2007).
2
  As another example of hold-up occurring under extreme conditions, consider the case of a company that
incentivizes its employees by promising high rewards if they are successful, but then is tempted to renege on its
promise when the rewards turn out to be excessive. For a discussion of how Xerox Corporation dealt with this
problem, see Harvard Business School cases 9-295-127, 9-298-109,5-298-152.


                                                          4
explores the role of asset ownership. (In Hart and Moore (2008) there are no assets,

renegotiation or hold-up but the parties can quit.) In Section 4 we consider a more general class

of contracts. Section 5 contains concluding remarks.

2. The Model

         We consider a buyer B and a seller S who are engaged in a long-term relationship. The

parties meet at date 0 and can trade a widget at date 1. There is uncertainty at date 0, but this is

resolved shortly before date 1, at date 1- , say. There is symmetric information throughout and

the parties are risk neutral and face no wealth constraints. Each party has an outside option that

he (or she) earns if trade does not occur. Let v, c denote B’s value and S’s cost if trade proceeds

smoothly (i.e., the parties cooperate at date 1), and let rb, rs denote B and S’s outside options. We

assume that v, c, rb, rs, although observable, are not verifiable.

         We follow Hart and Moore (2008) in supposing that for the gains from trade to be fully

realized each party must take a number of “helpful” or “cooperative” actions at date 1. These

actions cannot be specified in a date 0 contract because they are too complicated to describe in

advance. When the uncertainty is resolved at date 1- , some of these actions become describable

and so can be contracted on, while others are never contractible. 3 Thus some modification or

renegotiation of the contract is possible at date 1- . We assume that all the helpful actions are

chosen simultaneously by B and S at date 1. See Figure 1 for a time line.




3
  An example of a contractible helpful action would be where one party allows the other party to modify the
characteristics of the good to be traded, e.g., the delivery time An example of a noncontractible (or less contractible)
helpful action would be where one party provides useful information to the other party, consults with them before
making a decision, or responds to their phone calls or emails. For evidence that the same contractible action can lead
to different performance outomes ( depending on ownership structure ), suggesting that noncontractible actions are
important, see Januszewski Forbes and Lederman ( 2007 ).



                                                           5
              0                                               1-               1

              │__________________________________│____________│

        Parties meet                                     Uncertainty      Parties choose
        and contract                                resolved and date     helpful actions
                                                 0 contract modified      and trade occurs
                                                 and/or renegotiated
                                      Figure 1


We make the following assumptions:



(A1)   If at date 1 all helpful actions are taken, the value of the widget to B is v and the cost to S

       is c, where v > c. Hence net surplus = v – c in this case.



(A2)   If at date 1 all the contractible, but none of the noncontractible, helpful actions are taken,

       the value of the widget to B is v – ½ λ (v – c) and the cost to S is c + ½ λ (v – c), where 0

       < λ < 1. Hence net surplus = (1 – λ)(v – c) in this case.



(A3)   If at date 1 none of the helpful actions (contractible or otherwise) is taken, B’s value is

       very low (approximately, – ∞) and S’s cost is very high (approximately, + ∞). In this

       case each party walks away from the contract (neither party has an incentive to enforce it)

       and no trade occurs; that is, the parties earn their outside options.




                                                  6
         Note that the import of (A2) is that withholding noncontractible helpful actions moves v

and c in the direction of ½ (v + c).

         What determines whether a party is helpful? As in Hart and Moore (2008), we suppose

that being helpful does not cost significantly more than not being helpful: either it costs slightly

more or it costs slightly less, that is, a party may actually enjoy being helpful. To simplify

matters, we assume that a party is completely indifferent between being helpful and not.

         Given this indifference we take the view that a party will be willing to be helpful if he is

“well treated” by the other party, but not otherwise (negative reciprocity)4. Importantly, as in

Hart and Moore (2008), a party is “well treated” if he receives what he feels entitled to, where

the date 0 contract is a reference point for date 1 entitlements. To be more precise, neither party

feels entitled to an outcome outside those permitted by the contract. However, within the contract

there can be disagreement about the appropriate outcome.5

         It is useful to begin with the case where the parties write a “simple” contract at date 0 that

specifies a single trading price p (we normalize so that the no trade price is zero). Consider what

happens at date 1-, once the uncertainty is resolved. Each party has a choice. He can stick to the

contract. Or he can try to force the other party to renegotiate the contract – we interpret this as

“hold-up.”

         Let’s consider the scenario where the parties agree to stick to the contract. Under these

conditions, each party feels well-treated by the other party since he is getting exactly what the

4
  There is a large amount of empirical evidence in support of negative reciprocity. Many references can be found in
Hart and Moore (2008). For a recent paper, see Anderson and Simester (2007), which shows that customers who
have bought a product from a retailer, and later observe the same retailer selling it for less, reduce their demand for
other products sold by the retailer.
5
  To motivate the idea that the date 0 contract is a reference point for date 1 entitlements, Hart and Moore (2008)
make the companion assumption that the date 0 contract is negotiated under competitive conditions. The
competitive date 0 market provides objective measures of what B and S bring to the relationship, and it is supposed
that the parties accept these measures as “fair”. In contrast there are no objective measures or competitive market at
date 1 (or 1-), e.g., because the parties have made ( contractible) specific investments between dates 0 and 1. For a
more detailed discussion, see Hart and Moore (2008).


                                                           7
contract said he would: the contract specifies a single trading price p. Thus each party is willing

to be helpful, and all cooperative actions are undertaken. The buyer and seller’s payoff are,

respectively,



(2.1) Ub = v-p,



(2.2) Us = p-c.

         In the second scenario, one party engages in hold-up: that is, he tries to force the other

party to renegotiate the contract. He does this by threatening not to undertake any helpful

actions unless he receives a sidepayment. We assume that such behavior is viewed as outrageous

by the victim– it is a breach of the spirit of the date 0 contract – and leads, in the first instance, to

the end of cooperation. The result is a Nash equilibrium where neither party cooperates. This

yields the no-trade outcome described in (A3), with payoffs rb, rs for B, S, respectively.

          However, renegotiation is possible.6 Even if the relationship is soured the parties can

and will agree to undertake the helpful contractible actions at date 1. At the same time, it is

supposed that neither party will provide noncontractible cooperation (again this is a Nash

equilibrium). In effect the parties have a cold but correct relationship.7 Renegotiation therefore

yields surplus (1 – λ) (v – c) by (A2). Thus if




6
  In fact we suppose that the parties cannot commit ex ante not to renegotiate. Below we discuss whether such a
commitment would be desirable.
7
  Note that we suppose that the parties cannot negotiate around this coldness. One could imagine that the buyer,
anticipating that the seller is about to hold him up, would make a sidepayment to the seller to deflect the hold-up and
preserve the relationship. We take the view that, given that there is a perceived threat in the background, the
relationship is poisoned nonetheless. For some evidence supporting this view, and suggesting that even “big”
players act in this way, see New York Times, August 27, 2007, p.A1 (reporting on the fact that the renegotiation of a
large buy-out deal of a Home Depot business, triggered by the 2007 subprime mortgage crisis, created considerable
bad feeling ).


                                                          8
(A4)     (1 – λ)(v – c) > rb + rs,


the parties will renegotiate away from the no-trade outcome. We will assume that (A4) holds in

what follows, but we will discuss in Section 5 what happens if (A4) is relaxed.8

         In summary, hold-up leads to a loss of surplus of λ(v-c).

         We suppose a 50:50 split of the surplus from renegotiation, so after hold-up the parties’

payoffs are



(2.3) Ub = rb + ½ G,



(2.4) Us = rs + ½ G,

where

(2.5) G = (1- λ) (v-c) –rb – rs.

         It is easy to determine when hold-up occurs. Define pL to be the price p such that S is

indifferent between receiving p and holding B up, and pH to be the price such that B is indifferent

between paying p and holding S up. Then from (2.1) – (2.4)



(2.6) pL – c = rs + ½ G,



(2.7) v – pH = rb + ½ G,



and so

8
  Hart and Moore (2008) implicitly assume the opposite of (A4), with the consequence that hold-up and
renegotiation do not occur. Instead the parties quit if their outside options exceed what they earn in the relationship.
See Section 5 for more on the difference between the models.



                                                           9
(2.8) pL = c + rs + ½ G,



(2.9) pH = v – rb – ½ G.



Note that



(2.10) pH – pL = λ (v-c) > 0.



(2.10) reflects the fact that there is some friction in the renegotiation process. If hold-up did not

lead to the souring of the relationship, λ would be zero, and pH = pL. However, since hold-up

causes some dissipation of surplus, pH > pL: the price at which B is just ready to hold up S is

strictly greater than the price at which S is just ready to hold up B.

         Since S is indifferent between holding B up and not at p = pL, S will strictly prefer to hold

up B when p < pL. Similarly, B will strictly prefer to hold up S when p > pH. Thus hold-up is

avoided if and only if



(2.11) pL < p < pH.



Note that pH, pL varies with the state of the world, whereas p is chosen ex ante. The situation is

illustrated in Figure 29.




9
 The interval [pL,pH] can be thought of as corresponding to Klein’s self-enforcing contractual range (see Klein
(1996)). However, in our model, this range is derived without the need to introduce relational contracts.


                                                         10
p             pL             pH     pL            p            pH       pL             pH              p

        S holds up B                        No hold-up                           B holds up S

            (a)                                 (b)                                    (c)

                                                Figure 2



        To make progress, we put more structure on the random variables rb, rs. We suppose



(2.12) rb = αb + βb v + φ + γb ε,



(2.13) rs = αs − βs c + γs η,

where

(2.14) 1- λ > βb > 0, 1- λ > βs > 0, γb > 0, γs > 0.



Here αb, βb, γb, αs, βs and γs are constants (later they will depend on the assets the parties own),

and φ, ε, η are independent random variables with mean zero. (2.12) – (2.14) capture the idea

that B and S’s outside options co-vary with v, c, respectively, but not too strongly, and are also

subject to exogenous noise (ε, η). The noise term φ is a smoothing device: its rationale will

become clear in Section 3.

        Given (2.12) – (2.13), we can represent the state of the world by the 5-tuple ω = (v, c, φ,

ε, η). Both parties observe ω at date 1-. Recall that a simple contract consists of a single price p,

where p is chosen before the state of the world ω is realized. It is useful to rewrite pL, pH as

functions of ω. From (2.8) – (2.9), we have




                                                   11
(2.15)           pL (ω) = ½ [αs + γs η − αb – φ – γb ε + ((1 – λ) – βb) v + ((1 + λ) – βs)c],



(2.16)           pH (ω) = ½ [αs + γs η − αb – φ – γb ε + ((1 + λ) – βb) v + ((1 – λ) – βs)c].



         Clearly pL, pH are monotonic in v,c. Since hold-up occurs when pL (ω) > p or pH (ω) < p,

that is, when pL (ω) is high or pH (ω) is low, it follows that hold-up occurs, ceteris paribus, if v is

exceptionally high or low or c is exceptionally high or low. This is intuitive: if v or c is high, S

does relatively well in the renegotiation process and so has an incentive to hold B up; similarly,

if v or c is low, B does relatively well in the renegotiation process and so has an incentive to hold

S up. In addition it is clear from (2.15) – (2.16) that the effect of exceptional values of v,c is less

pronounced if βb and βs are large since pL, pH are less sensitive to v, c under these conditions.

         We turn now to an optimal simple contract. Since date 0 lump-sum transfers can be used

to allocate surplus, an optimal contract maximizes expected net surplus. Thus an optimal simple

contract solves:


(2.17)           Max        ∫ ( v − c)dF(ω ) +     ∫ (1 − λ )(v − c)dF(ω )
                                                                                ,
                   p          pL(ω) ≤ p ≤ pH(ω)            p < pL(ω)
                                                           or p > pH(ω)


where F is the distribution function of ω.

         It is clear that the first-best can be achieved in the case of certainty: just pick any price p

in the interval [pL (ω0), pH (ω0)], where ω0 is the state of the world. However, the first-best

typically cannot be achieved under uncertainty since it is not generally possible to find a single

price that lies in the intersection of a number of different [pL (ω), pH (ω)] intervals.



                                                    12
           Our analysis so far has an obvious shortcoming. Suppose that the parties write a simple

contract at date 0. Then, as we have just observed, with uncertainty it is very likely that p will lie

outside the [pL (ω), pH (ω)] range for some ω, and so one party will hold up the other to get a

better price. Why don’t the parties anticipate this and build the renegotiated price into the

original contract? This leads to a consideration of more flexible contracts. In Section 4 we

therefore broaden the analysis to allow the parties to specify a range of possible trading prices

[p, p ] in their date 0 contract, along the lines of Hart and Moore (2008). As we shall show, the

main insights of our analysis do not change and so for most of the paper we will confine our

attention to simple contracts.

           We close this section by noting that our model is consistent with Goldberg and

Erickson’s (1987) finding that price indexation is a common feature of contracts between

suppliers and purchasers of petroleum coke. Although risk aversion is a possible explanation,

Goldberg and Erickson argue that it is more likely that price indexation is used to reduce

opportunistic behavior. Our model is consistent with this. By indexing the trading price p on a

verifiable signal σ that is correlated with ω, the parties can more easily ensure that p ε [pL(ω),

pH(ω)]. This reduces hold-up.

3. Asset Ownership

           In this section we explore the idea that asset ownership can improve the parties’ trading

relationship. We take a simple view of asset ownership. Asset ownership matters because it

determines which assets each party can walk away with if trade does not occur.10 This in turn

affects parties’ outside options and their incentives to engage in hold-up.

           Denote by A the set of all assets at B and S’s disposal; we assume A is fixed and finite.11


10
     As in Hart and Moore (1990). See also Grossman and Hart (1986).
11
     We suppose that the assets in A are already specialized, and so cannot be bought or sold on the open market.


                                                           13
Let Ab be the set of assets B owns and As the set of assets S owns. We suppose



(3.1)    Ab ∩ As =    φ , Ab U As ⊆ A.


The first part of (3.1) says that B and S can’t walk away with the same asset. The inclusion in

the second part reflects the possibility that if an asset is jointly owned neither party can walk

away with it: that is, joint ownership gives each party a veto right on its use.12

         We now suppose that the coefficients αb, βb, γb, αs, βs, γs depend on asset ownership. In

particular, αb = αb (Ab), βb = βb (Ab), γb = γb (Ab), αs = αs (As), βs = βs (As), γs = γs (As). We also

make assumptions similar to those in the property rights literature (see Grossman and Hart

(1986) and Hart and Moore (1990)) about how these coefficients vary with asset ownership. In

particular, we assume that owning more assets increases the marginal payoffs of rb, rs, with

respect to v and c. That is,



(3.2)    βb is nondecreasing in Ab ,



(3.3)    βs is nondecreasing in As.



We also assume that (2.14) and (A4) hold for all ownership structures.

         We suppose that assets can be traded at date 0. Thus a contract is now a 3-tuple (Ab, As,

p), specifying an asset ownership allocation (Ab, As) and a price p, where Ab, As satisfy (3.1).

An optimal contract solves:

12
  We confine attention to simple ownership structures. It would not be difficult to generalize the analysis to allow
for options to own, etc.


                                                          14
(3.4)           Max             ∫ ( v − c ) dF ( ω ) +        ∫ (1 − λ )(v − c)dF(ω )        ,
          (Ab, As, p)       pL(ω;Ab, As) ≤ p ≤ pH(ω;Ab, As)    p < pL(ω;Ab, As)
                                                              or p > pH(ω;Ab, As)




where pL, pH are now indexed by the asset ownership allocation (Ab, As), as well as by ω.

         We begin our analysis of asset ownership by considering what happens if, ceteris paribus,

assets are transferred at date 0 from S to B. Then, given (3.2) – (3.3), βb rises and βs falls. As is

clear from (2.15) – (2.16), this makes pL and pH less sensitive to v than before since



        ∂p L
(3.5)        = ½ ((1 – λ) – βb ),
         ∂v



        ∂p H
(3.6)        = ½ ((1 + λ) – βb ),
         ∂v



and these both decrease. On the other hand, pL (ω) and pH (ω) become more sensitive to c since



        ∂p L
(3.7)        = ½ ((1 + λ) – βs),
         ∂c



        ∂p H
(3.8)        = ½ ((1 – λ) – βs),
         ∂c



and these both increase.



                                                  15
       Intuitively, a reduction in sensitivity of pL, pH is good since, if the interval

[pL, pH] does not vary much, it is easier to find a price p that lies in [pL, pH] for many ω. That is,

hold-up is less likely. This suggests that it is optimal for B to own all the assets if only v varies,

since this minimizes the sensitivity of pL and pH with respect to the state of the world; while, it is

optimal for S to own all the assets if only c varies. Proposition 1 confirms this.



Proposition 1. (1) Suppose that φ = ε = η ≡ 0, and c ≡ c0 where c0 is a constant. Then there

exists an optimal contract in which B owns all the assets, i.e., Ab = A, As =    φ.

       (2) Suppose that φ = ε = η ≡ 0 and v ≡ v0, where v0 is a constant. Then there exists an

optimal contract in which S owns all the assets, i.e., As = A, Ab =   φ.


       In the Appendix we prove a more general version of Proposition 1, and of all the other

propositions in this section. In these more general versions, a range of possible trading prices is

allowed in the date 0 contract.

       Note that it would not be difficult to establish uniqueness in Proposition 1 under slightly

stronger stochastic assumptions.

       Proposition 1 is reminiscent of the result in the property rights literature that one party

should own all the assets if his investment is important. Here the conclusion is that one party

should own all the assets if his payoff is uncertain. Proposition 1 is also similar to results that

have been obtained by Simon (1951) and Wernerfelt (1997), among others, showing that the

party with a more variable payoff should be the boss.




                                                  16
       Of course, in general, both v and c vary. Proposition 1 is not very helpful here since it

tells us only when one party should own everything. However, some progress can be made if we

introduce the idea of an idiosyncratic asset.

       Define an asset to be idiosyncratic to B if B’s owning it increases the sensitivity of rb to v

and S’s not owning it has no effect on the sensitivity of rs to c. Define an asset to be

idiosyncratic to S similarly.



Definition (i) Asset a is idiosyncratic to B if βb (Ab U {a}) > βb (Ab ) for all Ab ⊆ A, Ab ∩ {a} =

φ , and βs (As U {a}) = βs (As ) for all As ⊆ A.

       (ii) Asset a is idiosyncratic to S if βs (As U {a}) > βs (As) for all As ⊆ A, As ∩ {a} =   φ,

and βb (Ab U {a}) = βb (Ab) for all Ab ⊆ A.

       Note that one reason an asset may be idiosyncratic to a party is if that party has human

capital that is complementary to the asset, e.g., he is the only person who knows how to operate

it.

       Allocating an asset to the party to whom it is idiosyncratic would seem desirable since it

reduces payoff variability. However, it turns out that to establish this one must make strong

assumptions about the stochastic structure. In the next proposition we suppose that with high

probability v, c take on “normal” values v = v0, c = c0, while with small probability v, c can each

take on an “exceptional” value. Since exceptional values are unusual, we ignore the possibility

that v and c can take on an exceptional value at the same time. We also suppose that there is a

small amount of exogenous noise through the random variable φ, but we set ε = η = 0.




                                                   17
Proposition 2. Assume that ε = η = 0 and φ is uniformly distributed on [-k, k]. Suppose that

with probability 0 < π < 1 event 1 occurs: v = v0, c = c0; with probability (1 – π) αv event 2 occurs:

                                                                 − β b (A) v 0 + (1 + λ ) v 0 − 2λc 0
c = c0, v has support [vL, vH], where vL ≤ v0 and vH ≥                                                  ; with probability
                                                                          1 − λ − β b (A)


(1 – π) αc event 3 occurs: v = v0, c has support [cL, cH], where cH ≥ c0 and cL ≤

− β s (A)c 0 − 2λv 0 + (1 + λ )c 0
                                   . Here αv > 0, αc > 0, αv + αc = 1, k > 0, and φ   is independent of v and c in
         1 − λ − β s (A)


events 2 and 3 respectively. Then for small enough k the following is true: if π is close to 1 it is

uniquely optimal for B to own asset a if a is idiosyncratic to B and for S to own asset a if a is

idiosyncratic to S.

Proof. See Appendix

        It is useful to understand why Proposition 2 requires such strong assumptions about the

probability distribution of v and c. The reason is the following. Let p be the optimal price for

the general case where v, c are uncertain. Suppose that we transfer an asset that is idiosyncratic

to B from S to B. (In what follows we suppress assets in the notation.) We know that this will

reduce the variability of pL(ω), pH(ω) with respect to v. But this might reduce the probability

that p lies in [pL(ω), pH(ω)] if, say, p ∈[pL(ω1), pH(ω1)], p ∉ [pL(ω2), pH(ω2)] and [pL(ω1), pH(ω1)]

moves closer to [pL(ω2), pH(ω2)]. The stochastic structure in Proposition 2 avoids this kind of

situation.

        A simple application of Proposition 2 is to the case of strictly complementary assets.

Suppose assets a1 and a2 are strictly complementary. Then a2 by itself is of no use to S, while a1

and a2 together may be very useful to B. Assume B owns a1. Then we can define a new

economy in which a1 is inalienable, i.e., B always owns a1, and the effective set of (alienable)

assets is A \ {a1}. For this economy, a2 is idiosyncratic to B in the sense of Definition (i).



                                                          18
Hence, according to Proposition 2, it is better for B to own a1and a2. The same argument shows

that if S owns a1, it is better for S to own both. The conclusion is that strictly complementary

assets should be owned together (by B or S – without further information we cannot say which).

A similar argument shows that joint ownership is suboptimal under the conditions of

Proposition 2.

        Of course, these results are very reminiscent of those obtained in the property rights

literature (see particularly Hart and Moore (1990)). However, the driving force is different:

uncertainty rather than ex ante investments.

        So far we have emphasized the idea that ownership of an asset is good for one party

because it reduces the variability of their payoff relative to their outside option. However, there

is also a class of cases where ownership can increase variability and it may be better to take

assets away from people. The next proposition describes a situation where it is better to take

assets away from both parties, i.e., joint ownership is optimal. In this proposition v and c are

constant while φ and ε or η vary.



Proposition 3. Assume γb, γs are strictly increasing in Ab, As respectively, and φ is uniformly

distributed on [-k, k]. Suppose that with probability 0 < π < 1 event 1 occurs: v = v0, c = c0, ε =

0, η = 0; with probability (1 – π) αε event 2 occurs: v = v0, c = c0, η = 0, ε has support [εL, εH],

             2λ ( c 0 − v 0 )
where εL ≤                      and εH > 0; with probability (1 – π) αη event 3 occurs: v = v0, c = c0, ε = 0,
                γ b (φ )

                                             2λ ( c 0 − v 0 )
η has support [ηL, ηH], where ηL ≤                              and ηH > 0. Here αε ≥ 0, αη ≥ 0, αε + αη = 1, k >
                                                γ s (φ )

0, and φ is independent of ε and η in events 2 and 3 respectively. Then for small enough k the




                                                                19
following is true: if π is close to 1 it is uniquely optimal for all assets to be jointly owned by B

and S.

Proof. See Appendix

         Again similar results have been obtained in the property rights literature (see, e.g.,

Halonen (2002) and Rajan and Zingales (1998)). Note that Proposition 3 depends on the

assumption that owning more assets increases the variance of the outside option. Although

plausible, one can certainly imagine other possibilities. For this reason we are inclined to put

less weight on Proposition 3 than on Propositions 1 and 2.

4. Flexible Contracts

         As we noted in Section 2, anticipating the possibility of hold-up, the parties can build

some price flexibility into their contract. Following Hart and Moore (2008), we therefore now

allow the parties to specify a range of possible trading prices [p, p ] in their date 0 contract; the

idea is that the parties will agree on a price in [p, p ] once the uncertainty is resolved at date 1-.

At the end of the section we also briefly discuss the possibility of state-contingent contracts or

mechanisms.

         Suppose that the parties pick the range [p, p ]. What happens at date 1-, once ω is

realized? There are two cases. Define

         H (ω, p, p ; Ab, As) = [ pL (ω; Ab, As), pH (ω; Ab, As) ] ∩ [p, p ].

If H ≠   φ the parties can avoid hold up by choosing a price in H: such a price is consistent with

the date 0 contract and gives neither party an incentive to hold up the other. However, if H =          φ

hold-up cannot be avoided.

         Start with the first case. Even though no hold-up occurs, there will be disagreement

about the appropriate outcome within the contract. In the spirit of Hart and Moore (2008), we


                                                    20
suppose that each party is aggrieved to the extent that he does not receive what he feels entitled

to, and will respond by shading, i.e., cutting back on helpful actions. We assume that each party

feels entitled to the best outcome permitted by the contract. However, each party recognizes that

he faces the feasibility constraint that the other party can trigger hold-up, i.e., B doesn’t expect to

pay less than pL or S to receive more that pH. In other words B feels entitled to the lowest price

in H, Max (pL, p ), and S feels entitled to the highest price in H, Min (pH, p). Note that the

assumption that entitlements are constrained by what is feasible simplifies the analysis, but is not

crucial.

           To simplify matters we assume that the parties split the difference and set



(4.1) p̂ = ½ {Max (pL (ω; Ab, As), p) + Min (pH (ω; Ab, As), p )}.




As part of this deal the parties agree to undertake the contractible helpful actions. However, each

party cuts back on the noncontractible helpful actions, in proportion to his aggrievement. B is

aggrieved by



(4.2) ab = p̂ - Max (pL (ω; Ab, As), p),



and shades to the point where S’s payoff falls by θab. S is aggrieved by



(4.3) as = Min (pH (ω; Ab, As), p ) - p̂ ,




                                                   21
and shades to the point where B’s payoff falls by θas. The parameter θ is taken to be exogenous

and the same for B and S, and 0 < θ ≤ 1.

        Thus in Case 1, where H ≠   φ , net surplus is


(4.4)   W1 (ω, p, p ; Ab, As) = v – c – θ(ab + as) = v − c − θ {Min (pH (ω; Ab, As), p ).

                                                                      − Max (pL (ω; Ab, As), p)}.



        In contrast, in Case 2, where H =   φ , hold-up occurs, followed by renegotiation, and net

surplus is given by



(4.5)   W2 (ω) = (1 – λ)(v – c).



        Note that since hold-up leads to the withdrawal of all noncontractible helpful actions,

while shading leads to the withdrawal of only some of them, there is an implicit constraint that

total shading costs cannot exceed total hold-up costs, i.e.,



(4.6)   W1 (ω, p, p ; Ab, As) ≥ W2 (ω).



Fortunately, this constraint is automatically satisfied, given 0 < θ ≤ 1, since



(4.7)          Min (pH (ω; Ab, As), p ) − Max (pL (ω; Ab, As), p)

                                    ≤ pH (ω; Ab, As) − pL (ω; Ab, As)

                                    = λ(v – c),


                                                  22
where we are using (2.10). In other words, however large the price range [p, p ] is, net surplus is

higher if hold-up is avoided than if it occurs.13



           An optimal contract maximizes expected net surplus. Thus an optimal contract solves:



(4.8)              Max         ∫W   1   (ω, p, p ; Ab, As) dF (ω) + ∫ W2 (ω) dF (ω)                     ,
           (Ab, As p, p )
                                 H (ω, p, p ; Ab, As) ≠     φ      H (ω, p, p ; Ab, As) =     φ


where F is the distribution function of ω. (We assume that F has bounded support.)14                           The

trade-off is the following. As p falls or p rises, the set H becomes larger and so hold-up is less

likely. This is good given that hold-up reduces surplus, i.e., W1 ≥ W2. However, shading

represented by θ {Min (pH, p ) − Max (pL, p)} rises, which means that surplus in the absence of

hold-up falls, i.e., W1 is lower. This is bad.

           It is worth noting that this model provides a rationale for a long-term contract different

from the traditional one based on noncontractible investments. No long-term contract

corresponds to the case where p = - ∞, p = ∞ (everything is left to date 1). The advantage of this

is that hold-up is avoided (there is no contract to force renegotiation of). The disadvantage is

that shading costs are high on average.




13
  In fact (A2) implies the further constraint that each party’s shading costs cannot exceed ½ λ(v – c). This is
automatically satisfied given (4.1).
14
     It is easy to show that an optimal contract exists since the objective function is upper semicontinuous in [p, p ].


                                                             23
        It is useful to analyze the optimal contract in some simple cases. We have already seen in

Section 2 that a simple contract can achieve the first-best if there is no uncertainty. It turns out

that a non-simple contract can achieve the first-best if there are just two states: ω = ω1 or ω2. (In

what follows we suppress assets.) To see why, note that there are two possibilities. Either [pL

(ω1), pH (ω1)] ∩ [pL (ω2), pH (ω2)] is non-empty or it is empty. In the first case, choose any price

p̂ in the intersection and set p = p̂ = p . In the second case, suppose without loss of generality

that



                pL (ω1) < pH (ω1) < pL (ω2) < pH (ω2).



Then set p = pH (ω1), p = pL (ω2). In state ω1, p = pH (ω1) and in state ω2, p = pL (ω2). Hold-up

is avoided and there is no aggrievement since the set H is a singleton in both states.

        Once there are three states the first-best typically cannot be achieved even with a non-

simple contract. An example is presented in the Appendix.

        We close this section with some interpretations and observations. One obvious question

that can be asked about the model of this section is, why can’t the parties do better than specify a

price range? In fact, given that they will both learn the state of the world at date 1-, even though

it is not verifiable, why can’t they write an informal state contingent contract? Or why can’t they

agree to play a message game that will reveal the state of the world? Of course, if they could do

either of these things, they would arrange that the trading price p(ω) ε [pL (ω; Ab, As), pH (ω; Ab,

As)] for all ω, and the first-best is achieved.

        Informal understandings about contingencies are not uncommon. However, they are

likely to work better when the contingency is relatively objective (i.e., verifiable). It may be



                                                  24
reasonable to agree in advance that price should rise if industry costs increase, but it seems

problematic, and also less common, to let price vary with the seller’s own observable but

unverifiable cost (or the buyer’s observable but unverifiable value). The latter arrangement is

likely to lead to argument ex post. The reason may be that in practice there is always at least a

small amount of asymmetric information. The seller’s cost may appear to be high but there is

always the chance that it is low. Suppose that the buyer and seller are subject to self-serving

biases of the kind emphasized in the behavioral economics and psychology literatures, and they

exaggerate the probabilities of events favorable to them. Under these conditions specifying that

price should vary with cost will lead to disagreement about what the cost is. There will be

aggrievement and shading, just as there is with a price range. Similarly, a mechanism to reveal

the state may lead to annoyance about how the mechanism is played; again there will be

aggrievement and shading. For further discussion see Hart and Moore (2008).

        The above discussion also helps us to answer a second question. Since price ranges don’t

seem that common in practice, how should we interpret them? As we have just seen, one

interpretation of a price range is that it represents an attempt by the parties to write a state-

contingent contract. However, there are a least two other possible interpretations. First, the date

0 contract could be an “agreement to agree”; that is, a non-legally binding framework for future

negotiations. (In contrast, trades of assets at date 0 would be legally binding.) As noted in Hart

and Moore (2008), price ranges are sometimes observed in the case of agreements to agree.

Moreover, agreements to agree may not be that uncommon in the context we are studying. For

example, Goldberg (2007) argues that the famous contract between Fisher Body and General

Motors, which we mentioned in the Introduction, was not legally binding, i.e., it was actually an

agreement to agree.




                                                   25
       Another interpretation of a price range is the following. Suppose date 1 trade is not

instantaneous: rather the parties trade over a period of time, e.g., between dates 1 and 2. (For

simplicity, suppose uncertainty is still resolved at date 1-.) Then the parties might agree at date 0

on the length of their contract. For example, they might agree on a trading price that will operate

for a fraction τ of the period between dates 1 and 2. The parties recognize that when they get to

date 1-, they will renegotiate the price for the remaining fraction (1 - τ) of the period. A small

value of τ then corresponds to a flexible contract -- there is a wide range of possible (average)

prices over the period -- while a large value of τ corresponds to a rigid contract.

       This last interpretation can throw light on the work of Goldberg and Erickson (1987).

Goldberg and Erickson find that parties in the petroleum coke industry tend to write shorter-

term, i.e., more flexible, contracts in a more volatile environment. The parallel result in our

model is that an increase in uncertainty leads to a larger price range [p, p ]. Although further

assumptions would be required to prove a general result along these lines, the result is at least

true at the extremes. With no uncertainty the optimal contract is a single price p ε [pL (ω; Ab,

As), pH (ω; Ab, As)]; while with sufficiently large uncertainty the optimal contract will be a non-

degenerate price interval since the chance that a single price will lie in [pL (ω; Ab, As), pH (ω; Ab,

As)] becomes vanishingly small. Thus in a broad sense our model seems consistent with

Goldberg and Erickson (1987).



5. Conclusions

       In this paper we have studied the trade-off between contractual flexibility and rigidity in a

buyer-seller relationship. A flexible contract is good because it allows the parties to adjust the

terms of trade to uncertain events, but bad because it leads to argument, aggrievement, and




                                                  26
shading. A rigid contract avoids argument in normal times, but has the undesirable feature that if

value or cost falls outside the normal range one party will attempt to force renegotiation,

damaging the relationship and causing deadweight losses. We have shown that a judicious

allocation of asset ownership can improve this trade-off. For example, if the buyer’s value varies

a lot relative to the seller’s cost, allocating assets to the buyer will cause the value of the buyer’s

trade inside the relationship and his value outside the relationship to move together in such a way

that the seller’s ability to engage in hold-up is reduced. This increases efficiency.

      It is useful to review how our analysis differs from that found in the transactions cost and

property rights literatures. The transaction cost literature has emphasized that parties will

vertically integrate when the quasi-rents from their relationship are large. The property rights

literature has emphasized that asset ownership is determined by the marginal product of quasi-

rents with respect to noncontractible investments. In this paper we have suggested that the driver

of integration and asset ownership decisions might be a third factor: payoff uncertainty.

Although several of our results are similar to those obtained in the property rights literature, the

fact that we emphasize payoff uncertainty should, we hope, allow the theories to be distinguished

empirically.

    There are several assumptions of our analysis that could usefully be relaxed. First, we have

assumed that, even though hold-up causes deadweight losses, the parties prefer to continue

trading with each other after hold-up rather than to go their separate ways (assumption (A4)).

Relaxing this assumption opens up interesting new possibilities. Two cases need to be

distinguished. In the first, although the trading relationship is terminated after hold-up, the

parties can renegotiate asset ownership (this is similar to the assumption made in Baker et al. (

2002 ) ). Under these conditions, the surplus obtained after hold-up is independent of the date 0




                                                   27
assignment of assets, which is the critical feature of ( A4). Thus our results are unlikely to

change much in this case. The second case is where there are frictions in the asset renegotiation

process (perhaps because it is difficult even to trade assets after a relationship is poisoned), in

which case the date 0 ownership structure will affect the final outcome. Under these conditions

the initial assignment of assets matters not only in determining when hold-up occurs, but also in

affecting ex post surplus when it does. This opens the door to a richer theory of ownership.

      It would also be worth relaxing our assumption that hold-up sours the parties’ relationship

by the same amount regardless of the reasons for it. Consider two cases of seller hold-up. In one

the seller holds the buyer up because the buyer’s value has increased. In the other the seller holds

up the buyer because the seller’s cost has increased. It is arguable that the buyer will be less

angry in the second case since the seller’s behavior seems less opportunistic. We have taken the

contrary view that the buyer will view the cases as the same on the grounds that if the seller

wanted the price to rise under some conditions she should have built this into the initial contract.

However, it seems useful to develop a model where the two cases are treated differently.

      In most models of incomplete contracts, if the parties can commit not to renegotiate their

contract, the first-best is achieved. It is worth noting that this is not true here. In the absence of

renegotiation hold-up will never occur since it is impossible to change the terms of trade.

However, the parties will have an incentive to quit, by refusing to cooperate, whenever their

outside option exceeds their payoff inside the relationship. (This is similar to the case analyzed in

Hart and Moore ( 2008 ).) There will still be inefficiency—in fact in some cases it will be

greater. Asset ownership will matter although the effects will be somewhat different. In fact the




                                                   28
model is likely to resemble the second case discussed above in which ( A4) doesn’t hold, since,

as in that case, asset ownership will affect ex post surplus in the event that the parties quit.15

      An obvious question to ask is : to what kind of firm does the model apply? One point of

view is that the feelings of hostility and aggrievement that we have emphasized are plausible in

the case of small owner-managed firms, but less so in the case of large corporations. We are not

sure that this is entirely true. Large corporations are run by individuals who have big egos and

presumably therefore can have strong emotions. In fact the Home Depot case, described in

footnote 7, where contract renegotiation caused coldness, is one involving a large company. Still

it is undoubtedly the case that the effects we describe are likely to be different in a company

where many decisions are delegated. In fact one interesting trade-off is that it might be good for

a subordinate to make contract (re)negotiation decisions given that he does not care about hold-

up ( e.g., because he is on low-powered incentives ), and hence this will reduce ex post

deadweight losses, but it might be bad because he will negotiate an unfavorable deal in the first

place.

     As we have emphasized, our theory ignores ex ante considerations. In future work it would

be interesting to reintroduce these. For example, suppose that the seller can take an action-an ex

ante relationship-specific investment, say-that reduces her cost. To the extent that this moves

cost outside the “normal” range, this will give the buyer an incentive to hold the seller up.

Anticipating this, the seller will have less incentive to engage in such an investment. A model

that includes ex ante as well as ex post inefficiencies is likely to provide a richer understanding



15
  An interesting possibility is that, rather than committing not to renegotiate, the parties might try to constrain the
renegotiation process in their date 0 contract. For example, they could put in place an information revelation game
to be played if the relationship breaks down. Note, however, that one point of view is that incorporating a
renegotiation process in the initial contract enlarges the set of feasible outcomes and hence increases parties’
feelings of entitlement in the event that the relationship does not break down, thus raising aggrievement and shading
costs.


                                                          29
of the costs and benefits of asset ownership and more generally of vertical integration.

Developing a model along these lines is an interesting and challenging goal for future research.

                                               Appendix

              We first present an example where the first-best cannot be achieved even with

flexible contracts. We then prove Propositions 1-3.



Example 1

Suppose that there are three states, ω1, ω2, ω3, with probabilities π1, π2, π3, respectively. Only v

varies across the states: v (ω1) = 20, v (ω2) = 60, v (ω3) = 80. Assume c = 10, rb = rs = 0, λ = ½.

Then



                         pL (ω) = ¼ v + ¾ c,

                         pH (ω) = ¾ v + ¼ c.



The [pL (ω), pH (ω)] intervals are illustrated in Figure 3.




12.5           17.5             22.5            27.5                  47.5            62.5

 |____________|___________|____________|_________________|____________|

pL (ω1)        pH (ω1)         pL (ω2)         pL (ω3)                pH (ω2)        pH (ω3)



                                               Figure 3




                                                  30
       We see that the [pL (ω2), pH (ω2)], [pL (ω3), pH (ω3)] intervals overlap, but neither

overlaps with [pL (ω1), pH (ω1)]. There are three candidates for an optimal contract: one can

avoid hold-up in all states with some aggrievement; one can avoid hold-up in ω1 and ω2 without

aggrievement; or one can avoid hold-up in ω2 and ω3 without aggrievement.



Contract 1: Avoiding hold-up in all states

To avoid hold-up in all states, we need p ≤ pH (ω1), p ≥ pL (ω3). To minimize shading costs, we

want the highest p and lowest p . Hence set p = 17.5, p = 27.5. In ω1, p = 17.5 and there is no

aggrievement. In ω2 there is aggrievement of 5 since B would like p = 22.5 and S would like p =

27.5. In ω3, p = 27.5 and there is no aggrievement. Net surplus is given by



               W = 10 π1 + (50 – 5θ) π2 + 70 π3.



Contract 2: Avoiding hold-up in ω1, ω2

In this case it is best to set p = pH (ω1) = 17.5, p = pL (ω2) = 22.5. This avoids aggrievement in

states ω1, ω2 (see the above discussion of the two-state example). However, hold-up occurs in

ω3. Net surplus is given by



               W = 10 π1 + 50 π2 + 35 π3.



Contract 3: Avoiding hold-up in ω2, ω3




                                                 31
In this case it is best to set p = p = p̂ , where 27.5 ≤ p̂ ≤ 47.5. This avoids aggrievement in ω2,

ω3. However, hold-up occurs in ω1. Net surplus is given by



               W = 5 π1 + 50 π2 + 70 π3.



       Which of the above contracts is best depends on the parameters π1, π2, π3, and θ.

Contract 1 is optimal if θ or π2 is small. Contract 2 is optimal if π3 is small. Contract 3 is

optimal if π1 is small. None of these contracts achieves the first-best.



Proof of Proposition 1. We prove (1). Let (Ab, As, [p, p ]) be an optimal contract. The proof

proceeds in two steps. We first replace [p, p ] by another price interval, and show that shading

costs fall (weakly). We then allocate all the assets to B and make another change in the price

interval, and show that shading costs fall again and that the hold-up region becomes (weakly)

smaller. Thus the new contract in which B owns everything must also be optimal.



       Index the state by v. Let v be the smallest value of v, and v the largest of v, in the support

of F such that no hold-up occurs under contract (Ab, As, [p, p ]). Then



(A.1) [pL (v), pH (v)] ∩ [p, p ] ≠   φ


for v = v and v = v . Since pL (v), pH (v) are increasing in v, (A.1) must also hold for v ≤ v ≤ v ,

i.e., hold-up does not occur for intermediate v’s. Note that (A.1) implies that pH (v) ≥ p, pL ( v )

≤p.



                                                  32
        Now define a new price interval [p′, p ′], where



                p′ = pH (v) and p ′ = Max (pL ( v ), pH (v)).



Clearly p′ ≥ p. Also either p ′ ≤ p or p ′ = p′. In the first case the new price interval is a subset of

the previous price interval. In the second case it is a singleton. In both cases



                        [pL (v), pH (v)] ∩ [p′, p ′] ≠   φ


for v ≤ v ≤ v . Hence the new price interval avoids hold-up for v ≤ v ≤ v just like the old one.

In addition aggrievement and shading costs are lower under the new price interval given that

either the new price interval is a subset of the previous price interval or it is a singleton (in which

case shading costs are zero).

        Now assign all the assets to B, i.e., set Ab = A, As =    φ . Call this the new ownership

structure. Define a new price interval [p′′, p ′′], given by



(A.2)           p′′ = pHN (v), p ′′ = Max (pLN ( v ), pHN (v)),



where pLN, pHN represent the values of pL, pH under the new ownership structure. The price

interval [p′′, p ′′] avoids hold-up under the new ownership structure when v ≤ v ≤ v .

        We show next that shading costs are lower for each v ≤ v ≤ v under the new ownership

structure and price interval [p′′, p ′′] than under the old ownership structure and [p′, p ′] (which in




                                                    33
turn are lower than those under the old ownership structure and [p, p ]). That is, we demonstrate

that



(A.3)            Min (pHN (v), p ′′) – Max (pLN (v), p′′)

                                     ≤ Min (pH (v), p ′) – Max (pL (v), p′).



There are several cases to consider. Note first that if p′, p ′ = pH (v) ≥ pL ( v ), i.e., the right-hand

side (RHS) of (A.3) is zero, then

                 pHN (v) − pLN ( v ) = − (pHN ( v ) − pHN (v))

                                            + pHN ( v ) – pLN ( v )

                                     ≥ − (pH ( v ) – pH (v))

                                            + pH ( v ) – pL ( v )

                                     = pH (v) – pL ( v )

                                     ≥ 0,



                                                                                   ∂p H
where we are using the fact that pHN ( v ) – pHN (v) ≤ pH ( v ) – pH (v) since          falls the more
                                                                                    ∂v

assets B owns (by (3.6)), and pHN ( v ) – pLN ( v ) = pH ( v ) – pL ( v ), i.e., pH – pL

is independent of the ownership structure (see (2.10)). Hence pHN (v) ≥ pLN ( v ). It follows from

(A.2) that p′′ = p ′′ = pHN (v) and so the left-hand side (LHS) of (A.3) is zero. Therefore (A.3)

holds.

         Consider next the case where p′ = pH (v) < p ′ = pL ( v ). If p′′ = p ′′ = pHN (v) ≥ pLN ( v ),

(A.3) again holds. So suppose p′′ = pHN (v) < pLN ( v ) = p ′′. We must show that



                                                        34
(A.4)           Min (pHN (v), pLN ( v )) – Max (pLN (v), pHN (v))

                        ≤ Min (pH (v), pL ( v )) – Max (pL (v), pH (v)).



We can rewrite (A.4) as



(A.5)    Min {pHN (v)–pHN (v),pLN ( v )–pHN (v),          ≤ Min {pH (v)–pH (v),pL ( v )–pH (v),

                pHN (v)–pLN (v),pLN ( v )–pLN (v)}                 pH (v)–pL (v),pL ( v )–pL (v)}.



To establish (A.5) one shows that each component in the min formula on the LHS of (A.5) is no

greater than the corresponding component on the RHS of (A.5). This follows from the fact that

∂p H ∂p L
    ,     are nonincreasing in the assets that B owns, and that pH – pL is independent of
 ∂v   ∂v

ownership structure for a given v. Hence (A.4) holds and so does (A.3).

        In summary, the new ownership structure (in which B owns all the assets) and price range

[p′′, p ′′] yields (weakly) lower shading costs than the original ownership structure and price

range [p, p ]. Also the hold-up region is no larger (hold-up does not occur for v ≤ v ≤ v ). This

shows that allocating all the assets to B is optimal.                                                Q.E.D.



Proof of Proposition 2. Suppose a is idiosyncratic to B. We show that B should own a. The

proof is by contradiction. If the proposition is false, then, however small k is, we can construct a

sequence of optimal contracts (Abr, Asr, pr, p r) such that a ε Asr for all r, i.e., S owns asset a, and

πr → 1 as r → ∞. Without loss of generality (wlog) suppose that Abr → Ab(k), Asr → As(k), pr




                                                     35
→ p (k), p r → p (k). Then Ab(k), As (k), p (k), p (k) must be optimal for the case where event 1

occurs with probability 1. For small k the first-best can be achieved (exactly) in event 1 since

there is almost no uncertainty. A necessary condition for this is that there is a single trading

price p(k) in the limit, i.e., p (k) = p (k) = p (k) (so that shading costs are zero), and



(A.6)           pL (ω, Ab(k), As(k)) ≤ p (k) = p(k) = p (k) ≤ pH (ω, Ab(k), As(k))



for all – k ≤ φ ≤ k, where ω = (v0, c0, φ) and we now suppress ε = 0, η = 0. Here pL, pH are as in

(2.15) – (2.16) and are indexed by the limiting ownership structure.

        Consider a new sequence of contracts (Abr′, Asr′, pr′, p r′), where the only difference

between Abr′, Asr′ and Abr, Asr is that asset a is transferred to B, and




(A.7)           pr′ − pr = p r′ − p r

                        = ½ [αs (Asr \ {a}) – αs (Asr)

                                 + αb (Abr) – αb (Abr U {a})

                                 + βb (Abr) v0 – βb (Abr U {a}) v0]

                        = Δr (k).



In other words we adjust pr, p r by an amount equal to the change ΔpL, ΔpH in pL, pH that occurs

as a result of the shift in ownership structure, where ΔpL, ΔpH are evaluated at v = v0. Note that,

given the assumption that a is idiosyncratic to B, ΔpL, ΔpH depend on v, but not on c (or φ).




                                                   36
        What happens to expected net surplus as a result of this change? Expected net surplus is

a weighted average of surplus in the three events 1, 2, 3. Given that pr, p r, pLr, (ω) pHr (ω) all shift

by Δr when v = v0, nothing changes in events 1 and 3 for all r. That is, for each state ω, hold-up

occurs if and only if it did before, and the level of shading costs, if hold-up doesn’t occur,

remains constant. Thus net surplus is unchanged in events 1 and 3.

        Since the new contract cannot deliver higher expected net surplus than the original

contract, given that the original contract is optimal, it follows that net surplus must be (weakly)

lower in event 2. Let r → ∞. Wlog (Abr′, Asr′, pr′, p r′) → (Ab′ (k), As′ (k), p′ (k), p ′ (k)) and

Δr (k) → Δ (k). Given (A.6) – (A.7), we must have



(A.8) pL (ω, Ab′ (k), As′(k)) ≤ p′ (k) = p′ (k) = p ′ (k) ≤ pH (ω, Ab′ (k), As′ (k))



for all – k ≤ φ ≤ k, where ω = (v0, c0, φ). By the above arguments the contract (p′ (k), p ′ (k),

Ab′ (k), As′ (k)) delivers surplus no higher in event 2 than the contract (p (k), p (k), Ab (k), As

(k)).

        We show that this conclusion is false. Since the primed and unprimed contracts both

have a single trading price (p′ (k), p (k), respectively), shading costs are zero in both contracts.

We demonstrate that there is less hold-up in the primed contract. Since we are in event 2 index

the state by (v, φ). Then, from (A.7),



(A.9) p′ (k) – p (k) = pL ((v0, φ), Ab′ (k), As′ (k)) – pL ((v0, φ), Ab (k), As (k))

                     = pH ((v0, φ), Ab′ (k), As′ (k)) – pH ((v0, φ), Ab (k), As (k))

                     = Δ (k)



                                                    37
for all φ. Now hold-up occurs in the primed contract in state (v, φ) if and only if either p′ (k) <

pL ((v, φ), Ab′ (k), As′ (k)) or p′ (k) > pH ((v, φ), Ab′ (k), As′ (k)). Consider the first. Given (A.8)

and the fact that pL is increasing in v, p′ (k) < pL ((v, φ), Ab′ (k), As′ (k)) only if v > v0. But, if v

> v0,



(A.10)       pL ((v, φ), Ab′ (k), As′ (k)) – pL ((v0, φ), Ab′ (k), As′ (k))

                                 = ½ [(1 – λ) – βb (Ab U {a})] (v – v0)

                                 < ½ [(1 – λ) – βb (Ab)] (v – v0)

                                 = pL ((v, φ), Ab (k), As (k))

                                   – pL ((v0, φ), Ab (k), As (k)),



since a is idiosyncratic to B. From (A.9) – (A.10), we may conclude that p′ (k) < pL ((v, φ),

Ab′ (k), As′ (k)) ⇒ p (k) < pL ((v, φ), Ab (k), As (k)), i.e., hold-up occurs in the unprimed

contract if it occurs in the primed contract. A similar argument shows that p′ (k) > pH ((v, φ), Ab′

(k), As′ (k)) ⇒ p (k) > pH ((v, φ), Ab (k), As (k)). Putting the two arguments together, we may

conclude that hold-up costs are weakly lower in the primed contract than the unprimed one. In

fact, they are strictly lower: this follows from the assumption about the support of v in

Proposition 2, which ensures that pL ((v, φ), Ab (k), As (k)) > pH ((v, φ), Ab (k), As (k)) for large v

and φ close to zero (i.e., hold-up does occur sometimes), but not for v close to v0 (i.e., hold-up

does not always occur). Contradiction.                                                     Q.E.D.




                                                     38
Proof of Proposition 3. We sketch the proof since the argument is very similar to that of

Proposition 2. Suppose joint ownership is not optimal. For small k choose a sequence of

optimal contracts as π → 1.

The limiting contract is optimal for event 1. Hence (A.6) is satisfied. Consider a new sequence

of contracts where all assets are jointly owned and pr, p r are adjusted to reflect the new

ownership structure, i.e.,



               pr′ − pr = p r′ − p r

                       = ½ [αs ( φ ) − αs (Asr) – αb ( φ ) + αb (Abr)

                             – βs ( φ ) c0 + βs (Asr) c0 – βb ( φ ) v0 + βb (Abr) v0].



Then surplus does not change in event 1. Since the initial contract is optimal surplus must

weakly fall in events 2 or 3. Wlog suppose it falls in event 2. Take limits as r → ∞. The

limiting joint ownership contract has the property that pL, pH vary less with ε than under the

original contract. But this makes hold-up less likely. Hence the joint ownership contract creates

higher net surplus. Contradiction.                                                            Q.E.D




                                                   39
                                        REFERENCES



Anderson, Eric T. and Duncan I. Simester (2007) “Price Variation and Customer Antagonism,”

Unpublished, MIT.



Baker, George, Robert Gibbons, and Kevin Murphy (2002), “Relational Contracts and the

Theory of the Firm,” Quarterly Journal of Economics 117: 39-84.



Goldberg, Victor, (2007), “Lawyers Asleep at the Wheel,” Unpublished, Columbia Law School.



________, _______, and John R. Erickson (1987), “Quantity and Price Adjustment in Long-

Term Contracts: A Case Study of Petroleum Coke,” The Journal of Law and Economics 30: 369-

98.



Grossman, Sanford, and Oliver Hart (1986). “The Costs and Benefits of Ownership: A Theory

of Vertical and Lateral Integration,” Journal of Political Economy 94: 691-719.



Halonen, Maija (2002), “Reputation and the Allocation of Ownership,” The Economic Journal

112: 539-558.



Hart, Oliver, and John Moore (1990), “Property Rights and the Nature of the Firm,” Journal of

Political Economy 98: 1119-58.




                                               40
________, _______ (2008), “Contracts as Reference Points,” Quarterly Journal of Economics,

forthcoming.



Harvard Business School Case 9-295-127, Xerox Technology Ventures: March 29, 1998.

Harvard Business School Case 9-298-109, Xerox Technology Ventures: April 10, 1998.

Harvard Business School Case 5-298-152, Xerox Technology Ventures: April 27, 1998.



Januszewski Forbes, Silke, and Mara Lederman (2007), “Does Vertical Integration Affect Firm

Performance? Evidence from the Airline Industry,” Unpublished, UCSD.



Klein, Benjamin (1996), “Why Hold-ups Occur: The Self-Enforcing Range of Contractual

Relationships,” Economic Inquiry 34: 444-63.



______ (2007), “The Economic Lessons of Fisher Body-General Motors,” International Journal

of the Economics of Business 14: 1-36.



______, R. Crawford, and A. Alchian (1978), “Vertical Integration, Appropriable Rents, and the

Competitive Contracting Process,” Journal of Law and Economics 21: 297-326.



______, and Kevin M. Murphy (1997), “Vertical Integration as a Self-Enforcing Contractual

Arrangement,” American Economic Review 87: 415-420.




                                               41
Lafontaine, F. and Slade, M. (2007), “Vertical Integration and Firm Boundaries: The Evidence,”

Journal of Economic Literature, XLV: 629-685.



Rajan, Raghuram G., and Luigi Zingales (1998), “Power in a Theory of the Firm,” Quarterly

Journal of Economics 113: 361-386.



Simon, H. (1951) “A Formal Theory of the Employment Relationship,” Econometrica, XIX:

293-305.



Wernerfelt, Birger (1997), “On the Nature and Scope of the Firm: An Adjustment-Cost Theory,”

Journal of Business LXX: 489-514.



Williamson, Oliver (1971), “The Vertical Integration of Production: Market Failure

Considerations,” American Economic Review 61: 112-23.




                                              42
