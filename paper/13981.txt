                                NBER WORKING PAPER SERIES




     INVERSE PROBABILITY TILTING FOR MOMENT CONDITION MODELS WITH
                              MISSING DATA

                                          Bryan S. Graham
                                  Cristine Campos de Xavier Pinto
                                            Daniel Egel

                                        Working Paper 13981
                                http://www.nber.org/papers/w13981


                       NATIONAL BUREAU OF ECONOMIC RESEARCH
                                      1050 Massachusetts Avenue
                                         Cambridge, MA 02138
We would like to thank David Card, Stephen May       2008Jinyong Hahn, Patrick Kline, Justin McCrary,
                                               Cosslett,
Richard Smith, Tom Rothenberg, members of the Berkeley Econometrics Reading Group and especially
Michael Jansson for helpful discussions. We are particularly grateful to Gary Chamberlain, Guido
Imbens, Geert Ridder, Enrique Sentana and three anonymous referees for detailed comments on earlier
drafts. We also acknowledge feedback and suggestions from participants in seminars at the University
of Pittsburgh, Ohio State University, University of Southern California, University of California -
Riverside, University of California - Davis, University of Maryland, Georgetown University, Duke
University, the University of California - Berkeley, CEMFI (Madrid), Harvard University, Pontifícia
Universidade Católica do Rio do Janeiro and the 2009 Latin American Meetings of the Econometric
Society. This is a heavily revised and extended version of NBER Working Paper w13981 titled “Inverse
probability tilting and missing data problems”. Previous versions of this paper also circulated under
the title “A new method of estimating moment condition models with missing data when selection
is on observables.” Material in Section 4 of the initial NBER paper is not included in this version of
the paper, but may be found in the companion paper "Efficient estimation of data combination problems
by the method of auxiliary-to-study tilting" (NBER Working Paper w16928 ). All the usual disclaimers
apply. The views expressed herein are those of the author(s) and do not necessarily reflect the views
of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2008 by Bryan S. Graham, Cristine Campos de Xavier Pinto, and Daniel Egel. All rights reserved.
Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided
that full credit, including © notice, is given to the source.
Inverse Probability Tilting for Moment Condition Models with Missing Data
Bryan S. Graham, Cristine Campos de Xavier Pinto, and Daniel Egel
NBER Working Paper No. 13981
May 2008, Revised May 2011
JEL No. C14,C21,C23

                                             ABSTRACT

We propose a new inverse probability weighting (IPW) estimator for moment condition models with
missing data. Our estimator is easy to implement and compares favorably with existing IPW estimators,
including augmented inverse probability weighting (AIPW) estimators, in terms of efficiency, robustness,
and higher order bias. We illustrate our method with a study of the relationship between early Black-White
differences in cognitive achievement and subsequent differences in adult earnings. In our dataset the
early childhood achievement measure, the main regressor of interest, is missing for many units.


Bryan S. Graham                                     Daniel Egel
New York University                                 Institute on Global Conflict and Cooperation (IGCC)
19 W 4th Street, 6FL                                University of California - San Diego
New York, NY 10012                                  9500 Gilman Drive, MC 0518
and NBER                                            La Jolla, CA 92093-0518
bsg1@nyu.edu                                        degel@ucsd.edu

Cristine Campos de Xavier Pinto
Escola de Economia de São Paulo, FGV/SP
Rua Itapeva 474, sala 1200
São Paulo– SP, Brasil, 01332-000
cristinepinto@gmail.com
    Missing data are ubiquitous in applied econometric research. When data are miss-
ing at random (MAR), or selection is on observables, a simple consistent procedure is
to (i) reweight those units without any missing data by the inverse of the probability
of selection or the propensity score, and (ii) apply standard estimation methods to
this reweighted subsample (e.g., Wooldridge, 2007). Inverse probability weighting
(IPW) is widely-used to address attrition in panel data (e.g., Abowd, Crépon and
Kramarz, 2001), program evaluation under exogenous treatment assignment (e.g.,
Hirano, Imbens and Ridder, 2003), and to control biases caused by missing and/or
mismeasured regressors (e.g., Robins, Rotnitzky and Zhao, 1994). Chen, Hong and
Tarozzi (2004) and Wooldridge (2007) survey additional applications of IPW.
    In this paper we propose a modified version of inverse probability weighting, which
we call inverse probability tilting (IPT). Our procedure coincides with the IPW es-
timator of, for example, Wooldridge (2007), except that we replace the conditional
maximum likelihood estimate (CMLE) of the propensity score with an alternative
method of moments estimate. We show that if the unconditional moments used to
estimate the propensity score parameter are appropriately chosen our procedure (i)
is locally eﬃcient and (ii) remains consistent even if the propensity score is misspec-
ified. These properties, local eﬃciency and double robustness, which we carefully
define below, are not shared by the standard IPW estimator.2
    A key appeal of IPW is its conceptual and operational simplicity. Inverse probabil-
ity tilting preserves this advantage, while oﬀering improvements in terms of estimator
eﬃciency and robustness. However other modifications of IPW exist. A leading one,
which shares IPT’s local eﬃciency and double robustness properties, is the augmented
inverse probability weighting (AIPW) estimator introduced by Robins, Rotnitzky and
Zhao (1994).3 We characterize the  −1 order asymptotic bias of IPT and a class of
AIPW estimators under conditions where they are first order equivalent. We find
that IPT has smaller bias than AIPW in this setting. To our knowledge these are the
first higher-order comparisons in the missing data literature.
    In an illustrative empirical application we revisit Johnson and Neal’s (1998) analy-
   2
     To be more specific, IPW is locally eﬃcient at a rather peculiar data generating process (DGP).
Unfortunately this DGP is diﬃcult to interpret and a priori implausible. We discuss this point
below.
   3
     While perhaps less familiar to econometricians, although Hirano and Imbens (2001), Imbens
(2004), and Wooldridge (2007) are notable exceptions, AIPW methods are widely-studied (and
used) by statisticians. Tsiatis (2006) provides a book length treatment.



                                                 1
sis of the Black-White wage gap for young men in the United States. They find that
approximately 60 percent of the Black-White gap can be predicted by group diﬀer-
ences in cognitive skills acquired prior to labor market entry at age 18. We study
the predictive value of group diﬀerences in skills acquired prior to adolescence (i.e.,
by age 12). We find that pre-adolescent skill diﬀerences can account for about 40
percent of the overall wage gap and two thirds of pre-market eﬀect found by Johnson
and Neal (1998).
    Our analysis is complicated by the fact that a pre-adolescence test score is avail-
able for just 11 percent of respondents.4 In addition to being few in number, these
complete cases are unrepresentative of the sample as a whole. An analysis which
ignores these facts may be both inconsistent and imprecise. The IPT estimate of the
wage gap conditional on the preadolescence test score corrects for the unrepresenta-
tiveness of the complete cases. The IPT point estimate is also precisely determined.
Its standard error is, respectively, one third and one half, the length of the correspond-
ing unweighted complete case and IPW ones. Our application provides a concrete
example of the type of eﬃciency gains IPT can provide. These gains arise despite
the fact that we implement IPW with a heavily overparameterized propensity score
model, which theory suggests should lead to a precisely determined point estimate
(Hirano, Imbens and Ridder, 2003; Wooldridge, 2007).
    The next section formally defines the class of problems to which our IPT pro-
cedure applies. In Section 2 we present our estimator and characterize its large
sample properties. Section 3 compares the higher order bias of IPT with that of
the class of AIPW estimators introduced by Robins, Rotnitzky and Zhao (1994).
Section 4 presents the empirical application. Section 5 ends with some suggestions
for further research. Selected proofs are collected in the Appendix, which also in-
cludes details on computation. Additional proofs, further details on the empirical
application, and a full set of Monte Carlo experiments can be found in the Supple-
mental Web Appendix. Software implementing our procedure is available online at
https://files.nyu.edu/bsg1/public/.
  4
    Given the severity of the missing data problem in our sample one may reasonably question the
plausibility of the missing at random assumption. We emphasize that the goal of our empirical
application is illustrative.




                                               2
1    A semiparametric missing data model
Here we describe a general moment condition model with data missing at random
(MAR). Our set-up is as in Wooldridge (2007) except that our parameter is the
solution to a moment condition, as opposed to a population optimization, problem.
Let  = (10   0 )0 be a random vector, 0 an unknown parameter, and assume that:

Assumption 1.1 (Identification) For some known  × 1 vector of functions
 ( )
                            E [ ( 0 )] = 0

with (i) E [ ( )] 6= 0 for all  6= 0   ∈ G ⊂ R and G compact with 0 ∈
int (G), (ii) | ( )| ≤  () for all  ∈ Z with  () a non-negative function on
Z and E [ ()]  ∞ (iii)  ( ) is continuous on G for each  ∈ Z and con-
                                                         £            ¤
tinuously diﬀerentiable in a neighborhood of 0 , (iv) E k ( 0 )k2  ∞ and (v)
  £                      ¤
E sup∈G k∇  ( )k  ∞

    Assumption 1.1 provides a standard set of conditions under which the full sample
                                                     P
method-of-moments estimate of 0 , the solution to                b)  = 0, will be
                                                       =1  (  
consistent and asymptotically normal (cf., Newey and McFadden 1994, Theorems 2.6
and 3.4). Our interest is in identification and estimation when 1 is not observed
for all units. Let  be a binary indicator variable. When  = 1 we observe 1
and , while when  = 0 we observe only . Our benchmark model is defined by
Assumption 1.1 as well as:

Assumption 1.2 (Random Sampling) {    1 }   =1 is an independently and
identically distributed random sequence. We observe ,  and  = 1 for each
sampled unit.

Assumption 1.3 (Missing at Random) Pr ( = 1|  1 ) = Pr ( = 1| )

Assumption 1.4 (Strong Overlap) Let 0 () = Pr ( = 1| = )  then 0 
 ≤ 0 () ≤ 1 for some 0    1 and all  ∈ X ⊂ Rdim() 

Assumption 1.5 (Propensity Score Model) There is a unique 0∗ ∈ int (D∗ )
                ∗
with D∗ ⊂ Rdim( ) and compact, known vector  () of linearly independent functions
of and known function  (·) such that (i)  (·) is strictly increasing, continuously

                                          3
diﬀerentiable and maps into the unit interval with lim  () = 0 and lim  () = 1,
                                                         →−∞                   →∞
(ii) 0 () =  (()0 0∗ ) for all  ∈ X , and (iii) 0   ≤  (()0  ∗ ) ≤ 1 for all
 ∗ ∈ D∗ and  ∈ X .

    We refer to the model defined by Assumptions 1.1 to 1.5 as the semiparametric
missing data model. Chen, Hong and Tarozzi (2008) study this model without main-
taining Assumption 1.5, that is, with the propensity score left nonparametric. As is
well-known, removing Assumption 1.5 from the prior restriction does not aﬀect the
asymptotic precision with which 0 may be estimated (Hahn, 1998). We nevertheless
maintain it when deriving our local eﬃciency result (Theorem 2.1). Doing so is im-
portant for establishing regularity of our estimator. We also assess the properties of
IPT when Assumption 1.5 fails (Theorem 2.2).
    To get a sense of the range of problems to which our methods may be applied it
is helpful to consider a few specific examples.

Example 1.1 (Mean of a variable missing at random) Let 1 be a binary
indicator for an individual’s HIV status, let  = 1 if an individual is tested and
zero otherwise; 1 is logically observable only when  = 1 We would like to es-
timate the population prevalence of HIV: 0 = E [1 ]  This corresponds to setting
 ( ) = 1 − . Assumption 1.3 says that the testing decision is independent of
HIV status in subpopulations homogenous in . This may be plausible if  includes
measures of risk-taking behavior and other background characteristics so that it closely
approximates an individual’s own information set regarding their status. Assumption
1.4 requires that at least some individuals in every subpopulation defined in terms of
 =  get tested. Assumption 1.5 presumes the availability of a parametric model for
the testing decision. This example is closely related to that of average treatment eﬀect
(ATE) estimation under exogenous treatment assignment (see Section 5 below).

Example 1.2 (Regression function estimation with missing regressors)
Let 1 be a vector of demographic characteristics, 2 log earnings, 1 armed forces
qualification test (AFQT) score, and 3 a vector of always observed surrogates or
proxies for 1 (e.g., scores on subcomponents of the test, on earlier tests, etc.). Let
 = 1 if a unit’s test score is available and zero otherwise. Let  = (10  20  30 )0 
 = (10  20 )0 and  ( ) = (10  10 )0 (2 − 10 1 − 10 2 )  Here  corresponds to the
coeﬃcient vector indexing the linear predictor of log earnings given demographics and

                                                4
AFQT score as in Johnson and Neal (1998). This corresponds to a linear regression
model where the covariate of interest is subject to item non-response. Assumption 1.3
requires that across individuals with identical earnings (2 ), demographics (1 ), and
test proxies (3 ) the probability of observing the AFQT score is independent of its
value.

    Other examples of the semiparametric missing data model defined by Assumptions
1.1 to 1.5 include panel data models with attrition, certain forms of censored durations
and M-estimation under variable probability sampling. Chen, Hong and Tarozzi
(2004) and Wooldridge (2007) survey additional examples. See also Section 5 below.


2         Inverse probability tilting
Our first result shows that standard IPW, where the propensity score is estimated
by CMLE, is typically ineﬃcient under Assumptions 1.1 to 1.5. This motivates our
search for an eﬃcient variant of IPW. The maximal asymptotic precision with which
0 can be estimated under these assumptions was characterized by Robins, Rotnitzky
and Zhao (1994) and is given by the inverse of

                                         I (0 ) = Γ00 Λ−1
                                                        0 Γ0                                  (1)

with                   ∙         ¸                ∙                                 ¸
                      ( 0 )                Σ (; 0 )                        0
              Γ0 = E                    Λ0 = E            +  (; 0 )  (; 0 )            (2)
                         0                     0 ()
where Σ (; ) = V ( ( )|  = ) and  (; ) = E [ ( )|  = ]. We seek an
estimator which attains this bound.
    To describe the textbook IPW estimator we require some notation. Let  =
 ( )   () =  (  ) and  =  (  0 ). Similarly let  ( ∗ ) =  (0 ∗ ) and
 =  (0 0∗ )  Denote a random unit’s contribution to the score of the propensity
score log-likelihood evaluated at  ∗ = 0∗ by

                                                −
                                       ∗ =             1 
                                                (1 − )

with  () =    ()   for  = 1 25 Finally let  ( ; ) = E [ (  )|  ] and
    5
        To economize on notation we often omit an argument of a function when it is being evaluated


                                                  5
 =  ( ; 0 )  The inverse probability weighted estimate of 0 is given by the solution
to
                                  1 X   (  
                                     
                                                  b  )
                                                          = 0                           (3)
                                   =1  ( ( )0 b∗ )
                                                     

with b
       ∗
          the CMLE estimate of 0∗ . Proposition 2.1 summarizes the first order as-
                       b  .
ymptotic properties of 

Proposition 2.1 (Asymptotic Sampling Distribution of b           ) Suppose As-
                                   √                
                                         − 0 ) → N (0 AVar (b
sumptions 1.1 to 1.5 hold, then (i)  (b                            )) with

            ) = I (0 )−1
    AVar (b                                                                       (4)
                           ∙µµ      ¶           ¶ µµ      ¶           ¶0 ¸
                                                    
                  + Γ−1 E        − 1  − Π ∗        − 1  − Π ∗      Γ−10 
                                                    
            £         ¤         0 −1
                                                   £                       −1 ¤
for Π = E   
                
                   0
                     ∗ E [ ∗  ∗ ] and (ii)  0
                                                    AVar (b
                                                            ) − I (0 )      ≥ 0 for any
vector of constants .

Proof. See the supplemental web appendix.
    While the ineﬃciency of IPW, part (ii) of Proposition 2.1, is well known, the
asymptotic variance expression (4) provides new insight into its large sample prop-
erties. Observe that Π ∗ equals the best (i.e., mean squared error minimizing)
                      ¡      ¢
linear predictor of    
                          − 1   given ∗ .6 If ∗ happens to be a good predictor of
¡      ¢
  
    − 1  then IPW will be nearly eﬃcient. Consider the case where the propensity
score takes a logit form so that  () = exp ()  [1 + exp ()]  Some basic calculations
            ¡       ¢
give ∗ =   
                − 1  · ; therefore if it so happens that  can be written as a linear
function of  ·  then the asymptotic variance of IPW will coincide with that of an
eﬃcient estimator. An interpretation of Hirano, Imbens and Ridder (2003) is that if
the dimension of  is allowed to grow with the sample size, then  will eventually be
arbitrarily well-approximated by a linear function of  ·  so that this coincidence
holds generally (i.e., for all data generating processes (DGPs)). Wooldridge (2007)
makes a related point: (4) cannot increase if the dimension of  increases.
                                    ¡      0  ¢      ¡      0  ¢
at the ‘truth’. For example 1 = 1  () 0∗ =   () 0∗ .
   6
     Note that by the conditional mean zero property of the score function and Assumption 1.3
                           ∙µ       ¶     ¸     ∙        ¸     ∙        ¸
                                       0          0             0
                         E       − 1 ∗ = E        ∗ = E        ∗ 
                                                               



                                               6
    In practice the researcher is only able to fit a finite dimensional model for the
propensity score. Proposition 2.1 indicates that, except under very special circum-
stances, the resulting IPW estimate of 0 is ineﬃcient under Assumptions 1.1 to 1.5.
                                                                ¡       ¢
Expression (4) indicates this ineﬃciency is most acute when      
                                                                    − 1  is poorly ap-
proximated by a linear combination of ∗ , the vector of estimating equations for the
propensity score parameter  ∗ . This suggests that changing the estimating equations
                                                                       ¡      ¢
for  ∗ , such that a linear combination of them closely approximates   
                                                                           − 1  , might
improve estimator precision. This conjecture turns out to be correct. To show this
result we begin by positing a working model for the conditional mean of  ( 0 )
given .

Assumption 2.1 (Moment CEF Model) For some unique matrix Π∗0 and vector
of linear independent functions ∗ () with a constant in the first row, we have

                                 E [ ( 0 )| ] = Π∗0 ∗ () 

    The precise content of Assumption 2.1 depends on the form of  ( )  If  ( ) =
1 −  as in Example 1.1, then it is equivalent to assuming that the conditional mean
of 1 is a linear function of ∗ (). Example 1.2 provides a more complicated illus-
tration. In that case
                            Ã                                                       !
                                     1 2 − 1 10 1 − 1 E [1 | ]0 2
        E [ ( 0 )| ] =                                                           
                              E [1 | ] 2 − E [1 | ] 10 1 − E [1 10 | ] 2

so that selecting ∗ () requires formulating models for the first and second conditional
moments of 1 .7
    When  ( ) is nonlinear in  choosing ∗ () such that Assumption 2.1 holds
is more diﬃcult. In this case one can think of ∗ () as a vector of approximating
functions as in the literature on nonparametric sieve estimation (e.g., Chen, 2007;
see also Section 5 below). We emphasize that any approach to missing data which
involves imputation also requires formulating a model for E [  ( 0 )| ].
    Let  () denote the union of all linearly independent elements in ∗ () and
 () (recall that  () are the functions of  entering the propensity score model
   7
    To be explicit assume that E [ 1 | ] = 1 ()0 1 and  (E [ 1 10 | ]) = 2 ()0 2  Let
3 () consist of 1 () and all non-redundant interactions between its elements and those of 1
                                       0       0
and 2  then setting ∗ () = (2 ()  3 () )0 with any redundant entries removed is suﬃcient
for Assumption 2.1 to hold.

                                                 7
in Assumption 1.5). Let 1 +  equal the dimension of  (); this vector will include
                                                                ¡                     ¢0
a constant and  known functions of  Note that  () =  ()0  ∗ ()0 where
∗ () is the relative complement of  () in ∗ (). Letting 0 = (0∗0  00 )0  where 0 =
0 we have under Assumptions 1.1 to 1.5 the following just-identified unconditional
moment problem
                                     ∙                       ¸
                                          
                                  E                 ( 0 ) = 0                                (5)
                                     ( ()0 0 )
                                ∙µ                  ¶        ¸
                                        
                              E                  − 1  () = 0                                  (6)
                                   ( ()0 0 )
                                      ³             ´0
                               b         0     b0
                                       b     to set the sample analog of (5)
Our proposed estimator chooses   = 
and (6) equal to zero:

                            1 X
                               
                                        
                                                              b  ) = 0
                                                       (                                    (7)
                             =1 ( ( )0 b  )
                                Ã                         !
                          1 X
                                        
                                                      − 1  ( ) = 0                           (8)
                           =1 ( ( )0 b  )

    Several features of this estimator merit comment. First, as with the standard IPW
estimator, b  is the solution to an inverse probability weighted method of moments
problem (compare (7) with (3)). However, the fitted propensity score values used to
construct the weights are not conditional maximum likelihood estimates. Instead b 
is the solution to a method of moments problem.8 Importantly, under Assumption
                                                                          ¡      ¢
2.1, a linear combination of the estimating equations for b  equals    
                                                                              − 1  , which
                                                                9
Proposition 2.1 suggests might be important for eﬃciency.
    Second, if  () is not contained within ∗ (), then we add moments to the
propensity score estimating equation, replacing ∗ () with  ()  These additional
moments do not improve the precision of     b  , but they do ensure that (6) contains a
suﬃcient number of moment restrictions to pin down the propensity score parameter.
Third, in the opposite case where ∗ () is not contained within  (), we enrich the
propensity score model, replacing  ()0 0∗ with  ()0 0 in  (·). The eﬀect of this
    Consequently b  is an ineﬃcient estimate of 0 = (0∗0  00 ) .
   8                                                            0
   9
    An earlier version of this paper derived (6) as the solution to an optimal instrumental variables
problem based on the conditional moment formulation of the semiparametric missing data model
studied by Graham (2011). For brevity this derivation is omitted here.


                                                 8
replacement is to eliminate any overidentifying restrictions. To see this note that

                                ()0 0 =  ()0 0∗ + ∗ ()0 0 

where, by Assumption 1.5, 0 = 0. Nevertheless including ∗ () in the propen-
sity score model ensures that the combined dimension of (5) and (6) coincides with
dim (0 )+dim (0 ) =  +1+ so that 0 = (00  00 )0 is just-identified. This approach
to overidentification appears to be novel.10 Theorem 3.1 below shows that it results
in attractive higher order properties.
    An example helps to fix ideas. Let  ( ) = 1 −  as in Example 1.1 with
 scalar. We assume that Assumption 1.5 holds with  () = (1 )0 so that the
propensity score is, for example, logit with an index linear in . In choosing ∗ ()
such that Assumption 2.1 holds we are concerned about possible nonlinearities in
                                                      0
E [1 |  = ], therefore we set ∗ () = (1   2 )  This gives  () = ∗ () and
∗ () =  2  In this case we fit a propensity score model with an index that is
quadratic in  despite the fact that Assumption 1.5 says that a linear one will suﬃce.
We fit this model not by CMLE but by choosing b  to solve (8). Once we have
fitted our propensity score we compute   b  by choosing it to solve (7).
    Now consider the case where the analyst believes that the propensity score might
                                                                               0
vary sharply with  so that Assumption 1.5 requires  () = (1   2 ) , but that
E [1 |  = ] is linear in  so that Assumption 2.1 requires only ∗ () = (1 )0 . In
this case  () =  () and ∗ () is empty. Here the added moment serves only to
tie down the propensity score parameter; it does not increase the precision of     b  .
There is no need to overfit the propensity score in this case.
    The main diﬀerence between IPW and IPT is that the latter approach (i) overfits
the propensity score if Assumption 2.1 requires us to do so and (ii) we do not use
CMLE to fit the propensity score. In Appendix A we show that the first step of our
procedure requires solving a globally concave programming problem with unrestricted
domain. In theory this is no harder than computing the CMLE associated with a
binary choice logit model and in practice we have found this step to be straightforward.
The second step of our procedure, as with the standard IPW one, can be completed
by any M-estimation program that is able to accept user-specified weights.
  10
    It is similar in spirit to the introduction of ‘tilting’ parameters in the context of generalized
empirical likelihood (GEL) estimation of overidentified moment condition models (e.g., Imbens,
1997). This observation is the source of inverse probability tilting’s name.


                                                 9
    The next two theorems characterize the first order asymptotic properties of         b  .
The first result shows that when Assumptions 1.1 to 1.5, and Assumption 2.1 hold,
the asymptotic variance of b  equals I (0 )−1 . More precisely b   is locally eﬃcient
for 0 in the semiparametric model defined by Assumptions 1.1 to 1.5 at DGPs which
also satisfy Assumption 2.1.
    Equation (1) is the information bound for 0 without imposing the additional aux-
iliary Assumption 2.1. This assumption imposes restrictions on the joint distribution
of the data not implied by the baseline model. If these restrictions are added to the
prior used to calculate the eﬃciency bound, then it is generally possible to estimate
0 more precisely. We emphasize that our estimator is not eﬃcient with respect to
this augmented model. Rather it attains the bound defined by (1) if Assumption 2.1
happens to be true in the population being sampled from, but is not part of the prior
restriction used to calculate the bound. Newey (1990, p. 114), Robins, Rotnitzky and
Zhao (1994, p. 852 - 3) and Tsiatis (2006) discuss the concept of local eﬃciency in
detail. In what follows we will, for brevity, say  b  is locally eﬃcient at Assumption
2.1.

Theorem 2.1 (Local Semiparametric Efficiency of              b  ) Consider the semi-
parametric missing data model defined by Assumptions 1.1 to 1.5, then for     b  the
solution to (7), (i) b
                       is regular and (ii) locally eﬃcient at Assumption 2.1 with
√                     ¡           ¢
   (b  − 0 ) → N 0 I (0 )−1 .

Proof. See Appendix A.
                               b  has good eﬃciency properties. By choosing the
    Theorem 2.1 indicates that 
estimating equation for the propensity score with the properties of E [  ( 0 )| ] in
mind, eﬃciency improvements over the standard IPW estimator are possible.11
    Our next Theorem shows that IPW has a double robustness property (cf., Bang
and Robins, 2005; Tsiatis, 2006; Wooldridge, 2007). Restrictions (5) and (6) were
derived under the baseline missing data model defined by Assumptions 1.1 to 1.5.
  11
     We comment that the standard IPW estimator is also locally eﬃcient. However this occurs
not at DGPs¡     which¢ satisfy Assumption 2.1, but rather at ones where E [  ( 0 )| ] is linear in
 () ·   ()0 0∗  We find this condition a bit awkward from a modelling standpoint, however
it does help to explain why IPW is often nearly eﬃcient in Monte Carlo experiments where the
outcome equation is a direct function of the propensity score (e.g., Busso, DiNardo, and McCrary,
2009). If the data are missing completely at random (MCAR) such that 0 () = Pr ( = 1) = 0
for all  ∈ X , then IPW and IPT will be locally eﬃcient at the same DGPs as long as  () = ∗ () 



                                                  10
Consequently regardless of whether Assumption 2.1 also holds b     will be consistent
                                   12
for 0 and asymptotically normal. This is the first part of double robustness.
    Now consider a DGP where Assumptions 1.1 to 1.4 and 2.1, but not 1.5, hold.
That is, a situation where the propensity score is misspecified but the implicit moment
                                   
CEF model is not. In this case b → ∗ where ∗ is the pseudo-true value which solves
(6). This pseudo-true value has an interesting property. Rearranging (6) we get
                                  ∙                  ¸
                                       
                                E                () = E [ ()]                                     (9)
                                  ( ()0 ∗ )

The inverse probability weighted mean of  () in the  = 1 subpopulation coincides
with its full population mean, E [ ()]. This property holds regardless of whether
the true propensity score is of the form ( ()0 ) for some  = 0 
   In the sample, rearranging (8), we get

              X
              
                                       1 X
                                          
                                                                      1       
                     b   ( ) =
                                             ( )     b  =
                                                                                                   (10)
               =1
                                        =1                           ( ( )0 b  )

so that the inverse probability weighted mean of  () in the  = 1 complete case
subsample coincides with its full sample mean. By choosing the propensity score
parameter to solve (8) we ensure that the estimated inverse probability weights satisfy
                                                                     0
an exact balancing property. For example, if  ( ) = (1   2 ) with  scalar, then,
after reweighting the complete case sample with     b   the mean and variance of 
will coincide with their full sample counterparts. Since the first element of  ( ) is a
constant, the b  weights will also sum to 1.13
    Let  ( 1 ) be the joint distribution of  1 , then
                                          X
                      b  ( 1 ) =           b  1 ( ≤ ) 1 (1 ≤ 1 ) 
                                                                                                    (11)
                                            =1


is the estimate for the joint distribution of  and 1 implied by the IPT estimator
(cf., Back and Brown, 1993; Imbens, 1997). By (10) this distribution function satisfies
  12
     Its asymptotic variance, however, will lie above I (0 )−1 , in the matrix sense, unless Assumption
2.1 also holds.
                                                                           P
  13
     Equation (10) highlights that the existence of b  requires that     =1  ( )  lie within the
convex hull of the complete case subsample (a condition that is easy to check). Under Assumption
1.4 this will be true in large enough samples, but may not be in small samples; particularly when
overlap is poor.


                                                     11
the exact balancing condition
                          Z                              Z
                               () db  ( 1 ) =        () d ()                    (12)

where  () is the full sample empirical distribution function of . Since  () is
an eﬃcient estimate of the distribution of , it is reassuring that b  ( 1 ) satisfies
(12). We discuss the properties of b  ( 1 ) further in Section 3.
    The exact balancing property of b  ( 1 ) implies that b  may be consistent
for 0 , even if the maintained propensity score model is incorrect. Let Π0 = (Π∗0  0),
under Assumption 2.1 we have Π0 E [ ()] = E [Π∗0 ∗ ()] = E [ ( 0 )]  Using this
equality, Assumption 1.3, and exact balancing (9) we get
       ∙          ¸    ∙                  ¸
      ( )           0 ()  ( )
  E                 =E                      − E [ ( 0 )]
    ( ()0 ∗ )         ( ()0 ∗ )
                       ∙                  ¸
                         0 ()  ( )
                    =E                      − Π0 E [ ()]
                          ( ()0 ∗ )
                       ∙                       ¸         ∙                    ¸
                            0 ()                           0 ()
                    =E                  ( ) − Π0 E                    ()
                         ( ()0 ∗ )                     ( ()0 ∗ )
                       ∙                                                       ¸
                            0 ()
                    =E                 {E [  ( )| ] − E [ ( 0 )| ]} = 0 (13)
                         ( ()0 ∗ )

Therefore  = 0 is a solution to the inverse probability weighted population moment
even if there is no 0 such that ( ()0 0 ) = 0 () for all  ∈ X  This is the second
part of double robustness.
    If  ( ) is linear in  as in Examples 1.1 and 1.2 above, then  = 0 uniquely
solves (13). In the general nonlinear case ensuring uniqueness of the solution to
(13) may require the imposition of additional conditions, depending on the form of
 ( )  As such conditions are model-specific we do not formulate them here, but
note that doing so is facilitated by the fact that Assumption 1.4 and part (iv) of
Assumption 1.5 ensure that 0 () ( ()0 ∗ ) is bounded below by some positive
constant.14 Proceeding under the assumption that  = 0 uniquely solves (13) we get
our second result.

  14
     Wooldridge (2001, pp. 458 - 459) develops conditions for consistency of unweighted M-estimators
when the underlying sample is a stratified random one. His argument could be adapted to the current
setting for cases where  [ ( 0 )] = 0 corresponds to the first order condition of a population
optimization problem.


                                                 12
Theorem 2.2 ( Double Robustness of b          ) Suppose Assumptions 1.1 to 1.4,
either Assumption 1.5 or 2.1,  = 0 uniquely solves (13), and additional regularity
                     √                
conditions hold, then (b  − 0 ) → N (0 Ψ0 ) where the form of Ψ0 depends on
whether Assumption 1.5 or 2.1 holds (see Appendix A).

Proof. See Appendix A.
    Our formulation of the IPT estimator was undertaken with eﬃciency consider-
ations at the forefront. This led to an approach where the propensity score was
parameterized with two concerns in mind. First, the parametric propensity score
family needs to be rich enough to contain the true score. Second, it needs to be rich
enough to balance those functions of  which enter the CEF of  ( 0 ). Theorem
2.2 shows that the dividend to this approach extends beyond local eﬃciency. Even if
the propensity score is misspecified, IPT will remain consistent if E [ ( 0 )| ] is
linear in  ()  More heuristically Theorem 2.2 suggests that IPT will perform well
for moderately rich forms of  () when either the propensity score or the condi-
tional expectation of  ( 0 ) is smooth in . Researchers should choose  () to
be rich enough so that it accurately approximates whichever function, either 0 ()
or 0 () = E [ ( 0 )|  = ], is believed to be the least smooth. The double ro-
bustness properties of IPT are illustrated via a series of Monte Carlo experiments,
summarized in the Supplemental Web Appendix.


3    Other alternatives to IPW and higher order com-
     parisons
Theorems 2.1 and 2.2 provide one argument for routine use of IPT: it is (i) more
robust than either standard IPW or parametric imputation and (ii) locally eﬃcient
at Assumption 2.1. Computationally it is no harder than standard IPW (see Ap-
pendix A). Finally the exact balancing property is likely to be attractive to applied
researchers. It is consistent with the intuition that reweighting makes the complete
case subsample more like the full sample. Tables which assess balance after IPW are
commonly featured in applied work (e.g., Hirano and Imbens, 2001; see also Table 14
in the Supplemental Web Appendix).
    While the argument privileging IPT over IPW appears to be straightforward,
other alternatives to IPW exist. One such alternative is the class of augmented

                                          13
inverse probability weighting (AIPW) estimators introduced by Robins, Rotnitzky,
and Zhao (1994). Like IPT, AIPW is locally eﬃcient at Assumption 2.1. It is also
doubly robust. In this section we present two theoretical arguments for privileging
our IPT method over AIPW ones. First we show that the implicit estimate of the
joint distribution of  and 1 associated with IPT is attractive relative to the ones
associated with AIPW. Second we compare the higher order bias of the two types of
estimators.


3.1     A class of iterated AIPW estimators
Several versions of AIPW are now available (see Tan (2010) for a recent survey). Here
we describe a general set-up which captures many of them. Let  () =  (  ) and
 () =  (    ) be known, scalar-valued, nonnegative weight functions. We
require that  (    ) is such that E [ (    )| ] = 1. Our family of AIPW
estimators will be indexed by these two weight functions. Let b        () be an AIPW
estimate in the family, which is defined as the solution to
              (                                   ¡           ¢                 )
   1 X                    ¡                          b() ³
                                         ¢ b()  ;                       ´
                               b
                                   () −                      −  (b )   = 0        (14)
     =1             b
                   ( )                          b
                                                  ( )

with b the CMLE of the propensity score parameter and
                             "                  # "                     #−1
                             1 X                    X
                                                      
                                                    1
            b() (; ) =         b  () 0 ×
                                                             b  0
                                                          b               () 
                                   b  
                              =1                  =1

with b =  (b ), b =  (b ) and 
                                            b =  (b ) Note that b() (; ) is the fitted
value associated with a weighted least squares fit of  () onto  
    Setting  () =   () and  () =  () we get the original AIPW estimator
of Robins, Rotnitzky and Zhao (1994);  () = 1 and  () = 1 yields Newey’s (1994,
Section 5.3) estimator, while  () =   () and  () = (1 −  ())  () gives
the estimator suggested by Cao, Tsiatis and Davidian (2009) (see Table 1).15
    Hirano and Imbens (2001) and Wooldridge (2007) propose a doubly robust esti-
  15
    Many of the estimators listed in Table 1 were originally proposed in the context of a specific
form for  ( ). We adapt to the general case as necessary. Newey (1994) derives the large
sample properties of his estimator where the dimension of  () grows with  . Here we consider his
estimator with the dimension of  () held fixed.


                                                14
mator for the average treatment eﬀect under exogenous treatment assignment.16 It
turns out that setting  () =   () and  () = 1 gives their estimator. In the
general moment model case their approach chooses     b to solve

                               1 X
                                      b ( ; 
                                                  b ) = 0                                 (15)
                                 =1


where b (; ) is the weighted least squares fit
                              "               # "                #−1
                             1 X                  X
                                                    
                                                  1      
              b (; ) =          () 0 ×             0      ()                  (16)
                                   b 
                              =1                     b  
                                                   =1 

    The following Proposition shows that (15) is also a member of our class of AIPW
estimators.

Proposition 3.1 The solution to (15) is numerically identical to b
                                                                 () with  () =
  () and  () = 1.

Proof. Since the first element of  is a constant we have, by the first order condition
associated with (16),

                        1 X 
                                  { (  b
                                            ) − b (; )} = 0                          (17)
                              b
                           =1 


Adding the left-hand side of (17) to (15) and re-arranging gives the result.


3.2     Implicit distribution function estimates
A useful way to understand the properties of first order equivalent estimators is in
terms of their implicit distribution function estimates. After some simple algebra we
can show that the solution to (14) coincides with that to
                                  X
                                         b() (  b
                                                        () ) = 0
                                   =1


where
                                                  1  b
                                    b() =
                                                                                           (18)
                                                  b ()
  16
    Wooldridge’s (2007) estimator is actually slightly more general than the one described here in
that b (; ) need not correspond to a least squares fit.


                                                 15
with
                        ⎧   "                                                   ⎫
                        ⎨       X µ       ¶ # " X   
                                                                      #−1
                                                                                ⎬
                              1                 1
           b()   = 1−             − 1 0 ×           b  0
                                                        b               b  
                                                                          ×                         (19)
                        ⎩      =1 b            =1                         ⎭

for  = 1      This implies that the estimate of the joint distribution associated
with b() is
                                             X
                        b() ( 1 ) =           b() 1 ( ≤ ) 1 (1 ≤ 1 ) 
                                                                                                    (20)
                                               =1


(see Back and Brown, 1993, Proposition 1).
    This distribution function has several interesting properties. First if  =   (),
which is true for all the estimators listed in Table 1 except Newey’s (1994), then
                               Z                               Z
                                    () db() ( 1 ) =        () d () 

The re-weighted mean  () in the complete case ( = 1) subsample coincides with
its unweighted full sample mean. Since the unweighted full sample mean of  () is
an eﬃcient estimate of its population analog, then so is the re-weighted complete case
sample mean. In this sense the b() ( 1 ) inherits some of the eﬃciency properties of
 (). Since the first element of  ( ) is 1 the AIPW distribution function estimate
                               R
also integrates to 1 (i.e., db() ( 1 ) = 1).
     As noted in the previous section the IPT distribution function estimate (11) also
exactly balances the mean of  ( ) and integrates to one. However, it diﬀers from
b() ( 1 ) in that it is guaranteed to be non-decreasing, whereas b() ( 1 ) may
be decreasing in  and/or 1 over some ranges. Put diﬀerently some of the            b()
weights may be negative, while the      b  weights are positive by construction.
     To gain further insight into this problem consider the distribution function esti-
mator associated with standard IPW (e.g., Imbens, 2004):
                           X                                                               1 
       b  ( 1 ) =             b  1 ( ≤ ) 1 (1 ≤ 1 ) 
                                                                               b  =
                                                                                                   (21)
                               =1                                                          b




                                                        16
Now consider a random sample where

                µ       ¶
            1 X                       X                     1 X
                                                                
                      − 1  ( )  0 ⇔     b   ( ) 
                                                                    ( )           (22)
             =1 b                                          =1
                                        =1


In this case the IPW estimate of the mean of  ( ) exceeds its unweighted full sample
counterpart. The fact that the latter mean is eﬃcient, implies that former is not. The
AIPW distribution function estimator corrects this ineﬃciency by adjusting the IPW
weights as follows
                                         b  × b() 
                              b() = 
                              

with b() as defined in (19). Under (22) large realizations of  () are ‘too frequent’
in the complete case subsample (even after reweighting by the inverse of the estimated
propensity score). In such a situation b() will be less than one for  = 1 units with
large values of  () and greater than one for units with small values. In extreme cases
the resulting  b() may be negative or exceed one. Condition (22) is especially likely
to occur when the propensity score model is misspecified. In that            b
                                                              P     ³ case  ´corresponds
to a quasi-MLE propensity score estimate and hence 1                   b
                                                                =1   − 1  ( ) may
diﬀer from zero even in large samples.
    In practice the IPW and AIPW distribution functions can generate nonsensical
estimates. Let  ( ) = 1 −  Neither b     and b() are guaranteed to lie within
the convex hull of the data. If 1 ∈ {0 1}, for example, this means it is possible
    b  and 
for              b() to exceed one. In contrast b    will lie in the convex hull of
the data by construction. In our view an estimator which sets a weighted mean of
 ( ) equal to zero, where these weights need not lie on the unit interval is a priori
unattractive (cf., Robins, Sued, Lei-Gomez and Rotnitzky, 2007; Tan, 2010).


3.3    Higher order bias
Another way IPT and AIPW can be compared is in terms of their higher order bias.
In this section we present higher order bias expressions for both IPT and AIPW when
Assumptions 1.1 to 1.5 and Assumption 2.1 hold. Bias comparisons are interesting
in this case because IPT and AIPW are first order equivalent. Theorem 3.1, which is
based on an application of Lemma A.4 of Newey and Smith (2004), gives the result.




                                            17
Theorem 3.1 (Higher Order Bias) Suppose Assumptions 1.1 to 1.5, Assumption
2.1, and additional regularity conditions hold, then as  → ∞

                                        ( )    ¡     ¢
                       b() = 0 +
                                        +         +   −2                       (23)
                                           
                                         ¡ −2 ¢
                       b 
                              = 0 +    +                                      (24)
                                      

where
                                       ∙ 2 ¸
                           1 X −1
                              
                                           
                    = −        Γ E           0
                                                  I (0 )−1 
                           2 =1         
                              ∙                   ¸              ∙          ¸
                          −1     −1 1                 1 −1        −1
                       +Γ E          Γ    { − } + Γ E                 Γ 
                                 0                              0
                                 ∙                   ¸
                            −1              −1
              ( ) = −Γ E 2 Σ () Λ Π 
                                   
                              ∙½ µ            ¶       ¾                 ¸
                          −1               1               0 −1
                       +Γ E            2 −      −   Λ Π 
                                           
                              ∙ µ          ¶µ         ¶          ¸
                          −1                             0 −1
                       +Γ E           −         − 1  0  
                                               

                                                    
with  denoting a  × h1 vector i with a 1 in the  row and zeros elsewhere,  =
( ()0 0 ), and 0 = E 1−
                           
                              0 .

Proof. See Appendix A and the Supplemental Web Appendix.
    To understand Theorem 3.1 it is helpful to consider the asymptotic properties
                                                            b to set the optimal (i.e.,
of an infeasible ‘oracle’ estimator. This estimator chooses 
asymptotic variance minimizing) linear combination of the sample mean of
                                         ⎧                        ⎫
                                         ⎨        
                                                      (  )    ⎬
                         I ( 0 ) =       ³ 0 () ´ 0                         (25)
                                         ⎩      
                                              0 ()
                                                     − 1 0 ()   ⎭

equal to zero. This estimator is infeasible because (i) 0 () and 0 () are unknown
and (ii) the optimal linear combination is also unknown. An implication of Graham
(2011, Theorem 2.1) is that the eﬃcient GMM estimator based on (25) is also semi-
parametrically eﬃcient for the missing data problem defined by Assumptions 1.1 to
1.5.


                                              18
    A direct application of Theorem 4.1 of Newey and Smith (2004) to (25) gives an
asymptotic bias for this estimator of   This bias coincides with that of b      , de-
spite the fact that the oracle estimator is based on the true propensity score, 0 () 
conditional mean moment vector, 0 (), and GMM weight matrix. In contrast, the
bias expression for the AIPW estimate     b() contains additional terms. The addi-
tional terms arise from AIPW’s separation of the tasks of propensity score estimation
and imposition of the optimal set of balancing restrictions implied by Assumption
2.1. The first task generates no gains in terms of asymptotic precision, while at
the same time introducing sampling error into the vector of estimating equations for
b()  The second task results in an overidentified system of moment equations. The

finite sample properties of b() may degrade as a result. It is straightforward to con-
structed stylized examples where the bias of    b() increases with , the dimension
of  (), while that of b  does not. This will be especially true if the distribution
of  () is skewed and/or that of  ( 0 ) is heteroscedastic (see the Supplemental
Web Appendix for Monte Carlo examples).
    The contrast between the higher order bias of     b  and b
                                                                 () in some ways par-
allels that between empirical likelihood (EL) and two-step GMM for general mo-
ment condition models (Newey and Smith, 2004). The empirical likelihood estimator
transforms an overidentified moment conditional problem into a just-identified one
by introducing a vector of tilting parameters (cf., Imbens, 1997). Our approach to
overidentification, in contrast, involves overparameterizing the propensity score. The
idea of overfitting a nuisance function to eliminate overidentification appears to be
novel.
    An alternative to IPT would be to apply GEL directly to the set of moment
conditions underlying the AIPW estimator (cf., Qin, Zhang and Leung, 2009). Let
 = dim ( ()) and ∗ = dim (∗ ()). Such an approach would apply GEL to the
 + ∗ +  system of moments
                  ⎡                                                              ⎤
                                         
                                                   (  )
                                   ³ (() 0∗ ) ´ 0
                                             0
                 ⎢                                                               ⎥
                 ⎢                      
                                                 − 1 ∗ ()                      ⎥
                E⎢
                 ⎢ µ                (()0 0∗ ) ¶                              ⎥ = 0
                                                                                 ⎥
                 ⎣          −(()0 0∗ )                                      ⎦
                       (()0 0∗ )[1−(()0 0∗ )]
                                                         1 ( ()0 0∗ ) ()


Computation of b
                would involve solving a saddle point problem with 2 ( +  )+
∗ parameters (Newey and Smith, 2004; Section 2). In contrast computing    b 

                                                    19
requires solving a 1 +  ≤ ∗ +  dimensional globally concave problem and a
just-identified moment condition problem with  parameters. Our approach involves
a smaller parameter and sidesteps the need to solve a saddle point problem.


4      Basic skills and the Black-White wage gap
In an important pair of papers Neal and Johnson (1996) and Johnson and Neal (1998)
document that Black-White skill diﬀerences present prior to labor market entry (i.e.,
by age 18) can account for a substantial portion of the corresponding gap in adult
hourly earnings. In particular they find that three fifths of the raw 28 percent Black-
White gap in average hourly earnings can be predicted by diﬀerences in Armed Forces
Qualification Test (AFQT) scores, a measure of basic skills used by the military.
    Here we repeat Johnson and Neal ’s (1998) analysis after replacing AFQT scores
with measures of cognitive skills acquired prior to adolescence. The idea is to measure
how much of Black-White diﬀerences in hourly earnings can be accounted for by
diﬀerences in skills across the two groups already manifest prior to adolescence. If
a substantial portion of the wage gap can be so accounted for, then educational
interventions which aim to ameliorate racial inequality might be more appropriately
targeted toward younger children.17
    We reconstruct the National Longitudinal Survey of Youth 1979 (NLSY79) extract
analyzed by Johnson and Neal (1998). This sample is a stratified random sample of
young men from the United States born between 1962 and 1964. Measurements of
average hourly wages over the 1990 to 1993 period, race, as well as AFQT scores
are available for each individual. The NLSY79 also collected data from respondents’
school records. In some cases these records included (nationally normed) percentile
scores on IQ tests taken at various ages. We use those scores corresponding to tests
taken between the ages of 7 and 12 as measures of cognitive skills acquired prior to
adolescence. Unfortunately these scores are missing for almost 90 percent of individ-
uals. An unweighted analysis based on those individuals with complete information
would be problematic for two reasons: (i) there are few complete cases making precise
inference diﬃcult and (ii) the complete cases are not representative of the full sample
  17
    Interpreting any predictive relationship between early childhood test scores and subsequent labor
market earnings causally involves a number of subtleties. As our purposes are primarily illustrative,
we do not dwell on this issue here. See Neal and Johnson (1996) for a discussion of some of the
issues involved.


                                                 20
in terms of always-observed characteristics. Our IPT estimator is designed to address
both of these problems.
    Columns 1 and 2 of Table 2 replicate Columns 1 and 2 of Table 14-1 in John-
son and Neal (1998, p. 483) (with the exception that we exclude Hispanics from
our analysis).18 The first column reports the least squares fit of LogWage onto a
constant, YearOfBirth, and Black. The estimated wage gap between Blacks and
Whites of the same age is 28 percent. Column 2 adds AQFT to the set of explanatory
variables. The wage gap between Blacks and Whites of the same age with the same
pre-market AFQT score is only 11 percent. Seventeen percentage points of the uncon-
ditional Black-White hourly wage gap can be accounted for by average diﬀerences in
pre-market AFQT scores across the two groups. That a substantial portion of racial
diﬀerences in hourly wages can be accounted for by diﬀerences in skills acquired prior
to entry into the labor market is Neal and Johnson’s (1996) central result.
    Columns 3 and 4 of Table 2 replicate Columns 1 and 2 after replacing AFQT
with our preadolescence test score (EarlyTest). This is an unweighted analysis
based on the 144 complete cases. Conditioning on age alone, racial wage gaps in
the complete case subsample are very similar to those computed using the full sample
(Column 3). The wage gap conditional on the pre-adolescent test score is substantially
lower (Column 4). Unfortunately these wage gap estimates are very imprecise; their
standard errors are almost four times those of their Columns 1 and 2 counterparts.
A second problem with this analysis is that those individuals with early test scores
diﬀer systematically from those without them (See the Table 11 in the Supplemental
Web Appendix).
    To address bias due to non-randomness in the missingness process as well as to
improve precision we re-estimated the Table 2, Column 4 model using our IPT pro-
cedure. To appropriately use IPT we require that EarlyTest is missing at random
(Assumption 1.3). That is, conditional on YearOfBirth, Black, LogWage and
AFQT, we require that the probability of observing EarlyTest is independent of
its value. Given the severity of missingness in our dataset this assumption is poten-
tially problematic. We nevertheless maintain it in order to illustrate the practical
application of IPT.
    The joint support of YearOfBirth and Black contains 3 × 2 = 6 points.
We included in  () five non-redundant dummy variables for YearOfBirth-by-
 18
      See also Columns 1 and 3 of Table 1 in Neal and Johnson (1996, p. 875).


                                                21
Black cell (Whites born in 1962 are the excluded group). This resulted in full
distributional balance for the discretely-valued components of  We also balanced
the means, variances and covariance of AFQT and LogWage conditional on race
alone, and age alone, but not their interaction.19 That is  () also included AFQT,
LogWage, AFQT2 , LogWage2 and AFQT×LogWage as well as the interactions
of these variables with Black and the two year of birth dummies (1962 being the
excluded cohort). This led to a specification of  () with 26 elements.
    Our choice of  () was informed by two considerations. First, we wanted  ()
to be rich enough to allow for complex forms of selection into missingness (see As-
sumption 1.5) as well as for the conditional mean and variance of EarlyTest (see
Assumption 2.1 and Example 1.2). Second, we wanted to reweight the 144 complete
cases such that an analyst with access to these data alone would numerically exactly
reproduce the results of Johnson and Neal (1998) (i.e., the point estimates in Columns
1 and 2 of Table 2).20
    Column 2 of Table 3 reports IPT estimates of the best linear predictor of Log-
Wage given, YearOfBirth, Black, and EarlyTest. For comparison the un-
weighted complete case estimates are reproduced in Column 1 of the table, while
the standard inverse probability weighted (IPW) estimates are given in Column 3.
Relative to the unweighted complete case one, the IPT estimate of the Black-White
wage gap, conditional on skills acquired prior to adolescence (EarlyTest), is larger
in absolute value with a standard error almost two thirds smaller. Recall that the
wage gap conditional on age alone was 28 percent (Table 2, Column 1). Conditioning
on skills acquired prior to adolescence this gap falls to 18 percent. This is larger than
the 11 percent gap present after conditioning on the later AFQT score, but substan-
tially smaller than the unconditional gap. Put diﬀerently roughly 40 percent of the
raw Black-White wage gap can be accounted for by diﬀerences in average skill levels
across the two groups manifest prior to adolescence. This represents about two-thirds
of the pre-market eﬀect found by Neal and Johnson (1996).
    Column 3 of Table 3 reports IPW estimates of the same model. The IPW estimate
  19
      Given the near normal distribution of AFQT and LogWage in our sample focusing on the first
two moments of these variables seemed appropriate.
   20
      Our choice of  () ensures that all those moments used to compute the full sample least squares
fit of LogWage onto a constant, YearOfBirth, Black and AFQT are exactly balanced. Con-
sequently the corresponding IPT-weighted least squares fit based on the 144 complete cases alone
will be numerically identical to the unweighted full sample fit.



                                                 22
of the Black-White wage gap is imprecisely determined with a standard error over
twice as large as the IPT one. This provides a concrete example of the eﬃciency gains
IPT can provide relative to IPW (see Proposition 2.1 and Theorem 2.1). Columns
4 through 7 report estimates based on the four implementations of AIPW described
in Section 3. The AIPW point estimates, with the exception of Newey’s (1994), are
very similar to their IPT counterpart, albeit with slightly larger standard errors.21


5      Summary and extensions
The IPT procedure proposed in this paper is a promising alternative to standard IPW-
and AIPW-based approaches to missing data. We end by outlining some possible
extensions to IPT that might merit further research.

Program evaluation and related problems Thus far we have focused on prob-
lems where  is completely observed if  = 1. Now consider the case where
 = ( 0  00  10 )0 with   and  = (1 − ) 0 + 1 observed. That is we observe
0 if  = 0 and 1 if  = 1. Let the moment function take the separable form

                            ( ) = 1 (1   ) − 0 (0   ) 

Many problems fall into this basic set-up.

Example 5.1 (Average treatment effects (ATEs)) Let  = 1 and  = 0
respectively denote assignment to an active and control program or intervention and
1 and 0 the corresponding potential outcomes. The Average Treatment Eﬀect (ATE)
is
                                  0 = E [1 − 0 ] 

which corresponds to setting 1 (1   ) = 1 and 0 (0   ) = 0 + . Since each
unit can only be exposed to one intervention, either 1 or 0 is missing for all units.
  21
    In this particular example the implicit AIPW distribution function estimates are reasonably
similar to the IPT one; AIPW does not give inordinate weight to any particular respondent and
negative weight is attached to only a handful of units. The exception is Newey’s (1994) variant of
AIPW. Theorem 3.1 suggests this variant of AIPW is more biased than the others, consistent with
our empirical results.




                                               23
Example 5.2 (Two sample instrumental variables (TSIV) estimation with
compatible samples) Assume that dim () ≥ dim (0 ) and consider the following
instrumental variables model

                                1 = 00 0 +        E [ ] = 0

This suggests a moment function with 1 (1   ) = 1 and 0 (0   ) = 00 
Two independent random samples of size 1 and 0 from the same population are
available. In the first sample 1 values of 1 and  are recorded, while in the sec-
ond 0 values of 0 and  are recorded. For asymptotic analysis we assume that
  lim 1 (1 + 0 ) = 0  0. This is the two-sample instrumental variables
1 0 →∞
(TSIV) model analyzed by Angrist and Krueger (1992). Ridder and Moﬃtt (2007)
provide a technical and historical overview. This model is equivalent to a special case
of the semiparametric missing data model, an observation that is apparently new. As-
sume  units are randomly drawn from some target population. With probability 0
the  unit’s values for 1 and  are recorded, while with probably 1 − 0 its values
of 0 and  are recorded. The indicator variable  denotes which set of variables are
measured. The only diﬀerence between this sampling scheme and that of Angrist and
Krueger (1992) is that in the latter 1 and 0 are fixed by the researcher, whilst in the
missing data formulation they are random variables. An adaptation of the argument
given by Imbens and Lancaster (1996, Sections 2.1-2.2) shows that this diﬀerence does
not aﬀect inference.

   To apply IPT to these problems we find the b
                                                0      b1
                                                    ,   and b
                                                                   which solve
                    (                                                              )
            1 X
               
                                          b  ) (1 −  ) 0 (0    b
                         1 (1                                      )
                                                  −                                  =0
             =1         ( ( )0 b
                                        1
                                           )          1 − ( ( )0 b
                                                                         0
                                                                           )
                                              Ã                            !
                                      1 X
                                           
                                                      1 − 
                                                                        − 1  ( ) = 0
                                      =1 1 − ( ( )0 b    0
                                                                     )
                                                   Ã                       !
                                            1  X
                                                           
                                                                        − 1  ( ) = 0
                                           =1      ( ( )0 b1 )
                                                                


Note that this involves computing two propensity score parameter estimates. One
which balances the mean of  () in the  = 1 subsample with its full sample mean
(b
   1
       ) and one which balances the mean of  () in the  = 0 subsample with its


                                                  24
full sample mean (b0
                         ). Each of these propensity score estimates may be computed
using the algorithm described in Appendix A. The second step of estimation involves
solving a just-identified moment condition problem.
    It is straightforward to extend the arguments given above to show that the above
estimator is locally eﬃcient and doubly robust. As before  () should be rich
enough to adequately model the propensity score. Local eﬃciency requires that
E [0 (0   )| ] and E [ 1 (1   )| ] be linear in  () (this is also the con-
dition for double robustness). As in the examples outlined above the form of  ()
is often suggested by the structure of the problem. Consider eﬃcient estimation of
the ATE by IPT. This requires choosing  () such that the true propensity score is
                                          ¡       ¢
contained in the parametric family   ()0  and the true potential outcome CEFs
are linear in  ()  Consistency requires only one of these two restrictions to be true.

E [ ( 0 )| ] nonlinear If there is no  () such that E [ ( 0 )| ] is linear in
 () then neither our local eﬃciency or double robustness result can exactly hold
(although our procedure, like IPW, will still be consistent if the propensity score is
correctly specified). Although, in practice, E [ ( 0 )| ] may be well-approximated
by a function linear in  (), it is of interest to allow E [ ( 0 )| ] to be intrinsically
nonlinear. As a concrete example assume that we seek to estimate the marginal mean
of the binary-valued 1 . We posit the working model Pr (1 = 1| ) =  ( 0 ) and
choose b to maximize the log-likelihood
                X
                          {1 log  (0 ) + (1 − 1 ) log (1 −  (0 ))} 
                   =1


Note we use only the complete cases ( = 1 units) for this computation.
    Observe that if  () included  ( 0 0 ) as an element, then Assumption 2.1 would
hold by construction. We approximate this ideal by including the estimate  ( 0 b) as
an element of  () (along with the elements of  () and possibly other known func-
tions of ). Denote  ()  so defined, by  (; b ). Using this vector of balancing
functions we estimate the propensity score parameter by solving
                            Ã                                   !
                   1 X
                      
                                           
                                                             − 1  ( ; b ) = 0
                    =1        ( ( ; b )0 b  )

The IPT estimate of 0 is solved for as before. The main diﬀerence between the IPT


                                                    25
procedure introduced in Section 2 and the one sketched above is the inclusion of a
generated regressor in the propensity score model. It is possible that sampling error in
                                              b  . We conjecture that, appropriately
b could aﬀect the asymptotic properties of 
restated, Theorems 2.1 and 2.2 would remain valid, but that our higher-order bias
calculations would be aﬀected.

Data dependent choice of  () when E [ ( 0 )| ] is nonparametric As-
sume the propensity score is known, but that prior knowledge on the form of E [ ( 0 )| ]
is unavailable (i.e., it is nonparametric). If the first element of  () is −1 (0 ()),
then b  will be consistent. The choice of what other functions of  to include
in  () has implications for eﬃciency alone (and perhaps finite sample bias). In
this special case, the problem of choosing  () is closely related to that of moment
selection in conditional moment problems (e.g., Donald, Imbens and Newey, 2008).
Hirano, Imbens and Ridder (2003) also suggest incorporating a known propensity
score in a similar fashion, but do not make the connection between overparameter-
ization of the propensity score and moment selection. This connection is made, by
construction, explicit in the IPT setting. When the propensity score is also nonpara-
metric, choosing  () is no longer analogous to a pure moment selection problem
since  () also determines the quality with which the propensity score is approxi-
mated. It would be interesting to explore automated, data dependent, procedures for
choosing the components and dimension of  () in the above settings.

Estimation of overidentified moment condition models If dim ( ( )) 
dim () the procedure outlined above is not directly applicable. One approach overi-
dentification would be to estimate the inverse probability tilt as described above.
In step two the analyst could then apply two-step GMM (or GEL) using the IPT-
reweighted data. We conjecture that this procedure would be locally eﬃcient and
doubly robust. It would be interesting to construct a one step estimator for overiden-
tified models.


A     Appendix

This appendix outlines the proofs of the results given in the main text. Throughout
the Appendix we assume that  () = ∗ () =  () so that Π0 = Π∗0 and 0 = 0∗ 

                                          26
This is done only to simplify the notation and is without loss of generality. We also
drop ‘0’ subscripts, used to denote (true) population values, when doing so causes no
confusion. A supplemental web appendix, available at https://files.nyu.edu/bsg1/public/,
contains additional proofs.

Local eﬃciency and double robustness of b
                                          (Theorems 2.2 and 2.1)

    Consistency and double robustness When Assumptions 1.1 to 1.5 hold con-
sistency follows from arguments analogous to those of Wooldridge (2007) for IPW.
If Assumptions 1.1 to 1.4 and 2.1 hold, but not 1.5 (we do assume that the  (·)
function satisfies the stated regularity conditions; in particular that ( ()0 )  0
                                        
for all  ∈ X and  ∈ D) we have b → ∗ where ∗ is the pseudo-true value which
         £¡                    ¢     ¤                   £                          ¤
solves E ( ()0 ∗ ) − 1  () = 0 This gives E 0 ()  () ( ()0 ∗ ) =
E [ ()] so that under Assumption 1.3 and 2.1 we have equation (13) of the main text.
Therefore  = 0 is a solution to the IPW population moment. If  ( ) is linear in
, then this solution is also unique. Otherwise uniqueness follows by hypothesis.

    Asymptotic normality Asymptotic normality of         b  follows from Theorem
                                                      0
6.1 of Newey and McFadden (1994). Let  = ( 0   0 )  The  + 1 +  × 1 moment
vector and derivative matrix equal
            ⎛                     ⎞               "                                              #
                                                       ()           1 ()
                          ()
                ³  ()  ´                                        −  ()         () 0
                                                                               () 
    () = ⎝      
                                  ⎠    () =        ()  0
                                                                               1 ()
                                                                                                     
                   ()
                         − 1                            0            −  ()         0
                                                                                  ()  
                                                                                 (26)
First consider the case where Assumptions 1.1 to 1.5 hold. Let n = E [ (0 )]oand
       £               0¤
                              √                                            −1
                                   − 0 ) → N (0 Ψ0 ) for Ψ0 = ( 0 Ω−1 )
Ω = E  (0 )  (0 ) , then  (b
                                                                                                     1:1:
(where 1:1: is the upper left hand  ×  block of ).                    The covariance of
 =  (0 ) equals
                                  Ã h 0i      !
                                    E 
                                       
                                           0
                            Ω=                                                                      (27)
                                      00  0
with                         ∙    ¸                         ∙  ¸
                            1− 0                        1− 0
                     0 = E                    0 = E                                          (28)
                                                         




                                            27
The the population mean of  =  (0 ) equals
                                                Ã       £        ¤ !
                                                    Γ −E 1 0
                                    =                  £        ¤                                            (29)
                                                    0 −E 1 0

                                                                                         √ ³       ´
Using (27) and (29) we get a limiting sampling variance for                                b − 0 equal to

                ⎛   ³ h 0i               ´             £       ¤−1 0          £      ¤−1 −10
                 Γ−1 E 
                        
                           −  0 0 −1 0
                                       0 Γ
                                           −10
                                               + Γ−1 E 1 0    ∆0 0 ∆0 E 1 0    Γ
 −1 Ω −10   =⎝          £       ¤−1    n           £       ¤ £       ¤−1 o0
                       −E 1 0     0 0 0−1 − E 1 0 E 1 0        Γ−10
                                                                                                               (30)
                  n           £       ¤ £        ¤−1 o     £        ¤−1 !
              −Γ−1 0 0−1 − E 1 0 E 1 0       0 E 1 0
                                                                                                  
                                                 ()

where
          ∙               ¸                                               ∙         ¸−1       ∙        ¸−1
         ¡        −1
                      ¢ 0                                             1 0                      1 0
  ∆0 = E    − 0 0                                 (0 ) = E                    0 E             (31)
                                                                                              

   Now consider the case where Assumptions 1.1 to 1.4 and 2.1 hold, but not 1.5.
Let ∗ = (00  ∗0 )0  with ∗ the pseudo-true propensity score parameter. Let ∗ =
( ()0 ∗ ) etc. Under this set of assumptions we have
                    ⎛           h               i                     h        ³     ´        i  ⎞
                                0 ()                                0 ()    1−∗
                            E    2∗
                                       0                        E    ∗        ∗
                                                                                          0
           Ω∗ = ⎝        h        ³
                           0 () 1−∗
                                         ´ i                     h³
                                                                  0 ()        0 ()
                                                                                            ´ i ⎠
                        E ∗         ∗
                                           0               E     2∗
                                                                           −   2 ∗      + 1 0

and                             ⎛       h                i        h                  i ⎞
                                            0 ()              0 () 1∗
                                    E        ∗  0
                                                             −E              0
                        ∗ = ⎝                                   h ∗ ∗ i               ⎠
                                                0              −E 0()
                                                                      ∗
                                                                         1∗ 0
                                                                          ∗
                                                                             
            n                o
                          −1
so that Ψ0 = (∗0 Ω−1
                   ∗  ∗ )                          
                                      1:1:


   Local eﬃciency If Assumption 2.1 also holds we have E [| ] = Π0  =  so
that 0 0−1 = Π0 and hence
                                            ∙       ¸   ∙       ¸
                                       1−                1− 0
                    0 0−1 00     =E          0 0
                                           Π0  Π0 = E                                                     (32)
                                                          

                                                          28
                             ³ h 0i                ´
which gives the equality Γ−1 E  
                                     −    
                                          0 0
                                              −1 0
                                                 0 Γ
                                                      −10
                                                          = I (0 )−1  In that case we
also have ∆0 = 0 since E [|  ] = 0 0−1  Under these conditions (30) simplifies
to
                                        ¡                    ¢
                      −1 Ω −10 =  I (0 )−1   (0 )                     (33)

   Local eﬃciency at Assumption 2.1 follows if we can show that IPT is regular
under Assumptions 1.1 to 1.5. The score function for a parametric submodel of the
semiparametric missing data model is (e.g., Chen, Hong and Tarozzi, 2008)

    (  ; ) =  (1 | ; )
                                                                        µ        ¶
                           − ( ()0 )                                   
                  +        0  £           0  ¤ 1 ( ()0 ) () ×                  +  (; ) 
                    ( () ) 1 − ( () )                               

Under Assumption 1.1 we have, diﬀerentiating under the integral and using iterated
expectations,
                  ∙                                ¸
   (0 )     −1             log  (1  ; 0 )
           = −Γ E  ( 0 )
                                   
                         = −Γ−1 {E [ ( 0 )  (1 | ; 0 )] + E [ (; )  (; 0 )]} 

    Under Assumptions 1.1 to 1.5 standard calculations yield an asymptotically linear
                  b equal to:
representation of 
                 ½                          µ                   ¶       ¾
         1 X −1   (  0 )
            
                                         −1                               ¡      ¢
b = 0 −
              Γ            0     − 12 22            0     − 1  ( ) +  −12 
          =1     ( ( ) 0 )             ( ( ) 0 )

where −Γ−1 times the term in {·} is the influence function and 12 and 22 denote
the upper right-hand  × 1 +  and lower right-hand 1 +  × 1 +  blocks of  as
given in (29) above. Let  denote this influence function, by Theorem 2.2 of Newey
(1990), regularity of b
                       follows if

 (0 )
         = E [ ( | 0 )] = −Γ−1 {E [ ( 0 )  (1 | ; 0 )] + E [ (; 0 )  (; 0 )]} 
  

We have, using the conditional mean zero property of scores, the MAR assumption,




                                               29
and the fact that 0 () = ( ()0 0 )
                                  " n  (                         ³                     ´       o #
                                                 0)          −1              
                                              0        − 12 22          (()0 0 )
                                                                                         − 1  ( )
   E [ ( | 0 )] = −Γ−1 E        (() 0 )
                                                  × { (1 | ; 0 ) +  (; 0 )}
                                  ∙                                        ¸
                               ( 0 )
                            −1
                      = −Γ E               { (1 | ; 0 ) +  (; 0 )}
                             ( ()0 0 )
                      = −Γ−1 E [ ( 0 ) { (1 | ; 0 ) +  (; 0 )}]
                      = −Γ−1 {E [ ( 0 )  (1 | ; 0 )] + E [ (; 0 )  (; 0 )]} 

as required.

Consistent variance-covariance matrix estimation If Assumptions 1.1 to 1.4
and either 1.5 or 2.1 or both hold, then the asymptotic variance of b
                                                                     may be consis-
tently estimated by              ½³            ´−1 ¾
                            b        c 0 b −1 c
                            Ψ=      Ω                                       (34)
                                                               1:1:

        P     ³ ´          P     ³ ´ ³ ´0
with  = =1    and Ω = =1  b  b .
     c          b        b


Derivation of the higher order bias of IPT (Theorem 3.1) Here we outline
the derivation of the  ( −1 ) bias expressions for 
                                                     b  (i.e., equation (24) in the main
text). The derivation of the corresponding bias expression for the class of AIPW
estimators discussed in the main text can be found in the supplement. Newey and
Smith (2004, Lemma A.4, pp. 241 - 242) provide a general formula for the  ( −1 )
bias of M-estimators. As IPT and AIPW have M-estimator representations we use
their general result in our calculations. We maintain Assumption 2.1 throughout in
what follows (in addition to Assumptions 1.1 to 1.5).
    Let b be the solution to the  = dim () equations
                                             X
                                    b =
                                  ()                       b = 0
                                                          ()                                           (35)
                                                   =1


Under regularity conditions (see below) Newey and Smith (2004, Lemma A.4) show
that the asymptotic bias of b is given by
                                      µ                              i¶
                      b = −
                             −1
                                                   1 hX
                 Bias()               E [  ] + E                                            (36)
                                                  2   =1



                                                   30
where  is a  × 1 column vector with a one in the   row and zeros elsewhere and
          ∙    ¸                                             ∙ 2       ¸
        ()            −1              ()                ()
   =E             = −  ()   =         −   = E                             (37)
        0                               0                  0

   The IPT estimator of  = ( 0   0 )0 is given by the solution to (35) with
                                                 ⎛             ⎞
                                                     
                                                            ()
                                       () =   ⎝³  ()     ´ ⎠
                                                     
                                                     ()
                                                           − 1 

To apply (36) to IPT we require that the parameter space of  is compact with 0 in
its interior, continuity of  () in  and continuous diﬀerentiability in a neighborhood
of 0  and rank () = dim ()  These conditions are implied by Assumptions 1.1 and
1.5. Additionally we require a Lipschitz continuity condition on the third derivative
of  () and the existence of certain higher order moments. Specifically we assume
that (i) for some  () with E [ ()]  ∞
                        ° 3                         °
                        °   ()      3
                                             (  ) °
                        °                      0   °
                        °       ° ≤  ( ) k − 0 k
                                     −

                         ∙°           °¸ ∙°              °¸ ∙°              °¸
          £          6¤   °  (0 ) °6  °  2  (0 ) °6  °  3  (0 ) °2
and (ii) E k (0 )k  E ° 0 °  E °  0 °  and E °    ° are finite
for    = 1      + 1 +  (see Newey, 2002) These conditions will hold if  (·)
and  ( ) are both three times continuously diﬀerentiable with bounded derivatives
and enough moments of  () exist (e.g., if a component of  () is a Cauchy random
variable then (36) will not hold).
    Objects,  (0 )
                    0 ,  and  of (37) above specialize to


                            "
                                 
                                                          #      "          £       ¤ #
               (0 )           0
                                          − 1
                                                   0
                                                              Γ −E 1 0
                        =                              =                   £ 1 0 ¤
                0         0       − 1
                                      
                                             0
                                                                   0    −E    
                                                                                 
                           "                                      £       ¤#
                              
                                  0 − Γ   −      1
                                                 
                                                        0 + E 1 0
                        =                                   £ 1 0 ¤ 
                                  0         −     1
                                                 
                                                         0
                                                             + E   
                                                                      

Using the partitioned inverse formula we have
                                   "          £       ¤ £        ¤−1 #
                                    Γ−1 −Γ−1 E 1 0 E 1 0
                         −1     =                £      ¤−1                             (38)
                                     0        −E 1 0


                                                     31
Combining the above expressions then gives

E [  ]                                                                                (39)
      ⎡ h              i     h              £ 1 0 ¤ £ 1 0 ¤−1   i     h              £ 1 0 ¤−1 i ⎤
              −1 1           1−  −1                                  1− 1   0
           E  0Γ 
                        − E      0 Γ  E        E           + E            E         
= −⎣                                      h           £
                                                         
                                                              ¤   i                    
                                                                                                    ⎦
                                                1 0     1 0 −1
                                         E 1−
                                              
                                                   E   
                                                               

            £ 1      ¤ £       ¤−1
Let Π∗ ≡ E      
                      0 E 1 0 ; using (39) we have the first  rows of − −1 E [  ]
equal to
                             ∙                   ¸           ∙            ¸
                        −1    −1 1                     −1     −1
                       Γ E        Γ    { − Π∗ } + Γ E             Γ Π∗                              (40)
                              0                              0
                               "                          ∙       ¸−1 #
                                 1 −  1                   1 0
                       + Γ−1 E            { − Π∗ } 0 E           
                                                          

Assumption 2.1 gives  = Π0  so that Π∗ = Π0 ; therefore, applying the law of iterated
expectations, gives the last term in the expression above identically equal to zero.
    Now consider the second component of the bias expression (36). Evaluating
E [ 0 ] yields                      "                   #
                                                 −1
                                          I (0 )     0
                          E [ 0 ] =                                           (41)
                                              0      ()
For  = 1  , using the expression for  (0 ) 0  we have
                                            "                                   #
                                                 2                  0
                                                  0
                                                               − 1   
                                  = E                                
                                                                                                      (42)
                                                   0               0

for  as defined in (37) above. For  =  + 1   + 1 +  (=  ) we have instead
                                 ⎡                         ³                ´               ⎤
                                                          221
                                     − 1 −  0          2    −   2
                                                                                − 0
                         = E ⎣                           ³ 2        
                                                                            ´               ⎦         (43)
                                                            21        2               0
                                           0                 2
                                                                   −   
                                                                                − 
                                                                         hP                i
                                                               − −1       
Using (41), (42) and (43) the first  rows of                   2
                                                                     E          =1    can be shown to
                                                                                       
equal
    ½                          i¾                    ∙ 2 ¸
        − −1 hX                          1 X −1
                                              
                                                        
             E                 =−        Γ E         0
                                                               I (0 )−1                            (44)
         2     =1
                                 1::    2 =1       

                                                       32
Combining (40) and (44) yields  as given in the statement of the Theorem.

Computation Computation of        b  consists of two steps. In the first step, which is
                                b
nonstandard and detailed here,  is computed as the solution to (8). Here we outline
an approach to solving (8) which we have found to be computationally convenient
and very reliable in practice. This involves defining b to be the solution to a globally
concave programming problem with unrestricted domain. In the second b        is computed
                       22
as the solution to (7).
    Consider the following function
                                                 Z            µ ¶
                                                         −1    1
                              () =       +                      d                     (45)
                                      ()       1()         

with  (·) as defined in Assumption 1.5. When the propensity score takes the logit
 () = (1 + exp (−))−1 form (45) exists in closed form (see below). We implement
the logit specification in the empirical application and expect that most users will
do likewise. If a diﬀerent propensity score model is assumed, then (45) is can be
evaluated numerically.
   The first and second derivatives of  () are

                                        1                         1 ()
                            1 () =                2 () = −                           (46)
                                        ()                       ()2

so that (45) is strictly concave.
    We compute b by solving the following optimization problem

                                       1 X                    1 X
                                                                
                                                 ¡       0 ¢
             max  ()       () =          ( )  −        ( )0             (47)
                                       =1                   =1

Diﬀerentiating  () with respect to  gives an 1 +  × 1 gradient vector of

                               1 X                             1 X
                                                                 
                                          ¡       0 ¢
                   ∇  () =        1  ( )   ( ) −        ( )              (48)
                    1+×1       =1                            =1
  22
    The second step is identical to that associated with standard inverse probability weighting
(IPW). As the second step is both application specific, and typically straightforward to compute
using standard software (that accepts user-specified weights), we do not detail it here.




                                                 33
which coincides with (8) as required. The 1 +  × 1 +  Hessian matrix is

                                     1 X
                                        
                                                ¡          ¢
                        ∇  () =        2  ( )0   ( )  ( )0                      (49)
                        1+×1+       =1

This is a negative definite function of ; the problem (47) is consequently concave with
                                                                          P
a unique solution (if one exists). Existence of a solution requires that     =1  ( ) 
lie within the convex hull of the complete case subsample (this will be true in large
samples under Assumption 1.4, but should nevertheless be checked prior to compu-
tation).23
    In practice (48) will have an ‘exploding denominator’ when  ( )0  is a large
negative number. This can lead to numerical instabilities by causing the Hessian
to be ill-conditioned. We address this problem by noting that at a valid solution
P                  0b
   =1  ( ( ) ) = 1. Since Assumption 1.5 implies that  () is bounded
below by zero, this means that  ( ( )0 )  b   for all  = 1     . Letting
            0
 =  ( )  this inequality corresponds to requiring that

                                −1 ( )             = 1                             (50)

        b Let  ∗ = −1 (1); note that  ∗ → −∞ as  → ∞ suggesting that
at  = .                                       
(50) will be satisfied for most values of  in large enough samples. In small samples
(50) may be violated for some  at some iterations of the maximization procedure
(although not at a valid solution). Our approach to estimation involves replacing
                                               ∗
 () with a quadratic function when  ≤       ; this ensures that the denominator in
(48) is bounded. This will improve the condition of the Hessian with respect to 
without changing the solution Owen (2001, Chapter 12) proposes a similar procedure
in the context of empirical likelihood estimation of moment condition models.
    Specifically we replace  () in (47), (48) and (49) with
                                      (
                                                                      ∗
                                                   ()            
                          ◦ () =                          ∗ 2
                                                                                                  (51)
                                                   ∗
                                           +   + 2 (        ∗
                                                               )  ≤ 
  23
       Convex hull conditions also arise in research on empirical likelihood (e.g., Owen, 2001; pp. 85 -
87).




                                                    34
where  ,  and  are the solutions to

                                                          ∗
                                                 = 2 ( )
                                              ∗        ∗
                                      +   = 1 ( )
                                   ∗    ∗ 2          ∗
                           +   +    ( ) = 0 (  )
                                        2 

This choice of coeﬃcients ensures that ◦ () equals  (), as well as equality of first
                                 ∗
and second derivatives, at  =   
   When  () is logit our algorithm is particularly simple to implement. For  () =
exp ()  [1 + exp ()] we have

                                  () ∝  − exp (−) 

Diﬀerentiating with respect to  then gives 1 () = 1 + exp (−) and 2 () =
− exp (−)                         ³      ´
                 ∗                     1
                                                  ¡ 1 ¢
   We also have  = −1 (1) = ln 1−1    = ln −1   so that solving for  , 
and  yields
                               "       µ   ¶      ∙ µ       ¶¸2 #
                                        1       1        1
               = − ( − 1) 1 + ln          +     ln             
                                       −1      2      −1
                                     µ      ¶
                                         1
                  =  + ( − 1) ln            = − ( − 1) 
                                        −1


References
 [1] Abowd, John M., Bruno Crépon, and Francis Kramarz. (2001). “Moment estima-
     tion with attrition: an application to economic models,” Journal of the American
     Statistical Association 96 (456): 1223 - 1231.

 [2] Angrist, Joshua D. and Alan B. Krueger. (1992). “The eﬀect of age at school
     entry on educational attainment: an application of instrumental variables with
     moments from two samples,” Journal of the American Statistical Association 87
     (418): 328 - 336.

 [3] Back, Kerry and David P. Brown. (1993). “Implied probabilities in GMM esti-
     mators,” Econometrica 61 (4): 971 - 975.

                                           35
 [4] Bang, Heejung and James M. Robins. (2005). “Doubly robust estimation in miss-
     ing data and causal inference models,” Biometrics 61 (4): 962 - 972.

 [5] Busso, Matias, John DiNardo and Justin McCrary. (2009). “Finite sample prop-
     erties of semiparametric estimators of average treatment eﬀects,” Mimeo.

 [6] Cao, Weihua, Anastasios A. Tsiatis and Marie Davidian. (2009). “Improving
     eﬃciency and robustness of the doubly robust estimator for a population mean
     with incomplete data,” Biometrika 96 (3): 723 - 734.

 [7] Chen, Xiaohong. (2007). “Large sample sieve estimation of semi-nonparametric
     models,” Handbook of Econometrics 6 (B): 5549 - 5632. (J.J. Heckman & E.E.
     Leamer, Eds.). Amsterdam: North-Holland.

 [8] Chen, Xiaohong, Han Hong and Alessandro Tarozzi. (2004). “Semiparametric
     eﬃciency in GMM models of nonclassical measurement errors, missing data and
     treatment eﬀects, Mimeo.

 [9] Chen, Xiaohong, Han Hong and Alessandro Tarozzi. (2008). “Semiparametric
     eﬃciency in GMM models with auxiliary data,” Annals of Statistics 36 (2): 808
     - 843.

[10] Donald, Stephen G., Guido W. Imbens and Whitney K. Newey. (2008). “Choos-
     ing the number of moments in conditional moment restriction models,” Mimeo.

[11] Graham, Bryan S. (2011). “Eﬃciency bounds for missing data models with semi-
     parametric restrictions,” Econometrica 79 (2): 437 - 452.

[12] Hahn, Jinyong. (1998). “On the role of the propensity score in eﬃcient semi-
     parametric estimation of average treatment eﬀects,” Econometrica 66 (2): 315 -
     331.

[13] Hirano, Keisuke and Guido W. Imbens. (2001). “Estimation of causal eﬀects
     using propensity score weighting: an application to data on right heart catheter-
     ization,” Health Services and Outcomes Research 2 (3-4): 259 -278.

[14] Hirano, Keisuke, Guido W. Imbens and Geert Ridder. (2003). “Eﬃcient estima-
     tion of average treatment eﬀects using the estimated propensity score,” Econo-
     metrica 71 (4): 1161 - 1189.

                                         36
[15] Imbens, Guido. W. (1997). “One-step estimators of over-identified generalized
     method of moments models,” Review of Economic Studies 64 (3): 359 - 383.

[16] Imbens, Guido W. (2004). “Nonparametric estimation of average treatment ef-
     fects under exogeneity: a review,” Review of Economics and Statistics 86 (1): 4
     - 29.

[17] Imbens, Guido W. and Tony Lancaster. (1996). “Eﬃcient estimation and strat-
     ified sampling,” Journal of Econometrics 74 (2): 289 - 318.

[18] Johnson, William R. and Derek A. Neal (1998). “Basic skills and the black-
     white earnings gap,” The Black-White Test Score Gap: 480 - 500. (C. Jencks &
     M. Phillips, Eds.). Washington, D.C.: The Brookings Institution.

[19] Little, Roderick J. A. and Donald B. Rubin. (2002). Statistical Analysis with
     Missing Data. Hoboken, N.J.: John Wiley & Sons, Inc.

[20] Neal, Derek A. and William R. Johnson. (1996). “The role of premarket factors
     in black-white wage diﬀerences,” Journal of Political Economy 104 (5): 869 -
     895.

[21] Newey, Whitney K. (1990). “Semiparametric eﬃciency bounds,” Journal of Ap-
     plied Econometrics 5 (2): 99 - 135.

[22] Newey, Whitney K. (1994). “Series estimation of regression functionals,” Econo-
     metric Theory 10 (1): 1 - 28.

[23] Newey, Whitney K. (2002). “Stochastic Expansion for M-Estimator,” Lecture
     Note.

[24] Newey, Whitney K. and Daniel McFadden. (1994). “Large sample estimation
     and hypothesis testing,” Handbook of Econometrics 4: 2111 - 2245 (R.F. Engle
     & D.F. McFadden, Eds.). Amsterdam: North-Holland.

[25] Newey, Whitney K. and Richard J. Smith. (2004). “Higher order properties of
     GMM and generalized empirical likelihood estimators,” Econometrica 72 (1):
     219 - 255.

[26] Owen, Art. B. (2001). Empirical Likelihood. New York: Chapman & Hall/CRC.


                                        37
[27] Qin, Jing, Biao Zhang, and Denis H. Y. Leung. (2009). “Empirical likelihood
     in missing data problems,” Journal of the American Statistical Association 104
     (488): 1492 - 1503.

[28] Ridder, Geert and Robert Moﬃtt. (2007). “The econometrics of data combina-
     tion,” Handbook of Econometrics 6 (2): 5469 - 5547 (J.J. Heckman & E Leamer,
     Eds.). New York: North-Holland.

[29] Robins, James M., Andrea Rotnitzky and Lue Ping Zhao. (1994). “Estimation
     of regression coeﬃcients when some regressors are not always observed,”.Journal
     of the American Statistical Association 89 (427): 846 - 866.

[30] Robins, James, Mariela Sued, Quanhong Lei-Gomez and Andrea Rotnitzky.
     (2007). “Comment: performance of double-robust estimators when “inverse prob-
     ability” weights are highly variable,” Statistical Science 22 (4): 544 - 559.

[31] Tan, Zhiqiang. (2010). “Bounded, eﬃcient and doubly robust estimation with
     inverse weighting,” Biometrika 97 (3): 661 - 682.

[32] Tsiatis, Anastasios A. (2006). Semiparametric Theory and Missing Data. New
     York: Springer.

[33] Wooldridge, Jeﬀrey M. (2001). “Asymptotic properties of weighted M-estimators
     for standard stratified samples,” Econometric Theory 17 (2): 451 - 470.

[34] Wooldridge, Jeﬀrey M. (2007). “Inverse probability weighted estimation for gen-
     eral missing data problems,” Journal of Econometrics 141 (2): 1281 - 1301.




                                        38
              Table 1: Weight functions for diﬀerent AIPW estimators

                                                                            Locally      Doubly
 AIPW Estimator                                       ()       ()
                                                                           Eﬃcient?      Robust?
                                                                   
 Robins, Rotnitzky, and Zhao (1994)                   ()        ()
                                                                             Yes           Yes
 Newey (1994)                                          1             1       Yes           No
                                                     1− ()      
 Cao, Tsiatis and Davidian (2009)                      ()       ()
                                                                             Yes           Yes
                                                                   
 Hirano and Imbens (2001) / Wooldridge (2007)           1          ()
                                                                             Yes           Yes




Table 2: Replication of Table 14-1 of Johnson and Neal (1998) and unweighted com-
plete case analysis with pre-adolescent test score
                            (1)             (2)              (3)                 (4)
                                                    −             − 
                         −00458         −00466          −00947             −00940
    YearOfBirth
                        (00151)∗∗      (00147)∗∗        (00464)∗          (00470)∗
                         −02776         −01079          −02708             −01606
    Black
                        (00261)∗∗      (00284)∗∗       (00833)∗∗          (00900)+
                                          01645
    AFQT                     −                                   −                 −
                                        (00146)∗∗
                                                                               01011
    EarlyTest                −              −                    −
                                                                             (00539)+
    2                     0062          0183                 0068          0120
                          1 371         1 371                 144             144

NOTES: Estimation samples are as described in the main text. The 1979 baseline sampling
weights are used in place of the empirical measure when computing all estimates. A ‘∗∗ ’,
‘∗ ’ and ‘+ ’ denotes that a point estimate is significantly diﬀerent from zero at the 1, 5
and 10 percent levels. Standard errors (in parentheses) allow for arbitrary patterns of
heteroscedasticity and dependence across units residing in the same household at baseline.




                                            39
       Table 3: IPT, IPW and AIPW estimates of the Black-White wage gap conditional on preadolescent skills

                           (1)              (2)             (3)            (4)                (5)                 (6)              (7)
                       −                                                                        
 YearOfBirth
                        −00940          −00537         −00968        −00533            −00353             −00535          −00543
                       (00470)∗        (00162)∗∗      (00302)∗∗     (00165)∗∗          (00528)           (00166)∗∗       (00167)∗∗
 Black
                        −01606          −01837         −02126        −01836            −00797             −01871          −01837
                       (00900)+        (00356)∗∗      (00791)∗      (00418)∗∗          (01518)           (00392)∗∗       (00390)∗∗
                         01011           01112          01220         01049             00956              01072           01144
 EarlyTest
                       (00539)+        (00296)∗∗      (00362)∗∗     (00358)∗∗          (00360)           (00346)∗∗       (00344)∗∗

Notes: Samples are as described in the main text. The 1979 baseline sampling weights are used when computing all estimates.
A ‘∗∗ ’, ‘∗ ’ and ‘+ ’ denotes that a coeﬃcient is significantly diﬀerent from zero at the 1, 5 and 10 percent levels. Standard errors
(in parentheses) allow for arbitrary patterns of heteroscedasticity and dependence across units residing in the same household at
baseline.




                                                                 40
