                                NBER WORKING PAPER SERIES




                KNOWLEDGE GROWTH AND THE ALLOCATION OF TIME

                                         Robert E. Lucas, Jr.
                                           Benjamin Moll

                                        Working Paper 17495
                                http://www.nber.org/papers/w17495


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                     October 2011




We thank Roland Benabou, Paco Buera, Olivier Gueant, Gene Grossman, Boyan Jovanovic, Jean-Michel
Lasry, Stephen Morris, Ezra Oberfield, Nancy Stokey, and seminar participants at Minnesota, Notre
Dame, Princeton, Penn State, NYU, Washington, the Minneapolis Fed, the Chicago Fed, the 2011
SED and the NBER Summer Institute for helpful suggestions and criticism. The views expressed herein
are those of the authors and do not necessarily reflect the views of the National Bureau of Economic
Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2011 by Robert E. Lucas, Jr. and Benjamin Moll. All rights reserved. Short sections of text, not
to exceed two paragraphs, may be quoted without explicit permission provided that full credit, including
© notice, is given to the source.
Knowledge Growth and the Allocation of Time
Robert E. Lucas, Jr. and Benjamin Moll
NBER Working Paper No. 17495
October 2011
JEL No. O0,O15

                                            ABSTRACT

We analyze a model economy with many agents, each with a different productivity level. Agents divide
their time between two activities: producing goods with the production-related knowledge they already
have, and interacting with others in search of new, productivity-increasing ideas. These choices jointly
determine the economy’s current production level and its rate of learning and real growth. Individuals’
time allocation decisions depend on the knowledge distribution because the productivity levels of others
determine their own chances of improving their productivities through search. The time allocations
of everyone in the economy in turn determine the evolution of its knowledge distribution. We construct
the balanced growth path for this economy, thereby obtaining a theory of endogenous growth that
captures in a tractable way the social nature of knowledge creation. We also study the allocation chosen
by an idealized planner who takes into account and internalizes the external benefits of search, and
tax structures that implement an optimal solution. Finally, we provide two examples of alternative
learning technologies, as concrete illustrations of other directions that might be pursued.


Robert E. Lucas, Jr.
Department of Economics
The University of Chicago
1126 East 59th Street
Chicago, IL 60637
and NBER
relucas@midway.uchicago.edu

Benjamin Moll
106 Fisher Hall Department of Economics
Princeton University
Princeton, NJ 08544
moll@princeton.edu
1         Introduction
We analyze a new model of endogenous growth, driven by sustained improvements in individual
knowledge. Agents in this economy divide their time between two activities: producing goods
with the production-related knowledge they already have, and interacting with others in search
of new, productivity-increasing ideas.1 These choices jointly determine the economy’s current
production level and its rate of learning and real growth.
        The production technology in this model is kept very simple: Each person produces at a rate
that is the product of his personal productivity level and the fraction of time that he chooses
to spend producing goods. There are no factors of production other than labor and there
are no complementarities between workers. There are no markets, no prices, and no public
or private property other than individuals’ knowledge—their human capital. The learning
technology involves random meetings: Each person meets others at a rate that depends on
the fraction of time he spends in search. For us, a meeting means simply an observation of
someone else’s productivity. If that productivity is higher than his own, he adopts it in place
of the productivity he came in with. Everyone’s productivity level is simply the maximum of
the productivities of all the people he has ever met. To ensure that the growth generated by
this process can be sustained, we add an assumption to the effect that the stock of good ideas
waiting to be discovered is inexhaustible.2
        The state of the economy is completely described by the distribution of productivity levels.
An individual’s time allocation decisions will depend on this distribution because the produc-
tivity levels of others determine his own chances of improving his productivity through search.
Individuals’ time allocation decisions in turn determine learning rates and thus the evolution
of the productivity distribution. One of the two equilibrium conditions of the model is the
Bellman equation for the time allocation problem of a single atomistic agent who takes the
productivity distribution as given. The second condition is a law of motion for the productivity
distribution, given the policy functions of individual agents.
        These two equations take the form of partial differential equations, with time and produc-
tivity levels as the two independent variables. We motivate these two equations in the next
section. Then we focus on a particular solution of these equations, a balanced growth path,
    1
     Our tradeoffs at an individual level will be taken with little change from the models of on-the-job learning
of Ben-Porath (1967), Heckman (1976), and Rosen (1976).
   2
     Jovanovic and Rob (1989) describe a similar process of adoption or imitation of ideas. In their model,
however, the knowledge distribution converges to a steady state whereas our framework features sustained
growth. For more recent contributions that are similar in spirit to ours, see Bental and Peled (1996) and
particularly Perla and Tonetti (2011). A different approach to a similar set of questions as in our paper is
pursued by Fogli and Veldkamp (2011) who model the diffusion of knowledge among individuals in a network.


                                                       2
along which production grows at a constant rate and the distribution of relative productivities
remains constant. In Section 3 we discuss the properties of this balanced growth path and
develop an algorithm to calculate it, given parameters that describe the production and search
technologies.
        There is an evident external effect in this decentralized equilibrium. The private return
to knowledge acquisition motivates individual decisions that generate sustained productivity
growth but an individual agent does not take into account the fact that increases in his own
knowledge enrich the learning environment for the people around him. The social return to
search exceeds the private return, raising the possibility that taxes and subsidies can equate
private and social returns and improve both growth rates and welfare.3 In Section 4 we for-
mulate a planning problem, in which the planner directs the time allocations of each of the
continuum of individual agents in the economy. We show how this problem can be broken into
individual Bellman equations where the value function for each person is his marginal social
value under an optimal plan. We study the implied balanced growth path and compare the
implied policy function and distribution of relative productivities to those implied by the de-
centralized problem studied in Section 3. In Section 5 we consider the implementation of the
planning solution through the use of a Pigovian system of taxes and subsidies.
        All of the analysis in Sections 3-5 is based on a single, specific model of the search/learning
process. It turns out that the algorithm we develop for this model is quite easily adapted to the
analysis of a wide variety of other learning technologies. In Section 6 we describe two of these
alternative technologies and consider their implications and economic interpretations. Section
7 concludes the paper.


2         A Model Economy
There is a constant population of infinitely-lived agents. We identify each person at each date
as a realization of a draw z̃ from a cost distribution, described by its cdf

                                      F (z, t) = Pr{z̃ ≤ z at date t},

or equivalently by its density function f (z, t). This function f (·, t) fully describes the state of
the economy at t. A person with cost draw z̃ can produce ã = z̃ −θ units of a single consumption
good, where θ ∈ (0, 1).
    3
    In this respect the model is a direct descendant of Arrow (1962), Romer (1986), and Grossman and Helpman
(1991).


                                                     3
      We will formulate the equilibrium and planning problems of this economy in terms of this
cost distribution but of course we could instead do this in terms of the productivity distribution
G(a, t):
                     G(a, t) = Pr{z̃ −θ ≤ a} = Pr{z̃ ≥ a−1/θ } = 1 − F (a−1/θ , t).

For some purposes the economic interpretations seem clearer in this form, but algorithmically
the cost formulation is more convenient. We will find it useful to use both of them on occasion.
Here we continue with the cost formulation.
      Every person has one unit of labor per year. He allocates his time between a fraction
1 − s(z, t) devoted to goods production and s(z, t) devoted to improving his production-related
knowledge. His goods production is

                                                     [1 − s(z, t)] z −θ .                            (1)

Total production in the economy is
                                                 Z   ∞
                                   Y (t) =               [1 − s(z, t)] z −θ f (z, t)dz.
                                                 0


Individual preferences are
                                   Z    ∞                                                    
                                             −ρ(τ −t)                             −θ
                   V (z, t) = Et             e            [1 − s(z̃(τ ), τ )] z̃(τ ) dτ z(t) = z .   (2)
                                     t


      We model the evolution of the distribution f (z, t) as a process of individuals meeting others
from the same economy, comparing ideas, improving their own productivity. The details of
this meeting and learning process are as follows.4 A person z allocating the fraction s(z, t) to
learning observes the cost z ′ of one other person with probability α [s(z, t)] ∆ over an interval
(t, t + ∆) , where α is a given function. He compares his own cost level z with the cost z ′ of
the person he meets, and leaves the meeting with the best of the two costs, min(z, z ′ ). (These
meetings are not assumed to be symmetric: z learns from and perhaps imitates z ′ but z ′ does
not learn from z and in fact he may not be searching himself at all.)
      We assume that everyone in the economy behaves in this way, though the search effort
s(z, t) varies over time and across individuals at a point in time. Thinking of F (z, t) as the
fraction of people with cost below z at date t, this behavior results in a law of motion for F as
  4
   The process assumed here is an adaptation of ideas in Kortum (1997), Eaton and Kortum (1999), Alvarez,
Buera and Lucas (2008), and Lucas (2009).




                                                               4
follows:

       1 − F (z, t + ∆) = Pr{cost above z at t and no lower cost found in [t, t + ∆)}
                          Z ∞
                        =      f (y, t) Pr{no lower cost found in [t, t + ∆)}dy
                          Zz ∞
                        =      f (y, t) [1 − α(s(y, t))∆ + α(s(y, t))∆ (1 − F (z, t))] dy
                           z
                                                  Z ∞
                        = 1 − F (z, t) − F (z, t)      α(s(y, t))f (y, t)∆dy.
                                                                     z


Then                                                                             ∞
                     F (z, t + ∆) − F (z, t)
                                                                         Z
                                             = F (z, t)                              α(s(y, t))f (y, t)dy
                               ∆                                             z

and letting ∆ → 0 gives
                                                             ∞
                            ∂F (z, t)
                                                       Z
                                      = F (z, t)                 α(s(y, t))f (y, t)dy.
                              ∂t                         z


Differentiating with respect to z we obtain
                                                 z                                             ∞
           ∂f (z, t)
                                             Z                                            Z
                     = −α(s(z, t))f (z, t)           f (y, t)dy + f (z, t)                         α(s(y, t))f (y, t)dy.   (3)
              ∂t                             0                                             z


   Equation (3) can also be motivated by considering the evolution of the density at z directly,
as follows. Some agents who have cost z will adopt a lower cost y ≤ z and so there will be an
outflow of these agents. Other agents who have cost y ≥ z will adopt cost z and there will be
an inflow of these agents. Hence we can write

                              ∂f (z, t)   ∂f (z, t)       ∂f (z, t)
                                        =               +              .
                                 ∂t          ∂t     out      ∂t     in

Consider first the outflow. The f (z, t) agents at z have meetings at the rate α(s(z, t))f (z, t).
A fraction F (z, t) of these draws satisfy y < z and these agents leave z. Hence

                             ∂f (z, t)
                                           = −α(s(z, t))F (z, t)f (z, t).
                                ∂t     out

Next, consider the inflow. Agents with cost y ≥ z have meetings at the rate α(s(y, t))f (y, t).
Each of these meetings yields a draw z with probability f (z, t). Hence
                                                                 ∞
                           ∂f (z, t)
                                                        Z
                                        = f (z, t)                   α(s(y, t))f (y, t)dy.
                              ∂t     in                      z



                                                           5
Combining, we obtain (3). This type of equation is known in physics as a Boltzmann equation.
       Now consider the behavior of a single agent with current cost z, acting in an environment
characterized by a given density path f (z, t), all z, t ≥ 0. The agent wants to choose a policy
s(z, t) so as to maximize the discounted, expected value of his earnings stream, expression (2).
The Bellman equation for this problem is5
                                                                              z                                
                                                      ∂V (z, t)
                                                                         Z
                                               −θ
          ρV (z, t) = max           (1 − s)z        +           + α(s)             [V (y, t) − V (z, t)]f (y, t)dy .   (4)
                      s∈[0,1]                           ∂t                 0


The system (3) and (4) is an instance of what Lasry and Lions (2007) have called a “mean-field
game.” We summarize our discussion of the economy in the
       Definition: An equilibrium, given the initial distribution f (z, 0), is a triple (f, s, V ) of
functions on R2+ such that (i) given s, f satisfies (3) for all (z, t), (ii) given f , V satisfies (4),
and (iii) s(z, t) attains the maximum for all (z, t) .
       A complete analysis of this economy would require the ability to calculate solutions for all
initial distributions. This would be an economically useful project to carry out, but we limit
ourselves in this paper to the analysis of a set of particular solutions on which the growth rate
and the distribution of relative costs are both constant over time.
       Definition: A balanced growth path (BGP) is a number γ and a triple of functions (φ, σ, v)
on R+ such that
                                                    f (z, t) = eγt φ(zeγt ),                                           (5)

                                                    V (z, t) = eθγt v(zeγt ),                                          (6)

and
                                                      s(z, t) = σ(zeγt )                                               (7)

for all (z, t) , and (f, s, V ) is an equilibrium with the initial condition f (z, 0) = φ (z) .
       Intuitively, a BGP is simply a path for the distribution function along which all cost quantiles
shrink at the same rate γ (and hence all quantiles of productivity, z −θ , grow at rate θγ). That
is, on a BGP the cost cdf satisfies F (z, t) = Φ(zeγt ) and therefore the qth quantile, zq (t),
satisfies Φ(zq (t)eγt ) = q or
                                                     zq (t) = e−γt Φ−1 (q).

That the value and policy functions take the forms in (6) and (7) is then immediately implied.
       The analysis of balanced growth is facilitated by restating (3) and (4) in terms of relative
   5
    See Appendix A for a derivation of this continuous time Bellman equation as a limit of the corresponding
discrete time version.



                                                               6
costs x = zeγt . From (5), we have

                                ∂f (z, t)
                                          = γeγt φ(zeγt ) + eγt φ′ (zeγt )γzeγt
                                   ∂t
which from (3) and (7) implies
                                           Z        ∞                                       Z   x
                        ′
             φ(x)γ + φ (x)γx = φ(x)                     α(σ(y))φ(y)dy − α(σ(x))φ(x)                 φ(y)dy.    (8)
                                                x                                           0


Evaluating at x = 0, we have
                                                            Z       ∞
                                    φ(0)γ = φ(0)                        α(σ(y))φ(y)dy.                         (9)
                                                                0


The Bellman equation (4) becomes
                                                   Z x                      
                            ′               −θ
      (ρ − θγ) v(x) − v (x)γx = max (1 − σ)x + α(σ)     [v(y) − v(x)]φ (y) dy .                               (10)
                                      σ∈[0,1]                                     0


Total production on a balanced growth path is
                                                      Z     ∞
                                                θγt
                                  Y (t) = e                     [1 − σ(x)]x−θ φ(x)dx,                         (11)
                                                        0


provided the integral converges. Hence total production grows at the rate θγ.
   If all agents in this economy had the same cost level z̄, say, then no one would have any
motive to search and everyone would simply produce z̄ −θ forever. Such a trivial equilibrium
could be called a BGP with γ = 0, but our interest is in BGPs with γ > 0. To ensure that this
is a possibility we will need to add more structure. For this purpose, we add the assumption
that f (0, 0) ≡ limz→0 f (z, 0) > 0, implying that on a BGP φ(0) > 0. This condition is sufficient
to ensure that sustained growth at some rate γ > 0 is possible. Its interpretation is that the
stock of good ideas waiting to be discovered is inexhaustible. The next result shows that this
restriction is equivalent to the assumption that the initial distribution of productivity has a
Pareto tail with tail parameter 1/θ.
   Lemma 1: The initial cdf of productivity, G(a, 0) say, has a Pareto tail,

                                    1 − G(a, 0)
                                lim             =λ                        for some λ > 0,
                                a→∞    a−1/θ

if and only if z = a−1/θ satisfies f (0, 0) = λ > 0.



                                                                    7
      Proof: We have that G(a, 0) = 1 − F (a−1/θ , 0) and therefore

                      1 − G(a, 0)       F (a−1/θ , 0)       F (z, 0)
                  lim     −1/θ
                                  = lim     −1/θ
                                                      = lim          = f (0, 0) = λ.
                 a→∞     a          a→∞    a            z→0    z

        Thus requiring that f (0, 0) > 0 is the same thing as assuming a fat tailed initial pro-
  ductivity distribution and the parameter θ has the interpretation as the inverse of the tail
  parameter.
      Under the restriction f (0, 0) > 0, φ(0) > 0 and (9) imply that γ will be an average of the
  search intensities α at different cost levels x:
                                             Z       ∞
                                        γ=               α(σ(x))φ(x)dx.                              (12)
                                                 0


        We also assume that the learning technology function α : [0, 1] → R+ satisfies

                                α(s) ≥ 0, α′ (s) > 0, α′′ (s) < 0,        all s,

  and
                                  α(1) > 0, α′ (1) > 0, lim α′ (s) = ∞.                              (13)
                                                               s→0

  The discount rate ρ satisfies
                                                     ρ ≥ θα(1).                                      (14)

  This will ensure that the preferences in (2) are well-defined.


  3      Calculation and Analysis of Balanced Growth Paths
  In this section we describe the algorithm we use to calculate BGPs, given a specified function
  α, values for the parameters ρ and θ, and a value λ = φ(0) for the density at x = 0.
      We begin an iteration with initial guesses (φ0 , γ0) for (φ, γ) . Then for n = 0, 1, 2, ... we
  follow

Step 1. Given (φn , γn ), use (10) to calculate vn and σn .

Step 2. Given σn , solve (8) and (12) jointly to generate a new guess (φn+1 , γn+1 ).

      When these steps are completed, (φn+1 , γn+1) and (vn , σn ) have been calculated. When
  (φn+1 , γn+1) is close enough to (φn , γn ), we call (φn , γn , vn , σn ) a BGP equilibrium. Steps 1 and
  2 themselves involve iterative procedures which we describe in turn.

                                                           8
          For step 1, consider the Bellman equation (10). Define the function
                                                       Z    x
                                              S(x) =            [v(y) − v(x)]φ (y) dy.
                                                       0


   Then the first order condition for σ is

                                      S(x)α′ (σ) ≥ x−θ            with equality if σ < 1.                 (15)

          Under our assumptions on α, this condition can be solved for a unique σ(x) ∈ (0, 1], that
   satisfies σ ′ (x) > 0 as long as σ(x) < 1. There will be a unique value x̂ that satisfies

                                                                        x̂−θ
                                                           α′ (1) =           .
                                                                        S(x̂)

   Agents with relative costs x below x̂ will divide their time between producing and searching;
   agents at or above x̂ will be searching full time. For x ≥ x̂, v(x) is constant at v (x̂) and thus
   S(x) is constant at S(x̂). The value function v will satisfy v(x) > 0, v ′ (x) ≤ 0, limx→0 v(x) = ∞
   and
                                                           lim v ′ (x) = 0.                               (16)
                                                       x→∞

   The last condition motivates a boundary condition for the integro-differential equation (10).
   All these conclusions hold for any density φ and γ > 0.
          The computation of (vn , σn ) given (φn , γn ), follows itself an iterative procedure. We begin
   an iteration with an initial guess vn0 for vn .6 Then for j = 0, 1, 2, ... we follow

Step 1a. Given vnj (x), compute Snj (x) from (3) and σnj (x) from (15).

Step 1b. Given σnj (x), solve (10) together with the boundary condition (16) for vnj+1 (x). To carry
            out these calculations, we applied a finite difference method on a grid (x1 , x2 , ..., xI ) of I
            values. Details are provided in Appendix C.1.

          When vnj+1 and vnj are sufficiently close, we set (vn , σn ) = (vnj , σnj ). This completes step 1.
          For step 2, we express (8) as

                                  φ(x)γ + φ′ (x)γx = φ(x)ψ(x) − α(σ(x))φ(x)Φ(x)                           (17)
      6
          We use vn0 (x) = x−θ /(ρ − θγn ).




                                                                    9
where ψ and Φ are defined by
                             Z      ∞                                        Z       x
                    ψ(x) =              α(σ(y))φ(y)dy          and Φ(x) =                φ(y)dy .
                                x                                                0


Then

                                              ψ ′ (x) = −α(σ(x))φ(x)                                (18)
                                              Φ′ (x) = φ(x)                                         (19)

We further have φ(0) = λ, Φ(0) = 0. Finally, equation (12) can be written as γ = ψ(0). The
computation of (φn+1, γn+1 ) given (vn , σn ) again follows an iterative procedure. We begin an
                                 0
iteration with an initial guess γn+1 for γn+1 . Then for j = 0, 1, 2, ... we follow
                   j
   Step 2a. Given γn+1 and σn , solve for functions φjn+1(x), Φjn+1 (x), ψn+1
                                                                          j
                                                                              (x) by solving the
system of ODEs (17) to (19) with boundary conditions

                         φjn+1 (0) = λ,            Φjn+1 (0) = 0,    j
                                                                    ψn+1        j
                                                                         (0) = γn+1 .

We again use a finite difference method with details provided in Appendix C.3.
   Step 2b. Given φjn+1 , γn+1
                           j
                               and σn , update
                                         Z    ∞
                          j+1
                         γn+1    =ξ               α(σn (x))φjn+1 (x)dx + (1 − ξ)γn+1
                                                                                 j

                                          0


where ξ ∈ (0, 1] is a relaxation parameter.
         j+1      j
   When γn+1 and γn+1 are sufficiently close, we set (φn , γn ) = (φjn , γnj ). This completes step
2. For the initial guess we use an exponential with parameter λ, φ0 (x) = λ exp(−λx), and a
growth rate γ0 = α(1). For the function α we used

                                              α(s) = ksη ,     η ∈ (0, 1).

The computational procedure is outlined in more detail in the Appendix C.
   The mathematics of each of the steps just described, the solution to a Bellman equation, the
solution to an ordinary differential equation with given boundary questions, and the solution
to a fixed point problem in the growth parameter γ, are all well understood. We have not
been able to establish the existence or uniqueness of a BGP with γ > 0, but the algorithm we
have described calculates solutions to a high degree of accuracy for the exponential initial cost
density that we use as an initial guess and a variety of reasonable parameter values.

                                                          10
       Figures 1-4 report the results of one simulation of this model, and provide some information
on the sensitivity of the policy function to changes in parameters. Figure 5 provides some
typical sample paths, to illustrate the kind of changes over time an individual’s choices and
earnings will exhibit along the BGP we have computed. The figures are intended to illustrate
the qualitative properties of the model, and the calibration of parameters will depend on the
application and available data. But there is a good deal of closely related research that uses
time series on aggregate growth rates and cross-section data on individual agents to estimate
parameters related to our parameters θ and η and it will be useful to describe how the numbers
we use are related to this evidence.
       The growth rate of per capita GDP in the United States and other OECD countries has
fluctuated around two percent at least since World War II. This fact supports the application
of models that have a BGP equilibrium and suggest the value .02 for the product θγ. The pa-
rameter θ has interpretations both as a log variance parameter or as a tail parameter. Thinking
of agents in the model as individual workers as we have done, suggests using the variance of log
earnings to estimate θ. Lucas (2009), using a model with constant search effort, finds θ = 0.5
to be consistent with U.S. census earnings data. Gabaix (2009), Luttmer (forthcoming), and
others who identify agents (in our sense) with firms estimates θ = 1 (Zipf’s Law)as a good tail
parameter based on the size distribution of firms. Eaton and Kortum (2002) associate costs of
any specific good with an entire country, and obtain estimates of θ less than one, using inter-
national relative prices. Here we use the value θ = 0.5; results for θ = 0.7 are also shown in
Figure 1. Then given a choice of θ and a value for the parameter η, we can choose the constant
k so that γ = (.02)/θ.
       None of the studies cited above provides evidence on η, which measures the elasticity of
search intensity with respect to the time spent searching. To obtain information on η we need
evidence on the technology of on-the-job human capital accumulation, such as that used by
Ben-Porath (1967), Rosen (1976), Heckman (1976) and Hause (1980).7 Rosen (1976) used a
parameter similar to our η. He assigned the value η = 0.5, in part to get a functional form that
was easy to work with. We used η = 0.3. Perla and Tonetti (2011) use a model similar to ours
in which α(s) is linear in s, so that workers work full time above a productivity threshold and
search full time otherwise. Our model approaches this situation as η = 1, although the Perla
and Tonetti model is not a special case of ours. See Figure 4 for experiments at η values 0.3,
0.6, and 0.9.
   7
    Ben-Porath and Rosen suggested that any particular human capital path could be interpreted as a property
of an occupation, in which case one could view a person’s time allocation choices as implied by an initial, one-
time occupational choice. This appealing interpretation is open to us as well, as long as the path is interpreted
as a productivity-contingent stochastic process.


                                                       11
   Figure 1 plots the equilibrium time allocation function, σ(x), against relative productivity
levels, x−θ for the two θ values 0.5 and 0.7. The units on the productivity axis are arbitrary.
We normalized productivity by dividing by median productivity for each value of θ. A higher
θ value (higher variance, fatter tail) induces a higher return to search. At either θ value the
least productive people search full time; the most productive work almost full time.


                                         1

                                        0.9                                       θ    .5       .7
                                        0.8                                       γ   .04      .055
                                                                                  θ γ .02      .038
                Time Allocation, σ(x)




                                        0.7

                                        0.6

                                        0.5

                                        0.4
                                               θ = 0.5                     θ = 0.7
                                        0.3

                                        0.2

                                        0.1

                                         0
                                         0.2      0.4    0.6      0.8      1      1.2     1.4   1.6   1.8
                                                                              −θ
                                                               Productivity, x , rel. to Median


              Figure 1: Optimal Time Allocation, σ(x), for θ = 0.5 and θ = 0.7

   Figure 2 plots the productivity density for θ = 0.5, superimposed on a plot of a Pareto
density with tail parameter 1/θ = 2. The two curves coincide for large productivity levels.
Again, units are relative to the median value under the equilibrium density.
   Figure 3 plots two equilibrium Lorenz curves for the same case θ = 0.5. The curve furthest
from the diagonal (the one with the most inequality) plots the fraction of current production
(1 − σ(x))x−θ attributed to workers with productivity less than x−θ . This is the standard
income flow Lorenz curve. The other curve, the one with less inequality, plots the fraction
of total discounted expected earnings v(x) accounted for by people with current productivity
less than x−θ . Here v(x) is the value function calculated in our algorithm. This value Lorenz
curve takes into account the effects of mobility along with the effect of current productivity.
In dynamic problems such as the one we study, it will be more informative to examine present
value rather than flow Lorenz curves.
   Figure 4 plots the time allocation functions for three η values with θ set at 0.5. The η = 0.3
curve coincides with the θ = 0.5 curve in Figure 1.

                                                                           12
0.06                     Solid curve: calculated density

                         Dashed curve: Pareto Distribution with Parameter 1/θ
0.05


0.04


0.03


0.02


0.01


  0
   0               1            2            3           4             5         6
                             Productivity, x−θ, rel. to Median


           Figure 2: Productivity Density for θ = 0.5




   1
                 Earnings Lorenz Curve
 0.9             Value Lorenz Curve

 0.8

 0.7

 0.6

 0.5

 0.4

 0.3

 0.2

 0.1

   0
       0   0.1         0.2    0.3    0.4    0.5     0.6    0.7   0.8       0.9   1




Figure 3: Earnings and Value Lorenz Curves for θ = 0.5



                                           13
                                          1

                                         0.9    η = 0.6
                                         0.8

                                         0.7                         η = 0.9
                 Time Allocation, σ(x)
                                         0.6

                                         0.5

                                         0.4

                                         0.3
                                                       η = 0.3
                                         0.2

                                         0.1

                                          0
                                          0.2    0.4        0.6        0.8          1       1.2   1.4
                                                                          −θ
                                                           Productivity, x , rel. to Median


                                  Figure 4: Optimal Time Allocation, for various η values.

   Figure 5 shows various aspects of two randomly generated sample paths, which we call
stochastic careers. Agents in our model are infinitely-lived. A particular productivity sam-
ple path will never decrease—knowledge in our model is never lost—but on a BGP relative
productivities x−θ will wander forever with long run averages described by the cdf Φ(x). This
means, for example, that every sample path will be in the interval [x̂, ∞) for a fraction 1 − Φ(x̂)
of his career, where x̂−θ is the productivity level (defined in Section 3) below which it is not
worthwhile to work. He will return to [x̂, ∞) infinitely often. (We can make the same statement
about any x value but x̂ is chosen here for a reason.) We can get a good sense of an individual
career by thinking of each return to [x̂, ∞) as a death or retirement, where the departing worker
is replaced by a new potential worker who begins with some productivity x−θ    −θ
                                                                         0 ≤ x̂ . Like a
school child, this entrant starts with some work-relevant knowledge and can begin to acquire
more right away, but it may be some time before his knowledge level has a market value. In the
same way, some older workers, even those with successful careers in their past, will find that
the market value of their accumulated knowledge has fallen to zero, not because they forget
what they once knew but because the number of others who know more has grown.




                                                                       14
                                                   (a)                                                                                           (b)
                                9                                                                                    3.5




                                                                                −θ γ t
                                8
                                                                                                                              3




                                                                                   Productivity rel. to Trend, z e
                                                                                 −θ
                                7
                                                                                                                     2.5
      −θ




                                6
              Productivity, z




                                5                                                                                             2

                                4                                                                                    1.5

                                3
                                                                                                                              1
                                2
                                                                                                                     0.5
                                1

                                0                                                                                             0
                                    0   20   40           60   80    100                                                          0   20   40           60   80   100
                                                  Years                                                                                         Years


                                                   (c)                                                                                           (d)
                                1                                                                                             9

                          0.9                                                                                                 8
                                                                                           −θ




                          0.8
Time Allocation, s(z,t)




                                                                                                                              7
                                                                                                      Earnings, (1−s(z,t))z




                          0.7
                                                                                                                              6
                          0.6
                                                                                                                              5
                          0.5
                                                                                                                              4
                          0.4
                                                                                                                              3
                          0.3

                          0.2                                                                                                 2

                          0.1                                                                                                 1

                                0                                                                                             0
                                    0   20   40           60   80    100                                                          0   20   40           60   80   100
                                                  Years                                                                                         Years




                                                         Figure 5: Two Stochastic Careers.




                                                                           15
4      An Optimally Planned Economy
Neither the equilibrium conditions (3) and (4) for the decentralized economy nor their BGP
counterparts describe an economically efficient allocation. Each agent allocates his time to
maximize his own present value, but assigns no value to the benefits that increasing his knowl-
edge will have for others. Yet we are studying an economy where learning from others is the
sole engine of technological change.
    In this section, we ask how a hypothetical, benificent planner would allocate resources.
In our model economy, such a planner’s instruments are the time allocations of agents at
different cost levels and his objective is to maximize the expected value, discounted at ρ, of
total production. The state variable for this problem is the density f (z, t): a point in an infinite
dimensional space. We denote the value function, which maps a space of densities into R+ , by
W. The problem is then to choose a function s : R2+ → [0, 1] to solve
                                             Z   ∞                   Z     ∞
                                                     −ρ(τ −t)
                    W [f (z, t)] = max               e                         [1 − s(z, τ )] z −θ f (z, τ )dzdτ
                                    s(·,·)   t                         0


subject to the law of motion for f :
                                                             z                                   ∞
            ∂f (z, τ )
                                                     Z                                      Z
                       = −α(s(z, τ ))f (z, τ )                   f (y, τ )dy + f (z, τ )             α(s(y, τ ))f (y, τ )dy.   (20)
               ∂τ                                        0                                   z


and with f (z, t) given.
    Instead of looking at the planner’s Bellman equation directly, it turns out to be more
convenient to work with the marginal value to the planner of one type z individual, which we
denote by w(z, t). This marginal value is more formally defined in Appendix B but the idea is
as follows. First, define by w̃(z, f ) the marginal value of one type z individual if the distribution
is any function f :
                                                                          δW (f )
                                                   w̃(z, f ) ≡                    .
                                                                           δf (z)
Here δ/δf (z) is the “functional derivative” of the planner’s objective with respect to f at point
z, the analogue of the partial derivative ∂W (f)/∂fi for the case where z is discrete and hence
the distribution f takes values in Rn . See Appendix B.1 for a rigorous definition of such a
derivative. Note that the function w̃(z, f ) is defined over the entire state space, the space of
all possible density functions f .
    Now we define w(z, t) as the marginal value along the optimal trajectory of the distribution,
f (z, t):
                                                 w(z, t) ≡ w̃(z, f (z, t)),

                                                                     16
thereby reducing the planner’s problem from an infinite-dimensional to a two dimensional prob-
lem. The logic is the familiar variational argument: If a plan is optimal, it cannot be improved
by telling any individual at any time to deviate from it.

Proposition 1 The marginal value to the planner of one type z individual, w(z, t), satisfies
the Bellman equation
                                                         Z z                                
                                  −θ     ∂w(z, t)
      ρw(z, t) = max (1 − s)z +                    + α(s)      [w(y, t) − w(z, t)]f (y, t)dy
                 s∈[0,1]                    ∂t              0
                           Z ∞                                                                   (21)
                         −     α(s(y, t)) [w(y, t) − w(z, t)] f (y, t)dy.
                              z


   This result is intuitive. It states that the flow value ρw(z, t) contributed by one type z
individual is a sum of three terms. The first term is simply the output produced by this
individual. The second term is the expected value from improvements in type z’s future cost
to some y < z. We refer to this term as the “internal benefit from search”: It takes the same
form here as in the problem of an individual stated in (4), with private continuation values
replaced by the planner’s “social” values. Finally, the third term is the expected value from
improvements in the cost of other types y > z to z in case they should meet z. It is only in this
term, which we refer to as the “external benefit from search,” that the planning problem differs
from the individual optimization problem in the decentralized equilibrium. That is, individuals
internalize the benefit from search to themselves, but not the benefit to others.
   The planner’s optimal choice of search intensity satisfies
                                                   Z   z
                              −θ       ′
                          z        = α (s(z, t))           [w(y, t) − w(z, t)]f (y, t)dy.        (22)
                                                   0


The planner trades off costs and benefits from changing individual search intensities, s(z, t).
Increasing s(z, t) has three effects. First, production decreases by z −θ . Second, the outflow of
people at z increases by α′ (s(z, t)), corresponding to a loss
                                                                        Z   z
                                               ′
                                      −α (s(z, t))w(z, t)                       f (y, t)dy.
                                                                        0


Third, the inflow of people into y < z increases by α′ (s(z, t)). This corresponds to a gain
                                                       Z       z
                                           ′
                                       α (s(z, t))                 w(y, t)f (y, t)dy.
                                                           0


Note that the integral on the right hand-side of (22) is only taken over y ≤ z. This is because

                                                                   17
from (20) changing s(z, t) has no direct effect on the distribution at y > z which only depends
on the search intensities, s(y, t), of those individuals with costs y > z.
   As in the decentralized allocation, the Bellman equation here for the marginal value w(z, t)
(21) and the law of motion for the distribution (20) constitute a system of two partial differential
equations that completely summarize the necessary conditions for a solution to the planning
problem.
   A balanced growth path for the planning problem is defined in the same way as in the
decentralized equilibrium:

                           f (z, t) = eγt φ(zeγt ),    w(z, t) = eθγt ω(zeγt ).

Again, restating (20) and (21) in terms of relative productivities x = zeγt , we obtain a BGP
Bellman equation
                                                                     Z   x              
                             ′                             −θ
        (ρ − θγ) ω(x) − ω (x)γx = max (1 − σ)x + α(σ)            [ω(y) − ω(x)]φ(y)dy
                                  σ∈[0,1]                      0
                                  Z ∞                                                          (23)
                                −       α[ς(y)][ω(y) − ω(x)]φ(y)dy
                                        x


and an equation for the BGP distribution, (8). It is important to note that while the equation
for the distribution is the same as in the decentralized equilibrium, the planner will generally
choose a different time allocation, ς(x), and hence different arrival rates, α(ς(x)), implying a
different BGP distribution. Here and below we use the notation ς(x) for the planner’s policy
function, to distinguish it from the policy function σ(x) chosen by individual agents. Finally,
the parameter γ is given by (12) evaluated using the planner’s time allocation, ς(x).
   Figure 6 compares the time allocation, ς(x), chosen by the planner with the outcome of the
decentralized equilibrium. Not surprisingly, the planner assigns a higher fraction of time spent
searching to all individuals so as to internalize the “external benefit from search” discussed
above. This implies a higher growth rate θγ in the planning problem vis-à-vis the decentralized
economy. The larger amount of time allocated towards search is also reflected in a lower initial
level of total production, Y (0).
   Figures 7 and 8 compare the Lorenz curves for flow income and the present value of future
income in the decentralized equilibrium and planning problem. An immediate implication of
more time allocated towards search is a higher degree of income inequality in the planning
problem. This effect is, however, much more muted if we instead measure inequality by the
value Lorenz curve, which takes into account mobility in the productivity distribution.


                                                      18
                                         1

                                        0.9

                                        0.8
                Time Allocation, σ(x)   0.7

                                        0.6                                Optimal Allocation
                                                                           Growth rate = .027
                                        0.5

                                        0.4

                                        0.3

                                        0.2

                                        0.1 Equilibrium Allocation
                                                  Growth rate = .02
                                         0
                                                     0.4     0.6      0.8      1       1.2      1.4   1.6      1.8         2
                                                                    Productivity, x−θ, rel. to Median


Figure 6: Optimal time allocation, σ(x), in decentralized equilibrium and ς(x) in the planning
problem




                                          1

                                        0.9
                                                           Equilibrium Planner
                                        0.8
                                                   θγ        .02              .027
                                        0.7
                                                   Y(0)       .37              .31
                                        0.6

                                        0.5

                                        0.4

                                        0.3

                                        0.2

                                        0.1                                                                  Equilibrium
                                                                                                             Planner
                                          0
                                              0      0.1     0.2     0.3     0.4     0.5   0.6   0.7   0.8      0.9        1




Figure 7: Income Lorenz curves and growth rate, θγ, in decentralized equilibrium and planning
problem.


                                                                                   19
                              1

                             0.9
                                              Equilibrium Planner
                             0.8
                                       θγ       .02               .027
                             0.7
                                       Y(0)      .37               .31
                             0.6

                             0.5

                             0.4

                             0.3

                             0.2

                             0.1                                                                           Equilibrium
                                                                                                           Planner
                              0
                                   0    0.1     0.2        0.3   0.4     0.5           0.6     0.7   0.8      0.9           1




Figure 8: Present value Lorenz curves and growth rate, θγ, in decentralized equilibrium and
planning problem.

5     Tax Implementation of the Optimal Allocation
In this section we propose and illustrate a Pigovian tax structure that implements the optimal
allocation by aligning the private and social returns to search. In this model a flat tax on income
will be neutral: it will have identical effects on both sides of the first order condition (15). We
use such a tax to finance a productivity related subsidy τ (z, t) to offset the opportunity cost
z −θ s of search time s. The flat tax τ0 satisfies the government budget constraint
                     Z   ∞                                                     Z       ∞
                                                  −θ
                             τ (z, t)s(z, t)z          f (z, t)dz = τ0                     (1 − s(z, t))z −θ f (z, t)dz.
                     0                                                             0


Under this tax structure, the individual Bellman equation becomes
                                                                                                                       z                                
                                                                                   ∂V (z, t)
                                                                                                                    Z
                                                      −θ                 −θ
ρV (z, t) = max          (1 − τ0 )[(1 − s)z                + τ (z, t)z        s] +           + α(s)                         [V (y, t) − V (z, t)]f (y, t)dy .
           s∈[0,1]                                                                   ∂t                             0


The law of motion for the distribution (3) and the expression for aggregate output (11) are
unchanged.
    Let vn (x) (n for “net”) be the present value of an individual’s earnings, net of subsidies and




                                                                       20
taxes, and replace the equation defining the value function on a BGP (6) by

                                       V (z, t) = (1 − τ0 )eθγt vn (zeγt ).

In addition τ (z, t) = τ (zeγt ). This function vn (x) satisfies
                                                                                             Z        x                            
(ρ − θγ) vn (x) −   vn′ (x)γx   = max          (1 − σ)x           −θ          −θ
                                                                       + τ (x)x σ + α(σ)                   [vn (y) − vn (x)]φ (y) dy ,
                                 σ∈[0,1]                                                           0


where both the density φ and the growth rate γ are taken from the planning problem.
     As before, we let                           Z       x
                                     Sn (x) =                [vn (y) − vn (x)]φ (y) dy.
                                                     0

The first order condition is

                          (1 − τ (x)) x−θ ≤ α′ (σ)Sn (x) with equality if σ < 1.

The agent takes τ (x) as given and chooses σ(x).
     The planner wants to choose the subsidy rate τ (x) so that individuals choose σ(x) = ς(x),
the time allocation that the planner has already decided on. This choice is then

                                       (1 − τ (x))x−θ = α′ (ς(x))Sn (x)                                                          (24)

provided that ς(x) < 1. At the smallest value x̄ at which ς(x) = 1, τ (x̄) is the rate at which
the agent is indifferent between working a small amount and not working at all. For x > x̄,
equality in (24) gives the subsidy rate that maintains indifference as cost increases from x̄. Of
course, any higher subsidy rate in this range would have the same effect.
     The Bellman equation under the tax policy just described is
                                                                                             Z     x
     (ρ − θγ) vn (x) −   vn′ (x)γx   =x−θ                     ′
                                            − ς(x)α (ς(x))S(x) + α(ς(x))                               [vn (y) − vn (x)]φ (y) dy.
                                                                                               0


With the function α(σ) = kσ η that we use, α(σ) − σα′ (σ) = kσ η − σηkσ η−1 = (1 − η) α(σ) and
so                                                                                 Z   x
           (ρ − θγ) vn (x) −    vn′ (x)γx   =x    −θ
                                                         + (1 − η) α(ς(x))                 [vn (y) − vn (x)]φ (y) dy             (25)
                                                                                   0

on (0, x̄). On [x̄, ∞), vn (x) = vn (x̄) .
     Given ς(x) and γ from the planning problem, (25) can be solved for vn (x) and Sn (x),
applying the algorithm used earlier. The tax rate τ (x) can then be computed using (24). Figure

                                                                       21
9 plots the two policy functions σ(x) and ς(x) and the subsidy rate τ (x). On the interval A
on the figure, agents choose σ = 1 in both the decentralized and planned cases, so no tax is
needed to encourage more search. On the interval B, the planner wants everyone to search
full time so τ (x) is chosen to induce agents to prefer this to doing any production. The agents
with the lowest productivity on the interval B choose to work in the decentralized economy
but the planned allocation implemented by the tax improves their return from search enough
that no additional tax incentive is needed. On the interval C, the planner wants to increase
everyone’s search: compare σ(x) to ς(x). The opportunity cost of search increases without limit
as x−θ → ∞. This requires that τ (x) be an increasing function on C.



                     1

                    0.9
                          A          B                                          C
                    0.8

                    0.7              σ(x)                                ς(x)
                    0.6

                    0.5

                    0.4       Subsidy Rate
                                   τ(x)
                    0.3

                    0.2

                    0.1

                     0
                              0.3     0.4          0.5          0.6         0.7     0.8
                                     Productivity, x−θ, rel. to Median


                Figure 9: Pigovian Implementation of the Optimal Allocation

   In the example shown in Figure 9, the only agents with positive earnings are those on the
interval C. All of them pay the flat tax τ0 on earnings and receive offsetting subsidies designed
to encourage search. These subsidy rates increase faster than earnings, making the tax system
as a whole regressive. It is worth emphasizing that this is a feature of a tax system which has
the single purpose of encouraging productivity innovation. Considerations of distorting taxes
and distribution, central to much of tax analysis, have simply been set aside.




                                                  22
6         Alternative Learning Technologies
All of the analysis so far has been carried out under the learning technology described in
Section 2. Even under the limits of a one-dimensional model of knowledge, however, there
are many other models of learning that might be considered. It turns out that the algorithm
we describe in Section 3 is not difficult to adapt to some alternatives. Ultimately, which of
these and other alternatives are substantively interesting will depend on the evidence we are
trying to understand. In this section, we simply illustrate some theoretical possibilities with
two examples.


6.1         Limits to Learning
In the theory we have considered so far, a person’s current productivity level determines his
ability to produce goods but has no effect on his ability to acquire new knowledge. The
outcome of a search by agent z who meets an agent y < z is y, regardless of the value of his
own cost z. But it is easy to think of potential knowledge transfers that cannot be carried
out if the “recipient’s” knowledge level is too different from that of the “donor.” To explore
this possibility, we make use of an appropriate “kernel” to modify the law of motion for the
distribution (3). Assume for example that if an agent at z meets another agent at y, he can
adopt y with probability k(y, z, t); with probability 1 − k(y, z, t) he cannot do this and retains
his previous cost z. Then the law of motion for the distribution becomes
                                    ∞                                                                z
    ∂f (z, t)
                              Z                                                                Z
              = f (z, t)                α(s(y, t))f (y, t)k(z, y, t)dy − α(s(z, t))f (z, t)              f (y, t)k(y, z, t)dy.
       ∂t                       z                                                                0


A natural assumption on the kernel k is that the probability of z learning from y is unchanged
over time if z and y are at the same quantiles of the cost distribution

                   k(y, z, t) = k(y ′ , z ′ , t′ ),   for F (y, t) = F (y ′, t′ ) and F (z, t) = F (z ′ , t′ ).             (26)

(Think of our cohort interpretation of the stochastic careers in Figure 5. A “newborn” beginning
at date t + τ immediately benefits from the fact that productivities in general are eθγτ larger
than they were for his “parent” who arrived at t.) Along a balanced growth path for the
distribution as defined in (5), all cost quantiles shrink at a common rate γ. Hence (26) can be
written as8
                                                  k(y, z, t) = k(yeγt , zeγt , 0).
    8
        To see this, use that along a BGP F (z, t) = Φ(zeγt ) and let t′ = 0 in (26).


                                                                 23
       We find it convenient to work with the functional form

                                                   k(y, z, 0) = e−κ|y−z| ,                                                       (27)

where κ > 0 is the rate at which learning probabilities fall off as knowledge differences increase.
We can think of this kernel as reflecting an ordering in the learning process or some limits
to intellectual range.9 An equivalent interpretation of this kernel is that meeting probabilities
depend on the distance between different productivity types, so that each person has a higher
chance of meeting those with a knowledge level close to his own. In this interpretation, the
parameter κ captures the degree of socioeconomic segregation or stratification in a society.
       With the functional form in (27), we can derive the following expressions for the law of
motion for the distribution along a BGP
                                   Z     ∞                                                          Z    x
                  ′                                                −κ(y−x)
        φ(x)γ + φ (x)γx = φ(x)               α(σ(y))φ(y)e                    dy − α(σ(x))φ(x)                φ(y)e−κ(x−y)dy
                                     x                                                               0


Evaluating at x = 0, the growth rate of the economy is
                                                   Z       ∞
                                             γ=                α(σ(y))φ(y)e−κy dy.                                               (28)
                                                       0


Analogously, the corresponding Bellman equation is
                                                                                Z   x                                     
                          ′                                        −θ                                           −κ(x−y)
        (ρ − θγ) v(x) − v (x)γx = max                  (1 − σ)x         + α(σ)           [v(y) − v(x)]φ(y)e               dy .
                                       σ∈[0,1]                                   0


       Figure 10 plots the optimal time allocation, σ(x), for various values of the parameter mea-
suring the limits to learning, κ. Going from κ = 0 to κ = 0.01 changes people’s search behavior
dramatically. High productivity types allocate a roughly equal amount of time towards knowl-
edge acquisition regardless of κ. But low productivity types are discouraged from search,
resulting in search intensity being a hump-shaped function of current productivity. The reason
for this is that the benefit from search
                                               Z       x
                                  S(x) =                   [v(y) − v(x)]φ(y)e−κ(x−y) dy
                                                   0


is no longer very high for low productivity (high cost) types. Because low productivity types
   9
     Jovanovic and Nyarko (1996) suggested the following rationale for such limits to learning: different produc-
tivity types, z −θ , correspond to different activities and human capital is partially specific to a given activity.
When an agent switches to a new activity, he loses some of this human capital, and more so the more different
is the new activity.


                                                                  24
also have a low probability of benefiting from a meeting with a high productivity type, their
expected payoff from search is low and their search effort is discouraged. Increases in κ have little
effect on income inequality, as Figure 11 shows, but a large effect on present value inequality,
especially for low productivity types, as Figure 12 shows. Another way of putting this is that
social mobility decreases dramatically as κ increases.


                                           1

                                          0.9

                                          0.8         κ=0
                                          0.7
                  Time Allocation, σ(x)




                                          0.6

                                          0.5

                                          0.4   κ = .01
                                          0.3

                                          0.2
                                                                   κ = .015
                                          0.1

                                           0
                                                0.3       0.4      0.5       0.6       0.7     0.8   0.9   1
                                                                               −θ
                                                                Productivity, x , rel. to Median


                Figure 10: Optimal Time Allocation, σ(x), for various κ values.

   As can also be seen on these figures, the growth rate of the economy, θγ, declines as the
limits to learning, κ, increase. This is due to two effects. First and as just discussed, some low
productivity types allocate less time towards search. Because the growth rate of the economy
is an average of individual search intensities, this depresses growth. Second, there is a direct
negative effect of κ on the growth rate as can be seen in the formula (28). This direct effect
comes from the fact that the number of agents whose productivity exceeds any value 1/εθ at
any point in time (the inflow into the cost interval (0, ε)) is lower because low productivity
agents face a lower probability of meeting high productivity ones.
   Finally, Figure 13 also reports the time allocation chosen by an idealized social planner
who is constrained by the limits to learning that characterize the decentralized equilibrium.
Compared with the time allocation in the decentralized equilibrium reported in Figure 10, the
planner chooses a higher search intensity for each κ value. Note that even this planner gives up
on low productivity types because the social value of their attempts at knowledge acquisition
is diminished by the fact that they are unlikely to learn from those with high productivity.

                                                                             25
    1

  0.9
          κ     0     0.01     0.015
  0.8
         θγ     0.02 0.014 0.01
  0.7
         Y(0)   .37   .36     0.34
  0.6

  0.5

  0.4

  0.3

  0.2
                                                    κ=0
  0.1                                               κ = 0.01
                                                    κ=0.015
    0
     0          0.2          0.4        0.6   0.8              1



   Figure 11: Income Lorenz curves for various κ values.




    1

  0.9
          κ     0     0.01     0.015
  0.8
         θγ     0.02 0.014 0.01
  0.7
         Y(0)   .37   .36     0.34
  0.6

  0.5

  0.4

  0.3

  0.2
                                                    κ=0
  0.1                                               κ = 0.01
                                                    κ=0.015
    0
     0          0.2          0.4        0.6   0.8              1



Figure 12: Present Value Lorenz curves for various κ values.



                                   26
To obtain information on our parameter κ, our theory suggests studying the degree of social


                                             1

                                            0.9                         κ=0
                                            0.8
                                                  κ = .01
                                            0.7
                    Time Allocation, σ(x)


                                            0.6

                                            0.5

                                            0.4

                                            0.3
                                                                  κ = .015
                                            0.2

                                            0.1

                                             0
                                                            0.4          0.6              0.8          1   1.2
                                                                                   −θ
                                                                    Productivity, x , rel. to Median


                 Figure 13: Planner’s Time Allocation, σ(x), for various κ values.

mobility in a society. Comparing income and present value Lorenz curves in Figures 11 and
12, social mobility decreases sharply with κ. Both evidence on intra- and inter-generational
mobility is informative, even though our theory does not distinguish between the two. In section
3, we have already cited some studies on on-the-job human capital accumulation and the slope
of earnings profiles. There are also many studies examining the correlation in lifetime income
between parents and children (e.g. Solon, 1992) or intergenerational transition probabilities
between different income quantiles (e.g. Zimmerman, 1992).10


6.2       Symmetric Meetings
Another feature of the learning technology applied in Sections 1-5 is the fact that meetings
between two agents z and y are completely asymmetric. Agents could only upgrade their
knowledge through active search while the other party to the meeting gains nothing and can
well be unaware that he is being met.
       Depending on the specific application, this may not be the best assumption. For example,
Arrow (1969) argues that “the diffusion of an innovation [is] a process formally akin to the
  10
    See Becker and Tomes (1979), Benabou (2002) and Benhabib, Bisin and Zhu (2011) for alternative theories
of the relationship between inequality and the degree of intragenerational mobility.


                                                                                 27
spread of an infectious disease.” This description of meetings has a symmetric component: a
person can get “infected” even when he didn’t actively search for the “disease”. The model
can easily be extended to encompass the case where meetings are symmetric, as we now show.
To capture symmetric meetings, we assume that even if y initiated the meeting, z can learn
from y with probability β. Therefore, β parameterizes how strong passive spillovers are: β = 0
corresponds to our benchmark model; β = 1 is the case of perfectly symmetric meetings. Under
this assumption, we obtain the new law of motion
                                                              z
                         ∂f (z, t)
                                                      Z
                                   = − f (z, t)                   [α(s(z, t)) + βα(s(y, t))]f (y, t)dy
                            ∂t                            0
                                                      Z       ∞
                                         + f (z, t)               [α(s(y, t)) + βα(s(z, t))]f (y, t)dy.
                                                      z


The main difference from the asymmetric law of motion (3) is that here the search intensities
s(z, t) and s(y, t) enter in a symmetric fashion. Agents at z now have opportunities to upgrade
their productivities even if another agent y initiated the meeting. These opportunities arrive
at rate α(s(z, t)) + βα(s(y, t)) rather than just α(s(z, t)). The Bellman equation now becomes
                                                                       z                                                    
                                           ∂V (z, t)
                                                                   Z
                                    −θ
ρV (z, t) = max          (1 − s)z        +           +                      [α(s) + βα(s(y, t))][V (y, t) − V (z, t)]f (y, t)dy .
           s∈[0,1]                            ∂t                    0


The corresponding equations along a BGP are found as above. Figures 14 and 15 report the
optimal time allocation and productivity density for various values of the parameter measuring
the amount of passive spillovers, β. The more knowledge that can be acquired without actively
searching, the lower is agents’ incentive to search. Since the economy-wide growth rate is still
an average of individual search intensities, this “free-riding” implies that the growth rate is
actually lower the higher are spillovers, β. At the same time, a higher β implies that the
BGP distribution places more mass on high productivity types (Figure 15). Figures 16 to
18 compare the decentralized equilibrium just described to the allocation chosen by a social
planner when meetings are symmetric.                          The time allocation chosen by the social planner now
differs dramatically from that in the decentralized equilibrium. The planner makes the most
productive agents search full time, the high opportunity cost notwithstanding. He views them
as even more valuable as “teachers,” reaching out to meet less productive agents, increasing
the probability that less productive agents will learn from them. After such an unproductive
agent becomes productive, he searches full time for a while, but as his relative productivity
declines (as in panel (b) of Figure 5) he resumes working. While period-by-period income is
more unequally distributed under the planner’s time (Figure 17), this is no longer true for the


                                                                        28
                          1

                         0.9
                                                                        β      0     0.5    1
                         0.8                      β=0
                                                                        θγ     .020 .017 .015
                         0.7
 Time Allocation, σ(x)
                                                                       Y(0)    .37   0.5   0.66
                         0.6

                         0.5

                         0.4                           β = 0.5
                         0.3

                         0.2                            β=1
                         0.1

                          0
                                 0.2       0.3      0.4     0.5      0.6      0.7   0.8    0.9     1
                                                  Productivity, x−θ, rel. to Median


Figure 14: Optimal Time Allocation, σ(x), for various β values




                               β=0
                   0.06                     Dashed curve: Pareto Distribution with Parameter 1/θ


                                           β = .5
                   0.05

                                                        β=1
                   0.04


                   0.03


                   0.02


                   0.01


                          0
                               0.5     1         1.5      2    2.5       3     3.5   4     4.5     5
                                                           Productivity, x−θ


                         Figure 15: Productivity Densities for various β values



                                                                 29
                          1

                         0.9                                            Planner
                         0.8
 Time Allocation, σ(x)   0.7

                         0.6

                         0.5

                         0.4

                         0.3

                         0.2

                         0.1
                                                                Equilibrium
                          0
                               0          100     200       300         400       500           600
                                                  Productivity, x−θ, rel. to Median


Figure 16: Optimal Time Allocation with Symmetric Meetings




                           1

                         0.9
                                          Equilibrium Planner
                         0.8
                                   θγ       .018          .039
                         0.7

                         0.6

                         0.5

                         0.4

                         0.3

                         0.2

                         0.1                                                                  Equilibrium
                                                                                              Planner
                           0
                               0    0.1     0.2    0.3    0.4    0.5   0.6    0.7       0.8      0.9        1




                         Figure 17: Income Lorenz Curves, Symmetric Meetings



                                                                30
                      1

                    0.9
                                     Equilibrium Planner
                    0.8
                              θγ       .018         .039
                    0.7

                    0.6

                    0.5

                    0.4

                    0.3

                    0.2

                    0.1                                                            Equilibrium
                                                                                   Planner
                      0
                          0    0.1     0.2    0.3   0.4    0.5   0.6   0.7   0.8      0.9        1




                    Figure 18: Value Lorenz Curves, Symmetric Meetings

present value of income. The Lorenz curves in Figure 18 cross, meaning that in parts of the
distribution the decentralized equilibrium features too little mobility relative to the planning
problem.


7     Conclusion
We have proposed and studied a new model of economic growth in which individuals differ only
in their current productivity, and the state of the economy is fully described by the probability
distribution of productivities. The necessary conditions for equilibrium in the model take
the form of a Bellman equation describing individual decisions on the way to allocate time
between producing and searching for new ideas and a law-of-motion for the economy-wide
productivity distribution. With the right kind of initial conditions these forces can interact to
generate sustained growth. We show that among these possibilities is a balanced growth path,
characterized by a constant growth rate and a stable Lorenz curve describing relative incomes.
We provide an algorithm for calculating solutions along this path.
    This solution is the outcome of a decentralized system in which each agent acts in his own
interest. But the new knowledge obtained by any one agent benefits others by enriching their
intellectual environment and raising the return to their own search activities. We then formulate
the problem of a hypothetical planner who can allocate people’s time so as to internalize this

                                                          31
external effect. We show how the decentralized algorithm can be adapted to compute the
planning solution as well, and compare it to the decentralized solution. We then consider tax
structures that implements an optimal solution. Finally we provide two examples of alternative
learning technologies, as concrete illustrations of other directions that might be pursued.
      All of this is carried out in a starkly simple context in order to reveal the economic forces
involved and the nature of their interactions, and to build up our experience with a novel and
potentially useful mathematical structure. But we also believe that the external effects we
study here are centrally important to the understanding of economic growth and would like
to view our analysis as a step toward a realistically quantitative picture of the dynamics of
production and distribution.11


Appendix
      A      Derivation of Bellman Equation

Let time be indexed by t, t + ∆, .... Denote the discount factor between two periods by 1 − ∆ρ. The
Bellman equation is

      V (z, t) = max ∆(1 − s)z −θ + (1 − ∆ρ)
                 s∈[0,1]
                        Z ∞                                                                        
               × ∆α(s)       max{V (y, t + ∆), V (z, t + ∆)}f (y, t + ∆)dy + (1 − ∆α(s))V (z, t + ∆)
                           0

Rewrite as

              V (z, t) = max ∆(1 − s)z −θ + (1 − ∆ρ)
                         s∈[0,1]
                                Z z                                                           
                       × ∆α(s)       [V (y, t + ∆) − V (z, t + ∆)]f (y, t + ∆)dy + V (z, t + ∆) .
                                    0

Subtract (1 − ∆ρ)V (z, t) from both sides

       ∆ρV (z, t) = max ∆(1 − s)z −θ + (1 − ∆ρ)
                    s∈[0,1]
                           Z z                                                                      
                  × ∆α(s)       [V (y, t + ∆) − V (z, t + ∆)]f (y, t + ∆)dy + V (z, t + ∆) − V (z, t) .
                                0


Dividing by ∆ and taking the limit as ∆ → 0 yields equation (4).
 11
      In this regard, see also Choi (forthcoming).




                                                      32
   B      Proof of Proposition 1

   B.1      Mathematical Preliminaries

The value function of the planner W [f (z, t)] is a functional, that is a map from a space of functions to
the real numbers, or informally a “function of a function”. The planner chooses a function f (z, t) to
maximize this functional, which is the prototypical problem in the calculus of variations. The concept
of a functional derivative is helpful in solving this problem.
   Definition: The functional derivative of W with respect to f at point y is

            δW [f (z)]       W [f (z) + εδ(z − y)] − W [f (z)]  d
                       ≡ lim                                   = W [f (z) + εδ(z − y)]                    (29)
             δf (y)      ε→0                 ε                  dε                                  ε=0

where δ(·) is the Dirac delta function.
   The functional derivative is the natural generalization of the partial derivative. Thus, consider the
case where z is discrete and takes on n possible values, z ∈ {z1 , ..., zn }. The corresponding distribution
function is then simply a vector f ∈ Rn and the planner’s value function is an ordinary function of n
variables, W : Rn → R. The partial derivative in this case is defined as

                       ∂W (f )       W (f1 , ..., fi + ε, ..., fn ) − W (f1 , ..., fi , ..., fn )
                               ≡ lim                                                                      (30)
                        ∂fi      ε→0                             ε

If we denote by δ(i) ∈ Rn the vector that has elements δi (i) = 1 and δi (j) = 0 for all i 6= j, then (30)
cab be written as

                       ∂W (f )       W (f + εδ(i)) − W (f )  d
                               ≡ lim                        = W (f + εδ(i))
                        ∂fi      ε→0           ε             dε                              ε=0

It can be seen that the functional derivative in (29) is defined in the exact same way.
   Another fact that will be useful below, is that the integral of the Dirac delta function can be
expressed as the Heaviside step function
                                                        
                                     Z   z              1,        z≥0
                                             δ(ζ)dζ =                      ≡ H(z)
                                      −∞                0,        z<0

Similarly, integrals of the Dirac delta function centered at y are
                       Z   z                                   Z   ∞
                                δ(ζ − y)dζ = H(z − y),                 δ(ζ − y)dζ = H(y − z)
                           −∞                                  z




                                                          33
   B.2     Bellman Equation

With this mathematical apparatus in hand, the planner’s problem can be written in recursive form as
                                                            ∞                                                           ∞
                                                                                                                            δW [f ] ˆ
                                                    Z                                                           Z
                                                                                         −θ
                        ρW [f ] = max                           [1 − s(z)]z                      f (z)dz +                         f (z; s, f )dz                  (31)
                                            s           0                                                           0       δf (z)

where                                                                            Z       z                              Z       ∞
                        fˆ(z; s, f ) = −α(s(z))f (z)                                         f (y)dy + f (z)                        α(s(y))f (y)dy.                (32)
                                                                                     0                                      z



   Lemma 2: A solution s(·) to the planning problem must satisfy

                                                                        z                      
                                                                                δW [f ] δW [f ]
                                                                Z
                                     −θ         ′
                                 z        = α (s(z))                                   −          f (y)dy                                for all z.                (33)
                                                                    0           δf (y)   δf (z)


   Proof: The planner’s first order condition is
                                            Z          ∞                                                           ∞                                 
                             δ                                                                                          δW [f ] ˆ
                                                                                                            Z
                                                                                     −θ
                        0=                                  [1 − s(y)]y                      f (y)dy +                         f (y; s, f )dy
                           δs(z)                    0                                                           0       δf (y)

Using the definition of a functional derivative
                         ∞                                                                       ∞
              δ                                                    d
                    Z                                                                    Z
                                                    −θ
                                [1 − s(y)]y              f (y)dy =                                    [1 − (s(y) + εδ(y − z))]y −θ f (y)dy
            δs(z)   0                                              dε                        0                                                            ε=0
                                ∞                                                                                                                                  (34)
               d
                        Z
                                                        −θ                                   −θ
            =−                       δ(y − z)y               f (y)dy = −z                         f (z)
               dε           0

Using similar manipulations for the second term:

                                                                                      ∞
                                                                                             δW [f ] δfˆ(y; s, f )
                                                                                 Z
                                                        −θ
                                                    z        f (z) =                                               dy                                              (35)
                                                                                  0          δf (y) δs(z)

From (32), we have

          δfˆ(y; s, f )                                                                      y                                      ∞
                                                                                     Z                                      Z
                        = −α′ (s(y))δ(y − z)f (y)                                                f (ζ)dζ + f (y)                        α′ (s(ζ))δ(ζ − z)f (ζ)dζ
             δs(z)                                                                       0                                      y
                                                                                     Z       y
                            = −α′ (s(y))δ(y − z)f (y)                                            f (ζ)dζ + f (y)α′ (s(z))f (z)H(z − y)
                                                                                         0

where we use the relation between Dirac delta and Heaviside step function.




                                                                                                 34
   Therefore (35) can be written as

                          ∞                                          Z ∞                               Z y
                            δW [f ]                                       δW [f ]
                   Z
  z −θ f (z) =                      f (y)α′ (s(z))f (z)H(z − y)dy −               α(s(y))δ(y − z)f (y)     f (ζ)dζdy
                            δf (y)                                        δf (y)
                   Z0 z                                               0
                                                                                Z z                     0
                           δW [f ] ′                       δW [f ] ′
              =                   α (s(z))f (z)f (y)dy −          α (s(z))f (z)     f (ζ)dζ
                      0    δf (y)                          δf (z)                0

Collecting terms yields (33).


   B.3            Proof of Proposition 1

Differentiating (31) with respect to f (z), we obtain

                                                                                         ∞
                                                                              δ              δW (f ) ˆ
                                                                                     Z
                                                                     −θ
                                     ρw̃(z, f ) = (1 − s(z))z             +                          f (y; s, f )dy                               (36)
                                                                            δf (z)   0        δf (y)

We have

            δ                 ∞
                                  δW (f ) ˙                      ∞
                                                                      δw̃(y, f ) ˆ                             ∞
                                                                                                                               δfˆ(y; s, f )
                       Z                                     Z                                         Z
                                          f (y; s, f )dy =                      f (y; s, f )dy +                   w̃(y, f )                 dy   (37)
          δf (z)          0        δf (y)                    0         δf (y)                              0                      δf (z)

From (32) and using the relation between Dirac delta and Heaviside step function,

                              δfˆ(y; s, f )
                                                                Z y
                                            = − α(s(y))δ(y − z)     f (ζ)dζ − α(s(y))f (y)H(y − z)
                                 δf (z)                          0
                                                         Z ∞
                                              + δ(y − z)     α(s(ζ))f (ζ)dζ + f (y)α(s(z))H(z − y)
                                                                 y


and similarly for the last term. Hence

                  ∞
                                   δfˆ(y; s, f )
          Z                                                                Z z              Z ∞
                      w̃(y, f )                  dy = − w̃(z, f )α(s(z))       f (ζ)dζ −         w̃(y, f )α(s(y))f (y)dy
              0                       δf (z)                                 0               z
                                                                  Z ∞                        Z z
                                                      + w̃(z, f )      α(s(ζ))f (ζ)dζ +          w̃(y, f )f (y)α(s(z))dy
                                                              Z zz                             0

                                                    =α(s(z))       [w̃(y, f ) − w̃(z, f )]f (y)dy
                                                                0
                                                        Z ∞
                                                      −      α(s(y)) [w̃(y, f ) − w̃(z, f )] f (y)dy
                                                         z

Combining with (36) and (37), we have

                                       ∞
                                          δw̃(y, f ) ˆ
                                                Z
                                          −θ
      ρw̃(z, f ) =(1 − s(z))z +                     f (y; s, f )dy
                                     0      δf (y)
                             Z z                                   Z                         ∞
                   + α(s(z))     [w̃(y, f ) − w̃(z, f )]f (y)dy −                                α(s(y)) [w̃(y, f ) − w̃(z, f )] f (y)dy
                                           0                                             z




                                                                            35
Define
                                                            w(z, t) ≡ w̃(z, f (z, t))                                    (38)

Then
                                                            ∞
                               ∂w(z, t)                         δw̃(y, f (y, t)) ˆ
                                                       Z
                                        =                                       f (y; s(y, t), f (y, t))dy
                                 ∂t                     0          δf (y, t)
and hence
                                                                                                       z
                                                          ∂w(z, t)
                                                                                                   Z
                                                  −θ
               ρw(z, t) =(1 − s(z, t))z                 +          + α(s(z, t))
                                                                        [w(y, t) − w(z, t)]f (y, t)dy
                                                            ∂t        0
                            Z ∞                                                                                          (39)
                          −     α(s(y, t)) [w(y, t) − w(z, t)] f (y, t)dy
                                z

Further, using (38), the FOC (33) can be written as
                                                                    Z       z
                                        −θ          ′
                                    z           = α (s(z, t))                   [w(z, t) − w(y, t)] f (y)dy              (40)
                                                                        0

(39) and (40) can be summarized as (21).


       C     Computation

       C.1    Step 1: Solution to Bellman Equation – Decentralized Equilibrium

The BGP Bellman equation (10) can be rewritten as

                             (ρ − θγ)v(x) = x−θ [1 − σ(x)] + γxv ′ (x) + α[σ(x)]S(x)

where S(x) is defined as
                                    Z       x                                         Z       x
                           S(x) ≡               [v(y) − v(x)]φ(y)dy =                             v(y)φ(y)y − v(x)Φ(x)
                                        0                                                 0
                Rx
and Φ(x) =       0   φ(y)dy, that is the cdf corresponding to φ. The optimal choice σ(x) is defined implicitly
by the first order condition (15). We further have a boundary condition (16).
       We solve these equations using a finite difference method which approximates the function v(x)
on a finite grid, x ∈ {x1 , ..., xI }. We use the notation vi = v(xi ), i = 1, ..., I.12 We approximate the
derivative of v using a forward difference

                                                                                  vi+1 − vi
                                                                v ′ (xi ) ≈
                                                                                     hi
  12
       A useful reference is Candler (1999).




                                                                                36
where hi is the distance between grid points xi and xi+1 . The boundary condition (16) then implies

                                                       vI+1 − vI
                                     0 ≈ v ′ (xI ) =                  ⇒      vI+1 = vI .                    (41)
                                                          hI

Similarly, we approximate S(x) by

                                                             i
                                                             X
                                             Si = S(xi ) ≈         vl φl hl − vi Φi                         (42)
                                                             l=1


Further, denote by σi = σ(xi ) and αi = α[σ(xi )] the optimal time allocation and search intensity.
   We proceed in an iterative fashion: we guess vi0 and then for j = 0, 1, 2... form vij+1 as follows.
Form Sij as in (42), and obtain σij and αji from the first order condition (44). Write the Bellman
equation as

                                                 j+1
                                                     − vij+1
                                                                  " i                 #
                                                vi+1
         − θγ)vij+1            σij )x−θ                         j
                                                                   X j+1          j+1
    (ρ                = (1 −         i    + γxi              + αi     vl φl hl − vi Φi ,    i = 1, ..., I   (43)
                                                     hi
                                                                       l=1



                                                                      j+1
   Given v j and hence σ j and αj , and using the boundary condition vI+1 = vIj+1 , (43) is a system of
I equations in I unknowns, (v1j+1 , ..., vIj+1 ), that can easily be solved for the updated value function,
v j+1 . Using matrix notation

                                Aj v j+1 = bj ,    bji = (1 − σi )x−θ
                                                                   i ,       Aj = Bj − Cj




                                                             37
where13
                                                                                                                        
                       ρ − θγ + αj1 Φ1 +       γx1
                                                h1                − γx
                                                                    h1
                                                                       1
                                                                                         0       ...         0
                                                      ρ − θγ + αj2 Φ2 +      γx2
                                                                                       − γx
                                                                                                                        
                                   0                                         h2         h2
                                                                                             2
                                                                                                 ...         0           
             Bj = 
                                                                                                                        
                                    ..                         ..                       ..       ..          ..          
                  
                                    .                          .                          .        .         .          
                                                                                                                         
                                    0                                 ...               ...      . . . ρ − θγ + αjI ΦI
                                                                                  
                       α1 φ1 h1          0      ...          ...             0
                                                                
                 α2 φ1 h1 α2 φ2 h2 0           . . .      0     
                                                                
              j
                                    ..         ..          .. 
             C = α3 φ1 h1 α3 φ2 h2
                                        .          .        .  
                  .            ..   ..         ..
                  ..
                                                                 
                                .       .          .      0     
                                                                 
                   αI φ1 h1 αI φ2 h2 . . . αI φI−1 hI−1 αI φI hI

Solve the system of equations and iterate until v j+1 is close to v j .


       C.2    Step 1: Solution to Bellman Equation – Planning Problem

The Bellman equation for the planning problem (23), can be written as

                          (ρ − θγ) ω(x) − ω ′ (x)γx = [1 − σ(x)]x−θ + α[σ(x)]S(x) + Q(x)

where
                      Z   x                              Z   x
             S(x) ≡    [ω(y) − ω(x)]φ(y)dy =     ω(y)φ(y)dy − ω(x)Φ(x)
                     0                        0
                      Z ∞                                Z ∞
             Q(x) ≡ −     α[σ(y)][ω(y) − ω(x)]φ(y)dy = −     α[σ(y)]ω(y)φ(y)dy + ω(x)ψ(x)
                              x                                              x
                                                          Z       ∞
                                                 ψ(x) ≡               α(σ(y))φ(y)dy
                                                              x

and the optimal choice σ(x) is defined implicitly by the first-order condition

                                                      x−θ ≥ α′ [σ(x)]S(x).                                                   (44)

We use the same finite difference approximation as above, that is approximate ω(x) on a finite grid
x ∈ {x1 , ..., xI }. We again approximate the functions S(x), σ(x) and α(σ(x)) as in (42), and the
  13
       This follows from rearranging the Bellman equation as
                                                                  i
                                             γxi j+1 γxi j+1
                                  αji Φi                          j
                                                                      hl φl vlj+1 = (1 − σij )x−θ
                                                                    X
                     ρ − θγ +              +      vi −    vi+1 − αi                            i
                                             hi        hi
                                                                                 l=1

and then rewriting it in matrix notation.


                                                                      38
functions Q(x) and ψ(x) as

                                      N
                                      X                                                N
                                                                                       X
                    Qi = Q(xi ) ≈ −            αl ωl φl hl + ωi ψi ,   ψi = ψ(xi ) ≈             αl φl hl   (45)
                                         l=i                                               l=i

We again impose the boundary condition

                                                   ωI+1 − ωI
                              0 ≈ ω ′ (xI ) =                          ⇒     ωI+1 = ωI .
                                                       h

We again proceed in an iterative fashion: we guess ωi0 and then for j = 0, 1, 2... form ωij+1 as follows.
Form Sij and Qji as in (42) and (45), and obtain sji and αji from the first order condition (44). Write
the Bellman equation as

                                                     j+1
                                                    ωi+1 − ωij+1
               (ρ − θγ)ωij+1 = (1 − σij )x−θ
                                          i  + γx i
                                                         hi
                                  " i                       #    N                                          (46)
                                j
                                   X j+1              j+1
                                                                   αjl ωlj+1 φl hl + ωij+1 ψij
                                                                 X
                             + αi       ωl φl hl − ωi Φi −
                                     l=1                                     l=i


Given ω j and hence αj and σ j , this is again a system of I equations in I unknowns (ω1j+1 , ..., ωIj+1 )
that we can solve for the value function at the next iteration ω j+1 . We again write (46) in matrix
notation as
                       Aj ω j+1 = bj ,     bji = (1 − σi )x−θ
                                                           i ,             Aj = Bj − Cj + Dj




                                                           39
where14
                                                                                                                                          
                 ρ − θγ + αj1 Φ1 − ψ1j +             γx1
                                                      h1                − γx
                                                                          h1
                                                                             1
                                                                                                   0         ...                 0
                                                           ρ − θγ + αj2 Φ2 − ψ2j +        γx2
                                                                                                 − γx
                                                                                                                                          
                                  0                                                       h2      h2
                                                                                                       2
                                                                                                             ...                 0         
  Bj = 
                                                                                                                                          
                                   ..                                    ..                       ..         ..                  ..        
       
                                   .                                     .                          .          .                 .        
                                                                                                                                           
                                   0                                     ...                      ...        . . . ρ − θγ + αjI ΦI − ψIj
                                                                                 
                 α1 φ1 h1          0        ...            ...            0
                                                                                 
     α2 φ1 h1                α2 φ2 h2       0             ...            0       
                                                                                 
   j
                                           ..             ..             ..      
  C =
     α3 φ1 h1                α3 φ2 h2           .            .            .      
                                                                                  
      .                          ..        ..             ..
      ..
                                                                                  
                                  .             .            .           0       
                                                                                  
       αI φ1 h1               αI φ2 h2 . . . αI φI−1 hI−1 αI φI hI
                                                                                     
       α1 φ1 h1               α2 φ2 h2 α3 φ3 h3 . . .                αI φI hI
                                                                    
      0                      α2 φ2 h2 α3 φ3 h3 . . .    αI φI hI    
                                                                    
      .                                 ..     ..           ..
   j       .
                                                                     
  D =
      .                         0          .       .         .      
                                                                     
      .                          ..     ..     ..
      ..
                                                                     
                                  .        .       . αI−1 φI−1 hI−1 
                                                                     
          0                        0             ...        0        αI φI hI

Solve the system of equations and iterate until ω j+1 is close to ω j .


       C.3        Step 2: Distribution Function

This section briefly describes the finite difference method used to compute the functions φjn+1 (x),
Φjn+1 (x), ψn+1
            j
                (x) in Step 2a of the algorithm described in section 3. For notational simplicity, we
suppress the dependence of these functions on n (the main iteration). We approximate these functions
on a finite grid (x1 , ..., xI ) of I values. We approximate the derivatives in (17) to (19) by

                                          φji+1 − φji                          Φji+1 − Φji                           j
                                                                                                                    ψi+1 − ψij
                      (φj )′ (xi ) ≈                  ,      (Φj )′ (xi ) ≈                ,    (ψ j )′ (xi ) ≈
                                              hi                                   hi                                  hi
  14
       This follows from rearranging the Bellman equation as
                                                                     i               I
                                          γxi           γxi j+1
                     αji Φi       ψij           ωij+1 −     ωi+1 − αji   φl ωlj+1 hl +   αjl ωlj+1 φl hl = (1 − σij )x−θ
                                                                       X               X
       ρ − θγ +               −         +                                                                             i
                                          hi             hi
                                                                                 l=1                   l=i

and then rewriting it in matrix notation.




                                                                         40
so the finite difference approximation to (17) to (18) is

                                          φji+1 − φji
                              φji γ + γ               , xi = φji ψij − α(σi )φji Φji
                                               hi
                                               j
                                              ψi+1 − ψij
                                                           = −α(σi )φji
                                                  hi
                                             Φji+1 − Φji
                                                           = φji
                                                  hi

with boundary conditions
                                     φj1 = λ,       Φj1 = 0,     ψ1j = γnj .

This is a simple initial value problem which can simply be solved by running the system forward.


                                                References

Alvarez, Fernando E., Francisco J. Buera, and Robert E. Jr. Lucas. 2008. “Models of
  Idea Flows.” National Bureau of Economic Research, Inc NBER Working Papers 14135.

Arrow, Kenneth. 1962. “The Economic Implications of Learning by Doing.” Review of Eco-
  nomic Studies, 29: 155–173.

Arrow, Kenneth J. 1969. “Classificatory Notes on the Production and Transmission of Tech-
  nological Knowledge.” American Economic Review, 59(2): 29–35.

Becker, Gary S, and Nigel Tomes. 1979. “An Equilibrium Theory of the Distribution of
  Income and Intergenerational Mobility.” Journal of Political Economy, 87(6): 1153–89.

Benabou, Roland. 2002. “Tax and Education Policy in a Heterogenous Agent Economy:
  What Levels of Redistribution Maximize Growth and Effiency?” Econometrica, 70(2): 481–
  517.

Benhabib, Jess, Alberto Bisin, and Shenghao Zhu. 2011. “The Distribution of Wealth
  and Fiscal Policy in Economies With Finitely Lived Agents.” Econometrica, 79(1): 123–157.

Ben-Porath, Yoram. 1967. “The Production of Human Capital and the Life Cycle of Earn-
  ings.” Journal of Political Economy, 75: 352.

Bental, Benjamin, and Dan Peled. 1996. “The Accumulation of Wealth and the Cyclical
  Generation of New Technologies: A Search Theoretic Approach.” International Economic
  Review, 37(3): 687–718.

                                                        41
Candler, Graham V. 1999. “Finite-Difference Methods for Dynamic Programming Prob-
  lems.” In Computational Methods for the Study of Dynamic Economies. , ed. Ramon Marimon
  and Andrew Scott. Cambridge, England:Cambridge University Press.

Choi, Seung Mo. forthcoming. “How Large are Learning Externalities.” International Eco-
  nomic Review.

Eaton, Jonathan, and Samuel Kortum. 1999. “International Technology Diffusion: Theory
  and Measurement.” International Economic Review, 40(3): 537–70.

Eaton, Jonathan, and Samuel Kortum. 2002. “Technology, Geography, and Trade.”
  Econometrica, 70(5): 1741–1779.

Fogli, Alessandra, and Laura Veldkamp. 2011. “Germs, Social Networks and Growth.”
  NYU mimeo.

Gabaix, Xavier. 2009. “Power Laws in Economics and Finance.” Annual Review of Eco-
  nomics, 1(1): 255–293.

Grossman, Gene M, and Elhanan Helpman. 1991. “Quality Ladders in the Theory of
  Growth.” Review of Economic Studies, 58(1): 43–61.

Hause, John C. 1980. “The Fine Structure of Earnings and the On-the-Job Training Hypoth-
  esis.” Econometrica, 48(4): 1013–29.

Heckman, James J. 1976. “A Life-Cycle Model of Earnings, Learning, and Consumption.”
  Journal of Political Economy, 84(4): S11–44.

Jovanovic, Boyan, and Rafael Rob. 1989. “The Growth and Diffusion of Knowledge.”
  Review of Economic Studies, 56(4): 569–82.

Jovanovic, Boyan, and Yaw Nyarko. 1996. “Learning by Doing and the Choice of Tech-
  nology.” Econometrica, 64(6): 1299–1310.

Kortum, Samuel S. 1997. “Research, Patenting, and Technological Change.” Econometrica,
  65(6): 1389–1420.

Lasry, Jean-Michel, and Pierre-Louis Lions. 2007. “Mean field games.” Japanese Journal
  of Mathematics, 2: 229–260.

Lucas, Robert E. 2009. “Ideas and Growth.” Economica, 76(301): 1–19.

                                               42
Luttmer, Erzo G.J. forthcoming. “Technology Diffusion and Growth.” Journal of Economic
  Theory.

Perla, Jesse, and Christopher Tonetti. 2011. “Endogenous Risk and Growth.” NYU
  mimeo.

Romer, Paul M. 1986. “Increasing Returns and Long-run Growth.” Journal of Political
  Economy, 94(5): 1002–37.

Rosen, Sherwin. 1976. “A Theory of Life Earnings.” Journal of Political Economy, 84(4): S45–
  67.

Solon, Gary. 1992. “Intergenerational Income Mobility in the United States.” American Eco-
  nomic Review, 82(3): 393–408.

Zimmerman, David J. 1992. “Regression toward Mediocrity in Economic Stature.” American
  Economic Review, 82(3): 409–29.




                                            43
