                              NBER WORKING PAPER SERIES



               COLLEGE REMEDIATION GOES BACK TO HIGH SCHOOL:
              EVIDENCE FROM A STATEWIDE PROGRAM IN TENNESSEE

                                       Thomas J. Kane
                                       Angela Boatman
                                      Whitney Kozakowski
                                      Christopher Bennett
                                         Rachel Hitch
                                       Dana Weisenfeld

                                       Working Paper 26133
                               http://www.nber.org/papers/w26133


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                                    August 2019


We gratefully acknowledge financial support from the Bill & Melinda Gates Foundation. We
thank Mike Krause, Emily House, and Victoria Harpool (from the Tennessee Higher Education
Commission), Nate Schwartz, Jonathan Attridge, and Lacey Hartigan (from the Tennessee
Department of Education), Robert Denn, Jeannette Tippett, and Abbie Alexander (from the
SAILS program), Russ Deaton and Chris Tingle (from the Tennessee Board of Regents), Gregory
Kienzl (ACT) and Tammy Lemon (P20 Connect). We received much helpful advice and
feedback from our program officers, Yvonne Belanger and Janet Salm, throughout the project, as
well as Judy Scott-Clayton who provided detailed comments on an early draft. We also thank
Beth Morton for research assistance, Rachel Urso for district and school recruitment, Claire
Gogolen for development and administration of the teacher survey, and Jon Fullerton and
Corinne Herlihy for feedback on data collection and analysis. Finally, we thank the thousands of
students, teachers and principals in the Tennessee high schools that participated in the study. The
views expressed herein are those of the authors and do not necessarily reflect the views of the
National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2019 by Thomas J. Kane, Angela Boatman, Whitney Kozakowski, Christopher Bennett,
Rachel Hitch, and Dana Weisenfeld. All rights reserved. Short sections of text, not to exceed two
paragraphs, may be quoted without explicit permission provided that full credit, including ©
notice, is given to the source.
College Remediation Goes Back to High School: Evidence from a Statewide Program in Tennessee
Thomas J. Kane, Angela Boatman, Whitney Kozakowski, Christopher Bennett, Rachel Hitch,
and Dana Weisenfeld
NBER Working Paper No. 26133
August 2019
JEL No. H52,H75,I21,I23,I24,J24

                                         ABSTRACT

Many U.S. students arrive on college campus lacking the skills expected for college-level work.
As state leaders seek to increase postsecondary enrollment and completion, public colleges have
sought to lessen the delays created by remedial course requirements. Tennessee has taken a novel
approach by allowing students to complete their remediation requirements in high school. Using
both a difference-in-differences and a regression discontinuity design, we evaluate the program's
impact on college enrollment and credit accumulation, finding that the program boosted
enrollment in college-level math during the first year of college and allowed students to earn a
modest 4.5 additional college credits by their second year. We also report the first causal
evidence on remediation's impact on students' math skills, finding that the program did not
improve students' math achievement, nor boost students' chances of passing college math. Our
findings cast doubt on the effectiveness of the current model of remediation--whether in high
school or college--in improving students' math skills. They also suggest that the time cost of
remediation--whether pre-requisite or co-requisite remediation--is not the primary barrier
causing low degree completion for students with weak math preparation.

Thomas J. Kane                                       Christopher Bennett
Harvard Graduate School of Education                 Vanderbilt University
Center for Education Policy Research                 230 Appleton Place
50 Church St., 4th Floor                             PMB 414
Cambridge, MA 02138                                  Nashville, TN 37203
and NBER                                             chris.bennett@vanderbilt.edu
kaneto@gse.harvard.edu
                                                     Rachel Hitch
Angela Boatman                                       Center for Education Policy Research
Department of Educational Leadership                 50 Church Street, 4th Floor
and Higher Education                                 Cambridge, MA 02138
Boston College                                       griffish@gse.harvard.edu
222 Campion Hall
Chestnut Hill, MA 02467                              Dana Weisenfeld
USA                                                  Center for Education Policy Research
angela.boatman@bc.edu                                50 Church Street, 4th Floor
                                                     Cambridge, MA 02138
Whitney Kozakowski                                   dana_weisenfeld@gse.harvard.edu
Harvard Graduate School of Education
Cambridge, MA 02138
wkozakowski@g.harvard.edu


A data appendix is available at:
http://www.nber.org/data-appendix/w26133
I. INTRODUCTION

         Given the large wage differences between high-school and college-educated labor,

governors in 42 states have set ambitious goals for increasing postsecondary attainment for their

residents by 2025 (Lumina Foundation, 2018.) To meet such targets, state leaders must find ways

to serve the large numbers of students arriving at college without the math and literacy skills

traditionally expected for college-level coursework. Among first- and second-year college

students nationally in 2011-12, 29 percent of students at public 4-year institutions and 41 percent

of those at public 2-year institutions reported taking at least one remedial course (Skomsvold,

2014).

         Given the high proportion of remedial students who never complete any degree,

advocacy organizations, such as Complete College America, have argued that remedial

requirements are an unnecessary barrier and a cause of non-completion, describing college-level

remediation as a "bridge to nowhere" (Complete College America, 2012). As a result,

postsecondary institutions in many states have been reducing the time and delay created by

remediation requirements (for instance, by allowing students to take remedial coursework

simultaneously with college courses.) Tennessee has taken a unique approach, adjusting both high

school curricula and postsecondary remediation requirements.

         In 2012, the state launched a pilot initiative, known as the Seamless Alignment and

Integrated Learning Support (SAILS) program. The goal of the program was to shift the locus of

math remediation from college back to high school. Unlike most states in which students learn of

their remediation status only after arriving at college and taking a placement test, Tennessee

notifies students of their remediation status in high school based on their junior year ACT score.

Students in SAILS-participating high schools who score below the remediation threshold of 19




                                                 1
on the ACT math test (roughly half of the seniors in those schools) can fulfill their math

remediation by completing an online, in-person math course during their senior year. Although

staffed by high school instructors, the course is modelled on the remedial course offered in

community colleges in Tennessee. Those who complete all five modules are exempted from math

remediation when they enroll at a Tennessee community college.

       Beyond assessing the results of Tennessee's unique approach to the remediation

challenge, we make three additional contributions to the research on remediation:

       First, we present a simple framework for interpreting the effect of remediation

requirements: the "achievement effect" and the "delay/displacement effect". Remedial courses

may boost students' understanding of math and allow them to make faster progress in subsequent

courses requiring such skills ("the achievement effect"), but at the cost of delaying or displacing

college-level courses (the "delay/displacement" effect.) By describing prior estimates as the sum

of two parts, we hope to resolve the apparent contradiction between the prior findings of small

negative effects of remediation and recent claims that remediation is a primary cause of high

drop-out rates. Both could be true, but only if both achievement and the delay/displacement

effects were large. The design of the Tennessee program allows us to estimate both separately.

       Second, we measure impacts of remedial coursework on math achievement using a

regression discontinuity design. Past research has overlooked such achievement impacts due to

lack of data on the counter-factual: while most students are assigned to remediation based on a

single test score, they complete remediation by passing the remedial course. Colleges rarely

collect posttest data for participants, and even less often do they gather such data for a

comparison group. Thus, in order to learn about the impact of SAILS, we administered a

posttest and student survey to high school seniors in 119 schools participating in the SAILS




                                                  2
program. Using an RD design, we compare the subsequent achievement and survey responses of

high school seniors who scored just above and below the threshold as juniors.

       Third, we measure the opportunity cost of remedial requirements under both pre-requisite

remediation (the "delay effect") and co-requisite remediation (the "displacement effect.") Prior

to 2015, Tennessee community colleges required students who had not completed SAILS to pass

their remedial coursework before enrolling in college-level courses ("pre-requisite remediation");

for the seniors of 2014-15 and 2015-16, Tennessee community colleges allowed students to do

their remediation as a co- requisite, taking remedial courses alongside college-level courses. Co-

requisite remediation has been seen as an increasingly popular alternative to high-school based

remediation such as SAILS, with several states such as Florida, California and Texas moving to

statewide adoption (Logue, Douglas, Watanabe-Rose, 2019). Although not imposing the same

delay created by pre-requisite remediation, co-requisite requirements may still crowd-out or

displace college level coursework, given constraints on students' time.     Depending on the year

in which a high school first began implementing the program, SAILS allowed students to avoid

either pre-requisite or co-requisite remediation. We measure both the "delay effect" of pre-

requisite remediation and the "displacement effect" of co-requisite remediation using a

difference-in-difference design, comparing the changes in student outcomes for high schools

implementing SAILS in different years. Since co-requisite remediation and high-school

remediation are viewed as alternative ways of achieving similar goals, the incremental effect of

SAILS once the co-requisite policy was in place is relevant to current policy discussions.

       We find that, under the pre-requisite policy, remediation-eligible students (i.e. those with

ACT math scores below 19) enrolled in college-level math at higher rates after their high schools

began implementing SAILS, resulting in a 13-percentage point increase in the percentage of




                                                  3
students having passed college math by the end of their first year. By the end of their second year

in college, SAILS participants completed 4.5 additional college credits (roughly 1.5 courses)

compared to their counterparts in high schools without SAILS.1 In other words, students were

able to complete an additional college level course in place of the remedial math course that was

waived. However, removing the delay of the remedial course did not lead to a burst of progress

beyond that course. In other words, it does not seem that remediation requirements were the

primary constraint getting in the way of college credit accumulation for students.

        Second, SAILS appeared to improve students' perceptions of the usefulness and

enjoyment of math. Students just below the ACT math cutoff of 19 were more likely to perceive

that their math course content would be useful in their careers, to indicate they were better

prepared for college math, and to say that they were interested in math than those immediately

above the remediation threshold.

        Third, despite the positive impacts on students' perceptions of math, there was no

difference in math performance on the posttest for those immediately above and below the

remediation threshold (although the latter often took the SAILS course and the former did not),

implying that the course had little impact on students' math achievement over and above the high

school math course they would have taken otherwise.

        Finally, after the co-requisite policy was introduced in the fall of 2015, SAILS no longer

had an impact on the percentage of students taking or passing college math during their first year,

nor on the total number of credits completed at the end of their second year. The co-requisite

policy largely superseded the SAILS program by allowing students to complete their remediation

alongside college-level courses, rather than before them. Once the co-requisite policy was in


1
 Our measure of college credits earned excludes those earned prior to high school graduation (e.g., dual
enrollment).




                                                         4
place, exempting students from co-requisite courses did not allow students to make any faster

progress toward their degrees.

       However, SAILS and the co-requisite policy were not perfect substitutes. Even without

additional impacts on credit accumulation, the SAILS model has an important advantage over the

co-requisite policy: the SAILS program allowed a quarter of remediation-eligible students to

fulfill their remedial requirements in high school, rather than wait to do so in college. Because

high school seniors in Tennessee are required to take four years of math, such a shift represented

a net cost savings for students and taxpayers (given that the pupil to teacher ratio in the SAILs

course was similar to other high school math courses.)

       In sum, either approach to replacing pre-requisite remediation-- moving remediation to

high school or allowing students to do math remediation as a co-requisite-- seems to allow

community college students to enroll in college math more quickly and to accumulate an

additional 1.5 college courses by the end of their second year. However, such findings also

suggest that the pre-requisite remediation requirement is not the primary barrier to credit

accumulation and degree completion for many students--since, if it were, we would have

expected a larger burst of credit accumulation than the single course. Moreover, the SAILS

program did not seem to increase students' math achievement. Because the SAILS course was

modelled on the course delivered in community colleges, our findings raise doubts about the

impact of those courses in remediating students' math skills as well. We close by discussing the

promise of alleviating other potential barriers to college completion, such as better college

advising and efforts to remediate math skills earlier in high school.




                                                 5
II. LITERATURE REVIEW AND THEORETICAL FRAMEWORK

       In theory, remedial course requirements produce two types of effects: 1) they refresh

students' content knowledge in math (the "achievement effect"), and 2) they delay (in the case of

pre-requisite remediation) or displace (in the case of co-requisite remediation) students' ability to

accumulate degree credits during their initial years in college (the "delay/displacement effect").

       The achievement effect and the delay/displacement effects could partially--or fully--

offset each other. The remedial course may accelerate students' progress in subsequent college-

level courses. However, the time required to take the remedial course also diverts a student from

accumulating college-level credits for a degree. The former is hopefully positive, the latter

negative. The net effect of any remediation policy depends on the sum of the two effects.

       Unfortunately, researchers have been unable to distinguish between the achievement and

delay/displacement effects, focusing instead on the net effect of being flagged for remediation.

For instance, Calcagno and Long (2008) compared community college entrants on either side of

the remediation threshold in Florida. While they found a small positive effect of being

recommended for remediation on persistence after the first year of college, they ultimately found

no differences in degree completion, transfer, or completion of college credits. Martorell and

McFarlin (2011) studied over 250,000 students in public two-and 4-year colleges in Texas and

found that being identified for remediation slightly reduced credit accumulation and years in

college, but had no impact on degree attainment. Scott-Clayton and Rodriguez (2015) found that

students recommended for remediation in a large, urban community college system were no less

likely to enroll in postsecondary education or earn a college degree and completed roughly the

same number of terms and college credits as those immediately above the cutoff. Using data from

Tennessee, Boatman and Long (2018) found that in the years before the SAILS program students




                                                 6
on the margins of needing one developmental math course were less likely to persist to the

second year in college, and 5 percentage points less likely to have completed a degree within

eight years.

       Two recent studies have examined the effects of remedial interventions offered early--

either in the summer or during a first semester. Early Start, adopted in 2012 in California,

requires incoming California State University students to complete their remedial math and/or

English requirements in the summer prior to beginning college. Using an RD approach,

Kurlaender, Lusher, and Case (2017) found no significant improvements in persistence or first-

term GPA for students identified as needing math remediation under Early Start. The second

study focused on the City University of New York's (CUNY) Start program, which launched in

2009. The program delays college enrollment for one semester for incoming students who are

assessed as needing remediation in math, reading, and writing, and instead provides intensive

instruction in math, reading, and writing during that semester. It also provides a number of

services that go beyond remediation: providing advising, tutoring, and study skills courses. In a

randomized experiment, eligible students were assigned to CUNY Start or to traditional remedial

courses. Early results indicate that the program leads students to remain enrolled in CUNY

colleges at higher rates during the second semester (Scrivener et al., 2018). The authors also

examined the effects on student learning. They found that the treatment group had higher

performance in math, reading and writing. However, given substantial differential attrition in the

treatment and control groups, it is impossible to know if the treatment caused the improvement

or if the estimated effect was driven by differences in the composition of test-takers in the two

groups (e.g., the students who did not improve were less likely to take the test, especially in the

treatment group.) Given these limitations, the authors describe their results as "suggestive."




                                                 7
       Nationally, only 34 percent of community college students who enroll in a remedial

course complete a degree within six years (BPS, 2009). Such statistics have led critics of

remediation requirements to claim that the relationship is a causal one--that remediation

requirements delay students needlessly and lead many students to drop out (i.e. remediation is a

"bridge to nowhere.") However, given that the previous research on the impacts of college

remediation suggests that being recommended for remediation has a moderately negative or null

effect on degree completion, there are only two possible hypotheses that would be consistent

with small net effects:

       First, remedial course requirements may generate delays for many students, but since the

net effect is small, it would also have to be the case that remedial courses allow students to make

substantially faster progress toward a degree (the "high delay/high achievement boost"

hypothesis.) Therefore, moving the remediation to high school and eliminating the delays

caused by remedial coursework in college would be expected to generate a large boost in

postsecondary attainment.

       Alternatively, it could be that both the achievement effect and the delay effects of

remediation are small (the "low delay/low achievement boost" hypothesis.) (Other possibilities,

such as the hypothesis that remediation is both costly in terms of time and unhelpful in terms of

achievement would not be consistent with the prior literature, because we would have expected

large negative net effects of being flagged for remediation.)

       Because the SAILS high school course is modelled on the remedial math course offered

in community colleges, the SAILS program essentially provides the achievement boost of

remediation, without the time cost in college. Thus, we first measure the impact on remediation-

eligible students when their high schools began offering SAILS under pre-requisite remediation.




                                                 8
Under the high delay/high achievement boost hypothesis, we would have expected to see a large

increase in college math enrollments, math completion and credit accumulation after schools

began implementing SAILS.

        Later, when public colleges in Tennessee adopted the co-requisite policy, we measure the

displacement effect of co-requisite remediation courses. Again, if the displacement effect of co-

requisite remediation requirements at community college were large, we would expect to see a

large increase in credit accumulation for students at the schools implementing SAILS for the first

time.

        In addition to measuring the effect of SAILS in reducing the delay/displacement involved

in college-level remediation, we also measure the impacts of SAILS on students' math

achievement by comparing achievement on a posttest for those immediately above and below the

cutoff for remediation. If the high delay/high achievement boost hypothesis were true, and there

was a large achievement boost from remediation, we would expect to see a large impact from

participating in SAILS on students' math achievement.

III. STATE CONTEXT

        In the fall of 2012, 68 percent of first-year, first-time community college students in

Tennessee were enrolled in one or more developmental or remedial courses (Tennessee Higher

Education Commission, 2014). For first-time, full-time students who entered Tennessee

community colleges in fall 2011, only 28 percent completed a credential within 6 years

(Tennessee Higher Education Commission, 2018). As in many states, the high rates of

remediation and the low rates of degree and certificate completion have led leaders in Tennessee

to see remediation requirements as a primary barrier to degree completion.




                                                  9
       Unlike most other states, Tennessee notifies students of their remediation status in high

school. Tennessee uses students' 11th grade ACT math test scores to assign students to remedial

courses. The vast majority of students (around 82 percent each year) take the ACT in school

during their junior year. Students scoring below 19 on the ACT math test are told that they will

need to take a remedial course in math if they enroll in a public college or university in

Tennessee. Students who complete the SAILS curriculum in high school can avoid that

requirement if they proceed to enroll in a Tennessee community college.

Tennessee SAILS Program

       The SAILS course is self-paced, with students progressing through the material on their

own schedule, either over one semester or across the whole school year depending on their

school's course schedule. The course material is delivered entirely online, including videos,

homework problems, and assessments. Most of the work is completed in class, although students

have the option of working outside of class as well. Teachers serve as learning partners and

coaches; although they occasionally provide direct instruction, their primary role is to monitor

students' progress through the online modules and provide guidance when students are stuck.

Students and teachers are assisted by a team of field coordinators distributed across the 13

community colleges and overseen by the Tennessee Board of Regents. Of the students who

enrolled in the SAILS course in 2015-16, the vast majority (92 percent) completed the course

successfully. Completion rates were similar in 2014-15 but were lower in 2013-14 (69 percent)

(Higher Education for Higher Standards, 2016).

       The program was rolled out to 20 high schools in 2012-13. With additional state support,

the program expanded each year, serving 122 high schools in 2013-14, 182 high schools in 2014-

15, and 243 high schools in 2015-16. Beginning in 2012, students in Tennessee high schools




                                                 10
were required to enroll in math during all four years of high school in order to receive their

diploma. Therefore, for students enrolled in SAILS, the course is substituting for another high

school math course such as Pre-Calculus, Statistics, and Advanced Algebra and Trigonometry, or

Bridge Math. Bridge Math covers similar remedial math concepts as SAILS, although it is taught

in a traditional, direct-instruction format. A key difference is that students who successfully

complete Bridge Math courses do not receive automatic exemption from math remediation in

Tennessee community colleges. Although Bridge Math continues to be taught in SAILS-

participating high schools, our results below suggest that SAILS participants are not being drawn

other senior math courses such as Advanced Algebra and Trigonometry and Statistics.2



The Tennessee Promise and Co-Requisite Remediation

         As the SAILS program was expanding, Tennessee became the first state in the country to

offer statewide, tuition-free community college education for recent high school graduates

(beginning with the high school class of 2014-15). The Tennessee Promise scholarship covers

the cost of tuition and fees for recent high school graduates attending community and technical

colleges, along with a small number of public and private 4-year institutions offering associate

degrees. It is a "last dollar" scholarship, covering the cost of tuition and required fees that remain

after subtracting grant aid from other sources (e.g., Pell Grant, Tennessee HOPE scholarship).

There are no minimum ACT or high school GPA eligibility requirements for the Tennessee

Promise. Approximately three quarters of first-time freshman at Tennessee community colleges

received the TN Promise in 2014-15 (Tennessee Higher Education Commission & Student

Assistance Corporation, 2018).


2
 As reported in Table 4, there was no statistically significant difference in Bridge Math enrollments at the
remediation threshold in the SAILS participating schools.




                                                         11
        Also in fall 2015, Tennessee's community colleges transitioned from a policy of pre-

requisite remediation to a co-requisite policy, in which students are required to enroll in a

remedial course simultaneously with their college-level course. Like SAILS, the new

remediation policy was intended to allow students to enroll in college-level coursework directly

(Tennessee Board of Regents, 2016). However, a key difference is that SAILS allows students to

avoid having to take the remedial class entirely, potentially freeing up time to take other classes,

while the co-requisite remedial classes may have crowded out course-taking for other students.

        Because the Tennessee Promise and the co-requisite policy were implemented at the same

time, it is not possible for us to isolate the independent effect of each. However, it seems that the

combination of policy changes did have substantial impact. Figure 1 presents the proportion of

students enrolling in postsecondary education for the high school seniors of 2010-11 through

2015-16. We report trends separately for those with ACT math scores below 19 (the remediation-

eligible) and for those with ACT math scores of 19 and above. We also report separately for the

institutions that were and were not eligible for Tennessee Promise scholarships.3 There was more

than a 10-point increase in the percentage of remediation-eligible students enrolling in

institutions eligible for the Tennessee Promise. There was a smaller increase in college entry

among those with ACT math scores of 19 and above. These increases were accompanied by a

small decline in entry at institutions not eligible for the scholarship.

        Figure 2 portrays the trend in the proportion of community college entrants taking and

passing college math during their first year as well as the average number of college credits

students completed by the end of their second year after high school. As in Figure 1, we report

the trends separately for those with junior year ACT scores above and below the remediation


3
 Eligible institutions included Tennessee community colleges, Tennessee Colleges of Applied Technology, and some
4-year colleges with associate degree programs




                                                       12
threshold of 19. When the co-requisite was implemented, there was a substantial (33-point)

increase in the percentage of remediation-eligible students taking college math. It was

accompanied by a smaller increase--15 percentage points--in the proportion of community

college entrants passing college math, implying that about half of the new entrants passed the

college-level course.



IV. DATA AND SAMPLE
      The Tennessee Department of Education (TDOE) provided K-12 administrative records,

including student enrollment, demographic characteristics, courses, and ACT scores on a 1-36

scale for all high school seniors in the 2010-11 through 2015-16 school years. We supplemented

the TDOE data with information on the characteristics of students' high schools, such as

urbanicity and the proportion of students eligible for free or reduced-price lunch, from the

Common Core of Data (CCD).4 The Tennessee Higher Education Commission (THEC) and

Tennessee Board of Regents (TBR) provided data on students' postsecondary enrollment and

community college course grades from 2010-11 through 2016-17, as well as college degree

completion from 2010-11 through 2015-16. ACT provided data for the ACT math test scores

taken in students' junior year for the graduating high school class of 2015-16. Finally, we

received information on student and school participation from the SAILS program itself.

        In addition, we administered a posttest and survey to a sample of approximately 16,000

high school seniors at 119 high schools that were implementing SAILS in 2015-16, excluding

high schools that were in their first year of SAILS. We focused our data collection for the

posttest and survey on students enrolled in certain senior year math classes: all Bridge Math and



4
 If a student attended more than one high school during their senior year, we used the school where they attended
more days.




                                                        13
SAILS classes, as well as all Advanced Algebra and Trigonometry, Pre-Calculus, and Statistics

classes. To lessen the burden on schools, we excluded students in advanced classes such as

Advanced Placement and International Baccalaureate classes, since these students were likely to

be far above the cut-off. For the posttest, we also excluded students taking geometry in their

senior year, as these students typically were scoring far below the threshold.5 Among students in

the targeted classes, we received posttest and survey results for 69 percent of students, or

approximately 11,000 students. Excluding students without valid answer sheets and those for

whom ACT and MeasureTN were unable to find a match, we collected responses from

approximately 61 percent of students in targeted classes.

        The 50-minute, 35-item posttest was an abbreviated version of the ACT math test.

Students took the assessment at the end of their senior year math course either in November 2015

(for fall semester courses) or April 2016 (for spring semester or full-year courses). The posttest

was scored by ACT and matched to students' prior ACT records and K-12 records from TDOE.

The new scale, which ranged from 333 to 680, provided a finer level of detail than the integer

scale ACT uses for public reporting, which allowed us to identify students within a fraction of a

point above and below the remediation cutoff of 19. In addition, during the last five minutes of

the posttest, students completed a 15-item student survey on topics such as perceptions of their

math courses, attitudes towards math, and postsecondary aspirations.




5
 We also included classes labeled Finite Math, Discrete Math, Core Mathematics, and Algebra II when we saw large
numbers of seniors enrolled. However, other courses, particularly junior year courses with less than three seniors
enrolled, were also excluded to alleviate the burden of in-class testing for these teachers.




                                                        14
Sample

         Table 1 presents the characteristics of 2015-16 seniors, by the year in which their high

school began offering the SAILS program. Because the SAILS program records were incomplete

for the 20 schools which implemented the program in 2012-13, we excluded those schools from

all years. The 101 high schools which began implementing SAILS in 2013-14 had somewhat

higher percentages of White students, fewer Black students, and higher high school graduation

rates for seniors than schools that implemented SAILS in the two subsequent years. However,

the three waves of high schools each had similar proportions of students scoring below the

remediation threshold of 19 (50, 53 and 49 percent respectively). Relative to the schools that had

never offered the SAILS program as of 2015-16, the SAILS schools were more likely to be rural

(36 vs. 17 percent), more likely to have students with ACT math scores below 19 (51 vs. 46

percent), and more likely to have a higher share of White students (75 vs. 65 percent).

         Table 2 compares the student characteristics of the sample to the underlying population at

each phase of sample selection. Column 1 describes the characteristics of all students in all

eligible schools in their second or third year of implementation in 2015-16. Column 2 reports the

characteristics of all students in the subset of schools that agreed to participate. The participating

schools were very similar to the eligible schools in most measures, including demographic

characteristics and test scores. Column 3 reports the characteristics of all students in the targeted

math classes in the participating schools. Students in the targeted classes tended to have lower

than average ACT scores, with 63 percent scoring below 19 compared to 54 percent in the full

sample. They were also more likely to participate in SAILS than the full population of students

in the participating schools (43 vs. 33 percent).6 Column 4 reports the characteristics of the


6
 They were also more likely to take senior year math (99 percent vs. 92 percent) and were more likely to graduate
conditional on beginning their senior year (96 percent vs. 93 percent).




                                                         15
students in the targeted classes for whom we have posttest outcomes. The sample with posttest

scores was similar to those in the targeted classes, with the exception that they have slightly

fewer days absent and are more likely to graduate. Students who dropped out during their senior

year or who were frequently absent may not have been present to take the test.

V. EMPIRICAL STRATEGY

       We use two different quasi-experimental approaches to measure the impact of the SAILS

program. First, we exploit the fact that SAILS was implemented in waves, with high schools

implementing the program in different years. For this analysis, we use a difference-in-differences

(DD) design, comparing the change in outcomes in schools in the year they began implementing

SAILS against the change for those that had not yet implemented or had implemented SAILS in

some prior year. Second, we use a RD design that exploits the assignment rule for remediation in

Tennessee: scoring below 19 on the ACT math test. In this analysis, we identify the impact of

being assigned to remediation of any kind (SAILS, co-requisite and pre-requisite) versus no

remediation by comparing students scoring just above the cutoff to those scoring just below the

cutoff for assignment to remediation.



Difference-in-Differences (DD) Design

       Using the sample of students who are recommended for remediation, we compare the

change in outcomes for students from high schools that implemented SAILS in a given year

against the change in outcomes for schools that had not yet implemented SAILS (or had

implemented it in a prior year.) The co-requisite policy was implemented in the fall of 2015,

affecting the high school graduating classes of 2014-15 and beyond. Therefore, by using the cohort

of students who graduated in 2013- 14, we can estimate the effect of the SAILS program in the




                                                 16
context of pre-requisite remediation. We use those graduating in 2014-15 and 2015-16 to estimate

the effect of the SAILS program in the context of co-requisite remediation. Specifically, we estimate

the following difference-in-differences model:



    1                 __                        __                                            



       In equation (1),     is an outcome for student i in high school s in year t.

__ equals one for high schools implementing SAILS in 2013-14, when the pre-

requisite policy was in force. __ equals one for all high schools adopting

SAILS in 2014-15 or 2015-16, after the co-requisite policy was adopted.  and  are high

school and year fixed effects respectively.  is a vector of time-invariant student demographic

characteristics.    is a stochastic error term. Standard errors are clustered at the high school

level. The sample is limited to 12th grade students who are flagged as needing remediation based

on whether they score below 19 on their first junior year ACT score.

       The key assumption underlying the DD strategy is that the year-to-year change in SAILS-

participating and non-participating schools would have been the same if not for the

implementation of SAILS. One common test of this assumption is to evaluate whether the

schools that adopted SAILS were already on a different trajectory prior to adoption. Appendix

Table A2 shows that for the majority of outcomes, the trends for SAILS and non-SAILS schools

were parallel in the lead-up to the adoption of SAILS.

       We also test whether there is any evidence that the composition of the student body is

changing with the introduction of SAILS. As reported in Appendix Table A3, we find no




                                                 17
evidence that the proportion of students who are female, Black, Hispanic, or white changes with

the introduction of SAILS relative to the change in non-SAILS schools.



Regression Discontinuity (RD) Design

       In addition, we estimate the following model to compare the outcomes of students just

above and just below the remediation cutoff of 19:



2               19                                19                                      

       In this model,  represents the outcome for a student i in school s. 19 is an

indicator for student i in school s having an ACT math score below 19.  represents a

student's junior year ACT math score (centered at the cutoff) and serves as the running variable.

For the class of 2015-16, we have a rescaled version of the ACT with a finer scale than the 1-36

scale used for public reporting (see Figure 4). For 2013-14, we have only the publicly reported 1-

36 scale.  are high school fixed effects, and  denotes a vector of student-level demographic

controls for race and gender.    is the idiosyncratic error term. In this model, the parameter of

interest is  which captures any discontinuous shift in the expected value of  at the threshold.

We cluster errors at the level of the high school. The main specifications use a bandwidth of +/-

25 points with the finer grained, rescaled ACT scores or +/- 4 points with the coarse ACT. (In

Appendix Tables A4-A8, we show sensitivity tests for wider and narrower bandwidths.)

       Because the students most eager to avoid remediation could retake the ACT, we use a

student's first ACT math score as the running variable. Following McCrary (2008), we check that

the density of students is smooth through the cutoff for each of the subsamples we use for our

estimates in Appendix Figures A1 and A2. We also test for balance in the covariates near the




                                                18
threshold. In Appendix Tables A4, A5, and A7, we see that student characteristics are generally

smooth through the cutoff for the samples that we use for the analyses. The few differences that

we observe at the .05 level are consistent with the number of false positives that we would expect

when testing this many hypotheses. Moreover, we control for these demographic characteristics

in our main estimates and find that the results are not sensitive to their inclusion.

VI. RESULTS

        In Table 3, we estimate the effect of SAILS by examining the change in student outcomes

for remediation-recommended students when their high school began using SAILS. To provide

some perspective in interpreting the magnitude of the impacts, we also report the mean outcomes

for the comparison students (those who had an ACT math score below 19 in high schools that

were not participating in SAILS).

        In the top panel, we report impacts on outcomes which apply to all high school seniors,

whether or not they enter postsecondary education. As reported in the top row, when a high

school began implementing SAILS, about 40 percent of remediation-recommended students

enrolled in SAILS. Our interviews with school staff suggested that individual student enrollment

decisions were based on a number of factors--including student's college aspirations or comfort

with technology. In some cases, schools did not have enough qualified teachers or a sufficient

number of computers to accommodate all eligible students (IMPAQ International, 2016).

Because we may not the various ways that students might be selected into SAILS, we measure

the effect of SAILS implementation on all students with scores below the threshold (that is, the

results in Table 3 are intent-to-treat estimates.)

        As reported in the remaining rows in the top panel, SAILS implementation was not

accompanied by any increase in high school graduation, postsecondary enrollment, or a change in




                                                     19
the type of postsecondary institution attended. Although not surprising given the program goals,

the finding suggests that there was not a significant change in the unmeasured characteristics of

college entrants.

        In the lower panel of Table 3, we report impacts for students who entered community

college within one year after graduating from high school. A school's implementation of SAILS

was accompanied by a 28-percentage point decline in the percentage of community college

entrants taking remedial math during their first year in college. In other words, SAILS

implementation succeeded in shifting the locus of remediation from college back to high school

for 28 percent of remediation-recommended community college students. The impact was

similar under the pre-requisite and co-requisite policies.7

        In the final rows in Table 3, we report impacts on the proportion of students taking and

passing college math during their first and second years in community college. Under the pre-

requisite policy, SAILS implementation was accompanied by a 14-point boost in the percentage

of remediation-recommended students taking college math during their first year, relative to 45

percent in the non-participating schools. After accounting for failures and withdrawals, there was

a 6.3-point boost in the percentage of remediation-recommended students passing college math

by the end of their first year in college, relative to 30 percent in non-participating schools. In

other words, we estimate that SAILS-implementation led to a 14-percentage point increase in

college math enrollment. A subset of these students--about 6.3 percentage points--passed




7
  To help explain why there was not a 100 percent reduction in college remediation among students attending SAILS
high schools, first, only about 40 percent of remediation-recommended students at participating high schools
enrolled in SAILS. Second, only 66 percent of students at non-participating high schools with ACT math scores
below 19 actually took remedial math in their first year of college. To avoid remediation, these students may have
retaken the ACT, taken the ACCUPLACER test once on campus, enrolled in anon-degree program, or delayed
taking remedial requirements to later years. The product of these two percentages (40 percent x 66 percent = 27
percent) is similar to the estimated reduction in remediation in Table 3 (28 percent).




                                                       20
college math. The ratio (6.3/14) implies that just under half of the new enrollees in college math

passed the course.

        The estimated impacts on the percentage of students taking and passing college math

were smaller by the end of the second year in college, as students from the non-participating high

schools had the opportunity to complete their remedial courses and enroll in college-level classes.

By the end of the second year, the estimated impact on the percentage of students passing college

math was still positive (2 percentage points), but it was no longer statistically significant.

        We estimate that SAILS implementation under the pre-requisite policy also resulted in a

small increase in the number of college credits students completed: 1.0 credit during the first

year and 2.2 credits by the end of the second year. Only 4 percent of remediation-recommended

community college entrants completed an associate degree within 2 years. An additional 4

percent of remediation-recommended students completed a certificate program. We saw no

statistically significant impact of SAILS implementation either on the proportion of students

completing an associate degree or completing a certificate within 2 years.8

        If we are willing to assume that SAILS had no effect on the outcomes of remediation-

eligible students who did not participate, we can infer the effect of the SAILS treatment on

participating students by dividing the average impact on each outcome by the participation rate.

For example, the 14-point increase in the percentage of remediation-recommended seniors taking

college math in their first year translates to a 29-percentage point increase in math enrollments

for SAILS participants. The 6.6-point increase in the percentage of students passing college math

translates to a 13-point increase in the percentage of SAILS participants passing college math.

The 2.2 credit increase in credits by the end of the second year translates to a 4.5 credit increase


8
  However, some students may not have been seeking an associate degree or certificate, and two years is shorter than
the length of time many students require to complete.




                                                        21
for SAILS participants. These are all similar in magnitude to the improvements we reported in

Figure 2 between 2013-14 and 2014-15, when community colleges moved to the co-requisite

policy and allowed students with ACT scores below 19 to enroll directly in college-level math.9

         Table 3 also reports the impacts of SAILS implementation for the high school seniors of

2014-15 and 2015-16, after the co-requisite policy was in place. As reported in the top panel,

there was a similar shift in the locus of remediation from college back to high school, as the

students from SAILS participating high schools were 28 percentage points less likely to enroll in

college remediation during their first year in college. However, we no longer estimate a positive

impact on the proportion of students taking or passing college math during their first year. In

fact, the estimates are negative. Likewise, the estimated impacts on college credits completed by

the end of the first and second year of college is not significantly different from zero.

         The negative effect on taking college math appears to be driven by the high schools

launching SAILS in 2014-15. As shown in Figure 3, the trend in college math course-taking for

the set of high schools that implemented SAILS for the first time in 2014-15 increased in 2014-

15 (with the co-requisite policy), but not by as much as it did for other high schools. However,

by 2015-16, college math course-taking from these 2014-15 SAILS adopters had caught up with

the other high schools. When we drop from our estimation the high schools implementing SAILS

in 2014-15, the estimated impact of SAILS implementation on college course-taking shrinks to

2.4 percentage points and is no longer statistically different from zero.10



9
  Since the policy applied to all remediation-recommended students, the "treatment on the treated" and the "intent to
treat" effects were the same for the co-requisite policy.
10
   There are a few reasons the 2014-15 cohort of schools adopting SAILS might have had students who were less
likely to enroll in college math in community college. First, students in the 2014-15 SAILS adopting high schools
may have disproportionately attended community colleges that were slower to adopt co-requisite remediation for all
students. Another possibility is that these students may have been disproportionately less likely to apply for and
receive Tennessee Promise. Since Promise required full-time enrollment, this could have reduced these students'
likelihood of taking college math in their first year relative to peers in other high schools.




                                                         22
       Both SAILS and the co-requisite policy eliminate the barriers to entry into college math.

However, there are two key differences. One is that the co-requisite course may displace

students' ability to take other college-level courses. Another difference is that the knowledge

imparted during the SAILS course may fade between the senior year in high school and the first

year in college, while the co-requisite course provides "just in time" remediation. Whether or not

either of these advantages for the two approaches were substantive, they seem to have canceled

each other out, as the net effect of SAILS implementation on credit accumulation under the co-

requisite policy was zero.

       Virtually all of the reduction in college remediation expenses for the 28 percent of students

shifting their remediation to high school would have represented a net cost savings, because

Tennessee high school students are required to take four years of math. As long as the cost of

offering a SAILS course was comparable to the cost of offering another high school math course,

any reduction in instructional expenditures on co-requisite math instruction on college campuses

would have represented a net cost savings.



Regression Discontinuity Results

       In Table 4, we report the differences in student outcomes at the remediation threshold. We

report the difference for four groups: for those in participating and non-participating high school,

for the graduating classes of 2013-14 and 2015-16. While the impact estimates in Table 3 were

identified based on the differential changes in outcomes when schools began implementing

SAILS, the impacts in Table 4 are identified by differences in outcomes for those just above and

below the threshold of 19. They need not be the same. The comparison group in Table 3

consisted of similar students in high schools that had not yet implemented SAILS (or had

implemented SAILS in some prior year), while the comparison group in Table 4 is the set of




                                                23
students with similar achievement and characteristics who just missed being recommended for

remediation. We conduct both analyses to determine if our results are robust to different

comparison groups. (As an additional check, Appendix Tables 6 and 8 present RD results based

on multiple bandwidths for graduating seniors from 2015-16 and 2013-14, respectively.)

       In SAILS-participating schools in 2013-14, students just below the remediation threshold

were 27 percentage points more likely to enroll in SAILS than those just above the threshold.

This is smaller than the 41-percentage-point estimate of participation in SAILS in Table 3. One

possible reason is that estimates in Table 3 are for all students scoring below 19, while the results

in Table 4 would apply to those with ACT scores right at the remediation cutoff.

       At SAILS-participating schools in 2013-14, we estimate that those who were just below

the remediation threshold were 26.9 percentage points more likely than similar students just

above the threshold to take a remedial math class during their first year at a community college.

However, that difference was even larger at the non-participating schools, where those below the

threshold were 48.5 percentage points more likely to take a remedial class. In other words, if a

school were to switch from non-participating to participating in SAILS, the difference between

the two (i.e., 21.6 points) would determine the reduction in remediation at the threshold.

       In non- participating schools in 2013-14, those with an ACT score just below the

remediation threshold were 13.8 percentage points less likely to take a college math course and

7.8 percentage points less likely to pass a college math course during their first year in a

community college. They also accumulated 1.8 fewer college credits during their first year in

college.

       In SAILS-participating schools, the differences at the remediation threshold were smaller

and not statistically significant. Although there were 101 high schools that began offering SAILS




                                                 24
in 2013-14, this represents only a quarter of all high schools in the state. As such, we cannot

generate a precise estimate of the difference in parameters in the SAILS-participating and non-

participating schools in 2013-14. Nevertheless, our results indicate that there was a difference at

the remediation threshold in the proportion of students taking and passing college-level math in

the schools not participating in SAILS. In the schools with SAILS, those differences were not

statistically significant, suggesting that SAILS helped to reduce the negative effects of

assignment to remediation.

       The bottom panel of Table 4 reports analogous differences in 2015-16, after the

implementation of the co-requisite policy. The difference in discontinuities suggests that entrants

from SAILS schools were 13.1 percentage points less likely to take remedial math than at non-

participating schools. Although about half as large as we estimated in Table 3, the results imply

that SAILS did shift the locus of remediation from college back to high school.

       However, under the co-requisite policy in 2015-16, there were no longer any statistically

significant differences at the remediation threshold in the proportion of students taking or

passing college-level math--either in the SAILS-participating or in the non-participating

schools. This is consistent with our earlier conclusion that SAILS implementation had no effect

on college math enrollment or passage once the co-requisite policy was in place. There was also

no difference in credit accumulation during the first year in community college between those

immediately below and above the remediation threshold of 19.



Posttest and Student Survey Results

       For the remaining results, we focus on students in the 119 SAILS-participating schools

that administered the posttest and student survey in 2015-16. In Figure 4, we report the




                                                 25
proportion of students in the 119 SAILS-participating high schools who actually enrolled in

SAILS in 2015-16 as a function of their ACT score. To more precisely locate where the jump in

participation occurs, we use the finer-grained measure of math achievement provided to us by

ACT. The vertical line corresponds to an ACT score of 19. About 50 percent of those with ACT

scores immediately below 19 enrolled in the SAILS program in these high schools, with a small

percentage (roughly 10 percent) of those immediately above the ACT cut-off of 19 enrolled in

SAILS. Those who scored a fraction of a point below the remediation cut-off were roughly 40

percentage points more likely to be enrolled in SAILS than those just above the cut- off.

       To measure the causal impact of SAILS, we focus on differences in outcomes for all

students above and below the remediation threshold, whether or not those students are enrolled

in SAILS. We avoid comparing student participants and non-participants in SAILS schools

because an individual student's enrollment decision is likely to be influenced by other factors for

which we cannot control (e.g., the strength of the students' plans to complete college, a

counselor's recognition that they need extra help, their school's ability to pay for computer

equipment). For all these reasons and more, the individual students enrolling in the SAILS course

are likely to differ from those with similar ACT scores who are not enrolled in SAILS. Rather

than assume that we can control for all the relevant differences for students' enrolling in SAILS,

we are more comfortable assuming that the average student, regardless of SAILS enrollment, are

similar just above and below the remediation cut-off.

       Nevertheless, it is still possible to estimate the impact for the average student enrolling in

SAILS using the RD method. As long as being recommended for remediation only impacts a

student's outcome if he or she actually enrolled in the SAILS math course, we can instrument for

SAILS participation and divide any difference in outcomes at the threshold by the 41-percentage




                                                 26
point difference in SAILS enrollment at the threshold. While the difference in student outcomes

at the remediation threshold tells us the average effect of offering SAILS to students, dividing

that difference by the difference in students enrolled in SAILS provides an estimate of the

average effect on the students participating in SAILS.

            As shown in Figure 5 and Table 5, it appears that the students in the SAILS classes

improved no more (or less) on the ACT posttest than the students taking other math classes

during their senior year. Thus, the estimated impact of the school's offering SAILS is not

statistically different from zero.

            Of course, the skills tested on the ACT may differ from the actual SAILS curriculum. As

a result, the SAILS team identified the specific test questions which were aligned with each of

the five modules included in the SAILS curriculum. We then constructed a measure of the

percent of those items that students answered correctly and conducted a similar analysis, looking

for evidence of differences in student performance above and below the cut-off, and did not find

evidence of differences between SAILS-enrolled and non-SAILS students for those items judged

to be aligned with the five modules.

            It is important to remember that the comparison students--those scoring just above the

remediation threshold--are also typically enrolled in a math course of some kind, since

Tennessee students are required to complete four years of math in order to graduate. Other than

SAILS and the other remedial math course, Bridge Math, the three most popular courses taken

by students with an ACT math score of 19 in our sample of high schools were Advanced Algebra

and Trigonometry (34.3 percent)11, Pre-Calculus (26.5 percent), or Statistics (21.9 percent).
                                                                                                                12
Approximately 10 percent of these students were enrolled in more than one math class. Thus,


11
     We also include small numbers of students who enrolled in Discrete Math and Finite Math.
12
     Less than 2 percent of this group seemed not to be enrolled in any math course during their senior year.




                                                                  27
the estimated impacts on the math posttest in Table 5 is not relative to the absence of a math

course, but relative to the average math course that high school seniors with ACT math scores in

the neighborhood of 19 typically take.13

         In Table 6, we report differences in survey-based outcomes for those immediately above

and below the ACT cut-off of 19. We did not find any significant differences in students'

postsecondary college plans for those with ACT scores immediately above or below 19.

However, we did find that students just below the cut-off of 19 were 6.6 percentage points more

likely to perceive that their math course content would be useful in their careers, 10 percentage

points more likely to report that they felt prepared for college math, and 6 percentage points more

likely to say that they were interested in math. We also found that students just below the 19

cutoff were 8 percentage points less likely to say that their classes stayed busy, which may have

been due to the self-paced instructional model used in the SAILS program. To convert these into

impacts per student enrolled in SAILS, we divide by the difference in SAILS enrollment at the

cut-off (41 percentage points).

         In Table 7, we report differences at the remediation threshold for different subgroups of

students by gender and race, and by type of high school attended. It is worth noting that the

impact on student perception of being better prepared for college math was particularly large and

positive for Black students (43 percentage points). Despite this perception, we did not observe an

impact on posttest scores or see a disproportionate increase in college math enrollment, math

passage, or accumulated credits for Black students (estimates available upon request).




13
  We also examined the fraction of students taking a given math course in their senior year above and below the cutoff in SAILS
schools in 2015-16. Just below the cutoff for assignment to remediation, SAILS participation seems to mostly come at the
expense of taking Advanced Algebra and Trigonometry, and to a lesser extent Pre- Calculus and Statistics.




                                                              28
       There was little difference in the impact of SAILS in high-poverty vs. low-poverty high

schools. However, we find that SAILS was associated with a small negative difference in math

achievement in the rural schools (-6.3 points on the rescaled ACT test). When divided by the

percentage-point difference in students enrolling in SAILS (44.4 percentage points), this would

imply about a half-point decline in ACT scores on a 36-point scale for students in rural high

schools enrolling in the SAILS course.

       We also calculated the percentage of students who had completed all five modules before

the end of the semester or year (with 10 percent of the class time remaining.) In effect, this is a

measure of students' rate of progression in the SAILS curriculum prior to the final weeks of the

semester or academic year. We observed that a large share of some schools completed the

modules in the final weeks and days of the semester, while students in other schools made more

steady progress throughout the course. In the 25 percent of SAILS schools with the lowest

completion rate by the last tenth of the semester, only 4 percent of students had completed all

five modules. In the top 25 percent of SAILS schools, 77 percent of students had completed

SAILS by that point. In the schools where many students completed the modules in the last days

and weeks (or didn't complete SAILS at all), students immediately below the threshold were 23.7

percentage points less likely to report that their class stayed busy than the students just above the

threshold. In the schools where a higher proportion of students had completed the five modules

with time remaining, students were no more or less likely to report that their class stayed busy. In

other words, students' perception that SAILS kept them less busy than other math classes was

concentrated in schools where large numbers of students completed the program in the closing

days or weeks.




                                                 29
VII. CONCLUSION

       In the fall of 2013, Tennessee Governor Bill Haslam announced the "Drive to 55"

campaign with the goal of nearly doubling the share of Tennesseans with a college credential

from 32 percent to 55 percent by 2025 (Drive to 55, 2018). At the time the Governor made the

announcement, half of Tennessee high school seniors had ACT math scores below the level

considered necessary for enrolling in college-level math in the state's community colleges.

       Over the last five years, the state implemented two major reforms to its remediation

policies: the SAILS program allowed students to complete their math remediation during the

senior year in high school, and the co-requisite remediation policy allowed students to complete

their remediation concurrently with college coursework. Our results suggest that both were

effective in opening the doors to college-level coursework, increasing the proportion of

remediation-recommended students taking college-level math in their first year at community

college by roughly 30 percentage points. However, the impacts were not additive. Once the co-

requisite policy was adopted, the main effect of SAILS has been to shift the locus of remediation

back to high school for roughly a quarter of remediation-recommended students, but with no

incremental effect on college math enrollments or credit accumulation beyond that yielded by the

co-requisite policy.

       In addition, our evidence suggests that SAILS is not improving students' math

achievement nor boosting their likelihood of passing college math once they take the course. Of

the additional students who were able to take college-level math after the introduction of SAILS,

only about half passed college math. In effect, until the co-requisite policy was in place, the

SAILS program opened the door to college-level math for many students and about half of the

incremental entrants made it through the course successfully. The co-requisite policy opened the




                                                 30
same door for the remaining students, with the same result: about half of the incremental entrants

passed the math course.

       In finding a small net effect of remediation, our results are consistent with the findings of

earlier studies. However, our additional contribution has been to identify that both the time cost

of remediation and the achievement effect of remediation are each small in magnitude. When we

saw little impact on postsecondary attainment when students began completing remediation in

high school, we learned that eliminating the time cost of college-campus-based remediation had

little impact. Yet when we observed no difference in senior year math achievement for those

enrolling in SAILS, we learned that the achievement effect was small as well.

       Therefore, achieving significant improvements in the number of Tennesseans with a

postsecondary credential will require identifying and clearing other barriers to college completion

and not simply reducing the time cost of remediation. For instance, students may be having trouble

navigating their way toward a degree, struggling to understand their course requirements or

switching between majors. In a review of remedial education reform efforts in recent years, Bailey

and colleagues (2016) found that programs with comprehensive, integrated, and long-lasting

student supports produced the largest increases in college success outcomes. For example, programs

like the City University of New York's (CUNY) Accelerated Study in Associate Programs (ASAP)

that offer students comprehensive advising, tutoring, and financial support have been shown to

have impacts on degree completion (Scrivener et al., 2015). Other institutions, such as Georgia

State University, have been reaching out to students during the summer, allowing students to

choose "meta-majors" with common course requirements during their freshman year, redesigning




                                                31
                                                                                                          14
their introductory math courses, and automating parts of their advising system. Some of these

approaches have been tested with comparison groups and have been shown to produce

improvements in postsecondary access and persistence (Page & Gehlbach, 2017), though others

have not yet been evaluated (Kurzweil & Wu, 2015).

         Our findings suggest a more thorough rethinking of the content and delivery of

remediation. For instance, it could be that the senior year in high school is too late to start. In a

study of the effectiveness of a double-period algebra course in the 9th grade in the Chicago

Public Schools, researchers found positive impacts on students' achievement in algebra (Nomi &

Allensworth, 2009). Later work found positive impacts on credits earned in high school, test

scores, high school graduation, and college enrollment rates (Cortes, Goodman, & Nomi, 2015).

It is also possible that the self-paced, online course is not well-matched to the needs of low-

achieving students. A growing body of work from college and high school settings has found that

students with lower levels of academic preparation perform less well in online courses than with

traditional instruction (Xu & Jaggars, 2013; Bettinger, Fox, Loeb, & Taylor, 2017; Heppen, et al.,

2017). Although SAILS is not purely online (there is a teacher in the room), it is possible that the

self-paced format is less effective for the students who have struggled with the material in the

past. If states cannot find a model of remediation that actually increases students' success in math,

the next step would be to evaluate the consequences of eliminating remediation requirements for

more students.

         Many students are emerging from high school without the skills traditionally expected for

college-level coursework. In order to reach ambitious goals for increasing degree completion


14
   Other states have begun using high school grades in combination with test scores for making remediation decisions. A recent
study in New York found that some of the students exempted from remediation based on a combined measure were able to pass
college math (Barnett et al., 2018). These findings support earlier research with similar conclusions (Belfield & Crosta, 2012;
Scott-Clayton, 2012; Scott-Clayton, Crosta, & Belfield, 2014).




                                                              32
among their residents, many states are rethinking their remediation requirements. Our analysis of

Tennessee's experience suggests that either allowing students to do their remediation in high

school or allowing students to complete remediation alongside college coursework (co-requisite

remediation) does allow students to complete a modest number of additional credits, but is

unlikely to have a major effect on college completion for this group. Boosting degree completion

will require a more effective model of math remediation--either in high school or college-- or

the elimination of others barriers to completion, such as inadequate advising or the level of math

required in gateway college courses.




                                                33
REFERENCES

Bailey, T., Bashford, J., Boatman, A., Squires, J., & Weiss, M. (2016). IES practice guide: Strategies
     for postsecondary students in developmental education ­ A practice guide for college and uni-
     versity administrators, advisors, and faculty. U.S. Department of Education, Institute for
     Education Sciences. Retrieved from https://ies.ed.gov/ncee/wwc/PracticeGuide/23
Barnett, E.A.,Bergman, P., Kopko, E., Reddy, V., Belfield, C.R., & Roy, S. (2018). Multiple mea-
    sures placement using data analytics an implementation and early impacts report. The Center for
    the Analysis of Postsecondary Readiness and MDRC. Retrieved from https://www.
    insidehighered.com/sites/default/server_files/media/CAPR_Multiple%20Measures%20
    Assessment%20implementation%20report_final%20%281%29.pdf
Belfield, C.R., Crosta, P.M. (2012). Predicting success in college: The importance of placement tests
     and high school transcripts (Working Paper No. 42). Community College Research Center:
     Teachers College, Columbia University. Retrieved from https://ccrc.tc.columbia.edu/me-
     dia/k2/attachments/predicting-success-placement-tests-transcripts.pdf
Bettinger, E.P., Fox, L., Loeb, S., & Taylor, E. (2017). Virtual classrooms: How online college
     courses affect student success. American Economic Review, 107(9), 2855-75.
Boatman, A. & Long, B.T. (2018). Does remediation work for all students?: How the effects of
    postsecondary remedial and developmental courses vary by level of academic preparation.
    Educational Evaluation and Policy Analysis, 40(1), 29-58.
Beginning Postsecondary Students (BPS) (2009). Authors calculations from NCES QuickStats.
Calcagno, J. C., & Long, B. T.(2008). The impact of postsecondary remediation using a regression
    discontinuity approach: Addressing endogenous sorting and noncompliance (NBER Working
    Paper. No. 14194). Cambridge, MA: National Bureau of Economic Research.
Complete College America. (2012). Remediation: Higher education's bridge to nowhere.
   Retrieved from https://postsecondary.gatesfoundation.org/report/remediation-higher-educa-
   tions-bridge-to-nowhere/
Cortes, K.E., Goodman, J.S., & Nomi, T. (2015). Intensive math instruction and educational
    attainment: Long-run impacts of double-dose algebra. Journal of Human Resources, 50(1),
    108-158.
Drive to 55 Alliance (2018). Home. Retrieved from http://driveto55.org/
Educause. (2014, July 14). Chattanooga State Community College: U Do the Math Program. Re-
    trieved from https://library.educause.edu/~/media/files/library/2014/7/ngp1403-pdf.pdf
Heppen, J. B., Sorensen, N., Allensworth, E., Walters, K., Rickles, J., Taylor, S. S., & Michelman,
     V. (2017). The struggle to pass algebra: Online vs. face-to-face credit recovery for at-risk
     urban students. Journal of Research on Educational Effectiveness, 10(2), 272-296.
Higher Education for Higher Standards (2016). Precollege interventions help increase college
    readiness, reduce remediation. Retrieved from
    http://higheredforhigherstandards.org/scalingsails/



                                                  34
IMPAQ International. (2016, June). SAILS Implementation Study: Final report. Unpublished
   manuscript.
Kurlaender, M., Lusher, L., & Case, M. (2017). Evaluating remediation reforms at the California
    State University. Presentation. Retrieved from https://edpolicyinca.org/sites/default/files/
    Kurlaender%20PACE%20Presentation%20Slides%20April%2021%202017.pdf
Kurzweil, M., & Wu, D.D. (2015). Building a pathway to student success at Georgie State University
    (Case Study). New York: ITHAKA S+R.
Logue, A. W., Douglas, D., & Watanabe-Rose, M. (2019). Corequisite Mathematics
    Remediation: Results Over Time and in Different Contexts. Educational Evaluation and
    Policy Analysis.
Lumina Foundation. (2018). A Stronger Nation: Learning beyond high school builds American
   talent. Indianapolis, IN: Lumina Foundation.
   http://strongernation.luminafoundation.org/report/2019/#nation
Martorell, P., & McFarlin, I., Jr. (2011). Help or hindrance? The effects of college remediation on
    academic and labor market outcomes. The Review of Economics and Statistics, 93(2), 436-
    454.
McCrary, J. (2008). Manipulation of the running variable in the regression discontinuity design:
   A density test. Journal of Econometrics, 142(2), 698-714.
Nomi, T., & Allensworth, E. (2009). Double-dose algebra as an alternative strategy to remedia-
   tion: Effects on students' academic outcomes. Journal of Research on Educational Effective-
   ness, 2(2), 111-148.
Page, L., & Gehlbach, H. (2017). How an artificially intelligent virtual assistant helps students
    navigate the road to college. AERA Open, 3(4), 1-12. https://doi.
    org/10.1177/2332858417749220
Scott-Clayton, J., Crosta, P.M., & Belfield, C.R. (2014). Improving the targeting of treatment:
    Evidence from college remediation. Educational Evaluation and Policy Analysis, 36(3), 371­
    393. http://epa. sagepub.com/content/early/2014/01/28/0162373713517935
Scott-Clayton, J., & Rodriguez, O. (2012). Development, discouragement, or diversion? New evi-
    dence on the effects of college remediation. National Bureau of Economic Research (Working
    Paper No. 18328). Cambridge, MA: NBER.
Scrivener, S., Gupta, H., Weiss, M.J., Cohen, B., Scott Cormier, M., & Brathwaite, J. (2018).
     Becoming college-ready: Early Findings from a CUNY Start Evaluation. Retrieved from
     https://www.mdrc.org/sites/default/files/CUNY_START_Interim_Report_FINAL_0. pdf
Skomsvold, P. (2014). Profile of undergraduate students: 2011­12 (NCES 2015-167). National
   Center for Education Statistics, Institute of Education Sciences, U.S. Department of
   Education. Washington, DC.




                                                 35
Tennessee Board of Regents. (2016). Seamless Alignment and Integrated Learning Support
    (SAILS). Information Sheet. Retrieved from https://www.tbr.edu/sites/tbr.edu/files/
    SAILSInfoSheet.pdf
Tennessee Higher Education Commission (2013). Seamless Alignment and Integrated Learning
    Support: Program overview and update. Presentation. Retrieved from https://www.inside-
    highered.com/sites/default/server_files/files/SAILS%20THEC%20Template.pdf
Tennessee Higher Education Commission. (2014). 2013-2014 Tennessee Higher Education Com-
    mission Fact Book. Nashville, Tennessee: Author.
Tennessee Higher Education Commission. (2018). 2017-2018 Tennessee Higher Education Com-
    mission Fact Book. Nashville, Tennessee: Author.
Tennessee Higher Education Commission & Student Assistance Corporation. (2018). TN Prom-
    ise Annual Report. Nashville, Tennessee: Author.
Xu, D., & Jaggars, S.S.(2013). The impact of online learning on students' course outcomes: Ev-
    idence from a large community and technical college system. Economics of Education
    Review, 37(C), 46­57.




                                               36
Figure 1. Postsecondary Enrollment by Institutions' TN Promise Eligibility




Notes: This figure presents the proportion of Tennessee high school seniors who enrolled in postsecondary
institutions within 1 year of high school, by junior-year ACT math score and TN Promise eligibility of the
institution. "Promise-eligible" institutions include Tennessee community colleges, Tennessee Colleges of
Applied Technology, two public 4-year institutions that offered associate's degrees (Austin Peay State
University and Tennessee State University), and several private institutions that offered associate's degrees
(e.g., Bryan College and Cumberland University).




                                                                                                                1
Figure 2. Postsecondary Progress for Community College Entrants




Notes: This figure presents descriptive outcomes for high school seniors who enrolled in a Tennessee community
college within 1 year after high school, by junior-year ACT math score. The left panel shows the overall
proportion of these community college entrants who enrolled in and passed college-level math within 1 year after
high school. The right panel shows the number of credits these community college entrants earned within 2 years
after high school. Credits earned exclude remedial math courses, but may include remedial reading and writing
courses due to data limitations.




                                                                                                               2
  Figure 3. Rates of College Math-Taking, by SAILS Cohort (ACT<19)




Notes: This figure plots the percentage of community college enrollees who took college math within year one
after high school, grouping students by when their high school adopted schools (if ever). The x-axis represents
students' senior year in high school. Students who are seniors in 2014-15 would have experienced co-requisite
remediation when they arrived at community college in Fall 2015.




                                                                                                                  3
Figure 4. Proportion of Students Taking SAILS by Rescaled ACT Score




Notes: Figure depicts SAILS participation among seniors at high schools that offered SAILS in 2015-16,
with a focus on students near the threshold for math remediation based on their junior-year pre-test. Rescaled
scores refer to the finer-grained junior-year ACT math scores that ranged from 333 to 680. A coarse score of
19 on the ACT math section corresponded to a rescaled score of 506, as indicated with a vertical red line.




                                                                                                            4
Figure 5. Score on Posttest by Pretest Score




Notes: Figure depicts ACT math post-test scores for students at high schools that offered SAILS in 2015-16,
with a focus on students whose ACT math pre-test scores were near the threshold for math remediation.
Rescaled scores refer to the finer-grained junior-year ACT math scores that ranged from 333 to 680. A
coarse score of 19 on the ACT math section corresponded to a rescaled score of 506, as indicated with a
vertical red line.




                                                                                                          5
Table 1. Characteristics of high schools by first year of SAILS implementation
                                 Year of SAILS implementation       As of 2015-16
                                                                       Ever      Never
 Student characteristics         2013-14     2014-15     2015-16      SAILS      SAILS
 Male                              0.51        0.50        0.51        0.51       0.51
 White                             0.80        0.67        0.70        0.75       0.65
 Black                             0.16        0.30        0.26        0.22       0.30
 Hispanic                          0.07        0.05        0.06        0.06       0.06
 English language learner          0.07        0.04        0.05        0.06       0.06
 IEP                               0.13        0.12        0.11        0.12       0.12
 Days absent                      12.76       12.89       10.62       12.40      10.61
 Graduate high school              0.92        0.89        0.86        0.90       0.88
 Urban high school                 0.31        0.26        0.34        0.30       0.42
 Suburban/town high school         0.33        0.42        0.30        0.34       0.41
 Rural high school                 0.36        0.32        0.36        0.36       0.17
 Took senior math                  0.90        0.89        0.87        0.89       0.88
 Took SAILS                        0.29        0.28        0.16        0.26       0.00
 Have ACT math (rescaled)          0.68        0.69        0.71        0.69       0.70
 ACT math                         18.37       18.06       18.47       18.30      19.23
 ACT math <19                      0.50        0.53        0.49        0.51       0.46

 12th grade students (N)          24,511       11,311     12,224      49,622      24,115
 Schools beginning SAILS
 (N)                                101          66         58
 Total schools using SAILS
 (N)                                120         180        236         245          166
 Notes: The table reports characteristics for 2015-16 seniors in schools that had started
 SAILS in 2013-14, 2014-15 or 2015-16. The label, "Ever SAILS," refers to schools
 that ever participated in SAILS between 2013-14 and 2015-16. Rescaled scores refer
 to the finer-grained ACT scores ranging from 333 to 680.




                                                                                            6
Table 2. Comparing the posttest sample to the full sample of eligible schools (2015-16)
                                   Eligible
                                   Schools             Post-Test Participating Schools
                                  (n==187)                        (n==119)
                                                                 Students in    Students
                                      All              All        Targeted      with Post-
                                   students         students       Classes        Tests
                                       (1)              (2)           (3)           (4)
 Male                                 0.51             0.50          0.49          0.49
 White                                0.76             0.75          0.75          0.78
 Black                                0.21             0.22          0.22          0.19
 Hispanic                             0.06             0.06          0.07          0.06
 English language learner             0.06             0.06          0.06          0.05
 IEP                                  0.12             0.12          0.06          0.05
 Days absent                         12.98            11.97         12.58         10.73
 Graduate high school                 0.91             0.93          0.96          0.99
 Urban high school                    0.29             0.28          0.28          0.25
 Suburban/town high school           0.36             0.36           0.37          0.38
 Rural high school                    0.36             0.35          0.35          0.37
 Took senior math                    0.90             0.92           0.99          1.00
 Took SAILS                           0.30             0.33          0.43          0.46
 Has ACT math                         0.78             0.80          0.86          0.89
 ACT math                           18.24            18.13          17.54         17.79
 ACT math <19                         0.52             0.54          0.63          0.63
 Have ACT math (rescaled)            0.69              0.75          0.83          0.89
 ACT math (rescaled)                499.40           499.05        494.74        497.72

 12th grade students (N)             37398           22317          15808         9560
 Notes: The eligible schools are the 187 schools which were in their second or third year
 of SAILS implementation in 2015-16. The eligible, participating schools are the subset
 of 119 schools which agreed to participate in the posttest and student survey. Column 3
 limits the sample to those students which were in classes that administered the posttest.
 Column 4 limits this sample further to those students which actually took the posttest.
 Rescaled scores refer to the finer-grained ACT scores ranging from 333 to 680.




                                                                                             7
Table 3. Difference-in-differences estimates of the effect of SAILS
                                                                                     SAILS Impact:
  Dependent Variable                                             Mean for        Under        Under               N
                                                                   Non-       Pre-requisite Co-Requisite
                                                                  SAILS       Remediation Remediation
  A. High School and College Enrollment                          Schools

     SAILS participant                                             0.00         0.407***        0.409***      198,091
                                                                                 (0.024)         (0.019)
     High School (HS) Graduate                                     0.92          -0.000          -0.001       198,091
                                                                                 (0.005)         (0.004)
     Enrolled in any college by spring of 1st year after HS        0.52           -0.004         0.017*       198,091
                                                                                 (0.010)         (0.010)
     Enrolled in 2 Yr college by spring of 1st year after HS       0.27           0.001           0.012       198,091
                                                                                 (0.009)         (0.009)
     Enrolled in 4 Yr college by spring of 1st year after HS       0.26           -0.006          0.004       198,091
                                                                                 (0.007)         (0.006)
  B. Postsecondary Outcomes for CC Enrollees
     Took remedial math by spring of 1st year                      0.66          -0.283***       -0.284***       49,502
                                                                                   (0.023)         (0.018)
     Took remedial math by spring of 2nd year                        0.72        -0.299***       -0.322***       39,985
                                                                                   (0.024)         (0.022)
     Took college math by spring of 1st year                         0.45         0.140***       -0.035***       49,502
                                                                                   (0.019)         (0.013)
     Took college math by spring of 2nd year                         0.53         0.066***       -0.055***       39,985
                                                                                   (0.017)         (0.014)
     Pass college math by spring of 1st year                         0.30         0.063***       -0.054***       49,502
                                                                                   (0.014)         (0.012)
     Pass college math by spring of 2nd year                         0.37           0.021        -0.062***       39,985
                                                                                   (0.014)         (0.014)
     Total credits earned by spring of 1st year                     16.33         0.965***          0.210        42,398
                                                                                   (0.274)         (0.298)
     Total credits earned by spring of 2nd year                     25.04         2.210***          0.736        34,339
                                                                                   (0.548)         (0.707)
     Return for 2nd year of college                                  0.62           -0.017          -0.012       39,985
                                                                                   (0.013)         (0.014)
     Earned associate's degree by 2nd year                           0.04           0.002          -0.003        39,985
                                                                                   (0.006)         (0.006)
     Earned certificate by 2nd year                                  0.04           0.008           -0.003       39,985
                                                                                   (0.008)         (0.007)
  Notes: Impact estimates for each outcome are coefficients on indicators for attending a SAILS high school under
  pre-requisite remediation (those graduating in 2013-14) under co-requisite remediation (those graduating after
  2013-14), the reference category being those attending non-SAILS schools in the same year. The sample is
  limited to public high school seniors between 2010-11 and 2015-16 with junior year ACT math scores below 19.
  All specifications include h.s. fixed effects and indicators for race, ethnicity, and sex. The sample for the lower
  panel is limited to students enrolling in a Tennessee community college within 1 year after high school,
  regardless of degree intention. Heteroskedastic-robust standard errors are clustered by high school and are
  reported in parentheses (*p<.10; **p<.05; ***p<.01).
                                                                                                                          8
Table 4. RD estimates of the effect of assignment to remediation in SAILS and non-SAILS high schools
                                                SAILS schools              Non-SAILS Schools

                                                            Control                         Control    Difference in
 Dependent Variable                           Discontinuity mean          Discontinuity      mean      Discontinuity
                                              2013-14 High School Seniors
 SAILS participant                               0.271***    0.14              0.000           0.00       0.271***
                                                  (0.035)                     (0.000)                       (0.035)
 Took Bridge course                                -0.030    0.20            0.162***          0.30       -0.192***
                                                  (0.027)                     (0.020)                       (0.034)
 Outcomes for TN CC Enrollees:                 [N=11,259]                  [N=23,287]
 Took remedial math by spring of 1st year        0.269***    0.03            0.485***          0.04       -0.216***
                                                  (0.035)                     (0.025)                       (0.043)
 Took math by spring of 1st year                  -0.062     0.69           -0.138***          0.67          0.076
                                                  (0.049)                     (0.033)                       (0.059)
 Pass math by spring of 1st year                   0.008     0.47            -0.078**          0.49          0.086
                                                  (0.044)                     (0.036)                       (0.057)
                                                [N=3,206]                   [N=5,232]
 Total credits earned by spring of 1st year        0.096     22.31           -1.797**         21.84         1.893
                                                  (1.108)                     (0.770)                      (1.349)
                                                [N=2,805]                   [N=4,621]

                                                2015-16 High School Seniors
 SAILS Participation                              0.340***       0.07             0.001            0.00       0.339***
                                                   (0.024)                       (0.002)                       (0.024)
 Took Bridge course                                 -0.007       0.11           0.093***           0.20      -0.100***
                                                   (0.017)                       (0.026)                       (0.031)
  Outcomes for TN CC Enrollees:                  [N=12,073]                    [N=5,806]
 Took remedial math by spring of 1st year         0.146***       0.02           0.277***           0.01      -0.131***
                                                   (0.020)                       (0.033)                       (0.039)
                                                    [3939]                       [1553]
 Took math by spring of 1st year                     0.050       0.72            -0.052            0.76        0.102*
                                                   (0.037)                       (0.054)                       (0.065)
                                                    [3939]                       [1553]
 Pass math by spring of 1st year                    0.080*       0.50            -0.011            0.59         0.091
                                                   (0.041)                       (0.063)                       (0.075)
                                                    [3939]                       [1553]
 Total credits earned by spring of 1st year         -0.288      24.78             0.775           24.05        -1.063
                                                   (0.900)                       (1.220)                       (1.516)
                                                    [3440]                       [1388]
 Notes: We assume a linear relationship to the running variable above and below the cut-off. ACT scores are integer
 values for 2013-14 and rescaled score with within-integer values in 2015-16. All regressions also include high school
 fixed effects and indicators for race, ethnicity, and sex. We use a bandwidth of 4 integer points in 2013-14 and 25
 rescaled ACT points in 2015-16. We provide estimates for a variety of alternative bandwidths in the Appendix
 Tables A6 and A8. Control means are calculated for students within 10 points above the cut-off on the rescaled
 measure or a single point using the integer ACT measure. Heteroskedasty-robust standard errors are clustered by high
 school and included in parentheses (*p<0.10; **p<0.05; ***p<0.01).
                                                                                                                       9
Table 5. RD estimates for posttest outcomes in sampled SAILS high schools
                                                                                                 Control
                                                                 BW25    BW15     BW35            mean
 SAILS Participation                                           0.410*** 0.378*** 0.433***         0.11
                                                                (0.037)  (0.047)  (0.033)
 Post Test Math Score                                            -0.199  -1.435   -0.866          501.67
                                                                (2.242)  (3.133)  (1.922)
 Post Test Math, % Correct                                       -0.001   -0.007  -0.004           0.40
                                                                (0.010)  (0.013)  (0.008)
 SAILS-Aligned Post Test Math, % Correct                         -0.002   -0.011   -0.002          0.46
                                                                (0.011)  (0.016)  (0.010)
 Percent correct on questions covered in module 1               -0.022*   -0.012  -0.014           0.39
                                                                (0.013)  (0.022)  (0.013)
 Percent correct on questions covered in module 2                 0.006   -0.027    0.008          0.47
                                                                (0.014)  (0.019)  (0.012)
 Percent correct on questions covered in modules 3, 4, and 5      0.007    0.006  -0.003           0.50
                                                                (0.020)  (0.026)  (0.015)

 Observations                                                       3,845       1,831      6,117
 Notes: For the outcome in each row, we report the discontinuity at the remediation cut-off of 19,
 assuming a linear relationship between the outcome and the rescaled ACT score (the running variable)
 and allowing for different slopes above and below the cut-off. Each specification also includes high
 school fixed effects and demographic controls for race, ethnicity, and sex. We use a bandwidth of +/-
 25 points on the fine-grained, rescaled ACT (whose total range runs from 333 to 680) for our main
 specification, but also include a narrower (+/- 15 points) and a wider bandwidth (+/- 35 points). The
 optimal bandwidths suggested by Calonico, Cattaneo, and Titiunik (2014) range from 22 to 27 for all
 outcomes. Posttest Math % Correct indicates the % correct on the posttest, as opposed to the scale score
 on the posttest. SAILS-aligned Posttest % Correct indicates the % correct on the items on the posttest
 that the SAILS staff indicated as aligned with the SAILS curriculum. Sample includes only high school
 seniors in the schools that participated in the posttest and student surveys in the 2015-16 school year.
 Control means are the mean outcomes for students within 10 points above the cutoff. Standard errors are
 clustered at the high school level. (* p<0.10; **p<0.05; *** p<0.01).




                                                                                                            10
Table 6. RD estimates for student survey outcomes in sampled SAILS high schools
                                                                                              Control
                                                         BW25        BW15         BW35         mean
 Intend to attend college                                -0.001      -0.010        0.013       0.86
                                                        (0.028)     (0.039)       (0.025)
                                                         [3699]     [1765]        [5847]
 Plan to attend 2-year                                   -0.040       0.002       -0.030       0.36
                                                        (0.035)     (0.060)       (0.029)
                                                         [3699]     [1763]        [5845]
 Plan to attend 4-year                                    0.002      -0.025        0.012       0.51
                                                        (0.039)     (0.065)       (0.032)
                                                         [3699]     [1763]        [5845]
 Highest expected attainment - AA or certificate         -0.011      -0.034       -0.019       0.18
                                                        (0.033)     (0.054)       (0.033)
                                                         [3694]     [1762]        [5840]
 Highest expected attainment - BA/BS or Higher            0.011       0.034        0.019       0.82
                                                        (0.033)     (0.054)       (0.033)
                                                         [3694]     [1762]        [5840]
 Course content useful in career                         0.065*     0.105*        0.062*       0.42
                                                        (0.037)     (0.054)       (0.032)
                                                         [3719]     [1769]        [5884]
 Better prepared for college math                       0.102**       0.093      0.088**       0.58
                                                        (0.040)     (0.067)       (0.034)
                                                         [3721]     [1769]        [5883]
 More interested in math                               0.059**        0.024       0.040*       0.20
                                                        (0.030)     (0.051)       (0.023)
                                                         [3715]     [1768]        [5873]
 Class stays busy                                      -0.080** -0.178*** -0.085***            0.74
                                                        (0.040)     (0.057)       (0.032)
                                                         [3714]     [1766]        [5871]
 Notes: For the outcome in each row, we report the discontinuity at the remediation cut-off of 19,
 assuming a linear relationship between the outcome and the rescaled ACT score (the running
 variable) and allowing for different slopes above and below the cut-off. Each specification also
 includes high school fixed effects and demographic controls for race, ethnicity, and sex. The
 sample includes only high school seniors in the schools that participated in the posttest and
 student surveys in the 2015-16 school year. Optimal bandwidths from Calonico, Cattaneo, and
 Titiunik (2014) range from 16 to 34 depending on the outcome. We use a bandwidth of +/- 25
 points on the fine-grained, rescaled ACT (whose total range runs from 333 to 680) for our main
 specification, but also include a narrower (+/- 15 points) and a wider bandwidth (+/- 35 points).
 Sample sizes (in brackets) vary slightly across outcomes due to differential response rates to some
 questions. Control means are the mean outcomes for students within 10 points above the cutoff.
 Standard errors are clustered at the school level (* p<0.10; **p<0.05; *** p<0.01).




                                                                                                        11
Table 7. Subgroup analysis of RD estimates for student survey and post-test outcomes
                                                                              Student Survey
                                                            Course
                                                            content       Better          More
                                  SAILS       Post-test    useful in  prepared for interested in            Class stays
                               participation math score      career   college math        math                 busy
Student-level
    Female                      0.409***        1.157         0.056      0.126**          0.068               -0.080
                                 (0.047)       (3.446)      (0.054)      (0.061)         (0.046)              (0.056)
                                  [2057]       [2057]       [1996]        [1996]         [1994]               [1992]
    Male                        0.403***        -1.185        0.069      0.089*           0.059               -0.081
                                 (0.051)       (3.181)      (0.058)      (0.052)         (0.047)              (0.053)
                                  [1788]       [1788]       [1723]        [1725]         [1721]               [1722]
    Black                       0.395***         1.771        0.196     0.433***          0.170                -0.183
                                 (0.073)       (5.977)      (0.122)      (0.133)         (0.107)              (0.119)
                                   [684]         [684]        [651]        [651]          [649]                 [650]
    White                       0.400***        -0.553      0.081*       0.077*           0.052               -0.051
                                 (0.038)       (2.511)      (0.041)      (0.042)         (0.034)              (0.041)
                                  [3072]       [3072]       [2982]        [2984]         [2980]               [2978]
School-level
    Rural high school           0.444***      -6.317**      0.100*       0.103*           0.028                0.016
                                 (0.061)       (3.032)      (0.058)      (0.055)         (0.052)              (0.056)
                                  [1550]       [1550]       [1487]        [1490]         [1486]               [1487]
    Non-Rural high school       0.391***        4.533         0.043       0.109*        0.082**             -0.145***
                                 (0.046)       (3.077)      (0.050)      (0.057)         (0.036)              (0.053)
                                  [2295]       [2295]       [2232]        [2231]         [2229]               [2227]
    High Poverty School:        0.429***         1.062        0.109        0.162          0.112               -0.053
      >=65% School FRPL          (0.075)       (4.776)      (0.079)      (0.096)         (0.066)              (0.105)
                                   [884]         [884]        [840]        [843]          [839]                [842]
    Low Poverty School:         0.422***        -6.895       -0.024        0.079          0.061               -0.093
      <=35% School FRPL          (0.068)       (5.564)      (0.057)      (0.106)         (0.056)              (0.097)
                                   [599]         [599]        [583]        [583]          [583]                [582]
    % Complete at 90%           0.285***       -0.256        0.045         0.161          0.099              -0.237**
     through the course: Q1      (0.089)       (4.917)      (0.074)      (0.126)         (0.087)              (0.104)
                                   [614]         [614]        [583]        [583]          [582]                [581]
    % Complete at 90%           0.344***        1.673        0.123         0.087          0.025                0.047
     through the course: Q4      (0.075)       (3.946)      (0.075)      (0.067)         (0.057)              (0.062)
                                  [1077]       [1077]       [1060]        [1059]         [1058]               [1058]
Notes: Each estimate comes from a local linear model that regresses the outcome of interest on an indicator for a
student having a rescaled ACT score that is equivalent to scoring below 19, a rescaled ACT math score centered at the
threshold, and an interaction of the two. All regressions include high school fixed effects and demographic controls for
race, ethnicity, and sex. Sample is limited to high school seniors in the 119 schools that participated in the post-test
and student surveys in 2015-16, who took the post-test/student survey, and are in the demographic subgroup denoted
in column 1. Sample sizes (in brackets) vary slightly across outcomes due to response rates. All regressions use a
bandwidth of +/- 25 points. Control means are the the mean outcomes for students within 10 points above the cutoff.
Heteroskedastic robust standard errors are clustered by high school and included in parentheses (*p<0.10; **p<0.05;
***p<0.001).


                                                                                                                        12
