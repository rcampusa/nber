                        NBER WORKLNG PAPER SERIES




          EFFICIENT ESTflIATION OF A DYNAMIC ERROR-SHOCK MODEL

                               C. Hsiao
                             P.M. Robinson



                       Working Paper No. 157




              National Bureau of Economic Research, Inc.
                       675 Technology Square
                    Cambridge, Massachusetts    02139




                             November 1976




                    Preliminary:     Not for Quotation

 NBER   rking papers   are   distributed informally and in   limited number   for
 corrments only. They should not be quoted without written permission.
 This report has not undergone the review accorded official NBER publications
 in particular, it has not yet been submitted for approval by the Board of
 Directors.

*Universjty of California and National Bureau of Economic Research. Research
 supported in part by National Science Foundation Crant SOC7S-18919.

Harvard University. Research supported in part by National Science Foundation
  Grant SOC7S—13'436.
                                   Abstract
                                                                                   .
This paper is concerned with the estirrtion of the parameters in a dynamic
simultaneous equation model with stationary disturbances under the assimption
that the variables are subj ect to random measurement errors. The conditions
under which the parameters are identified are stated. An asymptotically
efficient    frequency-domain class of instrumental variables estimators is

suggested.     The procedure   consists   of two basic   steps.   The first step
transforms the model in such a way that the observed exogenous variables
are asymptotically orthogonal to the residual terms. The second step involves
an iterative procedure like that of Robinson [13].
                                   Contents


1. Introduction                                   2

2.   Identification arid   a Consistent Initial
       Estimator

3. Efficient Estimation                           8


..   Coirrnents                                   19

References                                        22
                                                                                                            2


1.        Introduction

          We assume the existence of an underlying economic system of the form



(1.1)                 B(t.-) +                               =     ,       t   =   1,2


Here '          x     and        are discrete vector-valued covariance-stationary

processes of dimension G, K and G, respectively; they have mean vectors

               and zero, respectively, and satisfy E                   =   0, all t, S, the
prime denoting transposition. The B. and Ti are matrices (of dinien-

sions GxG and GxK respectively) B0 being nonsingular and all zeros

of det{          B.z3} being outside the unit circle.
             j=0
          In this paper we assume in general that all the quantities in (1.1)

are unknown or unobserved (except for certain elements of the B and

knowledge of which will identify the model -- see below). The estimation

of (1.1) in the case where one observes                      and x exactly for
t =   1,2,... ,T,       in the absence of stringent restrictions on the autocovariarice

structure of                 has been considered by Hannan and Nicholls [8] (for the

case G = K =          1),   Hannan and Terrell [9] (for the case p = q =                     0),   Espasa

and Sargan [1]. We relax this requirement by assuming that we observe


                             =
                                      ,x          =
                                                      +i    ,    t = l,...,T
The             and         are Gxl and Kxl vector processes which satisfy
      =    0, EtC =         ts2'     Ent =   0,       Entr = 652ir0,       EtX = 0, Etr = 0,
           =   0,           being Kronecker's delta. Clearly,                      and         are con-

sistently and efficiently estimated by ,                   =T                          = T
                                                                                                   x
                                                                 t=l               X
respectively.          However, it will be apparent from knowledge of the classical

errors-in-variables problem that standard estimators of the B3, Ti, that
                                                                                3

would be asymptotically efficient if 0 were a null matrix, will not in

general be consistent or efficient when 0 is non-null. We shall not be

concerned with estimating c because under our assumptions it will not

be identifiable. We do wish to estimate 0, however, along with the B.

r. by consistent and efficient methods. Since the t' like the
play the role of white noise measurement errors, an a priori
                                                                assumption
that will often not be unreasonable, and will prevent too large an expan-

sion of the parameter space over that in [8], [9], is that the elements of

    are contemporaneously uncorrelated. Therefore, we assume throughout

•that 0 is a diagonal matrix. Moreover, we shall allow for the possibility

that we know that one or more of the elements of     x is, almost surely,
observed without error for all t, in which case we fix the corresponding

diagonal element of 0 as zero. (We nowhere require 0, or 2, to be

nonsingular). Therefore, we have achieved a generalization of the usual

dynamic simultaneous equations model: prior information that an exogenous

variable is error-free is equivalent to an exclusion constraint on a para-

meter. This will fit in well with our other constraints on the
                                                                        r,
for we assume, for simplicity, that all these are also of the exclusion

type (apart from a normalization and sign constraint on each equation).

     Measurement errors with similar properties were considered by Goldberger

[4,5], Geraci [3], Hsiao [10], etc. However, in their work, only the

static case of (1.1) (the case p = q   =
                                           0) was considered, and the
were assumed to be white noise. The most significant difference is that

we are principally concerned here with the case where    Xt is not white

noise, when the identification problem may be solved by the use of lagged

observable exogenous variables as instruments. We pay some attention also

to the case where   Xt is white noise, when the lagged exogenous variables
                                                                                      4


are useless as instruments and a basically different approach is required.


2.      Identification and a Consistent InitialEstimator

        When (1.1) is transformed in terms of the observables y, x, we have



                                          +                       =
(2.1)


(2.2)                         =
                                   Et +           + r.ntj
We   define the discrete Fourier transforms

                                                      T
                              w(X) = (2iiT1'2 )
                                             t=l

                              w(A) = (2T)_h/2yte1tX

                              w (x)   = (2irT)            u e1
                               U
                                                      t=lt
and replace (2.1) by an asymptotic approximation to its Fourier transform,

                                                  =               A   / 0
(2.3)                B(X)w(X) +       r(x)w(x)        w(X)    ,




where


                     B(X) =        B.e        ,   r(x)    =       r.e
                              3=0                             j=03


 omitting the terms in p,              which are 0(ThhI'2) when A           0. The

 transformed system can be treated as a contemporaneous model. Thus,

 because          and {c}         are incoherent of {x} but                 is not,

 w(X) can be decomposed into a sum of two orthogonal components, one of
                                                                                              5


which (depending upon {r}) is correlated with w(A), and the other

(depending upon {Et} {}) is not. Therefore, the measurement errors in

       can be amalgamated with (c} to produce a composite, stationary,

residual term. It would be possible to identify 2 if, for example,
   =   0,   almost surely, all t, whence (1.1) is a homogeneous structural

relation between Xt) ,         and   u is a moving average sequence of order

max(p,q), but we shall not do this; we prefer to allow for the presence

of a stationary         in (1.1), to possibly represent exogenous variables

that should have been included in (1.1). We could, indeed, have omitted

explicit reference to a measurement error pertaining to ,                     and indeed

the assumption that this measurement error is white noise essentially plays

no role in our results. In any case, if 0 =             0,     there is no problem in

consistently estimating the B., F., but merely an efficient estimation

problem caused by the moving average in                 in (2.2): if            is a moving

average sequence of order r then the residual term is a moving average

of order rnax(p,r), and a vector extension of the methods of Haqnan and

Nicholls [8] may be appropriate. We are concerned only with the case

8 t 0, however.

       For simplicity, we assume that B(A) and F(X) are relatively left

prime, so that the redundancy in the specification can be eliminated

(Hannan [7]) and the a priori information on the              B. r is entirely in the
form of exclusion restrictions. We also assume that


                    Cx(i) =
                              E(xt_1.Ix)(xt+_ux)'   ,        j = 0,1,... ,r

are nonsingular and unrestricted for some r > 0. Furthermore, because of

the requirement that the instrumental variable estimates discussed in §3 do

not involve a singular matrix, we follow Fisher [2, Condition 6.2.1] in
                                                                                              6


assuming that the pG+ (q+1)K elements of t-l                               . X_q are
not connected by any linear identities, where                 =

with L the lag operator. A sufficient condition for this to hold is:

(a) all zeros det{              B.z3} and det{   F.z} are outside the unit circle;
        p      .         qj=0.3               j=03
(b) {   ) B.z},      {     F.z3} are relatively left prime; i.e., they have       I,,,   as
        j=03             j=03
greatest common left divisor; and (c) rank(Bp1'q) = G.               Then, by the same
reasoning as in Hsiao [11], one can show that the number of excluded predeter-
mined variables be at least as great as the number of included joint dependent
variables less one is what is necessary for the identification of the 1th
equation. If we let one element in each row of Bo be prescribed as unity
the necessary and sufficient condition to locally identify (2.1) is that at
least (G-l) zeros be prescribed in each row of


                          A =
                                [B      B1          B r0
                                                              •••
                                                                       ]

and the rank of each submatrix of A obtained by taking the columns of A

with prescribed zeros in a certain row is (G-l).

        If         is a white noise, i.e., C(j) = 0          for j > 0,    we need a

much stronger condition to identify the unknown parameters of the th equa-

tion of (2.1). In particular, in addition to the conditiQn that the number

of excluded predetermined variables has to be at least as great as the

number of included joint dependent variables plus the number of unknown

measurement error variances (associated with the included current and lagged

exogenous variables) less one, we need additional conditions on the way the

included current or lagged exogenous appear in the 1th behavioral equation.

Let h denote the number of th lagged included exogenous variables which

are not measured exactly. We arrange them in increasing order so that

h > h71,           for i =      1,2,... ,q.   That is, the th lagged included exogenous

variables contain more inaccurately measured variables than 1th lagged

variables. Then this additional necessary condition is that the number of
                                                                              7


th lagged excluded exogenous variables be at least as great as the number

of additional unknown measurement error variances which were not introduced

by h ,...,h'1. It seems unlikely that x+ will be white noise, in
                 3,                              I-



the   context of a time series model such as (1.1). Given the assumption

that           is white noise, Xt will be white noise if and only if   x is
white noise, and the latter question can easily be resolved by looking t

the    data.
       Another way of stating the identification conditions is that there

exists a sufficient number of instrumental variables. Thus, provided the

model is identified we can apply an instrumental variables method equation

by equation to obtain consistent estimates of the Ba's and ri's and 0 (see below).

The standard instruments will be the current or lagged exogenous variables

which do not appear in the equation under consideration. Since the measure-

ment errors among the exogenous variables are assumed to be uncorrelated,

the excluded exogenous variables can be used as instruments irrespective

of whether they are observed exactly.

        Theoretically, all the lagged exogenous variables can be used as

instruments and the addition of new instrumental variables will increase

the efficiency unless the partial correlation between each variable in the

relationship and the new instrumental variables is zero after the effects

on the other instrumental variables have been allowed for. In practice,

if the first few instruments are well chosen, there may be no great advan-

tage in increasing the number of instruments. Sargan [15] has shown that

the estimates have large biases if the number of instrumental variables

becomes too large. Actually, he suggested that the number of instruments

should not be greater than 1/20.
                                                                                               8




3.       Efficient Estimation

         We assume that the normalization conditions on the equations (1.1) are

that the diagonal elements of B0 are all units. We write


(3.1)                       B(X) 'G =                        r(x) =
                                           B(eP(X)ØIG)                r(eq(x)eIK)
                      B =                            r =
                             [BO_IG3Bl...BP]                [r0r1...rq]
             e(X)' =        [l,e,..    .
                                           ,e]      eq(A)' =    [l,e1X,... ix)

All      prior constraints on B and r             are    zero ones, and we incorporate theip

in a way like that in Robinson [12]. Suppose there are                        zero constraints

on B. Then the unconstrained ones may be written as the G2(p+1)X 1 vector

     =                where L1 is obtained from                       eliminating rows
         L1vec(B),
                                                            Iby
corresponding to zero elements. Likewise, if there are G2 zero constraints

on F we write the unconstrained parameters as y = L2vec(F),                      where L2

is obtained from 1Gk eliminating rows corresponding to zero elements.

Also, we write 0 =                           where L3 is obtained from the (K-F) xK2
                              L3vec(O),
matrix obtained from                 2 by eliminating rows corresponding to the off-
                                 K
diagonal elements and the F, 0 < F < K,                    a priori zero diagonal elements

of 0.
          Since all processes are covariance stationary, we define the vto-

covaraince and cross-autocovariance matrices


          C(i) =     E{(xtExt)(xt÷-Ext)'}                Cyx(i) =   E{(YEYt)(xt÷Ext)'}

 and we assume the existence of the spectral and cross-spectral density

matrices
                                                                                                                        9



            =
                    C(j)e•'JA                               =
                                                                     Cyx(j)e•••JX
                                                                                                     -r <   x   <   r

Similar notation will be used to denote second order properties pertaining

to other sequences. We note that f(x) = ®,                               -r < A < it.

        Now it is known that, under fairly wide conditions (see Hannan [6,

Chapter IV]) the limiting covariance between the discrete Fourier transforms

of two stationary sequences is the cross-spectral density of the sequences.

Thus

                                          *
(3.1)                lini Ew (A)w (A) =
                           U     X
                                                  fUX (x) =      r(x)o     ,       x     0
                     T-,OD




We therefore rewrite (2.3) as


(3.2)           w(A) = (IG-B(A))w(x)          -
                                                   r(x)(IKof         (xy1)w(x) +                 w(X)   ,




                             w,.(A)   =
                                          w(A)      —
                                                        r(x)of(x1w(x)
when     fX(X) is nonsingular, and where                           is the GxG identity matrix.

Now because of (3.1) and because


                             urn Ew(A)w (X)* =
                             T-o
                                       X
                                                            fx   (x) ,         A   0 ,


we have

                  Urn Ew(x)wx(x)* =
                                              f(x)      -
                                                                r(A)of(AY'f(x)               =   0


Thus, (3.2) possesses (asymptotically) the classical property of orthogonality

between the "exogenous variable" w(A) and the "residual" w1(X).
                                                                                                     10


        We now rewrite (3.2) as


                                                        -
(3.3)              w(A) =     -B(e(X)®w(X))                 r(eq(A)®wx(x))
                              +                                         +
                                  r(eq(x)ØIK)ofx(xY1wx(x)                   w(A)

We use the relation vec(ABC) =            (C'øA)vec(B)               to rewrite (3.3) as


(3.4)                              w(A) =    X(X)L'         + w.(A)

                                             =    (, ,y' ,e      )

            =
     X(A)
                [-(e(x)øw(x)øIG),(e'(x)øw'(A)®IK),w'(x)f(xY1ør(A)]
                                                       0     0
                                                 L1
                                        L= 0 L2 0
                                                 0 0 L3

        We shall consider (3.4) for I equally-spaced values of A pver

(-Tr,Tr],   denoted       =
                              2jiL/T,    -1/2 <       2. < [T/2].       Now it is known that under

fairly general conditions (see Hannan [6, Chapter IV])                       the w(wL) are
asymptotically independent (complex) normally distributed, with zero means

and covariance matrix f_(w2.). Now, f(X) and r(A), in

X(x), are unknown but consistent estimation of both is possible. Thus,

an asymptotically efficient instrumental variables method will be possible

after we find an appropriate instrument for w(A). and a consistent

estimate of


                                   f.(X) =
                                    U
                                             lim Ew(X)w(X)
                                                   U   U




The method we propose follows that of Robinson [12]. One major difference

is that in Robinson [12] no measurement error was allowed for. A second

major difference is that in [13] a system of differential equations was tQ

                                                                                                          .
                                                                                11



be estimated. The discrete approximation used there led, in the frequency

domain, to matrix polynomials in iX rather than, as here, in e1). As

noted in [13], the method applies to difference equation models if one

replaces iX by e1X. A third departure from [13] lies in the identifi-

cation conditions. In both cases, a fundamental feature of the identifi-

cation problem is an aliasing problem connected to the exogenous variables.

However, in [13] the problem is concerned with identifying a continuous-time

signal from knowledge of a discrete one, whereas here it is concerned with

extracting a signal in the presence of noise. A fourth difference from [13]

is that here an, initial consistent estimate of y, as well as of ,         is
essential.

      As in [13], iteration may well be desirable, and so we describe our

procedure as if it were iterative, although iteration produces no improve-

ment in efficiency. Our procedure is efficient in the sense that the limit-          )

ing   covariance matrix of our estimates is the same as that of maximum-

likelihood estimates based on Gaussian w(X). Efficient estimates could

also be obtained by a minimum-distance procedure, using a suitable metric

(like that in Robinson [14]). They could also be obtained by replacing

w(X) in (3.2) by its instrument, and then using a type of generalized

least squares (like that in Hannan and Terrell [9]). With all these procedures,

again, iteration is probably desirable, but providing they are initiated

with consistent estimates, and providing the type of iterative step taken

is appropriate, asymptotically efficient estimates will result after a

single step. The reason we concentrate on our procedure is that it seems

among the simplest to compute and to describe.

      Before describing the method, some interim computations must be detailed.

For an integer M, much less than T (see below) we introduce the 2M sets
                                                                                                                      12


              B = {xI                                                      Imi <M-l
               m          m       2M<m2M' AmM} '
                 = {Xj   -Ir<A<-1T(l -k), ir(1           -) <A<M}
with A = 0       omitted from               Then for all m, -M-I <                          m <   M,    we define


                                                         f (A ) =
                    =                                                               w
                         4 wy(w)w(w)*                     x m              I
                                                                                B
                                                                                         x (w)w(w)*
                              m
(35)
                    2M
             yxm -- T  wy(w)wx(w)*                 ,
                                                         xy(xm)
                                                                   =
                                                                           yx(xm)*
                        m


where the sums are over w e B .               We       assume that 2M/T is sufficiently
                         .Q  m
small for the number of                 in each B to be at least max(G,K). In

that case, ? (A )
            x m           will     in general be nonsingular.

        Now denote by x), (i) the                       estimates of r(x), 0 obtained on

the th iterative step, with ?°(x) (o) the consistent ones referredtoing2

and below. Then define                     so that ?(A) =                                                 Returning
                                                                       ?3(eq(X)øIK).
to (3.2), we consider the first-order Taylor approximation


(3.6)
             r(A)(rK_ofX(x))



                                   =
                                       +
                                           r(A)(IK-3fX(xY1)
                                                                           -
                                                                                rK-0fX
                                                        f(xy1)         +
                                       r(A)(IK-
                                                                                                       where
                                                           xL                           x (Am),
We   replace A by w, and then replace f (c )                               by       ?

        B.    Then we approximate (3.2), with A =                 wa,, by

     w (w) ?i(A m )3 (A )w (w) =  xm x                                                  +
                                                                                            w(w) ,              e



                                    r _e(w) ®w(u)
                 xc,x)' =
                                    [eq()ø(IKIx(AY1)wx(A)øIG]
                                      (xY1wx (u)er(x)'
                                        x
                                                                                                     13
                                                                                                          1)
        An estimate of f is needed. We first put


               (x) =                                       p(x)   =
                                                                          B(x)r(x)
                          _(x)(IK_ofx(xY1)            ,




The Sisolutionhi of   (3.2)   is thus


(3.7)          w(X) =      (A)w(X) +w(X)              ,    w(A)       =
                                                                          B(A1w_(X)

where urn Ew (X)w (A)* = 0.            We have, therefore,
         T-' X        V


(3.8)
                                       f(x)
                                                  = (x)f(x)
(3.9)            =
                          - xy fyx*               -                       +
                 =
                     f(x) -
(3.10)                             fu(x)


We thus define, using (3.9), (3.10),

                               =              -



                               =
                     0)(Xm)
where    Bi(X) =                              (i)
                     (eq(X)eIK).                          being the estimate of B from
the th step. On 'ater iterative steps an estimate of (x)                              that incor-
porates the prior constraints may be used. If                                 is the estimate of o

from the th step, define


(3.11)                    '() = _(i)(A)(I_ê(i)?(x)—1)
                                   =
                                                                         13a


As already noted, the (O) (O) may be one of many consistent instrumen-

tal variables estimates. A consistent       may be found by applying

minimum distance methods to (3.2), after replacing B(X), r(x), f(X) by

°(x), P(X), ?X(A). Then       from (3.8), (3.10), put




                                                                               .



                                                                               .
                                                                                  14


                     =
                                  mxym - yxm3)m)*
                         +

                     =



for j>1.
     We   now discuss the instrument for w(X). From (3.7) we would like to

     MA)w(A). The instrument for w(w) on the th step will therefore




(3.12)


where     .3)) is (3.11) for j >1, and

(3.13)                       0(A) =

(Cf. (3.8)). As noted earlier, we could replace w() by (3.12) in (3.6),
and then use GLS like in [9]. Our procedure might be preferred in that it

seems to involve one less approximation. On the other hand, the GLS approach

has the advantage in that, unlike ours, it involves the inversion of a

synietric matrix. (Of course, our matrix converges to a symmetric matrix.)

Both types of procedure reduce, essentially, to three stage least squares

(3SLS) in the classical simultaneous equations case p = q = K' =   0,    f..(A)

constant, a priori. As noted in Robinson [13], (3.13) is a narrow-band

version of the reduced form estimate used in 3SLS.

     We are now able to define our efficient estimates,


(3.14)               (j+l) =   (LD')Ll)_1Ld)   .     i   -°

where
                           =        z(J),x m)*X(J)(A m)
                               mwe8m
                           =
                               mweB
                                  Z(W m
                                      X)*wy(w)
                                             L



                      =
                          eq(w)ø(IK_3x(x)_1)wx(u)øs1)(A)_1
                                           r'(x) 11C1)(x)—l


     To prove asymptotic properties, conditions additional to those in

are needed. We describe these as follows. Let                        c} be mutuafly
independent sequences of independent, identically distributed (i.i.d.)

random vectors. Let {x} {c} be mutually independent sequences, inde-

pendent also of {},        {}, with representations
                                                                                                     .
(3.15)                    = _jt_ '                 =




where     {-rt}, {v} are i.i.d. sequences with finite second moments. Also,

let the spectra f(A), f(X)            Lip a, a >       - (i.e.   satisfy Lipschitz

conditions of order greater than one half, see Zygmund [16]). (This is

slightly stronger than assuming flaJ <             , flbff       <   , where     fl' is

the Euclidean norm.) Therefore, f (A) e Lip a, a > -.                 Thus,    assuming

det{f(A)} is bounded away from zero, f(X1 e Lip a, a >                         also,   since

it is a rational function of the elements of f(A). Therefore, (X)                         Lip   a,

a > .-.    Also,   from (3.1), (3.2) it may be inferred that


                                =          -
                                    f(X)       r(X)of(AY1®F(X)

We note, parenthetically, that this is nonnegative definite, as is apparent

                                                                                                     .
                                                                                       16


on rewriting it as


     f.(x) =   f(x)   + B(x)cB(x)* + r(x)(f(x)+f(x)f(xylf(x))r(x)*


Because          is involved in our estimates, we must assume also that f

is positive definite. Now from the above, we may infer that f(X)              Lip a,

a > -,    and thus f(A) e Lip a, a >         -. It   follows from Zygmund [16] that

f(A) may be written as




                       (ce13X)     (cjei3X)*

Thus, in a mean square sense, we may take the time domain structural resi-

dual process, orthogonal to                 to be      with spectrum f and
representation


                            =
                                 _ocjpt_j

with i.i.d.           the last fact being inferred from the fact that

{v} are i.i.d. sequences. Further, in the solution of the system,



                                     =
(3.16)
                                         !jxt_j + Vt
(i.e. the time domain version of (3.7)), v must have a representation



                          Vt =
                                  gjtj
where {} is an i.i.d. sequence. Thus, because xt}, f'} are strictly

stationary and ergodic sequences with continuous spectra, because also
                                                                                    17
                                                                                         •
EX5V;
          0, all s, t, and because t(X)
                                                 te13>
                                                             e Lip a, a >   -, we
can, essentially, analyze the estimates in terms of the model (3.16), for

which theorems in [6], [13] are available. A small additional condition

is needed in order for the error of approximation of the Fourier transform

of (3.16) by (3.12) to be asymptotically negligible in the central limit

theorem. Let            have finite fourth moments and cross moments and let

the fourth cumulant functions of all elements of x x x÷ x be
                                                         1      2   '3      4
finite and expressible as the (trivariate) Fourier transform of a cçntinuous

function for all t1, t2, t3, t4. Then x also possesses the latter

property.

        It should be noted that the theorem below would hold under weaker con-

ditions than those above; in particular our i.i.d. assumption could be

relaxed. We have used these conditions for simplicity of exposition, and

because the weaker conditions would be unfamiliar to many readers.

        We define a matrix



                                        D11 U12 13
                                    0= D2 022 023
                                        Dj3 D3 D33

where the partitions are (p+1)G2:(q+1)GK:K2, and



                011 =
                            Jep(_X)e,(X)®L(A)fx(_X)(A)*®f(A)_IdX

                012 =
                            J



                013 =   -
                                J   e(X)®(X)®f(XY1r(X)dX
                                                                                        18
                                                                                             1

                D22 -

                     -
                         J
                D33 = fx r(x)*f_(x)*(x)dx

      Theorem. Under the above conditions, there exists some sequence

M = M(T)        increasing as T -   , such      that      tS   almost   surely (a.s.)

and T1"2(-.6) has a limiting niultivariate normal distribution with

zero means and covariance matrix (LDL'), where 0 is strongly consis-

tently estimated by                j   >   o.

       The proof will not be given in detail, as it resembles theorems in

[8], [9], [13], [14]. In any case, the theorem need be proved only for

j =   1.   We first deal with consistency. ?(x), uiO)(Am) ?(O)(Xm)

                were replaced by f(u), fu(w9).         r(w)    A(üt),    w 8m'
strong consistency certainly follows. However, we note that under our

conditions, including those described in §2, the initial estimates will be

strongly consistent. Also, for some M(T) increasing with 1,



                                       yx yx f(x)                       fu(X)


a.s. and uniformly in X, where the band is roughly centered on, and

degenerates to, X (see [14]). Because of these results, it follows that

there is an M(T) such that the above replacement is possible and so

(l)        5.    Next we consider asymptotic normality. In this case, we can

show that we may replace ?x(Xm) m' r10)(xm), °(Am) by the
a.s. limits as I -           but    M stays fixed. Then in this situation
                                                                                    19


Tlf2(l)_5) can be shown to be asymptotically multivariate normal, from

[14].        On increasing M, then,the   covariance matrix converges to (LDL').

        We note that LDL'     is essentially the limit of the information matrix

based on Gaussian w...(w). Therefore, its nonsingularity requires local

identifiability of the model. Note that, if iJ(X)        is identifiable, 0

is   identifiable by the relation

(3.17)                        f(x) + )f(x)       =




4.      Comments

        1)     An alternative frequency domain approach to the problem of dealing
with measurement error      is that of simply eliminating from one's estimate

those frequencies that seem likely to have a small signal-to--noise ratio,

usually high ones (see [9], for example). This approach has the advantage

over ours of making no explicit assumptions about the autocovariance struc-

ture of the measurement error, and of being somewhat easier computationally.

However, the portion of the frequency band with a small signal-to-noise

ratio may be rather large, and so if all these frequencies are omitted

the resulting estimate may have rather large variance. Moreover, there may

be no frequencies for which the signal-to-noise ratio is really large; this

may be the case when, as we assume, the measurement error has uniform

spectrum. On the other hand, our approach would often seem to be more

efficient, for F will tend to be small relative to the number of other

parameters. Its disadvantage, however, lies in the very strong assumptions

about f, which, if invalid, might lead to serious bias. The choice would

often seem to depend on whether the danger of bias in our method seems

greater or less than the danger of large variances, and possibly bias


                                                                                         .
                                                                                 20


also resulting from the other one. Some clues may be available by inspect-

ing fX(X). If the diagonal elements tend, say, to be very large for

small Am but very small for large A. the frequency-elimination method

may be the more suitable. On the other hand, if ?x(Xm) is more stable

over (-7r,rr], our approach might be preferred. The assumption that f

be diagonal, as well as flat, may also be examined. If it is reasonable,

the fx(Xm) will tend to be very well conditioned with the product of the

1th and th diagonal elements substantially greater than the squared modulus

of the (1)th element, for all i, j. On the other hand, this phenomenon

would occur also if the elements of   x. have low coherence. A more direct

way of verifying the flatness and diagonality assumptions would be to use

(3.17), investigating which matrices 0 approximately satisfy


                                                =
                       yxm +    P°(Am)fx(Am)

for   each A
            m
      2)    It seems that a frequency-domain approach is particularly natural

in the present case. With many time series models, an alternative efficient

time domain approach is based on an autoregression specification for the

residuals. A low order autoregressive specification may produce better

results in moderate samples than a frequency domain one, which seems to

require both M and T/M to be fairly large. Thus, Hannan and Terrell

[9] consider both types of approach for estimating simultaneous equations

with stationary errors. However, in our case, the effects of the measure-

ment errors are such that in general no autoregressive transformation could

possibly produce a model with white noise residuals incoherent of {x}.

       3)   Our procedure has been developed with computational considerations

in mind, and in this respect it seems simpler than some other procedures
                                                                               21



that might be used. However, the computation of the estimates still   seems

a formidable task, particularly if there is iteration. Nevertheless, time

domain procedures, as well as seemingly rather inappropriate and inflexib'e

(see comment 2) seem unlikely to be much easier coniputationally. It is

true that it is a tedious task to express the components of the 6Li),

      in terms of the real and imaginary parts of the summands, particularly

as inverses of complex matrices are involved. However, complex arithmetic

can often be carried out directly on the computer.
                                                                                 22


                                  References


[1] Espasa, A. and J.D. Sargan, "The Spectral Estimation of Simultaneous
     Equation Systems with Lagged Endogenous Variables." Paper presented
     at the Third World Congress of the Econometric Society, Toronto,
     Canada, August 1975.

[2] Fisher, F.M., The Identification Problem in Econometrics. New York:
     McGraw-Hill, 1966.

[3] Geraci, J., "Simultaneous Equation Models with Measurement Error."
     Ph.D. Thesis, University of Wisconsin, 1974.

[4] Goldberger, A.S., "Structural Equation Methods in the Social Sciences."
     Econometrica 40 (1972), 979-1001.

[5] _______________, "Unobservable Variables in Econometrics." In Frontiers
       of Econometrics, P. Zarembka (ed.), New York: Academic Press, 1973.

[6] Hannan, E.J., Multiple Time Series. New York: Wiley, 1970.

[7] _____________, "The Identification Problem for Multiple Equation
     Systems with Moving Average Errors." Econometrica 39 (1971), 751-765.

[8]    ____________ and D.F. Nicholls, "The Estimation of Mixed Regression,
       Autoregression, Moving Average and Distributed Lag Models."                    )
       Econometrica 40 (1972), 529-547.

[9]    ___________ and R.D. Terrell, "Multiple Equation Systems with
       Stationary Errors." Econometrica 41 (1973), 299-320.

[10] Hsiao, C., "Identification and Estimation of Simultaneous Equation
     Models with Measurement Error." International Economic Review 17
     (1976), 319—339.
                                                                       —
[11]   _________, "Measurement Error in a Dynamic Simultaneous Equations
       Model with Stationary Disturbances." Paper presented at the Econometric
       Society annual meeting, Atlantic City, N.J., September 1976.

[12] Robinson, P.M., "Identification, Estimation and Large-Sample Theory
     for Regressions Containing Unobservable Variables." International
     Economic Review 15 (1974), 680-692.

[13] ______________, "Instrumental Variables Estimation of Differential
     Equations." Econometrica 44 (1976), 765-776.

[14]   —             , "Fourier Estimation of Continuous Time Models." In
       Statistical Inference in Continuous Time Economic Models,
       A.R. Bergstrom (ed.). Amsterdam: North-Holland, 1976.

[15] Sargan, J.D., "The Estimation of Economic Relationships Using Instru-
     mental Variables." Econometrica 26 (1958), 393-415.
[16] Zygmund, A., Tripnornetric   Series,   0..   Cambridge: Cambridge
                                                                         23
     University Press, 1959.




                                                                          .
