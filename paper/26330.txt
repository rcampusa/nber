                              NBER WORKING PAPER SERIES




                        ON FINTECH AND FINANCIAL INCLUSION

                                       Thomas Philippon

                                      Working Paper 26330
                              http://www.nber.org/papers/w26330


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                                   September 2019




This paper was prepared for the 2019 BIS Annual Research Conference. I am grateful to my
discussants Manju Puri and David Dorn, to Hyun Shin, Marina Niessner, and participants at the
2019 BIS Annual Research Conference. I thank Marcos Sonnervig for outstanding research
assistance. The views expressed herein are those of the author and do not necessarily reflect the
views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2019 by Thomas Philippon. All rights reserved. Short sections of text, not to exceed two
paragraphs, may be quoted without explicit permission provided that full credit, including ©
notice, is given to the source.
On Fintech and Financial Inclusion
Thomas Philippon
NBER Working Paper No. 26330
September 2019
JEL No. G11,G2,G5,L1,N2

                                         ABSTRACT

The cost of financial intermediation has declined in recent years thanks to technological progress
and increased competition. I document this fact and I analyze two features of new financial
technologies that have stirred controversy: returns to scale, and the use of big data and machine
learning. I argue that the nature of fixed versus variable costs in robo-advising is likely to
democratize access to financial services. Big data is likely to reduce the impact of negative
prejudice in the credit market but it could reduce the effectiveness of existing policies aimed at
protecting minorities.


Thomas Philippon
New York University
Stern School of Business
44 West 4th Street, Suite 9-190
New York, NY 10012-1126
and NBER
tphilipp@stern.nyu.edu
   Fintech covers digital innovations and technology-enabled business model innovations in the financial sector.

Such innovations can disrupt existing industry structures and blur industry boundaries, facilitate strategic dis-
intermediation, change how existing firms create and deliver products and services, provide new gateways for
entrepreneurship, and democratize access to financial services. On the other hand, they create significant privacy,
regulatory and law-enforcement challenges and they could increase the scope for some forms of discrimination.
Examples of innovations that are central to Fintech today include various application of blockchain technologies,
new digital advisory and trading systems, artificial intelligence and machine learning, peer-to-peer lending, equity
crowdfunding and mobile payment systems. In this paper I offer some preliminary evidence and theoretical analysis
about the impact of technological progress in the finance industry.
   The first question is whether there has been any material change in financial intermediation in recent years.
To shed some light on this question, I update the work of Philippon (2015) with post-crisis U.S. data. The puzzle
emphasized in previous work was that the unit cost of financial intermediation had remained stubbornly close to 200
basis points for more than a century, despite advances ­ and large investments ­ in computers and communication
technologies. The post-crisis data suggests that this puzzle might be diminishing. I find that the unit cost of

financial intermediation has declined over the past 10 years.
   I then study two issues that are at the heart of the Fintech debate: access to finance and discrimination. If we
accept the fact that Fintech brings efficiency gains to financial intermediation, the next question is: how will these
gains be shared? Will Fintech democratize access to financial services or will it increase inequality?
   I highlight two forces that will shape the answer to these questions. The first is increasing returns to scale
brought by technology. I illustrate how this force plays out in the context of asset management and robo-advising.
Investors select advisors and advisors help them choose their investments (Pedersen, 2015). Search costs imply that
wealthy households have access to better advice. I argue that robo-advising and related technologies will change
the nature of fixed costs in a way that is likely to improve access to financial services. It may not, however, reduce
inequality among all groups.
   The second force is the use of big data and machine learning (BDML for short). I illustrate how this force plays
out in the context of consumer credit. I argue that this technology is likely to reduce unwarranted human biases
against minorities, but it will probably decrease the effectiveness of existing regulations. The tentative conclusion is

that Fintech can bring widely-shared welfare benefits but changes in existing policies and regulations are necessary
to achieve its full potential.


Recent literature      Philippon (2016) discusses the literature up to 2016 so I will mention here some recent papers.
Petralia et al. (2019) discuss the impact of new technologies on the banking industry. Focusing on residential
mortgages, Buchak et al. (2018) study the growth in the market share of shadow bank and Fintech lenders, arguing
that it can be explained by differences in regulation and technological advantages. They find that Fintech lenders



                                                           2
serve more creditworthy borrowers (relative to shadow banks) but charge higher interest rates (14-16 basis points),

which is consistent with the idea that consumers are willing to pay for better user experience and quick decisions.
Fuster et al. (2019) study the differences between Fintech and traditional lenders in the mortgage market and
find that the former is quicker in processing applications (20% faster), without increasing loan risk. They also
provide evidence that Fintech lenders adjust supply more elastically to demand shocks and increase the propensity
to refinance, especially among borrowers that are likely to benefit from it. Their results suggest that Fintech firms
have improved the efficiency of financial intermediation in mortgage markets.
    The advent of Fintech is often seen as a promising avenue for reducing inequality in access to credit. Bartlett
et al. (2018) study this issue, analyzing the role of Fintech lenders in alleviating discrimination in mortgage markets.
They find that all lenders, including Fintech, charge minorities more for purchase and refinance mortgages but that
Fintech algorithms discriminate 40% less than face-to-face lenders. Regarding the use of new technologies in credit
markets, Berg et al. (2019) analyse the information content of the "digital footprint" (an easily accessible information
for any firm conducting business in the digital sphere) for predicting consumer default. Berg et al. (2019) find that
the predictive power of these new data equals or exceeds that of traditional credit bureau scores. Their results

suggest that new technologies and new data might bring a superior ability for screening borrowers.
    Fintech firms are also competing in the market for wealth management. The United States is the leading market
for robo-advisors. In 2017, it accounted for more than half of all investments in robo-advisors (Abraham et al.,
2019). Nevertheless, the amount of assets managed by robo-advisors is still a small portion of total assets under
management, with average client wealth much smaller than the average in the industry (Economist, 2017). Abraham
et al. (2019) argues that because they save on fixed costs (such as salaries of financial advisors or maintenance of
physical offices), robo-advisors can reduce minimum investment requirements and charge lower fees. Finally, one
area that is not well developed is the study of the interaction between Fintech and incentives within organizations.
This is likely to be relevant for discrimination and other biases. For instance, Dobbie et al. (2018) show that the
misalignment of incentives inside financial firms can lead to biased lending decisions.



1     (In)efficiency of the Existing System

The main finding in Philippon (2015) is that the unit cost of financial intermediation in the U.S. has remained
around 200 basis points for the past 130 years. Improvements in information technologies have not been passed
through to the end users of financial services. This section offers an update of this work.


1.1    Financial Expenses and Intermediated Assets

To organize the discussion I use a simple model economy consisting of households, a non-financial business sector,

and a financial intermediation sector. The details of the model are in the Appendix. The income share of finance,



                                                           3
shown in Figure 1, is defined as1

                                              f
                                             yt   Value Added of Finance Industry
                                                =                                 .
                                             yt               GDP

The model assumes that financial services are produced under constant returns to scale. The income of the finance
          f
industry yt is then given by
                                                   f
                                                  yt = c,t bc,t + m,t mt + k,t kt ,                                                     (1)

where bc,t is consumer credit, mt are assets providing liquidity services, and kt is the value of intermediated corporate
assets. The parameters i,t 's are the unit cost of intermediation, pinned down by the intermediation technology.
The model therefore says that the income of the finance industry is proportional to the quantity of intermediated
assets, properly defined. The model predicts no income effect, i.e., no tendency for the finance income share to grow
with per-capita GDP. This does not mean that the finance income share should be constant, since the ratio of assets
to GDP can change. But it says that the income share does not grow mechanically with total factor productivity.
This is consistent with the historical evidence.2
    Measuring intermediated assets is complicated because these assets are heterogenous. As far as corporate finance
is concerned, the model is fundamentally a user cost model. Improvements in corporate finance (a decrease in k )
lower the user cost of capital and increase the capital stock, which, from a theoretical perspective, should include
all intangible investments and should be measured at market value. A significant part of the growth of the finance

industry over the past 30 years is linked to household credit. The model provides a simple way to model household
finance. The model also incorporates liquidity services provided by specific liabilities (deposits, checking accounts,
some form of repurchase agreements) issued by financial intermediaries. One can always write the RHS of (1) as
              m,t          k,t                                                       m,t         k,t
c,t bc,t +    c,t mt   +   c,t kt   . Philippon (2015) finds that the ratios         c,t   and   c,t   are close to one.3 As a result
one can define intermediated assets as
                                                          qt  bc,t + mt + kt .                                                          (2)

The principle is to measure the instruments on the balance sheets of non-financial users, households and non-
financial firms. This is the correct way to do the accounting, rather than looking at the balance sheet of financial
    1 Philippon (2015) discusses various issues of measurement. Conceptually, the best measure is value added, which is the sum of

profits and wages. Whenever possible, I therefore use the GDP share of the finance industry, i.e., the nominal value added of the finance
industry divided by the nominal GDP of the U.S. economy. One issue, however, is that before 1945 profits are not always properly
measured and value added is not available. As an alternative measure I then use the labor compensation share of the finance industry,
i.e., the compensation of all employees of the finance industry divided by the compensation of all employees in the U.S. economy.
Philippon (2015) also explains the robustness of the main findings to large changes in government spending (because of wars), the rise
of services (finance as a share of services displays a similar pattern to the one presented here), globalization (netting out imports and
exports of financial services).
    2 The fact that the finance share of GDP is the same in 1925 and in 1980 makes is already clear that there is no mechanical relationship

between GDP per capita and the finance income share. Similarly, Bickenbach et al. (2009) show that the income share of finance has
remained remarkably constant in Germany over the past 30 years. More precisely, using KLEMS for Europe (see O'Mahony and Timmer
(2009)) one can see that the finance share in Germany was 4.3% in 1980, 4.68% in 1990, 4.19% in 2000, and 4.47% in 2006.
    3 This is true most of the time, but not when quality adjustments are too large. Philippon (2015) provides calibrated quality

adjustments for the U.S. financial system.




                                                                     4
intermediaries. After aggregating the various types of credit, equity issuances and liquid assets into one measure, I

obtain the quantity of financial assets intermediated by the financial sector for the non-financial sector, displayed
in Figure 1.


                                             Figure 1: Finance Income and Intermediated Assets




                                             .08




                                                                                                                              4
                                                                                                                              Intermediated Assets/GDP
                                                  .06




                                                                                                                                                 3
                                       Share of GDP
                                     .04




                                                                                                                                   2
                                             .02




                                                                                                                              1
                                                        1880   1900   1920       1940     1960    1980     2000        2020
                                                                                    year...

                                                                  Share of GDP              Intermediated Assets/GDP


Notes: Both series are expressed as a share of GDP. Finance Income is the domestic income of the finance and insurance industries, i.e.,
aggregate income minus net exports. Intermediated Assets include debt and equity issued by non financial firms, household debt, and various
assets providing liquidity services. Data range for Intermediated Assets is 1886 - 2012. See Philippon (2015) for historical sources and details
about the underlying data.




1.2     Unit Cost and Quality Adjustments

I can then divide the income of the finance industry by the quantity of intermediated assets to obtain a measure of
the unit cost
                                                                                           f
                                                                                          yt
                                                                                 t           .                                                           (3)
                                                                                          qt

Figure 2 shows that this unit cost is around 2% and relatively stable over time. In other words, I estimate that it
costs two cents per year to create and maintain one dollar of intermediated financial asset. Equivalently, the annual
rate of return of savers is on average 2 percentage points below the funding cost of borrowers. The updated series
are similar to the ones in the original paper. The unit costs for other countries are estimated by Bazot (2013) who
finds convergence to US levels.


    The raw measure of Figure 2, however, does not take into account changes in the characteristics of borrowers.

These changes require quality adjustments to the raw measure of intermediated assets. For instance, corporate
finance involves issuing commercial paper for blue chip companies as well as raising equity for high-technology start-
ups. The monitoring requirements per dollar intermediated are clearly different in these two activities. Similarly,
with household finance, it is more expensive to lend to poor households than to wealthy ones, and relatively poor




                                                                                      5
                                             Figure 2: Unit Cost of Financial Intermediation
                                                                      Unit Cost




                                    .03
                                    .025
                                    .02
                                    .015
                                    .01
                                    .005
                                    0




                                           1880   1900   1920      1940          1960     1980     2000   2020
                                                                          time

                                                                2012 Data               New Data


Notes: The raw measure is the ratio of finance income to intermediated assets, displayed in Figure 1. The 2012 data is from Philippon (2015),
while the new data was accessed in May 2016. Data range is 1886 - 2015.



households have gained access to credit in recent years.4 Measurement problems arise when the mix of high- and
low-quality borrowers changes over time.
    Following Philippon (2015), I then perform a quality adjustment to the intermediated assets series. Figure 3
shows the quality adjusted unit cost series. It is lower than the unadjusted series by construction since quality
adjusted assets are (weakly) larger than raw intermediated assets. The gap between the two series grows when
there is entry of new firms, and/or when there is credit expansion at the extensive margin (i.e., new borrowers).
Even with the adjusted series, however, we do not see a significant decrease in the unit cost of intermediation over
time.
   4 Using the Survey of Consumer Finances, Moore and Palumbo (2010) document that between 1989 and 2007 the fraction of households

with positive debt balances increases from 72% to 77%. This increase is concentrated at the bottom of the income distribution. For
households in the 0-40 percentiles of income, the fraction with some debt outstanding goes from 53% to 61% between 1989 and 2007.
In the mortgage market, Mayer and Pence (2008) show that subprime originations account for 15% to 20% of all HMDA originations
in 2005.




                                                                          6
                                              Figure 3: Unit Cost and Quality Adjustment
                                                         Unit Cost, with Quality Adjustment




                                    .03
                                    .025
                                    .02
                                    .015
                                    .01
                                    .005
                                    0




                                           1880   1900   1920     1940          1960     1980       2000   2020
                                                                         time

                                                                Raw              Quality Adjusted


Notes: The quality adjusted measure takes into account changes in firms' and households' characteristics. Data range is 1886 - 2015.



    As I have argued in the past, the puzzle is why we have not seen substantial productivity gains in financial
intermediation. The good news is that, however late, these improvements might be happening now.



2     A Simple Model of Robo-Advising

I consider a simple model of imperfect competition in asset management services. The model emphasizes the role
of technology, and fixed costs in particular. The key point is that there are two types of fixed costs: fixed costs to
set up a business or a system or a platform; and then fixed cost per relationship with each client.
    There is a continuum of mass 1 of households whose wealth w is distributed according to the (cumulative)
distribution G (w). Households are risk neutral (or, equivalently, returns are risk adjusted) and have access to an
investment technology with gross return r. The reservation utility of a household is thus rw. Households also have
the option to hire an asset manager in order to earn higher returns.


2.1     Traditional Asset Management Equilibrium

There are N asset managers with access to an investment technology with return R > r. To be active they need
to pay the fixed cost  (per active firm). To work with a household they need to pay the relationship cost  (per
client). The asset management industry is oligopolistic and asset managers charge a fee f (w) for their services. I
restrict attention to linear fees of the form f (w) =  + µw, where the intercept covers the fixed cost and where µ
is a markup. For now the markup is simply a parameter but, as discussed later, it could be a decreasing function
of the number of active intermediaries. The parameters are such that µ < R - r.
    The key decision for a household is whether to hire an asset manager or not. Household w chooses to hire an




                                                                         7
asset manager if Rw - f (w) > rw, which happens if and only if

                                                                  
                                                    w > wo =          .                                                   (4)
                                                                R-r-µ

A fraction 1 - G (wo ) of households hire intermediation services, while the remaining fraction G (wo ) invest by
themselves at the low rate. I consider a symmetric equilibrium where intermediaries have the same number of

clients. The net profit of any intermediary is therefore

                                                                    
                                                           µ
                                                   (N )                 wdG (w) ,
                                                           N    wo

where wo is defined in equation (4). Note that N should be interpreted as the number of asset managers per capita
since the population is normalized to one. Finally, free entry requires


                                                          (N )  ,

with equality if entry is positive. This pins down the number of firms entering the market.

Definition 1. Given the cost structure (, ), an equilibrium with positive entry solves wo from equation (4) and

                                                               
                                                         µ
                                                    N=              wdG (w) .
                                                               wo


   Welfare is given by the following expression:



                                            wo                  
                                 W=              rwdG (w) +          (Rw - ) dG(w) - N 
                                        0                      wo
                                            wo                  
                                    =            rwdG (w) +          ((R - µ) w - ) dG(w)
                                        0                      wo


Let us briefly discuss the first best allocation. The planner's solution would set N = 1 to save on fixed entry costs,
                                                                
and µ = 0 to price at marginal cost. This implies wo =         R- r .   In this equilibrium all asset managers loose money so
the planner would need to impose lump-sum taxes on households to subsidize the financial intermediaries. Asset

management clearly improves welfare compared to a situation where all households earn the low rate r, but, as
expected, the decentralized equilibrium does not achieve the planner's outcome because asset managers need to
                                                     
charge a markup to cover their entry cost, and wo > wo .




                                                                8
2.2    Robo-Advisors: A Tale of Two Fixed Costs

Let us now introduce a new asset management technology, characterized by stronger returns to scale. More precisely,
we assume that robo advisors have access to the investment technology r < R  R, and have a higher fixed entry
cost  >  but a lower cost per client  < . This captures the core idea that it is costly to program the robo
( > ), but then it can easily manage a large number of clients ( < ). In the limit, we can even imagine that
 = 0. The existing literature has failed to capture the difference between these two types of fixed costs. I will

show that they have different welfare implications.
   Households now have three options. They can invest by themselves and earn r. They can hire a traditional
manager. Or they can hire a robo advisor. There are now two cutoffs to calculate w1 and w2 , one for the
participation decision (as before) and one for the choice of the type of asset manager. I assume that both types of
asset managers charge a markup µ, so robo advisory fees are  + µw while traditional management fees are  + µw.
Since R  R and  <  we know that relatively poor households will choose between autarky and robots. Hence
the first participation cutoff is
                                                             
                                                  w1 =              .                                               (5)
                                                          R - r - µ

The second cutoff is between the robo and traditional advisors: (R - µ) w2 -  = (R - µ) w2 - . Hence

                                                              - 
                                                      w2 =                                                          (6)
                                                             R - R

One can relatively easily accommodate R = R if we introduce horizontal or vertical differentiation between advisors
as in Pagnotta and Philippon (2018), or search costs between households and advisors as in Pedersen (2015) and
Garleanu and Pedersen (2018). For simplicity I consider here the case R < R that ensures an interior solution
without getting lost in the details of strategic interactions between various types of advisors. This could also capture
a convenience yield that investor perceive from interaction with a human being instead of a robo. Finally, it is

consistent with the stylized fact that very high net worth households still use mostly human advisors. The condition
for profitable entry by robots is w1 < w2 , which leads to the following Lemma.

Lemma 1. Robo advisors are active if and only if R >  R + ( -  ) (r + µ).

   We can now characterize the equilibrium when both types of advisors are active.

Proposition 1. Under the condition of Lemma 1, the equilibrium with robo advisors is characterized by the cutoffs
(w1 , w2 ) in equations (5,6) such that G (w1 ) poor households save by themselves, G (w2 ) - G (w1 ) middle-class
households hire robo advisors, and 1 - G (w2 ) rich households hire traditional managers. The number of robo
advisors is
                                                             w2
                                                      µ
                                               N0 =               wdG (w) ,
                                                             w1




                                                             9
and the number of traditional managers is

                                                                   
                                                              µ
                                                       N1 =            wdG (w) .
                                                                  w2


   Let us now analyse the welfare implication of robo advisors. Welfare is given by

                            w1                w2                                         
                  W =            rwdG (w) +         (R w -  ) dG(w) - N0  +                 (Rw - ) dG(w) - N1 ,
                        0                     w1                                     w2
                            w0                 w2                                    
                    =            rwdG (w) +         ((R - µ) w -  ) dG(w) +              ((R - µ) w - ) dG(w).
                        0                     w1                                    w2


Compared to the planner's allocation the participation cutoff w1 is still distorted by the markup µ exactly as in the
traditional equilibrium. The second cutoff w2 , however, is the same one that the planner would choose as one can
readily see from equation (6). There is thus no distortion at the robo/traditional advisor frontier.
   The following proposition establishes the key result that if robo entry is profitable , i.e., if we see any robo
advising at all, then there are more households using asset management services in the Fintech equilibrium than in
the traditional equilibrium.

Proposition 2. Under the condition of Lemma 1, robo advising improves access to asset management services,
i.e., w1 < w0 .

                                                                 
Proof. We need to show that w1 =          R - r - µ   < w0 =   R- r - µ .   This is true as long as  R + ( -  ) (r + µ) < R

which is exactly the condition in Lemma 1.

   The key take-away from this analysis is that, by lowering the fixed cost per relationship, Fintech allows more
households to benefit from advisory services. The fact that Fintech might require higher upfront cost  >  does
not matter because in equilibrium, the rich subsidize the poor. The rich pay the lion's share of fees that serve to
cover the fixed cost  of setting up the robo. Once this cost is paid, poor households benefit from cheaper services.
An important lesson here is that the nature of fixed costs matter a great deal for welfare. The welfare properties of
fixed "coding" costs are fundamentally different from those of fixed costs per client.

   The fact that Fintech increases participation does not mean that Fintech reduces inequality among all groups,
however. If we think that the cutoff wo used to be above the middle class and that the cutoff w1 is now below
the middle class, then inequality between the poor and the middle class increases as the middle class joins the rich
in having access to asset management services. Education may also become a stronger determinant of participa-
tion than before if education allows households to understand better the important features of the robo-advising
technology.




                                                                  10
3     Big Data and Discrimination

Let me now discuss the consequences of the increasing use of "non-traditional" data in consumer credit. For most
of the post-war era, banks have relied on the credit history of consumers to make lending decisions. Exactly how
these borrowing histories are compiled can differ from country to country, but the broad principles are similar. In
the U.S. for example, lenders (banks, mortgage lenders, credit card companies, financing companies) feed data on
their customers to credit-reporting firms (credit bureaus), such as Equifax, Experian, and TransUnion. These firms
aggregate the data and create files (credit reports) on consumers. The same firms (e.g. Experian or Equifax), or
others, can then create credit scores. In the U.S., another company, Fair Isaac Corporation, or FICO, has developed
the most widely-used score, the FICO score, which ranges from 300 to 850. Some lenders base their credit decisions
almost entirely on FICO score, while others also consider more detailed credit bureau reports.
    In recent years credit companies have started using new sources of data on consumer behavior, such as phone

bills, shopping histories, subscriptions, or browsing histories. These data are less structured than traditional ones
and new lenders often rely on machine learning algorithms to exploit them effectively. I will therefore refer to
the whole process as big data and machine learning, or BDML for short. BDML is useful since many potential
borrowers are not properly scored by traditional methods. In the U.S. for example about 50 million adults do not
have a FICO score, and another 50 million have subprime scores that are notoriously noisy. One can hope that
BDML will help bring credit to deserving borrowers who lack reliable scores. On the other hand, regulators worry
that BDML could inadvertently introduce new forms of discrimination or reactivate old ones. In the US, the Equal
Credit Opportunity Act and the Fair Housing Act make it illegal for a creditor to discriminate based on race, color,
religion or gender. I will therefore study the interaction between new technologies and existing regulations.


3.1    Setup

As in the case of robo-advising, I describe a simple model and then I ask how Fintech might affect the equilibrium.
The basic model follows the classic paper of Aigner and Cain (1977). There is a one-dimensional variable q that
captures the credit quality of an individual. The distribution of q is normal with mean q
                                                                                        ¯ and variance ¯ 2 . I use
'bars' to denote population averages and also, under rational expectations, unconditional beliefs. It is convenient
to work with precisions instead of variances so I define

                                                            1
                                                      ¯
                                                               .
                                                            ¯2
                                                            

All lenders observe a quantitative signal y1 about the credit quality of the borrower:


                                                    y1 = q + 1 ,




                                                           11
where 1 is normal with mean 0 and precision 1 . We can think of y1 as a standard credit score. After observing

the signal y1 , the conditional distribution of q is normal with mean

                                                                            ¯q
                                                                             ¯ + 1 y1
                                                          E [q | y 1 ] =
                                                                             ¯ + 1
                                                                             

and precision ¯ + 1 . Now imagine that the population includes two groups, denoted by z : a majority group z = A,

and a minority group z = B . If a lender can condition on group membership the conditional expectation becomes

                                                                            ¯q
                                                                             ¯z + 1z y1
                                                       E [ q | y1 , z ] =               .
                                                                              ¯ + 1z
                                                                              

I assume that the minority group has a weakly lower average credit quality, q   ¯A . For simplicity I assume that
                                                                            ¯B  q
¯A = 
     ¯B is the same for both groups but it is easy to allow for different population variances. A classic argument
in the literature on discrimination is that standard data favor the majority, in the sense that 1B < 1A . The lesser
precision of traditional signals could arise from a higher prevalence of missing data in the minority. For instance,
if they are less likely to be employed, minorities have fewer payroll statements. If they are less likely to get a loan,
they have shorter histories of repayments.
   Discrimination can take several forms. Statistical discrimination refers to the fact that, as long as the signal y1
is noisy, the posterior puts a positive weight on the prior. As a consequence, for a given signal y1 , a member of
the majority will receive a better score than a member of the minority.5 Under statistical discrimination, however,
there is no average bias since the average of a conditional expectation is correct and equal to the true population
mean: E [E [q | y1 , z ]] = q
                            ¯z for all z . Aigner and Cain (1977) and others have argued that statistical discrimination
is unlikely to explain all ­ or even most ­ of the discrimination that we observe empirically. Dobbie et al. (2018)
argue that the misalignment of incentives inside the firm can also lead to biases. They find that the short-term

incentives given to loan officers create a long-run bias against immigrants. I therefore consider the stronger issue of
prejudice in lending decisions.


3.2    Traditional Lenders

Traditional lenders meet face-to-face with borrowers. This has two consequences: they observe directly the type z ,
and they generate another signal u = q + u about credit quality with precision u . With two signals the conditional
distribution of q is normal with mean

                                                                        ¯q
                                                                         ¯z + u u + 1z y1
                                                   E [q | y 1 , z ] =                     ,
                                                                           ¯ + u + 1z
                                                                           
  5 Suppose                                                                           q (¯   ¯B )
                                                                                         qA -q
              for simplicity that 1B = 1A . Then E [q | y1 , A] - E [q | y1 , B ] =     q + 1
                                                                                                  .




                                                                         12
and precision ¯ + 1 + u . I assume that loan officers have a biased belief about the minority. They perceive the

average quality to be q    ¯B -  . We can think of  as arising from prejudice or negative stereotyping. The
                      ^B = q
conditional expectation of the lender is then


                                               ^ (y1 , u, B ) = ¯ (¯
                                                                   qB -  ) + u u + 1B y1
                                               E                                         .
                                                                      ¯ + u + 1B
                                                                      

                                                   ^ (y1 , u, B ) | B - q
Note that the average statistical bias is simply E E                    ¯B = -    ¯
                                                                                  
                                                                               ¯+u +1B . The harm potentially

imposed on the minority is stronger if the prejudice  is large and if the signal is noisy (1B is small).6


Regulations Regulators often impose constraints on the use of group membership in lending decisions. For
instance it is illegal in the U.S. to make lending decisions based on race or gender. We can capture this idea by
assuming that regulations prevent lenders from conditioning explicitly on z . The score of the traditional lender then
becomes
                                                                    ¯ (¯
                                                                       q -  ) + u u + 1 y1
                                                 T (y1 , u; B ) =                          ,
                                                                          ¯ + u + 1
                                                                          

which does not depend explicitly on z = B . The subjective bias remains and on average we have

                                                                                     ¯ -d
                                                                                           ¯
                                                E [T ( y 1 , u ; B ) | B ] = q
                                                                             ¯B -             ,
                                                                                    ¯ + u + 1
                                                                                    

      ¯ q
where d    ¯B reflects the regulatory constraint that prevents statistical discrimination based on group status.
        ¯- q
Consistent with the empirical literature I assume that the negative bias has not been fully eliminated by regulations,
         ¯ < .
i.e., 0  d


3.3      Univariate Unbiased Fintech Lending

Fintech lenders do not meet their clients face to face, but they have access to another quantitative signal


                                                                  y2 = q + 2 ,


where 2 is normal with mean zero and precision 2 . We can think of this signal as coming from non-standard data
sources, such as social media footprint or internet browsing history. The key point is that new data sources are
less likely to favor the majority. Everyone has a browsing history and almost everyone is on social media, or at
least there is no reason to believe that minorities are less likely to be on social media than the majority. I will thus
assume that 2B = 2A .
   6 I consider for simplicity the case of risk neutral lenders but it is worth pointing out that the results only get stronger if lenders are risk

averse. Risk averse lenders dislike lending to minorities because the residual conditional variance is higher. If we assume for example that
lenders have mean-variance preferences and hence care about the score per unit of uncertainty E [q | y1 , z ] /V [q | y1 , z ] =  ¯z +u u+1z y1 ,
                                                                                                                                 ¯q
then we see that a low value of 1z directly hurts the minority.




                                                                        13
   I refer to lending based on y2 as univariate unbiased Fintech lending. By unbiased I mean that the algorithms

do not suffer from the prejudice of humans in face to face interactions. As a result y2 is an unbiased estimate of
q . By univariate I mean that the signal is only about q . In particular it contains no direct information about z .
It is of course correlated with z because of differences in population-averages q
                                                                                ¯z , but conditional on q , it conveys
no information about z . I will relax these assumptions in the next sections. With two signals the conditional
                                                              ¯q
                                                               ¯+1 y1 +2 y2
distribution of q is normal with mean E [q | y1 , y2 ] =         ¯+1 +2
                                                                                 and precision q + 1 + 2 . On average, conditional
on z = B , we have
                                                                                      ¯
                                                                                     ¯d
                                                                                     
                                            E [E [q | y 1 , y 2 ] | B ] = q
                                                                          ¯B +             .
                                                                                 ¯ + 1 + 2
                                                                                 

We can finally compare Fintech lending to traditional lending from the perspective of the average minority borrower:

                                                                              ¯d
                                                                                ¯      ¯ -d
                                                                                             ¯
                     E [E [q | y1 , y2 ] | B ] - E [T (y1 , u; B ) | B ] =          +           ,
                                                                          ¯ + 1 + 2
                                                                                      ¯ + u + 1
                                                                                      
                                                                               ¯         ¯ 2 - u
                                                                        =            -d                      .
                                                                          ¯ + u + 1
                                                                                          ¯ + 1 + 2
                                                                                          

             ¯
             
The term   ¯+u +1
                    represents the gains from avoiding prejudice arising from face-to-face lending. It is unambiguously
positive and follows directly from the assumption that algorithms do not suffer from prejudice. The second term can
be positive or negative, depending on the quality of big data analytics. Since the evidence suggests that alternative
data sources improve signal quality we can assume that 2 > u , in which case the term is negative. Because Fintech
lending is more precise it puts less weight on priors and it reduces the regulatory subsidy that the minority enjoys.
                                                   ¯ 2 -u , is always positive. This leads us to the following
Notice however that the sum of the two effects,  - d ¯+1 +2
                                                     

Proposition

Proposition 3. Unbiased univariate Fintech lending reduces biases arising from prejudice against the minority.
Even though it can undermine the effectiveness of existing policies the net effect is alway positive for the minority.

   The proposition highlights the fundamental benefits of new lending technologies which come from two sources:
no prejudice and more precise signals. Note that the higher precision of the signal would be helpful in any case,
even if it was used by traditional lenders.

Remark 1. Even in the absence of Fintech lenders, giving traditional lenders access to the signal y2 decreases biases
against the minority.
                                                                       ¯(¯
                                                                         q - )+u u+1 y1 +2 y2
   If traditional lenders also observe y2 they will form the posterior      ¯+u +1 +2
                                                                                              and the bias will be
                   ¯
               ¯( -d)
               
reduced to  ¯+u +1 +2 . If 2 is high the bias becomes small. We turn next to the case where big data contains

multiple signals.




                                                                   14
3.4    Multivariate Unbiased Fintech Lending

The model above does not capture one pervasive worry that policy makers have about big data, namely that it
can inadvertently discover proxies for group membership. As Barocas and Selbst (2016) write "Approached without
care, data mining can reproduce existing patterns of discrimination, inherit the prejudice of prior decision makers,
or simply reflect the widespread biases that persist in society. It can even have the perverse result of exacerbating
existing inequalities by suggesting that historically disadvantaged groups actually deserve less favorable treatment."

   Let us then assume that, in addition to y2 as a proxy for q , big data analysis also generates a proxy for z .
The important point here is that this second signal is a byproduct of the machine learning approach. The BDML
system is looking for information, and to the extent that z is informative and that proxies for z can be constructed
in the data, then the system will find it and use it. I assume that the information takes the form of a signal s about
z . It is easy to model an imperfect signal but the intuition is the same if the signal is perfect and the derivation
is simpler. I therefore assume that the ML system constructs a perfect, albeit indirect proxy for z . The Fintech
lender's conditional expectation is then

                                                                      ¯q
                                                                       ¯B + 1 y1 + 2 y2
                                           E [q | y 1 , y 2 ; B ] =
                                                                         ¯ + 1 + 2
                                                                         

which is now an unbiased estimator of q
                                      ¯B . Therefore E [q | y1 , y2 , B ] = q
                                                                            ¯B > E [T (y1 , u; B ) | B ].

Proposition 4. Even if Big Data and Machine Learning lead to indirect proxies for group membership, Fintech

lending still reduces biases against minorities.

   Even in the most extreme case, unbiased Fintech lending produces pure statistical discrimination. To the extent
that minorities suffered from prejudice in the pre-fintech era, their welfare should increase when Fintech lenders
enter a market. This is consistent with the evidence in Bartlett et al. (2018) who find that Fintech algorithms
discriminate 40% less than face-to-face lenders.
                                ¯ <  , i.e., that policy did not over-shoot its targets and some negative bias
   These results assume that 0  d
remained before the introduction of the new lending technology. While this seems to be empirically plausible on
                                                                                                           ¯j  q
average, it does not rule out the possibility that in some location j the minority is doing so poorly that d   ¯j -q
                                                                                                                   ¯Bj

is larger than  , even though the opposite is true on average across all locations. In that particular location credit
market regulations lead to positive redistribution. Since the use of big data makes the credit market more neutral,
it reduces redistribution and it could potentially hurt the minorities in some specific locations.
   Broadly speaking, however, the analysis suggests that Fintech lending is likely to reduce discrimination as long as
the algorithms themselves do not suffer from prejudice. Let us therefore consider next the case of biased algorithms.




                                                                  15
3.5    Biased Multivariate Fintech lending

Suppose that Fintech engineers suffer from the same prejudice as loan officers and export their bias into their
algorithms. Once the BDML system constructs a proxy for z it applies a penalty to the true quality of minority
borrowers just as face-to-face officers did. This is arguably an extreme and unrealistic assumption because it is
more difficult to induce biases in an algorithm than during face-to-face meetings, and the evidence in Bartlett et al.
(2018) suggests that algorithms discriminate less. But this extreme assumption is helpful to make the point and

highlight the key issue. The conditional ­ and now biased ­ expectation becomes


                                      ^ [q | y 1 , y 2 , B ] = ¯ (¯
                                                                  qB -  ) + 1 y1 + 2 y2
                                      E                                                 ,
                                                                      ¯ + 1 + 2

and on average we have
                                        ^ [q | y 1 , y 2 , B ] | B = q          ¯
                                                                                
                                      E E                            ¯B -             .
                                                                            ¯ + 1 + 2
                                                                            

In this example Fintech lenders also suffer from prejudice. If we compare with traditional lenders we get

                                                                               ¯ -d  ¯
                    ^ [q | y 1 , y 2 , B ] | B - E [T ( y 1 , u ; B ) | B ] = 
                  E E                                                                   -
                                                                                              ¯
                                                                                              
                                                                                                    ,
                                                                              ¯ + u + 1
                                                                                          ¯ + 1 + 2
                                                                                          
                                                                                  ¯
                                                                                            2 - u      ¯ .
                                                                            =                         -d
                                                                              ¯ + u + 1
                                                                                          ¯ + 1 + 2
                                                                                          

            ¯ <  the term  2 -u - d
Even though d                       ¯ can be negative is 2 is small: Fintech lending can now potentially harm
                          ¯ + 1 + 2
                          

the minority. On the other hand, if 2 is significantly larger than u Fintech lending helps the minority despite its
prejudice. Why is that? As before, Fintech lending increases precision. The impact of the prejudice depends on
the precision of the credit scoring signal y2 . Even if there is prejudice, its impact is small if 2 is large because the
Bayesian part of the mechanism carries more weight.

Proposition 5. Biased multivariate Fintech lending can decrease the welfare of the minority, but this becomes
increasingly less likely as Fintech algorithms become more precise.

   There are two keys lessons here. The first lesson is that for Fintech to hurt the minority two issues must interact:
(i) BDML needs to build a direct proxy for group membership; and (ii) the algorithm itself must contain prejudice.
If only one issue is present, Fintech improves welfare for the minority. It is only in the biased multivariate case that

Fintech can be detrimental. The second lesson is that even in the pessimistic case, when Fintech lending becomes
precise enough it always improves welfare for the minority. Even when engineers suffer from prejudice and somehow
embed this prejudice into their algorithms, the prejudice decreases with the precision of the credit scoring model.




                                                              16
4    Conclusion

Fintech is likely to decrease the costs of financial intermediation, but also to create new regulatory issues. In this
short note I have highlighted two relevant forces that will shape the impact of Fintech on inequality. In the case of
robo-advisors, I have argued that the new pattern of fixed costs is likely to improve participation by relatively less
wealthy household. This may not lower inequality across all groups, however. In the credit market, I have argued
that alternate data sources are likely to reduce non-statistical discrimination. To the extent that minorities were
hurt by prejudice or negative stereotyping, alternate data sources will have a positive impact. On the other hand
new data can reduce the effectiveness of existing regulations.




                                                         17
References
Abraham, F., S. L. Schmukler, and J. Tessada (2019). Robo-advisors: Investing through machines. World Bank
 Policy Research Working Paper (134881).
Aigner, D. J. and G. G. Cain (1977). Statistical theories of discrimination in labor markets. ILR Review 30 (2),
  175­187.
Barocas, S. and A. Selbst (2016). Big data's disparate impact. California Law Review 104, 671­732.
Bartlett, R., A. Morse, R. Stanton, and N. Wallace (2018). Consumer-lending discrimination in the era of fintech.
  Working paper.
Bazot, G. (2013). Financial consumption and the cost of finance: Measuring financial efficiency in europe (1950-
  2007). Working Paper Paris School of Economics.
Berg, T., V. Burg, A. Gombovi, and M. Puri (2019). On the rise of fintechs ­ credit scoring using digital footprints.
  Working paper.
Bickenbach, F., E. Bode, D. Dohse, A. Hanley, and R. Schweickert (2009, October). Adjustment after the crisis:
  Will the financial sector shrink? Kiel Policy Brief.
Buchak, G., G. Matvos, T. Piskorski, and A. Seru (2018). Fintech, regulatory arbitrage, and the rise of shadow
  banks. Journal of Financial Economics 130 (3), 453 ­ 483.
Dobbie, W., A. Liberman, D. Paravisini, and V. Pathania (2018). Measuring bias in consumer lending.
Economist, T. (2017). Silicon speculators.
Fuster, A., M. Plosser, P. Schnabl, and J. Vickery (2019). The role of technology in mortgage lending. The Review
  of Financial Studies 32 (5), 1854­1899.
Garleanu, N. and L. H. Pedersen (2018). Efficiently inefficient markets for assets and asset management. The
 Journal of Finance 73 (4), 1663­1712.
Mayer, C. and K. Pence (2008). Subprime mortgages: What, where, and to whom? Staff Paper Federal Reserve
 Board.
Moore, K. B. and M. G. Palumbo (2010, June). The finances of american households in the past three recessions:
 Evidence from the survey of consumer finances. Staff Paper Federal Reserve Board.
O'Mahony, M. and M. P. Timmer (2009). Output, input and productivity measures at the industry level: The eu
  klems database. The Economic Journal 119 (538), F374­F403.
Pagnotta, E. and T. Philippon (2018, May). Competing on speed. Econometrica 86.
Pedersen, L. H. (2015). Efficiently Inefficient: How Smart Money Invests and Market Prices Are Determined.
  Princeton University Press.
Petralia, K., T. Philippon, T. Rice, and N. Véron (2019). Banking disrupted? financial intermediation in an era of
  transformational technology. Technical Report 22, Geneva Reports on the World Economy, ICMB and CEPR.
Philippon, T. (2015). Has the us finance industry become less efficient? on the theory and measurement of financial
  intermediation. The American Economic Review 105 (4), 1408­38.
Philippon, T. (2016). The fintech opportunity. NBER Working Paper.




                                                         18
