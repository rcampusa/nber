                                NBER WORKING PAPER SERIES




                    A TESTABLE THEORY OF IMPERFECT PERCEPTION

                                           Andrew Caplin
                                           Daniel Martin

                                        Working Paper 17163
                                http://www.nber.org/papers/w17163


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                      June 2011




We thank Nabil Al-Najjar, David Cesarini, Mark Dean, Jeff Ely, Sen Geng, Paul Glimcher, Natalia
Shestakova, Jonathan Weinstein, and seminar participants at Northwestern University and University
of Southern California for valuable comments. The views expressed herein are those of the authors
and do not necessarily reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2011 by Andrew Caplin and Daniel Martin. All rights reserved. Short sections of text, not to exceed
two paragraphs, may be quoted without explicit permission provided that full credit, including © notice,
is given to the source.
A Testable Theory of Imperfect Perception
Andrew Caplin and Daniel Martin
NBER Working Paper No. 17163
June 2011
JEL No. D01,D03

                                               ABSTRACT

We introduce a rational choice theory that allows for many forms of imperfect perception, including
failures of memory, selective attention, and adherence to simplifying rules of thumb. Despite its generality,
the theory has strong, simple, and intuitive implications for standard choice data and for more enriched
choice data. The central assumption is rational expectations: decision makers understand the relationship
between their perceptions, however limited they may be, and the (stochastic) consequences of their
available choices. Our theory separately identifies two distinct "framing" effects: standard effects involving
the layout of the prizes (e.g. order in a list) and novel effects relating to the information content of
the environment (e.g. how likely is the first in the list to be the best). Simple experimental tests both
affirm the basic model and confirm the existence of information-based framing effects.


Andrew Caplin
Department of Economics
New York University
19 W. 4th Street, 6th Floor
New York, NY 10012
and NBER
andrew.caplin@nyu.edu

Daniel Martin
Department of Economics
New York University
19 W. 4th Street, 6th Floor
New York, NY 10012
daniel.martin@nyu.edu
                   A Testable Theory of Imperfect Perception

                                  Andrew Capliny and Daniel Martinz


                                                June 15, 2011




                                                   Abstract

          We introduce a rational choice theory that allows for many forms of imperfect perception,
      including failures of memory, selective attention, and adherence to simplifying rules of thumb.
      Despite its generality, the theory has strong, simple, and intuitive implications for standard
      choice data and for more enriched choice data. The central assumption is rational expectations:
      decision makers understand the relationship between their perceptions, however limited they
      may be, and the (stochastic) consequences of their available choices. Our theory separately
      identi…es two distinct “framing”e¤ects: standard e¤ects involving the layout of the prizes (e.g.
      order in a list) and novel e¤ects relating to the information content of the environment (e.g.
      how likely is the …rst in the list to be the best). Simple experimental tests both a¢ rm the basic
      model and con…rm the existence of information-based framing e¤ects.
          Key Words: Stochastic Choice, Bounded Rationality, Imperfect Perception, Rational Ex-
      pectations, Framing E¤ects, Mistakes




1    Introduction

From Weber [1834] on, psychologists have explored the gap between subjective perceptions and
external reality (Glimcher [2010]). In recent years, economists have also worked to incorporate this
    We thank Nabil Al-Najjar, David Cesarini, Mark Dean, Je¤ Ely, Sen Geng, Paul Glimcher, Natalia Shestakova,
Jonathan Weinstein, and seminar participants at Northwestern University and University of Southern California for
valuable comments.
   y
     Center for Experimental Social Science and Department of Economics, New York University and National Bureau
of Economic Research.
   z
     Center for Experimental Social Science and Department of Economics, New York University.


                                                       1
gap into the theory of rational decision making. To date, progress has typically involved making
various highly speci…c (and mutually incompatible) assumptions concerning perceptual limitations,
including bounds on memory, rigid mental accounts, incomplete and selective attention, incomplete
search, rule of thumb decision making protocols, algorithmic approximations, etc. (e.g. Thaler
[1985], Mullainathan [2002], Wilson [2002], Sims [2003], Manzini and Mariotti [2007], Rabin and
Weizsacker [2009], Masatlioglu and Nakajima [2009], Gennaioli and Shleifer [2010], Gottlieb [2010],
Schwartzstein [2010], Ergin and Sarver [2010], Caplin and Dean [2011], Compte and Postlewaite
[2011], and Gabaix [2011]).

      An open question is how to introduce less circumscribed forms of imperfect perception into
decision theory. What makes this challenging is that, without some form of theoretical discipline,
rational choice theory becomes vacuous. Any pattern of behavior can be rationalized by some
distorted perception of reality. This is related to the di¢ culties in identifying “mistaken”decisions
from choice data, and the dangers of so doing without strong theoretical guidance.1

      We introduce a model of rational decision making that allows for a wide array of perceptual lim-
itations and mistakes, yet has strong and intuitive testable implications. The main substantive as-
sumption is rational expectations. In the “rational expectations perception-based representations”
(RE-PREPs) that we study, decision makers (DMs) fully understand the relationship between their
subjective perceptions, however limited they may be, and the (stochastic) consequences of available
choices. The restrictions that our theory imposes on choice data are simple to understand: choices
must be “unimprovable”. The precise form of the improvements that are ruled out depend on the
data available for model testing. We produce separate results for “framed” stochastic choice data
and for standard stochastic choice data.

      When the frame is observable, our theory separately identi…es two distinct framing e¤ects:
standard e¤ects involving the layout of the prizes (Rubinstein and Salant [2006], Salant and Ru-
binstein [2008], Bernheim and Rangel [2008], Reutskaja, Nagel, Camerer, and Rangel [2011]) and
novel e¤ects relating to the information content of the environment (e.g. the extent to which the
…rst in the list turns out to be the best). In this setting, we show that existence of a RE-PREP
representation is equivalent to a “No Improving Action Switches” (NIAS) condition: there must
be a utility function such that no action can be switched to an alternative action in a manner that
raises utility. This restriction corresponds to the non-emptiness of the feasible set for a data-de…ned
  1
      See Koszegi and Rabin [2008], Bernheim and Rangel [2008], and Gul and Pesendorfer [2008].


                                                         2
linear program.

        We present experimental tests that a¢ rm the basic model and con…rm the importance of
information-based framing e¤ects. While subjects make substantial choice mistakes in all treat-
ments, we …nd that the NIAS inequalities are always satis…ed. Further, both of the framing e¤ects
allowed by our model are present in the experimental data. Our experiment provides proof-of-
concept that our information-based framing e¤ect can be experimentally identi…ed, and that such
identi…cation can further understanding of the perceptual process. It also highlights the symbiotic
relationship between decision theory and experiments that generate non-standard choice data (see
also Caplin [2008], Caplin and Dean [2011], and Caplin, Dean, and Martin [forthcoming]).

        In addition to its implications for framed stochastic choice data, our theory places simple and
intuitive restrictions on standard stochastic choice data. These restrictions are weaker than those
imposed by stochastic utility models (e.g. Block and Marschak [1960], Luce [1959], McFadden
[1973], Falmange [1978], and Gul and Pesendorfer [2006]). By way of example, our theory covers
cases in which perceptual similarities between a very good prize and a very bad prize result in the
selection of a moderately good but distinctive prize when all three are available (e.g. Debreu [1960]
and Natenzon [2011]).2

        In section 2 we introduce our formal model and de…ne RE-PREP representations. In sections
3 and 4 we provide the observable restrictions associated with the model in cases in which the
decision making environment can be fully observed: the NIAS conditions. In section 5 we consider
the various framing e¤ects that our model encompasses. In section 6 we characterize the restric-
tions our model places on standard stochastic choice data. A theoretically-inspired experiment for
understanding the sources and nature of imperfect perception is presented in section 7. Concluding
remarks are in section 8.



2        Decision Making and Perceptions

We study decisions in which the DM may not fully understand all objects of choice. This may be
because there are many available options, because these items are complex, or because the DM is
    2
        In this sense, our results relate to the question posed more than …fty years ago by Block and Marschak [1960] con-
cerning how to distinguish stochastic choices with decision making errors from stochastic choices based on stochastic
utility.


                                                              3
not able or willing to expend the e¤ort to become thoroughly familiar with the available options.
This is the world envisaged in models of bounded rationality at least since the pioneering work of
Simon [1955].



2.1    Prizes, Actions, and Layouts

We assume that there is an “ideal observer” (IO) who understands fully the choice environment
and who is distinct from the DM whose choice behavior is being modeled. The IO knows not only
the key ingredients of the decision making environment that the DM is facing, but also the choices
that are made and the prizes received.

   A crucial feature of the model is that we distinguish the act of choice from the receipt of a prize.
It is through separate observation of actions and of their consequences that the IO in our model is
able to interpret some of the DM’s choices as based on misperception.

   In formal terms, there is a …nite prize set X with generic element xn , for n 2 f1; : : : ; N g: this
…xes the physical presentation of each option once and for all, including its packaging, etc. There
is a separate set Y of action choices that is also …nite and has at least the same cardinality as the
prize set,
                                      jY j = M    jXj = N      2:

Each y 2 Y is to be physically interpreted (e.g. a location on a screen or a line in a list). A layout
is an onto function f : Y ! X, with F the set of all such layouts,

                                    F = ff : Y ! Xjf is ontog:

It is the layout that connects actions with consequences. The assumption that layouts are onto
ensures that all prizes in X are in fact available to the DM. In certain cases we restrict the function
to be one-to-one (see section 6). However, allowing for the more general case enables the model to
cover such phenomena as “needle in a haystack” choice sets, in which one good prize is obscured
by the availability of several equivalent bad prizes. It is just such choice sets that underlie the
experiment of section 7.

   Our model draws strongly from the psychological tradition. In particular, our formulation of
the act of choice as separate from reception of a prize was inspired by simple choice experiments



                                                  4
of the drift-di¤usion form (see Ratcli¤ [1978], Ratcli¤ and McKoon [2008], Shadlen and Newsome
[2001]).



2.2       Choice Environment

If a given action choice y 2 Y always produced the same prize, one would expect the DM to
learn this, making the question of misperception moot. However, when there is doubt about
how actions get translated into prizes, there is room for misperception. We study a DM making
many independent choices in a stable environment identi…ed with a speci…c layout-generating
mechanism (a probability measure over layouts)                2    (F). We de…ne F( )          F as the support
of . We refer to the triple (X; Y; ) as the choice environment.

       In principle, the measure       provides the subject a statistical sense of what tends to happen
when a given action is selected. A DM’s choices may be in‡uenced both by this information and
by information derived from attending to the action-prize association in a given layout.



2.3       Ideal Data

Given        2    (F), an ideal data set (IDS) P identi…es the probability distribution over action
choices as it depends on the layout,
                                                 P :F !        (Y ):

This entire function is assumed to be known to the IO and provides the data that a theory of
choice must explain.3 It is the quadruple (X; Y; ; P ) that fully identi…es the objects upon which
our theory of perception is built. We call such a quadruple an ideal choice environment (ICE).

       Our model allows the structure of observed choices to be dependent on the layout. For example,
we allow for situations in which the …rst item in a list is most likely to be the best, which may
induce default behavior of selecting this option. In such cases, the stochastic structure of choice
may be impacted by which object is put …rst in the list. For that reason, a direct test of our theory
requires that the set of action choices Y is identi…able to the IO, and that the choice environment
  is also understood. Such knowledge is most naturally derived in an experiment, and plays a key
   3
       The domain of this data does not allow the order of the experimental runs to be recorded, hence we will not
consider explanatory hypotheses that involve learning about the structure of the experiment.



                                                         5
role in the experimental design of section 7. In section 6 we consider cases in which the layout is
unobservable, and the only available data relates to stochastic demand for prizes.



2.4     Subjective States and the Perception Function

The IO takes as given an ICE (X; Y; ; P ) and looks to structure perceptual theories of choice based
on three elements: a subjective state space S, a perception function                    that maps possible
layouts into simple lotteries over the subjective state space, and a choice function C that maps
possible subjective states into action choices.

   The set S speci…es in the IO’s model all permissible subjective mental states of the DM. In
general, S captures all decision relevant information the IO hypothesizes DMs to extract from
the choice environment and the speci…c layout in front of them. More speci…cally, S may encode
characteristics or facets of the available goods, the state of a …nite automaton, etc. Note that this
set need not be an accurate representation of the DM’s state of mind, rather it is the manner in
which the state is modeled by the IO in seeking to understand observed behavioral patterns.

   In the current context, the IO is presumed to set S =             (X)M , the space of ordered lists of M
subjective prize lotteries. Let smn be the probability that action choice ym results in prize xn , so
that,
                                         N
                                         X
                       S = fs 2   RM N
                                   + j         smn = 1 for all m 2 f1; : : : ; M gg:
                                         n=1
The reason the IO so limits the subjective state space is that the desired characterization of behavior
is based on expected utility theory, for which lotteries over prizes are the appropriate objects of
choice.

   The perception function maps possible layouts f 2 F( ) into            (S), the probability distributions
over S with …nite support,
                                               : F( )! (S):

Given …nite support, the set of lottery states that are perceived as possible in the given experiment,

                                                              f
                                  S( ) = [f 2F ( ) fs 2 Sj        (s) > 0g;

is …nite. It is this set that serves as the domain of the choice function,

                                           C : S( ) ! Y:

                                                     6
2.5    RE-PREPs

Since the space S is …xed from this point forward, one can specify a perceptual model by the two
elements    and C. For these to provide a possible explanation (perception-based representation or
PREP) of the observed data requires that their composition generates the IDS. We are interested
only in PREPs in which the DM can be modeled as an expected utility maximizer with rational
expectations. We require strictness in the utility comparison of some pair of acts in some state
of mind to prevent the conditions from being trivially satis…ed by a utility function in which all
utilities are identical.


De…nition 1 ( ; C; U ) form a rational expectations perception-based representation (RE-
PREP) of (X; Y; ; P ) if they satisfy:


   1. Data Matching: P f (y) =       f (C 1 (y))   for all f 2 F and y 2 Y .

   2. Rational Expectations: For all m 2 f1; : : : ; M g, n 2 f1; : : : ; N g, and s 2 S( ),
                                        P                                 f
                                          ff 2F ( )jf (ym )=xn g (f ) (s)
                                 smn =       P                    f
                                                                               :
                                                  ff 2F ( )g (f ) (s)


   3. Optimality: If C(s) = ym , then,
                             N
                             X                     N
                                                   X
                                   smn U (xn )           skn U (xn ) all k 2 f1; : : : ; M g ;
                             n=1                   n=1

      with the inequality being strict for some pair k; m with k; m 2 f1; : : : ; M g.


    Note that if there is only one action ever taken, so that there exists y 2 Y with C(s) = y for all
s 2 S, then it is trivial to …nd a RE-PREP by setting y as the unique utility maximizer. Hence we
will consider only cases in which there are at least two distinct actions taken with strictly positive
probability.



2.6    Rational Expectations and Experimentation

The most distinctive aspect of the RE-PREP is Rational Expectations, which when combined with
Data Matching, implies that the DM is aware of the consequences of all choices in each state


                                                          7
of mind. What this means is that in a RE-PREP, the statistical association between subjective
perceptions, choices, and prizes has been internalized by the DM. Implicitly, this is based on the
idea that this is a familiar environment and that DMs have learned through a process of trial and
error what the results are when any given choices are made in any particular state of mind. Having
thus experimented, each selects an optimal such action, and the consequences are then at least
acceptable, in the sense that they do not perceive there to be any action choice that is superior.
The full statement of this intuitive description of the axioms is formalized in our representation
theorem.

    As is often the case, the assumption of rational expectations is easiest to justify as the end result
of an unmodeled and unobserved process of experimentation. However, in the actual de…nition,
a speci…c deterministic action is taken in each state of mind, and there is no experimentation
whatsoever. The exact process of experimentation or decision making tremble that would produce
rational expectations and thereby rationalize the strong informational assumption that the RE-
PREP imbeds is not modeled.



3    Restrictions on Ideal Data: the 2                            2    2 Case

Our goal is to identify conditions on the IDS equivalent to existence of a RE-PREP. Before in-
troducing the general characterization theorem in the next section, we provide in this section a
thorough analysis of the 2     2     2 case, with two prizes X = fx1 ; x2 g; two actions Y = fy1 ; y2 g;
and two possible layouts F = fg; hg, in which actions yield di¤erent prizes,

                                          g(y1 ) = h(y2 ) = x1 ;

                                          g(y2 ) = h(y1 ) = x2 :

In this setting, one parameter (the probability of layout g) identi…es the layout-generating mecha-
nism,
                                                  g
                                                      2 [0; 1];

while two parameters pg1 , ph1 2 [0; 1] identify the IDS,

                                   (P g (y1 ); P g (y2 )) = (pg1 ; 1   pg1 );

                                   (P h (y1 ); P h (y2 )) = (ph1 ; 1   ph1 ):


                                                       8
To avoid triviality, we assume that both choices are made with strictly positive probability.

    Throughout this section, we will look for RE-PREPs using two perceptual states,

                                                   S = fs1 ; s2 g:

By de…nition,
                                          si11 ; si21 2 [0; 1] ; i = 1; 2;

denote the probability in subjective lottery state si that actions y1 ; y2 respectively will yield prize
x1 , with,
                                        si12 = 1     si11 , si22 = 1   si21 ;

representing the corresponding probabilities for prize x2 . Given the assumption that both choices
are observed, it must be that C(s1 ) 6= C(s2 ). Hence there is no loss of generality in setting
C(si ) = yi for i = 1; 2. We show in the next section that allowance for more than two subjective
states is unnecessary, so that the analysis of this section is more general than it appears.



3.1    Decision Tree Representation

Figures 1 and 2 illustrate the structure of this RE-PREP. Figure 1 is a representation of all states
of the world as directly seen by the IO, with the top branch recording the stochastic structure of
the layout, the second branch the stochastic choice of action that is observed with each layout, and
the …nal vertical line representing the deterministic association of the prize with the action as it
depends on the layout.

    Figure 2 presents the elements of the theory of DM behavior that the IO hypothesizes to be
responsible for DM choices. The main change from …gure 1 is the addition of nodes corresponding to
the two subjective states, s1 and s2 . These nodes are placed after the layout and prior to the action
stage. The subjective states are connected with dashed lines, which represent the information sets
of the DM. Each node has a black edge that goes to the action that is adopted in the RE-PREP,
action yi in state si , and also a grey edge corresponding to the untaken alternative action. Note
that the branches of the tree that lead to the mental states retain the same probability labels as
in …gure 1,   g;h (s1 )   = pg;h
                             1 and
                                     g;h (s2 )   = pg;h
                                                    2 , on the relevant branches of the tree. This re‡ects




                                                         9
Figure 1: Decision tree as seen by “ideal observer” (IO)




Figure 2: Decision tree for DM as hypothesized by IO



                          10
application of the …rst property of a RE-PREP, Data Matching, which requires that,

                                            g
                                                fC   1
                                                         (y1 )g =         g
                                                                              (s1 ) = pg1 ;
                                            h        1                    h
                                                fC       (y1 )g =             (s1 ) = ph1 :


      The question of whether or not a RE-PREP exists hinges on whether or not the Rational
Expectations condition and the Optimality condition can simultaneously be met.



3.2     Existence: An Example

Our …rst example involves        g   = 0:5, pg1 = 0:8, and ph1 = 0:2. In this case, substitution for                          based
on Data Matching reveals the Rational Expectations conditions to be:
                                     g pg                                   (1     g )(1           ph1 )
              s111   =   g pg
                                        1
                                            g )ph
                                                     = 0:8 =                  g                                    = s221 ;
                            1   + (1            1
                                                                       g (1  p1 ) + (1             g )(1   ph1 )
                            (1         g )ph                                            g (1   pg1 )
              s121   =   g pg + (1
                                           1
                                                     = 0:2 =                                                       = s211 :
                            1
                                            g )ph
                                                1
                                                                       g (1     pg1 )   + (1       g )(1   ph1 )

The remaining lottery probabilities s112 = s222 = 0:2 and s122 = s212 = 0:8 are implied. With this, the
conditions for Optimality of the chosen action are the same for each action:

                                0:8U (x1 ) + 0:2U (x2 )                0:2U (x1 ) + 0:8U (x2 ):

To ensure (as required for a RE-PREP) that this inequality is strict, we set,

                                                         U (x1 ) > U (x2 );

completing the speci…cation of the RE-PREP representation.



3.3     Non-Existence: An Example

An example that has no RE-PREP involves                       g   = 0:8 and pg1 = ph1 = 0:5. In this case, substitution
for    based on Data Matching reveals the Rational Expectations conditions to be:
                                     g pg                                               g (1   pg1 )
              s111   =   g pg
                                        1
                                                     = 0:8 =                                                       = s211 ;
                            1   + (1        g )ph
                                                1
                                                                       g (1     pg1 )   + (1       g )(1   ph1 )
                            (1         g )ph                                (1     g )(1           ph1 )
              s121 =     g pg
                                           1
                                            g )ph
                                                     = 0:2 =                  g                                    = s221 ;
                            1+ (1               1
                                                                       g (1  p1 ) + (1             g )(1   ph1 )


                                                                  11
with remaining lottery probabilities s112 = s212 = 0:2 and s122 = s222 = 0:8 implied. With this, the
conditions for Optimality depend on the state and are inverses of one another:

                                 0:8U (x1 ) + 0:2U (x2 )                         0:2U (x1 ) + 0:8U (x2 );

                                 0:2U (x1 ) + 0:8U (x2 )                         0:8U (x1 ) + 0:2U (x2 ):

The only utility functions that solve this involve U (x1 ) = U (x2 ), but in this case neither inequality
holds strictly, contrary to the de…nition of a RE-PREP.



3.4     Restrictions on the IDS

We now identify necessary and su¢ cient conditions on the IDS for existence of a RE-PREP for
general pg1 ; ph1 ;   g   2 (0; 1) in the two state world of …gure 2 with C(si ) = yi ; i = 1; 2. The Data
Matching condition is as implied in the …gure with                                         g (si )      = pgi and           h (si )   = phi for i = 1; 2.
Substitution for          then reveals the Rational Expectations conditions to be:
                                                               g pg
                                  s111 =       g pg
                                                                  1
                                                                         g )ph
                                                                                    = s122 ;
                                                  1      + (1                1
                                                                      g (1        pg1 )
                                  s211   =                                                                       = s222 :
                                               g (1            pg1 ) + (1              g )(1            ph1 ):

      The precise nature of the Optimality conditions depends on the utility function. If U (x1 ) >
U (x2 ), the condition is,
                                                                   1                          1
                                                    s111             and s222                   ,
                                                                   2                          2
with at least one strict. Substitution for s111 yields,

                                                               (1        g )ph               ph1
                                                   pg1                  g
                                                                             1
                                                                                       =         ;
                                                                                             R

where,
                                                                              g
                                                               R                   g
                                                                                       :
                                                                        1
Substitution for s222 yields,

                                                         (1           g )(1        ph1 )            1     ph1
                                         1   pg1                        g
                                                                                             =                ;
                                                                                                         R

or,
                                                                    R        1         ph1
                                                         pg1                     +         :
                                                                        R              R

                                                                        12
   Looking at these necessary conditions one can identify three cases depending on the value of
R: if R = 1 (     g   = 21 ), then in order for both inequalities to hold, one strictly, it is necessary and
                                                                                                                  ph
su¢ cient that pg1 > ph1 ; if R > 1 (      g   > 12 ), then the only constraint is pg1                  R 1
                                                                                                         R    +   R;
                                                                                                                   1
                                                                                                                       and …nally, if
                                                             ph
R<1(     g   < 21 ), the only constraint is pg1              R
                                                              1
                                                                  . The conditions in the case in which U (x2 ) > U (x1 )
are precisely the converse. Hence combining the two permissible utility functions, we arrive at the
following necessary and su¢ cient conditions:


      If R = 1 (      g   = 12 ), then,
                                                                    pg1 6= ph1 :

      If R > 1 (      g   > 12 ), then the constraints are,
                                                            R       1       ph1                 ph1
                                                pg1                     +       or pg1              :
                                                                R           R                   R

      If R < 1 (      g   < 21 ), then the constraints are,
                                                            ph1                 R       1       ph1
                                                pg1             or pg1                      +       :
                                                            R                       R           R


3.5    Two Examples

Example 1 Consider the case with                 g    = 0:8 so that R = 4. If U (x1 ) > U (x2 ), the condition is,

                                                      pg1       0:75 + 0:25ph1 :

Conversely, if U (x2 ) > U (x1 ), the condition is,

                                                            pg1     0:25ph1 :

We draw these constraint sets in …gure 3.


Example 2 The model can characterize an apparent reversal of preference, as when                                        g   = 0:5 and
stochastic action choice is,
                                                      pg1 = 0:9; ph1 = 0:7;

so that x1 is chosen with probability 0.9 with layout g, yet only with probability 0.3 with layout h.
To construct a RE-PREP in this case, set U (x1 ) > U (x2 ) and allow as usual for one mental state
s1 in which y1 is taken and another mental state s2 in which y2 is taken so that, by Data Matching,

                                           g
                                               (s1 ) = 0:9 and              h
                                                                                (s1 ) = 0:7:

                                                                    13
Figure 3: Constraints implied by R=4 (interior region is infeasible)




                                14
This implies that the lottery associated with choice of y1 in s1 is yields prize x1 with probability,
                                                         0:9
                                                                > 0:5;
                                                      0:9 + 0:7
Similarly, the prize lottery associated with action y2 in s2 yields x1 with probability,
                                                         0:3
                                                                > 0:5:
                                                      0:1 + 0:3
We complete the speci…cation of a RE-PREP by applying the Rational Expectations condition to set
the probabilities for the lotteries associated with the untaken actions in line with what they would
actually be,
                                            0:5 h (s1 )              0:7
                       s121 =             g  1          h  1
                                                               =             < 0:5;
                                     0:5 (s ) + 0:5 (s )          0:9 + 0:7
                                               0:5 1      g (s1 )
                                                                                  0:1
                       s211 =                  g   1                 h   1
                                                                             =           < 0:5:
                                     0:5 (1      (s )) + 0:5 (1        (s ))   0:1 + 0:3
Hence it is strictly optimal to pick y1 in s1 and y2 in s2 , completing the con…rmation that this is a
RE-PREP.



4      No Improving Action Switches

4.1      Blind Switches and Action Switches

A simple idea organizes the conditions identi…ed in the 2                    2       2 case and applies to the general
case. First, one must look through the actions that are chosen to the stochastic demand for prizes
that results. Consider example 1 above in this light, with                    g   = 0:8 so that R = 4, and suppose
that   pg1   = 0:75 and ph1 = 0 so that 1       pg1   = 0:25 and 1       ph1 = 1. In this case, whenever y1 is taken,
the layout is g, so that it yields prize x1 for sure. On the other hand, act y2 is taken both when
it yields prize x1 (layout h) and when it yields prize x2 (layout g). To understand the stochastic
demand for prizes resulting from action y2 , note that, conditional on this action being taken, the
layout is equally likely to be g or h,
                                         g   (1 pg1 )                   1    g )(1    ph1 )
                                                                    =                       = 0:5;
                            g   (1    pg1 ) + (1    g )(1   ph1 )       (1   g )(1    ph1 )
resulting in an overall even chance of winning prize x1 or prize x2 .

    One general point to note about this example is that if U (x1 ) > U (x2 ), the overall probability
of getting the good prize is 1 in the 60% of cases in which action y1 is taken, and 0.5 in the 40% of

                                                            15
cases in which action y2 is taken, for a net probability of 0.8. It is intuitive that there cannot be
a RE-PREP with a lower probability of getting the best prize, since the simple strategy of always
picking y1 yields the same outcome. This illustrates the “No Improving Blind Switches” (NIBS)
condition that we show in the section 5 to be necessary for a RE-PREP.

      There is a second observation that explains the constraints with more precision. Note that the
chance of getting the better prize from action y2 cannot be strictly less than 50%. Intuitively, if it
were to be thus, then it would be strictly superior to switch action y2 to y1 in state s1 , so as to
always take the action y1 . This is the No Improving Action Switches (NIAS) condition that we
show in the next section to fully characterize a RE-PREP.

      To apply the NIAS condition to the current case, note that the probability of receiving the good
prize when action y1 is taken is the conditional probability that the layout is g when y1 is taken,
                                                                g pg
                                                                   1
                                                  g pg                         g )ph
                                                                                            :
                                                     1   + (1                      1

The probability of receiving the good prize if action y2 had been taken every time that action y1
was taken would be the converse,
                                                     (1    g )ph
                                                               1
                                                  g pg          g )ph
                                                                      :
                                                     1+ (1          1
Hence the condition that this not yield an improvement is,

                                                  g g                          g
                                                   p1          (1                  )ph1 ;

or,
                                                                       ph1
                                                         pg1               :
                                                                       R
Similarly, the condition under which action y2 should not be globally replaced by action y1 is,

                                       (1     g
                                                  )(1          ph1 )               g
                                                                                       (1       pg1 );

or,
                                                          R            1           ph1
                                              pg1                          +           :
                                                                R                  R

      In the current case with   g   = 0:8 and R = 4, the only binding inequality is,

                                             pg1         0:75 + 0:25ph1 :

The fact that this is identical to the constraint identi…ed in example 1 for the case U (x1 ) > U (x2 )
(the upper left shaded region in …gure 3) is not coincidental.

                                                                16
4.2       The NIAS Inequalities

The above example pinpoints the central concept in our representation theorem, which involves
ruling out the existence of improving action switches.


De…nition 2 Utility function U : X ! R satis…es the NIAS inequalities with respect to (X; Y; ; P )
if for all k; m 2 f1; ::; M g,
                                 X
                                         (f )P f (ym )[U (f (ym ))            U (f (yk )]    0;
                                 f 2F

with at least one inequality strict.


     Note that the NIAS inequalities can be expressed in an alternative form that is more readily
compatible with the RE condition. In particular, given (X; Y; ; P ) and ym 2 Y such that P f (ym ) >
0 for some f 2 F( ), the stochastic demand for prizes associated with choosing yk in place of ym ,

 mk   2     (X) can be de…ned as,
                                                      P
                                                        ff 2F jf (yk )=xn g    (f )P f (ym )
                                   mk (xn )       =          P                                 :
                                                              f 2F    (f )P f (ym )
It is direct that the utility function U : X ! R satis…es the NIAS inequalities with respect to
(X; Y; ; P ) if, for all ym 2 Y such that P f (ym ) > 0 for some f 2 F( ), and for all k 2 f1; : : : ; M g,
                                        N
                                        X
                                              [   mm (xn )       mk (xn )]U (xn )       0;
                                        n=1

with at least one inequality strict.

     The key observation is that a necessary and su¢ cient condition for a RE-PREP is that there
exists a utility function such that the NIAS inequalities hold, so that for every taken action, it
is better not to switch to taking some …xed alternative action in all situations in which the given
action was taken. Note that        mm    2         (X) is the stochastic demand associated with choice of ym in
the IDS. Note also that the NIAS inequalities correspond to non-emptiness of the intersection of
(M        1)2 linear inequalities, which can be identi…ed using standard linear programming methods.


4.3       Characterization

Theorem 1 (X; Y; ; P ) have a RE-PREP representation if and only if there exists U : X ! R
satisfying the NIAS inequalities.

                                                                 17
Proof. Su¢ ciency: We identify a RE-PREP with exactly one state of mind sj for each action yj
that is taken with strictly positive probability, so that,

                                                       C(sj ) = yj :

We set      f (sj )   = P f (yj ) for all f 2 F( ) and j 2 f1; : : : ; M g, and pick U : X ! R satisfying the
NIAS inequalities. We note that, by construction, ( ; C) satisfy Data Matching. Moreover, given
yj 2 Y with P f (yj ) > 0, we use the Rational Expectations condition to solve for all sjmn : for all
m 2 f1; : : : ; M g, n 2 f1; : : : ; N g,
                                                 P
                                                   ff 2F jf (ym )=xn g   (f )P f (yj )
                                      sjmn   =        P                                  :
                                                          f 2F    (f )P f (yj )
Finally, note that, upon substitution for sm       m
                                           mn and skn as above, we derive the conditions for Opti-

mality as, for all k 2 f1; : : : ; M g,
      N
         "P                             f
                                             #                    N
                                                                        "P                                         #
     X       ff 2F jf (ym )=xn g (f )P (ym )
                                                                  X        ff 2F jf (yk )=xn g     (f )P f (ym )
                 P                f
                                               U (xn )                        P                                        U (xn );
                    f 2F (f )P (ym )                                              f 2F       (f )P f (ym )
      n=1                                                         n=1

with at least one strict. This reduces precisely to the NIAS inequalities that U satis…es by con-
struction.

    Necessity: A direct review of the above logic shows that identifying a utility function that sat-
is…es the NIAS inequalities is not only su¢ cient for a RE-PREP, but also necessary for a RE-PREP
in which there is only one state of mind per action. The full result follows from the observation
that if we identify a RE-PREP with more than one mental state for one or more action choices,
then there must exist a RE-PREP with only one mental state for each action choice: allowing for
multiple states does not expand the set of IDS for which a RE-PREP exists.

    Suppose that we have identi…ed a RE-PREP ( ; C; U ) of (X; Y; ; P ) such that, for all actions
yj taken with strictly positive probability, there exists states sj;p 2 S( ) for p 2 f1; : : : ; P (j)g with,

                                                 C(sj;p ) = yj for all p;

and with P (j) > 1 for some j.

                           ~ U ) that is identical to ( ; C; U ) except in the two respects. First, for
    De…ne a new triple (~; C;
                                                                                             ~ j ) = s~j ,
all j 2 f1; : : : ; M g such that action yj is taken with strictly positive probability, set C(y
where the prize lottery corresponding to state s~j is de…ned as,
                                   PP (j) P                          f j;p
                              j     p=1     ff 2F jf (ym )=xn g (f ) (s )
                            s~mn =     PP (j) P                            :
                                                                f j;p
                                          p=1    ff 2F g (f ) (s )


                                                             18
Second, de…ne ~ so that s~j is perceived in place of all sj;p ,
                                                                       P (j)
                                                                       X
                                                       ~f s~j =                f
                                                                                   (sj;p ):
                                                                       p=1



      By construction, note that C~          1 (y
                                                    j)   is a singleton with a single state s~j replacing all sj;p 2 S( ),

                                                            C~   1
                                                                     (yj ) = s~j .

                 ~ U ) form a RE-PREP of (X; Y; ; P ), note …rst that (~; C;
To show that (~; C;                                                       ~ U ) satis…es Data

Matching and Rational Expectations by construction. Optimality is established by noting that it
survives under convex combinations. What must be shown is that,
                         N
                         X                          N
                                                    X
                               s~m
                                 mn U (xn )                s~kmn U (xn ) for all m; k 2 f1; : : : ; M g :
                         n=1                        n=1

Upon substitution for s~m      ~m
                        mn and skn and after removing the common denominator, the Optimality

conditions become, for all m; k 2 f1; : : : ; M g,
      2                                    3                                       2                                                  3
   N    P (m)                                                               N        P (m)
  X     X       X                                                           X          X           X
      4                     (f ) f (sm;p )5 U (xn )                                4                                 (f )   f
                                                                                                                                (sm;p )5 U (xn );
  n=1     p=1 ff 2F jf (ym )=xn g                                           n=1        p=1 ff 2F jf (yk )=xn g

or,
        P (m) N                                                             P (m) N
        XX              X                                                   XX                    X
                                              f     m;p                                                                 f
                                      (f )        (s      )U (xn )                                               (f )       (sm;p )U (xn ):
        p=1 n=1 ff 2F jf (ym )=xn g                                         p=1 n=1 ff 2F jf (yk )=xn g


Validity of these conditions follows immediately from the fact that ( ; C; U ) form a RE-PREP of
(X; Y; ; P ), so that the Optimality condition implies that ym is a utility maximizer for each state
sm;p 2 S( ),
            N
            X          X                                                    N
                                                                            X                 X
                                             f
                                      (f )       (sm;p )U (xn )                                         (f )     f
                                                                                                                     (sm;p )U (xn ):
            n=1 ff 2F jf (ym )=xn g                                         n=1 ff 2F jf (yk )=xn g




      Note from the above proof that a necessary condition for ( ; C; U ) to comprise a RE-PREP of
(X; Y; ; P ) is that U satisfy the NIAS conditions.




                                                                       19
5     Two Framing E¤ects

5.1     Layout E¤ects

The characterization theorem allows for cases in which the layout has signi…cant impact on sto-
chastic demand – all that is necessary is that the NIAS conditions are satis…ed. Hence there may
be two frames f; g 2 F and x 2 X such that,

                             P f (fy 2 Y jf (y) = xg) 6= P g (fy 2 Y jg(y) = xg):

Consider for example top-down search in a list (see Rubinstein and Salant [2006]). In terms of
perception, this may plausibly result in greater clarity about objects high in the list than those
further down the list, which may in turn make them more likely to be chosen (as in Geng [2011]),
and also more likely to be of high utility when so chosen. The following stark example illustrates
these e¤ects at work.


Example 3 Suppose that there are 4 prizes, one of each value $1 through $4, and that each of the
four choices is ex ante equally likely to yield each prize:

                                          X = f$1; $2; $3; $4g;

                                          Y   = fym j1 m 4g;
                                                1
                                         (f ) =    all f 2 F:
                                                4!

Now suppose that the process of perception is such that the prize corresponding to action 1 (the top
line of four) is always seen with perfect clarity, while the other actions are not understood beyond
the prior and the identify of the prize corresponding to y1 . In this case, there are 4 subjective states,

                                    S( ) = f(x;      x)   2X     (X)3 g;

where      x   assigns to each ym with m > 1 the lottery that o¤ ers all prizes in X=x with probability
1
3.   If the DM is risk neutral, action y1 will be chosen whenever it is seen to contain a prize of $3
or $4, which is a 50% chance, with the other options dividing up the remaining probability. In this
case, note that selection of y1 can give rise only to prizes $3 and $4, with equal probability, while
for yn with n > 1, each action can give rise to any prize, with a one-third chance of either the $3
or the $4 prize, and a one-sixth chance of either the $1 or the $2 prize.


                                                     20
5.2   Informational E¤ects

When the impact of imperfect perception on stochastic choice is considered by economists, it is
typically treated as resulting from similarities between product characteristics (e.g. Debreu [1960]
and Natenzon [2011]). In such cases the precise layout has no impact on stochastic choice of prizes,
so standard framing e¤ects are not present. Yet even in such cases, the NIAS inequalities imply that
the layout-generating mechanism              may impact prize choice, since any RE-PREP of (X; Y; ; P )
must respect the information that the            provides on prize location.

   The No Improving Blind Switches (NIBS) inequalities mentioned in section 3 provide insight
into how the layout-generating mechanism impacts choice of prize. These inequalities summarize
the utility available to an agent who always makes the same choice of action. We show in theorem
2 that these simple inequalities on U : X ! R are necessary for ( ; C; U ) to provide a RE-PREP
representation of (X; Y; ; P ).


De…nition 3 Utility function U : X ! R satis…es the NIBS inequalities with respect to (X; Y; ; P )
if the chosen actions yield at least as high utility as would always choosing any …xed action yk 2 Y ,
                        X X                                                X
                                      (f )P f (ym )U (f (ym ))      max            (f )U (f (yk ));
                                                                   yk 2Y
                        f 2F ym 2Y                                         f 2F

with strict inequality for some yk 2 Y .


Theorem 2 If ( ; C; U ) provide a RE-PREP representation of (X; Y; ; P ), then U : X ! R
satis…es the NIBS inequalities.


Proof. As noted directly after the proof of theorem 1, if ( ; C; U ) provide a RE-PREP representa-
tion of (X; Y; ; P ), then U : X ! R must satisfy the NIAS inequalities. We show now that NIAS
implies NIBS. There are two cases:


  1. Suppose …rst that U : X ! R satis…es the NIAS inequalities, yet that there exists yk 2 Y
      such that,
                              X                           X X
                                      (f )U (f (yk )) >                (f )P f (ym )U (f (ym )):
                              f 2F                        f 2F ym 2Y
                   P
      Substitute    ym 2Y   P f (y   m)   = 1 on the LHS and rearrange to conclude that,
                       X X                                        X X
                                     (f )P f (ym )U (f (yk )) >                   (f )P f (ym )U (f (ym ));
                       ym 2Y f 2F                                 ym 2Y f 2F


                                                           21
     which in turn implies the existence of at least one possible action ym 6= yk 2 Y such that
     replacing ym by yk strictly increases utility,
                            X                                    X
                                    (f )P f (ym )U (f (yk )) >           (f )P f (ym )U (f (ym ));
                            f 2F                                 f 2F

     directly in contradiction to the NIAS inequalities.

  2. Now suppose that U : X ! R satis…es the NIAS inequalities, yet for all yk 2 Y ,
                             X                           X X
                                     (f )U (f (yk )) =                  (f )P f (ym )U (f (ym )):
                             f 2F                        f 2F ym 2Y
                  P
     Substitute     ym 2Y   P f (ym ) = 1 on the LHS and rearrange to conclude that,
                      X X                                        X X
                                    (f )P f (ym )U (f (yk )) =                 (f )P f (ym )U (f (ym )):
                      ym 2Y f 2F                                 ym 2Y f 2F

     Noting that the above holds for all yk 2 Y , we conclude that either there exists yk ; ym 2 Y
     such that,
                            X                                    X
                                    (f )P f (ym )U (f (yk )) >           (f )P f (ym )U (f (ym ));
                            f 2F                                 f 2F

     or for all yk ; ym 2 Y ,
                            X                                    X
                                    (f )P f (ym )U (f (yk )) =           (f )P f (ym )U (f (ym )):
                            f 2F                                 f 2F

     The former contradicts the weak inequality in NIAS, while the latter contradicts the need for
     strict inequality in at least one case.




   The necessity of the NIBS inequalities is intuitive, given that the Rational Expectations assump-
tion requires the DM to fully understand the statistical association between subjective perceptions,
choices, and prizes in a RE-PREP. These inequalities provide a particularly simple measure of the
information content of . They directly tie the degree of asymmetry in the layout-generating mech-
anism to the class of utility functions for which a RE-PREP exists. With a completely asymmetric
layout-generating mechanism in which a given action always produces the same prize, the NIBS
inequalities imply that all actions that are ever chosen must yield maximal utility. These inequali-
ties are less exacting when the layout-generating mechanism is completely symmetric, so that blind
choice of any action results in all prizes being equiprobable. In such a case, the NIBS inequalities

                                                          22
imply only that overall stochastic demand for prizes yields above the simple unweighted average
level of utility.

    The NIBS inequalities have important behavioral implications. They point out that the need
for perceptual attention depends on the layout-generating mechanism. In the extreme case, a par-
ticipant in a multiple-choice test could score 100% without the slightest need to read the questions
if the …rst answer was always correct. What this means is that attentional e¤ort is likely to be
a function of the layout-generating mechanism. The experiment in section 7 presents preliminary
evidence that this is indeed so –even in less extreme cases.



6     Imperfect Perception and Stochastic Choice

6.1    Stochastic Choice Data

It is rare in applied settings to have easy access to information on either action choices or the
layout-generating mechanism. For this reason, the standard data set for stochastic choice is the
pattern of observed demand for prizes across all choice problems. In this section, we characterize
restrictions on just such standard stochastic choice data associated with the existence of RE-PREP
representations based on a …xed utility function.


De…nition 4 A stochastic choice system (X; Q) comprises a …nite grand set X of prizes and
a correspondence,
                                         Q:X     !    (X );

with for all A 2 X ,
                                      QA (x) > 0 =) x 2 A;

where X is the set of all non-empty subsets of X.



6.2    RE-PREPs

We look for a representation of the entire choice system that involves a …xed utility function but
a variety of action choice subsets. We begin by specifying some action choice set Y , noting that it
may be conceptual rather than actually observed. For simplicity, we assume that Y has the same


                                                23
cardinality as X. We specify also choice sets YA                        Y with jYA j = jAj, corresponding to each set
A 2 X , as well as FA , the class of all 1-1 and onto functions from YA to A. The existence of a RE-
PREP then hinges on whether or not one can construct ideal data sets PA : FA (                               A)     !     (YA );
measures       A    2      (FA ); perception functions         A   : FA ! SA ; and choice functions CA : SA ! YA
with SA =           (X)jAj ; such that there exist RE-PREPs (A; YA ;                   A ; PA )   of the form (   A ; CA ; U )   in
which the stochastic choice system is reproduced. Note that the sets YA and Y are essentially
arbitrary.


De…nition 5 Stochastic choice system (X; Q) has a RE-PREP representation if there exists
Y with jY j = jXj, U : X              ! R, and quadruples (A; YA ;                A ; PA )   for all A 2 X ; with YA             Y;
jYA j = jAj;        A   2     (FA ); and PA : FA           !       (YA ); all of which have RE-PREP representations
(   A ; CA ; U )   with,
                                              X                  f
                                 QA (xn ) =               A (f )PA (f
                                                                      1
                                                                        (xn ))   for all xn 2 A;
                                              f 2FA

where the inverse function f           1   : A ! YA is de…ned by f (f            1 (x ))   = xn .
                                                                                     n




6.3      The Representation Theorem

The general characterization theorem captures the intuition that a RE-PREP representation exists
provided one can …nd a utility function such that expected utility in any choice problem A 2 X is
strictly higher than that associated with blind choice in A.


Theorem 3 Stochastic choice system (X; Q) has a RE-PREP representation if and only if there
exists U : X ! R such that, for all A 2 X ,
                                            X                            X U (xn )
                                                   QA (xn )U (xn ) >               :
                                                                            jAj
                                           xn 2A                         xn 2A


Proof. Su¢ ciency: De…ne the IDS so that it always gives rise to the given stochastic demand,

                                                      PAf (y) = QA (f (y));

                                                                                                                           1
for all f 2 FA and y 2 YA , and de…ne                 A   is a symmetric measure assigning equal probability              jAj!   to
each f 2 FA . With these two strong symmetry conditions, a direct counting argument shows that



                                                                   24
the stochastic demand for prizes associated with replacing ym with yk 6= ym is independent of ym
and yk . Speci…cally, the probability of getting prize xn 2 A with any such switch is,

                                                  A              1      QA (xn )
                                                  mk (xn )   =                   :
                                                                      jAj 1

With this strong symmetry among chosen and unchosen acts, there is one and only one inequality
for the NIAS condition to be satis…ed:
                               X                             X          1     QA (xn )
                                       QA (xn )U (xn ) >                               U (xn );
                                                                            jAj 1
                               xn 2A                         xn 2A

or,
                                         X                                  X U (xn )
                                                 QA (xn )U (xn ) >                    ;
                                                                               jAj
                                         xn 2A                           xn 2A

as assumed. Hence for all A 2 X , the NIAS conditions hold for (A; YA ;                                 A ; PA ),   which therefore
possesses a RE-PREP representation with the …xed utility function U : X ! R. Hence (X; Q) has
a symmetric RE-PREP representation.

      Necessity: Suppose that the condition is not satis…ed, but that (X; Q) has a RE-PREP repre-
sentation for some …xed utility function U : X ! R. We establish a contradiction by showing that
U does not satisfy the NIBS inequalities. By assumption, there exists A 2 X such that,
                                         X                                  X U (xn )
                                                 QA (xn )U (xn )                      :
                                                                               jAj
                                         xn 2A                           xn 2A

Substitution for QA (xn ) yields,
                         X X                    f
                                                                                 X U (xn )
                                                     1
                                         A (f )PA (f   (xn ))U (xn )                       :           ( )
                                                                                    jAj
                        xn 2A f 2FA                                              xn 2A

Note that the LHS of ( ) is simply the expected utility of the chosen acts,
               X X                   f
                                                                      X       X             f
                                          1
                              A (f )PA (f   (xn ))U (xn )        =                   A (f )PA (ym )U (f (ym )):
              xn 2A f 2FA                                             f 2FA ym 2YA

We now show the relationship between the RHS of ( ) and blind choices. Summation across blind
choices yields,
                X X                                    X X                                   X
                               A (f )U (f (yk ))   =                    A (f )U (xn )    =           U (xn ):   ( )
               yk 2YA f 2FA                            xn 2A f 2FA                           xn 2A

There are two cases to consider:



                                                                 25
  1. If all blind choices yield the same amount, ( ) implies that they all yield simple arithmetic
      average utility,
                             X                                X U (xn )
                                     A (f )U (f (yk ))   =              for all yk 2 YA :
                                                                 jAj
                             f 2FA                           xn 2A

      Substitution as indicated for LHS and RHS in ( ) then yields,
                         X      X               f
                                                                             X
                                         A (f )PA (ym )U (f (ym ))                   A (f )U (f (yk ));
                         f 2FA ym 2YA                                        f 2FA

      for all yk 2 Y . This directly contradicts NIBS, which requires strict inequality in the other
      direction.

  2. If not all blind choices yield the same amount of utility, ( ) implies that there exists yk 2 YA
      yielding strictly above simple arithmetic average utility from blind choice,
                                        X                                X U (xn )
                                                A (f )U (f (yk ))    >             :
                                                                            jAj
                                        f 2FA                            xn 2A

      Substitution as indicated for LHS and RHS in ( ) then yields,
                         X      X               f
                                                                             X
                                         A (f )PA (ym )U (f (ym ))       <           A (f )U (f (yk ));
                         f 2FA ym 2YA                                        f 2FA

      which directly contradicts NIBS.




6.4   Imperfect Perception or Stochastic Utility?

For more than …fty years, the dominant theory of stochastic choice has involved placing all ran-
domness in the utility function (see Luce [1959] and Block and Marschak [1960]). The most famous
axiom for such cases is Luce’s axiom, whereby the ratio of the probabilities of choosing any one
item over any other is independent of other “irrelevant”alternatives. While this has been relaxed in
many ways, most stochastic utility models place restrictions on the relative probabilities of choosing
one option over another across distinct choice sets. For example, a weaker form asserts that, if one
good is ever chosen with higher probability than an alternative in a given choice set, then it is
chosen with higher probability than that alternative in all choice sets.

   Our results show that there are weaker restrictions on standard stochastic choice data when
imperfect perception is the source of stochasticity. The following example illustrates a complete

                                                         26
reversal in choice probabilities between a two prize set and a three prize set. An item that is always
chosen in two prize set is never chosen in the three prize set.


Example 4 Consider X = fx1 ; x2 ; x3 g and assume that in binary choice with a symmetric layout-
generating mechanism, x1 is chosen with probability 1 over both x2 and x3 , and x2 is chosen with
probability 1 over x3 ,

                           Qfx1 ;x2 g (x1 ) = Qfx1 ;x3 g (x1 ) = Qfx2 ;x3 g (x2 ) = 1:

This means that a necessary condition for RE-PREPs to exist for all three sets is that U (x1 ) >
U (x2 ) > U (x3 ).
                           Qfx1 ;x2 g (x1 ) = Qfx1 ;x3 g (x1 ) = Qfx2 ;x3 g (x2 ) = 1:

The theorem implies that
                                            Qfx1 ;x2 ;x3 g (x3 ) = 1

is inconsistent with existence of a RE-PREP for the stochastic choice system. However, it is entirely
possible to have x2 chosen for sure,

                                            Qfx1 ;x2 ;x3 g (x2 ) = 1:

In this case, one can construct a RE-PREP for the stochastic choice system in which the layout-
generating mechanism is symmetric, the utility function satis…es U (x1 ) > U (x2 ) > U (x3 ), and
prize x2 is preferred to an equal chance of prizes x1 and x3 ,

                                                     U (x1 ) + U (x3 )
                                         U (x2 ) >                     :
                                                             2

The corresponding perception function is such that all prizes are perfectly identi…ed in two prize
sets, while there is complete inability to distinguish prizes 1 and 3 in three prize sets: the presence
of prize x2 induces confusion between x1 and x3 .


    While the above example is extreme, the broad idea is reasonable. Perceptual confusion may
indeed be more signi…cant in large choice sets than in small choice sets. As a result, a moderately
good item that is easy to identify may be particularly attractive in large choice sets because there
is little risk of it being confused with a bad item. Cases of this kind are modeled by Natenzon
[2011], and …t well with the work of Iyengar and Lepper [2000] on di¢ culties associated with choice
from large choice sets.

                                                       27
7        Experimental Evidence

As indicated, a test of our theory requires rich data on the decision making “frame”. We detail in
this section a simple laboratory experiment in which: (1) the ICE (X; Y; ; P ) is fully observed; and
(2) the layout-generating mechanism                is varied systematically. While subjects make substantial
choice mistakes in all treatments, we …nd that the NIAS inequalities are always satis…ed, so that
subjects behave in accordance with our model.

        Both of the framing e¤ects allowed for in our model are present in the experimental data. Not
only does the layout impact choice, but also the layout-generating mechanism. It is the latter e¤ect
that is most de…ning of our model, and the fact that we can control it experimentally is critical to
our ongoing research on imperfect perception.



7.1        Experimental Design

In each round, subjects were presented with three options, each of which is composed of 20 numbers.
Figure 4 shows a screen capture of a typical round. The value of each option is the sum of all 20
numbers, and subjects were incentivized to select the object with the highest value. In the baseline
symmetric treatment (“33%, 33%, 33%”), subjects were informed that all three options were equally
likely to be the highest valued option, but in two other treatments, the …rst option was more likely
to be the highest valued option. In one of the asymmetric treatments (“40%, 30%, 30%”), subject
were informed that the …rst option was approximately 40% likely to be the highest valued option
(the other two were both approximately 30% likely). In the other asymmetric treatment (“46%,
27%, 27%”), subjects were told that the …rst option was approximately 46% likely to be the highest
valued option (the other two were both approximately 27% likely). Subjects completed 12 rounds
of each treatment, which were presented in a random order.4



7.2        Testing for No Improving Action Switches (NIAS)

The experiment was run with 36 subjects in the CESS laboratory. As seen in table 1, subjects chose
the best (highest valued) option in 54% of rounds, which is higher than the expected percentage
    4
        The instructions provided to subjects are available in the appendix.




                                                            28
                                                Figure 4: A typical round


under random choice but far below that associated with perfect perception.5 The fraction of rounds
in which the highest valued option was chosen was stable over the course of the experiment – the
fraction in the …rst half of rounds was not signi…cantly di¤erent than the fraction in the second
half of rounds ( = 0:01).

                             Table 1. Percentage of rounds best option was chosen
                              Treatment               n        Rounds best option chosen
                              33%, 33%, 33%           418      54%
                              40%, 30%, 30%           424      52%
                              46%, 27%, 27%           422      56%
                              Overall                 1264     54%

       For a layout-generating mechanism , the NIAS inequalities are satis…ed for a utility function
U if,
                                      N
                                      X
                                            [   mm (xn )     mk (xn )]U (xn )   0;
                                      n=1
for every all k; m 2 f1; : : : ; M g, with at least one inequality strict. If the utility function is
normalized so that U ($8) = 1 and U ($4) = 0, then the NIAS inequalities reduce to,
                P                         f
                                                 P                        f
                  ff 2F jf (ym )=$8g (f )P (ym )  ff 2F jf (yk )=$8g (f )P (ym )
                      P              f
                                                     P               f
                                                                                 0:
                         f 2F (f )P (ym )                f 2F (f )P (ym )

These conditions imply that the percentage of rounds in which action ym is chosen and is best
must be no smaller, and sometimes strictly larger, than the percentage of rounds in which action
   5
       More than one option had the highest value in 2.4% of rounds. These rounds were removed to simplify the
analysis, but their exclusion does not qualitatively a¤ect the results.


                                                             29
ym is chosen, but action yk is best. This determines whether subjects could have done better by
switching from action ym to action yk because the rounds where ym was chosen and was best would
lose utility of 1 with the switch and the rounds where ym was chosen but yk was best would gain
utility of 1 with the switch.

             Table 2. Percentage of rounds chosen option was best by treatment
                                                   Best Option
               Treatment         Chosen Option     1st Option    2nd Option    3rd Option
               33%, 33%, 33%     1st Option        48%           25%           27%
                                 2nd Option        27%           51%           23%
                                 3rd Option        19%           24%           56%
               40%, 30%, 30%     1st Option        54%           23%           23%
                                 2nd Option        25%           53%           22%
                                 3rd Option        18%           14%           67%
               46%, 27%, 27%     1st Option        54%           19%           27%
                                 2nd Option        26%           44%           29%
                                 3rd Option        17%           23%           60%


   Table 2 shows, for the rounds in which a given action was taken, the percentage of rounds in
which each option was the best option. This table can be used to directly verify that the NIAS
inequalities hold for all treatments and all possible action switches. For example, in the “40%, 30%,
30%”treatment, the NIAS inequalities were satis…ed when the …rst option was chosen because the
percentage of rounds in which the …rst option was chosen and was best was 54%, while the two
alternative options were each optimal in only 23% of rounds in which the …rst option was chosen.
In fact, the condition holds for all treatments and all possible action switches. The closest the
NIAS condition comes to being violated is in the “46%, 27%, 27%” treatment for switching from
the second option (44%) to the third option (29%).



7.3   Two Framing E¤ects

As discussed previously, our model allows for two distinct forms of framing e¤ects, and we see
evidence of both in subjects’choices. As shown in table 3, we see slight evidence of order e¤ects:
the third option was selected less often than the second option, even though on average, there is

                                                 30
no informational di¤erence between the second and third option in any treatment. However, these
proportions are only signi…cantly di¤erent for the …rst treatment ( = 0:05).

                      Table 3. Percent of rounds each option chosen by treatment
                       Treatment          1st Option   2nd Option     3rd Option
                       33%, 33%, 33%      32%          38%            30%
                       40%, 30%, 30%      57%          23%            20%
                       46%, 27%, 27%      70%          16%            14%


    Also present is the second framing e¤ect, in which subjects respond to the information content
of the layout-generating mechanism, in particular the probability with which each available action
yields the best prize. The No Increasing Blind Switches (NIBS) condition requires that subjects
choose the best option more often than they would if they “blindly” selected the …rst option.
Table 1 above shows that this condition holds in every treatment because subjects did better on
average than they would by always selecting the …rst option. In addition, the …rst column of table
3 shows that the percent of rounds in which the …rst option was chosen increases substantially
as the likelihood of the …rst option being the best option increases and is signi…cantly higher in
the asymmetric treatments than the probability of the …rst option actually being the best option.
These results raise intriguing questions concerning the interaction between the layout-generating
mechanism and the quality of …nal choice.



8    Concluding Remarks

We have introduced a model of rational decision making that allows for an essentially unlimited
array of perceptual limitations. We study “rational expectations perception-based representations”
(RE-PREPs) in which DMs fully internalize how their perceptions relate to choices and to their
consequences. We show that the signature of the resulting theory is that stochastic choices are
“unimprovable”, with the precise improvements that can be ruled out depending on the data
available for model testing.

    Our …rst characterization result involves a data set that includes the …ne details of the decision
making environment, in particular detailed information about how the decision was presented to
the DM. In this context, we show that existence of a RE-PREP representation is equivalent to a


                                                 31
No Improving Action Switches (NIAS) condition. We also characterize standard stochastic choice
data consistent with our theory. The resulting restrictions, while intuitive, are weaker than those
imposed by stochastic utility models.

    Our model allows for both familiar framing e¤ects that relate to the layout of the prizes and
more novel e¤ects that relate to the information content of the environment. We outline an ex-
perimental design to explore these e¤ects, and …rst results support our model and indicate the
importance of information-based framing e¤ects. In ongoing work, we are further investigating the
interaction between environmental information and imperfect perception, with particular focus on
attention. We are also exploring the applicability of our general approach to questions of informa-
tion processing and Bayesian inference, as well as to strategic settings in which agents may have
di¤erent perceptions.



9    Bibliography


References

 [1] Bernheim, B. Douglas, and Antonio Rangel. 2008. “Choice-Theoretic Foundations for Be-
     havioral Welfare Economics.” In The Foundations of Positive and Normative Economics, ed.
     Andrew Caplin and Andrew Schotter. New York: Oxford University Press.

 [2] Block, H. D., and J. Marschak. 1960. “Random Orderings and Stochastic Theories of Re-
     sponse.” In Contributions to Probability and Statistics. Essays in honor of Harold Hotelling,
     ed. I. Olkin. Stanford University Press.

 [3] Caplin, Andrew. 2008. “Economic Theory and Psychological Data: Bridging the Divide.” In
     The Foundations of Positive and Normative Economics, ed. Andrew Caplin and Andrew Schot-
     ter. New York: Oxford University Press.

 [4] Caplin, Andrew, Mark Dean, and Daniel Martin. Forthcoming. “Search and Satis…cing.”Amer-
     ican Economic Review.

 [5] Caplin, Andrew, and Mark Dean. 2011. “Search, choice, and revealed preference.”Theoretical
     Economics, 6: 19-48.


                                                32
 [6] Compte, Olivier, and Andrew Postlewaite. 2011. “Mental Processes and Decision Making.”
    Mimeo.

 [7] Debreu, Gerard. 1960. “Review: Individual Choice Behavior.” American Economic Review,
    50(1): 186-188.

 [8] Ergin, Haluk, and Todd Sarver. 2010. “A Unique Costly Contemplation Representation.”
    Econometrica, 17: 1285-1339.

 [9] Falmagne, J. C. 1978. “A representation theorem for …nite random scale systems.”Journal of
    Mathematical Psychology, 18(1): 52-72.

[10] Gabaix, Xavier. 2011. “A Sparsity-Based Model of Bounded Rationality.”Mimeo. NYU Stern.

[11] Geng, Sen . 2011. “Asymmetric search, asymmetric choice errors, and status quo bias.”Mimeo.
    New York University.

[12] Gennaioli, Nicola, and Andrei Shleifer. 2010. “What Comes to Mind.” Quarterly Journal of
    Economics, 125(4): 1399-1433.

[13] Glimcher, Paul. 2010. Foundations of Neuroeconomic Analysis, Oxford University Press.

[14] Gottlieb, Daniel. 2010. “Imperfect Memory and Choice Under Risk.” Wharton Insurance and
    Risk Management Working Paper WP2010-05.

[15] Gul, Faruk, and Wolfgang Pesendorfer. 2008. “The Case for Mindless Economics.” In The
    Foundations of Positive and Normative Economics, ed. Andrew Caplin and Andrew Schotter.
    New York: Oxford University Press.

[16] Gul, Faruk, and Wolfgang Pesendorfer. 2006. “Random Expected Utility.” Econometrica,
    74(1): 121-146.

[17] Iyengar, Sheena, and Mark Lepper. 2000. “When Choice is Demotivating: Can One Desire
    Too Much of a Good Thing?” Journal of Personality and Social Psychology, 79: 995-1006.

[18] Koszegi, Botond, and Matthew Rabin. 2008. “Revealed Mistakes and Revealed Preferences.”
    In The Foundations of Positive and Normative Economics, ed. Andrew Caplin and Andrew
    Schotter. New York: Oxford University Press.

[19] Luce, R. Duncan. 1959. Individual Choice Behavior: a Theoretical Analysis. New York: Wiley.

                                              33
[20] McFadden, Daniel. 1973. Conditional logit analysis of qualitative choice behavior, Institute of
    Urban & Regional Development, University of California.

[21] Manzini, Paola, and Marco Mariotti. 2007. “Sequentially Rationalizable Choice.” American
    Economic Review, 97(5): 1824-1840.

[22] Masatlioglu, Yusufcan, and Daisuke Nakajima. 2009. “Choice by Iterative Search.”University
    of Michigan Working Paper.

[23] Mullainathan, Sendhil. 2002. “A Memory-Based Model of Bounded Rationality.” Quarterly
    Journal of Economics, 117: 735-774.

[24] Natenzon, Paulo. 2011. “Random Choice and Learning.” Mimeo. Princeton University.

[25] Rabin, Matthew, and Georg Weizsacker. 2009. “Narrow Bracketing and Dominated Choices.”
    American Economic Review, 99: 1508-1540.

[26] Ratcli¤, Roger. 1978. “A theory of memory retrieval.” Psychological Review, 85(2): 59-108.

[27] Ratcli¤, Roger, and Gail McKoon. 2008. “The di¤usion decision model: theory and data for
    two-choice decision tasks.” Neural Computation, 20: 873-922.

[28] Reutskaja, Elena, Rosemarie Nagel, Colin Camerer, and Antonio Rangel. 2011. “Search dy-
    namics in consumer choice under time pressure: An eyetracking study.” American Economic
    Review, 101: 900-926.

[29] Rubinstein, Ariel, and Yuval Salant. 2006. “A Model of Choice from Lists.” Theoretical Eco-
    nomics, 1(1): 3-17.

[30] Salant, Yuval, and Ariel Rubinstein. 2008. “("A", "f"): Choice with Frames,” Review of Eco-
    nomic Studies, 75(4): 1287-1296.

[31] Schwartzstein, Joshua. 2010. “Selective Attention and Learning.”Mimeo. Dartmouth College.

[32] Shadlen, Michael N., and William T. Newsome. 2001. “Neural basis of a perceptual decision
    in the parietal cortex (area LIP) of the rhesus monkey.”Journal of Neurophysiology, 86: 1916-
    1936.

[33] Simon, Herbert. 1955. “A Behavioral Model of Rational Choice.” Quarterly Journal of Eco-
    nomics, 69(1): 99-118.

                                                34
[34] Sims, Christopher A. 2003. “Implications of Rational Inattention.” Journal of Monetary Eco-
    nomics, 50 (3), 665–690.

[35] Thaler, Richard H. 1985. “Mental Accounting and Consumer Choice.” Marketing Science, 4,
    199-214.

[36] Weber, E. H. 1834; 1996. On the Tactile Senses, ed. H. E. Ross and D .J.Murray. New York:
    Experimental Psychology Series.

[37] Wilson, Andrea. 2002. “Bounded Memory and Biases in Information Processing.” Mimeo.
    Princeton University.




                                              35
                                            Appendix

Instructions

In this experiment, you will take part in 1 practice round and then 36 regular rounds. Any
choices you make during the practice round will not affect your final payment.

In each round, you will be shown 3 options, each of which contains 20 numbers. The value of
each option is the sum of all 20 numbers. Your task will be to choose the option that has the
highest value (or one of the options with the highest value). You cannot use a calculator or
scratch paper.

At the end of the experiment, we will select 3 of the 36 regular rounds for payment. In each
round selected for payment, if you chose the option with the highest value, you will get $8, if not,
you will get $4. Thus, the maximum total payment is $24 and the minimum total payment is $12.
When a round starts, you will be told which type of round it is. There are three different types of
rounds:

1. "33%, 33%, 33%" rounds (12 rounds total)
All options are equally likely (approximately 33% likely) to have the highest value. For all
options, each of the twenty numbers is a random integer between plus eighteen and minus
eighteen (all equally likely), and each number is determined independent of the other numbers.
Thus, the value of each option is independent of the value of the other options, and all options
are equally likely to have the highest value.

2. "40%, 30%, 30%" rounds (12 rounds total)
The first option is approximately 40% likely to have the highest value, and each of the others is
approximately 30% likely to have the highest value. For the first option, each of the twenty
numbers is a random integer between plus nineteen and minus eighteen (all equally likely). For
the second and third option, each of the twenty numbers is a random integer between plus
eighteen and minus eighteen (all equally likely). Once again, the value of each option is
independent of the value of the other options.

3. "46%, 27%, 27%" rounds (12 rounds total)
The first option is approximately 46% likely to have the highest value, and each of the others is
approximately 27% likely to have the highest value. For the first option, each of the twenty
numbers is a random integer between plus twenty and minus eighteen (all equally likely). For
the second and third option, each of the twenty numbers is a random integer between plus
eighteen and minus eighteen (all equally likely). Once again, the value of each option is
independent of the value of the other options.

When a round starts, no option will be selected. You can change which option is selected by
clicking on the button to the left of the option you want or by clicking anywhere on the option
itself. You are free to change which option is selected at any time and as many times as you
like.

Whenever you click on the 'Finished' button, the round will come to an end, and the selected
option will be recorded as your choice. After a brief pause, you will be given the opportunity to
either review the instructions again on the computer screen or proceed to the next round. This
will continue until you have completed 1 practice rounds and 36 regular rounds, for a total of 37
rounds.
