                              NBER WORKING PAPER SERIES




                 THE RISE OF FOR-PROFIT EXPERIMENTAL MEDICINE

                                         Pierre Azoulay
                                         Ariel Fishman

                                      Working Paper 26892
                              http://www.nber.org/papers/w26892


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                                    March 2020




Send all correspondence to pazoulay@mit.edu. We thank Sherry Glied, Joshua Graff Zivin, Scott
Stern, and Scott Shane for useful discussions. A major portion of this research was conducted
while both authors were at Columbia University. The usual disclaimer applies. The views
expressed herein are those of the authors and do not necessarily reflect the views of the National
Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2020 by Pierre Azoulay and Ariel Fishman. All rights reserved. Short sections of text, not to
exceed two paragraphs, may be quoted without explicit permission provided that full credit,
including © notice, is given to the source.
The Rise of For-Profit Experimental Medicine
Pierre Azoulay and Ariel Fishman
NBER Working Paper No. 26892
March 2020
JEL No. I13,I23,O31

                                           ABSTRACT

Beginning around 1990, academic medical centers have ceased to be the primary locus of
industry-sponsored clinical trial activity. Instead, clinical trials have increasingly been conducted
in private practices and for-profit, dedicated study sites. We examine the underlying causes of
this startling evolution. On the demand side, the greater availability of non-academic
investigators has enabled pharmaceutical firms to better match physicians' skills with specific
projects. On the supply side, we argue that the growth of managed care health insurance has
contributed to a rise in the number of non-academic physicians performing clinical research. We
find evidence consistent with these claims using a unique data set containing information about
85,919 site contracts for 7,735 clinical trials between 1991 and 2003. Furthermore, we examine
the gap in prevailing prices for comparable procedures conducted for clinical trials versus
conventional medical care, and conclude that the effect of managed care on entry is consistent
with non-academic physicians "inducing demand" so as to resist downward pressures on their
income.


Pierre Azoulay
MIT Sloan School of Management
100 Main Street, E62-487
Cambridge, MA 02142
and NBER
pazoulay@mit.edu

Ariel Fishman
Albert Einstein College of Medicine
1300 Morris Park Ave
The Bronx, NY 10461
ariel.fishman@einsteinmed.org
1     Introduction

Physicians invest in human capital through long years of training in medical school, resi-
dency, and clinical fellowship. During the routine provision of medical care, most physicians
apply their human capital narrowly, in ways that generate mostly private returns--both to
themselves and to their patients. This very same human capital, however, can also be de-
ployed in ways that generate social returns, during the conduct of clinical trials sponsored
by public research institutions or by pharmaceutical firms. Clinical research could gener-
ate contemporaneous spillovers on the health of private patients treated by physicians who
also treat experimental patients; and it certainly generates spillovers on the health of future
patients, through advances in useful medical knowledge.

    Borrowing from the vocabulary of the endogenous growth literature (e.g., Romer 1990),
the present chapter examines the demand and supply forces that shift skilled medical person-
nel from the "production sector" of the medical care economy--routine care--to its "ideas
sector"--participation in clinical trials.

    The clinical trials industry emerged in response to regulatory requirements for the devel-
opment of new pharmaceutical compounds. In order to gain approval for market introduc-
tion, the United States Food and Drug Administration (FDA) and its foreign equivalents
require that a pharmaceutical company provide substantial evidence of a drug's effectiveness,
through adequate and well-controlled clinical investigations. Although the precise require-
ments have evolved over the years, proof of effectiveness must generally be demonstrated by
the results of randomized controlled trials (RCTs). In contrast to early-stage drug discov-
ery research, which are often conducted within in-house laboratories, pharmaceutical firms
contract out the conduct of experimental human studies to independent physicians. Tra-
ditionally, most clinical trials were conducted by physicians employed in academic medical
centers or community hospitals. Since the early 1990s, however, academic organizations have
gradually ceased to be the primary locus of industry-sponsored drug development activities.
Instead, clinical trials have been taking place outside academic institutions: independent hos-
pitals, private practices and for-profit, dedicated clinical research sites. During the 1990s, the


                                                1
proportion of academic clinical sites decreased steadily from 70% of U.S. sites in 1991 to 35%
in 2001, as can be seen in Figure 1. The present chapter seeks to provide a comprehensive
examination of the underlying causes of this startling evolution.

   In a first step, we focus on the role played by the level of demand for clinical trials
by the pharmaceutical industry. Specifically, variation in project characteristics leads to
variation in the relative importance of doctors' effort on two tasks that compete for their
attention: data production --the routine manipulation, storage, and transfer of symbolic
information within established categories; and knowledge production --the establishment of
novel conceptual categories, hypotheses, and causal associations (Osberg, Wolff, and Baumol
1989). Pharmaceutical firms fine-tune the mix of academic and non-academic investigators
to achieve a desired skill mix for each project. This implies that the proportion of academic
investigators at the project level should correlate with variables that proxy for the importance
of knowledge-production activities, relative to data-production activities.

   On the supply side, we argue that the growth of managed care health insurance has
been a strong impetus for entry into the clinical trials industry. Under managed care, health
insurers took a more active role in attempting to reduce health care costs (and thus, the price
of insurance policies) through a variety of financial mechanisms. These mechanisms were
designed to mitigate the moral hazard inherent in insurance itself and to leverage the market
power of health consumers as a collective body to lower prices paid for medical services.
A perhaps unintended consequence was that these mechanisms also adversely affected the
earnings of medical service providers (Hadley and Mitchell 1999).

   In response, some physicians may have started conducting clinical trials instead of (or
in addition to) providing traditional patient care because payments from pharmaceutical
firms were more in line with the cost-plus arrangements characteristics of traditional in-
demnity insurance. However, the incentive to substitute experimental patients for private
patients is muted in academic medical centers, since academic physicians are typically not
full residual claimants on these incremental profits. Moreover, cooperating with industrial
firms often carries a stigma in the academic setting, because participating in clinical trials



                                               2
involves relinquishing some degree of intellectual autonomy to the sponsor. This argument
implies that "for-profit" clinical trial activity should be highest in areas of high managed
care penetration, but that this correlation should be smaller or zero in the case of academic
doctors.

   We use a variety of data sources to support our argument. The primary dataset consists
of 85,919 clinical trial contracts granted between 1991 and 2003 collected by Fast Track
Systems, Inc. In a first step, we aggregate the data up to the clinical trial level to show
that the fraction of academic investigators correlates with indicators of knowledge intensity,
such as different measures of compound novelty, whether the trial takes place in an inpatient
setting, and project phase. In a second step, we collapse this same source of information so as
to exploit cross-sectional and longitudinal variation in the volume of clinical trials activity
across geographic areas--counties or Health Service Areas (HSAs)--and show that high
managed care penetration in an area is associated with higher levels of "for-profit" clinical
research activity in that area, but bears little relationship with the volume of academic
clinical research.

   In a final step, we attempt to distinguish between two mechanisms that could underlie the
relationship between managed care and clinical research volumes. The growth of managed
care penetration is often alleged to have raised physicians' incentives to practice medicine
in groups, in part to gain negotiating leverage with insurers (Casalino, Pham and Bazzoli
2003). As a byproduct, medical groups often invest in information technology, and these
same IT investments could in theory lower the costs of entry into clinical research. In
contrast, the demand inducement explanation we favor does not imply that large practices
be more prone to enter the research arena, but is critically dependent on the existence
of rents earned by physicians on experimental patients. We adjudicate between these two
competing explanations in two ways. First, we show that small group practices (less than
ten physicians) are driving the correlation between "for-profit" research and managed care.
Second, we make use of a separate dataset supplied to us by RapidTrials, Inc. containing
payment data for 1,227 medical procedures conducted at clinical research sites from 1997
to 2004. We compare the prevailing price paid by clinical trial sponsors for these medical


                                              3
procedures to the Medicare fee schedule for those same procedures, and find that clinical
investigators earn two to three times more on average from pharmaceutical sponsors, relative
to Medicare.

    We also conduct interviews of two separate groups of physicians, both in 1999 and in
2007. These physicians had varying degrees of exposure to managed care, clinical trials, and
academic medicine, and represented a broad spectrum of career backgrounds and medical
specialties. We use the qualitative evidence to provide additional support for our hypotheses,
and to probe in more detail than the econometric evidence would permit the origins and likely
evolution of the for profit clinical trials industry.

    The rest of the paper proceeds as follows. In the next section, we present a brief overview
of clinical development and of the trends that have affected the clinical trials industry.
Section 3 provides a similar overview of managed care and its effects on physician behavior.
Section 4 describes the data, modeling approach, and identification strategy. Sections 5 and
6 respectively present the main qualitative and econometric results, while Section 7 offers
some concluding remarks.


2     The Rise of For-Profit Clinical Research

2.1    Historical context

Clinical development is a complex, time-consuming, and costly process, as experimental
studies demand careful coordination of activities across scientific disciplines, organizational
and institutional boundaries, and, occasionally, countries. Following the synthesis of a new
molecule and animal toxicology studies, drug companies must file Investigational New Drug
applications (INDs) with the Food and Drug Administration (FDA) in order to obtain the
necessary authorization for testing on patients the compound's efficacy in a particular disease.
The development process has a substantial risk of failure: Conditional on filing an IND, the
probability of eventual regulatory approval hovered slightly above 20% in the early 1990s
(corresponding to a cohort of 1979-1983 INDs; DiMasi 1995). Once the clinical phase is



                                                 4
completed, companies submit New Drug Applications (NDAs) to the FDA and regulatory
review begins, during which the firm's medical experts present the agency with evidence
for the product's safety and efficacy, as gathered from clinical trials. This process typically
involves a period of four to eight years between the filing of the IND and approval of the
NDA (DiMasi, Seibring, and Lasagna 1994; Kaitin and Healy 2000).1

       Prior to 1962, the FDA routinely considered evidence of efficacy as part of the drug
approval process, but this evidence was usually limited to casual observations from practicing
physicians (Quirk 1980: p. 197). A major scandal (the 1961 thalidomide disaster, in which
a drug marketed for the treatment of morning sickness was later found to cause severe
birth defects) and the rise of the consumer protection movement gave the impetus to the
adoption of the 1962 Kefauver Harris Amendment. This Act of Congress required that
every new drug be approved prior to its marketing, and that this approval depended on the
drug's being proven safe as well as effective. Further, the Act established a legal framework
for the subsequent use of randomized controlled trials (RCTs) as the "gold standard" in
clinical research. In addition to this substantive change, the FDA used its discretionary
power to influence the procedures according to which pharmaceutical companies would collect
clinical data, produce evidence, and determine marketing strategies. The Kefauver Harris
Amendment thus led to a proliferation of administrative rules that significantly raised the
costs of drug development (Peltzman 1973; Thomas 1990). Testifying to the importance of
these formal requirements is the extraordinary quantity of information processing necessary
for regulatory review: A complete NDA may contain up to 200 volumes of information (Quirk
1980).

       Long before formal testing requirements became enshrined into law, pharmaceutical com-
panies contracted experimental human studies to be conducted by clinicians employed out-
side the organizations. Pioneering examples of such collaborations include that of the Eli
   1
     While the FDA has dramatically reduced the time needed to evaluate NDAs following the Prescription
Drug User Fee Act (PDUFA) of 1992, this has been offset by a comparable increase in the length of the
clinical phase. For 67 new chemical entities approved by the FDA in 1993, 1994, and 1995, the mean length
of the clinical phase (IND filing to NDA submission) was 7.1 years; for the approval phase (NDA submission
to approval), it was 2.0 years (Kaitin and Manocchia 1997).




                                                    5
Lilly corporation and the University of Toronto for the development of synthetic insulin in
the 1920s, and that of Merck with University of Pennsylvania researchers in the 1930s for
the development of the anesthetic Vinethene (Swann 1988). The growing use of academic
researchers in this capacity reflected three major underlying phenomena: the rapid advances
in the fields of physiology and pathology in the early part of the twentieth century, which
formed a solid scientific foundation for clinical investigation (Harvey 1981); the emergence
of the modern medical school and its affiliated teaching hospital as a distinct research in-
stitution (Rothstein 1987); and the birth of a new profession, that of the full-time clinical
professor (Fye 1991). Clinical trials are thus conducted by physicians, known as clinical
investigators, who are located across different research sites.

   Clinical investigators operate out of a variety of different research sites, including aca-
demic medical centers, community hospitals, private practices, and for-profit clinical testing
organizations. The proportion of academic clinical sites decreased steadily over time, but
still represented over 70% of U.S. sites as late as 1991. That number shrank to a mere 35%
by 2001, according to industry sources (Hovde and Seskin 1997; Zisson 2001). There are
two broad classes of explanations for this shift that focus, respectively, on the demand- and
supply-sides of the market for clinical investigators.


2.2    Demand-side considerations

The academic and non-academic sectors differ in the relative emphasis put on knowledge
production (versus data production) by clinical investigators. In addition to conducting
industry-supported clinical trials, academic investigators also carry out "basic" clinical in-
vestigations, which are rewarded by publications, NIH grants, academic prestige, and pro-
motion. In contrast, at commercial sites, investigators' allocation of effort is not drawn
away from data production by competing incentives. This diversity provides pharmaceutical
firms with the ability to match the composition of the investigator team with the needs
of the clinical study. For example, when the study examines a more established scientific
hypothesis, the objectives of investigators in the commercial sector will be more aligned with



                                               6
sponsors' interests. By contrast, when hypothesis generation is more valuable or when the
product team "is ignorant about what it is ignorant about," then encouraging investigators
to follow their scientific intuition might become comparatively more valuable. According
to this view, the mix of academic and non-academic investigators results from a process by
which the pharmaceutical companies match investigators of various type and projects with
heterogeneous characteristics (Azoulay 2004).

   If changing preferences of pharmaceutical companies or changing FDA requirements
have increased the number of data-intensive projects, relative to the number of knowledge-
intensive projects, then this shift could account for part of the observed growth. A number
of reports have emphasized the increasing prevalence of "me-too" drugs in corporate R&D
strategies (e.g., NIHCM 2002). But these analyses only pertain to the characteristics of
approved drugs, and as we will document later, we do not find evidence of a shift towards
incremental projects in our data, which includes trials pertaining to drugs that eventually
secure FDA approval as well as drugs whose development is still in progress or has been
discontinued. Moreover, the ranks of non-academic clinical investigators have swelled with
such celerity that it seems unlikely that demand-side phenomena could have completely de-
termined the emergence of for-profit experimental medicine. In particular, explanations that
stress variation in project characteristics beg the question of why pharmaceutical firms were
not purposefully matching physicians with projects in the earlier period. Geographic varia-
tion in the extent of entry of for-profit investigators suggest that supply-side forces were also
at work.


2.3    Supply-side considerations

We view RCTs as an innovation that any doctor is "at risk" of adopting at any particular
point of time. The overall stock of potential investigators has increased over time, as medical
school curricula increasingly came to emphasize that RCTs provide the standard upon which
sound clinical decision-making should be based. Moreover, beginning in the late 1970s, the
FDA began a decade long effort to codify what had heretofore been informal agency practice.



                                               7
Culminating in the 1987 "IND/NDA rewrite," the new regulations added or clarified require-
ments for monitoring, record keeping, adverse event reporting and designing Phase II and III
studies in return for greater flexibility during safety testing (Sobel 1988). In general terms,
the regulations caused the agency to become more deeply involved in process-related issues
than had previously been the case. This massive codification effort may have made it easier
for non-academic physicians to learn how to conduct clinical trials, exogenously lowering the
costs of adoption and enabling them to incorporate clinical research into their traditional
practices. A more satisfying explanation for the rise of for-profit experimental medicine,
therefore, starts from the observation that the supply of non-academic investigators was
likely constrained until the late 1980s. The cumulative effect of new cohorts of physicians
familiar with RCTs and the procedural templates provided by the IND/NDA Rewrite re-
laxed this supply constraint and allowed pharmaceutical firms to draw from a wider pool
that included non-academic investigators. This explanation, while supported by anecdo-
tal evidence, does not lend itself to empirical testing since it is essentially a slow-moving
population-level trend.

        We focus instead on a different supply-side explanation: the rise of managed care health
insurance. In recent decades, managed care has created downward pressures on physicians'
personal incomes and reduced the utility they gain from practicing traditional patient care.
Affected physicians, in turn, have been more likely to substitute "experimental patients" for
their traditional patients.


3         Managed Care and Its Effects on Physician Behavior

Managed care refers interchangeably to a set of health insurance products and to an approach
to medical decision-making that gained wide prevalence in the U.S. healthcare environment
during the 1980s and 1990s.2 It is a general term used to describe a variety of mechanisms
through which health insurers seek both to control costs and to improve or maintain the
quality of medical care for their policyholders. The distinguishing features of these mech-
    2
        See Glied (2000) for a review.



                                                 8
anisms are usually some combination of (i) selective contracting, whereby payers negotiate
prices (often unilaterally) in the form of a "fee schedule" and selectively contract with a
limited number of healthcare providers in a given locale; (ii) monetary and non-monetary
incentives that steer health consumers towards the selected providers; (iii) utilization reviews
and controls that restrict providers' medical decisions, especially for more expensive medical
procedures; and (iv) the assumption of some financial risk by physicians in the form of cap-
itation contracts. In combination, these features have generally reduced the cost of health
insurance compared to indemnity policies, in which physicians are paid on a cost-plus basis.

   It was only in the 1980s that the number of patients enrolled in managed care plans
increased above nominal levels, due in part to the passage of the HMO Act of 1973, which
required certain types of employers to make HMOs available as an employee benefit. The
growing prevalence of managed care gave health care providers little choice but to contract
with managed care insurers or risk losing patient volume: By 1995, over 80% of physicians
had contracts with at least one managed care organization (Emmons and Simon 1995). The
vast majority of patients are now enrolled in some type of plan that falls under the umbrella
of managed care (Jensen, Morrisey, Gaffney, and Liston 1997). Even today, however, man-
aged care penetration varies widely across geographic areas, with concentration highest in
California (Glied 2000).

   A large number of studies (e.g., McLaughlin 1987; Miller and Luft 1997) have examined
the impact of managed care on health outcomes and expenditures, although evidence re-
garding the ability of managed care to alter the practice of medicine has been more limited.
Baker (1997; 1999) found that managed care lowers medical expenditures not only by con-
trolling costs for managed care patients but also by decreasing the revenues physicians receive
for services rendered to patients not subject to managed care and its incentive-based con-
tracts--i.e., the indemnity and fee-for-service (FFS) patient populations. Several spillovers
mechanisms between managed care and non-managed care patients also make it empirically
more difficult to isolate their effects. First, managed care's presence in a geographic area
creates a more competitive environment overall for the prevailing market prices charged for
medical procedures. Second, managed care reduces the incentive (and available revenue) for


                                               9
physicians to invest in higher-cost technologies, affecting the technology's availability and
the subsequent likelihood that physicians will utilize it with their non-managed care patients.
Finally, managed care spreads conservative behaviors and practice patterns, such that an
indemnity or FFS patient becomes less likely to receive a more expensive treatment than an
equivalent managed care patient, lest the physician be perceived as making a decision on the
basis of reimbursement level rather than on the basis of medical need. This general argument
also finds support in the research conducted by Glied and Zivin (2002), who show that drug
prescribing patterns converge as a greater proportion of a physician's practice consists of
managed care patients.

       Despite numerous efforts to document an effect of managed care on the income of physi-
cians, such studies have been far from conclusive (Clark and Thurston 2000; Hadley and
Mitchell 1999; Luft 1999; Simon, Dranove, and White 1998). In part, this reflects the lack
of a credibly exogenous source of variation to identify the effect of managed care penetra-
tion: Managed care organizations may be more likely to pursue market entry in areas in
which medical expenditures (of which physician income is a substantial component) are al-
ready high or expected to increase. But the lack of a consistent effect on physician income
could also reflect demand inducement or "target income" behavior on the part of physicians,
whereby physicians respond to fee cuts by increasing the volume of services provided. In
recent years, evidence has accumulated that this type of behavior indeed explains the lim-
ited success of large health care payers such as Medicare in lowering expenditures through
reductions in scheduled fees (Gruber, Kim, and Mayzlin 1999; Gruber and Owings 1996;
Leape 1989; Yip 1998).3

       This body of research builds on a general model of physician behavior proposed by
McGuire and Pauly (1991), who demonstrate that target income behavior often alleged to
characterize physicians' decisions is not necessary for demand inducement to take place.
Moderately strong income effects are sufficient, and the strength of income effects is the
   3
    Some policymakers have consequently incorporated demand inducement assumptions into fee schedule
adjustments, relying on the expectation that physicians will offset a portion of losses from fee reductions by
increasing the volume of services provided (Physician Payment Review Commission 1992; Reinhardt 1996;
1999).



                                                     10
key determinant of a physician's volume response to a reduction in fees. They also empha-
size that, in the presence of multiple payers, multiple avenues exist for recouping income
shortfalls. The extent to which physicians will substitute non-managed care patients for
managed care ones depends on the relative ease of inducement, the sensitivity of demand to
inducement, and the relative payment for services in each market.

      McGuire and Pauly (1991) motivated their model by considering the introduction of the
Medicare Fee Schedule in 1992, and its impact on the volume of procedures performed on
behalf of non-Medicare patients. We argue that this general model can apply to the case
where the payers of interest are not multiple insurers but instead, more broadly, multiple
types of revenue sources: namely, managed care insurers and pharmaceutical firms, who pay
for the medical services provided to patients enrolled in the clinical trials they sponsor. In-
deed, recent survey evidence suggests that "physician entrepreneurialism"--of which clinical
trials is a prime example--is associated with high managed care penetration and other finan-
cial pressures (Pham, Devers, May, and Berenson 2004).4 This substitution between patient
types (rather than between payer types within the traditional patient category) occurs as a
response to the gap in the relative payments between payer types.

      What remains to be explained is why patterns of substitution between patient care and
clinical research might differ between the academic and non-academic sectors. The main
distinction between academic investigators and their colleagues in private practice lies in
the relative strength of the explicit output incentives they face. Pharmaceutical companies
routinely provide bonuses and other financial enticements to clinical investigators for meeting
or exceeding enrollment targets. However, academic institutions prohibit such financial
incentives because of the potential conflict of interest they create between the patient and
the physician. Even in the absence of such restrictions, academic physicians are not full
residual claimants on the additional revenues generated by clinical trials; that said, such
  4
    We do not mean to suggest that clinical trials are the only way for physicians to generate revenues
beyond the treatment of ordinary ailments and injuries. Freudenheim (1996), for example, speculates that
the increased marketing of and consequent demand for expensive elective cosmetic procedures is a direct
consequence of managed care as well.




                                                  11
funds do provide a valued source of financial support that can supplement more traditional
sources of research funding.

   In addition, participating in industry-sponsored clinical trials has been a source of stigma
among clinical faculty in academic medical centers. Whereas basic research makes unique
demands on the creative and scientific insights of the investigator, clinical trials--especially
data-intensive ones--imply a substantial relinquishing of intellectual autonomy to the spon-
sor, since the investigator must adhere to an agreed-upon research protocol likely to have
been designed by someone else. As a result, clinical trials do not produce rewards commen-
surate with those brought by other academic activities, such as publications and NIH grants,
let alone intellectual satisfaction. Thus, we argue, not only will more clinical trial activity
take place in high managed care penetration areas, but this effect should also be especially
pronounced among non-academic investigators.

   Besides demand-inducement in a multiple-payer context, an association between man-
aged care penetration and clinical trial activity across geographic areas could be observed
for technological reasons, independent of substitution incentives. As managed care insurers
have increasingly leveraged their market power against a diffuse body of physicians, those
physicians, in turn, have tended to aggregate into larger group practices (Casalino et al.
2003; Casalino, Pham, and Bazzoli 2004). These large practices, having gained negotiat-
ing leverage, have also taken advantage of scale economies to invest in technologies such as
electronic recording of patient information and diagnostic imaging equipment. These sunk
assets are relevant to our argument, since they could be deployed to support the infras-
tructure needed to be productive in the realm of clinical research. The relevance of the
scale rationale for entry can be examined empirically, since it implies that, among physicians
in private practice, those practicing in large groups should drive the observed association
between managed care and clinical trials volume.




                                              12
4         Data and Methodological Considerations

4.1        Data sources and sample construction

We make use of several data sources to conduct our analysis. The first is a proprietary data
set of clinical investigator contracts made available by Fast Track Systems, Inc. Since the
late 1980s, Fast Track has collected detailed information on clinical research from clinical
trial sponsors. It then analyzes and aggregates this information for subscribing organizations
to help them plan budgets and negotiate clinical research contracts with investigative sites.
While no company can be identified by name due to confidentiality agreements, the data
collected represent a substantial share of the global clinical research industry.5 The data set
used for the present analysis includes 7,735 clinical trials conducted by 69 firms involving
1,912 clinical compounds and 85,919 research sites for studies conducted between 1991 and
2003. For each research site, the data include the amount of clinical research dollars spent
at the site as well as the name and location of the site and characteristics of the clinical pro-
tocol. Data about compounds under development was collected from Pharmaprojects, which
contained independent ratings about the relative novelty of compounds under development
and the FDA Orange Book, which is a compilation of compounds that have been approved
for marketing.

        For purposes of the present study, we coded each site for its status as academic or for-
profit. Site names were compared with names listed in the American Hospital Association's
(AHA) annual survey of acute-care hospitals, as well as to a list of academic medical centers.
Sites which were listed in the AHA database as teaching hospitals were coded as academic;
all other clinical research sites (save for veterans' hospitals unaffiliated with medical schools
and a few non-profit, non-academic hospitals) were coded as non-academic. These included
entities such as for-profit hospitals, private practices, and for-profit organizations set up for
the express purpose of conducting trials.
    5
    The sample comprises data from all of the Top 10 firms, 26 out of the Top 30 firms, and 33 out of the
Top 50 firms, where the rankings reflect R&D spending listed in annual reports to shareholders in the year
2000. Companies in the sample spent a total of $41,434 millions in R&D that year. This value corresponds
to 82% of the aggregate amount reported by the Top 45 heaviest spenders.



                                                   13
       We then aggregated the investigator contract information up to two distinct levels of
analysis: the clinical trial (i.e., project) level and the geographic unit level. This procedure
yielded two samples that we discuss in turn.


4.1.1      Project-level sample

In addition to our dependent variable (the proportion of academic sites in a clinical trial), the
data include a number of project characteristics, such as the phase of the trial, the name of
the chemical compound being tested, the medical indication for which it is being examined,
the length of the trial in weeks, the total number of medical procedures required in the trial
protocol, and whether the trial takes place in an outpatient setting. Medical indications
were further grouped into fifteen therapeutic classes.

       Since we could only reliably ascertain the academic status for U.S.-based clinical sites,
the sample was limited to 8,163 trials involving solely U.S. sites; 428 (5.24%) observations
consisting of trials beginning in 2002 or beyond were dropped because they involved trials
that were likely to be incomplete, yielding a final data set with 7,735 unique clinical trials.


4.1.2      Geographic unit-level sample

Gross revenue and number of contracts for each clinical site was aggregated at the Health
Service Area/year-level to create a panel data set of academic and non-academic clinical re-
search volume, measured in number of contracts awarded. Originally, Health Service Areas
(HSAs) were defined by the National Center for Health Statistics as a group of contigu-
ous counties which are "relatively self-contained" with respect to their medical care. Their
construction provides a level of analysis in which patients generally reside in the same geo-
graphic unit as where their health services are rendered, and are conceptually analogous to
Metropolitan Statistical Areas.6
   6
     We also conducted all the analyses at the county-year level, with substantively similar results. HSAs
may be a more meaningful unit of analysis than counties, as they account for situations where individuals
living near county borders are inclined to cross those borders to receive medical care. On the other hand,
health insurance mandates and legal climates vary from state to state--necessitating the inclusion of state
fixed effects in our regression models--so inclusion of a state dummy variable yielded cleaner models for
county-level analyses since no counties cross state borders. Specifications in which HSAs were assigned state


                                                     14
    To assess the impact of managed care on clinical trial activity, we used available data on
the market penetration of Health Maintenance Organizations (HMOs), which are the most
prevalent form of managed care, although other names and forms also exist. Panel data on
HMO enrollment were generously shared by Laurence Baker and have been analyzed in a
variety of papers on the subject of managed care (e.g., Baker 1997, 1999, 2000a, 2000b). The
data set includes information on total HMO enrollment and market share for each county
in the United States, excluding Alaska.7 These data were collected by Baker using HMO
enrollment information found in the National Directory of HMOs, published by the Group
Health Association of America. Additional details on the collection of these data can be
found in Baker (1997, Appendix A).

    It is important to acknowledge that this measure is at best an imperfect proxy for man-
aged care activity (Baker 2000a). Unfortunately, when measuring the influence of managed
care, applied researchers must trade off breadth of coverage with substantive depth. While
cross-sectional surveys provide better measures on the specific cost-containment activities
in which insurance plans engage, we rely on the HMO enrollment proxy because it is the
only measure available consistently over a length of time matching that of the clinical trial
data. Because the HMO data set ends in 1999, the clinical trial level analysis stems from a
more restricted set of investigator contracts signed between 1991 and 1999 (vs. 2001 as an
end-date in the project-level sample).

    Control variables for the panel were collected from a variety of publicly available sources.
Total population and demographic variables such as age and ethnicity for each county-year
observation were collected from the U.S. Census Bureau. The number of physicians by
county, in private practice or in academia, was drawn from the Area Resource File. Average
income by county originates from the Bureau of Economic Analysis at the U.S. Department
fixed effects for both states (for example, a St. Louis HSA would include state fixed effects for both Missouri
and Illinois), as well as specifications in which data were aggregated to modified HSAs divided by state
borders (in which St. Louis would be subdivided into two separate "modified" HSAs) all yielded materially
similar results.
    7
      Cities in Virginia were combined with adjoining counties. Parishes in the state of Louisiana and the
cities of Baltimore and St. Louis are all treated as counties. Every effort was made to ensure that the panel
structure remained constant in light of a very small number of changes in county borders between 1991 and
1999; market share and population information was generally allocated to 1991 geographic boundaries.



                                                      15
of Commerce. We also implicitly control for density in an area by adding a control for the log
of the land mass area is square miles. This is important in so far as the costs of monitoring
clinical investigators should imply that pharmaceutical firms have an incentive to locate sites
near airports, in areas with high population density. County demographic information was
aggregated to the HSA level for those analyses.

   The full data set contained 67,401 observations from 1991 to 1999, but only a subset of
this data was used for the supply-side analysis. Geographic information was missing from
3,318 observations, and 82 observations from Alaska and Puerto Rico were excluded, as there
was no managed care data available for these locations. The remaining 64,001 contracts was
further reduced by 5,208 to exclude non-profit, non-academic hospitals. Of the remaining
58,793 sites, approximately half (29,538) were coded as for-profit entities. This population
was examined more closely to analyze whether the relation between managed care and clinical
trial activity differed among large and small medical practices. Excluded for this ancillary
analysis were 2,873 observations that were hospitals, 12,830 observations that were free-
standing clinical trial providers, and 425 observations corresponding to staff-model HMOs.
5,407 observations consisted of independent physicians presumed not to be part of a group
practice. The remaining 8,005 observations consisted of 1,940 unique entities. Names on
this list were searched on the internet to find basic practice details such as specialty and to
determine the number of physicians practicing associated with the entity. The sample was
divided into one consisting solely of observations associated with 1,423 large practices (ten
physicians or more) versus another consisting solely of 6,582 small practices and 5,407 solo
practitioners (less than ten physicians).

   Finally, we collected additional data to examine the endogeneity between clinical trial
activity and HMO enrollment. Two types of data were collected to support this analysis
(detailed in the appendices): First, we collected information regarding the size distribution
of firms from the U.S. Census Bureau's annual County Business Patterns file. Second, we
collected information about state laws regulating the small-group insurance market that
were passed in a number of states in the 1990s. Data regarding these legislative events were
collected by Simon (2000); her efforts and those of others are listed in the footnotes and


                                              16
appendices of a few published and working papers (Buchmueller and Liu 2005; Hing and
Jensen 1999; Simon 2005).8


4.1.3      Procedure-level sample

The procedure-level dataset consists of pricing data for 1,227 medical procedures conducted
at 140 clinical research sites from 1997 to 2004, which was supplied to us by RapidTrials,
Inc. Founded in 1996, RapidTrials developed a database consisting of price information
for clinical protocols provided by (mostly non-academic) research sites. The data contain
detailed price information for a sample of medical procedures performed at each research site,
as well as for their counterpart in the Medicare fee schedule. Whereas the Fast Track data is
collected from clinical trial sponsors (i.e., pharmaceutical companies), the RapidTrials data
is collected primarily from research sites. This data source essentially trades off breadth of
detail across the pharmaceutical industry for depth of detail within research sites. These data
are typically used to help research sites and trial sponsors budget their estimated costs for
novel research protocols whose components consist of procedures that have been completed
at other research sites for other protocols. The data used for the present analysis consists of
1,227 observations performed at 140 research sites.

       We used the data to compare the prices prevailing for the same medical procedures
paid by Medicare and clinical trial sponsors. Doing so enables us to ascertain the extent
to which reimbursements for clinical research incorporate rents, since managed care and
Medicare payment levels track themselves fairly closely, according to industry observers.
With one exception, all variables for the procedure-level analysis are comprised of data from
the RapidTrials database. The lone variable from outside the data set consisted of a dummy
variable for whether the research site is located in an area where HMO penetration exceeds
30%.9 Independent variables of interest included indicator variables for a variety of site
types, including dedicated clinical research center, private medical practice, or other type
   8
     Importantly, Hing and Jensen (1999) also identify state laws affecting small group health insurance which
were already in place before 1990, when our panel begins.
   9
     This corresponds to the 75th percentile of the county-level distribution of HMO penetration in 1999, the
last year for which we have data available.



                                                     17
of site. Additional control variables include whether the procedure requires a subject visit,
laboratory visit, sample collection, or health status assessment.


4.1.4   Qualitative evidence

Qualitative accounts stem from two rounds of semi-structured interviews involving about
seventy physicians and other health care professionals in 1999 and 2007. The 1999 wave
focused on about forty individuals based in Boston, Massachusetts while the 2007 wave in-
volved about thirty individuals located across the United States. These interviews involved a
cross-section of physicians with varying experiences in and exposure to the managed care and
drug development industries. Interview subjects were identified through snowball sampling.
Interviews were conducted primarily over the telephone in 2007 but in person in 1999. We
took extensive notes and generated transcripts from these interviews that we then analyzed
to determine major themes.

   Interview subjects had a wide range of employment backgrounds. Most had formerly or
at the time of the interview worked in academic medicine, where they were first exposed
to conducting clinical research. Physicians who had left academic medicine generally did so
to establish private practices or join existing ones. Some interviewees maintained private
practices as a primary means of employment, while others used them to supplement income
obtained in separate employment. Several worked full-time in the pharmaceutical industry,
either for a pharmaceutical firm, a contract research organization (CRO), or in a free-standing
clinical trials provider; several others were employed in a hospital setting. All major medical
specialties were represented.


4.2     Descriptive statistics

Descriptive statistics for the project-level sample are displayed on Table 1. As can be seen in
Figure 2, the distribution of the fraction of academic investigators (%AM C ) in a trial exhibits
two mass points at 0 and 1, but 53.30% of the observations fall within the open interval ]0; 1[.
Thirty percent of the trials pertain to drugs that had already been approved by the FDA



                                               18
(though not necessarily in the same therapeutic indication). In Figure 3, we take a cursory
look at trends regarding the composition of drug project portfolios over time. We examine
whether the proportion of trials pertaining to new treatments has markedly increased or
decreased over time. We measure novelty in three ways: whether the drug being tested
is a novel compound, whether it is already approved, and whether the trial is designed to
address an ailment already well-treated by existing drugs. The proportion of trials for novel
compounds has increased, but so has the number of trials pertaining to already-approved
drugs. The proportion of trials addressing well-treated diseases has remained flat during the
same period. In light of this evidence, we can already conclude that it is very unlikely that
an increase in the proportion of data-intensive projects could by itself account for the rise
of for-profit experimental medicine.

   Descriptive statistics for the project-level sample are displayed in Table 2. Figures 4A
and 4B display maps of U.S. counties, where each county is shaded in light or dark tones
to indicate the intensity of clinical research activity in the county. It is apparent from these
maps that a relatively small number of counties account for the bulk of the activity. To
reinforce this point, Figures 5 displays the county-level distribution of the number of clinical
trial contracts between 1991 and 2001, broken down by affiliation status. In this analysis,
as in the multivariate results below, we exclude any geographic unit in which there is no
clinical trial activity during the whole period. The distribution for both these variables is
particularly skewed for academic sites, because the number of counties in which a teaching
hospital or a medical school exists is a relatively small subset of the counties in which clinical
research is conducted. Finally, Figure 6 is a map documenting the growth of HMO enrollment
throughout the continental U.S. in the 1990s.

   Descriptive statistics for the variables in the procedure-level sample are displayed in
Table 3.




                                               19
4.3     Econometric considerations
4.3.1   Project-level sample

To ascertain whether pharmaceutical firms' reliance on academic investigators is influenced
by the importance of knowledge-production activities, relative to data-production activi-
ties, we model the determinants of the fraction of academic investigators in a clinical trial,
%AM C , using the fractional logit estimator (Papke and Wooldridge 1996). Briefly, given
a sequence of observations (yi , Xi ) : i = 1, 2, ·, N where 0  yi  1 for all i, this estimator
assumes that the conditional mean of y given the observables in X takes the form:

                                     E [yi |Xi ] = (Xi  )

where (.) is the logit c.d.f. This ensures that the predicted values of y lie in the interval
]0; 1[. Estimation proceeds by Quasi-Maximum Likelihood (QML). The resulting estimate
is consistent as long as the conditional mean is correctly specified. Standard errors are
clustered at the level of the chemical compound.


4.3.2   Geographic-unit level sample

We first examine the determinants of HMO enrollment across and within geographic areas.
To do so we regress the log of the number of HMO enrollees on HSA and state characteristics,
including variables that capture the friendliness of the legal environment towards managed
care insurance plans. Second, we look at the effect of HMO enrollment on various measures
of clinical trial activity. The skewed distribution of the dependent variables (the number
of clinical sites or the amount of clinical research expenditures in a geographic unit) makes
the use of traditional least squares regression techniques problematic. The distribution of
these variables exhibits a large mass point at 0 (see Figure 5). As a result, we apply Pois-
son models to these specifications, which we estimate by quasi-maximum likelihood (pooled
cross-sections) or by conditional quasi-maximum likelihood (within geography models). Be-
cause the Poisson model is in the linear exponential family, the coefficient estimates remain
consistent as long as the mean of the dependent variable is correctly specified (Gouri´
                                                                                      eroux


                                              20
et al. 1984). Further, "robust" standard errors are consistent even if the underlying data
generating process is not Poisson.10

       Of course, the structure of the health insurance industry and entry into the clinical re-
search industry could be jointly determined. Both HMOs and physicians prone to participate
in clinical trials might cluster in similar geographic areas because common, unobserved fac-
tors drive entry decisions in both industries. This endogeneity is of particular concern in
the cross-sectional dimension, where one might suspect that areas in which health care is
expensive in ways not accounted for by our data attract both sets of organizations. In order
to identify the causal effect of HMO enrollment on clinical trial activity, a credibly exogenous
source of variation in HMO enrollment is needed. In the appendix, we document our (unsuc-
cessful) effort to use variation in state-level regulation of health insurance for small firms to
create exogenous shifters of HMO enrollment. Statistically insignificant second stage results
in an IV framework should not necessarily lead us to not reject the null hypothesis. However,
we stress that our results show a strong association between for-profit clinical trial activity
and managed care penetration. Of course, the particular pattern of this association suggests
that a casual mechanism may be involved, but our conclusions must remain tempered in
light of these disappointing IV results.


5        Results

5.1       Qualitative findings

Several premises were nearly universally agreed-upon by our interview subjects: Managed
care has adversely affected physicians' incomes and their autonomy in medical decision-
making. Physicians accepted managed care as an unavoidable circumstance beyond their
control, and a "fact of life" associated with working in the medical care sector. In response
to the reduction in income brought on by managed care, physicians considered several alter-
natives, such as working longer hours and performing a greater volume of ancillary services.
  10
    In fact the PQML estimator can be used for any non-negative dependent variables, whether integer or
continuous (see Santos-Silva and Tenreyro 2006).



                                                  21
Central to our core argument, one commonly mentioned reaction to managed care was an
increased use of clinical research to replace lost incomes. However, many physicians who
conducted clinical trials indicated that they enjoyed the work itself, and that reduced in-
volvement with managed care was a fortuitous byproduct.

   The major changes brought on by managed care each contributed to physicians' incli-
nations to conduct clinical trials. At the industry level, as discussed earlier, these changes
consisted of selective contracting, financial incentives to use particular physicians, utilization
review, and capitation contracts. From the perspective of the physician, however, the growth
of managed care lowered their overall earnings, reduced their patient volume, and, through
utilization review, decreased their sense of professional autonomy.

   Physicians' most commonly mentioned reaction to the income pressure from managed
care was simply to try to see more patients. Common practices included extending office
hours and reducing the amount of time spent with each patient. When we asked whether
entering clinical trials was a common tactic for replacing lost income, an oncologist replied
that becoming a clinical investigator would only lead to "incremental change" in income,
because he perceived the infrastructure needed to do clinical research as a significant entry
barrier: "[Clinical trials are] not the most efficient way for a physician to increase one's
income. It would be far more effective to increase the number of patients your practice is
seeing." Explicit mention of demand inducement was rare, possibly because of its prob-
lematic ethical undertones. In a single instance, a nephrologist complained that managed
care had "forced" him to require patients to come to his office to have a nurse administer
a particular injection procedure because in-office administration was reimbursed by insurers
while patient self-administered injections left the physician unpaid.

   Physicians attempted to increase the number of patients when wages were cut in order
to maintain desired income levels. As a gastroenterologist told us:

      "I think that the prevailing practice among doctors is to try to maintain a certain level
      of income. When reimbursements go down, they try to see more patients. It's about
      how many patients you have to see to make the same amount of money."




                                                 22
   Aside from causing an overall decline in income, the selective contracting component of
managed care also contributed to the growth of clinical trials. Physicians who did not receive
or accept a managed care contract experienced reduced patient volume because patients'
financial incentives steered them toward physicians with managed care contracts. Without
sufficient patient volume, excluded physicians and practices sought out clinical trials not only
to generate income but also to utilize their existing specialized assets, such as office space,
equipment, and support staff. Network exclusion, and the accompanying reduced patient
volume, was temporary. Clinical trials became not only a means to generate income but also
a way to bide one's time. As one cardiologist told us:

      "We would all vie for contracts from the HMOs. We would get a contract for a bloc
      of hundreds or thousands of patients, and take care of them, and then we would lose
      our contract because the HMO contracted with another practice for less money. The
      patients were moved around like cattle ­ it was terrible for them, and that's a whole
      other story. But without those contracts, the medical practice is hurting financially.
      Without those contracts, people would do clinical trials to pay for the lights and because
      there's nothing else to do with your time. . . It became a way to stay afloat until you
      could get a contract from an HMO again."

   Conducting clinical trials was certainly not the only response to managed care's growth.
Some physicians simply resigned themselves to earning less while others generated income
by doing work previously outsourced to laboratories or by performing elective cosmetic pro-
cedures. Many physicians (particularly academic ones) emphasized that their own forays
into clinical trials were fortuitous rather than intentional:

      "I look at managed care today, and I am quite glad that I am on this side of the business
      and not with a private practice. They [i.e., private practioners] are in pretty bad shape.
      But I chose to enter the trials business not out of foresight or because I was chased by
      managed care but instead because I was interested in the research component."

   Several physicians expressed the opiniom that they had explored clinical trials as an
option and rejected it because they perceived the investment to be too substantial or cost
structure too unfavorable. A gastroenterologist told us:

      "[The reimbursement for clinical trials] is usually a reasonable payment, but it's a
      lot of time and a lot of work. . . I don't want to put my practice through the major
      change that's involved in getting into the trials business, [even though] I continue to be
      disappointed that we're not getting more revenues from managed care."


                                                 23
This sentiment was echoed by an oncologist working full time in the clinical trials industry,
who told us:

      "A physician can't really just stick a toe in the water in order to get a few extra bucks
      on the side. It just doesn't happen like that. Because, in order to do a drug study,
      you need a clinical coordinator, case report forms, you need to spend a lot of time with
      patients on informed consent, and the procedures themselves. All of that takes time
      and effort."


   Clinical investigators in private practice sometimes perceived involvement in clinical trials
as a source of spillovers on to the traditional part of their practice. One oncologist noted
that that clinical trials were a money-loser for his practice. He stated:

      "We have to rely on the fact that it is a service to our patients. . . These people are not
      going to an academic center for something truly experimental. [They come to us for]
      something that has some literature behind it to support the likelihood of its success."


Another specialist indicated that he believed the motivation for private physicians to partici-
pate in clinical trials comes from "the idea of being relevant, knowing the latest therapies and
drugs, and the idea of enhancing one's own reputation and the reputation of one's practice,
i.e., `So and so does drug studies, so he's on the cutting edge.' "

   An important question to consider is that of the identities of physicians involved in clin-
ical trials--whether they were current or former academic physicians shifting their research
operations into the private sector, or physicians in private practice supplementing traditional
care with a new revenue source. We encountered both types of investigators in our qualita-
tive research. The emergence of for-profit experimental medicine has not coincided with a
net decrease in the volume of academic clinical research, as can be seen in Figure 1. Many
of the interviewed private physicians described their original exposure to clinical trials as
coming from their training in an academic setting. However, the growth of managed care
may have been the source of some degree of reallocation of physicians from academia to the
private sector. As one former academic psychiatrist told us:

      "[There are people like me] who have been full time academics in the past, but because
      of a dissatisfaction with the academic world, have left academia. They still have a
      love of research, and therefore decide to go to a full time research setting. . . Managed


                                                  24
      care has not just squeezed private practitioners, it has also squeezed university settings.
      Universities' patient populations are also insured by managed care to some degree, and
      the lower reimbursement levels have also inclined the institutions to look elsewhere
      for income. . . Clinical funding for research at universities has decreased in the last few
      years. There are quite simply, fewer opportunities for academic research. So this
      decline in clinical funding has caused physicians who are interested in research for
      research's sake to get involved outside of the academic context by getting their names
      into clinical trials."

   Overall, the prevailing sentiment was one of resignation toward managed care and, aside
from exiting the profession, a belief that clinical trials were one means for physicians to
shelter themselves from managed care's impact. As a psychiatrist who conducted trials on
a full-time basis told us:

      "I very frequently get inquiries from other psychiatrists about how to get in the business.
      They see it as very lucrative, they're tired of fending off managed care, and they think
      it represents a big business opportunity."

   For academic physicians, industry-sponsored clinical trials implied an additional layer of
incentive conflicts. The degree of potential participation varied from serving as one inves-
tigator enrolling patients for a study among many, to writing the clinical protocol for the
study. An oncologist noted:

      "How does one become the senior author on a large clinical trial? I participate in
      [some] trials [that] do not contribute to my academic advancement one single bit. . . If
      I am a good foot soldier, I will eventually be considered by the powers making these
      new drugs, so that when the next project comes along, I may be a co-writer or I will
      be given a Phase II. . . My expertise lies [in] clinical trial design. How to turn that into
      academic advancement is still a mystery to me."

   Several academic physicians we interviewed were keenly aware of the differences in the
motivation of academic and non-academic physicians in industry-sponsored studies. As one
of our interviewees volunteered, "[In academia], the currency is authorship. . . Currency to
someone who is running a factory is just going to be profit." However, academic medical
centers were not immune to the same financial pressures that beset private physicians, and
pragmatism dictated a growing acceptance of industry funding to finance other academic
missions. An academic internist remarked, "People are so desperate that they will take any-
thing. People have to do stuff with little scientific value to pay the rents and the electricity."


                                                  25
A neurologist described a prolific colleague as doing "twenty different studies simultaneously.
He could not survive with the five of them which are really interesting. As a result, he takes
on fifteen more which pay for the support staff." These examples all reflected a willingness
by some academic physicians to participate in clinical trials in any capacity.

   Academic medical centers engaged in a variety of activities to stem the exodus of industry-
funded clinical research away from their institutions. In the mid-1990s, academic institutions
had begun to establish offices for the purpose of attracting industry-funded clinical trials.
These offices streamlined processes and provided a common infrastructure for all studies
being run in the institution, but also advocated among academic clinicians to convince them
to participate in industry-sponsored studies. These efforts were far from completely effective.
A director of clinical trials for an academic hospital lamented:

     "We hear all the time: we are too slow and bureaucratic, we don't accrue as well as
     the other places, we are not interested in studies, when they can call [a proverbial] Dr.
     Smith and start enrolling patients with one phone call."


Several academic physicians noted how financial pressures had changed the desirability of
attracting industry studies to their institution. One noted, "There was an era where industry
money was considered second-class. . . There is now a greater willingness to cooperate with
industry." A pulmonologist noted:

     "The fact that one can have discretionary funds available by doing clinical trials, that
     allow to pay a salary here or there, is very, very useful to divisions. Industry is in part
     supporting the academic and clinical enterprise. Industry is coming to replace other
     sources of research support, in this day and age."


Stigma played a large role in muting the incentives to participate in industry-sponsored
studies. The same pulmonologist noted:

     "The problem is that industry will confine itself and sponsor clinical trials in areas
     where they think they will make some money. So there are going to be areas where just
     as much should be done but they are going to not be fostered by industry."


   Similar sentiments were echoed numerous times by different academic physicians, whose
views of industry studies ranged from indifferent to cynical, or even hostile. One stated "I


                                                 26
am actually wary of drug company money. It does not buy you much in your institution, and
does not necessarily produce very good science. This is kind of third rate funding as these
things go." Another observed:

      "There are people who do only NIH-funded research, and see industry-sponsored re-
      search as dirty. . . and then there are some that have become very prosperous by doing
      mainly industry research. By and large those people do not have the same academic
      prestige."


Fellow academics sometimes viewed investigators with ties to industry as being "tainted"
by a conflict of interest (Prasad 2020). This perspective became increasingly true in light of
several scandals involving human subjects protection (Baird, Downie, and Thompson 2002;
Stelfox, Chua, O'Rourke, and Detsky 1998).


5.2    Project-level evidence

We present the results of our analysis of the project-level sample. The credibility of this
analysis hinges on our ability to distinguish empirically between knowledge-intensive and
data-intensive projects. Fortunately, the data set contains a rich set of characteristics that
can plausibly proxy for the relative importance of knowledge-intensive activities. We begin
by measuring the innovativeness of a project in three distinct ways. FDA Approved indicates
whether the drug was approved for use at the beginning of the clinical trial, according to the
FDA Orange Book. As indicated by the descriptive statistics, nearly 30% of trials involved
compounds that had already been approved by the FDA to be marketed for a particular
indication. These additional trials can represent testing for new indications, testing for
whether specialized populations (e.g., children) can use the drug, or post-approval testing
required by the FDA to address potential safety issues.

   First-in-class corresponds to a novelty rating from Pharmaprojects, a database which
assesses, among other things, the extent to which a chemical compound is new to the scientific
community. For the present paper, we created a dummy variable coded as one if the drug
studied received the highest rating, indicating that it is the first of its kind. FDA Approved
is a dummy variable coded as one if the clinical trial pertains to a drug already approved in


                                               27
the U.S. (which might occur if the drug is being tested for new indications or examined on a
specialized population). Finally, Well-treated is a dummy coded as one if the drug is being
tested to treat a medical condition that is among the ten diseases with the largest number
of already approved treatments.11

       Further, we add a set of phase dummy variables to the specifications. Drug development
is a sequential process beginning with Phase I safety trials, continuing with Phase II "proof
of principle" trials, and ending with larger-scale, efficacy Phase III trials designed to validate
Phase II results in an environment as similar as possible to that of regular medical practice.
Phase IV studies are performed post-approval, often in an effort to ensure acceptance of the
new drug by prescribing physicians. Uncertainty regarding the compound's toxicity, side
effects, and other idiosyncrasies is resolved upon completion of each stage, so that one would
expect knowledge-production activities to assume decreasing prominence (relative to data-
production activities) as development unfolds. There is an important caveat for Phase I
trials, which correspond to projects whose degree of complexity vary widely, from the most
sophisticated (such as "first-in-man" pharmacokinetic and pharmacodynamic studies) to the
most routine and codified (such as bioavailability and bioequivalence studies which can take
place at any time along the path to regulatory submission). Unfortunately, the data at hand
makes it difficult to disentangle the "routine" from the "complex" Phase I studies. Phase I
oncology studies constitute an exception. Because of their harmful side-effects, nearly all
cancer drugs are first tested in patients--as opposed to healthy volunteers--so that one can
be fairly sure that these studies correspond to "first-in-man" experimentations. Our prior is
that the proportion of academic investigators decreases with project phase, with the highest
proportion in Phase I oncology trials, and the lowest in Phase IV trials. We also include
three other measures: the length of the trial in weeks, the total number of medical procedures
required in the trial protocol, and whether the trial takes place in an outpatient setting.

       Results from these analyses can be found in Table 4. The various specifications report
QML estimates of the fractional logit estimator, with robust standard errors clustered by
  11
     These are otitis media, insomnia, pneumonia, bronchitis, asthma, rheumatoid arthritis, pain, urinary
tract infections, skin and soft tissue infections, and hypertension. To select these diseases, we drew from a
list of ICD-9 codes and associated drugs provided to us by Frank Lichtenberg.


                                                     28
chemical compound. Models (1) through (3) each use a different metric to assess project
innovativeness. The three measures of innovativeness enter the model with the expected sign:
more innovative ot complex projects are associated with a higher proportion of academics
selected as investigators. The effect of these variables remains statistically significant in
column 4, in which all three measures are introduced simultaneously in the specification.

    The results pertaining to project phase are more mixed. The proportion of academics in
a trial decreases with project phase, with the notable exception of Phase IV projects, which
are associated with a higher proportion of academics than Phase III projects. Phase IV
trials are performed post-approval, often in an effort to ensure acceptance of the drug by
prescribing physicians. Academics might be better suited to this credentializing role than
are non-academic doctors with limited status and reputation.

    We also find that projects taking place outside of hospital settings, as well as trials that
involve a longer protocol, are associated with a lower proportion of academic doctors. The
number of medical procedures performed bears no apparent relationship with the use of
academic or non-academic investigators.

    The interpretation of the statistical estimates in column 4 is subject to caution, since
it does not account for the effect of unobserved firm practices related to both observable
study characteristics and the choice of investigators. For example, pharmaceutical firms
have been shown to exhibit heterogeneity in their "taste for science" in the setting of drug
discovery research (Cockburn et al. 2000). Column 5 alleviates this concern by adding to
the specification a full set of fixed firm effects. The results are qualitatively similar, although
the measure of innovativeness based on FDA approval loses statistical significance in this
more demanding specification.12

    Overall, the project-level evidence strongly suggests that the availability of investiga-
tors with academic and non-academic backgrounds provides pharmaceutical firms with the
opportunity to carefully match the composition of the investigator team with the type of
problems most likely to arise during the clinical study.
   12
      Indeed, one interviewee emphasized to us that this measure could be quite noisy. He described several
clinical trials he knew of as "cutting edge" that happened to involve new indications for approved compounds.


                                                     29
   Of course, this conclusion begs the question of why pharmaceutical firms did not engage
in such purposeful matching in earlier periods. In addition to demographic changes, we show
below that the diffusion of managed care insurance plans, by influencing physicians' incen-
tives, had the unintended consequence of encouraging a large proportion of non-academic
doctors to enter the clinical trials industry.


5.3     The effect of HMO penetration
5.3.1   Evidence from geographic variation

Table 5 presents results pertaining to the core hypothesis of the paper: that the growth of
managed care insurance in general, and of HMO enrollment in particular, has contributed
to the growth of the "for-profit" clinical trials industry. Conceptually analogous results were
found when aggregating to the county as a geographic unit of analysis or aggregating to the
Health Service Area (HSA; conceptually analogous to a metropolitan area).

   Columns (1) and (2) show that HMO enrollment is more strongly associated with non-
academic clinical research than with academic clinical research. At mean levels of the control
variables, increasing HMO enrollment from the 50th to the 75th percentile (approximately
from 30,500 enrollees to 103,000 enrollees) in a given population size (using the median value
of 285,000 people) increases the expected number of non-academic clinical trial contracts in
the HSA from 0.89 to 1.16, a 30.81% increase. The comparable magnitude for academic sites
is 7.63% but the corresponding estimate is not statistically significant. Note that these results
control for the size of the physician population in the HSA, both in and out of academia.
Therefore, it would be erroneous to ascribe the emergence of for-profit experimental medicine
merely to a bottleneck in the supply of academic physicians.

   The evidence thus suggests that managed care health insurance created incentives for
physicians to substitute "experimental patients" for HMO patients. However, this response
did not cut across the medical profession in a uniform fashion, but was concentrated among
the group of investigators facing fewer competing incentives: non-academic physicians. The
results in columns (1) and (2) controlled for state fixed effects, meaning that the source of


                                                 30
variation in HMO penetration we exploit comes from within states, but between HSAs or
counties. We have verified in unreported regressions that these results are also robust to the
inclusion of state-specific time trends. Columns (3) and (4) examine whether the results also
hold in the within dimension of the data, by estimating conditional Poisson Quasi-Maximum
Likelihood models. Unfortunately, there is not enough within-HSA variation in the data to
detect a statistically significant effect.

   As discussed earlier, there are two, not necessarily mutually exclusive stories, to ex-
plain the association between managed care penetration and clinical trial activity across
geographic areas. The first story is a purely neoclassical explanation, whereby managed care
has increased the returns to physicians to practice in large groups, increasing investment in
sunk assets such as IT and diagnostic equipment. The presence of these sunk assets lowers
the barriers to entry into clinical research, for they can be redeployed at relatively low cost
to support clinical trial operations. The second story, which we favor, is an incentive ex-
planation, whereby the wedge between payments for traditional and experimental care leads
physicians to substitute one type of patients for another.

   An implication of the first story is that the observed relation between managed care
and research activity should be stronger among large medical groups. Columns (5) and (6)
of Table 5 examine this possibility, but the results show that the opposite might be true.
Although the estimate of the effect is larger in magnitude for practices of 10 physicians or
more, only in the case of the small practices do we observed a statistically significant effect.
This pattern of correlations casts doubt on the scale rationale as the main driver of the effect
of managed care on research activity across geographic areas.


5.3.2   Evidence from procedure-level data

For the incentive story to hold true, it is necessary that reimbursements for clinical research
incorporate rents, relative to reimbursements for traditional care. We now present some
evidence that clearly point in this direction using procedure-level evidence. The RapidTrials




                                              31
data set enables us to compare the prevailing prices for identical procedures when paid for
by clinical trial sponsors or by Medicare.

   Several caveats are in order before delving into these data in more detail. First, contrary
to the Fast Track data presented earlier, there is no presumption here that these procedures
stem from a sample of trials that is representative of the underlying population. The data is
collected from clinical sites, with the explicit goal to allow sponsors to benchmark research
payments at the procedure level against industry norms. As a result, one would expect
smaller price variation for the medical procedures in this sample. Second, the data does
not compare the level of managed care payments with those of sponsor payments. Instead,
RapidTrials use the Medicare fee schedule as a benchmark. Obviously, this is a valid as-
sumption only in so far as managed care and Medicare levels of reimbursement track one
another closely. Third, it might be hazardous to interpret price variation between payers for
the same procedures as providing prima facie evidence of rents. Rather, this wedge could
correspond to additional costs that clinical investigators incur when treating experimental
patients, such as recording information on a case report form.

   With these caveats in mind, we turn to Figures 7 and 8. These figures document the
wedge between payments from Medicare and pharmaceutical sponsors in the cross-sectional
and longitudinal dimensions of the data, respectively. We find that pharmaceutical firms pay
almost three times as much as Medicare for the procedures in the sample on average, although
the difference varies enormously across procedures, as well as over time. In particular, there
is evidence of a narrowing of the payment gap in the more recent period.

   Table 6 presents OLS regression results to further investigate the determinants of the
payment gap. All models contain year effects. Column 1 consists of the base model, which
incorporates indicator variables for each type of procedure: treatment, radiology, subject
visit, laboratory visit, sample collection, or health-status assessment. Column (2) add inde-
pendent variables to account for the type of site in which the procedure data was collected:
dedicated research center, private practice, or "other." Column 3 adds an indicator variable
for whether the site is located in a county in which HMO penetration is higher than 30%



                                             32
(the 75th percentile of HMO penetration at the county level in 1999, the last year in which
data is available). Finally, Column 4 incorporates an interaction effect between site type and
the high-HMO penetration dummy. Contrary to our priors, we do find evidence that HMO
penetration correlates strongly with the clinical trial premium--one might expect that this
premium could be lower when physicians' face a tougher bargaining environment over the
price of medical care.

    It is worth noting that several of our interviewees expressed skepticism that a premium
existed at all. Two physician indicated that clinical trials were a money-loser for their
practices, and several other interviewees indicated that clinical trials were only a minor,
rather than a major, supplemental source of income for their medical practices. A CRO
executive told us in 1999 that

      "[Our competition comes] from private doctors who do not know their costs because
      studies are commingled with their practice. . . They are first-time, second-time inves-
      tigators. . . ready to take on studies that we would think generate losses. . . Then they
      realize they are losing money, or they get an FDA audit that does not go so well, and
      they drop out. The problem is that there is an infinite supply of these doctors."



6     Conclusion

Health policy researchers have long understood that institutional arrangements for the fi-
nancing and delivery of health care to consumers have important feedback effects on the
dynamics of technological change in medicine (Finkelstein 2007; Azoulay et al. 2020; Weis-
brod 1991). In this paper, we provide concrete evidence of such feedback from the perspective
of the physician, by highlighting how managed care health insurance has contributed to the
rise of the "for-profit" clinical trial industry. We show that geographic areas with high
HMO enrollment also see more "for-profit" clinical research activity, but do not see more
academic clinical research activity. Our results provide an example of complex feedback,
whereby changes in the structure of a downstream industry (medical care) affect the nature
of upstream R&D activities (in the pharmaceutical industry).




                                                 33
   Of course, the diffusion of managed care health insurance was not the only element of
the health care environment that was changing at the time of this study. The 1990s also
saw an increase in the cohorts of physicians trained in the age of evidence-based medicine.
These physicians might have been more prone to become producers (as opposed to merely
consumers) of clinical research data than their elder colleagues, who went to medical school
in a period during which randomized controlled trials did not occupy such a prominent place
in the curriculum. Moreover, these profit-minded, non-academic physicians might not have
been able to enter the clinical trials industry in the absence of regulatory events, such as the
IND/NDA rewrite of the 1980s. Because of the paucity of data covering the earlier period,
and also because the data at our disposal identifies individual sites (e.g., Massachusetts
General Hospital, Hill Top Research, etc.), but not individual physicians at these sites, we
can only speculate on the relative importance of these other contributing factors.




                                              34
                                            REFERENCES

Azoulay, P. 2004. Capturing knowledge within and across firm boundaries: Evidence from clinical
       development. American Economic Review, 94(5): 1591-1612.

Azoulay, P., Heggeness, M., & Kao, J. 2020. Medical progress and health care finance: Evidence from
       Academic Medical Centers. MIT, Working Paper.

Baird, P., Downie, J., & Thompson, J. 2002. Clinical trials and industry. Science, 297(5590): 2211-2211.

Baker, L. C. 1997. The effect of HMOs on fee-for-service health care expenditures: Evidence from
        Medicare. Journal of Health Economics, 16(4): 453-481.

Baker, L. C. 1999. Association of managed care market share and health expenditures for fee-for-service
        Medicare patients. Journal of the American Medical Association, 281(5): 432-437.

Baker, L. C. 2000a. Managed care and technology adoption in health care: evidence from magnetic
        resonance imaging, NBER working paper, Vol. #8020.

Baker, L. C. 2000b. What does HMO market share measure? Examining provider choice restrictions. In
        Garber, A. (Ed.), Frontiers in Health Policy Research, Vol. 3. Cambridge MA: MIT Press.

Besley, T. & Case, A. 2000. Unnatural experiments? Estimating the incidence of endogenous policies.
        Economic Journal, 110(467): F672-F694.

Buchmueller, T. C. & Liu, S. 2005. Health Insurance Reform and HMO Penetration in the Small Group
      Market, NBER Working Paper #11446.

Casalino, L. P., Devers, K. J., Lake, T. K., Reed, M., & Stoddard, J. J. 2003. Benefits of and barriers to
        large medical group practice in the United States. Archives of Internal Medicine, 163: 1958-1964.

Casalino, L. P., Pham, H., & Bazzoli, G. J. 2004. The growth of single specialty medical groups. Health
        Affairs, 23(2): 82-90.

Clark, R. & Thurston, N. K. 2000. The future of orthopaedics in the United States: An analysis of the
        effects of managed care in the face of an excess supply of orthopaedic surgeons. Arthroscopy,
        16(2): 116-120.

Cockburn, I., Henderson, R., & Stern, S. 2000, Untangling the Origins of Competitive Advantage.
       Strategic Management Journal, 21(10-11): 1123-1145.

DiMasi, J. A. 1995. Success rates for new drugs entering clinical testing in the United States. Clinical
        Pharmacology & Therapeutics, 58(1): 1-14.

DiMasi, J. A., Seibring, M. A., & Lasagna, L. 1994. New drug development in the United States from
        1963 to 1992. Clinical Pharmacology & Therapeutics, 55(6): 609-622.

Dranove, D., Simon, C. J., & White, W. D. 1998. Determinants of managed care penetration. Journal of
       Health Economics, 17: 729-745.




                                                     35
Emmons, D. W. & Simon, C. J. 1995. Managed care: Participation, revenues, and risk. In Gonzalez, M. L.
     (Ed.), Socioeconomic Characteristics of Medical Practice, Vol. 1995: 3-10. Chicago: American
     Medical Association, Center for Health Policy Research.

Finkelstein, A. 2007. The aggregate effects of health insurance: Evidence from the introduction of
        Medicare. Quarterly Journal of Economics, 122(1): 1-37.

Flynn, P., Wade, M., & Holahan, J. 1997. State health reform: Effects on labor markets and economic
        activity. Journal of Policy Analysis and Management, 16(2): 219-236.

Freudenheim, M. 1996. As insurers cut fees, doctors shift to elective procedures. New York Times, August
       24. New York.

Fye, W. B. 1991. The origin of the full-time faculty system: Implications for clinical research. Journal of
       the American Medical Association, 265(12): 1555-1562.

Glied, S. 2000. Managed Care. In Culyer, A. J. & Newhouse, J. P. (Eds.), Handbook of Health Economics,
        Vol. 1A: 707-753. Amsterdam: Elsevier.

Glied, S. & Zivin, J. G. 2002. How do doctors behave when some (but not all) of their patients are in
        managed care? Journal of Health Economics, 21(2): 337-353.

Gouriéroux, C., Montfort, A., & Trognon, A. 1984. Pseudo maximum likelihood methods: Applications to
        Poisson models. Econometrica, 52(3): 701-720.

Gruber, J., Kim, J., & Mayzlin, D. 1999. Physician fees and procedure intensity: the case of cesarean
        delivery. Journal of Health Economics, 18(4): 473-490.

Gruber, J. & Owings, M. 1996. Physician financial incentives and cesarean section delivery. RAND
        Journal of Economics, 27(1): 99-123.

Hadley, J. & Mitchell, J. M. 1999. HMO penetration and physicians' earnings. Medical Care, 37(11):
        1116-1127.

Harvey, A. M. 1981. Science at the Bedside: Clinical Research in American Medicine 1905-1945.
        Baltimore: Johns Hopkins University Press.

Hausman, J., Hall, B. H., & Griliches, Z. 1984. Econometric models for count data with an application to
      the patents-R&D relationship. Econometrica, 52(4): 909-938.

Hing, E. & Jensen, G. A. 1999. Health Insurance Portability and Accountability Act of 1996: Lessons
        from the states. Medical Care, 37(7): 692-705.

Hovde, M. & Seskin, R. 1997. Selecting U.S. clinical investigators. Applied Clinical Trials, 6(2): 34-42.

Jensen, G. A. & Morrisey, M. A. 1999. Small group reform and insurance provision by small firms, 1989-
        1995. Inquiry, 36(2): 176-187.

Jensen, G. A., Morrisey, M. A., Gaffney, S., & Liston, D. K. 1997. The new dominance of managed care:
        Insurance trends in the 1990s. Health Affairs, 16(1): 125-136.

Kaitin, K. I. & Healy, E. M. 2000. The new drug approvals of 1996, 1997, and 1998: Drug development
        trends in the user fee era. Drug Information Journal, 34(1): 1-14.


                                                     36
Kaitin, K. I. & Manocchia, M. 1997. The new drug approvals of 1993, 1994, and 1995: Trends in drug
        development. American Journal of Therapeutics, 4(1): 46-54.

Leape, L. L. 1989. Unnecessary surgery. Health Services Research, 24(3): 351-407.

Luft, H. S. 1999. Why are physicians so upset about managed care? Journal of Health Politics, Policy and
        Law, 24(5): 957-966.

McGuire, T. G. & Pauly, M. V. 1991. Physician response to fee changes with multiple payers. Journal of
       Health Economics, 10(4): 385-410.

McLaughlin, C. G. 1987. HMO growth and hospital expenses and use: a simultaneous equation approach.
      Health Services Research, 22(2): 183-205.

McLaughlin, C. G. 1988. Market responses to HMOs: Price or competition or rivalry? Inquiry, 25(2): 207-
      218.

Miller, R. H. & Luft, H. S. 1997. Does managed care lead to better or worse quality of care? A survey of
         recent studies shows mixed results on managed care plan performance. Health Affairs, 16(5): 7-25.

Mullahy, J. 1997. Instrumental-variable estimation of count data models: Applications to models of
       cigarette smoking behavior. The Review of Economics and Statistics, 79(4): 586-593.

National Institute for Health Care Management. 2002. Changing Patterns of Pharmaceutical Innovation.
       Washington, DC.

Oi, W. Y. & Idson, T. L. 1999. Firm size and wages. In Ashenfelter, O. & Card, D. (Eds.), Handbook of
       Labor Economics, Vol. 3B: 2165-2214. Amsterdam: North-Holland.

Osberg, L., Wolf, E. N., & Baumol, W. J. 1989. The Information Economy: The Implications of
        Unbalanced Growth. Halifax, Nova Scotia: The Institute for Research on Public Policy.

Papke, L. E. & Wooldridge, J. M. 1996. Econometric methods for fractional responses with an application
       to 401(k) plan participation rates. Journal of Applied Econometrics, 11(6): 619-632.

Peltzman, S. 1973. An evaluation of consumer protection legislation: The 1962 drug amendments. Journal
       of Political Economy, 81(5): 1049-1091.

Pham, H. H., Devers, K. J., May, J. H., & Berenson, R. 2004. Financial pressures spur physician
       entrepreneurialism. Health Affairs, 23(2): 70-81.

Physician Payment Review Commission. 1992. Annual Report to Congress.

Prasad, Vinayak K. 2020. How Bad Policy and Bad Evidence Harm People with Cancer. Baltimore,
     MD: Johns Hopkins University Press.

Quirk, P. J. 1980. Food and Drug Administration. In Wilson, J. Q. (Ed.), The Politics of Regulation: 191-
        235. New York: Basic Books.

Reinhardt, U. E. 1996. Is the target income hypothesis an economic heresy? Comment. Medical Care
       Research and Review, 53(3): 274-287.




                                                   37
Reinhardt, U. E. 1999. The economist's model of physician behavior. Journal of the American Medical
       Association, 281(5): 462-465.

Romer, P. 1990. Endogenous technological change. Journal of Political Economy, 98: S71­S102.

Rothstein, W. G. 1987. American Medical Schools and the Practice of Medicine: A History. New York:
        Oxford University Press.

Santos-Silva, J. M. C. & Tenreyro, S. 2006. The log of gravity. The Review of Economics and Statistics,
        88(4): 641-658.

Simon, C. J., Dranove, D., & White, W. D. 1998. The effect of managed care on the incomes of primary
       care and specialty physicians. Health Services Research, 33(3): 549-569.

Simon, K. I. 2000. Legislative summaries of state small-group health insurance reform 1990-1999,
       Unpublished Manuscript. University of Maryland.

Simon, K. I. 2005. Adverse selection in health insurance markets: Evidence from state small-group health
       insurance reforms. Journal of Public Economics, 89: 1865-1877.

Sobel, S. 1988. Policy considerations of the IND rewrite. Food and Drug Law Journal, 43(1): 185-192.

Stelfox, H. T., Chua, G., O'Rourke, K., & Detsky, A. S. 1998. Conflict of interest in the debate over
         calcium-channel antagonists. The New England Journal of Medicine, 338(2): 101-106.

Swann, J. P. 1988. Academic Scientists and the Pharmaceutical Industry: Cooperative Research in
       Twentieth Century America. Baltimore: Johns Hopkins University Press.

Thomas, L. G. 1990. Regulation and firm size: FDA impacts on innovation. RAND Journal of Economics,
      21(4): 497-517.

Weisbrod, B. A. 1991. The health care quadrilemma: An essay on technological change, insurance, quality
       of care, and cost containment. Journal of Economic Literature, 29(2): 523-552.

Windmeijer, F. 2008. GMM for panel count data models. In Mátyás, L. & Sevestre, P. (Eds.), The
      Econometrics of Panel Data: Fundamentals and Recent Developments in Theory and Practice.
      New York: Springer.

Yip, W. C. 1998. Physician response to Medicare fee reductions: Changes in the volume of coronary artery
       bypass graft (CABG) surgeries in the Medicare and private sectors. Journal of Health Economics,
       17(6): 675-699.

Zisson, S. 2001. Modest gains in SMO usage, Center Watch, Vol. 8: 1, 5-9.




                                                    38
Table 1. Descriptive statistics, project-level data.
                                   No. Obs    Mean     Std. Dev    Min       Max
 Percent AMC                        7,735     0.420      0.377      0         1
 FDA approved                       7,735     0.292      0.455      0         1
 First in class                     3,216     0.692      0.462      0         1
 Well-treated disease               7,735     0.127      0.333      0         1
 Phase 1 (oncology)                 7,735     0.041      0.197      0         1
 Phase 1 (other)                    7,735     0.312      0.463      0         1
 Phase 2                            7,735     0.220      0.415      0         1
 Phase 3                            7,735     0.358      0.479      0         1
 Phase 4                            7,735     0.069      0.254      0         1
 Nb. of procedures                  7,735    77.602    66.358       1        909
 Outpatient                         7,735     0.615      0.487      0         1
 Trial length (wks)                 7,735    20.586     33.579     0.14      520
Source: Fast Track Systems, Inc.



Table 2. Descriptive statistics, HSA-level data.
                                   No. Obs    Mean      Std. Dev    Min       Max
 Academic sites                     3,789      7.720      20.903     0        177
 For profit sites                   3,789      7.952      18.813     0        250
 HMO enrollees (×1,000)             3,789    124.704     346.066     0       7,008
 Population (×1,000)                3,789    560.721     914.233    21.2    12,091
 Avg. income (×1,000)               3,789     21.050       5.551   7.972     69.633
 Pop. over 65 (×1,000)              3,789     70.362     107.659    2.9     1,248.1
 Pop. under 15 (×1,000)             3,789    121.784     202.365   4.184    2,739.1
 Pop. non-white (×1,000)            3,789    154.330     438.571   0.159    7,448.7
 #MDs, office-based                 3,789    942.510   1,827.572   3.500    22,797
 #MDs, hospital/research            3,789     52.576     143.857     0       1,393
 #Small Firms (×1,000)              3,789      8.487      15.380   0.192    120.174
 Area in Square Miles               3,789      4.245       5.226   0.070    52.634
Source: Fast Track Systems, Inc.



Table 3. Descriptive statistics, procedure-level data.
                                   No. Obs    Mean      Std. Dev    Min      Max
 Price differential                 1,227     2.722       3.418    -0.854   45.731
 Dedicated research center          1,227     0.118       0.323       0       1
 Private practice                   1,227     0.800       0.400       0       1
 Other                              1,227     0.025       0.157       0       1
 HMO penetration over 30%           1,227     0.316       0.465       0       1
 Diagnostic procedures              1,227     0.268       0.443       0       1
 Treatment procedures               1,227     0.045       0.207       0       1
 Radiology                          1,227     0.134       0.341       0       1
 Subject visit                      1,227     0.422       0.494       0       1
 Laboratory Test                    1,227     0.098       0.297       0        1
 Sample collection                  1,227     0.028       0.164       0       1
 Health status assessment           1,227     0.008       0.090       0       1
Source: RapidTrials, Inc.




                                                 39
Table 4. Determinants of academic/for-profit investigator mix
[Fractional Logit Estimator]
                                               (1)          (2)           (3)             (4)            (5)
                                             -0.138*                                   -0.152*        -0.089
 FDA approved drug
                                             [0.068]                                    [0.067]        [0.064]
                                                           0.334**                       0.378**        0.259*
 Novel class of drug
                                                          [0.109]                       [0.107]        [0.103]
                                                                        -0.588**       -0.617**       -0.655**
 Popular ICD9
                                                                         [0.089]        [0.089]        [0.084]
                                               1.082**      1.127**       1.155**        1.162**        1.230**
 Phase 1 oncology dummy
                                              [0.200]      [0.203]       [0.200]        [0.202]        [0.196]
                                               0.990**      1.000**       1.043**        1.020**        0.952**
 Phase 2 dummy
                                              [0.089]      [0.089]       [0.088]        [0.088]        [0.084]
                                               0.583**      0.571**       0.636**        0.636**        0.599**
 Phase 3 dummy
                                              [0.091]      [0.092]       [0.091]        [0.091]        [0.086]
                                               0.777**      0.717**       0.793**        0.857**        0.800**
 Phase 4 dummy
                                              [0.122]      [0.123]       [0.122]        [0.121]        [0.118]
                                               0.014        0.021         0.028          0.024          0.032
 ln(No. of procedures)
                                              [0.030]      [0.030]       [0.029]        [0.029]        [0.029]
                                             -0.343**     -0.342**      -0.291**       -0.288**       -0.282**
 Outpatient only
                                              [0.078]      [0.079]       [0.078]        [0.078]        [0.074]
                                               0.105**      0.101**       0.097**        0.098**        0.068**
 ln(length of trial)
                                              [0.020]      [0.020]       [0.020]        [0.020]        [0.020]
                                               0.329        0.045         0.198        -0.069         -0.373
 Constant
                                              [0.172]      [0.193]       [0.169]        [0.190]        [0.331]
 Firm fixed effects                             No           No            No             No             Yes
 Log Pseudolikelihood                       -4,129.86    -4,125.01     -4,111.02      -4,098.14      -3,963.91
 df                                            7,703        7,702         7,703          7,700          7,612
 Note: Dependent variable in all models represents proportion of sites in a trial conducted in an academic
 medical center. All models contain 7,735 observations, with standard errors heteroskedasticity robust clustered
 by unique chemical compound. All models contain fourteen therapeutic class dummies, with oncology being
 the omitted class, and ten year-dummies, with 1991 being the omitted year. Models with novelty rating include
 dummy variable (not shown) for "rating unavailable" category. Omitted phase dummy is Phase 1 (non-cancer).

             significant at the 10% level
         *   significant at the 5% level
        **   significant at the 1% level




                                                         40
Table 5. Number of Clinical Trial Contracts Awarded Across
HSAs [QML Poisson]
                                       (1)         (2)          (3)           (4)                (5)        (6)
                                                    Cross-Section                                 Within-HSA
                                     Acad.                   Medical       Medical             Acad.
                                                   For                                                      For
                                    Medical                  Groups,       Groups,            Medical
                                                  Profit                                                   Profit
                                    Centers                 10+ docs       <10 docs           Centers
                                     0.066       0.223**       0.391        0.157*             0.041       0.038
 ln(HMO enrollees)
                                    [0.052]      [0.077]     [0.286]        [0.066]           [0.026]     [0.027]
                                    -2.149*       0.191       -0.916        -0.198            -3.590*     -2.940
 ln(Population)
                                    [0.916]      [1.215]     [3.136]        [1.346]           [1.414]     [2.654]
                                     0.441       0.720*        1.749         0.477            1.504**     2.007**
 ln(Avg. income)
                                    [0.277]      [0.329]     [1.194]        [0.324]           [0.342]     [0.707]
                                     0.625*      -0.338       -1.579        -0.061             1.252*     -0.498
 ln(Pop. over 65)
                                    [0.313]      [0.369]     [1.114]        [0.408]           [0.631]     [0.873]
                                     1.375*      -0.196        1.301         0.228             1.774*     2.409*
 ln(Pop. under 15)
                                    [0.635]      [0.899]     [2.075]        [0.937]           [0.812]     [1.173]
                                     0.142        0.012       -0.401         0.097            -0.296       0.679
 ln(Pop. non-white)
                                    [0.122]      [0.115]     [0.300]        [0.117]           [0.373]     [0.819]
                                     0.304       0.830*        1.582        0.675              0.164       0.407
 ln(MDs, Office-based)
                                    [0.406]      [0.385]     [1.198]        [0.396]           [0.330]     [0.525]
                                    1.294**       0.092       -0.269         0.124            0.285**     -0.140
 ln(MDs, hospital/research)
                                    [0.100]      [0.106]     [0.231]        [0.090]           [0.106]     [0.100]
                                    -0.495        0.135        0.736        -0.054            -0.424      -0.763
 ln(Small Firms)
                                    [0.272]      [0.322]     [0.839]        [0.403]           [0.629]     [0.902]
                                     0.093       0.289**       0.330        0.232*
 ln(Area in Square Miles)
                                    [0.066]      [0.102]     [0.240]        [0.094]
 No of Observations                  3,789        3,789       3,789          3,789             1,602        3,717
 No of HSAs                           421          421          421           421               178          413
 Log Likelihood                     -3,057       -5,719        -966         -4,053             -6,056      -12,297
 Note: Columns (1), (2), (3), and (4) are pooled cross-sectional models, estimated by QML Poisson. Models in
 Columns (5) and (6) are estimated by conditional fixed effects quasi-maximum likelihood. Dependent variable in all
 models consists of count of sites in a Health Service Area (HSA) that are academic, for-profit, and large vs. small
 medical practices. All models contain year and state fixed effects. Heteroskedasticity-robust standard errors are in
 brackets, clustered by Health Service Area.

             significant at the 10% level
         *   significant at the 5% level
        **   significant at the 1% level




                                                        41
Table 6. Determinants of Research/Medicare Price Wedge
                                                              (1)           (2)           (3)            (4)
                                                                           0.07          0.07           0.15
Dedicated Research Center
                                                                          (0.11)        (0.10)        (0.10)
                                                                           0.07          0.07           0.11
Private Practice
                                                                          (0.11)        (0.10)        (0.09)
                                                                           -0.02         -0.01          0.01
Other Site Types
                                                                          (0.13)        (0.12)        (0.12)
                                                                                         0.02           0.15
HMO Penetr. > 30%
                                                                                        (0.04)        (0.17)
                                                                                                       -0.24
Dedic. Res. Ctr × %HMO>.30
                                                                                                      (0.19)
                                                                                                       -0.13
Private Practice × %HMO>.30
                                                                                                      (0.18)
                                                            -0.92**       -0.92**       -0.92**       -0.92**
Treatment Proced.
                                                            (0.11)        (0.11)        (0.12)        (0.12)
                                                            -0.53**       -0.53**       -0.53**       -0.53**
Radiology
                                                            (0.07)        (0.07)        (0.07)        (0.07)
                                                            -0.90**       -0.90**       -0.90**       -0.90**
Subject Visit
                                                            (0.05)        (0.05)        (0.05)        (0.05)
                                                            -0.36**       -0.35**       -0.35**       -0.36**
Lab. Test
                                                            (0.13)        (0.13)        (0.13)        (0.13)
                                                            -0.57**       -0.56**       -0.56**       -0.57**
Sample Collection
                                                            (0.20)        (0.20)        (0.20)        (0.20)
                                                            -1.44**       -1.44**       -1.44**       -1.44**
Health Status Assessment
                                                            (0.13)        (0.13)        (0.13)        (0.14)
                                                             1.35**       1.27**        1.27**        1.22**
Constant
                                                            (0.11)        (0.15)        (0.15)        (0.14)
Adj. R2                                                       0.26          0.26          0.26          0.26
No. of Clinical Sites                                         140           140           140           140
Nb. of Observations (Procedures)                             1,225         1,225         1,225         1,225
Note: OLS estimates. The dependent variable is the difference between clinical trials and medicare fee
schedule: ln(Research Price) ­ ln(Medicare Price). Robust standard errors (cluster at the level of the clinical
site) in parentheses. Omitted procedure type dummy is Diagnostic. Year indicator variables are included
but not displayed.

              significant at the 10% level
          *   significant at the 5% level
         **   significant at the 1% level




                                                           42
Figure 1. Total number of clinical trial contracts, by investigator
type.




Figure 2. Proportion of academic investigators within a clinical
trial




                                 43
Figure 3. Proportion of clinical trials, by measures of novelty




                                 44
Figure 4A. Cumulative number of academic clinical sites, 1991-
1999, by county




Figure 4B. Cumulative number of for-profit clinical sites, 1991-
1999, by county.




                                45
Figure 5. Distribution of mean annual number of clinical trial
contracts by county.




Figure 6. Annual county-level growth in HMO enrollment.




                                46
Figure 7. Procedure-level price differences




Source: RapidTrials, Inc.




Figure 8. Evolution of Medicare/clinical trial price wedge




Source: RapidTrials, Inc.




                                47
                                               Appendix I:
                         "Small-Group" State Insurance Laws

Small-group state insurance mandates passed during the 1990s fall into three basic categories: the introduc-
tion of guaranteed renewal/guaranteed issue laws, ratings rules, and pre-existing condition laws. Guaranteed
renewal laws require insurance carriers to renew insurance policies to any existing customer (employer), re-
gardless of whether the past incurred medical costs and experience do or do not justify continuance as a
customer. Guaranteed issue laws, frequently passed alongside guaranteed renewal laws, require insurers to
sell policies to any customer willing to pay the premium. Laws involving ratings rules limit the extent to
which insurers can price an insurance product based on the underwritten expected medical expenses the
customer will incur. Finally, some states have passed laws which require that medical coverage be provided
for certain pre-existing medical conditions, such that expensive medical conditions which would ordinarily
raise the price of insurance must be covered under the policy provided, usually after some waiting period.
As Simon (2005) notes, it is difficult to isolate the effect of any single law because such laws tend to be
passed in groups. We followed her analytical approach, whereby the effects of laws are essentially aggregated
and states are modeled as having achieved "no reform", "partial reform" and "full reform," corresponding
to a dummy variable value of 0, 1 and 2 respectively. Because the effect of the individual laws are not the
substantive interest of the paper, this choice was driven by pragmatic considerations, most importantly the
fit of the first stage that results from different ways of coding and capturing the effect of the laws. Alternative
specifications yielded materially similar results.
Some complications that arose when coding the data on these laws should be noted. In general, states
that enact one type of regulation tend to enact other types of regulation simultaneously, leading to severe
multicollinearity issues when attempting to code the content of legislations with distinct dummy variables.
Further, legislation is usually not identical from state to state, and can even be amended within states--for
example, according to one source (Blue Cross and Blue Shield Association), the state of Virginia passed
distinct laws addressing pre-existing conditions in 1992, 1993, 1996, 1997 and 1998. Further, the year of
passage for state laws was not always identical among data sources. To address these problems, we tried
to identify the year during which the most significant state legislation on guaranteed issue/renewal, ratings
laws or pre-existing conditions affecting the small group was passed by comparing data sources.
In addition to these state-level events, the passage of federal legislation--the Health Insurance Portability
and Accountability Act (HIPAA) of 1996, which took effect the following year--complements reform in some
states while subsuming existing reforms in other states. The effect of HIPAA in our panel is that we treat
all states in which no law had been passed as of 1996 as having achieved partial reform in 1997 and beyond.




                                   Appendix II:
                         Skewed outcomes and IV estimation

Estimation of Between-County/HSA Models with Endogenous Regressors. Following the notation
of Windmeijer (2008), we choose to write our basic model:

                                           yi = exp(Xi  + i ) = µi i
The multiplicative error term i = exp(i ) ensures that we treat observable influences (the vector of explana-
tory variables X ) and unobservable factors i in a symmetric fashion. The associated moment conditions


                                                         i
are
                                                                    yi - µi
                                     E [i - 1|Xi ] = E                      |Xi = 0.                      (II.1)
                                                                       µi
where µi = exp(Xi  ). As Mullahy (1997) shows, if Xi is correlated with the unobservables in i such that
E [i - 1|Xi ] = 0, then the method of moments estimator that solves (II.1) is no longer consistent. If there
are instruments Z available then
                                                                    yi - µi
                                     E [i - 1|Zi ] = E                      |Zi = 0.                      (II.2)
                                                                       µi

                   yi -µi
Denoting gi = Zi     µi     , the GMM estimator that minimizes

                                                        N                         N
                                                   1                    -1   1
                                   QN ( ) =                   gi     WN                 gi                (II.3)
                                                   N    i=1
                                                                             N    i=1

is consistent for  . The efficient two-step weight matrix WN is given by
                                                               N
                                                         1
                                        WN (1 ) =                    gi (1 )gi (1 )                       (II.4)
                                                         N     i=1

where
                                                         yi - exp(Xi 1 )
                                           gi = Zi                                                        (II.5)
                                                              exp(Xi 1 )

and 1 is an initial consistent estimator. The GMM estimates presented below use the moment conditions
in (II.2), where the instrument vector Z contains exogenous county and state characteristics (population,
average income, etc.) and the two excluded instruments mentioned above.

Estimation of Within-County/HSA Models with Endogenous Regressors. A similar approach can
be applied to within-county or within-HSA models, in the spirit of the fixed effect Poisson model of Hausman,
Hall, and Griliches (1984). Let yit denote the skewed outcome to be explained for county i, i = 1 . . . N , at
time t, t = 1 . . . T ; and let Xit denote a vector of explanatory variables. An important feature of panel data
is the ability to control for time-invariant unobserved heterogeneity through the use of unit fixed effects. In
count or exponential models, these effects are generally modeled multiplicatively as

                                   yit = exp(Xit  + i ) + it = µit i + it                                 (II.6)

When the vector X only comprises strictly exogenous variables, the conditional mean of yit satisfies

                                   E [yit |i , Xit ] = E [yit |i , Xi1 , . . . , XiT ] .                  (II.7)

For this case, Hausman et al. (1984) use the Poisson conditional maximum likelihood estimator (CMLE),
                    T
conditioning on t=1 yit , which is a sufficient statistic for i . However, the Poisson maximum likelihood
estimator for  in a model with unit-specific intercepts does not suffer from the incidental parameter problem,
and is therefore consistent and the same as the CMLE estimator [see Windmeijer (2008: v-vi) for a short
proof]. The associated first order condition for  is equivalent to a moment estimator in a model where the
ratio of within-unit means are used to approximate the fixed unit effects. The moment conditions for this
within-group mean scaling estimator are given by
                                               N    T
                                          1                                  yi
                                                         Xit yit - µit                                    (II.8)
                                          N   i=1 t=1
                                                                             µi



                                                               ii
If the vector X contains one or more endogenous variables, but a vector of valid instruments Z is available,
one can estimate the mean-scaling model by substituting Z for X in (II.8):
                                            N   T
                                        1                             yi
                                                      Zit yit - µit        .                             (II.9)
                                        N   i=1 t=1
                                                                      µi




                                   Appendix III:
                           Endogeneity of HMO enrollment

Instrument relevance and instrument validity. Past researchers have long been aware of that managed
care penetration might be simultaneously determined with other variables of interest, but efforts to deal with
this endogeneity have only been met with limited success. The most popular approach has been to rely on
use the size distribution of firms to serve as identifying instruments in two-stage least squares regressions
(Baker 1997; Hadley and Mitchell 1999; McLaughlin 1987, 1988). Dranove et al. (1998) show that the
number of large firms in a geographic area positively influences managed care penetration. Baker (1997)
argues that areas with large firms may be particularly attractive to HMOs since large firms are more likely
to offer their employees a menu of health insurance policies that may include HMOs. From the point of view
of identification, the validity of such an instrument hinges on whether the source of variation in firm sizes
across (or within) geographic areas can really be assumed to be orthogonal to unobserved determinants of
the outcome of interest. Hadley and Mitchell (1999) argue that industry and work-force characteristics are
unlikely to have a strong, direct impact on physician practice choices, but in light of the well-documented
firm size-wage relationship (Oi and Idson 1999), and in the absence of a model explaining whence differences
in firm size originate, we choose not to rely on this identification strategy.
We propose an alternative approach that uses variation in state-level regulation of health insurance for small
firms to create exogenous shifters of HMO enrollment. The 1990s were a period of frequent state and federal
legislative events that affected the structure of the insurance industry. Health insurance in the United States
is primarily provided through employers. The total medical expenses incurred by patients pooled in smaller
groups--i.e., employees of small firms--is less predictable, so small employers tend to pay more for health
insurance. Further, because large employers provide more stable risk pools, and because the economies of
scale in plan administration can be substantial, insurers prefer large employers as customers. In order to
reduce the competitive disadvantage small businesses consequently face in labor markets because of their
inability to provide affordable health insurance, many states enacted legislation designed to increase the
ability of small groups to provide health coverage for their employees.
While the success of such legislation on the availability of health insurance has been debated (Hing and Jensen
1999; Jensen and Morrisey 1999; Simon 2005), the more relevant question for our analysis is how legislation
has affected the use of HMOs in particular. On the one hand, some insurers and policy analysts (e.g., Flynn
et al. 1997) have argued that such legislation would decrease coverage because it introduces various mandates
that drive up the price of insurance. This would suggest that the passage of these reforms has a negative
effect on HMO enrollment, as some employers will drop coverage entirely due to its increased cost. However,
the increased overall cost of insurance may instead cause employers to shift from more expensive indemnity,
fee-for-service products to cheaper managed care plans, thus increasing HMO enrollment. For instance,
Buchmueller and Liu (2005) argue that HMOs represent a potentially important self-selection mechanism
because of the restrictions placed on which providers patients can see and under what conditions they can
see them. If employers affected by these laws react by substituting HMO plans for commercial indemnity
insurance plans, then HMO market share could increase even as the number of employees covered decreases
overall. For our purposes, whether this substitution effect dominates does not really matter, and is a question


                                                        iii
best answered by the data itself. What does matter is that this effect of the legal environment influence the
market for clinical research only through its effect on HMO enrollment. This assumption forms the basis of
our identification strategy.
We constructed two instrumental variables: a dummy variable to capture the main effect of the laws on HMO
enrollment, and an interaction term between the presence of a law in a state and the number of potentially
affected firms in a given locale. These instruments address the endogeneity problem to the extent that the
laws are passed by states and are not endogenously driven by the structure of the clinical trials industry. Of
course, one might worry about the political economy of the laws, that is, that they may have been passed
because of changing economic climates in a state (Besley and Case 2000). This seems unlikely here, since
these laws were enacted because of concerns regarding the downstream pricing and delivery of health care
services, not because of concerns regarding upstream health care R&D.

Results. We begin by reporting results from a first-stage analysis of the determinants of HMO enrollment
between and within counties in Table A1. Model (1) merely regresses the log of the number of enrollees in a
county on standard demographic controls. Model (2) documents a correlation between the number of small
firms in a county (the threshold for smallness varies by county in accordance to the state statutes that are
introduced in the subsequent models). Model (3) introduces our two excluded instruments. At the mean
of the data, we find that states that pass "small group" mandates see a 4.79% increase in HMO enrollment
after the enactment of the law, relative to states that did not adopt the mandate. Interestingly, counties
with more affected firms in fact have lower HMO enrollment, compared to counties with fewer affected firms.
This is consistent with Buchmueller and Liu's (2005) argument that these mandates lead some small firms to
drop coverage altogether, while larger firms downgrade their menu of health plans and start offering managed
care options when none might have been available before. Model (4) shows that these results do not change
substantially in the within-county dimension of the data.
We perform F -tests of the hypothesis that these two variables are jointly different from zero, and easily
reject the null. To summarize, small group mandates did affect HMO enrollment, and they affected counties
differentially depending on their distribution of firm size. Our maintained assumption is that this source of
variation in HMO enrollment is orthogonal to unobserved determinants of clinical research activity across
geographic areas.
Table A2 presents our second stage GMM estimates. They results are disappointing. The estimates are not
statistically significant, and in the case of for-profit research activity, the magnitude is very small and of the
"wrong" sign. Clearly, the instruments described above do not allow us to establish a causal relationship
between managed care penetration and the rise of for-profit experimental medicine. Our results could merely
constitute an artifact of endogenous locational choice by HMOs and physicians. We remind the reader that
the failure to reject the null when using instruments is not necessarily damning for our hypothesis, since IV
estimates are less efficient that the Poisson QML estimates presented in Table 5 under the null hypothesis
that HMO penetration is exogenous.




                                                       iv
Table A1. First stage regression: Determinants of HMO
penetration among HSAs
                                                 (1)         (2)          (3)       (4)
                                               Cross-      Cross-       Cross-
                                                                                  Within
                                              Section     Section      Section
                                               4.077**    5.322**       5.015**   12.063*
ln(population)
                                               [0.947]     [1.001]      [1.008]    [5.001]
                                               1.125*     1.856**       1.971**   -1.872*
ln(avg. income)
                                               [0.509]     [0.542]      [0.543]    [0.921]
                                              -1.376**    -1.201**     -1.125**   -5.733**
ln(pop. over 65)
                                               [0.287]     [0.284]      [0.285]    [2.132]
                                               -0.809      -1.025       -0.765    -7.374**
ln(pop. under 15)
                                               [0.739]     [0.731]      [0.733]    [2.658]
                                               -0.111      -0.121       -0.123     -2.474
ln(pop. non-white)
                                               [0.105]     [0.103]      [0.103]    [1.428]
                                               -0.382      -0.032        0.007      1.342
ln(#MDs, office-based)
                                               [0.264]     [0.251]      [0.245]    [0.911]
                                                0.034      -0.024       -0.035     -0.096
ln(#MDs, hosp/research)
                                               [0.066]     [0.066]      [0.065]    [0.149]
                                              -0.318**    -0.253*      -0.254*
ln(area in sq mi)
                                               [0.110]     [0.109]      [0.109]
                                                          -1.548**     -1.381**     1.208
ln(#small firms)
                                                           [0.381]      [0.379]    [1.693]
                                                                       1.821**     1.540**
Regulated State
                                                                        [0.267]    [0.250]
                                                                       -0.229**   -0.193**
Regulated State × ln(#Small Firms)
                                                                        [0.031]    [0.028]
                                              -24.292**   -35.058**   -37.737**    25.356
Constant
                                               [5.548]     [6.366]      [6.435]   [25.880]
R2                                              0.675       0.679        0.688      0.326
Chi2 test: Law Vars = 0                                                29.385**   25.535**

Robust standard errors in brackets.

               significant at the 10% level
           *   significant at the 5% level
         **    significant at the 1% level




                                               v
Table A2. Number of Contracts Awarded across HSAs,
GMM Estimation using Law Instruments.
                                                             (1)           (2)
                                                           AMCs        For Profit
                                                            0.089        -0.006
 ln(#HMO enrollees)
                                                           [0.107]       [0.114]
                                                          -3.998**       -0.639
 ln(population)
                                                           [0.590]       [0.717]
                                                          -0.469**      0.625**
 ln(avg. income)
                                                           [0.177]       [0.178]
                                                          0.913**        -0.195
 ln(pop. over 65)
                                                           [0.147]       [0.202]
                                                           2.301**       0.847*
 ln(pop. under 15)
                                                           [0.355]       [0.426]
                                                          -0.150*       -0.183**
 ln(pop. non-white)
                                                           [0.061]       [0.050]
                                                            0.007       0.561**
 ln(#MDs, office-based)
                                                           [0.199]       [0.174]
                                                          1.448**       0.186**
 ln(#MDs, hosp/research)
                                                           [0.054]       [0.044]
                                                          0.667**        0.513*
 ln(#small firms)
                                                           [0.192]       [0.211]
                                                            0.006       0.133**
 ln(area in sq mi)
                                                           [0.028]       [0.040]
 No of Observations                                         3,996         3,996
 No of HSA/modified HSAs                                     444           444
 Test of overidentifying restrictions, df=2               9.883**         0.343

HSAs that cross state boundaries are modified by treating each state's portion of an HSA as a separate
geographic unit. Heteroskedasticity-robust standard errors are in brackets, clustered by Health Service Area.

              significant at the 10% level
          *   significant at the 5% level
         **   significant at the 1% level




                                                     vi
