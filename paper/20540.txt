                               NBER WORKING PAPER SERIES




                               ROBUST BENCHMARK DESIGN

                                          Darrell Duffie
                                         Piotr Dworczak

                                       Working Paper 20540
                               http://www.nber.org/papers/w20540


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                           October 2014, Revised March 2018




We are grateful for useful discussions with members of the Market Participants Group on
Reference Rate Reform (MPG). We have had particularly useful conversations with Matteo
Aquilina, Terry Belton, David Bowman, Finbarr Hutchison, Paul Milgrom, Anthony Murphy,
Holger Neuhaus, PierMario Satta, Roberto Schiavi, David Skeie, Andy Skrzypacz, Tom Steffen,
Jeremy Stein, Kevin Stiroh, James Vickery, Zhe Wang, Victor Westrupp, and Haoxiang Zhu. The
results and opinions expressed in this paper are not necessarily those of the Market Participants
Group on Reference Rate Reform, a committee chaired by Duffie that was established by the
Financial Stability Board and that published its final report in 2014, nor do they necessarily
reflect the views of the National Bureau of Economic Research.

At least one co-author has disclosed a financial relationship of potential relevance for this
research. Further information is available online at http://www.nber.org/papers/w20540.ack

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2014 by Darrell Duffie and Piotr Dworczak. All rights reserved. Short sections of text, not to
exceed two paragraphs, may be quoted without explicit permission provided that full credit,
including © notice, is given to the source.
Robust Benchmark Design
Darrell Duffie and Piotr Dworczak
NBER Working Paper No. 20540
October 2014, Revised March 2018
JEL No. D82,G12,G14,G18,G23

                                          ABSTRACT

Recent scandals over the manipulation of LIBOR, foreign exchange benchmarks, and other
financial benchmarks have spurred policy discussions over their appropriate design. We
characterize the optimal fixing of a benchmark as an estimator of a market value or reference rate.
The fixing data are the reports or transactions of agents whose profits depend on the fixing, and
who may therefore have incentives to manipulate it. If the benchmark administrator cannot detect
or deter the strategic splitting of trades, we show that the best linear unbiased fixing is the
commonly used volume-weighted average price (VWAP).


Darrell Duffie
Graduate School of Business
Stanford University
Stanford, CA 94305-7298
and NBER
duffie@stanford.edu

Piotr Dworczak
Graduate School of Business
Stanford University
655 Knight Way
Stanford, CA, 94305
dworczak@stanford.edu
1 Introduction                                                                                   2


1       Introduction
This paper solves a version of the problem faced by a financial benchmark administrator. The
benchmark administrator constructs a “fixing,” meaning an estimator of a market value or
reference rate that is based on transactions or other submission data. The data are often
generated by agents whose profits depend on the realization of the fixing. Agents may there-
fore misreport or trade at distorted prices in order to manipulate the fixing. We characterize
optimal transactions weights for benchmark fixings, assuming that the benchmark adminis-
trator cannot use transfers. If the benchmark administrator is also unable to detect or deter
the strategic splitting of trades, we show the best linear unbiased fixing is the commonly used
volume-weighted average price (VWAP).
    The London Interbank Offered Rate (LIBOR) is arguably the single most important
benchmark used in financial markets. Literally millions of different financial contracts, in-
cluding interest rate swaps, futures, options, variable rate bank loans, and mortgages, have
payments that are contractually linked to LIBOR. The aggregate outstanding amount of
LIBOR-linked contracts has been estimated by the Alternative Reference Rate Committee
(2018) at $200 trillion. LIBOR and related reference rates such as EURIBOR and TIBOR
also serve an important price discovery function,1 as benchmarks for evaluating investment
performance and as indicators of current conditions in credit and interest-rate markets. Sim-
ilar concerns have been raised over the manipulation of foreign exchange and commodity
benchmarks.2 Given the important role of benchmarks in financial markets, reports that they
have been systematically manipulated have triggered regulatory reforms. Among other juris-
dictions, the European Union (2016) introduced legislation3 in support of robust benchmarks,
which came into force on January 1, 2018.
    LIBOR is an estimate of the interest rate at which large banks can borrow short-term
wholesale funds on an unsecured basis in the interbank market. Each day, in each major
currency and for each of a range of key maturities, LIBOR is currently reported as a trimmed
average of the rates reported by a panel of banks to the benchmark administrator.4 Investiga-
tions have revealed purposeful misreporting of these rates. Two rather different incentives for
manipulation have been identified. The first, dramatically exacerbated by the financial crisis
    1
       The transparency role of benchmarks is explained in Duffie, Dworczak and Zhu (2017).
    2
       See Financial Stability Board (2014).
     3
       Financial Conduct Authority (2016) explains how the EU regulation “aims to ensure benchmarks
are robust and reliable, and to minimise conflicts of interest in benchmark-setting processes.”
     4
       For details, see, for example, Hou and Skeie (2013). The reports of each individually named
bank are revealed to the market. See also Financial Conduct Authority, 2012; BIS, 2013; Market
Participants Group on Reference Rate Reform, 2014. In order to weaken the incentive to under report
funding costs it has been suggested that the bank-level reports be made public with a three-month
lag.
1 Introduction                                                                                      3


of 2007-2009, was to improve market perceptions of a submitting bank’s creditworthiness, by
understating the rate at which the bank could borrow. The second incentive was to profit
from LIBOR-linked positions held by the bank. For example, in a typical email uncovered by
investigators, a trader at a reporting bank wrote to the LIBOR rate submitter: “For Monday
we are very long 3m cash here in NY and would like setting to be as low as possible...thanks.”5
This second form of manipulation, revealed by investigators to have been active over many
years, is the main subject of this paper.
    Manipulation has been reported across a range of financial market benchmarks. By Febru-
ary 2017, the Commodity Futures Trading Commission, alone, had fined dealers6 $5.29 billion
for manipulation of LIBOR, Euribor, foreign exchange benchmarks and the swap rate bench-
mark known as ISDAFIX. Benchmark manipulation has also been a recent concern for the
equity volatility benchmark known as VIX,7 and in the markets for various commodities,8
precious metals such as gold,9 and manufactured goods such as pharmaceuticals.10
    The Financial Stability Board is leading an ongoing global process to overhaul key ref-
erence rate and foreign currency benchmarks with a view to improving their robustness to
manipulation. A key principle of International Organization of Securities Commissions (2013)
is that fixings of key benchmarks should be “anchored” in actual market transactions or exe-
cutable quotations.
    This paper has a theoretical focus. Under restrictive conditions, we focus on the optimal
design of a transactions-based weighting scheme. In order to illustrate the problem that we
study, we ask the reader to imagine the following abstract situation. An econometrician is
choosing an efficient estimator of an unknown parameter. Data are generated by strategic
agents whose utilities depend on the realized outcome of the estimator. Thus, the chosen
estimator influences the data generating process. This game-theoretic component must be
   5
      December 14, 2006, Trader in New York to Submitter; source: Malloch and Mamorsky (2013).
Another example: “We have another big fixing tom[orrow] and with the market move I was hoping we
could set the 1M and 3M Libors as high as possible.”
    6
      See “CFTC Orders The Royal Bank of Scotland to Pay $85 Million Penalty for Attempted Ma-
nipulation of U.S. Dollar ISDAFIX Benchmark Swap Rates.”
    7
      See Griffin and Shams (2017).
    8
      For cases of oil, natural gas, and propane benchmark manipulation, see “Federal Court Orders $13
Million Fine in CFTC Crude Oil Manipulation Action against Parnon Energy Inc., Arcadia Petroleum
Ltd., and Arcadia Energy (Suisse) SA, and Crude Oil Traders James Dyer and Nicholas Wildgoose,”
CFTC, August 4, 2014; “CFTC Files and Settles Charges against Total Gas & Power North America,
Inc. and Therese Tran for Attempted Manipulation of Natural Gas Monthly Index Settlement Prices,”
CFTC, December 7, 2015; and “CFTC Finds Statoil ASA Attempted to Manipulate the Argus Far East
Index, a Propane Benchmark, to Benefit Statoil’s NYMEX-cleared Swaps Position,” CFTC, November
14, 2017.
    9
      See Vaughn (2014) and “How a Barclays’ options trader manipulated the gold price fix,” Reuters,
May 23, 2014.
   10
      See Gencarelli (2002).
1 Introduction                                                                               4


considered in the design of the estimator.
   Our model features a benchmark administrator who acts as a mechanism designer. The
agents that might manipulate the benchmark could be banks, broker-dealers, asset-management
firms, or individual traders within any of these types of firms. The mechanism designer ob-
serves the transactions generated by the anonymous agents. The data generated by each trans-
action consist only of the price and size (the notional amount) of the transaction. Whether
or not manipulated, the transactions prices are noisy signals of the fundamental value. For
non-manipulated transactions, noise arises from market microstructure effects, as explained
by Aı̈t-Sahalia and Yu (2009), and also from asynchronous reporting. For example, the
WM/Reuters benchmarks for major foreign exchange rates are fixed each day based on trans-
actions that occur within 5 minutes of 4:00pm London time. In an over-the-counter market,
moreover, each pair of transacting counterparties is generally unaware of the prices at which
other pairs of counterparties are negotiating trades at around the same time.
   In our model, the benchmark administrator is restricted to a fixing that is linear with
respect to transactions prices, with weighting coefficients that can depend on the size of the
transaction. A common method of benchmark fixing is the “volume weighted average price”
(VWAP), for which the weight on a given transaction price is proportional to the size of the
transaction. The VWAP benchmark is approximated, with a large number of transactions,
within the family of fixing designs that our modeled benchmark administrator can consider.
   Agents have private information about their exposures to the benchmark, and observe
private signals of the fundamental value of the benchmark asset. If an agent decides to trade
according to the signal received, there is no manipulation. However, the agent can choose to
manipulate by generating a transaction with an artificially inflated or reduced price in order
to gain from the associated distortion of the benchmark. Manipulation is assumed to be costly
for agents. For example, in order to cause an upward distortion in the benchmark, a trader
would need to buy the underlying asset at a price above its fair market value. In order to
manipulate the price downward, the agent would need to sell the asset at a price below its
true value. Either way, by trading at a distorted price, the agent suffers a loss. On the other
hand, the agent has pre-existing contracts (for example swaps) that can be settled at market
values linked to the benchmark. On a large pre-existing swap position, the agent may be able
to distort the benchmark enough to generate a profit that exceeds the cost of creating the
distortion.
   This suggests the benefit of avoiding benchmarks whose underlying asset market is thinly
traded relative to the market for financial instruments that are contractually linked to the
benchmark. In the case of LIBOR, unfortunately, the volume of transactions in the underlying
market for interbank loans that determines LIBOR is tiny by comparison with the volume of
swap contracts that are contractually settled on LIBOR. As emphasized by Duffie and Stein
1 Introduction                                                                                 5


(2015), this situation dramatically magnifies the incentive to manipulate LIBOR.
   Our model implies that manipulation is unavoidable when the potential benefits from
manipulation, measured by the monetary gain from changing the fixing by one unit, are large
relative to (i) the cost of manipulation, (ii) the average size of the transaction, and (iii) the
number of transactions in the market for the benchmark asset.
   Our main findings are the following. First, even if a benchmark can be found that induces
only honest (unmanipulated) transactions, this is not necessarily optimal from the viewpoint of
the efficiency of the estimator. This is because the transaction weights required for statistical
efficiency can be quite different from those minimizing the incentive to manipulate. Typically,
a statistically optimal benchmark fixing allows for a nonzero probability of manipulation.
Second, a robust benchmark must put nearly zero weight on small transactions. This is
intuitive, and stems from the fact that it is cheap for agents to make small manipulated
transactions. For instance, Scheck and Gross (2013) describe a strategy said to be used
by oil traders to manipulate the daily oil price benchmark published by Platts: “Offer to
sell a small amount at a loss to drive down published oil prices, then snap up shiploads at
the lower price.” Third, although the optimal transaction weight is always non-decreasing
in the size of a transaction, the optimal benchmark assigns nearly equal weight to all large
transactions. This follows from the fact that the optimal weighting function is concave in size,
with a slope that goes goes to zero as trade sizes become large. In many cases, the optimal
weight is actually constant above some threshold transaction size. This avoids overweighting
transactions made by agents with particularly strong incentives to manipulate. Fourth, our
main result characterizes the exact shape of the optimal weighting function, as a solution
to a certain second-order differential equation. In the examples that we study, this optimal
shape is well approximated by a weighting function that is linear in size up to a threshold,
and constant afterwards.
   In our baseline model, we assume that each trader’s transactions are aggregated into
a single composite transaction before it enters into the fixing, so that there is effectively
one transaction per agent. In Section 5, we relax this and allow traders to split their total
desired transaction into smaller trades. If the benchmark administrator cannot detect or deter
order splitting, we show the optimal fixing is the volume-weighted average price (VWAP).
VWAP fixings are popular, for example, for the settlement of futures contracts on the Chicago
Mercantile Exchange.11
   In addition to choice of the benchmark asset and the fixing design, regulators can im-
  11
     See Quick Facts on Settlements at CME Group, CME Group, October, 2014. For the NYMEX
crude oil futures contract, “If a trade(s) occurs on Globex between 14:28:00 and 14:30:00 ET, the
active month settles to the volume-weighted average price (VWAP), rounded to the nearest tradable
tick.”
1 Introduction                                                                                      6


plement a range of governance and compliance safeguards, raising the cost of manipulation,
consistent with the suggestions of Financial Conduct Authority (2012) and the International
Organization of Securities Commissions (2013). Our setting allows for an extra cost for trad-
ing at a price away from the fair value, associated with the risk of detection of manipulation
by the authorities, and resulting penalties or loss of reputation.
    For our theoretical analysis, we assume that the mechanism designer cannot use transfers.
In particular, fines or litigation damages, forms of negative transfer, may affect the cost of
manipulation exogenously but cannot be actively controlled by a benchmark administrator.
Building on our framework, Coulter, Shapiro and Zimmerman (2017) address the optimal
design of fines in a “revealed preference mechanism” that directly elicits private information
from the agents. Because Coulter et al. (2017) do not study the problem of designing an
optimal fixing, our approaches are complementary.
    Our work falls into a growing literature on mechanism design without transfers. This
body of research, however, typically focuses on allocation problems.12 The techniques we
use are reminiscent of those used to study direct revelation mechanisms and, to some degree,
principal-agent models. There are, however, essential differences. Because of the restriction on
the class of mechanisms (linear estimators), we cannot rely on the Revelation Principle. The
objective function is not typical. Our mechanism designer is minimizing the mean squared
error of the estimator (benchmark). Agents face a cost of misreporting their type which is
proportional to the deviation from the true type.13 Overall, we are forced to develop new
techniques that draw on tools from optimal control theory.
    We do not analyze estimators that assign different weights to transactions based on the
transactions prices themselves (that is, nonlinear estimators). This extension is an obvious
next step. For example, some benchmarks such as LIBOR dampen or eliminate the influence of
prices that are outliers. Eisl, Jankowitsch and Subrahmanyam (2014) and Youle (2014) argue
that the median estimator can significantly reduce the incentive to manipulate. However,
the net effect on the statistical efficiency of a median-based fixing as an estimator of the
underlying market value is unknown in a setting such as ours with strategic data generation.
    The remainder of the paper is organized as follows. Section 2 introduces the primitives
of the model and the solution concept. Section 3 offers some preliminary analysis in prepa-
ration for a treatment of the main problem in Section 4. Section 5 treats fixings that are
robust to order splitting. In Section 6, we introduce two specific models of manipulation that
micro-found our reduced-form baseline framework. Section 7 concludes and discusses some
  12
     See for example Ben-Porath, Dekel and Lipman (2014) and Mylovanov and Zapechelnyuk (2017).
  13
     Lacker and Weinberg (1989) analyze a model of an exchange economy where an agent may falsify
public information at a cost; Kartik (2009) studies a cheap talk game in which the Sender pays a cost
for deviating from the truth; Kephart and Conitzer (2016) formulate a Revelation Principle for a class
of models in which the agent faces a reporting cost.
2 The baseline model                                                                              7


extensions and future research directions. Most proofs are relegated to the appendix.



2     The baseline model
A mechanism designer (benchmark administrator) will estimate an uncertain variable Y, which
can be viewed as the “true” market value of an asset. To this end, she designs
                                                                         n     a benchmark
                                                                                     on
fixing, which is an estimator Ŷ that can depend on the transaction data (X̂i , ŝi )   gen-
                                                                                           i=1
erated by a fixed set {1, 2, . . . , n} of agents. Here, X̂i is the price and ŝi is the quantity of
the transaction of agent i. The size ŝi of each transaction is restricted to [0, s̄], a technical
simplification that could be motivated as a risk limit imposed by a market regulator or by an
agent’s available capital. The price X̂i is a noisy or manipulated signal of Y , in a sense to
be defined. Agents are strategic: they have preferences, to be explained, over their respective
transactions and over the benchmark Ŷ . The sensitivity of a given agent’s utility to Ŷ is
known only to that agent. The agents do not collude.
    We describe in detail the problem of the benchmark administrator and the agents. Further
interpretation of our assumptions is postponed to the end of the section.


2.1     The problem of the benchmark administrator
                                                              h          i
The benchmark administrator minimizes the mean squared error E (Y − Ŷ )2 of the bench-
mark fixing Ŷ , which is restricted to a linear estimator of the form
                                                  n
                                                  X
                                        Ŷ =            f (ŝi )X̂i ,
                                                  i=1


where f : [0, s̄] → R+ is a transaction weighting function to be chosen. In particular, the
weight placed on a given transaction depends only on its size, and not on its price or on the
identities of the agents. We do not require that the weights sum to one, but we do require the
estimator to be unbiased. We will provide distributional conditions under which unbiasedness
is equivalent to the condition that the weights sum to one in expectation, that is,

                                                n
                                            "               #
                                                X
                                        E             f (ŝi ) = 1.
                                                i=1

Later, we will discuss the restriction to fixing weights that are based only on transactions sizes,
as opposed to weights that could depend jointly on both the sizes and prices of transactions.
    We impose a mild regularity condition that is needed to ensure the existence of a solution
to the administrator’s problem. Let C K,M be the set of upper semi-continuous f : [0, s̄] → R+
2 The baseline model                                                                                         8


with the property that there exist at most K points 0 = s1 < s2 < ... < sK−1 < sK = s̄ such
that f is Lipshitz continuous with Lipshitz constant M in each (si , si+1 ). The constants K
and M are assumed to be finite but large.14 This regularity allows the weighting function f
to have finitely many jump discontinuities and points of non-differentiability.
    We summarize the problem of the benchmark administrator as
                                                       !2 
                                    n
                                                                                   " n         #
                                    X                                               X
                  inf      E Y −         f (ŝi )X̂i           subject to E             f (ŝi ) = 1.    (P)
               f ∈ C K,M
                                    i=1                                             i=1




2.2       The problem of the agents
                                                         n             on
We now explain how the transaction data                   (X̂i , ŝi )       are generated by strategic agents.
                                                                       i=1
We assume that an agent can conduct a manipulated transaction at some reduced-form net
benefit, without explicitly modeling the market in which the transaction takes place. In
Section 6, we propose two alternative stylized models of market trading that endogenize the
reduced-form costs and benefits of a manipulator.
    Agent i privately observes her type Ri , which is interpreted as the agent’s profit exposure
to the benchmark. Specifically, the agent’s payoff includes a profit component Ri Ŷ . This
type Ri can be negative, corresponding to cases when the agent holds a short position in the
asset whose value is positively correlated with the benchmark.
    Having observed Ri , the agent chooses a pair (ẑi , ŝi ) ∈ {−zi , 0, zi } × [0, s̄], where ẑi is a
price distortion and ŝi is a trade size. The absolute magnitude zi > 0 of the price distortion
is assumed to be exogenous, and can be a random variable, as discussed in Section 6. If
agent i chooses not to manipulate, in that ẑi = 0, the benchmark administrator observes
(X̂i , ŝi ) = (Xi , si ), where (Xi , si ) can be thought of the transaction (price and quantity)
of agent i that would be naturally preferred in the absence of manipulation incentives. The
transaction (Xi , si ) is determined by hedging or speculative motives that we do not model.
That is, we take the distribution of (Xi , si ) as given. This is further discussed in the next
subsection. On the other hand, if agent i chooses to manipulate, in that ẑi 6= 0, then the
benchmark administrator observes the transaction (X̂i , ŝi ) = (Xi + ẑi , ŝi ).
    Intuitively, the agent can trade some quantity ŝi at a distorted price to manipulate the
benchmark fixing. This substitution, however, induces a cost γŝi |Xi − X̂i | to the agent that is
proportional to the size of the transaction and to the deviation of the price from the market
level Xi , where γ > 0 is a fixed parameter.
    We assume that the agent does not observe Xi at the time of making the report to the
  14
       Formally, all our results hold for large enough M and K.
2 The baseline model                                                                                    9


benchmark administrator. That is, the agent cannot predict the market price when deciding
whether to manipulate or not. This assumption is motivated by tractability but is also realistic
in some settings, an example of which is discussed in Section 6.
    Without loss of generality, we normalize to zero the payoff to the agent associated with the
truthful reporting choice (X̂i , ŝi ) = (Xi , si ). Given the additivity of the benchmark across
transactions, each agent can ignore the contribution of any of the other transactions to the
distortion-related profit Ri Ŷ . We can thus summarize the problem of agent i as
                                                           h    h       i             i
                                   max                      Ri E ∆ẑi Ŷ − γŝi |ẑi | 1{ẑi 6=0} ,   (A)
                       ẑi ∈{−zi , 0, zi }, ŝi ∈[0, s̄]

       h       i
where E ∆ẑi Ŷ is the expected change in the benchmark fixing relative to choosing ẑi = 0.
(Thus, ∆0 Ŷ = 0.) We will later provide an explicit calculation of this expected change. Exis-
tence of solutions to the agent’s problem is guaranteed by the assumption that the weighting
function is upper semi-continuous. We assume that the agent chooses not to manipulate when
she is indifferent. If, conditional on manipulation, there are multiple optimal ŝi , then we as-
sume that the agent chooses the largest of these transaction sizes. (This tie breaker does not
affect our subsequent results.)


2.3     The distribution of transactions data
The unmanipulated transactions {(Xi , si )}ni=1 are generated as follows. First, Y is drawn from
some probability distribution with mean normalized to zero, and with some finite variance
σY2 . Then, a pair (i , si ) is drawn for every agent, i.i.d. across agents and independently of
Y . We assume that E (i | si ) = 0, and that var (i | si ) = σ2 for some σ2 > 0. The size si has a
cumulative distribution function (cdf) G with a continuous density g that is strictly positive
on [0, s̄]. The unmanipulated price is Xi = Y + i , which is therefore a noisy and unbiased
signal of Y , with variance σU2 ≡ σY2 +σ2 . The subscript U is a mnemonic for “unmanipulated.”
    The exposure types R1 , . . . , Rn are i.i.d. and independent of all other primitive random
variables in the model. The cdf H̃ of Ri has support contained by some interval [−R̄, R̄]. We
allow the case of R̄ = ∞. We assume that the probability distribution of Ri is symmetric
around zero, and that bigger incentives to manipulate are relatively less likely to occur than
smaller incentives. That is, H̃ has a finite variance and a density h̃ that is symmetric around
zero and strictly decreasing on (0, R̄). Examples include the normal and Laplace (“double
exponential”) distributions. Given the symmetry of H̃, we can define a cdf H on [0, R̄] such
that                                       
                                            1 − 1 H(−R)                    if R < 0,
                                    H̃(R) = 2 2                                         .
                                            1 + 1 H(R)                     if R ≥ 0.
                                             2   2
2 The baseline model                                                                             10


That is, H is the distribution of Ri conditional on Ri ≥ 0. We let h denote the density of H,
and we assume that h is twice continuously differentiable.
   The agents’ respective price-distortion magnitudes z1 , . . . , zn are i.i.d., and are indepen-
dent of all other primitive model variables. The variance σz2 of zi is finite and strictly positive.
        2 ≡ σ 2 +σ 2 > σ 2 denote the variance of the reported price X + ẑ conditional on the
We let σM    U    z     U                                             i    i
event {ẑi 6= 0} of a manipulation. The subscript M is thus a mnemonic for “manipulated.”


2.4       Comments on assumptions
For tractability, we have restricted attention to estimators that are linear with respect to
price, with weights depending only on the sizes of the respective transactions. The common
volume-weighted-average-price (VWAP) form of benchmark has relative size weights

                                                  ŝ
                                                Pn i          .
                                                    j=1 ŝj

For the case of a large number n of underlying transactions, the VWAP is therefore approx-
imately of the form that we study. Our assumption that the weight f (ŝi ) on transaction i
does not depend on the sizes of other transactions could be justified by the desire of the ad-
ministrator to avoid strategic interactions between agents’ decisions. This is similar in spirit
to motivations for strategy-proofness in mechanism-design problems. An implication of this
assumption is that the benchmark that we study is robust to some forms of collusion. For
example, agents cannot benefit by sharing information about their exposure types with each
other, nor from attempting to coordinate their decisions.
   We have assumed that variance of the price noise i associated with an unmanipulated
transaction has a variance that does not depend on the size of the transaction. It would be
more realistic to allow the price precision to be increasing with the size of the transaction, as
implicitly supported by volume-weighted-average-price (VWAP) schemes often used to report
representative prices in financial markets.15 Let κ(si ) = var (Xi | si )−1 denote the precision of
the unmanipulated price Xi conditional on the transaction size si . Focusing on the case of a
constant κ(s) allows us to greatly simplify our arguments and sharpen the results. However,
as shown in a preliminary version of this paper (Duffie and Dworczak, 2014), our qualitative
conclusions remain valid provided that κ(s) is a non-decreasing and concave function, and that
σz2 is large enough that a manipulated transaction has more price noise than an unmanipulated
transaction, regardless of its size.
   The problem faced by each agent is stylized. We aim to capture some of a manipulator’s
key incentives. The agent’s type (Xi , si ) can be interpreted as the transaction that the agent
  15
       See, for example, Berkowitz et al. (1988).
2 The baseline model                                                                                 11


would make, given current market conditions, to fulfill her usual “legitimate” business needs.
For example, such a trade could be the result of a natural speculative, market making, or
hedging motive. The assumption that each agent can make only one transaction is relaxed
in Section 5. Formally, this assumption is justified if all of the transactions of a given agent
are first aggregated and only then provided as a single input to the estimator. This is the
method currently used in the fixing of LIBOR by ICE Benchmark Administrator. Section 5
considers the problem of a benchmark administrator when such an aggregation is infeasible
or undesirable.
    For simplicity, we have also assumed that the size of a price manipulation is bounded by
zi . Alternatively, we could assume that there there is an increasing cost ψ(|z|) of manipula-
tion, based for instance on an increasing probability of detection. Formally, in our setting,
ψ(|z|) = c1{z ∈[−z
              /    i , zi ]}
                             , for some large c > 0. The results depend mainly, in this regard, on the
assumption that the manipulation levels chosen by agents are high enough that manipulated
transactions are less precise signals of price than unmanipulated transactions. This property
would hold across many plausible alternative model specifications.
    The cost of manipulation reflects the losses that the agent incurs when trading away
from market prices in order to manipulate the fixing. We take a partial-equilibrium approach,
relegating an endogenous model of trading and payoffs to Section 6. Our particular functional
form for the cost of manipulation, chosen in large part for its tractability, can be further
justified by an alternative interpretation of the nature of manipulations. Namely, imagine that
agents can submit “shill trades,” in the form of fictitious transactions at distorted prices, with
reimbursements,“kickbacks,” arranged through side payments. Then ŝi |Xi − X̂i | is precisely
the kickback cost of manipulation.16 Assuming that the cost of manipulation is linear, rather
than strictly convex, with respect to size and price distortion is a conservative approach in
that it allows for relatively higher profits associated with larger manipulations.
    Finally, Ri can be thought of as the position that the agent holds in contracts whose set-
tlement price is tied to the administered benchmark fixing. For example, many manipulators
of LIBOR were motivated by the fact that they held interest rate derivatives whose settlement
payments are contractually based on the fixing of LIBOR. For positions such as options whose
market values are nonlinear with respect to a benchmark, one can view Ri as the so-called
“delta” (first-order) sensitivity of the position value to the benchmark. The assumption that
Ri is symmetric around zero is, in effect, a belief by the benchmark administrator that upward
and downward manipulative incentives are similar, other than with respect to their signs.
  16
      This assumption is that the cost is linear in size. We can view γ as a per-dollar cost of using an
illegal transfer channel, for example resulting from the possibility of detection and punishment.
3 Using the fixing to deter manipulations                                                                                 12


3     Using the fixing to deter manipulations
In this section we provide some basic properties of an optimal benchmark, and present solu-
tions to some preliminary cases that provide intuition as well as elements on which to build
when solving the general case.


3.1      Solution without manipulation
For comparison purposes, we first solve the problem assuming that agents do not manipulate.
The law of iterated expectation implies that

                                                                         n
                                                                 "                  #
                                                                         X
                                                E [Ŷ | Y ] =        E         f (si ) Y.                               (3.1)
                                                                         i=1

                                                    Pn
Thus, Ŷ is unbiased if and only if E                    i=1 f (si )     = 1. It follows that

                                                                               n
                                     h
                                                     2
                                                         i     σ2   X 
                                                             =− Y +  E f 2 (si )σU2 .
                                                                                   
                                 E (Y − Ŷ )
                                                                n
                                                                           i=1

Using the symmetry assumption, we can formulate the problem of the benchmark adminis-
trator as                            ˆ   s̄                                          ˆ      s̄
                                                                                                                  1
                      inf      σU2            f 2 (s)g(s) ds subject to                          f (s)g(s) ds =     .
                    f ∈C K,M         0                                                  0                         n


Proposition 1 Absent manipulation, the weighting function that solves problem P is given
by f ? (s) = 1/n.


    The proof is skipped. This problem can be viewed as a simple case of ordinary-least-
squares estimation. The benchmark administrator’s optimal weights are proportional to the
precision of each price observation. Because the precisions are assumed to be identical and
in particular invariant to the sizes of transactions, the optimal weights are equal. There is an
obvious generalized-least-squares extension to the case of a general covariance structure for
the observation “noises” 1 , . . . , n .


3.2      Incentives to manipulate
We now turn to the manipulation problem A facing an agent. By symmetry, we may con-
centrate on the event of a positive manipulation incentive, Ri ≥ 0. Using the assumptions of
3 Using the fixing to deter manipulations                                                               13


Subsections 2.2 and 2.3, we can express the problem A of agent i as

                                      max                   [Ri f (ŝi ) − γŝi ] ẑi 1{ẑi 6=0} .    (3.2)
                             ẑi ∈{0, zi }, ŝi ∈[0, s̄]


An agent with type Ri manipulates if and only if there is some s ∈ [0, s̄] such that Ri f (s) > γs,
that is, if there is a size for the manipulated trade at which the impact on the benchmark
fixing is high enough to cover the associated manipulation cost.
    If an agent with type Ri chooses to manipulate, then all agents with types higher than Ri
also manipulate. Similarly, if an agent with type Ri chooses not to manipulate, all agents with
types below Ri also choose not to manipulate. It follows that with any weighting function f
we may associate a unique threshold Rf defined by

                           Rf = sup{R ≤ R̄ : Rf (s) ≤ γs,                             s ∈ [0, s̄]}.

That is, given f , the types above Rf manipulate and the types below Rf do not. This easy
observation leads to the following result.


Proposition 2 The benchmark administrator can ensure that there are no manipulations if
and only if R̄ ≤ nγE[s1 ]. If the benchmark administrator is further constrained to implement
non-manipulation, then the optimal weighting function f ? is given by f ? (s) = γ R̄−1 s on [0, s0 ]
and f ? (s) = f ? (s0 ) on [s0 , s̄], where s0 is chosen to satisfy the constraint
                                              ˆ     s̄
                                                                                1
                                                         f ? (s)g(s) ds =         .
                                                0                               n

Proof: We sketch the proof. The remaining details are easy. By the above characterization, it
is possible to implement no-manipulation (truthful reporting) if and only if, for every s ∈ [0, s̄],
                                                                     ´ s̄
we have R̄f (s) ≤ γs. Because the administrator is constrained by 0 f (s)g(s) ds = 1/n, it is
necessary that                                                ˆ     s̄
                                                1   γ
                                                  ≤                      sg(s) ds.
                                                n   R̄          0

This condition is also sufficient. If this condition holds, we can obtain the optimal weighting
function by applying standard techniques from optimal control theory. 

    The result states that implementing truthful reporting may sometimes be possible. How-
ever, the condition R̄ ≤ nγE[s1 ] is likely to be violated in practice, especially when the
underlying asset market for the benchmark is thinly traded relative to the market for instru-
ments that determine the incentives to manipulate, as is the case for LIBOR. A thinly traded
underlying market corresponds to the case in which R̄ is large relative to E[s1 ], the expected
3 Using the fixing to deter manipulations                                                            14


size of a typical transaction in the benchmark market. This condition is even less likely to be
satisfied when manipulation is relatively cheap (γ is small) or when there are few transactions
(n is small). The latter case is indeed a practical concern because banks are increasingly
reluctant to support benchmarks in the face of potential regulatory penalties and the risk
of private litigation, as documented by Brundsen, 2014 for the case of EURIBOR. The head
of the U.K. Financial Conduct Authority, Andrew Bailey, has similarly announced17 that
LIBOR may be discontinued because the number of reporting banks may become too small
once the agreement of the banks to continue reporting expires at the end of 2021.
    The following example shows that it need not be optimal for the benchmark administrator
to induce truthful reporting with certainty, even in the case when it is possible.

Example 1 Suppose that γ = 1, n = 10, R̄ = 5, σY2 = σ2 = σz2 = 1, g is the uniform density
on [0, 1], and h̃ is the uniform density18 on [−5, 5]. Then, f is feasible and implements
truthful reporting if and only if f (s) = s/5. The value of the benchmark administrator’s
objective function is 1/6. Consider an alternative weighting function fα that is linear up to a
threshold and then flat, in that

                                       fα (s) = α max{s, sα0 },

where α ≥ 1/5 and sα0 is chosen such that the constraint in problem P holds. If |Ri | > 1/α
then agent i manipulates, choosing ŝi = sα0 . The value of the administrator’s objective function
is in this case strictly below 1/6 for all α between 1/5 and 2/5. Thus, it is optimal to allow
manipulation. At the optimal choice of 1/4 for α? , the objective function is approximately
equal to 0.16, and the unconditional probability of manipulation is 1/5.

    A consequence of Proposition 2 is that the benchmark administrator should not restrict
attention to weighting functions that fully deter manipulation. The optimal weighting func-
tion instead influences the degree to which agents manipulate. For clarity of exposition, we
henceforth assume that R̄ = ∞, so that implementing truthful reporting is not possible.19
   17
      On November 24, 2017, a press release of the Financial Conduct Authority stated: “Andrew
Bailey, FCA Chief Executive, set out in a speech earlier this year that, whilst significant improvements
have been made to LIBOR since April 2013, the absence of active underlying markets means that
the future sustainability of LIBOR cannot be guaranteed. The support of the panels for LIBOR is
needed until the end of 2021, by when a transition can be made to alternative rates. The FCA has
been working with the panel banks to finalise an agreement for the banks to remain on the panels they
currently submit to until the end of 2021.”
   18
      The uniform density is not strictly decreasing, as assumed in Section 2, but this property is not
needed for this example.
   19
      This is practically without loss of generality because we can specify the cdf H of Ri to place
arbitrarily small probability mass above some finite R̄.
3 Using the fixing to deter manipulations                                                                                  15


3.3     Administrator’s problem under manipulation
We now derive a concise mathematical formulation of the problem P faced by the benchmark
administrator under the assumptions of Subsections 2.2 and 2.3.
    First, we use our symmetry assumptions to simplify the problem. From the viewpoint of
the benchmark administrator, the events ẑi = zi and ẑi = −zi are equally likely, even after
conditioning on ŝi . Therefore, equation (3.1) still holds if we replace si by ŝi . That is, forcing
the estimator Ŷ to be unbiased is equivalent to the requirement that E [ ni=1 f (ŝi )] = 1. We
                                                                              P

denote by Ψf ( · ) the cdf of the transaction size ŝi , conditional on its manipulation. That is,

                           Ψf (s) = PRi ∼H (argmaxŝ Ri f (ŝ) − γŝ ≤ s| Ri > Rf ).                                     (3.3)

By the law of iterated expectations and because of arguments presented in Subsection 3.2,
                     n ˆ              s̄
       h
                 2
                   i X                                                                                    σ2
                                           f 2 (ŝi ) σU2 H(Rf )g(ŝi ) dŝi + σM
                                                                                2
                                                                                  (1 − H(Rf )) dΨf (ŝi ) − Y .
                                                     
      E (Y − Ŷ ) =
                                  0                                                                         n
                            i=1

The displayed equation states that if |Ri | ≤ Rf (which happens with probability H(Rf )),
then the transaction of agent i is unmanipulated, ŝi = si , X̂i has variance σU2 , and ŝi has
probability density g. On the other hand, if the transaction is manipulated, which happens
                                                      2 from the viewpoint of the benchmark
with probability (1 − H(Rf )), then X̂i has variance σM
administrator.
    Similarly, we can express the constraint in problem P as

                     n                      n ˆ
                 "                #
                     X                      X         s̄
          1=E              f (ŝi ) =                      f (ŝi ) [H(Rf )g(ŝi ) dŝi + (1 − H(Rf )) dΨf (ŝi )] .
                     i=1                    i=1   0


To characterize the optimal benchmark, we use an approach familiar from principal-agent
models. We address the best way, given some target manipulation threshold R, for the
administrator to implement an outcome in which an agent with |Ri | ≤ R chooses not to
manipulate. As we saw before, this requires that the benchmark weight function satisfies the
additional constraint f (s) ≤ (γ/R)s. Solving this auxiliary problem is a key step towards
solving the original problem P. This auxiliary problem is illuminating in its own right.
For example, the benchmark administrator may have exogenous preferences for deterring
manipulation, which could be modeled by setting a high manipulation threshold R. Formally,
using the assumption that agents are symmetric, we can formulate the auxiliary problem as
                                  ˆ   s̄
                                                                      2
                                           f 2 (s) σU2 H(R)g(s) ds + σM
                                                                                         
                      inf                                               (1 − H(R)) dΨf (s)                             (P(R))
                  f ∈ C K,M       0
4 The optimal benchmark                                                                                  16


subject to20
                                                        γ
                                              f (s) ≤     s,   s ∈ [0, s̄],                            (3.4)
                                                        R
                            ˆ    s̄
                                                                                       1
                                      f (s) [H(R)g(s) ds + (1 − H(R)) dΨf (s)] =         .             (3.5)
                             0                                                         n
If the target manipulation threshold R is too high, then no function f inducing that threshold
(that is, satisfying constraint (3.4)) will satisfy constraint (3.5). Among all weighting functions
f satisfying (3.4), f (s) = (γ/R)s maximizes the left hand side of (3.5). In particular, under
this transaction weighting all manipulators choose the maximal transaction size s̄. Therefore,
if we define                                                                                  
                                       γH(R)           γ(1 − H(R))      1
                      R̂ = max R ≥ 0 :       E (s1 ) +             s̄ ≥                            ,
                                         R                  R           n

then the condition R ≤ R̂ is both necessary and sufficient for the set of feasible f to be
non-empty for the problem P(R).


4        The optimal benchmark
In this section we present the solution to the problem faced by the benchmark administrator.
Theorem 1a lists the main properties of the optimal benchmark. Theorem 1b describes the
exact shape of the optimal fixing under a technical assumption. When this technical assump-
tion fails, the optimal fixing can still be described as a solution to a parameterized differential
equation. The full description of this solution is relegated to Appendix A. Following the
statement of the main result, we discuss the intuition and sketch its proof. The remaining
details can be found in Appendix B.

Theorem 1a For any R ∈ (0, R̂), there exists a unique solution f ? to problem P(R). More-
over, f ? is non-decreasing, concave, continuously differentiable, and satisfies (f ? )0 (s̄) = 0.
There is some s0 > 0 such that f ? (s) coincides with (γ/R)s whenever s ≤ s0 .

     The following ordinary differential equation (ODE), which will play a key role in de-
termining the shape of the optimal fixing, is indexed by two parameters: s0 and s1 , with
0 < s0 < s1 < s̄. Consider

                                                                     σ2
                                                                                        
                                                                                     γ
                                      [f (s1 ) − f (s)] H(R)g(s) + σM    2  γh   f 0 (s)
                          f 00 (s) = − h σ2                  i     U                   ,           (4.1)
                                                                 0     γ           γ2
                                          M
                                         σ2
                                             f (s) − f (s 1 )  −h   f 0 (s)    (f 0 (s))3
                                             U

    20
         We abuse notation slightly by treating Ψf (s) as being defined by (3.3) with Rf replaced by R.
4 The optimal benchmark                                                                        17


with boundary conditions

                              f (s0 ) = (γ/R)s0 ,   f 0 (s0 ) = (γ/R).

Theorem 1b Suppose that there exist s0 < s1 < s̄ such that f ? , defined by
                                     
                                       γ
                                     
                                     R
                                        s,            s ∈ [0, s0 ]
                                     
                               ?
                              f (s) = solves (4.1),    s ∈ (s0 , s1 )
                                     
                                     
                                     f ? (s ),
                                     
                                                       s ∈ [s1 , s̄],
                                               1


is continuously differentiable and satisfies (3.5). Then, for any R ∈ (0, R̂), f ? is the unique
solution to the optimal fixing problem P(R).

When no s0 and s1 satisfying the condition of Theorem 1b can be found, the solution to the
optimal fixing problem P(R) satisfies a generalization of (4.1) on the interval [s0 , s̄] that is
provided in Appendix A.
    Intuitively, in Theorem 1b, for any given s0 , the point s1 is chosen so that f 0 (s1 ) = 0.
(This is called the “shooting method.”) This construction guarantees that f ? is continuously
differentiable. Then s0 can be chosen to satisfy (3.5). However, especially when s̄ is relatively
small, suitable choices for s0 and s1 might not exist. In such a case, the optimal f ? asymptotes
to a constant function without being constant on any interval; f ? satisfies a generalized version
of (4.1) given in Appendix A, which depends on an additional parameter chosen to satisfy
the boundary condition (f ? )0 (s̄) = 0.
    Because there is no explicit solution to the differential equation (4.1), a closed-form solu-
tion for the optimal fixing-weight function f ? is not available. However, Theorem 1a provides
a number of economic predictions about the form of the optimal benchmark.
    One robust finding is that the optimal weighting function becomes flat as the transaction
size increases, as captured by the property (f ? )0 (s̄) = 0. The optimal f ? is typically flat
after some threshold transaction size s1 < s̄, as predicted by Theorem 1b and as illustrated
in Example 2, to follow. Intuitively, assigning too much weight to very large transactions
is suboptimal because it induces agents with high manipulation incentives to choose large
transaction sizes, resulting in overweighting such large transactions in the estimator.
    Another general feature of the optimal benchmark is that f ? (s) coincides with (γ/R)s
for a sufficiently small transaction size s. In particular, f ? attaches small weight to small
transactions. The shape of the optimal fixing for small transactions is pinned down by the
binding constraint that an agent with the cutoff type R prefers to avoid manipulation. This
is intuitive. If a benchmark fixing places small weight on small transactions, then unmanip-
ulated transactions are underweighted compared to the weight that they would receive in a
4 The optimal benchmark                                                                          18


statistically efficient estimator. Therefore, it is optimal to place the maximal weight on small
transactions that is consistent with deterring manipulation by types above R.


Fig. 4.1: Optimal weighting function for Example 2 (The dotted line depicts the optimal
          solution in the absence of manipulations)




   Finally, Theorem 1a indicates that the optimal benchmark provides an incentive for
“smoothing out” manipulations, preventing them from “bunching” around a given trans-
action size. This is perhaps somewhat surprising. The manipulated transactions have the
same precisions as signals of Y , and yet it is optimal to attach different weights to them. In
particular this shows that the functions considered in Example 1 are not optimal. As added
intuition, we note that local behavior of f 0 has only second-order effects on the incremental
variance term σU2 f 2 (s)H(R) dG(s) associated with unmanipulated transactions. In contrast,
                               2 f 2 (s)(1 − H(R)) dΨ (s) for manipulated transactions is
the incremental variance term σM                     f
sensitive to the local behavior of f 0 . This follows from from the influence of f 0 on the distri-
bution Ψf , in that relatively small changes in the slope of f can lead to large changes in the
optimal transaction volume chosen by a manipulator. Under our assumptions, this variance
term is convex in f 0 . Thus, minimizing the variance term requires minimizing the variation
of f 0 (subject to meeting other criteria). As a result, f 0 changes continuously rather than
exhibiting discrete jumps.
   When the fixing function f ? is that given by Theorem 1b, all manipulators choose a trans-
action size in [s0 , s1 ], and the distribution of sizes has full support in that interval. However,
as shown in Figure 4.2, the distribution of manipulated transaction sizes is typically concen-
trated around s0 . Under these conditions, the optimal benchmark can be well-approximated
by a simple fixing that is linear up to a threshold, and constant afterwards. We comment
further on this point in Example 4.
   To illustrate the above discussion we consider the following numerical example.
4 The optimal benchmark                                                                                                                      19


Example 2 We take the parameters of Example 1, with the exception that h(x) = exp(−x/2)/2.
The given density h implies that, on average, the exposure to the benchmark asset is equal to
2. We set the manipulation threshold to be twice the mean, R = 4. The type threshold R = 4
corresponds to a probability of manipulation of around 14%. The optimal weighting function
is depicted in Figure 4.1. This function is smooth (C 1 ), but its first derivative changes rapidly
close to s0 ≈ 0.40. All of the manipulated transactions are in the interval [s0 , s1 ]. As can be
seen in Figure 4.2, manipulations are in fact highly concentrated around s0 .

      While the qualitative properties of the optimal weighting function are intuitive, the par-
ticular form of the ODE (4.1) is less clear. To gain intuition, we can rewrite (4.1) as
                                                     
            2                                   γ
                    f (s1 )σU2                            + [f (s) − f (s1 )] σU2 H(R)g(s) =
                                
      f (s)σM   −                    dH        0
                                              f (s)         |              {z            }
  |                      {z                           }                    IU
                         IM
                                                                                                                                        
                                                                      d               2                                  γ            γ
                                                                                              f (s1 )σU2
                                                                                                           
                                                                                f (s)σM   −                    h        0
                                                                                                                                             .
                                                                      ds                                               f (s)       f 0 (s)
                                                                           |                         {z                                    }
                                                                                                     IA


In the above formula, one may think of f (s1 ) as the optimal constant weight that would
be assigned to unmanipulated transactions for the efficient estimator (fixing) that would be
chosen in the absence of manipulation incentives. The term IU is zero, that is f (s) = f (s1 ),
when the weight is chosen optimally from the point of view of unmanipulated transactions.
This term is proportional to the density of sizes corresponding to unmanipulated transactions.
                                                      2 = f (s )σ 2 , when the weight is chosen
On the other hand, the term IM is zero, that is f (s)σM       1 U
optimally from the point of view of manipulated transactions. This term is proportional
to the density of sizes that arises from manipulated transactions. In both of these cases,
individually, the term IA is also zero because h (γ/f 0 (s)) (γ/f 0 (s)) = 0 when f is constant.21
Ideally the benchmark administrator would like to set both of the terms IM and IU to zero,
                             2 > σ 2 . Thus, the administrator faces a trade-off. She either
but this is impossible when σM    U
puts insufficient weight on unmanipulated transactions, which are relatively precise signals of
the fundamental value, or she puts too much weight on manipulated transactions, which are
relatively noisy signals of the fundamental value Y .
      In balancing these two effects, the administrator takes into account the term IA . By
assumption, types in [R, ∞) manipulate. By controlling f 0 , the administrator controls the
sizes of transactions chosen by types Ri in [R, ∞). Because the optimal fixing is concave and
differentiable, the optimal size of a manipulation is pinned down by the first-order condition
for the manipulator’s problem (3.2). Thus, an agent with type Ri = γ/f 0 (s) chooses size
  21
     While this seems to present some issues associated with division by zero, the result follows from
integrability of h, and is formally stated in Lemma 7 of Appendix B.
4 The optimal benchmark                                                                     20



                             Fig. 4.2: Density of manipulations




s. The term γ/f 0 (s) starts at R when s = 0, and ends at ∞ when s = s̄. It follows that
dH(γ/f 0 (s)) describes the density of manipulated transactions. The term IA accounts for the
fact that when the benchmark administrator chooses f (s) at s, she considers the effect of the
speed with which the slope changes on the distribution of the remaining mass of manipulated
transactions.
   To complete the characterization of the optimal fixing function f ? , we observe that for
the case R = 0 (at which every type manipulates), the optimal solution is f ? (s) = 1/n. This
                                                   2 . For the case R = R̂, there is only one
is analogous to Proposition 1, replacing σU2 with σM
feasible fixing function, that with f (s) = (γ/R)s, which is thus trivially optimal.


4.1    Choosing the optimal manipulation threshold R
Having characterized the solution to problem P(R) for a fixed manipulation threshold R,
one can solve the original problem P by choosing an optimal threshold R? . This involves
computing the optimal weighting function f ? for every R ∈ [0, R̂], evaluating the objective
function, and finding the maximum over all R, achieved at some R? . This optimum is attained,
by Berge’s Theorem. While analytic solutions are infeasible, this step can be done numerically.
We show below that the optimal R? is interior, and thus deters some manipulation but does
not minimize the probability of manipulation among all feasible weighting functions.

Proposition 3 The optimal manipulation threshold for problem P is interior: R? ∈ (0, R̂).

   A consequence of Proposition 3 is that the predictions of Theorem 1a about the shape of
the fixing hold at the optimal R? .

Example 3 With the parametric assumptions of Example 2, it turns out that R? ≈ 2.58
achieves the minimum for the benchmark administrator’s problem P. Figure 4.3 presents the
4 The optimal benchmark                                                                              21



                    Fig. 4.3: Optimal weighting functions for Example 3




optimal weighting function for R = 0.5, R = 2.58, and R = 5. The ex-ante probabilities of
manipulation under these target levels are approximately 0.78, 0.28, and 0.08, respectively.22



4.2     Derivation of the optimal benchmark
In this section, we sketch the proof of Theorems 1a and 1b. The remaining details are
presented in the Appendix.
    To solve the problem P(R), we must first determine Ψf ( · ) for each admissible f ∈ C K,M .
This is complicated by the fact that f need not be well behaved. For example, f is not
necessarily differentiable or even concave. However, we can use the structure of the manipu-
lation problem faced by agents to overcome this difficulty. We do this in a series of Lemmas
which establish that the optimal benchmark exists, and the weighting function f must be
continuous, non-decreasing, and concave.

Lemma 1 The problem P(R) admits a solution for any R ≤ R̂.

    Our proof of this lemma is relatively involved because the standard argument (exploit-
ing upper semi-continuity of the objective function on a compact domain) does not apply
directly. The weighting functions are allowed to have jump discontinuities, which can lead to
discontinuities in the objective function (especially if a small change in the weighting function
induces a large change in the behavior of manipulators) and failure of compactness. We deal
  22
     Although Figure 4.3 may suggest otherwise, the function corresponding to R = 5 has a zero
derivative at s = s̄. The second derivative gets large close to s = s̄, so the first derivative changes
rapidly in a small neighborhood of s̄. This is the case in which Theorem 1b does not apply and the
solution is described by Theorem 1 in Appendix A. Figure 4.3 shows that it is possible for two feasible
weighting functions to never cross. If the distribution of sizes ŝi were fixed, this would clearly be
impossible because any two such functions could not have the same expectation with respect to the
distribution of ŝi . However, this is possible when the distribution of ŝi depends on the shape of f .
4 The optimal benchmark                                                                        22


with these difficulties by exploiting the special structure of the problem and the regularity
conditions imposed on feasible f . For unmanipulated transactions, due to the continuous dis-
tribution of trade sizes, the properties of f on a measure-zero set (in particular at the finitely
many points of discontinuity) are irrelevant. For manipulated transactions, we observe that
discontinuities in the choice of the optimal size ŝi can occur only in cases for which the ma-
nipulator is indifferent between several transaction sizes. However, such cases are non-generic
with respect to Ri . Because Ri has a continuous distribution, any such cases can be ignored
when computing the expected payoff.
   A simple corollary of Lemma 1 is that the full problem P also admits a solution. This fol-
lows from the Maximum Theorem (also known as Berge’s Theorem) which implies continuity
of the value of the problem P(R) in the threshold type R.
   Having established existence, we can derive a series of restrictions on the shape of the
optimal weighting function.

Lemma 2 If f is a solution to problem P(R), then f is non-decreasing.

   The proof of this lemma is technical and thus relegated to the Appendix, but the intu-
ition behind this result is straightforward and instructive. Suppose that a feasible weighting
function f is not non-decreasing. Then we can find an interval [s0 , s1 ] ⊂ [0, s̄] such that no
manipulator chooses a transaction size in this interval. Intuitively, manipulators never choose
transactions that give them the same influence on the benchmark as some smaller (hence less
costly) transaction. Absent manipulation, however, we saw in Proposition 1 that the optimal
weight is constant. Thus, we can modify f in such an interval so as to retain feasibility but
improve the value of the program P. This rules out the optimality of f .

Lemma 3 If f is a solution to problem P(R), then f is continuous.

   By Lemma 2 and the regularity conditions imposed on any weighting function, we can
prove Lemma 3 merely by ruling out cases in which f jumps up at some s0 . If there is a jump
at s0 , then there are no manipulations in (s0 − , s0 ) for small  > 0 because the manipulator
can discretely increase the influence on the benchmark by choosing s0 instead, at a negligibly
higher cost. Absent manipulations, the jump in f is suboptimal because the optimal weight
for unmanipulated transactions is constant. So, we can improve on a discontinuous f by
“smoothing it out” in the neighborhood of s0 .

Lemma 4 If f is a solution to problem P(R), then f is concave.

   To prove Lemma 4, we use the fact that there can be no manipulations in intervals over
which the weighting function f fails to be concave, that is, where f lies below some affine
4 The optimal benchmark                                                                                 23


function. This follows from the linearity of costs. In such cases, we can modify f in such an
interval without inducing manipulation, so as to improve the weighting of the non-manipulated
transactions.
    Given Lemmas 1-4, it is without loss of generality that we consider only weighting functions
in the set
                F = {f ∈ C K,M : f is continuous, nondecreasing, and concave}.

The concavity of f implies that we can use first-order conditions to solve the agent’s manip-
ulation problem. However, f is not necessarily differentiable, so we use “superdifferential”
calculus.23 We denote by ∂f (s) the superdifferential of f at the point s. A function f ∈ F
is superdifferentiable at any point s ∈ (0, s̄) because f is concave, and the existence of a
superdifferential at 0 and s̄ follows from Ri f (s) ≤ γs, and the fact that f is non-decreasing.
Moreover, ∂f (s) is a non-decreasing correspondence in the strong set order that is singleton-
valued for almost all s. A transaction size ŝi is a global maximum of Ri f (s) − γs if and
only if 0 ∈ ∂(Ri f (ŝi ) − γŝi ), or simply γ/Ri ∈ ∂f (ŝi ). If f is actually differentiable at s, the
condition for optimality boils down to the usual first-order condition Ri f 0 (s) = γ.
    We can now characterize Ψf ( · ) for any f ∈ F. For some s ∈ [0, s̄] and some manipulation
threshold R,
                                                                   
                               Ψf (s) = P ŝi ≤ s      |Ri | ≥ R
                                                                          
                                      = P ∂f (ŝi ) ≥ ∂f (s) Ri ≥ R
                                                                
                                            γ        0 +
                                      =P        ≥ f (s ) Ri ≥ R
                                           Ri
                                                   
                                               γ
                                        H f 0 (s+ ) − H(R)
                                      =                      .
                                             1 − H(R)

Here, f 0 (s+ ) denotes the right derivative of f at s and (when applied to sets) the inequality
≥ is the strong set order.24 Because the right derivative of a concave function is a right-
continuous and non-increasing function, Ψf ( · ) is a well defined cdf. Discontinuities in f 0
correspond to atoms in the distribution of manipulated transaction sizes.
    The concavity of f implies that the derivative of f , whenever it exists, lies below γ/R.
Indeed, the derivative is non-increasing and the constraint f (s) ≤ (γ/R)s implies that
f 0 (0+ ) ≤ γ/R. Because f is non-decreasing, we also know that f 0 (s) ≥ 0. The inequal-
ity f (s) ≤ (γ/R)s implies that f (0) = 0. Once these properties are imposed, the constraint
   23
      See Rockafellar (1970) for the definitions of the subderivative and subdifferential of a convex func-
tion. The superderivative and superdifferential have the analogous definitions for a concave function.
   24
      That is, for subsets X and Y of the real line, X ≥ Y if for any x in X and y in Y , we have
max{x, y} ∈ X and min{x, y} ∈ Y .
5 Robustness to order splitting                                                                                   24


f (s) ≤ (γ/R)s is redundant. We will study a relaxed problem in which we do not impose
concavity of f , and instead apply the weaker conditions listed above. We will then verify that
the solution to the relaxed problem is concave, validating our approach.
    The relaxed problem can be phrased as an optimal control problem in which the control
variable is the derivative of f . This approach is valid because our assumptions and previous
analysis imply that f is absolutely continuous. So, we have
                                       ˆ   s̄                                      
                                                 2     2                 2       γ
                          min                   f (s) σU H(R) g(s) ds + σM dH                                   (4.2)
                  u: u(s) ∈ [0, γ/R]   0                                        u(s)

subject to
                                                     ˆ   s̄                                    
                             0                                                             γ              1
             f (0) = 0,    f (s) = u(s),                      f (s) H(R) dG(s) + dH                   =     .   (4.3)
                                                     0                                    u(s)            n

To solve this problem, we apply a theorem that gives sufficient conditions for a control variable
and the associated state variable to be optimal. Because the objective function is quadratic
in the state variable f and the constraint (4.3) is linear in f , the Hamiltonian is convex in
the state variable, implying a unique minimizer.

Lemma 5 There exists a unique solution to problem (4.2)-(4.3). The solution is non-decreasing,
concave, continuously differentiable everywhere, and coincides with (γ/R)s for small s. More-
over, the solution is given by the function f ? described by Theorem 1b whenever such a function
exists.

    Because f ? solves the relaxed problem (4.2)-(4.3) and is feasible for the original problem
P(R), f ? is also optimal for the original problem. Thus, the proof of Lemma 5 concludes the
proof of Theorem 1a-1b.


5    Robustness to order splitting
A practical concern related to the design of benchmarks based on transaction data is that
agents intending to trade total quantity s of the asset may split the order into several smaller
“chunks” in order to influence the benchmark fixing. So far, we have ruled out this possibility
by assuming that each agent conducts exactly one transaction. If we relax this assumption,
and in particular assume that the benchmark administrator is not able to aggregate all of
the transactions of a single agent, it turns out that the optimal benchmark from Section 4 is
susceptible to this type of manipulation. To see this, imagine that agent i, with a positive
manipulation incentive Ri , intends to trade the quantity s1 . (See Figure 4.1.) Beyond merely
distorting the price of this transaction, the agent can additionally influence the benchmark
5 Robustness to order splitting                                                                    25


fixing by submitting two smaller transactions, each with quantity s1 /2. Such a manipulation
is costless, given our linear cost function, and yields the agent a benefit of

                                    Ri (2f ? (s1 /2) − f ? (s1 )) > 0.

because of the concavity of the weighting function f ? .
    By an extension of this argument, if the designer chooses a benchmark fixing f , the
effective weighting function that will arise under optimal order-splitting takes the form

                f¯(s) = sup{f (q1 ) + · · · + f (qk ) : qi ∈ [0, s̄], q1 + · · · + qk = s}.

Therefore, if order-splitting is allowed and costless,25 it is without loss of generality to require
that the benchmark administrator chooses a weighting function f that leaves no incentive for
this type of order-splitting manipulation. This property is easily seen to be equivalent to the
condition that f is superadditive. In particular, for any positive integer k,

                                                                 s̄
                                       f (ks) ≥ kf (s),     s≤      .                           (5.1)
                                                                 k

Superadditivity is a cumbersome constraint in optimal control problems because it is a global
property, ruling out characterizations based on local behavior. Therefore, for tractability, we
will assume a slightly stronger mathematical condition by requiring (5.1) to hold for all real
k ≥ 1, and not only for integer k.
Condition 1 A benchmark weighting function f is robust to order-splitting if

                                            f (ks) ≥ kf (s),

for all k ∈ [1, ∞) and all s such that ks ≤ s̄.

    It is clear that the optimal weighting function found in Theorem 1a-1b is not robust to
order splitting. In fact, if f is concave but not linear, it cannot satisfy Condition 1.
Theorem 2 For any R ≤ R̂, the optimal solution f ? to problem P(R), subject to robustness
to order splitting, is given by f ? (s) = (γ/R̂)s. Thus, the optimal manipulation threshold R?
is equal to R̂, and the associated benchmark is the volume-weighted average price (VWAP).

    The proof can be found in Appendix B.7. Theorem 2 states that if the benchmark ad-
ministrator cannot deter or detect order-splitting, then the optimal benchmark is the volume-
weighted average price. The intuition for this result is relatively straightforward. When agents
  25
     Costless order splitting amounts to assumption that agents have no price impact in the underlying
market. With price impact, submitting smaller orders might actually improve the price received by
the agent, which further encourages order-splitting.
5 Robustness to order splitting                                                                 26



                   Fig. 5.1: Optimal weighting functions for Example 4




engage in strategic order splitting, the optimal weighting function cannot be concave unless it
is linear. At the same time, it is not optimal for the weighting function to be strictly convex
in any interval, for the reasons explained in the discussion of Lemma 4. Thus, it is optimal
to choose a linear weighting function. Under a linear weighting function, all manipulators
choose the largest feasible transaction size, which hence receives the highest possible weight.
Therefore, the optimal benchmark that is unbiased and robust to order splitting minimizes
the probability of manipulation.

Example 4 We adopt the parameters of Examples 2 and 3.26 The optimal benchmark fixing
in the baseline model leads to the threshold R? ≈ 2.58 which induces 28% of agents to manipu-
late. The optimal benchmark that deters order splitting is that which minimizes the probability
of manipulation subject to unbiasedness. This yields a manipulation incentive threshold R̂ of
about 5.35, leading to manipulation with a probability of about 7%. The minimized objective
function (mean squared error of the estimator) is 0.142 in the baseline case, and 0.19 when
restricted to Condition 1, robustness to order splitting. This sharp increase in benchmark
noise is caused by attaching a higher weight to manipulated transactions and inefficiently
small weight to small unmanipulated transactions.
   To put this in context, consider the optimal benchmark fixing in the class of capped-volume
weighted average price (CVWAP) fixings, those with a weighting function that in linear in
transaction size s up to some maximal transaction size, after which the weight remains con-
stant. The best such fixing has a mean squared error of 0.149 and induces manipulation by
an agent in the event that the agent’s manipulation incentive R exceeds 2.81, which has a
probability of about 24%. These three weighting functions are depicted in Figure 5.1.

  26
    Because we solve the example numerically, all numerical results reported in this and subsequent
examples are approximate.
6 Models of manipulation                                                                    27


6        Models of manipulation
This section presents two stylized models of trading and manipulation that give rise to the
functional forms for costs and incentives assumed in Section 2. Apart from providing a
microeconomic foundation for our assumptions, these models give more precise meanings to
some model parameters.


6.1       Committed quotes and costly search
We first consider a framework in which manipulation is costly because agents are committed
to offering execution at the price quotes they submit to the benchmark administrator. In
this framework, as is common in some actual benchmark settings, the submitting agents are
dealers whose quotes are used to fix the benchmark. This was the case for the main industry
benchmark for interest rate swaps known as ISDAFIX, whose manipulation27 triggered more
than $600 million in fines for several dealers, Deutsche Bank, Goldman Sachs, Royal Bank
of Scotland, Citibank, and Barclays, and to a more robust benchmark design, as outlined by
Aquilina, Ibikunle, Mollica, Pirrone and Steffen (2018).
     Manipulation consists in quoting a price that is an overestimate or underestimate of the
true value of the asset to the dealer. If the values for the asset are highly correlated among
market participants, then a mispriced quote is likely to be executed by a different investor,
yielding a loss to the quoting bank. In an instance of manipulation of ISDAFIX by Deutsche
Bank Securities Inc., the CFTC found28 that “DBSI Swap traders would tell the Swaps Broker
their need for a certain swap level at 11:00 a.m. or their need to have the level moved up
or down. On at least one occasion, the Swaps Broker expressed the need to know how much
‘ammo’ certain DBSI traders had to use in order to move the screen at 11:00 a.m.” The
“ammo” presumably refers to losses that the DBSI would incur from trades at manipulated
quotes.
     The probability of an execution at a distorted quote depends both on the degree of dis-
tortion and also on the transparency of the market. If quotes are public (as would be the case
in a centralized limit order book), a significantly distorted quote would be executed with a
probability close to one. If the market is more opaque or less active, and especially if quotes
are revealed to traders only upon request (as in bilateral over-the-counter markets and on
multilateral request-for-quote platforms), then the probability of incurring a loss by offering
a distorted quote would be lower.
    27
      See “CFTC Orders The Royal Bank of Scotland to Pay $85 Million Penalty for Attempted Ma-
nipulation of U.S. Dollar ISDAFIX Benchmark Swap Rates.”
   28
      See CFTC Orders Deutsche Bank Securities Inc. to Pay $70 Million Penalty for Attempted
Manipulation of U.S. Dollar ISDAFIX Benchmark Swap Rates, CFTC, February 1, 2018.
6 Models of manipulation                                                                                 28


    In our model, dealer i chooses ŝi ∈ [0, s̄] and ẑi ∈ {−z̄, 0, z̄}, for some constant z̄ > 0
which we could set to σz to match the notation from the baseline model. The variable Xi
is interpreted as the actual per-unit value of the asset to dealer i. The dealer commits to
trade up to ŝi units at a price X̂i = Xi + ẑi , where the pair (X̂i , ŝi ) is used as a benchmark
submission. For simplicity, we set the bid-ask spread to zero, that is, X̂i is both a bid and an
ask. We assume that Y has unbounded support, while i has a symmetric distribution on an
           , ¯], for some ¯ ≤ z̄/2. This captures the idea that the distortion in prices due to
interval [−¯
manipulation is larger than the distortion due to idiosyncratic differences in the value of the
asset to different traders.
    We adopt a stylized search protocol to determine the probability that a committed quote
is executed. Before observing its manipulation incentive type Ri , dealer i chooses a search
intensity λi ∈ [0, 1], paying a cost c(λi ) = 12 c̄λ2i . Here, λi is the probability that the dealer will
be allowed to trade at the committed quotes of some other (randomly chosen) dealer j. We
assume that each dealer is contacted at most once.29 Upon contacting j, dealer i maximizes
the value of its chosen transaction. Because Xi is the unit value of the asset to dealer i, the
resulting payoff of dealer i is
                                                                    
                            max max Xi − X̂j            s, max X̂j − Xi s .
                                      s≤ŝj               s≤ŝj


Here, dealer i buys or sells the maximum quantity ŝj to which dealer j has committed, due
to linearity in value. The difference between the value Xi and the quote X̂j determines the
direction of trade.

6.1.1   Solution

We focus on symmetric Nash equilibria. Dealer i makes two choices, the search intensity
λi and the manipulation levels (ẑi , ŝi ). Regarding the first choice, the expected payoff to a
dealer conditional on a successful search depends on the probability that other banks choose
to manipulate. If pM denotes the equilibrium probability of manipulation, then that expected
payoff is
                                                                
                         1                    1
  E (1 − pM )|Xi − Xj | + pM |Xi − z̄ − Xj | + pM |Xi + z̄ − Xj | E(ŝj )
                         2                    2
                                                          = [(1 − pM )E (|i − j |) + pM z̄] E(ŝj ) ≡ φ.
   29
     Formally, imagine the following iterative procedure. Dealer 1 contacts one of the in dealer N \ {1}
with probability λ1 . If dealer 1 contacts dealer j, then dealer 2 contacts one of the dealers in N \ {2, j}
with probability λ2 , and so on.
6 Models of manipulation                                                                        29


The optimal choice of search intensity is thus λ? = min 1, φc̄−1 .
                                                       

   As for the choice of manipulation, the dealer can always guarantee a zero payoff by quoting
a price equal to the true value Xi , regardless of the size ŝi , by choosing ẑi = 0. On the other
hand, choosing ẑi ∈ {−z̄, z̄} yields a payoff −z̄ŝi in the event of being contacted by another
dealer. The probability of being contacted is

                         n−1
                         X        
                               n−1                          k
                                     (λ? )k (1 − λ? )n−1−k     = λ? .
                                k                          n−1
                         k=1

Taking into account the payoff generated by influencing the benchmark, and normalizing the
payoff from not manipulating to zero, we see that the payoff from choosing (ŝi , ẑi ) is equal to

                                       (Ri f (ŝi ) − λ? ŝi ) ẑi

which is exactly the expression assumed in Section 2, when taking γ = λ? .

6.1.2   Discussion

Based on the simple model of the previous subsection, the parameter γ can be interpreted as
the probability of execution of a manipulated quote. If trade takes place on an active limit
order book, then it is natural to assume that the cost c̄ of search is nearly zero, and hence
that γ = λ? is close to 1. That is, manipulation would almost always yield a trading loss.
On the other hand, in an opaque over-the-counter markets, c̄ may be relatively large, and
hence manipulation is less costly – a manipulated quote might not always be executed. As
a consequence, holding the benchmark fixed, the probability of manipulation is higher in an
opaque market.
   Is λ? is less than one, there is an additional feedback effect between the benchmark fixing
and the probability of manipulation. The ex-ante probability pM of manipulation by any
dealer is 1 − H(Rf ), which is the probability that the dealer’s exposure type R exceeds the
threshold Rf determined by the weighting function f used in the fixing. If f is changed to
reduce manipulation, then Rf goes up and pM goes down. This, however, implies that the
incentive to search is reduced, because the probability of encountering a profitable distorted
quote gets smaller. As a consequence, λ? decreases, and manipulation becomes cheaper.
In a sense, the benchmark fixing and the market forces act as substitutes in preventing
manipulation when the market is relatively opaque.
   This discussion suggests that moving from a centralized to an opaque market may have an
ambiguous influence on the shape of the optimal benchmark. On one hand, because a given
manipulation of the price is less costly in an opaque market, the fixing that should be chosen
in an opaque market would place a relatively smaller weight on small transactions. On the
6 Models of manipulation                                                                      30


other hand, a fixing that deters manipulation lowers the cost of manipulating through the
equilibrium effect on the search intensity of other market participants.


6.2     An auction model
In this subsection, we consider an alternative trading model. When a liquidity shock hits a
dealer, it may request quotes from other dealers, as is typical on electronic request-for-quote
(RFQ) platforms. We model this as a sealed-bid auction. Absent incentives to manipulate,
the dealer will accept the most attractive quote, for example, the lowest ask when it needs to
buy the asset. The execution price, along with the corresponding trade volume, is then used
to calculate the benchmark fixing. If, however, the dealer wants to inflate the fixing in order
to take advantage of a long position in benchmark-linked assets, the dealer has an incentive
to trade at the highest ask offered in the auction. This induces a tradeoff between the loss
incurred in the auction and the gain associated with distorting the benchmark fixing.
   We build a stylized model that aims to capture the main incentives. Dealer i is hit by
a liquidity shock δi that takes one of the values {−∆, ∆} with equal probability, for some
∆ > 0. Dealer i then values each unit of the asset at Y + δi , for quantities up to si . Whenever
a dealer is hit by a shock, it requests quotes from two other dealers who have access to an
unlimited supply of the asset at the common-value price Y. (The restriction to only two other
dealers is not essential for the qualitative results but will yield explicit analytic solutions.)
We model the competition between the two quoting dealers as a first-price auction (Bertrand
competition). Absent incentives to manipulate, the dealer requesting the quote chooses the
more attractive of the quotes, and thus Bertrand forces push the price to Y. However, when
the quote-requesting dealer is a manipulator, it chooses the least attractive of the quotes,
creating an incentive for dealers to provide quotes further away from the value Y.

6.2.1   Solution

For concreteness, consider the case in which dealer i requests quotes to buy the asset (the
opposite case is symmetric). Let pM be the equilibrium probability that dealer i manipulates
by accepting the higher of the quotes, corresponding to the case of a positive exposure Ri .
In the unique symmetric equilibrium of the auction, the two dealers that provide quotes
randomize their offers according to a continuous distribution function F with support [Y +
λ∆, Y + ∆], where λ is determined in equilibrium. Following the line of argument in Stahl
(1989), this requires each of the two dealers to be indifferent between all per-unit quotes q in
the support of F, so that

                       [(1 − pM )(1 − F (q)) + pM F (q)] (q − Y ) = pM ∆.
6 Models of manipulation                                                                            31


Solving, we obtain
                                                   pM Y + ∆ − q
                                  F (q) = 1 −
                                                1 − 2pM q − Y
which is a well defined cdf when pM < 1/2. Moreover, we have λ = pM /(1 − pM ). If pM
is small, the quotes are close to Y . When pM is relatively high (but below 1/2), the quotes
are close30 to Y + ∆. With the above description, we can calculate equilibrium payoffs, and
the distribution of transaction data. Let εki , for k = 1, 2, and i = 1, 2, ..., n, be the profit
margin charged by dealer k in the auction requested by dealer i. That is, Y + ε1i and Y + ε2i
are the quotes received by dealer i. Normalizing the payoff from not manipulating to zero,
we take the cost of manipulation to be equal to the extra profit margin conceded by dealer
i through choosing the less attractive quote for ŝi units of the asset. This concession is
ŝi E max{ε1i , ε2i } − min{ε1i , ε2i } . Taking into account the benefit from influencing the fixing,
                                      

the net expected payoff from manipulation is equal to

                                         (Ri f (ŝi ) − ŝi ) Ezi ,

where the random variable zi is defined by zi = max{ε1i , ε2i } − min{ε1i , ε2i } . This setting
                                                                                

can therefore be viewed as a version of our basic model for the case γ = 1.

6.2.2   Discussion

The model of this section endogenizes the noise structure assumed in Section 2. The noise
term i reflects the dispersion in bids and asks quoted in the auction requested by dealer
i. Manipulated transactions are more noisy than unmanipulated transactions because the
worst price is further away from the mean Y than the best price. The noise term i is
± min{ε1i , ε2i }, with symmetric probability. Manipulated transactions contain an additional
noise term zi = max{ε1i , ε2i } − min{ε1i , ε2i }. Thus, we provided a game-theoretic foundation
for our assumption that manipulation reduces the signal-to-noise ratio of a benchmark.
    In the framework modeled in this section, there is an additional distortionary channel
for manipulation, through its impact on the probability distribution of unmanipulated data.
When it is more likely that a counterparty in a transaction is a manipulator, a trader might
provide a noisy quote, hoping that it will be accepted when the price distortion happens to
be of the sign preferred by the manipulator. As a result, even when the quote requester is
not a manipulator, and would take the most attractive quote, the distribution of quotes is
more dispersed. As the probability pM of manipulation rises, the probability distribution F
of quotes shifts towards quotes further away from the true value Y . Hence the variance of i
  30
     We leave out a description of the equilibrium for the case pM ≥ 1/2 which is less relevant for our
application. In that case, we would observe bids above Y + ∆.
7 Conclusions and future research                                                                    32


rises, in that |i | is distributed according to the CDF 1 − (1 − Fε ())2 , where

                                                            pM ∆ − 
                                        Fε () = 1 −                 ,
                                                         1 − 2pM 

implying that
                                              2                                
                                       pM                       2pM − 1     2pM − 1
                     σ2 = 2∆2                        − log 1 +           +           .
                                     1 − 2pM                    1 − pM      1 − pM

The noise level σ2 is increasing in ∆ and pM . In particular, limpM →1/2 σ2 = ∆2 .
     In this auction setting, because manipulation adversely impacts the precision of unmanip-
ulated price signals, the slope of the optimal benchmark weighting function f is lowered in
order to mitigate the risk of manipulation. The benchmark designer can affect the distribution
of i by choosing f so that pM = 1 − H(Rf ) is relatively low. As a result, the probability of
manipulation is smaller than in the baseline model in which the distribution of unmanipulated
transaction data is exogenous.


7        Conclusions and future research
We developed a simple model for the design of robust benchmark fixings in settings for which
incentives to manipulate the benchmark arise from a profit motive related to investment
positions that are valued according to the benchmark. We have restricted attention to fixings
that are given by a size-dependent weighted average price, an important limitation. We
characterize the optimal weight for each size of transaction. We showed that an optimal
benchmark fixing must in general allow some amount of manipulation, puts very small weight
on small transactions, and nearly equal weight on large transactions. When order-splitting
cannot be detected or otherwise deterred, the volume-weighted average price (VWAP) emerges
as the optimal design within the class of benchmark fixing methods that we consider.
     An important advance would be to allow weights that depend on the prices of transactions.
A simple example is the exclusion of “outlier” prices, as in the design of the LIBOR fixings,
which discards the highest and lowest quartiles of the panel of reports. A more sophisticated
approach would be to compute, for every transaction, the posterior probability that the
transaction is manipulated, and to use this information to construct weights.
     We have ignored collusion throughout.31




    31
         For a given benchmark design, a collusive model of manipulation is suggested by Osler (2016).
7 Conclusions and future research                                                         33


References
Aı̈t-Sahalia, Y. and Yu, J. (2009) High Frequency Market Microstructure Noise Estimates
  and Liquidity Measures, Annals of Statistics, 3, 422–457.

Alternative Reference Rate Committee (2018) Second Report, Federal Reserve Bank of New
  York.

Aquilina, M., Ibikunle, G., Mollica, V., Pirrone, A. and Steffen, T. (2018) The Visible Hand:
  Benchmarks, Regulation and Liquidity, Working paper, University of Edinburgh.

Bank of England (2014) Recommendations on additional financial benchmarks to be brought
  into UK regulatory scope, Fair and Effective Markets Review, Report to Her Majesty’s
  Treasury, August.

Ben-Porath, E., Dekel, E. and Lipman, B. L. (2014) Optimal allocation with costly verifica-
  tion, American Economic Review, 104, 3779–3813.

Berkowitz, S., Logue, D. and Noser, E. (1988) The total cost of transactions on the nyse,
  Journal of Finance, 43, 97–112.

BIS (2013) Towards Better Referece Rate Practices: A Central Bank Perspective, Bank for In-
  ternational Settlements, Basel, Working Group report, Bank for International Settlements.

Brousseau, A., V. Chailloux and Durre, A. (2009) Interbank Offered Rate: Effects of the
  Financial Crisis on the Information Content of the Fixing, IESEG School of Management
  Working Paper No. 2009-ECO-10.

Bruckner, A. M. and Ostrow, E. (1962) Some function classes related to the class of convex
  functions., Pacific J. Math., 12, 1203–1215.

Brundsen, J. (2014) ECB Seeks Rules to Stem Bank Exodus from Benchmark Panels,
  Bloomberg, June 19.

Chen, J. (2013) LIBOR’s Poker: Interbank Borrowing Costs and Strategic Reporting, Working
  paper, Haas School of Business, University of California, Berkeley., UC Berkley Haas School
  of Business Working Paper.

Coulter, B., Shapiro, J. and Zimmerman, P. (2017) A Mechanism for LIBOR, Workig paper.
  Said School of Business, Oxford University., unpublished Manuscript, University of Oxford.

Duffie, D. and Dworczak, P. (2014) Robust benchmark design, Working Paper, Stanford
  Graduate School of Business.
7 Conclusions and future research                                                          34


Duffie, D., Dworczak, P. and Zhu, H. (2017) Benchmarks in search markets, The Journal of
  Finance, 72, 1983–2044.

Duffie, D. and Stein, J. (2015) Reforming LIBOR and other financial market benchmarks,
  Journal of Economic Perspectives, 29, 191–212.

Eisl, A., Jankowitsch, R. and Subrahmanyam, M. (2014) The Manipulation Potential of Libor
  and Euribor, Working paper, New York University.

European Union (2016) Regulation (EU) 2016/1011 of the European Parliament and of the
  Council, European Union, Brussels.

Financial Conduct Authority (2012) The Final Report of the Wheatley Review of LIBOR,
  Financial Conduct Authority, Her Majesty’s Treasury, October.

Financial Conduct Authority (2014) Final Notice; Reference Number 121882, Financial Con-
  duct Authority, Financial Services Authority, London, England.

Financial Conduct Authority (2016) EU Benchmark Regulation.

Financial Stability Board (2014) Foreign Exchange Benchmarks Consultative Document, FI-
  nancial Stability Board, Basel.

Finch, G. and Larkin, N. (2014) U.K. Seeks to Criminalize Manipulation of 7 Benchmarks,
  Bloomberg, September 25.

Foreign Exchange Benchmark Group (2014) Foreign Exchange Benchmarks Consultative Re-
  port, Financial Stability Board, July.

Gencarelli, D. (2005) One Pill, Many Prices: Variation in Prescription Drug Prices in Selected
  Government Programs, National Health Policy Forum, Issue Brief Number 807, August 29,
  George Washington University.

Gencarelli, D. M. (2002) Average Wholesale Price for Prescription Drugs: Is There a More
  Appropriate Pricing Mechanism, NHPF Issue Brief, No. 775.

Griffin, J. and Shams, A. (2017) Manipulation in the VIX?, Review of Financial Studies, 31.

Hou, D. and Skeie, D. (2013) LIBOR: origins, economics, crisis, scandal and reform, The
  New Palgrave Dictionary of Economics, Online Edition, edited by Steven N. Durlauf and
  Lawrence E. Blume.
7 Conclusions and future research                                                        35


Hurtado, P. (2014) Deutsche Bank, HSBC Accused of Silver Fix Manipulation, Bloomberg,
  July 25.

International Organization of Securities Commissions (2013) Principles for Financial Bench-
  marks: Final Report, International Organization of Securities Commissions, FR07/13.

Kartik, N. (2009) Strategic communication with lying costs, The Review of Economic Studies,
  76, 1359–1395.

Kephart, A. and Conitzer, V. (2016) The revelation principle for mechanism design with re-
  porting costs, in Proceedings of the 2016 ACM Conference on Economics and Computation,
  ACM, New York, NY, USA, EC ’16, pp. 85–102.

Lacker, J. M. and Weinberg, J. A. (1989) Optimal contracts under costly state falsification,
  Journal of Political Economy, 97, 1345–1363.

Malloch, T. R. and Mamorsky, J. D. (2013) The End of Ethics and a Way Back: How To Fix
  a Fundamentally Broken Global Financial System, John Wiley & Sons Singapore Pte. Ltd.

Market Participants Group on Reference Rate Reform (2014) Final Report, Financial Stability
  Board.

Milgrom, P. and Shannon, C. (1994) Monotone comparative statics, Econometrica, 62, 157–
  180.

Mylovanov, T. and Zapechelnyuk, A. (2017) Optimal allocation with ex post verification and
  limited penalties, American Economic Review, 107, 2666–94.

Osler, C. (2016) Dealer Trading at the Fix, Working paper, Brandeis University.

Patterson, S. and Burne, K. (2013) CFTC Probes Potential Manipulation, Wall Street Jour-
  nal, April 8.

Rockafellar, T. (1970) Convex Analysis, Princeton: Princeton University Press.

Scheck, J. and Gross, J. (2013) Traders Try to Game Platts Oil-Price Benchmark, Wall Street
  Journal, June 19.

Seierstad, A. and Sydsaeter, K. (1987) Optimal Control Theory with Economic Applications,
  Elsevier, North-Holland, Advanced Textbooks in Economics, volume 24.

Stahl, I. D. O. (1989) Oligopolistic pricing with sequential consumer search, American Eco-
  nomic Review, 79, 700–712.
A The generalized statement of Theorem 1a-1b                                                           36


Vaughn, L. (2014) Gold Fix Study Shows Signs of Decade of Bank Manipulation, Bloomberg,
    February 8.

Youle, T. (2014) How Much Did Manipulation Distort the Libor?, Mimeo, Univeristy of
    Minnesota.



A         The generalized statement of Theorem 1a-1b
We first define a generalization of ODE (4.1). The differential equation is indexed by two
parameters: the starting point s0 and a constant η > 0:
                                                                                        
                                                                                     γ
                                          η − 2f (s)σU2 H(R)g(s) + 2γσM   2 h
                                                      
                                                                                    0
                                                                                   f (s)
                              f 00 (s) = −                                   2
                                                                                                     (A.1)
                                                    2 −η
                                                                   γ           γ
                                             2f (s)σM        −h0 f 0 (s)    (f 0 (s))3

                       with boundary conditions f (s0 ) = (γ/R)s0 , f 0 (s0 ) = γ/R.

Theorem 1 For any R ∈ (0, R̂), there exists a unique optimal solution f ? to problem P(R).
The optimal weighting function f ? is non-decreasing, concave, continuously differentiable ev-
erywhere, and given by
                                            
                                              γ
                                               s                 s ∈ [0, s0 ]
                                            R
                                            
                                            
                                f ? (s) =    solution to (A.1)    s ∈ (s0 , s1 ) .
                                            
                                            
                                            f ? (s )
                                            
                                                                  s ∈ [s1 , s̄]
                                                   1


The parameter η in (A.1) and the cutoff point s1 are chosen so that (f ? )0 (s̄) = 0: either s1 < s̄
in which case η = 2f ? (s1 )σU2 , or s1 = s̄ in which case η ∈ [2f ? (s1 )σU2 , 2f ? (s0 )σM
                                                                                           2 ) is chosen

so that the solution to (A.1) on [s0 , s̄] satisfies f 0 (s̄) = 0. Finally, the cutoff point s0 ∈ (0, s̄)
is chosen to satisfy the constraint (3.5).32

     Clearly, Theorem 1 implies Theorem 1a. To see that it also implies Theorem 1b, note that
f ? described by Theorem 1b corresponds exactly to the first case described by Theorem 1:
s1 < s̄ and η = 2f ? (s1 )σU2 . Because the solution is unique, when f ? described by Theorem 1b
exists, it must be optimal. In this case, the ODE (4.1) is obtained from (A.1) by plugging in
the above expression for η, and dividing the numerator and the denominator by 2σU2 .
     The derivation of the optimal benchmark in Section 4.2 along with the proofs found in
Appendix B establish the generalized version of Theorem 1a-1b described above.
    32
         The existence of such η, s0 , s1 and the existence of a solution to (A.1) will be proven.
B Proofs                                                                                            37


B     Proofs

B.1      Proof of Lemma 1
Let V (f ) be the value of the problem for a feasible function f , and let V ? be the value
of the infimum in P(R) (it exists because the objective function is bounded by zero from
below). By definition of an infimum, there exists a sequence of feasible functions fn such that
limn V (fn ) → V ? . We have to prove that a subsequence of fn converges to a well-defined and
feasible limit f , and that V (f ) = V ? .
    First, we define the limiting function f . Because each fn ∈ C K,M , we can define 0 = sn1 <
sn2 < ... < snKn−1 < snKn = s̄ such that fn is Lipshitz with constant M on each (sni , sni+1 ).
Because Kn ≤ K, and K is finite, there exists a subsequence (which we still denote by fn ) such
that Kn = L ≤ K for all n, and sni → si . For any i, take a compact subset Ai ⊂ (si , si+1 ).
Then, for large enough n, the sequence is uniformly bounded and equi-continuous on Ai , by
assumption. By the Arzelá-Ascoli Theorem, we can find a subsequence that converges point-
wise to some function f˜i on (si , si+1 ), and convergence is uniform on every compact subset.
The limiting function f˜i preserves the Lipshitz constant M . Because the function is bounded
and Lipshitz continuous, we can extend the function to [si , si+1 ] in such a way that f˜i is
continuous. Because there are finitely many i, we can find a subsequence of fn such that the
above properties hold for every interval (si , si+1 ). Finally, we define f to be a function that
coincides with f˜i on every (si , si+1 ), and is equal to max{f˜i−1 (si ), f˜i (si )} for each si . The
definition guarantees that f is upper semi-continuous, and thus belongs to the class C K,M .
The chosen subsequence of fn (which we will again denote by fn ) converges to f uniformly
on every compact A ⊂ [0, s̄] \ {s1 , ..., sL }.
    Second, we look at the properties of dΨf (s) – the distribution of manipulated trade sizes.
In this paragraph, we use Ri to denote a generic positive exposure type. Let
                                                                                      
                                                                                   γ
              Sf (Ri ) = argmaxs∈[0, s̄] {Ri f (s) − γs} ≡ argmaxs∈[0, s̄] f (s) −    s
                                                                                   Ri

be the set of maximizers in the manipulator’s problem. The function f (s) − (γ/Ri )s, defined
on a lattice [0, R̄] × [0, s̄], is quasi-supermodular in s, and has a strict single crossing property
in (s, Ri ). It follows from Milgrom and Shannon (1994) that the set Sf (Ri ) is a complete
sublattice, and any selection sf (Ri ) ∈ Sf (Ri ) is non-decreasing in Ri . In particular, this
means that Sf (Ri ) is a singleton for almost all Ri . Define s̄f (Ri ) = max Sf (Ri ). Then,
Ψf (s) = PRi ∼H (s̄f (Ri ) ≤ s).
    Third, we argue that limn V (fn ) = V (f ), and that f satisfies the constraints of the problem
B Proofs                                                                                                           38


P(R). It is enough to prove that
                                  ˆ         s̄                       ˆ    s̄
                         lim                     fnk (s)g(s)ds   =                 f k (s)g(s)ds, k ∈ {1, 2},    (B.1)
                             n         0                             0

and                              ˆ     s̄                            ˆ        s̄
                        lim                 fnk (s)dΨfn (s) =                      f k (s)dΨf (s), k ∈ {1, 2},   (B.2)
                         n        0                                      0

Showing (B.1) is straightforward – it follows from the Lebesgue dominated convergence the-
orem and the fact that fn converges to f almost surely. We prove that (B.2) holds as well.
Recalling that we are looking at the problem where agents with Ri ≥ R manipulate, we can
write                        ˆ                                   ˆ
                                      s̄                                 R̄
                                                 k                                               dH(Ri )
                                           f (s)dΨf (s) =                     (f (s̄f (Ri ))k            .
                                  0                                  R                          1 − H(R)
It is therefore enough to prove that fn (s̄fn (Ri )) → f (s̄f (Ri )) for almost all Ri . Intuitively,
we have to show that the weight chosen by manipulators changes continuously with the
weighting function, for almost all Ri . For some Ri , it is clear that the optimal choice can be
discontinuous when the manipulator is indifferent between two transaction sizes, but as we
saw in the second step of the proof, such situations are non-generic. It is enough to prove that
s̄fn (Ri ) converges to s̄f (Ri ) for almost all Ri . Indeed, if this is true, then the only scenario
in which fn (s̄fn (Ri )) might fail to converge to f (s̄f (Ri )) is when s̄fn (Ri ) approaches some si
at which f has a jump, and convergence to si is from the side where f is lower – however,
this would contradict the optimality of s̄fn (Ri ). To show convergence of s̄fn (Ri ) to s̄f (Ri )
for almost all Ri , it is enough to prove that the limit of s̄fn (Ri ) is a solution to the agent’s
problem at f . Then, the conclusion follows from the fact that, by step 2 of the proof, the set
of solutions is a singleton for almost all Ri .
    Let v(f ) = maxs∈[0, s̄] (Ri f (s) − γs), for a fixed Ri . Because the function Ri f (s) − γs is
upper semi-continuous
          S                 in s, it is enough to prove that v(fn ) → v(f ). Let Sn be defined as
             L         1        1
[0, s̄] \    i=1 [si − n , si + n ] – we removed each si with some small neighborhood from the
domain. Then, fn converges uniformly to f on Sn . We have, for large enough n,


  |v(fn ) − v(f )| = max (Ri fn (s) − γs) − max (Ri f (s) − γs)
                      s∈[0, s̄]                                  s∈[0, s̄]
            O(1)                                              O(1)
        ≤        + max(Ri fn (s) − γs) − max(Ri f (s) − γs) ≤      + Ri max |fn (s) − f (s)| ,
             n     s∈Sn                  s∈Sn                  n        s∈Sn


and the last expression goes to 0 by uniform convergence. Here, the term O(1) denotes a
constant, and the first inequality follows from the fact that all fn are uniformly bounded and
equi-continuous on each (sni , sni+1 ) (intuitively, removing a small part of the domain cannot
change the value of the optimization problem too much). This concludes the proof.
B Proofs                                                                                                39


B.2           Proof of Lemma 2
Take a feasible function f and suppose it is not nondecreasing. We will prove the result
by constructing a different feasible function f¯ that improves the objective function (hence, f
cannot be optimal). By assumption, there exist s0 and s1 such that s0 < s1 , but f (s0 ) > f (s1 ).
Without loss of generality we can assume (making the interval smaller if necessary and using
the regularity conditions on f ) that either (i) f is strictly decreasing in [s0 , s1 ] or (ii) f has
a jump discontinuity at s0 and f (s) is lower than f (s0 ) on (s0 , s1 ].33
    Consider case (i). By the choice of s0 and s1 , there are no manipulations in (s0 , s1 ), and
this will continue to be true for any function f that is non-increasing in this interval. We
can construct a non-increasing, Lipshitz continuous function fˆ on [s0 , s1 ] with the following
                                                 ´s                  ´s
properties: fˆ(s0 ) = f (s0 ), fˆ(s1 ) = f (s1 ), s01 fˆ(s)g(s) ds = s01 f (s)g(s) ds and there exists
s2 ∈ (s0 , s1 ) such that fˆ(s) < f (s) for s ∈ (s0 , s2 ) and fˆ(s) > f (s) for s ∈ (s2 , s1 ). We then
define                                           
                                                 fˆ(s) if s ∈ [s0 , s1 ]
                                         f¯(s) =
                                                 f (s) otherwise.

By construction, f¯ is feasible (in particular it satisfies the constraint that guarantees an
unbiased estimator). The difference in the value of the administrator’s objective function P
under f¯ and f is (using the fact that there are no manipulations in [s0 , s1 ] under f¯),
                  ˆ    s1                                     ˆ   s1
                            f¯2 (s) − f 2 (s) σU2 g(s) ds =            f¯(s) − f (s) φ(s)g(s) ds,
                                                                                   
                      s0                                      s0


where φ(s) ≡ f¯(s) + f (s) σU2 is a strictly decreasing function. By the mean value theorem,
                          

there exists x ∈ (s0 , s1 ) such that
                  ˆ    s1                                              ˆ   x
                            f¯(s) − f (s) φ(s)g(s) ds = φ(s0 )                 f¯(s) − f (s) g(s) ds.
                                                                                           
                    s0                                                 s0

       ´x
           f¯(s) − f (s) g(s) ds < 0 because the integrand is (strictly) negative on [s0 , s2 ),
                        
But      s0
                                     ´s
(strictly) positive on (s2 , s1 ] and s01 f¯(s) − f (s) g(s) ds = 0.
                                                       

    Therefore, f¯ is feasible and yields a smaller value of the objective function than does f .
    Now, consider case (ii). We can choose s1 so that f (s) < f (s0 ) for all s ∈ (s0 , s1 )
but not on any larger interval. By the choice of s1 , there cannot be any manipulations
in (s0 , s1 ) – this is because a manipulator would strictly prefer to choose s0 over any s
in that interval. Suppose that f is not (almost everywhere) constant on (s0 , s1 ). Then,
there is a way to improve on f by replacing it in this interval by a constant f¯(s) = α with
                    ´s                ´s
α(G(s1 ) − G(s0 )) = s01 f¯(s)g(s)ds = s01 f (s)g(s)ds. Indeed, under both f and f¯, there are
  33
       We assume here that s0 < s̄. The opposite case is very easy to rule out.
B Proofs                                                                                                        40


only unmanipulated transactions in the interval (s0 , s1 ), so the objective function changes by

            ˆ
                                                                              ´ s1                  !2 
                s1                                                                     f (s)g(s)ds
                                                                                  s0
      σU2            (f¯2 (s) − f 2 (s))g(s)ds < σU2 [G(s1 ) − G(s0 )] α2 −                            = 0,
            s0                                                                 G(s1 ) − G(s0 )

where the (strict) inequality follows from Jensen’s Inequality and the fact that f is not (almost
everywhere) constant. Thus, f could not be optimal.
   Finally, consider the opposite case in which f is constant (almost everywhere) on (s0 , s1 ).
By definition of s1 , we must in fact have s1 = s̄, and it is without loss of generality to assume
that f (s) = β for all s > s0 for some β (in the opposite case there is a simple way to improve
on f ). Because the construction of f¯ is similar to the previous cases, we only discuss it
informally and omit a formal calculation. For  > 0 small enough, β +  < f (s0 ), so if we raise
f (s) from β to β +  on (s0 , s̄], this has no influence on the distribution of manipulated trades.
To preserve constraint (3.5), we can now lower f by δ on [s0 − ∆, s0 ]. This might change
the distribution of manipulated trades but only in the direction desired by the administrator
– the manipulators are guaranteed to choose lower weights after the modification because,
for small enough , trade sizes above s0 are suboptimal. Define f¯ as a function obtained by
modifying f in a way described above with , δ, and ∆ such that constraint (3.5) is preserved.
Then, for small enough  and δ, f¯ achieves a strictly lower value of the objective function
than does f . Hence, f could not be optimal.


B.3         Proof of Lemma 3
Take a feasible candidate solution f and suppose that it is not continuous. By the regularity
condition and Lemma 2, it is enough to consider the case when f jumps up at some s0 ∈ (0, s̄).
Consider lowering f by  > 0 in the interval [s0 , s̄], where  is small. Note that after this
modification, the distribution of manipulated transactions conditional on ŝ ∈ [s0 , s̄] does not
change, but it is possible that some manipulators switch to choosing a size ŝ < s0 . However,
we can ignore this in the calculations because, by Lemma 2, the function f is lower on [0, s0 )
than it is on [s0 , s̄] (and continues to be lower if  is small enough) – hence, this can only
improve the objective function. Next, notice that for small enough ∆ and , there cannot be
any manipulations in (s0 − ∆, s0 ) because the choice of any s in this interval is dominated by
the choice of s0 . Let us define f¯ in the following way
                                             
                                             
                                             
                                             f (s)         s ≤ s0 − ∆
                                             
                                      f¯(s) = f (s) + δ     s ∈ (s0 − ∆, s0 ) ,
                                             
                                             
                                             
                                             f (s) −      s ≥ s0
B Proofs                                                                                                                                             41


where δ is chosen so that the constraint (3.5) holds (as noted before, we can ignore the
manipulated transactions):                          ˆ                          ˆ
                                                        s0                         s̄
                                                                 δg(s)ds =              g(s)ds.                                                (B.3)
                                                    s0 −∆                        s0

Because of (B.3), the function f¯ is feasible, so we only have to prove that f¯ achieves a lower
value of the objective function. We have
  ˆ     s̄                         ˆ   s̄
             σU2 f¯2 (s)g(s)ds −      σU2 f 2 (s)g(s)ds
    0                              0
                          ˆ s0                    ˆ s0                   ˆ                            s̄                     ˆ   s̄             
                 = σU δ 2
                       2
                                    g(s)ds + 2δ         f (s)g(s)ds +  2
                                                                                                            g(s)ds − 2                f (s)g(s)ds .
                              s0 −∆                              s0 −∆                            s0                          s0


The terms multiplied by 2 and δ 2 can be ignored because they are negligibly small compared
to other terms once  and δ are small enough (they cannot reverse a strict inequality). Using
equality (B.3), it is enough to prove that
                                                             ˆ    s0                         ˆ    s̄
                                1 − G(s0 )
                                                                        f (s)g(s)ds −                f (s)g(s)ds < 0.
                            G(s0 ) − G(s0 − ∆)               s0 −∆                            s0

or equivalently,                             ´ s0                                ´ s̄
                                              s0 −∆ f (s)g(s)ds                    s0    f (s)g(s)ds
                                                                             <                                .
                                            G(s0 ) − G(s0 − ∆)                          1 − G(s0 )
This means that we are done because
                   ´ s0                                                                          ´ s̄
                    s0 −∆ f (s)g(s)ds             f (s−
                                                      0 ) + f (s0 )                               s0        f (s)g(s)ds
                                                <                   <                                                     ,
                             G(s0 ) − G(s0 − ∆)           2                                            1 − G(s0 )

where f (s−
          0 ) is the left limit of f at s0 , and the inequality follows from the fact that f is
globally non-decreasing, and that there is a jump at s0 .


B.4            Proof of Lemma 4
Take a feasible f and suppose it is not concave. By Lemma 2 and Lemma 3, we can assume
that f is continuous and non-decreasing. This means that we can find an affine increasing
function ϕ(s) = a + bs and an interval [s0 , s1 ] such that ϕ(s0 ) = f (s0 ), ϕ(s1 ) = f (s1 ) and
ϕ(s) ≥ f (s) for all s ∈ (s0 , s1 ), with a strict inequality for at least some s̃ ∈ (s0 , s1 ). We first
prove that there can be no manipulations34 in (s0 , s1 ). It’s enough to show that for generic
   34
        Strictly speaking, the measure of manipulations is zero.
B Proofs                                                                                                   42


R, and for all s ∈ (s0 , s1 ),

                        Rf (s) − γs < max {Rf (s0 ) − γs0 , Rf (s1 ) − γs1 } .

We have
                                                      
                                                      Ra + (Rb − γ) s1                     if Rb > γ,
             max {Rf (s0 ) − γs0 , Rf (s1 ) − γs1 } =
                                                      Ra + (Rb − γ) s                      if Rb < γ.
                                                                                        0


Take the case Rb > γ. Then we have, for all s ∈ (s0 , s1 ),

                        Rf (s) − γs ≤ Ra + (Rb − γ) s < Ra + (Rb − γ) s1 .

Similarly, for Rb < γ and for all s ∈ (s0 , s1 ),

                        Rf (s) − γs ≤ Ra + (Rb − γ) s < Ra + (Rb − γ) s0 .

This conclusion depended only on the fact that f lies below the affine function ϕ. Thus, if f
cannot be improved upon by another feasible function f¯, it must be the case that f restricted
to the interval [s0 , s1 ] arises as a solution to the following optimal control problem:
                                                   ˆ   s1
                                            min             f˜2 (s)g(s) ds                               (B.4)
                                             u≥0     s0

subject to                       ˆ                             ˆ
                                     s1                            s1
                                          f˜(s)g(s) ds =                f (s)g(s) ds,
                                 s0                             s0

                                                   f˜0 (s) = u(s),

                                               f˜(s0 ) = f (s0 ),

                                               f˜(s1 ) ≤ f (s1 ),

                                                   f˜(s) ≤ ϕ(s).

Here, the first derivative plays the role of the control variable, and the weighting function is
the state variable. Notice that this is a problem mathematically equivalent to that considered
in Proposition 2. A standard application of optimal control techniques (see, for example, the
Arrow’s Theorem on page 107 of Seierstad and Sydsaeter, 1987) yields the conclusion that
the optimal f˜(s) is equal to ϕ(s) up to some s2 ∈ (s0 , s1 ), and is constant equal to f˜(s2 ) on
                                                        ´s                 ´s
(s2 , s1 ], where s2 is chosen to satisfy the constraint s01 f˜(s)g(s) ds = s01 f (s)g(s) ds. Note
that s2 < s1 because, by assumption, f lies strictly below ϕ for at least some points. Define
B Proofs                                                                                                                                     43


the function f¯ that coincides with f outside of the interval (s0 , s1 ) and is equal to the optimal
f˜ otherwise. Then, f¯ achieves a weakly lower value of the objective function than f , and has
a jump discontinuity at s1 . By Lemma 3, f¯ can be (strictly) improved upon, and hence f
cannot be optimal either.


B.5           Proof of Lemma 5
We will first find a solution to the relaxed problem (4.2) - (4.3), and then prove that it satisfies
the properties listed in Theorem 1, a generalization of Theorem 1a-1b found in Appendix A.
This will establish Theorem 1, and thus Lemma 5 and Theorem 1a-1b as a special case.
   We fix an R ∈ (0, R̂) which guarantees that the set of functions f ∈ F that satisfy the
constraints of problem (4.2) - (4.3) is non-empty.
   We can simplify the objective function (4.2): Applying integration by parts for the
Riemann-Stieltjes Integral, and using the fact that f is absolutely continuous, we obtain
  ˆ     s̄                                                   ˆ        s̄                            
              2               γ                     2                                      0 γ
             f (s) dH        0
                                                = f (s̄) − 2                 f (s)f (s)H             ds
    0                       f (s)                                   0                     f 0 (s)
                                                                                              ˆ s̄                          
                                                                                                         0               γ
                                                                                         =2        f (s)f (s) 1 − H              ds.
                                                                                                0                     f 0 (s)

Therefore, the objective function (4.2) becomes
                        ˆ   s̄                                                                                                
                                       2                                                       0                           γ
                                   f        (s)σU2 H(R)g(s)         + 2f (s)f                          2
                                                                                                   (s)σM       1−H        0
                                                                                                                                       ds.
                        0                                                                                                f (s)

Applying the same method, we get
                              ˆ        s̄                                       ˆ       s̄                       
                                                              γ                                    0            γ
                                            f (s) dH         0
                                                                             =                 f (s) 1 − H              ds,
                                   0                        f (s)                     0                      f 0 (s)

which allows us to express the constraint (4.3) as
                              ˆ        s̄                                      
                                                                              γ
                                                                              0           1
                                              f (s)H(R)g(s) + f (s) 1 − H    0
                                                                                      ds = .
                                   0                                        f (s)         n

Moreover, we can transform the problem into an unconstrained one by defining an auxiliary
state variable Γ by
                                   ˆ        s                                       
                                                                                  γ
                                                                                  0
                   Γ(s) =                        f (t)H(R)g(t) + f (t) 1 − H               dt, s ∈ [0, s̄].
                                       0                                       f 0 (t)
B Proofs                                                                                                    44


This means that                                                          
                                 0                                    γ0
                             Γ (s) = f (s)H(R)g(s) + f (s) 1 − H
                                                                   f 0 (s)
with Γ(0) = 0 and Γ(s̄) = 1/n.
   We thus have the following optimal control problem:
                             ˆ   s̄                                                           
                                            2                                                γ
             max         −              f       (s)σU2 H(R)g(s)   +              2
                                                                      2f (s)u(s)σM    1−H            ds   (B.5)
      u: u(s)∈[0, γ/R]       0                                                              u(s)

subject to

                                        f 0 (s) = u(s), f (0) = 0, f (s̄) − free,                         (B.6)
                                                   
                                                 γ                             1
        Γ0 (s) = f (s)H(R)g(s) + u(s) 1 − H             , Γ(0) = 0, Γ(s̄) = .                             (B.7)
                                                u(s)                          n

The Hamiltonian corresponding to the problem is
                                                                      
                                                                     γ
  H(f (s), u(s), s) = − f 2 (s)σU2 H(R)g(s) + 2f (s)u(s)σM
                                                         2
                                                            1−H
                                                                    u(s)
                                                                              
                                                                             γ
                       + p1 (s)u(s) + p2 (s) f (s)H(R)g(s) + u(s) 1 − H              , (B.8)
                                                                            u(s)

where pi (s), for i = 1, 2, are the multipliers on the two state variables f and Γ.
   The lemma below gives sufficient conditions for optimality and uniqueness of a candidate
solution.

Lemma 6 Let (f (s), u(s)) be a feasible pair for the problem (B.5) - (B.7). If there exists a
continuous and piecewise continuously differentiable function p(s) = (p1 (s), p2 (s)) such that
the following conditions are satisfied
                                                            
                                                          γ
   1. p01 (s) = 2f (s)σU2 − η H(R)g(s) + 2u(s)σM
                                               2
                            
                                                   1 − H u(s)    ;

   2. p02 (s) = 0;

   3. u(s) maximizes H(f (s), u, s) over u ∈ [0, γ/R] for all s ∈ [0, s̄];

   4. p1 (s̄) = 0;

   5. Ĥ(f, s) = maxu∈[0, γ/R] H(f, u, s) exists and is concave in f for all s,

then (f (s), u(s)) solve the problem (B.5) - (B.7). If Ĥ(f, s) is strictly concave in f for all s,
then f is the unique solution.

Proof: By direct application of the Arrow Sufficiency Theorem (Theorem 5 on page 107 of
Seierstad and Sydsaeter, 1987). 
B Proofs                                                                                     45


   Before we proceed, we state a simple lemma that will be used throughout.

Lemma 7 Suppose X is a nonnegative random variable with a finite variance and a continuously
differentiable decreasing density h on (0, ∞). Then limx→∞ h(x)x2 = limx→∞ h0 (x)x3 = 0.

Proof: The first claim follows directly from the definition of variance, and the second can be
obtained by applying integration by parts. 

   We will construct the functions p1 , p2 , and show that the conditions of Lemma 6 all
hold with (f, f 0 ) as described in Theorem 1. (We omit the superscript in f ? and write
f throughout.) We let η = p2 (s) for all s, for some constant η > 0. We conjecture that
η ∈ [2f (s0 )σU2 , 2f (s0 )σM
                            2 ) (we will verify that conjecture later). This definition of p (s)
                                                                                            2
satisfies condition 2 of Lemma 6.
   Consider the interval [0, s0 ], where f (s) = (γ/R)s, and u(s) = f 0 (s) = γ/R. We want to
make sure that condition 3 of Lemma 6 is satisfied:

                  γ             n 
                                      2
                                                γ           o
                    ∈ argmax − 2f (s)σM −η u 1−H        + p1 (s)u .
                  R   u∈[0, γ ]                    u
                              R


It is enough to show that the derivative of the objective function with respect to u is non-
negative, for all u ∈ [0, γ/R]:
                      h        γ 2 ih      γ  γ  γ i
                          η − 2 sσM 1 − H      + h       + p1 (s) ≥ 0.                    (B.9)
                               R            u   u   u

Notice that the second derivative with respect to u is given by

                                        γ 2 i γ 2  0  γ 
                                  h                         
                                   η − 2 sσM       −h
                                        R      u3       u

                                                                                          2 .
which, by the assumption that h is decreasing, is non-negative if and only if η ≥ 2(γ/R)sσM
Thus, the Hamiltonian is convex in the control variable u (implying a boundary solution) for
                            2 , and is concave otherwise. In either case, it is enough to show
all s such that η ≥ 2(γ/R)sσM
that (B.9) holds for u = γ/R, i.e., that
                          h     γ 2 i
                           η − 2 sσM  [1 − H(R) + Rh(R)] + p1 (s) ≥ 0.                   (B.10)
                                R

To satisfy condition 2 of Lemma 6, we set
                              h γ        i           γ 2
                     p01 (s) = 2 sσU2 − η H(R)g(s) +2 σM (1 − H(R))
                              | R      {z        }   R
                                           ≤0
B Proofs                                                                                                                            46


in the interval s ∈ [0, s0 ], using the assumption that η ≥ 2f (s0 )σU2 . Thus, we can write
                                                                                ˆ   sh
                                     γ 2                                               γ         i
                  p1 (s) = p1 (0) + 2 sσM (1 − H(R)) +                                2 τ σU2 − η H(R)g(τ )dτ.
                                     R                                          0      R

To show (B.10), we need to prove that
                                                        ˆ sh
h        γ 2 i                            γ 2                 γ         i
    η − 2 sσM  [1 − H(R) + Rh(R)]+p1 (0)+2 sσM (1−H(R))+     2 τ σU2 − η H(R)g(τ )dτ ≥ 0.
         R                                R              0    R

This is equivalent to
                                                       ˆ sh
                        h     γ 2 i                          γ         i
          η [1 − H(R)] + η − 2 sσM  [Rh(R)] + p1 (0) +      2 τ σU2 − η H(R)g(τ )dτ ≥ 0.
                              R                         0    R

The derivative of the left hand side is equal to

                                       γ 2         γ        
                                     −2 σM Rh(R) + 2 sσU2 − η H(R)g(s) ≤ 0,
                                       R            R

as long as 2(γ/R)sσU2 ≤ η which is true by conjecture when s ≤ s0 . Thus, we can choose
p1 (0) to satisfy the inequality (B.10) at s = s0 , and then it will hold on the entire interval
[0, s0 ]. We can define p1 (0) so that the inequality binds at s0 which gives us
        h γ                                           ˆ s0 h
             2
                  i            h     γ    2
                                            i                 γ         i
p1 (s) = 2 sσM − η [1 − H(R)] − η − 2 s0 σM [Rh(R)] −        2 τ σU2 − η H(R)g(τ )dτ.
          R                          R                 s      R

We have thus shown that conditions 1-3 of Lemma 6 all hold in the interval [0, s0 ].
      Next, consider the interval [s0 , s̄]. In this interval, we want to have an interior maximizer
                                                    2 , the Hamiltonian is concave in u, and
u(s) of the Hamiltonian (B.8). Because η ≤ 2f (s0 )σM
thus it is enough that the first-order condition holds at u = u(s) :
                                                                       
                                     2
                                                    γ        γ        γ
                       −       2f (s)σM    −η 1−H          +      h           + p1 (s) = 0.                                     (B.11)
                                                    u(s)     u(s)     u(s)

Taking the derivative over s, and using the fact that the equality holds at s = s0 , this is
equivalent to

                                                                                          γ2
                                                                                                            
      0                              γ            γ             γ                                            γ
              2                                                                     2
                                                                                      − η 3 h0                         u0 (s)+p01 (s) = 0.
                                                                            
−2f       (s)σM       1−H                      +      h                    + 2f (s)σM
                                    u(s)         u(s)          u(s)                       u (s)             u(s)
                                                                                                                                (B.12)
Using the fact that u(s) =                      f 0 (s),   so that     u0 (s)   =   f 00 (s),   and combining (B.12) with the
B Proofs                                                                                                                      47


differential equation from condition 1 of Lemma 6 for p1 , we obtain

                    γ2
                                                                                                                   
                                           γ                                                                    γ
              2
                − η 3 h0                              00
                                                     f (s) = η − 2f (s)σU2 H(R)g(s) + 2γσM
                                                                                         2
                                                                        
       2f (s)σM                                                                            h                              .
                    u (s)                 u(s)                                                                 u(s)

This means that it is enough to show that ODE (A.1) holds whenever u(s) > 0, and that
η = 2f (s)σU2 whenever u(s) = 0.
    Notice that from the first-order condition (B.11), we have
                                                                             
                                           2              γ
                                                                   γ        γ
                      p1 (s) =       2f (s)σM    −η 1−H          +      h           ,
                                                          u(s)     u(s)     u(s)

and thus condition 4 of Lemma 6 will hold as long as u(s̄) = 0. Moreover, to show that
p1 (s) is continuous and piecewise continuously differentiable, it is enough to prove that u(s)
is continuous. All of that is accomplished by the following lemma.

                                                 2 ), and a non-decreasing, concave solution f
Lemma 8 There exists η ∈ [2f (s0 )σU2 , 2f (s0 )σM
of class C 1 to the ODE
                                                                         2 h( γ )
                                            [η−2f (s)σU2 ]H(R)g(s)+2γσM          f 0 (s)
                                         −                                                if f 0 (s) > 0
                                         
                                         
                                                                               γ2
                                                                         
                                                      2             γ
       f 00 (s) = φ(s, f, (s) f 0 (s)) ≡      [2f (s)σM −η] −h ( f 0 (s) ) [f 0 (s)]3
                                                               0
                                                                                                                      (B.13)
                                         
                                         0                                                if   f 0 (s)   ≤0
                                         

                                                                         γ                        γ
on an interval [s0 , s̄] with boundary conditions f (s0 ) =              R s0   and f 0 (s0 ) =   R   such that f 0 (s̄) =
0. Moreover, if f 0 (s1 ) = 0 for some s1 < s̄, then η = 2f (s1 )σU2 (in the opposite case, η ≥
2f (s̄)σU2 ).

Proof: In the proof, we will rely on Lemma 7 which implies that the denominator of the ODE
(B.13) goes to 0 as f 0 (s) → 0. Fix a small  > 0. We will work with a modified ODE

                 f 00 (s) = φ (s, f, (s), f 0 (s)) ≡ min 0, φ(s, f, (s), min{, f 0 (s))} .
                                                         
                                                                                                                      (B.14)

With this modification, the function φ is uniformly Lipshitz continuous in f and f 0 (using the
assumption that the density h is twice continuously differentiable). By the Picard-Lindelöf
Theorem, there exists a unique solution of class C 1 which we will denote by fη,  (s); moreover,
the solution depends on η in a continuous way. Because the second derivative of fη,  (s) is
non-positive by definition of φ , we know that fη,  (s) is concave.
                                      0 (s̄) = 0. When  is small enough, and we take η to
    Next, we will choose η such that fη, 
                             2 , we have f 00 (s ) → −∞, so the function f 0 (s) will hit zero
be close enough to 2(γ/R)s0 σM            η,  0                          η, 
                                   0 (s̄) < 0. On the other hand, if we take η low enough,
for some s < s̄, and we will have fη, 
                                                         0 (s)) = 0, and hence f
in particular η < 2(γ/R)s0 σU2 , then φ (s, fη,  (s), fη,                    η,  (s) will coincide
B Proofs                                                                                                             48


                           0 (s̄) > 0. Thus, there exists an intermediate value η such that
with (γ/R)s. In this case fη, 
 0 (s̄) = 0: Let f = f
fη,                 η,  for this η. Thus, we have found a solution f to the modified ODE
(B.14) with the property that f0 (s̄) = 0.
                                                                                       γ          ´s
    Moreover, by the boundary conditions, we can write f (s) =                        R s0   +   s0   f0 (t)dt, and we
know that η ≥ 2f (s)σU2 for all s ≥ s0 , for  small enough. Indeed, if this last claim was not
true, then by the properties of the function φ , we could show that as f0 goes to 0, φ becomes
positive, and thus φ becomes 0. This, however, contradicts the fact that f0 (s̄) = 0. When
                                                  2 , then φ(s, f (s), f 0 (s)) ≤ 0, so f is a solution
η ≥ 2f (s)σU2 for all s ≥ s0 , and η < 2f (s0 )σM                                    
to the ODE
                                         f 00 (s) = φ(s, f, (s), min{, f 0 (s))}.                               (B.15)

This means that we can write f0 (s) as a fixed point of the following operator
                                                          ˆ   s             ˆ t                   
                                                 γ                      γ
           f0 (s)   =   Λ (f0 (s))   ≡ max 0,   −               φ t, s0 +      0          0
                                                                                  f (τ )dτ, f (t) dt .
                                                 R           s0         R      s0


We want to prove that f 0 (s) = lim→0 f0 (s) exists, and that f 0 is a fixed point of the limit
operator Λ = lim→0 Λ . By Tychonoff’s Theorem, we can obtain f 0 (s) which is a pointwise
limit of a subsequence of f0 (s) because f0 ∈ [0, γ/R]. We prove that the limiting function f 0 is
in fact continuous. The only point at which continuity of f 0 might fail is a point s1 at which
f 00 diverges to −∞ (at such a point, f 0 could have a jump discontinuity from a positive level
to 0). Because h ∈ C 2 , we can find a number B > 0 such that f00 (s) ≥ −B/f0 (s) uniformly
in  and s. Intuitively, f00 (s) cannot be highly negative unless f0 (s) is close to 0. But this
means that f0 (s) ≤ −B/f 00 (s) and in particular f0 (s) → 0 when f00 (s) → −∞. Therefore,
f 0 (s1 ) = 0 if f 00 diverges to −∞ at s1 , and hence f 0 is continuous at s1 . When a sequence
of non-decreasing continuous functions converges pointwise to a continuous (non-decreasing)
function, the convergence is uniform. Therefore, we have proven that f0 ⇒ f 0 . Because the
convergence is uniform, f 0 is also a fixed point of the limiting functional Λ. Thus, we have
obtained a continuous f 0 such that
                                                 ˆ   s            ˆ t                 
                         0          γ                         γ          0         0
                     f (s) ≡ max 0,   −                   φ t, s0 +     f (τ )dτ, f (t) dt ,
                                    R               s0        R      s0


and f 0 (s̄) = 0. In particular, this means that whenever f 0 > 0, f is a solution to the ODE
(B.13) (and hence (A.1)).
    To finish the proof, we argue that η ≥ 2f (s̄)σU2 , and if f 0 (s1 ) = 0 for some s1 < s̄, then
2f (s1 )σU2 = η. The first claim is a consequence of the inequality η ≥ 2f (s)σU2 for every  > 0
(proven earlier). Suppose that the second claim is not true. Then, because we proved uniform
B Proofs                                                                                        49


convergence of f0 to f 0 , for any δ > 0, we can find ¯ > 0 such that for all  < ¯,

                                               max |f0 (s)| < δ.                            (B.16)
                                              s∈[s1 , s̄]


However, when 2f (s1 )σU2 > η, (so that 2f (s)σU2 is bounded away from η on [s1 , s̄]), this
implies that −f00 gets arbitrarily large as δ gets small. This is a contradiction with f0 being
a solution to ODE (B.15) that at the same time satisfies (B.16). 

    Given Lemma 8, the proof of Lemma 5 is immediate. By taking η whose existence is
guaranteed by Lemma 8, we satisfy conditions 1-4 of Lemma 6. The functions p1 (s) and
p2 (s) are continuous and continuously differentaible by construction (and Lemma 8 which
guarantees that u(s) is continuous everywhere). The function Ĥ(f, s) is strictly concave in
f for all s because the Hamiltonian H is a quadratic (strictly concave) function of f. Finally,
we can choose s0 such that the corresponding f is feasible, that is, satisfies constraint (B.7),
or equivalently, (3.5). Indeed, (i) f depends on s0 in a continuous way, (ii) choosing s0 = s̄
yields f (s) = (γ/R)s which gives Γ(s̄) > 1/n because R < R̂, and (iii) when s0 → 0, the
corresponding f (s) also converges to zero pointwise, so Γ(s̄) < 1/n. By the intermediate value
theorem, there exists s0 ∈ (0, s̄) such that Γ(s̄) = 1/n, that is, constraint (3.5) holds.
    This implies that the constructed f is the unique solution to the problem (B.5) - (B.7).
Because this function is feasible for the original problem P(R), it is also the unique solution
to P(R).


B.6        Proof of Proposition 3
We will show that the optimal benchmark fixing with R ∈ {0, R̂} is dominated by choosing
a weighting function of the form

                                                      γ
                                          fβ (s) =        max{s, β},
                                                     R(β)

for some β ∈ [0, s̄], where R(β) is chosen to make fβ feasible, that is, to satisfy (3.5):
                           ˆ     β                            
                H(R(β))                                           1 − H(R(β))     1
                                      γτ g(τ )dτ + γβ(1 − G(β)) +             γβ = .
                 R(β)         0                                       R(β)        n

As noted in the discussion of Theorem 1a-1b, the optimal weighting function for R = 0 is
f (s) = 1/n, and the optimal weighting function for R = R̂ is f (s) = (γ/R̂)s. Importantly,
these two functions are the limits of the family fβ as β varies from 0 to s̄.35 Moreover,
  35
       Formally, we have fs̄ (s) = (γ/R̂)s and limβ→0 fβ (s) → 1/n for all s > 0.
B Proofs                                                                                                                       50


R(β) ∈ (0, R̂) for all β ∈ (0, s̄). Let
                                   ˆ     β                                       
                  H(R(β))                                                                1 − H(R(β)) 2 2 2
        V (β) =                               γ 2 τ 2 g(τ )dτ + γ 2 β 2 (1 − G(β)) σU2 +            γ β σM
                   R2 (β)             0                                                     R2 (β)

denote the value of the objective function (4.2) at fβ . Then, V (0) corresponds to the value
attained by the optimal weighting function with R = 0, and V (s̄) corresponds to the value
attained by the optimal weighting function with R = R̂. Because V is continuous and differ-
entiable, to prove Proposition 3, it is enough to show that V 0 (0) < 0, and V 0 (s̄) > 0.
      Using the implicit function theorem, we can write R(β) as a function of β with

                                                                    R(β)
                                                                 lim     = γn,
                                                                 β→0 β


and
                                             R(1 − H(R(β))G(β))
                  R0 (β) =                                       ´β           .
                               β − (H(R(β)) − h(R(β))R(β)) βG(β) − 0 τ g(τ )dτ

We can calculate the derivative of V (β) at β = s̄ directly:

                                                                                                ˆ     s̄
               h(R̂)R̂2 − 2H(R̂)R̂
                                                                                                                                       
                                                             1 − H(R̂)
  V 0 (s̄) =                                                         ´ s̄                               τ 2 g(τ )dτ σU2 − s̄2 σM
                                                                                                                                   2
                        R̂3                    s̄ − H(R̂) − h(R̂)R̂ s̄ − 0 τ g(τ )dτ               0
                                                                                                                       
                              2H(R̂)                 2                         1 − H(R̂)                   2  2
                     −                       s̄ −         s̄2                         ´ s̄         +     s̄ σM .
                               R̂2                   R̂2         s̄ − H(R̂) − h(R̂)R̂ s̄ − 0 τ g(τ )dτ    R̂2

               2 /σ 2 , then V 0 (s̄) > 0 is equivalent, after some simplifications, to
If we let λ = σM   U

 h                      i ˆ       s̄ 
                                          τ 2
                                                                                     ˆ s̄  τ         
     2H(R̂) − h(R̂)R̂                          g(τ )dτ < λ h(R̂)R̂ + 2 H(R̂) − h(R̂)R̂              g(τ )dτ .
                               0          s̄                                              0     s̄

We know that the density h is decreasing, and because a density is integrable, we must have
limR→0 h(R)R = 0. It follows that H(R) > h(R)R for all R > 0 because

                               d
                                 [H(R) − h(R)R] = h(R) − h(R) − h0 (R)R > 0.
                              dR

Therefore, V 0 (s̄) > 0 is equivalent to
                                                             h      i 2
                                                                     Es
                                                    2H(R̂) − h(R̂)R̂ s̄21
                                          λ>                                  .                                           (B.17)
                                             h(R̂)R̂ + 2 H(R̂) − h(R̂)R̂ Ess̄ 1
B Proofs                                                                                        51


Next, we have
                h                 i 2                h                 i
                                   Es
                  2H(R̂) − h(R̂)R̂ s̄21                2H(R̂) − h(R̂)R̂ Ess̄ 1
                                            ≤                                  ≤ 1,
           h(R̂)R̂ + 2 H(R̂) − h(R̂)R̂ Ess̄ 1   h(R̂)R̂ + 2 H(R̂) − h(R̂)R̂ Ess̄ 1

where the last inequality follows from the fact that, by direct calculation of the derivative,
the middle expression is increasing in Es1 /s̄. This proves that (B.17) always holds because its
left hand side is strictly greater than 1, while the right hand side is less than 1.
    Now, we will show that V 0 (0) < 0. We have

                                                               γ 2 h(0)
                             V 0 (0) = lim V 0 (β) = σU2 − σM
                                                            2
                                                    
                                                                         < 0.
                                       β→0                          n

This ends the proof.


B.7     Proof of Theorem 2
We will first show that f ? (s) = (γ/R̂)s solves problem P. It follows that f ? solves problem
P(R) for any R ≤ R̂, because f ? is feasible for P(R) for any R ≤ R̂.
    By arguments analogous to the ones used in the proof of Lemma 2 and Lemma 3, the
optimal function f is continuous and non-decreasing. By Bruckner and Ostrow (1962), As-
sumption 1 is equivalent to the following condition when f (0) = 0, and f is non-decreasing
and continuous:
                                                       f (s)
                                         f 0 (s− ) ≥         , for all s ∈ (0, s̄],
                                                         s
where f 0 (s− ) denotes the left Dini derivative of f at s. Because f ∈ C K,M together with
continuity of f implies that f is absolutely continuous, we can write that condition as

                                                     f (s)
                                         f 0 (s) ≥         , for a.e. s ∈ (0, s̄).           (B.18)
                                                       s

We first prove that under Assumption 1, all manipulators (Ri ≥ R) choose ŝi = s̄. We have

                  d                                   f (s)
                     (Rf (s) − γs) = Rf 0 (s) − γ ≥ R       − γ = s(Rf (s) − γs).
                  ds                                    s

This implies that if there exists any s > 0 at which a manipulator can make positive profits,
then that manipulator maximizes profits by choosing ŝi = s̄. This implies that the problem
to solve is                    ˆ    s̄
                       inf               f 2 (s)σU2 H(Rf )g(s)ds + f 2 (s̄)σM
                                                                            2
                                                                              (1 − H(Rf ))   (B.19)
                    f ∈C K,M    0
B Proofs                                                                                                                     52


subject to (B.18), and
                                                                   γ
                                                       f (s) ≤        s, ∀s ∈ [0, s̄],                                    (B.20)
                                                                   Rf
                         ˆ       s̄
                                                                                                              1
                                      f (s)H(Rf )g(s)ds + f (s̄)(1 − H(Rf )) =                                  .         (B.21)
                             0                                                                                n
Similarly as for the baseline model, we will parameterize the above problem by R = Rf , and
solve it first for any fixed R ≤ R̂.
   To simplify the objective function, note that
                                                                     ˆ     s̄
                                                      f 2 (s̄) = 2              f (s)f 0 (s)ds.
                                                                       0

Similarly, we can express condition (B.21) with R = Rf as
                                      ˆ    s̄                                             ˆ     s̄
                                                                                                                    1
                      H(R)                      f (s)g(s)ds + (1 − H(R))                             f 0 (s)ds =      .
                                       0                                                    0                       n

To incorporate condition (B.18) into the problem, we will redefine the control variable u(s)
relative to the baseline model. Instead of f 0 (s) = u(s), we let u(s) = f 0 (s)−f (s)/s. Constraint
(B.18) can now be expressed as u(s) ≥ 0. Thus, the full problem can be written as
                             ˆ        s̄                                                            
                                                 2                                              f (s)
                      min                    f       (s)σU2 g(s)   +          2
                                                                       2f (s)σM          u(s) +          ds               (B.22)
                      u≥0        0                                                                s

subject to

                                                        f (s)
                                      f 0 (s) = u(s) +        , f (0) = 0, f (s̄) − free                                  (B.23)
                                                         s 
                                                       f (s)                           1
       Γ0 (s) = H(R)f (s)g(s) + (1 − H(R)) u(s) +               , Γ(0) = 0, Γ(s̄) =                                       (B.24)
                                                         s                            n
                                                                                    γ
                                                                          f (s) ≤ s.                                      (B.25)
                                                                                    R

We conjecture that the constraint f (s) ≤ (γ/R)s is slack. We want to prove that the optimal
f is linear: f (s) = αs for some α ≤ γ/R. There exists a unique α under which a linear f
satisfies the constraint (B.21) (or B.24), namely, α = γ/R̂. Such f satisfies constraint (B.25),
and thus if it solves the relaxed problem, it also solves the original problem.
   The Hamiltonian corresponding to the relaxed problem (B.22) - (B.24) is
                                                                                             
                                 2                                                       f (s)
  H(f (s), u(s), s) = − f             (s)σU2 g(s)
                                       +                       2
                                                             2σM f (s)            u(s) +
                                                                                           s
                                                                            
                       f (s)                                              f (s)
     + p1 (s) u(s) +           + p2 (s) H(R)f (s)g(s) + (1 − H(R)) u(s) +          . (B.26)
                         s                                                  s
B Proofs                                                                                                 53


    We state sufficient conditions for a function f to be optimal, using Arrow’s Theorem.

Lemma 9 Let (f (s), u(s)) be a feasible pair for the problem (B.22) - (B.24). If there exists a
continuous and piecewise continuously differentiable function p(s) = (p1 (s), p2 (s)) such that
the following conditions are satisfied
                                                     
   1. p01 (s) = 2f (s)σU2 g(s) + 2σM
                                   2   u(s) + 2 f (s)   − p1 (s) 1s − p2 (s) H(R)g(s) + (1 − H(R)) 1s ;
                                                                                                     
                                                  s

   2. p02 (s) = 0;

   3. u(s) maximizes H(f (s), u, s) over u ≥ 0 for all s ∈ [0, s̄];

   4. p1 (s̄) = 0;

   5. Ĥ(f, s) = maxu∈[0, γ/R] H(f, u, s) exists and is concave in f for all s,

then (f (s), u(s)) solve the problem (B.22) - (B.24). If Ĥ(f, s) is strictly concave in f for all
s, then f is the unique solution.

Proof: By direct application of the Arrow Sufficiency Theorem (Theorem 5 on page 107 of
Seierstad and Sydsaeter, 1987). 

    Since we want to prove that f (s) = αs is optimal, we have u(s) = 0 for all s ∈ [0, s̄]. The
Hamiltonian is maximized at u = 0 across feasible u ≥ 0 when

                                2
                             −2σM f (s) + p1 (s) + p2 (s)(1 − H(R)) ≤ 0.

We can set p2 (s) = η for some constant η for all s (this will satisfy condition 2 of Lemma
9). The Hamiltonian is strictly concave in f . Thus, to satisfy all conditions of Lemma 9,
it is enough to prove that there exists a continuously differentiable p(s) (we abuse notation
slightly by dropping the subscript from p1 (s)) and a constant η such that

                                                                                    2
                                                             p(s) + η(1 − H(R)) ≤ 2σM αs,             (B.27)
                                                                      p(s̄) = 0,                      (B.28)
                           1                                                  1
              p0 (s) + p(s) = 2αsσU2 g(s) + 4σM
                                              2
                                                α − ηH(R)g(s) − η(1 − H(R)) ,                         (B.29)
                           s                                                  s

for all s ∈ [0, s̄]. Solving the ODE (B.29), we obtain
                        ˆ   s                                                               
               1
                              2ατ 2 σU2 g(τ )         2
                                                                                        
        p(s) =        κ+                        +   4σM ατ   − ηH(R)g(τ )τ − η(1 − H(R)) dτ       ,
               s         0
B Proofs                                                                                                                                                          54


for all s > 0, and some constant κ. With the final condition (B.28), we obtain
                                   ˆ   s̄ 
                      1
                                              2ατ 2 σU2 g(τ ) + 4σM
                                                                  2
                                                                                                  
             p(s) = −                                               ατ − ηH(R)g(τ )τ − η(1 − H(R)) dτ.
                      s            s

This means in particular that p(s) is well defined and continuously differentiable for all s ∈
(0, s̄]. To guarantee that we can define p(0) so that p(s) is continuous at s = 0, we need
                       ˆ    s̄ 
                               2ατ 2 σU2 g(τ ) + 4σM
                                                   2
                                                                                   
                                                     ατ − ηH(R)g(τ )τ − η(1 − H(R)) dτ = 0.                                                              (B.30)
                        0

Condition (B.30) is also sufficient: By d’Hosptial rule, if (B.30) holds, then the limit lims&0 p(s)
exists and is finite. Condition (B.30) pins down a unique candidate for η:
                                                              ´ s̄                        2 ατ dτ
                                                                       2ατ 2 σU2 g(τ ) + 4σM
                                                                                               
                                               η = ´ s̄          0
                                                                                                                     .
                                                             0   [H(R)g(τ )τ + (1 − H(R))] dτ

With η defined this way, and after simplifying the expressions, (B.27) becomes equivalent to
         ´ s̄  2 2        2
                                                                ˆ          s̄                                           
          0 τ σU g(τ ) + 2σM τ dτ
  ´ s̄                                                                            τ H(R)g(τ )dτ + (1 − H(R))s̄
   0     [H(R)g(τ )τ + (1 − H(R))] dτ                                    s
                                                                                                                                     ˆ   s̄
                                                                                                                          2 2
                                                                                                                     ≤   σM s̄   +            τ 2 σU2 g(τ )dτ,
                                                                                                                                     s

for all s ∈ [0, s̄]. Equivalently, after some simplifications,
           ˆ     s̄                ˆ        s                      ˆ s         
  H(R)                 τ g(τ )dτ                   τ 2 σU2 g(τ )dτ
                                                       + (1 − H(R))s̄      τ 2 σU2 g(τ )dτ
              0                      0
                                               ˆ s                  ˆ 0s̄                 ˆ                                                s               
                              2              2                              2 2
                           ≤ σM (1 − H(R))s̄       τ g(τ )dτ + H(R)        τ σU g(τ )dτ                                                           τ g(τ )dτ       ,
                                                                     0                                     0                              0

for all s ∈ [0, s̄]. Because the above expression is linear in H(R), and R does not appear
anywhere else in the expression, it is enough to show that it holds for both H(R) = 0 and
H(R) = 1. That is, it is enough to show that
                                                         ´ s̄                                ´s
                                                                 τ g(τ )dτ  τ g(τ )dτ
                                                    ´ s̄ 0 2        ≤ ´ s 02 2        ,                                                                  (B.31)
                                                                       0 τ σU g(τ )dτ
                                                          2
                                                     0 τ σU g(τ )dτ

and                                                ˆ     s                                   ˆ   s
                                                             τ 2 σU2 g(τ )dτ          ≤ s̄              2
                                                                                                     τ σM g(τ )dτ,                                       (B.32)
                                                     0                                       0

for all s ∈ [0, s̄]. Inequality (B.32) is clearly true because σU2 < σM
                                                                      2 by assumption. To prove
B Proofs                                                                                        55


inequality (B.31), it is enough to show that
                                           ´s
                                              τ g(τ )dτ
                                         ´s 0 2
                                             2
                                          0 τ σU g(τ )dτ

is decreasing in s. By calculating the derivative, we can show that a sufficient condition is
´s
 0 [τ − s] τ g(τ )dτ ≤ 0 for all s, which is clearly satisfied. This ends the proof that conditions
(B.27) – (B.29) all hold.
   Therefore, all conditions of Lemma 9 also hold, and thus we have proven that f (s) =
(γ/R̂)s is the unique solution to the relaxed problem (B.22) - (B.24) for any R ≤ R̂, and
hence also the problem (B.22) - (B.25). It follows that the same f solves the problem P and
P(R) for any R ≤ R̂.
