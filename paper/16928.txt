                                 NBER WORKING PAPER SERIES




    EFFICIENT ESTIMATION OF DATA COMBINATION MODELS BY THE METHOD
                   OF AUXILIARY-TO-STUDY TILTING (AST)

                                           Bryan S. Graham
                                   Cristine Campos de Xavier Pinto
                                             Daniel Egel

                                         Working Paper 16928
                                 http://www.nber.org/papers/w16928


                       NATIONAL BUREAU OF ECONOMIC RESEARCH
                                1050 Massachusetts Avenue
                                  Cambridge, MA 02138
                                       April 2011


We would like to thank David Card, Stephen Cosslett, Jinyong Hahn, Michael Jansson, Patrick Kline,
Richard Smith, Tom Rothenberg, and members of the Berkeley Econometrics Reading Group for helpful
discussions. We are particularly grateful to Gary Chamberlain, Guido Imbens, Justin McCrary, Geert
Ridder, Enrique Sentana and Leonard Stefanski for detailed comments on earlier drafts. This draft
has benefited from comments by the co-editor, associate editor and three anonymous referees. We
thank Jing Qin and Biao Zhang for assistance in replicating the Monte Carlo designs in Qin and Zhang
(2008). We also acknowledge feedback and suggestions from participants in seminars at the University
of Pittsburgh, Ohio State University, University of Southern California, University of California -
Riverside, University of California - Davis, University of Maryland, Georgetown University, Duke
University, University of California - Berkeley, CEMFI (Madrid), Pontifícia Universidade Católica
do Rio de Janeiro and the 2013 North American Summer Meeting of the Econometric Society. Preliminary
portions of the current paper previously appeared in Section 4 of an early draft of the NBER Working
Paper 'Inverse probability tilting and missing data problems.' The published version of that paper excludes
the material reported here. A supplemental appendix with proofs and additional details regarding computation
may be found on the first author's web page. All the usual disclaimers apply. The views expressed
herein are those of the authors and do not necessarily reflect the views of the National Bureau of Economic
Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2011 by Bryan S. Graham, Cristine Campos de Xavier Pinto, and Daniel Egel. All rights reserved.
Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided
that full credit, including © notice, is given to the source.
Efficient Estimation of Data Combination Models by the Method of Auxiliary-to-Study Tilting
(AST)
Bryan S. Graham, Cristine Campos de Xavier Pinto, and Daniel Egel
NBER Working Paper No. 16928
April 2011, Revised April 2015
JEL No. C01,C14,J31,J7

                                           ABSTRACT

We propose a locally efficient estimator for a class of semiparametric data combination problems. A
leading estimand in this class is the Average Treatment Effect on the Treated (ATT). Data combination
problems are related to, but distinct from, the class of missing data problems analyzed by Robins,
Rotnitzky and Zhao (1994) (of which the Average Treatment Effect (ATE) estimand is a special case).
Our estimator also possesses a double robustness property. Our procedure may be used to efficiently
estimate, among other objects, the ATT, the two-sample instrumental variables model (TSIV),
counterfactual distributions, poverty maps, and semiparametric difference-in-differences. In an
empirical application we use our procedure to characterize residual Black-White wage inequality
after flexibly controlling for 'pre-market' differences in measured cognitive achievement as in Neal
and Johnson (1996).


Bryan S. Graham                                   Daniel Egel
University of California - Berkeley               Institute on Global Conflict and Cooperation
530 Evans Hall #3880                              (IGCC)
Berkeley, CA 94720-3880                           University of California - San Diego
and NBER                                          9500 Gilman Drive, MC 0518
bgraham@econ.berkeley.edu                         La Jolla, CA 92093-0518
                                                  degel@ucsd.edu
Cristine Campos de Xavier Pinto
Escola de Economia de São Paulo, FGV/SP
Rua Itapeva 474, sala 1200
São Paulo– SP, Brasil, 01332-000
cristinepinto@gmail.com




A data appendix is available at:
http://www.nber.org/data-appendix/w16928
1     Introduction

Let  = ( 0   0   0 )0 denote a random vector drawn from some study population of interest
with distribution function   For some unique                   0,   and known function          ( ) of the same
dimension, we assume that
                                                 E [ (       0 )]   = 0                                       (1)

where E [ ] denotes expectations taken with respect to the study population. If a random
sample of  is available, then consistent estimation of                          0   (under regularity conditions) is
straightforward (e.g., Newey and McFadden, 1994). Many statistical models of interest can
be represented in terms of moment restrictions like (1); see Wooldridge (2002) for a textbook
exposition.
    In this paper we consider estimation of                 0   when a random sample of  is unavailable.
Instead two separate samples are available. The …rst is drawn from the study population
and contains  measurements of (  )  The second is drawn from an auxiliary popula-
tion (with distribution function  ; E [ ] denotes expectations taken with respect to this
distribution) and contains  measurements of (  )  While the variable  is common
to the two samples,  and  are not. Hahn (1998) and Chen, Hong and Tarozzi (2008)
show that identi…cation of        0   follows if (i) the conditional distributions of  given  in the
two populations coincide (although their marginal distributions for  may di¤er), (ii) the
support of  in the auxiliary population is at least as large as that in the study population
and (iii)     (   0)   is separable in the components depending on the ‘non-common’variables
 and 
                                 (    0)   =       (     0)     ¬      (    0)                       (2)

    Examples of statistical problems to which the above setup applies include the two sample
instrumental variables (TSIV) model of Angrist and Krueger (1992) and Ridder and Mof-
…tt (2007), the average treatment e¤ect on the treated (ATT) estimand from the program
evaluation literature (e.g., Heckman and Robb, 1985; Imbens, 2004), counterfactual earn-

                                                           1
ings/wealth decompositions as in Dinardo, Fortin and Lemieux (1996) and Barsky, Bound,
Charles and Lupton (2002), poverty mapping as in Elbers, Lanjouw and Lanjouw (2003) and
Tarozzi and Deaton (2009), direct standardization methods used in demography (e.g., Kita-
gawa, 1964), and models with mismeasured regressors and validation samples (e.g., Carroll
and Wand, 1991).
   To help …x ideas consider the ATT example. Here  denotes an individual’s potential
outcome under active treatment, say earnings given participation in a job training program,
 denotes her outcome under control (earnings in the absence of training) and  is a vector
of baseline covariates. Available is a random sample of (  ) from the population assigned
active treatment (i.e., ‘the treated’). A separate sample of measurements of (  ) is drawn
from a population of controls. The ATT,               0   = E [ ¬ ], is given by the solution to (1)
with      (    0)   =  and      (    0)   =+      0.

   Dehejia and Wahba (1999), revisiting earlier work by LaLonde (1986), combine two
distinct samples to estimate the e¤ect of the National Supported Work (NSW) demonstra-
tion, a labor training program, on the post-intervention earnings of trainees. Their study
sample consists of 185 NSW participants, while their auxiliary sample includes 2,490 non-
participants drawn from the Panel Study of Income Dynamics (PSID). These two samples
consist of random draws from distinct, non-overlapping, populations. The two sample feature
of their analysis distinguishes it from one seeking to estimate a population average treatment
e¤ect (ATE). In that case the researcher generally bases her analysis on a random sample
from the population of interest, where some units happen to be treated, and others not (e.g.,
Rosenbaum and Rubin, 1983). There the inferential problem is usefully conceptualized as
one of missing data and the general theory of Robins, Rotnitzky and Zhao (1994) directly
applies.


Relationship between data combination and missing data problems One perspec-
tive is that data combination problems are nothing more than a particular class of “missing



                                                          2
data”problems in which the auxiliary sample is collected independently, and from a di¤erent
population than that, of the study sample. Our use of the term missing data is more tech-
nical, referring, in particular, to the family of problems analyzed by Robins, Rotnitzky and
Zhao (1994, Section 8.1). In this family both the study and auxiliary samples are random
ones from the population of interest. It turns out that this di¤erence has statistical content
with, as we emphasize here (and others have before us), implications for estimator formula-
tion and properties. In an important paper Hahn (1998) showed that while prior restrictions
on the form of the propensity score do not lower the semiparametric variance bound for
the ATE, they do lower the corresponding bound for the ATT. Chen, Hong and Tarozzi
(2008) generalize this result, showing that, unlike in the missing data context (their ‘verify-
in-sample’case), knowledge of the form of the propensity score is asymptotically valuable in
data combination problems (their ‘verify-out-of-sample’case).
   Our contribution is to develop a ‡exible parametric estimator for general data combi-
nation problems with good e¢ ciency and robustness properties. Similar to the augmented
inverse probability weighting (AIPW) estimator for missing data problems due to Robins,
Rotnitzky and Zhao (1994), our data combination procedure is locally e¢ cient and pos-
sesses a double robustness property. This latter property, given the non-ancillarity of the
propensity score in the data combination problem, is surprising.
   To our knowledge we are the …rst to propose a locally e¢ cient estimator in the data
combination context. Chen, Hong and Tarozzi (2008) propose a globally e¢ cient estimator,
but their procedure requires nonparametric modelling as opposed to the ‡exible parametric
approach adopted here. Our methods provide a practical alternative to theirs when  is high
dimensional (cf., Firpo and Rothe, 2013). Abadie (2005) develops a parametric propensity
score reweighting (PSR) estimate of the ATT. Qin and Zhang (2008) show that Abadie’s
estimator can have low e¢ ciency in some settings and propose an alternative that uses
empirical likelihood ideas. Qin and Zhang (2008) do not characterize the semiparametric
e¢ ciency or robustness properties of their ATT estimator, nor show how to extend it to


                                              3
the wider class of problems considered here. Hirano and Imbens (2001) also propose a type
of propensity score reweighting estimator for the ATT. Their estimator exhibits a double
robustness property, but they do not consider issues of semiparametric e¢ ciency nor general
data combination problems as we do. Besides its robustness and e¢ ciency properties, our
estimator is simple to compute and is suitable for many applied problems, like the estimation
of the ATT, two sample instrumental variables and others cited above.
    In Section 2 we de…ne the semiparametric data combination model. Modestly extending
the work of Chen, Hong and Tarozzi (2008) we calculate the semiparametric e¢ ciency bound
for our model. We relate our e¢ ciency bound analysis to prior work on distribution function
estimation based on a random sample from the population of interest and a second, biased,
sample from the same population (e.g., Qin, 1998; Gilbert, Lele, Vardi, 1999). This discussion
motivates the form of our AST estimator, which we introduce in Section 3, where we also
formally characterize its large sample properties. Our key results are Theorems 3.1 to 3.3
below. Section 4 provides an illustrative empirical application and reports on the results of
several Monte Carlo experiments. Proofs of our main results are contained in the Appendix.
The Supplemental Web Appendix contains additional proof details, extra examples of data
combination problems, and additional Monte Carlo results. An algorithm for computing our
estimator, that we have found to work well in practice, is also described in the Supplemental
Web Appendix.



2     Semiparametric data combination model

A formal de…nition of the data combination model is given by Assumption 2.1 below. Let
 b R denote a compact subset of R 


Assumption 2.1 Semiparametric Data Combination Model
(i) (Identification) For some         ( ) =      (  ) ¬      (  ), equation (1) holds with
E [ ( )] 6= 0 for all   6=   0   2 G b R ,  2 Z b Rdim() ;


                                                4
(ii) (Conditional Distributional Equality)  ( j ) =  ( j ) and  ( j ) =
 ( j ) for all  2 W b Rdim( )   2 X b Rdim() and  2 Y b Rdim( ) ;
(iii) (Weak Overlap) Let  = f :  ()  0g for  =  , then                          ;
(iv) (Multinomial Sampling) With probability 0 2 (  1 ¬ ) for 0                                  1 we draw
a unit at random from  and record its realizations of  and  , otherwise we draw a
unit at random from  and record its realizations of  and  Let  = 1 if the  draw
( = 1      ) corresponds to a study population unit and  = 0 otherwise;
(v) (Propensity score model) There is a unique                       0   2 D b Rdim( )  known vector  ( )
of linearly independent functions of  with a constant in the …rst row, and known function
 ( ) such that (a)  ( ) is strictly increasing, di¤erentiable and maps into the unit interval
                                                       ()       1¬0 (()0 0 )
with lim  () = 0 and lim  () = 1, (b)              ()
                                                               =    0 1¬(()0 0 )
                                                                                       for all  2 W, and (c)
     !¬1                  !1

0   (()0 )       1 for all      2 D and  2 W.


   The …rst part of Assumption 2.1 implies global identi…ability of the complete data model.
The second part implies that the distributions of (  ) and (  ) in the two populations
di¤er only in terms of their marginal distributions for the always measured variable,  .
The third part ensures that, in large samples, for each unit in the study sample there will
be matching units with similar values of  in the auxiliary sample. The fourth part of
Assumption 2.1 allows us to treat the merged sample


                                                                         0 
                                  (   0 (1 ¬  ) 0   0 )     =1
                                                                                 


‘as if’it were a random one from a pseudo merged population with distribution function 
(let E [ ] denote expectations taken with respect to this distribution). The semiparametric
data combination model is typically de…ned by specifying properties of the merged popu-
lation (e.g., Hahn, 1998; Chen, Hong and Tarozzi, 2008). We prefer the formulation given
above because it (i) emphasizes that the problem is fundamentally one of combining two
datasets and (ii) in many applications the merged population does not correspond a real


                                                      5
world population. Neither (i) or (ii) are features of standard missing data problems (i.e.,
Robins, Rotnitzky and Zhao (1994)). We also note that formulating a model by imposing
restrictions on a pseudo-population is somewhat awkward (cf., the discussion in Abadie and
Imbens (2006, p. 239)).
   The sampling distribution induced by the multinomial scheme,  , has density


                             ( ) = 0 (1 ¬ 0 )1¬  ()  ()1¬ 


such that  ( j  = 1) =  () and  ( j  = 0) =  ()  Now consider the conditional
probability given  =  that a unit in the merged sample corresponds to a draw from
the study population. Let E[j  = ] = 0 () denote this ‘propensity score’, by Bayes’
Law we can de…ne a relationship between the study and auxiliary densities of  in terms of
0 ()
                                                 1 ¬ 0 0 ()
                               () =  ()                                                     (3)
                                                   0 1 ¬ 0 ()

Under the merged population formulation of the problem it is clear that part (i) of As-
sumption 2.1 corresponds to requiring that E [ (          0 )j    = 1] = 0 part (ii) to conditional
independence restrictions on the merged population distribution function of  ( j   = 1) =
 ( j   = 0) and  ( j   = 1) =  ( j   = 0)  and parts (iii) and (iv) to assuming
that 0 () is bounded away from one. Part (v) implies that the density ratio  ()  ()
takes a parametric form or, equivalently, that the propensity score is known up to a …nite
dimensional parameter.
   Identi…cation of   0   follows from, using parts (ii) and (iii) of Assumption 2.1 and Equation
(3), the equality

                                                       1 ¬  0 ( )
          E [ ( )] = E              (  ) ¬ E                              (  )       (4)
                               0                         0 1 ¬ 0 ( )




                                                  6
which is, by part (i) of Assumption 2.1, uniquely zero at           =    0    See Lemma 3.1 of Abadie
(2005) for a formal proof.


2.1    Example: Two sample instrumental variables (TSIV)

To give some idea of the range of problems to which our methods apply, we elaborate on
one common data combination problem in detail: the two sample instrumental variable
model (TSIV). This model is widely used by empirical researchers in economics (cf., Inoue
and Atsushi, 2010). Our observation that TSIV is a special case of the model de…ned by
Assumption 2.1 is a new one, with empirically relevant implications. In particular, the
Auxiliary-to-Study (AST) estimator we propose below is both (i) more e¢ cient and (ii)
consistent under a wider, and empirically relevant, set of assumptions, than, for example,
the estimators of Angrist and Krueger (1992) and Ridder and Mo¢ tt (2007).
   Additional examples of data combination problems are outlined in the Supplemental Web
Appendix. Chen, Hong and Tarozzi (2008), Ridder and Mo¢ tt (2007) and Abadie (2005)
provide further examples.
   Following Ridder and Mo¢ tt (2007), consider two sample instrumental variables (TSIV)
models of the form
                             E [f ( ; ) ¬  ( 1 ; )g  ( )] = 0

with  = (00  10 )0 . The …rst sample consists of measurements of (  ) and the second of
(  ). They assume that both samples are random ones from the study population (i.e.,
the samples are ‘compatible’). This corresponds to augmenting Assumption 2.1 with the
additional requirement that  () =  ()  The TSIV model is of the form required by (2)
with      (  ) =  ( ; )  ( ) and      (  ) =  ( 1 ; )  ( ). When  ( ) =  ,
                                                                         0 0
 ( ; ) =  and  ( 1 ; ) =  0 + 10           with   0   =(   0   0)    we have the linear model
analyzed by Angrist and Krueger (1992). Ridder and Mo¢ tt (2007) show how one may
estimate the Mixed Proportional Hazard (MPH) model under this setup, while Ichimura



                                                   7
and Martinez-Sanchis (2004) discuss binary choice models.
     A concrete example of a TSIV problem is provided by the work of Currie and Yelowitz
(2000), who consider the model E [ ( ¬  0       0   ¬ 10   0 )]   = 0 where  is an indicator for
whether a school-aged child has repeated a grade,  an indicator for residence in public
housing, 0 equals the number of male siblings in the household, and 1 equals the overall
number of siblings and also contains other household characteristics;  = (00  10 )0 . Their
interest centers on the causal e¤ect of residence in public housing on human capital acqui-
sition. The number of male siblings changes the probability of residence in public housing
since, conditional on the overall number of siblings, families with a mixture of boys and girls
qualify for larger units and hence higher (implicit) housing subsidies. Currie and Yelowitz
(2000) additionally argue that, conditional on the total number of one’s siblings, their gen-
der mix should not in‡uence schooling independently of any e¤ect mediated by exposure to
public housing. Hence 0 may serve as an instrumental variable for .
     Currie and Yelowitz (2000) observe  and  for a random subsample of children drawn
from the US Census. The Census, however, does not collect information on residence in
public housing, . This information is available in the US Current Population Survey
(CPS), which also includes measurements of  (but not  ). They treat both the Census
and CPS samples as random ones from their study population (school-aged children living
in the United States) and use a variant of Angrist and Krueger’s (1992) method to estimate
               0 0
 0   =(   0   0)    
     In applications of the TSIV model, like Currie and Yelowitz’s (2000), it is often found that
the sample moments of the common variables  di¤er signi…cantly across the two datasets
being combined (see also Björkland and Jäntti, 1997). This suggests that full compatibility
may fail in practice (i.e.,  () 6=  ()). The estimator presented below does not require
full compatibility and is generally more e¢ cient than the one proposed by Angrist and
Krueger (1992) (compare Theorems 3.1 and 3.2 below with Angrist and Krueger (1992, p.
331) or Ridder and Mo¢ tt (2007, p. 5505)).


                                                8
2.2      E¢ ciency bound

Hahn (1998, Theorem 1) calculated the semiparametric variance bound for the special case
where     0   is the ATT and part (v) of Assumption 2.1 is not part of the prior restriction.
Chen, Hong and Tarozzi (2008, Theorem 3) include part (v) in their prior, but assume that

    (  ) = 0. The following result generalizes that of Chen, Hong and Tarozzi (2008) to
the case where the moment function is of the form given in (2). To present this result we
require some additional notation. Let E [ j ] denote the mean squared error minimizing
linear predictor of  given  and de…ne

                            (        0)
         ¬0 () = E                           =                ¬0 = E [¬0 ( )]           0 () =  (()0 0 )
                              0
               () = E [        (         0 )j    = ]         () = E [         (    0 )j    = ]

            (;   0)   = V(      (     0 )j        = )            (;   0)   = V(       (    0 )j    = )
                                          ¬  (( )0 0 )
                         S =                                         1 (( )0 0 ) ( )
                                    (( )0 0 ) [1 ¬  (( )0 0 )]

with 1 () =  ()  and

                                             2
                               0 ( )               ( ; 0 )      ( ; 0 )
               ( ) =                                          +                                                             (5)
                                 0                  0 ( )     1 ¬ 0 ( )
                           + [ ( ) ¬  ( )] [ ( ) ¬  ( )]0
                                                             0 ( ) f ( ) ¬  ( )g 0
                           +E                  ¬1                                         S
                                       0 ( )                             0
                                                                                                                     0
                                        0 ¬1                            0 ( ) f ( ) ¬  ( )g 0
                               E [S S ]          E                ¬1                                S                    
                                                          0 ( )                     0

Theorem 2.1 (Semiparametric Variance Bound) Under Assumption 2.1 (i) the max-
imal asymptotic precision with which                       0   may be regularly estimated is given by the inverse




                                                                   9
of I ( 0 ) = ¬00 E [ ( )]¬1 ¬0 and (ii) the e¢ cient in‡uence function is

                                       
           e
               (   0)   = ¬¬¬1          f (  0 ) ¬  ( )g
                              0
                                      0 
                              1 ¬  0 ( )
                            ¬                    f (  0 ) ¬  ( )g
                                0 1 ¬ 0 ( ) 
                              0 ( )
                            +         f ( ) ¬  ( )g
                                0
                               1           
                            + E                 ¬ 1 0 ( ) f ( ) ¬  ( )g S         (6)
                              0        0 ( )

Proof. The proof, which involves a modest extension of the analysis of Chen, Hong and
Tarozzi (2008, Theorem 3), is in the Supplemental Web Appendix.
   It is easy to show that the information bound for         0   is smaller in the model which
leaves 0 ( ) nonparametric (i.e., where part (v) of Assumption 2.1 is not part of the prior).
Knowledge of the parametric form of the propensity score increases the large sample precision
with which     0   may be estimated. In contrast, in semiparametric missing data problems it
is well-known that parametric restrictions on the propensity score do not shift the e¢ ciency
bound (e.g., Robins, Rotnitzky and Zhao, 1994; Hahn, 1998). The value of prior restrictions
on the propensity score distinguishes the data combination problem from the missing data
one.
   To understand this di¤erence, we use the well known result that a biased sample may be
combined with a random one to form a more e¢ cient distribution function estimate as long
as the biasing function is known or parametrically speci…ed. Parts (v) of Assumption 2.1
implies that we can view the auxiliary sample as a biased sampled from the study population
of interest where the biasing function is known up to a …nite dimensional parameter (cf.,
Qin, 1998; Gilbert, Lele and Vardi, 1999; Ridder and Mo¢ tt, 2007).
   Here, and in what follows, we assume without loss of generality that the merged sample is
arranged such that its …rst  units correspond to study population draws, and its remaining
 units to auxiliary sample draws. Let (()0b  ) denote the conditional maximum



                                               10
likelihood estimate of the propensity score (based on the merged sample), then the estimate

                               
                               X                                (( )0b  )
                  be () =         be 1 (   )    be = P                             (7)
                                                                           0b
                               =1                             =1 (( )   )


e¢ ciently uses the information in both the study and auxiliary samples to estimate  ().
To understand (7) note that Bayes’law gives  ( ) =  (  j  = 1) = 0 ( )  ( ) 0 ;
replacing 0 ( ) and 0 with their maximum likelihood estimates, and  ( ) with the
empirical measure of the merged sample, 1 , gives b ( ) = be , for be de…ned in (7).
Equation (7) uses both study and auxiliary units – linked via a parametric form for the
propensity score –to e¢ ciently estimate  () 
      In contrast, in missing data problems the population of interest corresponds to what we
have termed the merged population. The most e¢ cient estimate of the merged population
distribution function of  is the merged sample empirical distribution function. This is true
irrespective of the form of the propensity score. This provides one intuition for why prior
knowledge of the form of the propensity score is not valuable in the missing data context
(cf., Graham, 2011).



3       Auxiliary-to-Study Tilting

In this section we present our Auxiliary-to-Study Tilting (AST) estimator and characterize its
large sample properties under di¤erent sets of assumptions. Since the parameter of interest,

 0   involves integration over the study population distributions of (  ) and (  ), these
two distribution functions must be (implicitly) estimated in order to estimate      0.   The AST
estimator utilizes distribution function estimates that share a …nite number of moments of
 in common with be (). That is we calibrate our estimates of the study population
distributions of (  ) and (  ) to features of (7) (which is a semiparametrically e¢ cient
estimate of  () when the propensity score takes a parametric form). This, as we explain
below, is the source of the e¢ ciency gains associated with our procedure.

                                                   11
   The idea of calibrating a distribution function estimate to information garnered from
auxiliary sources arises in other contexts. Little and Wu (1991) discuss contingency table
calibration to known margins and provide historical references (cf., Hellerstein and Imbens,
1999). Bickel, Ya’Acov and Wellner (1991) study estimation of linear functionals of proba-
bility measures with known marginals. Hirano, Imbens, Ridder and Rubin (2001) show how
calibration to marginal information from refreshment samples may be used to correct for
certain types of nonignorable attrition in panel data. In the context of average treatment
e¤ect estimation, Tan (2006) calibrates estimates of the two potential outcome distributions
to features of the empirical distribution of always observed variables (cf., Qin and Zhang,
2007; Graham, Pinto and Egel, 2012). Recently Cheng, Small, Tan, and Ten Have (2009)
apply related ideas to an instrumental variables model.


3.1    Outline of the AST estimator

Our estimator for           0,   which we call the auxiliary-to-study tilting (AST) estimator, is a
sequential method of moments estimator. In the …rst step we estimate the propensity score
parameter    by conditional maximum likelihood:


         1 X
                      ¬   ( )0 b 
                             h                   i 1  ( )0 b   ( ) = 0                   (8)
          =1   ( )0 b                  0b
                               1 ¬   ( )  
                         



   In the second step we compute a reweighting of both the study and auxiliary samples.
Let  ( ) be vector of known linearly independent functions of  with a constant 1 in the
…rst row and         and           be ‘tilting’parameters of the same dimension. We allow for  ( )
and  ( ) to include common elements or even coincide. Fixing               at b  and  at 
                                                                                              b  we

choose b to solve:

                  0                                              1
        1
            
            X                  1  ¬                     ( )0 b 
                  @                  
                                                  ¬ 1A                  ( ) = 0                (9)
                                0b            0b
                    1 ¬   ( )   +  ( )            b
                                                              
            =1




                                                        12
To understand this method of choosing b its helpful to rearrange (9) to get

          
       1 X 1 ¬        ( )0 b   ( )                                     0b
                                                                      1 X   ( )    ( )
                                                                    =                           (10)
             b  1 ¬   ( )0 b +  ( )0 b
        =1                                                          =1       b 
                                                                                  
                                          

                                              
                                              X                        
                                                                       X
                                                   b  ( ) =              be  ( ) 
                                         = +1                       =1


for

                   ( )0 b                      1
        b   = P                                                                    =  + 1     
                     ((    ) 0b   )             0b            0b
                 =1               1 ¬   ( )   +  ( ) 



and where the second line of (10) is equivalent to the …rst. The term to the right of the
equality in (10) is an estimate of E [ ( )] –the study population mean of  ( ) –based
on the e¢ cient distribution function estimate (7). It is consequently an e¢ cient estimate of
E [ ( )]  The solution to (9) –our estimate of  –is chosen to form a reweighting of the
                              P  
auxiliary sample such that      =1 b  ( ) is numerically identical to the e¢ cient estimate of

E [ ( )] based on be ().
      To better understand (10) recall that, as shown by Abadie (2005) and others, the propen-
sity score reweighting type estimator

                                                 0b
                            1 X 1 ¬    ( )  
                               
                b PSR
                 ( ) =                              1 (                               ) 
                                  b  1 ¬   ( )0 b
                             =1 
                                                     



is consistent for the study population distribution function of (  ). Our AST estimator
replaces bPSR ( ) with the more e¢ cient tilted version

                                               
                                               X
                            bAST ( ) =             b 1 (             ) 
                                              = +1



This tilted distribution estimate, unlike bPSR ( ), is guaranteed to integrate to one and


                                                        13
shares a …nite number of moment in common with be () 
      We also compute an analogous tilt of the study sample

                  0                             1
             1 X
                                                   ( )0 b 
                  @              
                                             ¬ 1A                  ( ) = 0                                           (11)
              =1   ( )0 b +  ( )0 b             b 
                                                       
                                       



so that
                                            
                                            X                        
                                                                     X
                                                   b  ( )   =         be  ( )                                  (12)
                                             =1                     =1

for
                        ( )0 b                 1
             b   = P                                                                            = 1      
                                  0b              0b            0b
                      =1 (( )   )   ( )   +  ( ) 


      With the auxiliary and study sample tilts in hand we then choose b to solve, holding
b and b …xed at their second step values,

                       
                       X                                         
                                                                 X
                             b      (    b ) ¬                 b      (    b ) = 0              (13)
                       =1                                   = +1



      Inspection of (13) indicates that our estimate of                          0   is based on two separate estimates of
the study population distribution function. The …rst, corresponding to the study tilt fb g 
                                                                                            =1

is an estimate of the study population distribution of (   ), the second, corresponding
to the auxiliary tilt, fb g
                             = +1 , is an estimate of the study population distribution of the

(   ). Neither of these two estimates coincide with the e¢ cient estimate of the study
population distribution of  alone (i.e, with (7)), but they do share important features
with it. Speci…cally they are constructed so that the means of  ( )  computed using the
two tilts, coincide with the e¢ cient estimate.


3.2       Large sample properties

Our next three results provide formal descriptions of the asymptotic sampling properties of
b under di¤erent combinations of assumptions. We begin with a characterization of the

                                                                 14
                         p
sampling properties of        (b ¬         0)   under our baseline model (i.e., Assumption 2.1). We
then outline our local semiparametric e¢ ciency and double robustness results.
   To state our …rst result we require some additional notation. Let


                               ( ) =          ( )          ( ) =       ( ) 




be weighted projections of           (    0)   and         (    0)   onto the space spanned by  ( ) 
with projection coe¢ cients of

                                  ¬
                        = E 1  ( )0 0  ( )  ( )0
                                    ¬                       ¬1
                             E 1  ( )0 0  ( )  ( )0     
                                 0 ( )      ¬
                        = E               1  ( )0 0  ( )  ( )0
                               1 ¬ 0 ( )
                                                                                               ¬1
                                   0 ( )      ¬
                             E               1  ( )0 0  ( )  ( )0                                   (14)
                                 1 ¬ 0 ( )

Also de…ne  (  ) =  (  ) ¬  (  ) with

                             1             
         (  ) =                            ¬ 1 0 ( ) f ( ) ¬  ( )g                             (15)
                             0         0 ( )
                                            
                             ¬E                  ¬ 1 0 ( ) f ( ) ¬  ( )g S
                                         0 ( )
                             1             1¬
         (  ) =                                ¬ 1 0 ( ) f ( ) ¬  ( )g                         (16)
                             0         1 ¬ 0 ( )
                                            1¬
                             ¬E                      ¬ 1 0 ( ) f ( ) ¬  ( )g S                  
                                         1 ¬ 0 ( )

Theorem 3.1 (Asymptotic Distribution) Suppose that Assumption 2.1 and additional
                                                      
regularity conditions hold, then (i) b !                 0   (ii)

                         p                            ¬
                              (b ¬         0)   ! N 0  ( 0 )¬1 +              ( 0) 




                                                            15
with
                                                                 0
                               ( 0 ) = ¬¬1                       ¬10
                                          0 E  (  )  (  ) ¬0

                                                p
and (iii) the asymptotic e¢ ciency of                0 (b ¬         0 ),   for any vector of constants , is
bounded below by

              p                                                   0  ( 0 )¬1 
         ae        0 (b ¬   0)                                h             i ¬           ¬ ¬1        0
                                                                                                                      (17)
                                             0  ( 0 )¬1  + 2 E 1¬ 0 ( )
                                                               2

                                                                          0 ( )
                                                                                  0 ¬¬1
                                                                                      0         ¬0             
                                                                     0




where   = max (    ) with


                  = sup k () ¬           ()k1              = sup k () ¬         ()k1   
                     2W                                              2W



and k k1 denoting the maximum absolute row sum norm.


   Theorem 3.1 indicates that under Assumption 2.1 our AST estimator is consistent and
asymptotically normal, but ine¢ cient relative to a semiparametrically e¢ cient estimator (cf.,
Theorem 2.1 above). Some insight into the degree of AST’s ine¢ ciency is provided by the
                                      2
bound (17). First, the term,              , indicates that the AST estimator performs better when
 () and  () are well-approximated by a linear combination of the elements of  () 
We discuss the nature of this approximation further below. Second, the performance of the
AST estimator will, in general, be sensitive to the degree of overlap. If the expected value of
the propensity score weight, 0 ( )  (1 ¬ 0 ( )), used to reweight auxiliary units is large,
as may be true if ; the upper bound on 0 ( ), is close to one (cf. part (v) of Assumption
2.1), then the performance of the AST estimator may be poor (cf., Khan and Tamer, 2010).
   More generally the form of  (  ) indicates that the relative e¢ ciency of b depends
on the quality of the linear approximations  ( ) '                       ( )   and  ( ) '          ( ).   This
is easiest to see in the special case where  ( )                   ( ), in which case (see (31) in Appendix
A), de…ning  =  ( ) ¬          ( )      =  ( ) ¬              ( )   and  = (1 ¬ 0 ( ))  +



                                                           16
0 ( )  :
                                                   1 ¬1     0 ( )
                                       ( 0) =       ¬ E
                                                    2 0
                                                                                      0
                                                                                            ¬¬10
                                                                                             0 
                                                   0     1 ¬ 0 ( )

so that the degree of ine¢ ciency depends on a (weighted) expectation of the squares and
cross products of a linear combination of the approximation errors. The form of                                         ( 0)
indicates that b will have high relative e¢ ciency whenever  ( ) and  ( ) are well
approximated by a linear combination of the elements of  ( )  This will be particularly
                                                                        0 ( )
true when overlap is good such that the weight                         1¬0 ( )
                                                                                   does not take on extreme values.
     Our next result, which characterizes when b will be e¢ cient, is anticipated by the
discussion above. Consider the assumption:


Assumption 3.1 (Moment CEF) For some unique pair of matrices                                                 and vector of
linear independent functions  ( ) with a constant in the …rst row, we have


                  E[      (    0 )j  ]   =       ( )     E[        (    0 )j  ]   =     ( ) 




     Assumption 3.1 posits a working model for the conditional expectation functions (CEFs)
of      (    0)   and       (     0)     given  . The substantive content of this assumption is,
of course, model and application speci…c. The ATT example discussed in the introduction
provides a simple illustration. In that case Assumption 3.1 implies that the CEFs of the
potential outcomes given active and control treatment,  and , are linear in  ( ). Thus,
if the object of interest is the ATT, the analyst should pick the elements of  ( ) so as to
provide a good approximation to these two CEFs. For the two sample instrumental variables
(TSIV) model it is possible to show that the correct  ( ) is an implication of the structure
of the …rst stage relationship between the endogenous right hand side variable, , and the
instrument vector,  .
     If both Assumptions 2.1 and 3.1 hold the Appendix shows that b is asymptotically




                                                                  17
linear with representation

                      p                      1 X     e
                           (b ¬   0)   =p             (    0)   +  (1)
                                               =1



from which our next Theorem directly follows.


Theorem 3.2 (Local Semiparametric Efficiency) Suppose that Assumption 2.1 and
additional regularity conditions hold, then for b the solution to (13), b is locally
                                        p                     ¬
e¢ cient at Assumption 3.1 such that  (b ¬ 0 ) ! N 0 I ( 0 )¬1 with I ( 0 ) as
de…ned in Theorem 2.1.


Proof. See Appendix A.
   Our e¢ ciency bound calculation, Theorem 2.1, gives the information bound for       0   with-
out imposing the additional auxiliary Assumption 3.1. This assumption imposes restrictions
on the joint distribution of the data not implied by the baseline model. If these restrictions
are added to the prior used to calculate the e¢ ciency bound, then it may be possible to
estimate   0   more precisely. Our estimator is not e¢ cient with respect to this augmented
model. Rather it attains the bound provided by Theorem 2.1 if Assumption 3.1 happens to
be true in the population being sampled from, but is not part of the prior restriction used
to calculate the bound. Newey (1990, p. 114), Robins, Rotnitzky and Zhao (1994, p. 852
- 3) and Tsiatis (2006) discuss the concept of local e¢ ciency in detail. In what follows we
will, for brevity, say b is locally e¢ cient at Assumption 3.1. The form of the variance
bound when semiparametric, or parametric (as in Assumption 3.1), restrictions on  () and
 () are maintained as part of the prior restriction is unknown. Graham (2011) studies
such restrictions in the missing data context.
   Next we give our double robustness result. Here our result is slightly less general than
similar results in the missing data literature, but nevertheless may be useful in practice.

                                                                                              
Theorem 3.3 (Double Robustness) Under parts (i) to (iv) of Assumption 2.1, b !


                                               18
 0   with a limiting normal distribution if either (a) part (v) of Assumption 2.1 also holds or
                                              exp()
(b) the analyst chooses  () =              1+exp()
                                                         and Assumption 3.1 holds.


Proof. See Appendix A.
     Theorem 3.3 indicates that the advantage of choosing  ( ) with Assumption 3.1 in mind
is twofold. Under the baseline model de…ned by Assumption 2.1, Theorem 3.2 implies that
b will have low sampling variation if  () = E [                           (     0 )j    = ] and  () =
E[       (    0 )j       = ] are approximately linear in  () (see also part (iii) of Theorem
3.1). This is the case covered by part (a) of the Theorem. Now consider the case where
the analyst misspeci…es the propensity score model, but Assumption 3.1 holds, part (b) of
Theorem 3.3 indicates that b will remain consistent for                           0    in this case if the analyst
chooses  () to take the logit form. We emphasize that the true propensity score model
may or may not be of the logit form.
     The peculiar feature of Theorem 3.3, relative to analogous results in the missing data
literature (e.g., Tsiatis, 2006), is the requirement that the assumed propensity score take the
logit form. To understand this requirement note that, in general, (7) will be an inconsistent
estimate of the study population distribution of  when the propensity score is misspeci-
…ed. Calibrating the study and auxiliary tilts to moments of this distribution will therefore
typically produce an inconsistent estimate of                     0.   However when condition (b) of Theorem
3.3 holds we have, from the estimating equations for the propensity score parameter,

                                      
                                   1 X
                                          ¬   ( )0 b                 ( ) = 0                         (18)
                                    =1


Now consider the mean of  ( ) with respect to be (). Using (18), and the fact that
                                   P              0b
                                                           P
                                                           
 ( ) contains a constant so that 
                                    =1 ((  )    ) =    , we have the equalities
                                                                            =1


                   
                   X                       
                                           X                                         P
                                                  (( )0b  )                            ( )
                         be    ( ) =         P                  ( ) =             =1
                                                                                          P          
                   =1                     =1      (( )0b  )
                                                   =1                                     =1 



                                                             19
                                                                 P
                                                                 
                                                                                  
Therefore, under the conditions of part (b) of Theorem 3.3,            be  ( ) ! E [ ( )] irre-
                                                                 =1
spective of whether the propensity score is correctly model. This implies that the study and
auxiliary tilts will be correctly calibrated such that, when Assumption 3.1 holds, b will
remain consistent for   0   Note that this estimate of E [ ( )] will not be e¢ cient when the
propensity score is misspeci…ed.
   Although the propensity score is not ancillary in the data combination problem, our
estimator remains consistent in the presence of propensity score misspeci…cation when  ()
takes the logit form. It is an open question where there exist a locally e¢ cient and doubly
robust estimator under non-logit parametric forms for the propensity score.
   The alternative estimator, which replaces maximum likelihood (ML) propensity score …t
computed in the …rst step of our procedure with the method of moments (MM) one

                                
                             1 X
                                    ¬   ( )0 b       ( ) = 0
                              =1


will be double robust but not locally e¢ cient (unless a logit form for  () is maintained
as part of Assumption 2.1, in which case the ML and MM …ts coincide). More generally
there is a tension between e¢ ciency, which requires using the MLE of the propensity score
for reweighting, and robustness to propensity score misspeci…cation.


Implications for practitioners Collectively Theorems 3.1 to 3.3 suggest several useful
guidelines for empirical researchers. First, when overlap is good, or equivalently the propen-
sity score weights 0 ( )  (1 ¬ 0 ( )) do not take very large values, Theorems 3.1 to 3.3
provide a very strong theoretical case for using AST in practice. If Assumption 3.1 happens
to be true in the sampled populations, then AST will be more e¢ cient than the propen-
sity score reweighting approach of Abadie (2005). This result is analogous to the enhanced
e¢ ciency of the Augmented Inverse Probability Weighting (AIPW) estimator of Robins,
Rotnitzky and Zhao (1994) relative to conventional Inverse Probability Weighting (IPW)



                                                20
in the missing data context. In practice high levels of precision will be observed whenever
 () and  () are reasonably well approximated by a linear combination of the elements
of  ()  A further advantage of the AST procedure is that, if the propensity score is in-
advertently misspeci…ed, AST will nevertheless remain consistent for       0   if Assumption 3.1
holds (and the analyst works with a logit form for  ()).
    In settings with poor overlap, the AST estimator may be highly variable and, in extreme
cases, may not even exist. To understand this last observation consider the case where  ()
takes the logit form. In that case the computation of the auxiliary tilt requires that the study
sample mean of  ( ) lie within the convex hull of the auxiliary sample. If the study and
auxiliary distributions of  are very di¤erent from one another, this convex hull condition
may fail in practice even if Assumption 2.1 holds in the population. We do not view this
as a weakness of our procedure, rather such situations alert the researcher to the fragility of
identi…cation when overlap is poor (cf., Khan and Tamer, 2010). When overlap is poor direct
imputation approach may be preferable (e.g., Kline, 2011; Chen, Hong and Tarozzi, 2008).
However imputation will be very sensitive to violations of Assumption 3.1; this limitation is
illustrated by our Monte Carlo experiments below.
    The computational algorithm detailed in the Supplemental Web Appendix is designed
to work well in situations where the convex hull condition is "nearly" violated and we rec-
ommend its routine use. For covariance matrix estimation we recommend use the textbook
formulae for the GMM estimator based on the moment vector implied by (8), (9), (11) and
(13) above and explicitly de…ned in the Appendix.



4     Application and Monte Carlo experiments

Empirical application Neal and Johnson (1996) study the role of ‘pre-market’(i.e., ac-
quired prior to age 18) di¤erences in cognitive achievement in explaining di¤erences in earn-
ings between young Black and White men. Using a sample of employed Black and White



                                              21
males drawn from the National Longitudinal Survey of Youth 1979 (NLSY79), Neal and
Johnson (1996) compute the least squares …t of the logarithm of hourly wages on a con-
stant, a black dummy, age, and Armed Forces Quali…cation Test (AFQT) percentile score
measured at age 16 to 18. They …nd that the coe¢ cient on the black dummy variable drops
by two thirds to three quarters when AFQT score is included as a covariate. On the basis
of this …nding they argue that di¤erences in the rate of cognitive skill acquisition across
Blacks and White prior to age 18, due to di¤erences in family background, school quality
and neighborhood characteristics, explains a substantial portion of subsequent Black-White
wage inequality. We do not provide an assessment of this interpretation here, rather our goal
is to illustrate the use of AST in a familiar setting.
   Let  denote real average wages from 1990 to 1993 for a random draw from the population
of Black men aged 16 to 18 in 1979 and residing in the United States. This population
corresponds to our study population of interest. Let  denote real wages for a random draw
from the population of White men aged 16 to 18 in 1979 and residing in the United States.
This corresponds to our auxiliary population. Let  be a vector including year of birth
and AFQT score (We transform the percentile scores used by Neal and Johnson (1996) onto
the real line using the inverse standard normal CDF). We compare features of the observed
distribution of Black wages with those of a hypothetical White population whose age and
AFQT distribution coincides with that of the Blacks (i.e., with study population’s). These
types of hypothetical comparisons underlie Oaxaca decompositions, as used in labor and
health economics, and similar exercises undertaken in demography (e.g., Kitagawa, 1964).
Barsky, Bound, Charles and Lupton (2002) and Fortin, Lemieux and Firpo (2010) survey
the application of decomposition methods in economics.
   Our sample closely resembles that used in Johnson and Neal (1998). It includes 1,371
measurements of real wages, race, age and AFQT scores drawn from the NLSY79. Through-
out we replace the empirical measure of our sample with the NLSY79 base year sampling
weights (although this adjustment has little e¤ect on our results). The age distributions


                                               22
for Blacks and Whites in the merged sample are, as would be expected, quite similar. The
distribution of AFQT scores across the two groups are quite di¤erent. The mean Black score
is approximately one standard deviation lower than the mean White score. The two distri-
butions also substantially di¤er in their second, third and fourth moments (not reported).
   Panel A of Table 1 reports estimates of mean log Wages for Blacks (Column 1), as well as
the Black-White average di¤erence (Column 2). On average, Blacks earn almost 28 percent
less per hour than Whites in our sample. Panel A also reports estimates of the CDF of
the Black wage distribution at selected points, and the corresponding Black-White CDF
di¤erences. For example, while over 45 percent of Blacks earn less than $7.50 per hour in
our sample, fewer than 30 percent of Whites do (Table 1, Row 3). Inspection of the CDF
di¤erences indicates that, while the distributions are most di¤erent at the lower wage levels,
di¤erences exist across the entire support of wages.
   Panel B of Table 1 reports average wage di¤erences between Blacks and a hypothetical
population of Whites whose distribution of age and AFQT score coincides with the Black
distribution. This allows for a comparison between Black and White wages that ‡exibly
controls for di¤erences between the two populations in age and AFQT score.
   In Column 1 of Panel B we report age- and AFQT-adjusted di¤erences in mean wages and
wage CDFs based on the conditional expectation projection (CEP) estimator of Chen, Hong,
and Tarozzi (2008). Our implementation of their procedure models the conditional expecta-
tion functions (CEFs) of  and  given  as a separable functions of a constant, two year
of birth dummies, a quadratic polynomial in transformed AFQT score, and twelve dummy
variables for the transformed AFQT score lying respectively below ¬2 ¬175     025 05
Let  ( ) be the vector containing all these functions of  . In principle, if the dimension
of the approximating model is allowed to grow with the sample size, the Chen, Hong, and
Tarozzi (2008) estimator is consistent for, and e¢ cient under, all data generating processes
satisfying parts (i) to (iv) of Assumption 2.1. In small samples the performance of the
estimator is heavily dependent on the quality of the two CEF approximations.


                                              23
        Table 1: Raw and adjusted di¤erences in Black versus White hourly        wages
                                 Panel A                      Panel B
                             (1)         (2)          (1)        (2)                (3)
                           Black       B¬W          CEP        PSR                AST
                            6749      ¬0279      ¬01108    ¬01072            ¬01052
    Average (log(Wage))
                           (0021)     (0026)     (00348)   (00303)           (00298)
                           00801      00566       00243     00246             00278
    Pr (Wage $500)
                          (00125)    (00135)     (00216)   (00193)           (00187)
                           04505      02948       01780     01737             01757
    Pr (Wage $750)
                          (00244)    (00275)     (00391)   (00355)           (00350)
                           06590      02691       00987     00964             00903
    Pr (Wage $1000)
                          (00244)    (00300)     (00406)   (00358)           (00353)
                           08020      02001       00417     00386             00348
    Pr (Wage $1250)
                          (00198)    (00265)     (00328)   (00288)           (00284)
                           08896      01426       00176     00129             00109
    Pr (Wage $1500)
                          (00153)    (00219)     (00238)   (00203)           (00202)

Notes: Results based on an extract of 1,371 Black and White men ages 16 to 18 in 1979 from the
NLSY79. Estimated standard errors, which account for within-household dependence in outcomes
across siblings, are reported in parentheses.


   Column 2 of Panel B implements the propensity score reweighting (PSR) estimator of
Hirano and Imbens (2001) and Abadie (2005). We model the propensity score as a logit
function with an index linear in  ( ) as de…ned above for the CEP estimator. The PSR
estimates are very close in magnitude and precision to the CEP estimates.
   Column 3 of Panel B implements our AST procedure using the same choice of  ( )
and  ( ) =  ( )  This choice ensures that the study and auxiliary sample tilts share
the following features with the e¢ cient distribution function estimate of  : (i) the mar-
ginal year of birth distributions coincide, (ii) the means and variances of the transformed
AFQT score coincide, (iii) the probability masses assigned to the intervals de…ned by the
¬2 ¬175     025 05 grid of AFQT score intervals coincide. Figure 1 plots undersmoothed
kernel density estimates of the actual Black and White AFQT score densities; the two distri-
butions are very di¤erent from one another. The …gure also plots a density estimate based
on the auxiliary sample tilt. This corresponds to the AFQT score density in the hypothetical
comparison population of Whites. As is evident from the …gure, our choice of  ( ) is rich


                                              24
Figure 1: AFQT Densities
Notes: The …gure plots kernel density estimates of the actual Black and White AFQT score
distributions as well as an estimate based on the auxiliary sample tilt. A Gaussian kernel is
used with a bandwidth equal to 1/2 of Silverman’s ‘rule-of-thumb’choice. Undersmoothing
highlights the ability of the auxiliary tilt to match local features of the Black AQFT density.


enough to closely match this density with its target Black one.
   After adjusting for age and AFQT di¤erences we …nd that, while a Black-White residual
log wage CDF gap remains at middle parts of the wage distribution, it disappears at the low
and high ends of this distribution. The average log wage gaps falls, after adjusting for age
and AFQT di¤erences, from ¬0279 to ¬0111.
   While the AST point estimates are similar to the corresponding CEP and PSR ones, their
estimated sampling precision is uniformly superior (as Theorem 3.2 would suggest).        The
close correspondence between the CEP, PSR and AST point estimates in our application
likely re‡ects a combination of two factors. First, while the AFQT distributions across Blacks
and Whites di¤er dramatically, the support of the Black distribution is clearly contained
within that of the White distribution. Hence part (iii) of Assumption 2.1 is well satis…ed.
Second the approximating models underlying each of the estimators are quite ‡exible. In
settings where overlap is weaker, and/or the approximating models more parsimonious (as
would be required when the dimension of  is large), we would expect the three estimators
to more often yield di¤erent point estimates depending on the true data generating process.


                                              25
                          Table 2: Parameter values for Monte Carlo experiments
                                 Design    (1)      (2)     (3)     (4)
                                   2
                                           1      23       1      23
                                   2
                                        34823   26590  17496  09253
                                   2        0        0      ¬1      ¬1



Monte Carlo We now report on a number of Monte Carlo experiments we conducted to
verify the theoretical properties described in Theorems 3.1 to 3.3. In particular we wish
to assess the relevance of our theoretical robustness and e¢ ciency results. To do this we
consider a stylized program evaluation setting. The analyst wishes to estimate the average
treatment e¤ect on the treated (ATT).
   In each of our …rst set of experiments we assume that  is distributed according to a
truncated normal distribution, with support [¬ ]  in both the study (treated) and aux-
iliary (control) populations. The location and scale parameters of these two distributions,
                           2                      2
respectively (           )   and (            ),   may di¤er. We assume a multinomial sampling scheme:
with probability 0 = 12 a draw of (  ) is taken at random from the study (treated)
population, otherwise a draw of (  ) is taken from the auxiliary (control) population.
Finally we assume that  and , which play the roles of the outcome under treatment and
control, are generated according to

                            ¬        2
        j              N 0      
                                               ¬                               h¬                                      i
                                                                                                      2       2                2
       j               N       0+         1  ¬          j=1       +   2   ¬       j=1           ¬    j=1             


                                2
where        j=1   and         j=1   are the study population mean and variance of  (which di¤er
                     2
from       and         due to truncation).
   The target parameter is                    0   = E [ ¬ ] =             0.   The propensity score induced by these
designs is of the logit form with an index quadratic in  :

                                                  ¬                                          2   ¬1
                                  0 () = 1 + exp ¬                 0   ¬    1    ¬   2            

                                                                 26
                                                          2                  2
where   0,       1   and     2   are functions of (     )   and (       )       (cf., Anderson, 1982). When
the study and auxiliary population distributions of  have di¤erent means, but a common
variance, the logit index will be linear in  . When both the means and variances di¤er,
then the index will generally be nontrivially quadratic in  .
                                                                                                            2
   Across all designs we assume a sample size of  = 1 000 and set                                 = 0       = 1      =
                                    2                              2
¬12   0   = 0      1   = 12,       = 1 and  = 3 We vary        and        2   across designs to, respectively,
induce nonlinearity in the (index of) the propensity score and E [                          (    0 )j  ]   =  ( ).
             2
We vary         across designs to keep the variance bound …xed. Across each of our designs
an e¢ cient estimator (under Assumption 2.1) will have an asymptotic standard error of
q
  I ( 0 )¬1 1000 = 110
   Table 2 gives the parameter con…gurations for each of four Monte Carlo designs. In the
…rst design both the propensity score, 0 (), and  () are ‘linear’in  (for 0 () ‘linear’
means linear in the logit index). In the second design the propensity score is quadratic in
, while  () remains linear. In Design three the reverse is true, while in Design four both
objects are ‘quadratic’. Across each design we implement the AST estimator with  ( ) being
the logit function and  ( ) =  ( ) = (1  )0 . For the conditional expectation projection
(CEP) estimator we proceed ‘as if’E [j  ] were linear in  , while our implementation of
propensity score reweighting (PSR) uses a logit propensity score with a linear index.
   Our AST estimator is consistent for                0   in designs 1 through 3. CEP is consistent in
designs 1 and 2, but inconsistent in design 3. The PSR estimator is consistent in designs
1 and 3, but inconsistent in design 2. All estimators are inconsistent in design 4 due to
the nonlinearity of both 0 () and  (). Table 3 reports the results of our experiments.
Column 1 lists a ‘pencil and paper’asymptotic bias calculation, while Column 2 gives the
median bias across 5,000 Monte Carlo replications (in both cases bias is scaled by the ‘pencil
and paper’asymptotic standard error reported in Column 3). As predicted, AST is median
unbiased (up to simulation error) in designs 1 through 3. In contrast, PSR is severely biased
in design 2 and CEP in design 3. As expected, all estimators perform poorly in design


                                                          27
                                     Table 3: Monte Carlo results
                 (1)           (2)        (3)       (4)          (5)        (6)
                                                                                      (7)
                Asym.         Med.       Asym.     Median        Std.     Cov. of
                                                                                     RMSE
                 Bias         Bias        SE.       SE.          Dev.     95% CI
                                 Design 1: 0 () linear,  () linear
       CEP       0.0000       0.0097      0.0997        0.0996   0.0986     0.9526   0.0986
       PSR       0.0000       0.0164      0.1007        0.1006   0.1005     0.9506   0.1005
       AST       0.0000       0.0055      0.0100        0.0998   0.0998     0.9540   0.0997
                               Design 2: 0 () quadratic,  () linear
       CEP       0.0000       0.0137      0.0925        0.0924   0.0947     0.9480   0.0947
       PSR       0.5053       0.5437      0.0905        0.0911   0.0912     0.9126   0.1039
       AST       0.0000       0.0169      0.0941        0.0931   0.0941     0.9470   0.0942
                               Design 3: 0 () linear,  () quadratic
       CEP      -1.6125   -2.0082         0.1309        0.1296   0.1627     0.6204   0.3111
       PSR       0.0000   -0.0137         0.1063        0.1037   0.1068     0.9420   0.1068
       AST       0.0000   -0.0266         0.1076        0.1054   0.1081     0.9416   0.1081
                          Design 4: 0 () quadratic,  () quadratic
       CEP      -4.6038   -6.7095         0.1192        0.1157   0.1728     0.0010   0.8196
       PSR      -3.0049   -3.1031         0.0847        0.0821   0.0858     0.1694   0.2670
       AST      -2.8789   -2.9313         0.0941        0.0873   0.0953     0.1726   0.2908



4. These bias properties are re‡ected in the coverage of standard, Wald-based, 95 percent
con…dence intervals for   0   (Column 6). By comparing columns 1 and 2 and columns 3 and
5, we see that –for the designs considered here –the …nite sample distributions of all of the
estimators are very well approximated by their asymptotic counterparts.



5    Summary

When the propensity score is parametrically speci…ed information in both the study and
auxiliary samples may be used to form an e¢ cient estimate of  , the variable common to
both datasets. An intuition for this insight follows from recognizing that, under part (v)
of Assumption 2.1, the auxiliary sample is equivalent to a biased sample from the study
population with the biasing function known up to a …nite dimensional parameter. Using
this e¢ cient distribution function estimate we tilt the propensity score reweighting (study



                                                   28
population) distribution function estimates of (  ) and (  ) so that they share certain
moments in common. By choosing these moments carefully (i.e., with reference to Assump-
tion 3.1) we can produce a locally e¢ cient estimate of      0   Even if the parametric relationship
between the study and auxiliary populations, as embodied in the propensity score model, is
misspeci…ed, AST remains consistent for        0   if Assumption 3.1 holds.
    To our knowledge we are the …rst to propose a locally e¢ cient estimator for the class
of data combination problems de…ned by Assumption 2.1. Our procedure also has a double
robustness property. Our results provide a useful complement to the work of Robins, Rot-
nitzky and Zhao (1994), Tan (2006) and others for missing data problems. Relative to Chen,
Hong and Tarozzi (2008), who do provide explicit results for data combination problems
(their so called ‘verify-out-of-sample’ case), our approach may be useful when  is high
dimensional such that their method, which requires nonparametric estimation of  () and
 (), is impractical.
    In future work it would be useful to study data dependent methods for choosing  ( ) 
Similarly it would be interesting to construct a locally e¢ cient estimator with minimal
variance across all estimators based on the linear approximating models  ( ) '               ( )

and  ( ) '      ( )    In the missing data context such estimators are called "improved
locally e¢ cient" (e.g., Tan (2010)).



A      Proofs

Proof of Theorem 3.1: The AST procedure coincides with a just identi…ed GMM estima-
tor based on the dim ( ( ))+2 dim ( ( ))+dim ( 0 ) vector of moment functions  (           0)




                                                   29
                            0 0
with   = ( 0     0
                  
                       0
                          )  This vector of moment functions is composed of the subvectors:

                                                    ¬
                                             ¬   ( )0 0                   ¬
                1 ( 0 )        =     ¬     0   ¬       ¬      0         1  ( )0 0  ( )
                dim(( )) 1            ( ) 0 1 ¬   ( ) 0
                                         0                                       1
                                       1 @             1¬                            ¬
           2 (   0  0 )      =                                           ¬ 1A   ( )0 0  ( )
             dim(( )) 1             0 1 ¬   ( )0 +  ( )       0
                                                           0              0
                                         0                                    1
                                       1 @                                       ¬
           3 (   0  0 )      =                                       ¬ 1A   ( )0 0  ( )
             dim(( )) 1             0   ( )0 +  ( )    0
                                                      0            0
                                                 ¬      0
                                                 ( ) 0
 4 (     0  0  0    0)    =                                      (  0 )
          dim( 0 ) 1                  0   ( )0 +  ( )0
                                                    0          0
                                                         ¬    0
                                        1¬             ( ) 0
                                      ¬                                           (  0 ) 
                                         0 1 ¬   ( )0 +  ( )0
                                                                          0            0


                                               0
   Let  = E [ (              0 )            ] ; a standard argument (e.g., Newey and McFadden, 1994)
gives, under regularity conditions, the asymptotically linear representation

                                                                     
                                                                                       !
                        p                                        1 X
                             b¬           0        = ¬   ¬1
                                                                p        (    0)       +  (1)    (19)
                                                                   =1

The in‡uence function for b corresponds to the last  elements of (19). By tedious, but
straightforward, calculation we can show that this subvector equals

                              
                           ¬1 X
       p                ¬44                                           ¬1
            (b ¬ 0 ) = p          4 (  0  0  0  0 ) ¬ 41 11   1 (  0 )                  (20)
                           =1
                              ¬1
                                  ¬     ¬1
                        +42 22   21 11  1 (  0 ) ¬ 2 (  0  0 )
                               ¬1
                                  ¬      ¬1
                        +43 33   31 11  1 (  0 ) ¬ 3 (  0  0 ) +  (1) 


where  equals the expected value of the derivative of the   subvector of  ( ) with
respect to the  subvector of                     evaluated at     =   0.

   Under part (v) of Assumption 2.1 the Information Matrix equality gives 11 = ¬E [S S0 ].




                                                                30
Calculation gives 41 equal to

                                    1      1¬                                    0
                            41 =      E                            (    0) S                      (21)
                                    0   1 ¬ 0 ( )

Using this result, iterated expectations and part (ii) of Assumption 2.1 we then get


                         ¬1                            1          1¬
                   ¬41 11 1 (            0)   =      E                 ( ) S      
                                                       0       1 ¬  ( )

Evaluating 21 yields, after some manipulation,

                                  1            1¬
                    21 = ¬          E                   ¬ 1 0 ( )  ( ) S0                          (22)
                                  0         1 ¬ 0 ( )

                 ¬                    ¬
where 0 ( ) =   ( )0     0    =   ( )0         0   +  ( )0   0    These results imply that


                  ¬1                     1               1¬
             21 11 1 ( ) =             E                      ¬ 1 0 ( )  ( ) S           
                                         0            1 ¬ 0 ( )

Similar calculations give

                                    1              
                      31 = ¬          E                ¬ 1 0 ( )  ( ) S0                           (23)
                                    0          0 ( )

yielding
                    ¬1                       1                
               31 11 1 (       0)   =      E                  ¬ 1 0 ( )  ( ) S       
                                             0            0 ( )

   Evaluating 22 and 42 yields

                      1     0 ( )      ¬
             22 =      E             1  ( )0 0  ( )  ( )0                                        (24)
                     0   1 ¬ 0 ( )
                        1     0 ( )      ¬
             42   = ¬ E                1  ( )0 0  (  0 )  ( )0                               (25)
                       0   1 ¬ 0 ( )




                                                           31
Using (24) and (25) and iterated expectations we get

                                     0 ( )     ¬
                     ¬1
                42 22 = ¬E                   1  ( )0       0    ( )  ( )0
                                   1 ¬ 0 ( )
                                                                                           ¬1
                                     0 ( )     ¬
                                 E             1  ( )0       0    ( )  ( )0
                                   1 ¬ 0 ( )
                               
                               = ¬    




as de…ned in (14) of the main text.
   Now consider 33 and 43 ; we have

                             1      ¬
                    33 = ¬     E 1  ( )0       0     ( )  ( )0                                 (26)
                             0
                             1      ¬
                    43   = ¬ E 1  ( )0         0        (    0 )  ( )
                                                                                   0
                                                                                                      (27)
                             0

Using (26) and (27) and iterated expectations we get

                                ¬
                       ¬1
                  43 33 = E 1  ( )0 0  ( )  ( )0
                                  ¬                                      ¬1 
                             E 1  ( )0 0  ( )  ( )0                  =          




also as de…ned in (14) of the main text.
   Recalling the de…nitions,  ( ) =        ( )   and  ( ) =          ( )       substituting the
expressions derived immediately above into (20), and rearranging, yields the form of the
in‡uence function stated in the theorem.
   Now recall the de…nitions of  (  ) and  (  ) given in (15) and (16) of the main
text. By the de…nition of the LP operator we have that E [ (  ) S0 ] = E [ (  ) S0 ] =
0 This follows since  (  ) and  (  ) are linear prediction errors, with S the vec-
tor of predictors. The conditional mean zero property of the score function also yields the
restrictions E [  (  )j  ] = E [  (  )j  ] = 0 From these properties, and direct




                                              32
calculation, we have that


                            E    e
                                     (   0 ) f   (  ) ¬  (  )g = 0


from which the claimed form of the asymptotic variance of                  0   follows.
   Let  be a vector of constants. By linearity of the LP operator, the Cauchy-Schwartz
inequality, and recalling that  (  ) =  (  ) ¬  (  ), we have that


 0 V ( (  )) 
                                1       1¬
                      0 V                        ¬ 1 0 ( ) f ( ) ¬  ( )g
                                0    1 ¬ 0 ( )
                                                  1    
                                              +             ¬ 1 0 ( ) f ( ) ¬  ( )g 
                                                 0 0 ( )

This bound will hold with equality if  ( )               ( ) since, by the de…nitions of               and     ,

we will have (in that case) the zero covariance results

                                            0 ( )     ¬
               E ( ( ) ¬  ( ))                  1  ( )0       0        ( )0     = 0                    (28)
                                          1 ¬ 0 ( )
                                                        ¬
                                E f ( ) ¬  ( )g 1  ( )0       0        ( )0     = 0


Iterated expectations and (28) then give

                               
                             E      ¬ 1 0 ( ) f ( ) ¬  ( )g S0
                            0 ( )
                                                ¬
                      = E f ( ) ¬  ( )g 1  ( )0 0  ( )0 = 0                                            (29)


and also

                            1¬
                E                     ¬ 1 0 ( ) f ( ) ¬  ( )g S0
                          1 ¬ 0 ( )
                      "                                                                        #
                                     ( ¬ 0 ( ))2 ¬          0
            = ¬E f ( ) ¬  ( )g               2 1  ( )                      0     ( )0 = 0             (30)
                                     (1 ¬ 0 ( ))


                                                        33
Equations (29) and (30) imply that, if  ( )        ( ), then, after manipulation,

                                            1      0 ( )
                         V ( (  )) =     2
                                               E                   0
                                                                                                      (31)
                                            0   1 ¬ 0 ( )

with the right-hand-side of (31) an upper bound otherwise. Recalling the de…nition of given
in the statement of the Theorem, and making use of the various compact support conditions
embedded in Assumption 2.1, we get the bound

                                               2
                                                         0 ( )
                       0 V ( (  ))           E               0 0 
                                             20       1 ¬ 0 ( )

from which (17) follows directly.


Proof of Theorem 3.2: Under Assumption 3.1, we have that                        =      and      =     .

This implies that  (  ) and  (  ) are identically equal to zero. The result then
follows directly from Theorem 2.1.


Proof of Theorem 3.3: Asymptotic normality follows from standard results. Consistency
under part (a) is a consequence of Equation (4) in the main text. Showing consistency under
part (b) is more complicated. Denote the probability limits of b, b ,and b when part (v) of
                                                                              ¬
Assumption 2.1 fails to hold by, respectively ,  , and  . Let  ( ) =   ( )0       and
             ¬
 ( ) =   ( )0 +  ( )0  for  =  . If  ( ) takes the logit form, then  ( )
will satisfy the population restriction E [1 (      )] = E [( ¬  ( ))  ( )] = 0 so that,
using iterated expectations and rearranging, we have the equality.

                                                        ( )
                           E [ ( )j  = 1] = E               ( )                                  (32)
                                                         0




                                               34
We also have E [2 (                 )] = E [3 (            )] = 0, which, respectively multiplying by

    and        (using Assumption 3.1), gives the additional equalities:

                                1¬
                         E                ( )  ( )              = E [ ( )  ( )]                 (33)
                             1 ¬  ( )
                                    
                              E           ( )  ( )              = E [ ( )  ( )]                (34)
                                  ( )

Using (32), (33), (34), Assumption 3.1, iterated expectations, and part (ii) of Assumption
2.1 yields

                                                               ( )
                     E [4 (                    )] = E        f ( ) ¬  ( )g
                                                                0
                                                                         ( )
                                                         = (  ¬ ) E           ( )
                                                                          0
                                                         = E [ ( ) ¬  ( )j  = 1]

                                                         = E [ ( )j  = 1] 


which by part (i) of Assumption 2.1 is uniquely zero at                      =   0.




References

 [1] Abadie, Alberto. (2005). “Semiparametric di¤erence-in-di¤erences,” Review of Eco-
      nomic Studies 72 (1): 1 - 19.

 [2] Abadie, Alberto and Guido W. Imbens. (2006). “Large sample properties of matching
      estimators for average treatment e¤ects,”Econometrica 74 (1): 235 - 267.

 [3] Anderson, J.A. (1982). “Logistic discrimination,” Handbook of Statistics 2: 169 - 191
      (P.R. Krishnaiah & L.N. Kanal, Eds.). Amsterdam: North-Holland.

 [4] Angrist, Joshua D. and Alan B. Krueger. (1992). “The e¤ect of age at school entry on
      educational attainment: an application of instrumental variables with moments from


                                                            35
    two samples,”Journal of the American Statistical Association 87 (418): 328 - 336.

 [5] Barsky, Robert, John Bound, Kerwin Ko’Charles and Joseph P. Lupton. (2002). “Ac-
    counting for the black-white wealth gap: a nonparametric approach,” Journal of the
    American Statistical Association 97 (459): 663 - 673.

 [6] Bickel, Peter J., Ya’Acov Ritov and Jon A. Wellner. (1991). "E¢ cient estimation of
    linear functionals of a probability measure P with known marginal distributions," Annals
    of Statistics 19 (3): 1316 - 1346.

 [7] Björklund, Anders and Markus Jäntti. (1997). “Intergenerational income mobility in
    Sweden compared to the United States,” American Economic Review 87 (5): 1009 -
    1018.

 [8] Carroll, R. J. and M. P. Wand. (1991). “Semiparametric estimation in logistic measure-
    ment error models,”Journal of the Royal Statistical Society B 53 (3): 573 - 585.

 [9] Chen, Xiaohong, Han Hong and Alessandro Tarozzi. (2008). “Semiparametric e¢ ciency
    in GMM models with auxiliary data,”Annals of Statistics 36 (2): 808 - 843.

[10] Cheng, Jing, Dylan S. Small, Zhiqiang Tan, and Thomas R. Ten Have. (2009). “E¢ cient
    nonparametric estimation of causal e¤ects in randomized trials with noncompliance,”
    Biometrika 96 (1): 19 - 36.

[11] Currie, Janet and Aaron Yelowitz. (2000). “Are public housing projects good for kids?”
    Journal of Public Economics 75 (1): 99 - 124

[12] Dehejia, Rajeev H. and Sadek Wahba. (1999). “Causal e¤ects in nonexperimental stud-
    ies: reevaluating the evaluation of training programs,”Journal of the American Statis-
    tical Association 94 (448): 1053 - 1062.




                                               36
[13] Dinardo, John, Nicole M. Fortin, Thomas Lemieux. (1996). “Labor market institutions
    and the distribution of wages, 1973 - 1992: a semiparametric approach,” Econometrica
    64 (5): 1001 - 1044.

[14] Elbers, Chris, Jean O. Lanjouw and Peter Lanjouw. (2003). “Micro–level estimation of
    poverty and inequality,”Econometrica 71 (1): 355 - 364.

[15] Firpo, Sergio and Cristoph Rothe. (2013). "Semiparametric estimation and inference
    using doubly robust moment conditions," Mimeo.

[16] Fortin, Nicole, and Thomas Lemieux, and Sergio Firpo. (2011). “Decomposition meth-
    ods in economics,” Handbook of Labor Economics 4A: 1 - 102 (O. Ashenfelter & D.
    Card, Eds.). Amsterdam: North-Holland.

[17] Gilbert, Peter B., Subhash R. Lele and Yehuda Vardi. (1999). “Maximum likelihood
    estimation in semiparametric selection bias models with application to AIDS vaccine
    trials,”Biometrika 86 (1): 27 - 43.

[18] Graham, Bryan S. (2011). “E¢ ciency bounds for missing data models with semipara-
    metric restrictions,”Econometrica 79 (2): 437 - 452.

[19] Graham, Bryan S., Cristine Campos de Xavier Pinto, and Daniel Egel. (2012). “Inverse
    probability tilting for moment condition models with missing data,”Review of Economic
    Studies 79 (3): 1053 - 1079.

[20] Hahn, Jinyong. (1998). “On the role of the propensity score in e¢ cient semiparametric
    estimation of average treatment e¤ects,”Econometrica 66 (2): 315 - 331.

[21] Heckman, James J. and R. Robb. (1985). "Alternative Methods for Evaluating the Im-
    pact of Interventions". In Longitudinal Analysis of Labor Market Data, ed.., J. Heckman
    and B Singer Cambridge: Cambridge University Press.




                                            37
[22] Hellerstein, Judith K. and Guido W. Imbens. (1999). “Imposing moment restrictions
    from auxiliary data by weighting,”Review of Economics and Statistics 81 (1): 1 - 14.

[23] Hirano, Keisuke and Guido W. Imbens. (2001). “Estimation of causal e¤ects using
    propensity score weighting: an application to data on right heart catheterization,”
    Health Services and Outcomes Research 2 (3-4): 259 -278.

[24] Hirano, Keisuke, Guido W. Imbens and Geert Ridder. (2003). “E¢ cient estimation of
    average treatment e¤ects using the estimated propensity score,” Econometrica 71 (4):
    1161 - 1189.

[25] Hirano, Keisuke, Guido W. Imbens, Geert Ridder, Donald B. Rubin. (2001). “Combin-
    ing panel data sets with attrition and refreshment samples,”Econometrica 69 (6): 1645
    - 1659.

[26] Ichimura, Hidehiko and Elena Martinez-Sanchis. (2004). “Identi…cation and estimation
    of GMM models by a combination of two data sets,”Mimeo.

[27] Imbens, Guido W. (2004). "Nonparametric Estimation of Average Treatment E¤ect
    under Exogeneity: A Review," Review of Economic and Statistics 86(1): 4-29.

[28] Inoue, Atsushi and Gary Solon. (2010). "Two-sample instrumental variables estimators,"
    Review of Economics and Statistics 92 (3): 557 - 561.

[29] Johnson, William R. and Derek A. Neal (1998). “Basic skills and the black-white earn-
    ings gap,”The Black-White Test Score Gap: 480 - 500. (C. Jencks & M. Phillips, Eds.).
    Washington, D.C.: The Brookings Institution.

[30] Khan, Shakeeb and Elie Tamer (2010). “Irregular identi…cation, support conditions, and
    inverse weight estimation,”Econometrica 78 (6): 2021 - 2042.

[31] Kitagawa, Evelyn M. (1964). “Standardized comparisons in population research,” De-
    mography 1 (1): 296 - 315.

                                            38
[32] Kline, Patrick. (2011). “Oaxaca-Blinder as a reweighting estimator,” American Eco-
    nomic Review Papers & Proceedings, forthcoming.

[33] Lalonde, Robert J. (1986). “Evaluating the econometric evaluations of training pro-
    grams,”American Economic Review 76 (4): 604 - 620.

[34] Little, Roderick J.A. and Mei-Miau Wu. (1991). “Models for contingency tables with
    known margins when target and sampled populations di¤er,” Journal of the American
    Statistical Association 86 (413): 87 - 95.

[35] Neal, Derek A. and William R. Johnson. (1996). “The role of premarket factors in
    black-white wage di¤erences,”Journal of Political Economy 104 (5): 869 - 895.

[36] Newey, Whitney K. (1990). “Semiparametric e¢ ciency bounds,” Journal of Applied
    Econometrics 5 (2): 99 - 135.

[37] Newey, Whitney K. and Daniel McFadden. (1994). "Large sample estimation and hy-
    pothesis testing," Handbook of Econometrics 4: 2111 - 2245 (R.F. Engle & D.L. Mc-
    Fadden, Eds.). Amsterdam: North-Holland.

[38] Qin, Jing. (1998). “Inferences for case-control and semiparametric two-sample density
    ratio models,”Biometrika 85 (3): 619 - 630.

[39] Qin, Jing, and Biao Zhang. (2007). “Empirical-likelihood-based inference in missing
    response problems and its application in observational studies,” Journal of the Royal
    Statistical Society: Series B 69 (1): 101 –122.

[40] Qin, Jing, and Biao Zhang. (2008). “Empirical-likelihood-based di¤erence-in-di¤erences
    estimators,”Journal of the Royal Statistical Society B 70 (2): 329 - 349.

[41] Ridder, Geert and Robert Mo¢ tt. (2007). "The Econometrics of Data Combination,"
    Handbook of Econometrics 6B: 5469 - 5547 (J.J. Heckman & E.E. Leamer, Ed.). Ams-
    terdam: North-Holland.

                                             39
[42] Robins, James M., Andrea Rotnitzky and Lue Ping Zhao. (1994). "Estimation of regres-
    sion coe¢ cients when some regressors are not always observed," Journal of the American
    Statistical Association 89 (427): 846 - 866.

[43] Rosenbaum, Paul R. and Donald B. Rubin. (1983). “The central role of the propensity
    score in observational studies for causal e¤ects,”Biometrika 70 (1): 41 - 55.

[44] Tan, Zhiqiang. (2006). “A distributional approach for causal inference using propensity
    scores,”Journal of the American Statistical Association 101 (476): 1619 - 1637.

[45] Tan, Zhiqiang. (2010). "Bounded, e¢ cient and doubly robust estimation with inverse
    weighting", Biometrika, 97(3): 661-682.

[46] Tarozzi, Alessandro and Angus Deaton. (2009). “Using census and survey data to es-
    timate poverty and inequality for small areas,” Review of Economics and Statistics 91
    (4): 773 - 792.

[47] Tsiatis, Anastasios A. (2006). Semiparametric Theory and Missing Data. New York:
    Springer

[48] Wooldridge, Je¤rey M. (2002). Econometric Analysis of Cross Section and Panel Data.
    Cambridge, MA: MIT Press.




                                              40
